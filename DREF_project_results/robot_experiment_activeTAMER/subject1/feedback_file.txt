Current timestep = 0. State = [[-0.2032317   0.23001175]]. Action = [[ 0.06301153 -0.07999313  0.10210943  0.69323933]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [True, False, False, False, False, True]
State prediction error at timestep 0 is tensor(0.0605, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 0 of 1
Current timestep = 1. State = [[-0.20955272  0.2352755 ]]. Action = [[-0.23293771  0.16465878 -0.17285912 -0.90503055]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, False, True]
State prediction error at timestep 1 is tensor(0.0592, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1 of -1
Current timestep = 2. State = [[-0.21879077  0.24074745]]. Action = [[ 0.11273491 -0.17564566  0.23865744 -0.8214303 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, False, True]
State prediction error at timestep 2 is tensor(0.0395, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 2 of 1
Current timestep = 3. State = [[-0.21537147  0.21621141]]. Action = [[-0.15695702 -0.21790253 -0.08746356 -0.9405148 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, False, True]
State prediction error at timestep 3 is tensor(0.0291, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3 of 0
Current timestep = 4. State = [[-0.22820176  0.19843179]]. Action = [[-0.22495282 -0.08037092 -0.01218922 -0.96605897]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, False, True]
State prediction error at timestep 4 is tensor(0.0206, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 4 of -1
Current timestep = 5. State = [[-0.25769082  0.20235837]]. Action = [[-0.15818314  0.22562358 -0.17804173 -0.8143355 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, False, True]
State prediction error at timestep 5 is tensor(0.0290, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 5 of -1
Current timestep = 6. State = [[-0.27500075  0.2212975 ]]. Action = [[-0.22982733 -0.23627551 -0.01316921 -0.9404633 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, False, True]
State prediction error at timestep 6 is tensor(0.0181, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 6 of -1
Current timestep = 7. State = [[-0.26574925  0.21032196]]. Action = [[ 0.24866843 -0.16104779  0.10796064 -0.4370445 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, False, True]
State prediction error at timestep 7 is tensor(0.0189, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7 of 1
Current timestep = 8. State = [[-0.25540105  0.19460896]]. Action = [[-0.12283143 -0.00767058  0.23067284  0.6926651 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, False, True]
State prediction error at timestep 8 is tensor(0.0224, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 8 of -1
Current timestep = 9. State = [[-0.25077546  0.20536159]]. Action = [[0.11642486 0.22295201 0.18139392 0.40411592]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, False, True]
State prediction error at timestep 9 is tensor(0.0219, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 9 of -1
Current timestep = 10. State = [[-0.2426624   0.21773966]]. Action = [[-0.11528769 -0.11729009 -0.12373963 -0.86223596]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, False, True]
State prediction error at timestep 10 is tensor(0.0057, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 10 of 0
Current timestep = 11. State = [[-0.24154745  0.21318774]]. Action = [[ 0.09672427  0.01084447 -0.18684514 -0.2567131 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, False, True]
State prediction error at timestep 11 is tensor(0.0132, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 11 of -1
Current timestep = 12. State = [[-0.23479472  0.20741102]]. Action = [[ 0.13142574 -0.05327415  0.2441222  -0.14058995]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, False, True]
State prediction error at timestep 12 is tensor(0.0035, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 12 of 0
Current timestep = 13. State = [[-0.22785565  0.20231824]]. Action = [[-0.16009313 -0.07876678 -0.10969526 -0.09360325]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, False, True]
State prediction error at timestep 13 is tensor(0.0068, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 13 of -1
Current timestep = 14. State = [[-0.23764192  0.19252019]]. Action = [[-0.19466074 -0.09134457  0.20080477 -0.13983119]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, False, True]
State prediction error at timestep 14 is tensor(0.0012, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 14 of -1
Current timestep = 15. State = [[-0.25370914  0.18530901]]. Action = [[-0.2304131  -0.15222105 -0.22881432 -0.07936394]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, False, True]
State prediction error at timestep 15 is tensor(0.0063, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 15 of -1
Current timestep = 16. State = [[-0.2543307   0.18614927]]. Action = [[ 0.0304172   0.04985216 -0.1584313  -0.68929577]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, False, True]
State prediction error at timestep 16 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 16 of -1
Current timestep = 17. State = [[-0.2501059   0.19423863]]. Action = [[ 0.17637229  0.15628147  0.24498355 -0.9514652 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, False, True]
State prediction error at timestep 17 is tensor(0.0065, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 17 of -1
Current timestep = 18. State = [[-0.23918155  0.19926445]]. Action = [[ 0.09687352 -0.07991509  0.19045079  0.5825982 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, False, True]
State prediction error at timestep 18 is tensor(0.0023, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 18 of 1
Current timestep = 19. State = [[-0.22374244  0.19377097]]. Action = [[ 0.19659188 -0.04747885 -0.21361001  0.8043201 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, False, True]
State prediction error at timestep 19 is tensor(0.0020, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 19 of 1
Current timestep = 20. State = [[-0.1969516   0.18798628]]. Action = [[ 0.19786328 -0.02434206 -0.20155539  0.01216328]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, False, True]
State prediction error at timestep 20 is tensor(0.0008, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 20 of 1
Current timestep = 21. State = [[-0.1711351   0.18928534]]. Action = [[0.17407411 0.06819326 0.24146426 0.7175288 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, False, True]
State prediction error at timestep 21 is tensor(0.0005, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 21 of 1
Current timestep = 22. State = [[-0.15225616  0.18587393]]. Action = [[-0.10449955 -0.2103209   0.10472244  0.85860276]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [True, False, False, False, False, True]
State prediction error at timestep 22 is tensor(0.0010, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 22 of 1
Current timestep = 23. State = [[-0.15051974  0.17343669]]. Action = [[ 0.02593729  0.04673031 -0.0208782  -0.9080122 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [True, False, False, False, False, True]
State prediction error at timestep 23 is tensor(0.0119, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 23 of -1
Current timestep = 24. State = [[-0.15498497  0.1673102 ]]. Action = [[-0.1482696  -0.14771241 -0.00731014  0.41461658]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [True, False, False, False, False, True]
State prediction error at timestep 24 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 24 of 0
Current timestep = 25. State = [[-0.16401824  0.1467629 ]]. Action = [[-0.1136578  -0.18687183  0.1701467   0.6928241 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [True, False, False, False, False, True]
State prediction error at timestep 25 is tensor(0.0024, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 25 of 0
Current timestep = 26. State = [[-0.18307635  0.11872263]]. Action = [[-0.18368128 -0.18252611 -0.02531236 -0.27571988]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [True, False, False, False, True, False]
State prediction error at timestep 26 is tensor(0.0039, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 26 of 0
Current timestep = 27. State = [[-0.20823802  0.09307661]]. Action = [[-0.11129327 -0.14474213 -0.17150699  0.71136785]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [True, False, False, False, True, False]
State prediction error at timestep 27 is tensor(0.0056, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 27 of 0
Current timestep = 28. State = [[-0.22453943  0.08603024]]. Action = [[-0.19213547  0.07515919  0.1107108   0.9703145 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [True, False, False, False, True, False]
State prediction error at timestep 28 is tensor(0.0076, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 28 of -1
Current timestep = 29. State = [[-0.24068889  0.08593336]]. Action = [[-0.01429045 -0.07989168 -0.19910821 -0.17100173]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [True, False, False, False, True, False]
State prediction error at timestep 29 is tensor(0.0068, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 29 of -1
Current timestep = 30. State = [[-0.25468627  0.0792591 ]]. Action = [[-0.13105178  0.01473564  0.20913416  0.47921216]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [True, False, False, False, True, False]
State prediction error at timestep 30 is tensor(0.0104, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 30 of -1
Current timestep = 31. State = [[-0.26029432  0.06892823]]. Action = [[ 0.00997615 -0.17421466 -0.10052401 -0.96921664]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [True, False, False, False, True, False]
State prediction error at timestep 31 is tensor(0.0129, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 31 of -1
Current timestep = 32. State = [[-0.2651434  0.0650402]]. Action = [[0.15089598 0.19956213 0.20958322 0.6902697 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [True, False, False, False, True, False]
State prediction error at timestep 32 is tensor(0.0106, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 32 of 0
Current timestep = 33. State = [[-0.26078662  0.06780491]]. Action = [[-0.0568976  -0.179675   -0.06845345 -0.5024086 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [True, False, False, False, True, False]
State prediction error at timestep 33 is tensor(0.0092, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 33 of 0
Current timestep = 34. State = [[-0.2617499   0.04552453]]. Action = [[-0.045243   -0.1951001   0.02254787 -0.1500969 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [True, False, False, False, True, False]
State prediction error at timestep 34 is tensor(0.0125, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 34 of 0
Current timestep = 35. State = [[-0.26306942  0.03790271]]. Action = [[0.07802185 0.20230624 0.19010046 0.6598551 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [True, False, False, False, True, False]
State prediction error at timestep 35 is tensor(0.0122, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 35 of 0
Current timestep = 36. State = [[-0.25310665  0.04048766]]. Action = [[ 0.18890458 -0.1755988   0.03435552 -0.7841798 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [True, False, False, False, True, False]
State prediction error at timestep 36 is tensor(0.0114, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 36 of 1
Current timestep = 37. State = [[-0.23070449  0.03665407]]. Action = [[ 0.23231086  0.15993488 -0.09626415 -0.41295373]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [True, False, False, False, True, False]
State prediction error at timestep 37 is tensor(0.0084, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 37 of 1
Current timestep = 38. State = [[-0.20887184  0.03410627]]. Action = [[-0.03119987 -0.22049162 -0.11155394 -0.6799309 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [True, False, False, False, True, False]
State prediction error at timestep 38 is tensor(0.0066, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 38 of 1
Current timestep = 39. State = [[-0.20097065  0.01939124]]. Action = [[ 0.14677644 -0.02869469 -0.09212139  0.33315897]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [True, False, False, False, True, False]
State prediction error at timestep 39 is tensor(0.0077, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 39 of 1
Current timestep = 40. State = [[-0.1887256   0.00520307]]. Action = [[ 0.10275397 -0.18009557 -0.11730108  0.51044166]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [True, False, False, False, True, False]
State prediction error at timestep 40 is tensor(0.0087, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 40 of 1
Current timestep = 41. State = [[-0.17851451 -0.02139378]]. Action = [[-0.03019641 -0.15451658  0.24611104 -0.19770104]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [True, False, False, False, True, False]
State prediction error at timestep 41 is tensor(0.0107, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 41 of 0
Current timestep = 42. State = [[-0.17972514 -0.03505457]]. Action = [[-0.11582378 -0.02923436 -0.09156421 -0.6350526 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [True, False, False, False, True, False]
State prediction error at timestep 42 is tensor(0.0118, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 42 of -1
Current timestep = 43. State = [[-0.18240315 -0.03086307]]. Action = [[ 0.11492729  0.13931274 -0.14944388 -0.7670745 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [True, False, False, False, True, False]
State prediction error at timestep 43 is tensor(0.0122, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 43 of 1
Current timestep = 44. State = [[-0.18023798 -0.0142734 ]]. Action = [[ 0.01830807  0.17177153  0.0582301  -0.8492806 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [True, False, False, False, True, False]
State prediction error at timestep 44 is tensor(0.0109, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 44 of 0
Current timestep = 45. State = [[-0.17873558  0.00257681]]. Action = [[-0.13158987  0.02889672 -0.24202843 -0.4513396 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [True, False, False, False, True, False]
State prediction error at timestep 45 is tensor(0.0040, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 45 of 0
Current timestep = 46. State = [[-0.18857472  0.01394072]]. Action = [[-0.13845725  0.12057713  0.1539669   0.28687716]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [True, False, False, False, True, False]
State prediction error at timestep 46 is tensor(0.0038, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 46 of -1
Current timestep = 47. State = [[-0.20425081  0.02632646]]. Action = [[-0.11187656  0.01114729 -0.06505866  0.71384096]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [True, False, False, False, True, False]
State prediction error at timestep 47 is tensor(0.0040, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 47 of -1
Current timestep = 48. State = [[-0.20955399  0.01864298]]. Action = [[ 0.16883174 -0.15207712 -0.19434085  0.63127136]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [True, False, False, False, True, False]
State prediction error at timestep 48 is tensor(0.0050, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 48 of 1
Current timestep = 49. State = [[-0.21143033  0.00358385]]. Action = [[-0.18683735 -0.06669192 -0.23897728 -0.6875189 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [True, False, False, False, True, False]
State prediction error at timestep 49 is tensor(0.0040, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 49 of 0
Current timestep = 50. State = [[-0.21877082 -0.00493635]]. Action = [[-0.01220365 -0.04071639  0.17291862 -0.5693558 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [True, False, False, False, True, False]
State prediction error at timestep 50 is tensor(0.0049, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 50 of 0
Current timestep = 51. State = [[-0.23286718 -0.02179341]]. Action = [[-0.22763726 -0.20104894  0.09493649  0.5502918 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 51 is [True, False, False, False, True, False]
State prediction error at timestep 51 is tensor(0.0095, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 51 of -1
Current timestep = 52. State = [[-0.24398497 -0.05143315]]. Action = [[ 0.17903    -0.21762343 -0.22040078 -0.22992057]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 52 is [True, False, False, False, True, False]
State prediction error at timestep 52 is tensor(0.0105, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 52 of 0
Current timestep = 53. State = [[-0.23111618 -0.06413928]]. Action = [[0.17543611 0.12173748 0.19203135 0.81573033]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 53 is [True, False, False, False, True, False]
State prediction error at timestep 53 is tensor(0.0142, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 53 of 1
Current timestep = 54. State = [[-0.21577975 -0.07014556]]. Action = [[ 0.1010676  -0.2194092   0.14693975  0.0459398 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 54 is [True, False, False, False, True, False]
State prediction error at timestep 54 is tensor(0.0126, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 54 of 1
Current timestep = 55. State = [[-0.20752266 -0.07241075]]. Action = [[-0.02584389  0.23290446  0.01496074  0.09860682]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 55 is [True, False, False, False, True, False]
State prediction error at timestep 55 is tensor(0.0100, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 55 of 0
Current timestep = 56. State = [[-0.19650707 -0.05016157]]. Action = [[0.23568189 0.12576348 0.22649068 0.62917686]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 56 is [True, False, False, False, True, False]
State prediction error at timestep 56 is tensor(0.0108, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 56 of 1
Current timestep = 57. State = [[-0.17535478 -0.04598048]]. Action = [[-0.00948015 -0.14337018  0.08781064 -0.8851428 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 57 is [True, False, False, False, True, False]
State prediction error at timestep 57 is tensor(0.0095, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 57 of 0
Current timestep = 58. State = [[-0.16908628 -0.06348518]]. Action = [[ 0.14951044 -0.1974373  -0.16484083  0.92813516]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 58 is [True, False, False, False, True, False]
State prediction error at timestep 58 is tensor(0.0171, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 58 of 1
Current timestep = 59. State = [[-0.15478557 -0.08462729]]. Action = [[ 0.06523541 -0.05869842 -0.02175799  0.9210801 ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 59 is [True, False, False, False, True, False]
State prediction error at timestep 59 is tensor(0.0197, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 59 of 0
Current timestep = 60. State = [[-0.13888288 -0.08647871]]. Action = [[0.22316274 0.03963235 0.01254424 0.3716377 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 60 is [True, False, False, False, True, False]
State prediction error at timestep 60 is tensor(0.0139, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 60 of 1
Current timestep = 61. State = [[-0.1194099  -0.09169058]]. Action = [[-0.13243583 -0.14433324  0.08794951  0.01308978]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 61 is [True, False, False, False, True, False]
State prediction error at timestep 61 is tensor(0.0130, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 61 of -1
Current timestep = 62. State = [[-0.11486694 -0.11375795]]. Action = [[ 0.23586881 -0.16353713 -0.01166649  0.47819674]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 62 is [True, False, False, False, True, False]
State prediction error at timestep 62 is tensor(0.0211, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 62 of 0
Current timestep = 63. State = [[-0.10044001 -0.13366368]]. Action = [[-0.07467911 -0.08526568 -0.19924654  0.890921  ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 63 is [True, False, False, True, False, False]
State prediction error at timestep 63 is tensor(0.0306, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 63 of -1
Current timestep = 64. State = [[-0.10047956 -0.14680168]]. Action = [[ 0.01325074 -0.08944821  0.20394853 -0.45037746]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 64 is [True, False, False, True, False, False]
State prediction error at timestep 64 is tensor(0.0228, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 64 of -1
Current timestep = 65. State = [[-0.09482038 -0.15516226]]. Action = [[ 0.17770672 -0.02627142 -0.23692258 -0.5377398 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 65 is [True, False, False, True, False, False]
State prediction error at timestep 65 is tensor(0.0240, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 65 of 0
Current timestep = 66. State = [[-0.08561819 -0.16462322]]. Action = [[-0.12337154 -0.11025511 -0.23293748 -0.75698936]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 66 is [True, False, False, True, False, False]
State prediction error at timestep 66 is tensor(0.0299, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 66 of -1
Current timestep = 67. State = [[-0.09465162 -0.17968957]]. Action = [[-0.17761727 -0.04092449 -0.21955022 -0.25096154]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 67 is [True, False, False, True, False, False]
State prediction error at timestep 67 is tensor(0.0252, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 67 of -1
Current timestep = 68. State = [[-0.10679567 -0.17491722]]. Action = [[-0.07052428  0.22832218  0.10930812  0.8729007 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 68 is [True, False, False, True, False, False]
State prediction error at timestep 68 is tensor(0.0317, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 68 of -1
Current timestep = 69. State = [[-0.10821558 -0.15948874]]. Action = [[ 0.21517462 -0.07434076  0.17070717  0.28328443]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 69 is [True, False, False, True, False, False]
State prediction error at timestep 69 is tensor(0.0246, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 69 of -1
Current timestep = 70. State = [[-0.0979647  -0.15719312]]. Action = [[ 0.09860247  0.06475466 -0.13526511 -0.07406461]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 70 is [True, False, False, True, False, False]
State prediction error at timestep 70 is tensor(0.0195, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 70 of 0
Current timestep = 71. State = [[-0.09534042 -0.14583568]]. Action = [[-0.20551583  0.1712153  -0.23812109  0.56454015]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 71 is [True, False, False, True, False, False]
State prediction error at timestep 71 is tensor(0.0202, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 71 of 0
Current timestep = 72. State = [[-0.09478111 -0.13515092]]. Action = [[ 0.21567541 -0.07059272 -0.13285522  0.68233943]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 72 is [True, False, False, True, False, False]
State prediction error at timestep 72 is tensor(0.0231, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 72 of 0
Current timestep = 73. State = [[-0.09269884 -0.14303139]]. Action = [[-0.11049555 -0.1011011  -0.07148284  0.19292474]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 73 is [True, False, False, True, False, False]
State prediction error at timestep 73 is tensor(0.0184, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 73 of -1
Current timestep = 74. State = [[-0.08875503 -0.15407836]]. Action = [[ 0.19163424 -0.07680899 -0.13683107  0.30665827]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 74 is [True, False, False, True, False, False]
State prediction error at timestep 74 is tensor(0.0210, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 74 of -1
Current timestep = 75. State = [[-0.07171263 -0.16133222]]. Action = [[ 0.16386086 -0.03231689  0.02715537  0.9886737 ]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 75 is [True, False, False, True, False, False]
State prediction error at timestep 75 is tensor(0.0326, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 75 of 0
Current timestep = 76. State = [[-0.05524037 -0.17996523]]. Action = [[-0.05465348 -0.24138048 -0.05908291  0.6335572 ]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 76 is [True, False, False, True, False, False]
State prediction error at timestep 76 is tensor(0.0322, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 76 of -1
Current timestep = 77. State = [[-0.05066054 -0.20038165]]. Action = [[ 0.17573065 -0.01922275 -0.10659838  0.09180164]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 77 is [True, False, False, True, False, False]
State prediction error at timestep 77 is tensor(0.0285, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 77 of 0
Current timestep = 78. State = [[-0.02865641 -0.20852807]]. Action = [[ 0.16637325 -0.10975151 -0.09991446  0.43344724]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 78 is [False, True, False, True, False, False]
State prediction error at timestep 78 is tensor(0.0354, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 78 of -1
Current timestep = 79. State = [[-0.01039269 -0.2186053 ]]. Action = [[-0.15149792  0.06689727  0.22006989 -0.22393888]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 79 is [False, True, False, True, False, False]
State prediction error at timestep 79 is tensor(0.0331, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 79 of -1
Current timestep = 80. State = [[-0.01035542 -0.22843157]]. Action = [[ 0.16773006 -0.22731242  0.22806719 -0.74393755]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 80 is [False, True, False, True, False, False]
State prediction error at timestep 80 is tensor(0.0395, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 80 of -1
Current timestep = 81. State = [[-0.00131262 -0.24479467]]. Action = [[ 0.13782549 -0.05505691  0.14784855 -0.39650965]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 81 is [False, True, False, True, False, False]
State prediction error at timestep 81 is tensor(0.0413, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 81 of -1
Current timestep = 82. State = [[ 0.02100577 -0.24724095]]. Action = [[0.14856839 0.04442582 0.2311714  0.15378964]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 82 is [False, True, False, True, False, False]
State prediction error at timestep 82 is tensor(0.0420, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 82 of -1
Current timestep = 83. State = [[ 0.0351271  -0.24581668]]. Action = [[-0.01469079 -0.02659102  0.24103743 -0.559975  ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 83 is [False, True, False, True, False, False]
State prediction error at timestep 83 is tensor(0.0445, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 83 of -1
Current timestep = 84. State = [[ 0.03387186 -0.2442993 ]]. Action = [[-0.18015917  0.12616533 -0.0602441  -0.5747276 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 84 is [False, True, False, True, False, False]
State prediction error at timestep 84 is tensor(0.0438, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 84 of -1
Current timestep = 85. State = [[ 0.03291183 -0.245105  ]]. Action = [[ 0.13554275 -0.10531566  0.15397906 -0.42719674]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 85 is [False, True, False, True, False, False]
State prediction error at timestep 85 is tensor(0.0420, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 85 of -1
Current timestep = 86. State = [[ 0.03555516 -0.2393602 ]]. Action = [[ 0.04928344  0.14379343 -0.17426619  0.2810471 ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 86 is [False, True, False, True, False, False]
State prediction error at timestep 86 is tensor(0.0371, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 86 of 0
Current timestep = 87. State = [[ 0.03945579 -0.22357027]]. Action = [[-0.10183604  0.15704066 -0.22263303  0.30634415]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 87 is [False, True, False, True, False, False]
State prediction error at timestep 87 is tensor(0.0340, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 87 of 1
Current timestep = 88. State = [[ 0.04136858 -0.21261518]]. Action = [[ 0.13772333 -0.05302095  0.20379543 -0.24904013]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 88 is [False, True, False, True, False, False]
State prediction error at timestep 88 is tensor(0.0317, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 88 of -1
Current timestep = 89. State = [[ 0.04843073 -0.20661598]]. Action = [[ 0.08561295  0.10448295  0.07977191 -0.60737234]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 89 is [False, True, False, True, False, False]
State prediction error at timestep 89 is tensor(0.0348, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 89 of -1
Current timestep = 90. State = [[ 0.05554558 -0.2008308 ]]. Action = [[ 0.21153969 -0.11860177 -0.05131873 -0.9169962 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 90 is [False, False, True, True, False, False]
State prediction error at timestep 90 is tensor(0.0391, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 90 of -1
Current timestep = 91. State = [[ 0.0533819  -0.20959741]]. Action = [[-0.13963956 -0.15197214  0.07968473 -0.1122092 ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 91 is [False, False, True, True, False, False]
State prediction error at timestep 91 is tensor(0.0319, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 91 of 0
Current timestep = 92. State = [[ 0.05162442 -0.22174811]]. Action = [[ 0.08107272 -0.04389875  0.1157029   0.90303683]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 92 is [False, False, True, True, False, False]
State prediction error at timestep 92 is tensor(0.0408, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 92 of 0
Current timestep = 93. State = [[ 0.05145257 -0.22343782]]. Action = [[ 0.15710461 -0.16726749  0.21922863  0.28397858]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 93 is [False, False, True, True, False, False]
State prediction error at timestep 93 is tensor(0.0327, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 93 of -1
Current timestep = 94. State = [[ 0.05145257 -0.22343782]]. Action = [[0.16226524 0.10357463 0.21165943 0.32020462]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 94 is [False, False, True, True, False, False]
State prediction error at timestep 94 is tensor(0.0311, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 94 of -1
Current timestep = 95. State = [[ 0.04928122 -0.2316613 ]]. Action = [[-0.10530517 -0.10163465 -0.11908518  0.8453758 ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 95 is [False, True, False, True, False, False]
State prediction error at timestep 95 is tensor(0.0401, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 95 of -1
Current timestep = 96. State = [[ 0.03735226 -0.25514376]]. Action = [[-0.1721706  -0.2079051  -0.07608247 -0.66731316]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 96 is [False, True, False, True, False, False]
State prediction error at timestep 96 is tensor(0.0381, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 96 of -1
Current timestep = 97. State = [[ 0.02785463 -0.26929402]]. Action = [[ 0.15344942  0.06162506 -0.17042746 -0.58822614]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 97 is [False, True, False, True, False, False]
State prediction error at timestep 97 is tensor(0.0362, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 97 of -1
Current timestep = 98. State = [[ 0.0331343 -0.2561731]]. Action = [[-0.16459575  0.20820022 -0.21674937 -0.08400524]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 98 is [False, True, False, True, False, False]
State prediction error at timestep 98 is tensor(0.0286, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 98 of 0
Current timestep = 99. State = [[ 0.02875463 -0.23330648]]. Action = [[ 0.00211802  0.12688214  0.16571245 -0.44649792]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 99 is [False, True, False, True, False, False]
State prediction error at timestep 99 is tensor(0.0242, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 99 of 1
Current timestep = 100. State = [[ 0.02275623 -0.22960334]]. Action = [[-0.10866901 -0.12740923 -0.02676719 -0.3929903 ]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 100 is [False, True, False, True, False, False]
State prediction error at timestep 100 is tensor(0.0251, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 100 of 0
Current timestep = 101. State = [[ 0.01848683 -0.24642587]]. Action = [[ 0.2425597  -0.18116798 -0.16832432  0.65451384]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 101 is [False, True, False, True, False, False]
State prediction error at timestep 101 is tensor(0.0342, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 101 of -1
Current timestep = 102. State = [[ 0.0231162  -0.25581133]]. Action = [[-0.02671827 -0.00337727  0.14141726 -0.808302  ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 102 is [False, True, False, True, False, False]
State prediction error at timestep 102 is tensor(0.0307, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 102 of -1
Current timestep = 103. State = [[ 0.02235514 -0.26506683]]. Action = [[ 0.01471475 -0.14273152 -0.19190599  0.10977089]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 103 is [False, True, False, True, False, False]
State prediction error at timestep 103 is tensor(0.0311, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 103 of -1
Current timestep = 104. State = [[ 0.03259335 -0.27404445]]. Action = [[ 0.24337742  0.01555631 -0.20415778 -0.74897546]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 104 is [False, True, False, True, False, False]
State prediction error at timestep 104 is tensor(0.0329, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 104 of -1
Current timestep = 105. State = [[ 0.05450714 -0.27429265]]. Action = [[ 0.16612929  0.05811322 -0.21917401 -0.7692874 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 105 is [False, False, True, True, False, False]
State prediction error at timestep 105 is tensor(0.0355, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 105 of -1
Current timestep = 106. State = [[ 0.05583582 -0.26463905]]. Action = [[-0.09425312  0.21102607 -0.05335486  0.05630946]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 106 is [False, False, True, True, False, False]
State prediction error at timestep 106 is tensor(0.0267, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 106 of 0
Current timestep = 107. State = [[ 0.05729443 -0.25354055]]. Action = [[ 0.10919487 -0.21217228 -0.22843178  0.3060789 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 107 is [False, False, True, True, False, False]
State prediction error at timestep 107 is tensor(0.0308, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 107 of -1
Current timestep = 108. State = [[ 0.05729443 -0.25354055]]. Action = [[0.07543892 0.03646901 0.19247669 0.9638746 ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 108 is [False, False, True, True, False, False]
State prediction error at timestep 108 is tensor(0.0312, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 108 of -1
Current timestep = 109. State = [[ 0.05729443 -0.25354055]]. Action = [[ 0.12826103 -0.09408875  0.10887158 -0.7881324 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 109 is [False, False, True, True, False, False]
State prediction error at timestep 109 is tensor(0.0278, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 109 of -1
Current timestep = 110. State = [[ 0.05324654 -0.26422048]]. Action = [[-0.08078343 -0.19694304 -0.19462152  0.01769006]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 110 is [False, False, True, True, False, False]
State prediction error at timestep 110 is tensor(0.0300, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 110 of -1
Current timestep = 111. State = [[ 0.05093695 -0.27620566]]. Action = [[ 0.21500453 -0.03258751  0.16438758 -0.9042581 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 111 is [False, False, True, True, False, False]
State prediction error at timestep 111 is tensor(0.0298, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 111 of -1
Current timestep = 112. State = [[ 0.04798264 -0.28210106]]. Action = [[-0.07590121 -0.06748813  0.0534969   0.22022271]]. Reward = [0.]
Curr episode timestep = 112
Current timestep = 113. State = [[ 0.04450881 -0.2868781 ]]. Action = [[ 0.24605954 -0.10098752 -0.2147491   0.587024  ]]. Reward = [0.]
Curr episode timestep = 113
Current timestep = 114. State = [[ 0.04302456 -0.28831998]]. Action = [[ 0.17568019 -0.09013601 -0.1205568   0.59245694]]. Reward = [0.]
Curr episode timestep = 114
Current timestep = 115. State = [[ 0.04220755 -0.28912994]]. Action = [[-0.01354733 -0.1211651  -0.21625079  0.93596053]]. Reward = [0.]
Curr episode timestep = 115
Current timestep = 116. State = [[ 0.04170379 -0.28923875]]. Action = [[ 0.2027865   0.06647155 -0.24133104  0.01066434]]. Reward = [0.]
Curr episode timestep = 116
Current timestep = 117. State = [[ 0.03988764 -0.28334686]]. Action = [[-0.07249944  0.1332191   0.03401798  0.26062655]]. Reward = [0.]
Curr episode timestep = 117
Current timestep = 118. State = [[ 0.03894318 -0.27380618]]. Action = [[ 0.0437032   0.0471032   0.1508348  -0.02846503]]. Reward = [0.]
Curr episode timestep = 118
Current timestep = 119. State = [[ 0.03968232 -0.2692715 ]]. Action = [[ 0.23992026 -0.1625124  -0.12369028  0.10565734]]. Reward = [0.]
Curr episode timestep = 119
Current timestep = 120. State = [[ 0.04288149 -0.25747195]]. Action = [[0.08742678 0.17616984 0.10692772 0.8704574 ]]. Reward = [0.]
Curr episode timestep = 120
Current timestep = 121. State = [[ 0.04489839 -0.24289897]]. Action = [[ 0.21175197 -0.22270197  0.15984946  0.9644457 ]]. Reward = [0.]
Curr episode timestep = 121
Current timestep = 122. State = [[ 0.04509372 -0.24123968]]. Action = [[ 0.12908101 -0.08590582 -0.2182627   0.89028406]]. Reward = [0.]
Curr episode timestep = 122
Current timestep = 123. State = [[ 0.04336138 -0.24418724]]. Action = [[-0.08036959 -0.06739198  0.11083424 -0.4213574 ]]. Reward = [0.]
Curr episode timestep = 123
Current timestep = 124. State = [[ 0.04118718 -0.24717586]]. Action = [[ 0.16435677  0.2070252  -0.1548611   0.6095643 ]]. Reward = [0.]
Curr episode timestep = 124
Current timestep = 125. State = [[ 0.04041801 -0.24754585]]. Action = [[ 0.21536183  0.21090373 -0.13431334 -0.90963906]]. Reward = [0.]
Curr episode timestep = 125
Current timestep = 126. State = [[-0.24973205  0.02109756]]. Action = [[-0.23676157 -0.03416759  0.08197388  0.33100832]]. Reward = [0.]
Curr episode timestep = 126
Current timestep = 127. State = [[-0.23703033  0.03032564]]. Action = [[ 0.1981672   0.11925882  0.21968663 -0.6930009 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 128. State = [[-0.21714725  0.04376337]]. Action = [[0.11643007 0.09319752 0.11468479 0.3700223 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 129. State = [[-0.2045823   0.06341479]]. Action = [[0.01160079 0.16561744 0.00744453 0.69926655]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 130. State = [[-0.18987471  0.06605545]]. Action = [[ 0.21400344 -0.17000392 -0.14356618  0.04697812]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 131. State = [[-0.1770296   0.05226262]]. Action = [[-0.12912308 -0.14030224 -0.03566894 -0.7498567 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 132. State = [[-0.17790917  0.04181572]]. Action = [[ 0.02043048  0.01045945  0.23139411 -0.7995374 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 133. State = [[-0.17401262  0.03049739]]. Action = [[ 0.1107254  -0.15835868  0.19286889 -0.9163108 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 134. State = [[-0.16155332  0.00855707]]. Action = [[ 0.16220534 -0.19699234  0.04304221 -0.6016942 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 135. State = [[-0.14717647 -0.00468467]]. Action = [[ 0.02271894  0.02382907 -0.00298533 -0.4975204 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 136. State = [[-0.13532645  0.00163635]]. Action = [[0.15612245 0.1538828  0.15532827 0.29230285]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 137. State = [[-0.11730655  0.00560621]]. Action = [[ 0.07637817 -0.06040099 -0.07088971 -0.45523834]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 138. State = [[-0.10768092 -0.00152032]]. Action = [[ 0.04849795 -0.10804087 -0.11852472  0.8088536 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 139. State = [[-0.10688071  0.003139  ]]. Action = [[-0.11427419  0.18738821 -0.19035275 -0.6840857 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 140. State = [[-0.11268146  0.02404479]]. Action = [[-0.08048984  0.20568174 -0.12436709 -0.5003952 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 141. State = [[-0.11294265  0.03749933]]. Action = [[ 0.14401758 -0.05634418  0.11702341 -0.41513962]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 142. State = [[-0.10812797  0.03107379]]. Action = [[-0.00528109 -0.10716999 -0.13926697 -0.36349058]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 143. State = [[-0.11241974  0.01864028]]. Action = [[-0.22424896 -0.12483546  0.0218415   0.35872567]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 144. State = [[-1.1721171e-01 -2.5748539e-05]]. Action = [[ 0.02095369 -0.13489519 -0.02380928  0.46173167]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 145. State = [[-0.11413287  0.00048798]]. Action = [[0.19345433 0.18177599 0.19733608 0.6221812 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 146. State = [[-0.1129704  -0.00536682]]. Action = [[-0.15351872 -0.21946375  0.17327607  0.6443076 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 147. State = [[-0.11498798 -0.02188161]]. Action = [[-0.01512238 -0.0958453  -0.16898185  0.271922  ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 148. State = [[-0.12058476 -0.03936653]]. Action = [[-0.10689077 -0.14301315  0.10336161  0.81747246]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 149. State = [[-0.12591197 -0.06029047]]. Action = [[ 0.03290626 -0.1435525  -0.08482274  0.68861437]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 150. State = [[-0.12309895 -0.05904784]]. Action = [[0.12803698 0.22622424 0.18114638 0.56131244]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 151. State = [[-0.12627433 -0.03512855]]. Action = [[-0.20962201  0.2330611   0.14677954  0.8018161 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 152. State = [[-0.13576788 -0.0039094 ]]. Action = [[-0.09602563  0.18459666 -0.00754885 -0.7314968 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 153. State = [[-0.1398203   0.02158303]]. Action = [[0.16004387 0.13373032 0.00493392 0.880772  ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 154. State = [[-0.14148378  0.02392408]]. Action = [[-0.13870135 -0.14826055 -0.2045044   0.81201077]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 155. State = [[-0.14072484  0.00893115]]. Action = [[ 0.09406272 -0.14940323  0.04359645  0.8246263 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 156. State = [[-0.13078693  0.00993899]]. Action = [[ 0.24614048  0.20192769  0.2290433  -0.9950467 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 157. State = [[-0.12197254  0.01509525]]. Action = [[-0.13818206 -0.06866091  0.09395903  0.6858747 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 158. State = [[-0.12029929  0.02160921]]. Action = [[ 0.14994323  0.14482093  0.04878187 -0.8020616 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 159. State = [[-0.10610349  0.03226269]]. Action = [[ 0.23162758  0.05473638 -0.00315666 -0.33088177]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 160. State = [[-0.08579315  0.04127871]]. Action = [[ 0.02703798  0.05476642 -0.17297037 -0.7119362 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 161. State = [[-0.07919717  0.05814387]]. Action = [[ 0.02049342  0.20308441  0.12264901 -0.69282407]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 162. State = [[-0.07936511  0.06911211]]. Action = [[-0.18263589 -0.0755755  -0.24274556  0.6948371 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 163. State = [[-0.081419    0.07704368]]. Action = [[ 0.1476456   0.14806211 -0.16939951  0.21297467]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 164. State = [[-0.08402993  0.09040295]]. Action = [[-0.03824574  0.08682624  0.05168176 -0.5769498 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 165. State = [[-0.08118468  0.1098565 ]]. Action = [[ 0.121768    0.21609902 -0.20928141 -0.38670743]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 166. State = [[-0.07453004  0.12174541]]. Action = [[-0.15392296 -0.09543881 -0.1933503  -0.30231607]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 167. State = [[-0.07191496  0.12239386]]. Action = [[0.17484725 0.03455824 0.04658124 0.07137454]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 168. State = [[-0.06821978  0.12383744]]. Action = [[-0.06667688 -0.01003385 -0.01127362  0.6974189 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 169. State = [[-0.06722829  0.13550974]]. Action = [[ 0.08749497  0.21751213 -0.15324105 -0.7829633 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 170. State = [[-0.05217621  0.14229597]]. Action = [[ 0.23202908 -0.11458552 -0.04757772  0.92457664]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 171. State = [[-0.03373111  0.15000862]]. Action = [[1.8581748e-04 1.4832807e-01 5.8657825e-02 9.1339731e-01]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 171 is [False, True, False, False, False, True]
State prediction error at timestep 171 is tensor(0.0118, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 171 of -1
Current timestep = 172. State = [[-0.02420635  0.16534975]]. Action = [[ 0.081835    0.12041643  0.12363225 -0.93114376]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 172 is [False, True, False, False, False, True]
State prediction error at timestep 172 is tensor(0.0159, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 172 of -1
Current timestep = 173. State = [[-0.00469121  0.16412361]]. Action = [[ 0.15489548 -0.20662168 -0.11436173  0.7272277 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 173 is [False, True, False, False, False, True]
State prediction error at timestep 173 is tensor(0.0153, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 173 of 0
Current timestep = 174. State = [[0.01099    0.14117429]]. Action = [[ 0.09446692 -0.15194976  0.15609396 -0.942222  ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 174 is [False, True, False, False, False, True]
State prediction error at timestep 174 is tensor(0.0235, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 174 of 0
Current timestep = 175. State = [[0.0194812  0.12334114]]. Action = [[-0.21599995 -0.11222287 -0.12051231 -0.8849082 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 175 is [False, True, False, False, True, False]
State prediction error at timestep 175 is tensor(0.0212, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 175 of 1
Current timestep = 176. State = [[0.01790719 0.12228277]]. Action = [[ 0.16099048  0.14368004  0.24378312 -0.5980569 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 176 is [False, True, False, False, True, False]
State prediction error at timestep 176 is tensor(0.0162, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 176 of -1
Current timestep = 177. State = [[0.0280111  0.12699813]]. Action = [[ 0.20034778 -0.05442062  0.1842103  -0.03035402]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 177 is [False, True, False, False, False, True]
State prediction error at timestep 177 is tensor(0.0175, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 177 of -1
Current timestep = 178. State = [[0.04581959 0.11635813]]. Action = [[-0.04376523 -0.17275174  0.00314564 -0.5635495 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 178 is [False, True, False, False, True, False]
State prediction error at timestep 178 is tensor(0.0245, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 178 of 0
Current timestep = 179. State = [[0.04770597 0.10241515]]. Action = [[-0.09459931 -0.03595877 -0.2156983   0.67710924]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 179 is [False, True, False, False, True, False]
State prediction error at timestep 179 is tensor(0.0145, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 179 of -1
Current timestep = 180. State = [[0.04156165 0.10845146]]. Action = [[-0.19188546  0.12660989  0.0029867   0.16787589]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 180 is [False, True, False, False, True, False]
State prediction error at timestep 180 is tensor(0.0165, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 180 of 0
Current timestep = 181. State = [[-2.2052355e-01 -1.3931344e-04]]. Action = [[ 0.01149535 -0.17293645  0.0295952   0.22933555]]. Reward = [100.]
Curr episode timestep = 54
Current timestep = 182. State = [[-0.21230835  0.00918388]]. Action = [[-0.00585113  0.14829329 -0.09087205  0.24404347]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 183. State = [[-0.21592718  0.01381209]]. Action = [[-0.14241116 -0.08913907 -0.01595725 -0.5627526 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 184. State = [[-0.2262542   0.01080322]]. Action = [[-0.2176617  -0.01672371  0.19592017  0.81125665]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 185. State = [[-0.24030106  0.02155946]]. Action = [[ 0.12462583  0.22922146 -0.10149348  0.8678808 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 186. State = [[-0.23930286  0.02778878]]. Action = [[ 0.06944734 -0.14517991  0.0345403   0.51430225]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 187. State = [[-0.22690244  0.0136532 ]]. Action = [[ 0.168037   -0.1473115   0.14682394  0.992152  ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 188. State = [[-0.20540135 -0.00494378]]. Action = [[ 0.17351785 -0.14986578 -0.11354622 -0.19512862]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 189. State = [[-0.1815851  -0.00653496]]. Action = [[ 0.17918286  0.19565177 -0.2297431   0.26698828]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 190. State = [[-0.1618336  -0.00681339]]. Action = [[ 0.05505529 -0.13591534  0.0228444   0.91650915]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 191. State = [[-0.14408165 -0.01574514]]. Action = [[ 0.24566007 -0.07898375  0.04591092  0.67164695]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 192. State = [[-0.11603981 -0.01980294]]. Action = [[ 0.14215851  0.04974222  0.00180057 -0.93596095]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 193. State = [[-0.09358593 -0.02241358]]. Action = [[ 0.10963535 -0.06722166  0.04114121  0.7290232 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 194. State = [[-0.07382419 -0.01635698]]. Action = [[ 0.19634789  0.16965437  0.1911301  -0.6704341 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 195. State = [[-0.05787405 -0.01490361]]. Action = [[-0.06045772 -0.11528671 -0.1954236  -0.9004038 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 196. State = [[-0.05872587 -0.02494381]]. Action = [[-0.10911372 -0.11124468  0.18268615  0.73856497]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 197. State = [[-0.05373693 -0.04332654]]. Action = [[ 0.23218441 -0.15900213 -0.14852443  0.04064131]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 198. State = [[-0.04433272 -0.04253718]]. Action = [[ 0.01111057  0.21566802 -0.09644267 -0.6103023 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 198 is [False, True, False, False, True, False]
State prediction error at timestep 198 is tensor(0.0011, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 198 of 1
Current timestep = 199. State = [[-0.04352679 -0.02649182]]. Action = [[-0.23909684  0.06419864 -0.21925467 -0.25711507]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 199 is [False, True, False, False, True, False]
State prediction error at timestep 199 is tensor(0.0013, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 199 of 0
Current timestep = 200. State = [[-0.04722125 -0.03061961]]. Action = [[ 0.14760089 -0.18230651  0.06867182  0.49487257]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 200 is [False, True, False, False, True, False]
State prediction error at timestep 200 is tensor(0.0007, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 200 of 0
Current timestep = 201. State = [[-0.0443085  -0.05705361]]. Action = [[ 0.05133691 -0.20152137  0.19066298 -0.41184044]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 201 is [False, True, False, False, True, False]
State prediction error at timestep 201 is tensor(0.0025, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 201 of -1
Current timestep = 202. State = [[-0.04320816 -0.08500521]]. Action = [[-0.06014824 -0.19361766 -0.1864852   0.4247973 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 202 is [False, True, False, False, True, False]
State prediction error at timestep 202 is tensor(0.0019, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 202 of -1
Current timestep = 203. State = [[-0.04374038 -0.08989222]]. Action = [[0.00047237 0.19505501 0.0375073  0.3951192 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 203 is [False, True, False, False, True, False]
State prediction error at timestep 203 is tensor(0.0005, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 203 of 1
Current timestep = 204. State = [[-0.03807038 -0.06561662]]. Action = [[ 0.20754796  0.21063524 -0.20223153  0.8886486 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 204 is [False, True, False, False, True, False]
State prediction error at timestep 204 is tensor(0.0007, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 204 of 1
Current timestep = 205. State = [[-0.18044063  0.17277522]]. Action = [[-0.00779465 -0.03572023  0.00129113  0.19355667]]. Reward = [100.]
Curr episode timestep = 23
Current timestep = 206. State = [[-0.1649978   0.19348413]]. Action = [[ 0.00784174 -0.01157767 -0.00767992 -0.7252525 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 207. State = [[-0.15706079  0.1960218 ]]. Action = [[ 0.15537542  0.06522217 -0.21597514  0.78103995]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 208. State = [[-0.14022072  0.20937178]]. Action = [[ 0.08715293  0.14920586 -0.12044531 -0.927955  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 209. State = [[-0.135838    0.22076555]]. Action = [[-0.18867703 -0.04987445 -0.19274153 -0.95906836]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 210. State = [[-0.14006725  0.21885465]]. Action = [[-0.0786486  -0.09050828 -0.00724475 -0.25411975]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 211. State = [[-0.13879645  0.2044976 ]]. Action = [[ 0.12354398 -0.12875064 -0.07054085  0.57924235]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 212. State = [[-0.12934795  0.17948881]]. Action = [[ 0.15916938 -0.23260215 -0.1728327  -0.2881627 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 213. State = [[-0.11376963  0.15741472]]. Action = [[ 0.20434403 -0.05986215  0.17394534  0.09859538]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 214. State = [[-0.08906386  0.14892812]]. Action = [[ 0.219336    0.01559767 -0.02928334 -0.26600868]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 215. State = [[-0.07569233  0.16253084]]. Action = [[-0.13329464  0.22243363  0.19214594 -0.7625906 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 216. State = [[-0.08543313  0.18315028]]. Action = [[-0.08466545  0.13383585  0.10764337  0.18613493]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 217. State = [[-0.09191409  0.18601677]]. Action = [[-0.16449545 -0.20314102 -0.1132955   0.2107259 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 218. State = [[-0.09774239  0.18910107]]. Action = [[-0.03657132  0.17554477  0.12105539 -0.08858198]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 219. State = [[-0.10481568  0.200616  ]]. Action = [[-0.01297294  0.02433142 -0.1075909  -0.7792294 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 220. State = [[-0.10130282  0.18968907]]. Action = [[ 0.09320471 -0.23143698  0.08582127  0.3003143 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 221. State = [[-0.10162839  0.17202045]]. Action = [[-0.16525848 -0.09571451  0.08299232 -0.67451334]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 222. State = [[-0.10833988  0.14950973]]. Action = [[-0.06635189 -0.23465545 -0.09507343  0.8417996 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 223. State = [[-0.11983387  0.1446785 ]]. Action = [[-0.11205173  0.21019909 -0.01082738 -0.4388697 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 224. State = [[-0.13020195  0.16244695]]. Action = [[ 0.00143236  0.10385528 -0.15000501 -0.84396577]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 225. State = [[-0.13676317  0.17687254]]. Action = [[-0.04866409  0.09576851  0.2137711   0.22860694]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 226. State = [[-0.14396036  0.17785382]]. Action = [[-0.09223664 -0.13871606 -0.034135    0.1516633 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 227. State = [[-0.14674945  0.15558596]]. Action = [[ 0.13390747 -0.21934776  0.17668122 -0.13450348]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 228. State = [[-0.13955249  0.1344908 ]]. Action = [[ 0.0324918  -0.08806518 -0.07974234 -0.8367881 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 229. State = [[-0.14426842  0.12985162]]. Action = [[-0.1743768   0.06023943 -0.23480687  0.3234191 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 230. State = [[-0.14408478  0.11716136]]. Action = [[ 0.19781744 -0.20486943 -0.08350879 -0.5562057 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 231. State = [[-0.13602492  0.10305215]]. Action = [[ 0.04858488 -0.0025789  -0.00791106  0.04554152]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 232. State = [[-0.14245725  0.10723184]]. Action = [[-0.21549304  0.129803    0.12144959 -0.03692341]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 233. State = [[-0.15245502  0.12565337]]. Action = [[-0.03054212  0.20163238  0.21646148  0.67134   ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 234. State = [[-0.15599276  0.13292521]]. Action = [[ 0.08306709 -0.14469458  0.09441486 -0.08347321]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 235. State = [[-0.14947248  0.11802381]]. Action = [[ 0.07519001 -0.16625772 -0.09944656 -0.7158601 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 236. State = [[-0.14983517  0.09282748]]. Action = [[-0.22119135 -0.21940313 -0.01012658 -0.0907492 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 237. State = [[-0.16873898  0.08371345]]. Action = [[-0.15462756  0.15480518  0.04520988 -0.20772398]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 238. State = [[-0.17910798  0.10059071]]. Action = [[ 0.18617532  0.22080311 -0.19463038 -0.19992161]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 239. State = [[-0.17469043  0.11494768]]. Action = [[ 0.09156165  0.04380152 -0.02701075 -0.30437875]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 240. State = [[-0.16640331  0.1262095 ]]. Action = [[ 0.10918766  0.12355483 -0.1472524   0.9770725 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 241. State = [[-0.15570669  0.13602377]]. Action = [[ 0.06404775 -0.01296328 -0.03186952  0.34406233]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 242. State = [[-0.13871309  0.14548749]]. Action = [[ 0.24012074  0.11612758 -0.14380144  0.04897332]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 243. State = [[-0.12054291  0.1608936 ]]. Action = [[ 0.01658496  0.11770344 -0.09180266 -0.3991369 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 244. State = [[-0.10717156  0.17249608]]. Action = [[ 0.16804913  0.07187358  0.12693441 -0.5348103 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 245. State = [[-0.1001211   0.19493467]]. Action = [[-0.13987003  0.22732472 -0.19334452 -0.892257  ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 246. State = [[-0.10846817  0.21304846]]. Action = [[-0.16005109 -0.0170802  -0.04340762 -0.14767146]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 247. State = [[-0.11742494  0.22642434]]. Action = [[-0.0925135   0.13085908 -0.05453798  0.39887023]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 248. State = [[-0.12053518  0.22476403]]. Action = [[ 0.06492534 -0.22070287  0.20115    -0.95261437]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 249. State = [[-0.12462853  0.22530659]]. Action = [[-0.12268426  0.21111211 -0.13651767 -0.2923571 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 250. State = [[-0.125444    0.22458677]]. Action = [[ 0.14305785 -0.19137467 -0.07543288 -0.29716694]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 251. State = [[-0.12950875  0.20884866]]. Action = [[-0.23358643 -0.12316391  0.21085045  0.9132328 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 252. State = [[-0.14446828  0.18997009]]. Action = [[-0.15902737 -0.15618321  0.14266407 -0.36991125]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 253. State = [[-0.16533326  0.1626297 ]]. Action = [[-0.16925105 -0.24234584  0.10382694 -0.09034705]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 254. State = [[-0.19078362  0.13792399]]. Action = [[-0.19201362 -0.08241321  0.20898917  0.7400873 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 255. State = [[-0.20249687  0.13115552]]. Action = [[ 0.2393525   0.10301214 -0.13983439  0.69006443]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 256. State = [[-0.20561293  0.12295838]]. Action = [[-0.21458487 -0.20579246  0.06516242 -0.40413117]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 257. State = [[-0.21573457  0.12415719]]. Action = [[-0.11437345  0.19530728  0.18204618 -0.5586717 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 258. State = [[-0.21806173  0.12533447]]. Action = [[ 0.19633302 -0.15840779 -0.07817039 -0.66862565]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 259. State = [[-0.21026734  0.11720561]]. Action = [[ 0.08095351  0.01826233 -0.16412187  0.52015173]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 260. State = [[-0.2073066   0.12651064]]. Action = [[0.04386914 0.21712005 0.06385732 0.41935062]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 261. State = [[-0.20283093  0.13862954]]. Action = [[0.04752216 0.05000156 0.08430737 0.21440923]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 262. State = [[-0.19009091  0.1336037 ]]. Action = [[ 0.2056323 -0.1823368  0.0511452  0.7450261]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 263. State = [[-0.1816186   0.12973991]]. Action = [[-0.17562707  0.07318816 -0.15607503  0.13994908]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 264. State = [[-0.1931902   0.12828062]]. Action = [[-0.2405006  -0.09692407  0.1685406  -0.76768494]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 265. State = [[-0.20403077  0.11776275]]. Action = [[ 0.01645619 -0.12526457  0.15787995  0.9556253 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 266. State = [[-0.21297938  0.1179867 ]]. Action = [[-0.13686803  0.15567353  0.11562109  0.7788135 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 267. State = [[-0.21889226  0.13717508]]. Action = [[ 0.17505068  0.20404363 -0.19922556 -0.7757008 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 268. State = [[-0.21131016  0.15220821]]. Action = [[0.16491401 0.09758398 0.08670878 0.30603802]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 269. State = [[-0.20405293  0.16097668]]. Action = [[-0.14338985 -0.03142262 -0.16682503 -0.40858412]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 270. State = [[-0.19818673  0.15389735]]. Action = [[ 0.20960116 -0.14593461  0.15497988 -0.11443365]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 271. State = [[-0.19250679  0.14559573]]. Action = [[-0.02565823 -0.00452235  0.09836081  0.10238981]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 272. State = [[-0.18982545  0.13628939]]. Action = [[-0.02365682 -0.13957293 -0.02550758 -0.9496116 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 273. State = [[-0.18482614  0.12132833]]. Action = [[ 0.03024405 -0.11059979  0.17365104  0.8636308 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 274. State = [[-0.18322028  0.09790521]]. Action = [[-0.00983873 -0.21484444  0.23019779 -0.42235208]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 275. State = [[-0.18116586  0.08862779]]. Action = [[ 0.04005092  0.12988839  0.13821268 -0.5678219 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 276. State = [[-0.1881131  0.1022189]]. Action = [[-0.178919    0.19241372  0.05338106 -0.6558674 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 277. State = [[-0.19196714  0.12017558]]. Action = [[ 0.15967321  0.0879294   0.11674333 -0.7433761 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 278. State = [[-0.18083757  0.13362451]]. Action = [[ 0.22276318  0.13030046 -0.21615367  0.4523995 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 279. State = [[-0.16532281  0.14077283]]. Action = [[-0.04795796 -0.11742175 -0.13629864 -0.95546013]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 280. State = [[-0.15866254  0.13182487]]. Action = [[ 0.15057057 -0.06765482 -0.24638216 -0.20642334]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 281. State = [[-0.15317534  0.13162532]]. Action = [[-0.06023122  0.12118387 -0.20084041  0.4510808 ]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 282. State = [[-0.14661261  0.12713471]]. Action = [[ 0.16643772 -0.17455205  0.00094655  0.18155062]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 283. State = [[-0.13206021  0.11872186]]. Action = [[ 0.06817108  0.00749582 -0.097865   -0.19384241]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 284. State = [[-0.13000117  0.10536763]]. Action = [[-0.15569295 -0.23426832  0.11990079  0.72364163]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 285. State = [[-0.13302304  0.10310055]]. Action = [[-0.12542623  0.19098336 -0.13486966  0.7794417 ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 286. State = [[-0.13503146  0.11425225]]. Action = [[ 0.16317207  0.08031374 -0.08573413  0.07579923]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 287. State = [[-0.13525426  0.13164417]]. Action = [[ 0.015091    0.22250879 -0.22944511  0.884187  ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 288. State = [[-0.13500865  0.15224428]]. Action = [[ 0.01721346  0.08639354  0.2366862  -0.7503394 ]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 289. State = [[-0.12951405  0.150256  ]]. Action = [[ 0.100007   -0.18051346  0.0118241   0.9307991 ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 290. State = [[-0.1207947   0.13295735]]. Action = [[-0.02368739 -0.19194786 -0.05887204  0.41237915]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 291. State = [[-0.11476009  0.13263313]]. Action = [[ 0.07782233  0.24683803  0.08916622 -0.17270607]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 292. State = [[-0.10857357  0.15589052]]. Action = [[ 0.05741024  0.21939167 -0.17953514  0.7216377 ]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 293. State = [[-0.09428313  0.177193  ]]. Action = [[ 0.22063452  0.0811947  -0.2314546   0.13344789]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 294. State = [[-0.07219987  0.19327797]]. Action = [[ 0.09668195  0.04232973  0.01924363 -0.00788039]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 295. State = [[-0.06841464  0.211247  ]]. Action = [[-0.21761182  0.20230928 -0.20129544 -0.3967924 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 296. State = [[-0.08087034  0.22508055]]. Action = [[-0.18007722 -0.06265968 -0.1475339   0.1015135 ]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 297. State = [[-0.08319489  0.22554494]]. Action = [[ 0.17623124  0.00261623 -0.19632968  0.4317119 ]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 298. State = [[-0.08480658  0.23063436]]. Action = [[-0.03020447  0.12527025 -0.1427592  -0.7072859 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 299. State = [[-0.0812999   0.22368601]]. Action = [[ 0.0450258  -0.23360138 -0.18418738 -0.08968711]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 300. State = [[-0.08077664  0.2212122 ]]. Action = [[-0.09639199  0.13917208  0.01689973 -0.73172194]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 301. State = [[-0.07547558  0.21346103]]. Action = [[ 0.22490478 -0.22348216  0.22067124 -0.8385701 ]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 302. State = [[-0.05893743  0.18985876]]. Action = [[ 0.16597831 -0.11752249 -0.22493811  0.41382694]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 303. State = [[-0.04986898  0.18028624]]. Action = [[-0.10140839  0.01387736  0.20914513 -0.7982895 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 303 is [False, True, False, False, False, True]
State prediction error at timestep 303 is tensor(0.0047, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 303 of -1
Current timestep = 304. State = [[-0.05599267  0.18889692]]. Action = [[-0.20727068  0.11431986 -0.02920529  0.62701595]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 305. State = [[-0.06043992  0.18745932]]. Action = [[ 0.08016688 -0.17545037 -0.17386283 -0.46582586]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 306. State = [[-0.05393724  0.18958496]]. Action = [[ 0.24414656  0.2350074  -0.20772164  0.60785186]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 307. State = [[-0.03497181  0.19841406]]. Action = [[ 0.17268968 -0.04145244  0.03066698  0.4306476 ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 307 is [False, True, False, False, False, True]
State prediction error at timestep 307 is tensor(0.0023, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 307 of -1
Current timestep = 308. State = [[-0.01789641  0.20281386]]. Action = [[-0.03152089  0.08707598 -0.09195367  0.3610971 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 308 is [False, True, False, False, False, True]
State prediction error at timestep 308 is tensor(0.0038, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 308 of -1
Current timestep = 309. State = [[-0.0102086   0.20595239]]. Action = [[ 0.15760177 -0.04616289  0.1924538  -0.6394622 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 309 is [False, True, False, False, False, True]
State prediction error at timestep 309 is tensor(0.0046, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 309 of -1
Current timestep = 310. State = [[-0.00171494  0.2163358 ]]. Action = [[-0.13897868  0.18985713  0.22949421  0.8818672 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 310 is [False, True, False, False, False, True]
State prediction error at timestep 310 is tensor(0.0033, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 310 of -1
Current timestep = 311. State = [[-0.00731996  0.2254553 ]]. Action = [[-0.04625832 -0.11147922  0.22049081 -0.24532443]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 311 is [False, True, False, False, False, True]
State prediction error at timestep 311 is tensor(0.0061, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 311 of -1
Current timestep = 312. State = [[-0.00357179  0.22436239]]. Action = [[ 0.21827823  0.08407331 -0.05565271 -0.82665455]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 312 is [False, True, False, False, False, True]
State prediction error at timestep 312 is tensor(0.0038, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 312 of -1
Current timestep = 313. State = [[0.00779842 0.23126817]]. Action = [[-0.18771628 -0.01659521 -0.24675952 -0.5109317 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 313 is [False, True, False, False, False, True]
State prediction error at timestep 313 is tensor(0.0071, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 313 of -1
Current timestep = 314. State = [[-0.00128975  0.24158156]]. Action = [[-0.16730055  0.15124401 -0.09555537  0.7238494 ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 314 is [False, True, False, False, False, True]
State prediction error at timestep 314 is tensor(0.0032, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 314 of -1
Current timestep = 315. State = [[-0.01062459  0.26050228]]. Action = [[ 0.21414661  0.13103187 -0.1164299   0.0958966 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 315 is [False, True, False, False, False, True]
State prediction error at timestep 315 is tensor(0.0036, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 315 of -1
Current timestep = 316. State = [[-0.0043303  0.2653627]]. Action = [[ 0.14864147  0.02254239 -0.2410861   0.3901484 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 316 is [False, True, False, False, False, True]
State prediction error at timestep 316 is tensor(0.0039, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 316 of -1
Current timestep = 317. State = [[0.00981533 0.27174726]]. Action = [[ 0.00547475  0.02268022 -0.06702057  0.6032448 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 317 is [False, True, False, False, False, True]
State prediction error at timestep 317 is tensor(0.0049, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 317 of -1
Current timestep = 318. State = [[0.00727405 0.27705324]]. Action = [[-0.11719647  0.04493913 -0.18249242  0.44818735]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 318 is [False, True, False, False, False, True]
State prediction error at timestep 318 is tensor(0.0053, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 318 of -1
Current timestep = 319. State = [[0.0033728  0.28364307]]. Action = [[-0.00751522  0.05834919 -0.05601217 -0.45069283]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 319 is [False, True, False, False, False, True]
State prediction error at timestep 319 is tensor(0.0061, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 319 of -1
Current timestep = 320. State = [[-0.00114336  0.28991637]]. Action = [[-0.12812236 -0.00760248 -0.05684069  0.35253692]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 320 is [False, True, False, False, False, True]
State prediction error at timestep 320 is tensor(0.0058, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 320 of -1
Current timestep = 321. State = [[-0.00337926  0.29327932]]. Action = [[ 0.19303334  0.21899807 -0.12902994 -0.9562911 ]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 321 is [False, True, False, False, False, True]
State prediction error at timestep 321 is tensor(0.0026, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 321 of -1
Current timestep = 322. State = [[0.00215739 0.28381845]]. Action = [[ 0.21210247 -0.13328248  0.10105851  0.8220844 ]]. Reward = [0.]
Curr episode timestep = 116
Current timestep = 323. State = [[0.00820128 0.26879257]]. Action = [[-0.1403725  -0.12122735  0.04002732 -0.747247  ]]. Reward = [0.]
Curr episode timestep = 117
Current timestep = 324. State = [[0.01437074 0.25453582]]. Action = [[ 0.20003203 -0.09707026 -0.08832923  0.5536995 ]]. Reward = [0.]
Curr episode timestep = 118
Current timestep = 325. State = [[0.01996354 0.2531288 ]]. Action = [[ 0.04404178  0.18444973 -0.16263236  0.45777237]]. Reward = [0.]
Curr episode timestep = 119
Current timestep = 326. State = [[0.02090106 0.25163302]]. Action = [[-0.22744656 -0.22682625 -0.17135529 -0.46401238]]. Reward = [0.]
Curr episode timestep = 120
Current timestep = 327. State = [[0.01467985 0.24526802]]. Action = [[-0.09138341  0.03277457  0.16202861  0.9563544 ]]. Reward = [0.]
Curr episode timestep = 121
Current timestep = 328. State = [[0.012007   0.23452038]]. Action = [[ 0.12964463 -0.18229988 -0.21984805  0.6297722 ]]. Reward = [0.]
Curr episode timestep = 122
Current timestep = 329. State = [[0.01547319 0.22380498]]. Action = [[ 0.09092104  0.04809752 -0.02408937 -0.9151471 ]]. Reward = [0.]
Curr episode timestep = 123
Current timestep = 330. State = [[0.01536625 0.21067408]]. Action = [[-0.19469504 -0.24343975  0.06940201 -0.8157542 ]]. Reward = [0.]
Curr episode timestep = 124
Current timestep = 331. State = [[0.01528933 0.18289949]]. Action = [[ 0.1786856  -0.16018818 -0.22528458 -0.6512837 ]]. Reward = [0.]
Curr episode timestep = 125
Current timestep = 332. State = [[-0.17882581 -0.03464795]]. Action = [[-0.04408191 -0.20558633 -0.12968664 -0.30401653]]. Reward = [0.]
Curr episode timestep = 126
Current timestep = 333. State = [[-0.15983878 -0.04196468]]. Action = [[ 0.10367939 -0.04801975  0.02578902 -0.13323873]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 334. State = [[-0.15490083 -0.05361352]]. Action = [[-0.03904112 -0.12898584 -0.17913377  0.83485246]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 335. State = [[-0.15047981 -0.07563222]]. Action = [[ 0.09932816 -0.19331211  0.1795417   0.7590451 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 336. State = [[-0.13471581 -0.09638163]]. Action = [[ 0.20870674 -0.07204151 -0.11967358  0.5265604 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 337. State = [[-0.11957636 -0.09268122]]. Action = [[-0.08062533  0.19844759  0.19367024 -0.13613987]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 338. State = [[-0.12554497 -0.09683391]]. Action = [[-0.2264677  -0.19826424  0.0912385   0.423656  ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 339. State = [[-0.13258272 -0.10454722]]. Action = [[-0.05491748  0.05196685 -0.10638511 -0.9371653 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 340. State = [[-0.14641365 -0.09235088]]. Action = [[-0.13390811  0.18669611 -0.03576569 -0.36859143]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 341. State = [[-0.15506415 -0.08150057]]. Action = [[ 0.11870876 -0.04176798 -0.09691319  0.85156417]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 342. State = [[-0.15042923 -0.0827917 ]]. Action = [[ 0.12112316 -0.04329327  0.02163175 -0.40289825]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 343. State = [[-0.14716105 -0.08348709]]. Action = [[-7.5582355e-02  3.4788251e-04  1.8234828e-01 -7.7900594e-01]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 344. State = [[-0.14989759 -0.0725887 ]]. Action = [[-0.080726    0.22091758 -0.13371314 -0.1309216 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 345. State = [[-0.1474222  -0.05524261]]. Action = [[ 0.21183604  0.06657839 -0.1496214   0.28669548]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 346. State = [[-0.14335299 -0.03725484]]. Action = [[-0.03645349  0.17234385 -0.03058036 -0.48178744]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 347. State = [[-0.14485805 -0.02563147]]. Action = [[-0.04265545 -0.00809148 -0.08905967  0.2570535 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 348. State = [[-0.14209874 -0.01997131]]. Action = [[ 0.11675775  0.0669342  -0.02998236 -0.861591  ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 349. State = [[-0.12471242 -0.01132114]]. Action = [[ 0.23008898  0.06398836 -0.22159918  0.4475665 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 350. State = [[-0.09885094  0.00521672]]. Action = [[0.1764895  0.17105576 0.00741717 0.8776195 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 351. State = [[-0.07556935  0.03247638]]. Action = [[ 0.13507628  0.24600774  0.02952808 -0.32765234]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 352. State = [[-0.05985003  0.058479  ]]. Action = [[ 0.02995157  0.09233683 -0.23326212  0.1906848 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 353. State = [[-0.05558009  0.06698631]]. Action = [[-0.05907241 -0.02293439  0.08167663  0.92186725]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 354. State = [[-0.05993004  0.07307698]]. Action = [[-0.17443259  0.05259764  0.13470066 -0.10889059]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 355. State = [[-0.0730176   0.06910428]]. Action = [[-0.21144359 -0.14802112  0.03297597  0.94390714]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 356. State = [[-0.08106533  0.07375249]]. Action = [[0.21734786 0.2167269  0.03553402 0.09831882]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 357. State = [[-0.07264265  0.08499999]]. Action = [[0.19079652 0.03476483 0.16970867 0.83679605]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 358. State = [[-0.0583783   0.08133296]]. Action = [[ 0.01078951 -0.14666581 -0.00987972 -0.22850037]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 359. State = [[-0.05663159  0.08125358]]. Action = [[ 0.01678926  0.11651483  0.14214289 -0.08556634]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 360. State = [[-0.05760748  0.08984149]]. Action = [[-0.13477401  0.05164397 -0.11436768  0.33452725]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 361. State = [[-0.05779549  0.08484104]]. Action = [[ 0.03714827 -0.16932328  0.04563722 -0.873347  ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 362. State = [[-0.05479806  0.06131707]]. Action = [[ 0.03237113 -0.2420473  -0.06335194 -0.35851252]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 363. State = [[-0.05106163  0.03730601]]. Action = [[-0.01298763 -0.1059214  -0.05023795  0.5294609 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 364. State = [[-0.04872439  0.0238615 ]]. Action = [[ 0.03967309 -0.05940896 -0.08738786  0.7724515 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 364 is [False, True, False, False, True, False]
State prediction error at timestep 364 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 364 of 1
Current timestep = 365. State = [[-0.04690807  0.01802   ]]. Action = [[ 0.04120952  0.04125696  0.10655469 -0.39755118]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 365 is [False, True, False, False, True, False]
State prediction error at timestep 365 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 365 of 0
Current timestep = 366. State = [[-0.04729836  0.02168229]]. Action = [[-0.00500423  0.04966885 -0.02677451  0.7381675 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 366 is [False, True, False, False, True, False]
State prediction error at timestep 366 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 366 of 0
Current timestep = 367. State = [[-0.0520313   0.03820834]]. Action = [[-0.21391025  0.23195022 -0.16683653  0.34791362]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 368. State = [[-0.05473184  0.04643076]]. Action = [[ 0.21100968 -0.17475347  0.13917875 -0.1769312 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 369. State = [[-0.05352806  0.04333525]]. Action = [[-0.12944329  0.08042401  0.0491873   0.84180737]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 370. State = [[-0.05517801  0.05148207]]. Action = [[ 0.083139    0.09924299 -0.17193642  0.11087978]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 371. State = [[-0.04736518  0.06507337]]. Action = [[ 0.24080393  0.14495677  0.08010915 -0.71035427]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 371 is [False, True, False, False, True, False]
State prediction error at timestep 371 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 371 of -1
Current timestep = 372. State = [[-0.25827152  0.18399055]]. Action = [[ 0.16202003  0.19875136 -0.10320219  0.23463047]]. Reward = [100.]
Curr episode timestep = 39
Current timestep = 373. State = [[-0.25045642  0.19550645]]. Action = [[-0.05109134 -0.21176523  0.2444568  -0.15410608]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 374. State = [[-0.24830635  0.18440248]]. Action = [[-0.1748405  -0.08360404 -0.19008273 -0.73345965]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 375. State = [[-0.24960744  0.19139431]]. Action = [[ 0.07789594  0.20705003 -0.0497904   0.12539685]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 376. State = [[-0.24804525  0.19174904]]. Action = [[ 0.02910581 -0.17355096  0.05494088  0.5215516 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 377. State = [[-0.24904048  0.19152819]]. Action = [[-0.04108208  0.1196605  -0.07301891 -0.57954526]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 378. State = [[-0.24943195  0.18485008]]. Action = [[-0.09387417 -0.23747079 -0.16367458 -0.6501467 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 379. State = [[-0.24910751  0.16107363]]. Action = [[-0.0070612  -0.21694568  0.07485741  0.7228823 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 380. State = [[-0.24438953  0.15049168]]. Action = [[0.18361986 0.13652807 0.19507986 0.536783  ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 381. State = [[-0.23026794  0.16432954]]. Action = [[0.21244758 0.19727081 0.23786706 0.63602245]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 382. State = [[-0.21611919  0.17311068]]. Action = [[-0.14764448 -0.10161403  0.09548041  0.75101745]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 383. State = [[-0.21566963  0.1726945 ]]. Action = [[ 0.09991631  0.03563604  0.19355428 -0.27199936]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 384. State = [[-0.21580338  0.1736231 ]]. Action = [[-0.08837968 -0.00039314 -0.13593093  0.04403138]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 385. State = [[-0.22267799  0.17066789]]. Action = [[-0.18747137 -0.1045955  -0.01918307  0.878258  ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 386. State = [[-0.22697306  0.17195949]]. Action = [[ 0.20665479  0.15769902 -0.1545566   0.18074358]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 387. State = [[-0.22343563  0.17526013]]. Action = [[-0.06056464 -0.05401802  0.22410542 -0.79460144]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 388. State = [[-0.2265903  0.1764638]]. Action = [[-0.10969009 -0.00677913  0.20474449  0.93806076]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 389. State = [[-0.22493169  0.17997965]]. Action = [[ 0.20989794  0.07807425 -0.00792611  0.13622642]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 390. State = [[-0.22014658  0.17930463]]. Action = [[ 0.00930151 -0.05682631 -0.15984607 -0.6296059 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 391. State = [[-0.21368727  0.18123607]]. Action = [[ 0.10148257  0.06892037 -0.23911966 -0.7667832 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 392. State = [[-0.20635054  0.17730306]]. Action = [[-0.08688763 -0.15133417  0.10424748  0.4249251 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 393. State = [[-0.20199779  0.1628048 ]]. Action = [[ 0.08411694 -0.11576447  0.03124845 -0.8735693 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 394. State = [[-0.20251706  0.14935388]]. Action = [[-0.15053497 -0.09368226  0.17863    -0.79641825]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 395. State = [[-0.20760469  0.14182992]]. Action = [[-0.06403288 -0.01544292 -0.11786667 -0.87007016]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 396. State = [[-0.21042745  0.13473946]]. Action = [[-0.03392787 -0.07930735 -0.05404191 -0.7855301 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 397. State = [[-0.22195205  0.11574477]]. Action = [[-0.16730954 -0.22520882 -0.20718905  0.09259868]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 398. State = [[-0.23396425  0.10803398]]. Action = [[ 0.12387782  0.19086432 -0.15317167  0.5467999 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 399. State = [[-0.23085313  0.1044146 ]]. Action = [[ 0.05209079 -0.17355645 -0.12290737  0.18542254]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 400. State = [[-0.23431651  0.10190045]]. Action = [[-0.19214249  0.04763329  0.07650656 -0.28818178]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 401. State = [[-0.23389077  0.09047949]]. Action = [[ 0.17820528 -0.1852742   0.16761714 -0.63018113]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 402. State = [[-0.22690862  0.09107219]]. Action = [[ 0.10060722  0.24505097  0.1681807  -0.19970495]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 403. State = [[-0.21763891  0.11442051]]. Action = [[ 0.09131917  0.22999361  0.1262368  -0.38230366]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 404. State = [[-0.21433116  0.13219956]]. Action = [[-0.12852424 -0.01770768 -0.19177188  0.9673898 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 405. State = [[-0.21397316  0.14076862]]. Action = [[ 0.13920844  0.10712361  0.2340461  -0.60822666]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 406. State = [[-0.21048363  0.14527214]]. Action = [[-0.04738806 -0.0303525   0.1931676   0.4259696 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 407. State = [[-0.21180545  0.14471172]]. Action = [[-0.11832434 -0.04747972 -0.16231093 -0.19692111]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 408. State = [[-0.22536628  0.15373932]]. Action = [[-0.20144333  0.15114778 -0.0645479   0.85190296]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 409. State = [[-0.25009543  0.17191255]]. Action = [[-0.1983705   0.07590485 -0.12215388  0.34624386]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 410. State = [[-0.266785    0.18657257]]. Action = [[ 0.09527493  0.15604556 -0.08716613  0.15453637]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 411. State = [[-0.26156044  0.19638029]]. Action = [[ 0.19074923  0.04473338 -0.10334423  0.36381197]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 412. State = [[-0.23905155  0.1970398 ]]. Action = [[ 0.24358863 -0.07637194  0.12246394 -0.4122346 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 413. State = [[-0.21008897  0.18081455]]. Action = [[ 0.21618757 -0.20740727  0.05810675 -0.7302963 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 414. State = [[-0.19537167  0.16720387]]. Action = [[-0.204009   -0.04984607 -0.16834505  0.02273822]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 415. State = [[-0.20375565  0.1739864 ]]. Action = [[-0.12611857  0.19448295 -0.23649119 -0.5454693 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 416. State = [[-0.20495526  0.17099446]]. Action = [[ 0.15964317 -0.2328056  -0.0717085  -0.75211036]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 417. State = [[-0.19531158  0.1645306 ]]. Action = [[ 0.1764943   0.14729825  0.00786278 -0.8787028 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 418. State = [[-0.18522     0.15691522]]. Action = [[-0.06255248 -0.23505224 -0.13608576 -0.70765144]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 419. State = [[-0.17619605  0.15299916]]. Action = [[ 0.1983729   0.14287019 -0.02744961 -0.34464478]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 420. State = [[-0.1675138   0.15352854]]. Action = [[-0.06209478 -0.09552997 -0.05058573 -0.40292728]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 421. State = [[-0.16350213  0.13538988]]. Action = [[-3.90082598e-04 -2.36738294e-01  1.18368596e-01 -6.39422953e-01]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 422. State = [[-0.15287684  0.11334527]]. Action = [[ 0.2053377  -0.06481758  0.04452932  0.66542244]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 423. State = [[-0.14102001  0.08895954]]. Action = [[ 0.05267388 -0.21491723 -0.1833605  -0.15680295]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 424. State = [[-0.12538998  0.07514869]]. Action = [[ 0.22487399  0.06450045  0.01204869 -0.39082623]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 425. State = [[-0.11167797  0.07733605]]. Action = [[-0.13926893 -0.0168165  -0.05594091 -0.7718628 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 426. State = [[-0.11787847  0.08796205]]. Action = [[-0.14479287  0.18728781 -0.18641162  0.819729  ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 427. State = [[-0.13373493  0.10021769]]. Action = [[-0.22391133 -0.03116658  0.14285302  0.13879895]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 428. State = [[-0.14444116  0.10149571]]. Action = [[0.10190284 0.00854853 0.05322212 0.43382168]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 429. State = [[-0.13634574  0.10610498]]. Action = [[ 0.2397097   0.10064256 -0.12205236  0.16326022]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 430. State = [[-0.12197908  0.1061928 ]]. Action = [[ 0.11769146 -0.07220346  0.11977804  0.2845968 ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 431. State = [[-0.11254016  0.09673609]]. Action = [[-0.09953812 -0.13842672  0.00656706 -0.6085474 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 432. State = [[-0.11113956  0.10046176]]. Action = [[0.07153594 0.21437117 0.20515409 0.09581268]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 433. State = [[-0.10329584  0.12207987]]. Action = [[ 0.20830905  0.23484835 -0.13880965 -0.11995703]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 434. State = [[-0.08162539  0.14960739]]. Action = [[ 0.1250838   0.16613972 -0.0297671  -0.05947018]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 435. State = [[-0.07168884  0.16414307]]. Action = [[-0.18594983 -0.05699389 -0.17521745  0.75659156]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 436. State = [[-0.07001825  0.16798404]]. Action = [[0.17663473 0.07512406 0.16949803 0.35762143]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 437. State = [[-0.05753076  0.17885306]]. Action = [[ 0.2170609   0.14331308 -0.2207331   0.24083948]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 438. State = [[-0.04325503  0.20655957]]. Action = [[-0.11322656  0.23668855 -0.02054057 -0.87585676]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 438 is [False, True, False, False, False, True]
State prediction error at timestep 438 is tensor(0.0010, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 438 of -1
Current timestep = 439. State = [[-0.05180318  0.24301046]]. Action = [[-0.18899134  0.19518924 -0.03025615  0.07829022]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 440. State = [[-0.06671789  0.26498026]]. Action = [[-0.14255525  0.06233272 -0.06067917  0.3620832 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 441. State = [[-0.07384666  0.27429834]]. Action = [[ 0.09613174  0.22345561  0.18230069 -0.23906219]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 442. State = [[-0.08060141  0.28273258]]. Action = [[-0.13068843  0.09283578 -0.09110004  0.03574395]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 443. State = [[-0.08891436  0.28701085]]. Action = [[-0.01221764 -0.05954231 -0.00812152  0.42700207]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 444. State = [[-0.08890173  0.2864408 ]]. Action = [[ 0.08992967  0.01643607 -0.08366056 -0.24906516]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 445. State = [[-0.08853623  0.28607515]]. Action = [[-0.15466772  0.20508724  0.10455513  0.89050794]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 446. State = [[-0.08355585  0.2767727 ]]. Action = [[ 0.07611686 -0.14820762 -0.02745481 -0.39812875]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 447. State = [[-0.07933637  0.27017266]]. Action = [[0.08024225 0.09849948 0.13821465 0.6755471 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 448. State = [[-0.07853721  0.27234852]]. Action = [[ 0.15205824  0.19622567  0.07555389 -0.10062933]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 449. State = [[-0.07241616  0.2732418 ]]. Action = [[0.19117197 0.05468744 0.06406966 0.66751814]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 450. State = [[-0.05852233  0.27248463]]. Action = [[-0.03887933 -0.10582519 -0.19291401 -0.89618903]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 451. State = [[-0.05135424  0.2609649 ]]. Action = [[ 0.09954953 -0.09790486 -0.0629057  -0.2245686 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 452. State = [[-0.04026746  0.25332624]]. Action = [[ 0.16072333  0.04855558 -0.17976856 -0.21125245]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 453. State = [[-0.03405805  0.26821467]]. Action = [[-0.20874383  0.19133815 -0.03379726  0.38081813]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 454. State = [[-0.03769366  0.2688117 ]]. Action = [[-0.00816603 -0.23413323 -0.14179356  0.53188586]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 455. State = [[-0.03305557  0.25940934]]. Action = [[ 0.15557617  0.02572042 -0.07713972  0.53751314]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 456. State = [[-0.03100037  0.25698695]]. Action = [[ 0.00243628  0.03985476  0.05454934 -0.1901499 ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 457. State = [[-0.02761555  0.26321378]]. Action = [[ 0.11406019  0.11484647 -0.16931717  0.816851  ]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 458. State = [[-0.01608341  0.27514568]]. Action = [[ 0.03197244  0.0091204  -0.11992118  0.7157564 ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 459. State = [[-0.0097604   0.27860975]]. Action = [[ 0.20095122  0.20796967 -0.14169541 -0.07310081]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 460. State = [[-0.00718887  0.26936463]]. Action = [[-0.102424   -0.18518256  0.02674034  0.45133328]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 461. State = [[-0.00983883  0.25637305]]. Action = [[-0.2038538  -0.11007379  0.01176918 -0.5584857 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 462. State = [[-0.01853148  0.23520081]]. Action = [[-0.10860939 -0.23817435 -0.08988909  0.58118653]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 463. State = [[-0.03439047  0.22253112]]. Action = [[-0.06167242  0.08665079  0.1752404   0.33155942]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 464. State = [[-0.03705101  0.22766055]]. Action = [[ 0.19396818  0.09557185 -0.20004342 -0.29558492]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 465. State = [[-0.02797845  0.2249377 ]]. Action = [[ 0.23575705 -0.04989579  0.17475215 -0.2035802 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 466. State = [[-0.00503026  0.21545245]]. Action = [[ 0.24425244 -0.08766785 -0.07583162  0.83009696]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 467. State = [[0.01518231 0.21536899]]. Action = [[-0.0427942   0.09425399 -0.03928581 -0.00755525]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 468. State = [[0.01867584 0.20923775]]. Action = [[ 0.01685199 -0.1677692   0.02995196 -0.8159011 ]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 469. State = [[0.02607453 0.20612763]]. Action = [[0.14891902 0.10941008 0.19886497 0.07057679]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 470. State = [[0.04060367 0.21698925]]. Action = [[ 0.18745291  0.11319089 -0.01978299 -0.2889799 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 471. State = [[0.06239631 0.2156031 ]]. Action = [[ 0.04098088 -0.15872258 -0.11241603 -0.24216264]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 471 is [False, False, True, False, False, True]
State prediction error at timestep 471 is tensor(0.0006, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 471 of -1
Current timestep = 472. State = [[0.07247493 0.2067145 ]]. Action = [[ 0.17393366  0.01681507 -0.16460088  0.9275253 ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 472 is [False, False, True, False, False, True]
State prediction error at timestep 472 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 472 of -1
Current timestep = 473. State = [[0.07151688 0.20662184]]. Action = [[-0.16891918 -0.02678321 -0.05957088 -0.6475356 ]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 473 is [False, False, True, False, False, True]
State prediction error at timestep 473 is tensor(0.0006, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 473 of -1
Current timestep = 474. State = [[0.06963719 0.20637357]]. Action = [[ 0.19565237 -0.03177673 -0.05612157  0.53013074]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 474 is [False, False, True, False, False, True]
State prediction error at timestep 474 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 474 of -1
Current timestep = 475. State = [[0.06965578 0.20630425]]. Action = [[ 0.22185034  0.22474384 -0.01068184  0.9109814 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 475 is [False, False, True, False, False, True]
State prediction error at timestep 475 is tensor(3.7328e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 475 of -1
Current timestep = 476. State = [[0.07120422 0.1952896 ]]. Action = [[-0.01482236 -0.2047499  -0.21832712 -0.27039206]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 476 is [False, False, True, False, False, True]
State prediction error at timestep 476 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 476 of 0
Current timestep = 477. State = [[0.07330218 0.18273963]]. Action = [[ 0.01283637 -0.04994833 -0.071242   -0.5027706 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 477 is [False, False, True, False, False, True]
State prediction error at timestep 477 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 477 of -1
Current timestep = 478. State = [[0.07317316 0.18249117]]. Action = [[ 0.06600079 -0.07549    -0.13037182 -0.16999888]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 478 is [False, False, True, False, False, True]
State prediction error at timestep 478 is tensor(4.1867e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 478 of -1
Current timestep = 479. State = [[0.07313046 0.18240908]]. Action = [[0.02312523 0.00701332 0.0939554  0.24766457]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 479 is [False, False, True, False, False, True]
State prediction error at timestep 479 is tensor(6.5243e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 479 of -1
Current timestep = 480. State = [[0.0731091  0.18236804]]. Action = [[ 0.02518299  0.11909854 -0.10151197  0.5224154 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 480 is [False, False, True, False, False, True]
State prediction error at timestep 480 is tensor(5.2857e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 480 of -1
Current timestep = 481. State = [[0.06911465 0.1882547 ]]. Action = [[-0.1374501   0.08681417 -0.06936689  0.93087447]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 481 is [False, False, True, False, False, True]
State prediction error at timestep 481 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 481 of -1
Current timestep = 482. State = [[0.0635998  0.19394241]]. Action = [[ 0.20231974  0.10698488 -0.05740042 -0.50564146]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 482 is [False, False, True, False, False, True]
State prediction error at timestep 482 is tensor(1.5411e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 482 of -1
Current timestep = 483. State = [[0.06334508 0.19433531]]. Action = [[ 0.23154777  0.23017615 -0.21951382 -0.8442419 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 483 is [False, False, True, False, False, True]
State prediction error at timestep 483 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 483 of -1
Current timestep = 484. State = [[0.05919227 0.18961157]]. Action = [[-0.14907992 -0.08961581 -0.18558803  0.17956686]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 484 is [False, False, True, False, False, True]
State prediction error at timestep 484 is tensor(6.5583e-06, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 484 of 0
Current timestep = 485. State = [[0.04264415 0.1814367 ]]. Action = [[-0.0179763  -0.00435436 -0.13471346  0.9481691 ]]. Reward = [0.]
Curr episode timestep = 112
Current timestep = 486. State = [[0.04386382 0.17730139]]. Action = [[ 0.10800615 -0.05567215  0.10239118  0.4769075 ]]. Reward = [0.]
Curr episode timestep = 113
Current timestep = 487. State = [[0.0402132  0.16499309]]. Action = [[-0.2005934  -0.16393344  0.0084728   0.9517095 ]]. Reward = [0.]
Curr episode timestep = 114
Current timestep = 488. State = [[0.02985228 0.15100075]]. Action = [[ 0.21421766 -0.11830217  0.02296212  0.6860173 ]]. Reward = [0.]
Curr episode timestep = 115
Current timestep = 489. State = [[0.0304521  0.14143649]]. Action = [[ 0.04410663 -0.1205413   0.10617605  0.59669626]]. Reward = [0.]
Curr episode timestep = 116
Current timestep = 490. State = [[0.02950418 0.14356121]]. Action = [[ 0.07961434  0.17584175 -0.1283849  -0.58644867]]. Reward = [0.]
Curr episode timestep = 117
Current timestep = 491. State = [[0.0339957  0.15881531]]. Action = [[ 0.19131392  0.17641276 -0.06704283  0.86373615]]. Reward = [0.]
Curr episode timestep = 118
Current timestep = 492. State = [[0.03925506 0.15999845]]. Action = [[-0.14451659 -0.2088679  -0.22004996  0.5315409 ]]. Reward = [0.]
Curr episode timestep = 119
Current timestep = 493. State = [[0.03399467 0.14439268]]. Action = [[-0.18258327 -0.1287231   0.06341144  0.5707556 ]]. Reward = [0.]
Curr episode timestep = 120
Current timestep = 494. State = [[0.02798959 0.12722987]]. Action = [[ 0.06765851 -0.09729114  0.04926628  0.28074503]]. Reward = [0.]
Curr episode timestep = 121
Current timestep = 495. State = [[0.02923591 0.12809274]]. Action = [[ 0.14058119  0.18000782  0.10712695 -0.940153  ]]. Reward = [0.]
Curr episode timestep = 122
Current timestep = 496. State = [[0.02882097 0.13301028]]. Action = [[-0.11836745 -0.03558113 -0.14514132  0.11973917]]. Reward = [0.]
Curr episode timestep = 123
Current timestep = 497. State = [[0.02415278 0.1245187 ]]. Action = [[-0.15768474 -0.16514564  0.19333261 -0.54314965]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 497 is [False, True, False, False, True, False]
State prediction error at timestep 497 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 497 of 1
Current timestep = 498. State = [[0.0138311  0.12259017]]. Action = [[0.12731579 0.18784407 0.00746006 0.3279922 ]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 498 is [False, True, False, False, True, False]
State prediction error at timestep 498 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 498 of -1
Current timestep = 499. State = [[-0.15034328 -0.17663606]]. Action = [[-0.01109475  0.22021079 -0.15815002  0.6581359 ]]. Reward = [0.]
Curr episode timestep = 126
Current timestep = 500. State = [[-0.14187367 -0.20788422]]. Action = [[-0.22088207 -0.13560335 -0.03771552  0.06511009]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 501. State = [[-0.15821405 -0.21069096]]. Action = [[-0.21697156  0.18227279  0.23828447  0.33552086]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 502. State = [[-0.17691752 -0.20915075]]. Action = [[-0.07017833 -0.10351974 -0.03489794  0.95434904]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 503. State = [[-0.18200856 -0.20709206]]. Action = [[ 0.02870283  0.13333249 -0.09365319  0.02429795]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 504. State = [[-0.17719798 -0.19626111]]. Action = [[ 0.18743545  0.03449568 -0.0730354   0.8836696 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 505. State = [[-0.1728414  -0.18061827]]. Action = [[-0.02933303  0.17998222  0.1650899   0.24669456]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 506. State = [[-0.17632283 -0.15577401]]. Action = [[-0.17717771  0.203834    0.19982678  0.8110926 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 507. State = [[-0.1759157  -0.12411991]]. Action = [[ 0.20659122  0.21392709 -0.17536503  0.0694418 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 508. State = [[-0.16105337 -0.09892447]]. Action = [[ 0.23319805  0.09893757 -0.099742    0.7230711 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 509. State = [[-0.13758294 -0.08762481]]. Action = [[0.16485807 0.03446016 0.08398759 0.0824616 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 510. State = [[-0.11596879 -0.0706659 ]]. Action = [[0.17672235 0.20434102 0.16693878 0.22198951]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 511. State = [[-0.08689477 -0.06752492]]. Action = [[ 0.24507618 -0.22107463 -0.13587676  0.20798099]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 512. State = [[-0.07193485 -0.08944274]]. Action = [[-0.20868672 -0.19424954 -0.19126001 -0.2771235 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 513. State = [[-0.07235378 -0.10833284]]. Action = [[ 0.16852006 -0.08355789  0.0637393  -0.05226445]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 514. State = [[-0.06512764 -0.10887871]]. Action = [[0.02735782 0.14049798 0.07653016 0.00437462]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 515. State = [[-0.06719349 -0.11498833]]. Action = [[-0.229578   -0.15393849 -0.16044837 -0.2422334 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 516. State = [[-0.07784223 -0.1190319 ]]. Action = [[-0.15046544  0.07344413  0.23087424  0.12813365]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 517. State = [[-0.09739625 -0.13230875]]. Action = [[-0.1984818  -0.24237344 -0.11685197  0.6572242 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 518. State = [[-0.12129185 -0.16132693]]. Action = [[-0.1560138  -0.20465943  0.00507447  0.08545876]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 519. State = [[-0.1299799  -0.16635203]]. Action = [[ 0.2152937   0.16960615 -0.19097628 -0.09140778]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 520. State = [[-0.11776944 -0.15092643]]. Action = [[ 0.20257145  0.13126606  0.00713968 -0.230407  ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 521. State = [[-0.09865019 -0.13350537]]. Action = [[ 0.14102519  0.07980293 -0.01140396  0.27532494]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 522. State = [[-0.08971535 -0.13353188]]. Action = [[-0.14477663 -0.1215415   0.08632141  0.5727322 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 523. State = [[-0.09071585 -0.14702944]]. Action = [[ 0.05142796 -0.15752779 -0.04658359 -0.38398075]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 524. State = [[-0.08436991 -0.14876506]]. Action = [[0.16620529 0.16177422 0.03119195 0.88491356]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 525. State = [[-0.07986708 -0.15737088]]. Action = [[-0.14039671 -0.22850403  0.18702394  0.3425349 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 526. State = [[-0.07573488 -0.17524341]]. Action = [[ 0.205244   -0.1104375   0.19333053 -0.42088413]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 527. State = [[-0.0556556 -0.1722868]]. Action = [[ 0.22706115  0.19197172  0.1278975  -0.04026306]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 528. State = [[-0.02879787 -0.16658165]]. Action = [[ 0.191059   -0.03769433 -0.24328181 -0.9040095 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 529. State = [[-0.00971685 -0.17536476]]. Action = [[-0.01001172 -0.15292485  0.1534642   0.98809195]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 530. State = [[-0.01047561 -0.18204348]]. Action = [[-0.1797948   0.06816918  0.07127166  0.5819454 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 531. State = [[-0.01654769 -0.18317513]]. Action = [[-0.13895518  0.00884145  0.01495126  0.84402514]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 532. State = [[-0.02549224 -0.19611757]]. Action = [[-0.08553469 -0.18970373  0.03056663  0.72590876]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 533. State = [[-0.03584445 -0.19873923]]. Action = [[-0.06330699  0.15014324 -0.07242081 -0.67907685]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 534. State = [[-0.03774308 -0.20218371]]. Action = [[ 0.1888889  -0.22087765 -0.22922778  0.7420788 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 535. State = [[-0.03378766 -0.2142912 ]]. Action = [[ 0.09720796 -0.03982717  0.24284649 -0.71560365]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 536. State = [[-0.03093042 -0.22217843]]. Action = [[ 0.01690012 -0.07036188 -0.18170106 -0.18760902]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 537. State = [[-0.02113917 -0.23971574]]. Action = [[ 0.19917348 -0.21687883 -0.12418061  0.03836334]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 538. State = [[ 0.00566305 -0.26466906]]. Action = [[ 0.24020427 -0.14498979  0.10375741 -0.6636216 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 539. State = [[ 0.03989784 -0.2651706 ]]. Action = [[ 0.1941325   0.22555572  0.07044572 -0.51796466]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 540. State = [[ 0.06221901 -0.25675038]]. Action = [[ 0.21398818  0.24602869 -0.0167643  -0.4894194 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 540 is [False, False, True, True, False, False]
State prediction error at timestep 540 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 540 of -1
Current timestep = 541. State = [[ 0.06773271 -0.2520335 ]]. Action = [[-0.22762868  0.10103878 -0.02106987 -0.34141153]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 541 is [False, False, True, True, False, False]
State prediction error at timestep 541 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 541 of -1
Current timestep = 542. State = [[ 0.06572415 -0.24159342]]. Action = [[-0.05364625  0.08927855  0.04896563  0.87853384]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 543. State = [[ 0.05443728 -0.22833496]]. Action = [[-0.24302316  0.136949    0.14523318  0.09770131]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 544. State = [[ 0.03321313 -0.2150866 ]]. Action = [[ 0.0776588   0.03357729 -0.04810016  0.69977593]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 545. State = [[ 0.02469978 -0.22582066]]. Action = [[-0.04448733 -0.20507269 -0.09903371  0.846087  ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 546. State = [[ 0.00999803 -0.241738  ]]. Action = [[-0.2356925  -0.04297969  0.0573073   0.46218443]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 547. State = [[-0.00312334 -0.25692725]]. Action = [[ 0.1594541  -0.18063709 -0.22433694 -0.39055586]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 548. State = [[-0.00380668 -0.27744132]]. Action = [[ 0.06491655 -0.1488401   0.115753   -0.7335823 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 549. State = [[-0.00531661 -0.28663242]]. Action = [[-0.07119063  0.04304975  0.00494981  0.54182863]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 550. State = [[-0.01035373 -0.2873828 ]]. Action = [[-0.16761687  0.04204589 -0.14907375 -0.5115896 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 551. State = [[-0.01608414 -0.28814742]]. Action = [[-0.04798007 -0.23569793  0.10174602  0.48226118]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 552. State = [[-0.02227831 -0.29019162]]. Action = [[-0.13003972 -0.00745687  0.14847475  0.7219869 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 553. State = [[-0.04070171 -0.28416824]]. Action = [[-0.22097425  0.14124835 -0.22981197  0.46481872]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 554. State = [[-0.06555393 -0.27164146]]. Action = [[ 0.10255504 -0.21392307  0.0192292   0.34272718]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 555. State = [[-0.06900658 -0.25598374]]. Action = [[ 0.03275496  0.23615867 -0.06226815 -0.12990648]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 556. State = [[-0.07476425 -0.22982268]]. Action = [[-0.1952013   0.13563028  0.19876617 -0.77842206]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 557. State = [[-0.09320735 -0.22055835]]. Action = [[ 0.02960509 -0.11102775 -0.05671215  0.5519819 ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 558. State = [[-0.09876593 -0.22317275]]. Action = [[-0.06546748  0.00761363 -0.1509047   0.5255656 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 559. State = [[-0.09959965 -0.22428887]]. Action = [[ 0.11219269 -0.0384289   0.13940293 -0.7967945 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 560. State = [[-0.09312941 -0.22783862]]. Action = [[ 0.18486214 -0.07504347 -0.13877909  0.7986052 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 561. State = [[-0.0902463 -0.2280508]]. Action = [[-0.12389278  0.11348513 -0.15465498  0.2003634 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 562. State = [[-0.08807622 -0.22625852]]. Action = [[ 0.1558271  -0.05890422 -0.01865306  0.24119079]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 563. State = [[-0.08245854 -0.22252566]]. Action = [[0.05680764 0.07127056 0.10113499 0.09561205]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 564. State = [[-0.07090903 -0.214081  ]]. Action = [[ 0.14431319  0.07824251 -0.15145372 -0.7630416 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 565. State = [[-0.05666562 -0.22056754]]. Action = [[ 0.09728977 -0.22645965 -0.05927241 -0.23171288]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 566. State = [[-0.03390539 -0.21986194]]. Action = [[0.23766217 0.21674895 0.00913858 0.03233576]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 567. State = [[-0.00323672 -0.19525653]]. Action = [[0.19570279 0.24910527 0.05149791 0.8900156 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 568. State = [[ 0.02403327 -0.16899301]]. Action = [[ 0.20668668  0.10591382 -0.22240949 -0.45574415]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 569. State = [[ 0.04050663 -0.145782  ]]. Action = [[-0.17762874  0.23503226  0.13942716  0.3957392 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 570. State = [[ 0.03188953 -0.13796934]]. Action = [[-0.24322294 -0.1472144   0.00366417  0.95141673]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 571. State = [[ 0.02297744 -0.15098894]]. Action = [[ 0.03659284 -0.11019513 -0.08089043 -0.65695596]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 572. State = [[ 0.02483303 -0.14698195]]. Action = [[ 0.17701232  0.16715527 -0.20693946 -0.8862489 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 573. State = [[ 0.02134078 -0.1446525 ]]. Action = [[-0.24718566 -0.08162138 -0.14403644 -0.3409255 ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 574. State = [[ 0.01209577 -0.13878568]]. Action = [[-0.09995449  0.156214    0.00697449 -0.6966046 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 575. State = [[ 0.0050974  -0.11479586]]. Action = [[0.02190021 0.2222364  0.02588806 0.03659344]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 576. State = [[-0.19401032 -0.22290473]]. Action = [[0.00955233 0.1539062  0.17646676 0.85188985]]. Reward = [100.]
Curr episode timestep = 76
Current timestep = 577. State = [[-0.18252315 -0.24502662]]. Action = [[-0.07092762  0.12974277 -0.0745679   0.39021206]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 578. State = [[-0.19166414 -0.2456614 ]]. Action = [[-0.22271453 -0.04451698 -0.18825667  0.6266264 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 579. State = [[-0.20689584 -0.23844865]]. Action = [[-0.09150767  0.17598271  0.10255462 -0.47384113]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 580. State = [[-0.21245474 -0.23346597]]. Action = [[ 0.14625275 -0.15499538  0.18559399  0.1941427 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 581. State = [[-0.21026254 -0.22617117]]. Action = [[-0.02740151  0.21613646 -0.12430969 -0.9503509 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 582. State = [[-0.21704504 -0.20569384]]. Action = [[-0.20180672  0.18411157  0.02225456 -0.4269352 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 583. State = [[-0.2249073  -0.18159048]]. Action = [[0.08304286 0.16377747 0.19990617 0.17002296]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 584. State = [[-0.22305779 -0.16431898]]. Action = [[0.0607433  0.02267998 0.09575114 0.75725126]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 585. State = [[-0.22814235 -0.15301192]]. Action = [[-0.2220673   0.13340595 -0.17597143  0.7985662 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 586. State = [[-0.23369764 -0.15255967]]. Action = [[ 0.17397895 -0.20275353  0.16370735 -0.76238716]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 587. State = [[-0.22327659 -0.1696004 ]]. Action = [[ 0.15895614 -0.15501319 -0.22027664 -0.18448305]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 588. State = [[-0.21456859 -0.19389981]]. Action = [[ 0.00457647 -0.22110726  0.1164282   0.82599175]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 589. State = [[-0.21273501 -0.1999333 ]]. Action = [[-0.03577316  0.22957575  0.03038499 -0.22372985]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 590. State = [[-0.21951665 -0.18080825]]. Action = [[-0.19719745  0.19313517 -0.20795089 -0.6413364 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 591. State = [[-0.22325069 -0.16585065]]. Action = [[ 0.09926733  0.00365204  0.13432974 -0.7022537 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 592. State = [[-0.21852273 -0.17353731]]. Action = [[ 0.10896748 -0.22054444  0.11190346 -0.7848552 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 593. State = [[-0.2167719  -0.18570723]]. Action = [[-0.05374888 -0.03224649 -0.12527274  0.16764808]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 594. State = [[-0.21274695 -0.17958409]]. Action = [[ 0.12537551  0.18217838 -0.00289921  0.89821124]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 595. State = [[-0.21184593 -0.18434362]]. Action = [[-0.08135043 -0.22107409 -0.1402096  -0.65424824]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 596. State = [[-0.21825889 -0.19534373]]. Action = [[-0.16367991  0.00523487 -0.1746627   0.8179189 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 597. State = [[-0.23307557 -0.2139879 ]]. Action = [[-0.1610907  -0.21989067 -0.23821692 -0.06049961]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 598. State = [[-0.25345606 -0.21810172]]. Action = [[-0.2036599   0.22784948 -0.13096274 -0.16001755]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 599. State = [[-0.26786768 -0.20598806]]. Action = [[ 0.01169294  0.04718518  0.04475021 -0.40007186]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 600. State = [[-0.26781553 -0.20586036]]. Action = [[ 0.08611715 -0.11762953 -0.13494352 -0.8379778 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 601. State = [[-0.2681705  -0.20813875]]. Action = [[-0.20789154  0.09357953 -0.04124048 -0.6441837 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 602. State = [[-0.2686853  -0.20917295]]. Action = [[-0.24425939 -0.24131972 -0.00789067 -0.6146033 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 603. State = [[-0.26279268 -0.19795585]]. Action = [[ 0.12941694  0.20705509 -0.05376309  0.2929001 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 604. State = [[-0.24833013 -0.17433643]]. Action = [[ 0.16876364  0.1791622   0.16638446 -0.12640452]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 605. State = [[-0.23466626 -0.16133203]]. Action = [[ 0.09004033 -0.05851795 -0.08054832  0.802768  ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 606. State = [[-0.22487827 -0.15015271]]. Action = [[-0.01158288  0.1951828  -0.02808692  0.5059581 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 607. State = [[-0.21744421 -0.14963065]]. Action = [[ 0.13275391 -0.23296553  0.16312873  0.09780705]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 608. State = [[-0.20300211 -0.16939434]]. Action = [[ 0.10161275 -0.16108622  0.07215658 -0.12158191]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 609. State = [[-0.19351096 -0.17306668]]. Action = [[-0.04372539  0.20666862  0.12075457  0.93539953]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 610. State = [[-0.19334365 -0.16169435]]. Action = [[-0.05891466  0.05585635 -0.06108609 -0.83071864]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 611. State = [[-0.19532578 -0.14848645]]. Action = [[-0.06656271  0.14291441  0.11373413 -0.43885112]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 612. State = [[-0.19781248 -0.14086625]]. Action = [[ 0.10747886 -0.08829591  0.10435441  0.88013875]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 613. State = [[-0.1887805  -0.12911722]]. Action = [[0.17211306 0.21940333 0.11987573 0.19648015]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 614. State = [[-0.17001787 -0.12218148]]. Action = [[ 0.24661857 -0.10870409  0.0627583  -0.8463749 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 615. State = [[-0.1505347 -0.1380094]]. Action = [[-0.04733151 -0.21355176  0.16963893 -0.7564452 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 616. State = [[-0.14046812 -0.16323963]]. Action = [[ 0.18640706 -0.22395203  0.09607562  0.8178818 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 617. State = [[-0.11691176 -0.16895446]]. Action = [[0.14655817 0.22390866 0.14097041 0.4698342 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 618. State = [[-0.10246844 -0.1722427 ]]. Action = [[ 0.03033698 -0.2051035   0.00654635  0.32610548]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 619. State = [[-0.10053425 -0.1872332 ]]. Action = [[-0.1501211  -0.07068908 -0.11454946  0.9241352 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 620. State = [[-0.10322503 -0.19251806]]. Action = [[-0.01376505  0.05154943 -0.2331551   0.44450033]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 621. State = [[-0.10534645 -0.19940393]]. Action = [[-0.03147268 -0.11329117 -0.12429261 -0.4538955 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 622. State = [[-0.11033159 -0.21574412]]. Action = [[-0.02733032 -0.17166121  0.20903343  0.24848235]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 623. State = [[-0.11555831 -0.2264356 ]]. Action = [[-0.08869454  0.04441279  0.17406881  0.19598413]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 624. State = [[-0.113488   -0.23769481]]. Action = [[ 0.23430324 -0.21432544 -0.09682602  0.39312375]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 625. State = [[-0.10171451 -0.23717591]]. Action = [[0.0976595  0.22968328 0.03125075 0.78057694]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 626. State = [[-0.09042303 -0.21997674]]. Action = [[ 0.06019506  0.11400074  0.12762725 -0.04142374]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 627. State = [[-0.08780238 -0.20990306]]. Action = [[-0.20261174  0.05109113 -0.00183815  0.8437871 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 628. State = [[-0.09822921 -0.21356812]]. Action = [[-0.19076423 -0.09363364 -0.10530119  0.37792015]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 629. State = [[-0.10890771 -0.20767757]]. Action = [[ 0.05142921  0.18313205 -0.02276926 -0.12121916]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 630. State = [[-0.11291264 -0.20765245]]. Action = [[-0.06381577 -0.20914236 -0.19978459  0.9688051 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 631. State = [[-0.12311821 -0.21845926]]. Action = [[-0.07201006 -0.02022755  0.13288936  0.8733134 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 632. State = [[-0.13527372 -0.22092205]]. Action = [[-0.17858501  0.06525132 -0.11259577  0.49848247]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 633. State = [[-0.15071292 -0.21718583]]. Action = [[-0.00770092  0.00525036 -0.09960209  0.49466395]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 634. State = [[-0.15753727 -0.21230185]]. Action = [[-0.12386408  0.08385089  0.08613142 -0.00683868]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 635. State = [[-0.16167466 -0.19339916]]. Action = [[ 0.21533006  0.22112477  0.09146154 -0.72595465]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 636. State = [[-0.15330023 -0.18141101]]. Action = [[ 0.11120349 -0.1530074  -0.22239728 -0.74546945]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 637. State = [[-0.15057772 -0.18097714]]. Action = [[-0.13055597  0.09223974 -0.00656793  0.8201295 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 638. State = [[-0.14721644 -0.1678369 ]]. Action = [[0.15313202 0.18033224 0.02338508 0.7544596 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 639. State = [[-0.13818324 -0.14030229]]. Action = [[ 0.10190699  0.22244951  0.07584929 -0.88086766]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 640. State = [[-0.13525385 -0.13449553]]. Action = [[-0.17308009 -0.20446408  0.17021126  0.5722077 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 641. State = [[-0.14487724 -0.13413717]]. Action = [[-0.18052387  0.16315588 -0.17484863  0.00262165]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 642. State = [[-0.15021047 -0.11187421]]. Action = [[ 0.21953559  0.23682314  0.23061025 -0.84477097]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 643. State = [[-0.13892609 -0.10107931]]. Action = [[ 0.18199664 -0.138912   -0.09826952  0.8860389 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 644. State = [[-0.12081492 -0.10279585]]. Action = [[ 0.1286403   0.00102288 -0.08823773  0.9549289 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 645. State = [[-0.1118919  -0.11097199]]. Action = [[-0.12745759 -0.10707366 -0.06680924  0.9015045 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 646. State = [[-0.12064946 -0.11691844]]. Action = [[-0.2233774   0.05520386  0.17306685  0.8977885 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 647. State = [[-0.13583945 -0.11310349]]. Action = [[-0.09124693  0.05687982 -0.10594776 -0.12459499]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 648. State = [[-0.15400004 -0.1018014 ]]. Action = [[-0.2411232   0.13237935  0.17186669  0.26863885]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 649. State = [[-0.17433104 -0.07806367]]. Action = [[-0.01979965  0.23608083  0.16517872 -0.86112493]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 650. State = [[-0.17664583 -0.06979102]]. Action = [[ 0.10183638 -0.19041178  0.07340243 -0.0831939 ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 651. State = [[-0.17328341 -0.07029416]]. Action = [[ 0.11718121  0.12036294  0.2215403  -0.77761126]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 652. State = [[-0.17675835 -0.06265073]]. Action = [[-0.2242699   0.05970204  0.05556086  0.8659495 ]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 653. State = [[-0.17618425 -0.0700882 ]]. Action = [[ 0.18880078 -0.24513906  0.06793165  0.9779825 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 654. State = [[-0.17074816 -0.07491862]]. Action = [[ 0.05853683  0.16021764 -0.16424267  0.7069714 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 655. State = [[-0.1615153 -0.0595932]]. Action = [[0.15138504 0.16724432 0.09791064 0.2592696 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 656. State = [[-0.15683313 -0.05831851]]. Action = [[-0.16883165 -0.18507545 -0.1375394   0.21416306]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 657. State = [[-0.15753216 -0.07471549]]. Action = [[ 0.06759462 -0.16434965 -0.13649504  0.11860037]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 658. State = [[-0.15290634 -0.08020245]]. Action = [[ 0.10888329  0.12188417  0.15270609 -0.23644423]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 659. State = [[-0.15601069 -0.08734287]]. Action = [[-0.19788168 -0.18161501 -0.03786775 -0.10675865]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 660. State = [[-0.15777344 -0.10668224]]. Action = [[ 0.13938057 -0.1894437   0.20470834  0.5065696 ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 661. State = [[-0.15885854 -0.11346702]]. Action = [[-0.16402362  0.17531031 -0.14024599  0.5858576 ]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 662. State = [[-0.15682256 -0.11528659]]. Action = [[ 0.23609793 -0.16018394  0.03543293  0.68071365]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 663. State = [[-0.14838657 -0.1159368 ]]. Action = [[ 0.00777054  0.12139785 -0.05425033  0.8048023 ]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 664. State = [[-0.1457034  -0.11216592]]. Action = [[ 0.02586204 -0.02939163  0.14216116 -0.78512603]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 665. State = [[-0.13095354 -0.10724724]]. Action = [[ 0.22701049  0.07268056 -0.15292202  0.9270351 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 666. State = [[-0.11952071 -0.11576986]]. Action = [[-0.15195307 -0.19958803 -0.10216597  0.30971444]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 667. State = [[-0.11633202 -0.11850786]]. Action = [[0.14382821 0.12454268 0.06302536 0.42393184]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 668. State = [[-0.10483281 -0.12437683]]. Action = [[ 0.17209479 -0.17777431  0.06804571 -0.1780039 ]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 669. State = [[-0.08083547 -0.131364  ]]. Action = [[ 0.21227783  0.0235633  -0.02544278 -0.860593  ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 670. State = [[-0.05608399 -0.12719944]]. Action = [[0.11981708 0.07435018 0.0109342  0.2520696 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 671. State = [[-0.03864024 -0.11009956]]. Action = [[ 0.06327412  0.23571712 -0.22029608  0.43605924]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 672. State = [[-0.22109956  0.01281247]]. Action = [[ 0.14185756 -0.15205489  0.1448659   0.04652464]]. Reward = [100.]
Curr episode timestep = 95
Current timestep = 673. State = [[-0.21571985  0.00670357]]. Action = [[-0.07974571 -0.1896529   0.12369725 -0.89459854]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 674. State = [[-0.21302816 -0.00949941]]. Action = [[ 0.11312792 -0.11589293  0.15431255 -0.46961915]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 675. State = [[-0.2041141  -0.00979301]]. Action = [[ 0.10040015  0.17635727 -0.04153195  0.44324923]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 676. State = [[-0.18794443 -0.01250708]]. Action = [[ 0.15279183 -0.16502918 -0.21518445  0.4862702 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 677. State = [[-0.1630663  -0.02049675]]. Action = [[ 0.228322   -0.0275165  -0.12149218 -0.10690194]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 678. State = [[-0.13441044 -0.03123676]]. Action = [[ 0.15803021 -0.12848295 -0.15129355  0.30859637]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 679. State = [[-0.11689486 -0.0426571 ]]. Action = [[ 0.01499858 -0.03893295 -0.08166739 -0.8625571 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 680. State = [[-0.11454066 -0.03645315]]. Action = [[ 0.01857331  0.20888135 -0.21258613  0.22229135]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 681. State = [[-0.11396933 -0.03885775]]. Action = [[-0.01553209 -0.21867524 -0.15159632 -0.8590998 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 682. State = [[-0.11356105 -0.05673944]]. Action = [[-0.04676755 -0.12952314  0.13620123 -0.9468458 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 683. State = [[-0.11354414 -0.07775913]]. Action = [[ 0.07134008 -0.17424998 -0.03526166  0.58852434]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 684. State = [[-0.10204781 -0.07988669]]. Action = [[ 0.19926625  0.20132446 -0.07624242  0.56780803]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 685. State = [[-0.0844373  -0.06654608]]. Action = [[-0.03522868  0.09173071 -0.21673267 -0.27631724]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 686. State = [[-0.08735204 -0.0520448 ]]. Action = [[-0.16257182  0.1224764  -0.1453971  -0.36389953]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 687. State = [[-0.09453323 -0.03067864]]. Action = [[-0.09792508  0.16439354 -0.21050334 -0.64888865]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 688. State = [[-0.10202372 -0.00486927]]. Action = [[-0.01467702  0.22982037  0.19734386  0.2307682 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 689. State = [[-0.10952593  0.00917956]]. Action = [[-0.11445267 -0.0954939   0.1960598  -0.9277332 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 690. State = [[-0.11201701 -0.00730208]]. Action = [[ 0.09417212 -0.22936377  0.05409431  0.5385153 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 691. State = [[-0.11046477 -0.01829197]]. Action = [[ 0.10830933  0.06247067 -0.05636764  0.2866279 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 692. State = [[-0.10625914 -0.01661221]]. Action = [[ 0.06964722  0.0058088   0.09684342 -0.5554711 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 693. State = [[-0.10695753 -0.02993899]]. Action = [[-0.19694886 -0.21480468  0.18467444 -0.77002   ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 694. State = [[-0.11588848 -0.04296621]]. Action = [[-0.15494187  0.00717756 -0.14842694  0.5049794 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 695. State = [[-0.12008477 -0.03565236]]. Action = [[ 0.18433255  0.19120419 -0.2093031   0.29123056]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 696. State = [[-0.1252317  -0.01314705]]. Action = [[-0.22266573  0.19279763  0.02213177 -0.25912124]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 697. State = [[-0.1300737   0.01304854]]. Action = [[0.12482038 0.1374985  0.15446836 0.36019993]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 698. State = [[-0.13533509  0.01022469]]. Action = [[-0.21559423 -0.24023493  0.20755047  0.03303969]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 699. State = [[-0.13651758 -0.00062104]]. Action = [[ 0.19193977  0.01054546 -0.13504802  0.48732674]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 700. State = [[-0.13032377 -0.00850191]]. Action = [[ 0.07929412 -0.1110597   0.08183083  0.1904726 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 701. State = [[-0.12501712 -0.03092649]]. Action = [[ 0.0392465  -0.24191451 -0.15766855  0.36363494]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 702. State = [[-0.11157648 -0.03669422]]. Action = [[ 0.23460257  0.22592068 -0.02916601 -0.09880114]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 703. State = [[-0.08462562 -0.02925232]]. Action = [[ 0.2218805  -0.03497003  0.14766377 -0.6981521 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 704. State = [[-0.07200434 -0.01820933]]. Action = [[-0.2163486   0.17636788  0.14966083 -0.05573565]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 705. State = [[-0.07456324 -0.00852794]]. Action = [[ 0.02074081 -0.02291642  0.22050142 -0.31637377]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 706. State = [[-0.07150305 -0.00296444]]. Action = [[0.14112797 0.08013293 0.07939982 0.5471834 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 707. State = [[-0.0665928   0.00187867]]. Action = [[ 4.2174906e-02 -1.4793873e-04  1.4582005e-01 -2.7852803e-01]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 708. State = [[-0.05556018 -0.00521079]]. Action = [[ 0.19450629 -0.14438395 -0.05793941  0.90730023]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 709. State = [[-0.04458509 -0.00396221]]. Action = [[-0.19303297  0.13707408  0.05511162 -0.1879471 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 710. State = [[-0.04158802  0.00159015]]. Action = [[ 0.18533617  0.00769836 -0.09418204 -0.52759624]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 711. State = [[-0.16148987 -0.01448424]]. Action = [[ 0.13955659  0.20525965 -0.17523406  0.96521187]]. Reward = [100.]
Curr episode timestep = 38
Current timestep = 712. State = [[-0.13668692 -0.01570189]]. Action = [[ 0.22470081  0.07233775  0.08390146 -0.57352585]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 713. State = [[-0.11094634 -0.01325214]]. Action = [[ 0.14312741  0.00878716 -0.11214629 -0.17482466]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 714. State = [[-0.09010935 -0.02107432]]. Action = [[ 0.08868715 -0.16709276 -0.17983505  0.4057951 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 715. State = [[-0.07447404 -0.04161235]]. Action = [[ 0.13358039 -0.20945062 -0.11346924  0.15297878]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 716. State = [[-0.0529684  -0.05695242]]. Action = [[0.20938095 0.00976712 0.02993044 0.01684642]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 717. State = [[-0.20675093 -0.00642842]]. Action = [[-0.05423796  0.0543288   0.01324534  0.04932535]]. Reward = [100.]
Curr episode timestep = 5
Current timestep = 718. State = [[-0.19264494 -0.02279893]]. Action = [[ 0.13886887 -0.23080972 -0.01685706 -0.21087462]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 719. State = [[-0.18145129 -0.05175838]]. Action = [[-0.05035147 -0.2067877  -0.17405602 -0.39956158]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 720. State = [[-0.18229486 -0.08381274]]. Action = [[-0.00870657 -0.23604228 -0.01692531 -0.8273442 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 721. State = [[-0.17589132 -0.09358656]]. Action = [[ 0.17205477  0.17282319 -0.11633724  0.710624  ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 722. State = [[-0.16622686 -0.09738932]]. Action = [[-0.02642761 -0.17521445 -0.03170502 -0.01979673]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 723. State = [[-0.15767208 -0.09989909]]. Action = [[0.14245635 0.11297041 0.06203127 0.02427888]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 724. State = [[-0.15035486 -0.10505095]]. Action = [[-0.14831933 -0.14493467 -0.08270293  0.57833576]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 725. State = [[-0.15505953 -0.12419087]]. Action = [[-0.06114471 -0.17788541  0.07050917 -0.81439376]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 726. State = [[-0.15434177 -0.13835058]]. Action = [[ 0.18133742 -0.02711219 -0.20739873  0.72243404]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 727. State = [[-0.14278242 -0.1441116 ]]. Action = [[ 0.17246634 -0.04490025 -0.09479991 -0.47302222]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 728. State = [[-0.12599698 -0.14470805]]. Action = [[0.00594497 0.09389281 0.22527614 0.7586217 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 729. State = [[-0.1249382  -0.12843584]]. Action = [[-0.09984979  0.23455799  0.10994834  0.86625123]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 730. State = [[-0.12566571 -0.11681603]]. Action = [[ 0.0087336  -0.08609357  0.13946769  0.73748565]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 731. State = [[-0.12557478 -0.106538  ]]. Action = [[ 0.00945431  0.20225209  0.14765155 -0.26938462]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 732. State = [[-0.11935706 -0.08264038]]. Action = [[ 0.19658709  0.18989825 -0.01864927 -0.8021937 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 733. State = [[-0.11068041 -0.08085436]]. Action = [[-0.05760761 -0.24339657 -0.20606026  0.8274901 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 734. State = [[-0.11023657 -0.08504539]]. Action = [[ 0.01755676  0.11457101 -0.13893445 -0.87569875]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 735. State = [[-0.1024771  -0.08434606]]. Action = [[ 0.16186696 -0.05344002 -0.18557519 -0.00537437]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 736. State = [[-0.08523983 -0.09448271]]. Action = [[ 0.10896593 -0.15547353 -0.09018037 -0.5398134 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 737. State = [[-0.06427491 -0.11057246]]. Action = [[ 0.20305055 -0.09102795 -0.15310264  0.83177733]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 738. State = [[-0.05006682 -0.1145912 ]]. Action = [[-0.07861388  0.08107516 -0.05854905  0.0882777 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 739. State = [[-0.04562342 -0.10035961]]. Action = [[ 0.10908952  0.20754975  0.15136081 -0.79903215]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 740. State = [[-0.0395018 -0.0718997]]. Action = [[-0.01570782  0.23994848  0.17221701 -0.83642405]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 741. State = [[-0.0387517  -0.04494129]]. Action = [[0.05881023 0.13055736 0.02128452 0.43313718]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 742. State = [[-0.03854443 -0.04307065]]. Action = [[-0.10437199 -0.17597203  0.03649402  0.21998465]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 743. State = [[-0.04061474 -0.03571975]]. Action = [[-0.03991443  0.24628395  0.18151051  0.23757172]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 744. State = [[-0.04325523 -0.03500609]]. Action = [[-0.04521511 -0.21913648  0.11150429  0.9754621 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 745. State = [[-0.04440984 -0.03463468]]. Action = [[ 0.10175642  0.19092667  0.11305696 -0.57619804]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 746. State = [[-0.03845089 -0.02202625]]. Action = [[ 0.16042489  0.06786388  0.19464916 -0.7900395 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 747. State = [[-0.24784504 -0.11421885]]. Action = [[ 0.21131954 -0.09760916  0.11647072 -0.08832502]]. Reward = [100.]
Curr episode timestep = 29
Current timestep = 748. State = [[-0.24682964 -0.13543603]]. Action = [[-0.1139356  -0.12279868  0.05791968  0.01676011]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 749. State = [[-0.25028768 -0.14449827]]. Action = [[-0.23980013  0.19598785 -0.08782765  0.1458919 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 750. State = [[-0.24511987 -0.13420887]]. Action = [[ 0.19584966  0.2239092   0.03757358 -0.91991854]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 751. State = [[-0.22961095 -0.13411911]]. Action = [[ 0.14211643 -0.22502925 -0.11326319  0.49100184]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 752. State = [[-0.22231899 -0.1401816 ]]. Action = [[-0.19325349  0.08287004 -0.01125258 -0.71371794]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 753. State = [[-0.22329938 -0.14571935]]. Action = [[ 0.14856702 -0.14385936 -0.06254417 -0.3959762 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 754. State = [[-0.21129155 -0.14061947]]. Action = [[ 0.17445874  0.22164536  0.10297474 -0.13571304]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 755. State = [[-0.20409831 -0.12046257]]. Action = [[-0.16169202  0.16903603 -0.05209899 -0.59851056]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 756. State = [[-0.20870252 -0.0965308 ]]. Action = [[-0.06175682  0.19437331  0.01966548  0.269709  ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 757. State = [[-0.21238439 -0.07095139]]. Action = [[ 0.06892318  0.14690667 -0.01955669  0.48566616]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 758. State = [[-0.20958175 -0.05240143]]. Action = [[ 0.11150819  0.08883965 -0.08101588  0.53365755]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 759. State = [[-0.20318818 -0.03427217]]. Action = [[ 0.04134279  0.1592477  -0.16646038  0.49242604]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 760. State = [[-0.19566959 -0.01965444]]. Action = [[ 0.09161091  0.04977271 -0.2002903  -0.3397997 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 761. State = [[-0.18126395 -0.00084167]]. Action = [[0.09585792 0.20327234 0.13002527 0.73024654]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 762. State = [[-0.16179168  0.01394923]]. Action = [[ 0.21234357  0.00282431  0.08537483 -0.93792707]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 763. State = [[-0.13742466  0.00965507]]. Action = [[ 0.12213075 -0.1415645   0.19288504 -0.91415805]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 764. State = [[-0.11341882 -0.00934803]]. Action = [[ 0.24460065 -0.2274102   0.23406011 -0.6994889 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 765. State = [[-0.08341452 -0.01143195]]. Action = [[ 0.19056153  0.24515438 -0.17249142 -0.26334757]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 766. State = [[-0.06011643  0.00410842]]. Action = [[ 0.06700739  0.08141053 -0.04188225 -0.02361643]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 767. State = [[-0.05034472 -0.00034302]]. Action = [[-0.04508907 -0.2258387  -0.15114652  0.3322519 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 768. State = [[-0.04863911 -0.02040171]]. Action = [[ 0.07617527 -0.13379525 -0.0212685  -0.7181166 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 769. State = [[-0.04853309 -0.02556433]]. Action = [[-0.18346441  0.09703895  0.00897485  0.80690825]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 770. State = [[-0.04885281 -0.0116921 ]]. Action = [[ 0.15791503  0.2065655  -0.06480771  0.6245234 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 771. State = [[-0.04194082  0.00095642]]. Action = [[ 0.22428387  0.00030276  0.21522072 -0.25769973]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 772. State = [[-0.1874133   0.12622653]]. Action = [[ 0.0012973  -0.05141126  0.05056792 -0.11674428]]. Reward = [100.]
Curr episode timestep = 24
Current timestep = 773. State = [[-0.17160353  0.15450278]]. Action = [[ 0.06744844  0.20452097 -0.2033225  -0.676231  ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 774. State = [[-0.1758      0.18430202]]. Action = [[-0.20435667  0.2457656   0.03423718 -0.58899575]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 775. State = [[-0.19409306  0.22012703]]. Action = [[-0.07137389  0.23909014 -0.11716273 -0.23211265]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 776. State = [[-0.2021996   0.23021498]]. Action = [[-0.06985581 -0.17630468  0.13348672 -0.17477643]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 777. State = [[-0.20242788  0.22722355]]. Action = [[-0.0271337   0.00873253  0.08337259  0.08188212]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 778. State = [[-0.19780484  0.21662772]]. Action = [[ 0.17942065 -0.13917239  0.22369057  0.07071364]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 779. State = [[-0.18620966  0.21139225]]. Action = [[ 0.17201608  0.09412512 -0.04832186  0.9012821 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 780. State = [[-0.16295262  0.20426737]]. Action = [[ 0.14137268 -0.17619526 -0.03641975 -0.34095562]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 781. State = [[-0.15228593  0.1910444 ]]. Action = [[-0.09446301 -0.0749483  -0.1099121  -0.5307233 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 782. State = [[-0.15349035  0.18287937]]. Action = [[-0.15964763 -0.07663837  0.21692142  0.0838716 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 783. State = [[-0.15064088  0.16428663]]. Action = [[ 0.10036346 -0.23740757 -0.23473454  0.9381523 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 784. State = [[-0.15047835  0.13245988]]. Action = [[-0.09748966 -0.24819207 -0.05267681  0.2114017 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 785. State = [[-0.16040614  0.09910891]]. Action = [[-0.12964377 -0.2351673  -0.09525558 -0.48261905]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 786. State = [[-0.16546687  0.06953152]]. Action = [[ 0.10051894 -0.12898588  0.08360454 -0.10202384]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 787. State = [[-0.1620211   0.05915203]]. Action = [[0.08565953 0.04136896 0.09264576 0.8013427 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 788. State = [[-0.15830241  0.05876865]]. Action = [[ 0.07674813  0.01821899 -0.10066471  0.6492766 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 789. State = [[-0.15693156  0.05625448]]. Action = [[-0.09480861 -0.05411449  0.15122801  0.90416837]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 790. State = [[-0.15582456  0.05346982]]. Action = [[0.09065729 0.00191504 0.24110872 0.86371875]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 791. State = [[-0.16039926  0.06419974]]. Action = [[-0.20704898  0.22686255  0.18643272  0.7822794 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 792. State = [[-0.16769412  0.07862578]]. Action = [[0.0465129  0.01932427 0.17778462 0.17429793]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 793. State = [[-0.16993496  0.08640075]]. Action = [[ 0.01610574  0.09537888 -0.04345134  0.5559778 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 794. State = [[-0.1702199   0.10627829]]. Action = [[ 0.08817163  0.22540927 -0.13014138 -0.59505004]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 795. State = [[-0.1591102   0.11029256]]. Action = [[ 0.19104174 -0.21195123 -0.16162153 -0.9153963 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 796. State = [[-0.1387763   0.10981601]]. Action = [[ 0.13302398  0.14539856 -0.12964068 -0.5355846 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 797. State = [[-0.12723304  0.1111277 ]]. Action = [[-0.04684301 -0.10583641 -0.05893904 -0.55247146]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 798. State = [[-0.12438726  0.09918255]]. Action = [[-0.050594   -0.16174108  0.21957442  0.48210835]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 799. State = [[-0.11673038  0.07366586]]. Action = [[ 0.20968163 -0.2315153  -0.21943507 -0.85693043]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 800. State = [[-0.11012183  0.05797677]]. Action = [[-0.0700071   0.11069775 -0.03363252  0.24993694]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 801. State = [[-0.10754993  0.06641198]]. Action = [[ 0.11047655  0.09699273 -0.02966255  0.40046525]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 802. State = [[-0.10275254  0.06764494]]. Action = [[ 0.05297583 -0.08623502 -0.19893692  0.06005061]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 803. State = [[-0.10237624  0.06813068]]. Action = [[-0.17149329  0.04733008 -0.08197397  0.20814693]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 804. State = [[-0.10758083  0.07436991]]. Action = [[-0.09936005  0.05241594 -0.21163923  0.8133626 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 805. State = [[-0.11789012  0.07407781]]. Action = [[-0.1924446  -0.09977755 -0.07005867  0.7640947 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 806. State = [[-0.12805888  0.05392106]]. Action = [[ 0.04239386 -0.24422048  0.13701552  0.1126883 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 807. State = [[-0.12614965  0.04487504]]. Action = [[ 0.22181934  0.14120191 -0.21148136 -0.47246623]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 808. State = [[-0.11560079  0.05400016]]. Action = [[0.12015444 0.10677695 0.07880738 0.01904011]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 809. State = [[-0.11264966  0.06418525]]. Action = [[-0.24089314  0.02986449 -0.12199825  0.13358247]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 810. State = [[-0.11218699  0.06797439]]. Action = [[ 0.21581611 -0.01189913  0.17988303  0.94103765]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 811. State = [[-0.11218001  0.05432035]]. Action = [[-0.1501    -0.2394161 -0.1520645 -0.4476763]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 812. State = [[-0.11327218  0.04358309]]. Action = [[-0.06336541  0.04705054 -0.06041908  0.47453547]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 813. State = [[-0.11413296  0.04580918]]. Action = [[ 0.11098784  0.06800187  0.07723993 -0.53263336]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 814. State = [[-0.11771347  0.06152976]]. Action = [[-0.10448268  0.24454623 -0.23053962 -0.38129318]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 815. State = [[-0.1156713   0.06706417]]. Action = [[ 0.22472653 -0.22407387  0.00237221  0.2353375 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 816. State = [[-0.10276236  0.06918614]]. Action = [[ 0.13683334  0.2478599   0.12594533 -0.08321631]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 817. State = [[-0.09162949  0.09093698]]. Action = [[-0.0278887   0.1468305  -0.06041694 -0.94566625]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 818. State = [[-0.08706958  0.1159529 ]]. Action = [[ 0.13638008  0.22385329 -0.09215064 -0.27949458]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 819. State = [[-0.07434992  0.12015515]]. Action = [[-0.0564739  -0.2483321   0.04358518  0.59179044]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 820. State = [[-0.0673582   0.10929431]]. Action = [[ 0.17978543 -0.01036167  0.08881044  0.8465866 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 821. State = [[-0.06200049  0.11743136]]. Action = [[-0.11064103  0.20683551 -0.16708975 -0.79543126]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 822. State = [[-0.06481305  0.11947967]]. Action = [[-0.06555918 -0.18397884  0.03044444 -0.8158299 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 823. State = [[-0.06758056  0.10789412]]. Action = [[-0.11969817 -0.10401845 -0.10814345 -0.18115866]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 824. State = [[-0.07372581  0.08911977]]. Action = [[-0.12836881 -0.16881227  0.21938616  0.02325034]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 825. State = [[-0.08655034  0.09060594]]. Action = [[-0.14746156  0.23106545  0.08420873 -0.02488667]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 826. State = [[-0.09581183  0.10007525]]. Action = [[ 0.21511173 -0.04826644 -0.15289547  0.60768676]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 827. State = [[-0.0855726   0.08513674]]. Action = [[ 0.21252644 -0.22896911 -0.1290899   0.1716268 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 828. State = [[-0.07079002  0.05727249]]. Action = [[ 0.10109198 -0.14383096  0.00575298  0.4222474 ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 829. State = [[-0.05792057  0.04913666]]. Action = [[ 0.12468123  0.09496224 -0.09761633 -0.98803437]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 830. State = [[-0.04666448  0.0529478 ]]. Action = [[-0.02330649 -0.0169536   0.20003462 -0.02695888]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 831. State = [[-0.04637147  0.05275878]]. Action = [[ 0.01576155 -0.0010289   0.13100299  0.20667446]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 832. State = [[-0.0480883   0.03921323]]. Action = [[-0.1838773  -0.22886679  0.21351361 -0.5279798 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 833. State = [[-0.04440634  0.01801108]]. Action = [[ 0.0865145  -0.12957965 -0.05349834  0.8565891 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 834. State = [[-0.04616473  0.00243838]]. Action = [[-0.19950171 -0.05266856 -0.09449807  0.43172085]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 835. State = [[-0.05336878 -0.00664997]]. Action = [[ 0.015403   -0.03861195  0.19374284  0.13348222]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 836. State = [[-0.05361208 -0.00882173]]. Action = [[0.10966238 0.00731933 0.1979999  0.819718  ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 837. State = [[-0.05489266 -0.01297211]]. Action = [[-0.13540187 -0.06330675 -0.20782146 -0.91426116]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 838. State = [[-0.0569089  -0.01157615]]. Action = [[ 0.10221404  0.12169427  0.2364729  -0.31236053]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 839. State = [[-0.04862125  0.00445388]]. Action = [[ 0.2263534   0.18928415  0.19506437 -0.5583395 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 840. State = [[-0.24445045 -0.18402325]]. Action = [[ 0.1568858   0.14934194  0.0767473  -0.05188459]]. Reward = [100.]
Curr episode timestep = 67
Current timestep = 841. State = [[-0.24272256 -0.19705783]]. Action = [[-0.15946864  0.17433935  0.01581821 -0.33934593]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 842. State = [[-0.251567   -0.18181723]]. Action = [[-0.10223371  0.15597713 -0.03321409  0.14525151]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 843. State = [[-0.25755286 -0.16557902]]. Action = [[0.02247891 0.05742386 0.10802174 0.47398508]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 844. State = [[-0.25460625 -0.16575864]]. Action = [[ 0.14310864 -0.15107031 -0.20851961  0.21983945]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 845. State = [[-0.25320923 -0.16957526]]. Action = [[-0.08483928  0.01633888 -0.10391378 -0.528258  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 846. State = [[-0.25887445 -0.17717385]]. Action = [[-0.1044504  -0.08514483  0.03637046  0.7567222 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 847. State = [[-0.26682392 -0.1714705 ]]. Action = [[-0.04843351  0.22725469  0.11501175  0.5685053 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 848. State = [[-0.27026454 -0.17152193]]. Action = [[ 0.04574639 -0.22237231 -0.06760833 -0.43399847]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 849. State = [[-0.26673758 -0.18868245]]. Action = [[ 0.12173516 -0.14408007 -0.01828685 -0.85330635]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 850. State = [[-0.26408294 -0.19960219]]. Action = [[-0.10831624 -0.2023621  -0.14515905 -0.4278357 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 851. State = [[-0.25450346 -0.18974744]]. Action = [[0.17370623 0.21280083 0.23399127 0.8144208 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 852. State = [[-0.24595751 -0.16809113]]. Action = [[-0.11768812  0.19932371  0.1586445  -0.5659946 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 853. State = [[-0.25129503 -0.16177928]]. Action = [[-0.11169972 -0.13608673 -0.1476458   0.0522275 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 854. State = [[-0.25470978 -0.16589496]]. Action = [[ 0.09671584 -0.02570932 -0.17912878  0.5896361 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 855. State = [[-0.25145382 -0.15697856]]. Action = [[ 0.06626832  0.16676372 -0.09999366  0.768052  ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 856. State = [[-0.25006038 -0.15077141]]. Action = [[-0.00232083  0.002446   -0.11339876 -0.8398179 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 857. State = [[-0.24114868 -0.1415935 ]]. Action = [[ 0.16108185  0.10199684 -0.21024175 -0.30556834]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 858. State = [[-0.23080906 -0.13986863]]. Action = [[-0.04331216 -0.11147228 -0.22869764 -0.32028604]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 859. State = [[-0.22369243 -0.14945616]]. Action = [[ 0.14713907 -0.11426149  0.03220192  0.7659874 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 860. State = [[-0.20440999 -0.16907153]]. Action = [[ 0.18397307 -0.22087944 -0.03755715 -0.14734691]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 861. State = [[-0.18230325 -0.18090662]]. Action = [[ 0.11350787  0.09877437 -0.0469545   0.10223389]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 862. State = [[-0.17698655 -0.16878393]]. Action = [[-0.17123213  0.2343272  -0.11171325 -0.605517  ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 863. State = [[-0.17464009 -0.16389878]]. Action = [[ 0.18371236 -0.23748824 -0.15010455 -0.08215857]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 864. State = [[-0.17016852 -0.16879737]]. Action = [[-0.03551869  0.10970899  0.21547687 -0.16526616]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 865. State = [[-0.1707053  -0.16676545]]. Action = [[-0.08083352  0.01696405  0.04171953  0.03337157]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 866. State = [[-0.1727178  -0.16557166]]. Action = [[-0.05532169  0.01127797  0.07977855  0.23000503]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 867. State = [[-0.18391912 -0.17637184]]. Action = [[-0.15670307 -0.18160722  0.03220516  0.563511  ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 868. State = [[-0.19453478 -0.18694091]]. Action = [[-0.00472045  0.00449523 -0.20404705 -0.04170656]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 869. State = [[-0.1908395  -0.17437723]]. Action = [[ 0.19292343  0.23290166 -0.13048391 -0.57959616]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 870. State = [[-0.17535187 -0.14608322]]. Action = [[0.2149663 0.1801424 0.2088772 0.9802346]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 871. State = [[-0.16161464 -0.11912839]]. Action = [[-0.01461202  0.20011121 -0.06181885  0.3492937 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 872. State = [[-0.15519668 -0.09554717]]. Action = [[ 0.09438929  0.1069653  -0.15966399  0.6658995 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 873. State = [[-0.14733215 -0.09412904]]. Action = [[ 0.02428845 -0.16671884  0.17127037 -0.7398366 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 874. State = [[-0.14451478 -0.08595951]]. Action = [[ 0.00681174  0.24475867 -0.15885971  0.64351296]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 875. State = [[-0.13548563 -0.08108365]]. Action = [[ 0.14523047 -0.13029917  0.10680038 -0.8064914 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 876. State = [[-0.1268232  -0.09622596]]. Action = [[-0.09544984 -0.17356575 -0.21853042 -0.79451185]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 877. State = [[-0.11957511 -0.11720592]]. Action = [[ 0.21835855 -0.16894023  0.20914811  0.5968008 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 878. State = [[-0.10736734 -0.1460395 ]]. Action = [[-0.04311283 -0.23497231  0.10952023  0.6021029 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 879. State = [[-0.11105148 -0.16549204]]. Action = [[-0.21454172  0.00957686  0.21668577 -0.641347  ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 880. State = [[-0.11720698 -0.17268206]]. Action = [[-0.0075123  -0.02351347 -0.13182868  0.9615731 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 881. State = [[-0.11814096 -0.17423695]]. Action = [[ 0.11975005  0.0216032   0.04966348 -0.5005185 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 882. State = [[-0.1171496  -0.16390924]]. Action = [[-0.00717901  0.15191463 -0.0478361   0.30595505]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 883. State = [[-0.10927001 -0.13931596]]. Action = [[ 0.1688833   0.2336865  -0.19956014  0.5985565 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 884. State = [[-0.10063495 -0.11182644]]. Action = [[-0.00741841  0.14553264  0.23595124 -0.67551416]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 885. State = [[-0.09586288 -0.09022978]]. Action = [[ 0.08316395  0.14285836 -0.02632388  0.5299643 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 886. State = [[-0.08396444 -0.08806988]]. Action = [[ 0.12728506 -0.18719953 -0.15561911  0.93726134]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 887. State = [[-0.06610182 -0.09248453]]. Action = [[ 0.13589549  0.06314346 -0.14040585  0.49981713]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 888. State = [[-0.05118853 -0.1005628 ]]. Action = [[ 0.04467714 -0.16335581 -0.18488678  0.8110573 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 889. State = [[-0.03412122 -0.12213971]]. Action = [[ 0.23982888 -0.22162105  0.18687838  0.45794392]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 890. State = [[-0.01250386 -0.1339016 ]]. Action = [[ 0.00832424  0.10250071  0.08538079 -0.22274745]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 891. State = [[-0.01050377 -0.12117045]]. Action = [[-0.1564177   0.18812484  0.2046166  -0.7106547 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 892. State = [[-0.01440647 -0.11579342]]. Action = [[-0.14063025 -0.0798628  -0.15894629  0.44199133]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 893. State = [[-0.01879864 -0.12813118]]. Action = [[ 0.04239702 -0.15139928  0.1511544  -0.0427202 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 894. State = [[-0.01851166 -0.12735838]]. Action = [[ 0.14929372  0.1515539  -0.05617625 -0.7240587 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 895. State = [[-0.01011511 -0.12795317]]. Action = [[ 0.22800058 -0.1527903  -0.21204746  0.5907397 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 896. State = [[ 0.0026982  -0.13806981]]. Action = [[-0.16570152 -0.04996665  0.05541828  0.39232135]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 897. State = [[ 0.00125245 -0.13973317]]. Action = [[-0.08727643  0.06741697  0.116218    0.43033743]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 898. State = [[-0.0038304  -0.12930153]]. Action = [[-0.15627101  0.16718984  0.164154    0.51153076]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 899. State = [[-0.02058939 -0.1050192 ]]. Action = [[-0.22259066  0.22963756  0.02267605 -0.16026151]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 900. State = [[-0.04030109 -0.07072604]]. Action = [[ 0.04895788  0.20508683 -0.17596585 -0.8351346 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 901. State = [[-0.04807533 -0.05992098]]. Action = [[-0.13742767 -0.08925056  0.1613166   0.30245852]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 902. State = [[-0.06185849 -0.07155702]]. Action = [[-0.10748753 -0.14326635 -0.1459801   0.8601322 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 903. State = [[-0.0674457 -0.0674087]]. Action = [[ 0.22171015  0.21834934 -0.05863728  0.23476517]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 904. State = [[-0.05637766 -0.05448243]]. Action = [[ 0.18467408  0.00684115  0.11969373 -0.6903217 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 905. State = [[-0.04645094 -0.06224101]]. Action = [[-0.04091457 -0.1955402   0.1190891  -0.35721004]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 906. State = [[-0.0451226  -0.08627453]]. Action = [[ 0.0118418  -0.22244498 -0.09421948 -0.6528217 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 907. State = [[-0.04661698 -0.09336518]]. Action = [[-0.15227088  0.18039873 -0.19946896 -0.18582183]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 908. State = [[-0.04963189 -0.0744671 ]]. Action = [[0.00027898 0.23348168 0.11809573 0.10421276]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 909. State = [[-0.05418167 -0.06830645]]. Action = [[-0.06765276 -0.21962388  0.15697712 -0.7508325 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 910. State = [[-0.0533617  -0.08767235]]. Action = [[ 0.17767876 -0.1721322   0.10656551  0.73851204]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 911. State = [[-0.05144126 -0.10554835]]. Action = [[-0.08987898 -0.07173118 -0.21989681 -0.03028518]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 912. State = [[-0.05836184 -0.10151412]]. Action = [[-0.21260436  0.2279292   0.07975107 -0.69801456]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 913. State = [[-0.06604789 -0.09625358]]. Action = [[ 0.16002169 -0.14369093 -0.20259081 -0.21109676]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 914. State = [[-0.05949545 -0.09034841]]. Action = [[0.15248787 0.18777394 0.19843066 0.69437313]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 915. State = [[-0.05800686 -0.07563155]]. Action = [[-0.18223122  0.10212725 -0.22429672 -0.922204  ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 916. State = [[-0.06308302 -0.05456279]]. Action = [[-0.10368416  0.19449684 -0.10533345  0.15443683]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 917. State = [[-0.06501164 -0.02626526]]. Action = [[ 0.22832882  0.20617062 -0.15537126  0.7258558 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 918. State = [[-0.05327133 -0.00343184]]. Action = [[ 0.23720258  0.1131492  -0.05322433  0.88381934]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 919. State = [[-0.19851042 -0.036756  ]]. Action = [[-0.05165684 -0.09334396 -0.04689103  0.83337307]]. Reward = [100.]
Curr episode timestep = 78
Current timestep = 920. State = [[-0.1857714  -0.05615182]]. Action = [[ 0.00182432 -0.2149666   0.05096611  0.60333157]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 921. State = [[-0.18822342 -0.0657436 ]]. Action = [[-0.13565053  0.09797129 -0.14423425 -0.8330257 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 922. State = [[-0.18823807 -0.07404554]]. Action = [[ 0.08790183 -0.1704863  -0.23428303 -0.9416358 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 923. State = [[-0.1934829 -0.0791086]]. Action = [[-0.21321665  0.08223504  0.13702229 -0.16405356]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 924. State = [[-0.21005194 -0.07335992]]. Action = [[-0.1690215   0.07981831  0.02414542 -0.527721  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 925. State = [[-0.23223822 -0.05731867]]. Action = [[-0.14610316  0.17454457 -0.23051521  0.830173  ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 926. State = [[-0.23997633 -0.05529957]]. Action = [[ 0.19571373 -0.2013743  -0.06048295 -0.74072045]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 927. State = [[-0.24265523 -0.05891571]]. Action = [[-0.1911164   0.09998479  0.18606621  0.44287324]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 928. State = [[-0.24938242 -0.06636655]]. Action = [[-0.04707089 -0.16463788 -0.12862083  0.01365221]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 929. State = [[-0.25315836 -0.07699458]]. Action = [[ 0.01165956 -0.01075894 -0.0729385   0.8363197 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 930. State = [[-0.25386173 -0.08736511]]. Action = [[ 0.04129595 -0.12617882  0.1646936  -0.72615457]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 931. State = [[-0.25022087 -0.09448264]]. Action = [[ 0.12121853 -0.01938516 -0.09682159  0.21115816]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 932. State = [[-0.24142104 -0.09614088]]. Action = [[ 0.12615782  0.03924713 -0.06907001 -0.5078526 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 933. State = [[-0.23415983 -0.08269145]]. Action = [[-0.05207269  0.235349    0.13523471  0.19489467]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 934. State = [[-0.23674788 -0.05811502]]. Action = [[-0.06118515  0.17878824 -0.20440328 -0.12843686]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 935. State = [[-0.23907714 -0.05282971]]. Action = [[ 0.00538707 -0.1855822  -0.10991254  0.47967374]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 936. State = [[-0.22935344 -0.06389528]]. Action = [[ 0.21676123 -0.08268243  0.18570393 -0.22542685]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 937. State = [[-0.20828651 -0.07362153]]. Action = [[ 0.19021809 -0.05122814  0.17188063  0.12732196]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 938. State = [[-0.17946403 -0.08174523]]. Action = [[ 0.2316249  -0.06264213  0.07494867  0.00349462]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 939. State = [[-0.15430176 -0.07961094]]. Action = [[ 0.13594675  0.13275748 -0.16022399  0.23351526]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 940. State = [[-0.13312455 -0.08446842]]. Action = [[ 0.14992324 -0.17170855  0.08944905 -0.20332229]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 941. State = [[-0.11171789 -0.10281169]]. Action = [[ 0.1246208  -0.1844977  -0.02009244  0.72349906]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 942. State = [[-0.09950203 -0.12282822]]. Action = [[-0.03893322 -0.0859044  -0.20346443 -0.6133781 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 943. State = [[-0.10449223 -0.13369568]]. Action = [[-0.22145942 -0.01236151 -0.1427184  -0.29634392]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 944. State = [[-0.11055845 -0.13064939]]. Action = [[-0.02346005  0.1599727   0.10080335  0.4458946 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 945. State = [[-0.11236314 -0.11644989]]. Action = [[ 0.00838932  0.07604292 -0.07121949  0.09201467]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 946. State = [[-0.11691771 -0.12049559]]. Action = [[-0.09717354 -0.1802453   0.09667727  0.84029603]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 947. State = [[-0.13503824 -0.13610451]]. Action = [[-0.2338666  -0.08587775  0.20724937 -0.29443842]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 948. State = [[-0.16424115 -0.15400922]]. Action = [[-0.16145864 -0.15307632  0.09449941  0.03461158]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 949. State = [[-0.17466474 -0.1733493 ]]. Action = [[ 0.15799397 -0.15328705  0.22935218 -0.73515135]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 950. State = [[-0.17351353 -0.19772689]]. Action = [[-0.03761679 -0.1847851  -0.15596874  0.0043751 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 951. State = [[-0.18111773 -0.20993346]]. Action = [[-0.18080474  0.08989081 -0.04506046  0.03847384]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 952. State = [[-0.1977574  -0.20960765]]. Action = [[-0.1412573  -0.013556    0.22235864  0.63511264]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 953. State = [[-0.21592306 -0.21770807]]. Action = [[-0.15466462 -0.07995328 -0.12101406  0.41958487]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 954. State = [[-0.2303882  -0.23106907]]. Action = [[ 0.06100813 -0.15191676 -0.10973224  0.58102405]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 955. State = [[-0.22762866 -0.24099594]]. Action = [[ 0.12801063 -0.03401549 -0.0685039   0.39431584]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 956. State = [[-0.23001392 -0.24043098]]. Action = [[-0.2001541   0.11226386  0.09722579  0.83290124]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 957. State = [[-0.24024287 -0.22659485]]. Action = [[-0.14788745  0.22622246  0.02108523  0.93293643]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 958. State = [[-0.24950364 -0.21322541]]. Action = [[ 0.17004001 -0.07475737 -0.01483142 -0.1834476 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 959. State = [[-0.23981428 -0.2171065 ]]. Action = [[ 0.17812675 -0.10538492 -0.02386376  0.6042452 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 960. State = [[-0.22821377 -0.23202607]]. Action = [[ 0.08262557 -0.20944697  0.041888   -0.25509477]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 961. State = [[-0.220838   -0.23779202]]. Action = [[-0.06515375  0.22122717 -0.11514729  0.14091873]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 962. State = [[-0.21433824 -0.21674705]]. Action = [[ 0.12825894  0.18880147 -0.13141441 -0.4894427 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 963. State = [[-0.19854407 -0.20064381]]. Action = [[ 0.21363688 -0.01528513  0.18757516 -0.8610842 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 964. State = [[-0.19053262 -0.21032272]]. Action = [[-0.17794801 -0.20643486 -0.07288447  0.51004815]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 965. State = [[-0.19050586 -0.21544774]]. Action = [[ 0.12877369  0.11399829 -0.18091278  0.6337851 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 966. State = [[-0.18268287 -0.19684468]]. Action = [[ 0.06584629  0.24391767  0.00045589 -0.25209218]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 967. State = [[-0.17435911 -0.18866429]]. Action = [[ 0.09868145 -0.15852103 -0.18071313  0.16799796]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 968. State = [[-0.15806764 -0.19194293]]. Action = [[ 0.15353411  0.03478068 -0.19771646  0.5287746 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 969. State = [[-0.14520274 -0.20227142]]. Action = [[ 0.00463095 -0.18367012 -0.02938987 -0.65722066]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 970. State = [[-0.13970558 -0.21497479]]. Action = [[ 0.04498884 -0.05287755  0.07319951 -0.04347396]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 971. State = [[-0.12967587 -0.21090332]]. Action = [[ 0.13884342  0.15833837  0.14122245 -0.2118522 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 972. State = [[-0.11382452 -0.2010915 ]]. Action = [[ 0.07189786  0.05824623 -0.21703222  0.2308265 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 973. State = [[-0.10129239 -0.20722859]]. Action = [[ 0.07306921 -0.18574893  0.04550576 -0.28904665]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 974. State = [[-0.09644846 -0.20403375]]. Action = [[-0.04849729  0.20829558 -0.15712045  0.924232  ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 975. State = [[-0.10074726 -0.1855727 ]]. Action = [[-0.23186766  0.20195347  0.07276922  0.7209852 ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 976. State = [[-0.11830382 -0.17525212]]. Action = [[-0.19484255 -0.05809285 -0.16475798  0.32615662]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 977. State = [[-0.13063098 -0.16151589]]. Action = [[ 0.05934915  0.23591897 -0.08514513 -0.7353843 ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 978. State = [[-0.12667571 -0.13719101]]. Action = [[ 0.1933491   0.1014989  -0.09288937 -0.40801156]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 979. State = [[-0.12316829 -0.1379066 ]]. Action = [[-0.05799359 -0.20726193 -0.09052473 -0.08630073]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 980. State = [[-0.1212761  -0.15849838]]. Action = [[ 0.10472471 -0.21139884  0.23023584  0.9031129 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 981. State = [[-0.12123949 -0.1677913 ]]. Action = [[-0.15204951  0.15133429 -0.23255917 -0.6251594 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 982. State = [[-0.12851532 -0.15533903]]. Action = [[-0.15762605  0.16697574 -0.20984007 -0.5817698 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 983. State = [[-0.13973062 -0.15328243]]. Action = [[ 0.01840466 -0.1742353   0.04643559 -0.70425254]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 984. State = [[-0.14283058 -0.17346886]]. Action = [[ 0.01103377 -0.22683072 -0.16151005  0.64100194]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 985. State = [[-0.13788165 -0.1831583 ]]. Action = [[ 0.196814    0.08945614 -0.01267312 -0.5987271 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 986. State = [[-0.1280646 -0.168378 ]]. Action = [[ 0.04406381  0.22604749  0.24019426 -0.26635063]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 987. State = [[-0.11828854 -0.14031018]]. Action = [[0.07995865 0.22538921 0.17210954 0.05127573]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 988. State = [[-0.10305643 -0.13239898]]. Action = [[ 0.20699775 -0.20750123 -0.00153036  0.2366085 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 989. State = [[-0.09007761 -0.14099708]]. Action = [[-0.07818055 -0.02987292 -0.13481139  0.33712554]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 990. State = [[-0.09130897 -0.14210261]]. Action = [[-0.10433371  0.07062188  0.11410797 -0.36270362]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 991. State = [[-0.09716118 -0.14554805]]. Action = [[-0.13238202 -0.04366414 -0.06434362  0.6353831 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 992. State = [[-0.11349328 -0.1355053 ]]. Action = [[-0.21499695  0.21858245  0.03559428  0.59585   ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 993. State = [[-0.125854   -0.12345207]]. Action = [[ 0.19395989 -0.06473136  0.11255723  0.7364329 ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 994. State = [[-0.12040456 -0.11357305]]. Action = [[0.08602542 0.16877979 0.1026147  0.4919529 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 995. State = [[-0.11643998 -0.08958045]]. Action = [[-0.0308134   0.24585867  0.22391802 -0.7530337 ]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 996. State = [[-0.12103447 -0.057896  ]]. Action = [[-0.17144014  0.18018645  0.02924082 -0.08829892]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 997. State = [[-0.12639558 -0.0343649 ]]. Action = [[ 0.0912286   0.10601148  0.06407785 -0.54629767]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 998. State = [[-0.11756748 -0.03675777]]. Action = [[ 0.23428586 -0.23444128  0.01882207  0.5347028 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 999. State = [[-0.09775762 -0.05413011]]. Action = [[ 0.14739308 -0.08438921 -0.12860799 -0.32269663]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 1000. State = [[-0.07603858 -0.05411059]]. Action = [[ 0.15638119  0.13545752 -0.01861157 -0.37873638]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 1001. State = [[-0.05074157 -0.05835244]]. Action = [[ 0.20988107 -0.18952303  0.038562    0.31755245]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 1002. State = [[-0.1462709  -0.13673446]]. Action = [[0.03077027 0.18765843 0.19212303 0.38839746]]. Reward = [100.]
Curr episode timestep = 82
Current timestep = 1003. State = [[-0.12875754 -0.14335088]]. Action = [[ 0.06824863  0.15929776 -0.11732404  0.21482897]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1004. State = [[-0.11473341 -0.12886629]]. Action = [[ 0.16789478  0.11066854 -0.0199731   0.78935575]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1005. State = [[-0.09376152 -0.133818  ]]. Action = [[ 0.12598819 -0.22220203  0.15103206 -0.28666627]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1006. State = [[-0.06903688 -0.15485218]]. Action = [[ 0.23637655 -0.20425294  0.03872031  0.6782937 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1007. State = [[-0.03920506 -0.18312506]]. Action = [[ 0.19913802 -0.19396472 -0.14129779  0.05452096]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1008. State = [[-0.01520276 -0.19531237]]. Action = [[0.07077065 0.09372854 0.19110769 0.5968523 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1009. State = [[-0.0028029  -0.20794007]]. Action = [[ 0.05793586 -0.23079889 -0.06768367  0.5588199 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1010. State = [[ 0.01094268 -0.219466  ]]. Action = [[0.13747716 0.03066862 0.19696647 0.06919205]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1011. State = [[ 0.02315795 -0.21946418]]. Action = [[-0.06693801  0.06347588 -0.22651985  0.5001347 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1012. State = [[ 0.0273214  -0.21199946]]. Action = [[ 0.16108698  0.07300976  0.0976496  -0.250458  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1013. State = [[ 0.04600374 -0.20396288]]. Action = [[0.19803542 0.03990471 0.13644311 0.41645682]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1014. State = [[ 0.0669644  -0.20039132]]. Action = [[-0.0206206   0.02104011  0.05999851  0.8003392 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1015. State = [[ 0.06803448 -0.20644982]]. Action = [[-0.11634395 -0.12058415  0.19068691 -0.49682438]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1016. State = [[ 0.06577344 -0.21198237]]. Action = [[ 0.03784621 -0.03367572  0.07270482 -0.01605308]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1017. State = [[ 0.06554722 -0.21280627]]. Action = [[ 0.10669279  0.24241662 -0.01174457 -0.37553275]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1018. State = [[ 0.06511237 -0.21300873]]. Action = [[0.07739094 0.19992733 0.21138132 0.93791676]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1019. State = [[ 0.06511237 -0.21300873]]. Action = [[ 0.05332899  0.00041994 -0.21821736 -0.1018638 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1020. State = [[ 0.06552188 -0.20142496]]. Action = [[-0.07964951  0.22540733 -0.1856233  -0.6497592 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1021. State = [[ 0.06525874 -0.1863794 ]]. Action = [[-0.03268448  0.02897778  0.01246148  0.32796693]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1022. State = [[ 0.06421706 -0.17426307]]. Action = [[-0.02587672  0.14655414 -0.13766135 -0.0186308 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1023. State = [[ 0.05583373 -0.15229937]]. Action = [[-0.1859152   0.15958232  0.0451777   0.8383746 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 1024. State = [[ 0.03677126 -0.1283023 ]]. Action = [[-0.2082894   0.16451854 -0.17980269  0.556448  ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 1025. State = [[ 0.01902564 -0.10804296]]. Action = [[ 0.07728964  0.07058501  0.13627768 -0.45855117]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 1026. State = [[-0.2545379  -0.11388787]]. Action = [[-0.17231387  0.1437003   0.10083863 -0.02157968]]. Reward = [100.]
Curr episode timestep = 23
Current timestep = 1027. State = [[-0.25220218 -0.12658177]]. Action = [[-0.05302303  0.04080707  0.19213182 -0.05223584]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1028. State = [[-0.25297847 -0.132017  ]]. Action = [[-0.00606105 -0.11091471 -0.16044725  0.91715884]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1029. State = [[-0.25411102 -0.13185856]]. Action = [[-0.02300809  0.12819508 -0.11867383  0.78628016]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1030. State = [[-0.25033456 -0.12680186]]. Action = [[ 0.15801984  0.02416897 -0.00897425 -0.2890756 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1031. State = [[-0.24111472 -0.13147147]]. Action = [[ 0.0691821  -0.17973885 -0.12658189 -0.8706448 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1032. State = [[-0.2225332 -0.1490315]]. Action = [[ 0.21065372 -0.15815958 -0.05386552 -0.60106754]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1033. State = [[-0.19541425 -0.15570025]]. Action = [[0.19308573 0.12411046 0.04033208 0.57107866]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1034. State = [[-0.18156442 -0.15540785]]. Action = [[-0.05756375 -0.03406373  0.0837087   0.03556085]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1035. State = [[-0.18235916 -0.15114358]]. Action = [[-0.07323706  0.10232779  0.11032009  0.8446474 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1036. State = [[-0.18324257 -0.15521514]]. Action = [[ 0.04336572 -0.1702101  -0.11688593  0.5635896 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1037. State = [[-0.17418452 -0.15680131]]. Action = [[ 0.21131814  0.08238572 -0.06911343  0.7400782 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1038. State = [[-0.16345717 -0.16927695]]. Action = [[-0.09097624 -0.22736068 -0.17934701 -0.16723281]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1039. State = [[-0.1594897  -0.18061987]]. Action = [[ 0.146402   -0.00449458  0.18238461 -0.5868773 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1040. State = [[-0.15335059 -0.18612309]]. Action = [[-0.00986201 -0.05931149  0.13564506  0.9851198 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1041. State = [[-0.14359985 -0.20280237]]. Action = [[ 0.12674358 -0.20200461 -0.16749513  0.3310008 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1042. State = [[-0.13534449 -0.21603104]]. Action = [[-0.07841587  0.05354494 -0.11971125 -0.3490125 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1043. State = [[-0.14408238 -0.21422626]]. Action = [[-0.24212104  0.08510181  0.02922258  0.8412187 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1044. State = [[-0.15831497 -0.22275743]]. Action = [[-0.10437888 -0.14655176 -0.18438552  0.13447547]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1045. State = [[-0.17399967 -0.24508567]]. Action = [[-0.07692593 -0.21142519  0.14373851  0.6149385 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1046. State = [[-0.17591894 -0.24724665]]. Action = [[ 0.20808178  0.18092489 -0.12594305  0.6018789 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1047. State = [[-0.16845626 -0.22891057]]. Action = [[-0.03142551  0.18715912  0.08047116 -0.13188481]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 1048. State = [[-0.17426106 -0.22560959]]. Action = [[-0.18784109 -0.16421518 -0.1669618  -0.87029576]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 1049. State = [[-0.18860778 -0.24580498]]. Action = [[-0.08930963 -0.2017029   0.08343938  0.03884292]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 1050. State = [[-0.20583573 -0.25945958]]. Action = [[-0.14045791  0.01047638 -0.1627669   0.11239815]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 1051. State = [[-0.21157432 -0.2520377 ]]. Action = [[0.04540676 0.22588706 0.04373723 0.7219193 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 1052. State = [[-0.2036932  -0.22296335]]. Action = [[0.21910569 0.2073704  0.05125451 0.784214  ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 1053. State = [[-0.1873245  -0.21274394]]. Action = [[ 0.16973391 -0.16522616  0.18252575  0.74477077]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 1054. State = [[-0.17151266 -0.21185207]]. Action = [[0.11240181 0.08307368 0.09859952 0.62775767]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 1055. State = [[-0.15287475 -0.2182129 ]]. Action = [[ 0.16961786 -0.17866635  0.21232224  0.6639024 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 1056. State = [[-0.12857299 -0.22519481]]. Action = [[ 0.18027335  0.02692664 -0.13341594  0.40471017]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 1057. State = [[-0.1082432  -0.23163761]]. Action = [[ 0.09903595 -0.09888691  0.03447875 -0.26464784]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 1058. State = [[-0.1009524  -0.24518399]]. Action = [[-0.09163567 -0.11226588 -0.00733136  0.17307127]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 1059. State = [[-0.09959789 -0.25779328]]. Action = [[ 0.09170589 -0.06941789 -0.0208334  -0.5821794 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 1060. State = [[-0.09255724 -0.2600525 ]]. Action = [[ 0.06010649  0.07273644 -0.21837805  0.34869206]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 1061. State = [[-0.08910967 -0.25052205]]. Action = [[-0.02040897  0.1309438  -0.24468596  0.8110987 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 1062. State = [[-0.09427697 -0.24167119]]. Action = [[-0.23798797  0.07761216  0.01968789  0.16096497]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 1063. State = [[-0.09722682 -0.22426282]]. Action = [[ 0.01225305  0.24057111 -0.23167765  0.07813883]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 1064. State = [[-0.09694517 -0.20685759]]. Action = [[ 0.07392713 -0.04069492  0.10595641  0.09668481]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 1065. State = [[-0.09696065 -0.20652996]]. Action = [[ 0.01422867 -0.04623634  0.10041863  0.0168637 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 1066. State = [[-0.09920461 -0.19679977]]. Action = [[-0.15653513  0.21126539  0.0618493   0.45001566]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 1067. State = [[-0.10511187 -0.1805336 ]]. Action = [[ 0.03681967  0.05916685 -0.17007853  0.24890947]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 1068. State = [[-0.11401016 -0.17025042]]. Action = [[-0.19696301  0.06968296 -0.12119049 -0.45842326]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 1069. State = [[-0.12090778 -0.17644496]]. Action = [[ 0.20545149 -0.24067076  0.16915256 -0.5323123 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 1070. State = [[-0.11508827 -0.18353488]]. Action = [[ 0.0843398   0.07412288 -0.14064269 -0.3755405 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 1071. State = [[-0.11479787 -0.17078918]]. Action = [[-0.1631072   0.21734262  0.00202292 -0.53482664]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 1072. State = [[-0.11512264 -0.15843937]]. Action = [[ 0.04469287 -0.01120213 -0.20503938  0.7390429 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 1073. State = [[-0.12100115 -0.16589546]]. Action = [[-0.16831824 -0.1417841  -0.09089705  0.28183722]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 1074. State = [[-0.13424811 -0.17632096]]. Action = [[-0.11223137 -0.04168969  0.14858991  0.53066826]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 1075. State = [[-0.13992424 -0.17158607]]. Action = [[ 0.09919578  0.16404015 -0.09831417 -0.7111323 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 1076. State = [[-0.13165298 -0.1601048 ]]. Action = [[ 0.20818973  0.01432979 -0.12546562 -0.11919183]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 1077. State = [[-0.1298201  -0.16080272]]. Action = [[-0.21083924 -0.06993823  0.22026253 -0.46155226]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 1078. State = [[-0.13241135 -0.17562   ]]. Action = [[ 0.13989067 -0.23600961 -0.12939343 -0.15622586]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 1079. State = [[-0.12213717 -0.20051676]]. Action = [[ 0.19633138 -0.16985306 -0.1281242   0.8651874 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 1080. State = [[-0.1011181  -0.20609516]]. Action = [[ 0.13501525  0.15638256 -0.03976192  0.3432908 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 1081. State = [[-0.07944365 -0.20139873]]. Action = [[ 0.21369687 -0.02506599  0.21986032 -0.4762559 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 1082. State = [[-0.06538171 -0.19104357]]. Action = [[-0.13649835  0.20454624  0.08211592  0.347538  ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 1083. State = [[-0.05864874 -0.18943824]]. Action = [[ 0.19862288 -0.21992043 -0.14298226  0.8752054 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 1084. State = [[-0.0470864 -0.1962441]]. Action = [[ 0.03584471  0.0371297  -0.10211521  0.60339284]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 1085. State = [[-0.0418663  -0.18798062]]. Action = [[ 0.06063119  0.14170307 -0.22761244 -0.21633196]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 1086. State = [[-0.03171178 -0.17326199]]. Action = [[0.09080058 0.1174885  0.1224885  0.7598989 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 1087. State = [[-0.01747456 -0.17578197]]. Action = [[ 0.13893154 -0.21361874  0.13622668  0.8950527 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 1088. State = [[ 0.0021757  -0.18899031]]. Action = [[ 0.1392749  -0.06249747 -0.12112793  0.83847547]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 1089. State = [[ 0.01246337 -0.18801711]]. Action = [[-0.18990026  0.1638281  -0.18199657 -0.74560314]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 1090. State = [[ 0.01439508 -0.18050519]]. Action = [[0.17373723 0.02009401 0.18612257 0.27504265]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 1091. State = [[ 0.01854284 -0.18610202]]. Action = [[-0.04464279 -0.16054069  0.21830672  0.23921049]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 1092. State = [[ 0.02443497 -0.19539563]]. Action = [[ 0.20422989 -0.05428866  0.04387832  0.598845  ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 1093. State = [[ 0.03877857 -0.20700838]]. Action = [[-0.02245507 -0.09738733  0.08335057 -0.63376296]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 1094. State = [[ 0.04251067 -0.20772049]]. Action = [[ 0.02791744  0.13243288  0.14536572 -0.90984666]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 1095. State = [[ 0.04232923 -0.20469831]]. Action = [[-0.22067828  0.02133724 -0.0134993  -0.13895386]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 1096. State = [[ 0.04148433 -0.19802162]]. Action = [[0.11584786 0.07608539 0.07594848 0.36606932]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 1097. State = [[ 0.04078969 -0.17982167]]. Action = [[-0.14999884  0.21794304  0.23724842 -0.47929704]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 1098. State = [[ 0.03648625 -0.16323726]]. Action = [[0.16454944 0.1208086  0.21160603 0.696115  ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 1099. State = [[ 0.03487387 -0.14950043]]. Action = [[-0.03973539  0.17428845 -0.1409961   0.60232925]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 1100. State = [[ 0.03223573 -0.14595105]]. Action = [[ 0.02873945 -0.17141601  0.1126278   0.345006  ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 1101. State = [[ 0.02155097 -0.15454972]]. Action = [[-0.2260819   0.00742835  0.08975384  0.5601388 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 1102. State = [[ 0.01046236 -0.15744384]]. Action = [[ 0.02338302  0.00645661 -0.08285141 -0.35532928]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 1103. State = [[ 0.00827408 -0.15700965]]. Action = [[-0.04124786  0.02173471 -0.15687785 -0.6174268 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 1104. State = [[ 0.00815101 -0.15963122]]. Action = [[ 0.237257   -0.11525255 -0.2345161   0.7096553 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 1105. State = [[ 0.006622   -0.17626694]]. Action = [[-0.14920355 -0.20494388  0.23164505 -0.9720014 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 1106. State = [[ 0.00506486 -0.18710786]]. Action = [[ 0.11370218  0.07481989 -0.11719808 -0.7409372 ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 1107. State = [[ 0.0053321 -0.185152 ]]. Action = [[-0.12014772  0.04159874  0.11873925  0.8644638 ]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 1108. State = [[ 0.00040918 -0.17307027]]. Action = [[-0.1757163   0.20727938  0.02230486 -0.6583647 ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 1109. State = [[-0.01154475 -0.16116388]]. Action = [[-0.0689722  -0.0558781  -0.01181592  0.6853242 ]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 1110. State = [[-0.02023179 -0.15094873]]. Action = [[-0.08750218  0.20319653 -0.1761301   0.7323122 ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 1111. State = [[-0.02569595 -0.12951627]]. Action = [[ 0.12668553  0.06434077 -0.11677152 -0.16471767]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 1112. State = [[-0.01833954 -0.13119751]]. Action = [[ 0.22344184 -0.17140864  0.08811176 -0.12441748]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 1113. State = [[-0.01146169 -0.12521766]]. Action = [[-0.0202616   0.23993528  0.02232796 -0.16586864]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 1114. State = [[-0.00791034 -0.11595959]]. Action = [[ 0.10122782 -0.07698855  0.0601266   0.0184617 ]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 1115. State = [[-0.00277388 -0.10406193]]. Action = [[-0.04277521  0.23455548  0.12682825  0.23242915]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 1116. State = [[-0.2502867 -0.0778733]]. Action = [[-0.08803293  0.11787754 -0.0702967  -0.34285372]]. Reward = [100.]
Curr episode timestep = 89
Current timestep = 1117. State = [[-0.244843   -0.08730884]]. Action = [[ 0.06077191 -0.01633337  0.22815442  0.7508912 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1118. State = [[-0.24384487 -0.09407866]]. Action = [[-0.13855033 -0.06875414  0.15900826  0.11886227]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1119. State = [[-0.24509439 -0.11257923]]. Action = [[ 0.09870937 -0.20146427  0.2258339  -0.05531466]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1120. State = [[-0.24335878 -0.12726745]]. Action = [[-0.20514639  0.17611414  0.09798542 -0.5159079 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1121. State = [[-0.2436285  -0.12545423]]. Action = [[-0.05102815  0.1076158  -0.1633024  -0.5645712 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1122. State = [[-0.24401918 -0.11897231]]. Action = [[-0.01021798  0.07356763  0.21736205 -0.76003444]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1123. State = [[-0.24962698 -0.12211794]]. Action = [[-0.13995202 -0.16881476 -0.03684655  0.20290017]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1124. State = [[-0.25737035 -0.13107906]]. Action = [[-0.17596163 -0.02403229 -0.11766654 -0.42305255]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1125. State = [[-0.25750536 -0.13413867]]. Action = [[ 0.1089898  -0.05502483 -0.10412361 -0.23112082]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1126. State = [[-0.25272202 -0.14257078]]. Action = [[ 0.07854456 -0.0979161  -0.14887665  0.02919364]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1127. State = [[-0.23537469 -0.15015034]]. Action = [[ 0.24780232  0.0091846  -0.02903216 -0.9330576 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1128. State = [[-0.20819695 -0.1628122 ]]. Action = [[ 0.16428453 -0.17163755  0.12447566  0.11530662]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1129. State = [[-0.1874698  -0.16977778]]. Action = [[ 0.08777848  0.08510885 -0.1618119   0.32817054]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1130. State = [[-0.17903824 -0.17834245]]. Action = [[-0.01509701 -0.16876437  0.12070671 -0.34236872]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1131. State = [[-0.17678401 -0.17722762]]. Action = [[-0.00683509  0.17575794 -0.21520537 -0.47988456]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1132. State = [[-0.175872   -0.16372187]]. Action = [[0.00787878 0.11128971 0.1084047  0.37176442]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1133. State = [[-0.17561714 -0.15416324]]. Action = [[-0.02071269  0.0241296   0.07451701  0.61233556]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1134. State = [[-0.16667433 -0.14899848]]. Action = [[ 0.21215004  0.01133645  0.16119534 -0.9034628 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1135. State = [[-0.1492289  -0.15473469]]. Action = [[ 0.10592324 -0.16858713  0.09718308 -0.00444722]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1136. State = [[-0.12604177 -0.1660458 ]]. Action = [[ 0.21408075 -0.04806639  0.05661988  0.32610238]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1137. State = [[-0.10701473 -0.16136983]]. Action = [[-0.00503205  0.18700677  0.08218238  0.09926224]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 1138. State = [[-0.10574291 -0.1560995 ]]. Action = [[-0.05998611 -0.04665796  0.04982305 -0.57940876]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 1139. State = [[-0.10697299 -0.16176215]]. Action = [[-0.05539876 -0.08978042 -0.09244853  0.5349796 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 1140. State = [[-0.11628545 -0.17655   ]]. Action = [[-0.18618517 -0.14371444 -0.08312996 -0.05993533]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 1141. State = [[-0.12485549 -0.18880378]]. Action = [[ 0.03342295 -0.01435168  0.16703469 -0.24625391]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 1142. State = [[-0.12513357 -0.19514915]]. Action = [[ 0.09292823 -0.08071829  0.1015178   0.38091695]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 1143. State = [[-0.11757749 -0.21053809]]. Action = [[ 0.1696985  -0.20467748  0.07418677  0.12107003]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 1144. State = [[-0.10181677 -0.21551457]]. Action = [[ 0.0675188   0.2088049  -0.09019464  0.96298087]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 1145. State = [[-0.09593926 -0.20888472]]. Action = [[-0.05358177 -0.00953887 -0.12945059  0.77095914]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 1146. State = [[-0.09745038 -0.20056331]]. Action = [[-0.12442024  0.14334181 -0.02103677 -0.17605102]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 1147. State = [[-0.09607527 -0.20173633]]. Action = [[ 0.16671363 -0.20498069 -0.2046486  -0.19372392]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 1148. State = [[-0.0861014  -0.21943489]]. Action = [[ 0.2013089  -0.20113167 -0.20232959  0.37284946]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 1149. State = [[-0.06540895 -0.25056052]]. Action = [[ 0.1008746  -0.24790472  0.05428085  0.69178   ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 1150. State = [[-0.05014349 -0.26123992]]. Action = [[0.05977517 0.17663318 0.11061653 0.86350155]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 1151. State = [[-0.03787794 -0.26716453]]. Action = [[ 0.18887964 -0.21508771 -0.06941912 -0.2844231 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 1152. State = [[-0.01099928 -0.2654716 ]]. Action = [[0.18318206 0.21985751 0.2332598  0.80428123]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 1153. State = [[ 0.00488285 -0.25111404]]. Action = [[-0.08824238  0.11619475  0.10072172  0.87653875]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 1154. State = [[ 0.01467252 -0.2319276 ]]. Action = [[ 0.24353105  0.14768761 -0.0466592  -0.49396044]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 1155. State = [[ 0.03767413 -0.21532851]]. Action = [[ 0.17850697  0.06021827 -0.16952363 -0.15042782]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 1156. State = [[ 0.0583222 -0.2103849]]. Action = [[ 0.22008443 -0.1791353   0.04265571 -0.17098504]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 1157. State = [[ 0.06511439 -0.2097817 ]]. Action = [[ 0.18346542  0.12498489  0.06843042 -0.00277132]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 1158. State = [[ 0.06567055 -0.20953012]]. Action = [[ 0.07018101 -0.22005446  0.17046726  0.44387686]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 1159. State = [[ 0.06569276 -0.20951411]]. Action = [[ 0.01670876  0.21695954  0.01011783 -0.49957412]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 1160. State = [[ 0.06516775 -0.20976637]]. Action = [[-0.1240631   0.01951426  0.17681822  0.7372649 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 1161. State = [[ 0.06434713 -0.20964997]]. Action = [[0.11539757 0.02948886 0.0754807  0.2714107 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 1162. State = [[ 0.0642348 -0.20975  ]]. Action = [[ 0.15628466  0.1026313  -0.19765295  0.28199697]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 1163. State = [[ 0.0642348 -0.20975  ]]. Action = [[ 0.14482856  0.02885768 -0.1438535  -0.20460105]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 1164. State = [[ 0.06118123 -0.22248636]]. Action = [[-0.03276435 -0.22070494  0.04617357  0.04029334]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 1165. State = [[ 0.05773734 -0.23338054]]. Action = [[-0.07325676  0.02840853 -0.15426286 -0.09867972]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 1166. State = [[ 0.05597579 -0.23663618]]. Action = [[ 0.14134538 -0.17833453  0.05244336 -0.35299516]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 1167. State = [[ 0.05565396 -0.2370082 ]]. Action = [[ 0.20073986  0.17348814  0.00487822 -0.14154446]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 1168. State = [[ 0.05543612 -0.23709264]]. Action = [[0.07288334 0.23141709 0.17655069 0.147228  ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 1169. State = [[ 0.05531337 -0.23710676]]. Action = [[ 0.2346518  -0.06328648  0.24342516  0.7221004 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 1170. State = [[ 0.05094862 -0.24372184]]. Action = [[-0.115879   -0.09479435 -0.13797158  0.40376627]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 1171. State = [[ 0.04629703 -0.2596669 ]]. Action = [[ 0.06411475 -0.16549176  0.18739003 -0.89739597]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 1172. State = [[ 0.04158131 -0.2610383 ]]. Action = [[-0.1734568   0.18963152  0.17712685 -0.41848105]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 1173. State = [[ 0.02546446 -0.25289384]]. Action = [[-0.23393387  0.04465747  0.12270945 -0.40337622]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 1174. State = [[ 0.01082205 -0.242776  ]]. Action = [[ 0.20269799  0.04695565 -0.02868004  0.3022921 ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 1175. State = [[ 0.01206629 -0.24751815]]. Action = [[ 0.04225263 -0.21238466 -0.11709556  0.21225786]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 1176. State = [[ 0.01357691 -0.26253238]]. Action = [[ 0.08670142 -0.09402633  0.1172561  -0.753357  ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 1177. State = [[ 0.01362841 -0.27012715]]. Action = [[-0.07293047 -0.00674839  0.081705   -0.06330425]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 1178. State = [[ 0.01229218 -0.27895856]]. Action = [[ 0.03034481 -0.10279384 -0.11528528  0.0524596 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 1179. State = [[ 0.01127789 -0.28521425]]. Action = [[-0.21640019 -0.20881169  0.06317675 -0.08835512]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 1180. State = [[ 0.01367   -0.2857926]]. Action = [[ 0.10765949  0.00566652  0.11810556 -0.6153417 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 1181. State = [[ 0.02209143 -0.27808303]]. Action = [[-0.08245057  0.17948341 -0.05930376 -0.5007492 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 1182. State = [[ 0.02332734 -0.27134857]]. Action = [[ 0.15158165 -0.22934297  0.02576193  0.1211201 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 1183. State = [[ 0.02183927 -0.26971096]]. Action = [[-0.13479435  0.03732842 -0.08653687 -0.9390469 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 1184. State = [[ 0.01967696 -0.27622542]]. Action = [[-0.00355189 -0.14332123  0.10035256  0.37167287]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 1185. State = [[ 0.01255719 -0.27378815]]. Action = [[-0.163363    0.1797877  -0.20391618 -0.18688673]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 1186. State = [[-0.00036947 -0.26338777]]. Action = [[-0.10164419  0.02620262 -0.06825386  0.5578792 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 1187. State = [[-0.0043747  -0.24988386]]. Action = [[0.22463554 0.16740733 0.17286026 0.94601774]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 1188. State = [[-0.00042215 -0.22692397]]. Action = [[ 0.00247437  0.09694055 -0.13491863  0.13152719]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 1189. State = [[ 0.00815968 -0.2042093 ]]. Action = [[ 0.21259564  0.20611948 -0.07637545  0.6093364 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 1190. State = [[ 0.02549928 -0.18927619]]. Action = [[ 0.23572212 -0.07519948  0.00831336 -0.49230528]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 1191. State = [[ 0.05112276 -0.1851063 ]]. Action = [[ 0.15097213  0.06558481  0.00052515 -0.01511878]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 1192. State = [[ 0.06796286 -0.18172859]]. Action = [[ 0.18040857 -0.08611672  0.2106159   0.66766214]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 1193. State = [[ 0.06930273 -0.18526624]]. Action = [[-0.16484639 -0.04855485 -0.0233762  -0.04395938]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 1194. State = [[ 0.06754062 -0.18861097]]. Action = [[ 0.16484347 -0.12007235  0.01066476  0.13620543]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 1195. State = [[ 0.06742057 -0.17654562]]. Action = [[-0.05484214  0.23266989  0.14410639  0.92077374]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 1196. State = [[ 0.06726019 -0.16142222]]. Action = [[0.01130438 0.09194481 0.05684099 0.29680097]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 1197. State = [[ 0.06725994 -0.15957758]]. Action = [[ 0.24044204 -0.12677011 -0.05235431 -0.68381894]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 1198. State = [[ 0.06726488 -0.1591788 ]]. Action = [[ 0.0930832  -0.24801473  0.16647008  0.81655705]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 1199. State = [[ 0.06726488 -0.1591788 ]]. Action = [[ 0.05764395 -0.13217409  0.07454586  0.04002881]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 1200. State = [[ 0.06726488 -0.1591788 ]]. Action = [[ 0.1741994   0.10117859  0.06788248 -0.31247485]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 1201. State = [[ 0.06089454 -0.15473236]]. Action = [[-0.20137675  0.07613331  0.22587353  0.27281976]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 1202. State = [[ 0.04814977 -0.14909753]]. Action = [[-0.05596201  0.00127181  0.1658116   0.33913708]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 1203. State = [[ 0.04246212 -0.15715736]]. Action = [[ 0.04118901 -0.17027168  0.00230163  0.32819355]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 1204. State = [[ 0.03761474 -0.16283174]]. Action = [[-0.06450805  0.06841817  0.22138238 -0.73443365]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 1205. State = [[ 0.0331004  -0.16977808]]. Action = [[ 4.9218535e-04 -1.3255963e-01  1.7336583e-01 -8.1714302e-01]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 1206. State = [[ 0.02281323 -0.17909335]]. Action = [[-0.20206082 -0.00605288 -0.18445669 -0.29789454]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 1207. State = [[ 0.00978633 -0.19346093]]. Action = [[ 0.05304283 -0.1941325  -0.00262876  0.55728054]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 1208. State = [[ 0.00852337 -0.20583735]]. Action = [[ 0.02605295 -0.03797424  0.05197823  0.65882826]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 1209. State = [[ 0.01017296 -0.21752651]]. Action = [[ 0.12915125 -0.1179089   0.18935034  0.9299443 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 1210. State = [[ 0.01434975 -0.23326541]]. Action = [[ 0.11782488 -0.12874827 -0.16982865  0.22542822]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 1211. State = [[ 0.01698442 -0.23731792]]. Action = [[-0.06254308  0.11353257 -0.07585607  0.16377115]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 1212. State = [[ 0.01823595 -0.2274511 ]]. Action = [[-0.05790851  0.13936514 -0.18692675 -0.63321596]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 1213. State = [[ 0.0184767  -0.21488115]]. Action = [[-0.06637642  0.0604575   0.18726233  0.9289335 ]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 1214. State = [[ 0.01552988 -0.21192665]]. Action = [[-0.0459688  -0.04298197  0.20514041 -0.3174094 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 1215. State = [[ 0.0160569 -0.2023972]]. Action = [[ 0.06947705  0.17107046 -0.00846463 -0.3048427 ]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 1216. State = [[ 0.01024347 -0.20557204]]. Action = [[-0.14742973 -0.23872034  0.13211364 -0.40717423]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 1217. State = [[ 0.00752401 -0.20789558]]. Action = [[0.13964808 0.14378083 0.02337363 0.06631184]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 1218. State = [[ 0.0102338 -0.2087535]]. Action = [[ 0.07767159 -0.12477586 -0.00934972  0.5193955 ]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 1219. State = [[ 0.01881847 -0.21016975]]. Action = [[ 0.19934314  0.01077086 -0.07044137  0.4022696 ]]. Reward = [0.]
Curr episode timestep = 102
Current timestep = 1220. State = [[ 0.03678809 -0.2197177 ]]. Action = [[ 0.16981691 -0.192072    0.01515695 -0.25639158]]. Reward = [0.]
Curr episode timestep = 103
Current timestep = 1221. State = [[ 0.054211   -0.23493166]]. Action = [[ 0.23484647 -0.09035385  0.02038199  0.49120677]]. Reward = [0.]
Curr episode timestep = 104
Current timestep = 1222. State = [[ 0.05300396 -0.23728766]]. Action = [[-0.21379259  0.04027915  0.00271577 -0.82910097]]. Reward = [0.]
Curr episode timestep = 105
Current timestep = 1223. State = [[ 0.05012756 -0.23148015]]. Action = [[-0.095873    0.13876525 -0.15681157  0.49938726]]. Reward = [0.]
Curr episode timestep = 106
Current timestep = 1224. State = [[ 0.04520369 -0.22420473]]. Action = [[ 0.19188023 -0.10951322  0.13656604  0.37194276]]. Reward = [0.]
Curr episode timestep = 107
Current timestep = 1225. State = [[ 0.04460196 -0.20951287]]. Action = [[ 0.00722739  0.22991705 -0.00169317  0.6720228 ]]. Reward = [0.]
Curr episode timestep = 108
Current timestep = 1226. State = [[ 0.03523219 -0.20487364]]. Action = [[-0.15563673 -0.21370824  0.09057829 -0.01361823]]. Reward = [0.]
Curr episode timestep = 109
Current timestep = 1227. State = [[ 0.02622619 -0.20828159]]. Action = [[-0.00549228  0.11446786 -0.08008257 -0.6889514 ]]. Reward = [0.]
Curr episode timestep = 110
Current timestep = 1228. State = [[ 0.01384778 -0.20525542]]. Action = [[-0.19201347  0.00290069  0.17431962 -0.9166145 ]]. Reward = [0.]
Curr episode timestep = 111
Current timestep = 1229. State = [[-0.00782839 -0.1978279 ]]. Action = [[-0.17123985  0.10085881 -0.12188661  0.17311454]]. Reward = [0.]
Curr episode timestep = 112
Current timestep = 1230. State = [[-0.02984688 -0.1761502 ]]. Action = [[-0.14397146  0.23326078  0.04752967  0.22349286]]. Reward = [0.]
Curr episode timestep = 113
Current timestep = 1231. State = [[-0.0437882  -0.15434295]]. Action = [[0.09812647 0.01881185 0.06770885 0.9043343 ]]. Reward = [0.]
Curr episode timestep = 114
Current timestep = 1232. State = [[-0.04481029 -0.14796108]]. Action = [[-0.08660153  0.03661278 -0.12617742 -0.8705876 ]]. Reward = [0.]
Curr episode timestep = 115
Current timestep = 1233. State = [[-0.0482806  -0.14219835]]. Action = [[ 0.04262507  0.03437242 -0.17151257 -0.92317986]]. Reward = [0.]
Curr episode timestep = 116
Current timestep = 1234. State = [[-0.04495659 -0.14468908]]. Action = [[ 0.2011869  -0.12660281  0.16269243  0.41954684]]. Reward = [0.]
Curr episode timestep = 117
Current timestep = 1235. State = [[-0.04667423 -0.13966854]]. Action = [[-0.21093369  0.1730769   0.08001459 -0.19286114]]. Reward = [0.]
Curr episode timestep = 118
Current timestep = 1236. State = [[-0.04904773 -0.13153736]]. Action = [[ 0.00667575  0.01464778 -0.19555192 -0.93950665]]. Reward = [0.]
Curr episode timestep = 119
Current timestep = 1237. State = [[-0.04863471 -0.13017473]]. Action = [[ 0.15269426 -0.02699654 -0.1324108  -0.33049268]]. Reward = [0.]
Curr episode timestep = 120
Current timestep = 1238. State = [[-0.04559945 -0.13717036]]. Action = [[ 0.07628444 -0.13680302 -0.16394004  0.1521411 ]]. Reward = [0.]
Curr episode timestep = 121
Current timestep = 1239. State = [[-0.03305685 -0.1443497 ]]. Action = [[ 0.22133422 -0.01597705  0.0584943  -0.9617469 ]]. Reward = [0.]
Curr episode timestep = 122
Current timestep = 1240. State = [[-0.01999213 -0.15816236]]. Action = [[-0.07443899 -0.19237463  0.1608226   0.00638938]]. Reward = [0.]
Curr episode timestep = 123
Current timestep = 1241. State = [[-0.01503404 -0.16537698]]. Action = [[ 0.11422148  0.12692618 -0.16439494  0.83054876]]. Reward = [0.]
Curr episode timestep = 124
Current timestep = 1242. State = [[-0.01258232 -0.15817983]]. Action = [[-0.21734141  0.07822242 -0.01064785  0.5517094 ]]. Reward = [0.]
Curr episode timestep = 125
Current timestep = 1243. State = [[-0.18479194 -0.09224429]]. Action = [[-0.1963292   0.13102129  0.24455833  0.81500506]]. Reward = [0.]
Curr episode timestep = 126
Current timestep = 1244. State = [[-0.18158057 -0.09232109]]. Action = [[-0.23146053  0.20480075  0.05557039 -0.8110713 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1245. State = [[-0.1852611  -0.07756637]]. Action = [[ 0.12786502  0.07227713 -0.20054339  0.8788897 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1246. State = [[-0.18720292 -0.06590663]]. Action = [[-0.12041134  0.07684663  0.00312796 -0.81552494]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1247. State = [[-0.18885969 -0.06102687]]. Action = [[-0.00081936 -0.03338507  0.16206431  0.28349185]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1248. State = [[-0.19283679 -0.05144602]]. Action = [[-0.08198038  0.162821    0.01285535  0.82792604]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1249. State = [[-0.199056  -0.0364416]]. Action = [[-0.05458215  0.05884391  0.12014568 -0.3517478 ]]. Reward = [0.]
Curr episode timestep = 5
