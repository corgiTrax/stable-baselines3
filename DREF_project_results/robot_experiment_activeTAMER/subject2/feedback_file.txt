Current timestep = 0. State = [[-0.23111522 -0.01808827]]. Action = [[-0.13564564  0.00678432  0.18865979 -0.05637622]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [True, False, False, False, True, False]
State prediction error at timestep 0 is tensor(0.0351, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 0 of -1
Current timestep = 1. State = [[-0.22672376 -0.0170823 ]]. Action = [[0.23065758 0.04796004 0.24687088 0.59084105]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False]
State prediction error at timestep 1 is tensor(0.0346, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1 of 1
Current timestep = 2. State = [[-0.21138439 -0.00213733]]. Action = [[ 0.04328829  0.218689    0.18177572 -0.18623453]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, True, False]
State prediction error at timestep 2 is tensor(0.0248, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 2 of 0
Current timestep = 3. State = [[-0.1996613   0.02819648]]. Action = [[0.23364794 0.23114598 0.01776975 0.14704108]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, True, False]
State prediction error at timestep 3 is tensor(0.0178, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3 of 0
Current timestep = 4. State = [[-0.1746209   0.04774585]]. Action = [[-0.10847643 -0.03244638 -0.18628262  0.05655169]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, True, False]
State prediction error at timestep 4 is tensor(0.0081, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 4 of 0
Current timestep = 5. State = [[-0.17920375  0.04806241]]. Action = [[-0.08189082  0.01989505  0.14609891  0.41195524]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, True, False]
State prediction error at timestep 5 is tensor(0.0090, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 5 of -1
Current timestep = 6. State = [[-0.19024323  0.05331467]]. Action = [[-0.16598393  0.02364448  0.17810255  0.9280553 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, True, False]
State prediction error at timestep 6 is tensor(0.0073, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 6 of -1
Current timestep = 7. State = [[-0.20932661  0.06079505]]. Action = [[-0.11609864  0.07225254  0.1372627   0.97228193]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, True, False]
State prediction error at timestep 7 is tensor(0.0077, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7 of -1
Current timestep = 8. State = [[-0.21918346  0.06304042]]. Action = [[ 0.08206543 -0.06085588  0.18031397  0.29099083]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, True, False]
State prediction error at timestep 8 is tensor(0.0111, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 8 of 1
Current timestep = 9. State = [[-0.21359625  0.04625177]]. Action = [[ 0.11499405 -0.16886926  0.22261372 -0.7315567 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, True, False]
State prediction error at timestep 9 is tensor(0.0063, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 9 of 1
Current timestep = 10. State = [[-0.21149236  0.04330263]]. Action = [[-0.05594194  0.1570425  -0.20117457 -0.46183938]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, True, False]
State prediction error at timestep 10 is tensor(0.0036, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 10 of -1
Current timestep = 11. State = [[-0.20844358  0.03866927]]. Action = [[ 0.13189113 -0.24300562  0.01991332  0.27040565]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, True, False]
State prediction error at timestep 11 is tensor(0.0063, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 11 of 1
Current timestep = 12. State = [[-0.20072183  0.00745478]]. Action = [[-0.05786885 -0.22142068  0.07047644 -0.44499242]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, True, False]
State prediction error at timestep 12 is tensor(0.0031, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 12 of 1
Current timestep = 13. State = [[-0.21017346 -0.02490524]]. Action = [[-0.23617399 -0.23538232 -0.00741428  0.06204891]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, True, False]
State prediction error at timestep 13 is tensor(0.0055, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 13 of -1
Current timestep = 14. State = [[-0.22513829 -0.03407368]]. Action = [[-0.00328191  0.20252123 -0.10790026 -0.5441805 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, True, False]
State prediction error at timestep 14 is tensor(0.0042, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 14 of 1
Current timestep = 15. State = [[-0.22269467 -0.01777706]]. Action = [[ 0.17524022  0.07394162 -0.02035134 -0.94432396]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, True, False]
State prediction error at timestep 15 is tensor(0.0010, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 15 of 1
Current timestep = 16. State = [[-0.20592606 -0.01800785]]. Action = [[ 0.21977746 -0.17660329 -0.0272049   0.27711582]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, True, False]
State prediction error at timestep 16 is tensor(0.0032, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 16 of 1
Current timestep = 17. State = [[-0.19223393 -0.03198939]]. Action = [[-0.22839862 -0.01208283  0.12529248 -0.3632949 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, True, False]
State prediction error at timestep 17 is tensor(0.0025, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 17 of -1
Current timestep = 18. State = [[-0.21310088 -0.02357636]]. Action = [[-0.23981191  0.21847859  0.07611367  0.27876687]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, True, False]
State prediction error at timestep 18 is tensor(0.0018, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 18 of -1
Current timestep = 19. State = [[-0.24001695 -0.00518524]]. Action = [[-0.21328981 -0.03910869  0.22770149  0.31821346]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, True, False]
State prediction error at timestep 19 is tensor(0.0034, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 19 of -1
Current timestep = 20. State = [[-0.2645953  -0.01042349]]. Action = [[-0.12352115 -0.14614993 -0.00420184  0.7130147 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, True, False]
State prediction error at timestep 20 is tensor(0.0033, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 20 of -1
Current timestep = 21. State = [[-0.26482493 -0.01072454]]. Action = [[-0.10747716  0.18778077 -0.13832375  0.3942554 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, True, False]
State prediction error at timestep 21 is tensor(0.0042, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 21 of -1
Current timestep = 22. State = [[-0.26482493 -0.01072454]]. Action = [[-0.13971014  0.2464019   0.1554687   0.83213806]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [True, False, False, False, True, False]
State prediction error at timestep 22 is tensor(0.0022, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 22 of -1
Current timestep = 23. State = [[-0.26482493 -0.01072454]]. Action = [[-0.20019798 -0.16772906 -0.20897152  0.56403065]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [True, False, False, False, True, False]
State prediction error at timestep 23 is tensor(0.0036, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 23 of -1
Current timestep = 24. State = [[-0.26482493 -0.01072454]]. Action = [[-0.17122363 -0.23080963  0.0546284   0.33434868]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [True, False, False, False, True, False]
State prediction error at timestep 24 is tensor(0.0058, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 24 of -1
Current timestep = 25. State = [[-0.2582363  -0.01132557]]. Action = [[ 0.2227461  -0.02702023  0.18663955  0.41511977]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [True, False, False, False, True, False]
State prediction error at timestep 25 is tensor(0.0046, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 25 of 1
Current timestep = 26. State = [[-0.24103166 -0.02428211]]. Action = [[ 0.17207605 -0.22546932 -0.11569117  0.24997187]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [True, False, False, False, True, False]
State prediction error at timestep 26 is tensor(0.0043, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 26 of 1
Current timestep = 27. State = [[-0.22633398 -0.03154925]]. Action = [[0.07071298 0.22482538 0.19404992 0.4580555 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [True, False, False, False, True, False]
State prediction error at timestep 27 is tensor(0.0024, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 27 of 1
Current timestep = 28. State = [[-0.22267087 -0.01941396]]. Action = [[-0.1853291  -0.05473697 -0.19843057 -0.45877022]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [True, False, False, False, True, False]
State prediction error at timestep 28 is tensor(0.0016, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 28 of -1
Current timestep = 29. State = [[-0.22062892 -0.03213261]]. Action = [[ 0.2384454  -0.17548193 -0.19074363 -0.60312945]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [True, False, False, False, True, False]
State prediction error at timestep 29 is tensor(0.0019, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 29 of 1
Current timestep = 30. State = [[-0.20101725 -0.03463845]]. Action = [[ 0.23287007  0.19345272 -0.13526042  0.9595444 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [True, False, False, False, True, False]
State prediction error at timestep 30 is tensor(0.0008, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 30 of 1
Current timestep = 31. State = [[-0.18093343 -0.01861989]]. Action = [[-0.09962258  0.05276191  0.13522121  0.45346498]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [True, False, False, False, True, False]
State prediction error at timestep 31 is tensor(0.0007, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 31 of 0
Current timestep = 32. State = [[-0.19074462 -0.00811793]]. Action = [[-0.23822774  0.10021234 -0.11546323 -0.39805543]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [True, False, False, False, True, False]
State prediction error at timestep 32 is tensor(0.0006, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 32 of -1
Current timestep = 33. State = [[-0.20243174  0.01398919]]. Action = [[0.18263048 0.19657862 0.12650985 0.8280417 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [True, False, False, False, True, False]
State prediction error at timestep 33 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 33 of 1
Current timestep = 34. State = [[-0.18821526  0.0340962 ]]. Action = [[ 0.19864535  0.1193288  -0.24529496  0.6289164 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [True, False, False, False, True, False]
State prediction error at timestep 34 is tensor(0.0006, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 34 of 1
Current timestep = 35. State = [[-0.17696662  0.0517114 ]]. Action = [[-0.14415753  0.1001662  -0.01429626 -0.97676045]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [True, False, False, False, True, False]
State prediction error at timestep 35 is tensor(0.0009, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 35 of -1
Current timestep = 36. State = [[-0.17947361  0.0533103 ]]. Action = [[ 0.04371268 -0.14979804 -0.02827027 -0.55971384]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [True, False, False, False, True, False]
State prediction error at timestep 36 is tensor(0.0006, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 36 of 1
Current timestep = 37. State = [[-0.17604446  0.04542525]]. Action = [[ 0.13261095  0.00894681  0.18070686 -0.04304194]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [True, False, False, False, True, False]
State prediction error at timestep 37 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 37 of 1
Current timestep = 38. State = [[-0.16377714  0.03597745]]. Action = [[ 0.13586605 -0.14951305 -0.01952399  0.10013378]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [True, False, False, False, True, False]
State prediction error at timestep 38 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 38 of 1
Current timestep = 39. State = [[-0.147588    0.01930352]]. Action = [[ 0.04086357 -0.08715445  0.07851136 -0.921879  ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [True, False, False, False, True, False]
State prediction error at timestep 39 is tensor(0.0010, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 39 of 1
Current timestep = 40. State = [[-0.14698198 -0.00159644]]. Action = [[-0.17491461 -0.21451482 -0.03989284 -0.77378756]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [True, False, False, False, True, False]
State prediction error at timestep 40 is tensor(0.0013, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 40 of 1
Current timestep = 41. State = [[-0.14897634 -0.02789269]]. Action = [[ 0.09170651 -0.14997704  0.04941937 -0.7539811 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [True, False, False, False, True, False]
State prediction error at timestep 41 is tensor(0.0016, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 41 of 0
Current timestep = 42. State = [[-0.14081363 -0.04586443]]. Action = [[ 0.15440035 -0.07096121  0.0695726   0.677032  ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [True, False, False, False, True, False]
State prediction error at timestep 42 is tensor(0.0020, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 42 of 1
Current timestep = 43. State = [[-0.12469392 -0.05669842]]. Action = [[ 0.16281527 -0.07540567  0.19380563 -0.25747383]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [True, False, False, False, True, False]
State prediction error at timestep 43 is tensor(0.0038, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 43 of 1
Current timestep = 44. State = [[-0.10275824 -0.07005119]]. Action = [[ 0.15210381 -0.1178201   0.1429472  -0.45558965]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [True, False, False, False, True, False]
State prediction error at timestep 44 is tensor(0.0057, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 44 of 1
Current timestep = 45. State = [[-0.07650088 -0.08930968]]. Action = [[ 0.23245764 -0.1497177   0.16773435  0.48883927]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [True, False, False, False, True, False]
State prediction error at timestep 45 is tensor(0.0089, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 45 of 1
Current timestep = 46. State = [[-0.0527533  -0.09588263]]. Action = [[-0.19237109  0.12942395  0.07827798 -0.9508661 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [True, False, False, False, True, False]
State prediction error at timestep 46 is tensor(0.0168, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 46 of 1
Current timestep = 47. State = [[-0.0519789  -0.08119971]]. Action = [[ 0.17851388  0.12559983 -0.03441244 -0.39503455]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [True, False, False, False, True, False]
State prediction error at timestep 47 is tensor(0.0103, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 47 of 1
Current timestep = 48. State = [[-0.05494059 -0.0788373 ]]. Action = [[-0.2204541  -0.11736692  0.04246202 -0.03092074]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [True, False, False, False, True, False]
State prediction error at timestep 48 is tensor(0.0098, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 48 of -1
Current timestep = 49. State = [[-0.06071021 -0.09424435]]. Action = [[-0.04018322 -0.1152505   0.20240307 -0.9230186 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [True, False, False, False, True, False]
State prediction error at timestep 49 is tensor(0.0134, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 49 of -1
Current timestep = 50. State = [[-0.05852237 -0.08827826]]. Action = [[ 0.2316755   0.239077   -0.0793514   0.87038827]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [True, False, False, False, True, False]
State prediction error at timestep 50 is tensor(0.0107, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 50 of 1
Current timestep = 51. State = [[-0.04817626 -0.0802314 ]]. Action = [[ 0.19354016 -0.17478758 -0.18010028 -0.13005924]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 51 is [False, True, False, False, True, False]
State prediction error at timestep 51 is tensor(0.0084, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 51 of 1
Current timestep = 52. State = [[-0.15035827  0.01039919]]. Action = [[ 0.24179652 -0.08749302  0.21575838 -0.5149345 ]]. Reward = [100.]
Curr episode timestep = 52
Scene graph at timestep 52 is [True, False, False, False, True, False]
State prediction error at timestep 52 is tensor(3.2852e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 52 of 0
Current timestep = 53. State = [[-0.1350733   0.00615409]]. Action = [[-0.16671437 -0.1689855  -0.08296803 -0.57491165]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 53 is [True, False, False, False, True, False]
State prediction error at timestep 53 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 53 of 0
Current timestep = 54. State = [[-0.14981976  0.00485257]]. Action = [[-0.23171867  0.18898183 -0.18613367  0.55912495]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 54 is [True, False, False, False, True, False]
State prediction error at timestep 54 is tensor(9.6970e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 54 of -1
Current timestep = 55. State = [[-0.16283463  0.03288262]]. Action = [[ 0.186234    0.23353797 -0.0285058  -0.28555024]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 55 is [True, False, False, False, True, False]
State prediction error at timestep 55 is tensor(0.0009, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 55 of 0
Current timestep = 56. State = [[-0.16268586  0.04849772]]. Action = [[-0.09969091 -0.02808884  0.1283752  -0.48946548]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 56 is [True, False, False, False, True, False]
State prediction error at timestep 56 is tensor(0.0011, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 56 of 0
Current timestep = 57. State = [[-0.16540065  0.05640402]]. Action = [[-0.00181821  0.13554549  0.07570815 -0.17069358]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 57 is [True, False, False, False, True, False]
State prediction error at timestep 57 is tensor(0.0016, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 57 of -1
Current timestep = 58. State = [[-0.16045061  0.0790697 ]]. Action = [[ 0.2418136   0.20663926  0.02470505 -0.65511066]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 58 is [True, False, False, False, True, False]
State prediction error at timestep 58 is tensor(0.0033, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 58 of -1
Current timestep = 59. State = [[-0.14160417  0.09578132]]. Action = [[-0.0673379  -0.04097912 -0.07616675 -0.5650391 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 59 is [True, False, False, False, True, False]
State prediction error at timestep 59 is tensor(0.0044, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 59 of 0
Current timestep = 60. State = [[-0.13738948  0.09948093]]. Action = [[ 0.1747452   0.12418732  0.09696963 -0.15763098]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 60 is [True, False, False, False, True, False]
State prediction error at timestep 60 is tensor(0.0044, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 60 of -1
Current timestep = 61. State = [[-0.11646065  0.10914096]]. Action = [[0.21296555 0.00322932 0.11239117 0.5593841 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 61 is [True, False, False, False, True, False]
State prediction error at timestep 61 is tensor(0.0066, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 61 of -1
Current timestep = 62. State = [[-0.09827641  0.1038897 ]]. Action = [[-0.13505964 -0.15414253 -0.22954513  0.21564937]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 62 is [True, False, False, False, True, False]
State prediction error at timestep 62 is tensor(0.0058, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 62 of 1
Current timestep = 63. State = [[-0.09572663  0.0865242 ]]. Action = [[ 0.164956   -0.07210948  0.08534971 -0.6048857 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 63 is [True, False, False, False, True, False]
State prediction error at timestep 63 is tensor(0.0038, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 63 of 1
Current timestep = 64. State = [[-0.09373255  0.08269952]]. Action = [[-0.1179772   0.01340035  0.08007729 -0.5350277 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 64 is [True, False, False, False, True, False]
State prediction error at timestep 64 is tensor(0.0037, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 64 of 1
Current timestep = 65. State = [[-0.09098686  0.06813673]]. Action = [[ 0.09330624 -0.23214489  0.15573037  0.11056614]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 65 is [True, False, False, False, True, False]
State prediction error at timestep 65 is tensor(0.0022, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 65 of 1
Current timestep = 66. State = [[-0.08882138  0.05745803]]. Action = [[ 0.03351787  0.11330706 -0.2045087   0.9419992 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 66 is [True, False, False, False, True, False]
State prediction error at timestep 66 is tensor(0.0043, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 66 of 0
Current timestep = 67. State = [[-0.08180837  0.05095422]]. Action = [[ 0.14553225 -0.20598364 -0.01435503  0.24887931]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 67 is [True, False, False, False, True, False]
State prediction error at timestep 67 is tensor(0.0019, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 67 of 1
Current timestep = 68. State = [[-0.06433039  0.03405803]]. Action = [[ 0.09551257 -0.04701056  0.2435767   0.3064618 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 68 is [True, False, False, False, True, False]
State prediction error at timestep 68 is tensor(0.0029, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 68 of 1
Current timestep = 69. State = [[-0.06241132  0.02476381]]. Action = [[-0.19310024 -0.08691102  0.23027223 -0.0122267 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 69 is [True, False, False, False, True, False]
State prediction error at timestep 69 is tensor(0.0029, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 69 of 1
Current timestep = 70. State = [[-0.07112285  0.00575054]]. Action = [[-0.18296298 -0.19935268 -0.0424908  -0.7255032 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 70 is [True, False, False, False, True, False]
State prediction error at timestep 70 is tensor(0.0038, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 70 of -1
Current timestep = 71. State = [[-0.07920355 -0.01227974]]. Action = [[ 0.09917963 -0.02685426  0.12380821 -0.67360616]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 71 is [True, False, False, False, True, False]
State prediction error at timestep 71 is tensor(0.0027, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 71 of 0
Current timestep = 72. State = [[-0.07125394 -0.00113643]]. Action = [[ 0.21405676  0.22563758  0.20771205 -0.90071905]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 72 is [True, False, False, False, True, False]
State prediction error at timestep 72 is tensor(0.0041, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 72 of 1
Current timestep = 73. State = [[-0.0654901  0.0084188]]. Action = [[-0.07711932 -0.08851677 -0.19522178 -0.44889385]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 73 is [True, False, False, False, True, False]
State prediction error at timestep 73 is tensor(0.0029, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 73 of 1
Current timestep = 74. State = [[-0.05761648 -0.00359977]]. Action = [[ 0.2322253  -0.13527241  0.24418199 -0.76742   ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 74 is [True, False, False, False, True, False]
State prediction error at timestep 74 is tensor(0.0035, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 74 of 1
Current timestep = 75. State = [[-0.04064518 -0.01257753]]. Action = [[0.0111343  0.06752831 0.15723413 0.9600835 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 75 is [False, True, False, False, True, False]
State prediction error at timestep 75 is tensor(0.0058, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 75 of 1
Current timestep = 76. State = [[-0.03952878 -0.01755622]]. Action = [[-0.05869059 -0.14595231 -0.188539    0.83445466]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 76 is [False, True, False, False, True, False]
State prediction error at timestep 76 is tensor(0.0057, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 76 of 1
Current timestep = 77. State = [[-0.03923268 -0.03776287]]. Action = [[-0.03654812 -0.19207701 -0.11320296  0.00516152]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 77 is [False, True, False, False, True, False]
State prediction error at timestep 77 is tensor(0.0051, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 77 of -1
Current timestep = 78. State = [[-0.03698445 -0.06774399]]. Action = [[ 0.14291924 -0.22743419 -0.17602357 -0.85836303]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 78 is [False, True, False, False, True, False]
State prediction error at timestep 78 is tensor(0.0078, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 78 of -1
Current timestep = 79. State = [[-0.16296074 -0.08412334]]. Action = [[ 0.10526294 -0.12375206  0.23878735 -0.16662538]]. Reward = [100.]
Curr episode timestep = 26
Scene graph at timestep 79 is [True, False, False, False, True, False]
State prediction error at timestep 79 is tensor(0.0055, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 79 of 0
Current timestep = 80. State = [[-0.13703775 -0.10132767]]. Action = [[ 0.23352659 -0.12291315 -0.16635132  0.3643129 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 80 is [True, False, False, False, True, False]
State prediction error at timestep 80 is tensor(0.0058, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 80 of 1
Current timestep = 81. State = [[-0.10397556 -0.12266746]]. Action = [[ 0.21097821 -0.18445821 -0.00929591 -0.0454334 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 81 is [True, False, False, False, True, False]
State prediction error at timestep 81 is tensor(0.0084, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 81 of -1
Current timestep = 82. State = [[-0.07413334 -0.14535442]]. Action = [[ 0.19934118 -0.11798626  0.19614142 -0.71189547]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 82 is [True, False, False, True, False, False]
State prediction error at timestep 82 is tensor(0.0112, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 82 of -1
Current timestep = 83. State = [[-0.05182274 -0.14826822]]. Action = [[ 0.07713997  0.14515036  0.01320869 -0.85465634]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 83 is [True, False, False, True, False, False]
State prediction error at timestep 83 is tensor(0.0133, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 83 of 1
Current timestep = 84. State = [[-0.04446468 -0.14397657]]. Action = [[-0.01602963 -0.08148238  0.02089271 -0.27815533]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 84 is [False, True, False, True, False, False]
State prediction error at timestep 84 is tensor(0.0132, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 84 of -1
Current timestep = 85. State = [[-0.03710591 -0.15499301]]. Action = [[ 0.19784468 -0.13001461  0.02961937 -0.64998007]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 85 is [False, True, False, True, False, False]
State prediction error at timestep 85 is tensor(0.0141, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 85 of -1
Current timestep = 86. State = [[-0.00990527 -0.1547641 ]]. Action = [[ 0.16155076  0.19315788  0.06748042 -0.64366835]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 86 is [False, True, False, True, False, False]
State prediction error at timestep 86 is tensor(0.0164, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 86 of 1
Current timestep = 87. State = [[ 0.00782696 -0.15449305]]. Action = [[ 0.03030142 -0.1683106   0.15017265  0.27100492]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 87 is [False, True, False, True, False, False]
State prediction error at timestep 87 is tensor(0.0192, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 87 of -1
Current timestep = 88. State = [[ 0.01127058 -0.16808869]]. Action = [[-0.1911665  -0.04248978  0.09945935 -0.52767813]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 88 is [False, True, False, True, False, False]
State prediction error at timestep 88 is tensor(0.0212, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 88 of -1
Current timestep = 89. State = [[ 0.00282927 -0.1661019 ]]. Action = [[-0.1499994   0.17052382  0.19146478  0.5521774 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 90. State = [[-0.00180676 -0.15291218]]. Action = [[-0.05105339  0.04511634  0.20606369 -0.82372034]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 91. State = [[-0.00879356 -0.15742528]]. Action = [[-0.04805702 -0.13814521 -0.034523    0.22474658]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 92. State = [[-0.01231893 -0.1562366 ]]. Action = [[ 0.15682864  0.13881147 -0.16199803  0.36380196]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 93. State = [[-0.004196   -0.14348711]]. Action = [[ 0.22153565  0.05183163 -0.02577239 -0.8015387 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 94. State = [[ 0.00272877 -0.13897544]]. Action = [[-0.03082833 -0.04000214 -0.1255933   0.72884417]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 95. State = [[ 0.01075194 -0.145527  ]]. Action = [[ 0.224271   -0.11046128  0.24847573  0.27045512]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 96. State = [[ 0.03873583 -0.1593188 ]]. Action = [[ 0.2461159  -0.12807791  0.1654768   0.9936242 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 97. State = [[ 0.0643976  -0.17232499]]. Action = [[ 0.00903505 -0.04866128 -0.04947497 -0.7236747 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 97 is [False, False, True, True, False, False]
State prediction error at timestep 97 is tensor(0.0226, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 97 of -1
Current timestep = 98. State = [[ 0.07394733 -0.17742239]]. Action = [[ 0.03935266 -0.22266944 -0.04972526 -0.26784694]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 98 is [False, False, True, True, False, False]
State prediction error at timestep 98 is tensor(0.0235, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 98 of -1
Current timestep = 99. State = [[ 0.07009631 -0.19094075]]. Action = [[-0.22589242 -0.17539777  0.05355114 -0.4659493 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 99 is [False, False, True, True, False, False]
State prediction error at timestep 99 is tensor(0.0251, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 99 of -1
Current timestep = 100. State = [[ 0.05846564 -0.21992043]]. Action = [[-0.1374164  -0.17171206 -0.20874873 -0.7328994 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 100 is [False, False, True, True, False, False]
State prediction error at timestep 100 is tensor(0.0258, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 100 of -1
Current timestep = 101. State = [[ 0.05045503 -0.234937  ]]. Action = [[ 0.09417781 -0.1947509  -0.1637541   0.795033  ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 101 is [False, False, True, True, False, False]
State prediction error at timestep 101 is tensor(0.0264, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 101 of -1
Current timestep = 102. State = [[ 0.04822059 -0.22807711]]. Action = [[-0.06437211  0.14242828 -0.02546276 -0.66528153]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 103. State = [[ 0.04775591 -0.22102702]]. Action = [[0.07746029 0.01560324 0.20690194 0.83133507]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 104. State = [[ 0.0481387  -0.21856028]]. Action = [[ 0.17414421 -0.20577478 -0.05327456  0.0566287 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 105. State = [[ 0.048188   -0.21801634]]. Action = [[-0.01405773  0.00232488  0.20352489 -0.8753507 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 106. State = [[ 0.04821604 -0.21770486]]. Action = [[ 0.20624101  0.15459573 -0.02342367  0.11942947]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 107. State = [[ 0.0429153  -0.21565309]]. Action = [[-0.23251773  0.04867369  0.07370681 -0.3249843 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 108. State = [[ 0.03215348 -0.22125185]]. Action = [[ 0.09528708 -0.17201209 -0.21724154  0.51151466]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 109. State = [[ 0.02933259 -0.23760554]]. Action = [[-0.02475962 -0.13735513  0.22191301  0.5156498 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 110. State = [[ 0.02714116 -0.24758042]]. Action = [[ 0.24736726 -0.11915225 -0.12545553 -0.9149755 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 111. State = [[ 0.02643816 -0.26110882]]. Action = [[ 0.11994848 -0.21883105  0.17359212  0.96406984]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 112. State = [[ 0.03203076 -0.26974204]]. Action = [[ 0.18110323  0.11406547 -0.22924757  0.75155747]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 113. State = [[ 0.04727257 -0.2772389 ]]. Action = [[ 0.13960883 -0.19878352 -0.11815453  0.95320797]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 114. State = [[ 0.05769688 -0.28473967]]. Action = [[-0.20217577  0.11415085 -0.14556737  0.5141094 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 115. State = [[ 0.05776226 -0.28411278]]. Action = [[ 0.08050349 -0.15389335 -0.09022167 -0.8235983 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 116. State = [[ 0.05718674 -0.28522342]]. Action = [[-0.05153859 -0.00303891 -0.17200693 -0.98098284]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 117. State = [[ 0.05661093 -0.2864891 ]]. Action = [[ 0.20098248 -0.24367054  0.1843062   0.68382263]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 118. State = [[ 0.05632492 -0.28669092]]. Action = [[ 0.08488625  0.02271459  0.23796558 -0.39498675]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 119. State = [[ 0.05599678 -0.27500317]]. Action = [[-0.07721093  0.23671821  0.16380507  0.936219  ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 120. State = [[ 0.05191238 -0.25646275]]. Action = [[ 0.12866122 -0.00128199  0.23963737 -0.95774823]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 121. State = [[ 0.05166718 -0.2536895 ]]. Action = [[ 0.22421485  0.18432415 -0.10698575  0.97280073]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 122. State = [[ 0.04482247 -0.25220883]]. Action = [[-0.18077454  0.04031271 -0.08465455  0.1101011 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 123. State = [[ 0.02571795 -0.24793129]]. Action = [[-0.07627492  0.0055688  -0.1836336  -0.9710293 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 124. State = [[ 0.02002029 -0.247111  ]]. Action = [[ 0.12160844 -0.05283228 -0.09360406  0.4167291 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 125. State = [[ 0.0146217  -0.26259965]]. Action = [[-0.1172393  -0.2222543  -0.0068159  -0.02090383]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 126. State = [[ 0.00373263 -0.26718065]]. Action = [[-0.17467532  0.20487162 -0.09892341  0.48646092]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 127. State = [[-0.00396821 -0.24732697]]. Action = [[0.01696983 0.21160907 0.13532066 0.2263478 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 128. State = [[-0.00588009 -0.2233551 ]]. Action = [[ 0.06202352  0.06384298 -0.14102043 -0.34244847]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 129. State = [[ 0.00072532 -0.20686106]]. Action = [[ 0.2461003   0.1090475   0.11024877 -0.43199962]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 130. State = [[ 0.00535017 -0.1984093 ]]. Action = [[-0.09242262 -0.01795116 -0.15010945 -0.45824683]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 131. State = [[ 0.01144756 -0.19195904]]. Action = [[ 0.24087328  0.06910092 -0.04606843  0.87864566]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 132. State = [[ 0.03278629 -0.17118701]]. Action = [[ 0.20155397  0.2426402   0.19810945 -0.7761005 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 133. State = [[ 0.04814252 -0.15412349]]. Action = [[ 0.20672375  0.06384864 -0.06369144 -0.8937726 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 134. State = [[ 0.05060583 -0.15141952]]. Action = [[ 0.16911626  0.02105609  0.15644869 -0.06864125]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 135. State = [[ 0.05085633 -0.1582619 ]]. Action = [[-0.01933727 -0.14161265  0.08469924 -0.5572205 ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 136. State = [[ 0.05311003 -0.15106417]]. Action = [[0.06720257 0.24102673 0.19709113 0.50919545]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 137. State = [[ 0.05177724 -0.14674325]]. Action = [[-0.19333223 -0.14208479  0.15278202 -0.3892069 ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 138. State = [[ 0.05063412 -0.15164982]]. Action = [[ 0.21981862 -0.19774608 -0.16010863  0.32212222]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 139. State = [[ 0.04469461 -0.14109366]]. Action = [[-0.22869173  0.23271781  0.1172024   0.61779344]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 140. State = [[ 0.0326994  -0.11368544]]. Action = [[-0.03908472  0.18354145 -0.08048369 -0.65899163]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 140 is [False, True, False, False, True, False]
State prediction error at timestep 140 is tensor(0.0011, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 140 of 1
Current timestep = 141. State = [[-0.1546274  -0.03493083]]. Action = [[-0.12042332  0.10202554 -0.15139928  0.56767833]]. Reward = [100.]
Curr episode timestep = 61
Current timestep = 142. State = [[-0.12887582 -0.05015416]]. Action = [[ 0.2277107  -0.18872377  0.18106931  0.95737123]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 143. State = [[-0.11423409 -0.07689717]]. Action = [[-0.18105692 -0.17972818  0.15808088  0.23324811]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 144. State = [[-0.11724188 -0.09613868]]. Action = [[ 0.06768098 -0.07956666  0.23022693 -0.4625588 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 145. State = [[-0.11848454 -0.11469282]]. Action = [[-0.10881774 -0.14885719  0.04505166  0.4928341 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 146. State = [[-0.11891019 -0.13581587]]. Action = [[ 0.13545215 -0.16428906 -0.00529461  0.7731147 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 146 is [True, False, False, True, False, False]
State prediction error at timestep 146 is tensor(0.0019, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 146 of -1
Current timestep = 147. State = [[-0.1110935  -0.14036413]]. Action = [[ 0.08170366  0.21054137  0.06524697 -0.14128429]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 147 is [True, False, False, True, False, False]
State prediction error at timestep 147 is tensor(0.0030, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 147 of 1
Current timestep = 148. State = [[-0.10196257 -0.13127851]]. Action = [[ 0.07656413 -0.12713876 -0.05752638 -0.02290988]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 148 is [True, False, False, True, False, False]
State prediction error at timestep 148 is tensor(0.0013, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 148 of 1
Current timestep = 149. State = [[-0.08690996 -0.13266805]]. Action = [[ 0.15982065  0.11944076  0.20795196 -0.77975875]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 150. State = [[-0.0648236  -0.11771286]]. Action = [[ 0.1780867   0.17920607 -0.14090659 -0.8727146 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 151. State = [[-0.05160306 -0.11562349]]. Action = [[-0.08942331 -0.17725995 -0.00144194 -0.501458  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 152. State = [[-0.05757578 -0.12572585]]. Action = [[-0.2093691  -0.03419861  0.09063396 -0.27373755]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 153. State = [[-0.06324241 -0.12612757]]. Action = [[-0.02107319  0.09621385  0.16457897  0.25744343]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 154. State = [[-0.06247981 -0.13275035]]. Action = [[ 0.17505017 -0.21845783  0.16195214 -0.4117931 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 155. State = [[-0.06182317 -0.1372008 ]]. Action = [[ 0.0067493   0.12476549 -0.08415823 -0.20675886]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 156. State = [[-0.06555195 -0.13174921]]. Action = [[-0.23948415  0.04545721 -0.19864057  0.44757867]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 157. State = [[-0.07012033 -0.14035557]]. Action = [[ 0.01481566 -0.193921    0.08217981 -0.6270818 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 158. State = [[-0.08215016 -0.1459051 ]]. Action = [[-0.21460113  0.09913099 -0.23064227  0.2943716 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 159. State = [[-0.09134924 -0.13087253]]. Action = [[ 0.17173514  0.19545537 -0.08221114  0.00902665]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 160. State = [[-0.0928374 -0.1080059]]. Action = [[-0.11870269  0.1243673  -0.11004424  0.3545723 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 161. State = [[-0.09440359 -0.10178594]]. Action = [[ 0.05235723 -0.09353186  0.00579876  0.10638964]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 162. State = [[-0.09691418 -0.09303759]]. Action = [[-0.1132279   0.19222039  0.04201907 -0.64966965]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 163. State = [[-0.0987791  -0.08029668]]. Action = [[ 0.06335908  0.02518207 -0.2469066   0.8860295 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 164. State = [[-0.0976178  -0.08601324]]. Action = [[ 0.07156938 -0.18181463 -0.2053109  -0.28083062]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 165. State = [[-0.09350837 -0.10376728]]. Action = [[ 0.08792666 -0.14106698 -0.0841828  -0.7361698 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 166. State = [[-0.09593727 -0.10850833]]. Action = [[-0.22445408  0.12858945  0.14864689  0.29805064]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 167. State = [[-0.10412396 -0.11861448]]. Action = [[-0.11213323 -0.20781578  0.22845697  0.30822825]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 168. State = [[-0.10948496 -0.11730955]]. Action = [[ 0.20612347  0.21164435 -0.03623816  0.9074075 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 169. State = [[-0.1099148  -0.10926538]]. Action = [[-0.14222065 -0.02979243  0.11555389  0.73279643]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 170. State = [[-0.11013812 -0.10869369]]. Action = [[ 0.10652801  0.00423568  0.18194294 -0.6561218 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 171. State = [[-0.11039726 -0.10433262]]. Action = [[-0.07648998  0.06789818  0.0556086  -0.84785736]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 172. State = [[-0.11194818 -0.1108603 ]]. Action = [[-0.04236451 -0.18687834  0.05717695  0.11882329]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 173. State = [[-0.11248215 -0.1250189 ]]. Action = [[ 0.09232149 -0.10005018 -0.21030003 -0.10352606]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 174. State = [[-0.11752958 -0.12262614]]. Action = [[-0.20282157  0.19133604 -0.19717999 -0.27154446]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 175. State = [[-0.12354737 -0.1079508 ]]. Action = [[ 0.05571857  0.10177249 -0.10374671  0.6790824 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 176. State = [[-0.12388639 -0.09932905]]. Action = [[ 0.00847661  0.00578666  0.20135304 -0.90450925]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 177. State = [[-0.1163367  -0.10780844]]. Action = [[ 0.23561883 -0.20465393 -0.07711168  0.8455999 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 178. State = [[-0.10839646 -0.12806186]]. Action = [[ 0.01367655 -0.15658566 -0.06083584 -0.7361914 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 179. State = [[-0.09718644 -0.14324668]]. Action = [[ 0.18563184 -0.04074086  0.19104865 -0.8417637 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 180. State = [[-0.0752492  -0.14700648]]. Action = [[ 0.14914817  0.00787675  0.1647667  -0.61161536]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 181. State = [[-0.05305169 -0.14018285]]. Action = [[ 0.21545243  0.13907075 -0.22165434  0.11641014]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 182. State = [[-0.03609837 -0.12075183]]. Action = [[-0.10312241  0.21536374  0.19609612 -0.7495477 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 183. State = [[-0.0363702  -0.10971221]]. Action = [[ 0.05378896 -0.08204979  0.22194147 -0.66311145]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 184. State = [[-0.0388444  -0.10849691]]. Action = [[-0.21364225  0.05421466 -0.07845476  0.0742631 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 185. State = [[-0.03692821 -0.11717442]]. Action = [[ 0.24541208 -0.20305869  0.22976205 -0.34854776]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 186. State = [[-0.02524368 -0.12418099]]. Action = [[ 0.14374202  0.05970204  0.21578833 -0.19352412]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 187. State = [[-0.01490868 -0.13495618]]. Action = [[-0.08005401 -0.20180061  0.22917306  0.93297434]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 187 is [False, True, False, True, False, False]
State prediction error at timestep 187 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 187 of 1
Current timestep = 188. State = [[-0.01588526 -0.15162146]]. Action = [[-0.04557498 -0.03070717  0.0977878  -0.8940748 ]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 189. State = [[-0.01201268 -0.14560036]]. Action = [[ 0.1639049   0.14681062 -0.2048835  -0.6991307 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 190. State = [[-0.01254327 -0.1352103 ]]. Action = [[-0.23492174  0.08147049  0.24434614  0.57397103]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 191. State = [[-0.0216889  -0.13985308]]. Action = [[-0.21505344 -0.1550175  -0.01907268 -0.56157386]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 192. State = [[-0.03822678 -0.13753653]]. Action = [[-0.1166503   0.18700194  0.22494513 -0.91183835]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 193. State = [[-0.04812658 -0.13925833]]. Action = [[ 0.13668722 -0.22821781  0.0723249  -0.42907572]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 194. State = [[-0.04215841 -0.15964729]]. Action = [[ 0.1928837  -0.17570786  0.22073439 -0.5246963 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 195. State = [[-0.03033752 -0.18184723]]. Action = [[ 0.16848665 -0.13606614 -0.08409092 -0.93250114]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 196. State = [[-0.00910357 -0.2068121 ]]. Action = [[ 0.17249203 -0.24885742  0.197959   -0.665807  ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 197. State = [[ 0.00275516 -0.23132603]]. Action = [[-0.18933861 -0.0292688   0.24166071  0.5929861 ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 198. State = [[ 0.00512663 -0.2446333 ]]. Action = [[ 0.19933736 -0.13710403  0.2114411  -0.97881097]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 199. State = [[ 0.02086096 -0.25339738]]. Action = [[ 0.16427273  0.00593075 -0.0620153   0.42102015]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 200. State = [[ 0.03498481 -0.2651876 ]]. Action = [[-0.02727638 -0.16087994  0.22052842 -0.98036844]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 201. State = [[ 0.03802918 -0.26991397]]. Action = [[-0.05328941  0.16039592 -0.03626119  0.6634953 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 202. State = [[ 0.03819127 -0.26642546]]. Action = [[ 0.16813529 -0.19415106 -0.00908598 -0.28632683]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 203. State = [[ 0.03885442 -0.2565581 ]]. Action = [[-0.04686788  0.15897316 -0.05520691 -0.9537454 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 204. State = [[ 0.04093179 -0.23341157]]. Action = [[-0.02159242  0.21364021 -0.0128435  -0.3868965 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 205. State = [[ 0.03978527 -0.20429245]]. Action = [[-0.1436106   0.19902295 -0.2097534  -0.8706462 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 206. State = [[ 0.03793631 -0.17454721]]. Action = [[ 0.14035028  0.20390257 -0.16220447 -0.23005545]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 207. State = [[ 0.0408548  -0.16353637]]. Action = [[ 0.11777669 -0.1670009   0.17785028  0.87834036]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 208. State = [[ 0.04128223 -0.17565022]]. Action = [[-0.03323311 -0.12758139 -0.16643636  0.8763654 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 209. State = [[ 0.03656383 -0.19282834]]. Action = [[-0.23738836 -0.0586846  -0.22149496  0.8677925 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 210. State = [[ 0.02627035 -0.20715524]]. Action = [[-0.07708153 -0.09477514  0.05196509 -0.6757212 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 211. State = [[ 0.00820388 -0.22645451]]. Action = [[-0.22055769 -0.16431504  0.11172071 -0.7693261 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 212. State = [[-0.0046977  -0.22659679]]. Action = [[0.09406161 0.22141498 0.23132607 0.7167047 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 213. State = [[-0.00831476 -0.20944096]]. Action = [[-0.1273397   0.07317698  0.08893964  0.5352428 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 214. State = [[-0.01254242 -0.20628874]]. Action = [[ 0.17909348 -0.1013006   0.19760093 -0.8952958 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 215. State = [[-0.01173176 -0.22027732]]. Action = [[-0.02167533 -0.19372167  0.19706094  0.41722727]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 216. State = [[-0.01829067 -0.2342914 ]]. Action = [[-0.1986158   0.02300322 -0.22296381 -0.5411025 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 217. State = [[-0.03098544 -0.2521172 ]]. Action = [[-0.07278249 -0.22395006  0.22094065 -0.7199946 ]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 218. State = [[-0.03142617 -0.25399342]]. Action = [[ 0.16156572  0.22969285  0.08605257 -0.18810964]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 219. State = [[-0.03450638 -0.2517    ]]. Action = [[-0.22061074 -0.1371066  -0.19704296 -0.57417256]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 220. State = [[-0.04242646 -0.25344914]]. Action = [[-0.00640801  0.09488404 -0.0176433  -0.8502192 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 221. State = [[-0.04200823 -0.2524883 ]]. Action = [[ 0.15732843 -0.08855236 -0.05388197 -0.620015  ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 222. State = [[-0.03236496 -0.2535732 ]]. Action = [[ 0.1999278  -0.03137359  0.23213294 -0.90734386]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 223. State = [[-0.01839461 -0.26054925]]. Action = [[ 0.18966001 -0.12968212  0.14029509 -0.4012596 ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 224. State = [[-0.00641082 -0.26321223]]. Action = [[-0.19578561  0.17032385 -0.14149201  0.97472143]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 225. State = [[-0.00725193 -0.26612848]]. Action = [[-0.00044927 -0.13654807 -0.21835141  0.406551  ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 226. State = [[-0.01373694 -0.27280873]]. Action = [[-0.12484333 -0.00794078 -0.19000405 -0.20584285]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 227. State = [[-0.02568639 -0.2714029 ]]. Action = [[-0.18106258  0.10491648  0.17327264  0.876827  ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 228. State = [[-0.03441904 -0.26909685]]. Action = [[ 0.1832293  -0.08115064  0.06268027  0.85237193]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 229. State = [[-0.02770214 -0.25861332]]. Action = [[ 0.12257138  0.21102086  0.12948525 -0.54304254]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 230. State = [[-0.02772537 -0.25483754]]. Action = [[-0.19129133 -0.15239058 -0.19405855  0.09071159]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 231. State = [[-0.02737075 -0.24895379]]. Action = [[ 0.12000754  0.21422261  0.00455737 -0.3828326 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 232. State = [[-0.027185   -0.22344895]]. Action = [[-0.17073072  0.24834666  0.15115273 -0.56543094]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 233. State = [[-0.02761902 -0.21247244]]. Action = [[ 0.20743275 -0.19160265 -0.23828419  0.66965103]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 234. State = [[-0.02298916 -0.2081884 ]]. Action = [[0.0709005  0.16131607 0.06544128 0.32853103]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 235. State = [[-0.02224847 -0.20774049]]. Action = [[-0.1276336  -0.10589132  0.13230282  0.94335985]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 236. State = [[-0.02911697 -0.2083642 ]]. Action = [[-0.18536665  0.08489192 -0.04584776 -0.8635586 ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 237. State = [[-0.03701612 -0.2095523 ]]. Action = [[-0.00868516 -0.04261702 -0.14914185  0.08562553]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 238. State = [[-0.04426198 -0.22547102]]. Action = [[-0.07150987 -0.22419369  0.05058274 -0.9784463 ]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 239. State = [[-0.04335955 -0.22731636]]. Action = [[ 0.18282163  0.18709248 -0.01272321  0.69906855]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 240. State = [[-0.03297805 -0.22941235]]. Action = [[ 0.23616707 -0.22349074  0.03212446  0.15118003]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 241. State = [[-0.0154084 -0.2321333]]. Action = [[ 0.09681565  0.12567514 -0.02010658  0.46125054]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 242. State = [[-0.00682667 -0.21711852]]. Action = [[-0.10283983  0.20835084  0.11190119  0.34354055]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 243. State = [[-0.00990151 -0.21361962]]. Action = [[-0.087596   -0.18645413 -0.12393533 -0.530624  ]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 244. State = [[-0.0080979  -0.20899494]]. Action = [[ 0.19473147  0.19711334  0.00472081 -0.70051944]]. Reward = [0.]
Curr episode timestep = 102
Current timestep = 245. State = [[ 0.00534989 -0.18821403]]. Action = [[ 0.19258857  0.16733485 -0.23898976 -0.4558518 ]]. Reward = [0.]
Curr episode timestep = 103
Current timestep = 246. State = [[ 0.02373927 -0.18427217]]. Action = [[ 0.07628471 -0.18164472  0.10895264 -0.96631545]]. Reward = [0.]
Curr episode timestep = 104
Current timestep = 247. State = [[ 0.03704095 -0.19867936]]. Action = [[ 0.13983476 -0.12937556 -0.01772904  0.9381838 ]]. Reward = [0.]
Curr episode timestep = 105
Current timestep = 248. State = [[ 0.0474701 -0.2074589]]. Action = [[-0.10963044  0.02914995 -0.11367413 -0.6652393 ]]. Reward = [0.]
Curr episode timestep = 106
Current timestep = 249. State = [[ 0.04662637 -0.20830624]]. Action = [[ 0.23489392  0.2001118  -0.16485599  0.9443462 ]]. Reward = [0.]
Curr episode timestep = 107
Current timestep = 250. State = [[ 0.04037076 -0.21864213]]. Action = [[-0.18782924 -0.14073473 -0.03349411 -0.6830687 ]]. Reward = [0.]
Curr episode timestep = 108
Current timestep = 251. State = [[ 0.03893567 -0.21630907]]. Action = [[ 0.12954697  0.21041784  0.01498258 -0.36119264]]. Reward = [0.]
Curr episode timestep = 109
Current timestep = 252. State = [[ 0.04235706 -0.1945363 ]]. Action = [[ 0.03778705  0.1920093   0.14904732 -0.86713374]]. Reward = [0.]
Curr episode timestep = 110
Current timestep = 253. State = [[ 0.04245669 -0.19102417]]. Action = [[-0.01362801 -0.23193234 -0.14415126 -0.6057614 ]]. Reward = [0.]
Curr episode timestep = 111
Current timestep = 254. State = [[ 0.04039876 -0.21356858]]. Action = [[-0.02889292 -0.21468028 -0.20399858 -0.34769958]]. Reward = [0.]
Curr episode timestep = 112
Current timestep = 255. State = [[ 0.0386684  -0.23043042]]. Action = [[-0.0598076   0.01924095  0.20094126  0.9387238 ]]. Reward = [0.]
Curr episode timestep = 113
Current timestep = 256. State = [[ 0.03382742 -0.23200394]]. Action = [[-0.18348347  0.05937466  0.0049783   0.5296651 ]]. Reward = [0.]
Curr episode timestep = 114
Current timestep = 257. State = [[ 0.03032743 -0.2209575 ]]. Action = [[ 0.11391643  0.19379663 -0.16471452  0.25842428]]. Reward = [0.]
Curr episode timestep = 115
Current timestep = 258. State = [[ 0.03200079 -0.19813362]]. Action = [[ 0.00693578  0.10598889 -0.05413416  0.44642472]]. Reward = [0.]
Curr episode timestep = 116
Current timestep = 259. State = [[ 0.03209042 -0.18194324]]. Action = [[-0.05600573  0.10732675  0.10943782  0.6852701 ]]. Reward = [0.]
Curr episode timestep = 117
Current timestep = 260. State = [[ 0.02146425 -0.17899944]]. Action = [[-0.24542364 -0.0538556   0.19423214 -0.71496016]]. Reward = [0.]
Curr episode timestep = 118
Current timestep = 261. State = [[ 0.00039471 -0.17676455]]. Action = [[-0.07728148  0.04500347 -0.22239219  0.68417275]]. Reward = [0.]
Curr episode timestep = 119
Current timestep = 262. State = [[-0.01441518 -0.16811027]]. Action = [[-0.14227414  0.10269126  0.23962629  0.5342331 ]]. Reward = [0.]
Curr episode timestep = 120
Current timestep = 263. State = [[-0.03656163 -0.17040916]]. Action = [[-0.2035332  -0.14977734 -0.02000804 -0.21781647]]. Reward = [0.]
Curr episode timestep = 121
Current timestep = 264. State = [[-0.05340571 -0.1890115 ]]. Action = [[ 0.12519571 -0.2300908  -0.03851762 -0.31938392]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 264 is [True, False, False, True, False, False]
State prediction error at timestep 264 is tensor(0.0008, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 264 of -1
Current timestep = 265. State = [[-0.06167952 -0.21595314]]. Action = [[-0.14325686 -0.12009351  0.20407617  0.7268672 ]]. Reward = [0.]
Curr episode timestep = 123
Current timestep = 266. State = [[-0.07175967 -0.23583947]]. Action = [[-0.02335989 -0.18574551  0.06194159  0.4665469 ]]. Reward = [0.]
Curr episode timestep = 124
Current timestep = 267. State = [[-0.08013541 -0.2412134 ]]. Action = [[-0.10237575  0.21540114  0.14150584 -0.79348916]]. Reward = [0.]
Curr episode timestep = 125
Current timestep = 268. State = [[-0.1907549  -0.22127107]]. Action = [[-0.00348967  0.06518483  0.08341354  0.8727523 ]]. Reward = [0.]
Curr episode timestep = 126
Current timestep = 269. State = [[-0.18382315 -0.24543108]]. Action = [[-0.16630311  0.05773294  0.20662498 -0.9099393 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 270. State = [[-0.1827756  -0.23397127]]. Action = [[ 0.1399644   0.19625056  0.06580144 -0.86750346]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 271. State = [[-0.17135318 -0.22169541]]. Action = [[ 0.23165053 -0.01049407 -0.19713853  0.3771726 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 272. State = [[-0.15006803 -0.22802545]]. Action = [[ 0.1457147  -0.21134509 -0.033149    0.45572948]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 273. State = [[-0.1301625  -0.25226292]]. Action = [[ 0.05206525 -0.193334   -0.11755401  0.9369626 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 274. State = [[-0.12663412 -0.2709896 ]]. Action = [[-0.14198133 -0.02593887  0.16088045 -0.45782185]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 275. State = [[-0.12949176 -0.2735386 ]]. Action = [[0.10932556 0.0631566  0.11583003 0.23592508]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 276. State = [[-0.12253068 -0.2798344 ]]. Action = [[ 0.12059823 -0.17070352  0.00490251  0.76926434]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 277. State = [[-0.10849696 -0.28388467]]. Action = [[0.03025228 0.10971394 0.1987567  0.26971364]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 278. State = [[-0.10747876 -0.2887955 ]]. Action = [[-0.13247944 -0.10067719 -0.15062074 -0.9636402 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 279. State = [[-0.10362875 -0.2948003 ]]. Action = [[ 0.21693474 -0.07308596 -0.18402533 -0.8463928 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 280. State = [[-0.09309307 -0.29916096]]. Action = [[-0.01365353 -0.20187367 -0.1618977   0.6134808 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 281. State = [[-0.09275378 -0.30189538]]. Action = [[-0.07818963 -0.01684028  0.21673447 -0.06361216]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 282. State = [[-0.09322643 -0.30202466]]. Action = [[-0.00261235  0.07251933 -0.16638924 -0.68022424]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 283. State = [[-0.09890301 -0.2911924 ]]. Action = [[-0.20395046  0.21277887  0.09730089 -0.8472607 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 284. State = [[-0.10338109 -0.2667252 ]]. Action = [[ 0.04117385  0.22251004 -0.07001309 -0.35813326]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 285. State = [[-0.10420819 -0.2563076 ]]. Action = [[-0.04217805 -0.14563784  0.23617953  0.74458027]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 286. State = [[-0.10959671 -0.26773825]]. Action = [[-0.03454089 -0.11002867 -0.01484811 -0.25416535]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 287. State = [[-0.11808003 -0.275334  ]]. Action = [[-0.11754125  0.00828364  0.12514934  0.83864486]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 288. State = [[-0.12680475 -0.27719465]]. Action = [[-0.18607353 -0.19592722  0.13803673  0.6271913 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 289. State = [[-0.13977122 -0.2780838 ]]. Action = [[-2.1741965e-01  2.2986531e-04  3.6898136e-02 -7.8440684e-01]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 290. State = [[-0.15932885 -0.27432594]]. Action = [[-0.0521397   0.07743999  0.2276029  -0.91428834]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 291. State = [[-0.16624984 -0.27121344]]. Action = [[ 0.24032646 -0.22208588  0.15903503 -0.73918587]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 292. State = [[-0.16107753 -0.25659823]]. Action = [[0.15475726 0.21189669 0.1347782  0.65381753]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 293. State = [[-0.14834727 -0.24580558]]. Action = [[ 0.21310586 -0.14974566 -0.22405343  0.8060558 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 294. State = [[-0.13986862 -0.24215622]]. Action = [[-0.05250975  0.12520543  0.1476362   0.32231438]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 295. State = [[-0.14282092 -0.2512579 ]]. Action = [[-0.10353038 -0.23889185 -0.03497306 -0.15495223]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 296. State = [[-0.13937956 -0.2589795 ]]. Action = [[ 0.21483433  0.06617475  0.13143545 -0.4141078 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 297. State = [[-0.1282653  -0.25388744]]. Action = [[ 0.04856926  0.06837216 -0.10453996 -0.9175371 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 298. State = [[-0.11421825 -0.25103456]]. Action = [[ 0.2260277  -0.03618033 -0.17258367 -0.39966708]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 299. State = [[-0.09947697 -0.25239295]]. Action = [[-1.06125325e-01 -5.41269779e-04 -1.98737532e-02 -9.50222969e-01]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 300. State = [[-0.095163  -0.2570652]]. Action = [[ 0.14404687 -0.09732884  0.14909542 -0.60382515]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 301. State = [[-0.08984463 -0.255808  ]]. Action = [[-0.04185539  0.11646658  0.19855314 -0.11730927]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 302. State = [[-0.09295899 -0.26492533]]. Action = [[-0.13794991 -0.19197041  0.04373288  0.2011671 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 303. State = [[-0.10986208 -0.28799856]]. Action = [[-0.22615081 -0.1719465  -0.06785014  0.51284814]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 304. State = [[-0.11807936 -0.29645312]]. Action = [[ 0.09001279  0.10841778  0.22073591 -0.30949903]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 305. State = [[-0.11744336 -0.2944566 ]]. Action = [[ 0.23994559 -0.16321832 -0.06792158 -0.46716058]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 306. State = [[-0.1173869  -0.29440078]]. Action = [[-0.03219602 -0.2162632  -0.21933647 -0.18415761]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 307. State = [[-0.1173869  -0.29440078]]. Action = [[ 0.20221868 -0.10410926  0.23131493 -0.6394611 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 308. State = [[-0.1118928  -0.28150964]]. Action = [[ 0.12218368  0.19224033 -0.03684449 -0.8949853 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 309. State = [[-0.10786504 -0.26699302]]. Action = [[-0.0861567   0.03815013  0.23546386 -0.926113  ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 310. State = [[-0.10266208 -0.25151187]]. Action = [[0.15103644 0.15091258 0.07049116 0.9531498 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 311. State = [[-0.10462966 -0.25156844]]. Action = [[-0.19669269 -0.19466257 -0.0240597  -0.70194674]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 312. State = [[-0.10766211 -0.2621655 ]]. Action = [[ 0.15669513 -0.06216708  0.09466803  0.7066703 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 313. State = [[-0.09928939 -0.27609593]]. Action = [[ 0.18969458 -0.1976058   0.1839869  -0.2600128 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 314. State = [[-0.08904203 -0.28457358]]. Action = [[-0.10322902  0.13915807 -0.1169858  -0.02165639]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 315. State = [[-0.0892719  -0.28303784]]. Action = [[-0.11424872 -0.22305514 -0.04300794  0.49133205]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 316. State = [[-0.08265179 -0.28421474]]. Action = [[ 0.20824495 -0.08501679  0.09237576  0.85883236]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 317. State = [[-0.06203353 -0.29151616]]. Action = [[ 0.20392668 -0.10486814  0.14447758  0.7407019 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 318. State = [[-0.04138019 -0.293138  ]]. Action = [[ 0.0296151   0.11363769 -0.01475084 -0.2437998 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 319. State = [[-0.03577949 -0.289863  ]]. Action = [[ 0.23418173 -0.17905144 -0.05238217  0.29264998]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 320. State = [[-0.03494932 -0.289032  ]]. Action = [[ 0.06697163 -0.21932857  0.07265913 -0.6978583 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 321. State = [[-0.02349033 -0.27885234]]. Action = [[ 0.2156074   0.13465509 -0.15774813 -0.6417445 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 322. State = [[-0.01022865 -0.26092005]]. Action = [[-0.14811558  0.23154235 -0.21569897 -0.2963369 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 323. State = [[-0.00576662 -0.25048   ]]. Action = [[ 0.18148369 -0.15235639  0.17637178  0.32723773]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 324. State = [[-0.00121162 -0.2626545 ]]. Action = [[-0.00033925 -0.15986724  0.07786939  0.09743345]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 325. State = [[-0.00096233 -0.27303132]]. Action = [[-0.08478005  0.02017856 -0.01153827  0.8160958 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 326. State = [[-0.00544721 -0.27270904]]. Action = [[-0.20647329  0.10610014  0.00713637  0.9687635 ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 327. State = [[-0.01213512 -0.27544847]]. Action = [[-0.01460712 -0.07440478  0.10648438  0.0214709 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 328. State = [[-0.01491505 -0.2871836 ]]. Action = [[ 0.13868117 -0.17500468 -0.19224814 -0.70155936]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 329. State = [[-0.01174669 -0.2849753 ]]. Action = [[0.09340009 0.17888802 0.08653095 0.6299268 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 330. State = [[-0.00854078 -0.27702758]]. Action = [[ 0.03068984 -0.14868492  0.01507533  0.11689115]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 331. State = [[-0.00816895 -0.27552113]]. Action = [[ 0.22590876 -0.2376346   0.19300377  0.83409154]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 332. State = [[-0.00146509 -0.28432837]]. Action = [[ 0.16429156 -0.18608944  0.18325138 -0.8853435 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 333. State = [[ 0.00601223 -0.29820037]]. Action = [[-0.23927926 -0.00786111 -0.00695764  0.7814722 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 334. State = [[ 0.00344975 -0.30297044]]. Action = [[ 0.24527478 -0.24491334  0.06373972  0.5355071 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 335. State = [[ 0.00878942 -0.29164755]]. Action = [[ 0.20884058  0.17615867  0.19725484 -0.9084302 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 336. State = [[ 0.01315899 -0.28089175]]. Action = [[ 0.21648872 -0.18110842  0.21521273 -0.9250322 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 337. State = [[ 0.02228402 -0.28323758]]. Action = [[ 0.22881961 -0.12811795  0.12379766  0.50184274]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 338. State = [[ 0.04043991 -0.2828826 ]]. Action = [[-0.08564913  0.1275627   0.10327831 -0.87377536]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 339. State = [[ 0.04115288 -0.27808872]]. Action = [[ 0.06066048  0.01947671 -0.04692781 -0.5363477 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 340. State = [[ 0.04149513 -0.2748644 ]]. Action = [[-0.12402007  0.04006445 -0.10226312  0.6523497 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 341. State = [[ 0.03511534 -0.28311518]]. Action = [[-0.18719473 -0.12753674  0.24169993  0.75573516]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 342. State = [[ 0.02932926 -0.29139352]]. Action = [[ 0.18756974 -0.16472138 -0.19688167 -0.501675  ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 343. State = [[ 0.03061244 -0.2904357 ]]. Action = [[ 0.1918273  -0.00331289  0.17667112  0.43195903]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 344. State = [[ 0.03137406 -0.28605735]]. Action = [[-0.11617056  0.08652914 -0.10936454  0.19856465]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 345. State = [[ 0.0274771 -0.2897948]]. Action = [[-0.14123783 -0.09969869 -0.13291278  0.74806356]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 346. State = [[ 0.02319713 -0.29544857]]. Action = [[ 0.18231446 -0.24571222  0.1725356   0.87576497]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 347. State = [[ 0.01930455 -0.29957724]]. Action = [[-0.06485939 -0.05358332  0.10382178 -0.47753012]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 348. State = [[ 0.01724202 -0.29247922]]. Action = [[ 0.12994838  0.16514838 -0.12840994 -0.9666228 ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 349. State = [[ 0.01931715 -0.2823456 ]]. Action = [[ 0.05614096 -0.15208013  0.23987651  0.3537736 ]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 350. State = [[ 0.01962502 -0.28070134]]. Action = [[-0.04159421 -0.20067854  0.19978592  0.86393046]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 351. State = [[ 0.01799977 -0.27019793]]. Action = [[-0.1491004   0.19989869 -0.11529341 -0.82551473]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 352. State = [[ 0.01517521 -0.25795376]]. Action = [[ 0.13347429 -0.07228923  0.04876065  0.00972509]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 353. State = [[ 0.01740891 -0.2662718 ]]. Action = [[ 0.11352694 -0.18998046 -0.24670345 -0.61335874]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 354. State = [[ 0.01634585 -0.28399798]]. Action = [[ 0.0257082  -0.13682044  0.09261632  0.85379744]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 355. State = [[ 0.02800582 -0.29215315]]. Action = [[ 0.23144233  0.02399099  0.0607419  -0.6205156 ]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 356. State = [[ 0.04281183 -0.2911975 ]]. Action = [[-0.18947203  0.08242774 -0.2025061  -0.22236311]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 357. State = [[ 0.03989459 -0.28964713]]. Action = [[-0.12492359  0.0513528   0.06211871 -0.6609782 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 358. State = [[ 0.03741063 -0.2883948 ]]. Action = [[ 0.17505026  0.10464162 -0.11233369 -0.04532176]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 359. State = [[ 0.03890432 -0.2793202 ]]. Action = [[ 0.12877893  0.11230212  0.24718508 -0.25004917]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 360. State = [[ 0.04457876 -0.25941098]]. Action = [[ 0.1341581   0.1517325  -0.15274595  0.6878625 ]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 361. State = [[ 0.0471409 -0.2452707]]. Action = [[ 0.21198118  0.22200617 -0.05311204  0.24639535]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 362. State = [[ 0.04763071 -0.24354517]]. Action = [[ 0.21165061 -0.04140982 -0.21047439  0.1766715 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 363. State = [[ 0.0448366 -0.2528049]]. Action = [[-0.16851357 -0.15001337  0.07486036 -0.77413636]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 364. State = [[ 0.04160925 -0.2600923 ]]. Action = [[ 0.24639264 -0.07872446 -0.10515377 -0.7109053 ]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 365. State = [[ 0.041273   -0.24890201]]. Action = [[-0.06250425  0.24390692 -0.20480758 -0.39487445]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 366. State = [[ 0.04124619 -0.23605384]]. Action = [[ 0.165344   -0.04521492  0.1778363  -0.8496427 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 367. State = [[ 0.04139149 -0.23414478]]. Action = [[ 0.14968613 -0.04226226  0.1898219   0.28722155]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 368. State = [[ 0.03770072 -0.22246638]]. Action = [[-0.13283339  0.19849494  0.11660451 -0.85823697]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 369. State = [[ 0.02140458 -0.1958366 ]]. Action = [[-0.1856426   0.19443381  0.09386659  0.95951915]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 370. State = [[ 0.0076929  -0.17419006]]. Action = [[ 0.18724579  0.02702838 -0.02783442 -0.08876145]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 371. State = [[ 0.00660441 -0.1576206 ]]. Action = [[-0.18275078  0.2188214  -0.15803245  0.06173205]]. Reward = [0.]
Curr episode timestep = 102
Current timestep = 372. State = [[ 0.00189841 -0.12774499]]. Action = [[ 0.15230268  0.16364014  0.22645158 -0.5258892 ]]. Reward = [0.]
Curr episode timestep = 103
Current timestep = 373. State = [[ 0.0060372  -0.11636401]]. Action = [[ 0.1480639  -0.06281015 -0.16601035 -0.8208584 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 373 is [False, True, False, False, True, False]
State prediction error at timestep 373 is tensor(7.8570e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 373 of 1
Current timestep = 374. State = [[ 0.00679728 -0.11748343]]. Action = [[-0.18045881 -0.01532117  0.13377196 -0.50252426]]. Reward = [0.]
Curr episode timestep = 105
Current timestep = 375. State = [[-0.00063353 -0.12287884]]. Action = [[-0.19189698 -0.03448012 -0.18361181  0.9761505 ]]. Reward = [0.]
Curr episode timestep = 106
Current timestep = 376. State = [[-0.00792323 -0.13922131]]. Action = [[ 0.13048321 -0.23359975 -0.10922332  0.381042  ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 376 is [False, True, False, True, False, False]
State prediction error at timestep 376 is tensor(1.3195e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 376 of -1
Current timestep = 377. State = [[-0.00835876 -0.1548036 ]]. Action = [[-0.00103627  0.04563749 -0.24055438  0.5655334 ]]. Reward = [0.]
Curr episode timestep = 108
Current timestep = 378. State = [[-0.00791637 -0.15053418]]. Action = [[ 0.08460695  0.05763933  0.07934311 -0.37157762]]. Reward = [0.]
Curr episode timestep = 109
Current timestep = 379. State = [[ 0.00024373 -0.15355626]]. Action = [[ 0.20281538 -0.14125289  0.1584174   0.53526485]]. Reward = [0.]
Curr episode timestep = 110
Current timestep = 380. State = [[ 0.0149844  -0.15682337]]. Action = [[ 0.0677081   0.04299903  0.12082434 -0.3420202 ]]. Reward = [0.]
Curr episode timestep = 111
Current timestep = 381. State = [[ 0.0287866 -0.142604 ]]. Action = [[ 0.07484704  0.23763502 -0.079119    0.3694576 ]]. Reward = [0.]
Curr episode timestep = 112
Current timestep = 382. State = [[ 0.03281839 -0.11540676]]. Action = [[-0.15190578  0.19840628  0.20907411 -0.5312497 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 382 is [False, True, False, False, True, False]
State prediction error at timestep 382 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 382 of 1
Current timestep = 383. State = [[-0.15836461 -0.04188382]]. Action = [[-0.17230561  0.07560691  0.15635228  0.07480562]]. Reward = [100.]
Curr episode timestep = 114
Current timestep = 384. State = [[-0.14248721 -0.04744095]]. Action = [[ 0.02028468 -0.01555094  0.21897781 -0.651928  ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 385. State = [[-0.1309022  -0.05766992]]. Action = [[ 0.23721749 -0.1464637   0.00689882  0.80117273]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 386. State = [[-0.11416485 -0.05644099]]. Action = [[-0.0810079   0.22731042 -0.20318954  0.8056617 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 387. State = [[-0.1134134  -0.03628122]]. Action = [[ 0.09338641  0.17436516 -0.06253812 -0.56836265]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 388. State = [[-0.11065642 -0.02279024]]. Action = [[-0.16664611 -0.01171947  0.04546335  0.9779351 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 389. State = [[-0.11187214 -0.02166663]]. Action = [[ 0.03623715 -0.04488364  0.13560775 -0.44151175]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 390. State = [[-0.11898595 -0.029917  ]]. Action = [[-0.21915685 -0.10364991 -0.05432585  0.70214987]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 391. State = [[-0.13128601 -0.04568391]]. Action = [[-0.08537287 -0.11888492  0.0323706  -0.21769094]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 392. State = [[-0.13785708 -0.05372544]]. Action = [[-0.03488523  0.03971279 -0.19924016 -0.24489176]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 393. State = [[-0.1522075  -0.05997459]]. Action = [[-0.22371076 -0.11130038  0.10288405 -0.5024715 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 394. State = [[-0.1667596  -0.05700824]]. Action = [[ 0.21438289  0.17480668 -0.0337806  -0.7047957 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 395. State = [[-0.1551207  -0.03792814]]. Action = [[ 0.20511198  0.1566638  -0.10953099  0.46197093]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 396. State = [[-0.13883245 -0.03312269]]. Action = [[ 0.10698831 -0.13907517 -0.07736616  0.8185339 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 397. State = [[-0.12171759 -0.02814218]]. Action = [[ 0.16632006  0.16136447  0.14137536 -0.3146441 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 398. State = [[-0.103594   -0.02868756]]. Action = [[ 0.05062953 -0.1399385  -0.01004475  0.75251245]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 399. State = [[-0.09480318 -0.04692243]]. Action = [[ 0.09546396 -0.22413553 -0.10732779 -0.38589454]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 400. State = [[-0.08587517 -0.07608421]]. Action = [[-0.04541332 -0.20849487  0.22647423  0.7019    ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 401. State = [[-0.08308876 -0.08101879]]. Action = [[ 0.07001245  0.21957639 -0.1160402  -0.88749504]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 402. State = [[-0.07787001 -0.06631317]]. Action = [[ 0.07028195  0.09717363 -0.08431619  0.01948965]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 403. State = [[-0.06313226 -0.05019964]]. Action = [[0.23031217 0.13561153 0.05791262 0.12343621]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 404. State = [[-0.04136754 -0.05275781]]. Action = [[-0.04186182 -0.23060592  0.01841044  0.7400284 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 405. State = [[-0.03676724 -0.04946046]]. Action = [[ 0.12300244  0.22139665 -0.22839807  0.5139588 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 406. State = [[-0.24952239 -0.16937298]]. Action = [[-0.18524697  0.16612583 -0.21246713 -0.62382305]]. Reward = [100.]
Curr episode timestep = 22
Scene graph at timestep 406 is [True, False, False, True, False, False]
State prediction error at timestep 406 is tensor(0.0317, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 406 of 0
Current timestep = 407. State = [[-0.2472457  -0.18206802]]. Action = [[-0.0564408   0.16994351 -0.24815473  0.45382273]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 408. State = [[-0.24975017 -0.1754439 ]]. Action = [[-0.08054811  0.0065442   0.17921689  0.78338575]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 409. State = [[-0.24825686 -0.16590978]]. Action = [[ 0.15947065  0.10175824 -0.11440784  0.30730736]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 410. State = [[-0.24535918 -0.15826984]]. Action = [[0.00265372 0.00061998 0.18028402 0.3299923 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 411. State = [[-0.243328   -0.16720839]]. Action = [[ 0.01471731 -0.22741607 -0.01753867  0.52227354]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 412. State = [[-0.22890513 -0.18442543]]. Action = [[ 0.24562708 -0.09176543  0.22897339 -0.87204164]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 413. State = [[-0.21653712 -0.19068126]]. Action = [[-0.19689879  0.07261741  0.03329277  0.5431801 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 414. State = [[-0.22384314 -0.20315693]]. Action = [[-0.01596335 -0.23596124 -0.049685    0.23962903]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 415. State = [[-0.22750324 -0.21369804]]. Action = [[ 0.03440598  0.05536425  0.12530035 -0.490681  ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 416. State = [[-0.22041805 -0.2041611 ]]. Action = [[ 0.15781564  0.15946496 -0.14375679 -0.91020584]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 417. State = [[-0.20400721 -0.19636345]]. Action = [[ 0.15843731 -0.02158098 -0.02593264 -0.55015105]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 418. State = [[-0.19533147 -0.20335945]]. Action = [[-0.1253978  -0.12917447  0.09362495  0.5829985 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 419. State = [[-0.18764234 -0.2031175 ]]. Action = [[ 0.24009055  0.09512043 -0.09525892 -0.7775909 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 420. State = [[-0.16495946 -0.20257398]]. Action = [[ 0.21471405 -0.04110922 -0.16455594 -0.6215559 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 421. State = [[-0.14287026 -0.19586666]]. Action = [[ 0.02295685  0.15690333  0.06743422 -0.7488369 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 422. State = [[-0.14041808 -0.17936261]]. Action = [[-0.14068003  0.14575839 -0.14941125 -0.8516776 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 423. State = [[-0.14793755 -0.16141275]]. Action = [[-0.16621354  0.11846405  0.07922983 -0.93600965]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 424. State = [[-0.15362528 -0.14492866]]. Action = [[ 0.1511603   0.0945136   0.06775817 -0.15522057]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 425. State = [[-0.14230797 -0.12929198]]. Action = [[ 0.23894694  0.08964649 -0.16865513 -0.22038215]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 426. State = [[-0.11914787 -0.11630177]]. Action = [[0.17885607 0.08808219 0.10842177 0.8025837 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 427. State = [[-0.09119862 -0.11609583]]. Action = [[ 0.24485725 -0.13913645  0.20982593 -0.7253118 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 428. State = [[-0.06800056 -0.12069409]]. Action = [[-0.01381506  0.03105316 -0.23647472  0.80194664]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 429. State = [[-0.07135925 -0.13465004]]. Action = [[-0.2005219  -0.20616075 -0.19139954  0.9577484 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 430. State = [[-0.08091717 -0.1346434 ]]. Action = [[-0.1445144   0.22777325  0.20777684  0.74273205]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 431. State = [[-0.08166133 -0.11104991]]. Action = [[ 0.22470975  0.18348715 -0.21463789 -0.7524731 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 432. State = [[-0.0757253  -0.08631214]]. Action = [[0.10755339 0.14597714 0.22847593 0.3349967 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 433. State = [[-0.06957332 -0.08406213]]. Action = [[ 0.00880194 -0.16794871 -0.03176731  0.9208133 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 434. State = [[-0.06887707 -0.09573437]]. Action = [[-0.0863103  -0.08970752 -0.21357244 -0.22947222]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 435. State = [[-0.07182158 -0.10804033]]. Action = [[-0.09650657 -0.07447159  0.05395153  0.5441413 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 436. State = [[-0.08256038 -0.10988062]]. Action = [[-0.21721056  0.09647161 -0.0958913   0.01787281]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 437. State = [[-0.1026649  -0.11360385]]. Action = [[-0.21536224 -0.08120736  0.23391372  0.12546468]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 438. State = [[-0.11772841 -0.11270717]]. Action = [[ 0.12966418  0.08911672 -0.04550654  0.8668864 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 439. State = [[-0.1170059  -0.10223743]]. Action = [[ 0.04752654  0.07795629  0.19781953 -0.09990478]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 440. State = [[-0.11359718 -0.08459777]]. Action = [[ 0.08653155  0.18257713 -0.07652467 -0.52094877]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 441. State = [[-0.10481165 -0.07429076]]. Action = [[ 0.15307227 -0.08933096 -0.19481473 -0.00411159]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 442. State = [[-0.08853946 -0.08078651]]. Action = [[ 0.09185493 -0.10488471 -0.16145739 -0.6569624 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 443. State = [[-0.08514828 -0.08938437]]. Action = [[-0.1453543  -0.01451901 -0.17828628  0.2654034 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 444. State = [[-0.08751272 -0.08301224]]. Action = [[-0.03547254  0.17433542  0.21775258 -0.72189724]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 445. State = [[-0.09090293 -0.08618056]]. Action = [[-0.03153768 -0.22130778  0.12489146  0.90622854]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 446. State = [[-0.10110717 -0.10048945]]. Action = [[-0.2319686  -0.03500986  0.04377186  0.5696461 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 447. State = [[-0.11700342 -0.09477373]]. Action = [[-0.06699596  0.2174272  -0.15343614  0.5114417 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 448. State = [[-0.13121516 -0.08146548]]. Action = [[-0.15422913 -0.01859091  0.1567977  -0.60697615]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 449. State = [[-0.15321387 -0.08493367]]. Action = [[-0.16045208 -0.06727174  0.13034862  0.08941019]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 450. State = [[-0.17859857 -0.07538905]]. Action = [[-0.23326772  0.22890073  0.16658431  0.91673005]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 451. State = [[-0.19544777 -0.0449306 ]]. Action = [[0.17516682 0.22995341 0.1637156  0.5473106 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 452. State = [[-0.19713287 -0.03835006]]. Action = [[-0.11763404 -0.19602878  0.17176789 -0.5601409 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 453. State = [[-0.20552777 -0.03342462]]. Action = [[-0.13421324  0.19807118 -0.12965623 -0.11384851]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 454. State = [[-0.2072609  -0.03062634]]. Action = [[ 0.18919027 -0.136774   -0.1740115   0.03288829]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 455. State = [[-0.20522262 -0.0273056 ]]. Action = [[-0.07171607  0.13770181 -0.16470923 -0.935964  ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 456. State = [[-0.20089017 -0.03387368]]. Action = [[ 0.18128839 -0.22211152 -0.19094415 -0.66640985]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 457. State = [[-0.19603123 -0.04509756]]. Action = [[ 0.02159211  0.01712903 -0.1825494   0.4603964 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 458. State = [[-0.18677399 -0.04368222]]. Action = [[ 0.18589583  0.04848573 -0.18547294 -0.54924846]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 459. State = [[-0.17879616 -0.03501616]]. Action = [[-0.19367245  0.12086123  0.2426708  -0.94355536]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 460. State = [[-0.18538241 -0.02314236]]. Action = [[-0.08524622  0.06922027  0.12779388  0.37575328]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 461. State = [[-0.18382815 -0.00958954]]. Action = [[ 0.21897697  0.12496156 -0.24393387  0.8262017 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 462. State = [[-0.1798472   0.01335254]]. Action = [[-0.0539993   0.23743463  0.11803144  0.09755588]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 463. State = [[-0.18025106  0.02212057]]. Action = [[ 0.02952152 -0.17626567 -0.09256241  0.56905234]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 464. State = [[-0.18240291  0.01563368]]. Action = [[-0.17195264 -0.03423953  0.04634643 -0.868097  ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 465. State = [[-0.18036589 -0.00042036]]. Action = [[ 0.20044911 -0.18515831  0.13198763 -0.9212176 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 466. State = [[-0.16911125 -0.01868647]]. Action = [[ 0.15545684 -0.09001091 -0.20646636 -0.8681236 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 467. State = [[-0.15646298 -0.02379969]]. Action = [[ 0.06983477  0.06915411 -0.0201412   0.51808834]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 468. State = [[-0.143172   -0.02448523]]. Action = [[ 0.09858948 -0.05476561 -0.23752643  0.8453703 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 469. State = [[-0.1386575  -0.01954789]]. Action = [[-0.0123736   0.12907109 -0.24171923 -0.28124714]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 470. State = [[-0.14288965 -0.00509951]]. Action = [[-0.21993561  0.14661059  0.18278587 -0.48934776]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 471. State = [[-0.14475168  0.01737506]]. Action = [[ 0.20761985  0.17977452  0.12952852 -0.6312347 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 472. State = [[-0.13924763  0.02171514]]. Action = [[-0.07559997 -0.1764625   0.02041006 -0.5202728 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 473. State = [[-0.14031771  0.02100944]]. Action = [[-0.07480043  0.08560976  0.23759294 -0.5924062 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 474. State = [[-0.14702597  0.02310074]]. Action = [[-0.15421993 -0.01650167  0.20861384 -0.81542134]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 475. State = [[-0.1547707   0.03293915]]. Action = [[ 0.12215346  0.18501747  0.1668075  -0.1795299 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 476. State = [[-0.14783011  0.03242266]]. Action = [[ 0.22722137 -0.20718858  0.05042765  0.9777616 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 477. State = [[-0.12698132  0.01122285]]. Action = [[ 0.1757999  -0.20277217 -0.06487072 -0.0392769 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 478. State = [[-0.11726194  0.00283416]]. Action = [[-0.2366441   0.12220511 -0.00831193 -0.20228523]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 479. State = [[-0.11635387 -0.00703278]]. Action = [[ 0.17647457 -0.22959532  0.23515749  0.6495459 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 480. State = [[-0.10359441 -0.02828924]]. Action = [[ 0.20704982 -0.11091249  0.03996176  0.0005995 ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 481. State = [[-0.08427423 -0.02692671]]. Action = [[ 0.06660718  0.19582921 -0.14324775  0.8035898 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 482. State = [[-0.06939592 -0.00659307]]. Action = [[0.12626144 0.19781935 0.00082695 0.10893536]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 483. State = [[-0.06146321  0.00368837]]. Action = [[-0.16453366 -0.08364369  0.22861105 -0.6311754 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 484. State = [[-0.06379174  0.00792547]]. Action = [[0.01580262 0.08705637 0.19684368 0.18158841]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 485. State = [[-0.06818877  0.02414555]]. Action = [[-0.03974667  0.20942551  0.19683295 -0.27495444]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 486. State = [[-0.07485148  0.03011956]]. Action = [[-0.12166126 -0.17918736  0.18335894  0.703936  ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 487. State = [[-0.07659379  0.02751984]]. Action = [[0.11870715 0.0946188  0.09591201 0.32727122]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 488. State = [[-0.07168407  0.01706439]]. Action = [[ 0.15950477 -0.24396722 -0.12429535 -0.3664636 ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 489. State = [[-0.05871547  0.01336541]]. Action = [[ 0.13257685  0.19243231 -0.14081757  0.3395207 ]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 490. State = [[-0.21353179  0.14103083]]. Action = [[ 0.23239002  0.11442029 -0.15595844 -0.37986422]]. Reward = [100.]
Curr episode timestep = 83
Scene graph at timestep 490 is [True, False, False, False, False, True]
State prediction error at timestep 490 is tensor(0.0188, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 490 of 0
Current timestep = 491. State = [[-0.19382486  0.1639183 ]]. Action = [[0.23423302 0.11413717 0.200535   0.62431216]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 491 is [True, False, False, False, False, True]
State prediction error at timestep 491 is tensor(0.0006, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 491 of 0
Current timestep = 492. State = [[-0.1620774  0.1616084]]. Action = [[ 0.12200361 -0.23266286 -0.13021916 -0.5265059 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 493. State = [[-0.15061001  0.16069296]]. Action = [[ 0.16661012  0.24354327  0.04779285 -0.9537012 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 494. State = [[-0.1415753   0.18575707]]. Action = [[-0.20235178  0.1835328   0.2415097   0.2528249 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 495. State = [[-0.15550637  0.20887661]]. Action = [[-0.1268954   0.06573057  0.10285884  0.02351272]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 496. State = [[-0.16800337  0.22722326]]. Action = [[-0.05545241  0.16468829 -0.04626167 -0.89142627]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 497. State = [[-0.17412895  0.23254016]]. Action = [[-0.05604212 -0.13158783 -0.15372324 -0.13014978]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 498. State = [[-0.17499806  0.21598002]]. Action = [[-0.11604607 -0.2452455  -0.24839975  0.5287913 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 499. State = [[-0.18469782  0.18824276]]. Action = [[-0.10599945 -0.19604744  0.23721325  0.8661413 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 500. State = [[-0.19357643  0.17799246]]. Action = [[-0.00301881  0.0995582   0.17321557 -0.18162036]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 501. State = [[-0.20288596  0.17078675]]. Action = [[-0.15739185 -0.19096799 -0.09584233 -0.802882  ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 502. State = [[-0.21862154  0.1588623 ]]. Action = [[-0.03456165  0.02755275 -0.13483444  0.49346364]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 503. State = [[-0.216052    0.14953873]]. Action = [[ 0.1712805  -0.12856345 -0.04919037 -0.7997613 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 504. State = [[-0.20638749  0.12639546]]. Action = [[ 0.05965525 -0.22466134  0.13092494 -0.44644868]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 505. State = [[-0.19404633  0.09678972]]. Action = [[ 0.19697899 -0.20740351 -0.14346239  0.88579965]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 506. State = [[-0.18488239  0.07487319]]. Action = [[-0.13427714 -0.04942282  0.21503487 -0.53293765]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 507. State = [[-0.19247746  0.06836037]]. Action = [[-0.1350051   0.00224438  0.11571795  0.09423792]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 508. State = [[-0.19291507  0.07941082]]. Action = [[ 0.1933164   0.24532014 -0.19320132 -0.46501923]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 509. State = [[-0.18598689  0.09156672]]. Action = [[ 0.16001257  0.00407389 -0.0220232  -0.71363425]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 510. State = [[-0.17366229  0.08260091]]. Action = [[ 0.02496773 -0.22511572  0.04047611 -0.10763109]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 511. State = [[-0.16710317  0.08052554]]. Action = [[ 0.05649453  0.21019512  0.17710751 -0.9324382 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 512. State = [[-0.16381434  0.0783003 ]]. Action = [[-0.14212033 -0.2233856  -0.1214588  -0.32589918]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 513. State = [[-0.1683883   0.07904535]]. Action = [[-0.08651793  0.14941525  0.17161489 -0.00407684]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 514. State = [[-0.18117927  0.07212675]]. Action = [[-0.19364041 -0.23019834  0.18327606  0.771191  ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 515. State = [[-0.19151483  0.0644742 ]]. Action = [[ 0.16209239  0.12230939 -0.20754907 -0.17113537]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 516. State = [[-0.18550266  0.05716307]]. Action = [[ 0.10924593 -0.1756555   0.07211617  0.79512584]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 517. State = [[-0.17583534  0.03830991]]. Action = [[ 0.08368963 -0.13530362  0.20873314 -0.75339586]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 518. State = [[-0.16003364  0.03836003]]. Action = [[ 0.236539    0.21085763  0.2445842  -0.49042803]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 519. State = [[-0.13666058  0.06149154]]. Action = [[ 0.10964769  0.1957317   0.23499578 -0.86428696]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 520. State = [[-0.12426307  0.08209933]]. Action = [[ 0.04963091  0.11947474 -0.04909208  0.4056716 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 521. State = [[-0.10845916  0.08517781]]. Action = [[ 0.21612161 -0.11792371 -0.22284316 -0.57240534]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 522. State = [[-0.09080853  0.08562715]]. Action = [[0.00446773 0.04504749 0.1677103  0.01371312]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 523. State = [[-0.08806968  0.08117574]]. Action = [[-0.08844787 -0.11947611  0.12061727  0.05853403]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 524. State = [[-0.0831961   0.07972945]]. Action = [[ 0.20826632  0.09174544 -0.16977769  0.5652857 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 525. State = [[-0.06191744  0.07031707]]. Action = [[ 0.19944453 -0.23377347 -0.20495303  0.14484274]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 526. State = [[-0.04749428  0.06209044]]. Action = [[-0.08689234  0.12542874  0.2471388   0.11296809]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 527. State = [[-0.04242367  0.06749421]]. Action = [[ 0.15858653  0.04484016 -0.0040457   0.4544027 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 528. State = [[-0.17491831  0.17072426]]. Action = [[-0.13323162  0.14435947  0.09710029 -0.3542515 ]]. Reward = [100.]
Curr episode timestep = 37
Current timestep = 529. State = [[-0.15657552  0.18788868]]. Action = [[-0.03082989 -0.10421474 -0.23404172 -0.9613723 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 530. State = [[-0.1508725   0.16805562]]. Action = [[ 0.08959949 -0.22845641 -0.07639229 -0.5570293 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 531. State = [[-0.14999814  0.15618646]]. Action = [[-0.14577958  0.02866313 -0.05602171 -0.19547921]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 532. State = [[-0.1482861   0.14772731]]. Action = [[ 0.11349881 -0.11781299 -0.01623121  0.8242333 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 533. State = [[-0.14816618  0.14987777]]. Action = [[ 0.03640783  0.20241189  0.19971329 -0.9297089 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 534. State = [[-0.13906854  0.14618744]]. Action = [[ 0.20354778 -0.19568616  0.24056554  0.88852644]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 535. State = [[-0.12200577  0.12818378]]. Action = [[-0.08023471 -0.19285248  0.14921099 -0.61197567]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 536. State = [[-0.11552875  0.10430086]]. Action = [[ 0.1399343  -0.16433924  0.08483276 -0.01169026]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 537. State = [[-0.11409676  0.10351358]]. Action = [[-0.09804934  0.24810013  0.1682486  -0.2339803 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 538. State = [[-0.11548249  0.11585723]]. Action = [[ 0.10420966  0.04631099 -0.06879964  0.390939  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 539. State = [[-0.11156315  0.1119696 ]]. Action = [[-0.07409973 -0.17463034 -0.07699543  0.34760237]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 540. State = [[-0.11278202  0.11482368]]. Action = [[ 0.03385392  0.17076933 -0.22285956  0.3079455 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 541. State = [[-0.11643318  0.12016761]]. Action = [[-0.17908062 -0.05766009 -0.06406793  0.46471727]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 542. State = [[-0.12351323  0.11627784]]. Action = [[-0.1164529  -0.08330065  0.17140841 -0.49996352]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 543. State = [[-0.1245897   0.11889701]]. Action = [[ 0.21351457  0.14807564 -0.18831982 -0.26743913]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 544. State = [[-0.1212137   0.11115639]]. Action = [[-0.00366919 -0.22969298  0.07922953  0.00873375]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 545. State = [[-0.12141127  0.08886541]]. Action = [[-0.15445963 -0.20256689 -0.19466914 -0.7954364 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 546. State = [[-0.11975298  0.06952975]]. Action = [[ 0.14000219 -0.06578119 -0.11992599 -0.10875762]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 547. State = [[-0.11736823  0.05905504]]. Action = [[-0.07764849 -0.05282013  0.2388534  -0.51864505]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 548. State = [[-0.11993752  0.0574061 ]]. Action = [[-0.06382607  0.05403242 -0.16809514 -0.16493624]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 549. State = [[-0.12699588  0.05621298]]. Action = [[-0.08147755 -0.04834232 -0.2330422   0.9423187 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 550. State = [[-0.13317256  0.06628938]]. Action = [[ 0.07505289  0.22957462  0.15382296 -0.5925593 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 551. State = [[-0.13153611  0.07596603]]. Action = [[ 0.1467883  -0.04666537 -0.14442134  0.42658758]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 552. State = [[-0.12594058  0.06356721]]. Action = [[-0.07809004 -0.21861249  0.17251554  0.9229977 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 553. State = [[-0.13139986  0.05988371]]. Action = [[-0.17935804  0.1431213   0.19298786  0.6878216 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 554. State = [[-0.13897914  0.06842282]]. Action = [[0.04026619 0.06190813 0.20979863 0.20797682]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 555. State = [[-0.13407165  0.06165693]]. Action = [[ 0.20701903 -0.19781332 -0.1610133   0.48361015]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 556. State = [[-0.12555136  0.04703495]]. Action = [[ 0.05875957 -0.02651495  0.20675239 -0.71580625]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 557. State = [[-0.1175328   0.03386749]]. Action = [[ 0.0907068  -0.1527478  -0.20557918 -0.34192955]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 558. State = [[-0.11181191  0.01725497]]. Action = [[-0.19774808 -0.08560818  0.04179084  0.1878494 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 559. State = [[-0.11065313  0.00794319]]. Action = [[ 0.1750414  -0.02420738 -0.0184015  -0.21422714]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 560. State = [[-0.10660963 -0.00644026]]. Action = [[ 0.02167282 -0.17501293 -0.19177724  0.01425815]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 561. State = [[-0.10495432 -0.0163855 ]]. Action = [[-0.14988598  0.05558273  0.23576453 -0.3491484 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 562. State = [[-0.10532465 -0.01823617]]. Action = [[ 0.01815686 -0.05441739 -0.02982417 -0.7594509 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 563. State = [[-0.11211689 -0.00853054]]. Action = [[-0.1450325   0.20532301  0.05206007 -0.83086604]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 564. State = [[-0.11944956 -0.01123994]]. Action = [[ 0.03182316 -0.23796016 -0.2279435   0.0274539 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 565. State = [[-0.11960751 -0.02832426]]. Action = [[ 0.02897376 -0.07463026  0.21855164 -0.67242974]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 566. State = [[-0.11678282 -0.0428743 ]]. Action = [[ 0.08811444 -0.11948308  0.2264846  -0.8677373 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 567. State = [[-0.1179759  -0.04838259]]. Action = [[-0.16539839  0.09485185 -0.18116976 -0.36007875]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 568. State = [[-0.11850589 -0.05840101]]. Action = [[ 0.06152788 -0.21328685  0.11145627  0.01316237]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 569. State = [[-0.11729921 -0.0754151 ]]. Action = [[ 0.08064219 -0.08356458  0.22900662 -0.7205856 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 570. State = [[-0.11385313 -0.08912374]]. Action = [[ 0.05122808 -0.07352215  0.19697121  0.20922923]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 571. State = [[-0.10959547 -0.08645725]]. Action = [[ 0.07133055  0.17948774 -0.0125602   0.65062046]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 572. State = [[-0.10701392 -0.08863449]]. Action = [[-0.04247305 -0.17632675 -0.21637945  0.6556866 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 573. State = [[-0.10602973 -0.10526666]]. Action = [[ 0.04654765 -0.15585265  0.20453635  0.3224784 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 574. State = [[-0.10564449 -0.11002044]]. Action = [[-0.05544773  0.1555619  -0.24698018  0.71850896]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 575. State = [[-0.10454006 -0.10580219]]. Action = [[ 0.09921393 -0.02670752  0.19015545  0.43307674]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 576. State = [[-0.1003757  -0.10882798]]. Action = [[ 0.08175743 -0.06930959  0.19562906  0.46382153]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 577. State = [[-0.08616279 -0.12375856]]. Action = [[ 0.16063893 -0.22608525  0.22233427 -0.84726167]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 578. State = [[-0.07162255 -0.14702958]]. Action = [[ 0.01112604 -0.08578038 -0.24198002  0.01934934]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 579. State = [[-0.06850195 -0.14391638]]. Action = [[-0.01277997  0.21024388 -0.11299288  0.10076284]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 580. State = [[-0.06439468 -0.12129857]]. Action = [[ 0.06066188  0.20711243 -0.2306198   0.6159563 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 581. State = [[-0.05569874 -0.11274074]]. Action = [[ 0.1322124  -0.1350029  -0.24492292 -0.16137344]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 582. State = [[-0.04583159 -0.12964113]]. Action = [[ 0.02934033 -0.23824196  0.20287848  0.6699197 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 582 is [False, True, False, True, False, False]
State prediction error at timestep 582 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 582 of 1
Current timestep = 583. State = [[-0.02953661 -0.14792469]]. Action = [[ 0.19106287  0.04272419 -0.00779055  0.43387628]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 584. State = [[-0.01933307 -0.14331084]]. Action = [[-0.19104639  0.0743933   0.22874898  0.22362483]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 585. State = [[-0.02002445 -0.13007852]]. Action = [[ 0.06589338  0.17658663  0.23536915 -0.07494867]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 586. State = [[-0.01651009 -0.1093745 ]]. Action = [[0.1394636  0.11149031 0.06949222 0.5507753 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 586 is [False, True, False, False, True, False]
State prediction error at timestep 586 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 586 of 1
Current timestep = 587. State = [[-0.00467172 -0.1077911 ]]. Action = [[ 0.06314912 -0.18692298 -0.11085407 -0.26425147]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 588. State = [[ 0.00328903 -0.10616768]]. Action = [[ 0.14852107  0.18405145 -0.05303289  0.7672932 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 589. State = [[-0.15210825 -0.07974521]]. Action = [[-0.1812894   0.18364584  0.24843633  0.76581454]]. Reward = [100.]
Curr episode timestep = 60
Current timestep = 590. State = [[-0.12789068 -0.08349659]]. Action = [[ 0.21899855  0.10977834 -0.14137502 -0.7900421 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 591. State = [[-0.09900005 -0.08102988]]. Action = [[ 0.22763139 -0.02504219 -0.09185155 -0.12959081]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 592. State = [[-0.0827999  -0.06939586]]. Action = [[-0.16050075  0.23031253 -0.08521843 -0.78803176]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 593. State = [[-0.08742639 -0.03877773]]. Action = [[-0.06953958  0.2203385  -0.23439746  0.8586507 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 594. State = [[-0.09119106 -0.02699161]]. Action = [[-0.07189742 -0.10893993  0.19498146 -0.4230867 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 595. State = [[-0.10217498 -0.04178919]]. Action = [[-0.20338139 -0.16589856 -0.24370591 -0.813994  ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 596. State = [[-0.11337756 -0.05350735]]. Action = [[ 0.05201265 -0.0033897   0.23503047 -0.73029083]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 597. State = [[-0.11155634 -0.0614518 ]]. Action = [[ 0.12620553 -0.10550436  0.14807898  0.00262213]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 598. State = [[-0.11453948 -0.06563662]]. Action = [[-0.2150861   0.03332236  0.03432649 -0.4436379 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 599. State = [[-0.12586634 -0.05850021]]. Action = [[-0.11683777  0.13266271 -0.19598934  0.40915823]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 600. State = [[-0.13360228 -0.05805784]]. Action = [[ 0.17316589 -0.1409483  -0.01067229  0.47492516]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 601. State = [[-0.12814218 -0.0562217 ]]. Action = [[0.12910774 0.13594446 0.12786162 0.25670862]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 602. State = [[-0.12377045 -0.04641178]]. Action = [[-0.05160859  0.08826178  0.1785236  -0.91932136]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 603. State = [[-0.12208106 -0.02757167]]. Action = [[ 0.07658917  0.17900467 -0.00991809 -0.54761815]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 604. State = [[-0.12005224 -0.00596723]]. Action = [[-0.15174735  0.12894791  0.18569946 -0.36237139]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 605. State = [[-0.11863169  0.01952534]]. Action = [[ 0.19740671  0.20705152  0.15740797 -0.2834761 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 606. State = [[-0.10926685  0.04563816]]. Action = [[0.10476491 0.19971108 0.14579928 0.9167032 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 607. State = [[-0.08957391  0.0722058 ]]. Action = [[ 0.23806864  0.15540391  0.04183546 -0.23883855]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 608. State = [[-0.07332602  0.07346593]]. Action = [[-0.193942   -0.22702992 -0.08916664 -0.16791785]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 609. State = [[-0.07497772  0.05036361]]. Action = [[-0.08564335 -0.2070558  -0.1714715   0.8883569 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 610. State = [[-0.07640752  0.03772416]]. Action = [[-0.00907242  0.0400815   0.00445735 -0.10982567]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 611. State = [[-0.07765124  0.03618005]]. Action = [[-0.0368831  -0.01558867  0.00793353  0.91946244]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 612. State = [[-0.07970137  0.02816374]]. Action = [[ 0.00165933 -0.12431858 -0.10154599  0.20472872]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 613. State = [[-0.08789504  0.02371342]]. Action = [[-0.09075025  0.06765324 -0.08342558 -0.9131201 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 614. State = [[-0.09102696  0.02905823]]. Action = [[ 0.16799882  0.07406455 -0.15273955 -0.21200198]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 615. State = [[-0.08523148  0.01941363]]. Action = [[ 0.1131413  -0.23130299 -0.11903563  0.01980186]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 616. State = [[-0.07987294  0.01763112]]. Action = [[ 0.01726884  0.17967686 -0.1832928   0.548918  ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 617. State = [[-0.0714716   0.03845472]]. Action = [[0.15285903 0.24172089 0.1009872  0.01425564]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 618. State = [[-0.05899621  0.0439082 ]]. Action = [[-0.01305334 -0.20938748 -0.17094167 -0.33678186]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 619. State = [[-0.05975688  0.04771892]]. Action = [[-0.03759454  0.19312686 -0.23832737 -0.07564646]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 620. State = [[-0.06289517  0.05652602]]. Action = [[-0.14896482 -0.02039832 -0.10610004 -0.866511  ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 621. State = [[-0.06662808  0.06936197]]. Action = [[ 0.08708227  0.20850092  0.21240923 -0.43110824]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 622. State = [[-0.0680057   0.07326309]]. Action = [[ 0.04980245 -0.16314681  0.00339991 -0.9347483 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 623. State = [[-0.06714032  0.07010868]]. Action = [[-0.09851918  0.0184159   0.21992192  0.48897016]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 624. State = [[-0.06134812  0.06204749]]. Action = [[ 0.22002381 -0.11097842  0.04544765 -0.43946362]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 625. State = [[-0.04677749  0.0621851 ]]. Action = [[ 0.13013613  0.14310703  0.06334016 -0.01201671]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 626. State = [[-0.03950996  0.07371365]]. Action = [[-0.19437142  0.0659537   0.23674172  0.66978014]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 627. State = [[-0.04028923  0.07365232]]. Action = [[ 0.11458725 -0.11033289  0.07751617 -0.44264674]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 628. State = [[-0.03933446  0.0702882 ]]. Action = [[ 0.04477429  0.02288234 -0.03563714 -0.17186898]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 629. State = [[-0.24606118  0.10809644]]. Action = [[ 0.18962678 -0.04060905  0.10686579 -0.87439346]]. Reward = [100.]
Curr episode timestep = 39
Current timestep = 630. State = [[-0.23224732  0.11411687]]. Action = [[ 0.16260272 -0.12827297  0.01976833 -0.6494954 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 631. State = [[-0.22608638  0.10668861]]. Action = [[-0.1974945  -0.05873179  0.24664187 -0.61677194]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 632. State = [[-0.22218677  0.08803497]]. Action = [[ 0.23472479 -0.20323385  0.21797442  0.3208437 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 633. State = [[-0.20813027  0.06952813]]. Action = [[ 0.1564621  -0.06801584  0.14737913 -0.89827275]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 634. State = [[-0.18576145  0.0519753 ]]. Action = [[ 0.13145691 -0.16214977 -0.18368869 -0.06035745]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 635. State = [[-0.1799113   0.02844411]]. Action = [[-0.21058373 -0.2007006  -0.06949781 -0.352499  ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 636. State = [[-0.17764276  0.01966801]]. Action = [[0.22948664 0.12390631 0.09943688 0.80176246]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 637. State = [[-0.17685148  0.03651768]]. Action = [[-0.19704296  0.23849595 -0.20936406 -0.83141476]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 638. State = [[-0.17419429  0.0441014 ]]. Action = [[ 0.237943   -0.16580743 -0.21580431  0.37590194]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 639. State = [[-0.15846762  0.02423513]]. Action = [[ 0.12261742 -0.22336423  0.2075628   0.56809556]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 640. State = [[-0.14046173  0.00738783]]. Action = [[ 0.13319376  0.00121313 -0.19898532  0.9512178 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 641. State = [[-0.12286783  0.00998566]]. Action = [[ 0.09632093  0.10373327 -0.20628189  0.21999645]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 642. State = [[-0.10476843  0.00309613]]. Action = [[ 0.14324605 -0.1916799   0.21372873 -0.26465917]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 643. State = [[-0.09224523  0.00577514]]. Action = [[ 0.01803115  0.21733725 -0.22119795 -0.4285313 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 644. State = [[-0.08893362  0.00885243]]. Action = [[-0.06466942 -0.14146627  0.10702109 -0.8915257 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 645. State = [[-0.08978925  0.00079899]]. Action = [[-0.10980463 -0.05771811 -0.17106746 -0.880941  ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 646. State = [[-0.09040811 -0.01419257]]. Action = [[ 0.02441484 -0.15284319  0.06881329 -0.3351966 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 647. State = [[-0.09187362 -0.03841969]]. Action = [[-0.01607178 -0.2232715   0.10083583  0.23285866]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 648. State = [[-0.09208579 -0.05506434]]. Action = [[ 0.05253658  0.01335901 -0.2397677   0.04890919]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 649. State = [[-0.09390485 -0.06369966]]. Action = [[-0.11853796 -0.09446019  0.06024954  0.86739135]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 650. State = [[-0.10051195 -0.07781918]]. Action = [[-0.03089947 -0.10986617  0.05831587  0.5198388 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 651. State = [[-0.10388128 -0.07870296]]. Action = [[-0.03614229  0.15025902 -0.04841778 -0.46633613]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 652. State = [[-0.10506307 -0.07574204]]. Action = [[-0.01471148 -0.04933211 -0.22010092  0.3085034 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 653. State = [[-0.10446009 -0.08702654]]. Action = [[ 0.08698335 -0.1717909   0.05366737  0.30397248]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 654. State = [[-0.10123457 -0.10053699]]. Action = [[ 0.11932984 -0.04658599  0.01603693 -0.56802136]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 655. State = [[-0.09651733 -0.09779911]]. Action = [[0.05635595 0.13728651 0.15981486 0.63633156]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 656. State = [[-0.09607565 -0.0825672 ]]. Action = [[-0.16608529  0.1708414  -0.19138387 -0.6461683 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 657. State = [[-0.09289166 -0.05922789]]. Action = [[0.2203579  0.15700042 0.24632314 0.0916357 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 658. State = [[-0.0924273  -0.03763556]]. Action = [[-0.21010143  0.16236514  0.1697349   0.86536074]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 659. State = [[-0.10244302 -0.02656216]]. Action = [[-0.15746643 -0.06324959 -0.22151873  0.79248667]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 660. State = [[-0.10339539 -0.02708912]]. Action = [[ 0.21026215 -0.0055467  -0.04005088 -0.4330157 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 661. State = [[-0.09381842 -0.03418484]]. Action = [[ 0.20490855 -0.1142101   0.09904408  0.28498363]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 662. State = [[-0.0868427  -0.05205498]]. Action = [[-0.23179394 -0.1683527  -0.10474342 -0.6743373 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 663. State = [[-0.0902625  -0.05502408]]. Action = [[ 0.01488844  0.16462919  0.03859007 -0.76487416]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 664. State = [[-0.08917809 -0.03777001]]. Action = [[ 0.12219653  0.16454524  0.14038187 -0.4693122 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 665. State = [[-0.08086503 -0.0178489 ]]. Action = [[ 0.1922434   0.13998482 -0.10672422 -0.39355934]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 666. State = [[-0.07097044 -0.00751912]]. Action = [[-0.14090669 -0.01728846 -0.0532573  -0.4245273 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 667. State = [[-0.07398523  0.00114501]]. Action = [[-0.03789404  0.10724196  0.11437678  0.3352641 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 668. State = [[-0.08125917  0.01188308]]. Action = [[-0.1804706   0.03019086 -0.14112677 -0.5743961 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 669. State = [[-0.08645849  0.00365053]]. Action = [[ 0.14915413 -0.21427257 -0.19292448 -0.33743554]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 670. State = [[-0.09005739 -0.01336532]]. Action = [[-0.19337505 -0.08849671  0.04602823 -0.4772529 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 671. State = [[-0.09469798 -0.01631689]]. Action = [[ 0.00924864  0.11193845  0.08216274 -0.32435775]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 672. State = [[-0.09340009 -0.01265843]]. Action = [[ 0.16796282 -0.0138883   0.23776335 -0.23167539]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 673. State = [[-0.08387791 -0.01184713]]. Action = [[ 0.19379342  0.00318646 -0.17844434 -0.5408991 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 674. State = [[-0.067875   -0.01886833]]. Action = [[ 0.09686628 -0.13031127  0.24216372 -0.8587997 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 675. State = [[-0.05869888 -0.03205833]]. Action = [[-0.09699693 -0.08089185  0.09920409 -0.49372125]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 676. State = [[-0.05460902 -0.0303723 ]]. Action = [[ 0.1903466   0.15204608 -0.00459099 -0.7013414 ]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 677. State = [[-0.04891744 -0.0156914 ]]. Action = [[-0.0967761   0.13379532 -0.09381337 -0.1031853 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 678. State = [[-0.05324589  0.00288712]]. Action = [[-0.07977721  0.13830405  0.12233281 -0.89328504]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 679. State = [[-0.05022949  0.0045312 ]]. Action = [[ 0.19634324 -0.17149182 -0.09594545  0.86657155]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 680. State = [[-0.15292244  0.17522226]]. Action = [[ 0.17210698  0.15427685  0.18189442 -0.2510991 ]]. Reward = [100.]
Curr episode timestep = 50
Current timestep = 681. State = [[-0.12291311  0.20636106]]. Action = [[ 0.18547651  0.15736216 -0.13442059  0.88806915]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 682. State = [[-0.09851881  0.21489337]]. Action = [[ 0.20716482 -0.04080181  0.19011927  0.12213433]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 683. State = [[-0.06759848  0.21250963]]. Action = [[ 0.23422688 -0.04872802 -0.0438745  -0.2500199 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 684. State = [[-0.04865297  0.22103183]]. Action = [[-0.0526579   0.16978323  0.18966961 -0.03609496]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 684 is [False, True, False, False, False, True]
State prediction error at timestep 684 is tensor(0.0011, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 684 of -1
Current timestep = 685. State = [[-0.04799252  0.23749788]]. Action = [[-0.1762004   0.0003545  -0.12960224  0.2552935 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 685 is [False, True, False, False, False, True]
State prediction error at timestep 685 is tensor(0.0016, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 685 of 0
Current timestep = 686. State = [[-0.05235934  0.24284726]]. Action = [[ 0.18920359  0.09474465 -0.20222872 -0.16397542]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 687. State = [[-0.0336169   0.23412625]]. Action = [[ 0.18406367 -0.20534307  0.13465402  0.24077034]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 687 is [False, True, False, False, False, True]
State prediction error at timestep 687 is tensor(0.0010, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 687 of -1
Current timestep = 688. State = [[-0.00507898  0.21529156]]. Action = [[ 0.22360072 -0.1105984  -0.16940321 -0.2650401 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 688 is [False, True, False, False, False, True]
State prediction error at timestep 688 is tensor(0.0021, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 688 of -1
Current timestep = 689. State = [[0.01544328 0.22034541]]. Action = [[-0.05737157  0.2076317   0.1087485  -0.5546662 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 689 is [False, True, False, False, False, True]
State prediction error at timestep 689 is tensor(0.0035, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 689 of -1
Current timestep = 690. State = [[0.01430555 0.2454957 ]]. Action = [[ 0.0981968   0.23570731  0.01736128 -0.23482823]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 690 is [False, True, False, False, False, True]
State prediction error at timestep 690 is tensor(0.0039, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 690 of -1
Current timestep = 691. State = [[0.03429164 0.26022008]]. Action = [[-0.00314274 -0.19254029  0.12918139  0.7025733 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 692. State = [[0.03199381 0.26199785]]. Action = [[-0.00143206  0.20089439 -0.21179618  0.74754167]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 693. State = [[0.02251738 0.2801152 ]]. Action = [[-0.12887669  0.18150532  0.0492987  -0.7763406 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 694. State = [[0.01475365 0.29193586]]. Action = [[-0.07744929 -0.11020869  0.24913532 -0.42947495]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 695. State = [[0.01495493 0.29099926]]. Action = [[ 0.062644    0.24037766  0.09496188 -0.20853794]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 696. State = [[0.01335198 0.2931689 ]]. Action = [[-0.02386966  0.03641522  0.00871545 -0.8466857 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 697. State = [[0.01156295 0.28785446]]. Action = [[-0.17636944 -0.19163463  0.06999204  0.7846124 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 698. State = [[0.00998037 0.27083755]]. Action = [[ 0.01415047 -0.18355954  0.18970102 -0.7224275 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 699. State = [[0.01014316 0.24597754]]. Action = [[-0.07440931 -0.21441099  0.06486148  0.73661506]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 700. State = [[0.00026831 0.22425164]]. Action = [[-0.06378785 -0.04252709  0.11498046 -0.21455777]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 701. State = [[-0.00820485  0.22518685]]. Action = [[ 0.00497669  0.13758045  0.22750542 -0.39623404]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 702. State = [[-0.00935901  0.21712822]]. Action = [[ 0.008764   -0.24866094 -0.14313549 -0.58922124]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 703. State = [[-0.00088043  0.19217223]]. Action = [[ 0.21747282 -0.14657196 -0.11692044  0.29290462]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 704. State = [[0.00376592 0.18445387]]. Action = [[ 0.04964057  0.16630375 -0.20685673 -0.55019236]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 705. State = [[-0.00062368  0.19211672]]. Action = [[-2.4608935e-01  5.7011843e-04  2.1832144e-01 -7.1588022e-01]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 706. State = [[-0.00806734  0.19010088]]. Action = [[-0.0442383  -0.11222497 -0.06203046  0.51363516]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 707. State = [[-0.01024887  0.1830876 ]]. Action = [[-0.05598474 -0.02154677 -0.09884186 -0.19139206]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 708. State = [[-0.02051628  0.1868439 ]]. Action = [[-0.14466842  0.07764098  0.17226672 -0.65531147]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 709. State = [[-0.03383321  0.19994   ]]. Action = [[0.24527657 0.2224071  0.10624427 0.83946383]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 710. State = [[-0.03916536  0.21765906]]. Action = [[-0.16440564  0.14574528  0.2102812   0.05508506]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 711. State = [[-0.04207887  0.223185  ]]. Action = [[ 0.10031343 -0.18384217 -0.00840661 -0.15630537]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 712. State = [[-0.04505609  0.22338831]]. Action = [[-0.21818049  0.08848682 -0.0564892  -0.4835428 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 713. State = [[-0.05306806  0.2236016 ]]. Action = [[-0.06069116 -0.09025611  0.09790474  0.4875617 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 714. State = [[-0.0599246  0.2264249]]. Action = [[-0.01776247  0.12051862 -0.22944023  0.23104024]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 715. State = [[-0.06408722  0.23968539]]. Action = [[ 0.15623292  0.17803508  0.02759278 -0.6959556 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 716. State = [[-0.06929572  0.25751248]]. Action = [[-0.04388498  0.19843876  0.14162737 -0.51767254]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 717. State = [[-0.06860973  0.26565123]]. Action = [[ 0.18802088 -0.09979351  0.19824833  0.18675637]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 718. State = [[-0.05782935  0.27086365]]. Action = [[0.07399639 0.12963897 0.16308913 0.57354295]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 719. State = [[-0.04723817  0.28215733]]. Action = [[ 0.05038893  0.0275301  -0.00134805 -0.11755109]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 720. State = [[-0.03905654  0.29139245]]. Action = [[ 0.11911377  0.11177409 -0.16081652  0.2795986 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 721. State = [[-0.02025378  0.29173887]]. Action = [[ 0.19151843 -0.11915757 -0.16499811 -0.61266   ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 722. State = [[0.00628225 0.27596182]]. Action = [[ 0.2160657  -0.14818461  0.17451578 -0.32908738]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 723. State = [[0.03838512 0.25224516]]. Action = [[ 0.2209521  -0.17893618  0.22426242 -0.8853257 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 724. State = [[0.06584986 0.23716667]]. Action = [[ 0.09674972 -0.01061977  0.11940083  0.4368044 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 724 is [False, False, True, False, False, True]
State prediction error at timestep 724 is tensor(0.0021, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 724 of -1
Current timestep = 725. State = [[0.07792533 0.23008002]]. Action = [[ 0.00353226 -0.22832921 -0.23582806 -0.47143775]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 725 is [False, False, True, False, False, True]
State prediction error at timestep 725 is tensor(0.0024, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 725 of -1
Current timestep = 726. State = [[0.07792533 0.23008002]]. Action = [[ 0.08547527 -0.14015779  0.24708179  0.41331708]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 726 is [False, False, True, False, False, True]
State prediction error at timestep 726 is tensor(0.0016, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 726 of -1
Current timestep = 727. State = [[0.07792533 0.23008002]]. Action = [[ 0.19987425 -0.21297784 -0.07619551  0.10486734]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 727 is [False, False, True, False, False, True]
State prediction error at timestep 727 is tensor(0.0019, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 727 of -1
Current timestep = 728. State = [[0.07677136 0.22905667]]. Action = [[-0.15814792 -0.10342126 -0.11281312  0.3173493 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 728 is [False, False, True, False, False, True]
State prediction error at timestep 728 is tensor(0.0023, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 728 of -1
Current timestep = 729. State = [[0.07624503 0.22333804]]. Action = [[-0.1536615  -0.14398424 -0.10865778  0.65744066]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 729 is [False, False, True, False, False, True]
State prediction error at timestep 729 is tensor(0.0017, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 729 of 0
Current timestep = 730. State = [[0.07489918 0.21946594]]. Action = [[ 0.09647393 -0.18892902  0.01376066  0.89865184]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 731. State = [[0.07004527 0.22827238]]. Action = [[-0.13698336  0.15408242  0.02170813  0.4718747 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 732. State = [[0.06545852 0.23421665]]. Action = [[-0.0905748  -0.11251441 -0.1838773   0.32302272]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 733. State = [[0.06500425 0.23376581]]. Action = [[ 0.13411337  0.06687152  0.04084104 -0.11581743]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 734. State = [[0.06367872 0.23318572]]. Action = [[-0.10541537 -0.04935169  0.05382925  0.8011837 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 735. State = [[0.06086376 0.23036778]]. Action = [[-0.18490797 -0.13765837  0.10395199 -0.8394173 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 736. State = [[0.06080772 0.2256609 ]]. Action = [[ 0.01044676 -0.04387993 -0.19906934 -0.07528198]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 737. State = [[0.06166624 0.22315599]]. Action = [[ 0.12101987  0.18401399  0.06483841 -0.48956966]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 738. State = [[0.06173571 0.22284548]]. Action = [[ 0.2059494  -0.20977859  0.1184155  -0.71922946]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 739. State = [[0.0617147  0.22278242]]. Action = [[ 0.225245    0.05039826 -0.2036704   0.48026   ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 740. State = [[0.0617147  0.22278242]]. Action = [[ 0.0785245  -0.2179166   0.08350095  0.7526734 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 741. State = [[0.0617147  0.22278242]]. Action = [[ 0.23732743 -0.07780915  0.11793423  0.5875416 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 742. State = [[0.05752776 0.23251407]]. Action = [[-0.01934475  0.21955955  0.12028167  0.03754973]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 743. State = [[0.05193835 0.24342695]]. Action = [[ 0.24176127 -0.2227307  -0.17746262 -0.73076886]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 744. State = [[0.04680358 0.2572932 ]]. Action = [[-0.04037634  0.19808918 -0.11230153 -0.8935362 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 745. State = [[0.04429745 0.26147044]]. Action = [[ 0.08153385 -0.18356901 -0.07496822  0.48467803]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 746. State = [[0.04834206 0.25409374]]. Action = [[ 0.14940691 -0.06145617 -0.17361513 -0.73619395]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 747. State = [[0.04908899 0.2526926 ]]. Action = [[ 0.19522244 -0.10647468  0.07457304 -0.94036233]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 748. State = [[0.04921316 0.25245908]]. Action = [[ 0.17497152 -0.09287532  0.23394191  0.8845203 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 749. State = [[0.05304468 0.24445774]]. Action = [[-0.00529137 -0.18047088 -0.24617548  0.3955183 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 750. State = [[0.05589328 0.23546089]]. Action = [[-0.18000534  0.00904554 -0.23186223 -0.787334  ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 751. State = [[0.04669308 0.24710873]]. Action = [[-0.21351214  0.13661098  0.18201649 -0.9428487 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 752. State = [[0.03692525 0.25810745]]. Action = [[-0.16188428 -0.17577918 -0.13662502  0.92839766]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 753. State = [[0.03292525 0.2568257 ]]. Action = [[-0.16588947 -0.0836294   0.23058045 -0.01291478]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 754. State = [[0.02495369 0.26937056]]. Action = [[-0.15511218  0.2221669   0.23057264 -0.12332046]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 755. State = [[0.00860461 0.29531768]]. Action = [[ 0.10147968  0.14436144 -0.19376165 -0.7367135 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 756. State = [[0.00272586 0.30489212]]. Action = [[ 0.23521778  0.21803588  0.08733833 -0.62145853]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 757. State = [[0.00155865 0.30378404]]. Action = [[-0.214051   -0.21877396 -0.13979807  0.35356426]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 758. State = [[0.00125601 0.30074343]]. Action = [[-0.05767936  0.1434378  -0.10145769  0.5902786 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 759. State = [[0.00110046 0.3002265 ]]. Action = [[0.15714914 0.054883   0.19499809 0.13371813]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 760. State = [[0.00649637 0.29028165]]. Action = [[ 0.18090099 -0.0886887   0.1719409  -0.7121081 ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 761. State = [[0.01419551 0.2775186 ]]. Action = [[ 0.03952739  0.12479714 -0.18144916 -0.70905775]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 762. State = [[0.01981731 0.26745453]]. Action = [[ 0.10774964 -0.07691924  0.20491484 -0.28794783]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 763. State = [[0.03070597 0.2483398 ]]. Action = [[ 0.13883114 -0.07620448 -0.01511678  0.82280135]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 764. State = [[0.03814506 0.23488459]]. Action = [[ 0.2450419  -0.24183473 -0.01672687  0.19288969]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 765. State = [[0.04035751 0.23342809]]. Action = [[ 0.1397978   0.08329707 -0.01046279 -0.3863997 ]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 766. State = [[0.03853199 0.24408086]]. Action = [[-0.05664247  0.2090551   0.20859635  0.5859175 ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 767. State = [[0.03018805 0.2732066 ]]. Action = [[-0.22210899  0.22576141  0.00623631  0.50178266]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 768. State = [[0.01332369 0.3024901 ]]. Action = [[ 0.2391972  -0.16972667  0.17747948 -0.82038563]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 769. State = [[0.00574042 0.3129642 ]]. Action = [[-0.17292328 -0.01454066 -0.1508232  -0.6047246 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 770. State = [[0.00060563 0.32016957]]. Action = [[ 0.20702109  0.17694879  0.06957826 -0.5802637 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 771. State = [[-0.00068877  0.32133824]]. Action = [[ 0.21987039  0.10302365  0.0363673  -0.21604514]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 772. State = [[0.00511439 0.3121415 ]]. Action = [[ 0.20141709 -0.11476035  0.19723701  0.5191722 ]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 773. State = [[0.0137156 0.2984403]]. Action = [[-0.03325129 -0.06861234 -0.14401732 -0.7273849 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 774. State = [[0.01670925 0.29357845]]. Action = [[-0.19168378  0.10751751 -0.13982713 -0.75273484]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 775. State = [[0.01731305 0.29258248]]. Action = [[-0.09346154  0.20290273  0.120345   -0.6378281 ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 776. State = [[0.02199299 0.27854198]]. Action = [[ 0.23325956 -0.21422474  0.23356605 -0.8893613 ]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 777. State = [[0.0440456  0.23743777]]. Action = [[ 0.09549135 -0.20086578  0.17397124  0.71622086]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 778. State = [[0.0535947  0.22415788]]. Action = [[-0.08049572  0.19725356  0.12371373  0.7461698 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 779. State = [[0.05290487 0.22903398]]. Action = [[ 0.05119765 -0.027676   -0.07248066  0.18342197]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 780. State = [[0.05305779 0.22868711]]. Action = [[ 0.24795961  0.08556804  0.02857047 -0.83018863]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 781. State = [[0.05306654 0.22866045]]. Action = [[ 0.14089334 -0.17454743  0.19067785 -0.7056316 ]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 782. State = [[0.04995073 0.23508331]]. Action = [[-0.1741184   0.05040324  0.06005523  0.6647872 ]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 783. State = [[0.04652125 0.2386845 ]]. Action = [[-0.17291135 -0.18089585  0.23931122 -0.09047866]]. Reward = [0.]
Curr episode timestep = 102
Current timestep = 784. State = [[0.0462395  0.23770815]]. Action = [[ 0.16441983  0.19820616 -0.0146161   0.681319  ]]. Reward = [0.]
Curr episode timestep = 103
Current timestep = 785. State = [[0.04613116 0.23766406]]. Action = [[ 0.15955427  0.00484064  0.10655099 -0.11509597]]. Reward = [0.]
Curr episode timestep = 104
Current timestep = 786. State = [[0.04352787 0.23731396]]. Action = [[-0.23517823 -0.08219779 -0.19298552  0.44999015]]. Reward = [0.]
Curr episode timestep = 105
Current timestep = 787. State = [[0.04026157 0.2367842 ]]. Action = [[0.24182242 0.04462799 0.23034728 0.13702369]]. Reward = [0.]
Curr episode timestep = 106
Current timestep = 788. State = [[0.03702764 0.24540488]]. Action = [[0.05896983 0.19146803 0.212417   0.08137333]]. Reward = [0.]
Curr episode timestep = 107
Current timestep = 789. State = [[0.02653707 0.2677279 ]]. Action = [[-0.15094788  0.1602099  -0.15736665  0.24494159]]. Reward = [0.]
Curr episode timestep = 108
Current timestep = 790. State = [[0.01696178 0.28303304]]. Action = [[-0.02878913 -0.14507174 -0.22562933 -0.949712  ]]. Reward = [0.]
Curr episode timestep = 109
Current timestep = 791. State = [[0.02008809 0.27225748]]. Action = [[-0.07372648 -0.23696353 -0.02227807  0.934181  ]]. Reward = [0.]
Curr episode timestep = 110
Current timestep = 792. State = [[0.02040188 0.26841667]]. Action = [[-0.13954264  0.14942944  0.01705098 -0.45870513]]. Reward = [0.]
Curr episode timestep = 111
Current timestep = 793. State = [[0.01280018 0.27983347]]. Action = [[ 0.01595929  0.06158057  0.00864726 -0.5963663 ]]. Reward = [0.]
Curr episode timestep = 112
Current timestep = 794. State = [[0.0147625 0.2754986]]. Action = [[ 0.22293153 -0.13594322 -0.24587849  0.78041387]]. Reward = [0.]
Curr episode timestep = 113
Current timestep = 795. State = [[0.02508931 0.25752038]]. Action = [[-0.04572128 -0.0876722   0.15546802  0.840224  ]]. Reward = [0.]
Curr episode timestep = 114
Current timestep = 796. State = [[0.02908559 0.2518653 ]]. Action = [[ 0.1314106   0.13834947  0.14271134 -0.91140586]]. Reward = [0.]
Curr episode timestep = 115
Current timestep = 797. State = [[0.02993525 0.25093254]]. Action = [[-0.01589993 -0.05590236  0.07609451 -0.5974877 ]]. Reward = [0.]
Curr episode timestep = 116
Current timestep = 798. State = [[0.02539641 0.2610735 ]]. Action = [[-0.2044214   0.15919366 -0.23141392 -0.24880445]]. Reward = [0.]
Curr episode timestep = 117
Current timestep = 799. State = [[0.01688233 0.27343306]]. Action = [[-0.12992652 -0.15068233 -0.12484357  0.92166424]]. Reward = [0.]
Curr episode timestep = 118
Current timestep = 800. State = [[0.01538366 0.2750696 ]]. Action = [[ 0.1585435   0.13439661 -0.04874995  0.11680651]]. Reward = [0.]
Curr episode timestep = 119
Current timestep = 801. State = [[0.01210153 0.2806153 ]]. Action = [[-0.14693639 -0.01266587  0.21770024 -0.29873824]]. Reward = [0.]
Curr episode timestep = 120
Current timestep = 802. State = [[0.00391545 0.29414272]]. Action = [[-0.05287358  0.10756576  0.16467726  0.44176412]]. Reward = [0.]
Curr episode timestep = 121
Current timestep = 803. State = [[-0.00354823  0.305859  ]]. Action = [[-0.11063074  0.18250811  0.22192365 -0.5553174 ]]. Reward = [0.]
Curr episode timestep = 122
Current timestep = 804. State = [[-0.00548931  0.30878565]]. Action = [[-0.03492166  0.00856566 -0.14086314  0.26698053]]. Reward = [0.]
Curr episode timestep = 123
Current timestep = 805. State = [[-0.00600882  0.3095801 ]]. Action = [[-0.22021155  0.21944886  0.06890237  0.10271537]]. Reward = [0.]
Curr episode timestep = 124
Current timestep = 806. State = [[-0.00051067  0.29825842]]. Action = [[ 0.17726809 -0.19425194  0.23819566  0.08213377]]. Reward = [0.]
Curr episode timestep = 125
Current timestep = 807. State = [[-0.16333811  0.05323915]]. Action = [[-0.13109872 -0.07622752  0.18337548  0.8950019 ]]. Reward = [0.]
Curr episode timestep = 126
Current timestep = 808. State = [[-0.15348937  0.06747474]]. Action = [[0.042633   0.13349357 0.14817858 0.02312732]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 809. State = [[-0.1343841   0.07322565]]. Action = [[ 0.22875196 -0.09033993  0.16279685  0.603724  ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 810. State = [[-0.11423935  0.0760757 ]]. Action = [[0.02034765 0.08984661 0.13511139 0.7802179 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 811. State = [[-0.10732597  0.09392583]]. Action = [[ 0.06271857  0.23893261 -0.1521214  -0.8000519 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 812. State = [[-0.10426684  0.11896222]]. Action = [[-0.0895413   0.10068703 -0.08410412  0.84792435]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 813. State = [[-0.11115617  0.12196749]]. Action = [[-0.22828329 -0.15882516 -0.22254987 -0.87806123]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 814. State = [[-0.11462843  0.11488608]]. Action = [[ 0.14045101 -0.00293961 -0.0113101   0.20074463]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 815. State = [[-0.11342098  0.11224448]]. Action = [[ 0.02997935  0.00176945  0.05496866 -0.79157376]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 816. State = [[-0.1097601   0.11286652]]. Action = [[ 0.08292878  0.03663024  0.22644061 -0.9146361 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 817. State = [[-0.09770291  0.11570624]]. Action = [[ 0.2289412   0.03736496 -0.13153836 -0.21396124]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 818. State = [[-0.0703979   0.11100186]]. Action = [[ 0.16142517 -0.13259089  0.02107486  0.882781  ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 819. State = [[-0.05830171  0.09681568]]. Action = [[-0.1963248  -0.1479508   0.10385174 -0.3379923 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 820. State = [[-0.06240354  0.08761398]]. Action = [[-0.10908991  0.01599264  0.08163771 -0.18839347]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 821. State = [[-0.06198497  0.07293943]]. Action = [[ 0.12180775 -0.21098378  0.17586046 -0.6842988 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 822. State = [[-0.05711927  0.04857025]]. Action = [[ 0.11254027 -0.17835434 -0.12442067  0.25040722]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 823. State = [[-0.04355983  0.02608028]]. Action = [[ 0.23702875 -0.10530047 -0.23398578 -0.6554582 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 824. State = [[-0.1938006   0.02434846]]. Action = [[-0.10929163  0.08947292 -0.1325456   0.36948597]]. Reward = [100.]
Curr episode timestep = 16
Current timestep = 825. State = [[-0.1868153   0.03461775]]. Action = [[-0.15395041  0.06148532 -0.15585749 -0.64039683]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 826. State = [[-0.18942475  0.03403134]]. Action = [[ 0.02126035 -0.11713329  0.07333601 -0.6975423 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 827. State = [[-0.18309776  0.02101974]]. Action = [[ 0.21747074 -0.11410971  0.05131429 -0.20045161]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 828. State = [[-0.17610563 -0.00197934]]. Action = [[-0.11676435 -0.23806593 -0.13727047 -0.35586202]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 829. State = [[-0.17875081 -0.02224829]]. Action = [[-0.06503609 -0.05817038 -0.1921171   0.24682915]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 830. State = [[-0.18651004 -0.04477519]]. Action = [[-0.13618805 -0.22287071  0.21134174 -0.45299405]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 831. State = [[-0.20179477 -0.07500073]]. Action = [[-0.09901898 -0.21389222  0.07066596  0.19208145]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 832. State = [[-0.20579351 -0.08963977]]. Action = [[0.16928583 0.0334399  0.23058143 0.8310003 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 833. State = [[-0.20316072 -0.09052779]]. Action = [[-0.11220089  0.01498351  0.23632345  0.7066523 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 834. State = [[-0.20759907 -0.09846096]]. Action = [[-0.05989648 -0.11414659  0.2200149   0.524364  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 835. State = [[-0.21795484 -0.10874215]]. Action = [[-0.15814418 -0.02459262  0.00562871 -0.39418757]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 836. State = [[-0.22694437 -0.10842049]]. Action = [[ 0.13986552  0.08543292 -0.20513077  0.28764713]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 837. State = [[-0.2304283  -0.09794522]]. Action = [[-0.16564612  0.12251818 -0.18750948  0.8527434 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 838. State = [[-0.23352578 -0.09738067]]. Action = [[ 0.09045833 -0.16124453 -0.0431971  -0.7505858 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 839. State = [[-0.23253118 -0.11465461]]. Action = [[-0.03628476 -0.18402348  0.0795275   0.45943224]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 840. State = [[-0.23553039 -0.12128974]]. Action = [[-0.02337733  0.1524576   0.2142474   0.12381423]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 841. State = [[-0.24249983 -0.12938698]]. Action = [[-0.1301458  -0.20778802  0.1497156  -0.55501604]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 842. State = [[-0.2465458  -0.13240103]]. Action = [[ 0.10566446  0.14920446 -0.23123439 -0.5115602 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 843. State = [[-0.24138042 -0.13677576]]. Action = [[ 0.0989776  -0.19454451  0.00708669  0.1306758 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 844. State = [[-0.23491544 -0.14903347]]. Action = [[ 0.06334376 -0.06526652  0.0878405   0.8053365 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 845. State = [[-0.23688358 -0.1482471 ]]. Action = [[-0.1959828   0.15879661 -0.07315612 -0.35208344]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 846. State = [[-0.2342346  -0.13391903]]. Action = [[0.23103938 0.13165721 0.24024802 0.20573294]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 847. State = [[-0.23099002 -0.13385026]]. Action = [[-0.14600635 -0.16681036 -0.23789762 -0.13506019]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 848. State = [[-0.2264444  -0.12767026]]. Action = [[ 0.21239895  0.19966245  0.06437981 -0.417601  ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 849. State = [[-0.20826884 -0.11371133]]. Action = [[ 0.22159207  0.04912093 -0.10516337  0.02023995]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 850. State = [[-0.19026883 -0.10691149]]. Action = [[-0.00909622  0.02934963 -0.1512663  -0.553271  ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 851. State = [[-0.1777381  -0.10369494]]. Action = [[ 0.22466415 -0.00390635 -0.23750381  0.5417954 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 852. State = [[-0.15440476 -0.10831885]]. Action = [[ 0.10403335 -0.10724136 -0.09717219 -0.7314437 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 853. State = [[-0.13726729 -0.1175188 ]]. Action = [[ 0.10564172 -0.09152281  0.05835411  0.41461146]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 854. State = [[-0.11613923 -0.11548706]]. Action = [[ 0.23497868  0.16199389 -0.11901864 -0.08250189]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 855. State = [[-0.10104235 -0.10032989]]. Action = [[-0.15126342  0.15884519 -0.15413503  0.55566704]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 856. State = [[-0.09810403 -0.09571612]]. Action = [[ 0.169523   -0.1409851  -0.1797424   0.59513366]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 857. State = [[-0.08569249 -0.08740085]]. Action = [[ 0.11117435  0.2205931  -0.02423614  0.15077972]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 858. State = [[-0.06360576 -0.07210171]]. Action = [[ 0.21024463  0.06758544 -0.14963241  0.27625704]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 859. State = [[-0.21343087 -0.2046079 ]]. Action = [[0.23469633 0.12638947 0.24194965 0.7853112 ]]. Reward = [100.]
Curr episode timestep = 34
Current timestep = 860. State = [[-0.19692996 -0.22200365]]. Action = [[0.23857671 0.0770686  0.13969845 0.81700444]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 861. State = [[-0.1674106  -0.21380173]]. Action = [[0.24613088 0.12687778 0.2093193  0.21244907]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 862. State = [[-0.1333736  -0.21692102]]. Action = [[ 0.22760016 -0.21138006  0.11132732  0.5214312 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 863. State = [[-0.10312627 -0.22892725]]. Action = [[ 0.14964381 -0.04477501 -0.23346826  0.9397447 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 864. State = [[-0.08967078 -0.22602017]]. Action = [[-0.11373594  0.1822798   0.20742795  0.12173522]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 865. State = [[-0.08930695 -0.2206507 ]]. Action = [[-0.02201949 -0.00704218 -0.19039659  0.59279513]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 866. State = [[-0.08747727 -0.20758413]]. Action = [[0.0773291  0.19426104 0.22757429 0.890285  ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 867. State = [[-0.08733604 -0.17975554]]. Action = [[-0.11931634  0.22253513  0.02983329  0.35879564]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 868. State = [[-0.09925647 -0.16650783]]. Action = [[-0.2221687  -0.04784566  0.06036311 -0.6605164 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 869. State = [[-0.1095319  -0.15983854]]. Action = [[ 0.11793193  0.09720901  0.18646404 -0.9505018 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 870. State = [[-0.10814094 -0.15476157]]. Action = [[ 0.04255402 -0.06559128  0.03654966  0.4663291 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 871. State = [[-0.10804451 -0.14805582]]. Action = [[-0.08220099  0.15442076 -0.15193518  0.39212012]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 872. State = [[-0.10535657 -0.14981489]]. Action = [[ 0.14918107 -0.191623   -0.08160093  0.31038976]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 873. State = [[-0.09526837 -0.16968119]]. Action = [[ 0.20414233 -0.2195648  -0.10199997 -0.19885921]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 874. State = [[-0.0828433  -0.17767313]]. Action = [[-0.10935357  0.17240757 -0.05078909  0.63072443]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 875. State = [[-0.08301454 -0.1738839 ]]. Action = [[ 0.03925815 -0.00307083 -0.22796343  0.95017004]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 876. State = [[-0.08307082 -0.17775235]]. Action = [[ 0.01023075 -0.10754664 -0.1819025  -0.11420774]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 877. State = [[-0.08224729 -0.17146963]]. Action = [[0.02258545 0.17794985 0.22789365 0.7115638 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 878. State = [[-0.08086881 -0.16330661]]. Action = [[ 0.03183717  0.00054485  0.21767116 -0.3868518 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 879. State = [[-0.08467415 -0.17490007]]. Action = [[-0.19223452 -0.2121839   0.07365119 -0.53424084]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 880. State = [[-0.09132216 -0.18764912]]. Action = [[-0.05571488 -0.00456437 -0.07790411  0.24829745]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 881. State = [[-0.08930636 -0.19370365]]. Action = [[ 0.20667171 -0.08639094 -0.00753738  0.89367604]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 882. State = [[-0.07732717 -0.20669825]]. Action = [[ 0.18359339 -0.14961009  0.09565124 -0.09978437]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 883. State = [[-0.06783872 -0.22242032]]. Action = [[-0.21051177 -0.04912236 -0.19713199 -0.9746234 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 884. State = [[-0.07070204 -0.23424661]]. Action = [[ 0.14940569 -0.10268673  0.04119864 -0.10727423]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 885. State = [[-0.06662554 -0.2299836 ]]. Action = [[0.05386633 0.19275838 0.22752604 0.26124358]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 886. State = [[-0.05887393 -0.21179017]]. Action = [[-0.00704223  0.16834798  0.07799268 -0.7256974 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 887. State = [[-0.05300528 -0.18462014]]. Action = [[ 0.06642121  0.22007987 -0.21066011 -0.7544915 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 888. State = [[-0.05432408 -0.16832364]]. Action = [[-0.21209246  0.0151839  -0.18335249 -0.87080497]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 889. State = [[-0.05625422 -0.15667018]]. Action = [[ 0.03761232  0.12772065  0.15758044 -0.6898967 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 890. State = [[-0.05657582 -0.13526034]]. Action = [[-0.01399346  0.19909692 -0.12701073 -0.13351399]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 891. State = [[-0.05417341 -0.12214865]]. Action = [[ 0.19555682 -0.07144204 -0.20776758  0.90258765]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 892. State = [[-0.04905257 -0.11012761]]. Action = [[0.04161847 0.20466799 0.24381542 0.8625622 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 893. State = [[-0.04202529 -0.09828851]]. Action = [[ 7.8314900e-02  2.4288893e-04 -2.4690749e-01 -6.6297525e-01]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 894. State = [[-0.03502901 -0.10674249]]. Action = [[-0.01300226 -0.19239056 -0.20480369  0.78967977]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 895. State = [[-0.02802935 -0.12717058]]. Action = [[ 0.1624155  -0.21035725 -0.2090002   0.8366022 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 895 is [False, True, False, True, False, False]
State prediction error at timestep 895 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 895 of 1
Current timestep = 896. State = [[-0.00618889 -0.13333017]]. Action = [[0.1300244  0.23738009 0.19818458 0.37802482]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 897. State = [[-1.1937444e-05 -1.3352057e-01]]. Action = [[-0.18224348 -0.20487948  0.10463509  0.14430332]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 898. State = [[-0.00702115 -0.15336797]]. Action = [[-0.12645617 -0.14323677 -0.10681254  0.23861015]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 899. State = [[-0.02089463 -0.16450305]]. Action = [[-0.22992033  0.03946561 -0.18580021 -0.8067813 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 900. State = [[-0.04440502 -0.17144854]]. Action = [[-0.24681826 -0.04443941  0.01024079 -0.02752632]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 901. State = [[-0.06241957 -0.15930685]]. Action = [[ 0.11421841  0.23499897 -0.2327391  -0.6915952 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 902. State = [[-0.05699111 -0.13069469]]. Action = [[ 0.20227116  0.17019176  0.10102451 -0.47563326]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 903. State = [[-0.05317949 -0.10379963]]. Action = [[0.00649151 0.18963954 0.00456241 0.25256503]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 904. State = [[-0.04504027 -0.09053553]]. Action = [[ 0.188966   -0.0620544   0.21522582 -0.82530177]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 904 is [False, True, False, False, True, False]
State prediction error at timestep 904 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 904 of 1
Current timestep = 905. State = [[-0.27145287  0.05882909]]. Action = [[ 0.13642943  0.07726836 -0.03791752 -0.6238671 ]]. Reward = [100.]
Curr episode timestep = 45
Current timestep = 906. State = [[-0.27106154  0.06554745]]. Action = [[-0.10278291  0.13604856  0.15867025 -0.3885066 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 907. State = [[-0.27103406  0.0655513 ]]. Action = [[-0.23055868 -0.02684177 -0.02399041  0.7884445 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 908. State = [[-0.26020545  0.06737524]]. Action = [[0.22064698 0.01418409 0.2344796  0.7663567 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 909. State = [[-0.24412179  0.06990557]]. Action = [[-0.22968563 -0.10932361  0.11508092  0.30180454]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 910. State = [[-0.24320966  0.07007004]]. Action = [[-0.22900793  0.12007597 -0.05679904 -0.23653209]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 911. State = [[-0.24288143  0.07592212]]. Action = [[ 0.00882927  0.10893321  0.24253085 -0.06725103]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 912. State = [[-0.24212752  0.08037752]]. Action = [[ 0.00823009 -0.00323974  0.09790081 -0.5383434 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 913. State = [[-0.23513602  0.08283132]]. Action = [[ 0.08788991  0.02952033  0.10968682 -0.64075345]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 914. State = [[-0.21793087  0.0755615 ]]. Action = [[ 0.19740799 -0.20149648  0.07282564 -0.49119908]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 915. State = [[-0.20103961  0.05713387]]. Action = [[ 0.00300911 -0.14459905  0.21275663 -0.9004062 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 916. State = [[-0.18871857  0.04304337]]. Action = [[ 0.20945108 -0.05087981 -0.19176278  0.39265084]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 917. State = [[-0.16901721  0.04946378]]. Action = [[ 0.04600182  0.2056793  -0.16052417  0.4154873 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 918. State = [[-0.15273511  0.07265029]]. Action = [[ 0.21725193  0.24758017 -0.18396366 -0.8539981 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 919. State = [[-0.12396151  0.10382654]]. Action = [[0.23225719 0.19971621 0.22015822 0.21578515]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 920. State = [[-0.09988879  0.11755209]]. Action = [[-0.01450761 -0.08597551 -0.18984658 -0.41690397]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 921. State = [[-0.0954678   0.11186553]]. Action = [[ 0.04169053 -0.08521754 -0.10498607  0.20048332]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 922. State = [[-0.08707612  0.0958894 ]]. Action = [[ 0.09227931 -0.18231694  0.15944096 -0.7923162 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 923. State = [[-0.07186823  0.09402987]]. Action = [[ 0.1685665   0.2034809  -0.23096329  0.46527994]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 924. State = [[-0.04992235  0.0969018 ]]. Action = [[ 0.09081393 -0.10836494  0.01716921  0.4656825 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 925. State = [[-0.0365122   0.10313912]]. Action = [[ 0.09611627  0.16841197 -0.23415498  0.6244464 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 926. State = [[-0.02214296  0.12556484]]. Action = [[0.07583663 0.22653055 0.10503674 0.893783  ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 926 is [False, True, False, False, False, True]
State prediction error at timestep 926 is tensor(0.0005, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 926 of 1
Current timestep = 927. State = [[-0.00877849  0.14605619]]. Action = [[-0.04878345 -0.04982305 -0.23331614 -0.85428894]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 928. State = [[-0.01048444  0.15416293]]. Action = [[ 0.05438238  0.17704827 -0.13228521 -0.58275753]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 929. State = [[-0.00264471  0.16240585]]. Action = [[ 0.11375925 -0.03321794 -0.24095716  0.9483435 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 930. State = [[0.00526831 0.15210383]]. Action = [[-0.23800051 -0.22701004  0.01505628  0.5788516 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 931. State = [[-0.00025698  0.15098254]]. Action = [[-0.09191602  0.15516055 -0.2427969  -0.9269476 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 932. State = [[-0.00461323  0.1558827 ]]. Action = [[ 0.08860329 -0.05381876  0.09850705  0.98072326]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 933. State = [[-0.00804555  0.16475016]]. Action = [[-0.00679348  0.21364391 -0.1986353   0.6250675 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 934. State = [[-0.00644716  0.1645405 ]]. Action = [[ 0.1665479  -0.20451672 -0.23857048  0.9049156 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 935. State = [[-0.00355999  0.16587019]]. Action = [[-0.01492868  0.22550607  0.19372708  0.01481998]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 936. State = [[-0.00316438  0.16906916]]. Action = [[ 0.07706994 -0.10405284  0.2423811  -0.17429495]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 937. State = [[-0.00076755  0.17151435]]. Action = [[-0.18900032  0.03531793  0.15091628 -0.7886415 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 938. State = [[-0.00367705  0.1748938 ]]. Action = [[-0.12650517 -0.02456614  0.06259194  0.14780045]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 939. State = [[-0.01655766  0.19083819]]. Action = [[-0.24706295  0.23907131  0.18741232  0.91196275]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 940. State = [[-0.03869348  0.22011311]]. Action = [[0.11019343 0.1704973  0.24281275 0.04846048]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 941. State = [[-0.03631839  0.23047242]]. Action = [[0.24543768 0.04244781 0.09584707 0.13146305]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 942. State = [[-0.02625657  0.22521739]]. Action = [[-0.24425955 -0.22825108  0.06572092  0.7768884 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 943. State = [[-0.0214271   0.19970816]]. Action = [[ 0.19530594 -0.22332196  0.13080359 -0.63891816]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 944. State = [[-0.02166941  0.17622645]]. Action = [[-0.23386261 -0.11579081 -0.11549053 -0.25280774]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 945. State = [[-0.02729813  0.1736032 ]]. Action = [[ 0.14368507  0.167436    0.15492052 -0.20050132]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 946. State = [[-0.02911241  0.17986481]]. Action = [[-0.15336752 -0.02775924  0.10599449 -0.60554576]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 947. State = [[-0.03253903  0.18656209]]. Action = [[0.03593582 0.08549929 0.16132635 0.2686926 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 948. State = [[-0.03391574  0.1990557 ]]. Action = [[ 0.1449129   0.1695903   0.23443377 -0.31304216]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 949. State = [[-0.03495594  0.20267288]]. Action = [[-0.19093607 -0.13562778 -0.23282845 -0.9454219 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 950. State = [[-0.0364216   0.20070651]]. Action = [[-0.03779393  0.00217944  0.16013128 -0.5204361 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 951. State = [[-0.0436567   0.21348657]]. Action = [[0.0194619  0.24694389 0.16516495 0.73621225]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 952. State = [[-0.04435376  0.22171251]]. Action = [[ 0.22379455 -0.08972339 -0.03082281  0.9305295 ]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 953. State = [[-0.04153617  0.22998105]]. Action = [[-0.02358583  0.24189556  0.22806284 -0.7907327 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 954. State = [[-0.04510799  0.2494874 ]]. Action = [[-0.23647127  0.02296481 -0.00939721 -0.73692024]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 955. State = [[-0.04915939  0.25398958]]. Action = [[ 0.06411418 -0.08310354 -0.15250789 -0.53700143]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 956. State = [[-0.04802553  0.25025386]]. Action = [[-0.00523031 -0.00361188  0.22829458 -0.5484944 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 957. State = [[-0.04621232  0.25691408]]. Action = [[ 0.19137505  0.21607018 -0.1563099   0.8230312 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 958. State = [[-0.04587546  0.27182308]]. Action = [[-0.22517854  0.00406253 -0.04934381 -0.5646337 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 959. State = [[-0.05028969  0.27568805]]. Action = [[-0.05122676 -0.07099836  0.14666292 -0.63902974]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 960. State = [[-0.04717074  0.26291862]]. Action = [[ 0.09579453 -0.1605241  -0.20712171  0.8066611 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 961. State = [[-0.04003522  0.24024364]]. Action = [[ 0.1530506  -0.20455675 -0.2192094   0.7220546 ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 962. State = [[-0.03498934  0.23065549]]. Action = [[-0.13502125  0.11362675  0.13877866 -0.84540087]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 963. State = [[-0.04463021  0.24325775]]. Action = [[-0.24588014  0.133273   -0.15681198  0.8979957 ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 964. State = [[-0.06618701  0.2626743 ]]. Action = [[ 0.00821859  0.12725145 -0.11676094 -0.5088668 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 965. State = [[-0.07789002  0.27680296]]. Action = [[-0.17361708  0.03817704 -0.15536845 -0.4983158 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 966. State = [[-0.09111656  0.28252164]]. Action = [[-0.00201848  0.18026862  0.22776699  0.31765246]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 967. State = [[-0.08954795  0.27971283]]. Action = [[ 0.13128042 -0.03695369 -0.03910244 -0.7615179 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 968. State = [[-0.08707523  0.2772187 ]]. Action = [[-0.01961878  0.21945155  0.1534962  -0.7346519 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 969. State = [[-0.08661542  0.2760917 ]]. Action = [[0.11418638 0.18230832 0.07451615 0.19600403]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 970. State = [[-0.08497287  0.2794431 ]]. Action = [[ 0.13051921  0.09983048 -0.02133332  0.23573852]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 971. State = [[-0.0837194   0.28144285]]. Action = [[0.1197677  0.20019841 0.19533363 0.5171399 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 972. State = [[-0.08364765  0.2813814 ]]. Action = [[-0.21278885  0.14940953  0.01951087  0.7800436 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 973. State = [[-0.08364765  0.2813814 ]]. Action = [[-0.04206094  0.19558173 -0.1251168   0.97315216]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 974. State = [[-0.08364765  0.2813814 ]]. Action = [[ 0.19776332  0.16567242 -0.08131218 -0.66213745]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 975. State = [[-0.08364765  0.2813814 ]]. Action = [[-0.2256877   0.15914845  0.18173352 -0.507495  ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 976. State = [[-0.08364765  0.2813814 ]]. Action = [[-0.1673207   0.24272859  0.21029878  0.84683514]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 977. State = [[-0.08118731  0.27783382]]. Action = [[ 0.01314703 -0.07791597 -0.15260153 -0.92063165]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 978. State = [[-0.08548655  0.28382298]]. Action = [[-0.19732098  0.12195992  0.19896612 -0.6428701 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 979. State = [[-0.09071546  0.29137173]]. Action = [[-0.05759038  0.1863656  -0.11591581 -0.1335119 ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 980. State = [[-0.08745065  0.28053913]]. Action = [[ 0.08420312 -0.2157359  -0.24044652 -0.7069468 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 981. State = [[-0.07918853  0.26713923]]. Action = [[ 0.203897    0.03929842 -0.17880404  0.5648056 ]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 982. State = [[-0.06559314  0.26783457]]. Action = [[0.2359466  0.12709379 0.23131427 0.21892893]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 983. State = [[-0.04356588  0.2667792 ]]. Action = [[-0.02296053 -0.17288055  0.01753604  0.20774019]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 984. State = [[-0.03127682  0.2500151 ]]. Action = [[ 0.21843791 -0.1023778  -0.0997217  -0.795435  ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 985. State = [[-0.00573651  0.23081218]]. Action = [[ 0.22717005 -0.16132307  0.24569318  0.06265318]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 986. State = [[0.01720878 0.20583645]]. Action = [[-0.11656693 -0.2137553  -0.23378648  0.76121855]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 987. State = [[0.01577952 0.20746109]]. Action = [[-0.11529037  0.23993507  0.13972512 -0.73024064]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 988. State = [[0.01333064 0.23223004]]. Action = [[ 0.22290671  0.24543476 -0.17718469  0.94953394]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 989. State = [[0.01895802 0.2453493 ]]. Action = [[-0.15149283 -0.11365411  0.21299118 -0.17986548]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 990. State = [[0.01948373 0.25023884]]. Action = [[ 0.11858696  0.13326854 -0.08227652 -0.21645784]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 991. State = [[0.02505095 0.24990569]]. Action = [[ 0.10551718 -0.09342262  0.06358311 -0.6535345 ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 992. State = [[0.02282457 0.2574887 ]]. Action = [[-0.22474621  0.202223    0.24524808  0.90983725]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 993. State = [[0.01848362 0.27871355]]. Action = [[ 0.21318263  0.14549142  0.03422162 -0.58032393]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 994. State = [[0.03626483 0.28676108]]. Action = [[ 0.22221297 -0.04871765 -0.21378759 -0.86382866]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 995. State = [[0.0551335 0.2833686]]. Action = [[-0.20544083  0.19870216  0.10766232  0.87736917]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 996. State = [[0.05579419 0.28214327]]. Action = [[-0.20816675  0.19839376  0.24290848 -0.09891814]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 997. State = [[0.05633089 0.28082952]]. Action = [[-0.24210733  0.22262785 -0.13975134 -0.8298333 ]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 998. State = [[0.05676715 0.2795939 ]]. Action = [[ 0.0312404   0.01615494  0.19095823 -0.67720985]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 999. State = [[0.05679293 0.2794856 ]]. Action = [[-0.02025677  0.15506119  0.0025847   0.47121716]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 1000. State = [[0.05679293 0.2794856 ]]. Action = [[ 0.00111777  0.24460399 -0.03260997 -0.7911621 ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 1001. State = [[0.05679293 0.2794856 ]]. Action = [[0.00287423 0.18159562 0.07639614 0.39124238]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 1002. State = [[0.05679293 0.2794856 ]]. Action = [[ 0.08816034  0.15317893 -0.22210775  0.47520852]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 1003. State = [[0.05639683 0.27935997]]. Action = [[-0.10314879 -0.08502978  0.23125517 -0.520932  ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 1004. State = [[0.05601321 0.2793188 ]]. Action = [[0.18941283 0.12195385 0.03573871 0.48414373]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 1005. State = [[0.04975003 0.28691015]]. Action = [[-0.22401342  0.07288471 -0.18382205 -0.98550975]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 1006. State = [[0.0489655  0.28620526]]. Action = [[ 0.08071473 -0.12058082 -0.03224695 -0.19239509]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 1007. State = [[0.053244   0.27812406]]. Action = [[ 0.02439585 -0.06252438  0.16628566  0.5873959 ]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 1008. State = [[0.05548679 0.27397153]]. Action = [[ 0.24608052  0.12401596 -0.20251428  0.6833236 ]]. Reward = [0.]
Curr episode timestep = 102
Current timestep = 1009. State = [[0.05918662 0.26242563]]. Action = [[-0.01981522 -0.22560312  0.04984766  0.38608146]]. Reward = [0.]
Curr episode timestep = 103
Current timestep = 1010. State = [[0.06702031 0.23827067]]. Action = [[-0.11391346 -0.20563845  0.04524425  0.36756825]]. Reward = [0.]
Curr episode timestep = 104
Current timestep = 1011. State = [[0.05165476 0.20812352]]. Action = [[-0.19686277 -0.13455449  0.14688432  0.9305377 ]]. Reward = [0.]
Curr episode timestep = 105
Current timestep = 1012. State = [[0.02513858 0.20202719]]. Action = [[-0.2135587   0.08739597  0.01857725  0.02670896]]. Reward = [0.]
Curr episode timestep = 106
Current timestep = 1013. State = [[0.00694857 0.20067751]]. Action = [[ 0.16378516 -0.04944697  0.03379166  0.02826893]]. Reward = [0.]
Curr episode timestep = 107
Current timestep = 1014. State = [[0.01073921 0.1841924 ]]. Action = [[ 0.01896337 -0.22671251 -0.13245265 -0.60175174]]. Reward = [0.]
Curr episode timestep = 108
Current timestep = 1015. State = [[0.00690634 0.15548061]]. Action = [[-0.24573988 -0.18436365 -0.20916222  0.8243567 ]]. Reward = [0.]
Curr episode timestep = 109
Current timestep = 1016. State = [[-0.0183007   0.13285954]]. Action = [[-0.16987558 -0.06309679  0.07626322  0.18057775]]. Reward = [0.]
Curr episode timestep = 110
Current timestep = 1017. State = [[-0.0440942   0.10949469]]. Action = [[-0.16626005 -0.20983854  0.23159963  0.23091173]]. Reward = [0.]
Curr episode timestep = 111
Current timestep = 1018. State = [[-0.06882261  0.09760997]]. Action = [[-0.06519471  0.09398535  0.17541105  0.07084823]]. Reward = [0.]
Curr episode timestep = 112
Current timestep = 1019. State = [[-0.07191344  0.08539857]]. Action = [[ 0.19968289 -0.24416322 -0.03568588  0.93358374]]. Reward = [0.]
Curr episode timestep = 113
Current timestep = 1020. State = [[-0.07209201  0.0556708 ]]. Action = [[-0.17499912 -0.20697004 -0.17091386  0.6743274 ]]. Reward = [0.]
Curr episode timestep = 114
Current timestep = 1021. State = [[-0.07945483  0.04156179]]. Action = [[ 0.12066811  0.07852083 -0.10549343  0.0985744 ]]. Reward = [0.]
Curr episode timestep = 115
Current timestep = 1022. State = [[-0.08307881  0.0349314 ]]. Action = [[-0.16967475 -0.12496409  0.10724145  0.16176009]]. Reward = [0.]
Curr episode timestep = 116
Current timestep = 1023. State = [[-0.09458013  0.01767705]]. Action = [[-0.08604324 -0.12875949 -0.09371048  0.23327398]]. Reward = [0.]
Curr episode timestep = 117
Current timestep = 1024. State = [[-0.10843449  0.00066457]]. Action = [[-0.13614953 -0.08141565 -0.19277573  0.9143002 ]]. Reward = [0.]
Curr episode timestep = 118
Current timestep = 1025. State = [[-0.1190599  -0.01524537]]. Action = [[ 0.09322438 -0.14092846  0.14212409  0.50881743]]. Reward = [0.]
Curr episode timestep = 119
Current timestep = 1026. State = [[-0.11853974 -0.03398564]]. Action = [[ 0.01761279 -0.13385734 -0.24893321  0.74596405]]. Reward = [0.]
Curr episode timestep = 120
Current timestep = 1027. State = [[-0.12432805 -0.05869097]]. Action = [[-0.1859718  -0.19784497  0.03647903 -0.86284834]]. Reward = [0.]
Curr episode timestep = 121
Current timestep = 1028. State = [[-0.13632649 -0.063173  ]]. Action = [[ 0.03647959  0.21861187 -0.21644485  0.62983525]]. Reward = [0.]
Curr episode timestep = 122
Current timestep = 1029. State = [[-0.1263054  -0.04038569]]. Action = [[ 0.24747574  0.20554122 -0.19606626 -0.77846575]]. Reward = [0.]
Curr episode timestep = 123
Current timestep = 1030. State = [[-0.10921437 -0.03057734]]. Action = [[ 0.17794845 -0.09298629  0.01047057 -0.39002067]]. Reward = [0.]
Curr episode timestep = 124
Current timestep = 1031. State = [[-0.0955763  -0.02176163]]. Action = [[-0.01204151  0.18019003  0.21854061  0.635705  ]]. Reward = [0.]
Curr episode timestep = 125
Current timestep = 1032. State = [[-0.20952344  0.20146474]]. Action = [[ 0.07823369 -0.19897115  0.11063632 -0.6706607 ]]. Reward = [0.]
Curr episode timestep = 126
Current timestep = 1033. State = [[-0.18805732  0.22719556]]. Action = [[ 0.2295413   0.040378   -0.00648759  0.5563737 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1034. State = [[-0.15743728  0.2276592 ]]. Action = [[ 0.22166947 -0.0636847  -0.09927368  0.78797626]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1035. State = [[-0.13041708  0.23571318]]. Action = [[ 0.17059273  0.19554889 -0.06225996  0.7311462 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1036. State = [[-0.11404891  0.24839018]]. Action = [[-0.09404533 -0.02998143 -0.02966094  0.00199795]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1037. State = [[-0.11224938  0.2382434 ]]. Action = [[-0.03969598 -0.22164719  0.1964311   0.5488149 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1038. State = [[-0.10891436  0.21518096]]. Action = [[-0.04501519 -0.19429126  0.22247183 -0.56354636]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1039. State = [[-0.10516238  0.20060045]]. Action = [[ 0.14642102  0.00812858  0.20422241 -0.50721973]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1040. State = [[-0.09867487  0.18880989]]. Action = [[ 0.11693662 -0.11576837 -0.1677007  -0.07096255]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1041. State = [[-0.09897013  0.18965864]]. Action = [[-0.21094082  0.13952234 -0.18668564 -0.8363936 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1042. State = [[-0.11294238  0.20664524]]. Action = [[-0.2204547   0.09149811  0.15090144 -0.7280209 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1043. State = [[-0.13504344  0.20531091]]. Action = [[-0.23831537 -0.20677157 -0.12970144 -0.57608515]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1044. State = [[-0.1493576   0.18304309]]. Action = [[ 0.17889279 -0.13338879  0.04746401 -0.7715893 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1045. State = [[-0.14973523  0.15785721]]. Action = [[-0.14798549 -0.2368209   0.14716092 -0.48787093]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1046. State = [[-0.16544333  0.12887254]]. Action = [[-0.20765898 -0.19283564  0.16808751 -0.10313046]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1047. State = [[-0.1769282   0.11826604]]. Action = [[0.21458784 0.16439608 0.0171853  0.41853964]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1048. State = [[-0.17458099  0.1134578 ]]. Action = [[-0.11935844 -0.18750477  0.18043995 -0.1811583 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1049. State = [[-0.1839316   0.10821302]]. Action = [[-0.14440902  0.05068368 -0.13923748 -0.50999564]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1050. State = [[-0.19171941  0.11926797]]. Action = [[0.15050668 0.21594527 0.11604118 0.57227325]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1051. State = [[-0.19235002  0.12395182]]. Action = [[-0.05305663 -0.11418417 -0.14171347 -0.05688292]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1052. State = [[-0.19750251  0.11469629]]. Action = [[-0.17023154 -0.14193824  0.2389848  -0.15198672]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1053. State = [[-0.20072643  0.1127132 ]]. Action = [[ 0.16114354  0.16580957  0.23963279 -0.73957884]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 1054. State = [[-0.19978407  0.12641832]]. Action = [[0.02259746 0.13886952 0.08021092 0.5235964 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 1055. State = [[-0.19873433  0.13346204]]. Action = [[-0.01139852 -0.07888627  0.2318899   0.6795647 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 1056. State = [[-0.18945305  0.14109239]]. Action = [[ 0.23818073  0.1822049   0.1395939  -0.01388294]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 1057. State = [[-0.17751223  0.150947  ]]. Action = [[-0.03730218  0.02313691  0.1372621   0.8567846 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 1058. State = [[-0.17718379  0.15331231]]. Action = [[ 0.02027512 -0.00657006  0.1265178  -0.696068  ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 1059. State = [[-0.1658554   0.15301536]]. Action = [[ 0.21612859 -0.02088585 -0.12076044  0.3311211 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 1060. State = [[-0.13763285  0.14059839]]. Action = [[ 0.24345505 -0.22801273  0.10794133 -0.59696066]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 1061. State = [[-0.11646387  0.1128603 ]]. Action = [[-0.04583207 -0.21449609 -0.01139805 -0.3908643 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 1062. State = [[-0.1027497   0.08695511]]. Action = [[ 0.22415084 -0.13547622 -0.11823437 -0.0406661 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 1063. State = [[-0.09112831  0.08388925]]. Action = [[-0.03120361  0.19178545 -0.12455636  0.0754205 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 1064. State = [[-0.08028477  0.07872964]]. Action = [[ 0.2466672  -0.2309309   0.13481551  0.8640325 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 1065. State = [[-0.05102826  0.05974795]]. Action = [[ 0.17245859 -0.0981586  -0.15857294  0.83842874]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 1066. State = [[-0.22266582  0.16767994]]. Action = [[ 0.2070232   0.00851762 -0.23484673  0.7186707 ]]. Reward = [100.]
Curr episode timestep = 33
Current timestep = 1067. State = [[-0.20783176  0.18782029]]. Action = [[ 0.14557803  0.00132906 -0.15709496 -0.40814543]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1068. State = [[-0.18429668  0.18047741]]. Action = [[ 0.17230666 -0.16017297  0.07694635  0.31841755]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1069. State = [[-0.15835956  0.15891993]]. Action = [[ 0.21827185 -0.19278288  0.08978146 -0.1630851 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1070. State = [[-0.12874028  0.14776313]]. Action = [[ 0.2252664   0.03910968 -0.0214709   0.33387053]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1071. State = [[-0.10090023  0.14136393]]. Action = [[ 0.12089521 -0.10796043  0.2412523   0.72870934]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1072. State = [[-0.09459119  0.1445772 ]]. Action = [[-0.15476617  0.16873688 -0.07720117 -0.0338499 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1073. State = [[-0.10241907  0.14912203]]. Action = [[-0.19285329 -0.09975627 -0.08204351 -0.93794274]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1074. State = [[-0.11175484  0.15235275]]. Action = [[-0.09976768  0.05210111 -0.06105886  0.16397285]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1075. State = [[-0.12046736  0.16151345]]. Action = [[0.1328702  0.14513525 0.22002769 0.50353265]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1076. State = [[-0.12159482  0.16305482]]. Action = [[-0.05917306 -0.10833775  0.04504535 -0.45307678]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1077. State = [[-0.11777955  0.15017931]]. Action = [[ 0.04344633 -0.16787748 -0.13457578  0.49431515]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1078. State = [[-0.11420584  0.15039283]]. Action = [[0.15085363 0.23618546 0.20239848 0.26385236]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1079. State = [[-0.10912503  0.16253582]]. Action = [[0.02659836 0.05882633 0.18884203 0.45032048]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1080. State = [[-0.10540603  0.15989542]]. Action = [[-0.03660136 -0.16450854  0.00421894  0.83666754]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1081. State = [[-0.10406045  0.15099616]]. Action = [[-0.09157681 -0.08641985  0.01628    -0.1991812 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1082. State = [[-0.10545302  0.14178145]]. Action = [[-0.04668501 -0.05156307  0.019485   -0.10694671]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1083. State = [[-0.11319483  0.13135765]]. Action = [[-0.11976805 -0.10576278  0.19197404 -0.58287764]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1084. State = [[-0.11928034  0.1271305 ]]. Action = [[ 0.04897854  0.08600271 -0.03531693 -0.81954986]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1085. State = [[-0.12176202  0.14051187]]. Action = [[ 0.06661046  0.19444352  0.11077192 -0.3117808 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1086. State = [[-0.12871726  0.15690327]]. Action = [[-0.11516188  0.07850575  0.11240515  0.58514416]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1087. State = [[-0.13808946  0.17424758]]. Action = [[-0.12095508  0.09876546  0.19023454 -0.1339128 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 1088. State = [[-0.14462827  0.18373221]]. Action = [[-0.03794198 -0.01483947  0.23801461  0.22341537]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 1089. State = [[-0.14757673  0.18269175]]. Action = [[-0.05637069 -0.04279143  0.1001983  -0.4183749 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 1090. State = [[-0.14993745  0.18558146]]. Action = [[ 0.09308153  0.10611579 -0.18259013 -0.65431106]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 1091. State = [[-0.1503522   0.19829795]]. Action = [[0.08764654 0.18007296 0.22099757 0.2627951 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 1092. State = [[-0.14651118  0.20667374]]. Action = [[ 0.10422894 -0.03973721  0.07173011  0.82555676]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 1093. State = [[-0.14779128  0.21805885]]. Action = [[-0.14185232  0.17829913 -0.23042955 -0.90895647]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 1094. State = [[-0.15097103  0.22328869]]. Action = [[ 0.052376   -0.11733891 -0.01046792 -0.6504323 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 1095. State = [[-0.14262211  0.23013082]]. Action = [[ 0.18217716  0.21340126 -0.23603381 -0.6592006 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 1096. State = [[-0.11891824  0.2451617 ]]. Action = [[ 0.21134502  0.05174369 -0.11889099 -0.17495286]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 1097. State = [[-0.08940098  0.25514865]]. Action = [[ 0.23813245  0.0373905  -0.05018504 -0.8321752 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 1098. State = [[-0.06423023  0.2695581 ]]. Action = [[ 0.06354231  0.15076444  0.03685185 -0.9224244 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 1099. State = [[-0.04052414  0.2692965 ]]. Action = [[ 0.19875646 -0.18176535  0.03476578  0.27006352]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 1100. State = [[-0.02974801  0.27075195]]. Action = [[-0.21183251  0.11854884 -0.12280309 -0.23897588]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 1101. State = [[-0.03407423  0.2818675 ]]. Action = [[ 0.11153966  0.10586333  0.1424354  -0.30022782]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 1102. State = [[-0.03186703  0.28589988]]. Action = [[-0.15567304 -0.09991688  0.13528636 -0.037386  ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 1103. State = [[-0.03728311  0.28854975]]. Action = [[-0.17425884 -0.00566877 -0.2069919  -0.45286047]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 1104. State = [[-0.0398572  0.2827857]]. Action = [[ 0.12866789 -0.1048343  -0.2329004  -0.6000091 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 1105. State = [[-0.04355874  0.2757316 ]]. Action = [[-0.19509754 -0.04100926 -0.23415989  0.9473547 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 1106. State = [[-0.05159818  0.272246  ]]. Action = [[-0.11844686  0.23654783  0.01310506 -0.99060535]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 1107. State = [[-0.05294709  0.2730676 ]]. Action = [[ 0.17563224  0.10129222 -0.1596079   0.62109613]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 1108. State = [[-0.05124    0.2786363]]. Action = [[ 0.06846958  0.08909234  0.00982749 -0.49956733]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 1109. State = [[-0.0495625   0.28552675]]. Action = [[-0.03514087  0.04751256 -0.13243215 -0.66272044]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 1110. State = [[-0.04379591  0.2879038 ]]. Action = [[ 0.23401308  0.00979379 -0.04881641  0.03709888]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 1111. State = [[-0.0292628  0.2938484]]. Action = [[0.19556046 0.17904073 0.19972035 0.02117312]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 1112. State = [[-0.02870862  0.2935814 ]]. Action = [[0.00087261 0.09963566 0.0043166  0.66753507]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 1113. State = [[-0.02456545  0.28672197]]. Action = [[ 0.06427866 -0.10792838  0.16787487 -0.43415242]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 1114. State = [[-0.0197958  0.2792342]]. Action = [[-0.03639688  0.21687719 -0.07746714 -0.82047147]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 1115. State = [[-0.02377873  0.28509718]]. Action = [[-0.1948551   0.08089384  0.15179443 -0.40825844]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 1116. State = [[-0.02555309  0.2875096 ]]. Action = [[ 0.08710507 -0.05662759  0.06041399  0.05637193]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 1117. State = [[-0.02487523  0.28599524]]. Action = [[-0.11816174  0.20764244  0.18453622  0.1543566 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 1118. State = [[-0.02535741  0.28009462]]. Action = [[-0.17066936 -0.13213247  0.15740329  0.2612362 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 1119. State = [[-0.03104582  0.26394823]]. Action = [[-0.21088256 -0.19848864 -0.04641035  0.40781355]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 1120. State = [[-0.04111488  0.2456048 ]]. Action = [[ 0.16694221 -0.05533507 -0.22288044  0.8167057 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 1121. State = [[-0.04082575  0.23824386]]. Action = [[-0.11496696 -0.02843207  0.1272386   0.01496375]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 1122. State = [[-0.04908128  0.24059324]]. Action = [[-0.09178737  0.08076745  0.17953235 -0.90097964]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 1123. State = [[-0.0586303   0.25530735]]. Action = [[ 0.06437695  0.23641637  0.19170839 -0.8719794 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 1124. State = [[-0.06248344  0.2729099 ]]. Action = [[ 0.12506485  0.10928321  0.07329151 -0.3201484 ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 1125. State = [[-0.05854489  0.2800462 ]]. Action = [[-0.1706611   0.19496942  0.2385456   0.8134471 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 1126. State = [[-0.05556929  0.28394762]]. Action = [[ 0.11508089  0.05478427 -0.16716158  0.13937843]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 1127. State = [[-0.05014765  0.28753605]]. Action = [[-0.10098264 -0.08482224  0.20362315  0.5755966 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 1128. State = [[-0.0529562   0.29082552]]. Action = [[-0.1110571   0.05288321 -0.22997883  0.42418766]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 1129. State = [[-0.05437416  0.28535038]]. Action = [[-0.03427964 -0.17032087 -0.18325181 -0.6657317 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 1130. State = [[-0.05705958  0.26884237]]. Action = [[-0.08099821 -0.14666383 -0.03546381 -0.14592063]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 1131. State = [[-0.06831113  0.25554192]]. Action = [[-0.17457624 -0.04975107 -0.07128948 -0.9370558 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 1132. State = [[-0.07628077  0.24861702]]. Action = [[ 0.16111949 -0.01379631 -0.16346228  0.09200251]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 1133. State = [[-0.07998212  0.23863588]]. Action = [[-0.23128717 -0.14427112  0.08098564 -0.36959183]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 1134. State = [[-0.08561443  0.21608473]]. Action = [[ 0.21489036 -0.14148724 -0.08935344  0.23115659]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 1135. State = [[-0.0766921   0.19984448]]. Action = [[ 0.06392592 -0.05310799  0.21863854 -0.7950019 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 1136. State = [[-0.06753066  0.18064143]]. Action = [[ 0.09751928 -0.20068435 -0.11387429  0.44242978]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 1137. State = [[-0.05690882  0.16048843]]. Action = [[ 0.013347   -0.05094473  0.15742862 -0.505969  ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 1138. State = [[-0.04966483  0.14583874]]. Action = [[ 0.10897735 -0.123584    0.07460782 -0.23469889]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 1139. State = [[-0.04693826  0.12953274]]. Action = [[-0.13205661 -0.09421527  0.22348815 -0.01346612]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 1140. State = [[-0.05569153  0.10720864]]. Action = [[-0.13869452 -0.22716598  0.07729313 -0.34170485]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 1141. State = [[-0.07535257  0.09276342]]. Action = [[-0.23796389  0.06325155 -0.11996275 -0.5416382 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 1142. State = [[-0.10624661  0.0868988 ]]. Action = [[-0.17051089 -0.08021575  0.07519242  0.61792827]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 1143. State = [[-0.12098074  0.0781046 ]]. Action = [[ 0.14952707 -0.02206768 -0.21475023  0.8988675 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 1144. State = [[-0.11961329  0.07729043]]. Action = [[-0.04873575  0.01376918  0.15287107  0.7705674 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 1145. State = [[-0.12072249  0.07967519]]. Action = [[-0.00402516  0.05264786  0.10505593 -0.24112928]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 1146. State = [[-0.11694017  0.08622009]]. Action = [[ 0.20541662  0.10660553 -0.05741793  0.61935854]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 1147. State = [[-0.10743743  0.09254064]]. Action = [[ 0.14049426  0.01394901 -0.13497129  0.4360162 ]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 1148. State = [[-0.09922352  0.10451724]]. Action = [[-0.03960134  0.1445396  -0.242009   -0.17047101]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 1149. State = [[-0.10149134  0.11580849]]. Action = [[-0.04275511  0.05375034  0.03727356  0.00692165]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 1150. State = [[-0.10435365  0.11131011]]. Action = [[-0.10629341 -0.21388327 -0.2402482   0.22418976]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 1151. State = [[-0.11161568  0.11799628]]. Action = [[-0.18210211  0.24759555  0.07757908  0.5826572 ]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 1152. State = [[-0.13307129  0.13148542]]. Action = [[-0.20734027 -0.02664456  0.20109239 -0.10031843]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 1153. State = [[-0.14155556  0.13463119]]. Action = [[ 0.24487248  0.04503587  0.09083778 -0.48440337]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 1154. State = [[-0.14003244  0.13832717]]. Action = [[-0.0169653   0.07127631  0.23156098 -0.2099188 ]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 1155. State = [[-0.14059024  0.1513165 ]]. Action = [[ 0.01758122  0.18624967 -0.12269792 -0.27617884]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 1156. State = [[-0.1349003  0.1639689]]. Action = [[ 0.14668053 -0.0082009  -0.12306342  0.5321121 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 1157. State = [[-0.11894936  0.17914973]]. Action = [[ 0.16501474  0.17736924  0.24869388 -0.60110664]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 1158. State = [[-0.09727304  0.19548789]]. Action = [[0.18616626 0.04990172 0.23088369 0.6923318 ]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 1159. State = [[-0.07238591  0.2131151 ]]. Action = [[0.21078682 0.18710238 0.21051785 0.35713482]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 1160. State = [[-0.05321153  0.23510082]]. Action = [[-0.05865322  0.10716566 -0.06043252  0.31762254]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 1161. State = [[-0.04608923  0.25279465]]. Action = [[0.13063174 0.1479125  0.23512763 0.557641  ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 1162. State = [[-0.03705113  0.26682746]]. Action = [[-0.03263299 -0.00044239 -0.23592396  0.15271032]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 1163. State = [[-0.03049015  0.27773616]]. Action = [[0.22073334 0.19099766 0.13862953 0.7815839 ]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 1164. State = [[-0.00872099  0.28970268]]. Action = [[ 0.06642923 -0.04432294  0.20032305 -0.04612273]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 1165. State = [[0.00272917 0.29138002]]. Action = [[ 0.22103086  0.09589413 -0.23491289 -0.4460262 ]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 1166. State = [[0.0057845 0.2919829]]. Action = [[0.05369034 0.16004768 0.02113134 0.15653694]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 1167. State = [[0.01075074 0.28679436]]. Action = [[ 0.1212858  -0.06400734  0.08472654  0.4656105 ]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 1168. State = [[0.02656619 0.2796504 ]]. Action = [[ 0.15717238 -0.01873609 -0.2017901   0.23853087]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 1169. State = [[0.04283563 0.27908152]]. Action = [[ 0.23734438 -0.19049132  0.07907254 -0.52089596]]. Reward = [0.]
Curr episode timestep = 102
Current timestep = 1170. State = [[0.04451104 0.28127557]]. Action = [[-0.13575128 -0.0007114  -0.23661397 -0.49209452]]. Reward = [0.]
Curr episode timestep = 103
Current timestep = 1171. State = [[0.04612483 0.2751014 ]]. Action = [[-0.03426731 -0.15885581 -0.22879377  0.8187281 ]]. Reward = [0.]
Curr episode timestep = 104
Current timestep = 1172. State = [[0.0462251  0.26757586]]. Action = [[ 0.19546562  0.18417734  0.13262436 -0.03378689]]. Reward = [0.]
Curr episode timestep = 105
Current timestep = 1173. State = [[0.04002969 0.27780956]]. Action = [[-0.12642075  0.18169826 -0.09720238 -0.04362631]]. Reward = [0.]
Curr episode timestep = 106
Current timestep = 1174. State = [[0.03309146 0.2894096 ]]. Action = [[0.15200359 0.20424694 0.24810001 0.22392797]]. Reward = [0.]
Curr episode timestep = 107
Current timestep = 1175. State = [[0.03210236 0.29111272]]. Action = [[ 0.16062686  0.23482668  0.0763436  -0.1258899 ]]. Reward = [0.]
Curr episode timestep = 108
Current timestep = 1176. State = [[0.02610108 0.29582474]]. Action = [[-0.150856    0.02815834 -0.03437586 -0.20940566]]. Reward = [0.]
Curr episode timestep = 109
Current timestep = 1177. State = [[0.0077425  0.30047384]]. Action = [[-0.18780388  0.0011332   0.15703821  0.04552996]]. Reward = [0.]
Curr episode timestep = 110
Current timestep = 1178. State = [[-0.0204812   0.30261415]]. Action = [[-0.24197623 -0.01012674 -0.20265858  0.0178839 ]]. Reward = [0.]
Curr episode timestep = 111
Current timestep = 1179. State = [[-0.04312506  0.30164483]]. Action = [[ 0.1828675   0.1881657  -0.19175068 -0.53798383]]. Reward = [0.]
Curr episode timestep = 112
Current timestep = 1180. State = [[-0.04749634  0.3002143 ]]. Action = [[ 0.09437129  0.12117541  0.23482856 -0.8716737 ]]. Reward = [0.]
Curr episode timestep = 113
Current timestep = 1181. State = [[-0.04784558  0.29991576]]. Action = [[-0.05731015  0.0914734   0.23723751  0.28704906]]. Reward = [0.]
Curr episode timestep = 114
Current timestep = 1182. State = [[-0.0430681  0.295148 ]]. Action = [[ 0.18958363 -0.04730973 -0.22664507 -0.7525279 ]]. Reward = [0.]
Curr episode timestep = 115
Current timestep = 1183. State = [[-0.03161417  0.2816018 ]]. Action = [[ 0.15950501 -0.13769938 -0.17524733 -0.5593278 ]]. Reward = [0.]
Curr episode timestep = 116
Current timestep = 1184. State = [[-0.02259581  0.26791462]]. Action = [[ 0.22801018  0.21273702  0.19083014 -0.31155884]]. Reward = [0.]
Curr episode timestep = 117
Current timestep = 1185. State = [[-0.01324393  0.25344563]]. Action = [[ 0.24058169 -0.22522594  0.24239638 -0.5738152 ]]. Reward = [0.]
Curr episode timestep = 118
Current timestep = 1186. State = [[0.00868038 0.23218651]]. Action = [[ 0.07017967 -0.0016202  -0.03425586  0.86633253]]. Reward = [0.]
Curr episode timestep = 119
Current timestep = 1187. State = [[0.01417425 0.23205273]]. Action = [[-0.06311718  0.06214046 -0.1876867  -0.7929409 ]]. Reward = [0.]
Curr episode timestep = 120
Current timestep = 1188. State = [[0.0148242  0.24827977]]. Action = [[ 0.0337677   0.21762732 -0.23440237  0.74869955]]. Reward = [0.]
Curr episode timestep = 121
Current timestep = 1189. State = [[0.01436072 0.2635331 ]]. Action = [[-0.17056488 -0.04012969  0.21210587 -0.9191519 ]]. Reward = [0.]
Curr episode timestep = 122
Current timestep = 1190. State = [[0.00506683 0.2761152 ]]. Action = [[-0.16299298  0.10864151 -0.14160231 -0.6116692 ]]. Reward = [0.]
Curr episode timestep = 123
Current timestep = 1191. State = [[-0.00516693  0.2789138 ]]. Action = [[ 0.08776897 -0.08374369  0.22605479 -0.6204259 ]]. Reward = [0.]
Curr episode timestep = 124
Current timestep = 1192. State = [[-0.00419724  0.27660802]]. Action = [[0.2371844  0.22407955 0.07352674 0.25221086]]. Reward = [0.]
Curr episode timestep = 125
Current timestep = 1193. State = [[-0.19964758 -0.06969565]]. Action = [[0.0225957  0.17334831 0.24170649 0.7604276 ]]. Reward = [0.]
Curr episode timestep = 126
Current timestep = 1194. State = [[-0.18911359 -0.07671995]]. Action = [[ 0.04250407  0.00560799 -0.10049328 -0.6728168 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1195. State = [[-0.17500232 -0.07570797]]. Action = [[ 0.23024493  0.03864309  0.0793314  -0.23072797]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1196. State = [[-0.14711654 -0.07620943]]. Action = [[ 0.16787854  0.00932276 -0.07712722  0.40422225]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1197. State = [[-0.1259433  -0.08791917]]. Action = [[ 0.06329042 -0.21663228 -0.09292215 -0.41240227]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1198. State = [[-0.11883005 -0.08914819]]. Action = [[-0.08026703  0.19318023 -0.17282096  0.87082267]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1199. State = [[-0.11016849 -0.07715491]]. Action = [[0.24872974 0.06857115 0.22760653 0.47951508]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1200. State = [[-0.09592576 -0.0623128 ]]. Action = [[-0.04293951  0.14671701  0.21418905  0.25414968]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1201. State = [[-0.09757134 -0.05017251]]. Action = [[-0.11800197  0.01195297  0.23858345 -0.38230288]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1202. State = [[-0.09817367 -0.04165575]]. Action = [[ 0.1317774   0.09634268  0.15117913 -0.6182033 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1203. State = [[-0.08966839 -0.02836062]]. Action = [[0.15790266 0.10146827 0.20225245 0.2530501 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1204. State = [[-0.07766862 -0.01777807]]. Action = [[-0.04587162  0.04257789 -0.00349204 -0.56769556]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1205. State = [[-0.06825629 -0.01596477]]. Action = [[ 0.19889814 -0.05309103  0.11010885 -0.5529036 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1206. State = [[-0.05823402 -0.02554113]]. Action = [[-0.20186554 -0.14264308  0.21390861  0.48282993]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1207. State = [[-0.06835686 -0.02241869]]. Action = [[-0.18727909  0.21882373 -0.21762928 -0.47566533]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1208. State = [[-0.07772091 -0.01573393]]. Action = [[ 0.05886158 -0.1127872  -0.06116278  0.56952286]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1209. State = [[-0.0785154  -0.01806778]]. Action = [[-0.00699188  0.05107602  0.19594163  0.44402504]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1210. State = [[-0.07414538 -0.00604599]]. Action = [[ 0.2236892  0.1699017  0.2219882 -0.2821753]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1211. State = [[-0.06575008 -0.00685618]]. Action = [[-0.00916295 -0.20032671 -0.14344157  0.8963213 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1212. State = [[-0.0658554  -0.00374559]]. Action = [[-0.02073699  0.19862777 -0.1821789  -0.20646125]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1213. State = [[-0.06451336  0.01477383]]. Action = [[0.08854902 0.14858836 0.06522238 0.35091496]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1214. State = [[-0.06084608  0.02434294]]. Action = [[-0.16444936 -0.03604986 -0.00203824  0.8080244 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 1215. State = [[-0.05863938  0.03578879]]. Action = [[ 0.22274613  0.18250737 -0.23659082  0.94085264]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 1216. State = [[-0.04199827  0.03677718]]. Action = [[ 0.18691665 -0.17872113  0.21581578  0.63085985]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 1217. State = [[-0.2625689   0.00793257]]. Action = [[-0.17906067 -0.20577262  0.18399608  0.07743454]]. Reward = [100.]
Curr episode timestep = 23
Current timestep = 1218. State = [[-0.25485042  0.01157876]]. Action = [[0.20539895 0.05388921 0.18903804 0.688625  ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1219. State = [[-0.24317673  0.00594857]]. Action = [[-0.02609816 -0.1946901  -0.09264508  0.8341465 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1220. State = [[-0.23462977  0.0054774 ]]. Action = [[0.20138228 0.18042529 0.03127176 0.7504327 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1221. State = [[-0.21317272  0.01075618]]. Action = [[ 0.12666452 -0.0356622   0.13646135 -0.7718191 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1222. State = [[-0.1937979   0.00265557]]. Action = [[ 0.13276207 -0.150614    0.02033496 -0.17784303]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1223. State = [[-0.17054652 -0.0050379 ]]. Action = [[ 0.23339173 -0.00884856 -0.14573781 -0.34801722]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1224. State = [[-0.15331478 -0.00643095]]. Action = [[-0.07332493  0.01116347  0.11765882  0.26754797]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1225. State = [[-0.14657375 -0.00631335]]. Action = [[ 0.14625007  0.01251408 -0.01349594  0.6307788 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1226. State = [[-0.12944078  0.00194261]]. Action = [[ 0.15485126  0.15229407 -0.17083502 -0.51872313]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1227. State = [[-0.11885477  0.01657206]]. Action = [[-0.08960465  0.09213877  0.1135723   0.25380087]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1228. State = [[-0.12201206  0.02720866]]. Action = [[0.01057839 0.05644324 0.04831415 0.6369376 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1229. State = [[-0.11597929  0.02056006]]. Action = [[ 0.11135933 -0.20222342 -0.13820307 -0.84086585]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1230. State = [[-0.10178635  0.00602149]]. Action = [[ 0.12372431 -0.098977    0.15005255 -0.17720032]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1231. State = [[-0.08297687 -0.00868805]]. Action = [[ 0.15534729 -0.09800959  0.13651407 -0.4091618 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1232. State = [[-0.06755679 -0.01559997]]. Action = [[0.00391498 0.00797585 0.16369635 0.98457766]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1233. State = [[-0.05595307 -0.02334418]]. Action = [[ 0.2172203  -0.09940921  0.19259584 -0.03421229]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1234. State = [[-0.04282365 -0.04014035]]. Action = [[-0.20633498 -0.14508839  0.0239788  -0.5021126 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1235. State = [[-0.04540657 -0.06453408]]. Action = [[ 0.00125018 -0.20505424 -0.13568705 -0.5994223 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1236. State = [[-0.04656    -0.09361082]]. Action = [[ 0.02167955 -0.21467772 -0.06517421 -0.5372257 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1237. State = [[-0.04565303 -0.10829844]]. Action = [[-0.00858679  0.06421989  0.22674084  0.5156534 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1238. State = [[-0.04594576 -0.11769604]]. Action = [[-0.01037607 -0.15001379  0.2061221   0.40124953]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 1239. State = [[-0.04499523 -0.11464535]]. Action = [[ 0.059434    0.22262895 -0.11132821  0.7701614 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 1240. State = [[-0.03528761 -0.11559103]]. Action = [[ 0.2407952  -0.22054748  0.10247073  0.19261575]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 1241. State = [[-0.01469611 -0.11205882]]. Action = [[ 0.12547565  0.23263037  0.05648303 -0.05613035]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 1242. State = [[ 0.0039925  -0.11325792]]. Action = [[ 0.13203195 -0.2001846   0.1616692   0.24280071]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 1243. State = [[ 0.01542872 -0.11454087]]. Action = [[-0.09611645  0.1330781   0.05920422 -0.4755546 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 1244. State = [[ 0.01565673 -0.10735182]]. Action = [[ 0.05472654  0.04623178  0.04105568 -0.4870726 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 1245. State = [[ 0.02413714 -0.10492107]]. Action = [[ 0.18454164 -0.04358211 -0.11561719 -0.15541476]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 1246. State = [[ 0.04198988 -0.1077978 ]]. Action = [[ 0.04701155 -0.04397018  0.23324943 -0.5181265 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 1247. State = [[ 0.04632807 -0.11866191]]. Action = [[-0.18969375 -0.11697894  0.13382068  0.4935578 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 1248. State = [[ 0.03908324 -0.11991079]]. Action = [[-0.2257804   0.13932657 -0.05696848  0.65791106]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 1249. State = [[ 0.02350972 -0.10723229]]. Action = [[-0.06853989  0.09116656 -0.23364425  0.47058344]]. Reward = [0.]
Curr episode timestep = 31
