Current timestep = 0. State = [[-0.22204866  0.00807698]]. Action = [[-0.06810179 -0.1812338  -0.22207685  0.43036366]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [True, False, False, False, True, False]
State prediction error at timestep 0 is tensor(0.0380, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 0 of 1
Current timestep = 1. State = [[-0.21418251  0.00207185]]. Action = [[ 0.23785993  0.10886186 -0.19512782 -0.06584024]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False]
State prediction error at timestep 1 is tensor(0.0306, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1 of 1
Current timestep = 2. State = [[-0.19507186  0.00299381]]. Action = [[-0.02721393 -0.09778586  0.11797369  0.03992236]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, True, False]
State prediction error at timestep 2 is tensor(0.0200, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 2 of 1
Current timestep = 3. State = [[-0.18553992  0.00229903]]. Action = [[ 0.23990431  0.09158725  0.18618488 -0.4769491 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, True, False]
State prediction error at timestep 3 is tensor(0.0138, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3 of 1
Current timestep = 4. State = [[-0.16511618  0.0033634 ]]. Action = [[-0.05958381 -0.07774019  0.2394095  -0.39588666]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, True, False]
State prediction error at timestep 4 is tensor(0.0068, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 4 of 1
Current timestep = 5. State = [[-0.16860585 -0.0092742 ]]. Action = [[-0.11773887 -0.15836321 -0.13532141  0.77178764]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, True, False]
State prediction error at timestep 5 is tensor(0.0088, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 5 of -1
Current timestep = 6. State = [[-0.17471813 -0.01114043]]. Action = [[-0.00944611  0.21505961  0.15974867  0.749715  ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, True, False]
State prediction error at timestep 6 is tensor(0.0090, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 6 of -1
Current timestep = 7. State = [[-0.18208507  0.00818382]]. Action = [[-0.13192293  0.04049435  0.02247968  0.2293638 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, True, False]
State prediction error at timestep 7 is tensor(0.0055, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7 of -1
Current timestep = 8. State = [[-0.18983407  0.02460177]]. Action = [[-0.05386041  0.20781839  0.09907216  0.60117435]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, True, False]
State prediction error at timestep 8 is tensor(0.0050, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 8 of -1
Current timestep = 9. State = [[-0.20618242  0.03418395]]. Action = [[-0.19476332 -0.1596797  -0.23561877 -0.83067787]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, True, False]
State prediction error at timestep 9 is tensor(0.0046, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 9 of -1
Current timestep = 10. State = [[-0.2265885   0.02254212]]. Action = [[-0.10054579  0.02920529 -0.22584565  0.22213316]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, True, False]
State prediction error at timestep 10 is tensor(0.0050, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 10 of -1
Current timestep = 11. State = [[-0.24364606  0.03701898]]. Action = [[-0.09605496  0.20735192  0.0109452  -0.04803675]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, True, False]
State prediction error at timestep 11 is tensor(0.0064, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 11 of -1
Current timestep = 12. State = [[-0.25785124  0.06613369]]. Action = [[-0.03382292  0.17833167  0.02847508  0.7911501 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, True, False]
State prediction error at timestep 12 is tensor(0.0066, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 12 of -1
Current timestep = 13. State = [[-0.25459838  0.09268484]]. Action = [[ 0.23758218  0.21527696 -0.13655566 -0.7472757 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, True, False]
State prediction error at timestep 13 is tensor(0.0102, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 13 of -1
Current timestep = 14. State = [[-0.24553825  0.09978218]]. Action = [[-0.1416526  -0.17615223  0.01565564  0.20436656]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, True, False]
State prediction error at timestep 14 is tensor(0.0063, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 14 of -1
Current timestep = 15. State = [[-0.2530589   0.10033514]]. Action = [[-0.09512755  0.1823667  -0.19562835 -0.66622925]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, True, False]
State prediction error at timestep 15 is tensor(0.0085, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 15 of -1
Current timestep = 16. State = [[-0.26357886  0.11804315]]. Action = [[-0.00266725  0.05751744 -0.20970398 -0.05505222]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, True, False]
State prediction error at timestep 16 is tensor(0.0092, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 16 of -1
Current timestep = 17. State = [[-0.2654728   0.12129661]]. Action = [[-0.23075709 -0.001279   -0.0186815  -0.02753425]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, True, False]
State prediction error at timestep 17 is tensor(0.0077, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 17 of -1
Current timestep = 18. State = [[-0.26250756  0.13126145]]. Action = [[0.13679859 0.18200225 0.09572458 0.29985845]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, False, True]
State prediction error at timestep 18 is tensor(0.0082, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 18 of 1
Current timestep = 19. State = [[-0.25924793  0.13993716]]. Action = [[-0.03693104 -0.0867874  -0.03908737  0.86655366]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, False, True]
State prediction error at timestep 19 is tensor(0.0049, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 19 of -1
Current timestep = 20. State = [[-0.26222154  0.14177538]]. Action = [[-0.1015294   0.06260723 -0.19156903 -0.54676485]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, False, True]
State prediction error at timestep 20 is tensor(0.0099, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 20 of -1
Current timestep = 21. State = [[-0.2664742   0.14494161]]. Action = [[-0.15169553  0.07172152  0.15714192  0.56450534]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, False, True]
State prediction error at timestep 21 is tensor(0.0051, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 21 of -1
Current timestep = 22. State = [[-0.26654404  0.15653905]]. Action = [[ 0.11464015  0.2252954  -0.0978038  -0.785154  ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [True, False, False, False, False, True]
State prediction error at timestep 22 is tensor(0.0100, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 22 of -1
Current timestep = 23. State = [[-0.26551     0.17181015]]. Action = [[-0.20568496  0.19803128  0.19888791  0.8960111 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [True, False, False, False, False, True]
State prediction error at timestep 23 is tensor(0.0049, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 23 of -1
Current timestep = 24. State = [[-0.2657267   0.17252544]]. Action = [[-0.10331577 -0.20799658 -0.13616656  0.936033  ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [True, False, False, False, False, True]
State prediction error at timestep 24 is tensor(0.0040, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 24 of -1
Current timestep = 25. State = [[-0.25491598  0.1663255 ]]. Action = [[ 0.2046012  -0.13010797  0.19855088 -0.9061924 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [True, False, False, False, False, True]
State prediction error at timestep 25 is tensor(0.0099, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 25 of 1
Current timestep = 26. State = [[-0.23899426  0.14937842]]. Action = [[-0.15447272 -0.2091645   0.03809503 -0.06766975]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [True, False, False, False, False, True]
State prediction error at timestep 26 is tensor(0.0046, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 26 of 1
Current timestep = 27. State = [[-0.23825221  0.1387026 ]]. Action = [[ 0.1689853   0.15491432 -0.12942427 -0.87976766]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [True, False, False, False, False, True]
State prediction error at timestep 27 is tensor(0.0037, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 27 of 1
Current timestep = 28. State = [[-0.23683394  0.14215422]]. Action = [[-0.14746903 -0.15174828  0.1073983   0.41990542]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [True, False, False, False, False, True]
State prediction error at timestep 28 is tensor(0.0014, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 28 of 1
Current timestep = 29. State = [[-0.24085313  0.12909207]]. Action = [[-0.02495071 -0.07666487  0.0078814   0.40958977]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [True, False, False, False, False, True]
State prediction error at timestep 29 is tensor(0.0007, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 29 of 1
Current timestep = 30. State = [[-0.23796242  0.11142273]]. Action = [[ 0.06219864 -0.18775979  0.12553182 -0.89368176]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [True, False, False, False, True, False]
State prediction error at timestep 30 is tensor(0.0021, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 30 of 1
Current timestep = 31. State = [[-0.2293671  0.1040701]]. Action = [[0.23841926 0.16523886 0.12174597 0.07961547]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [True, False, False, False, True, False]
State prediction error at timestep 31 is tensor(0.0005, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 31 of 1
Current timestep = 32. State = [[-0.21818088  0.11278778]]. Action = [[-0.22771281 -0.04377191 -0.05838084  0.52992773]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [True, False, False, False, True, False]
State prediction error at timestep 32 is tensor(1.2490e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 32 of -1
Current timestep = 33. State = [[-0.23304386  0.12209465]]. Action = [[-0.111413    0.16224018 -0.10331932 -0.90338355]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [True, False, False, False, True, False]
State prediction error at timestep 33 is tensor(0.0016, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 33 of -1
Current timestep = 34. State = [[-0.24111117  0.13186051]]. Action = [[ 0.06310022 -0.07710958  0.17107433 -0.24101663]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [True, False, False, False, False, True]
State prediction error at timestep 34 is tensor(0.0023, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 34 of 1
Current timestep = 35. State = [[-0.24070354  0.12020253]]. Action = [[-0.06628868 -0.1164315  -0.16561155  0.8607583 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [True, False, False, False, True, False]
State prediction error at timestep 35 is tensor(5.3038e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 35 of 1
Current timestep = 36. State = [[-0.24674009  0.10561632]]. Action = [[-0.04717718 -0.06390554 -0.17955822 -0.84128535]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [True, False, False, False, True, False]
State prediction error at timestep 36 is tensor(0.0020, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 36 of -1
Current timestep = 37. State = [[-0.25386798  0.09726908]]. Action = [[-0.11260414 -0.09200647  0.20852476  0.7013223 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [True, False, False, False, True, False]
State prediction error at timestep 37 is tensor(0.0012, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 37 of 1
Current timestep = 38. State = [[-0.25916466  0.07709861]]. Action = [[ 0.17994434 -0.15182878 -0.223115    0.5972526 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [True, False, False, False, True, False]
State prediction error at timestep 38 is tensor(0.0012, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 38 of 1
Current timestep = 39. State = [[-0.2505251   0.06638786]]. Action = [[ 0.08481094  0.02182528 -0.05918941 -0.50889385]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [True, False, False, False, True, False]
State prediction error at timestep 39 is tensor(0.0024, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 39 of 1
Current timestep = 40. State = [[-0.24649824  0.06697865]]. Action = [[-0.1756964   0.01601198  0.09588543  0.8371334 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [True, False, False, False, True, False]
State prediction error at timestep 40 is tensor(0.0022, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 40 of 1
Current timestep = 41. State = [[-0.2501075   0.05727527]]. Action = [[-0.16429257 -0.16248873  0.17797235  0.3431201 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [True, False, False, False, True, False]
State prediction error at timestep 41 is tensor(0.0026, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 41 of -1
Current timestep = 42. State = [[-0.2510928   0.04374071]]. Action = [[0.14665943 0.07355368 0.13602465 0.54579306]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [True, False, False, False, True, False]
State prediction error at timestep 42 is tensor(0.0032, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 42 of 1
Current timestep = 43. State = [[-0.24861553  0.03542033]]. Action = [[-0.07277814 -0.2337505   0.11565089  0.66583204]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [True, False, False, False, True, False]
State prediction error at timestep 43 is tensor(0.0034, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 43 of -1
Current timestep = 44. State = [[-0.24494357  0.0270461 ]]. Action = [[0.12101972 0.15841618 0.17097908 0.01329982]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [True, False, False, False, True, False]
State prediction error at timestep 44 is tensor(0.0030, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 44 of 1
Current timestep = 45. State = [[-0.24205075  0.04696479]]. Action = [[ 0.01142338  0.19130236 -0.02300666  0.73516273]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [True, False, False, False, True, False]
State prediction error at timestep 45 is tensor(0.0025, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 45 of -1
Current timestep = 46. State = [[-0.22945188  0.05872541]]. Action = [[ 0.22057825 -0.08902949 -0.01837131  0.66196465]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [True, False, False, False, True, False]
State prediction error at timestep 46 is tensor(0.0008, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 46 of 1
Current timestep = 47. State = [[-0.20341645  0.0653995 ]]. Action = [[ 0.17002863  0.2071042  -0.02573802 -0.04596567]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [True, False, False, False, True, False]
State prediction error at timestep 47 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 47 of 1
Current timestep = 48. State = [[-0.17922303  0.08561332]]. Action = [[ 0.1952498   0.08665422 -0.06804742  0.68233085]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [True, False, False, False, True, False]
State prediction error at timestep 48 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 48 of 1
Current timestep = 49. State = [[-0.15333098  0.08451007]]. Action = [[ 0.08945969 -0.16097522  0.20166504 -0.4220847 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [True, False, False, False, True, False]
State prediction error at timestep 49 is tensor(0.0008, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 49 of 1
Current timestep = 50. State = [[-0.13953891  0.0597505 ]]. Action = [[ 0.12272531 -0.22696462  0.10195857  0.716589  ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [True, False, False, False, True, False]
State prediction error at timestep 50 is tensor(0.0026, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 50 of 1
Current timestep = 51. State = [[-0.13540395  0.04817787]]. Action = [[-0.16145761  0.1360226  -0.18312658 -0.87808967]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 51 is [True, False, False, False, True, False]
State prediction error at timestep 51 is tensor(0.0026, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 51 of -1
Current timestep = 52. State = [[-0.13532753  0.04436722]]. Action = [[ 0.1572128  -0.20696548 -0.01821363  0.66000056]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 52 is [True, False, False, False, True, False]
State prediction error at timestep 52 is tensor(0.0034, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 52 of 1
Current timestep = 53. State = [[-0.12922719  0.02576336]]. Action = [[-0.04012379 -0.07955778 -0.07712835  0.72465396]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 53 is [True, False, False, False, True, False]
State prediction error at timestep 53 is tensor(0.0041, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 53 of 1
Current timestep = 54. State = [[-0.11841892  0.03070918]]. Action = [[ 0.23537445  0.19628906 -0.22717957  0.7299584 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 54 is [True, False, False, False, True, False]
State prediction error at timestep 54 is tensor(0.0053, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 54 of 1
Current timestep = 55. State = [[-0.08990693  0.03002088]]. Action = [[ 0.16360718 -0.21963069  0.15676546  0.45927966]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 55 is [True, False, False, False, True, False]
State prediction error at timestep 55 is tensor(0.0074, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 55 of 1
Current timestep = 56. State = [[-0.07561048  0.01858993]]. Action = [[0.0338558  0.06741554 0.06794873 0.49732256]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 56 is [True, False, False, False, True, False]
State prediction error at timestep 56 is tensor(0.0089, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 56 of 1
Current timestep = 57. State = [[-0.06810369  0.0088493 ]]. Action = [[ 0.07118475 -0.22539651 -0.0029175  -0.12409461]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 57 is [True, False, False, False, True, False]
State prediction error at timestep 57 is tensor(0.0095, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 57 of 1
Current timestep = 58. State = [[-0.05311992  0.00156015]]. Action = [[ 0.17199197  0.15045232  0.05903417 -0.24066854]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 58 is [True, False, False, False, True, False]
State prediction error at timestep 58 is tensor(0.0125, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 58 of 1
Current timestep = 59. State = [[-0.20869468 -0.15410385]]. Action = [[ 0.11764395 -0.13060397  0.21257842 -0.8263734 ]]. Reward = [100.]
Curr episode timestep = 59
Scene graph at timestep 59 is [True, False, False, True, False, False]
State prediction error at timestep 59 is tensor(0.0241, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 59 of -1
Current timestep = 60. State = [[-0.20202772 -0.17047477]]. Action = [[-0.09717394 -0.00440887 -0.15324664 -0.14810258]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 60 is [True, False, False, True, False, False]
State prediction error at timestep 60 is tensor(0.0284, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 60 of -1
Current timestep = 61. State = [[-0.20725782 -0.17734072]]. Action = [[-0.06439649 -0.03497237  0.19390422 -0.09085673]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 61 is [True, False, False, True, False, False]
State prediction error at timestep 61 is tensor(0.0286, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 61 of -1
Current timestep = 62. State = [[-0.22148718 -0.1875032 ]]. Action = [[-0.23706722 -0.07095921  0.09088331  0.78524876]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 62 is [True, False, False, True, False, False]
State prediction error at timestep 62 is tensor(0.0309, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 62 of -1
Current timestep = 63. State = [[-0.24212728 -0.18663597]]. Action = [[-0.05621794  0.15904519 -0.0329254  -0.7373584 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 63 is [True, False, False, True, False, False]
State prediction error at timestep 63 is tensor(0.0366, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 63 of -1
Current timestep = 64. State = [[-0.2534304  -0.17344059]]. Action = [[-0.14387049  0.06607547 -0.05340426  0.59042764]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 64 is [True, False, False, True, False, False]
State prediction error at timestep 64 is tensor(0.0286, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 64 of -1
Current timestep = 65. State = [[-0.26743308 -0.16706048]]. Action = [[-0.12120521  0.22775048 -0.1641971   0.7704897 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 65 is [True, False, False, True, False, False]
State prediction error at timestep 65 is tensor(0.0294, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 65 of -1
Current timestep = 66. State = [[-0.26355392 -0.16866252]]. Action = [[ 0.16848695 -0.08469018  0.18050098 -0.9620437 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 66 is [True, False, False, True, False, False]
State prediction error at timestep 66 is tensor(0.0306, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 66 of -1
Current timestep = 67. State = [[-0.24777935 -0.1649547 ]]. Action = [[ 0.2205413   0.10554886  0.06619605 -0.86871433]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 67 is [True, False, False, True, False, False]
State prediction error at timestep 67 is tensor(0.0303, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 67 of 1
Current timestep = 68. State = [[-0.22127588 -0.16793168]]. Action = [[ 0.22906423 -0.18839467  0.1567162  -0.569142  ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 68 is [True, False, False, True, False, False]
State prediction error at timestep 68 is tensor(0.0248, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 68 of 1
Current timestep = 69. State = [[-0.20182884 -0.18888818]]. Action = [[-0.08047815 -0.14847048  0.2397905   0.65348077]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 69 is [True, False, False, True, False, False]
State prediction error at timestep 69 is tensor(0.0273, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 69 of -1
Current timestep = 70. State = [[-0.20242967 -0.2021845 ]]. Action = [[ 0.06944585 -0.03206934  0.0343973   0.6692414 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 70 is [True, False, False, True, False, False]
State prediction error at timestep 70 is tensor(0.0292, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 70 of -1
Current timestep = 71. State = [[-0.20287344 -0.20304948]]. Action = [[-0.15981525  0.06459564 -0.0848847   0.02233124]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 71 is [True, False, False, True, False, False]
State prediction error at timestep 71 is tensor(0.0319, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 71 of -1
Current timestep = 72. State = [[-0.22015198 -0.2146998 ]]. Action = [[-0.23820162 -0.19986832 -0.17284565 -0.9258742 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 72 is [True, False, False, True, False, False]
State prediction error at timestep 72 is tensor(0.0367, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 72 of -1
Current timestep = 73. State = [[-0.24774237 -0.23997326]]. Action = [[-0.18133275 -0.0894942   0.12808955 -0.11401635]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 73 is [True, False, False, True, False, False]
State prediction error at timestep 73 is tensor(0.0407, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 73 of -1
Current timestep = 74. State = [[-0.25951287 -0.23558226]]. Action = [[ 0.19047421  0.1967985  -0.22589915 -0.6020997 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 74 is [True, False, False, True, False, False]
State prediction error at timestep 74 is tensor(0.0441, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 74 of 1
Current timestep = 75. State = [[-0.24029282 -0.22334716]]. Action = [[ 0.20469838 -0.08864605  0.11596957 -0.42964625]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 75 is [True, False, False, True, False, False]
State prediction error at timestep 75 is tensor(0.0341, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 75 of 1
Current timestep = 76. State = [[-0.2286248  -0.23556732]]. Action = [[-0.03451088 -0.1589412  -0.13261797 -0.07656682]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 76 is [True, False, False, True, False, False]
State prediction error at timestep 76 is tensor(0.0356, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 76 of -1
Current timestep = 77. State = [[-0.22310472 -0.24871123]]. Action = [[ 0.14746433 -0.04074517  0.1257317  -0.7092106 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 77 is [True, False, False, True, False, False]
State prediction error at timestep 77 is tensor(0.0389, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 77 of -1
Current timestep = 78. State = [[-0.21240674 -0.26642644]]. Action = [[-0.0348056  -0.20601185 -0.05936615  0.3542472 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 78 is [True, False, False, True, False, False]
State prediction error at timestep 78 is tensor(0.0391, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 78 of -1
Current timestep = 79. State = [[-0.22103386 -0.2825045 ]]. Action = [[-0.22045003  0.05654672  0.10132056 -0.33418953]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 79 is [True, False, False, True, False, False]
State prediction error at timestep 79 is tensor(0.0470, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 79 of -1
Current timestep = 80. State = [[-0.22792248 -0.27687517]]. Action = [[0.11671889 0.13192928 0.1814853  0.47381806]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 80 is [True, False, False, True, False, False]
State prediction error at timestep 80 is tensor(0.0401, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 80 of 1
Current timestep = 81. State = [[-0.21395487 -0.26660427]]. Action = [[ 0.2435723  -0.04840447  0.00277054  0.62785935]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 81 is [True, False, False, True, False, False]
State prediction error at timestep 81 is tensor(0.0339, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 81 of 1
Current timestep = 82. State = [[-0.1899701  -0.26994574]]. Action = [[ 0.1752963  -0.11600544 -0.18483736  0.54314685]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 82 is [True, False, False, True, False, False]
State prediction error at timestep 82 is tensor(0.0341, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 82 of 1
Current timestep = 83. State = [[-0.17058383 -0.27887934]]. Action = [[ 0.0149177  -0.24514298  0.19983023 -0.64490014]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 83 is [True, False, False, True, False, False]
State prediction error at timestep 83 is tensor(0.0376, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 83 of 1
Current timestep = 84. State = [[-0.17256261 -0.27375168]]. Action = [[-0.13782552  0.166893   -0.18586932 -0.34352803]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 84 is [True, False, False, True, False, False]
State prediction error at timestep 84 is tensor(0.0375, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 84 of 1
Current timestep = 85. State = [[-0.17259678 -0.27515608]]. Action = [[ 0.11138761 -0.16432533  0.04915872  0.12434459]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 85 is [True, False, False, True, False, False]
State prediction error at timestep 85 is tensor(0.0328, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 85 of -1
Current timestep = 86. State = [[-0.16098633 -0.28883338]]. Action = [[ 0.24059969 -0.17639334  0.03842887 -0.84913737]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 86 is [True, False, False, True, False, False]
State prediction error at timestep 86 is tensor(0.0365, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 86 of 1
Current timestep = 87. State = [[-0.13935967 -0.297731  ]]. Action = [[-0.03148076  0.1458664   0.09891415  0.52839994]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 87 is [True, False, False, True, False, False]
State prediction error at timestep 87 is tensor(0.0384, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 87 of 1
Current timestep = 88. State = [[-0.13559875 -0.29021898]]. Action = [[ 0.09059921  0.02147537 -0.19812892 -0.31025815]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 88 is [True, False, False, True, False, False]
State prediction error at timestep 88 is tensor(0.0374, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 88 of 1
Current timestep = 89. State = [[-0.11963121 -0.28755063]]. Action = [[ 0.2435826  -0.04417828  0.06638685  0.9177116 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 89 is [True, False, False, True, False, False]
State prediction error at timestep 89 is tensor(0.0342, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 89 of 1
Current timestep = 90. State = [[-0.08764719 -0.2921416 ]]. Action = [[ 0.15314263 -0.01902191  0.23676383 -0.73049694]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 90 is [True, False, False, True, False, False]
State prediction error at timestep 90 is tensor(0.0396, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 90 of 1
Current timestep = 91. State = [[-0.07373449 -0.28699526]]. Action = [[-0.12052971  0.17016625  0.17821598 -0.17795038]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 91 is [True, False, False, True, False, False]
State prediction error at timestep 91 is tensor(0.0392, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 91 of 1
Current timestep = 92. State = [[-0.06757078 -0.28262085]]. Action = [[ 0.24534914 -0.15553017  0.13111576  0.21972764]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 92 is [True, False, False, True, False, False]
State prediction error at timestep 92 is tensor(0.0326, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 92 of 1
Current timestep = 93. State = [[-0.05492111 -0.28814816]]. Action = [[ 0.05668145 -0.16569512  0.23562866 -0.4876144 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 93 is [True, False, False, True, False, False]
State prediction error at timestep 93 is tensor(0.0400, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 93 of 1
Current timestep = 94. State = [[-0.04692031 -0.28264552]]. Action = [[0.18091395 0.093027   0.24541017 0.77846384]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 94 is [False, True, False, True, False, False]
State prediction error at timestep 94 is tensor(0.0362, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 94 of 1
Current timestep = 95. State = [[-0.02687929 -0.28172073]]. Action = [[ 0.0076623  -0.2296743   0.17616093  0.7114818 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 95 is [False, True, False, True, False, False]
State prediction error at timestep 95 is tensor(0.0399, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 95 of 1
Current timestep = 96. State = [[-0.02633271 -0.28163475]]. Action = [[-0.09036499 -0.2086535  -0.02018428  0.4662211 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 96 is [False, True, False, True, False, False]
State prediction error at timestep 96 is tensor(0.0363, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 96 of 1
Current timestep = 97. State = [[-0.01993149 -0.27065158]]. Action = [[ 0.13455302  0.1773724   0.15158829 -0.71051246]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 97 is [False, True, False, True, False, False]
State prediction error at timestep 97 is tensor(0.0378, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 97 of 1
Current timestep = 98. State = [[-0.00834742 -0.24833493]]. Action = [[0.03462037 0.12456053 0.20674199 0.84061646]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 98 is [False, True, False, True, False, False]
State prediction error at timestep 98 is tensor(0.0333, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 98 of 1
Current timestep = 99. State = [[ 0.00320236 -0.24312262]]. Action = [[ 0.21878067 -0.14363313  0.00170499  0.794749  ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 99 is [False, True, False, True, False, False]
State prediction error at timestep 99 is tensor(0.0324, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 99 of -1
Current timestep = 100. State = [[ 0.03972329 -0.25540325]]. Action = [[ 0.15835956 -0.04178312  0.10799161 -0.6187284 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 100 is [False, True, False, True, False, False]
State prediction error at timestep 100 is tensor(0.0411, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 100 of -1
Current timestep = 101. State = [[ 0.05599425 -0.25886944]]. Action = [[0.19051355 0.05756092 0.13073474 0.71888256]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 101 is [False, False, True, True, False, False]
State prediction error at timestep 101 is tensor(0.0410, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 101 of -1
Current timestep = 102. State = [[ 0.05599425 -0.25886944]]. Action = [[ 0.20523486 -0.16309543  0.026173    0.206272  ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 102 is [False, False, True, True, False, False]
State prediction error at timestep 102 is tensor(0.0368, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 102 of -1
Current timestep = 103. State = [[ 0.05420494 -0.26498964]]. Action = [[-0.05944674 -0.07687154 -0.00703643 -0.8841396 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 103 is [False, False, True, True, False, False]
State prediction error at timestep 103 is tensor(0.0439, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 103 of -1
Current timestep = 104. State = [[ 0.05132024 -0.27152628]]. Action = [[ 0.15500462 -0.19081084 -0.17806555  0.27818108]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 104 is [False, False, True, True, False, False]
State prediction error at timestep 104 is tensor(0.0369, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 104 of -1
Current timestep = 105. State = [[ 0.05191394 -0.2656877 ]]. Action = [[-0.0322831   0.1274395   0.23965931 -0.1491803 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 105 is [False, False, True, True, False, False]
State prediction error at timestep 105 is tensor(0.0385, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 105 of -1
Current timestep = 106. State = [[ 0.05399698 -0.25044447]]. Action = [[-0.00550459  0.16141582 -0.129423    0.6341226 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 106 is [False, False, True, True, False, False]
State prediction error at timestep 106 is tensor(0.0341, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 106 of 1
Current timestep = 107. State = [[ 0.05419791 -0.23942398]]. Action = [[-1.1927988e-01 -3.2380223e-05  7.7488273e-02 -3.3583057e-01]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 107 is [False, False, True, True, False, False]
State prediction error at timestep 107 is tensor(0.0342, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 107 of -1
Current timestep = 108. State = [[ 0.05309034 -0.24055237]]. Action = [[ 0.19452223  0.15548748 -0.17115936  0.15555596]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 108 is [False, False, True, True, False, False]
State prediction error at timestep 108 is tensor(0.0281, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 108 of -1
Current timestep = 109. State = [[ 0.05365741 -0.2346345 ]]. Action = [[ 0.04217851  0.08405355  0.21202663 -0.87511206]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 109 is [False, False, True, True, False, False]
State prediction error at timestep 109 is tensor(0.0352, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 109 of 1
Current timestep = 110. State = [[ 0.04401743 -0.24136302]]. Action = [[-0.23650019 -0.2042293   0.24489743  0.34866226]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 110 is [False, True, False, True, False, False]
State prediction error at timestep 110 is tensor(0.0277, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 110 of -1
Current timestep = 111. State = [[ 0.02292007 -0.26781046]]. Action = [[-0.15483609 -0.13402778  0.14541638 -0.83755654]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 111 is [False, True, False, True, False, False]
State prediction error at timestep 111 is tensor(0.0325, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 111 of -1
Current timestep = 112. State = [[ 0.00925032 -0.285502  ]]. Action = [[ 0.13736647 -0.17126034  0.24232447  0.6232306 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 112 is [False, True, False, True, False, False]
State prediction error at timestep 112 is tensor(0.0263, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 112 of -1
Current timestep = 113. State = [[ 0.01610067 -0.2960841 ]]. Action = [[ 0.22140336 -0.0801526  -0.19367638 -0.3356328 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 113 is [False, True, False, True, False, False]
State prediction error at timestep 113 is tensor(0.0287, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 113 of -1
Current timestep = 114. State = [[ 0.02784896 -0.3010443 ]]. Action = [[ 0.15826404 -0.08767195  0.23926806 -0.01327133]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 114 is [False, True, False, True, False, False]
State prediction error at timestep 114 is tensor(0.0260, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 114 of -1
Current timestep = 115. State = [[ 0.02795344 -0.3011217 ]]. Action = [[ 0.10367423 -0.20948938  0.07293761 -0.64837927]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 115 is [False, True, False, True, False, False]
State prediction error at timestep 115 is tensor(0.0319, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 115 of -1
Current timestep = 116. State = [[ 0.02795344 -0.3011217 ]]. Action = [[ 0.2059694  -0.20337544  0.15189373  0.97293055]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 116 is [False, True, False, True, False, False]
State prediction error at timestep 116 is tensor(0.0297, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 116 of -1
Current timestep = 117. State = [[ 0.02794462 -0.30111986]]. Action = [[-0.13464406 -0.19653223 -0.07577747  0.01915956]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 117 is [False, True, False, True, False, False]
State prediction error at timestep 117 is tensor(0.0265, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 117 of -1
Current timestep = 118. State = [[ 0.02794462 -0.30111986]]. Action = [[ 0.06497848 -0.11780231  0.14071107 -0.8313744 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 119. State = [[ 0.03650976 -0.295075  ]]. Action = [[0.18708262 0.11358342 0.20027244 0.53002656]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 120. State = [[ 0.04666809 -0.29843923]]. Action = [[-0.22899975 -0.08448993  0.12542164  0.24960053]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 121. State = [[ 0.04438555 -0.3029911 ]]. Action = [[ 0.21798122 -0.04609676  0.09474766  0.96449375]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 122. State = [[ 0.04390207 -0.30384356]]. Action = [[-0.062001   -0.23673387 -0.04663056 -0.8870107 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 123. State = [[ 0.04392784 -0.30383214]]. Action = [[0.24751672 0.13507736 0.19219455 0.50621414]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 124. State = [[ 0.04385403 -0.3038434 ]]. Action = [[-0.10437971 -0.103138   -0.01938562  0.1857661 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 125. State = [[ 0.04385403 -0.3038434 ]]. Action = [[ 0.20501119  0.13772133 -0.08943874 -0.62059605]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 126. State = [[ 0.04385403 -0.3038434 ]]. Action = [[ 0.17641538  0.03377303  0.22070423 -0.5807707 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 127. State = [[ 0.04385403 -0.3038434 ]]. Action = [[ 0.17761886  0.18514168  0.17793518 -0.9975032 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 128. State = [[ 0.04390153 -0.30361152]]. Action = [[0.02266508 0.02420914 0.07364944 0.11743057]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 129. State = [[ 0.04528461 -0.2942875 ]]. Action = [[-0.02790278  0.1711328  -0.17268002  0.91510415]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 130. State = [[ 0.04714555 -0.28036606]]. Action = [[-0.00222021  0.05480629  0.10764086  0.6606828 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 131. State = [[ 0.04786082 -0.2760984 ]]. Action = [[ 0.13351727 -0.0776104   0.18424305  0.7663406 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 132. State = [[ 0.04794577 -0.27501327]]. Action = [[ 0.23165384 -0.10201557 -0.05671903  0.5099082 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 133. State = [[ 0.04792298 -0.27506918]]. Action = [[ 0.21466842 -0.11236072  0.18909922 -0.26026624]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 134. State = [[ 0.04792298 -0.27506918]]. Action = [[ 0.23518065 -0.02747251  0.19062907  0.05323124]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 135. State = [[ 0.04912615 -0.26741725]]. Action = [[ 0.06069618  0.0998041  -0.03978556 -0.41456634]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 136. State = [[ 0.0488922  -0.25571316]]. Action = [[-0.11736757  0.07439947  0.07154256 -0.93831444]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 137. State = [[ 0.04825545 -0.25524727]]. Action = [[ 0.08882028 -0.1142786   0.19023868 -0.95814365]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 138. State = [[ 0.04778406 -0.26119477]]. Action = [[ 0.08386606 -0.07892263  0.2058577   0.5713743 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 139. State = [[ 0.04864377 -0.26040035]]. Action = [[ 0.0389708   0.08987418 -0.02519438 -0.16194546]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 140. State = [[ 0.04911727 -0.25922936]]. Action = [[ 0.19954678 -0.09028265  0.18687415  0.54114795]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 141. State = [[ 0.04831471 -0.26789773]]. Action = [[ 0.00461957 -0.18041249  0.20365614 -0.86779964]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 142. State = [[ 0.04865215 -0.2759809 ]]. Action = [[ 0.07277748 -0.01878022  0.22838658 -0.8924706 ]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 143. State = [[ 0.04973629 -0.2774309 ]]. Action = [[ 0.21637386  0.12506247 -0.09265986  0.54489195]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 144. State = [[ 0.04977524 -0.27742714]]. Action = [[ 0.19496226 -0.17886533 -0.09116596  0.0480119 ]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 145. State = [[ 0.04747004 -0.28916213]]. Action = [[-0.10963103 -0.1751948   0.03450269 -0.5259426 ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 146. State = [[ 0.04462132 -0.30350375]]. Action = [[ 0.2311936  -0.03102301  0.14275777 -0.73953694]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 147. State = [[ 0.04427129 -0.30520684]]. Action = [[ 0.03671125 -0.09664999  0.2033866   0.24328756]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 148. State = [[ 0.04718045 -0.30280164]]. Action = [[ 0.12313896  0.05383047  0.0030295  -0.73198587]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 149. State = [[ 0.05482636 -0.30182546]]. Action = [[-0.17133236 -0.15688531  0.10759914 -0.41152108]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 149 is [False, False, True, True, False, False]
State prediction error at timestep 149 is tensor(0.0016, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 149 of -1
Current timestep = 150. State = [[ 0.05490819 -0.3016236 ]]. Action = [[-0.14006667 -0.1514525  -0.17537956 -0.32552844]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 150 is [False, False, True, True, False, False]
State prediction error at timestep 150 is tensor(0.0013, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 150 of -1
Current timestep = 151. State = [[ 0.05490819 -0.3016236 ]]. Action = [[-0.09436795 -0.13149951  0.03706664  0.4780568 ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 151 is [False, False, True, True, False, False]
State prediction error at timestep 151 is tensor(0.0023, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 151 of -1
Current timestep = 152. State = [[ 0.05490819 -0.3016236 ]]. Action = [[ 0.21003973 -0.05510437  0.00887918 -0.5799166 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 153. State = [[ 0.0549338  -0.30161196]]. Action = [[-0.19850127 -0.17170547 -0.13143675  0.65361214]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 154. State = [[ 0.05669545 -0.29158303]]. Action = [[-0.07258707  0.18904203 -0.1736755   0.5532222 ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 155. State = [[ 0.05818255 -0.2819476 ]]. Action = [[ 0.13537875  0.23121291  0.09842137 -0.05488682]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 156. State = [[ 0.05837211 -0.28084445]]. Action = [[ 0.23229492 -0.1946732   0.19474894 -0.91386044]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 157. State = [[ 0.05837378 -0.28069896]]. Action = [[ 0.06663397  0.23353964 -0.01580223 -0.5977726 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 158. State = [[ 0.05837378 -0.28069896]]. Action = [[-0.16136399 -0.24933653  0.22353235 -0.62337613]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 159. State = [[ 0.05892586 -0.2729623 ]]. Action = [[-0.08918492  0.13456511  0.1376439  -0.06912291]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 160. State = [[ 0.05887247 -0.2616019 ]]. Action = [[-0.03607029  0.04634172 -0.09652345 -0.6650795 ]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 161. State = [[ 0.05559729 -0.26587096]]. Action = [[ 0.00996521 -0.16343315  0.03464657  0.5713644 ]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 162. State = [[ 0.05145386 -0.26314974]]. Action = [[-0.12281311  0.18752635  0.0313639   0.05095041]]. Reward = [0.]
Curr episode timestep = 102
Current timestep = 163. State = [[ 0.04514156 -0.25428823]]. Action = [[ 0.18142176 -0.03138359 -0.07668835 -0.35416067]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 163 is [False, True, False, True, False, False]
State prediction error at timestep 163 is tensor(0.0008, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 163 of 1
Current timestep = 164. State = [[ 0.03789414 -0.2641999 ]]. Action = [[-0.15450153 -0.17642978 -0.14595264 -0.9181562 ]]. Reward = [0.]
Curr episode timestep = 104
Current timestep = 165. State = [[ 0.01502234 -0.2812819 ]]. Action = [[-0.17937614 -0.0846895  -0.03544781  0.38605082]]. Reward = [0.]
Curr episode timestep = 105
Current timestep = 166. State = [[ 0.00359543 -0.28473434]]. Action = [[ 0.13594162  0.03671905 -0.1293156  -0.31015253]]. Reward = [0.]
Curr episode timestep = 106
Current timestep = 167. State = [[ 0.00664215 -0.28308263]]. Action = [[ 0.1345833  -0.01342186  0.20774585 -0.34353864]]. Reward = [0.]
Curr episode timestep = 107
Current timestep = 168. State = [[ 0.0073488  -0.27276492]]. Action = [[-0.16672064  0.20024371  0.24252602 -0.82361513]]. Reward = [0.]
Curr episode timestep = 108
Current timestep = 169. State = [[ 0.00988735 -0.2511832 ]]. Action = [[ 0.10867348  0.13701051 -0.24110115 -0.66347975]]. Reward = [0.]
Curr episode timestep = 109
Current timestep = 170. State = [[ 0.01134172 -0.22767141]]. Action = [[-0.11749677  0.18295962  0.1809442   0.24213481]]. Reward = [0.]
Curr episode timestep = 110
Current timestep = 171. State = [[ 0.00985961 -0.20612858]]. Action = [[-0.03642532  0.11005387 -0.17760113  0.71881175]]. Reward = [0.]
Curr episode timestep = 111
Current timestep = 172. State = [[ 0.0044222  -0.19051898]]. Action = [[-0.07631513  0.07224062  0.02928424  0.01133347]]. Reward = [0.]
Curr episode timestep = 112
Current timestep = 173. State = [[-0.00085824 -0.18266936]]. Action = [[ 0.06357849  0.00542626 -0.13656223 -0.68895394]]. Reward = [0.]
Curr episode timestep = 113
Current timestep = 174. State = [[ 0.00100921 -0.17648344]]. Action = [[ 0.12946147  0.06002271 -0.06565306  0.96315837]]. Reward = [0.]
Curr episode timestep = 114
Current timestep = 175. State = [[ 0.00380053 -0.16628413]]. Action = [[-0.04922754  0.08038324  0.05339736 -0.6949504 ]]. Reward = [0.]
Curr episode timestep = 115
Current timestep = 176. State = [[-0.0016288  -0.17015888]]. Action = [[-0.15081455 -0.16012156  0.17625523 -0.1330517 ]]. Reward = [0.]
Curr episode timestep = 116
Current timestep = 177. State = [[-0.0055046  -0.19058648]]. Action = [[ 0.08921385 -0.23179327  0.22466376  0.24931979]]. Reward = [0.]
Curr episode timestep = 117
Current timestep = 178. State = [[-1.5048761e-04 -2.0441419e-01]]. Action = [[0.20497781 0.01401022 0.09605879 0.70196676]]. Reward = [0.]
Curr episode timestep = 118
Current timestep = 179. State = [[ 0.00310293 -0.19765599]]. Action = [[-0.06179106  0.16072291  0.1671735   0.76542926]]. Reward = [0.]
Curr episode timestep = 119
Current timestep = 180. State = [[ 0.00180645 -0.18004158]]. Action = [[-0.14961751  0.19712067 -0.07440411 -0.8158566 ]]. Reward = [0.]
Curr episode timestep = 120
Current timestep = 181. State = [[ 0.00207752 -0.15527624]]. Action = [[0.13125238 0.13132524 0.12306911 0.84497094]]. Reward = [0.]
Curr episode timestep = 121
Current timestep = 182. State = [[ 0.00611527 -0.1440694 ]]. Action = [[ 0.13495338 -0.01625186  0.16439784  0.39652038]]. Reward = [0.]
Curr episode timestep = 122
Current timestep = 183. State = [[ 0.02025308 -0.1451068 ]]. Action = [[ 0.21405256 -0.08670506  0.12780786 -0.2597679 ]]. Reward = [0.]
Curr episode timestep = 123
Current timestep = 184. State = [[ 0.04300954 -0.15678649]]. Action = [[ 0.1948179  -0.1697972   0.22007403 -0.5291902 ]]. Reward = [0.]
Curr episode timestep = 124
Current timestep = 185. State = [[ 0.06569431 -0.17614701]]. Action = [[ 0.05975646 -0.08887897 -0.06958134 -0.06077617]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 185 is [False, False, True, True, False, False]
State prediction error at timestep 185 is tensor(0.0027, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 185 of -1
Current timestep = 186. State = [[-0.2085097   0.16787356]]. Action = [[ 0.11478892  0.23948652 -0.08098108  0.68647623]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 186 is [True, False, False, False, False, True]
State prediction error at timestep 186 is tensor(0.0842, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 186 of -1
Current timestep = 187. State = [[-0.18793383  0.17475663]]. Action = [[ 0.12536594 -0.21355261  0.15032196  0.36015487]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 187 is [True, False, False, False, False, True]
State prediction error at timestep 187 is tensor(0.0025, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 187 of 1
Current timestep = 188. State = [[-0.1721533   0.14865306]]. Action = [[ 0.15896392 -0.16992654 -0.17474614  0.5859424 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 188 is [True, False, False, False, False, True]
State prediction error at timestep 188 is tensor(0.0032, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 188 of 1
Current timestep = 189. State = [[-0.14500947  0.13582839]]. Action = [[ 0.23846745 -0.01777795 -0.14629872  0.68627954]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 190. State = [[-0.11455867  0.13106565]]. Action = [[ 0.22980157 -0.04862824  0.22242159  0.59288   ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 191. State = [[-0.0814169   0.13097712]]. Action = [[ 0.23400384  0.05228889  0.16975904 -0.19956559]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 192. State = [[-0.06225128  0.14558735]]. Action = [[-0.06845793  0.2045601   0.07434976 -0.7555472 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 193. State = [[-0.06055976  0.14577831]]. Action = [[-0.11610615 -0.22928609 -0.00617608  0.5076268 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 194. State = [[-0.05547342  0.12106606]]. Action = [[ 0.119223   -0.24484447 -0.11709529 -0.63975745]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 195. State = [[-0.05371978  0.11395706]]. Action = [[ 0.03209323  0.20742097 -0.05513862  0.6336484 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 196. State = [[-0.05182844  0.11261906]]. Action = [[ 0.08230928 -0.14151518  0.01485687  0.33386993]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 197. State = [[-0.04074256  0.11036792]]. Action = [[ 0.21770668  0.0896998   0.15363425 -0.1975494 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 197 is [False, True, False, False, True, False]
State prediction error at timestep 197 is tensor(0.0092, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 197 of 1
Current timestep = 198. State = [[-0.00394024  0.12971991]]. Action = [[ 0.18921244  0.21648896 -0.10062675 -0.330782  ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 198 is [False, True, False, False, False, True]
State prediction error at timestep 198 is tensor(0.0163, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 198 of -1
Current timestep = 199. State = [[0.0245948  0.13724065]]. Action = [[-0.13273929 -0.21116562  0.20914966  0.95185673]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 199 is [False, True, False, False, False, True]
State prediction error at timestep 199 is tensor(0.0141, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 199 of 1
Current timestep = 200. State = [[0.02539291 0.12592831]]. Action = [[0.05674294 0.02697819 0.14717585 0.72799397]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 200 is [False, True, False, False, False, True]
State prediction error at timestep 200 is tensor(0.0132, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 200 of 1
Current timestep = 201. State = [[0.02539291 0.12592831]]. Action = [[ 0.24428713 -0.1990161   0.13642704 -0.16756982]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 201 is [False, True, False, False, False, True]
State prediction error at timestep 201 is tensor(0.0148, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 201 of -1
Current timestep = 202. State = [[-0.27147216 -0.20014703]]. Action = [[-0.16401687 -0.18343425  0.14282769 -0.78444064]]. Reward = [100.]
Curr episode timestep = 15
Current timestep = 203. State = [[-0.26668373 -0.22558239]]. Action = [[ 0.135248   -0.06233512  0.1730262   0.48743534]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 204. State = [[-0.25631136 -0.23640028]]. Action = [[-0.00526418 -0.09063667  0.0046213  -0.06982082]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 205. State = [[-0.24268408 -0.2353945 ]]. Action = [[ 0.2406095   0.14305866 -0.08227821 -0.9473573 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 206. State = [[-0.22537865 -0.22989231]]. Action = [[ 0.01480645 -0.01012227 -0.05009414 -0.5024853 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 207. State = [[-0.22418036 -0.23478548]]. Action = [[-0.06417365 -0.1002602  -0.18409123  0.28901708]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 208. State = [[-0.21947831 -0.22623621]]. Action = [[0.11277616 0.23454797 0.03562385 0.7636452 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 209. State = [[-0.20409739 -0.22132382]]. Action = [[ 0.21432108 -0.12690008  0.01675758 -0.7671088 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 210. State = [[-0.19562282 -0.23631448]]. Action = [[-0.23999184 -0.13053304  0.04734394 -0.7222653 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 211. State = [[-0.20652772 -0.24753708]]. Action = [[-0.10188052 -0.01664242 -0.01506831 -0.8623239 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 212. State = [[-0.20604548 -0.25786683]]. Action = [[ 0.23525923 -0.14548725 -0.0676391  -0.7298562 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 213. State = [[-0.1866997  -0.26154682]]. Action = [[ 0.23759949  0.05464888 -0.11616218  0.6083584 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 214. State = [[-0.16000022 -0.2657216 ]]. Action = [[ 0.16334552 -0.07962289 -0.10460216 -0.36412668]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 215. State = [[-0.1459334  -0.26596984]]. Action = [[-0.1119635   0.14080763  0.23642838  0.8464886 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 216. State = [[-0.1397337  -0.25571054]]. Action = [[ 0.16817343  0.06564301 -0.14454852  0.06685293]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 217. State = [[-0.12140244 -0.24900621]]. Action = [[ 0.22871703 -0.05487067  0.00647935  0.3494451 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 218. State = [[-0.09181952 -0.24006559]]. Action = [[ 0.1739775   0.20389038 -0.11945778  0.7947278 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 219. State = [[-0.07815672 -0.22416998]]. Action = [[-0.0915519   0.08517867 -0.0502286   0.7213414 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 220. State = [[-0.08230086 -0.23061678]]. Action = [[-0.08719413 -0.22439232 -0.10575286 -0.06124842]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 221. State = [[-0.08392166 -0.22851832]]. Action = [[ 0.06265473  0.22041649 -0.0054065  -0.10905451]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 222. State = [[-0.07493123 -0.2108965 ]]. Action = [[0.20837015 0.08120587 0.06330764 0.3175739 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 223. State = [[-0.06293914 -0.21372418]]. Action = [[ 0.01726675 -0.1836979   0.08500239 -0.48270476]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 224. State = [[-0.04753508 -0.23210394]]. Action = [[ 0.19688267 -0.18879996  0.15561575 -0.14027876]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 225. State = [[-0.03804965 -0.25139537]]. Action = [[-0.18679683 -0.04419601 -0.12608398 -0.9906952 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 226. State = [[-0.03649714 -0.24766098]]. Action = [[0.17659992 0.18086147 0.03886151 0.10937417]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 227. State = [[-0.02859557 -0.24880132]]. Action = [[ 0.07227233 -0.2106947  -0.24369164  0.96901774]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 228. State = [[-0.01613154 -0.24545747]]. Action = [[ 0.06991035  0.236197   -0.01570927 -0.44675028]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 229. State = [[-0.01156821 -0.22721034]]. Action = [[ 0.0179888   0.10783163 -0.22440897  0.6940125 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 230. State = [[-0.00924949 -0.22883143]]. Action = [[-0.02488868 -0.18860035 -0.23224738 -0.69522846]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 231. State = [[-0.00098475 -0.2475719 ]]. Action = [[ 0.19446597 -0.20797184 -0.02280521 -0.6755275 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 232. State = [[ 0.00743051 -0.27901176]]. Action = [[-0.18859926 -0.20491739  0.04248899 -0.525693  ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 233. State = [[ 0.00357856 -0.28492036]]. Action = [[-0.01192611  0.22471407  0.21614963 -0.90008587]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 234. State = [[ 0.00472122 -0.27789465]]. Action = [[-0.15128547 -0.14420375 -0.0863283  -0.49851763]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 235. State = [[ 0.00552413 -0.2839421 ]]. Action = [[ 0.1066668  -0.16849458 -0.06549947 -0.75221217]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 236. State = [[ 0.01622315 -0.2933434 ]]. Action = [[ 0.18699026 -0.08312838  0.21451387 -0.9145644 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 237. State = [[ 0.03243128 -0.3026598 ]]. Action = [[-0.01981734 -0.0267292   0.16593206 -0.30838132]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 238. State = [[ 0.03673816 -0.30553547]]. Action = [[ 0.2408241  -0.23924476  0.20461458 -0.8168348 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 239. State = [[ 0.03666138 -0.30582494]]. Action = [[-0.03672674 -0.0966913   0.24121377 -0.36877382]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 240. State = [[ 0.03657529 -0.30600423]]. Action = [[-0.05500689  0.02893841  0.21506935  0.03114426]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 241. State = [[ 0.03655166 -0.30598995]]. Action = [[ 0.1966624  -0.05834496 -0.21041378  0.5118792 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 242. State = [[ 0.03655166 -0.30598995]]. Action = [[ 0.09132645 -0.17120256  0.14160976  0.5419593 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 243. State = [[ 0.03636362 -0.30587634]]. Action = [[-0.18679424 -0.22927313  0.0164642   0.5688654 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 244. State = [[ 0.03624939 -0.30588114]]. Action = [[-0.04834589  0.0228157   0.18528473 -0.02588773]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 245. State = [[ 0.03570499 -0.30623192]]. Action = [[ 0.00213796 -0.19704486 -0.22401117  0.9362041 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 246. State = [[ 0.03529094 -0.30652   ]]. Action = [[-0.08086196 -0.09004939  0.09203947 -0.67981446]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 247. State = [[ 0.03433289 -0.3052065 ]]. Action = [[-0.09867921  0.06348836  0.01355442 -0.05012792]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 248. State = [[ 0.03298438 -0.30468735]]. Action = [[-0.18498465 -0.03027698  0.21746624  0.5688869 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 249. State = [[ 0.02879211 -0.29271054]]. Action = [[-0.13863084  0.23071238 -0.09208903  0.33449018]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 250. State = [[ 0.01906304 -0.2791562 ]]. Action = [[-0.01615405 -0.05546588  0.22747213 -0.19365472]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 251. State = [[ 0.02277741 -0.26666677]]. Action = [[0.24117768 0.19831356 0.23307845 0.92423034]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 252. State = [[ 0.02847293 -0.23803744]]. Action = [[-0.05901794  0.18638688  0.14593554 -0.1357485 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 253. State = [[ 0.02628331 -0.23680608]]. Action = [[-0.08923885 -0.23404701 -0.08004937 -0.12631506]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 254. State = [[ 0.01771388 -0.24151075]]. Action = [[-0.14343524  0.11041486  0.1181885   0.4432932 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 255. State = [[ 0.0135418  -0.22895953]]. Action = [[-0.03016922  0.2060324   0.04755604  0.8225937 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 256. State = [[ 0.01118671 -0.22388129]]. Action = [[ 0.18387741 -0.22858973 -0.1052343   0.3288077 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 257. State = [[ 0.01899801 -0.22717088]]. Action = [[ 0.21882713  0.05410492 -0.19558083  0.80021024]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 258. State = [[ 0.02609061 -0.23955584]]. Action = [[-0.10815346 -0.23357914  0.08704609 -0.9440779 ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 259. State = [[ 0.02359151 -0.25683016]]. Action = [[-0.0333655  -0.02925311 -0.10756436  0.56727695]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 260. State = [[ 0.02501609 -0.27330235]]. Action = [[ 0.16285783 -0.2253687   0.16729018  0.23661089]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 261. State = [[ 0.03884447 -0.29123548]]. Action = [[ 0.14631066 -0.03611183  0.06777287 -0.6653181 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 262. State = [[ 0.0493454  -0.29559943]]. Action = [[-0.15667453  0.06768984 -0.16175872  0.43470597]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 263. State = [[ 0.04928772 -0.29577303]]. Action = [[ 0.18766248  0.23767191  0.2397846  -0.01053625]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 264. State = [[ 0.04928772 -0.29577303]]. Action = [[-0.00851607 -0.22652875 -0.19156411  0.44256258]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 265. State = [[ 0.04928772 -0.29577303]]. Action = [[ 0.229182   -0.02734779  0.08339754  0.5048213 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 266. State = [[ 0.04939817 -0.2925922 ]]. Action = [[-0.04569036  0.07864666 -0.1009298  -0.41990483]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 267. State = [[ 0.04948754 -0.29023722]]. Action = [[-0.20871273 -0.16389054 -0.23794037 -0.88407046]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 268. State = [[ 0.04888408 -0.2798136 ]]. Action = [[-0.07616451  0.18935663  0.22378474  0.5791719 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 269. State = [[ 0.03924903 -0.2727655 ]]. Action = [[-0.16450123 -0.0815869   0.23147678  0.509876  ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 270. State = [[ 0.0289623 -0.2762162]]. Action = [[ 0.03268671 -0.24901834 -0.13244948 -0.35891533]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 271. State = [[ 0.02671319 -0.27473938]]. Action = [[ 0.12781817  0.00613216  0.10854852 -0.3900721 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 272. State = [[ 0.03123102 -0.2595903 ]]. Action = [[ 0.06185627  0.24795002  0.06675121 -0.80468905]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 273. State = [[ 0.0382541  -0.23398665]]. Action = [[ 0.16087902  0.04011303 -0.19273928  0.23384476]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 274. State = [[ 0.04669018 -0.2228977 ]]. Action = [[ 0.07685444  0.06323946 -0.05084252  0.8741591 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 275. State = [[ 0.05400536 -0.21839406]]. Action = [[ 0.19895673 -0.06653953  0.2173076  -0.578767  ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 276. State = [[ 0.05758667 -0.21187946]]. Action = [[ 0.07196704  0.07440954  0.05902201 -0.54846334]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 277. State = [[ 0.06307474 -0.20719434]]. Action = [[ 0.1927892  -0.20332856 -0.19794266  0.6700971 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 278. State = [[ 0.05888997 -0.21781944]]. Action = [[-0.23391533 -0.18513028  0.17042437 -0.08311981]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 279. State = [[ 0.05334554 -0.2271799 ]]. Action = [[-0.02861308  0.0187155   0.02662158  0.6355262 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 280. State = [[ 0.04964585 -0.2385616 ]]. Action = [[-0.01826748 -0.15484579 -0.005023    0.4675008 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 281. State = [[ 0.03799734 -0.26341847]]. Action = [[-0.18132551 -0.24272542  0.24283895 -0.8540861 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 282. State = [[ 0.02595422 -0.28205764]]. Action = [[ 0.20226276 -0.18576324  0.09125155 -0.61995935]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 283. State = [[ 0.02421912 -0.2804081 ]]. Action = [[ 0.12696087  0.08078969 -0.07656732  0.98209095]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 284. State = [[ 0.03213229 -0.26596913]]. Action = [[0.14994729 0.19275329 0.03633636 0.75197256]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 285. State = [[ 0.03692794 -0.2516394 ]]. Action = [[ 0.2092011  -0.12000722  0.15613589 -0.14807779]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 286. State = [[ 0.03775499 -0.2502091 ]]. Action = [[-0.06032908 -0.03459197 -0.20162748 -0.34033298]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 287. State = [[ 0.03761775 -0.2504908 ]]. Action = [[ 0.23383594 -0.11328435 -0.20826814 -0.61339086]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 288. State = [[ 0.041494   -0.24046546]]. Action = [[0.09752864 0.17202789 0.11215296 0.5024688 ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 289. State = [[ 0.04269825 -0.2332315 ]]. Action = [[-0.0307588  -0.06306112 -0.20572701  0.9233929 ]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 290. State = [[ 0.04381076 -0.2243042 ]]. Action = [[-0.04965733  0.18165535 -0.19668533 -0.9238484 ]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 291. State = [[ 0.04467942 -0.21473858]]. Action = [[ 0.13415208  0.11564937  0.0231199  -0.8625011 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 292. State = [[ 0.04480326 -0.2134434 ]]. Action = [[0.16025972 0.21336311 0.13351852 0.59260225]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 293. State = [[ 0.04670174 -0.20202686]]. Action = [[ 0.05105445  0.18399334  0.17051172 -0.11798799]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 294. State = [[ 0.04770176 -0.18717062]]. Action = [[ 0.18453991  0.16879904 -0.15247433 -0.49199486]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 295. State = [[ 0.04720974 -0.19528449]]. Action = [[-0.00537513 -0.19503498  0.17345679 -0.5197944 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 296. State = [[ 0.04745207 -0.19473502]]. Action = [[0.01171333 0.16846219 0.19725084 0.924232  ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 297. State = [[ 0.04890811 -0.17993343]]. Action = [[ 0.0191164   0.17574412 -0.0200161   0.3130721 ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 298. State = [[ 0.04966184 -0.16489671]]. Action = [[ 0.11067075  0.21519321 -0.1494336  -0.9449146 ]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 299. State = [[ 0.0496969  -0.16302277]]. Action = [[0.14077514 0.24094188 0.15809649 0.44291723]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 300. State = [[ 0.04969961 -0.16286673]]. Action = [[ 0.19173801 -0.16920999  0.1959008   0.7923169 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 301. State = [[ 0.04969961 -0.16286673]]. Action = [[ 0.11961824 -0.02711798 -0.13954203  0.03489709]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 302. State = [[ 0.04969961 -0.16286673]]. Action = [[ 0.15868431 -0.14450361  0.11050412 -0.4841981 ]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 303. State = [[ 0.0500301  -0.16126928]]. Action = [[ 0.06769174  0.0211677  -0.08446923  0.3229947 ]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 304. State = [[ 0.05193304 -0.15384115]]. Action = [[ 0.01632684  0.08617955 -0.02216163 -0.78751093]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 305. State = [[ 0.0501552 -0.1415649]]. Action = [[-0.2177827   0.10227835  0.04973105 -0.96921134]]. Reward = [0.]
Curr episode timestep = 102
Current timestep = 306. State = [[ 0.04880128 -0.13342193]]. Action = [[ 0.10593116 -0.15818496 -0.19068457 -0.79634666]]. Reward = [0.]
Curr episode timestep = 103
Current timestep = 307. State = [[ 0.04878049 -0.13248828]]. Action = [[ 0.1953209  -0.04255337  0.24290168  0.44829345]]. Reward = [0.]
Curr episode timestep = 104
Current timestep = 308. State = [[ 0.0484493  -0.14507341]]. Action = [[ 0.0669277  -0.24540667 -0.22554205  0.38070714]]. Reward = [0.]
Curr episode timestep = 105
Current timestep = 309. State = [[ 0.04654975 -0.14711991]]. Action = [[-0.14555022  0.21124461  0.15570015 -0.69113594]]. Reward = [0.]
Curr episode timestep = 106
Current timestep = 310. State = [[ 0.04152634 -0.13846894]]. Action = [[ 0.15323108 -0.17858547  0.22913238  0.03178346]]. Reward = [0.]
Curr episode timestep = 107
Current timestep = 311. State = [[ 0.03040108 -0.1462002 ]]. Action = [[-0.20608367 -0.13691743 -0.06508452  0.29667854]]. Reward = [0.]
Curr episode timestep = 108
Current timestep = 312. State = [[ 0.01536209 -0.15401305]]. Action = [[ 0.22830003 -0.19736473 -0.09609272  0.8383751 ]]. Reward = [0.]
Curr episode timestep = 109
Current timestep = 313. State = [[ 0.01103884 -0.15854591]]. Action = [[-0.07184446 -0.04245579 -0.12455866 -0.16893506]]. Reward = [0.]
Curr episode timestep = 110
Current timestep = 314. State = [[-0.00032082 -0.17629188]]. Action = [[-0.09738357 -0.21914199 -0.06707907  0.43974924]]. Reward = [0.]
Curr episode timestep = 111
Current timestep = 315. State = [[-0.01931732 -0.20294546]]. Action = [[-0.2164966  -0.1988552  -0.04551929  0.134179  ]]. Reward = [0.]
Curr episode timestep = 112
Current timestep = 316. State = [[-0.03392532 -0.21194302]]. Action = [[0.11267781 0.13008988 0.23591533 0.34033918]]. Reward = [0.]
Curr episode timestep = 113
Current timestep = 317. State = [[-0.02817581 -0.20299312]]. Action = [[ 0.2014235   0.06096661  0.10118449 -0.65706146]]. Reward = [0.]
Curr episode timestep = 114
Current timestep = 318. State = [[-0.01726304 -0.18834017]]. Action = [[ 0.13547099  0.14727873  0.19510269 -0.66562843]]. Reward = [0.]
Curr episode timestep = 115
Current timestep = 319. State = [[-0.01034011 -0.16334255]]. Action = [[-0.06656504  0.22030193 -0.197704    0.02325749]]. Reward = [0.]
Curr episode timestep = 116
Current timestep = 320. State = [[-0.00613311 -0.14747278]]. Action = [[ 0.15767646 -0.06214972 -0.18296804  0.5087035 ]]. Reward = [0.]
Curr episode timestep = 117
Current timestep = 321. State = [[ 0.00808918 -0.15630162]]. Action = [[ 1.8337148e-01 -1.7926411e-01  1.2904406e-04 -5.5453271e-01]]. Reward = [0.]
Curr episode timestep = 118
Current timestep = 322. State = [[ 0.02293679 -0.15754686]]. Action = [[-0.04992031  0.17914236 -0.13931052 -0.84583974]]. Reward = [0.]
Curr episode timestep = 119
Current timestep = 323. State = [[ 0.02444921 -0.14157937]]. Action = [[-0.06296772  0.15297437  0.10998487 -0.77963364]]. Reward = [0.]
Curr episode timestep = 120
Current timestep = 324. State = [[ 0.0177324 -0.1360703]]. Action = [[-0.2052271  -0.08141835  0.21529937 -0.294926  ]]. Reward = [0.]
Curr episode timestep = 121
Current timestep = 325. State = [[ 0.01624928 -0.1357731 ]]. Action = [[ 0.22125018  0.04063889  0.12074125 -0.75279945]]. Reward = [0.]
Curr episode timestep = 122
Current timestep = 326. State = [[ 0.01293385 -0.13784574]]. Action = [[-0.23190935 -0.06672788  0.09085533  0.17325413]]. Reward = [0.]
Curr episode timestep = 123
Current timestep = 327. State = [[ 0.01080365 -0.15118308]]. Action = [[ 0.16158605 -0.20485662  0.13581163  0.60156846]]. Reward = [0.]
Curr episode timestep = 124
Current timestep = 328. State = [[ 0.01476296 -0.17282294]]. Action = [[ 0.14877638 -0.16548531  0.01195502  0.70809615]]. Reward = [0.]
Curr episode timestep = 125
Current timestep = 329. State = [[-0.21784067  0.00086776]]. Action = [[-0.14308019 -0.23393124  0.15604907 -0.7999086 ]]. Reward = [0.]
Curr episode timestep = 126
Current timestep = 330. State = [[-0.20801513 -0.00827884]]. Action = [[-0.01730108 -0.11847252 -0.1312774   0.2876904 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 331. State = [[-0.20034304 -0.01496083]]. Action = [[ 0.19219089  0.00184146  0.20749804 -0.46748197]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 332. State = [[-0.19220905 -0.03253088]]. Action = [[-0.19962724 -0.23850422  0.10365874 -0.8108105 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 333. State = [[-0.20557359 -0.06426477]]. Action = [[-0.19867946 -0.23241852 -0.14291087  0.636654  ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 334. State = [[-0.21884951 -0.0966694 ]]. Action = [[ 0.01885331 -0.20171379  0.21238244 -0.56425196]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 335. State = [[-0.21445748 -0.10610724]]. Action = [[ 0.22840148  0.13074201 -0.24270596  0.61500967]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 336. State = [[-0.20903715 -0.1051065 ]]. Action = [[-0.12857874 -0.0486574  -0.05765143 -0.9691689 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 337. State = [[-0.21510893 -0.12076466]]. Action = [[-0.11309749 -0.22871906 -0.0899564   0.94920754]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 338. State = [[-0.21511355 -0.14747965]]. Action = [[ 0.2092734  -0.19577251  0.02960417 -0.36355877]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 339. State = [[-0.21162686 -0.16180535]]. Action = [[-0.10118452  0.06291422 -0.18215102 -0.87410563]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 340. State = [[-0.21655571 -0.17575605]]. Action = [[-0.07731253 -0.22112918 -0.13139546 -0.98881453]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 341. State = [[-0.21753228 -0.17750879]]. Action = [[0.05651084 0.24525839 0.0344229  0.22554243]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 342. State = [[-0.21344963 -0.15704755]]. Action = [[0.01860732 0.16181338 0.22505593 0.477309  ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 343. State = [[-0.20635812 -0.15458427]]. Action = [[ 0.1942259  -0.2058141   0.11153424 -0.9335788 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 344. State = [[-0.1858423 -0.1479475]]. Action = [[ 0.20442277  0.22341454 -0.00913712  0.7297466 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 345. State = [[-0.1765664  -0.12720402]]. Action = [[-0.21853773  0.17519838 -0.11136238  0.2530768 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 346. State = [[-0.17425725 -0.12383939]]. Action = [[ 0.2032525  -0.19036162  0.05441889  0.52260923]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 347. State = [[-0.16091391 -0.13349102]]. Action = [[ 0.16587275 -0.05199862  0.20678806  0.22794938]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 348. State = [[-0.13854541 -0.14614996]]. Action = [[ 0.16447687 -0.13893512  0.0418056   0.37348914]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 349. State = [[-0.1157646  -0.16609408]]. Action = [[ 0.14247647 -0.16616748  0.10644463  0.6815939 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 350. State = [[-0.0973487  -0.17863393]]. Action = [[0.0895462  0.00940153 0.16817933 0.38611197]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 351. State = [[-0.07769272 -0.18500243]]. Action = [[ 0.23144898 -0.07943273  0.08654034 -0.7445357 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 352. State = [[-0.05193305 -0.20213068]]. Action = [[ 0.10683361 -0.1890522   0.08191097  0.0802362 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 353. State = [[-0.03548282 -0.21369457]]. Action = [[0.0731014  0.07445183 0.18863803 0.7952056 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 354. State = [[-0.03085547 -0.22214727]]. Action = [[-0.14029287 -0.13164046 -0.17749533  0.8224728 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 355. State = [[-0.02694438 -0.22885   ]]. Action = [[ 0.23911488  0.00042874 -0.10881296 -0.17192519]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 356. State = [[-0.01417627 -0.22520596]]. Action = [[-0.03134069  0.11208114  0.05964041 -0.16982824]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 357. State = [[-0.01518891 -0.21006589]]. Action = [[-0.17271096  0.22813821 -0.06627074  0.2802571 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 358. State = [[-0.0143175  -0.19245945]]. Action = [[ 0.15487099 -0.00233635  0.10407275 -0.1825229 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 359. State = [[-0.00949767 -0.19735003]]. Action = [[ 0.12887141 -0.16841538 -0.23500884  0.92589927]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 360. State = [[-0.00396295 -0.2080021 ]]. Action = [[-0.08756104 -0.05376437  0.21296513 -0.64864004]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 361. State = [[-0.0088447  -0.21546635]]. Action = [[-0.1853096   0.00151226 -0.00056218 -0.34475434]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 362. State = [[-0.00971846 -0.20592317]]. Action = [[0.11333561 0.22975418 0.0536989  0.6773248 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 363. State = [[-0.01682162 -0.20742846]]. Action = [[-0.22324474 -0.24446386 -0.17272498  0.6034187 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 364. State = [[-0.02445868 -0.2180474 ]]. Action = [[ 0.03415981 -0.00450693  0.20407647 -0.41255522]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 365. State = [[-0.02069935 -0.21700549]]. Action = [[ 0.2333582   0.03940248 -0.09988555 -0.59602404]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 366. State = [[-0.01837597 -0.2242239 ]]. Action = [[-0.05617779 -0.17154324 -0.01195456 -0.79044825]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 367. State = [[-0.01832409 -0.24264601]]. Action = [[ 0.05715603 -0.15011165  0.21666679 -0.55800235]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 368. State = [[-0.00823686 -0.26606396]]. Action = [[ 0.19280943 -0.21025653  0.05699691  0.42025304]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 369. State = [[ 0.0081875  -0.28101674]]. Action = [[-0.0799455   0.05098721 -0.00463749 -0.86822593]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 370. State = [[ 0.00481654 -0.28347287]]. Action = [[-0.17202158  0.01697254  0.1114974   0.9357494 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 371. State = [[-0.00278189 -0.28219602]]. Action = [[-0.15699616  0.10627884  0.2358023   0.62972665]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 372. State = [[-0.0062865  -0.27125782]]. Action = [[ 0.10782701  0.0982818  -0.21544045 -0.35044378]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 373. State = [[-0.00485179 -0.26327145]]. Action = [[-0.11785977 -0.23650901 -0.15164882  0.00289834]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 374. State = [[-0.00835832 -0.26816794]]. Action = [[-0.11009264 -0.10175341  0.2125597  -0.85412914]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 375. State = [[-0.01844225 -0.26108587]]. Action = [[-0.16879317  0.23680985  0.13967735  0.94946337]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 376. State = [[-0.03336094 -0.24249862]]. Action = [[0.0245454  0.03445947 0.01809835 0.50443006]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 377. State = [[-0.04179241 -0.23399429]]. Action = [[-0.19582313  0.08474076  0.18895388  0.27760196]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 378. State = [[-0.06108781 -0.23974095]]. Action = [[-0.03592789 -0.22783196  0.1152491   0.9684539 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 379. State = [[-0.06785302 -0.26077682]]. Action = [[ 0.01442954 -0.15214673 -0.21689023 -0.6012453 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 380. State = [[-0.07612541 -0.2656864 ]]. Action = [[-0.17352119  0.14458573 -0.13108857 -0.47977746]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 381. State = [[-0.0853539  -0.25231928]]. Action = [[ 0.0525949   0.15871045 -0.23900656  0.4708711 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 382. State = [[-0.08530097 -0.2500159 ]]. Action = [[ 0.02288419 -0.19085416 -0.21689045 -0.16941166]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 383. State = [[-0.081545   -0.26411182]]. Action = [[ 0.19085628 -0.15715718  0.06856483 -0.08019567]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 384. State = [[-0.0704572  -0.27918425]]. Action = [[ 0.23527509 -0.11202192 -0.10309489 -0.19756311]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 385. State = [[-0.05236256 -0.29621288]]. Action = [[ 0.0334321  -0.13260078  0.19334617 -0.95258546]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 386. State = [[-0.04148048 -0.3083986 ]]. Action = [[ 0.11702925 -0.02845348  0.00820786  0.9495063 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 387. State = [[-0.03194172 -0.31154028]]. Action = [[ 0.23842847 -0.09588555  0.15394485 -0.6231981 ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 388. State = [[-0.03026972 -0.31224942]]. Action = [[-0.10889478 -0.21922846 -0.16374533 -0.773051  ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 389. State = [[-0.02324771 -0.31203368]]. Action = [[0.14455822 0.0130963  0.13550806 0.01182997]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 390. State = [[-0.01475214 -0.30483663]]. Action = [[-0.22233652  0.20111465 -0.02611814  0.6553831 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 391. State = [[-0.00806176 -0.2845833 ]]. Action = [[ 0.22570422  0.21071547  0.16694766 -0.66981167]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 392. State = [[-0.00369921 -0.26408583]]. Action = [[ 0.15293044 -0.19125752  0.10231537 -0.49091887]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 393. State = [[ 0.00558205 -0.25672418]]. Action = [[0.19649541 0.02959001 0.05005899 0.03844082]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 394. State = [[ 0.0262341 -0.2554429]]. Action = [[ 0.15781748 -0.06829995 -0.22988708  0.19331467]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 395. State = [[ 0.04258755 -0.24547593]]. Action = [[-0.05418767  0.24428332 -0.23372012  0.1399622 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 396. State = [[ 0.04387062 -0.23270704]]. Action = [[ 0.18565369 -0.09934539 -0.0463635  -0.30454385]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 397. State = [[ 0.04404805 -0.23108284]]. Action = [[ 0.15442115 -0.11793974 -0.24933587 -0.8942771 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 398. State = [[ 0.04408978 -0.230696  ]]. Action = [[0.19396439 0.14970839 0.15596813 0.9053105 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 399. State = [[ 0.04282316 -0.22240084]]. Action = [[-0.18716171  0.15316361 -0.17014384  0.6268089 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 400. State = [[ 0.03717128 -0.21971972]]. Action = [[-0.0896392  -0.11343694 -0.2122605  -0.04668003]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 401. State = [[ 0.03316325 -0.22544517]]. Action = [[ 0.09184808 -0.0098273   0.03708914 -0.35929865]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 402. State = [[ 0.03314191 -0.23271824]]. Action = [[ 0.01609048 -0.13150428  0.03673553  0.67673886]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 403. State = [[ 0.0324767 -0.2388151]]. Action = [[ 0.20280713 -0.18439007  0.06287253  0.90742433]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 404. State = [[ 0.03255578 -0.2498781 ]]. Action = [[ 0.08002937 -0.1858846   0.00355566  0.09676611]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 405. State = [[ 0.03179828 -0.25624263]]. Action = [[-0.10131206  0.15352684 -0.23566595  0.35598338]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 406. State = [[ 0.0343733  -0.25409243]]. Action = [[ 0.17602271 -0.06409022  0.16908306 -0.5338131 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 407. State = [[ 0.03631812 -0.26294932]]. Action = [[ 0.03703761 -0.16058975  0.10105312 -0.67546266]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 408. State = [[ 0.03887431 -0.26621318]]. Action = [[-0.10868758  0.13418436  0.03803805 -0.39047074]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 409. State = [[ 0.04045557 -0.25205618]]. Action = [[-0.05210114  0.22407675  0.00887698 -0.20415217]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 410. State = [[ 0.04077442 -0.24377847]]. Action = [[ 0.04158053 -0.15523687 -0.08287448  0.14860046]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 411. State = [[ 0.03733431 -0.23735511]]. Action = [[-0.1628703   0.19401956 -0.01575977  0.43959582]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 412. State = [[ 0.03476397 -0.21862131]]. Action = [[-0.0657672   0.19876403  0.08291855  0.7514105 ]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 413. State = [[ 0.02783667 -0.20208281]]. Action = [[ 0.20859513 -0.11395097  0.21638215 -0.5375874 ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 414. State = [[ 0.02660499 -0.18860778]]. Action = [[-0.00154515  0.18494546  0.23839194  0.6415248 ]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 415. State = [[ 0.01932902 -0.18516481]]. Action = [[-0.07428536 -0.19571197 -0.02800493  0.68822193]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 416. State = [[ 0.01520529 -0.19196215]]. Action = [[0.05406046 0.03177065 0.23856935 0.95426404]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 417. State = [[ 0.01845054 -0.20174943]]. Action = [[ 0.20435429 -0.22483367  0.04534578  0.2299484 ]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 418. State = [[ 0.0290922 -0.2160815]]. Action = [[ 0.20398909 -0.03702502  0.14787883  0.91312337]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 419. State = [[ 0.04952925 -0.22682779]]. Action = [[ 0.13684028 -0.10285465  0.2228356  -0.06709093]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 420. State = [[ 0.06346522 -0.23817658]]. Action = [[-0.03244811 -0.0372493   0.00239584 -0.10411078]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 421. State = [[ 0.0637671  -0.23160008]]. Action = [[-0.16763772  0.21672517  0.12154269  0.63469696]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 422. State = [[ 0.05901299 -0.21257108]]. Action = [[-0.22153227  0.20921075  0.17300093 -0.28106546]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 423. State = [[ 0.04391526 -0.19413956]]. Action = [[ 0.2434966  -0.19909695  0.16410261 -0.23211634]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 424. State = [[ 0.03155945 -0.19114761]]. Action = [[-0.23112541  0.02237833 -0.10767239 -0.6064879 ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 425. State = [[ 0.01415007 -0.19492841]]. Action = [[ 0.09049395 -0.14246571  0.09706193 -0.95540583]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 426. State = [[ 0.01566684 -0.20987959]]. Action = [[ 0.18267858 -0.17058241 -0.22387235 -0.35538065]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 427. State = [[ 0.02073814 -0.23297754]]. Action = [[ 0.15230829 -0.22908974  0.06819561 -0.4994068 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 428. State = [[ 0.04067596 -0.24976417]]. Action = [[ 0.14783475  0.03593117 -0.22388941  0.6546743 ]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 429. State = [[ 0.05330961 -0.25025415]]. Action = [[ 0.1842314   0.2244963  -0.20641792 -0.31828648]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 430. State = [[ 0.05072537 -0.25759244]]. Action = [[-0.20912471 -0.08196053 -0.02047881 -0.30534923]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 431. State = [[ 0.04946128 -0.26357004]]. Action = [[ 0.03897864  0.02383485 -0.12165165 -0.35602617]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 432. State = [[ 0.04723988 -0.25599888]]. Action = [[-0.17174222  0.1790506  -0.00501466  0.94421744]]. Reward = [0.]
Curr episode timestep = 102
Current timestep = 433. State = [[ 0.04258113 -0.24633075]]. Action = [[ 0.05085292  0.00969571  0.10121542 -0.12446618]]. Reward = [0.]
Curr episode timestep = 103
Current timestep = 434. State = [[ 0.0427411  -0.24499232]]. Action = [[ 0.2004199   0.02694786 -0.24024816 -0.9606428 ]]. Reward = [0.]
Curr episode timestep = 104
Current timestep = 435. State = [[ 0.04441835 -0.23260254]]. Action = [[0.00702885 0.21489975 0.20833492 0.85740256]]. Reward = [0.]
Curr episode timestep = 105
Current timestep = 436. State = [[ 0.03713537 -0.21622667]]. Action = [[-0.18513037  0.00281501 -0.04608864  0.14930677]]. Reward = [0.]
Curr episode timestep = 106
Current timestep = 437. State = [[ 0.02489675 -0.19981807]]. Action = [[-0.0125224   0.20303068  0.1502499  -0.04883915]]. Reward = [0.]
Curr episode timestep = 107
Current timestep = 438. State = [[ 0.0222461  -0.19119003]]. Action = [[ 0.10504258 -0.15500034  0.14296502 -0.9785136 ]]. Reward = [0.]
Curr episode timestep = 108
Current timestep = 439. State = [[ 0.02178916 -0.1828063 ]]. Action = [[-0.06168869  0.2419413   0.03094479 -0.0537374 ]]. Reward = [0.]
Curr episode timestep = 109
Current timestep = 440. State = [[ 0.01164249 -0.16693445]]. Action = [[-0.23695472  0.04688701  0.19758892 -0.51132494]]. Reward = [0.]
Curr episode timestep = 110
Current timestep = 441. State = [[ 1.2760820e-04 -1.5180273e-01]]. Action = [[ 0.1776154   0.11442846 -0.20216963 -0.93042684]]. Reward = [0.]
Curr episode timestep = 111
Current timestep = 442. State = [[ 0.00098405 -0.149356  ]]. Action = [[-0.02236111 -0.12548022  0.06483662  0.91590476]]. Reward = [0.]
Curr episode timestep = 112
Current timestep = 443. State = [[ 0.00075088 -0.15306064]]. Action = [[-0.032215   -0.00561371 -0.09206416 -0.8604813 ]]. Reward = [0.]
Curr episode timestep = 113
Current timestep = 444. State = [[ 0.00595516 -0.15275869]]. Action = [[ 2.3398891e-01 -6.6743791e-04  1.1298919e-01  6.9508052e-01]]. Reward = [0.]
Curr episode timestep = 114
Current timestep = 445. State = [[ 0.00820871 -0.15152045]]. Action = [[-0.1691518   0.05844185 -0.06764221  0.89782333]]. Reward = [0.]
Curr episode timestep = 115
Current timestep = 446. State = [[ 0.00841718 -0.14219555]]. Action = [[0.07572085 0.11823934 0.16685545 0.2435739 ]]. Reward = [0.]
Curr episode timestep = 116
Current timestep = 447. State = [[ 0.01158182 -0.13309762]]. Action = [[ 0.11398271  0.03564718 -0.2064134  -0.86605936]]. Reward = [0.]
Curr episode timestep = 117
Current timestep = 448. State = [[ 0.01727889 -0.1324019 ]]. Action = [[ 0.08133352 -0.08084849  0.19564506 -0.5908206 ]]. Reward = [0.]
Curr episode timestep = 118
Current timestep = 449. State = [[ 0.02595552 -0.1436108 ]]. Action = [[ 0.06419948 -0.17097045 -0.16457456 -0.689328  ]]. Reward = [0.]
Curr episode timestep = 119
Current timestep = 450. State = [[ 0.02921806 -0.14784238]]. Action = [[-0.10289103  0.1614553  -0.20473035  0.00877512]]. Reward = [0.]
Curr episode timestep = 120
Current timestep = 451. State = [[ 0.02911532 -0.14101157]]. Action = [[-0.02311538  0.03613111  0.21416768 -0.13259757]]. Reward = [0.]
Curr episode timestep = 121
Current timestep = 452. State = [[ 0.02399315 -0.13165186]]. Action = [[-0.19333142  0.10451344 -0.04228666 -0.41909814]]. Reward = [0.]
Curr episode timestep = 122
Current timestep = 453. State = [[ 0.01915239 -0.11122952]]. Action = [[ 0.0465157   0.18352392 -0.1946286  -0.81322014]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 453 is [False, True, False, False, True, False]
State prediction error at timestep 453 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 453 of 1
Current timestep = 454. State = [[-0.22532587  0.2166486 ]]. Action = [[-0.1272442  -0.0687789  -0.08497036  0.8482847 ]]. Reward = [100.]
Curr episode timestep = 124
Current timestep = 455. State = [[-0.20637372  0.2464025 ]]. Action = [[ 0.19063431  0.08052588  0.15411541 -0.4903611 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 456. State = [[-0.18044709  0.24285612]]. Action = [[ 0.1669083  -0.17778909  0.10695979  0.02876806]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 457. State = [[-0.16603075  0.22226517]]. Action = [[-0.11707518 -0.23658131 -0.15082707 -0.53225785]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 458. State = [[-0.15923135  0.2064101 ]]. Action = [[ 0.16753957  0.00820455 -0.17045729 -0.8503424 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 459. State = [[-0.15383787  0.19866493]]. Action = [[-0.01436146 -0.08777975  0.0684911  -0.94439286]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 460. State = [[-0.15681113  0.20032264]]. Action = [[-0.14290002  0.10286683  0.07697004 -0.39254355]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 461. State = [[-0.15547584  0.20974766]]. Action = [[ 0.21470678  0.13243869 -0.04014683 -0.48917973]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 462. State = [[-0.14140001  0.22911997]]. Action = [[0.17503753 0.23419109 0.10410038 0.54603577]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 463. State = [[-0.13057145  0.2584127 ]]. Action = [[-0.09280485  0.17603344  0.1325916  -0.4751169 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 464. State = [[-0.13715892  0.2852906 ]]. Action = [[-0.05344144  0.16449982  0.11316556 -0.3332773 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 465. State = [[-0.14466283  0.30351916]]. Action = [[-0.02267335  0.08997065  0.23262334 -0.38447452]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 466. State = [[-0.14430524  0.31353995]]. Action = [[-0.17760266  0.10691717 -0.00416598 -0.52692205]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 467. State = [[-0.14081922  0.31022134]]. Action = [[ 0.11160636 -0.07133824  0.0527783  -0.8629582 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 468. State = [[-0.12888622  0.30427197]]. Action = [[ 0.042808   -0.08293229 -0.09317425  0.57578254]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 469. State = [[-0.123266    0.29927832]]. Action = [[-0.19953977  0.0189189   0.2078794   0.24128568]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 470. State = [[-0.12273104  0.29811633]]. Action = [[-0.0585508  -0.03051507  0.00565505 -0.03953993]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 471. State = [[-0.11387526  0.29456916]]. Action = [[ 0.24614576 -0.00278483  0.20536956  0.534629  ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 472. State = [[-0.10149069  0.28980407]]. Action = [[-0.14237481 -0.11520317 -0.17773657  0.7803912 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 473. State = [[-0.10485552  0.28645825]]. Action = [[-0.21378334 -0.03830105  0.1512242  -0.4629537 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 474. State = [[-0.10740036  0.28754547]]. Action = [[0.24850106 0.09196466 0.22392994 0.9657004 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 475. State = [[-0.10341885  0.2793144 ]]. Action = [[-0.09868605 -0.18553089  0.15628761 -0.09324026]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 476. State = [[-0.09206889  0.25663868]]. Action = [[ 0.23627758 -0.20904842  0.11672667  0.4466163 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 477. State = [[-0.07695255  0.24601404]]. Action = [[0.23136467 0.17960945 0.2153362  0.09374809]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 478. State = [[-0.05532209  0.24631299]]. Action = [[ 0.06307051 -0.1117343  -0.10827035  0.9279275 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 479. State = [[-0.05219461  0.25027734]]. Action = [[-0.13425389  0.13574451  0.07547146 -0.01749647]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 480. State = [[-0.05026773  0.2582341 ]]. Action = [[ 0.16499454  0.05491653  0.01502663 -0.61399496]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 481. State = [[-0.04975893  0.2697085 ]]. Action = [[-0.24031253  0.04971212 -0.13836384 -0.8739208 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 481 is [False, True, False, False, False, True]
State prediction error at timestep 481 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 481 of -1
Current timestep = 482. State = [[-0.05352153  0.27315527]]. Action = [[ 0.01111764 -0.12692136  0.22155058 -0.57115865]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 483. State = [[-0.05593666  0.26777828]]. Action = [[-0.14358002 -0.00702514 -0.2043811  -0.88860095]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 484. State = [[-0.05832617  0.27046755]]. Action = [[0.21005765 0.12500927 0.1896573  0.4730953 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 485. State = [[-0.05786698  0.28127334]]. Action = [[ 0.06521794  0.17935526 -0.0168875   0.5472262 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 486. State = [[-0.0512476   0.29518026]]. Action = [[ 0.01217878  0.04369885 -0.1777334  -0.5468507 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 487. State = [[-0.04278712  0.28922385]]. Action = [[ 0.04638046 -0.24267925 -0.14342104 -0.96926093]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 487 is [False, True, False, False, False, True]
State prediction error at timestep 487 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 487 of 1
Current timestep = 488. State = [[-0.03909037  0.27060416]]. Action = [[-0.20639656 -0.16691315  0.2115975  -0.7974091 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 488 is [False, True, False, False, False, True]
State prediction error at timestep 488 is tensor(0.0007, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 488 of 1
Current timestep = 489. State = [[-0.04155961  0.26397663]]. Action = [[ 0.06398761  0.09474364 -0.01700683  0.23341334]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 489 is [False, True, False, False, False, True]
State prediction error at timestep 489 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 489 of -1
Current timestep = 490. State = [[-0.04936302  0.27445203]]. Action = [[-0.22524482  0.06997761  0.2281642   0.6926806 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 490 is [False, True, False, False, False, True]
State prediction error at timestep 490 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 490 of -1
Current timestep = 491. State = [[-0.06249876  0.27598882]]. Action = [[-0.07165793 -0.19234501 -0.22990344 -0.77639246]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 492. State = [[-0.06335527  0.25286812]]. Action = [[ 0.17742091 -0.13790415  0.1594609   0.7325245 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 493. State = [[-0.06311893  0.23695815]]. Action = [[-0.17822474 -0.07322757  0.22183591 -0.6973331 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 494. State = [[-0.07277879  0.21526036]]. Action = [[-0.07025185 -0.23062965  0.22121304  0.4428954 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 495. State = [[-0.07501671  0.1833315 ]]. Action = [[ 0.10607156 -0.19695768 -0.2326278   0.9629625 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 496. State = [[-0.07201129  0.16404583]]. Action = [[ 0.06338704 -0.02005865  0.19414955  0.21267366]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 497. State = [[-0.07067192  0.15876438]]. Action = [[0.0328187  0.00122035 0.02476802 0.9930277 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 498. State = [[-0.07045542  0.15332118]]. Action = [[-0.04219401 -0.04796411 -0.1689028  -0.92883   ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 499. State = [[-0.07059759  0.15986554]]. Action = [[0.12313524 0.24104214 0.19126272 0.9176227 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 500. State = [[-0.06923994  0.16605179]]. Action = [[ 0.06420395 -0.05230471  0.1916472  -0.7260247 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 501. State = [[-0.06469644  0.1600876 ]]. Action = [[ 0.06428388 -0.09905301 -0.10187048  0.19514   ]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 502. State = [[-0.0588075   0.14915769]]. Action = [[ 0.05564561 -0.05658603  0.00399014 -0.9538423 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 503. State = [[-0.04956893  0.14483996]]. Action = [[ 0.13351369  0.01857308 -0.14503758  0.0908196 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 503 is [False, True, False, False, False, True]
State prediction error at timestep 503 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 503 of 1
Current timestep = 504. State = [[-0.03086668  0.13758288]]. Action = [[-0.01502468 -0.15919474  0.00554612 -0.9834224 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 504 is [False, True, False, False, False, True]
State prediction error at timestep 504 is tensor(0.0019, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 504 of 1
Current timestep = 505. State = [[-0.17431773 -0.19138993]]. Action = [[ 0.10509545 -0.19679749 -0.20836939  0.4578557 ]]. Reward = [100.]
Curr episode timestep = 50
Current timestep = 506. State = [[-0.15860271 -0.20346692]]. Action = [[0.03567982 0.15884772 0.09994695 0.41610503]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 507. State = [[-0.1602532  -0.20645945]]. Action = [[-0.15631323 -0.12804358 -0.07858275  0.82951236]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 508. State = [[-0.15698144 -0.22368188]]. Action = [[ 0.24457645 -0.2400306  -0.18406342 -0.7778462 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 509. State = [[-0.14288433 -0.25164846]]. Action = [[ 0.02025032 -0.16171233  0.20293713 -0.41336697]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 510. State = [[-0.14320296 -0.27898273]]. Action = [[-0.06455167 -0.22291745 -0.12476091  0.4966824 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 511. State = [[-0.14524062 -0.2886285 ]]. Action = [[-0.00138317  0.18592697 -0.08309945  0.85300684]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 512. State = [[-0.14358109 -0.2840631 ]]. Action = [[ 0.17508662 -0.21354562 -0.17321993  0.8583896 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 513. State = [[-0.14248863 -0.2823498 ]]. Action = [[-0.01402242 -0.23869668 -0.18674284  0.4379418 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 514. State = [[-0.13234903 -0.27849028]]. Action = [[ 0.23662731  0.01369631 -0.23317647 -0.77144504]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 515. State = [[-0.10708317 -0.26425168]]. Action = [[ 0.22517791  0.19930458 -0.13523142  0.43591356]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 516. State = [[-0.08200608 -0.25259152]]. Action = [[ 0.09861851 -0.00840819  0.16624197  0.9228151 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 517. State = [[-0.07074697 -0.25108555]]. Action = [[ 1.9069761e-02  7.7182353e-03 -5.5569410e-04 -9.1233969e-01]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 518. State = [[-0.06535056 -0.25596043]]. Action = [[ 0.08010161 -0.13353506  0.12335351 -0.30152112]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 519. State = [[-0.04679946 -0.2537398 ]]. Action = [[0.16560435 0.16240776 0.01853755 0.3587376 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 520. State = [[-0.03883239 -0.24187493]]. Action = [[-0.23117967  0.12861982  0.1189467  -0.6379661 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 521. State = [[-0.04028979 -0.22991708]]. Action = [[ 0.06721383  0.0522005  -0.07761824 -0.31502473]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 522. State = [[-0.03789128 -0.23058084]]. Action = [[ 0.1360687  -0.15486147  0.17181918 -0.5437608 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 523. State = [[-0.03398226 -0.23462906]]. Action = [[-0.02542999  0.00504833  0.06554407 -0.06093091]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 524. State = [[-0.03709538 -0.23585229]]. Action = [[-0.20248891  0.06098756  0.04769665 -0.9201061 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 525. State = [[-0.04258625 -0.2450299 ]]. Action = [[-0.00776836 -0.12396297 -0.01960698 -0.743258  ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 526. State = [[-0.04445745 -0.24562828]]. Action = [[ 0.03394103  0.10190511 -0.22447278 -0.8592765 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 527. State = [[-0.05142935 -0.25410688]]. Action = [[-0.17342734 -0.17566386 -0.12636034 -0.46670341]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 528. State = [[-0.05903819 -0.2737196 ]]. Action = [[ 0.19061983 -0.2365049   0.06003234 -0.48232847]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 529. State = [[-0.05203053 -0.2982827 ]]. Action = [[ 0.17470354 -0.19013882 -0.0341294   0.3273486 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 530. State = [[-0.03538997 -0.31494543]]. Action = [[ 0.02585256 -0.01515675  0.15369368  0.4821961 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 531. State = [[-0.03052525 -0.31224242]]. Action = [[-0.13759945  0.1786393  -0.23730396  0.07744229]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 532. State = [[-0.03155949 -0.30309007]]. Action = [[-0.08591869  0.09762245 -0.02113903 -0.5437188 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 533. State = [[-0.02667858 -0.28516167]]. Action = [[ 0.19715938  0.16693592 -0.07249135  0.922874  ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 534. State = [[-0.02227219 -0.25665048]]. Action = [[-0.09090434  0.22344682 -0.10432181 -0.08385015]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 535. State = [[-0.02917331 -0.25374696]]. Action = [[-0.16714513 -0.208621    0.19072968  0.816579  ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 536. State = [[-0.03511021 -0.26144025]]. Action = [[ 0.15078801  0.00859368 -0.1963464  -0.05915576]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 537. State = [[-0.03864188 -0.24972305]]. Action = [[-0.20702496  0.23365009 -0.21587144 -0.3378796 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 538. State = [[-0.05150959 -0.2444977 ]]. Action = [[-0.07367377 -0.15029429  0.08520791 -0.7737935 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 539. State = [[-0.05430399 -0.24678013]]. Action = [[ 0.02331063  0.07550526  0.22923604 -0.77231747]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 540. State = [[-0.06599089 -0.25609276]]. Action = [[-0.23868215 -0.17785092 -0.07921591  0.21657181]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 541. State = [[-0.09741315 -0.2792697 ]]. Action = [[-0.17475726 -0.21577908  0.21010673  0.33090615]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 542. State = [[-0.12244626 -0.30349776]]. Action = [[-0.16116068 -0.13301426 -0.14974017 -0.15789694]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 543. State = [[-0.13874742 -0.31406426]]. Action = [[-0.08799401 -0.06074753 -0.08503428  0.12659502]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 544. State = [[-0.14024834 -0.31598493]]. Action = [[ 0.038286    0.03254199 -0.05515268 -0.02839434]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 545. State = [[-0.13998677 -0.31545806]]. Action = [[-0.20697327 -0.11917935  0.14143991  0.4407035 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 546. State = [[-0.14000376 -0.31551626]]. Action = [[ 0.08212841 -0.2375061  -0.14768425  0.5635935 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 547. State = [[-0.14000376 -0.31551626]]. Action = [[-0.1657006  -0.01119561 -0.03521146  0.94614697]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 548. State = [[-0.14000376 -0.31551626]]. Action = [[-0.22915976 -0.19978274 -0.22529043 -0.16884845]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 549. State = [[-0.14857696 -0.3078257 ]]. Action = [[-0.21720146  0.16333658  0.00381827  0.94252574]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 550. State = [[-0.16370904 -0.29885706]]. Action = [[-0.11508816 -0.23047364 -0.03532723 -0.5758384 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 551. State = [[-0.1622276 -0.2856966]]. Action = [[ 0.12152654  0.18785363  0.05310106 -0.9717158 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 552. State = [[-0.1515457  -0.25910547]]. Action = [[0.16260678 0.1289975  0.16796324 0.41158748]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 553. State = [[-0.1439302 -0.2555845]]. Action = [[ 0.07400858 -0.20281823  0.22682661 -0.3148446 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 554. State = [[-0.13844569 -0.25045532]]. Action = [[-0.02583227  0.23528016 -0.23640355  0.8143586 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 555. State = [[-0.12719934 -0.23628436]]. Action = [[ 0.23957789  0.03283179  0.13072044 -0.22336578]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 556. State = [[-0.1133418  -0.24200529]]. Action = [[ 0.04074734 -0.2275996  -0.10830739 -0.86656386]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 557. State = [[-0.10193485 -0.24703726]]. Action = [[ 0.11399531  0.11830544 -0.13943543 -0.8893483 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 558. State = [[-0.09173204 -0.2514561 ]]. Action = [[ 0.05273294 -0.14353997  0.05438647 -0.81201625]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 559. State = [[-0.08209589 -0.2453555 ]]. Action = [[ 0.02266628  0.2298196  -0.12527342  0.09571052]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 560. State = [[-0.07716995 -0.23569049]]. Action = [[ 0.03582975 -0.00908633 -0.21128142 -0.19952774]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 561. State = [[-0.07627462 -0.23983707]]. Action = [[-0.12114035 -0.09946927 -0.01373488  0.9249425 ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 562. State = [[-0.07581598 -0.23352186]]. Action = [[ 0.10202712  0.18517816  0.18720874 -0.2652536 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 563. State = [[-0.07735562 -0.23520032]]. Action = [[-0.10740173 -0.18520524 -0.24402626  0.03393281]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 564. State = [[-0.07967377 -0.24708526]]. Action = [[ 0.06097597 -0.08518595 -0.11204237  0.7704475 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 565. State = [[-0.07540882 -0.24237274]]. Action = [[ 0.09733266  0.19057727 -0.19863291  0.8756422 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 566. State = [[-0.06406611 -0.23577954]]. Action = [[ 0.1823178  -0.07650554 -0.05869263 -0.04147601]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 567. State = [[-0.04664714 -0.24410602]]. Action = [[ 0.04882729 -0.1159866  -0.0852332  -0.9382277 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 568. State = [[-0.04403426 -0.24106447]]. Action = [[-0.23955086  0.23950514 -0.17298177 -0.05071199]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 569. State = [[-0.04522331 -0.23378576]]. Action = [[ 0.17323771 -0.05717228  0.14275628  0.63966537]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 570. State = [[-0.03998929 -0.24580373]]. Action = [[ 0.11940578 -0.24918753  0.10019928 -0.8030983 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 571. State = [[-0.03591266 -0.2701738 ]]. Action = [[-0.06721389 -0.1699866  -0.13309832 -0.8812337 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 572. State = [[-0.04022302 -0.29003507]]. Action = [[-0.07079767 -0.06871849 -0.2034222  -0.9027427 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 573. State = [[-0.03202892 -0.29161403]]. Action = [[ 0.2479473   0.08632895  0.00898156 -0.47424245]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 574. State = [[-0.0174304  -0.28977162]]. Action = [[-0.04253757  0.01519465  0.00955406 -0.5288472 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 575. State = [[-0.01543903 -0.282242  ]]. Action = [[ 0.0173347   0.11768275 -0.12737954 -0.44581056]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 576. State = [[-0.00593693 -0.27257904]]. Action = [[ 0.19194248  0.01791388  0.10299689 -0.66037047]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 577. State = [[ 0.01741132 -0.27144733]]. Action = [[ 0.177418   -0.03998244  0.16275838  0.9440174 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 578. State = [[ 0.03643674 -0.27197897]]. Action = [[-0.01851566 -0.21690345 -0.14151786  0.03875482]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 579. State = [[ 0.04267962 -0.27258042]]. Action = [[0.19696254 0.02066725 0.19754624 0.77036023]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 580. State = [[ 0.04454675 -0.26859576]]. Action = [[ 0.05815578  0.08184698 -0.10106739  0.6051278 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 581. State = [[ 0.04528362 -0.26586235]]. Action = [[ 0.06352398 -0.23473567 -0.22542346  0.26690853]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 582. State = [[ 0.04254948 -0.2776393 ]]. Action = [[-0.08505729 -0.22601369 -0.04942434  0.44846416]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 583. State = [[ 0.04366609 -0.28698203]]. Action = [[ 0.12593836  0.03107256 -0.07907254 -0.2171098 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 584. State = [[ 0.0537658 -0.2865673]]. Action = [[ 0.1039142  -0.20253907  0.23480421  0.83456004]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 585. State = [[ 0.05640101 -0.2841191 ]]. Action = [[ 0.039581    0.06240305 -0.16954798 -0.16591895]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 586. State = [[ 0.06201947 -0.2753688 ]]. Action = [[-0.14024723  0.16475546 -0.02216245  0.2898574 ]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 587. State = [[ 0.06280783 -0.26762956]]. Action = [[ 0.08819085  0.00387001 -0.05544308 -0.43638194]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 588. State = [[ 0.06206211 -0.25909838]]. Action = [[-0.09817213  0.13067347 -0.02045727 -0.17789459]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 589. State = [[ 0.05885004 -0.24971862]]. Action = [[ 0.13373908 -0.18535681 -0.1931081  -0.06741583]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 590. State = [[ 0.05137016 -0.25573587]]. Action = [[-0.1671118  -0.09761459  0.06846744  0.18066788]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 591. State = [[ 0.03478223 -0.27233824]]. Action = [[-0.11594495 -0.15931773 -0.16127269 -0.47094506]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 592. State = [[ 0.02064355 -0.27417353]]. Action = [[-0.07112336  0.16024655 -0.00612321  0.42435396]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 593. State = [[ 0.00341205 -0.2770372 ]]. Action = [[-0.14783268 -0.17856935 -0.10872287  0.2814356 ]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 594. State = [[-0.00671888 -0.29072446]]. Action = [[ 0.07637134 -0.10723948  0.24148655 -0.1341989 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 595. State = [[-0.01165036 -0.2952795 ]]. Action = [[-0.12696478  0.05671644  0.2244519   0.84354043]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 596. State = [[-0.01187765 -0.28703475]]. Action = [[ 0.1548152   0.13880375 -0.18531422  0.6233115 ]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 597. State = [[-0.00891793 -0.27777463]]. Action = [[ 0.15075201 -0.22296014 -0.17191929 -0.95647526]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 598. State = [[-0.00687439 -0.26859608]]. Action = [[-0.0011365   0.13043112  0.16757494 -0.21037936]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 599. State = [[-0.00547652 -0.26713526]]. Action = [[ 0.0077709  -0.17343864 -0.22490393  0.7013545 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 600. State = [[ 0.00187367 -0.26032782]]. Action = [[ 0.2182993   0.21752921  0.11225289 -0.9928546 ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 601. State = [[ 0.00343764 -0.23939624]]. Action = [[-0.2161115   0.16105175 -0.19852132 -0.5162371 ]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 602. State = [[ 0.00330349 -0.22977953]]. Action = [[ 0.16798627 -0.07163841 -0.00819275  0.9061115 ]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 603. State = [[ 0.00262818 -0.23405997]]. Action = [[-0.13408928 -0.06548285  0.01909667  0.30098522]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 604. State = [[ 0.00388845 -0.23614404]]. Action = [[ 0.17513514 -0.01013547  0.2194835  -0.0154807 ]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 605. State = [[ 0.00888625 -0.24215184]]. Action = [[ 0.10205767 -0.11340797  0.11187384 -0.7846614 ]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 606. State = [[ 0.01512443 -0.24166091]]. Action = [[-0.18522832  0.18587345 -0.11252238  0.44631827]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 607. State = [[ 0.02225656 -0.22384423]]. Action = [[ 0.23114502  0.19649416 -0.23101641 -0.7513711 ]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 608. State = [[ 0.02339595 -0.21642593]]. Action = [[-0.03725901 -0.19157754  0.00315481  0.07346904]]. Reward = [0.]
Curr episode timestep = 102
Current timestep = 609. State = [[ 0.02028103 -0.22920837]]. Action = [[-0.1098424  -0.09647451  0.08591807 -0.9518539 ]]. Reward = [0.]
Curr episode timestep = 103
Current timestep = 610. State = [[ 0.01039236 -0.24958141]]. Action = [[-0.19812137 -0.15922393  0.00391003  0.2221762 ]]. Reward = [0.]
Curr episode timestep = 104
Current timestep = 611. State = [[-0.00952902 -0.26606512]]. Action = [[-0.20387632 -0.00525777  0.05984041  0.9360174 ]]. Reward = [0.]
Curr episode timestep = 105
Current timestep = 612. State = [[-0.02857548 -0.28407687]]. Action = [[-0.12814935 -0.19521432 -0.11372134  0.43011796]]. Reward = [0.]
Curr episode timestep = 106
Current timestep = 613. State = [[-0.04162719 -0.2965175 ]]. Action = [[ 0.12618452 -0.20927784 -0.20208718  0.12847686]]. Reward = [0.]
Curr episode timestep = 107
Current timestep = 614. State = [[-0.04543743 -0.2983953 ]]. Action = [[-0.01266533  0.00179774  0.06372049  0.51833344]]. Reward = [0.]
Curr episode timestep = 108
Current timestep = 615. State = [[-0.04423958 -0.2992445 ]]. Action = [[ 0.18036062 -0.05662245 -0.20983522 -0.87973654]]. Reward = [0.]
Curr episode timestep = 109
Current timestep = 616. State = [[-0.0305395 -0.2887403]]. Action = [[ 0.21540916  0.21008062 -0.24040005  0.9897516 ]]. Reward = [0.]
Curr episode timestep = 110
Current timestep = 617. State = [[-0.01011853 -0.27166146]]. Action = [[ 0.21408772  0.06756335  0.17495811 -0.887556  ]]. Reward = [0.]
Curr episode timestep = 111
Current timestep = 618. State = [[ 0.00769213 -0.2659561 ]]. Action = [[-0.09627333 -0.2247216  -0.21889476  0.59115434]]. Reward = [0.]
Curr episode timestep = 112
Current timestep = 619. State = [[ 0.0120863  -0.26570874]]. Action = [[ 0.08265677 -0.06509943 -0.11615813 -0.16261786]]. Reward = [0.]
Curr episode timestep = 113
Current timestep = 620. State = [[ 0.0167295  -0.26981115]]. Action = [[-0.0443671  -0.05193195 -0.03339046  0.31847918]]. Reward = [0.]
Curr episode timestep = 114
Current timestep = 621. State = [[ 0.01801948 -0.26578724]]. Action = [[-0.01485465  0.16773719  0.20820183 -0.65964895]]. Reward = [0.]
Curr episode timestep = 115
Current timestep = 622. State = [[ 0.02468064 -0.2601368 ]]. Action = [[ 0.17204255 -0.06672238  0.19931966 -0.22543263]]. Reward = [0.]
Curr episode timestep = 116
Current timestep = 623. State = [[ 0.03194512 -0.2684505 ]]. Action = [[-0.04025158 -0.14629753  0.23474851  0.4822005 ]]. Reward = [0.]
Curr episode timestep = 117
Current timestep = 624. State = [[ 0.03155113 -0.27390453]]. Action = [[-0.05499493  0.09512976 -0.23045093  0.26321375]]. Reward = [0.]
Curr episode timestep = 118
Current timestep = 625. State = [[ 0.03147437 -0.27332062]]. Action = [[-0.22092582 -0.23257242  0.0776903   0.15974474]]. Reward = [0.]
Curr episode timestep = 119
Current timestep = 626. State = [[ 0.03149047 -0.26831222]]. Action = [[-0.0833223   0.10271928  0.15667754 -0.50046194]]. Reward = [0.]
Curr episode timestep = 120
Current timestep = 627. State = [[ 0.03015505 -0.27361408]]. Action = [[ 0.0245586  -0.2000775   0.19111568 -0.4546169 ]]. Reward = [0.]
Curr episode timestep = 121
Current timestep = 628. State = [[ 0.02280251 -0.28490382]]. Action = [[-0.18970913 -0.00829422 -0.20527633  0.0983243 ]]. Reward = [0.]
Curr episode timestep = 122
Current timestep = 629. State = [[ 0.00802931 -0.29144117]]. Action = [[-0.1698992   0.02684274 -0.19129807  0.26470637]]. Reward = [0.]
Curr episode timestep = 123
Current timestep = 630. State = [[-0.00973591 -0.28131413]]. Action = [[-0.19496149  0.21652478 -0.20798285  0.9272585 ]]. Reward = [0.]
Curr episode timestep = 124
Current timestep = 631. State = [[-0.02937632 -0.26356518]]. Action = [[-0.00187783 -0.2429315  -0.14973778 -0.3809526 ]]. Reward = [0.]
Curr episode timestep = 125
Current timestep = 632. State = [[-0.23562478  0.00962489]]. Action = [[-0.0282726   0.13151246  0.1336078   0.09736454]]. Reward = [0.]
Curr episode timestep = 126
Current timestep = 633. State = [[-0.2362249   0.01855247]]. Action = [[-0.13368474  0.0827992   0.07651925 -0.07847524]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 634. State = [[-0.23315649  0.01467244]]. Action = [[ 0.18623468 -0.17145985  0.11477536  0.64137745]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 635. State = [[-0.23072916 -0.00839435]]. Action = [[-0.13287841 -0.24433148  0.18108398 -0.05507529]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 636. State = [[-0.22648098 -0.02443862]]. Action = [[0.20870787 0.01145583 0.24226493 0.5731412 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 637. State = [[-0.20952724 -0.03895103]]. Action = [[ 0.09971815 -0.1809933  -0.10317597 -0.9865259 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 638. State = [[-0.19038029 -0.0624692 ]]. Action = [[ 0.20024592 -0.16664419 -0.18227357 -0.8011097 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 639. State = [[-0.17285976 -0.08340642]]. Action = [[ 0.00805089 -0.10688555 -0.2237004   0.08474767]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 640. State = [[-0.16114593 -0.09457354]]. Action = [[ 0.24794972 -0.03364365 -0.00596753 -0.74833506]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 641. State = [[-0.14428294 -0.09056152]]. Action = [[-1.5210928e-01  1.7699444e-01  1.1968613e-04 -6.0927784e-01]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 642. State = [[-0.14673963 -0.06957494]]. Action = [[-0.02843098  0.22965616 -0.07365061 -0.729055  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 643. State = [[-0.1556405  -0.06537228]]. Action = [[-0.19127646 -0.22392735  0.06690454 -0.7614972 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 644. State = [[-0.15580373 -0.07043649]]. Action = [[ 0.24821365  0.08397183  0.21575704 -0.3988756 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 645. State = [[-0.13984741 -0.07805673]]. Action = [[ 0.19083828 -0.2001995  -0.1001894  -0.41014582]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 646. State = [[-0.12820302 -0.07931186]]. Action = [[-0.07846773  0.17866772 -0.10702594 -0.65163666]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 647. State = [[-0.12687515 -0.08182533]]. Action = [[ 0.05988532 -0.16941394  0.09702644  0.5005877 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 648. State = [[-0.12538597 -0.08280794]]. Action = [[-0.02034247  0.11239314  0.17180204 -0.32333606]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 649. State = [[-0.12404069 -0.08064702]]. Action = [[ 0.04433769 -0.01601115  0.13363928 -0.3374256 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 650. State = [[-0.12595148 -0.06831206]]. Action = [[-0.1753722   0.22393888  0.18455255 -0.62591153]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 651. State = [[-0.1232715  -0.06203273]]. Action = [[ 0.20616204 -0.17439139 -0.16940533 -0.97455007]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 652. State = [[-0.11862703 -0.06580145]]. Action = [[ 0.03518724  0.04816532 -0.2156605   0.86849236]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 653. State = [[-0.10772411 -0.07855538]]. Action = [[ 0.18104535 -0.2419613  -0.16158581  0.12267482]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 654. State = [[-0.08217422 -0.09625701]]. Action = [[ 0.1401118  -0.04247119  0.03010601 -0.49202096]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 655. State = [[-0.06225414 -0.08937413]]. Action = [[ 0.11710948  0.22158998  0.20124042 -0.5271464 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 656. State = [[-0.0520419  -0.07316387]]. Action = [[-0.0241885   0.09539866 -0.15171674 -0.9279928 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 657. State = [[-0.05339424 -0.06411734]]. Action = [[-0.17652196  0.01525545  0.02872968 -0.87838227]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 658. State = [[-0.06427918 -0.05508193]]. Action = [[-0.2251552   0.1015448   0.24441457 -0.9106114 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 659. State = [[-0.07557869 -0.04181955]]. Action = [[0.10541624 0.07622993 0.18140092 0.4991783 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 660. State = [[-0.0773567  -0.02407013]]. Action = [[-0.00719614  0.19514197 -0.17504002  0.0785737 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 661. State = [[-0.07804856 -0.01794481]]. Action = [[ 0.07025123 -0.15821983 -0.08193859 -0.5445605 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 662. State = [[-0.06854784 -0.03231622]]. Action = [[ 0.21936339 -0.14729524 -0.17743626 -0.43615687]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 663. State = [[-0.04446483 -0.04422825]]. Action = [[ 0.22057033 -0.01787943  0.14698371  0.45227683]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 663 is [False, True, False, False, True, False]
State prediction error at timestep 663 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 663 of 1
Current timestep = 664. State = [[-0.18713683  0.01929541]]. Action = [[-0.12848073  0.04396182  0.20868528  0.35303354]]. Reward = [100.]
Curr episode timestep = 31
Current timestep = 665. State = [[-0.17633924  0.02161555]]. Action = [[-0.02551556 -0.0044895   0.234314   -0.26672232]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 666. State = [[-0.17070776  0.0352628 ]]. Action = [[0.16253304 0.21208757 0.05621353 0.36626506]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 667. State = [[-0.14715415  0.04772861]]. Action = [[ 0.22714284 -0.05843456 -0.00512485 -0.74366754]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 668. State = [[-0.12296765  0.03986905]]. Action = [[ 0.04230043 -0.15351579  0.01465794 -0.1766575 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 669. State = [[-0.11831197  0.01970113]]. Action = [[-0.09945635 -0.17994003  0.06640476 -0.6858195 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 670. State = [[-0.11341523 -0.00482668]]. Action = [[ 0.17862722 -0.17399643 -0.02411416 -0.87067944]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 671. State = [[-0.1019108  -0.01120943]]. Action = [[0.06249446 0.11883122 0.02798387 0.58341765]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 672. State = [[-0.08737267 -0.01147768]]. Action = [[ 0.17359996 -0.06413278 -0.22575043 -0.11497766]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 673. State = [[-0.07025018 -0.01247037]]. Action = [[0.05464745 0.01128292 0.1862455  0.749086  ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 674. State = [[-0.06256326 -0.02620544]]. Action = [[ 0.02701017 -0.21089219 -0.2193381   0.29364884]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 675. State = [[-0.06061958 -0.04930416]]. Action = [[ 0.00328743 -0.15953586  0.1420852  -0.1486916 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 676. State = [[-0.05674912 -0.05197531]]. Action = [[0.06537801 0.19842386 0.12596273 0.91626525]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 677. State = [[-0.05175481 -0.047007  ]]. Action = [[-0.05114312 -0.06178755  0.15941393  0.8013747 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 678. State = [[-0.04407369 -0.06098237]]. Action = [[ 0.20272017 -0.22283365 -0.11093569 -0.7249729 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 678 is [False, True, False, False, True, False]
State prediction error at timestep 678 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 678 of 1
Current timestep = 679. State = [[-0.18420325  0.11686918]]. Action = [[ 0.21373573 -0.09633988 -0.0179176   0.39559162]]. Reward = [100.]
Curr episode timestep = 14
Current timestep = 680. State = [[-0.16813664  0.12976329]]. Action = [[-0.09598406 -0.09692129 -0.09732389 -0.788687  ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 681. State = [[-0.16739528  0.1279834 ]]. Action = [[0.13078332 0.10060933 0.13679749 0.01755404]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 682. State = [[-0.16525137  0.14385675]]. Action = [[0.0643512  0.2184856  0.03971148 0.7696204 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 683. State = [[-0.1620434   0.15845492]]. Action = [[-0.20976749 -0.09313881  0.23336053 -0.61371845]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 684. State = [[-0.16584903  0.15205328]]. Action = [[-0.0106117  -0.11870161  0.10011208 -0.25146455]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 685. State = [[-0.1616481   0.14747168]]. Action = [[ 0.22115535  0.08113062 -0.06877324  0.9418597 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 686. State = [[-0.14824829  0.13733515]]. Action = [[ 0.18347007 -0.17864822 -0.02516487 -0.93210757]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 687. State = [[-0.13351303  0.13091025]]. Action = [[-0.0181088   0.05114746  0.24547014  0.70016   ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 688. State = [[-0.12365714  0.12638971]]. Action = [[ 0.20392147 -0.07028756  0.01606739 -0.1696806 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 689. State = [[-0.10855693  0.12893112]]. Action = [[-0.03967187  0.09922332 -0.13739084 -0.6400496 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 690. State = [[-0.10481012  0.1460536 ]]. Action = [[ 0.08053103  0.23853624 -0.23380527 -0.9064889 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 691. State = [[-0.09973938  0.15218441]]. Action = [[-0.19810121 -0.21837732 -0.11156341  0.85334647]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 692. State = [[-0.11060631  0.15244603]]. Action = [[-0.1977879   0.08530441  0.07610065 -0.4213202 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 693. State = [[-0.11676588  0.14272626]]. Action = [[ 0.17557353 -0.21477869  0.07954764 -0.6186753 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 694. State = [[-0.10646465  0.12013123]]. Action = [[ 0.21124136 -0.13004723  0.23595619 -0.95838124]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 695. State = [[-0.09386365  0.10721613]]. Action = [[ 0.1527623   0.02942511  0.1375916  -0.2463001 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 696. State = [[-0.07904328  0.11229185]]. Action = [[-0.02260138  0.09023073 -0.18414016 -0.31771904]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 697. State = [[-0.07872663  0.10917759]]. Action = [[-0.1498312  -0.16239864 -0.14208606  0.01997781]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 698. State = [[-0.07549767  0.08724494]]. Action = [[ 0.10196343 -0.24242061  0.145361    0.50189376]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 699. State = [[-0.07395571  0.07014834]]. Action = [[-0.09158111 -0.01421633  0.10117057 -0.09979367]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 700. State = [[-0.07392863  0.07030427]]. Action = [[0.13004565 0.10276812 0.2127859  0.7039187 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 701. State = [[-0.07697744  0.08444364]]. Action = [[-0.10634774  0.19200996  0.18794751 -0.96031684]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 702. State = [[-0.07475123  0.09411772]]. Action = [[ 2.2446817e-01 -4.8630551e-02 -1.0471046e-04  3.0616093e-01]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 703. State = [[-0.06016964  0.0888703 ]]. Action = [[ 0.12627923 -0.08197278  0.15495169 -0.02889913]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 704. State = [[-0.03753998  0.09196459]]. Action = [[ 0.24864823  0.13262907  0.22113279 -0.7799974 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 704 is [False, True, False, False, True, False]
State prediction error at timestep 704 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 704 of 1
Current timestep = 705. State = [[-0.1587451   0.04275982]]. Action = [[ 0.04633662  0.16080469 -0.12152748 -0.41182745]]. Reward = [100.]
Curr episode timestep = 25
Current timestep = 706. State = [[-0.13069905  0.04058243]]. Action = [[ 0.22210568 -0.16887528  0.07409823 -0.78873974]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 707. State = [[-0.10167652  0.02502905]]. Action = [[ 0.20776737 -0.12608628 -0.2122647   0.7311629 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 708. State = [[-0.07494252  0.0013382 ]]. Action = [[ 0.15698218 -0.23370217 -0.12984331  0.16229296]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 709. State = [[-0.06292672 -0.02291246]]. Action = [[-0.13612883 -0.10786992  0.00245509 -0.08585203]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 710. State = [[-0.07086677 -0.03307118]]. Action = [[-0.23895842  0.00800446 -0.2002903  -0.21564221]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 711. State = [[-0.07520466 -0.03832356]]. Action = [[ 0.21702808 -0.04392263 -0.22736758 -0.13988543]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 712. State = [[-0.07463688 -0.03913584]]. Action = [[-0.10870436  0.02925399  0.00241995 -0.7031195 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 713. State = [[-0.0805729  -0.04330586]]. Action = [[-0.18675415 -0.06972331 -0.12613767 -0.9763671 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 714. State = [[-0.08634716 -0.04152351]]. Action = [[0.19474632 0.11192036 0.19189149 0.11085856]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 715. State = [[-0.08620621 -0.02537902]]. Action = [[-0.05728874  0.19780898 -0.03378978 -0.27285337]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 716. State = [[-0.08294496  0.0005688 ]]. Action = [[ 0.17683116  0.16470218  0.15434313 -0.774647  ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 717. State = [[-0.06744962  0.01883166]]. Action = [[0.20359367 0.08904308 0.09796968 0.84799266]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 718. State = [[-0.04955847  0.03954945]]. Action = [[0.0027864  0.19766867 0.10504839 0.35871732]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 718 is [False, True, False, False, True, False]
State prediction error at timestep 718 is tensor(0.0006, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 718 of 1
Current timestep = 719. State = [[-0.04906375  0.07080077]]. Action = [[-0.05394393  0.18548799  0.20998919  0.27219772]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 719 is [False, True, False, False, True, False]
State prediction error at timestep 719 is tensor(0.0008, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 719 of -1
Current timestep = 720. State = [[-0.04768535  0.08408603]]. Action = [[ 0.15092474 -0.02369153  0.01830381 -0.841688  ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 720 is [False, True, False, False, True, False]
State prediction error at timestep 720 is tensor(3.7048e-06, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 720 of 1
Current timestep = 721. State = [[-0.23369144  0.21390978]]. Action = [[-0.02710199 -0.19267868 -0.24343039 -0.73344344]]. Reward = [100.]
Curr episode timestep = 15
Current timestep = 722. State = [[-0.22931537  0.2423134 ]]. Action = [[-0.23403488 -0.07030901 -0.16163501  0.7410673 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 723. State = [[-0.2353779   0.24269998]]. Action = [[ 0.14298788  0.03982016 -0.05448806  0.14697933]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 724. State = [[-0.22214451  0.2356865 ]]. Action = [[ 0.24408814 -0.08118367  0.22230461 -0.24553335]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 725. State = [[-0.21229957  0.23033743]]. Action = [[-0.21268286 -0.06743838  0.1041131  -0.9272835 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 726. State = [[-0.21892822  0.23064394]]. Action = [[-0.05404739  0.05266425  0.24476448 -0.44130534]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 727. State = [[-0.22937071  0.22210202]]. Action = [[-0.19963141 -0.22979596  0.14090952 -0.3527211 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 728. State = [[-0.24081832  0.20915961]]. Action = [[ 0.12779194  0.0786128   0.15261024 -0.8502552 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 729. State = [[-0.2309744   0.19956084]]. Action = [[ 0.20937806 -0.1426105  -0.19122827 -0.04719561]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 730. State = [[-0.21068333  0.19212984]]. Action = [[0.24050194 0.05207533 0.23560292 0.11884594]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 731. State = [[-0.19312723  0.18897644]]. Action = [[-0.11814719 -0.11990869  0.16024387  0.7175695 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 732. State = [[-0.18568087  0.17131487]]. Action = [[ 0.1891151  -0.1523991   0.11645982 -0.32563704]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 733. State = [[-0.16866629  0.15553384]]. Action = [[ 0.16859955 -0.02602836 -0.15796681 -0.07886571]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 734. State = [[-0.1450515   0.13907553]]. Action = [[ 0.17999327 -0.21177344 -0.09884255  0.29245162]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 735. State = [[-0.1301229   0.11092708]]. Action = [[-0.14111792 -0.22932824 -0.17956834  0.18144941]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 736. State = [[-0.13276467  0.08237155]]. Action = [[-0.11524525 -0.20474952 -0.00838101 -0.36134064]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 737. State = [[-0.13365136  0.05580876]]. Action = [[ 0.14193234 -0.15408577 -0.171997   -0.11779916]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 738. State = [[-0.12656401  0.02887611]]. Action = [[-0.01373412 -0.17599903  0.14044282 -0.8596498 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 739. State = [[-0.12336379  0.01758911]]. Action = [[ 0.09989375  0.07071978  0.13104403 -0.9297293 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 740. State = [[-0.11759381  0.02153695]]. Action = [[ 0.11594713  0.06511101 -0.08699122 -0.7756202 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 741. State = [[-0.10463431  0.02770095]]. Action = [[ 0.20297092  0.05812925  0.15477055 -0.1187675 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 742. State = [[-0.0749599   0.03561137]]. Action = [[0.24421519 0.05185872 0.05299598 0.30143762]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 743. State = [[-0.05420693  0.03158104]]. Action = [[-0.05532116 -0.16657354 -0.04754344  0.02361584]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 744. State = [[-0.04974692  0.00917426]]. Action = [[ 0.00454888 -0.21147965  0.18721557  0.8512982 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 744 is [False, True, False, False, True, False]
State prediction error at timestep 744 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 744 of 1
Current timestep = 745. State = [[-0.04504614 -0.01594429]]. Action = [[-0.04571335 -0.09476113  0.1951747  -0.5284947 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 745 is [False, True, False, False, True, False]
State prediction error at timestep 745 is tensor(0.0006, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 745 of 1
Current timestep = 746. State = [[-0.04409131 -0.03691736]]. Action = [[ 0.02723876 -0.2156648  -0.17510508  0.8876394 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 746 is [False, True, False, False, True, False]
State prediction error at timestep 746 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 746 of -1
Current timestep = 747. State = [[-0.03906167 -0.06713371]]. Action = [[ 0.11722773 -0.19855869  0.16717511  0.58030796]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 747 is [False, True, False, False, True, False]
State prediction error at timestep 747 is tensor(0.0006, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 747 of -1
Current timestep = 748. State = [[-0.24937685  0.17204325]]. Action = [[ 0.13594759 -0.00375654  0.20892662 -0.7705479 ]]. Reward = [100.]
Curr episode timestep = 26
Current timestep = 749. State = [[-0.2434898   0.19247277]]. Action = [[-0.2146829  -0.00468291 -0.0561296  -0.5748048 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 750. State = [[-0.23532343  0.18941772]]. Action = [[ 0.17195904 -0.05925547 -0.14282842 -0.67419416]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 751. State = [[-0.21567476  0.1787056 ]]. Action = [[ 0.09446156 -0.16443259  0.06518045 -0.89412296]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 752. State = [[-0.20017084  0.17724456]]. Action = [[0.17448023 0.20677423 0.13025206 0.7535715 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 753. State = [[-0.16962126  0.1786842 ]]. Action = [[ 0.24745429 -0.15236975 -0.05200051 -0.6818785 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 754. State = [[-0.14817646  0.16406077]]. Action = [[-0.02001819 -0.16271755 -0.08869651  0.5647433 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 755. State = [[-0.13468505  0.15158576]]. Action = [[ 0.23351547  0.00072706  0.02817163 -0.57395095]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 756. State = [[-0.10981771  0.14058259]]. Action = [[ 0.11061272 -0.15644863  0.05415699  0.91020656]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 757. State = [[-0.09468219  0.1361195 ]]. Action = [[ 0.08280373  0.11104631 -0.15061723 -0.07646435]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 758. State = [[-0.0849176  0.1282509]]. Action = [[-0.06061666 -0.22325899  0.13414243 -0.9534641 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 759. State = [[-0.08776873  0.11326304]]. Action = [[-0.2233083  -0.07509506  0.2309038  -0.66561705]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 760. State = [[-0.09109252  0.09335607]]. Action = [[ 0.07948202 -0.2060794  -0.2255267  -0.4707467 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 761. State = [[-0.09497098  0.08505763]]. Action = [[-0.12918857  0.09154898 -0.23847488 -0.00355893]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 762. State = [[-0.10294147  0.07340829]]. Action = [[-0.02812573 -0.22146663  0.0676446   0.96602714]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 763. State = [[-0.1048701   0.06583171]]. Action = [[ 0.10837331  0.11339968  0.17577219 -0.83683133]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 764. State = [[-0.10542995  0.07034257]]. Action = [[-0.08419028  0.03240135  0.16730681 -0.94656837]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 765. State = [[-0.10505777  0.06920755]]. Action = [[ 0.02328593 -0.08693704 -0.1449441   0.31551552]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 766. State = [[-0.10387338  0.0734979 ]]. Action = [[ 0.11580139  0.15311548 -0.13139994 -0.47254425]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 767. State = [[-0.10020573  0.06926528]]. Action = [[ 0.03105545 -0.17482656  0.08532435 -0.40554905]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 768. State = [[-0.09215088  0.0654253 ]]. Action = [[0.1510753  0.07974029 0.1769048  0.527652  ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 769. State = [[-0.07721825  0.07786248]]. Action = [[ 0.17786956  0.17568511  0.24117202 -0.03173202]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 770. State = [[-0.05567548  0.08075614]]. Action = [[ 0.13141015 -0.11024064 -0.19036493  0.9825126 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 771. State = [[-0.03673489  0.06317908]]. Action = [[ 0.10156405 -0.2462217  -0.10730451  0.48764753]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 771 is [False, True, False, False, True, False]
State prediction error at timestep 771 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 771 of 1
Current timestep = 772. State = [[-0.23074201 -0.19824885]]. Action = [[ 0.09627479 -0.22589238  0.05699074 -0.22441441]]. Reward = [100.]
Curr episode timestep = 23
Current timestep = 773. State = [[-0.22186077 -0.21050085]]. Action = [[ 0.00399747  0.20917928  0.2116437  -0.87340856]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 774. State = [[-0.22852279 -0.18930618]]. Action = [[-0.19853842  0.22743407 -0.07954094  0.8928708 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 775. State = [[-0.23942219 -0.18284959]]. Action = [[-0.04134209 -0.19190927 -0.03013094 -0.9427688 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 776. State = [[-0.23722705 -0.18929039]]. Action = [[ 0.20825809  0.00111234  0.05224186 -0.8178028 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 777. State = [[-0.2325275 -0.1878501]]. Action = [[-0.02346691  0.05050671  0.20104939 -0.1945315 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 778. State = [[-0.22078879 -0.17824623]]. Action = [[0.20555982 0.09979689 0.10156024 0.6576011 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 779. State = [[-0.19889985 -0.1580569 ]]. Action = [[ 0.19158337  0.22725827 -0.02780961 -0.8301237 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 780. State = [[-0.1715667  -0.14614676]]. Action = [[ 0.20664072 -0.09818935  0.18287462  0.9878893 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 781. State = [[-0.14925267 -0.15190119]]. Action = [[ 0.03281453 -0.07213509  0.2057729  -0.9509649 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 782. State = [[-0.14462781 -0.1500397 ]]. Action = [[-0.0970107   0.11671698  0.17467311  0.3295784 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 783. State = [[-0.14289407 -0.15724185]]. Action = [[ 0.10826004 -0.2117828   0.12194106 -0.1036827 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 784. State = [[-0.12965944 -0.17615288]]. Action = [[ 0.21654278 -0.15666786  0.23208681 -0.14765006]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 785. State = [[-0.11053856 -0.17747146]]. Action = [[-0.00406444  0.22080457 -0.2323508  -0.5721318 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 786. State = [[-0.11327538 -0.15584114]]. Action = [[-0.19525638  0.22704443  0.17636073  0.15514326]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 787. State = [[-0.11495463 -0.12584105]]. Action = [[0.13083917 0.18436229 0.19891518 0.97238874]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 788. State = [[-0.1093955  -0.11991958]]. Action = [[ 0.11965668 -0.18223993 -0.22602561  0.3603778 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 789. State = [[-0.10345303 -0.13126808]]. Action = [[-0.07598361 -0.07500754 -0.05440733  0.9612143 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 790. State = [[-0.09573386 -0.14796245]]. Action = [[ 0.23600763 -0.17303324 -0.14798284  0.34210515]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 791. State = [[-0.07534441 -0.16045786]]. Action = [[ 0.06428754 -0.01026508 -0.05778566  0.7710576 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 792. State = [[-0.06942685 -0.16031006]]. Action = [[-0.04421455  0.07668406 -0.05021329 -0.6320943 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 793. State = [[-0.06254977 -0.16004401]]. Action = [[ 0.17439026 -0.04590851 -0.18797119  0.11140537]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 794. State = [[-0.0429775  -0.15075742]]. Action = [[ 0.15723133  0.20082122 -0.12423578  0.59079266]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 795. State = [[-0.03037471 -0.12693211]]. Action = [[-0.04927413  0.211766    0.16802144  0.6580728 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 796. State = [[-0.15483592 -0.03342772]]. Action = [[-0.09335271  0.22472543  0.03558314  0.84060884]]. Reward = [100.]
Curr episode timestep = 23
Current timestep = 797. State = [[-0.14171384 -0.02617769]]. Action = [[-0.09047008  0.22332567  0.06760383 -0.5039693 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 798. State = [[-0.14702205 -0.02668195]]. Action = [[-0.1084561  -0.21109301 -0.12389924  0.11129999]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 799. State = [[-0.15920421 -0.03537281]]. Action = [[-0.24205242  0.01875815  0.22351268 -0.33305025]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 800. State = [[-0.17896703 -0.04921184]]. Action = [[-0.03535677 -0.20478864  0.13079476  0.50608397]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 801. State = [[-0.18236165 -0.0705316 ]]. Action = [[ 0.09567019 -0.12246592 -0.1347271  -0.5986893 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 802. State = [[-0.18602358 -0.09665942]]. Action = [[-0.14034939 -0.24759428  0.02218977  0.72832596]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 803. State = [[-0.18416789 -0.1235509 ]]. Action = [[ 0.24217063 -0.13393797  0.11559278  0.19656444]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 804. State = [[-0.17175403 -0.14054966]]. Action = [[ 0.09625864 -0.05595694  0.13934305  0.55079377]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 805. State = [[-0.16090432 -0.15619215]]. Action = [[ 0.08045852 -0.16821916  0.11874789  0.6738751 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 806. State = [[-0.14438629 -0.15899777]]. Action = [[ 0.12154812  0.19112813 -0.16465057  0.6647513 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 807. State = [[-0.12703119 -0.15266831]]. Action = [[ 0.20958605 -0.04025427 -0.0807178   0.86423874]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 808. State = [[-0.11199297 -0.15445963]]. Action = [[-0.10517792 -0.02516942  0.15871072 -0.8060646 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 809. State = [[-0.10377534 -0.15721083]]. Action = [[ 0.23001522 -0.0425166   0.05588406  0.40080595]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 810. State = [[-0.08422951 -0.15132535]]. Action = [[ 0.08241081  0.16223311  0.07093811 -0.8326535 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 811. State = [[-0.07071306 -0.1549842 ]]. Action = [[ 0.14494842 -0.21590814  0.21841782 -0.38345444]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 812. State = [[-0.06103577 -0.15485397]]. Action = [[-0.21252674  0.21882668  0.20755163 -0.2439276 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 813. State = [[-0.06043422 -0.14958003]]. Action = [[ 0.18266392 -0.09102896 -0.12887485 -0.7832799 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 814. State = [[-0.05880702 -0.14680271]]. Action = [[-0.08202621  0.0988501   0.09238622 -0.7568573 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 815. State = [[-0.05259041 -0.15070762]]. Action = [[ 0.19871008 -0.16394953 -0.0302252   0.0911957 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 816. State = [[-0.04461069 -0.150758  ]]. Action = [[-0.12634765  0.14129841 -0.04054536  0.4012512 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 817. State = [[-0.05187368 -0.13551995]]. Action = [[-0.22539473  0.21297956  0.01261985  0.65938044]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 818. State = [[-0.06108792 -0.12327062]]. Action = [[ 0.02599791 -0.08381033 -0.06293955  0.60785604]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 819. State = [[-0.06270049 -0.11614931]]. Action = [[-0.02704863  0.16140205  0.01991326  0.32811427]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 820. State = [[-0.07578966 -0.1173079 ]]. Action = [[-0.22788605 -0.17622554 -0.11396062  0.3939923 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 821. State = [[-0.09883326 -0.11850014]]. Action = [[-0.09447342  0.11966002  0.08659381 -0.21800911]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 822. State = [[-0.11427715 -0.11265751]]. Action = [[-0.14052072  0.01032412 -0.19444332  0.81113267]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 823. State = [[-0.12916212 -0.10414138]]. Action = [[-0.05983993  0.10440952 -0.23919366 -0.75619614]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 824. State = [[-0.14430259 -0.08751953]]. Action = [[-0.19225486  0.1397632   0.20586878  0.11280537]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 825. State = [[-0.17345576 -0.0870597 ]]. Action = [[-0.18772547 -0.17404146 -0.18348917 -0.59467375]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 826. State = [[-0.18903662 -0.09969472]]. Action = [[ 0.09928221 -0.07545018  0.16751805  0.29795027]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 827. State = [[-0.1906204  -0.09921797]]. Action = [[-0.07690665  0.10320389 -0.18215604  0.39341366]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 828. State = [[-0.19371527 -0.0959852 ]]. Action = [[-0.04843397  0.01398924  0.18334365  0.3277372 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 829. State = [[-0.19566384 -0.10269011]]. Action = [[ 0.0187043  -0.1494939  -0.13520549  0.865693  ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 830. State = [[-0.19966826 -0.11747076]]. Action = [[-0.04622859 -0.10652974 -0.11745414 -0.9246632 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 831. State = [[-0.20447835 -0.11412257]]. Action = [[-0.0617712   0.22373497  0.08791241 -0.23688388]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 832. State = [[-0.20494029 -0.08641058]]. Action = [[ 0.17221114  0.23919973 -0.21746613 -0.8482957 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 833. State = [[-0.20269255 -0.06680978]]. Action = [[0.01308686 0.02098423 0.02912605 0.6137873 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 834. State = [[-0.20029904 -0.06979737]]. Action = [[ 0.01288405 -0.16516303  0.07353628  0.05323935]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 835. State = [[-0.19130571 -0.08927803]]. Action = [[ 0.18389124 -0.22824825  0.15290484 -0.10907656]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 836. State = [[-0.1794754  -0.09358347]]. Action = [[ 0.05960801  0.23960024 -0.07162511 -0.8966947 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 837. State = [[-0.1731741  -0.07491091]]. Action = [[ 0.04861876  0.13393301  0.24247879 -0.9202002 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 838. State = [[-0.16726506 -0.07583372]]. Action = [[ 0.02192554 -0.21868879 -0.12643437 -0.2453202 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 839. State = [[-0.16733992 -0.09869534]]. Action = [[-0.10833171 -0.18077634  0.13425857  0.9939258 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 840. State = [[-0.1798277  -0.12591068]]. Action = [[-0.22386822 -0.20242476 -0.13721834  0.93653774]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 841. State = [[-0.19655004 -0.14234185]]. Action = [[-0.13248903  0.03231871  0.11726278  0.00399828]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 842. State = [[-0.21306029 -0.14100757]]. Action = [[-0.14107314  0.08227596  0.23076412  0.6602526 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 843. State = [[-0.22118708 -0.13933623]]. Action = [[ 0.15401125 -0.06344008 -0.03807828  0.02581501]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 844. State = [[-0.21195187 -0.14998272]]. Action = [[ 0.1692765  -0.16386978 -0.02204123 -0.16860926]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 845. State = [[-0.2085875  -0.15642723]]. Action = [[-0.1499311   0.09800169 -0.10576722  0.3074621 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 846. State = [[-0.21399395 -0.15420753]]. Action = [[-0.10332626  0.02111864  0.08007178  0.35861945]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 847. State = [[-0.21290487 -0.15896124]]. Action = [[ 0.17830849 -0.1310719   0.23797974  0.52095914]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 848. State = [[-0.216398   -0.17323038]]. Action = [[-0.16797307 -0.13686047 -0.1968186   0.38590848]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 849. State = [[-0.21975867 -0.18080732]]. Action = [[ 0.11025661  0.07167172 -0.18573919 -0.6993901 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 850. State = [[-0.21169838 -0.17886133]]. Action = [[ 0.15641946 -0.01314321 -0.09559745 -0.4191985 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 851. State = [[-0.20437188 -0.18828437]]. Action = [[-0.00692666 -0.18028347 -0.15122008 -0.66944206]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 852. State = [[-0.20444779 -0.20077558]]. Action = [[-0.0982258  -0.00605252 -0.0596908  -0.48665273]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 853. State = [[-0.20310071 -0.19889122]]. Action = [[0.11857295 0.08511677 0.21324587 0.35605788]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 854. State = [[-0.19579576 -0.18526879]]. Action = [[ 0.07611993  0.16261864 -0.203465    0.5599015 ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 855. State = [[-0.19537465 -0.18768646]]. Action = [[-0.17214659 -0.2079709   0.18592459 -0.8397506 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 856. State = [[-0.19547708 -0.19039255]]. Action = [[ 0.14860392  0.11397332 -0.15298408  0.9415448 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 857. State = [[-0.18534489 -0.1990406 ]]. Action = [[ 0.17202228 -0.22952253 -0.00364876  0.14545584]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 858. State = [[-0.16325144 -0.21031442]]. Action = [[0.14055365 0.02772951 0.02918079 0.6340003 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 859. State = [[-0.15362462 -0.22206813]]. Action = [[-0.01814894 -0.1835482  -0.11090413 -0.14276212]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 860. State = [[-0.1521604  -0.24123336]]. Action = [[ 0.03559604 -0.13919047  0.07240734 -0.36693233]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 861. State = [[-0.1368712 -0.2526407]]. Action = [[ 0.20448822  0.01164532 -0.23107561  0.7228384 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 862. State = [[-0.11916178 -0.2619518 ]]. Action = [[ 0.01495382 -0.1142711   0.19512367  0.9708657 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 863. State = [[-0.11465994 -0.25660306]]. Action = [[-0.02087615  0.23984379 -0.0818907   0.09138441]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 864. State = [[-0.10638516 -0.24118836]]. Action = [[0.14815241 0.05797368 0.1081042  0.90132284]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 865. State = [[-0.10068572 -0.24361275]]. Action = [[-0.10098714 -0.15196007  0.07993782 -0.46777844]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 866. State = [[-0.1052979  -0.25130016]]. Action = [[-0.1228933   0.0131934  -0.06163147  0.65814507]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 867. State = [[-0.10701304 -0.24762312]]. Action = [[ 0.09205386  0.10765666  0.24869758 -0.56057614]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 868. State = [[-0.10199881 -0.23330998]]. Action = [[ 0.08958045  0.12987056  0.06840706 -0.34585083]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 869. State = [[-0.08732528 -0.21056667]]. Action = [[ 0.23413864  0.1870318  -0.0838438  -0.7712012 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 870. State = [[-0.07318258 -0.19487743]]. Action = [[-0.05670364  0.02921939  0.23426157 -0.684536  ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 871. State = [[-0.07128447 -0.19185717]]. Action = [[ 0.0582242  -0.03462461  0.15943235 -0.4321941 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 872. State = [[-0.0707901  -0.18703775]]. Action = [[-0.20588447  0.12475559  0.24103141  0.6987667 ]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 873. State = [[-0.07515513 -0.16797005]]. Action = [[-0.06480989  0.19982737 -0.10376152  0.7148149 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 874. State = [[-0.07586163 -0.14863604]]. Action = [[0.237939   0.03195077 0.08917233 0.41720533]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 875. State = [[-0.06660512 -0.1525902 ]]. Action = [[ 0.07928944 -0.17472483  0.12209269 -0.2987095 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 876. State = [[-0.05540236 -0.16928157]]. Action = [[ 0.16295278 -0.16761209  0.02272046 -0.28243196]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 877. State = [[-0.03902563 -0.173125  ]]. Action = [[ 0.0133034   0.16761732 -0.19378382  0.8826678 ]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 878. State = [[-0.02755273 -0.16954203]]. Action = [[ 0.18457276 -0.05991279 -0.06523937 -0.2324264 ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 879. State = [[-0.01651012 -0.16435182]]. Action = [[-0.2202099   0.13223338 -0.01944157 -0.31038326]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 880. State = [[-0.01831027 -0.14594394]]. Action = [[ 0.03590801  0.22973335 -0.13028598  0.784747  ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 881. State = [[-0.0173045  -0.13485359]]. Action = [[ 0.11164156 -0.14513402 -0.21798126 -0.98576194]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 882. State = [[-0.0156819  -0.14605592]]. Action = [[-0.01700354 -0.13459349  0.16744474  0.6480466 ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 883. State = [[-0.01079134 -0.15837361]]. Action = [[ 0.1368916  -0.05346726  0.20127577 -0.31498694]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 884. State = [[ 0.00194523 -0.15995376]]. Action = [[0.08924931 0.07338506 0.21678054 0.6998625 ]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 885. State = [[ 0.01594989 -0.15288517]]. Action = [[0.07960936 0.08753526 0.18276608 0.0463959 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 886. State = [[ 0.0207308 -0.1557473]]. Action = [[-0.21873441 -0.10432163 -0.20056    -0.5148363 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 887. State = [[ 0.01964185 -0.15501423]]. Action = [[ 0.17662746  0.10174435  0.16505471 -0.6947256 ]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 888. State = [[ 0.01958014 -0.16241318]]. Action = [[-0.11274788 -0.21531329  0.19053018  0.19760835]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 889. State = [[ 0.02560776 -0.15915447]]. Action = [[ 0.21716523  0.2329573   0.00136808 -0.5013373 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 890. State = [[ 0.03809936 -0.14203973]]. Action = [[ 0.06530273  0.08708829 -0.07908626  0.7638563 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 891. State = [[ 0.04804433 -0.13472886]]. Action = [[ 0.166556    0.00159961 -0.01176451  0.80931807]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 892. State = [[ 0.04668238 -0.14757113]]. Action = [[-0.14483717 -0.23544344 -0.24800414 -0.67589206]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 893. State = [[ 0.03927285 -0.15655404]]. Action = [[-0.18318771  0.08842748 -0.08528368  0.53847814]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 894. State = [[ 0.03069546 -0.15917137]]. Action = [[-0.01638889 -0.02784681 -0.12222922  0.9914627 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 895. State = [[ 0.02321677 -0.17076226]]. Action = [[-0.08154306 -0.15890898 -0.21458615  0.36913073]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 896. State = [[ 0.0130819  -0.17038998]]. Action = [[-0.12980947  0.17629999  0.04028943 -0.97725797]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 897. State = [[ 0.00435306 -0.14673306]]. Action = [[ 0.21422449  0.21307969 -0.20336527 -0.96425474]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 898. State = [[ 0.0158552  -0.12600216]]. Action = [[ 0.23000073  0.03449196 -0.13273938  0.77527857]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 899. State = [[ 0.03975995 -0.11176743]]. Action = [[0.21558803 0.11987472 0.02089491 0.38238966]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 899 is [False, True, False, False, True, False]
State prediction error at timestep 899 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 899 of -1
Current timestep = 900. State = [[ 0.06081081 -0.11382019]]. Action = [[-0.11952689 -0.23569256 -0.10866383  0.17386854]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 900 is [False, False, True, False, True, False]
State prediction error at timestep 900 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 900 of -1
Current timestep = 901. State = [[ 0.05930045 -0.12196238]]. Action = [[ 0.0382033   0.15186489 -0.05120122 -0.8357778 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 901 is [False, False, True, False, True, False]
State prediction error at timestep 901 is tensor(1.4004e-06, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 901 of -1
Current timestep = 902. State = [[ 0.05821859 -0.12473059]]. Action = [[-0.08639316 -0.18308827  0.0800373  -0.46238905]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 902 is [False, False, True, False, True, False]
State prediction error at timestep 902 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 902 of -1
Current timestep = 903. State = [[ 0.0557161  -0.14632681]]. Action = [[-0.0361252  -0.16952655  0.07015777 -0.4121353 ]]. Reward = [0.]
Curr episode timestep = 106
Current timestep = 904. State = [[ 0.0548475  -0.15792741]]. Action = [[0.23123604 0.08975914 0.09112257 0.62842155]]. Reward = [0.]
Curr episode timestep = 107
Current timestep = 905. State = [[ 0.05508133 -0.15367776]]. Action = [[ 0.0440369   0.12346658 -0.23153947  0.38017523]]. Reward = [0.]
Curr episode timestep = 108
Current timestep = 906. State = [[ 0.05496189 -0.15036376]]. Action = [[ 0.12013394 -0.24428539 -0.17169094 -0.4079659 ]]. Reward = [0.]
Curr episode timestep = 109
Current timestep = 907. State = [[ 0.05496209 -0.1496578 ]]. Action = [[ 0.11669913 -0.00828199 -0.23382188 -0.66405594]]. Reward = [0.]
Curr episode timestep = 110
Current timestep = 908. State = [[ 0.05496205 -0.14950068]]. Action = [[ 0.2096565   0.21852958 -0.18262695 -0.31468117]]. Reward = [0.]
Curr episode timestep = 111
Current timestep = 909. State = [[ 0.05541755 -0.14476737]]. Action = [[ 0.05364043  0.06676114 -0.12233274 -0.7441156 ]]. Reward = [0.]
Curr episode timestep = 112
Current timestep = 910. State = [[ 0.05227402 -0.15002348]]. Action = [[-0.19604641 -0.16565906  0.05662078 -0.25552332]]. Reward = [0.]
Curr episode timestep = 113
Current timestep = 911. State = [[ 0.04721367 -0.1576326 ]]. Action = [[ 0.13331556 -0.15788604 -0.20623177  0.7764393 ]]. Reward = [0.]
Curr episode timestep = 114
Current timestep = 912. State = [[ 0.03443162 -0.17168818]]. Action = [[-0.23664002 -0.15551314 -0.1784246   0.05815268]]. Reward = [0.]
Curr episode timestep = 115
Current timestep = 913. State = [[ 0.0171109 -0.1920254]]. Action = [[ 0.05149984 -0.18138237  0.17761418 -0.5521477 ]]. Reward = [0.]
Curr episode timestep = 116
Current timestep = 914. State = [[ 0.01707317 -0.21666165]]. Action = [[ 0.14461756 -0.21351384 -0.09673963 -0.96515304]]. Reward = [0.]
Curr episode timestep = 117
Current timestep = 915. State = [[ 0.01285061 -0.23849961]]. Action = [[-0.21024923 -0.0316239   0.1297279  -0.04222298]]. Reward = [0.]
Curr episode timestep = 118
Current timestep = 916. State = [[ 0.00946404 -0.25007105]]. Action = [[ 0.04808614 -0.09797761 -0.18740198  0.13504577]]. Reward = [0.]
Curr episode timestep = 119
Current timestep = 917. State = [[ 0.01275822 -0.2547019 ]]. Action = [[ 0.17268366  0.01922634  0.09480929 -0.38007283]]. Reward = [0.]
Curr episode timestep = 120
Current timestep = 918. State = [[ 0.01415092 -0.25868186]]. Action = [[-0.06917    -0.07056916 -0.01900005  0.6491666 ]]. Reward = [0.]
Curr episode timestep = 121
Current timestep = 919. State = [[ 0.01430782 -0.25702316]]. Action = [[-0.00464299  0.13334432 -0.08950895 -0.9225458 ]]. Reward = [0.]
Curr episode timestep = 122
Current timestep = 920. State = [[ 0.0180488  -0.25182912]]. Action = [[ 0.12201512 -0.00197135  0.11139774 -0.30456716]]. Reward = [0.]
Curr episode timestep = 123
Current timestep = 921. State = [[ 0.02165114 -0.25048542]]. Action = [[-0.19100004  0.01942497 -0.16867015  0.78293467]]. Reward = [0.]
Curr episode timestep = 124
Current timestep = 922. State = [[ 0.02227418 -0.2448542 ]]. Action = [[ 0.11515963  0.07982025 -0.11678775 -0.54726535]]. Reward = [0.]
Curr episode timestep = 125
Current timestep = 923. State = [[-0.21903706 -0.04044674]]. Action = [[-0.0149485  -0.1905426   0.16621587  0.24971926]]. Reward = [0.]
Curr episode timestep = 126
Current timestep = 924. State = [[-0.21267563 -0.03903672]]. Action = [[-0.11870717  0.14769584 -0.07382238 -0.73373085]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 925. State = [[-0.20630197 -0.04426751]]. Action = [[ 0.2326088  -0.21803504  0.0911684  -0.55313337]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 926. State = [[-0.19664825 -0.06604172]]. Action = [[-0.00491822 -0.17795523  0.06988388 -0.6608016 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 927. State = [[-0.18498808 -0.09388608]]. Action = [[ 0.17791745 -0.22001174 -0.1404837   0.96177197]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 928. State = [[-0.17757057 -0.10422418]]. Action = [[-0.19482937  0.1534605   0.08993477  0.0745424 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 929. State = [[-0.18101212 -0.10252926]]. Action = [[ 0.05631074 -0.03400685 -0.06031816 -0.51269245]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 930. State = [[-0.18546629 -0.10210996]]. Action = [[-0.15658437  0.01819953  0.03144148 -0.35199505]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 931. State = [[-0.18282229 -0.10140899]]. Action = [[ 0.23479444  0.00951716  0.11023682 -0.96064746]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 932. State = [[-0.17252351 -0.08852381]]. Action = [[ 0.11686146  0.17381626 -0.23232944  0.28017843]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 933. State = [[-0.15024424 -0.08762057]]. Action = [[ 0.23828816 -0.1735941   0.04492351 -0.8585746 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 934. State = [[-0.12538332 -0.08712626]]. Action = [[ 0.0847412   0.12296894  0.23455134 -0.76362723]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 935. State = [[-0.10329675 -0.09410645]]. Action = [[ 0.2419079  -0.19560806 -0.2431405   0.20081806]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 936. State = [[-0.08395808 -0.0973407 ]]. Action = [[-0.06249528  0.1185725   0.07705164  0.7515671 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 937. State = [[-0.09021633 -0.09753458]]. Action = [[-0.23707764 -0.041502   -0.00767669 -0.55145276]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 938. State = [[-0.09550437 -0.09037711]]. Action = [[ 0.02668756  0.15585726 -0.06486893 -0.20599449]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 939. State = [[-0.09224794 -0.07270335]]. Action = [[ 0.20521402  0.11187527  0.1250565  -0.66771704]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 940. State = [[-0.07717754 -0.05767431]]. Action = [[ 0.23224121  0.10155845 -0.13577987  0.42961013]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 941. State = [[-0.0480838 -0.0527067]]. Action = [[ 0.19930059 -0.07202336 -0.18466875  0.18943167]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 942. State = [[-0.15746666 -0.135308  ]]. Action = [[ 0.20476496 -0.22597556  0.24661839 -0.36551756]]. Reward = [100.]
Curr episode timestep = 18
Current timestep = 943. State = [[-0.14484668 -0.15167671]]. Action = [[-0.01629739 -0.04686417  0.11248657  0.9457476 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 944. State = [[-0.14369428 -0.14497556]]. Action = [[ 0.01971626  0.19088492  0.08629996 -0.88526106]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 945. State = [[-0.13365242 -0.12939633]]. Action = [[ 0.18041155  0.12745318 -0.03118409 -0.8378519 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 946. State = [[-0.11826576 -0.1242941 ]]. Action = [[ 0.00962222 -0.09164903 -0.19384444  0.24216723]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 947. State = [[-0.11163397 -0.11361109]]. Action = [[ 0.06505919  0.22396559 -0.16387881  0.93352246]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 948. State = [[-0.09835944 -0.09937001]]. Action = [[ 0.20137203  0.03445411  0.02241522 -0.46213675]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 949. State = [[-0.07445735 -0.10600401]]. Action = [[ 0.12277091 -0.20411834 -0.14596312 -0.4546339 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 950. State = [[-0.06641566 -0.12935342]]. Action = [[-0.1552001  -0.19964446 -0.00371109 -0.15826082]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 951. State = [[-0.06515796 -0.13278589]]. Action = [[ 0.15183473  0.18729472 -0.15406168 -0.20070547]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 952. State = [[-0.05045981 -0.11374436]]. Action = [[ 0.19715834  0.18457186 -0.0198174  -0.6715096 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 953. State = [[-0.17896114 -0.00187283]]. Action = [[0.04167101 0.2307499  0.187181   0.8988054 ]]. Reward = [100.]
Curr episode timestep = 10
Current timestep = 954. State = [[-0.1710195  -0.01631184]]. Action = [[-0.22197534 -0.21031554 -0.09604342  0.9557042 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 955. State = [[-0.17063597 -0.01911257]]. Action = [[0.23358399 0.2183243  0.2278297  0.2138058 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 956. State = [[-0.16592193 -0.02071222]]. Action = [[-0.01314196 -0.20262063  0.10904819 -0.88256496]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 957. State = [[-0.15658355 -0.02672467]]. Action = [[ 0.18653625  0.04200619 -0.01805755  0.848011  ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 958. State = [[-0.13517033 -0.02571604]]. Action = [[ 0.15433961  0.04398385 -0.02043927 -0.3398186 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 959. State = [[-0.11092167 -0.01156039]]. Action = [[ 0.20426199  0.20485306 -0.16667224  0.8009814 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 960. State = [[-0.09504146 -0.00473343]]. Action = [[-0.11611052 -0.12541622 -0.04047748  0.8106673 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 961. State = [[-0.09492767 -0.00725468]]. Action = [[ 0.04373321 -0.00751831  0.13115382 -0.698268  ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 962. State = [[-0.09544246 -0.02111795]]. Action = [[-0.08303466 -0.19070487  0.02179763 -0.671594  ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 963. State = [[-0.0971332  -0.04703604]]. Action = [[-0.02449988 -0.21818651  0.21790296  0.8341    ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 964. State = [[-0.09905624 -0.06496631]]. Action = [[-0.03222173 -0.02929935  0.11790106  0.81130207]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 965. State = [[-0.09570904 -0.07035454]]. Action = [[ 0.20063552 -0.00407526 -0.04783982  0.51644063]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 966. State = [[-0.08296475 -0.06241879]]. Action = [[ 0.1118874   0.17335367 -0.21533567 -0.86919045]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 967. State = [[-0.07554254 -0.05487289]]. Action = [[-0.09552038 -0.00134431  0.1962989   0.39208722]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 968. State = [[-0.06830288 -0.04332111]]. Action = [[ 0.23936757  0.16021612  0.11803114 -0.62379307]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 969. State = [[-0.05354344 -0.04111218]]. Action = [[-0.00475951 -0.16250715  0.19877231 -0.3023463 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 970. State = [[-0.05080263 -0.0396331 ]]. Action = [[ 0.03273642  0.13971615 -0.13906613  0.5212618 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 971. State = [[-0.05097293 -0.04567712]]. Action = [[-0.24039933 -0.18075314  0.0064795   0.47963178]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 972. State = [[-0.0499658  -0.05803874]]. Action = [[ 0.23900366 -0.05771409  0.12604433 -0.9178619 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 973. State = [[-0.041601   -0.05740895]]. Action = [[ 0.15387267  0.09179616  0.12265378 -0.12791187]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 974. State = [[-0.19740008 -0.0438689 ]]. Action = [[-0.12424348  0.03836274  0.01704943  0.07288778]]. Reward = [100.]
Curr episode timestep = 20
Current timestep = 975. State = [[-0.17836075 -0.04521493]]. Action = [[0.14680004 0.11881521 0.04062006 0.31795883]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 976. State = [[-0.15771207 -0.03299091]]. Action = [[0.21262026 0.11710191 0.18829903 0.6120328 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 977. State = [[-0.12903135 -0.01702443]]. Action = [[ 0.20251024  0.12514281 -0.18652962 -0.7401443 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 978. State = [[-0.10232488 -0.00887912]]. Action = [[ 0.11530197 -0.0201335  -0.03729814  0.05020952]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 979. State = [[-0.09203105 -0.01225594]]. Action = [[-0.10691954 -0.10102277 -0.17748737 -0.5224016 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 980. State = [[-0.0964895  -0.00724675]]. Action = [[-0.11808398  0.1602984  -0.21358648 -0.19889587]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 981. State = [[-0.09863307  0.00677474]]. Action = [[ 0.14411509  0.0926421  -0.02783939  0.00336707]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 982. State = [[-0.09602227  0.0012627 ]]. Action = [[ 0.05043691 -0.20589904 -0.20214397  0.33974206]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 983. State = [[-0.09432347 -0.01264739]]. Action = [[-0.15290941 -0.08480468  0.14822796  0.7255831 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 984. State = [[-0.08897325 -0.02543665]]. Action = [[ 0.23964518 -0.06950162  0.03869414 -0.3354174 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 985. State = [[-0.08288177 -0.04605333]]. Action = [[-0.11725703 -0.24609482  0.05536425  0.12793362]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 986. State = [[-0.0840546  -0.05988298]]. Action = [[ 0.04271045  0.04724133  0.06434172 -0.5930453 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 987. State = [[-0.08435273 -0.051379  ]]. Action = [[-0.01250346  0.17227733  0.02675962 -0.15682888]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 988. State = [[-0.09137112 -0.03582565]]. Action = [[-0.21087536  0.10517156  0.0486775  -0.16416258]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 989. State = [[-0.09385222 -0.03480336]]. Action = [[ 0.15814427 -0.1444666   0.14452225  0.47782195]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 990. State = [[-0.08432956 -0.03129459]]. Action = [[ 0.21953219  0.15814424  0.02528688 -0.14527857]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 991. State = [[-0.06132713 -0.02759017]]. Action = [[ 0.17492124 -0.04587857 -0.00150988 -0.90837514]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 992. State = [[-0.04113868 -0.01611973]]. Action = [[ 0.09013593  0.19753763 -0.14488867  0.31794894]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 993. State = [[-0.15541388  0.08280616]]. Action = [[0.06410372 0.10916317 0.14554673 0.10464382]]. Reward = [100.]
Curr episode timestep = 18
Current timestep = 994. State = [[-0.13064133  0.09106251]]. Action = [[ 0.166843   -0.06025109  0.21650803 -0.24923146]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 995. State = [[-0.11041353  0.09578265]]. Action = [[ 0.12974054  0.12142897  0.16074085 -0.6729491 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 996. State = [[-0.10180474  0.09790727]]. Action = [[-0.18882479 -0.0919925  -0.13948788 -0.13920248]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 997. State = [[-0.10036714  0.08176046]]. Action = [[ 0.11574173 -0.22435367 -0.07596777 -0.51624054]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 998. State = [[-0.09796497  0.05933128]]. Action = [[-0.02769889 -0.1253247   0.05257553  0.9683478 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 999. State = [[-0.09580806  0.03540185]]. Action = [[ 0.02295631 -0.22027689  0.10929224  0.03072238]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1000. State = [[-0.09544998  0.01731557]]. Action = [[-0.05364186 -0.0351233  -0.18812346 -0.23692912]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1001. State = [[-0.09017419  0.01940678]]. Action = [[0.21505833 0.15023655 0.20190752 0.12412667]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1002. State = [[-0.08244672  0.02994631]]. Action = [[ 0.04566103  0.08125016  0.10726759 -0.4247706 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1003. State = [[-0.08055926  0.04818286]]. Action = [[-0.06203951  0.19829679  0.13070941 -0.63155764]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1004. State = [[-0.07743401  0.06243667]]. Action = [[ 0.13121623  0.00929573 -0.14395729 -0.11242455]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1005. State = [[-0.06963368  0.06539956]]. Action = [[-0.05786189 -0.00541696 -0.10178885 -0.8779611 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1006. State = [[-0.06626829  0.05228569]]. Action = [[ 0.11171943 -0.24004851 -0.0201152   0.1197114 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1007. State = [[-0.05308699  0.04159438]]. Action = [[ 0.2028377   0.05109957  0.20939803 -0.78688055]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1008. State = [[-0.19058327  0.19808142]]. Action = [[ 0.08290511 -0.05705446  0.14138281 -0.23582709]]. Reward = [100.]
Curr episode timestep = 14
Current timestep = 1009. State = [[-0.17163503  0.21899375]]. Action = [[ 0.09648553 -0.04944305  0.0665161  -0.15052128]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1010. State = [[-0.16589063  0.20782033]]. Action = [[-0.1663403  -0.23197831  0.01504889  0.6821605 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1011. State = [[-0.1581663   0.17933406]]. Action = [[ 0.22199708 -0.21088934 -0.16270691 -0.19068718]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1012. State = [[-0.147152    0.15826797]]. Action = [[ 0.10559461 -0.04239339  0.21143636 -0.8190279 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1013. State = [[-0.13912855  0.14654332]]. Action = [[-0.08324012 -0.10955921  0.12266046 -0.2582999 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1014. State = [[-0.13304357  0.12367206]]. Action = [[ 0.11018741 -0.22459136  0.01212692 -0.33185554]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1015. State = [[-0.12915157  0.09868642]]. Action = [[-0.10596964 -0.16448343 -0.21125124  0.47640967]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1016. State = [[-0.12488608  0.06974836]]. Action = [[ 0.12556231 -0.2437055  -0.05739155  0.47993112]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1017. State = [[-0.12072352  0.05786072]]. Action = [[-0.01797929  0.15826759  0.13123202  0.49739444]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1018. State = [[-0.11601494  0.05243197]]. Action = [[ 0.15708044 -0.1613087   0.00690028  0.36515045]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1019. State = [[-0.10672662  0.05047372]]. Action = [[ 0.12235546  0.13932061 -0.06591593 -0.8987974 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1020. State = [[-0.09878401  0.05813511]]. Action = [[-0.17301154  0.00559595 -0.24299689 -0.78020704]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1021. State = [[-0.1071251   0.06269376]]. Action = [[-0.1517461   0.02400672  0.19186884 -0.38984329]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1022. State = [[-0.10607287  0.05461766]]. Action = [[ 0.2219317  -0.17654935  0.23774451  0.8325629 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1023. State = [[-0.10164011  0.03380121]]. Action = [[-0.08132496 -0.15555343  0.0753879  -0.84902894]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1024. State = [[-0.10618428  0.02626572]]. Action = [[-0.16244908  0.04714411  0.05717331  0.37537563]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1025. State = [[-0.11880647  0.03450789]]. Action = [[-0.08994409  0.14457986  0.06633779  0.9242736 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1026. State = [[-0.12865049  0.04681907]]. Action = [[ 0.06276941  0.07728857 -0.15547696  0.47343707]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1027. State = [[-0.13180174  0.04746724]]. Action = [[-0.12273452 -0.11277248  0.09200999  0.4084661 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1028. State = [[-0.1360264   0.02803576]]. Action = [[-0.03275533 -0.24612772  0.0227049  -0.05703396]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1029. State = [[-0.13963807  0.00951223]]. Action = [[ 0.06601307 -0.02304198  0.20407873  0.53592706]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 1030. State = [[-0.14044014 -0.00496486]]. Action = [[-0.05844124 -0.15800105 -0.22618751 -0.7554861 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 1031. State = [[-0.14290467 -0.01954197]]. Action = [[ 0.03245053 -0.04497485  0.22973657  0.91701436]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 1032. State = [[-0.14930804 -0.01737984]]. Action = [[-0.1488226   0.14730072 -0.17483166 -0.6779158 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 1033. State = [[-0.16052172 -0.0132776 ]]. Action = [[-0.12131724 -0.0334439   0.20638132  0.0657897 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 1034. State = [[-0.18263924 -0.00507695]]. Action = [[-0.21264128  0.15376759 -0.01954542 -0.8483887 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 1035. State = [[-0.20398916  0.00112359]]. Action = [[-0.05648881 -0.0777981  -0.0709866  -0.6639921 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 1036. State = [[-0.21200265  0.00424749]]. Action = [[0.10295206 0.11153489 0.22394824 0.67201936]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 1037. State = [[-0.2044721   0.00791909]]. Action = [[ 0.19202995 -0.02800088 -0.15883715  0.3145721 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 1038. State = [[-0.20227365  0.01906321]]. Action = [[-0.16336975  0.18181443 -0.132776    0.15438843]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 1039. State = [[-0.20404157  0.02953745]]. Action = [[0.12542897 0.00711873 0.10020053 0.16851366]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 1040. State = [[-0.19001268  0.04430143]]. Action = [[ 0.24336666  0.18976045 -0.1794118   0.3237412 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 1041. State = [[-0.16266108  0.04751704]]. Action = [[ 0.15903598 -0.18525082 -0.17002308 -0.58650136]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 1042. State = [[-0.14430845  0.04467243]]. Action = [[ 0.12127206  0.0988012   0.13419688 -0.2676623 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 1043. State = [[-0.13362727  0.03616063]]. Action = [[-0.07550754 -0.23111112 -0.09103937 -0.25878167]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 1044. State = [[-0.13242327  0.02722265]]. Action = [[-0.05135594  0.0530583  -0.01669453  0.75065374]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 1045. State = [[-0.13777904  0.02306645]]. Action = [[-0.10199425 -0.08246613 -0.20717667 -0.24624133]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 1046. State = [[-0.1385996   0.00889895]]. Action = [[ 0.08281907 -0.13686037 -0.00573702 -0.34944522]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 1047. State = [[-0.13808265  0.00481643]]. Action = [[-0.01502118  0.11412406 -0.04129912 -0.96134293]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 1048. State = [[-0.13562533  0.0017709 ]]. Action = [[ 0.12633431 -0.11298135  0.1625793  -0.6140829 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 1049. State = [[-0.13226028 -0.00717688]]. Action = [[-0.01807016 -0.06564459  0.03809497 -0.97489357]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 1050. State = [[-0.13004453 -0.02666236]]. Action = [[-0.02032681 -0.22897834 -0.10582219 -0.7098433 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 1051. State = [[-0.13333207 -0.03586721]]. Action = [[-0.1738322   0.1398626  -0.22896174  0.11892748]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 1052. State = [[-0.14648843 -0.03903113]]. Action = [[-0.1317321  -0.12023193  0.17602402  0.01706159]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 1053. State = [[-0.15562686 -0.05939851]]. Action = [[ 0.08704656 -0.24086145 -0.20736472 -0.47654903]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 1054. State = [[-0.15253483 -0.0761479 ]]. Action = [[ 0.10676163  0.01572418  0.21070391 -0.3282205 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 1055. State = [[-0.14630911 -0.08569914]]. Action = [[ 0.08219266 -0.11088158  0.23260987  0.3919567 ]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 1056. State = [[-0.1309766  -0.09962078]]. Action = [[ 0.24308744 -0.0775203   0.07251298 -0.2910822 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 1057. State = [[-0.11444417 -0.10776665]]. Action = [[-0.07839698 -0.03373206  0.03402895  0.57672095]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 1058. State = [[-0.11621867 -0.11966354]]. Action = [[-0.0838955  -0.12579232  0.03778249  0.20551872]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 1059. State = [[-0.10909636 -0.11660121]]. Action = [[ 0.23652595  0.2088897   0.21197784 -0.26908326]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 1060. State = [[-0.10216383 -0.11981405]]. Action = [[-0.08360077 -0.22476819 -0.15050332 -0.29206353]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 1061. State = [[-0.10168472 -0.123606  ]]. Action = [[ 0.04210514  0.13941377  0.07152122 -0.19184506]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 1062. State = [[-0.091491   -0.12158243]]. Action = [[ 0.22178665 -0.05821356 -0.17705888  0.1670456 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 1063. State = [[-0.06847005 -0.11214767]]. Action = [[ 0.1263634   0.18054649 -0.09914032 -0.8870952 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 1064. State = [[-0.05245634 -0.11006865]]. Action = [[ 0.02173415 -0.1395175   0.09678698 -0.74253076]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 1065. State = [[-0.04475505 -0.10496778]]. Action = [[ 0.13362652  0.15931845 -0.22780205  0.7241802 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 1066. State = [[-0.21404825  0.02533387]]. Action = [[ 0.23259214 -0.00590807 -0.07840709 -0.34762704]]. Reward = [100.]
Curr episode timestep = 57
Current timestep = 1067. State = [[-0.19817238  0.03428044]]. Action = [[ 0.22306997  0.09445798  0.08333302 -0.7869603 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1068. State = [[-0.17165188  0.03880443]]. Action = [[ 0.10051799 -0.08213617 -0.09706342  0.9257963 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1069. State = [[-0.15508254  0.04190392]]. Action = [[ 0.12460014  0.10038865 -0.21511087 -0.36720985]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1070. State = [[-0.13311772  0.0350698 ]]. Action = [[ 0.17792773 -0.19664656 -0.21361312  0.01017857]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1071. State = [[-0.10645094  0.0182411 ]]. Action = [[ 0.21832639 -0.12816404  0.06352925 -0.09263754]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1072. State = [[-0.08506904  0.01300449]]. Action = [[ 0.02893427  0.08672529  0.05550548 -0.20809102]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1073. State = [[-0.07947665  0.00387184]]. Action = [[-0.06086706 -0.18740943  0.1943956   0.5816345 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1074. State = [[-0.07875103 -0.02070434]]. Action = [[ 0.04877731 -0.23124018  0.06950456 -0.00276095]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1075. State = [[-0.06954639 -0.04434133]]. Action = [[ 0.15192813 -0.09088063  0.00274274  0.5896052 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1076. State = [[-0.06113739 -0.05755273]]. Action = [[-0.08726913 -0.07120173  0.04052117  0.25016952]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1077. State = [[-0.06683005 -0.06030056]]. Action = [[-0.19654253  0.06498593 -0.18233064  0.47988224]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1078. State = [[-0.06971784 -0.04705209]]. Action = [[ 0.12448999  0.2075578  -0.05025651  0.919554  ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1079. State = [[-0.07162789 -0.02814084]]. Action = [[ 0.01517189  0.09615043 -0.19800064 -0.13470364]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1080. State = [[-0.06892491 -0.02340331]]. Action = [[ 0.09845793 -0.07346079  0.21108264 -0.6812671 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1081. State = [[-0.06645002 -0.02371646]]. Action = [[-0.06809771  0.02477619 -0.15202834 -0.09872198]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1082. State = [[-0.06615813 -0.02693204]]. Action = [[ 0.02006605 -0.0799031   0.15714955  0.4778993 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1083. State = [[-0.06310263 -0.04295609]]. Action = [[ 0.0964829  -0.211854   -0.00747776  0.41643226]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1084. State = [[-0.05667802 -0.065471  ]]. Action = [[-0.00193202 -0.10046405 -0.04690361  0.0814867 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1085. State = [[-0.05073262 -0.08234988]]. Action = [[ 0.1019406  -0.11752781  0.1467005  -0.77492535]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1086. State = [[-0.04163847 -0.10455481]]. Action = [[ 0.01387775 -0.19978723 -0.23972434 -0.06679404]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1087. State = [[-0.0406644 -0.1133725]]. Action = [[-0.01732421  0.11603379 -0.04052557  0.16885138]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 1088. State = [[-0.04091921 -0.11294421]]. Action = [[-0.10667229 -0.044864    0.19349873 -0.0970757 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 1089. State = [[-0.03726628 -0.10225138]]. Action = [[ 0.21735823  0.19442481 -0.11269969  0.40900826]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 1090. State = [[-0.21408913 -0.07771154]]. Action = [[ 0.14168176 -0.1279938   0.03846905 -0.43841422]]. Reward = [100.]
Curr episode timestep = 23
Current timestep = 1091. State = [[-0.20613931 -0.07619128]]. Action = [[-0.07879311  0.19436121 -0.1551242   0.59045005]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1092. State = [[-0.20212577 -0.06074963]]. Action = [[0.18031383 0.09742996 0.14882258 0.8524797 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1093. State = [[-0.1853482  -0.05594646]]. Action = [[ 0.21673304 -0.07251754 -0.14085658 -0.6437699 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1094. State = [[-0.15179884 -0.06621763]]. Action = [[ 0.24563357 -0.14818403 -0.23470189  0.05306005]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1095. State = [[-0.12393297 -0.07443675]]. Action = [[ 0.08547628 -0.0011183   0.17572993 -0.5717824 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1096. State = [[-0.10158825 -0.06964099]]. Action = [[ 0.23492354  0.13119358 -0.20082162 -0.89741594]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1097. State = [[-0.08698866 -0.076405  ]]. Action = [[-0.19811583 -0.18896063  0.15499985 -0.31989545]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1098. State = [[-0.08694431 -0.0766797 ]]. Action = [[ 0.13646436  0.14592883 -0.08872122 -0.9280157 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1099. State = [[-0.08983577 -0.05875154]]. Action = [[-0.19006436  0.20180285  0.10226038 -0.1658321 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1100. State = [[-0.09845673 -0.03488645]]. Action = [[-0.1221195   0.11906582  0.04987255 -0.9792324 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1101. State = [[-0.10532547 -0.01527029]]. Action = [[ 0.03458187  0.13085178 -0.01075517  0.0105294 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1102. State = [[-0.11252582  0.00481179]]. Action = [[-0.1524763   0.14547765 -0.17623205  0.04640806]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1103. State = [[-0.12579326  0.01443327]]. Action = [[-0.09956184 -0.05931871  0.10370719 -0.25761175]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1104. State = [[-0.12975664  0.01115512]]. Action = [[ 0.17335635 -0.02571005  0.2369808  -0.5104653 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1105. State = [[-0.13505204  0.01798754]]. Action = [[-0.22889328  0.12936348 -0.04022917  0.78975224]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1106. State = [[-0.14421993  0.03927404]]. Action = [[0.0651283  0.219679   0.20879436 0.54406476]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1107. State = [[-0.14836228  0.0527737 ]]. Action = [[-0.07416207 -0.03544484  0.09342325  0.1599474 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1108. State = [[-0.15299867  0.05703512]]. Action = [[-0.10431655  0.03133959 -0.22631274  0.0851965 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1109. State = [[-0.15685236  0.07093608]]. Action = [[ 0.15635604  0.18736404  0.08889678 -0.70653385]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1110. State = [[-0.15487362  0.07049181]]. Action = [[-0.00590681 -0.1901154   0.01120454  0.55870295]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1111. State = [[-0.14753442  0.04934159]]. Action = [[ 0.1616016  -0.19968718 -0.20339304 -0.18912733]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 1112. State = [[-0.13807644  0.03533505]]. Action = [[ 0.06654879  0.00312099  0.19234121 -0.40153217]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 1113. State = [[-0.13616271  0.04407829]]. Action = [[-0.14672194  0.19388437  0.14162937  0.7467638 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 1114. State = [[-0.13370205  0.05548238]]. Action = [[ 0.20511648  0.04490751 -0.14680846 -0.21164036]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 1115. State = [[-0.12656218  0.06839172]]. Action = [[-0.03058818  0.14015707  0.0573889  -0.6400019 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 1116. State = [[-0.12016771  0.08912533]]. Action = [[ 0.1585213   0.17473426 -0.1616817  -0.5310899 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 1117. State = [[-0.10768103  0.10541981]]. Action = [[-0.01959951  0.0378885   0.05690679 -0.92286307]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 1118. State = [[-0.10222288  0.10804608]]. Action = [[ 0.11860913 -0.05087084  0.12369028 -0.7967633 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 1119. State = [[-0.09131417  0.10908519]]. Action = [[ 0.02530605  0.02320901 -0.20733227  0.77043355]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 1120. State = [[-0.08153258  0.1126658 ]]. Action = [[ 0.15668684  0.07413015 -0.13978185 -0.33730745]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 1121. State = [[-0.07338414  0.12456099]]. Action = [[-0.14374912  0.09271419  0.03461552  0.2396648 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 1122. State = [[-0.06938352  0.13229619]]. Action = [[ 0.2191202   0.0005506  -0.18383862  0.12787366]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 1123. State = [[-0.04954733  0.12714586]]. Action = [[ 0.12522697 -0.12025815 -0.10713448  0.4175316 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 1123 is [False, True, False, False, False, True]
State prediction error at timestep 1123 is tensor(3.4720e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1123 of -1
Current timestep = 1124. State = [[-0.03213429  0.13010034]]. Action = [[ 0.08412254  0.17044401  0.243281   -0.02073461]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 1124 is [False, True, False, False, False, True]
State prediction error at timestep 1124 is tensor(3.3955e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1124 of -1
Current timestep = 1125. State = [[-0.0176374   0.14172521]]. Action = [[-0.01117831  0.01293162  0.2433159  -0.33906543]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 1125 is [False, True, False, False, False, True]
State prediction error at timestep 1125 is tensor(9.4791e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1125 of -1
Current timestep = 1126. State = [[-0.01443364  0.13739844]]. Action = [[ 0.09931672 -0.0999209  -0.04997177 -0.627087  ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 1127. State = [[-0.0143355   0.13682835]]. Action = [[-0.10046121  0.05743682  0.06889039 -0.127805  ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 1128. State = [[-0.0075992   0.12629642]]. Action = [[ 0.19834569 -0.19207282 -0.10287973  0.2649423 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 1129. State = [[0.00050119 0.13016757]]. Action = [[-0.11541587  0.24408755  0.07051224  0.3384018 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 1130. State = [[-1.0662846e-04  1.2983266e-01]]. Action = [[ 0.06249812 -0.22351918  0.07123289 -0.6615206 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 1131. State = [[0.0060801  0.12260603]]. Action = [[ 0.14426303  0.04878584  0.00036353 -0.35217702]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 1131 is [False, True, False, False, True, False]
State prediction error at timestep 1131 is tensor(1.9880e-06, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1131 of -1
Current timestep = 1132. State = [[0.01952984 0.12935026]]. Action = [[-0.19347018  0.04763842 -0.11745036 -0.5717621 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 1132 is [False, True, False, False, False, True]
State prediction error at timestep 1132 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1132 of -1
Current timestep = 1133. State = [[0.01464361 0.14232516]]. Action = [[0.08115339 0.1795167  0.2388553  0.35617054]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 1134. State = [[0.01235686 0.14845285]]. Action = [[ 0.0299384  -0.06493121  0.14424929  0.8444952 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 1135. State = [[0.01188891 0.13519028]]. Action = [[-0.22908609 -0.24146071 -0.03810757 -0.04803902]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 1136. State = [[0.00834146 0.13269366]]. Action = [[ 0.04235223  0.19925365  0.23579794 -0.8901204 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 1137. State = [[0.00762557 0.1374907 ]]. Action = [[ 0.10238528 -0.06561381  0.00903702  0.69018745]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 1138. State = [[0.00945362 0.13509327]]. Action = [[-0.00353612 -0.0208112   0.08053434 -0.7517552 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 1139. State = [[0.00902768 0.13599053]]. Action = [[-0.06996308  0.0350728   0.03092062  0.41473293]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 1140. State = [[0.00449476 0.12540554]]. Action = [[-0.17296015 -0.21252327 -0.09174299 -0.07597125]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 1141. State = [[-0.22620787 -0.10435747]]. Action = [[-1.2771812e-01 -2.4037278e-01  1.3574958e-04 -6.8670934e-01]]. Reward = [100.]
Curr episode timestep = 50
Current timestep = 1142. State = [[-0.21834846 -0.11113784]]. Action = [[ 0.06053942  0.07985771  0.22582668 -0.41585726]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1143. State = [[-0.21222268 -0.09740779]]. Action = [[0.06672648 0.19343483 0.23146415 0.14032316]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1144. State = [[-0.207326   -0.08319245]]. Action = [[-0.09031111  0.03487152  0.0305112   0.6006048 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1145. State = [[-0.200985   -0.06940614]]. Action = [[ 0.19521147  0.14873707 -0.03276877 -0.5997434 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1146. State = [[-0.1920843 -0.051028 ]]. Action = [[-0.09249273  0.10892269  0.06107563 -0.07822496]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1147. State = [[-0.19473432 -0.03908806]]. Action = [[-0.02431215  0.04009455 -0.24593471  0.35395694]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1148. State = [[-0.1877983  -0.04424539]]. Action = [[ 0.21757802 -0.18468933  0.00687128  0.01415431]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1149. State = [[-0.1644051  -0.06467232]]. Action = [[ 0.19561797 -0.19242015 -0.14557745  0.3159541 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1150. State = [[-0.15118688 -0.07946324]]. Action = [[-0.13498197 -0.00604525  0.15587151  0.7198756 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1151. State = [[-0.15029779 -0.08638405]]. Action = [[ 0.1157735  -0.05308615 -0.07496984 -0.82803774]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1152. State = [[-0.13774095 -0.09384539]]. Action = [[ 0.19377512 -0.06121668  0.03559589 -0.76168406]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1153. State = [[-0.12442755 -0.09735014]]. Action = [[-0.09695752  0.03666449 -0.03154787  0.00095534]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1154. State = [[-0.11613441 -0.09989853]]. Action = [[ 0.20709568 -0.05736491 -0.22183073 -0.09299076]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1155. State = [[-0.09466416 -0.09585328]]. Action = [[0.18715829 0.13104287 0.19748133 0.72101617]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1156. State = [[-0.07424701 -0.09522236]]. Action = [[ 0.04034299 -0.08709291  0.19834766 -0.9507387 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1157. State = [[-0.07362273 -0.10425966]]. Action = [[-0.19635287 -0.09246936 -0.16271718  0.1109426 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1158. State = [[-0.07495147 -0.12220459]]. Action = [[ 0.17880815 -0.18433852  0.21287349  0.8141725 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1159. State = [[-0.06723598 -0.1473467 ]]. Action = [[ 0.10874102 -0.20345615  0.2342673  -0.01246893]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1160. State = [[-0.05755407 -0.15218987]]. Action = [[-0.07948607  0.2184625   0.09513623 -0.5963704 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1161. State = [[-0.06351469 -0.1374062 ]]. Action = [[-0.21427897  0.11779687 -0.14450677  0.13494945]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1162. State = [[-0.06843414 -0.13983363]]. Action = [[ 0.05339897 -0.20156191  0.07145765  0.9336903 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 1163. State = [[-0.07136541 -0.15087615]]. Action = [[-0.03714743 -0.02654028 -0.11171639  0.718976  ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 1164. State = [[-0.07194382 -0.15282008]]. Action = [[ 0.02080083  0.03398567 -0.02215807 -0.1978212 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 1165. State = [[-0.07985659 -0.16726622]]. Action = [[-0.19352071 -0.23328303 -0.2323384   0.6961138 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 1166. State = [[-0.08687522 -0.17424192]]. Action = [[0.16685307 0.13195914 0.12021387 0.92214036]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 1167. State = [[-0.0851245  -0.16533513]]. Action = [[-0.0787572   0.08329391  0.08420298 -0.7556357 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 1168. State = [[-0.08632915 -0.17021579]]. Action = [[-0.02486224 -0.17615291  0.07852921  0.93276095]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 1169. State = [[-0.08812756 -0.1790371 ]]. Action = [[-0.00527635 -0.0406664   0.19667906  0.9366393 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 1170. State = [[-0.09240885 -0.18917707]]. Action = [[-0.09174886 -0.07452631  0.23071617  0.01474762]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 1171. State = [[-0.09596329 -0.19152142]]. Action = [[0.03235993 0.09686112 0.05488032 0.21355367]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 1172. State = [[-0.09178692 -0.18370198]]. Action = [[ 0.18914896  0.05342358  0.12072048 -0.3379072 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 1173. State = [[-0.08629053 -0.16805106]]. Action = [[-0.06475437  0.1882881   0.15154356 -0.3287258 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 1174. State = [[-0.08399318 -0.1448716 ]]. Action = [[ 0.03909069  0.14850849 -0.11153804  0.4623809 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 1175. State = [[-0.08409096 -0.13703626]]. Action = [[-0.06323159 -0.10018472  0.13532472 -0.4520558 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 1176. State = [[-0.08856085 -0.1523146 ]]. Action = [[-0.08229469 -0.19413024 -0.12934785  0.7972195 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 1177. State = [[-0.10257899 -0.17764786]]. Action = [[-0.16596158 -0.17393625  0.21573853  0.8093586 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 1178. State = [[-0.12362135 -0.20373441]]. Action = [[-0.22186285 -0.16943635  0.23557442  0.08063185]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 1179. State = [[-0.14418137 -0.22288862]]. Action = [[-0.05106537 -0.06298432  0.23422343  0.87396944]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 1180. State = [[-0.14534403 -0.2337639 ]]. Action = [[ 0.21480119 -0.08776009 -0.19040449  0.8291737 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 1181. State = [[-0.14442885 -0.24429582]]. Action = [[-0.12847318 -0.05947343  0.10675746 -0.39421678]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 1182. State = [[-0.14489792 -0.2450255 ]]. Action = [[ 0.07624051  0.1071603  -0.10428135 -0.20694876]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 1183. State = [[-0.13415301 -0.23175944]]. Action = [[ 0.21957308  0.13300699 -0.03788677  0.561147  ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 1184. State = [[-0.1143433  -0.20713873]]. Action = [[ 0.15570128  0.22094208  0.19075    -0.48590803]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 1185. State = [[-0.09363316 -0.17479813]]. Action = [[ 0.20586744  0.24006677  0.1270153  -0.6890064 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 1186. State = [[-0.06712176 -0.1513774 ]]. Action = [[0.18103713 0.04010695 0.1465362  0.74816656]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 1187. State = [[-0.04713161 -0.15663847]]. Action = [[ 0.10103294 -0.20785278  0.11298746 -0.30685693]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 1188. State = [[-0.03366137 -0.15546519]]. Action = [[ 0.03128582  0.1912399   0.0623669  -0.65026975]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 1189. State = [[-0.02058474 -0.1341046 ]]. Action = [[ 0.22952992  0.21346766 -0.207875    0.132272  ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 1190. State = [[-0.00570295 -0.10497656]]. Action = [[-0.20013568  0.24188629  0.07358375 -0.66796833]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 1190 is [False, True, False, False, True, False]
State prediction error at timestep 1190 is tensor(0.0008, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1190 of 1
Current timestep = 1191. State = [[-0.23357117  0.03623063]]. Action = [[-0.21167646 -0.1608787  -0.24007924  0.305004  ]]. Reward = [100.]
Curr episode timestep = 49
Current timestep = 1192. State = [[-0.21275143  0.04150505]]. Action = [[ 0.24797899 -0.02242835  0.00420472 -0.2238521 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1193. State = [[-0.18959852  0.03361614]]. Action = [[ 0.04255602 -0.14641672 -0.19968891 -0.9120965 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1194. State = [[-0.17883228  0.01961179]]. Action = [[ 0.10443401 -0.11238849  0.1312859  -0.89497215]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1195. State = [[-0.17847788  0.02355247]]. Action = [[-0.2341306   0.22450164 -0.20885833 -0.8814378 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1196. State = [[-0.19114007  0.02770718]]. Action = [[-0.19883162 -0.16153586  0.14783031  0.5822811 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1197. State = [[-0.19982891  0.02046218]]. Action = [[ 0.21610302  0.05105144 -0.11734091  0.18850386]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1198. State = [[-0.18641476  0.02078411]]. Action = [[ 0.20586717 -0.01503617 -0.08747843  0.700722  ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1199. State = [[-0.17915188  0.03327322]]. Action = [[-0.21859388  0.21452194  0.24113113 -0.7245106 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1200. State = [[-0.18414284  0.04527041]]. Action = [[ 0.09820527 -0.04081184 -0.01764481 -0.85783327]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1201. State = [[-0.17493978  0.04567442]]. Action = [[ 0.21170717  0.0079414   0.21828464 -0.5525672 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1202. State = [[-0.15283346  0.0397012 ]]. Action = [[ 0.12032008 -0.1199185   0.23889565 -0.8824884 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1203. State = [[-0.13715428  0.03070534]]. Action = [[ 0.03545862 -0.05241078  0.2364834   0.8872113 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1204. State = [[-0.1342877   0.01447102]]. Action = [[-0.07158995 -0.18355988  0.14916706 -0.09354925]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1205. State = [[-0.13850448 -0.00306749]]. Action = [[-0.12789293 -0.07441676 -0.08531943 -0.20599878]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1206. State = [[-0.13808729 -0.02195914]]. Action = [[ 0.15777826 -0.17213552 -0.18223086  0.7411151 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1207. State = [[-0.13608642 -0.04624194]]. Action = [[-0.10916901 -0.1753886   0.15904814 -0.13725305]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1208. State = [[-0.14007482 -0.07207911]]. Action = [[-0.05131829 -0.18140589 -0.07177429  0.8297173 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1209. State = [[-0.13612886 -0.09054767]]. Action = [[ 0.21382982 -0.05289996  0.06734973  0.62341285]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1210. State = [[-0.12541667 -0.10297018]]. Action = [[ 0.11472648 -0.08915511  0.03187081  0.0024085 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1211. State = [[-0.11612131 -0.10954008]]. Action = [[-0.03247309  0.00026587  0.17311361 -0.01100141]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1212. State = [[-0.11354498 -0.1013793 ]]. Action = [[ 0.05526897  0.16415209  0.22348535 -0.93195903]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 1213. State = [[-0.11058752 -0.10109498]]. Action = [[ 0.01691401 -0.13861233  0.05911121 -0.2087276 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 1214. State = [[-0.09828569 -0.10669504]]. Action = [[ 0.22941002 -0.00788361  0.2006543  -0.89579624]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 1215. State = [[-0.0698748 -0.1105058]]. Action = [[ 0.18890494 -0.0293756  -0.03921205 -0.5942374 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 1216. State = [[-0.04651449 -0.12011883]]. Action = [[ 0.0958094  -0.13226452 -0.24156435  0.9437189 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 1217. State = [[-0.03740023 -0.13508357]]. Action = [[-0.04198939 -0.07326439  0.14353663  0.589895  ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 1218. State = [[-0.03492787 -0.14987314]]. Action = [[ 0.05418155 -0.12777391 -0.1686022   0.4653896 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 1219. State = [[-0.02898172 -0.15710312]]. Action = [[ 0.06780136  0.06267715 -0.02206413 -0.14575344]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 1220. State = [[-0.02050215 -0.14948077]]. Action = [[ 0.09358248  0.0960376  -0.24711667  0.29902303]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 1221. State = [[-0.00394244 -0.13414642]]. Action = [[0.14438039 0.16219294 0.10380879 0.81770945]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 1222. State = [[ 0.01795674 -0.10847483]]. Action = [[ 0.15031305  0.237452    0.04664311 -0.910352  ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 1223. State = [[-0.18050157  0.0727076 ]]. Action = [[-0.1983715  -0.13835263  0.15571743  0.67174697]]. Reward = [100.]
Curr episode timestep = 31
Current timestep = 1224. State = [[-0.16962448  0.08447388]]. Action = [[-0.12451899  0.01759773  0.13951999  0.96384406]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1225. State = [[-0.16976017  0.07998825]]. Action = [[ 0.08596659 -0.13032925  0.21242186 -0.15942395]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1226. State = [[-0.1638141   0.07415555]]. Action = [[ 0.14210248  0.00711185  0.23145568 -0.5149423 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1227. State = [[-0.14669128  0.07724673]]. Action = [[ 0.13710958  0.097801    0.23156363 -0.14080358]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1228. State = [[-0.13022396  0.07803823]]. Action = [[ 0.04790038 -0.07661918  0.18818092 -0.26075935]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1229. State = [[-0.11735531  0.07836055]]. Action = [[ 0.19482374  0.04575229 -0.24339662 -0.50911945]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1230. State = [[-0.10249574  0.06843752]]. Action = [[-0.07939568 -0.20565493 -0.16970102 -0.14274585]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1231. State = [[-0.10302339  0.05755511]]. Action = [[-0.08432557  0.01901862  0.16765007 -0.57470435]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1232. State = [[-0.10268266  0.05119368]]. Action = [[ 0.03008854 -0.09031975  0.07728809 -0.00805795]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1233. State = [[-0.10397818  0.05558476]]. Action = [[ 0.05564669  0.19118583 -0.23802964 -0.42203557]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1234. State = [[-0.09980801  0.06740422]]. Action = [[0.12143624 0.06441522 0.13534534 0.5531819 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1235. State = [[-0.08323842  0.0592605 ]]. Action = [[ 0.13288409 -0.24177203  0.11478442 -0.9562283 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1236. State = [[-0.06877486  0.04524044]]. Action = [[ 0.07094708 -0.04195037  0.10873595  0.3218361 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1237. State = [[-0.06520522  0.03511304]]. Action = [[-0.18922003 -0.09106013 -0.23220581  0.64337766]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1238. State = [[-0.06766982  0.03390477]]. Action = [[-0.0109916   0.10305619  0.20365962 -0.12719828]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1239. State = [[-0.06727313  0.04209261]]. Action = [[ 0.16457748  0.08372054 -0.16034147  0.5831032 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1240. State = [[-0.05948914  0.03683253]]. Action = [[ 0.15260267 -0.17859676  0.1909324   0.8311188 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1241. State = [[-0.04339818  0.01796594]]. Action = [[ 0.0382818  -0.17478988 -0.21692595 -0.0257467 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1242. State = [[-0.21136214 -0.02205321]]. Action = [[ 0.14957589 -0.15949924  0.13149089  0.5791869 ]]. Reward = [100.]
Curr episode timestep = 18
Current timestep = 1243. State = [[-0.19661097 -0.02610293]]. Action = [[ 0.17535484 -0.01056586 -0.10265121  0.29665756]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1244. State = [[-0.18372396 -0.02323682]]. Action = [[-0.07425466  0.09492537 -0.05869335 -0.25905764]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1245. State = [[-0.17362005 -0.03034939]]. Action = [[ 0.23770356 -0.18242934  0.12688929  0.00198734]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1246. State = [[-0.14896381 -0.04723615]]. Action = [[ 0.15648988 -0.13742489  0.00109079  0.18737388]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1247. State = [[-0.13963619 -0.04879716]]. Action = [[-0.20313105  0.17712188 -0.06960201 -0.48175085]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1248. State = [[-0.13984634 -0.04077238]]. Action = [[ 0.16037375  0.03229654 -0.15925065  0.96394706]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1249. State = [[-0.13111496 -0.0339795 ]]. Action = [[ 0.14465913  0.04888096 -0.02697366 -0.5525012 ]]. Reward = [0.]
Curr episode timestep = 6
