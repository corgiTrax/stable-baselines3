Current timestep = 0. State = [[-0.25107092 -0.0450854   0.10659638  1.        ]]. Action = [[0.         0.         0.14802909 1.        ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [False, True, 2, False, True]
Human Feedback received at timestep 0 of 0
Current timestep = 1. State = [[-0.25090528 -0.04602423  0.10676241  1.        ]]. Action = [[ 0.          0.         -0.06350148  1.        ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [False, True, 2, False, True]
Human Feedback received at timestep 1 of 0
Current timestep = 2. State = [[-0.24666587 -0.04968959  0.11988407  1.        ]]. Action = [[0.        0.        1.8394399 1.       ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [False, True, 2, False, True]
Human Feedback received at timestep 2 of 1
Current timestep = 3. State = [[-0.24608862 -0.05120229  0.15265496  1.        ]]. Action = [[ 0.         0.        -1.9858425  1.       ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [False, True, 2, False, True]
Human Feedback received at timestep 3 of -1
Current timestep = 4. State = [[-0.25368264 -0.05097876  0.0967004   1.        ]]. Action = [[ 0.         0.        -1.4602067  1.       ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [False, True, 2, False, True]
Human Feedback received at timestep 4 of -1
Current timestep = 5. State = [[-0.25088352 -0.05238655  0.05902578  1.        ]]. Action = [[0.        0.        1.0714314 1.       ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [False, True, 2, False, True]
Human Feedback received at timestep 5 of 1
Current timestep = 6. State = [[-0.24376312 -0.05369249  0.08268264  1.        ]]. Action = [[0.        0.        1.1012421 1.       ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [False, True, 2, False, True]
Human Feedback received at timestep 6 of 1
Current timestep = 7. State = [[-0.24347319 -0.05319605  0.1039159   1.        ]]. Action = [[ 0.         0.        -1.2056339  1.       ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [False, True, 2, False, True]
Human Feedback received at timestep 7 of -1
Current timestep = 8. State = [[-0.24917331 -0.05301291  0.08671259  1.        ]]. Action = [[ 0.         0.        -1.3218414  1.       ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [False, True, 2, False, True]
Human Feedback received at timestep 8 of 0
Current timestep = 9. State = [[-0.24551225 -0.05348888  0.09464611  1.        ]]. Action = [[0.        0.        1.0569367 1.       ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [False, True, 2, False, True]
Human Feedback received at timestep 9 of 1
Current timestep = 10. State = [[-0.23873976 -0.0546403   0.11928928  1.        ]]. Action = [[0.        0.        1.0646889 1.       ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [False, True, 2, False, True]
Human Feedback received at timestep 10 of 1
Current timestep = 11. State = [[-0.23627815 -0.05445003  0.16273423  1.        ]]. Action = [[0.        0.        1.3197896 1.       ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [False, True, 2, False, True]
Human Feedback received at timestep 11 of 1
Current timestep = 12. State = [[-0.23496626 -0.05434566  0.21439514  1.        ]]. Action = [[0.       0.       1.958461 1.      ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [False, True, 2, False, True]
Human Feedback received at timestep 12 of 1
Current timestep = 13. State = [[-0.24320278 -0.05260639  0.28373042  1.        ]]. Action = [[0.        0.        0.6741924 1.       ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [False, True, 2, True, False]
Human Feedback received at timestep 13 of 1
Current timestep = 14. State = [[-0.23729044 -0.05264799  0.31789267  1.        ]]. Action = [[0.        0.        1.2126293 1.       ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [False, True, 2, True, False]
Human Feedback received at timestep 14 of 1
Current timestep = 15. State = [[-0.23545733 -0.05254598  0.35447538  1.        ]]. Action = [[0.        0.        1.9366212 1.       ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [False, True, 2, True, False]
Human Feedback received at timestep 15 of 0
Current timestep = 16. State = [[-0.23410188 -0.05276523  0.35498872  1.        ]]. Action = [[ 0.          0.         -0.53050923  1.        ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [False, True, 2, True, False]
Human Feedback received at timestep 16 of -1
Current timestep = 17. State = [[-0.23400941 -0.0532257   0.3601519   1.        ]]. Action = [[0.        0.        0.9398024 1.       ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [False, True, 2, True, False]
Human Feedback received at timestep 17 of 1
Current timestep = 18. State = [[-0.23556131 -0.05301059  0.36999968  1.        ]]. Action = [[ 0.          0.         -0.64967155  1.        ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [False, True, 2, True, False]
Human Feedback received at timestep 18 of 0
Current timestep = 19. State = [[-0.23661688 -0.05310108  0.35925886  1.        ]]. Action = [[ 0.          0.         -0.72507215  1.        ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [False, True, 2, True, False]
Human Feedback received at timestep 19 of 0
Current timestep = 20. State = [[-0.2335548  -0.05340216  0.34427863  1.        ]]. Action = [[0.        0.        1.8076501 1.       ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [False, True, 2, True, False]
Human Feedback received at timestep 20 of 0
Current timestep = 21. State = [[-0.2336674  -0.05339006  0.34418482  1.        ]]. Action = [[0.        0.        1.5681357 1.       ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [False, True, 2, True, False]
Human Feedback received at timestep 21 of 0
Current timestep = 22. State = [[-0.23334357 -0.05352684  0.34902743  1.        ]]. Action = [[0.        0.        0.8689892 1.       ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [False, True, 2, True, False]
Human Feedback received at timestep 22 of 1
Current timestep = 23. State = [[-0.23365396 -0.05358744  0.35615554  1.        ]]. Action = [[0.        0.        1.4899302 1.       ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [False, True, 2, True, False]
Human Feedback received at timestep 23 of 0
Current timestep = 24. State = [[-0.23365396 -0.05358744  0.35615554  1.        ]]. Action = [[0.        0.        1.4807603 1.       ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [False, True, 2, True, False]
Human Feedback received at timestep 24 of 0
Current timestep = 25. State = [[-0.2332894  -0.05354345  0.36173815  1.        ]]. Action = [[0.         0.         0.46287847 1.        ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [False, True, 2, True, False]
Human Feedback received at timestep 25 of 0
Current timestep = 26. State = [[-0.23623651 -0.05311681  0.37073532  1.        ]]. Action = [[0.        0.        1.2665915 1.       ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [False, True, 2, True, False]
Human Feedback received at timestep 26 of 0
Current timestep = 27. State = [[-0.23623651 -0.05311681  0.37073532  1.        ]]. Action = [[0.        0.        1.9140658 1.       ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [False, True, 2, True, False]
Human Feedback received at timestep 27 of 0
Current timestep = 28. State = [[-0.23792197 -0.05284812  0.36085448  1.        ]]. Action = [[ 0.         0.        -1.3949513  1.       ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [False, True, 2, True, False]
Human Feedback received at timestep 28 of -1
Current timestep = 29. State = [[-0.23278701 -0.05347278  0.34872866  1.        ]]. Action = [[0.        0.        1.0154529 1.       ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [False, True, 2, True, False]
Human Feedback received at timestep 29 of 1
Current timestep = 30. State = [[-0.23497957 -0.05298988  0.3463958   1.        ]]. Action = [[ 0.        0.       -1.495092  1.      ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [False, True, 2, True, False]
Human Feedback received at timestep 30 of -1
Current timestep = 31. State = [[-0.23551773 -0.0535363   0.30951607  1.        ]]. Action = [[ 0.         0.        -1.3093023  1.       ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [False, True, 2, True, False]
Human Feedback received at timestep 31 of -1
Current timestep = 32. State = [[-0.2330004  -0.05396273  0.27960172  1.        ]]. Action = [[0.       0.       1.651021 1.      ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [False, True, 2, True, False]
Human Feedback received at timestep 32 of 0
Current timestep = 33. State = [[-0.23649848 -0.05296389  0.3259472   1.        ]]. Action = [[0.        0.        1.2498207 1.       ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [False, True, 2, True, False]
Human Feedback received at timestep 33 of 1
Current timestep = 34. State = [[-0.23634352 -0.05314072  0.37092385  1.        ]]. Action = [[0.        0.        0.8391068 1.       ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [False, True, 2, True, False]
Human Feedback received at timestep 34 of 1
Current timestep = 35. State = [[-0.23673709 -0.05325297  0.39365318  1.        ]]. Action = [[ 0.          0.         -0.44146585  1.        ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [False, True, 2, True, False]
Human Feedback received at timestep 35 of 0
Current timestep = 36. State = [[-0.23704796 -0.05349135  0.39327404  1.        ]]. Action = [[0.        0.        1.5637498 1.       ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [False, True, 2, True, False]
Human Feedback received at timestep 36 of 0
Current timestep = 37. State = [[-0.23711903 -0.0535784   0.39318138  1.        ]]. Action = [[0.        0.        1.5338297 1.       ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [False, True, 2, True, False]
Human Feedback received at timestep 37 of 0
Current timestep = 38. State = [[-0.23711903 -0.0535784   0.39318138  1.        ]]. Action = [[0.        0.        1.0727763 1.       ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [False, True, 2, True, False]
Human Feedback received at timestep 38 of 0
Current timestep = 39. State = [[-0.23711903 -0.0535784   0.39318138  1.        ]]. Action = [[0.        0.        1.8370185 1.       ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [False, True, 2, True, False]
Human Feedback received at timestep 39 of 0
Current timestep = 40. State = [[-0.23711903 -0.0535784   0.39318138  1.        ]]. Action = [[0.        0.        1.1425116 1.       ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [False, True, 2, True, False]
Human Feedback received at timestep 40 of 0
Current timestep = 41. State = [[-0.23711903 -0.0535784   0.39318138  1.        ]]. Action = [[0.        0.        1.8276925 1.       ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [False, True, 2, True, False]
Human Feedback received at timestep 41 of 0
Current timestep = 42. State = [[-0.24001238 -0.05315513  0.3786125   1.        ]]. Action = [[ 0.         0.        -1.4940741  1.       ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [False, True, 2, True, False]
Human Feedback received at timestep 42 of -1
Current timestep = 43. State = [[-0.23317228 -0.05383478  0.33208945  1.        ]]. Action = [[ 0.         0.        -0.6461077  1.       ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [False, True, 2, True, False]
Human Feedback received at timestep 43 of -1
Current timestep = 44. State = [[-0.23223002 -0.05415407  0.30656943  1.        ]]. Action = [[ 0.        0.       -0.610185  1.      ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [False, True, 2, True, False]
Human Feedback received at timestep 44 of -1
Current timestep = 45. State = [[-0.23675871 -0.05428269  0.2782779   1.        ]]. Action = [[ 0.        0.       -0.814754  1.      ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [False, True, 2, True, False]
Human Feedback received at timestep 45 of -1
Current timestep = 46. State = [[-0.23515715 -0.05425617  0.25423598  1.        ]]. Action = [[ 0.          0.         -0.08180773  1.        ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [False, True, 2, True, False]
Human Feedback received at timestep 46 of 0
Current timestep = 47. State = [[-0.23563592 -0.05368861  0.25312766  1.        ]]. Action = [[0.       0.       0.359442 1.      ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [False, True, 2, True, False]
Human Feedback received at timestep 47 of 0
Current timestep = 48. State = [[-0.23523486 -0.0537621   0.25516874  1.        ]]. Action = [[0.         0.         0.20898366 1.        ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [False, True, 2, True, False]
Human Feedback received at timestep 48 of 1
Current timestep = 49. State = [[-0.23628731 -0.0536024   0.25037533  1.        ]]. Action = [[ 0.         0.        -1.0484926  1.       ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [False, True, 2, True, False]
Human Feedback received at timestep 49 of -1
Current timestep = 50. State = [[-0.23553723 -0.05369974  0.23822832  1.        ]]. Action = [[0.        0.        0.9762974 1.       ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [False, True, 2, True, False]
Human Feedback received at timestep 50 of 1
Current timestep = 51. State = [[-0.258712    0.04299712  0.11575384  1.        ]]. Action = [[ 0.         0.        -0.0342679  1.       ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 52. State = [[-0.2583307   0.04924461  0.09590948  1.        ]]. Action = [[ 0.         0.        -1.2921236  1.       ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 52 is [False, True, 2, False, True]
Human Feedback received at timestep 52 of -1
Current timestep = 53. State = [[-0.2601743   0.04983448  0.0488803   1.        ]]. Action = [[ 0.          0.         -0.33979356  1.        ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 53 is [False, True, 2, False, True]
Human Feedback received at timestep 53 of -1
Current timestep = 54. State = [[-0.25939795  0.04998524  0.0409112   1.        ]]. Action = [[ 0.          0.         -0.31635094  1.        ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 54 is [False, True, 2, False, True]
Human Feedback received at timestep 54 of 0
Current timestep = 55. State = [[-0.25587118  0.04927761  0.04649813  1.        ]]. Action = [[0.        0.        0.9384763 1.       ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 55 is [False, True, 2, False, True]
Human Feedback received at timestep 55 of 1
Current timestep = 56. State = [[-0.2523934   0.05080565  0.05510178  1.        ]]. Action = [[ 0.          0.         -0.32220078  1.        ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 56 is [False, True, 2, False, True]
Human Feedback received at timestep 56 of 0
Current timestep = 57. State = [[-0.2524693   0.05079778  0.05509122  1.        ]]. Action = [[ 0.         0.        -1.0035576  1.       ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 57 is [False, True, 2, False, True]
Human Feedback received at timestep 57 of 0
Current timestep = 58. State = [[-0.24955074  0.05045833  0.06594259  1.        ]]. Action = [[0.        0.        1.4088788 1.       ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 58 is [False, True, 2, False, True]
Human Feedback received at timestep 58 of 1
Current timestep = 59. State = [[-0.24554019  0.05130062  0.10981531  1.        ]]. Action = [[0.        0.        1.2740209 1.       ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 59 is [False, True, 2, False, True]
Human Feedback received at timestep 59 of 1
Current timestep = 60. State = [[-0.24707955  0.05314182  0.15668191  1.        ]]. Action = [[0.        0.        0.7602093 1.       ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 60 is [False, True, 2, False, True]
Human Feedback received at timestep 60 of 1
Current timestep = 61. State = [[-0.25108334  0.05173193  0.16538893  1.        ]]. Action = [[ 0.         0.        -1.5198964  1.       ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 61 is [False, True, 2, False, True]
Human Feedback received at timestep 61 of -1
Current timestep = 62. State = [[-0.25601298  0.05153951  0.12833436  1.        ]]. Action = [[ 0.          0.         -0.66979337  1.        ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 62 is [False, True, 2, False, True]
Human Feedback received at timestep 62 of -1
Current timestep = 63. State = [[-0.25213322  0.05157479  0.12042575  1.        ]]. Action = [[0.        0.        1.0972311 1.       ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 63 is [False, True, 2, False, True]
Human Feedback received at timestep 63 of 0
Current timestep = 64. State = [[-0.24736777  0.05239113  0.136868    1.        ]]. Action = [[0.         0.         0.07587123 1.        ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 64 is [False, True, 2, False, True]
Human Feedback received at timestep 64 of 1
Current timestep = 65. State = [[-0.24750939  0.05235146  0.13765918  1.        ]]. Action = [[ 0.          0.         -0.05164111  1.        ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 65 is [False, True, 2, False, True]
Human Feedback received at timestep 65 of 0
Current timestep = 66. State = [[-0.24665873  0.05227279  0.1442153   1.        ]]. Action = [[0.         0.         0.60558176 1.        ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 66 is [False, True, 2, False, True]
Human Feedback received at timestep 66 of 1
Current timestep = 67. State = [[-0.24694826  0.05234741  0.15765786  1.        ]]. Action = [[ 0.         0.        -0.3090794  1.       ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 67 is [False, True, 2, False, True]
Human Feedback received at timestep 67 of 0
Current timestep = 68. State = [[-0.24796665  0.05222905  0.16002326  1.        ]]. Action = [[0.         0.         0.47867393 1.        ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 68 is [False, True, 2, False, True]
Human Feedback received at timestep 68 of 1
Current timestep = 69. State = [[-0.25053436  0.05212729  0.15973958  1.        ]]. Action = [[ 0.         0.        -0.9556351  1.       ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 69 is [False, True, 2, False, True]
Human Feedback received at timestep 69 of -1
Current timestep = 70. State = [[-0.2549963   0.05155377  0.1396426   1.        ]]. Action = [[ 0.          0.         -0.56233037  1.        ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 70 is [False, True, 2, False, True]
Human Feedback received at timestep 70 of -1
Current timestep = 71. State = [[-0.25774956  0.05157918  0.11774711  1.        ]]. Action = [[ 0.         0.        -1.0372641  1.       ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 71 is [False, True, 2, False, True]
Human Feedback received at timestep 71 of -1
Current timestep = 72. State = [[-0.26055363  0.0507763   0.0775256   1.        ]]. Action = [[ 0.        0.       -0.677878  1.      ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 72 is [False, True, 2, False, True]
Human Feedback received at timestep 72 of -1
Current timestep = 73. State = [[-0.25794208  0.05090375  0.06045108  1.        ]]. Action = [[ 0.          0.         -0.86768794  1.        ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 73 is [False, True, 2, False, True]
Human Feedback received at timestep 73 of 0
Current timestep = 74. State = [[-0.25794208  0.05090375  0.06045108  1.        ]]. Action = [[0.         0.         0.15496969 1.        ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 74 is [False, True, 2, False, True]
Human Feedback received at timestep 74 of 0
Current timestep = 75. State = [[-0.25142336  0.05114239  0.0712785   1.        ]]. Action = [[0.        0.        1.1690092 1.       ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 75 is [False, True, 2, False, True]
Human Feedback received at timestep 75 of 1
Current timestep = 76. State = [[-0.24553746  0.05238182  0.09087682  1.        ]]. Action = [[ 0.         0.        -0.0619874  1.       ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 76 is [False, True, 2, False, True]
Human Feedback received at timestep 76 of 0
Current timestep = 77. State = [[-0.24356595  0.0523522   0.10599524  1.        ]]. Action = [[0.        0.        1.4787297 1.       ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 77 is [False, True, 2, False, True]
Human Feedback received at timestep 77 of 1
Current timestep = 78. State = [[-0.24621776  0.05331018  0.14408787  1.        ]]. Action = [[ 0.          0.         -0.27056718  1.        ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 78 is [False, True, 2, False, True]
Human Feedback received at timestep 78 of 0
Current timestep = 79. State = [[-0.24685119  0.05315113  0.14652488  1.        ]]. Action = [[0.        0.        0.4270532 1.       ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 79 is [False, True, 2, False, True]
Human Feedback received at timestep 79 of 1
Current timestep = 80. State = [[-0.24595661  0.0534424   0.15620619  1.        ]]. Action = [[0.         0.         0.29256558 1.        ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 80 is [False, True, 2, False, True]
Human Feedback received at timestep 80 of 1
Current timestep = 81. State = [[-0.24778822  0.05345736  0.15849234  1.        ]]. Action = [[ 0.          0.         -0.63052034  1.        ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 81 is [False, True, 2, False, True]
Human Feedback received at timestep 81 of -1
Current timestep = 82. State = [[-0.24794213  0.05336206  0.15812449  1.        ]]. Action = [[0.        0.        0.5594337 1.       ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 82 is [False, True, 2, False, True]
Human Feedback received at timestep 82 of 1
Current timestep = 83. State = [[-0.24477108  0.05399431  0.17539738  1.        ]]. Action = [[0.       0.       1.810432 1.      ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 83 is [False, True, 2, False, True]
Human Feedback received at timestep 83 of 1
Current timestep = 84. State = [[-0.24941511  0.05391042  0.23931298  1.        ]]. Action = [[0.        0.        0.5388112 1.       ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 84 is [False, True, 2, True, False]
Human Feedback received at timestep 84 of 1
Current timestep = 85. State = [[-0.24555239  0.0549654   0.26381963  1.        ]]. Action = [[0.         0.         0.74309874 1.        ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 85 is [False, True, 2, True, False]
Human Feedback received at timestep 85 of 1
Current timestep = 86. State = [[-0.24582832  0.05584767  0.29277098  1.        ]]. Action = [[0.       0.       0.817374 1.      ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 86 is [False, True, 2, True, False]
Human Feedback received at timestep 86 of 1
Current timestep = 87. State = [[-0.24320202  0.05620084  0.313851    1.        ]]. Action = [[ 0.          0.         -0.44596565  1.        ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 87 is [False, True, 2, True, False]
Human Feedback received at timestep 87 of 0
Current timestep = 88. State = [[-0.24366745  0.05608594  0.30946776  1.        ]]. Action = [[ 0.          0.         -0.36504328  1.        ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 88 is [False, True, 2, True, False]
Human Feedback received at timestep 88 of -1
Current timestep = 89. State = [[-0.24405862  0.05596868  0.30325395  1.        ]]. Action = [[ 0.          0.         -0.01384008  1.        ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 89 is [False, True, 2, True, False]
Human Feedback received at timestep 89 of 0
Current timestep = 90. State = [[-0.24426512  0.05592367  0.2997296   1.        ]]. Action = [[ 0.          0.         -0.26726735  1.        ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 90 is [False, True, 2, True, False]
Human Feedback received at timestep 90 of -1
Current timestep = 91. State = [[-0.24524526  0.0554234   0.28634912  1.        ]]. Action = [[ 0.         0.        -0.8528304  1.       ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 91 is [False, True, 2, True, False]
Human Feedback received at timestep 91 of -1
Current timestep = 92. State = [[-0.24101885  0.05484415  0.25958225  1.        ]]. Action = [[ 0.          0.         -0.08590353  1.        ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 92 is [False, True, 2, True, False]
Human Feedback received at timestep 92 of 0
Current timestep = 93. State = [[-0.24072906  0.05483727  0.26034874  1.        ]]. Action = [[0.        0.        0.4968362 1.       ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 93 is [False, True, 2, True, False]
Human Feedback received at timestep 93 of 1
Current timestep = 94. State = [[-0.2393974   0.05532414  0.27057707  1.        ]]. Action = [[0.        0.        0.6896062 1.       ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 94 is [False, True, 2, True, False]
Human Feedback received at timestep 94 of 1
Current timestep = 95. State = [[-0.24096835  0.05559932  0.29518092  1.        ]]. Action = [[0.         0.         0.69211864 1.        ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 95 is [False, True, 2, True, False]
Human Feedback received at timestep 95 of 1
Current timestep = 96. State = [[-0.24245408  0.05570819  0.32146513  1.        ]]. Action = [[0.        0.        0.7142267 1.       ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 96 is [False, True, 2, True, False]
Human Feedback received at timestep 96 of 1
Current timestep = 97. State = [[-0.24332462  0.05556546  0.33552617  1.        ]]. Action = [[ 0.          0.         -0.64433837  1.        ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 97 is [False, True, 2, True, False]
Human Feedback received at timestep 97 of -1
Current timestep = 98. State = [[-0.24335718  0.05548718  0.3309287   1.        ]]. Action = [[0.         0.         0.09849787 1.        ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 98 is [False, True, 2, True, False]
Human Feedback received at timestep 98 of 0
Current timestep = 99. State = [[-0.24344319  0.0554306   0.32769856  1.        ]]. Action = [[ 0.          0.         -0.38651466  1.        ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 99 is [False, True, 2, True, False]
Human Feedback received at timestep 99 of -1
Current timestep = 100. State = [[-0.24028668  0.055301    0.31979626  1.        ]]. Action = [[ 0.5680195   0.         -0.20830381  1.        ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 100 is [False, True, 0, True, False]
Human Feedback received at timestep 100 of -1
Current timestep = 101. State = [[-0.22589625  0.05548928  0.3171066   1.        ]]. Action = [[0.2045722 0.        0.6140666 1.       ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 101 is [False, True, 0, True, False]
Human Feedback received at timestep 101 of 1
Current timestep = 102. State = [[-0.22468005  0.05560041  0.31944782  1.        ]]. Action = [[-0.80336493  0.         -0.5500972   1.        ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 102 is [False, True, 0, True, False]
Human Feedback received at timestep 102 of -1
Current timestep = 103. State = [[-0.26235193  0.13432272  0.11426076  1.        ]]. Action = [[ 0.00827956  0.         -0.04850996  1.        ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 104. State = [[-0.25926518  0.15020125  0.1001249   1.        ]]. Action = [[-0.7475981  0.         0.7407901  1.       ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 104 is [False, True, 0, True, False]
Human Feedback received at timestep 104 of 0
Current timestep = 105. State = [[-0.25904995  0.15026744  0.10018686  1.        ]]. Action = [[-0.7932153  0.         1.5161963  1.       ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 105 is [False, True, 0, True, False]
Human Feedback received at timestep 105 of 0
Current timestep = 106. State = [[-0.2587692   0.1503538   0.10026786  1.        ]]. Action = [[-0.6035479  0.         1.6672549  1.       ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 106 is [False, True, 0, True, False]
Human Feedback received at timestep 106 of 0
Current timestep = 107. State = [[-0.2502678   0.15098253  0.11066575  1.        ]]. Action = [[0.46687293 0.         1.3527966  1.        ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 107 is [False, True, 0, True, False]
Human Feedback received at timestep 107 of 1
Current timestep = 108. State = [[-0.23717117  0.15148003  0.13628909  1.        ]]. Action = [[0.4282205  0.         0.05340266 1.        ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 108 is [False, True, 0, True, False]
Human Feedback received at timestep 108 of 1
Current timestep = 109. State = [[-0.2206744   0.1525709   0.15423621  1.        ]]. Action = [[0.14682841 0.         1.0639591  1.        ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 109 is [False, True, 0, True, False]
Human Feedback received at timestep 109 of 1
Current timestep = 110. State = [[-0.21742453  0.15485683  0.19079332  1.        ]]. Action = [[-0.27229357  0.          0.85240674  1.        ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 110 is [False, True, 0, True, False]
Human Feedback received at timestep 110 of -1
Current timestep = 111. State = [[-0.21572615  0.15434197  0.21637286  1.        ]]. Action = [[0.8204484  0.         0.13729501 1.        ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 111 is [False, True, 0, True, False]
Human Feedback received at timestep 111 of 1
Current timestep = 112. State = [[-0.19130698  0.1548483   0.23489925  1.        ]]. Action = [[0.45976222 0.         0.7311189  1.        ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 112 is [False, True, 0, True, False]
Human Feedback received at timestep 112 of 1
Current timestep = 113. State = [[-0.16436289  0.15628324  0.26235187  1.        ]]. Action = [[0.85001004 0.         0.73880076 1.        ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 113 is [False, True, 0, True, False]
Human Feedback received at timestep 113 of 1
Current timestep = 114. State = [[-0.14156243  0.15645732  0.28631404  1.        ]]. Action = [[ 0.27909946  0.         -0.02102053  1.        ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 114 is [False, True, 0, True, False]
Human Feedback received at timestep 114 of 1
Current timestep = 115. State = [[-0.13578139  0.15838091  0.28022859  1.        ]]. Action = [[-0.4930755   0.         -0.59823024  1.        ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 115 is [False, True, 0, True, False]
Human Feedback received at timestep 115 of -1
Current timestep = 116. State = [[-0.13842972  0.15956667  0.27893576  1.        ]]. Action = [[-0.18286937  0.          0.8323438   1.        ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 116 is [False, True, 0, True, False]
Human Feedback received at timestep 116 of -1
Current timestep = 117. State = [[-0.14313495  0.15833937  0.298422    1.        ]]. Action = [[0.42880368 0.         0.65110874 1.        ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 117 is [False, True, 0, True, False]
Human Feedback received at timestep 117 of 1
Current timestep = 118. State = [[-0.13093796  0.15802486  0.3078019   1.        ]]. Action = [[ 0.55715966  0.         -0.73626626  1.        ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 118 is [False, True, 0, True, False]
Human Feedback received at timestep 118 of 1
Current timestep = 119. State = [[-0.11898915  0.15837373  0.2913581   1.        ]]. Action = [[ 0.25792146  0.         -0.46394515  1.        ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 119 is [False, True, 0, True, False]
Human Feedback received at timestep 119 of 1
Current timestep = 120. State = [[-0.11499471  0.15965404  0.27198526  1.        ]]. Action = [[-0.45658815  0.         -1.1676517   1.        ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 120 is [False, True, 0, True, False]
Human Feedback received at timestep 120 of 0
Current timestep = 121. State = [[-0.10592596  0.15956154  0.2497129   1.        ]]. Action = [[0.7567493  0.         0.82947993 1.        ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 121 is [False, True, 0, True, False]
Human Feedback received at timestep 121 of 1
Current timestep = 122. State = [[-0.08750987  0.15879929  0.26274088  1.        ]]. Action = [[0.99139476 0.         0.14258313 1.        ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 122 is [False, True, 0, True, False]
Human Feedback received at timestep 122 of 1
Current timestep = 123. State = [[-0.06027659  0.16068949  0.27183184  1.        ]]. Action = [[0.39909565 0.         0.23494363 1.        ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 123 is [False, True, 0, True, False]
Human Feedback received at timestep 123 of 1
Current timestep = 124. State = [[-0.04896238  0.15965162  0.28048542  1.        ]]. Action = [[-0.20500052  0.          0.10562491  1.        ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 124 is [False, True, 0, True, False]
Human Feedback received at timestep 124 of 0
Current timestep = 125. State = [[-0.03976831  0.15802686  0.2942336   1.        ]]. Action = [[0.94251037 0.         0.9142506  1.        ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 125 is [False, True, 0, True, False]
Human Feedback received at timestep 125 of 1
Current timestep = 126. State = [[-0.00836924  0.15867317  0.32332596  1.        ]]. Action = [[0.95847297 0.         0.407856   1.        ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 126 is [False, True, 0, True, False]
Human Feedback received at timestep 126 of 1
Current timestep = 127. State = [[0.02604233 0.15863357 0.32770175 1.        ]]. Action = [[ 0.97921896  0.         -0.7457447   1.        ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 127 is [False, True, 0, False, True]
Human Feedback received at timestep 127 of -1
Current timestep = 128. State = [[0.06371597 0.16244376 0.29885256 1.        ]]. Action = [[ 0.19449234  0.         -0.16357028  1.        ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 128 is [False, True, 0, False, True]
Human Feedback received at timestep 128 of -1
Current timestep = 129. State = [[0.07018196 0.16342796 0.29660162 1.        ]]. Action = [[ 0.6265656  0.        -0.4066229  1.       ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 129 is [False, True, 0, False, True]
Human Feedback received at timestep 129 of -1
Current timestep = 130. State = [[0.0720861  0.16262019 0.29884136 1.        ]]. Action = [[0.23760092 0.         0.139184   1.        ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 130 is [False, True, 0, False, True]
Human Feedback received at timestep 130 of -1
Current timestep = 131. State = [[0.07343713 0.16307123 0.30080536 1.        ]]. Action = [[ 0.7576282   0.         -0.01437128  1.        ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 131 is [False, True, 0, False, True]
Human Feedback received at timestep 131 of 0
Current timestep = 132. State = [[0.0762687  0.16272248 0.30268782 1.        ]]. Action = [[0.37951636 0.         0.15323281 1.        ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 132 is [False, True, 0, False, True]
Human Feedback received at timestep 132 of -1
Current timestep = 133. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[ 0.8720536   0.         -0.33601642  1.        ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 133 is [False, True, 0, False, True]
Human Feedback received at timestep 133 of 0
Current timestep = 134. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[ 0.8716122  0.        -1.5460893  1.       ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 134 is [False, True, 0, False, True]
Human Feedback received at timestep 134 of 0
Current timestep = 135. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[0.91225994 0.         0.25341773 1.        ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 135 is [False, True, 0, False, True]
Human Feedback received at timestep 135 of 0
Current timestep = 136. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[0.96958566 0.         0.6364255  1.        ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 136 is [False, True, 0, False, True]
Human Feedback received at timestep 136 of 0
Current timestep = 137. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[0.45870948 0.         0.49970818 1.        ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 137 is [False, True, 0, False, True]
Human Feedback received at timestep 137 of 0
Current timestep = 138. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[ 0.7097571   0.         -0.24476612  1.        ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 138 is [False, True, 0, False, True]
Human Feedback received at timestep 138 of 0
Current timestep = 139. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[0.7085397  0.         0.52826285 1.        ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 139 is [False, True, 0, False, True]
Human Feedback received at timestep 139 of 0
Current timestep = 140. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[0.6439725 0.        0.2801838 1.       ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 140 is [False, True, 0, False, True]
Human Feedback received at timestep 140 of 0
Current timestep = 141. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[ 0.86237454  0.         -0.7536721   1.        ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 141 is [False, True, 0, False, True]
Human Feedback received at timestep 141 of 0
Current timestep = 142. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[ 0.6087513   0.         -0.45794964  1.        ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 142 is [False, True, 0, False, True]
Human Feedback received at timestep 142 of 0
Current timestep = 143. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[0.72435665 0.         0.11428165 1.        ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 143 is [False, True, 0, False, True]
Human Feedback received at timestep 143 of 0
Current timestep = 144. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[ 0.54371977  0.         -0.5105009   1.        ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 144 is [False, True, 0, False, True]
Human Feedback received at timestep 144 of 0
Current timestep = 145. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[ 0.3825333   0.         -0.08809435  1.        ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 145 is [False, True, 0, False, True]
Human Feedback received at timestep 145 of 0
Current timestep = 146. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[0.73059034 0.         0.64141846 1.        ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 146 is [False, True, 0, False, True]
Human Feedback received at timestep 146 of 0
Current timestep = 147. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[ 0.26885843  0.         -0.6810591   1.        ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 147 is [False, True, 0, False, True]
Human Feedback received at timestep 147 of 0
Current timestep = 148. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[ 0.358361    0.         -0.84563875  1.        ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 148 is [False, True, 0, False, True]
Human Feedback received at timestep 148 of 0
Current timestep = 149. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[ 0.6477195  0.        -0.6257193  1.       ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 149 is [False, True, 0, False, True]
Human Feedback received at timestep 149 of 0
Current timestep = 150. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[0.9043087 0.        1.150543  1.       ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 150 is [False, True, 0, False, True]
Human Feedback received at timestep 150 of 0
Current timestep = 151. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[ 0.4502082   0.         -0.48237586  1.        ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 151 is [False, True, 0, False, True]
Human Feedback received at timestep 151 of 0
Current timestep = 152. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[0.56055975 0.         0.04097462 1.        ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 152 is [False, True, 0, False, True]
Human Feedback received at timestep 152 of 0
Current timestep = 153. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[0.5519041 0.        0.5101502 1.       ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 153 is [False, True, 0, False, True]
Human Feedback received at timestep 153 of 0
Current timestep = 154. State = [[0.09266772 0.1639115  0.3066522  1.        ]]. Action = [[0.8241234  0.         0.20907354 1.        ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 154 is [False, True, 0, False, True]
Human Feedback received at timestep 154 of 0
Current timestep = 155. State = [[-0.26956725  0.09948769  0.10732765  1.        ]]. Action = [[-0.02669573  0.          0.02348852  1.        ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 156. State = [[-0.2537661   0.11085258  0.10612071  1.        ]]. Action = [[0.7854887 0.        1.4964504 1.       ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 156 is [False, True, 0, True, False]
Human Feedback received at timestep 156 of 1
Current timestep = 157. State = [[-0.2256849   0.11204511  0.15295812  1.        ]]. Action = [[0.59455144 0.         1.5993681  1.        ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 157 is [False, True, 0, True, False]
Human Feedback received at timestep 157 of 1
Current timestep = 158. State = [[-0.19670618  0.11444687  0.20884575  1.        ]]. Action = [[0.8265512 0.        0.7564192 1.       ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 158 is [False, True, 0, True, False]
Human Feedback received at timestep 158 of 1
Current timestep = 159. State = [[-0.16347232  0.11535355  0.23828638  1.        ]]. Action = [[0.84575474 0.         0.58484554 1.        ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 159 is [False, True, 0, True, False]
Human Feedback received at timestep 159 of 1
Current timestep = 160. State = [[-0.13983335  0.11453008  0.26151913  1.        ]]. Action = [[0.32748246 0.         0.31914926 1.        ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 160 is [False, True, 0, True, False]
Human Feedback received at timestep 160 of 1
Current timestep = 161. State = [[-0.12932123  0.11558438  0.2728433   1.        ]]. Action = [[ 0.03873491  0.         -0.13155007  1.        ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 161 is [False, True, 0, True, False]
Human Feedback received at timestep 161 of 0
Current timestep = 162. State = [[-0.12289774  0.11512675  0.26793864  1.        ]]. Action = [[ 0.8099531  0.        -0.3311553  1.       ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 162 is [False, True, 0, True, False]
Human Feedback received at timestep 162 of 1
Current timestep = 163. State = [[-0.09486602  0.11752981  0.27103347  1.        ]]. Action = [[0.46135497 0.         1.1338589  1.        ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 163 is [False, True, 0, True, False]
Human Feedback received at timestep 163 of 1
Current timestep = 164. State = [[-0.0712698   0.11632836  0.29671475  1.        ]]. Action = [[ 0.77280784  0.         -0.18912339  1.        ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 164 is [False, True, 0, True, False]
Human Feedback received at timestep 164 of 1
Current timestep = 165. State = [[-0.04660186  0.11754328  0.30015433  1.        ]]. Action = [[0.72715735 0.         0.28035307 1.        ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 165 is [False, True, 0, True, False]
Human Feedback received at timestep 165 of 1
Current timestep = 166. State = [[-0.01479207  0.11588246  0.3068245   1.        ]]. Action = [[ 0.929971    0.         -0.10258281  1.        ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 166 is [False, True, 0, True, False]
Human Feedback received at timestep 166 of 1
Current timestep = 167. State = [[0.02342363 0.11857733 0.30503285 1.        ]]. Action = [[0.8451767  0.         0.20711589 1.        ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 167 is [False, True, 0, False, True]
Human Feedback received at timestep 167 of -1
Current timestep = 168. State = [[0.05825836 0.11857196 0.31446496 1.        ]]. Action = [[0.8074415  0.         0.31674695 1.        ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 168 is [False, True, 0, False, True]
Human Feedback received at timestep 168 of -1
Current timestep = 169. State = [[0.0834186  0.12200884 0.32252917 1.        ]]. Action = [[0.6615472  0.         0.03790259 1.        ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 169 is [False, True, 0, False, True]
Human Feedback received at timestep 169 of 0
Current timestep = 170. State = [[0.08306513 0.1217462  0.32265514 1.        ]]. Action = [[0.6362891 0.        0.0450201 1.       ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 170 is [False, True, 0, False, True]
Human Feedback received at timestep 170 of 0
Current timestep = 171. State = [[0.08301221 0.12174381 0.3175678  1.        ]]. Action = [[ 0.05358088  0.         -0.4700874   1.        ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 171 is [False, True, 0, False, True]
Human Feedback received at timestep 171 of 0
Current timestep = 172. State = [[0.08509652 0.12213136 0.30681473 1.        ]]. Action = [[ 0.9097221  0.        -1.4070313  1.       ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 172 is [False, True, 0, False, True]
Human Feedback received at timestep 172 of 0
Current timestep = 173. State = [[0.08509652 0.12213136 0.30681473 1.        ]]. Action = [[ 0.6445379   0.         -0.23961282  1.        ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 173 is [False, True, 0, False, True]
Human Feedback received at timestep 173 of 0
Current timestep = 174. State = [[0.08509652 0.12213136 0.30681473 1.        ]]. Action = [[ 0.77153707  0.         -0.61174595  1.        ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 174 is [False, True, 0, False, True]
Human Feedback received at timestep 174 of 0
Current timestep = 175. State = [[0.08509652 0.12213136 0.30681473 1.        ]]. Action = [[ 0.39333332  0.         -0.51220024  1.        ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 175 is [False, True, 0, False, True]
Human Feedback received at timestep 175 of 0
Current timestep = 176. State = [[0.08509652 0.12213136 0.30681473 1.        ]]. Action = [[ 0.87552094  0.         -0.4291184   1.        ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 176 is [False, True, 0, False, True]
Human Feedback received at timestep 176 of 0
Current timestep = 177. State = [[0.08509652 0.12213136 0.30681473 1.        ]]. Action = [[ 0.39930487  0.         -0.7080617   1.        ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 177 is [False, True, 0, False, True]
Human Feedback received at timestep 177 of 0
Current timestep = 178. State = [[0.08509652 0.12213136 0.30681473 1.        ]]. Action = [[0.8922503 0.        0.8727808 1.       ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 178 is [False, True, 0, False, True]
Human Feedback received at timestep 178 of 0
Current timestep = 179. State = [[0.08509652 0.12213136 0.30681473 1.        ]]. Action = [[ 0.2846017   0.         -0.02819812  1.        ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 179 is [False, True, 0, False, True]
Human Feedback received at timestep 179 of 0
Current timestep = 180. State = [[0.08158182 0.12360109 0.30126575 1.        ]]. Action = [[-0.89773834  0.         -0.72614384  1.        ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 180 is [False, True, 0, False, True]
Human Feedback received at timestep 180 of 1
Current timestep = 181. State = [[0.07610774 0.12242137 0.28595978 1.        ]]. Action = [[ 0.21399367  0.         -0.62031806  1.        ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 181 is [False, True, 0, False, True]
Human Feedback received at timestep 181 of 1
Current timestep = 182. State = [[0.07796503 0.12249575 0.26207456 1.        ]]. Action = [[0.5981145 0.        0.6237707 1.       ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 182 is [False, True, 0, False, True]
Human Feedback received at timestep 182 of 0
Current timestep = 183. State = [[0.07797661 0.12250921 0.26189935 1.        ]]. Action = [[ 0.5925696   0.         -0.27921486  1.        ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 183 is [False, True, 0, False, True]
Human Feedback received at timestep 183 of 0
Current timestep = 184. State = [[0.07797661 0.12250921 0.26189935 1.        ]]. Action = [[0.7945061  0.         0.44533873 1.        ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 184 is [False, True, 0, False, True]
Human Feedback received at timestep 184 of 0
Current timestep = 185. State = [[0.07796962 0.12250747 0.26182327 1.        ]]. Action = [[0.9973171  0.         0.21838021 1.        ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 185 is [False, True, 0, False, True]
Human Feedback received at timestep 185 of 0
Current timestep = 186. State = [[0.07796962 0.12250747 0.26182327 1.        ]]. Action = [[0.8082452  0.         0.24031973 1.        ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 186 is [False, True, 0, False, True]
Human Feedback received at timestep 186 of 0
Current timestep = 187. State = [[0.07796962 0.12250747 0.26182327 1.        ]]. Action = [[0.88185453 0.         1.564012   1.        ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 187 is [False, True, 0, False, True]
Human Feedback received at timestep 187 of 0
Current timestep = 188. State = [[0.07796962 0.12250747 0.26182327 1.        ]]. Action = [[ 0.8593885   0.         -0.09603524  1.        ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 188 is [False, True, 0, False, True]
Human Feedback received at timestep 188 of 0
Current timestep = 189. State = [[0.07796255 0.12250571 0.26174647 1.        ]]. Action = [[0.9535606  0.         0.72620296 1.        ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 189 is [False, True, 0, False, True]
Human Feedback received at timestep 189 of 0
Current timestep = 190. State = [[0.07831498 0.12247529 0.25813085 1.        ]]. Action = [[-0.03621346  0.         -0.31093335  1.        ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 190 is [False, True, 0, False, True]
Human Feedback received at timestep 190 of 0
Current timestep = 191. State = [[0.07986351 0.1223339  0.2600273  1.        ]]. Action = [[-0.08304149  0.          0.7191353   1.        ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 191 is [False, True, 0, False, True]
Human Feedback received at timestep 191 of -1
Current timestep = 192. State = [[0.07954574 0.1223912  0.2721503  1.        ]]. Action = [[0.79253674 0.         0.5065048  1.        ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 192 is [False, True, 0, False, True]
Human Feedback received at timestep 192 of 0
Current timestep = 193. State = [[0.07954574 0.1223912  0.2721503  1.        ]]. Action = [[0.6116235 0.        0.4092524 1.       ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 193 is [False, True, 0, False, True]
Human Feedback received at timestep 193 of 0
Current timestep = 194. State = [[0.07954574 0.1223912  0.2721503  1.        ]]. Action = [[0.95739603 0.         0.49737835 1.        ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 194 is [False, True, 0, False, True]
Human Feedback received at timestep 194 of 0
Current timestep = 195. State = [[0.07954574 0.1223912  0.2721503  1.        ]]. Action = [[0.9072895 0.        0.2923398 1.       ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 195 is [False, True, 0, False, True]
Human Feedback received at timestep 195 of 0
Current timestep = 196. State = [[0.07574915 0.12525901 0.2844148  1.        ]]. Action = [[-0.98992795  0.          0.6758497   1.        ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 196 is [False, True, 0, False, True]
Human Feedback received at timestep 196 of 1
Current timestep = 197. State = [[0.04981032 0.12693359 0.30316505 1.        ]]. Action = [[ 0.96210957  0.         -0.9591849   1.        ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 197 is [False, True, 0, False, True]
Human Feedback received at timestep 197 of 0
Current timestep = 198. State = [[0.04990016 0.12600538 0.29448855 1.        ]]. Action = [[ 0.4961239   0.         -0.70430565  1.        ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 198 is [False, True, 0, False, True]
Human Feedback received at timestep 198 of -1
Current timestep = 199. State = [[0.05562784 0.12533896 0.27617213 1.        ]]. Action = [[ 0.8123541   0.         -0.15897334  1.        ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 199 is [False, True, 0, False, True]
Human Feedback received at timestep 199 of -1
Current timestep = 200. State = [[0.06652758 0.12384903 0.2658967  1.        ]]. Action = [[ 0.9200604   0.24679244 -0.00404358  1.        ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 200 is [False, True, 1, False, True]
Human Feedback received at timestep 200 of 0
Current timestep = 201. State = [[0.06659167 0.12364244 0.2659191  1.        ]]. Action = [[ 0.8364066  -0.43318534  0.22150373  1.        ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 201 is [False, True, 1, False, True]
Human Feedback received at timestep 201 of 0
Current timestep = 202. State = [[0.0666193  0.12364122 0.2659192  1.        ]]. Action = [[0.8776262 0.5580691 0.1610372 1.       ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 202 is [False, True, 1, False, True]
Human Feedback received at timestep 202 of 0
Current timestep = 203. State = [[0.06657694 0.1214389  0.2735748  1.        ]]. Action = [[-0.81013244 -0.1955899   0.4738481   1.        ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 203 is [False, True, 1, False, True]
Human Feedback received at timestep 203 of 1
Current timestep = 204. State = [[0.05619316 0.11986493 0.27389652 1.        ]]. Action = [[-0.82786566  0.0534972  -0.75614977  1.        ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 204 is [False, True, 1, False, True]
Human Feedback received at timestep 204 of 1
Current timestep = 205. State = [[0.04447984 0.11940104 0.25803158 1.        ]]. Action = [[ 0.5976678  -0.22344857 -0.0909605   1.        ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 205 is [False, True, 1, False, True]
Human Feedback received at timestep 205 of -1
Current timestep = 206. State = [[0.05321075 0.12473524 0.26739666 1.        ]]. Action = [[0.7999959  0.61445665 0.93678045 1.        ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 206 is [False, True, 1, False, True]
Human Feedback received at timestep 206 of -1
Current timestep = 207. State = [[-0.2654489  -0.02528526  0.10377312  1.        ]]. Action = [[ 0.9036267  -0.9773663  -0.44899702  1.        ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 208. State = [[-0.25943014 -0.03810959  0.0959335   1.        ]]. Action = [[ 0.5125514  -0.45739007  0.736675    1.        ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 208 is [False, True, 1, True, False]
Human Feedback received at timestep 208 of -1
Current timestep = 209. State = [[-0.23964757 -0.04991216  0.11640547  1.        ]]. Action = [[0.77929306 0.11101365 1.3696508  1.        ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 209 is [False, True, 1, True, False]
Human Feedback received at timestep 209 of 1
Current timestep = 210. State = [[-0.20763351 -0.06374522  0.16912584  1.        ]]. Action = [[ 0.6165774 -0.9517519  1.1510286  1.       ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 210 is [False, True, 1, True, False]
Human Feedback received at timestep 210 of -1
Current timestep = 211. State = [[-0.18020362 -0.09253418  0.21524118  1.        ]]. Action = [[ 0.5821434 -0.5872452  1.4067059  1.       ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 211 is [False, True, 1, True, False]
Human Feedback received at timestep 211 of -1
Current timestep = 212. State = [[-0.1575524  -0.10810097  0.26962027  1.        ]]. Action = [[0.34882915 0.02911901 0.96649027 1.        ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 212 is [False, True, 1, True, False]
Human Feedback received at timestep 212 of 1
Current timestep = 213. State = [[-0.14165482 -0.12156874  0.29874164  1.        ]]. Action = [[ 0.4961319  -0.8509222  -0.01733112  1.        ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 213 is [False, True, 1, True, False]
Human Feedback received at timestep 213 of -1
Current timestep = 214. State = [[-0.1271688  -0.15277012  0.32389852  1.        ]]. Action = [[ 0.48039067 -0.9127942   1.3024454   1.        ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 214 is [False, True, 1, True, False]
Human Feedback received at timestep 214 of -1
Current timestep = 215. State = [[-0.11015473 -0.16987462  0.34901524  1.        ]]. Action = [[ 0.86796     0.12208128 -0.9784212   1.        ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 215 is [False, True, 1, True, False]
Human Feedback received at timestep 215 of 1
Current timestep = 216. State = [[-0.08068439 -0.17227717  0.3213278   1.        ]]. Action = [[ 0.1181761   0.08608902 -0.22814167  1.        ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 216 is [False, True, 1, True, False]
Human Feedback received at timestep 216 of 0
Current timestep = 217. State = [[-0.07689021 -0.18360326  0.31254214  1.        ]]. Action = [[-0.02274311 -0.85538685 -0.39207816  1.        ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 217 is [False, True, 1, True, False]
Human Feedback received at timestep 217 of -1
Current timestep = 218. State = [[-0.07071176 -0.20858087  0.3035287   1.        ]]. Action = [[ 0.6930394  -0.76242316 -0.05016649  1.        ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 218 is [False, True, 1, True, False]
Human Feedback received at timestep 218 of -1
Current timestep = 219. State = [[-0.0542235  -0.23851936  0.30201483  1.        ]]. Action = [[-0.13145113 -0.6544982   0.12854838  1.        ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 219 is [False, True, 1, True, False]
Human Feedback received at timestep 219 of -1
Current timestep = 220. State = [[-0.05374588 -0.26156676  0.30138353  1.        ]]. Action = [[ 0.68300223 -0.63391155 -0.478415    1.        ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 220 is [False, True, 1, True, False]
Human Feedback received at timestep 220 of -1
Current timestep = 221. State = [[-0.02169929 -0.2831297   0.29119435  1.        ]]. Action = [[ 0.73734546 -0.34116757  0.3839469   1.        ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 221 is [False, True, 1, True, False]
Human Feedback received at timestep 221 of -1
Current timestep = 222. State = [[ 0.00591204 -0.29032263  0.3121021   1.        ]]. Action = [[ 0.712119   -0.04264534  1.1114273   1.        ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 222 is [False, True, 1, True, False]
Human Feedback received at timestep 222 of 0
Current timestep = 223. State = [[ 0.0219765  -0.29538783  0.33609977  1.        ]]. Action = [[ 0.00281107 -0.20577747 -0.65206504  1.        ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 223 is [False, True, 1, True, False]
Human Feedback received at timestep 223 of -1
Current timestep = 224. State = [[ 0.03925141 -0.29056484  0.31700832  1.        ]]. Action = [[0.8133601  0.7856258  0.05961251 1.        ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 224 is [False, True, 1, True, False]
Human Feedback received at timestep 224 of 1
Current timestep = 225. State = [[ 0.06321152 -0.2831731   0.3163674   1.        ]]. Action = [[ 0.35912418 -0.33786666 -0.09638345  1.        ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 225 is [False, True, 1, True, False]
Human Feedback received at timestep 225 of -1
Current timestep = 226. State = [[ 0.07169667 -0.28835478  0.3105957   1.        ]]. Action = [[-0.732351    0.08177578 -0.36495543  1.        ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 226 is [False, True, 1, True, False]
Human Feedback received at timestep 226 of -1
Current timestep = 227. State = [[ 0.06947032 -0.29109424  0.31068712  1.        ]]. Action = [[-0.5611491  -0.8266642  -0.03269899  1.        ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 227 is [False, True, 1, True, False]
Human Feedback received at timestep 227 of 0
Current timestep = 228. State = [[ 0.0691987  -0.29118106  0.31040093  1.        ]]. Action = [[ 0.79728246 -0.55841726  0.54409814  1.        ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 228 is [False, True, 1, True, False]
Human Feedback received at timestep 228 of 0
Current timestep = 229. State = [[ 0.06404449 -0.28583202  0.31430906  1.        ]]. Action = [[-0.93531084  0.63404703  0.35446286  1.        ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 229 is [False, True, 1, True, False]
Human Feedback received at timestep 229 of 1
Current timestep = 230. State = [[ 0.03729536 -0.26718464  0.32058612  1.        ]]. Action = [[-0.45749998  0.33521545 -0.01155508  1.        ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 230 is [False, True, 1, True, False]
Human Feedback received at timestep 230 of 1
Current timestep = 231. State = [[ 0.02966372 -0.24937683  0.3253332   1.        ]]. Action = [[0.839103   0.46877348 0.33258748 1.        ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 231 is [False, True, 1, True, False]
Human Feedback received at timestep 231 of 1
Current timestep = 232. State = [[ 0.04613561 -0.22326498  0.32729307  1.        ]]. Action = [[ 0.9495342   0.8156103  -0.09604955  1.        ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 232 is [False, True, 1, True, False]
Human Feedback received at timestep 232 of 1
Current timestep = 233. State = [[ 0.06862155 -0.19176507  0.33002862  1.        ]]. Action = [[0.4192624  0.727617   0.13173485 1.        ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 233 is [False, True, 1, True, False]
Human Feedback received at timestep 233 of 1
Current timestep = 234. State = [[ 0.08111827 -0.1740323   0.32864708  1.        ]]. Action = [[0.6484871  0.60481715 0.18150544 1.        ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 234 is [False, True, 1, True, False]
Human Feedback received at timestep 234 of 0
Current timestep = 235. State = [[ 0.08082326 -0.16648377  0.32542953  1.        ]]. Action = [[-0.38920575  0.43601704 -0.48473704  1.        ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 235 is [False, True, 1, True, False]
Human Feedback received at timestep 235 of 1
Current timestep = 236. State = [[ 0.07929098 -0.14398186  0.3123132   1.        ]]. Action = [[ 0.08451164  0.8168459  -0.8841016   1.        ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 236 is [False, True, 1, True, False]
Human Feedback received at timestep 236 of 1
Current timestep = 237. State = [[ 0.07481049 -0.13071905  0.27798676  1.        ]]. Action = [[-0.6794456  -0.31686306 -0.66245675  1.        ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 237 is [False, True, 1, True, False]
Human Feedback received at timestep 237 of -1
Current timestep = 238. State = [[ 0.06370068 -0.12842023  0.2765452   1.        ]]. Action = [[-0.6751598   0.74905586  1.5274796   1.        ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 238 is [False, True, 1, True, False]
Human Feedback received at timestep 238 of 1
Current timestep = 239. State = [[ 0.04400171 -0.09669407  0.32033908  1.        ]]. Action = [[0.48758316 0.62296534 0.69842124 1.        ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 239 is [False, True, 1, True, False]
Human Feedback received at timestep 239 of 1
Current timestep = 240. State = [[ 0.0434527  -0.07214975  0.3387097   1.        ]]. Action = [[-0.2089001   0.6671386   0.42423248  1.        ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 240 is [False, True, 1, True, False]
Human Feedback received at timestep 240 of 1
Current timestep = 241. State = [[ 0.04290425 -0.04335366  0.36323962  1.        ]]. Action = [[0.5491103 0.7131314 0.6833396 1.       ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 241 is [False, True, 1, True, False]
Human Feedback received at timestep 241 of 1
Current timestep = 242. State = [[ 0.05374398 -0.02289689  0.38013515  1.        ]]. Action = [[0.5656686  0.29762304 0.25006294 1.        ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 242 is [False, True, 1, True, False]
Human Feedback received at timestep 242 of 1
Current timestep = 243. State = [[ 6.3506871e-02 -4.2880358e-05  3.8468906e-01  1.0000000e+00]]. Action = [[-0.0957669   0.91801906 -0.18197036  1.        ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 243 is [False, True, 1, True, False]
Human Feedback received at timestep 243 of -1
Current timestep = 244. State = [[0.06598867 0.0207916  0.37715897 1.        ]]. Action = [[ 0.28788257  0.08927357 -0.7295861   1.        ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 244 is [False, True, 1, False, True]
Human Feedback received at timestep 244 of 0
Current timestep = 245. State = [[0.07278303 0.03669577 0.35283703 1.        ]]. Action = [[-0.2864915  0.6095073 -0.4332595  1.       ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 245 is [False, True, 1, False, True]
Human Feedback received at timestep 245 of -1
Current timestep = 246. State = [[0.07033975 0.04726697 0.34492293 1.        ]]. Action = [[ 0.9414265   0.8477218  -0.16990352  1.        ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 246 is [False, True, 1, False, True]
Human Feedback received at timestep 246 of 0
Current timestep = 247. State = [[0.06789941 0.05671247 0.3449395  1.        ]]. Action = [[-0.4086597   0.41549695 -0.00343037  1.        ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 247 is [False, True, 1, False, True]
Human Feedback received at timestep 247 of -1
Current timestep = 248. State = [[0.06213788 0.07732831 0.35093915 1.        ]]. Action = [[-0.5908808   0.79070663  0.5480478   1.        ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 248 is [False, True, 1, False, True]
Human Feedback received at timestep 248 of -1
Current timestep = 249. State = [[0.04199937 0.11624981 0.36325705 1.        ]]. Action = [[-0.67778593  0.9218451  -0.11464429  1.        ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 249 is [False, True, 1, False, True]
Human Feedback received at timestep 249 of -1
Current timestep = 250. State = [[0.01991502 0.13948883 0.36142695 1.        ]]. Action = [[ 0.2214663   0.06851339 -0.03330564  1.        ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 250 is [False, True, 1, False, True]
Human Feedback received at timestep 250 of 0
Current timestep = 251. State = [[0.01720668 0.15250976 0.3532383  1.        ]]. Action = [[ 0.18044567  0.84794354 -0.94100046  1.        ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 251 is [False, True, 1, False, True]
Human Feedback received at timestep 251 of -1
Current timestep = 252. State = [[0.01521533 0.18331026 0.31518722 1.        ]]. Action = [[-0.60398614  0.89947677 -0.586359    1.        ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 252 is [False, True, 1, False, True]
Human Feedback received at timestep 252 of -1
Current timestep = 253. State = [[0.00619673 0.21525104 0.29885757 1.        ]]. Action = [[ 0.88703895  0.65776205 -0.4804082   1.        ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 253 is [False, True, 1, False, True]
Human Feedback received at timestep 253 of -1
Current timestep = 254. State = [[0.02346707 0.24391119 0.2840302  1.        ]]. Action = [[-0.17400908  0.59581566  0.73898697  1.        ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 254 is [False, True, 1, False, True]
Human Feedback received at timestep 254 of -1
Current timestep = 255. State = [[0.0183246  0.26707706 0.29310897 1.        ]]. Action = [[-0.17665607  0.73143625 -0.43318546  1.        ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 255 is [False, True, 1, False, True]
Human Feedback received at timestep 255 of -1
Current timestep = 256. State = [[0.01552323 0.28332976 0.2857485  1.        ]]. Action = [[0.40901637 0.7146349  0.34159327 1.        ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 256 is [False, True, 1, False, True]
Human Feedback received at timestep 256 of 0
Current timestep = 257. State = [[0.02101465 0.2799929  0.28890446 1.        ]]. Action = [[ 0.9145982  -0.23270637  0.37715673  1.        ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 257 is [False, True, 1, False, True]
Human Feedback received at timestep 257 of 0
Current timestep = 258. State = [[0.04241128 0.26955447 0.299049   1.        ]]. Action = [[ 0.18915725 -0.45517176  0.4551947   1.        ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 258 is [False, True, 1, False, True]
Human Feedback received at timestep 258 of 1
Current timestep = 259. State = [[-0.25427786 -0.05162458  0.0880881   1.        ]]. Action = [[-0.08244032  0.42090166  0.34466362  1.        ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 260. State = [[-0.24262355 -0.05399984  0.08418003  1.        ]]. Action = [[0.778934   0.58544457 1.2843871  1.        ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 260 is [False, True, 1, True, False]
Human Feedback received at timestep 260 of 1
Current timestep = 261. State = [[-0.21721438 -0.03973038  0.11697043  1.        ]]. Action = [[0.7825651  0.48384666 0.8339133  1.        ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 261 is [False, True, 1, True, False]
Human Feedback received at timestep 261 of 1
Current timestep = 262. State = [[-0.18858598 -0.02103671  0.15014176  1.        ]]. Action = [[0.34974587 0.417135   0.91186833 1.        ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 262 is [False, True, 1, True, False]
Human Feedback received at timestep 262 of 1
Current timestep = 263. State = [[-0.17730512 -0.01106906  0.17189248  1.        ]]. Action = [[0.6019677  0.71047986 0.6857183  1.        ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 263 is [False, True, 1, True, False]
Human Feedback received at timestep 263 of 0
Current timestep = 264. State = [[-1.6268192e-01 -2.6542242e-04  1.9248714e-01  1.0000000e+00]]. Action = [[0.813491   0.59559083 1.5316052  1.        ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 264 is [False, True, 1, True, False]
Human Feedback received at timestep 264 of -1
Current timestep = 265. State = [[-0.13840303  0.01428971  0.23589034  1.        ]]. Action = [[ 0.69616556  0.29478514 -0.02299142  1.        ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 265 is [False, True, 1, False, True]
Human Feedback received at timestep 265 of 0
Current timestep = 266. State = [[-0.1289242   0.01592814  0.24418877  1.        ]]. Action = [[0.74404    0.17740226 0.55020523 1.        ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 266 is [False, True, 1, False, True]
Human Feedback received at timestep 266 of 0
Current timestep = 267. State = [[-0.10233744  0.01837022  0.27610204  1.        ]]. Action = [[ 0.6541152 -0.1912396  1.1809487  1.       ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 267 is [False, True, 1, False, True]
Human Feedback received at timestep 267 of 1
Current timestep = 268. State = [[-0.07952074  0.01217217  0.30540496  1.        ]]. Action = [[ 0.5072273  -0.21361011 -0.41466975  1.        ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 268 is [False, True, 1, False, True]
Human Feedback received at timestep 268 of 1
Current timestep = 269. State = [[-0.06094654  0.01043951  0.30658558  1.        ]]. Action = [[0.7243197 0.1203208 0.3719089 1.       ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 269 is [False, True, 1, False, True]
Human Feedback received at timestep 269 of 0
Current timestep = 270. State = [[-0.03524558  0.01089946  0.32508475  1.        ]]. Action = [[ 0.8375938  -0.11933994  0.67424774  1.        ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 270 is [False, True, 1, False, True]
Human Feedback received at timestep 270 of 0
Current timestep = 271. State = [[-0.00158097  0.01105859  0.35322627  1.        ]]. Action = [[0.8377068  0.07785285 0.51649857 1.        ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 271 is [False, True, 1, False, True]
Human Feedback received at timestep 271 of 0
Current timestep = 272. State = [[0.03195582 0.01652973 0.37043118 1.        ]]. Action = [[0.78406787 0.36876    0.60716295 1.        ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 272 is [False, True, 1, False, True]
Human Feedback received at timestep 272 of -1
Current timestep = 273. State = [[0.05601661 0.02487704 0.3780974  1.        ]]. Action = [[ 0.7988343   0.07879233 -1.5381398   1.        ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 273 is [False, True, 1, False, True]
Human Feedback received at timestep 273 of 0
Current timestep = 274. State = [[0.09240923 0.02723495 0.3269536  1.        ]]. Action = [[ 0.9048773   0.20854652 -0.1352731   1.        ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 274 is [False, True, 1, False, True]
Human Feedback received at timestep 274 of 0
Current timestep = 275. State = [[0.08866107 0.02739609 0.32017815 1.        ]]. Action = [[-0.75999284 -0.03172207 -1.0886499   1.        ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 275 is [False, True, 1, False, True]
Human Feedback received at timestep 275 of 1
Current timestep = 276. State = [[0.08111207 0.03099995 0.28981376 1.        ]]. Action = [[-0.7629141   0.04997277 -0.43489134  1.        ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 276 is [False, True, 1, False, True]
Human Feedback received at timestep 276 of -1
Current timestep = 277. State = [[0.06856921 0.03138324 0.28093463 1.        ]]. Action = [[ 0.61997855 -0.1425618   0.1720345   1.        ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 277 is [False, True, 1, False, True]
Human Feedback received at timestep 277 of 1
Current timestep = 278. State = [[0.07008538 0.02895315 0.28261325 1.        ]]. Action = [[ 0.96894395 -0.04870367  1.2783747   1.        ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 278 is [False, True, 1, False, True]
Human Feedback received at timestep 278 of 0
Current timestep = 279. State = [[0.07008538 0.02895315 0.28261325 1.        ]]. Action = [[0.96026015 0.0204531  1.0336771  1.        ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 279 is [False, True, 1, False, True]
Human Feedback received at timestep 279 of 0
Current timestep = 280. State = [[0.0729198  0.03161794 0.28127328 1.        ]]. Action = [[ 0.5534477   0.29965997 -0.0034188   1.        ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 280 is [False, True, 1, False, True]
Human Feedback received at timestep 280 of -1
Current timestep = 281. State = [[0.08070938 0.03581885 0.27867827 1.        ]]. Action = [[ 0.43580186 -0.00353378  0.9821725   1.        ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 281 is [False, True, 1, False, True]
Human Feedback received at timestep 281 of 0
Current timestep = 282. State = [[0.08070938 0.03581885 0.27867827 1.        ]]. Action = [[ 0.67212903 -0.19359559 -0.34122813  1.        ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 282 is [False, True, 1, False, True]
Human Feedback received at timestep 282 of 0
Current timestep = 283. State = [[0.08069851 0.03581743 0.27853093 1.        ]]. Action = [[ 0.96536374 -0.02133393 -0.19535017  1.        ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 283 is [False, True, 1, False, True]
Human Feedback received at timestep 283 of 0
Current timestep = 284. State = [[0.08069851 0.03581743 0.27853093 1.        ]]. Action = [[0.6486248  0.10467803 0.3457203  1.        ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 284 is [False, True, 1, False, True]
Human Feedback received at timestep 284 of 0
Current timestep = 285. State = [[0.08069851 0.03581743 0.27853093 1.        ]]. Action = [[0.5674834  0.0361979  0.05860114 1.        ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 285 is [False, True, 1, False, True]
Human Feedback received at timestep 285 of 0
Current timestep = 286. State = [[0.08069851 0.03581743 0.27853093 1.        ]]. Action = [[0.9915576  0.09684944 0.18054914 1.        ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 286 is [False, True, 1, False, True]
Human Feedback received at timestep 286 of 0
Current timestep = 287. State = [[0.07703531 0.03980064 0.27387577 1.        ]]. Action = [[-0.89561826  0.13111806 -0.5555785   1.        ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 287 is [False, True, 1, False, True]
Human Feedback received at timestep 287 of -1
Current timestep = 288. State = [[0.07197214 0.04347199 0.26492083 1.        ]]. Action = [[ 0.9958699  -0.15740979  1.0055256   1.        ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 288 is [False, True, 1, False, True]
Human Feedback received at timestep 288 of 0
Current timestep = 289. State = [[0.07067209 0.0411972  0.27674818 1.        ]]. Action = [[-0.7007798  -0.15487099  0.9962282   1.        ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 289 is [False, True, 1, False, True]
Human Feedback received at timestep 289 of 1
Current timestep = 290. State = [[0.05132298 0.03653681 0.29143852 1.        ]]. Action = [[ 0.78611064 -0.15850633 -0.74573326  1.        ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 290 is [False, True, 1, False, True]
Human Feedback received at timestep 290 of 1
Current timestep = 291. State = [[0.06095016 0.03135004 0.2724234  1.        ]]. Action = [[ 0.6412016  -0.19049942  0.14578891  1.        ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 291 is [False, True, 1, False, True]
Human Feedback received at timestep 291 of 1
Current timestep = 292. State = [[0.0711252  0.02629586 0.27111813 1.        ]]. Action = [[ 0.7480844  -0.16298538 -0.33484244  1.        ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 292 is [False, True, 1, False, True]
Human Feedback received at timestep 292 of 0
Current timestep = 293. State = [[0.0711252  0.02629586 0.27111813 1.        ]]. Action = [[ 0.8228612  -0.13015318 -0.44726145  1.        ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 293 is [False, True, 1, False, True]
Human Feedback received at timestep 293 of 0
Current timestep = 294. State = [[0.07053559 0.02426827 0.28320262 1.        ]]. Action = [[-0.88566154 -0.06086212  0.9033818   1.        ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 295. State = [[0.06595147 0.02226092 0.30198243 1.        ]]. Action = [[ 0.64221203 -0.20400506  0.7612803   1.        ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 296. State = [[0.06564806 0.02207894 0.30323136 1.        ]]. Action = [[ 0.92845345 -0.18391085 -0.22910202  1.        ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 297. State = [[0.06564806 0.02207894 0.30323136 1.        ]]. Action = [[ 0.9140916  -0.00915223  0.4729209   1.        ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 298. State = [[0.06423047 0.02036004 0.30135396 1.        ]]. Action = [[-0.15914458 -0.20707488 -0.24937618  1.        ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 299. State = [[0.06235773 0.01629052 0.28991824 1.        ]]. Action = [[ 0.6784408 -0.0497331 -0.7205422  1.       ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 300. State = [[-0.26989785  0.0729443   0.11045085  1.        ]]. Action = [[-0.13049424 -0.14138025  0.716553   -0.9567293 ]]. Reward = [100.]
Curr episode timestep = 40
Current timestep = 301. State = [[-0.25707942  0.07737686  0.10624955  1.        ]]. Action = [[ 0.6620736  -0.38504827  1.3027244   0.9172479 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 301 is [False, True, 3, False]
Human Feedback received at timestep 301 of 1
Current timestep = 302. State = [[-0.2640432   0.14637555  0.12250651  1.        ]]. Action = [[ 0.90903044 -0.10994905  0.5292113  -0.6135292 ]]. Reward = [-10.]
Curr episode timestep = 1
Current timestep = 303. State = [[-0.2541353   0.15669349  0.1132093   1.        ]]. Action = [[ 0.4874903  -0.46435612  0.6585865   0.11453807]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 303 is [False, True, 3, False]
Human Feedback received at timestep 303 of 1
Current timestep = 304. State = [[-0.25543296 -0.11428097  0.11889949  1.        ]]. Action = [[ 0.8938936  -0.43637455  0.7141609  -0.4774372 ]]. Reward = [-10.]
Curr episode timestep = 1
Current timestep = 305. State = [[-0.2498591  -0.07427547  0.12608828  1.        ]]. Action = [[ 0.83353233  0.35537946  1.653667   -0.9048564 ]]. Reward = [-10.]
Curr episode timestep = 0
Current timestep = 306. State = [[-0.24855685 -0.12598032  0.12158246  1.        ]]. Action = [[ 0.61873436  0.3089037   1.2483299  -0.15961522]]. Reward = [-10.]
Curr episode timestep = 0
Current timestep = 307. State = [[-0.23664093 -0.13262932  0.11683245  1.        ]]. Action = [[0.91144073 0.5891125  1.0266879  0.06895125]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 307 is [False, True, 3, False]
Human Feedback received at timestep 307 of 1
Current timestep = 308. State = [[-0.20889984 -0.12069148  0.1406636   1.        ]]. Action = [[0.5515237  0.26258647 0.7508664  0.0084945 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 308 is [False, True, 3, False]
Human Feedback received at timestep 308 of 1
Current timestep = 309. State = [[-0.19263047 -0.11569694  0.15930636  1.        ]]. Action = [[0.6703061  0.61862874 0.8819699  0.05817425]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 309 is [False, True, 3, False]
Human Feedback received at timestep 309 of 0
Current timestep = 310. State = [[-0.19263047 -0.11569694  0.15930636  1.        ]]. Action = [[ 0.63776493  0.14481544 -0.1554035   0.32118356]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 310 is [False, True, 3, False]
Human Feedback received at timestep 310 of 0
Current timestep = 311. State = [[-0.19263047 -0.11569694  0.15930636  1.        ]]. Action = [[0.71675634 0.3403144  0.01662374 0.88047624]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 311 is [False, True, 3, False]
Human Feedback received at timestep 311 of 0
Current timestep = 312. State = [[-0.19263047 -0.11569694  0.15930636  1.        ]]. Action = [[ 0.8374357   0.34629273  0.01835132 -0.14322615]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 312 is [False, True, 3, False]
Human Feedback received at timestep 312 of 0
Current timestep = 313. State = [[-0.19256048 -0.11571096  0.15933242  1.        ]]. Action = [[ 0.618577    0.15282655 -0.0048269   0.09581351]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 313 is [False, True, 3, False]
Human Feedback received at timestep 313 of 0
Current timestep = 314. State = [[-0.19256048 -0.11571096  0.15933242  1.        ]]. Action = [[0.8177899  0.29484034 1.1629019  0.93645823]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 314 is [False, True, 3, False]
Human Feedback received at timestep 314 of 0
Current timestep = 315. State = [[-0.19256048 -0.11571096  0.15933242  1.        ]]. Action = [[ 0.86349034  0.16342545  1.0447454  -0.06545532]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 315 is [False, True, 3, False]
Human Feedback received at timestep 315 of 0
Current timestep = 316. State = [[-0.18906018 -0.10831809  0.1700678   1.        ]]. Action = [[0.18288398 0.4167142  0.8636613  0.8877065 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 316 is [False, True, 3, False]
Human Feedback received at timestep 316 of 1
Current timestep = 317. State = [[-0.18184234 -0.09898818  0.1935752   1.        ]]. Action = [[0.88890696 0.38189232 0.8068495  0.92769635]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 317 is [False, True, 3, False]
Human Feedback received at timestep 317 of 0
Current timestep = 318. State = [[-0.18182394 -0.09884621  0.19369963  1.        ]]. Action = [[0.7732384  0.06679249 0.3374462  0.7383313 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 318 is [False, True, 3, False]
Human Feedback received at timestep 318 of 0
Current timestep = 319. State = [[-0.18186238 -0.09873268  0.1936983   1.        ]]. Action = [[0.89099884 0.20881712 0.65013385 0.72000396]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 319 is [False, True, 3, False]
Human Feedback received at timestep 319 of 0
Current timestep = 320. State = [[-0.18205051 -0.09868585  0.19368929  1.        ]]. Action = [[0.8505199  0.32207465 0.86445    0.73501253]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 320 is [False, True, 3, False]
Human Feedback received at timestep 320 of 0
Current timestep = 321. State = [[-0.17045671 -0.09455743  0.20905277  1.        ]]. Action = [[0.6393049  0.21454334 1.3800232  0.7320759 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 321 is [False, True, 3, False]
Human Feedback received at timestep 321 of 1
Current timestep = 322. State = [[-0.14647956 -0.08973671  0.2526496   1.        ]]. Action = [[0.736074   0.07933497 0.27178073 0.9798708 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 322 is [False, True, 3, False]
Human Feedback received at timestep 322 of 1
Current timestep = 323. State = [[-0.11949005 -0.08453543  0.28096542  1.        ]]. Action = [[0.6301458 0.1962167 1.125586  0.9940473]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 323 is [False, True, 3, False]
Human Feedback received at timestep 323 of 1
Current timestep = 324. State = [[-0.08763027 -0.07600256  0.3248112   1.        ]]. Action = [[0.78887856 0.22072816 1.0511646  0.88330376]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 324 is [False, True, 3, True]
Human Feedback received at timestep 324 of 1
Current timestep = 325. State = [[-0.06562899 -0.0678095   0.34723297  1.        ]]. Action = [[ 0.5658119   0.17595816 -0.7833177   0.38359523]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 325 is [False, True, 3, True]
Human Feedback received at timestep 325 of -1
Current timestep = 326. State = [[-0.04288942 -0.06002497  0.327748    1.        ]]. Action = [[ 0.6926398   0.26704407 -0.35427666  0.96470857]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 326 is [False, True, 3, True]
Human Feedback received at timestep 326 of -1
Current timestep = 327. State = [[-0.0228993  -0.05402543  0.3100554   1.        ]]. Action = [[ 0.50165176 -0.02020061 -0.8841703   0.4874506 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 327 is [False, True, 3, True]
Human Feedback received at timestep 327 of -1
Current timestep = 328. State = [[ 0.00163199 -0.05234154  0.2805571   1.        ]]. Action = [[ 0.58459675  0.0748055  -0.7984066   0.92173004]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 328 is [False, True, 3, True]
Human Feedback received at timestep 328 of -1
Current timestep = 329. State = [[ 0.02991357 -0.04920756  0.2590277   1.        ]]. Action = [[0.5386355  0.17411554 0.48436642 0.9443674 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 329 is [False, True, 3, True]
Human Feedback received at timestep 329 of -1
Current timestep = 330. State = [[ 0.04954962 -0.04708346  0.2834152   1.        ]]. Action = [[ 0.854578   -0.15613854  1.0855718   0.5476481 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 330 is [False, True, 3, True]
Human Feedback received at timestep 330 of -1
Current timestep = 331. State = [[ 0.07478985 -0.05059453  0.31321055  1.        ]]. Action = [[-0.46216774 -0.04756665  0.31896305  0.85806775]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 331 is [False, True, 3, True]
Human Feedback received at timestep 331 of -1
Current timestep = 332. State = [[ 0.07384145 -0.05333852  0.3162137   1.        ]]. Action = [[ 0.44163728 -0.0533213  -0.05953181  0.42045784]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 332 is [False, True, 3, True]
Human Feedback received at timestep 332 of 0
Current timestep = 333. State = [[ 0.08004253 -0.05546058  0.32566306  1.        ]]. Action = [[ 0.11476445 -0.17757452  0.44102335  0.8564954 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 333 is [False, True, 3, True]
Human Feedback received at timestep 333 of -1
Current timestep = 334. State = [[ 0.08580115 -0.05491734  0.34531146  1.        ]]. Action = [[0.18349385 0.15864706 0.6353836  0.8962997 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 334 is [False, True, 3, True]
Human Feedback received at timestep 334 of 1
Current timestep = 335. State = [[ 0.08984858 -0.05286826  0.35968614  1.        ]]. Action = [[0.6300595  0.0693053  0.68653035 0.63499427]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 335 is [False, True, 3, True]
Human Feedback received at timestep 335 of 0
Current timestep = 336. State = [[ 0.08996955 -0.05212578  0.35202518  1.        ]]. Action = [[ 0.13024199  0.10726404 -0.86660683  0.7335551 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 336 is [False, True, 3, True]
Human Feedback received at timestep 336 of 0
Current timestep = 337. State = [[ 0.1015522  -0.05073678  0.32989383  1.        ]]. Action = [[-0.1383236   0.01344812 -0.34091425  0.9637623 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 337 is [False, True, 3, False]
Human Feedback received at timestep 337 of 1
Current timestep = 338. State = [[ 0.10148564 -0.05065576  0.3228533   1.        ]]. Action = [[0.76386404 0.04730439 0.32100344 0.9852364 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 338 is [False, True, 3, False]
Human Feedback received at timestep 338 of 0
Current timestep = 339. State = [[ 0.10148469 -0.05065577  0.32277948  1.        ]]. Action = [[ 0.67822695  0.046399   -0.48414755  0.5637975 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 339 is [False, True, 3, False]
Human Feedback received at timestep 339 of 0
Current timestep = 340. State = [[ 0.10043493 -0.04908124  0.31832302  1.        ]]. Action = [[-0.460752    0.09168673 -0.55282664  0.8665483 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 340 is [False, True, 3, False]
Human Feedback received at timestep 340 of 0
Current timestep = 341. State = [[ 0.09924619 -0.04312274  0.3131481   1.        ]]. Action = [[-0.09649706  0.16620731  0.09466338  0.87895274]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 341 is [False, True, 3, True]
Human Feedback received at timestep 341 of 1
Current timestep = 342. State = [[ 0.09153637 -0.03793998  0.3208826   1.        ]]. Action = [[-0.89991254 -0.00326592  0.41762686  0.630883  ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 342 is [False, True, 3, True]
Human Feedback received at timestep 342 of -1
Current timestep = 343. State = [[ 0.06259819 -0.03600541  0.31956384  1.        ]]. Action = [[-0.6910395  -0.03256691 -0.7768612   0.7103865 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 343 is [False, True, 3, True]
Human Feedback received at timestep 343 of -1
Current timestep = 344. State = [[ 0.04929453 -0.03645583  0.29339805  1.        ]]. Action = [[ 0.9435754  -0.10419703 -0.12645245  0.6996355 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 344 is [False, True, 3, True]
Human Feedback received at timestep 344 of -1
Current timestep = 345. State = [[ 0.060394   -0.04395874  0.2889173   1.        ]]. Action = [[ 0.81427383 -0.3292954   0.06368995  0.8701389 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 345 is [False, True, 3, True]
Human Feedback received at timestep 345 of -1
Current timestep = 346. State = [[ 0.07563712 -0.05193456  0.2880265   1.        ]]. Action = [[ 0.10893476 -0.14472437  0.29645133  0.19265914]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 346 is [False, True, 3, True]
Human Feedback received at timestep 346 of -1
Current timestep = 347. State = [[ 0.07876555 -0.05688366  0.29469854  1.        ]]. Action = [[ 0.83279085  0.00405228 -0.19725049  0.8328668 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 347 is [False, True, 3, True]
Human Feedback received at timestep 347 of 0
Current timestep = 348. State = [[ 0.07874042 -0.0569976   0.29452327  1.        ]]. Action = [[0.9311714  0.12733555 0.5043318  0.9041263 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 348 is [False, True, 3, True]
Human Feedback received at timestep 348 of 0
Current timestep = 349. State = [[ 0.07874042 -0.0569976   0.29452327  1.        ]]. Action = [[0.94076633 0.13928306 0.01979804 0.67023015]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 349 is [False, True, 3, True]
Human Feedback received at timestep 349 of 0
Current timestep = 350. State = [[ 0.07706232 -0.05312865  0.30213344  1.        ]]. Action = [[-0.7552398   0.3035214   0.4990797   0.90324426]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 350 is [False, True, 3, True]
Human Feedback received at timestep 350 of -1
Current timestep = 351. State = [[ 0.07383982 -0.04662826  0.321551    1.        ]]. Action = [[0.427168   0.09546411 0.6893077  0.8465607 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 351 is [False, True, 3, True]
Human Feedback received at timestep 351 of -1
Current timestep = 352. State = [[ 0.07571726 -0.04447145  0.33607543  1.        ]]. Action = [[ 0.58958936 -0.12619847 -0.42024887  0.7020447 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 352 is [False, True, 3, True]
Human Feedback received at timestep 352 of 0
Current timestep = 353. State = [[ 0.07200371 -0.04715569  0.34620872  1.        ]]. Action = [[-0.9820611  -0.11547047  0.41195607  0.9442668 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 353 is [False, True, 3, True]
Human Feedback received at timestep 353 of -1
Current timestep = 354. State = [[ 0.05800666 -0.04876713  0.37546992  1.        ]]. Action = [[ 0.45246673 -0.06207621  1.0513005   0.56956303]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 354 is [False, True, 3, True]
Human Feedback received at timestep 354 of -1
Current timestep = 355. State = [[ 0.05589116 -0.052505    0.3921683   1.        ]]. Action = [[-0.7597528   0.17691827  0.85171103  0.870558  ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 355 is [False, True, 3, True]
Human Feedback received at timestep 355 of 0
Current timestep = 356. State = [[ 0.05675593 -0.05248151  0.3849468   1.        ]]. Action = [[ 0.505152   -0.06676823 -0.7124338   0.8957193 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 356 is [False, True, 3, True]
Human Feedback received at timestep 356 of -1
Current timestep = 357. State = [[ 0.06570508 -0.05050918  0.36119846  1.        ]]. Action = [[ 0.5793499  -0.05697149 -1.4745498   0.67302585]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 357 is [False, True, 3, True]
Human Feedback received at timestep 357 of -1
Current timestep = 358. State = [[-0.26038128 -0.08510897  0.10637621  1.        ]]. Action = [[ 0.7272848   0.00928581 -1.3136668   0.877985  ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 359. State = [[-0.250723   -0.09643516  0.10251372  1.        ]]. Action = [[ 0.6460482  -0.02483559  1.5531802   0.76848125]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 359 is [False, True, 3, False]
Human Feedback received at timestep 359 of 1
Current timestep = 360. State = [[-0.22693427 -0.09417565  0.14221108  1.        ]]. Action = [[0.9377022  0.33856773 0.5777528  0.7778355 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 360 is [False, True, 3, False]
Human Feedback received at timestep 360 of 1
Current timestep = 361. State = [[-0.20047048 -0.09231588  0.1591675   1.        ]]. Action = [[0.7670591  0.41449094 1.2081289  0.8308084 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 361 is [False, True, 3, False]
Human Feedback received at timestep 361 of 0
Current timestep = 362. State = [[-0.19191115 -0.08933219  0.16820708  1.        ]]. Action = [[0.62779593 0.18121016 0.6148472  0.95185184]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 362 is [False, True, 3, False]
Human Feedback received at timestep 362 of 1
Current timestep = 363. State = [[-0.17578426 -0.08578937  0.18350226  1.        ]]. Action = [[0.6615511  0.3545339  0.43555045 0.92022336]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 363 is [False, True, 3, False]
Human Feedback received at timestep 363 of 0
Current timestep = 364. State = [[-0.17559667 -0.08567593  0.1837209   1.        ]]. Action = [[0.62736976 0.27117085 0.96900177 0.20501459]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 364 is [False, True, 3, False]
Human Feedback received at timestep 364 of 0
Current timestep = 365. State = [[-0.17556688 -0.08561456  0.18375918  1.        ]]. Action = [[0.78332996 0.07570148 0.0925262  0.88599813]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 365 is [False, True, 3, False]
Human Feedback received at timestep 365 of 0
Current timestep = 366. State = [[-0.16545503 -0.07853874  0.19945896  1.        ]]. Action = [[0.5709709  0.41819906 1.4191225  0.52752876]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 366 is [False, True, 3, False]
Human Feedback received at timestep 366 of 1
Current timestep = 367. State = [[-0.13973355 -0.06550617  0.2443833   1.        ]]. Action = [[0.75486493 0.19159114 0.16688943 0.92718494]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 367 is [False, True, 3, False]
Human Feedback received at timestep 367 of 1
Current timestep = 368. State = [[-0.12537436 -0.06084023  0.2559754   1.        ]]. Action = [[ 0.80002     0.20596147 -0.6930156   0.47664905]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 368 is [False, True, 3, False]
Human Feedback received at timestep 368 of 0
Current timestep = 369. State = [[-0.12530327 -0.06044536  0.25593865  1.        ]]. Action = [[ 0.92866254  0.10871994 -0.51867175  0.799685  ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 369 is [False, True, 3, False]
Human Feedback received at timestep 369 of 0
Current timestep = 370. State = [[-0.12100521 -0.05966371  0.25061232  1.        ]]. Action = [[ 0.43135583  0.04120672 -0.41004515  0.9043386 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 371. State = [[-0.1063866  -0.05129021  0.24708824  1.        ]]. Action = [[0.18584788 0.44176888 0.24519324 0.8904327 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 372. State = [[-0.0954157  -0.04408934  0.24771817  1.        ]]. Action = [[ 0.59819937 -0.0831809  -0.24405384  0.8950722 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 372 is [False, True, 3, True]
Human Feedback received at timestep 372 of -1
Current timestep = 373. State = [[-0.07501429 -0.04329122  0.2441283   1.        ]]. Action = [[ 0.09256566 -0.00412953  0.28600764  0.326535  ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 373 is [False, True, 3, True]
Human Feedback received at timestep 373 of -1
Current timestep = 374. State = [[-0.06189616 -0.0432539   0.2499197   1.        ]]. Action = [[ 0.8447788  -0.0648396  -0.17647088  0.8684342 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 374 is [False, True, 3, True]
Human Feedback received at timestep 374 of -1
Current timestep = 375. State = [[-0.04115878 -0.0434917   0.24847473  1.        ]]. Action = [[ 0.35652125 -0.10537601 -0.7987876   0.89992094]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 375 is [False, True, 3, True]
Human Feedback received at timestep 375 of -1
Current timestep = 376. State = [[-0.03546301 -0.04372704  0.25264284  1.        ]]. Action = [[ 0.45325732 -0.07937962  0.33198953  0.3857335 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 376 is [False, True, 3, True]
Human Feedback received at timestep 376 of -1
Current timestep = 377. State = [[-0.01841794 -0.0446641   0.26342508  1.        ]]. Action = [[ 0.55814767 -0.06609368  0.09252787  0.6517055 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 377 is [False, True, 3, True]
Human Feedback received at timestep 377 of -1
Current timestep = 378. State = [[ 0.00377598 -0.04575587  0.2620644   1.        ]]. Action = [[ 0.78119326  0.03410339 -0.15576768  0.385638  ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 378 is [False, True, 3, True]
Human Feedback received at timestep 378 of -1
Current timestep = 379. State = [[ 0.03630237 -0.04333607  0.26621822  1.        ]]. Action = [[0.47705996 0.2576511  0.5064564  0.9716749 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 379 is [False, True, 3, True]
Human Feedback received at timestep 379 of -1
Current timestep = 380. State = [[ 0.06083513 -0.0397168   0.2848802   1.        ]]. Action = [[0.98087764 0.05613852 0.4481473  0.9739511 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 380 is [False, True, 3, True]
Human Feedback received at timestep 380 of -1
Current timestep = 381. State = [[ 0.09431804 -0.03604935  0.29560685  1.        ]]. Action = [[-0.6373658   0.07933772  0.05674744  0.92599916]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 381 is [False, True, 3, True]
Human Feedback received at timestep 381 of -1
Current timestep = 382. State = [[ 0.08160291 -0.03689803  0.29028016  1.        ]]. Action = [[-0.8813309  -0.21872455 -0.74693465  0.82910836]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 382 is [False, True, 3, True]
Human Feedback received at timestep 382 of -1
Current timestep = 383. State = [[ 0.07247666 -0.03912575  0.28519148  1.        ]]. Action = [[0.52383757 0.05237234 0.58176136 0.15908396]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 383 is [False, True, 3, True]
Human Feedback received at timestep 383 of -1
Current timestep = 384. State = [[ 0.07352148 -0.04153398  0.29979655  1.        ]]. Action = [[-0.6046615  -0.02974039  0.37179613  0.9136666 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 384 is [False, True, 3, True]
Human Feedback received at timestep 384 of -1
Current timestep = 385. State = [[ 0.06715608 -0.03870154  0.3135777   1.        ]]. Action = [[ 0.8468778   0.1188544  -0.29189885  0.83133173]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 385 is [False, True, 3, True]
Human Feedback received at timestep 385 of -1
Current timestep = 386. State = [[ 0.06133556 -0.040269    0.30326927  1.        ]]. Action = [[-0.1883027  -0.18692708 -0.854326    0.5750818 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 386 is [False, True, 3, True]
Human Feedback received at timestep 386 of -1
Current timestep = 387. State = [[ 0.04941732 -0.04400123  0.28884158  1.        ]]. Action = [[-0.50732046  0.06355238  0.2814412   0.6492605 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 387 is [False, True, 3, True]
Human Feedback received at timestep 387 of -1
Current timestep = 388. State = [[ 0.04069049 -0.0467317   0.29333714  1.        ]]. Action = [[-0.13474095 -0.0957287   0.11285496  0.7792711 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 388 is [False, True, 3, True]
Human Feedback received at timestep 388 of -1
Current timestep = 389. State = [[ 0.04249939 -0.04609198  0.30265126  1.        ]]. Action = [[0.73625565 0.07435834 0.6037097  0.94125986]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 389 is [False, True, 3, True]
Human Feedback received at timestep 389 of -1
Current timestep = 390. State = [[ 0.04636314 -0.04538251  0.31217608  1.        ]]. Action = [[0.11601663 0.12839448 0.2449379  0.8104434 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 390 is [False, True, 3, True]
Human Feedback received at timestep 390 of -1
Current timestep = 391. State = [[ 0.05558112 -0.03860662  0.32290682  1.        ]]. Action = [[0.8137293  0.23099673 0.28918767 0.886402  ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 391 is [False, True, 3, True]
Human Feedback received at timestep 391 of -1
Current timestep = 392. State = [[ 0.06404959 -0.03353123  0.3345379   1.        ]]. Action = [[ 0.9455447  -0.02431166 -1.0922256   0.50772405]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 392 is [False, True, 3, True]
Human Feedback received at timestep 392 of -1
Current timestep = 393. State = [[ 0.06913877 -0.03192812  0.3351993   1.        ]]. Action = [[ 0.6557493  -0.0307287   0.13663554  0.6673455 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 393 is [False, True, 3, True]
Human Feedback received at timestep 393 of -1
Current timestep = 394. State = [[ 0.08807291 -0.02797652  0.34996247  1.        ]]. Action = [[-0.06965959  0.09960747  0.96305776  0.79566634]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 394 is [False, True, 3, True]
Human Feedback received at timestep 394 of 0
Current timestep = 395. State = [[ 0.09130261 -0.02751931  0.37655973  1.        ]]. Action = [[0.7469599  0.13471794 0.2889235  0.79450846]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 395 is [False, True, 3, True]
Human Feedback received at timestep 395 of 0
Current timestep = 396. State = [[ 0.09101643 -0.02474026  0.37235382  1.        ]]. Action = [[-0.25884128  0.17031217 -0.49658704  0.47757638]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 397. State = [[ 0.09089754 -0.02271603  0.36832246  1.        ]]. Action = [[0.784341   0.14513564 0.8131268  0.7163055 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 398. State = [[ 0.08802447 -0.01954254  0.36288872  1.        ]]. Action = [[-0.4691056   0.12296224 -0.50959396  0.8591764 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 399. State = [[ 0.0837895  -0.01755327  0.35605952  1.        ]]. Action = [[ 0.49569046 -0.05336982 -0.82794726  0.6238197 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 400. State = [[ 0.08286618 -0.01710804  0.35475963  1.        ]]. Action = [[ 0.52718115 -0.21305716 -0.00090635  0.8982271 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 401. State = [[ 0.08310853 -0.02129515  0.35791162  1.        ]]. Action = [[ 0.2851627  -0.31270778  0.58072114  0.8998145 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 402. State = [[ 0.08293334 -0.02607235  0.36054087  1.        ]]. Action = [[ 0.95195603 -0.16029948 -1.1581013   0.8261533 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 403. State = [[ 0.08103797 -0.03022128  0.35223517  1.        ]]. Action = [[-0.10890627 -0.19810712 -1.2055658   0.67616725]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 404. State = [[ 0.08422448 -0.03194575  0.33065072  1.        ]]. Action = [[0.76971006 0.04349554 0.09942937 0.92798114]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 405. State = [[ 0.08456202 -0.03196127  0.32882065  1.        ]]. Action = [[ 0.8534831  -0.02938157 -0.9641824   0.92984056]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 406. State = [[ 0.08455199 -0.03376266  0.33266866  1.        ]]. Action = [[-0.20201486 -0.0452491   0.49021244  0.7625638 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 407. State = [[ 0.08461596 -0.03562111  0.33417672  1.        ]]. Action = [[-0.04262185  0.02224207 -0.47019732  0.7809675 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 408. State = [[ 0.08458573 -0.03563729  0.33236313  1.        ]]. Action = [[ 0.43556404 -0.05282074  0.32839537  0.87248445]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 409. State = [[ 0.07823195 -0.03718433  0.32833794  1.        ]]. Action = [[-0.9204606  -0.06135553 -0.1828053   0.8211987 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 410. State = [[-0.26736578  0.1114677   0.11195973  1.        ]]. Action = [[ 0.36563087 -0.03218615 -0.23532462  0.6652899 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 411. State = [[-0.25321427  0.12045986  0.10231335  1.        ]]. Action = [[ 0.80305076 -0.36108804  0.519794    0.70101666]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 411 is [False, True, 3, False]
Human Feedback received at timestep 411 of 1
Current timestep = 412. State = [[-0.2230409   0.10989209  0.12200146  1.        ]]. Action = [[ 0.8175491  -0.32977164  1.6188111   0.7457392 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 412 is [False, True, 3, False]
Human Feedback received at timestep 412 of 1
Current timestep = 413. State = [[-0.19926654  0.10254099  0.16342133  1.        ]]. Action = [[ 0.88557434 -0.3888439   1.5065854   0.8173113 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 414. State = [[-0.19921842  0.1022054   0.16345376  1.        ]]. Action = [[ 0.77155936 -0.32293457  0.9162812   0.81344914]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 415. State = [[-0.19240232  0.09875999  0.17144977  1.        ]]. Action = [[ 0.49266052 -0.26128507  0.60576916  0.2540753 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 416. State = [[-0.1807243   0.09355494  0.18651693  1.        ]]. Action = [[ 0.8258672  -0.34075707  0.83705044  0.77678514]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 417. State = [[-0.17636105  0.08895148  0.19231325  1.        ]]. Action = [[ 0.03463769 -0.29551518  0.28254724  0.5180001 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 418. State = [[-0.17557219  0.08273288  0.199996    1.        ]]. Action = [[ 0.9134711  -0.26638293  0.6649251   0.47808766]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 419. State = [[-0.16559462  0.07846387  0.21396293  1.        ]]. Action = [[ 0.6003187  -0.25274432  0.92362213  0.7259439 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 420. State = [[-0.14099325  0.06816638  0.24583657  1.        ]]. Action = [[ 0.8473593  -0.32180393  0.7285309   0.715765  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 421. State = [[-0.11257333  0.05961417  0.27275693  1.        ]]. Action = [[ 0.89383125 -0.25219065  0.25061584  0.79280233]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 422. State = [[-0.08456729  0.05015797  0.28054488  1.        ]]. Action = [[ 0.93240213 -0.21372938 -0.33152294  0.16171694]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 422 is [False, True, 3, True]
Human Feedback received at timestep 422 of -1
Current timestep = 423. State = [[-0.04701675  0.04211447  0.2745251   1.        ]]. Action = [[ 0.79127645 -0.17771375 -0.14139712  0.3691399 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 424. State = [[-0.0272503   0.03691614  0.27079818  1.        ]]. Action = [[-0.14747149 -0.18427324  0.13394308  0.85974956]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 425. State = [[-0.02568986  0.03136361  0.27430746  1.        ]]. Action = [[ 0.3391137  -0.22439945 -0.89007473  0.6283088 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 426. State = [[-0.02482934  0.02772963  0.272751    1.        ]]. Action = [[ 0.16974926 -0.21036696 -0.21924698  0.5918846 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 427. State = [[-0.01866578  0.02190483  0.26245227  1.        ]]. Action = [[ 0.32785416 -0.13385046 -0.30808473  0.79572284]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 428. State = [[-0.00426261  0.01515414  0.25081226  1.        ]]. Action = [[ 0.81251884 -0.17052191 -0.4544022   0.93507075]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 429. State = [[0.02092198 0.01240478 0.23559052 1.        ]]. Action = [[ 0.89817095 -0.24143422 -0.3802681   0.7190547 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 430. State = [[0.02640625 0.00806682 0.2533789  1.        ]]. Action = [[-0.42513537 -0.13161695  1.5186605   0.59433603]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 431. State = [[0.03252136 0.00150316 0.2942133  1.        ]]. Action = [[ 0.78753376 -0.15382254  0.6184919   0.7502881 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 432. State = [[ 0.04597339 -0.00289917  0.30760202  1.        ]]. Action = [[ 0.9175314  -0.12466377 -0.74983     0.73535013]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 433. State = [[ 0.07631479 -0.00610451  0.2849655   1.        ]]. Action = [[ 0.6164175  -0.07655478 -0.24555576  0.7140806 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 434. State = [[ 0.09795533 -0.00677465  0.27777764  1.        ]]. Action = [[ 0.50561094 -0.17705685  0.03829408  0.82940567]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 435. State = [[ 0.0986943  -0.01131548  0.28830448  1.        ]]. Action = [[-0.6894875  -0.15189707  0.5945344   0.9457743 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 436. State = [[ 0.09622939 -0.01817224  0.30933887  1.        ]]. Action = [[-0.13345802 -0.07816106  0.68852067  0.89928746]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 437. State = [[ 0.09024281 -0.02030095  0.31590405  1.        ]]. Action = [[-0.4808082  -0.06030345 -1.0482135   0.8842405 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 438. State = [[ 0.07775883 -0.02664192  0.2987314   1.        ]]. Action = [[-0.92570734 -0.29088295 -0.48385227  0.87090445]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 439. State = [[ 0.0565014  -0.03314276  0.28878242  1.        ]]. Action = [[-0.68704385 -0.067285    0.4600706   0.72077394]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 440. State = [[ 0.03965222 -0.03549846  0.30946258  1.        ]]. Action = [[ 0.78395116 -0.0812974   0.7954054   0.19600105]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 441. State = [[ 0.04532241 -0.03848173  0.3172177   1.        ]]. Action = [[ 0.8616427  -0.0265528  -0.48072863  0.8110366 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 442. State = [[ 0.05259762 -0.0400961   0.31123835  1.        ]]. Action = [[-0.871682   -0.10056758  0.08886027  0.85424995]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 443. State = [[ 0.05121033 -0.04246901  0.31428963  1.        ]]. Action = [[0.40190327 0.07365906 0.18251348 0.9335537 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 444. State = [[ 0.04876203 -0.04180127  0.3081227   1.        ]]. Action = [[-0.4543922   0.05572009 -0.7466099   0.49174905]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 445. State = [[ 0.04611879 -0.04211449  0.29615328  1.        ]]. Action = [[ 0.4445101  -0.1180132  -0.40102565  0.74324155]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 446. State = [[-0.26355785 -0.01873465  0.10697296  1.        ]]. Action = [[ 0.29127574  0.08165383  0.0970664  -0.09457332]]. Reward = [100.]
Curr episode timestep = 35
Current timestep = 447. State = [[-0.25578564 -0.02343603  0.10237597  1.        ]]. Action = [[ 0.56251657 -0.09371471  1.4121857   0.48162043]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 447 is [False, True, 3, False]
Human Feedback received at timestep 447 of 1
Current timestep = 448. State = [[-0.23177871 -0.02791275  0.14143257  1.        ]]. Action = [[0.8825859  0.01752508 1.190618   0.5753093 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 449. State = [[-0.20172676 -0.02861276  0.18502574  1.        ]]. Action = [[ 0.7252023  -0.0286476   0.9279456   0.55555844]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 450. State = [[-0.17410596 -0.02832534  0.22345324  1.        ]]. Action = [[0.41267443 0.09518242 1.0222657  0.5569322 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 451. State = [[-0.15279774 -0.02824271  0.2615115   1.        ]]. Action = [[ 0.53290606 -0.11484009  0.7327299   0.82905555]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 452. State = [[-0.12883165 -0.0303166   0.2878035   1.        ]]. Action = [[ 0.8192643  -0.10910064  0.32673144  0.47029173]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 453. State = [[-0.10291385 -0.03368352  0.30738047  1.        ]]. Action = [[ 0.6809714  -0.15385401  0.21675682  0.08965611]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 454. State = [[-0.07614528 -0.03472267  0.32193887  1.        ]]. Action = [[0.9376843  0.17466891 0.48095107 0.48093104]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 454 is [False, True, 3, True]
Human Feedback received at timestep 454 of -1
Current timestep = 455. State = [[-0.04105287 -0.03550911  0.33058503  1.        ]]. Action = [[ 0.60791016 -0.15030217 -0.6411848   0.61743784]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 455 is [False, True, 3, True]
Human Feedback received at timestep 455 of -1
Current timestep = 456. State = [[-0.02172685 -0.03913628  0.30757374  1.        ]]. Action = [[-0.2522791  -0.19276386 -0.61669755  0.36388385]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 457. State = [[-0.01990936 -0.0454827   0.29123145  1.        ]]. Action = [[ 0.7936559  -0.15784192 -0.6770294   0.5063939 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 458. State = [[ 0.00314141 -0.04948826  0.26931277  1.        ]]. Action = [[ 0.3867526  -0.04842508  0.09552765  0.5472559 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 459. State = [[ 0.01938387 -0.05242893  0.26592007  1.        ]]. Action = [[ 0.8503233  -0.1105414  -0.30786622  0.40813887]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 460. State = [[ 0.05239727 -0.05577421  0.27115497  1.        ]]. Action = [[ 0.7837435  -0.07412136  1.1923709   0.2695334 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 461. State = [[ 0.0780203  -0.05821164  0.31467932  1.        ]]. Action = [[ 0.37036133 -0.00531024  1.4414401   0.20884573]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 462. State = [[ 0.09088905 -0.05911822  0.35018831  1.        ]]. Action = [[0.9879861  0.15090072 0.25970578 0.6498288 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 463. State = [[ 0.09574778 -0.05872617  0.35566863  1.        ]]. Action = [[-0.19082499  0.06928194 -0.03490567  0.64651287]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 464. State = [[ 0.09535602 -0.05877759  0.35566247  1.        ]]. Action = [[ 0.75949955  0.19685829 -1.0691268   0.31652832]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 465. State = [[ 0.09535602 -0.05877759  0.35566247  1.        ]]. Action = [[0.96177006 0.12241232 0.17284656 0.21377838]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 466. State = [[ 0.09529054 -0.05883084  0.3504419   1.        ]]. Action = [[ 0.04989398 -0.06578207 -0.6812395   0.36280358]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 467. State = [[ 0.09491848 -0.05745248  0.3360371   1.        ]]. Action = [[-0.65322864  0.17472363 -0.13315892  0.45661283]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 468. State = [[ 0.09215336 -0.05560007  0.33709922  1.        ]]. Action = [[ 0.48028696  0.06150341 -0.839638    0.17878366]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 469. State = [[ 0.09179693 -0.05506253  0.33691388  1.        ]]. Action = [[ 0.6742867  -0.03551114 -1.2158645   0.57741   ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 470. State = [[ 0.08843941 -0.05318794  0.32615507  1.        ]]. Action = [[-0.04504853  0.13500106 -0.80813205  0.19436657]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 471. State = [[ 0.08924337 -0.05092565  0.30987802  1.        ]]. Action = [[0.7090603  0.08705425 0.36958766 0.04483819]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 472. State = [[ 0.08925168 -0.05069723  0.30775926  1.        ]]. Action = [[0.999493   0.00620878 0.5815697  0.03711343]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 473. State = [[-0.27086434  0.10188863  0.11406353  1.        ]]. Action = [[ 0.09186614  0.18275487 -0.18618286 -0.02830487]]. Reward = [-10.]
Curr episode timestep = 26
Current timestep = 474. State = [[-0.25364387  0.11105479  0.11145636  1.        ]]. Action = [[ 0.94881153 -0.21108967  1.2778828   0.28230786]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 474 is [False, True, 3, False]
Human Feedback received at timestep 474 of 1
Current timestep = 475. State = [[-0.21838576  0.10459221  0.1444245   1.        ]]. Action = [[ 0.8933606  -0.2495243   0.8726201   0.08612263]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 476. State = [[-0.18545584  0.09547572  0.18135579  1.        ]]. Action = [[ 0.83046436 -0.3115812   1.2618082   0.22680056]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 477. State = [[-0.16348155  0.08823969  0.21435238  1.        ]]. Action = [[ 0.88136435 -0.21039951  0.38610053  0.16744709]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 478. State = [[-0.14649658  0.08460469  0.23518537  1.        ]]. Action = [[ 0.87343    -0.22655994  1.2437887   0.18207145]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 479. State = [[-0.12603022  0.081046    0.26609355  1.        ]]. Action = [[ 0.7601323  -0.17793864 -0.86183786  0.12487233]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 480. State = [[-0.1224687   0.08122979  0.270447    1.        ]]. Action = [[ 0.940181   -0.26930308 -1.0130485   0.1902864 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 481. State = [[-0.11185082  0.0775406   0.28514147  1.        ]]. Action = [[ 0.80501306 -0.18760818  1.0306344   0.25342345]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 482. State = [[-0.09040309  0.06801774  0.3035363   1.        ]]. Action = [[ 0.74873185 -0.30054033 -0.862998    0.28553534]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 482 is [False, True, 3, True]
Human Feedback received at timestep 482 of -1
Current timestep = 483. State = [[-0.06619498  0.05764883  0.28372595  1.        ]]. Action = [[ 0.63355935 -0.29881096 -0.62107444  0.16389346]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 484. State = [[-0.04579406  0.05391804  0.26584956  1.        ]]. Action = [[ 0.3155117  -0.17936236 -0.96795523  0.15209031]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 485. State = [[-0.03009883  0.04768551  0.27480605  1.        ]]. Action = [[ 0.8498523  -0.2440114   0.6841023   0.18992007]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 486. State = [[-0.01338954  0.04231074  0.28724438  1.        ]]. Action = [[ 0.24082541 -0.13117498 -0.05863309  0.21149874]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 487. State = [[0.00396623 0.03361705 0.2966462  1.        ]]. Action = [[ 0.41472232 -0.3218842   0.7289963   0.15545547]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 488. State = [[0.02107742 0.02572158 0.3167049  1.        ]]. Action = [[ 0.8404391  -0.0680669   0.18358803  0.17134845]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 489. State = [[0.05160015 0.01770791 0.3268687  1.        ]]. Action = [[ 0.83860683 -0.37895238  0.53635097  0.05501664]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 490. State = [[0.08342704 0.00695998 0.34300736 1.        ]]. Action = [[ 0.67560184 -0.14778018  0.39276743  0.14147544]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 491. State = [[0.10555797 0.00402322 0.35299668 1.        ]]. Action = [[ 0.8373674  -0.03802502 -0.3125199   0.12305593]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 491 is [False, True, 3, False]
Human Feedback received at timestep 491 of 1
Current timestep = 492. State = [[-0.26865304  0.04466458  0.11217008  1.        ]]. Action = [[-0.755967   -0.10536194  0.6230192  -0.21744049]]. Reward = [-10.]
Curr episode timestep = 18
Current timestep = 493. State = [[-0.25746346  0.04875332  0.11135855  1.        ]]. Action = [[ 0.47076333 -0.15308869  1.5566931   0.38159704]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 494. State = [[-0.2348748   0.0456551   0.15460826  1.        ]]. Action = [[ 0.88999987 -0.15652484  1.4450073   0.36172748]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 495. State = [[-0.20370933  0.04058589  0.20446831  1.        ]]. Action = [[ 0.7679281  -0.24271357  0.8716562   0.3664745 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 496. State = [[-0.17591934  0.03582967  0.23603556  1.        ]]. Action = [[0.44248867 0.03915107 0.60644054 0.27845573]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 497. State = [[-0.14974236  0.03293559  0.26408857  1.        ]]. Action = [[ 0.93568707 -0.24003613  0.55186796  0.13387048]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 498. State = [[-0.12891208  0.02574995  0.28658187  1.        ]]. Action = [[ 0.03575361 -0.19887102  0.17164493  0.07776713]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 499. State = [[-0.11706139  0.0219902   0.28827736  1.        ]]. Action = [[ 0.7929027  -0.0065394  -0.482121    0.16995764]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 500. State = [[-0.08738501  0.01983797  0.2894874   1.        ]]. Action = [[ 0.90480185 -0.12331265  0.7848778   0.25658488]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 500 is [False, True, 3, True]
Human Feedback received at timestep 500 of -1
Current timestep = 501. State = [[-0.0584134   0.01207535  0.3015067   1.        ]]. Action = [[ 0.8080244  -0.15105677 -0.84374106  0.04245257]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 502. State = [[-0.02523061  0.00905926  0.28507248  1.        ]]. Action = [[ 0.769292   -0.16262662  0.31545758  0.23525047]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 503. State = [[0.00167136 0.00381922 0.28686532 1.        ]]. Action = [[ 0.5093305  -0.17218363 -0.09759009  0.22060657]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 504. State = [[ 0.01880866 -0.00347149  0.28073874  1.        ]]. Action = [[-0.0208686  -0.17360878 -0.31782985  0.0576123 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 505. State = [[ 0.02545328 -0.00768287  0.28384912  1.        ]]. Action = [[ 0.22030997 -0.03306657  0.67448807  0.13091898]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 506. State = [[-0.2642966  -0.02116328  0.11436301  1.        ]]. Action = [[-0.04996639 -0.1288048  -0.3247285  -0.13667548]]. Reward = [100.]
Curr episode timestep = 13
Current timestep = 507. State = [[-0.25424707 -0.02427125  0.10784998  1.        ]]. Action = [[ 0.8537332  -0.03846085  0.98183274  0.40331757]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 507 is [False, True, 3, False]
Human Feedback received at timestep 507 of 1
Current timestep = 508. State = [[-0.22510345 -0.03093112  0.13343     1.        ]]. Action = [[ 0.8419213  -0.06606108  1.1647737   0.33513868]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 509. State = [[-0.19865865 -0.03373357  0.17540699  1.        ]]. Action = [[ 0.37094963 -0.07297319  0.8763032   0.40160263]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 510. State = [[-0.18649709 -0.03462747  0.19825138  1.        ]]. Action = [[0.8640021  0.00749779 0.8654773  0.3115542 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 511. State = [[-0.18291338 -0.03479813  0.20200956  1.        ]]. Action = [[0.7581619  0.20172143 0.4329555  0.3973502 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 512. State = [[-0.18298069 -0.03474033  0.20225833  1.        ]]. Action = [[ 0.4004388  -0.1329174  -0.54954123  0.21696413]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 513. State = [[-0.17050304 -0.03759021  0.21759707  1.        ]]. Action = [[ 0.8012018  -0.19912249  1.1878295   0.3103565 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 514. State = [[-0.15202877 -0.0427288   0.24553923  1.        ]]. Action = [[ 0.63700795 -0.11088079 -0.32072842  0.2115016 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 515. State = [[-0.14309834 -0.04368336  0.25329024  1.        ]]. Action = [[0.52364516 0.00864732 0.07570243 0.16228032]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 516. State = [[-0.12452198 -0.04387851  0.27085522  1.        ]]. Action = [[ 0.8297434  -0.07312942  0.8484678   0.2171588 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 517. State = [[-0.09324884 -0.04520231  0.29196158  1.        ]]. Action = [[ 0.9288932  -0.07513422 -0.00746965  0.1338166 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 517 is [False, True, 3, True]
Human Feedback received at timestep 517 of -1
Current timestep = 518. State = [[-0.06651158 -0.0495754   0.29740474  1.        ]]. Action = [[ 0.09330881 -0.2305451  -0.11201084  0.15681171]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 519. State = [[-0.06027467 -0.05104559  0.28688386  1.        ]]. Action = [[ 0.72044444  0.0723474  -0.6345868   0.12437189]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 520. State = [[-0.03293574 -0.05146066  0.27681327  1.        ]]. Action = [[0.24196923 0.03745294 0.3476715  0.1169486 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 521. State = [[-0.02076182 -0.05261999  0.29183543  1.        ]]. Action = [[ 0.21658254 -0.07670718  0.8163371   0.1519978 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 522. State = [[-0.00532119 -0.05346486  0.32368684  1.        ]]. Action = [[0.38263607 0.10593975 1.0543337  0.15275943]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 523. State = [[ 0.01106536 -0.05057715  0.35947856  1.        ]]. Action = [[0.5761931  0.1617223  0.5695925  0.09903574]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 524. State = [[ 0.0233655  -0.04540402  0.36949125  1.        ]]. Action = [[ 0.43381345  0.1712923  -0.6762551   0.00937307]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 525. State = [[-0.26913336  0.03083831  0.11591639  1.        ]]. Action = [[-0.5758024   0.02156186 -0.10707843 -0.01996791]]. Reward = [100.]
Curr episode timestep = 18
Current timestep = 526. State = [[-0.26297277  0.03282341  0.10623641  1.        ]]. Action = [[ 0.5385326  -0.22698271  0.58521104  0.44350445]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 526 is [False, True, 3, False]
Human Feedback received at timestep 526 of 1
Current timestep = 527. State = [[-0.23982303  0.02812582  0.12163759  1.        ]]. Action = [[ 0.7047001  -0.08220905  1.5030255   0.3796618 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 528. State = [[-0.21359299  0.02809777  0.17041434  1.        ]]. Action = [[0.787415   0.04327679 0.55650973 0.3684758 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 529. State = [[-0.19277933  0.02939893  0.18629268  1.        ]]. Action = [[ 0.92443967 -0.29968023  0.6755123   0.4374385 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 530. State = [[-0.1832852   0.02607383  0.20656484  1.        ]]. Action = [[ 0.078475   -0.22128779  1.6191216   0.47639894]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 531. State = [[-0.18145704  0.02103729  0.24643688  1.        ]]. Action = [[ 0.9067168  -0.25838625  0.07756162  0.19169533]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 532. State = [[-0.17055316  0.01887042  0.25322545  1.        ]]. Action = [[ 0.8529093  -0.16579539  0.01064396  0.14258504]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 533. State = [[-0.14511155  0.01652681  0.27345842  1.        ]]. Action = [[ 0.8019259  -0.09726697  0.95542645  0.20013332]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 534. State = [[-0.11336353  0.01175672  0.3121139   1.        ]]. Action = [[ 0.8371476 -0.127769   1.2513847  0.2749617]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 535. State = [[-0.26983616  0.10230044  0.11738202  1.        ]]. Action = [[ 0.8390424   0.05976164 -0.92240787 -0.07666177]]. Reward = [100.]
Curr episode timestep = 9
Current timestep = 536. State = [[-0.2584181   0.10984059  0.1123565   1.        ]]. Action = [[ 0.50379467 -0.37507594  1.4557924   0.47056592]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 537. State = [[-0.23439455  0.09921385  0.15524232  1.        ]]. Action = [[ 0.90824664 -0.2725767   1.6548092   0.60921335]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 538. State = [[-0.20619142  0.08664473  0.20032237  1.        ]]. Action = [[ 0.57364726 -0.4642073  -0.22506654  0.42100632]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 539. State = [[-0.19431514  0.07859053  0.20797704  1.        ]]. Action = [[ 0.9409772  -0.22237086  0.7343154   0.17464209]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 540. State = [[-0.19274783  0.07814138  0.20916842  1.        ]]. Action = [[ 0.86042345 -0.38491178  0.35821056  0.02118766]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 541. State = [[-0.1771535   0.07673703  0.22640152  1.        ]]. Action = [[ 0.8520247  -0.11200851  1.3261316   0.24426413]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 542. State = [[-0.14251405  0.07014383  0.26325768  1.        ]]. Action = [[ 0.984076   -0.19111794  0.8104298   0.16824055]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 543. State = [[-0.26411527  0.01037616  0.1159574   1.        ]]. Action = [[ 0.97805834 -0.34051442 -0.6116377  -0.11883157]]. Reward = [-10.]
Curr episode timestep = 7
Current timestep = 544. State = [[-0.25302854  0.01184917  0.11180352  1.        ]]. Action = [[ 0.92505634 -0.09666055  1.1082466   0.42222238]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 545. State = [[-0.22552742  0.01041527  0.14075969  1.        ]]. Action = [[ 0.7422795  -0.08345187  1.4288011   0.4595623 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 546. State = [[-0.19324005  0.00606208  0.19150618  1.        ]]. Action = [[ 0.9484844  -0.3121335   0.97867155  0.42251515]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 547. State = [[-1.6678381e-01  7.1951578e-04  2.1947171e-01  1.0000000e+00]]. Action = [[ 0.94263005 -0.01046807  0.07503557  0.34219134]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 548. State = [[-1.6113508e-01  2.3177270e-04  2.2404288e-01  1.0000000e+00]]. Action = [[ 0.65147376 -0.16154039  0.2014823   0.3059845 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 549. State = [[-0.15193647 -0.00325613  0.23328462  1.        ]]. Action = [[ 0.7090732  -0.25339913  0.7078624   0.28835952]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 550. State = [[-0.13524464 -0.00936675  0.2509639   1.        ]]. Action = [[ 0.6097598  -0.22827476 -0.27429688  0.14897525]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 551. State = [[-0.13151498 -0.01080458  0.25493056  1.        ]]. Action = [[ 0.38126397 -0.14409482 -0.3577671   0.03621042]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 552. State = [[-0.12599427 -0.01110551  0.25851482  1.        ]]. Action = [[0.55214524 0.01364684 0.13099742 0.11697447]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 553. State = [[-0.10667832 -0.01292383  0.27478507  1.        ]]. Action = [[ 0.8094003  -0.19550085  0.7741666   0.07897162]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 554. State = [[-0.08135484 -0.01340373  0.29291776  1.        ]]. Action = [[ 0.47902882  0.15497172 -0.09625471  0.05900025]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 554 is [False, True, 3, True]
Human Feedback received at timestep 554 of -1
Current timestep = 555. State = [[-0.05849893 -0.01282151  0.30705184  1.        ]]. Action = [[ 0.52140605 -0.04388964  0.9192269   0.05228209]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 555 is [False, True, 3, True]
Human Feedback received at timestep 555 of -1
Current timestep = 556. State = [[-0.2645571  -0.03221352  0.11735324  1.        ]]. Action = [[ 0.40490115 -0.13164395  0.5336838  -0.15225089]]. Reward = [100.]
Curr episode timestep = 12
Current timestep = 557. State = [[-0.25767216 -0.03704964  0.11539458  1.        ]]. Action = [[0.5080433  0.06494045 1.6900916  0.6342447 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 557 is [False, True, 3, False]
Human Feedback received at timestep 557 of 1
Current timestep = 558. State = [[-0.23479192 -0.03791491  0.16806655  1.        ]]. Action = [[0.8227329  0.09486389 1.7151103  0.5453689 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 559. State = [[-0.21376808 -0.03790791  0.2128631   1.        ]]. Action = [[ 3.4592259e-01 -1.1429429e-02 -1.1074543e-04  5.1573849e-01]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 560. State = [[-0.19377132 -0.03823534  0.21894236  1.        ]]. Action = [[ 0.8486639  -0.03581774 -0.35964656  0.36405385]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 561. State = [[-0.1651096  -0.03919074  0.22512563  1.        ]]. Action = [[ 0.64782    -0.11714554  0.7574024   0.39709997]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 562. State = [[-0.13800663 -0.04140237  0.24500492  1.        ]]. Action = [[ 0.838776   -0.09626514  0.18119621  0.3485458 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 563. State = [[-0.11048432 -0.04292189  0.2516581   1.        ]]. Action = [[ 0.48852825 -0.00343466 -0.03894854  0.09094119]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 564. State = [[-0.08359434 -0.04813984  0.2697094   1.        ]]. Action = [[ 0.7159562  -0.26982594  1.3812666   0.0384351 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 564 is [False, True, 3, True]
Human Feedback received at timestep 564 of -1
Current timestep = 565. State = [[-0.26872277  0.08553407  0.11715753  1.        ]]. Action = [[ 0.46634245  0.18805051  0.9867337  -0.02642733]]. Reward = [100.]
Curr episode timestep = 8
Current timestep = 566. State = [[-0.25823343  0.09372979  0.11222298  1.        ]]. Action = [[ 0.66372514 -0.18759078  0.9770398   0.42657614]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 566 is [False, True, 3, False]
Human Feedback received at timestep 566 of 1
Current timestep = 567. State = [[-0.2312038   0.08629037  0.13702422  1.        ]]. Action = [[ 0.5965942  -0.3082509   1.1211286   0.59652686]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 568. State = [[-0.20738117  0.0769451   0.17726387  1.        ]]. Action = [[ 0.89921355 -0.25638324  0.93075824  0.33435905]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 569. State = [[-0.18346354  0.07308707  0.20222603  1.        ]]. Action = [[ 0.7216077  -0.34173143  0.84567213  0.14305663]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 570. State = [[-0.18178286  0.07237066  0.20478965  1.        ]]. Action = [[ 0.70423543 -0.2763089   0.27519274  0.11436152]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 571. State = [[-0.1816805   0.0722698   0.20541587  1.        ]]. Action = [[ 0.64885175 -0.35736376 -0.0535444   0.21665263]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 572. State = [[-0.18165798  0.07213905  0.20547698  1.        ]]. Action = [[ 0.9314282  -0.2963382  -0.09627354  0.19941354]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 573. State = [[-0.18164834  0.07200574  0.20548917  1.        ]]. Action = [[ 0.55356574 -0.21678627  0.5851469   0.06550455]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 574. State = [[-0.17432466  0.06878155  0.21730198  1.        ]]. Action = [[ 0.36973047 -0.22467971  1.1072731   0.13608181]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 575. State = [[-0.16374175  0.06461384  0.24573183  1.        ]]. Action = [[ 0.9330635  -0.06384987  0.15115929 -0.0364604 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 576. State = [[-0.27286622  0.06699824  0.14296792  1.        ]]. Action = [[ 0.58218324 -0.33803266  0.7552843  -0.01829183]]. Reward = [-10.]
Curr episode timestep = 10
Current timestep = 577. State = [[-0.25908273  0.06339041  0.15412137  1.        ]]. Action = [[ 0.8624852  -0.362643    1.3044052   0.23476481]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 578. State = [[-0.2421991   0.05830153  0.1731037   1.        ]]. Action = [[-0.46658754 -0.28151894  0.94039416  0.4138825 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 579. State = [[-0.22700557  0.05482906  0.1880478   1.        ]]. Action = [[ 0.74969554 -0.1997546   0.94969845  0.47426844]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 580. State = [[-0.20195986  0.04820586  0.22653951  1.        ]]. Action = [[ 0.46206105 -0.19711804  1.2662661   0.16440451]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 581. State = [[-0.17826991  0.04000975  0.27309757  1.        ]]. Action = [[ 0.777954   -0.31097084  0.9231403   0.1577276 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 582. State = [[-0.1500455   0.03234127  0.29959184  1.        ]]. Action = [[ 0.73826647 -0.10324621 -0.19471979  0.16623628]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 583. State = [[-0.12511629  0.02689197  0.30953327  1.        ]]. Action = [[ 0.6864362  -0.22262585  0.3646748   0.01194119]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 584. State = [[-0.10014772  0.0196705   0.31690943  1.        ]]. Action = [[ 0.6882453  -0.13842106 -0.03887117  0.00849462]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 585. State = [[-0.26234213 -0.02096506  0.11515875  1.        ]]. Action = [[ 0.3804717  -0.12650055 -0.9848993  -0.12269878]]. Reward = [100.]
Curr episode timestep = 8
Current timestep = 586. State = [[-0.25321516 -0.02564659  0.11108852  1.        ]]. Action = [[ 0.7644334  -0.10419339  1.193181    0.5025897 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 587. State = [[-0.23098831 -0.03364467  0.14174663  1.        ]]. Action = [[ 0.60746515 -0.1251216   1.4525199   0.42977846]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 588. State = [[-0.20322521 -0.03441317  0.19373983  1.        ]]. Action = [[0.86073935 0.1868912  0.99648714 0.25676048]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 589. State = [[-0.17767847 -0.03368441  0.22184771  1.        ]]. Action = [[0.824355   0.24080229 0.15377164 0.25477266]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 590. State = [[-0.1631943  -0.03350397  0.23852485  1.        ]]. Action = [[ 0.7790333  -0.08873403  0.90486574  0.29616547]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 591. State = [[-0.1366654  -0.03258136  0.265839    1.        ]]. Action = [[0.6581954  0.13005614 0.15500426 0.0827105 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 592. State = [[-0.264329   -0.02931282  0.11711738  1.        ]]. Action = [[ 0.83631444  0.19992626 -0.15097165 -0.01485598]]. Reward = [-10.]
Curr episode timestep = 6
Current timestep = 593. State = [[-0.2541721  -0.0354619   0.10984917  1.        ]]. Action = [[ 0.9271301  -0.09310484  0.9048872   0.08257484]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 594. State = [[-0.22878757 -0.03969322  0.12034719  1.        ]]. Action = [[ 0.6630306  -0.15299076 -0.06467247  0.60933506]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 595. State = [[-0.2021558  -0.04424708  0.13829917  1.        ]]. Action = [[ 0.64836    -0.06803465  1.1608968   0.58683085]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 596. State = [[-0.18104476 -0.0486968   0.17118172  1.        ]]. Action = [[0.12862217 0.0354557  0.67754745 0.22179735]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 597. State = [[-0.1750873  -0.04868091  0.18975693  1.        ]]. Action = [[ 0.5005964   0.18906009 -0.18185782  0.36078477]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 598. State = [[-0.16220573 -0.04964226  0.2078895   1.        ]]. Action = [[ 0.5182688  -0.02444625  1.2203898   0.41047263]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 599. State = [[-0.14036556 -0.04923785  0.24623935  1.        ]]. Action = [[0.81401587 0.11419082 0.63000774 0.24229538]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 600. State = [[-0.11531587 -0.04793179  0.26539603  1.        ]]. Action = [[ 0.59315276  0.00357127 -0.22203207  0.14309514]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 601. State = [[-0.09103509 -0.04625644  0.2731363   1.        ]]. Action = [[0.93801665 0.10062361 0.40933108 0.00381863]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 601 is [False, True, 3, True]
Human Feedback received at timestep 601 of -1
Current timestep = 602. State = [[-0.26962495  0.03862239  0.11766241  1.        ]]. Action = [[ 0.08684707  0.30252516  0.98697305 -0.03185827]]. Reward = [100.]
Curr episode timestep = 9
Current timestep = 603. State = [[-0.26012042  0.0412176   0.11595292  1.        ]]. Action = [[ 0.52839065 -0.23356724  1.3866789   0.4762268 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 603 is [False, True, 3, False]
Human Feedback received at timestep 603 of 1
Current timestep = 604. State = [[-0.23776232  0.03715125  0.15365718  1.        ]]. Action = [[ 0.54100156 -0.02946198  1.5491171   0.52247524]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 605. State = [[-0.21829005  0.0343737   0.20494458  1.        ]]. Action = [[ 0.5480814  -0.27386618  0.7258198   0.25341356]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 606. State = [[-0.19002788  0.02671076  0.24274059  1.        ]]. Action = [[ 0.92340004 -0.18941277  1.1889019   0.30795276]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 607. State = [[-0.15909636  0.01987513  0.27730888  1.        ]]. Action = [[ 0.75812554 -0.2212367   0.07155967  0.14913785]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 608. State = [[-0.1336126   0.01653549  0.28785375  1.        ]]. Action = [[ 0.6128695  -0.04137212 -0.05249131  0.04034901]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 609. State = [[-0.26236758 -0.14030689  0.11878026  1.        ]]. Action = [[-0.00881773 -0.12689036 -0.6303413  -0.00191802]]. Reward = [-10.]
Curr episode timestep = 6
Current timestep = 610. State = [[-0.25462148 -0.15301163  0.1064085   1.        ]]. Action = [[0.7740048  0.27993894 0.1803906  0.8532798 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 611. State = [[-0.23296654 -0.13954338  0.1181828   1.        ]]. Action = [[0.7547941 0.7032175 1.4389248 0.7048204]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 612. State = [[-0.20258865 -0.11621569  0.14975801  1.        ]]. Action = [[0.8351139  0.6065748  0.10772777 0.510954  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 613. State = [[-0.18269081 -0.10348137  0.15951626  1.        ]]. Action = [[ 0.6822493   0.20683563 -0.12280619  0.37962282]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 614. State = [[-0.17998877 -0.10246547  0.16073205  1.        ]]. Action = [[0.8773706  0.13795507 0.00212359 0.4281144 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 615. State = [[-0.17907915 -0.10177331  0.16102727  1.        ]]. Action = [[0.7535001  0.27811694 1.249182   0.46856844]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 616. State = [[-0.17851594 -0.10101201  0.16109994  1.        ]]. Action = [[0.8318871  0.39697945 0.19265199 0.631246  ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 617. State = [[-0.17835529 -0.10038108  0.16102208  1.        ]]. Action = [[0.35703754 0.3265108  0.7137475  0.6159694 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 618. State = [[-0.17824322 -0.09993912  0.16096789  1.        ]]. Action = [[0.6409261  0.4966483  0.94155216 0.6680497 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 619. State = [[-0.17824322 -0.09993912  0.16096789  1.        ]]. Action = [[ 0.21227455  0.35979438 -0.06380594  0.6909044 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 620. State = [[-0.17824322 -0.09993912  0.16096789  1.        ]]. Action = [[0.42077386 0.2819562  1.3825498  0.7065948 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 621. State = [[-0.17824322 -0.09993912  0.16096789  1.        ]]. Action = [[0.7013105  0.12428164 0.48992276 0.45182836]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 622. State = [[-0.17824322 -0.09993912  0.16096789  1.        ]]. Action = [[0.69754684 0.07633567 1.4733777  0.4549265 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 623. State = [[-0.17824322 -0.09993912  0.16096789  1.        ]]. Action = [[0.54070234 0.05470991 0.5900724  0.7185559 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 624. State = [[-0.1781311  -0.09995523  0.16102134  1.        ]]. Action = [[0.73294675 0.15045834 0.39866948 0.5688937 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 625. State = [[-0.1781311  -0.09995523  0.16102134  1.        ]]. Action = [[0.79743564 0.20572221 0.8027837  0.6509032 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 626. State = [[-0.17733262 -0.09477688  0.16684134  1.        ]]. Action = [[-0.0338102   0.38152862  0.6021023   0.5846882 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 627. State = [[-0.17618947 -0.08801841  0.17663382  1.        ]]. Action = [[ 0.7737342   0.32476425 -0.237077    0.5582876 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 628. State = [[-0.1754651  -0.08758726  0.17707396  1.        ]]. Action = [[0.5929017  0.35233712 0.619714   0.5863074 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 629. State = [[-0.16125895 -0.08487549  0.1953346   1.        ]]. Action = [[0.82027006 0.08502662 1.4869337  0.41878057]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 630. State = [[-0.13239035 -0.08046183  0.25048414  1.        ]]. Action = [[0.7477286  0.11586213 1.2698994  0.48687184]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 631. State = [[-0.10162733 -0.07576847  0.29681367  1.        ]]. Action = [[0.75207925 0.13539374 0.752856   0.13884473]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 632. State = [[-0.2696529   0.13850881  0.11766166  1.        ]]. Action = [[ 0.6468811   0.06899464  0.11621094 -0.03374797]]. Reward = [100.]
Curr episode timestep = 22
Current timestep = 633. State = [[-0.25496033  0.14833462  0.1109942   1.        ]]. Action = [[ 0.8417144  -0.40915722  0.875957    0.8347447 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 634. State = [[-0.2278086   0.13767229  0.13328467  1.        ]]. Action = [[ 0.5937607  -0.3549782   1.2960291   0.72565734]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 635. State = [[-0.20062687  0.12483702  0.17783271  1.        ]]. Action = [[ 0.8236699 -0.361683   0.7704804  0.3515345]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 636. State = [[-0.17231521  0.11333285  0.21746883  1.        ]]. Action = [[ 0.25783384 -0.32541907  1.4274874   0.16483855]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 637. State = [[-0.15503162  0.09968428  0.26690096  1.        ]]. Action = [[ 0.61717415 -0.40030158  0.977648    0.12770021]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 638. State = [[-0.13286145  0.08659473  0.29606915  1.        ]]. Action = [[ 0.50443065 -0.3592276  -0.05509043  0.07115304]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 639. State = [[-0.12148444  0.07600767  0.30873317  1.        ]]. Action = [[ 0.22389638 -0.24013066  0.3362286   0.04287291]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 640. State = [[-0.10725142  0.06540168  0.32554498  1.        ]]. Action = [[ 0.709159   -0.28129077  0.5006571   0.05480993]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 641. State = [[-0.2684157   0.13966809  0.11683723  1.        ]]. Action = [[ 0.78108776 -0.4166913   0.9532852  -0.04446101]]. Reward = [100.]
Curr episode timestep = 8
Current timestep = 642. State = [[-0.2504633   0.15012209  0.11638312  1.        ]]. Action = [[ 0.91599405 -0.36131108  1.4413867   0.66427255]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 643. State = [[-0.22222644  0.13816348  0.15317732  1.        ]]. Action = [[ 0.78168416 -0.40094495  0.98437667  0.7825254 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 644. State = [[-0.19023132  0.12565589  0.18904181  1.        ]]. Action = [[ 0.81697583 -0.34677607  0.75744295  0.5947083 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 645. State = [[-0.16713421  0.1189393   0.21098739  1.        ]]. Action = [[ 0.50022364 -0.3491261   0.20293236  0.19818604]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 646. State = [[-0.1653842   0.11726697  0.21299328  1.        ]]. Action = [[ 0.7023779  -0.38878888  0.42407846  0.16068196]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 647. State = [[-0.15229143  0.11084843  0.22708558  1.        ]]. Action = [[ 0.85654247 -0.40086067  0.9081273   0.08993399]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 648. State = [[-0.12495255  0.09936785  0.25682867  1.        ]]. Action = [[ 0.69110405 -0.32825768  0.36256957  0.06030691]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 649. State = [[-0.10092811  0.08786177  0.28053978  1.        ]]. Action = [[ 0.913198  -0.340101   0.6375499  0.0100199]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 650. State = [[-0.06967839  0.07491024  0.2925662   1.        ]]. Action = [[ 0.8661289  -0.30463302 -0.28202355  0.01092744]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 650 is [False, True, 3, True]
Human Feedback received at timestep 650 of -1
Current timestep = 651. State = [[-0.2641439  -0.00134232  0.11533533  1.        ]]. Action = [[ 0.8725722 -0.3788663 -0.5136876 -0.0741207]]. Reward = [100.]
Curr episode timestep = 9
Current timestep = 652. State = [[-0.25599986 -0.00589516  0.11152585  1.        ]]. Action = [[ 0.6992692  -0.13628554  1.309463    0.79103434]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 652 is [False, True, 3, False]
Human Feedback received at timestep 652 of 1
Current timestep = 653. State = [[-0.2319982  -0.0093953   0.14753456  1.        ]]. Action = [[ 0.8043623  -0.03479117  1.1007895   0.73198533]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 654. State = [[-0.20282516 -0.0138798   0.18948716  1.        ]]. Action = [[ 0.77754474 -0.23497802  1.1165676   0.6620439 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 655. State = [[-0.1791735  -0.01797485  0.21799818  1.        ]]. Action = [[ 0.924338   -0.04428762 -0.40331638  0.6522572 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 656. State = [[-0.16526322 -0.01989672  0.23424816  1.        ]]. Action = [[ 0.772084   -0.12582111  0.83032656  0.48719156]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 657. State = [[-0.1387708  -0.02291841  0.26368695  1.        ]]. Action = [[ 0.5515083  -0.0460372   0.7053001   0.34673464]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 658. State = [[-0.12058879 -0.02447437  0.2849621   1.        ]]. Action = [[ 0.20757973 -0.01233798 -0.01382256  0.11977613]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 659. State = [[-0.10612768 -0.02977078  0.29979697  1.        ]]. Action = [[ 0.83680964 -0.31911284  0.7003956   0.02377319]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 660. State = [[-0.26695833  0.05147594  0.11891208  1.        ]]. Action = [[-0.29761755  0.08966088 -0.19572687 -0.0147391 ]]. Reward = [100.]
Curr episode timestep = 8
Current timestep = 661. State = [[-0.253923    0.05434845  0.11543391  1.        ]]. Action = [[ 0.5821059  -0.35435998  1.408515    0.8166518 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 662. State = [[-0.23022898  0.04598609  0.1542334   1.        ]]. Action = [[ 0.7860496  -0.22446847  1.4962702   0.8349848 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 663. State = [[-0.20102443  0.03845957  0.20326342  1.        ]]. Action = [[ 0.9221318  -0.31796825  0.7532482   0.62845004]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 664. State = [[-0.17319907  0.02798368  0.23726489  1.        ]]. Action = [[ 0.08246946 -0.24083847  0.69379425  0.51242924]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 665. State = [[-0.15547885  0.0184154   0.265653    1.        ]]. Action = [[ 0.8509717  -0.27716887  0.64166784  0.2940178 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 666. State = [[-0.12889206  0.01246327  0.29410625  1.        ]]. Action = [[ 0.74638057 -0.04304254  0.48019934  0.16637933]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 667. State = [[-0.10657074  0.00934615  0.31682655  1.        ]]. Action = [[ 0.39500213 -0.16728729  0.46373844  0.07269931]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 668. State = [[-0.26268402 -0.17844155  0.11832624  1.        ]]. Action = [[ 0.8195138  -0.05148524  0.33818197 -0.01108855]]. Reward = [100.]
Curr episode timestep = 7
Current timestep = 669. State = [[-0.25459176 -0.19042246  0.11234059  1.        ]]. Action = [[0.7374952 0.6896131 1.1857977 0.9819317]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 670. State = [[-0.23265241 -0.1738779   0.14239456  1.        ]]. Action = [[0.78025484 0.5338259  1.44262    0.9483104 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 671. State = [[-0.19960186 -0.15074204  0.19422424  1.        ]]. Action = [[0.91298556 0.5779259  0.86848545 0.91095245]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 672. State = [[-0.16153514 -0.1283185   0.23618348  1.        ]]. Action = [[0.8229289  0.5309131  1.3981104  0.91258144]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 673. State = [[-0.12982184 -0.10738985  0.2821339   1.        ]]. Action = [[0.5822753  0.47360575 0.60464597 0.6432843 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 674. State = [[-0.10953207 -0.09494372  0.30912504  1.        ]]. Action = [[0.20822644 0.15604031 0.38099647 0.05378366]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 675. State = [[-0.10492866 -0.08393537  0.3260434   1.        ]]. Action = [[-0.33275998  0.33407235  0.33647585  0.07616031]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 676. State = [[-0.10565869 -0.07166796  0.3273886   1.        ]]. Action = [[ 0.62021625  0.38331175 -0.85453606  0.02327406]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 677. State = [[-0.09345914 -0.06374977  0.3175919   1.        ]]. Action = [[0.01925755 0.05294251 0.26587105 0.02698565]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 677 is [False, True, 3, True]
Human Feedback received at timestep 677 of 1
Current timestep = 678. State = [[-0.26949146  0.12338854  0.11552662  1.        ]]. Action = [[ 0.3034798   0.12360561 -0.9332111  -0.04643285]]. Reward = [100.]
Curr episode timestep = 9
Current timestep = 679. State = [[-0.2572352   0.13216016  0.10934827  1.        ]]. Action = [[ 0.64109385 -0.40119243  0.9581001   0.7939204 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 679 is [False, True, 3, False]
Human Feedback received at timestep 679 of 1
Current timestep = 680. State = [[-0.22780706  0.11878843  0.13697688  1.        ]]. Action = [[ 0.8140905  -0.39346266  1.4223347   0.7569628 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 681. State = [[-0.20045795  0.10542221  0.18714485  1.        ]]. Action = [[ 0.69395375 -0.44004983  1.0453553   0.5742912 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 682. State = [[-0.1809893   0.09699527  0.21470024  1.        ]]. Action = [[ 0.7922746  -0.3304175   0.79828525  0.33201277]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 683. State = [[-0.16717453  0.0926521   0.22653115  1.        ]]. Action = [[ 0.8895962  -0.2241506   0.56437016  0.28842795]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 684. State = [[-0.14813316  0.08842556  0.2454243   1.        ]]. Action = [[ 0.02258694 -0.30801433 -0.09509635  0.18897879]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 685. State = [[-0.13423577  0.08317117  0.25043505  1.        ]]. Action = [[ 0.96213186 -0.3335513   0.07792854  0.14085734]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 686. State = [[-0.10573369  0.07354441  0.25771946  1.        ]]. Action = [[ 0.81824064 -0.25798744  0.22002578  0.09870136]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 687. State = [[-0.07971877  0.06443338  0.26470077  1.        ]]. Action = [[ 0.3242923  -0.23324966  0.05951548  0.0471673 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 687 is [False, True, 3, True]
Human Feedback received at timestep 687 of 1
Current timestep = 688. State = [[-0.2687078   0.06718195  0.11606204  1.        ]]. Action = [[ 0.7010343  -0.30278635 -0.17660308 -0.0401051 ]]. Reward = [100.]
Curr episode timestep = 9
Current timestep = 689. State = [[-0.25356805  0.07267834  0.11062472  1.        ]]. Action = [[ 0.93623865 -0.26179922  0.9791789   0.90129757]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 689 is [False, True, 3, False]
Human Feedback received at timestep 689 of 1
Current timestep = 690. State = [[-0.22127838  0.06469103  0.13653716  1.        ]]. Action = [[ 0.5980649  -0.30450535  1.1903689   0.75174475]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 691. State = [[-0.20542909  0.05622     0.1715525   1.        ]]. Action = [[ 0.23991859 -0.1446507   0.40957165  0.75113964]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 692. State = [[-0.18667427  0.05008155  0.19832027  1.        ]]. Action = [[ 0.38726485 -0.1679318   1.213057    0.6328895 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 693. State = [[-0.17799182  0.04599585  0.22893928  1.        ]]. Action = [[ 0.8464174  -0.20360267  0.17786503  0.37179315]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 694. State = [[-0.17678514  0.04501093  0.2307047   1.        ]]. Action = [[ 0.4000461  -0.16488224 -0.31087518  0.24875319]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 695. State = [[-0.16636613  0.0415453   0.23791261  1.        ]]. Action = [[ 0.80628836 -0.25808614  0.31504464  0.2769047 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 696. State = [[-0.1426095   0.03394883  0.2611442   1.        ]]. Action = [[ 0.62174344 -0.31439686  0.8662467   0.16662586]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 697. State = [[-0.119504    0.02642407  0.27730346  1.        ]]. Action = [[ 0.5324029  -0.08057994 -0.52797794  0.03242147]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 698. State = [[-0.1027889   0.01909196  0.27441075  1.        ]]. Action = [[ 0.25106645 -0.2730571   0.2112999   0.04134548]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 699. State = [[-0.08593834  0.0107766   0.29967636  1.        ]]. Action = [[ 0.565004   -0.2206397   1.3692389   0.01803124]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 699 is [False, True, 3, True]
Human Feedback received at timestep 699 of -1
Current timestep = 700. State = [[-0.26948833  0.08872751  0.12177408  1.        ]]. Action = [[ 0.67679787 -0.2172544  -0.08811021 -0.07066256]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 701. State = [[-0.2557193   0.08801024  0.13106798  1.        ]]. Action = [[ 0.929404  -0.2001853  1.1334643  0.8356137]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 701 is [False, True, 3, False]
Human Feedback received at timestep 701 of 1
Current timestep = 702. State = [[-0.2211059   0.08016434  0.16091916  1.        ]]. Action = [[ 0.91320705 -0.34301078  0.9717462   0.92767763]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 703. State = [[-0.1919028   0.06890192  0.19244839  1.        ]]. Action = [[ 0.5442476  -0.34851766  0.6951089   0.7435758 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 704. State = [[-0.16381784  0.05796222  0.22507252  1.        ]]. Action = [[ 0.9474851 -0.2240423  1.0170574  0.5674162]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 705. State = [[-0.13179424  0.04971609  0.27030054  1.        ]]. Action = [[ 0.42983234 -0.19621634  1.2224796   0.13639498]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 706. State = [[-0.11607423  0.04460816  0.3021893   1.        ]]. Action = [[ 0.06342888 -0.23186779 -1.1518834   0.08783448]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 707. State = [[-0.10564546  0.04400523  0.30863696  1.        ]]. Action = [[ 0.86705756 -0.01248175  0.01168108  0.07005262]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 708. State = [[-0.08215332  0.0420867   0.3164978   1.        ]]. Action = [[ 0.6526716  -0.17107439  0.13125682  0.00114465]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 708 is [False, True, 3, True]
Human Feedback received at timestep 708 of -1
Current timestep = 709. State = [[-0.26237044 -0.07819069  0.11643486  1.        ]]. Action = [[ 0.6831417  -0.09938842 -0.44319093 -0.01908106]]. Reward = [100.]
Curr episode timestep = 8
Current timestep = 710. State = [[-0.25563145 -0.08472632  0.10239789  1.        ]]. Action = [[ 0.8334632   0.20161903 -0.1171478   0.95952845]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 711. State = [[-0.23147796 -0.07754083  0.10789548  1.        ]]. Action = [[0.7558899 0.5418484 1.2858386 0.9679065]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 712. State = [[-0.20451485 -0.06587945  0.14139289  1.        ]]. Action = [[0.6708212  0.18131459 1.0520663  0.940501  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 713. State = [[-0.18419106 -0.06112003  0.16949324  1.        ]]. Action = [[ 0.9013424  -0.04574263  1.7092242   0.9692111 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 714. State = [[-0.17975426 -0.06049271  0.17311998  1.        ]]. Action = [[ 0.34696102 -0.01690167  0.18634772  0.79590344]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 715. State = [[-0.17972934 -0.06033095  0.17334338  1.        ]]. Action = [[0.44992805 0.15677118 0.27464724 0.83906555]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 716. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[0.80806506 0.00764227 0.9549413  0.7910361 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 717. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[0.94450545 0.22318065 0.7074697  0.85004663]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 718. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[0.91626024 0.02875948 0.8256917  0.83826613]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 719. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[0.6656904  0.12323201 0.7204685  0.6853504 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 720. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[0.8526299  0.06791151 0.65738726 0.84456396]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 721. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[ 0.76219416  0.19092548 -0.08082998  0.7579315 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 722. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[ 0.55839944  0.09452641 -0.01217604  0.9009131 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 723. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[0.5900229  0.1143961  0.20455885 0.90470636]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 724. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[0.74536276 0.16588414 0.7623775  0.888885  ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 725. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[0.73839104 0.2028476  0.39173675 0.9086478 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 726. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[0.84869933 0.02579522 0.85470533 0.90434337]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 727. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[ 7.7612877e-01 -4.2092800e-04  9.9184966e-01  8.1075191e-01]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 728. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[ 0.69233096 -0.10484427  0.5028157   0.7553084 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 729. State = [[-0.17971309 -0.06033148  0.17338817  1.        ]]. Action = [[0.68197656 0.12978458 0.50386405 0.73109865]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 730. State = [[-0.1760523  -0.06058928  0.18334219  1.        ]]. Action = [[ 0.18916261 -0.0562185   0.7789023   0.91280675]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 731. State = [[-0.1618666  -0.06108012  0.21472837  1.        ]]. Action = [[ 0.7077241  -0.08827311  1.0774529   0.7377639 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 732. State = [[-0.13163672 -0.05916985  0.2562717   1.        ]]. Action = [[0.8878639  0.26610518 0.916301   0.5381794 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 733. State = [[-0.09819424 -0.05505989  0.30012834  1.        ]]. Action = [[0.6741836  0.01513362 1.2618027  0.11739671]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 733 is [False, True, 3, True]
Human Feedback received at timestep 733 of 1
Current timestep = 734. State = [[-0.07261572 -0.05358922  0.34280828  1.        ]]. Action = [[0.50689864 0.03287435 0.15218186 0.06698656]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 735. State = [[-0.05724523 -0.05286219  0.34519848  1.        ]]. Action = [[ 0.48736906  0.03299248 -0.2686746   0.00156689]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 736. State = [[-0.26137403 -0.13503146  0.11673179  1.        ]]. Action = [[ 0.59103143  0.16350293  0.16650724 -0.01542103]]. Reward = [100.]
Curr episode timestep = 26
Current timestep = 737. State = [[-0.25452277 -0.1438043   0.11436405  1.        ]]. Action = [[0.6516359  0.56595206 1.3825026  0.99871063]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 737 is [False, True, 3, False]
Human Feedback received at timestep 737 of 1
Current timestep = 738. State = [[-0.23248985 -0.1287741   0.15235919  1.        ]]. Action = [[0.7849009  0.39513624 1.2575269  0.99524355]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 739. State = [[-0.2010853  -0.11226952  0.19740689  1.        ]]. Action = [[0.72800565 0.42279196 0.8614385  0.9970186 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 740. State = [[-0.18131429 -0.10376288  0.21900609  1.        ]]. Action = [[0.81701434 0.37295055 0.46119213 0.97281504]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 741. State = [[-0.1655998  -0.09653199  0.2371346   1.        ]]. Action = [[0.8389056  0.37786305 1.1081433  0.9081943 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 742. State = [[-0.13757338 -0.08436491  0.27130473  1.        ]]. Action = [[0.6690757  0.2410568  0.4018526  0.70417714]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 743. State = [[-0.11413628 -0.07695664  0.29998305  1.        ]]. Action = [[0.55893064 0.13943851 0.9476383  0.09513056]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 744. State = [[-0.26307344 -0.03867521  0.11472233  1.        ]]. Action = [[ 0.7967607   0.11184466 -0.27157116 -0.00447869]]. Reward = [100.]
Curr episode timestep = 7
Current timestep = 745. State = [[-0.25283337 -0.04466303  0.10905179  1.        ]]. Action = [[ 0.8049568  -0.00504172  1.1054296   0.9734613 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 746. State = [[-0.22710675 -0.04576688  0.14019048  1.        ]]. Action = [[0.65154195 0.12249768 1.463973   0.97569084]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 747. State = [[-0.19834727 -0.04626577  0.19305629  1.        ]]. Action = [[ 0.7693436 -0.0725894  1.125401   0.9835193]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 748. State = [[-0.16722924 -0.04918268  0.23857725  1.        ]]. Action = [[ 0.5919002  -0.11507088  1.136198    0.85307014]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 749. State = [[-0.14259547 -0.05306616  0.2730429   1.        ]]. Action = [[0.6020322  0.01693118 0.15131855 0.4408983 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 750. State = [[-0.12558886 -0.05330517  0.29776165  1.        ]]. Action = [[0.05252492 0.02057219 0.9105668  0.06668699]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 751. State = [[-0.11785143 -0.05302292  0.31562382  1.        ]]. Action = [[ 0.05718255  0.05238163 -0.13103366  0.0494951 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 752. State = [[-0.11901578 -0.04787565  0.31842166  1.        ]]. Action = [[-0.21416765  0.26101267  0.26318836  0.01393557]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 753. State = [[-0.11196449 -0.03922895  0.33084723  1.        ]]. Action = [[0.68945026 0.16296709 0.31080937 0.08397055]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 754. State = [[-0.27009255  0.10305551  0.11728334  1.        ]]. Action = [[ 0.8404316   0.2087518  -1.0880927  -0.00725108]]. Reward = [-10.]
Curr episode timestep = 9
Current timestep = 755. State = [[-0.25483406  0.11209458  0.11206841  1.        ]]. Action = [[ 0.81517005 -0.27847636  1.1041431   0.94154274]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 756. State = [[-0.22660658  0.10267048  0.14125615  1.        ]]. Action = [[ 0.9057839 -0.3605652  1.1453013  0.9635544]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 757. State = [[-0.19209452  0.0922606   0.18388556  1.        ]]. Action = [[ 0.85142386 -0.22560775  0.9746156   0.8171065 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 758. State = [[-0.15514259  0.08110802  0.22780596  1.        ]]. Action = [[ 0.9220381  -0.38270313  1.2617133   0.5502763 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 759. State = [[-0.12362982  0.06840111  0.27090064  1.        ]]. Action = [[ 0.46180677 -0.3314438   0.6331959   0.17797565]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 760. State = [[-0.10258265  0.05760319  0.30403262  1.        ]]. Action = [[ 0.49359107 -0.26668668  1.0132341   0.05132115]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 761. State = [[-0.263747   -0.10459571  0.11723768  1.        ]]. Action = [[ 0.35254586 -0.24864125 -0.25141656 -0.00323516]]. Reward = [100.]
Curr episode timestep = 6
Current timestep = 762. State = [[-0.257353   -0.11268016  0.11084449  1.        ]]. Action = [[0.62276495 0.45004475 1.0982108  0.9890758 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 763. State = [[-0.24083917 -0.1017882   0.13702542  1.        ]]. Action = [[0.62784886 0.4600699  0.9912362  0.9965527 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 764. State = [[-0.21290746 -0.08854042  0.17841053  1.        ]]. Action = [[0.87143874 0.15282106 1.3109679  0.9850061 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 765. State = [[-0.18820441 -0.0784152   0.21367928  1.        ]]. Action = [[0.09514499 0.2991519  0.0832231  0.95582557]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 766. State = [[-0.1717281  -0.06980891  0.23254499  1.        ]]. Action = [[0.5928328  0.11912656 0.95709443 0.682196  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 767. State = [[-0.15683804 -0.06700228  0.2570177   1.        ]]. Action = [[ 0.95995903  0.08263493 -0.11785305  0.7642498 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 768. State = [[-0.15536219 -0.06682192  0.2591228   1.        ]]. Action = [[ 0.8783605   0.20518756 -0.54818225  0.46329522]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 769. State = [[-0.14231451 -0.06242279  0.27808532  1.        ]]. Action = [[0.86657    0.24881577 1.3811405  0.5624994 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 770. State = [[-0.11387504 -0.0585697   0.3158004   1.        ]]. Action = [[ 0.767529   -0.15495473  0.01878524  0.18314493]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 771. State = [[-0.09652944 -0.05803893  0.3179427   1.        ]]. Action = [[ 0.82328427  0.0570085  -1.2070653   0.04188466]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 771 is [False, True, 3, True]
Human Feedback received at timestep 771 of 1
Current timestep = 772. State = [[-0.06151482 -0.05770155  0.27616665  1.        ]]. Action = [[ 8.1542277e-01 -2.6843727e-02 -9.8233998e-01  8.3732605e-04]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 773. State = [[-0.02409258 -0.0577166   0.250371    1.        ]]. Action = [[ 0.949698   -0.02286577  0.04079628  0.03074825]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 774. State = [[-0.26713124  0.01895403  0.11563762  1.        ]]. Action = [[ 0.81555784  0.01338875  1.0932815  -0.03516376]]. Reward = [100.]
Curr episode timestep = 12
Current timestep = 775. State = [[-0.25590625  0.01951638  0.11369599  1.        ]]. Action = [[ 0.9173627  -0.15506077  1.5616784   0.99872994]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 775 is [False, True, 3, False]
Human Feedback received at timestep 775 of 1
Current timestep = 776. State = [[-0.22151753  0.01478827  0.16235048  1.        ]]. Action = [[ 0.79190755 -0.31059504  1.6896048   0.9150665 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 777. State = [[-0.18821502  0.00688967  0.22114019  1.        ]]. Action = [[ 0.92296374 -0.24340904  0.88566756  0.9740701 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 778. State = [[-1.6647568e-01  4.4363485e-05  2.5304282e-01  1.0000000e+00]]. Action = [[-0.13735455 -0.04843509  0.6159816   0.90566325]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 779. State = [[-0.15521191 -0.00709221  0.2861576   1.        ]]. Action = [[ 0.7125566  -0.4136815   1.2997108   0.59569657]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 780. State = [[-0.13004044 -0.01685215  0.3270813   1.        ]]. Action = [[ 0.91377544 -0.1481874   0.2695694   0.19969332]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 781. State = [[-0.10506923 -0.02208016  0.33491543  1.        ]]. Action = [[ 0.76826763 -0.12352425 -0.7036971   0.01814246]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 782. State = [[-0.07713957 -0.02924675  0.3110481   1.        ]]. Action = [[ 0.8835242  -0.21870899 -0.97346044  0.02681315]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 782 is [False, True, 3, True]
Human Feedback received at timestep 782 of -1
Current timestep = 783. State = [[-0.03735811 -0.03445482  0.28814653  1.        ]]. Action = [[0.27850616 0.08849418 0.49163342 0.02270389]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 784. State = [[-0.26883462  0.09299983  0.11925735  1.        ]]. Action = [[ 0.3449943   0.11796606  0.71223116 -0.04724276]]. Reward = [100.]
Curr episode timestep = 9
Current timestep = 785. State = [[-0.25748265  0.10060494  0.10917335  1.        ]]. Action = [[ 0.8712176  -0.31392688  0.41821647  0.99369586]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 785 is [False, True, 3, False]
Human Feedback received at timestep 785 of 1
Current timestep = 786. State = [[-0.22813234  0.09337525  0.12595424  1.        ]]. Action = [[ 0.65717316 -0.20390809  1.1459079   0.9762238 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 787. State = [[-0.19954206  0.08236366  0.1646702   1.        ]]. Action = [[ 0.70317245 -0.39199883  1.4469128   0.99864364]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 788. State = [[-0.17819451  0.07168578  0.21585798  1.        ]]. Action = [[ 0.03748143 -0.19344938  1.0852838   0.98432505]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 789. State = [[-0.16362356  0.06226893  0.2538751   1.        ]]. Action = [[ 0.7572508  -0.34152615  0.6339321   0.816761  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 790. State = [[-0.13557386  0.05160249  0.28332198  1.        ]]. Action = [[ 0.8713187 -0.2462219  0.4732015  0.588392 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 791. State = [[-0.10766167  0.04295679  0.3087565   1.        ]]. Action = [[ 0.9336138  -0.27705622  0.5638368   0.10262108]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 792. State = [[-0.07431762  0.03322583  0.32835835  1.        ]]. Action = [[ 0.83413374 -0.27645206  0.32653785  0.03607213]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 792 is [False, True, 3, True]
Human Feedback received at timestep 792 of -1
Current timestep = 793. State = [[-0.261073   -0.15519328  0.11524266  1.        ]]. Action = [[ 0.93129706 -0.15411472 -0.62587166 -0.01178867]]. Reward = [100.]
Curr episode timestep = 8
Current timestep = 794. State = [[-0.26148745 -0.17200997  0.10276586  1.        ]]. Action = [[-0.04789382  0.23456502  0.5445137   0.9980705 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 794 is [False, True, 3, False]
Human Feedback received at timestep 794 of 1
Current timestep = 795. State = [[-0.25019273 -0.16366048  0.11979271  1.        ]]. Action = [[0.8260572  0.5657066  1.3424807  0.99930024]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 796. State = [[-0.23084548 -0.14105062  0.16114885  1.        ]]. Action = [[0.830551   0.7440556  0.7473326  0.98738945]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 797. State = [[-0.19795746 -0.11476768  0.18723345  1.        ]]. Action = [[0.70654225 0.45526683 0.15541244 0.9993727 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 798. State = [[-0.16979001 -0.09849616  0.20911007  1.        ]]. Action = [[0.76897955 0.2720827  1.0676985  0.99592364]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 799. State = [[-0.1456338  -0.09205257  0.23456417  1.        ]]. Action = [[0.8193197  0.16137362 0.2987628  0.9840721 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 800. State = [[-0.13185602 -0.08572296  0.25147054  1.        ]]. Action = [[0.8593631  0.33303738 1.151726   0.98692036]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 801. State = [[-0.10413723 -0.07745124  0.28365198  1.        ]]. Action = [[ 0.5939288   0.11074424 -0.04071486  0.7967758 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 802. State = [[-0.08879883 -0.06949793  0.28365955  1.        ]]. Action = [[ 0.4886415   0.33123875 -0.7761022   0.22829258]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 802 is [False, True, 3, True]
Human Feedback received at timestep 802 of -1
Current timestep = 803. State = [[-0.0676878  -0.06247266  0.26385438  1.        ]]. Action = [[ 0.8720348   0.02708614 -0.681273    0.07866716]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 804. State = [[-0.06314642 -0.06269826  0.26784113  1.        ]]. Action = [[ 0.29141998 -0.00833637  0.3971722   0.0026592 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 805. State = [[-0.05729241 -0.05877842  0.2848773   1.        ]]. Action = [[-0.30024672  0.16769242  0.81187224  0.02286398]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 806. State = [[-0.27213076  0.06161774  0.1213663   1.        ]]. Action = [[ 0.39154816  0.07580137  1.4188313  -0.00410557]]. Reward = [100.]
Curr episode timestep = 12
Current timestep = 807. State = [[-0.25975856  0.06022609  0.12428303  1.        ]]. Action = [[ 0.8683071 -0.2762146  0.6120086  0.9968221]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 807 is [False, True, 3, False]
Human Feedback received at timestep 807 of 1
Current timestep = 808. State = [[-0.2319569   0.05299209  0.134129    1.        ]]. Action = [[ 0.80139804 -0.2523259   0.3284793   0.99689555]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 809. State = [[-0.20278966  0.04594969  0.15276395  1.        ]]. Action = [[ 0.6641867  -0.14614457  0.8028152   0.9979842 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 810. State = [[-0.18249683  0.04321428  0.17141418  1.        ]]. Action = [[ 0.7856623  -0.24401897  1.3628576   0.97158504]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 811. State = [[-0.18037117  0.042662    0.17372653  1.        ]]. Action = [[ 0.8458264 -0.1930157  1.376081   0.9773824]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 812. State = [[-0.17979155  0.04225651  0.17418103  1.        ]]. Action = [[ 0.6310835  -0.26435435  1.0473752   0.95423126]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 813. State = [[-0.17987384  0.04206932  0.17420633  1.        ]]. Action = [[ 0.9393568  -0.11457306  0.4467306   0.96621585]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 814. State = [[-0.17979436  0.04209518  0.1743216   1.        ]]. Action = [[ 0.9044905  -0.27645928  0.9356394   0.973613  ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 815. State = [[-0.1697678   0.03962723  0.19108978  1.        ]]. Action = [[ 0.43352056 -0.14060467  1.5316906   0.9811672 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 816. State = [[-0.14871106  0.03734239  0.2487347   1.        ]]. Action = [[0.6087642  0.00773001 1.5538988  0.932302  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 817. State = [[-0.12587158  0.03454679  0.28800538  1.        ]]. Action = [[ 0.8060541  -0.15657687 -0.30269086  0.53740907]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 818. State = [[-0.09895815  0.02904594  0.3035536   1.        ]]. Action = [[ 0.7317172  -0.260432    0.8919127   0.09024394]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 818 is [False, True, 3, True]
Human Feedback received at timestep 818 of 1
Current timestep = 819. State = [[-0.06998334  0.02049261  0.3280424   1.        ]]. Action = [[ 0.78223634 -0.16354752 -0.02534008  0.00219715]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 820. State = [[-0.26809183  0.08789579  0.11662064  1.        ]]. Action = [[ 0.53788066 -0.11738151  0.33493757 -0.02886379]]. Reward = [100.]
Curr episode timestep = 13
Current timestep = 821. State = [[-0.25660947  0.0925827   0.11366644  1.        ]]. Action = [[ 0.72842646 -0.41362607  1.1414099   0.9879637 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 821 is [False, True, 3, False]
Human Feedback received at timestep 821 of 1
Current timestep = 822. State = [[-0.22749715  0.0814345   0.14557603  1.        ]]. Action = [[ 0.73439634 -0.29859728  1.3221471   0.9974506 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 823. State = [[-0.1987729   0.07260573  0.19234799  1.        ]]. Action = [[ 0.8585963  -0.23287404  1.1228833   0.98955226]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 824. State = [[-0.16947742  0.06254162  0.23264576  1.        ]]. Action = [[ 0.42679787 -0.30345452  0.6984372   0.9667269 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 825. State = [[-0.1539554   0.05665101  0.25217095  1.        ]]. Action = [[ 0.86810493 -0.11674088 -0.6827879   0.68507814]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 826. State = [[-0.14315888  0.05455366  0.26274058  1.        ]]. Action = [[ 0.73986506 -0.14878649  0.38957334  0.41890538]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 827. State = [[-0.12091374  0.04750701  0.27416787  1.        ]]. Action = [[ 0.8659295  -0.23749667 -0.2262274   0.23330617]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 828. State = [[-0.10322294  0.04078005  0.26276296  1.        ]]. Action = [[-0.08923656 -0.21933466 -0.58255506  0.03470409]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 829. State = [[-0.09624414  0.03028594  0.25917313  1.        ]]. Action = [[ 0.18395722 -0.36159062  0.46030045  0.08542442]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 829 is [False, True, 3, True]
Human Feedback received at timestep 829 of 1
Current timestep = 830. State = [[-0.07961348  0.01568091  0.27815434  1.        ]]. Action = [[ 0.8334017  -0.3027625   0.83458304  0.05964684]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 830 is [False, True, 3, True]
Human Feedback received at timestep 830 of -1
Current timestep = 831. State = [[-0.26080298 -0.11298954  0.11661798  1.        ]]. Action = [[ 0.07633185 -0.14359522  0.13108063 -0.00412649]]. Reward = [100.]
Curr episode timestep = 10
Current timestep = 832. State = [[-0.25242978 -0.1232212   0.11329518  1.        ]]. Action = [[0.7101059  0.4268322  1.4268551  0.99849236]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 832 is [False, True, 3, False]
Human Feedback received at timestep 832 of 1
Current timestep = 833. State = [[-0.22807702 -0.11031882  0.15367752  1.        ]]. Action = [[0.8756993  0.5250187  1.5288546  0.99022293]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 834. State = [[-0.20071726 -0.0943571   0.2110353   1.        ]]. Action = [[0.23967957 0.22194445 1.591341   0.9969555 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 835. State = [[-0.18661162 -0.08079042  0.26855722  1.        ]]. Action = [[0.25867856 0.43133378 0.9168868  0.993376  ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 836. State = [[-0.17043923 -0.06559137  0.30123347  1.        ]]. Action = [[0.46370864 0.3694036  0.38902354 0.7586856 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 837. State = [[-0.15855768 -0.0581479   0.31688967  1.        ]]. Action = [[ 0.7808889   0.27444232 -1.6559936   0.26144266]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 838. State = [[-0.1464635  -0.05182046  0.33409274  1.        ]]. Action = [[0.8237792  0.33938718 1.1660492  0.08278131]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 839. State = [[-0.12035145 -0.04376779  0.3634689   1.        ]]. Action = [[ 0.8359133   0.10053694 -0.11479056  0.09656286]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 840. State = [[-0.10176254 -0.04085519  0.35435924  1.        ]]. Action = [[ 0.25378168  0.00398242 -1.0865153   0.03853798]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 841. State = [[-0.0871039  -0.03759041  0.3301104   1.        ]]. Action = [[-0.02997065  0.18966413 -0.28383088  0.0835979 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 841 is [False, True, 3, True]
Human Feedback received at timestep 841 of -1
Current timestep = 842. State = [[-0.08087626 -0.0317991   0.3147014   1.        ]]. Action = [[ 0.6935079   0.06954741 -0.6910951   0.05358553]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 843. State = [[-0.05933679 -0.0283523   0.28620532  1.        ]]. Action = [[ 0.8149606   0.06210017 -1.0583167   0.04663312]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 844. State = [[-0.0242339  -0.02676174  0.2600965   1.        ]]. Action = [[ 0.89280057 -0.1083262   0.3653841   0.00960493]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 845. State = [[-0.2717238   0.12426777  0.13780168  1.        ]]. Action = [[ 0.7615378  -0.2273522   0.46669364 -0.04653108]]. Reward = [100.]
Curr episode timestep = 13
Current timestep = 846. State = [[-0.25520194  0.1378101   0.13452719  1.        ]]. Action = [[ 0.81789494 -0.39672446  1.4276576   0.9930216 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 846 is [False, True, 3, False]
Human Feedback received at timestep 846 of 1
Current timestep = 847. State = [[-0.2246946   0.12476736  0.17598738  1.        ]]. Action = [[ 0.6820686  -0.40762603  1.0519662   0.93618464]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 848. State = [[-0.19806565  0.11333334  0.21558036  1.        ]]. Action = [[ 0.81468487 -0.31807125  1.0271292   0.9767642 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 849. State = [[-0.173346    0.10321075  0.25556198  1.        ]]. Action = [[ 0.0951519  -0.27835     1.1242242   0.78768253]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 850. State = [[-0.15720756  0.09226473  0.28947416  1.        ]]. Action = [[ 0.78587925 -0.24918425  0.15000153  0.3402779 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 851. State = [[-0.13690951  0.08419769  0.3044847   1.        ]]. Action = [[ 0.65472496 -0.20787036  0.1490283   0.21344745]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 852. State = [[-0.11378752  0.0767441   0.302688    1.        ]]. Action = [[ 0.8898866  -0.17599493 -0.71145105  0.06884444]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 853. State = [[-0.08286995  0.06822146  0.28800896  1.        ]]. Action = [[ 0.37877083 -0.37264168  0.10133076  0.06864274]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 853 is [False, True, 3, True]
Human Feedback received at timestep 853 of -1
Current timestep = 854. State = [[-0.06061454  0.05907161  0.29066133  1.        ]]. Action = [[ 0.9040971  -0.05934882  0.09238338  0.05065501]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 855. State = [[-0.03721645  0.05250201  0.2840945   1.        ]]. Action = [[ 0.33844578 -0.3156377  -0.63025045  0.02381825]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 856. State = [[-0.01903801  0.0452282   0.26408675  1.        ]]. Action = [[ 0.2628287  -0.10734975 -0.3822565   0.02256966]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 857. State = [[-0.2635959   0.00590369  0.11451039  1.        ]]. Action = [[ 0.67665434 -0.22850835  0.01562333 -0.03813517]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 858. State = [[-0.25548574  0.00657704  0.10992672  1.        ]]. Action = [[ 0.7278533  -0.05958527  1.0696673   0.99754214]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 859. State = [[-0.23878467  0.00369443  0.12830478  1.        ]]. Action = [[ 0.5042012  -0.24846148  0.29841232  0.8589988 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 860. State = [[-2.1105163e-01 -9.0405316e-04  1.4895403e-01  1.0000000e+00]]. Action = [[ 0.8612329  -0.03789544  1.1325188   0.9720683 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 861. State = [[-0.19014752 -0.00219714  0.17823978  1.        ]]. Action = [[ 0.85258746 -0.1897828   0.8894012   0.9797753 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 862. State = [[-0.18580559 -0.00233666  0.18065724  1.        ]]. Action = [[ 0.753803  -0.134278   1.1764474  0.9687673]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 863. State = [[-0.18507598 -0.00233555  0.18113424  1.        ]]. Action = [[ 0.6328769  -0.08279794  1.1020734   0.8966905 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 864. State = [[-0.17088321 -0.00249018  0.19767593  1.        ]]. Action = [[ 0.91748977 -0.01177931  1.3366973   0.9479376 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 865. State = [[-0.13909446 -0.00646208  0.24423483  1.        ]]. Action = [[ 0.8445866  -0.29823446  0.919857    0.86910677]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 866. State = [[-0.10539351 -0.01440332  0.2800761   1.        ]]. Action = [[ 0.7834511  -0.11918503  0.560061    0.15191245]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 867. State = [[-0.08278955 -0.01761438  0.29770535  1.        ]]. Action = [[ 0.45374846 -0.06291574 -0.25480628  0.05651665]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 868. State = [[-0.06779762 -0.02284857  0.2882166   1.        ]]. Action = [[ 0.26529193 -0.2888186  -0.47784638  0.03228426]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 869. State = [[-0.05087076 -0.02841129  0.28683862  1.        ]]. Action = [[ 0.630842   -0.05149591  0.5360482   0.00424743]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 870. State = [[-0.03974254 -0.0306748   0.29382262  1.        ]]. Action = [[ 0.16198766 -0.02322388 -0.81745505  0.02224672]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 871. State = [[-0.02499546 -0.02985554  0.2648855   1.        ]]. Action = [[ 0.9778147   0.1364479  -0.9606831   0.03290343]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 872. State = [[-0.26606753  0.08261675  0.11727341  1.        ]]. Action = [[-0.2636031  -0.00481606  0.7031882  -0.02273989]]. Reward = [100.]
Curr episode timestep = 14
Current timestep = 873. State = [[-0.2505833   0.08601531  0.11670404  1.        ]]. Action = [[ 0.93784106 -0.43572116  1.3667028   0.9887159 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 874. State = [[-0.21929973  0.0760124   0.15025608  1.        ]]. Action = [[ 0.8485093  -0.32752705  1.0516822   0.9797425 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 875. State = [[-0.18890868  0.06541931  0.18020292  1.        ]]. Action = [[ 0.71722984 -0.22092259 -0.05318773  0.95111704]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 876. State = [[-0.17346308  0.06197532  0.18683736  1.        ]]. Action = [[ 0.6766517  -0.30665857  1.035764    0.91368604]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 877. State = [[-0.17157379  0.06036253  0.1881793   1.        ]]. Action = [[ 0.698393   -0.06348264  0.5900929   0.8247309 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 878. State = [[-0.15899129  0.05676404  0.20336223  1.        ]]. Action = [[ 0.81005514 -0.18055022  1.3304121   0.8168912 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 879. State = [[-0.12445025  0.04809931  0.24955966  1.        ]]. Action = [[ 0.67043066 -0.33133316  1.2606955   0.44034398]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 880. State = [[-0.10427261  0.03899459  0.2869023   1.        ]]. Action = [[-0.00869608 -0.1859616   0.35770273  0.06165683]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 881. State = [[-0.09390526  0.03145324  0.30304483  1.        ]]. Action = [[ 0.45116258 -0.17016232  0.2968905   0.01791358]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 882. State = [[-0.07672232  0.02579967  0.31809345  1.        ]]. Action = [[ 0.8677772  -0.21258318  0.22182298  0.02585268]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 883. State = [[-0.27098784  0.13233867  0.14100678  1.        ]]. Action = [[ 0.7599633  -0.03624958 -0.03476214 -0.01441848]]. Reward = [100.]
Curr episode timestep = 10
Current timestep = 884. State = [[-0.25543588  0.13108017  0.14446443  1.        ]]. Action = [[ 0.9264903  -0.31451452  0.573652    0.993762  ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 885. State = [[-0.2371782   0.12025117  0.15881869  1.        ]]. Action = [[-0.00870919 -0.39278054  0.7067485   0.9802444 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 886. State = [[-0.22502334  0.10531198  0.17571324  1.        ]]. Action = [[ 0.66617393 -0.43719798  0.17312074  0.94600284]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 887. State = [[-0.19895938  0.09460921  0.20067921  1.        ]]. Action = [[ 0.75990033 -0.20064646  1.4195771   0.95458126]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 888. State = [[-0.1772547   0.08927735  0.23395827  1.        ]]. Action = [[ 0.7806232  -0.2474317  -0.28587294  0.69290996]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 889. State = [[-0.16514653  0.08361756  0.24854048  1.        ]]. Action = [[ 0.672971   -0.32702005  0.87677646  0.26064134]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 890. State = [[-0.14775544  0.07790972  0.27161944  1.        ]]. Action = [[ 0.8789861  -0.10688549 -0.51983166  0.1876378 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 891. State = [[-0.13694605  0.07325445  0.27920493  1.        ]]. Action = [[ 0.7439816  -0.27040923  0.13034582  0.12999022]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 892. State = [[-0.11812995  0.06254391  0.28183082  1.        ]]. Action = [[ 0.81152725 -0.29555094 -0.5743201   0.11465621]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 893. State = [[-0.09025007  0.05348799  0.26690057  1.        ]]. Action = [[ 0.4578122  -0.31160718 -0.08954704  0.06958425]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 894. State = [[-0.06841403  0.04164022  0.27077776  1.        ]]. Action = [[ 0.7065263  -0.2871145   0.47493815  0.04589581]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 895. State = [[-0.04222862  0.03033599  0.29049698  1.        ]]. Action = [[ 0.7608565  -0.3166777   0.6497226   0.01655841]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 896. State = [[-0.02496589  0.02080246  0.3088529   1.        ]]. Action = [[-0.4215839  -0.12197214  0.29087806  0.01063561]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 897. State = [[-0.26312327 -0.07205088  0.11568852  1.        ]]. Action = [[ 0.7648859  -0.13982826  0.01321268 -0.00483721]]. Reward = [100.]
Curr episode timestep = 13
Current timestep = 898. State = [[-0.25514    -0.08091213  0.1120453   1.        ]]. Action = [[0.5181253  0.17470598 1.2434835  0.9871206 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 899. State = [[-0.23756842 -0.07693964  0.14734922  1.        ]]. Action = [[0.70640445 0.26825857 1.5649102  0.94884753]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 900. State = [[-0.2096955  -0.07389243  0.20209363  1.        ]]. Action = [[0.8803208  0.02512419 1.2605124  0.93608665]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 901. State = [[-0.17886098 -0.07255272  0.2492017   1.        ]]. Action = [[0.4264351  0.05314922 0.86126375 0.86944366]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 902. State = [[-0.1546844  -0.06863729  0.28167653  1.        ]]. Action = [[0.79900706 0.16392517 0.4025631  0.19625008]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 903. State = [[-0.12947005 -0.06235743  0.30348244  1.        ]]. Action = [[0.80871665 0.21332204 0.25293875 0.1269387 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 904. State = [[-0.09911132 -0.0534699   0.32562795  1.        ]]. Action = [[0.6142268  0.24982548 0.85201764 0.05492532]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 905. State = [[-0.08170444 -0.04825766  0.34073818  1.        ]]. Action = [[-0.05015337 -0.09456044 -0.34108424  0.04578972]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 906. State = [[-0.0748449  -0.04855069  0.33609292  1.        ]]. Action = [[ 0.3648666  -0.01998574 -0.11497879  0.03371394]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 907. State = [[-0.05983933 -0.04880942  0.34264758  1.        ]]. Action = [[ 0.5126078  -0.01322454  0.74084044  0.03365374]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 908. State = [[-0.04254578 -0.04497639  0.35871285  1.        ]]. Action = [[ 0.70911753  0.23379827 -0.1540916   0.02657878]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 909. State = [[-0.01525764 -0.03793909  0.352486    1.        ]]. Action = [[ 0.66134405  0.24134016 -0.18398511  0.00226104]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 910. State = [[-0.26736587  0.10014977  0.11783055  1.        ]]. Action = [[ 0.7162838  -0.0363819  -0.545336   -0.03554791]]. Reward = [100.]
Curr episode timestep = 12
Current timestep = 911. State = [[-0.25404528  0.10988077  0.10926003  1.        ]]. Action = [[ 0.85334635 -0.23014575  0.86936855  0.9612441 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 912. State = [[-0.22470309  0.10234462  0.1243389   1.        ]]. Action = [[ 0.8678818  -0.30133694  0.30764866  0.9655349 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 913. State = [[-0.19055873  0.09235819  0.14660871  1.        ]]. Action = [[ 0.93287635 -0.3503328   1.3159361   0.8435943 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 914. State = [[-0.16426738  0.08402564  0.18116198  1.        ]]. Action = [[ 0.89558375 -0.29044074  0.6754327   0.8107028 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 915. State = [[-0.16015008  0.08311138  0.18464611  1.        ]]. Action = [[ 0.88570476 -0.20875543  0.84963727  0.38385963]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 916. State = [[-0.15887141  0.08303434  0.18550959  1.        ]]. Action = [[ 0.8009665  -0.3207209   0.6114974   0.32618225]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 917. State = [[-0.15839963  0.08314563  0.18587612  1.        ]]. Action = [[ 0.55467343 -0.34654093  0.7671571   0.32662368]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 918. State = [[-0.1480962   0.07755925  0.2017238   1.        ]]. Action = [[ 0.56650734 -0.3717928   1.1862335   0.2522664 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 919. State = [[-0.12547962  0.06717745  0.2394087   1.        ]]. Action = [[ 0.875952   -0.23669803  0.6573541   0.23344398]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 920. State = [[-0.10622057  0.06336094  0.26196125  1.        ]]. Action = [[ 0.43940246 -0.33540994 -0.64913976  0.14383626]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 921. State = [[-0.09178297  0.0569182   0.27626464  1.        ]]. Action = [[ 0.9604001  -0.29141986  0.7673125   0.06680858]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 922. State = [[-0.06202453  0.04973151  0.29924303  1.        ]]. Action = [[ 0.8380101  -0.18096638  0.2401073   0.03902042]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 923. State = [[-0.03213478  0.04426253  0.3048438   1.        ]]. Action = [[ 0.85173845 -0.0500378  -0.16937077  0.0047816 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 924. State = [[-0.27140698  0.12733701  0.14113995  1.        ]]. Action = [[-0.02230155 -0.12532204  0.5997734  -0.01369834]]. Reward = [100.]
Curr episode timestep = 13
Current timestep = 925. State = [[-0.25398502  0.12371183  0.1514509   1.        ]]. Action = [[ 0.89788103 -0.42047763  1.2609682   0.9863975 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 926. State = [[-0.22561808  0.11386056  0.18145385  1.        ]]. Action = [[ 0.9234923  -0.30730295  1.0078063   0.98830366]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 927. State = [[-0.18749186  0.10132509  0.22876424  1.        ]]. Action = [[ 0.8800396  -0.37179768  1.3780689   0.92155015]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 928. State = [[-0.16201909  0.09402612  0.26511002  1.        ]]. Action = [[ 0.71636415 -0.42865694 -0.33816028  0.37866306]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 929. State = [[-0.15163511  0.08945059  0.26772067  1.        ]]. Action = [[ 0.764889   -0.17644542 -0.24378777  0.20545089]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 930. State = [[-0.13061935  0.08177532  0.26618373  1.        ]]. Action = [[ 0.55993843 -0.35912997 -0.1660831   0.17429566]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 931. State = [[-0.11028414  0.07368106  0.25737616  1.        ]]. Action = [[ 0.72796154  0.00156069 -0.5952896   0.15568161]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 932. State = [[-0.07846513  0.07075702  0.25514105  1.        ]]. Action = [[ 0.78599715 -0.23477018  0.8888562   0.06276321]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 933. State = [[-0.06000983  0.06700843  0.27510723  1.        ]]. Action = [[ 0.7160821  -0.27673483 -0.7332442   0.05068088]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 934. State = [[-0.05141782  0.06256818  0.28140122  1.        ]]. Action = [[ 0.56302464 -0.22916782  0.2993617   0.01774466]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 935. State = [[-0.030448    0.05063128  0.30297828  1.        ]]. Action = [[ 0.29573655 -0.4158883   1.1570168   0.02503896]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 936. State = [[-0.27223036  0.13423988  0.13945699  1.        ]]. Action = [[ 0.5789788  -0.3025344   0.12633729 -0.00148451]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 937. State = [[-0.25722718  0.13166375  0.15202986  1.        ]]. Action = [[ 0.76322985 -0.40514064  1.597548    0.98780453]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 938. State = [[-0.23343435  0.12080533  0.18410033  1.        ]]. Action = [[ 0.79470277 -0.29539967  0.04602194  0.99207306]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 939. State = [[-0.20529106  0.11051995  0.20000012  1.        ]]. Action = [[ 0.88053524 -0.35285997  0.5189507   0.9289539 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 940. State = [[-0.18378858  0.10310772  0.2156571   1.        ]]. Action = [[ 0.94114864 -0.3805158  -0.17599201  0.5196738 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 941. State = [[-0.16880079  0.09535547  0.22951294  1.        ]]. Action = [[ 0.724432  -0.4145776  0.9135642  0.3852855]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 942. State = [[-0.13706952  0.08340387  0.26449046  1.        ]]. Action = [[ 0.90309274 -0.2762829   1.256057    0.31001222]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 943. State = [[-0.10477932  0.07109766  0.30165988  1.        ]]. Action = [[ 0.79545546 -0.3581168   0.33222365  0.13422477]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 944. State = [[-0.08040284  0.05968401  0.308155    1.        ]]. Action = [[ 0.5230465  -0.25328612 -0.6389781   0.04397488]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 945. State = [[-0.06165648  0.0512295   0.28768826  1.        ]]. Action = [[ 0.32726276 -0.19357324 -0.68211246  0.04578972]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 946. State = [[-0.03887684  0.04519784  0.27325496  1.        ]]. Action = [[ 0.7350508  -0.14837956  0.07662821  0.02244914]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 947. State = [[-0.02203038  0.03790256  0.2641783   1.        ]]. Action = [[ 0.46992385 -0.17042834 -0.75484705  0.0150373 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 948. State = [[-0.00616279  0.02928701  0.23684666  1.        ]]. Action = [[-0.29591513 -0.35618913 -0.47732186  0.00521123]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 949. State = [[-0.2702972   0.07776189  0.12225938  1.        ]]. Action = [[ 0.69206536 -0.32090986  0.60878944 -0.0245828 ]]. Reward = [100.]
Curr episode timestep = 12
Current timestep = 950. State = [[-0.2561039   0.07449619  0.13488197  1.        ]]. Action = [[ 0.68047714 -0.36213732  1.6604033   0.9691949 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 951. State = [[-0.235406    0.06701858  0.17024846  1.        ]]. Action = [[ 0.706403   -0.22316551  0.33351064  0.9870211 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 952. State = [[-0.2084318   0.05895452  0.18628553  1.        ]]. Action = [[ 0.7709596  -0.23195702  0.35538507  0.89633155]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 953. State = [[-0.18181625  0.05129809  0.1983628   1.        ]]. Action = [[ 0.72307646 -0.20081002 -0.15709972  0.70528567]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 954. State = [[-0.15330862  0.04340916  0.2097871   1.        ]]. Action = [[ 0.68918157 -0.2724322   0.8557222   0.42308056]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 955. State = [[-0.12042752  0.03395101  0.24335326  1.        ]]. Action = [[ 0.86763525 -0.18739986  1.1075459   0.17822874]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 956. State = [[-0.09065396  0.02668403  0.2735954   1.        ]]. Action = [[ 0.75099385 -0.19221342  0.16476989  0.07225668]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 957. State = [[-0.06456172  0.02139009  0.28349698  1.        ]]. Action = [[ 0.5255883  -0.11180091 -0.04611647  0.03052449]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 958. State = [[-0.04935535  0.02032439  0.28506052  1.        ]]. Action = [[-0.50107825 -0.17640597 -1.3886206  -0.00190991]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 959. State = [[-0.03937393  0.01924537  0.291086    1.        ]]. Action = [[ 0.8262495  -0.04047441  0.25784516  0.00490975]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 960. State = [[-0.26977232  0.16682772  0.11677173  1.        ]]. Action = [[-0.40354764 -0.19166291 -0.5198966  -0.01716155]]. Reward = [100.]
Curr episode timestep = 10
Current timestep = 961. State = [[-0.25501657  0.18148316  0.11633214  1.        ]]. Action = [[ 0.6858156  -0.40663248  1.4726725   0.9830662 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 962. State = [[-0.23131931  0.1686241   0.14671925  1.        ]]. Action = [[ 0.6319642  -0.4418875   0.38160372  0.9562807 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 963. State = [[-0.20955385  0.15244417  0.15513732  1.        ]]. Action = [[ 0.6416458  -0.49306726 -0.46392858  0.91468096]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 964. State = [[-0.19726434  0.14445935  0.15220277  1.        ]]. Action = [[ 0.87821245 -0.42638516  0.23120809  0.8674233 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 965. State = [[-0.19631355  0.14300762  0.15176582  1.        ]]. Action = [[ 0.8677435  -0.3853805   0.81223536  0.7974243 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 966. State = [[-0.19606431  0.1419162   0.15190913  1.        ]]. Action = [[ 0.71672964 -0.36782038  1.6378274   0.8452891 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 967. State = [[-0.19581844  0.14158933  0.1520294   1.        ]]. Action = [[ 0.9581044  -0.34590203  0.62245274  0.7803601 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 968. State = [[-0.1957607   0.14107908  0.15154973  1.        ]]. Action = [[ 0.6846874  -0.39727354  0.83677053  0.8167484 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 969. State = [[-0.19580215  0.14105551  0.15155798  1.        ]]. Action = [[ 0.74617124 -0.35828912  1.0542254   0.79206073]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 970. State = [[-0.18919434  0.13562529  0.1565057   1.        ]]. Action = [[ 0.3915136  -0.32876146  0.5385735   0.7056005 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 971. State = [[-0.17764279  0.12964611  0.1656471   1.        ]]. Action = [[ 0.78802073 -0.4242134   0.748791    0.68059087]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 972. State = [[-0.17494218  0.12893148  0.16799107  1.        ]]. Action = [[ 0.7411947  -0.42873943  0.7418151   0.47642946]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 973. State = [[-0.17441979  0.12873976  0.16839232  1.        ]]. Action = [[ 0.93743837 -0.3724916   0.82563543  0.427894  ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 974. State = [[-0.17434078  0.1287903   0.16849087  1.        ]]. Action = [[ 0.77723634 -0.4058913   0.96648717  0.39653933]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 975. State = [[-0.17446908  0.1287972   0.16851594  1.        ]]. Action = [[ 0.796227   -0.34191412  1.21363     0.42679632]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 976. State = [[-0.17446908  0.1287972   0.16851594  1.        ]]. Action = [[ 0.8131089  -0.29046118  0.5812917   0.34474587]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 977. State = [[-0.16178596  0.12364277  0.18714541  1.        ]]. Action = [[ 0.6599891  -0.35616994  1.5872529   0.43366873]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 978. State = [[-0.13424388  0.11151826  0.24092782  1.        ]]. Action = [[ 0.78924704 -0.34803104  1.3185403   0.29404807]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 979. State = [[-0.10823371  0.09875504  0.28229854  1.        ]]. Action = [[ 0.6871636  -0.36795092  0.47037172  0.2036463 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 980. State = [[-0.08362679  0.08586064  0.3005312   1.        ]]. Action = [[ 0.91185    -0.3107499  -0.13153958  0.08635104]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 981. State = [[-0.05148876  0.07389709  0.2967809   1.        ]]. Action = [[ 0.89792585 -0.33235776 -0.29656768  0.0190599 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 982. State = [[-0.01849853  0.06258184  0.2913082   1.        ]]. Action = [[ 0.6325469  -0.20088482  0.17635298  0.01756883]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 983. State = [[-0.25977048 -0.1630711   0.1134156   1.        ]]. Action = [[ 0.9394636  -0.02546674  1.2005339  -0.01829791]]. Reward = [100.]
Curr episode timestep = 22
Current timestep = 984. State = [[-0.25088608 -0.18000302  0.10613489  1.        ]]. Action = [[0.7960844  0.3266785  0.92919254 0.98768353]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 985. State = [[-0.22711203 -0.1755302   0.13173428  1.        ]]. Action = [[0.885165   0.17029095 1.2534134  0.99141574]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 986. State = [[-0.19340281 -0.16501772  0.17788517  1.        ]]. Action = [[0.6578829  0.44890547 1.5691962  0.96749365]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 987. State = [[-0.16897948 -0.14672466  0.22608523  1.        ]]. Action = [[0.31289732 0.44808435 0.2518518  0.90934014]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 988. State = [[-0.1572503  -0.13686825  0.2369565   1.        ]]. Action = [[0.64660716 0.58706856 0.08101964 0.27372456]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 989. State = [[-0.14408286 -0.1342589   0.2502225   1.        ]]. Action = [[0.76649857 0.08282948 0.8195121  0.20856953]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 990. State = [[-0.11610469 -0.12471932  0.27837375  1.        ]]. Action = [[0.890679   0.5112245  0.59724    0.15819192]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 991. State = [[-0.08841262 -0.10870655  0.30680236  1.        ]]. Action = [[0.70489335 0.31236863 0.4042704  0.11065507]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 992. State = [[-0.06967396 -0.09724835  0.31190598  1.        ]]. Action = [[ 0.2579801   0.2898699  -0.6566373   0.04785419]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 993. State = [[-0.049274   -0.08756108  0.29738745  1.        ]]. Action = [[ 0.7750361   0.2038449  -0.12487912  0.01776516]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 994. State = [[-0.2616351  -0.08756182  0.11281499  1.        ]]. Action = [[ 0.7034435   0.11584413  0.648366   -0.01368475]]. Reward = [100.]
Curr episode timestep = 10
Current timestep = 995. State = [[-0.26007187 -0.09442713  0.10798014  1.        ]]. Action = [[-0.12229609  0.28218138  1.1116686   0.9827874 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 996. State = [[-0.24931921 -0.09016493  0.13358001  1.        ]]. Action = [[0.94865453 0.27866614 0.8465564  0.9970217 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 997. State = [[-0.2236823  -0.08254767  0.17260106  1.        ]]. Action = [[0.9438715 0.1425085 1.4392588 0.95794  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 998. State = [[-0.18968095 -0.07686401  0.22326829  1.        ]]. Action = [[0.81030214 0.09289694 1.194309   0.97211146]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 999. State = [[-0.16539201 -0.0743292   0.25893566  1.        ]]. Action = [[0.84670377 0.16427934 0.03140092 0.42141175]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1000. State = [[-0.14989494 -0.07283612  0.273755    1.        ]]. Action = [[0.8651955  0.0948962  0.6868479  0.16929078]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1001. State = [[-0.12425191 -0.07008912  0.29516742  1.        ]]. Action = [[0.65863085 0.08436978 0.01067805 0.13666451]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1002. State = [[-0.10282096 -0.061076    0.29587966  1.        ]]. Action = [[ 0.8041105   0.40564895 -0.63820577  0.07846904]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1003. State = [[-0.07727393 -0.05384818  0.2794734   1.        ]]. Action = [[ 0.5559622   0.26209486 -1.2399975   0.01507723]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1004. State = [[-0.07619118 -0.05269978  0.27876544  1.        ]]. Action = [[ 0.6656189   0.00821543 -0.95366573  0.01232719]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1005. State = [[-0.07100178 -0.05250182  0.2821421   1.        ]]. Action = [[ 0.5534625  -0.1113497   0.18911076  0.01209152]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1006. State = [[-0.05117562 -0.05448431  0.29172122  1.        ]]. Action = [[ 0.4795928  -0.15026045  0.3758831   0.01232457]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1007. State = [[-0.02912073 -0.05745407  0.30655894  1.        ]]. Action = [[ 0.64301944 -0.11195701  0.43108416  0.01458204]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1008. State = [[-0.2605702  -0.1383759   0.11821228  1.        ]]. Action = [[-0.8508307   0.30287266 -0.6338537  -0.00970131]]. Reward = [100.]
Curr episode timestep = 13
Current timestep = 1009. State = [[-0.2527851  -0.15045744  0.11248173  1.        ]]. Action = [[0.81336474 0.47295094 1.3441198  0.7879734 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1010. State = [[-0.22788192 -0.13961563  0.14877653  1.        ]]. Action = [[0.851385  0.3696959 0.9983511 0.9053639]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1011. State = [[-0.20211923 -0.12575115  0.18356118  1.        ]]. Action = [[0.1764189  0.34989107 0.83338904 0.96338916]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1012. State = [[-0.18183815 -0.11736085  0.21942338  1.        ]]. Action = [[ 0.79522574 -0.03329706  1.081492    0.96046853]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1013. State = [[-0.15075846 -0.10920598  0.26397538  1.        ]]. Action = [[0.6910329  0.4664117  1.068954   0.69638515]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1014. State = [[-0.12139466 -0.09700582  0.2925472   1.        ]]. Action = [[ 0.9307319   0.1921246  -0.17893314  0.19706106]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1015. State = [[-0.09536674 -0.08970302  0.29604363  1.        ]]. Action = [[ 0.45291817  0.19893181 -0.11489666  0.06721413]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1016. State = [[-0.07379155 -0.08392652  0.30013266  1.        ]]. Action = [[0.663013   0.10129178 0.34357643 0.04603565]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1017. State = [[-0.05068469 -0.08158793  0.32167214  1.        ]]. Action = [[0.42692423 0.00431132 0.95966697 0.04057813]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1018. State = [[-0.03103275 -0.07280119  0.3395241   1.        ]]. Action = [[ 0.8948438   0.37929916 -0.5069506   0.02526069]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1019. State = [[-0.00217369 -0.06095031  0.32076502  1.        ]]. Action = [[ 7.7830315e-01  3.3244097e-01 -6.1614692e-01  6.4158440e-04]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1020. State = [[-0.26030555 -0.12940024  0.11563616  1.        ]]. Action = [[-0.38810754  0.09852278 -0.45554674 -0.02592081]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 1021. State = [[-0.25378212 -0.14026496  0.10983337  1.        ]]. Action = [[0.6420479 0.3908924 1.2327251 0.9970596]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1022. State = [[-0.2330041  -0.1306444   0.14450724  1.        ]]. Action = [[0.8396535  0.39012468 1.4682586  0.9977739 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1023. State = [[-0.20216212 -0.1147034   0.20180751  1.        ]]. Action = [[0.48247826 0.3756913  1.5176861  0.9879259 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1024. State = [[-0.17420082 -0.10053962  0.25651038  1.        ]]. Action = [[0.92272913 0.29550958 0.9209261  0.9521171 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1025. State = [[-0.14376958 -0.09184518  0.2841241   1.        ]]. Action = [[ 0.79141116  0.1815027  -0.15514433  0.25574243]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1026. State = [[-0.11604105 -0.08073314  0.2849      1.        ]]. Action = [[ 0.88954186  0.40867698 -0.53910756  0.14762616]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1027. State = [[-0.08373551 -0.06953358  0.2709087   1.        ]]. Action = [[ 0.5840943   0.22690642 -0.05981338  0.07035279]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1028. State = [[-0.05984212 -0.05904848  0.28217706  1.        ]]. Action = [[0.38901138 0.28121448 1.0689068  0.01170421]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1029. State = [[-0.03911258 -0.04731743  0.31889126  1.        ]]. Action = [[0.45898724 0.27547407 1.0274856  0.02101016]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1030. State = [[-0.02391129 -0.03941651  0.3373856   1.        ]]. Action = [[ 0.5671413   0.10188019 -0.66513157  0.01619649]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1031. State = [[-0.26485217  0.00155283  0.11588865  1.        ]]. Action = [[ 0.88253987 -0.07396257  0.77354145 -0.01807016]]. Reward = [100.]
Curr episode timestep = 10
Current timestep = 1032. State = [[-0.2517764  -0.00245798  0.10846362  1.        ]]. Action = [[ 0.8487463  -0.19186091  0.7667203   0.9680686 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1033. State = [[-0.23168978 -0.00903715  0.12689525  1.        ]]. Action = [[ 0.6599872  -0.10902137  1.1888278   0.98573446]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1034. State = [[-0.2046294  -0.01246324  0.16266106  1.        ]]. Action = [[ 0.8614788  -0.07667875  0.37938404  0.8353722 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1035. State = [[-0.18094328 -0.01452488  0.17647463  1.        ]]. Action = [[ 0.83192587 -0.17920613 -0.51498294  0.88033366]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1036. State = [[-0.17883421 -0.01461606  0.17776172  1.        ]]. Action = [[ 0.581074   -0.01246172 -0.5232129   0.7702234 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1037. State = [[-0.17886794 -0.01467944  0.17776497  1.        ]]. Action = [[ 0.5709593  -0.01529121  0.6517906   0.786216  ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1038. State = [[-0.16522896 -0.0166577   0.19444865  1.        ]]. Action = [[ 0.9250033  -0.14052236  1.3962591   0.7947135 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1039. State = [[-0.13091186 -0.01824971  0.24359864  1.        ]]. Action = [[0.79016733 0.10367727 1.1505017  0.6398773 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1040. State = [[-0.09774157 -0.01945636  0.28510657  1.        ]]. Action = [[ 0.8327422  -0.20273352  0.5911598   0.09015656]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1041. State = [[-0.07281943 -0.02038953  0.32091722  1.        ]]. Action = [[0.4376682  0.10737419 1.1546962  0.02517831]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1042. State = [[-0.0476386  -0.01802929  0.35535538  1.        ]]. Action = [[0.83646035 0.16777122 0.31807804 0.02862775]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1043. State = [[-0.02597061 -0.01978712  0.3692069   1.        ]]. Action = [[ 0.30692625 -0.3199643   0.05373096  0.01981425]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1044. State = [[-0.26295012 -0.17741634  0.11718548  1.        ]]. Action = [[-0.2783907  -0.17680293  0.29854584 -0.00480831]]. Reward = [100.]
Curr episode timestep = 12
Current timestep = 1045. State = [[-0.25882727 -0.18714808  0.10370253  1.        ]]. Action = [[0.4742651  0.81207657 0.43653798 0.99761677]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1046. State = [[-0.24025396 -0.16801116  0.12010816  1.        ]]. Action = [[0.7993152  0.62354684 1.7131433  0.99668646]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1047. State = [[-0.21155693 -0.14400388  0.17396657  1.        ]]. Action = [[0.846488   0.39370465 0.8096819  0.9923444 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1048. State = [[-0.17816202 -0.12897918  0.20856565  1.        ]]. Action = [[0.69865894 0.24329865 0.7323196  0.99170136]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1049. State = [[-0.15675287 -0.12407901  0.22829238  1.        ]]. Action = [[0.4738946  0.22821951 0.07033253 0.8249769 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1050. State = [[-0.1459478  -0.11694219  0.24134834  1.        ]]. Action = [[0.5634843  0.37045777 0.73819447 0.4925964 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1051. State = [[-0.12164477 -0.09888028  0.265929    1.        ]]. Action = [[0.80442667 0.6556121  0.49624944 0.20213652]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1052. State = [[-0.09820113 -0.08037046  0.2918252   1.        ]]. Action = [[0.43196487 0.26635933 0.5133107  0.1031096 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1053. State = [[-0.07795374 -0.07375725  0.31465617  1.        ]]. Action = [[0.72562504 0.06429017 0.47177482 0.02327025]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1054. State = [[-0.05253006 -0.07217427  0.32641235  1.        ]]. Action = [[ 0.6671612  -0.04498833 -0.05951643  0.00762308]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1055. State = [[-0.02567364 -0.06804924  0.33564022  1.        ]]. Action = [[0.7942097  0.2512499  0.5036082  0.01301765]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1056. State = [[-0.26583865 -0.05067882  0.11347734  1.        ]]. Action = [[-0.02654475 -0.00186986 -0.29909682 -0.01181334]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 1057. State = [[-0.25601912 -0.05901666  0.10839637  1.        ]]. Action = [[ 0.8286021  -0.03370112  1.1238515   0.99644136]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1058. State = [[-0.23048247 -0.06086474  0.13755156  1.        ]]. Action = [[0.90617204 0.03040028 1.189903   0.9617504 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1059. State = [[-0.19819902 -0.06046601  0.18036352  1.        ]]. Action = [[0.5906676  0.16031694 0.8375535  0.9858676 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1060. State = [[-0.17874375 -0.06029988  0.2025682   1.        ]]. Action = [[0.7438164  0.23581982 0.05429435 0.9341581 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1061. State = [[-0.17705777 -0.06023641  0.20561348  1.        ]]. Action = [[0.47182214 0.02710903 0.45493817 0.8021493 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1062. State = [[-0.17719577 -0.05992872  0.20636944  1.        ]]. Action = [[0.7951131  0.24324596 0.48065472 0.68515897]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1063. State = [[-0.17709298 -0.05985727  0.20649998  1.        ]]. Action = [[0.87369835 0.15874219 0.05590749 0.580626  ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1064. State = [[-0.17718469 -0.05976216  0.20651066  1.        ]]. Action = [[0.7465012  0.47507143 0.18784523 0.48746765]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1065. State = [[-0.17726116 -0.05970189  0.20647778  1.        ]]. Action = [[ 0.85590124 -0.05577135 -0.12601161  0.5994835 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1066. State = [[-0.17726116 -0.05970189  0.20647778  1.        ]]. Action = [[ 0.81247103  0.04399776 -0.18919897  0.6575849 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1067. State = [[-0.17724943 -0.05963885  0.20647117  1.        ]]. Action = [[0.8215935  0.05496657 0.29548383 0.55985165]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1068. State = [[-0.17724943 -0.05963885  0.20647117  1.        ]]. Action = [[0.78569984 0.21676397 0.56025505 0.6414838 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1069. State = [[-0.17724943 -0.05963885  0.20647117  1.        ]]. Action = [[0.74674857 0.05378938 0.5529046  0.69932973]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1070. State = [[-0.16493027 -0.05618336  0.21636036  1.        ]]. Action = [[0.93399715 0.26627433 0.68180346 0.6669115 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1071. State = [[-0.14277276 -0.05259604  0.23489444  1.        ]]. Action = [[ 0.7747958   0.04932952 -0.6229353   0.4352646 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1072. State = [[-0.12989827 -0.05202658  0.24557172  1.        ]]. Action = [[0.8097305  0.02375937 0.6375184  0.19063199]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1073. State = [[-0.10308307 -0.05254905  0.26049647  1.        ]]. Action = [[ 0.7694781  -0.1910699  -0.29173636  0.14400506]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1074. State = [[-0.07577092 -0.05320464  0.27011275  1.        ]]. Action = [[0.60018015 0.02975619 0.8749857  0.06256306]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1075. State = [[-0.05522753 -0.05450887  0.30416167  1.        ]]. Action = [[ 0.09133315 -0.08568573  1.2605925   0.03611255]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1076. State = [[-0.03952337 -0.05531561  0.34005105  1.        ]]. Action = [[0.774137   0.02565086 0.32223797 0.0174433 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1077. State = [[-0.2685049   0.07530859  0.1176737   1.        ]]. Action = [[ 0.558918    0.2617345  -0.29342628 -0.00262147]]. Reward = [100.]
Curr episode timestep = 20
Current timestep = 1078. State = [[-0.2539955   0.08176007  0.11158971  1.        ]]. Action = [[ 0.8762119  -0.2535497   0.949667    0.99510074]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1079. State = [[-0.22581127  0.07349857  0.13441396  1.        ]]. Action = [[ 0.6717694  -0.33827996  0.97090125  0.9731679 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1080. State = [[-0.1948861   0.06252361  0.17811398  1.        ]]. Action = [[ 0.60341394 -0.26096296  1.7653413   0.9706023 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1081. State = [[-0.16837636  0.05428626  0.2428748   1.        ]]. Action = [[ 0.84362245 -0.20048118  1.4875205   0.7713845 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1082. State = [[-0.1383371   0.04681935  0.2953859   1.        ]]. Action = [[ 0.6904435  -0.22710907  0.71780086  0.20207727]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1083. State = [[-0.11370188  0.04077871  0.32512274  1.        ]]. Action = [[ 0.52101064 -0.14697981  0.17423844  0.10339558]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1084. State = [[-0.09641411  0.03384207  0.32610887  1.        ]]. Action = [[ 0.43486714 -0.1927566  -0.5837283   0.02732408]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1085. State = [[-0.07325111  0.02651757  0.31759855  1.        ]]. Action = [[ 0.85044026 -0.24885821  0.12947941  0.01290548]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1086. State = [[-0.04596333  0.02020146  0.32865208  1.        ]]. Action = [[ 0.92437005 -0.10219812  0.6766679   0.0065285 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1087. State = [[-0.26354328 -0.04068805  0.11545666  1.        ]]. Action = [[ 0.18882537 -0.00564086 -0.7191292  -0.01105666]]. Reward = [100.]
Curr episode timestep = 9
Current timestep = 1088. State = [[-0.25376278 -0.04752777  0.11120278  1.        ]]. Action = [[0.7880182  0.01285875 1.4494658  0.9876411 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1089. State = [[-0.23122258 -0.04970112  0.14920256  1.        ]]. Action = [[0.75303984 0.04938304 1.000803   0.92995906]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1090. State = [[-0.20311084 -0.04890222  0.17901593  1.        ]]. Action = [[0.6770688  0.18580282 0.01666951 0.990541  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1091. State = [[-0.18636431 -0.04737369  0.18800062  1.        ]]. Action = [[0.92295885 0.24235392 0.5991547  0.92243123]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1092. State = [[-0.1844034  -0.04558166  0.18873775  1.        ]]. Action = [[ 0.7316054  -0.0204041   0.10517859  0.756171  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1093. State = [[-0.17329596 -0.04643546  0.20741886  1.        ]]. Action = [[ 0.26259017 -0.10036606  1.6148727   0.7524023 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1094. State = [[-0.15527795 -0.04646786  0.2559812   1.        ]]. Action = [[0.6927376  0.04812574 1.2857227  0.46633112]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1095. State = [[-0.1308545  -0.04692212  0.297843    1.        ]]. Action = [[ 0.5233973  -0.0522536   0.35189772  0.2092334 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1096. State = [[-0.11491889 -0.04720476  0.3185414   1.        ]]. Action = [[0.06737411 0.07910097 0.36906195 0.09231961]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1097. State = [[-0.10613425 -0.04547963  0.3186551   1.        ]]. Action = [[ 0.80011666  0.0172143  -0.92919946  0.07594442]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1098. State = [[-0.08046524 -0.04283451  0.29841667  1.        ]]. Action = [[ 0.78971267  0.13757455 -0.512324    0.04431081]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1099. State = [[-0.05580863 -0.04088217  0.28060994  1.        ]]. Action = [[ 0.17908049  0.06061697 -0.3100152   0.03502882]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1100. State = [[-0.03816998 -0.03985019  0.2877424   1.        ]]. Action = [[0.63538    0.01180065 1.1320748  0.00826514]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1101. State = [[-0.2674581   0.10993586  0.11893691  1.        ]]. Action = [[ 0.8092284   0.05920696  0.05710936 -0.00475383]]. Reward = [100.]
Curr episode timestep = 13
Current timestep = 1102. State = [[-0.25186446  0.1196247   0.11365344  1.        ]]. Action = [[ 0.71975243 -0.3854848   1.2196774   0.9942479 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1103. State = [[-0.22632673  0.10774528  0.14935385  1.        ]]. Action = [[ 0.86827326 -0.30225635  1.4103904   0.9725907 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1104. State = [[-0.19142859  0.0981993   0.20422414  1.        ]]. Action = [[ 0.8311409  -0.23502612  1.5001831   0.9345746 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1105. State = [[-0.15621482  0.08756372  0.26184297  1.        ]]. Action = [[ 0.8437965  -0.41122913  1.4541097   0.44381082]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1106. State = [[-0.12625057  0.07447378  0.31068847  1.        ]]. Action = [[ 0.57209706 -0.30482602  0.48964906  0.23130691]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1107. State = [[-0.10658751  0.06419368  0.32910317  1.        ]]. Action = [[ 0.5539489  -0.26484394 -0.25361764  0.10262573]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1108. State = [[-0.09444818  0.05810565  0.32119688  1.        ]]. Action = [[ 0.05702472 -0.10485727 -0.43730307  0.0546006 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1109. State = [[-0.07900812  0.05112727  0.31443283  1.        ]]. Action = [[ 0.7565119  -0.24976635  0.07642531  0.05324745]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1110. State = [[-0.06013622  0.03886102  0.30803895  1.        ]]. Action = [[ 0.2936256  -0.42753947 -0.4398259   0.02341473]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1111. State = [[-0.04397848  0.02497393  0.2933629   1.        ]]. Action = [[ 0.8369758  -0.24713463 -0.7036147   0.00270009]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1112. State = [[-0.26985464  0.17514527  0.11606048  1.        ]]. Action = [[ 0.84142363 -0.1918006  -0.3715477  -0.00141674]]. Reward = [100.]
Curr episode timestep = 10
Current timestep = 1113. State = [[-0.2554965   0.1905992   0.11326575  1.        ]]. Action = [[ 0.5272393 -0.4155178  1.4387035  0.991019 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1114. State = [[-0.23429483  0.17625509  0.1541122   1.        ]]. Action = [[ 0.70362234 -0.5194221   1.2217202   0.9432088 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1115. State = [[-0.20658167  0.15913199  0.19472006  1.        ]]. Action = [[ 0.86665463 -0.44589138  0.6069946   0.8908794 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1116. State = [[-0.17278199  0.14416064  0.23117861  1.        ]]. Action = [[ 0.7763696  -0.44781625  1.2686448   0.40367532]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1117. State = [[-0.14527132  0.12825072  0.26631972  1.        ]]. Action = [[ 0.5732124  -0.40150547  0.15396023  0.28048873]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1118. State = [[-0.12418394  0.11269024  0.28925425  1.        ]]. Action = [[ 0.5332205  -0.4207874   0.8098469   0.17786121]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1119. State = [[-0.10203829  0.09515817  0.3306865   1.        ]]. Action = [[ 0.5346019  -0.55448127  1.6929162   0.12863457]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1120. State = [[-0.08332502  0.08037082  0.36929557  1.        ]]. Action = [[ 0.3806045  -0.17033863 -0.2819059   0.07911909]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1121. State = [[-0.0702201   0.06927606  0.3626688   1.        ]]. Action = [[ 0.9346963  -0.37902677 -0.4565165   0.02100003]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1122. State = [[-0.03807177  0.05408742  0.35071948  1.        ]]. Action = [[ 0.4016266  -0.3349707  -0.12895727  0.00274038]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1123. State = [[-0.02473935  0.04034121  0.33867407  1.        ]]. Action = [[ 0.04539573 -0.4003147  -0.9979844   0.00322723]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1124. State = [[-0.26328048 -0.117722    0.11241326  1.        ]]. Action = [[ 0.76567817 -0.29501122 -0.6976328  -0.0154413 ]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 1125. State = [[-0.2581956  -0.12935892  0.0988024   1.        ]]. Action = [[0.55702615 0.26038742 0.43878436 0.95442593]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1126. State = [[-0.2411523  -0.12094004  0.10954154  1.        ]]. Action = [[0.9105723  0.47666526 0.79441524 0.9893224 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1127. State = [[-0.2145999  -0.10563321  0.13857244  1.        ]]. Action = [[0.40162098 0.36324596 0.72903824 0.9828372 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1128. State = [[-0.19136691 -0.09169129  0.17161186  1.        ]]. Action = [[0.5796329  0.28410113 1.3453496  0.9897113 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1129. State = [[-0.17476998 -0.08530959  0.20710328  1.        ]]. Action = [[0.62578535 0.10022938 0.613256   0.9698484 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1130. State = [[-0.16742562 -0.08546438  0.21826643  1.        ]]. Action = [[ 0.32358718 -0.1138742   0.63271976  0.8586856 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1131. State = [[-0.14753965 -0.08388163  0.24391428  1.        ]]. Action = [[0.80517864 0.19998562 0.7709074  0.69768786]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1132. State = [[-0.1267297  -0.0812913   0.26620802  1.        ]]. Action = [[ 0.11117113  0.18125546 -0.8377514   0.24424267]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1133. State = [[-0.11424737 -0.07653423  0.27905262  1.        ]]. Action = [[0.82172894 0.28411865 0.6503043  0.12201607]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1134. State = [[-0.10033836 -0.06831741  0.29002708  1.        ]]. Action = [[-0.02643448  0.17531586 -0.6999917   0.09538841]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1135. State = [[-0.09951295 -0.06076967  0.2763161   1.        ]]. Action = [[-0.1828345   0.21800447 -0.2946254   0.03648317]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1136. State = [[-0.08970577 -0.05466688  0.282073    1.        ]]. Action = [[0.78980684 0.12833357 1.046669   0.04953134]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1137. State = [[-0.06776144 -0.04959708  0.29439235  1.        ]]. Action = [[ 0.6884643   0.05115426 -0.5185739   0.01720262]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1138. State = [[-0.04185387 -0.04800489  0.2956775   1.        ]]. Action = [[0.75442135 0.01600718 0.53912497 0.03004289]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1139. State = [[-0.018183   -0.04791515  0.32485816  1.        ]]. Action = [[ 0.16884685 -0.08051884  1.2642913   0.00354075]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1140. State = [[-0.27136996  0.05962701  0.1151737   1.        ]]. Action = [[ 0.9734862   0.00416481  0.33650732 -0.00431877]]. Reward = [100.]
Curr episode timestep = 15
Current timestep = 1141. State = [[-0.2578741   0.06285618  0.11458939  1.        ]]. Action = [[ 0.6277373  -0.32933378  1.5001154   0.9742248 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1142. State = [[-0.23483175  0.05426928  0.15500572  1.        ]]. Action = [[ 0.7577691 -0.3049382  1.3457665  0.9520056]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1143. State = [[-0.20605691  0.04629638  0.20134014  1.        ]]. Action = [[ 0.7109852  -0.13496941  0.82972693  0.92145133]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1144. State = [[-0.17438069  0.041025    0.23869456  1.        ]]. Action = [[ 0.8868625  -0.1672917   1.0196862   0.43846118]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1145. State = [[-0.1465974   0.03187748  0.2761196   1.        ]]. Action = [[ 0.1540668  -0.29027808  0.58932567  0.2524085 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1146. State = [[-0.13031657  0.02615505  0.2927917   1.        ]]. Action = [[ 0.763435   -0.05116898 -0.11645317  0.10794961]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1147. State = [[-0.11809301  0.02397352  0.2916839   1.        ]]. Action = [[-0.13385409 -0.12384105 -0.48206425  0.08573937]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1148. State = [[-0.11327972  0.01580314  0.27424988  1.        ]]. Action = [[ 0.80432    -0.23906237 -0.9664116   0.07476723]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1149. State = [[-0.09101918  0.01321773  0.24998851  1.        ]]. Action = [[ 0.42254496 -0.09821671 -0.99896455  0.06471622]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1150. State = [[-0.08761723  0.01261586  0.24751276  1.        ]]. Action = [[ 0.13301766 -0.16958082 -0.96537256  0.03812599]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1151. State = [[-0.08697913  0.00785905  0.2472215   1.        ]]. Action = [[-0.03652418 -0.29896766 -0.1201793   0.04611969]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1152. State = [[-0.08712049  0.00268661  0.24780819  1.        ]]. Action = [[ 0.03135788 -0.16508162 -0.9700594   0.04891407]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1153. State = [[-7.5613245e-02 -6.2994804e-04  2.5662437e-01  1.0000000e+00]]. Action = [[ 0.96384144 -0.11966276  0.83667755  0.03930175]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1154. State = [[-0.04887477 -0.00403962  0.27086863  1.        ]]. Action = [[ 0.76019263 -0.07098985  0.12587142  0.02331758]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1155. State = [[-0.01886847 -0.00594379  0.28057456  1.        ]]. Action = [[ 0.86899066 -0.03775042  0.35584903  0.01606143]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1156. State = [[-0.27145433  0.11887992  0.13570192  1.        ]]. Action = [[ 0.73507524  0.13035798 -0.35887718 -0.01784217]]. Reward = [100.]
Curr episode timestep = 15
Current timestep = 1157. State = [[-0.25416097  0.13246535  0.13046414  1.        ]]. Action = [[ 0.92217326 -0.3057741   1.0038025   0.925827  ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1158. State = [[-0.22646606  0.12253262  0.15502205  1.        ]]. Action = [[ 0.64798224 -0.32914758  0.923682    0.9192606 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1159. State = [[-0.20472813  0.11001364  0.18542308  1.        ]]. Action = [[ 0.23921835 -0.42559218  0.53684306  0.621161  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1160. State = [[-0.18831591  0.09303644  0.21144038  1.        ]]. Action = [[ 0.4845724  -0.5050515   0.8670449   0.43080056]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1161. State = [[-0.16511768  0.07847847  0.24532528  1.        ]]. Action = [[ 0.7865033  -0.2595737   0.811414    0.29077876]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1162. State = [[-0.13791376  0.06718301  0.2774534   1.        ]]. Action = [[ 0.6619227  -0.34907734  0.53775334  0.2756021 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1163. State = [[-0.12280119  0.06144596  0.2972745   1.        ]]. Action = [[ 0.52412915 -0.34947193 -1.2912127   0.17124271]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1164. State = [[-0.11083652  0.05518102  0.31035176  1.        ]]. Action = [[ 0.8714652  -0.24593526  0.78129435  0.1142838 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1165. State = [[-0.08657853  0.04769365  0.3202296   1.        ]]. Action = [[ 0.656144   -0.10597813 -0.73427486  0.07878745]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1166. State = [[-0.05522805  0.04481192  0.3060439   1.        ]]. Action = [[ 0.98702836 -0.09469187  0.0486722   0.02618527]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1167. State = [[-0.2630695  -0.13435982  0.11388586  1.        ]]. Action = [[ 0.85763013 -0.18884754  0.43491268 -0.00976205]]. Reward = [100.]
Curr episode timestep = 10
Current timestep = 1168. State = [[-0.254336   -0.1472484   0.10837251  1.        ]]. Action = [[0.92272365 0.33260787 1.2749805  0.9015231 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1169. State = [[-0.23248808 -0.13761286  0.1456694   1.        ]]. Action = [[0.4655769  0.44909596 1.4348049  0.99208117]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1170. State = [[-0.21010572 -0.12405393  0.19242676  1.        ]]. Action = [[0.5971439  0.19800305 0.67753744 0.9299127 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1171. State = [[-0.19386192 -0.11318441  0.21093473  1.        ]]. Action = [[-9.1788888e-02  3.3646572e-01 -1.4054775e-04  8.7895715e-01]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1172. State = [[-0.18232432 -0.09717868  0.22224194  1.        ]]. Action = [[0.8619962  0.52248216 0.7565198  0.751699  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1173. State = [[-0.1503898  -0.0830204   0.25415704  1.        ]]. Action = [[0.8656887  0.1328597  0.70351434 0.4974494 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1174. State = [[-0.11912964 -0.07465843  0.2724994   1.        ]]. Action = [[ 0.9196913   0.30436957 -0.38499343  0.20432293]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1175. State = [[-0.08870775 -0.06616157  0.26480988  1.        ]]. Action = [[ 0.6817932   0.19208598 -0.28577065  0.08591461]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1176. State = [[-0.05855088 -0.06168948  0.2741299   1.        ]]. Action = [[0.91723037 0.0178678  1.0058517  0.03170025]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1177. State = [[-0.26334137 -0.03960511  0.11349052  1.        ]]. Action = [[-0.26985562  0.17108035 -0.30477476 -0.00332487]]. Reward = [100.]
Curr episode timestep = 9
Current timestep = 1178. State = [[-0.25511676 -0.04570302  0.11008022  1.        ]]. Action = [[0.59953916 0.02550817 1.15587    0.983624  ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1179. State = [[-0.24549915 -0.04644579  0.1329024   1.        ]]. Action = [[0.06546474 0.072505   0.56426644 0.9751793 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1180. State = [[-0.23827909 -0.04627313  0.15575245  1.        ]]. Action = [[ 0.30787206 -0.03078091  0.6217637   0.97181034]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1181. State = [[-0.22002468 -0.04384916  0.1827305   1.        ]]. Action = [[0.66912436 0.2816398  0.9394131  0.9013512 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1182. State = [[-0.19248316 -0.03989218  0.20876034  1.        ]]. Action = [[ 0.88459754  0.07870173 -0.13417578  0.7648866 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1183. State = [[-0.16189882 -0.03684063  0.22376223  1.        ]]. Action = [[0.8686656  0.10009766 0.6737571  0.31945968]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1184. State = [[-0.1394808  -0.03485549  0.24185069  1.        ]]. Action = [[ 0.19545448  0.20848906 -0.00993133  0.18175983]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1185. State = [[-0.12643392 -0.03420716  0.24911226  1.        ]]. Action = [[ 0.8306854  -0.10097188  0.3088777   0.17929637]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1186. State = [[-0.09604649 -0.03500633  0.2695352   1.        ]]. Action = [[ 0.71786594 -0.03096813  1.1110888   0.08446956]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1187. State = [[-0.06550696 -0.03793344  0.30569762  1.        ]]. Action = [[ 0.847965   -0.18211061  0.6829691   0.0332855 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1188. State = [[-0.03450167 -0.03911735  0.32440645  1.        ]]. Action = [[ 0.889848    0.17854834 -0.08973491  0.00376415]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1189. State = [[-0.26748627  0.04946923  0.1164008   1.        ]]. Action = [[ 0.54033923 -0.22312617 -0.7308302  -0.00381982]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 1190. State = [[-0.25537136  0.05503327  0.11448474  1.        ]]. Action = [[ 0.49987125 -0.07255691  1.3732083   0.848951  ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1191. State = [[-0.23901613  0.05085934  0.14713094  1.        ]]. Action = [[ 0.5605997  -0.303383    0.77981424  0.7993156 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1192. State = [[-0.21405314  0.04479001  0.18290146  1.        ]]. Action = [[ 0.8510114  -0.13528454  1.2421508   0.46092832]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1193. State = [[-0.18071896  0.03861088  0.22923031  1.        ]]. Action = [[ 0.69655466 -0.19205916  1.2837629   0.34939098]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1194. State = [[-0.14850846  0.03022646  0.27650648  1.        ]]. Action = [[ 0.8794763  -0.29247957  0.7791259   0.23205411]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1195. State = [[-0.11540958  0.0215044   0.32126758  1.        ]]. Action = [[ 0.91757953 -0.19550562  1.3602176   0.16351557]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1196. State = [[-0.08813347  0.01233533  0.3505463   1.        ]]. Action = [[ 0.82295656 -0.25822377 -0.7095213   0.07183468]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1197. State = [[-0.06753932  0.0035725   0.33270398  1.        ]]. Action = [[-0.31902504 -0.3029514  -0.40874696  0.03064513]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1198. State = [[-0.0654261  -0.00484262  0.3220853   1.        ]]. Action = [[ 0.94730043 -0.04920405 -0.82982874  0.00284827]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1199. State = [[-0.0355198  -0.00930905  0.28907427  1.        ]]. Action = [[ 0.88180196 -0.16647202 -0.93774104  0.00971878]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1200. State = [[-0.2675333   0.06683169  0.11589843  1.        ]]. Action = [[ 0.9165429  -0.18655014 -0.39254808 -0.0137279 ]]. Reward = [100.]
Curr episode timestep = 10
Current timestep = 1201. State = [[-0.25141004  0.07013519  0.11587427  1.        ]]. Action = [[ 0.8659501  -0.36463904  1.4932783   0.71069646]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1202. State = [[-0.22367859  0.06155793  0.15435293  1.        ]]. Action = [[ 0.813462   -0.25847536  1.0801771   0.5403609 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1203. State = [[-0.19642726  0.05160365  0.19852392  1.        ]]. Action = [[ 0.16198683 -0.30492604  1.2895494   0.39686   ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1204. State = [[-0.18971483  0.04503642  0.23049827  1.        ]]. Action = [[ 0.6761811  -0.15994787  0.13652134  0.3340218 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1205. State = [[-0.18617472  0.04323884  0.23350632  1.        ]]. Action = [[ 0.6816454  -0.2994001  -0.43462992  0.29745352]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1206. State = [[-0.18667711  0.04251011  0.23362747  1.        ]]. Action = [[ 0.9291384  -0.26337922 -0.51563954  0.2934029 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1207. State = [[-0.18617597  0.0424672   0.234362    1.        ]]. Action = [[ 0.62244725 -0.35612047 -0.04360533  0.2934816 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1208. State = [[-0.17646676  0.03878403  0.2406535   1.        ]]. Action = [[ 0.7519467  -0.29437977  0.18673253  0.2623161 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1209. State = [[-0.15258962  0.03053271  0.26358443  1.        ]]. Action = [[ 0.8530514  -0.30580544  1.1598387   0.24998808]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1210. State = [[-0.12172142  0.02018423  0.29521856  1.        ]]. Action = [[ 0.66345406 -0.22757185  0.18429852  0.17644393]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1211. State = [[-0.10084645  0.01394353  0.29979232  1.        ]]. Action = [[ 0.736516   -0.08223718 -0.7371845   0.10179317]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1212. State = [[-0.07105606  0.00992418  0.27856424  1.        ]]. Action = [[ 0.7490108  -0.14169925 -0.29858935  0.0396868 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1213. State = [[-0.04764445  0.00536671  0.27694717  1.        ]]. Action = [[ 0.13279569 -0.14215362  0.47051263  0.00300479]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1214. State = [[-0.27277195  0.07508732  0.12310191  1.        ]]. Action = [[ 0.14424682 -0.08828163  1.3302026  -0.01135445]]. Reward = [100.]
Curr episode timestep = 13
Current timestep = 1215. State = [[-0.26506191  0.07621204  0.12737611  1.        ]]. Action = [[ 0.42019904 -0.05685627  0.82034326  0.63356495]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1216. State = [[-0.24575858  0.07256297  0.14902025  1.        ]]. Action = [[ 0.7573185  -0.31879085  1.0115819   0.55708766]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1217. State = [[-0.21740177  0.06163029  0.17485318  1.        ]]. Action = [[ 0.819445   -0.33276236 -0.11603653  0.44684172]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1218. State = [[-0.1925169   0.05282804  0.18747611  1.        ]]. Action = [[ 0.58820856 -0.26003873  0.59427834  0.40111983]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1219. State = [[-0.16289137  0.04380298  0.21490853  1.        ]]. Action = [[ 0.78986573 -0.18044478  1.0929317   0.34816456]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1220. State = [[-0.13950966  0.03905448  0.23999842  1.        ]]. Action = [[ 0.4801334  -0.17936397  0.03240395  0.21726322]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1221. State = [[-0.1293427   0.03573824  0.24855387  1.        ]]. Action = [[ 0.53618765 -0.2125628   0.22672963  0.1934824 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1222. State = [[-0.11157699  0.02719541  0.26250777  1.        ]]. Action = [[ 0.7439208  -0.2769968   0.38963127  0.14056861]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1223. State = [[-0.0868567  0.0194166  0.2693431  1.       ]]. Action = [[ 0.4648813  -0.15027916 -0.18428564  0.0949719 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1224. State = [[-0.06487145  0.01387655  0.2749615   1.        ]]. Action = [[ 0.67835844 -0.11273456  0.47669125  0.05043888]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1225. State = [[-0.04005555  0.00765816  0.28884792  1.        ]]. Action = [[ 0.7621689  -0.26188785  0.19190335  0.01124823]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1226. State = [[-0.27012226  0.17637679  0.11590715  1.        ]]. Action = [[ 0.667305   -0.04947227 -0.5184244  -0.00759047]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 1227. State = [[-0.2604846   0.18891731  0.10527557  1.        ]]. Action = [[ 0.38798738 -0.5125347   0.4324367   0.5188962 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1228. State = [[-0.23891258  0.17456289  0.12031697  1.        ]]. Action = [[ 0.808192   -0.44220674  1.199141    0.50428534]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1229. State = [[-0.21335328  0.15827832  0.15904793  1.        ]]. Action = [[ 0.53795123 -0.43130362  0.86177206  0.45840216]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1230. State = [[-0.18751934  0.14355838  0.19207218  1.        ]]. Action = [[ 0.8014827  -0.39756942  0.76839256  0.38450503]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1231. State = [[-0.15501434  0.128654    0.2263273   1.        ]]. Action = [[ 0.874501   -0.44671494  0.97496986  0.33310032]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1232. State = [[-0.13307585  0.12002929  0.2538148   1.        ]]. Action = [[ 0.78421366 -0.34168226 -0.48610806  0.2402041 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1233. State = [[-0.12954813  0.11909944  0.25844017  1.        ]]. Action = [[ 0.19139421 -0.26802218 -0.43360567  0.18340087]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1234. State = [[-0.12226639  0.11540034  0.2723672   1.        ]]. Action = [[ 0.35527325 -0.23544174  1.0182335   0.17218614]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1235. State = [[-0.10266455  0.10609388  0.3022014   1.        ]]. Action = [[ 0.76422644 -0.25733423  0.44643927  0.1514585 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1236. State = [[-0.08003063  0.0931735   0.32145214  1.        ]]. Action = [[ 0.7888336  -0.420884    0.16674542  0.09831464]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1237. State = [[-0.06422873  0.08171527  0.31981573  1.        ]]. Action = [[-0.32107866 -0.30356252 -0.5321531   0.04466963]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1238. State = [[-0.06052093  0.06890549  0.30933848  1.        ]]. Action = [[ 0.80859673 -0.28071856 -0.7754233   0.02409959]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1239. State = [[-0.03807953  0.05443025  0.2761089   1.        ]]. Action = [[ 0.74389005 -0.3425964  -0.982224    0.02258909]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1240. State = [[-0.01007098  0.04683713  0.24633507  1.        ]]. Action = [[ 0.01914752 -0.13971746  0.01301575  0.00341988]]. Reward = [0.]
Curr episode timestep = 13
