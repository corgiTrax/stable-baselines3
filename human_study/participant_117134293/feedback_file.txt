Current timestep = 0. State = [[-0.2579657   0.00789552]]. Action = [[-0.02517132 -0.00313229  0.08415417 -0.03610903]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [True, False, False, False, True, False]
State prediction error at timestep 0 is 0.012
Current timestep = 1. State = [[-0.25773534  0.00786076]]. Action = [[ 0.01121883  0.03684529 -0.07181501 -0.24135602]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False]
State prediction error at timestep 1 is 0.012
Current timestep = 2. State = [[-0.25779152  0.00829174]]. Action = [[-0.06113325  0.04126974  0.03300034  0.97395396]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, True, False]
State prediction error at timestep 2 is 0.012
Current timestep = 3. State = [[-0.25811496  0.00965719]]. Action = [[-0.06263261  0.07551753 -0.02271957 -0.21903908]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, True, False]
State prediction error at timestep 3 is 0.012
Current timestep = 4. State = [[-0.25902674  0.01240133]]. Action = [[-0.02606332 -0.08540395 -0.09080984  0.91687274]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, True, False]
State prediction error at timestep 4 is 0.012
Current timestep = 5. State = [[-0.25956765  0.01236246]]. Action = [[-0.07761858  0.08164795 -0.07904283 -0.8448607 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, True, False]
State prediction error at timestep 5 is 0.012
Current timestep = 6. State = [[-0.26086882  0.01396821]]. Action = [[ 0.09810986 -0.04243719 -0.07681088 -0.2252906 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, True, False]
State prediction error at timestep 6 is 0.012
Current timestep = 7. State = [[-0.26121038  0.01428649]]. Action = [[-0.05269296  0.07933923 -0.05097861  0.7123525 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, True, False]
State prediction error at timestep 7 is 0.012
Current timestep = 8. State = [[-0.2618357   0.01637212]]. Action = [[ 0.0754961   0.04299169 -0.08663189 -0.08161724]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, True, False]
State prediction error at timestep 8 is 0.012
Current timestep = 9. State = [[-0.26241556  0.01833274]]. Action = [[-0.07022719 -0.05783322  0.0835178   0.24431825]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, True, False]
State prediction error at timestep 9 is 0.012
Current timestep = 10. State = [[-0.26267964  0.01841912]]. Action = [[ 0.06681105 -0.08201386 -0.0795724  -0.67114556]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, True, False]
State prediction error at timestep 10 is 0.012
Current timestep = 11. State = [[-0.26252145  0.0168944 ]]. Action = [[-0.00926805 -0.06453748  0.05081462 -0.9684069 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, True, False]
State prediction error at timestep 11 is 0.012
Current timestep = 12. State = [[-0.26256195  0.0141682 ]]. Action = [[-0.00988554 -0.09839112  0.08039667 -0.614913  ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, True, False]
State prediction error at timestep 12 is 0.012
Current timestep = 13. State = [[-0.26281607  0.01019542]]. Action = [[ 0.09057599 -0.05426887  0.07797232  0.24568582]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, True, False]
State prediction error at timestep 13 is 0.012
Current timestep = 14. State = [[-0.2625818   0.00623064]]. Action = [[ 0.07226252  0.01412418 -0.09395985 -0.4160719 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, True, False]
State prediction error at timestep 14 is 0.012
Current timestep = 15. State = [[-0.26162902  0.00389043]]. Action = [[-0.05909092 -0.05171558 -0.0525969   0.7692232 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, True, False]
State prediction error at timestep 15 is 0.012
Current timestep = 16. State = [[-0.2619847   0.00144072]]. Action = [[-0.08847439  0.07359082 -0.01290637  0.7894316 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, True, False]
State prediction error at timestep 16 is 0.012
Current timestep = 17. State = [[-0.26231682  0.00131383]]. Action = [[ 0.00787131  0.08607116 -0.07212043 -0.33679414]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, True, False]
State prediction error at timestep 17 is 0.012
Current timestep = 18. State = [[-0.26279908  0.00277854]]. Action = [[-0.03301679  0.08093991 -0.04848113 -0.731575  ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, True, False]
State prediction error at timestep 18 is 0.012
Current timestep = 19. State = [[-0.26360267  0.00537082]]. Action = [[ 0.00312903 -0.03759826  0.05114145 -0.25821555]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, True, False]
State prediction error at timestep 19 is 0.012
Current timestep = 20. State = [[-0.2638974   0.00626556]]. Action = [[ 0.0632496   0.05764089 -0.0382315   0.49787724]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, True, False]
State prediction error at timestep 20 is 0.012
Current timestep = 21. State = [[-0.2643764   0.00768953]]. Action = [[ 0.05672931  0.00467298 -0.07356826  0.501621  ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, True, False]
State prediction error at timestep 21 is 0.012
Current timestep = 22. State = [[-0.26426205  0.00849445]]. Action = [[ 0.06753404  0.09819474  0.039411   -0.9514527 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [True, False, False, False, True, False]
State prediction error at timestep 22 is 0.012
Current timestep = 23. State = [[-0.26328278  0.0112678 ]]. Action = [[-0.02280841  0.06887992  0.05683497  0.03624845]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [True, False, False, False, True, False]
State prediction error at timestep 23 is 0.012
Current timestep = 24. State = [[-0.26325178  0.01463246]]. Action = [[ 0.03349089  0.09955809  0.05350745 -0.682824  ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [True, False, False, False, True, False]
State prediction error at timestep 24 is 0.012
Current timestep = 25. State = [[-0.26282316  0.01926046]]. Action = [[-0.0462237  -0.08078437  0.09888066  0.63734305]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [True, False, False, False, True, False]
State prediction error at timestep 25 is 0.012
Current timestep = 26. State = [[-0.2628492   0.02074503]]. Action = [[ 0.04534339  0.01859118 -0.00705447 -0.01341397]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [True, False, False, False, True, False]
State prediction error at timestep 26 is 0.012
Current timestep = 27. State = [[-0.2623336   0.02181267]]. Action = [[-0.05272523 -0.06325215  0.00538734 -0.01878482]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [True, False, False, False, True, False]
State prediction error at timestep 27 is 0.012
Current timestep = 28. State = [[-0.2624332   0.02170575]]. Action = [[-7.3070809e-02  1.4945790e-02 -7.2551519e-04 -9.1120285e-01]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [True, False, False, False, True, False]
State prediction error at timestep 28 is 0.012
Current timestep = 29. State = [[-0.26269615  0.02216191]]. Action = [[ 0.05071848  0.05536649 -0.01994523 -0.4208697 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [True, False, False, False, True, False]
State prediction error at timestep 29 is 0.012
Current timestep = 30. State = [[-0.26304576  0.0232635 ]]. Action = [[-0.01370352  0.06336819 -0.09457915 -0.95380545]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [True, False, False, False, True, False]
State prediction error at timestep 30 is 0.012
Current timestep = 31. State = [[-0.2637493   0.02532117]]. Action = [[-0.02395083  0.01285665 -0.02076205  0.84736323]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [True, False, False, False, True, False]
State prediction error at timestep 31 is 0.012
Current timestep = 32. State = [[-0.26444352  0.02728452]]. Action = [[ 4.3716282e-04 -7.0835866e-02 -7.5898826e-02 -4.9097490e-01]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [True, False, False, False, True, False]
State prediction error at timestep 32 is 0.012
Current timestep = 33. State = [[-0.26444927  0.02711857]]. Action = [[-0.07968862 -0.07912775  0.08637451 -0.9374181 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [True, False, False, False, True, False]
State prediction error at timestep 33 is 0.012
Current timestep = 34. State = [[-0.2644758   0.02594141]]. Action = [[ 0.0229729   0.01553579 -0.09458311  0.09854746]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [True, False, False, False, True, False]
State prediction error at timestep 34 is 0.012
Current timestep = 35. State = [[-0.26455525  0.0257423 ]]. Action = [[-0.02379552 -0.03595639  0.03375626  0.6699455 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [True, False, False, False, True, False]
State prediction error at timestep 35 is 0.012
Current timestep = 36. State = [[-0.26456162  0.02502204]]. Action = [[ 0.09312334 -0.00839349  0.06660537  0.02484822]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [True, False, False, False, True, False]
State prediction error at timestep 36 is 0.012
Current timestep = 37. State = [[-0.26435894  0.02443735]]. Action = [[ 0.0663007  -0.04746206  0.0988551   0.314659  ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [True, False, False, False, True, False]
State prediction error at timestep 37 is 0.012
Current timestep = 38. State = [[-0.2636577   0.02302128]]. Action = [[-0.03301517 -0.06903735 -0.06527947 -0.56067777]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [True, False, False, False, True, False]
State prediction error at timestep 38 is 0.012
Current timestep = 39. State = [[-0.26351318  0.02073802]]. Action = [[-0.02143808 -0.03881108 -0.03790156  0.5556381 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [True, False, False, False, True, False]
State prediction error at timestep 39 is 0.012
Current timestep = 40. State = [[-0.26363578  0.01832768]]. Action = [[-0.09060122  0.09276371 -0.07957199  0.32077074]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [True, False, False, False, True, False]
State prediction error at timestep 40 is 0.012
Current timestep = 41. State = [[-0.26410684  0.01819037]]. Action = [[ 0.04349054 -0.03881253  0.08305307 -0.17703742]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [True, False, False, False, True, False]
State prediction error at timestep 41 is 0.012
Current timestep = 42. State = [[-0.2641414   0.01720237]]. Action = [[-0.03742965  0.00716915  0.0617476   0.46081853]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [True, False, False, False, True, False]
State prediction error at timestep 42 is 0.012
Current timestep = 43. State = [[-0.26414132  0.01676363]]. Action = [[ 0.06237604  0.05458137  0.02491368 -0.7390872 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [True, False, False, False, True, False]
State prediction error at timestep 43 is 0.012
Current timestep = 44. State = [[-0.26412922  0.01696299]]. Action = [[-0.00907054  0.07323664  0.05582912 -0.0730992 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [True, False, False, False, True, False]
State prediction error at timestep 44 is 0.012
Current timestep = 45. State = [[-0.26464525  0.01835301]]. Action = [[ 0.04537082 -0.01607694  0.02252619 -0.51758724]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [True, False, False, False, True, False]
State prediction error at timestep 45 is 0.012
Current timestep = 46. State = [[-0.26467416  0.01858224]]. Action = [[0.03811892 0.04228497 0.09190296 0.02757192]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [True, False, False, False, True, False]
State prediction error at timestep 46 is 0.012
Current timestep = 47. State = [[-0.26454148  0.0193175 ]]. Action = [[-0.01317835 -0.02618026  0.0384618   0.755185  ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [True, False, False, False, True, False]
State prediction error at timestep 47 is 0.012
Current timestep = 48. State = [[-0.26449776  0.01953243]]. Action = [[-0.04631549  0.02226819 -0.08048056  0.37288344]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [True, False, False, False, True, False]
State prediction error at timestep 48 is 0.012
Current timestep = 49. State = [[-0.26483527  0.02033721]]. Action = [[ 0.04538212  0.03099369 -0.08087294  0.8847685 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [True, False, False, False, True, False]
State prediction error at timestep 49 is 0.012
Current timestep = 50. State = [[-0.26487896  0.02114604]]. Action = [[-0.03130955 -0.08020533 -0.04806885 -0.02700591]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [True, False, False, False, True, False]
State prediction error at timestep 50 is 0.012
Current timestep = 51. State = [[-0.26476613  0.02097693]]. Action = [[ 0.08275392  0.09060951 -0.01434544  0.1242373 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 51 is [True, False, False, False, True, False]
State prediction error at timestep 51 is 0.012
Current timestep = 52. State = [[-0.26375192  0.0217218 ]]. Action = [[ 0.07275843 -0.08305749  0.07526415  0.5712166 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 52 is [True, False, False, False, True, False]
State prediction error at timestep 52 is 0.012
Current timestep = 53. State = [[-0.26158267  0.02169313]]. Action = [[-0.04576635 -0.02269816 -0.0494803  -0.8974389 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 53 is [True, False, False, False, True, False]
State prediction error at timestep 53 is 0.012
Current timestep = 54. State = [[-0.26020038  0.0214929 ]]. Action = [[-0.04895029 -0.08923292  0.08332331  0.16367233]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 54 is [True, False, False, False, True, False]
State prediction error at timestep 54 is 0.012
Current timestep = 55. State = [[-0.2599022   0.01940075]]. Action = [[-0.03475114 -0.07091607 -0.03284355  0.7207265 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 55 is [True, False, False, False, True, False]
State prediction error at timestep 55 is 0.012
Current timestep = 56. State = [[-0.25995177  0.01678913]]. Action = [[ 0.02381404  0.04445919 -0.05927184  0.91396666]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 56 is [True, False, False, False, True, False]
State prediction error at timestep 56 is 0.012
Current timestep = 57. State = [[-0.26007617  0.01569862]]. Action = [[ 0.09283268 -0.06270957  0.09320115 -0.27012765]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 57 is [True, False, False, False, True, False]
State prediction error at timestep 57 is 0.012
Current timestep = 58. State = [[-0.25910303  0.01397855]]. Action = [[-0.00675305 -0.07176851 -0.03619952  0.02913284]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 58 is [True, False, False, False, True, False]
State prediction error at timestep 58 is 0.012
Current timestep = 59. State = [[-0.25809428  0.01153843]]. Action = [[-0.08985103  0.09186571  0.01365498 -0.01006943]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 59 is [True, False, False, False, True, False]
State prediction error at timestep 59 is 0.012
Current timestep = 60. State = [[-0.25822553  0.01160457]]. Action = [[ 0.03257651  0.06013202 -0.01982924  0.36233544]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 60 is [True, False, False, False, True, False]
State prediction error at timestep 60 is 0.012
Current timestep = 61. State = [[-0.25829533  0.01214238]]. Action = [[ 0.08748408 -0.0035544   0.04789095  0.6086904 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 61 is [True, False, False, False, True, False]
State prediction error at timestep 61 is 0.012
Current timestep = 62. State = [[-0.2577455   0.01205485]]. Action = [[-0.0061772  -0.06493673 -0.0312747  -0.59949154]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 62 is [True, False, False, False, True, False]
State prediction error at timestep 62 is 0.012
Current timestep = 63. State = [[-0.257214    0.01178444]]. Action = [[ 0.03622233  0.06289604  0.06601017 -0.9037737 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 63 is [True, False, False, False, True, False]
State prediction error at timestep 63 is 0.012
Current timestep = 64. State = [[-0.25650942  0.01224456]]. Action = [[-0.0444268   0.00884514 -0.09802714 -0.55001134]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 64 is [True, False, False, False, True, False]
State prediction error at timestep 64 is 0.012
Current timestep = 65. State = [[-0.2565531   0.01244908]]. Action = [[-0.07457881  0.00533535  0.06909239 -0.73126566]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 65 is [True, False, False, False, True, False]
State prediction error at timestep 65 is 0.012
Current timestep = 66. State = [[-0.25666016  0.01266641]]. Action = [[ 0.02870005 -0.06568596 -0.09837475 -0.78596085]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 66 is [True, False, False, False, True, False]
State prediction error at timestep 66 is 0.012
Current timestep = 67. State = [[-0.2565536   0.01224844]]. Action = [[ 0.09941655 -0.03260429  0.0816211   0.7270007 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 67 is [True, False, False, False, True, False]
State prediction error at timestep 67 is 0.012
Current timestep = 68. State = [[-0.25538298  0.01177286]]. Action = [[0.0126427  0.08787294 0.07834474 0.43771553]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 68 is [True, False, False, False, True, False]
State prediction error at timestep 68 is 0.012
Current timestep = 69. State = [[-0.25450826  0.01224046]]. Action = [[-0.08297069 -0.05488757  0.05622382  0.3013432 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 69 is [True, False, False, False, True, False]
State prediction error at timestep 69 is 0.012
Current timestep = 70. State = [[-0.25456005  0.01206434]]. Action = [[-0.01454542 -0.02396128 -0.07411633  0.02888215]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 70 is [True, False, False, False, True, False]
State prediction error at timestep 70 is 0.012
Current timestep = 71. State = [[-0.25468153  0.01149004]]. Action = [[ 0.00488553 -0.00518494  0.036042   -0.54344183]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 71 is [True, False, False, False, True, False]
State prediction error at timestep 71 is 0.012
Current timestep = 72. State = [[-0.25478855  0.01086381]]. Action = [[-0.06774455 -0.02733359 -0.00795063  0.9019809 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 72 is [True, False, False, False, True, False]
State prediction error at timestep 72 is 0.012
Current timestep = 73. State = [[-0.25497314  0.00989436]]. Action = [[ 0.01881512  0.09733189  0.04219944 -0.14095664]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 73 is [True, False, False, False, True, False]
State prediction error at timestep 73 is 0.012
Current timestep = 74. State = [[-0.25511214  0.0106488 ]]. Action = [[-0.01836509 -0.0853783   0.02358713 -0.5593137 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 74 is [True, False, False, False, True, False]
State prediction error at timestep 74 is 0.012
Current timestep = 75. State = [[-0.25518653  0.00958276]]. Action = [[-0.04543436 -0.07269826  0.09658947 -0.39439988]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 75 is [True, False, False, False, True, False]
State prediction error at timestep 75 is 0.012
Current timestep = 76. State = [[-0.2552505   0.00735555]]. Action = [[-3.7618410e-02  1.8163025e-04 -4.0399708e-02  7.1356511e-01]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 76 is [True, False, False, False, True, False]
State prediction error at timestep 76 is 0.012
Current timestep = 77. State = [[-0.256034   0.0054908]]. Action = [[-0.01348653 -0.07660855 -0.0293747  -0.311545  ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 77 is [True, False, False, False, True, False]
State prediction error at timestep 77 is 0.012
Current timestep = 78. State = [[-0.2565243   0.00303354]]. Action = [[ 0.0088176  -0.09705828  0.04007175  0.51455307]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 78 is [True, False, False, False, True, False]
State prediction error at timestep 78 is 0.012
Current timestep = 79. State = [[-0.25707555 -0.00087624]]. Action = [[-0.08410595 -0.05526781 -0.08487031 -0.64967614]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 79 is [True, False, False, False, True, False]
State prediction error at timestep 79 is 0.012
Current timestep = 80. State = [[-0.25871733 -0.00496168]]. Action = [[-0.00273821 -0.06441283 -0.0241676  -0.23225856]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 80 is [True, False, False, False, True, False]
State prediction error at timestep 80 is 0.012
Current timestep = 81. State = [[-0.25992635 -0.00950789]]. Action = [[ 0.0523889  -0.02938996 -0.06605877 -0.47577   ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 81 is [True, False, False, False, True, False]
State prediction error at timestep 81 is 0.012
Current timestep = 82. State = [[-0.26031426 -0.01255799]]. Action = [[-0.08084679  0.09289929 -0.05120718 -0.83660877]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 82 is [True, False, False, False, True, False]
State prediction error at timestep 82 is 0.012
Current timestep = 83. State = [[-0.2615992 -0.0130961]]. Action = [[ 0.09557936  0.0084514   0.03005014 -0.7967107 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 83 is [True, False, False, False, True, False]
State prediction error at timestep 83 is 0.012
Current timestep = 84. State = [[-0.26155907 -0.01316044]]. Action = [[ 1.0477938e-02 -7.7143312e-04 -8.6157724e-02 -9.0358460e-01]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 84 is [True, False, False, False, True, False]
State prediction error at timestep 84 is 0.012
Current timestep = 85. State = [[-0.2614273 -0.0133554]]. Action = [[ 0.03765007  0.03227519 -0.03392147 -0.30874026]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 85 is [True, False, False, False, True, False]
State prediction error at timestep 85 is 0.012
Current timestep = 86. State = [[-0.26132065 -0.0133311 ]]. Action = [[-0.01675708 -0.05415622  0.066994   -0.28540534]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 86 is [True, False, False, False, True, False]
State prediction error at timestep 86 is 0.012
Current timestep = 87. State = [[-0.26132372 -0.01364735]]. Action = [[-0.05287606 -0.01641592  0.01526015 -0.12867564]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 87 is [True, False, False, False, True, False]
State prediction error at timestep 87 is 0.012
Current timestep = 88. State = [[-0.26150593 -0.01459331]]. Action = [[-0.00321083 -0.00711001 -0.05035846  0.3568728 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 88 is [True, False, False, False, True, False]
State prediction error at timestep 88 is 0.012
Current timestep = 89. State = [[-0.2616989  -0.01533229]]. Action = [[-5.0467383e-02 -9.0453409e-02  3.1928718e-04  9.8299289e-01]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 89 is [True, False, False, False, True, False]
State prediction error at timestep 89 is 0.012
Current timestep = 90. State = [[-0.26229873 -0.01772207]]. Action = [[-0.06923585  0.08169415 -0.01754173  0.30456305]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 90 is [True, False, False, False, True, False]
State prediction error at timestep 90 is 0.012
Current timestep = 91. State = [[-0.26345372 -0.01787663]]. Action = [[-0.0972987   0.05307455 -0.09755058 -0.79303753]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 91 is [True, False, False, False, True, False]
State prediction error at timestep 91 is 0.012
Current timestep = 92. State = [[-0.26589793 -0.01692819]]. Action = [[ 0.02130534 -0.06689826  0.01533963 -0.19529057]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 92 is [True, False, False, False, True, False]
State prediction error at timestep 92 is 0.012
Current timestep = 93. State = [[-0.26704466 -0.01771868]]. Action = [[ 0.0036811   0.06034426 -0.0312944   0.37502968]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 93 is [True, False, False, False, True, False]
State prediction error at timestep 93 is 0.012
Current timestep = 94. State = [[-0.26771694 -0.01717266]]. Action = [[0.03166024 0.00575425 0.01886453 0.10213578]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 94 is [True, False, False, False, True, False]
State prediction error at timestep 94 is 0.012
Current timestep = 95. State = [[-0.26794648 -0.01676314]]. Action = [[-0.02989867  0.04017638 -0.06231183 -0.81921107]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 95 is [True, False, False, False, True, False]
State prediction error at timestep 95 is 0.012
Current timestep = 96. State = [[-0.26878437 -0.01559284]]. Action = [[-0.00971439  0.0301424  -0.07408705 -0.04370892]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 96 is [True, False, False, False, True, False]
State prediction error at timestep 96 is 0.012
Current timestep = 97. State = [[-0.2696287 -0.0140344]]. Action = [[ 0.0807774   0.04114463  0.08333304 -0.6593675 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 97 is [True, False, False, False, True, False]
State prediction error at timestep 97 is 0.012
Current timestep = 98. State = [[-0.2699783  -0.01254754]]. Action = [[-0.03965494  0.01769154  0.01191881  0.92147255]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 98 is [True, False, False, False, True, False]
State prediction error at timestep 98 is 0.012
Current timestep = 99. State = [[-0.27055064 -0.01090619]]. Action = [[-0.03942654  0.02698264 -0.08467113 -0.16999316]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 99 is [True, False, False, False, True, False]
State prediction error at timestep 99 is 0.012
Current timestep = 100. State = [[-0.27111933 -0.00916918]]. Action = [[-0.06031826 -0.08776253 -0.00947938  0.11940181]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 100 is [True, False, False, False, True, False]
State prediction error at timestep 100 is 0.012
Current timestep = 101. State = [[-0.27199996 -0.00969546]]. Action = [[-0.09161872 -0.01099446  0.04641641  0.28773856]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 101 is [True, False, False, False, True, False]
State prediction error at timestep 101 is 0.012
Current timestep = 102. State = [[-0.27426195 -0.01001122]]. Action = [[0.03710111 0.04353496 0.02696779 0.2768674 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 102 is [True, False, False, False, True, False]
State prediction error at timestep 102 is 0.012
Current timestep = 103. State = [[-0.27543262 -0.00953793]]. Action = [[ 0.08918381 -0.00831923 -0.08352672 -0.28873467]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 103 is [True, False, False, False, True, False]
State prediction error at timestep 103 is 0.012
Current timestep = 104. State = [[-0.27533808 -0.00964239]]. Action = [[-0.04273349 -0.04148028  0.08754414 -0.7239744 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 104 is [True, False, False, False, True, False]
State prediction error at timestep 104 is 0.012
Current timestep = 105. State = [[-0.27543747 -0.00999776]]. Action = [[-0.01482176 -0.03528193 -0.02799021 -0.9768368 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 105 is [True, False, False, False, True, False]
State prediction error at timestep 105 is 0.012
Current timestep = 106. State = [[-0.2759102  -0.01091332]]. Action = [[ 0.08357575 -0.01348406  0.08208784 -0.11461991]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 106 is [True, False, False, False, True, False]
State prediction error at timestep 106 is 0.012
Current timestep = 107. State = [[-0.27584252 -0.01137453]]. Action = [[-0.01091077 -0.00968432  0.08984665 -0.08456141]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 107 is [True, False, False, False, True, False]
State prediction error at timestep 107 is 0.012
Current timestep = 108. State = [[-0.2759338  -0.01203295]]. Action = [[-0.01592769 -0.02231164 -0.00850479 -0.52216256]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 108 is [True, False, False, False, True, False]
State prediction error at timestep 108 is 0.012
Current timestep = 109. State = [[-0.2760938  -0.01269295]]. Action = [[ 0.058874    0.04144724 -0.0447047  -0.8177222 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 109 is [True, False, False, False, True, False]
State prediction error at timestep 109 is 0.012
Current timestep = 110. State = [[-0.27606165 -0.01256839]]. Action = [[ 0.08087202  0.00300796  0.06354868 -0.9461646 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 110 is [True, False, False, False, True, False]
State prediction error at timestep 110 is 0.012
Current timestep = 111. State = [[-0.27536184 -0.01240805]]. Action = [[ 0.08202185  0.07949492 -0.05382702  0.9906614 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 111 is [True, False, False, False, True, False]
State prediction error at timestep 111 is 0.012
Current timestep = 112. State = [[-0.2739116 -0.0119748]]. Action = [[ 0.08528724 -0.01235012  0.06995175 -0.96350336]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 112 is [True, False, False, False, True, False]
State prediction error at timestep 112 is 0.012
Current timestep = 113. State = [[-0.27147734 -0.01135658]]. Action = [[-0.07417892  0.0336945   0.06228643  0.84478045]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 113 is [True, False, False, False, True, False]
State prediction error at timestep 113 is 0.012
Current timestep = 114. State = [[-0.27090585 -0.01061137]]. Action = [[ 0.06916561  0.0973826  -0.03375982  0.2454791 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 114 is [True, False, False, False, True, False]
State prediction error at timestep 114 is 0.012
Current timestep = 115. State = [[-0.26977184 -0.00776828]]. Action = [[-0.01158882  0.08103619  0.08105295 -0.38037252]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 115 is [True, False, False, False, True, False]
State prediction error at timestep 115 is 0.012
Current timestep = 116. State = [[-0.26952246 -0.00489508]]. Action = [[ 0.03212031 -0.03029605 -0.07179489  0.67524683]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 116 is [True, False, False, False, True, False]
State prediction error at timestep 116 is 0.012
Current timestep = 117. State = [[-0.26867533 -0.00345445]]. Action = [[0.05970105 0.08509628 0.01517849 0.4118315 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 117 is [True, False, False, False, True, False]
State prediction error at timestep 117 is 0.012
Current timestep = 118. State = [[-0.26711765 -0.00074899]]. Action = [[-0.00548008  0.03136968  0.09019355  0.8506783 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 118 is [True, False, False, False, True, False]
State prediction error at timestep 118 is 0.012
Current timestep = 119. State = [[-0.2659281   0.00188497]]. Action = [[ 0.07496005  0.0512901   0.06044472 -0.5467224 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 119 is [True, False, False, False, True, False]
State prediction error at timestep 119 is 0.012
Current timestep = 120. State = [[-0.2637259   0.00472278]]. Action = [[ 0.01337998 -0.0130128  -0.07320319 -0.27900124]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 120 is [True, False, False, False, True, False]
State prediction error at timestep 120 is 0.012
Current timestep = 121. State = [[-0.26158723  0.00639386]]. Action = [[-0.07190643  0.06262528  0.08503192 -0.14114434]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 121 is [True, False, False, False, True, False]
State prediction error at timestep 121 is 0.012
Current timestep = 122. State = [[-0.26081088  0.00940752]]. Action = [[ 0.08701735 -0.01347913 -0.01041719  0.5711534 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 122 is [True, False, False, False, True, False]
State prediction error at timestep 122 is 0.012
Current timestep = 123. State = [[-0.25891885  0.01065286]]. Action = [[-0.01879687 -0.03573602  0.01343177  0.10692334]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 123 is [True, False, False, False, True, False]
State prediction error at timestep 123 is 0.012
Current timestep = 124. State = [[-0.2569794   0.01092728]]. Action = [[ 0.01601466 -0.02323282  0.05927012  0.21763086]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 124 is [True, False, False, False, True, False]
State prediction error at timestep 124 is 0.012
Current timestep = 125. State = [[-0.25541413  0.01104949]]. Action = [[-0.07914612  0.01010527 -0.01630551 -0.05132365]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 125 is [True, False, False, False, True, False]
State prediction error at timestep 125 is 0.012
Current timestep = 126. State = [[-0.25554448  0.01154974]]. Action = [[ 0.06825583 -0.00703262  0.04944303 -0.04624939]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 126 is [True, False, False, False, True, False]
State prediction error at timestep 126 is 0.012
Current timestep = 127. State = [[-0.255249    0.01159279]]. Action = [[-0.04754002  0.00680681 -0.01599861  0.01879144]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 127 is [True, False, False, False, True, False]
State prediction error at timestep 127 is 0.012
Current timestep = 128. State = [[-0.25532928  0.01154296]]. Action = [[-0.09623236  0.02034541 -0.01810242  0.18736851]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 128 is [True, False, False, False, True, False]
State prediction error at timestep 128 is 0.012
