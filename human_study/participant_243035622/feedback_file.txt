Current timestep = 0. State = [[-0.3270049  -0.09084156]]. Action = [[-0.02517132 -0.00313229  0.         -0.03610903]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is None
Current timestep = 1. State = [[-0.3284511  -0.08900083]]. Action = [[ 0.01121883  0.03684529  0.         -0.24135602]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False]
State prediction error at timestep 1 is 0.012
Human Feedback received at timestep 1 of None
Current timestep = 2. State = [[-0.3323186  -0.08544317]]. Action = [[-0.06113325  0.04126974  0.          0.97395396]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, True, False]
Current timestep = 3. State = [[-0.3383631  -0.08004148]]. Action = [[-0.06263261  0.07551753  0.         -0.21903908]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, True, False]
State prediction error at timestep 3 is 0.012
Human Feedback received at timestep 3 of None
Current timestep = 4. State = [[-0.3429387  -0.08150396]]. Action = [[-0.02606332 -0.08540395  0.          0.91687274]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, True, False]
Current timestep = 5. State = [[-0.3490021  -0.07965203]]. Action = [[-0.07761858  0.08164795  0.         -0.8448607 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, True, False]
Current timestep = 6. State = [[-0.34893882 -0.07850175]]. Action = [[ 0.09810986 -0.04243719  0.         -0.2252906 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, True, False]
Current timestep = 7. State = [[-0.3492724  -0.07514054]]. Action = [[-0.05269296  0.07933923  0.          0.7123525 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, True, False]
State prediction error at timestep 7 is 0.012
Human Feedback received at timestep 7 of None
Current timestep = 8. State = [[-0.34811005 -0.06969579]]. Action = [[ 0.0754961   0.04299169  0.         -0.08161724]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, True, False]
Current timestep = 9. State = [[-0.35013327 -0.07000023]]. Action = [[-0.07022719 -0.05783322  0.          0.24431825]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, True, False]
State prediction error at timestep 9 is 0.012
Human Feedback received at timestep 9 of None
Current timestep = 10. State = [[-0.34971988 -0.0753062 ]]. Action = [[ 0.06681105 -0.08201386  0.         -0.67114556]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, True, False]
State prediction error at timestep 10 is 0.012
Human Feedback received at timestep 10 of None
Current timestep = 11. State = [[-0.34873503 -0.08106681]]. Action = [[-0.00926805 -0.06453748  0.         -0.9684069 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, True, False]
Current timestep = 12. State = [[-0.34941414 -0.08864632]]. Action = [[-0.00988554 -0.09839112  0.         -0.614913  ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, True, False]
State prediction error at timestep 12 is 0.012
Human Feedback received at timestep 12 of None
Current timestep = 13. State = [[-0.3451792  -0.09532307]]. Action = [[ 0.09057599 -0.05426887  0.          0.24568582]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, True, False]
State prediction error at timestep 13 is 0.012
Human Feedback received at timestep 13 of None
Current timestep = 14. State = [[-0.33860153 -0.09723782]]. Action = [[ 0.07226252  0.01412418  0.         -0.4160719 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, True, False]
Current timestep = 15. State = [[-0.33855936 -0.10063896]]. Action = [[-0.05909092 -0.05171558  0.          0.7692232 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, True, False]
Current timestep = 16. State = [[-0.3438158 -0.1003454]]. Action = [[-0.08847439  0.07359082  0.          0.7894316 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, True, False]
State prediction error at timestep 16 is 0.012
Human Feedback received at timestep 16 of None
Current timestep = 17. State = [[-0.3458716  -0.09542044]]. Action = [[ 0.00787131  0.08607116  0.         -0.33679414]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, True, False]
Current timestep = 18. State = [[-0.34760857 -0.08906771]]. Action = [[-0.03301679  0.08093991  0.         -0.731575  ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, True, False]
Current timestep = 19. State = [[-0.3488182  -0.08823722]]. Action = [[ 0.00312903 -0.03759826  0.         -0.25821555]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, True, False]
State prediction error at timestep 19 is 0.012
Human Feedback received at timestep 19 of None
Current timestep = 20. State = [[-0.34626248 -0.08579159]]. Action = [[0.0632496  0.05764089 0.         0.49787724]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, True, False]
Current timestep = 21. State = [[-0.342236   -0.08267199]]. Action = [[0.05672931 0.00467298 0.         0.501621  ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, True, False]
Current timestep = 22. State = [[-0.33771208 -0.07604022]]. Action = [[ 0.06753404  0.09819474  0.         -0.9514527 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [True, False, False, False, True, False]
Current timestep = 23. State = [[-0.33737254 -0.06802481]]. Action = [[-0.02280841  0.06887992  0.          0.03624845]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [True, False, False, False, True, False]
State prediction error at timestep 23 is 0.012
Human Feedback received at timestep 23 of None
Current timestep = 24. State = [[-0.33695143 -0.05916549]]. Action = [[ 0.03349089  0.09955809  0.         -0.682824  ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [True, False, False, False, True, False]
Current timestep = 25. State = [[-0.33869988 -0.05770453]]. Action = [[-0.0462237  -0.08078437  0.          0.63734305]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [True, False, False, False, True, False]
Current timestep = 26. State = [[-0.3381048  -0.05767744]]. Action = [[ 0.04534339  0.01859118  0.         -0.01341397]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [True, False, False, False, True, False]
State prediction error at timestep 26 is 0.012
Human Feedback received at timestep 26 of None
Current timestep = 27. State = [[-0.33955047 -0.05927359]]. Action = [[-0.05272523 -0.06325215  0.         -0.01878482]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [True, False, False, False, True, False]
State prediction error at timestep 27 is 0.012
Human Feedback received at timestep 27 of None
Current timestep = 28. State = [[-0.3442493  -0.05989646]]. Action = [[-0.07307081  0.01494579  0.         -0.91120285]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [True, False, False, False, True, False]
Current timestep = 29. State = [[-0.34387147 -0.05626411]]. Action = [[ 0.05071848  0.05536649  0.         -0.4208697 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [True, False, False, False, True, False]
Current timestep = 30. State = [[-0.34318334 -0.05048785]]. Action = [[-0.01370352  0.06336819  0.         -0.95380545]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [True, False, False, False, True, False]
Current timestep = 31. State = [[-0.3446865  -0.04688857]]. Action = [[-0.02395083  0.01285665  0.          0.84736323]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [True, False, False, False, True, False]
Current timestep = 32. State = [[-0.34537023 -0.04917354]]. Action = [[ 4.3716282e-04 -7.0835866e-02  0.0000000e+00 -4.9097490e-01]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [True, False, False, False, True, False]
Current timestep = 33. State = [[-0.3490955 -0.0550513]]. Action = [[-0.07968862 -0.07912775  0.         -0.9374181 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [True, False, False, False, True, False]
Current timestep = 34. State = [[-0.35011888 -0.0571089 ]]. Action = [[0.0229729  0.01553579 0.         0.09854746]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [True, False, False, False, True, False]
Current timestep = 35. State = [[-0.35075063 -0.05881244]]. Action = [[-0.02379552 -0.03595639  0.          0.6699455 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [True, False, False, False, True, False]
Current timestep = 36. State = [[-0.34704706 -0.06053897]]. Action = [[ 0.09312334 -0.00839349  0.          0.02484822]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [True, False, False, False, True, False]
Current timestep = 37. State = [[-0.34123677 -0.0633743 ]]. Action = [[ 0.0663007  -0.04746206  0.          0.314659  ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [True, False, False, False, True, False]
Current timestep = 38. State = [[-0.34045175 -0.06886414]]. Action = [[-0.03301517 -0.06903735  0.         -0.56067777]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [True, False, False, False, True, False]
Current timestep = 39. State = [[-0.3418825  -0.07414134]]. Action = [[-0.02143808 -0.03881108  0.          0.5556381 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [True, False, False, False, True, False]
Current timestep = 40. State = [[-0.34645125 -0.0722801 ]]. Action = [[-0.09060122  0.09276371  0.          0.32077074]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [True, False, False, False, True, False]
Current timestep = 41. State = [[-0.34738398 -0.07240871]]. Action = [[ 0.04349054 -0.03881253  0.         -0.17703742]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [True, False, False, False, True, False]
State prediction error at timestep 41 is 0.012
Human Feedback received at timestep 41 of None
Current timestep = 42. State = [[-0.34785113 -0.07390076]]. Action = [[-0.03742965  0.00716915  0.          0.46081853]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [True, False, False, False, True, False]
State prediction error at timestep 42 is 0.012
Human Feedback received at timestep 42 of None
Current timestep = 43. State = [[-0.34558818 -0.07153713]]. Action = [[ 0.06237604  0.05458137  0.         -0.7390872 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [True, False, False, False, True, False]
Current timestep = 44. State = [[-0.34431395 -0.06599911]]. Action = [[-0.00907054  0.07323664  0.         -0.0730992 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [True, False, False, False, True, False]
State prediction error at timestep 44 is 0.012
Human Feedback received at timestep 44 of None
Current timestep = 45. State = [[-0.34240717 -0.06398208]]. Action = [[ 0.04537082 -0.01607694  0.         -0.51758724]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [True, False, False, False, True, False]
State prediction error at timestep 45 is 0.012
Human Feedback received at timestep 45 of None
Current timestep = 46. State = [[-0.33944783 -0.06147002]]. Action = [[0.03811892 0.04228497 0.         0.02757192]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [True, False, False, False, True, False]
State prediction error at timestep 46 is 0.012
Human Feedback received at timestep 46 of None
Current timestep = 47. State = [[-0.33906823 -0.06076062]]. Action = [[-0.01317835 -0.02618026  0.          0.755185  ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [True, False, False, False, True, False]
Current timestep = 48. State = [[-0.34161144 -0.0599232 ]]. Action = [[-0.04631549  0.02226819  0.          0.37288344]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [True, False, False, False, True, False]
Current timestep = 49. State = [[-0.34073713 -0.05722469]]. Action = [[0.04538212 0.03099369 0.         0.8847685 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [True, False, False, False, True, False]
Current timestep = 50. State = [[-0.3410031  -0.05961129]]. Action = [[-0.03130955 -0.08020533  0.         -0.02700591]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [True, False, False, False, True, False]
Current timestep = 51. State = [[-0.33802786 -0.05763282]]. Action = [[0.08275392 0.09060951 0.         0.1242373 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 51 is [True, False, False, False, True, False]
State prediction error at timestep 51 is 0.012
Human Feedback received at timestep 51 of None
Current timestep = 52. State = [[-0.33209655 -0.05824121]]. Action = [[ 0.07275843 -0.08305749  0.          0.5712166 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 52 is [True, False, False, False, True, False]
Current timestep = 53. State = [[-0.33138907 -0.06134968]]. Action = [[-0.04576635 -0.02269816  0.         -0.8974389 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 53 is [True, False, False, False, True, False]
Current timestep = 54. State = [[-0.334476   -0.06685781]]. Action = [[-0.04895029 -0.08923292  0.          0.16367233]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 54 is [True, False, False, False, True, False]
Current timestep = 55. State = [[-0.3370901  -0.07392347]]. Action = [[-0.03475114 -0.07091607  0.          0.7207265 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 55 is [True, False, False, False, True, False]
Current timestep = 56. State = [[-0.33656964 -0.07507531]]. Action = [[0.02381404 0.04445919 0.         0.91396666]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 56 is [True, False, False, False, True, False]
State prediction error at timestep 56 is 0.012
Human Feedback received at timestep 56 of None
Current timestep = 57. State = [[-0.33120745 -0.07767337]]. Action = [[ 0.09283268 -0.06270957  0.         -0.27012765]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 57 is [True, False, False, False, True, False]
Current timestep = 58. State = [[-0.32833883 -0.08389764]]. Action = [[-0.00675305 -0.07176851  0.          0.02913284]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 58 is [True, False, False, False, True, False]
State prediction error at timestep 58 is 0.012
Human Feedback received at timestep 58 of None
Current timestep = 59. State = [[-0.3318823  -0.08305091]]. Action = [[-0.08985103  0.09186571  0.         -0.01006943]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 59 is [True, False, False, False, True, False]
Current timestep = 60. State = [[-0.33297646 -0.07838884]]. Action = [[0.03257651 0.06013202 0.         0.36233544]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 60 is [True, False, False, False, True, False]
Current timestep = 61. State = [[-0.32820085 -0.07664732]]. Action = [[ 0.08748408 -0.0035544   0.          0.6086904 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 61 is [True, False, False, False, True, False]
Current timestep = 62. State = [[-0.32613924 -0.07976142]]. Action = [[-0.0061772  -0.06493673  0.         -0.59949154]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 62 is [True, False, False, False, True, False]
Current timestep = 63. State = [[-0.3243946  -0.07876316]]. Action = [[ 0.03622233  0.06289604  0.         -0.9037737 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 63 is [True, False, False, False, True, False]
Current timestep = 64. State = [[-0.3255149  -0.07654376]]. Action = [[-0.0444268   0.00884514  0.         -0.55001134]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 64 is [True, False, False, False, True, False]
Current timestep = 65. State = [[-0.33025914 -0.07610568]]. Action = [[-0.07457881  0.00533535  0.         -0.73126566]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 65 is [True, False, False, False, True, False]
Current timestep = 66. State = [[-0.33115077 -0.07938772]]. Action = [[ 0.02870005 -0.06568596  0.         -0.78596085]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 66 is [True, False, False, False, True, False]
State prediction error at timestep 66 is 0.012
Human Feedback received at timestep 66 of None
Current timestep = 67. State = [[-0.32550073 -0.08299406]]. Action = [[ 0.09941655 -0.03260429  0.          0.7270007 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 67 is [True, False, False, False, True, False]
State prediction error at timestep 67 is 0.012
Human Feedback received at timestep 67 of None
Current timestep = 68. State = [[-0.3216882 -0.0795166]]. Action = [[0.0126427  0.08787294 0.         0.43771553]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 68 is [True, False, False, False, True, False]
Current timestep = 69. State = [[-0.324924 -0.079347]]. Action = [[-0.08297069 -0.05488757  0.          0.3013432 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 69 is [True, False, False, False, True, False]
Current timestep = 70. State = [[-0.32778  -0.082482]]. Action = [[-0.01454542 -0.02396128  0.          0.02888215]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 70 is [True, False, False, False, True, False]
State prediction error at timestep 70 is 0.012
Human Feedback received at timestep 70 of None
Current timestep = 71. State = [[-0.3279824  -0.08397991]]. Action = [[ 0.00488553 -0.00518494  0.         -0.54344183]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 71 is [True, False, False, False, True, False]
Current timestep = 72. State = [[-0.33110738 -0.08600672]]. Action = [[-0.06774455 -0.02733359  0.          0.9019809 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 72 is [True, False, False, False, True, False]
Current timestep = 73. State = [[-0.33222526 -0.08249398]]. Action = [[ 0.01881512  0.09733189  0.         -0.14095664]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 73 is [True, False, False, False, True, False]
Current timestep = 74. State = [[-0.33280078 -0.08355485]]. Action = [[-0.01836509 -0.0853783   0.         -0.5593137 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 74 is [True, False, False, False, True, False]
Current timestep = 75. State = [[-0.33577377 -0.089941  ]]. Action = [[-0.04543436 -0.07269826  0.         -0.39439988]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 75 is [True, False, False, False, True, False]
Current timestep = 76. State = [[-0.3392199  -0.09303892]]. Action = [[-3.7618410e-02  1.8163025e-04  0.0000000e+00  7.1356511e-01]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 76 is [True, False, False, False, True, False]
Current timestep = 77. State = [[-0.3414189  -0.09785232]]. Action = [[-0.01348653 -0.07660855  0.         -0.311545  ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 77 is [True, False, False, False, True, False]
Current timestep = 78. State = [[-0.3419085  -0.10598537]]. Action = [[ 0.0088176  -0.09705828  0.          0.51455307]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 78 is [True, False, False, False, True, False]
Current timestep = 79. State = [[-0.34617656 -0.1131292 ]]. Action = [[-0.08410595 -0.05526781  0.         -0.64967614]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 79 is [True, False, False, False, True, False]
State prediction error at timestep 79 is 0.012
Human Feedback received at timestep 79 of None
Current timestep = 80. State = [[-0.3493777  -0.11977927]]. Action = [[-0.00273821 -0.06441283  0.         -0.23225856]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 80 is [True, False, False, False, True, False]
Current timestep = 81. State = [[-0.34769306 -0.12471276]]. Action = [[ 0.0523889  -0.02938996  0.         -0.47577   ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 81 is [True, False, False, False, True, False]
Current timestep = 82. State = [[-0.3502639  -0.12274865]]. Action = [[-0.08084679  0.09289929  0.         -0.83660877]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 82 is [True, False, False, False, True, False]
Current timestep = 83. State = [[-0.3496516  -0.11991539]]. Action = [[ 0.09557936  0.0084514   0.         -0.7967107 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 83 is [True, False, False, False, True, False]
Current timestep = 84. State = [[-0.34718603 -0.11969393]]. Action = [[ 1.0477938e-02 -7.7143312e-04  0.0000000e+00 -9.0358460e-01]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 84 is [True, False, False, False, True, False]
Current timestep = 85. State = [[-0.34530267 -0.11827753]]. Action = [[ 0.03765007  0.03227519  0.         -0.30874026]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 85 is [True, False, False, False, True, False]
State prediction error at timestep 85 is 0.012
Human Feedback received at timestep 85 of None
Current timestep = 86. State = [[-0.3454343 -0.120103 ]]. Action = [[-0.01675708 -0.05415622  0.         -0.28540534]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 86 is [True, False, False, False, True, False]
Current timestep = 87. State = [[-0.34890392 -0.12305215]]. Action = [[-0.05287606 -0.01641592  0.         -0.12867564]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 87 is [True, False, False, False, True, False]
Current timestep = 88. State = [[-0.35100242 -0.12475462]]. Action = [[-0.00321083 -0.00711001  0.          0.3568728 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 88 is [True, False, False, False, True, False]
State prediction error at timestep 88 is 0.012
Human Feedback received at timestep 88 of None
Current timestep = 89. State = [[-0.35404032 -0.13023002]]. Action = [[-0.05046738 -0.09045341  0.          0.9829929 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 89 is [True, False, False, False, True, False]
State prediction error at timestep 89 is 0.012
Human Feedback received at timestep 89 of None
Current timestep = 90. State = [[-0.35926694 -0.1299755 ]]. Action = [[-0.06923585  0.08169415  0.          0.30456305]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 90 is [True, False, False, True, False, False]
State prediction error at timestep 90 is 0.012
Human Feedback received at timestep 90 of None
Current timestep = 91. State = [[-0.36676252 -0.12599865]]. Action = [[-0.0972987   0.05307455  0.         -0.79303753]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 91 is [True, False, False, True, False, False]
Current timestep = 92. State = [[-0.37007698 -0.1277802 ]]. Action = [[ 0.02130534 -0.06689826  0.         -0.19529057]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 92 is [True, False, False, True, False, False]
Current timestep = 93. State = [[-0.37006626 -0.12681435]]. Action = [[0.0036811  0.06034426 0.         0.37502968]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 93 is [True, False, False, True, False, False]
Current timestep = 94. State = [[-0.3686967 -0.1245316]]. Action = [[0.03166024 0.00575425 0.         0.10213578]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 94 is [True, False, False, True, False, False]
State prediction error at timestep 94 is 0.012
Human Feedback received at timestep 94 of None
Current timestep = 95. State = [[-0.36961532 -0.12174302]]. Action = [[-0.02989867  0.04017638  0.         -0.81921107]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 95 is [True, False, False, False, True, False]
Current timestep = 96. State = [[-0.3714131  -0.11859533]]. Action = [[-0.00971439  0.0301424   0.         -0.04370892]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 96 is [True, False, False, False, True, False]
Current timestep = 97. State = [[-0.36826617 -0.11461917]]. Action = [[ 0.0807774   0.04114463  0.         -0.6593675 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 97 is [True, False, False, False, True, False]
Current timestep = 98. State = [[-0.3682648  -0.11114176]]. Action = [[-0.03965494  0.01769154  0.          0.92147255]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 98 is [True, False, False, False, True, False]
Current timestep = 99. State = [[-0.37182084 -0.10839062]]. Action = [[-0.03942654  0.02698264  0.         -0.16999316]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 99 is [True, False, False, False, True, False]
Current timestep = 100. State = [[-0.3737007  -0.10682634]]. Action = [[0.         0.         0.         0.11940181]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 100 is [True, False, False, False, True, False]
State prediction error at timestep 100 is 0.012
Human Feedback received at timestep 100 of None
Current timestep = 101. State = [[-0.37439188 -0.10590777]]. Action = [[0.         0.         0.         0.28773856]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 101 is [True, False, False, False, True, False]
Current timestep = 102. State = [[-0.37305108 -0.10270731]]. Action = [[0.03710111 0.04353496 0.         0.2768674 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 102 is [True, False, False, False, True, False]
Current timestep = 103. State = [[-0.36794305 -0.10029064]]. Action = [[ 0.08918381 -0.00831923  0.         -0.28873467]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 103 is [True, False, False, False, True, False]
Current timestep = 104. State = [[-0.36748224 -0.10127585]]. Action = [[-0.04273349 -0.04148028  0.         -0.7239744 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 104 is [True, False, False, False, True, False]
Current timestep = 105. State = [[-0.36962137 -0.10389086]]. Action = [[-0.01482176 -0.03528193  0.         -0.9768368 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 105 is [True, False, False, False, True, False]
Current timestep = 106. State = [[-0.36617258 -0.10537354]]. Action = [[ 0.08357575 -0.01348406  0.         -0.11461991]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 106 is [True, False, False, False, True, False]
State prediction error at timestep 106 is 0.012
Human Feedback received at timestep 106 of None
Current timestep = 107. State = [[-0.3641017  -0.10588992]]. Action = [[-0.01091077 -0.00968432  0.         -0.08456141]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 107 is [True, False, False, False, True, False]
Current timestep = 108. State = [[-0.3647807  -0.10744979]]. Action = [[-0.01592769 -0.02231164  0.         -0.52216256]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 108 is [True, False, False, False, True, False]
Current timestep = 109. State = [[-0.36200017 -0.10626697]]. Action = [[ 0.058874    0.04144724  0.         -0.8177222 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 109 is [True, False, False, False, True, False]
Current timestep = 110. State = [[-0.35580534 -0.10451893]]. Action = [[ 0.08087202  0.00300796  0.         -0.9461646 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 110 is [True, False, False, False, True, False]
Current timestep = 111. State = [[-0.34866193 -0.09961282]]. Action = [[0.08202185 0.07949492 0.         0.9906614 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 111 is [True, False, False, False, True, False]
Current timestep = 112. State = [[-0.34126097 -0.09682806]]. Action = [[ 0.08528724 -0.01235012  0.         -0.96350336]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 112 is [True, False, False, False, True, False]
Current timestep = 113. State = [[-0.34117305 -0.09506026]]. Action = [[-0.07417892  0.0336945   0.          0.84478045]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 113 is [True, False, False, False, True, False]
State prediction error at timestep 113 is 0.012
Human Feedback received at timestep 113 of None
Current timestep = 114. State = [[-0.3397638  -0.08869367]]. Action = [[0.06916561 0.0973826  0.         0.2454791 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 114 is [True, False, False, False, True, False]
Current timestep = 115. State = [[-0.33869064 -0.08047839]]. Action = [[-0.01158882  0.08103619  0.         -0.38037252]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 115 is [True, False, False, False, True, False]
Current timestep = 116. State = [[-0.3376005  -0.07808656]]. Action = [[ 0.03212031 -0.03029605  0.          0.67524683]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 116 is [True, False, False, False, True, False]
Current timestep = 117. State = [[-0.33387274 -0.07311687]]. Action = [[0.05970105 0.08509628 0.         0.4118315 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 117 is [True, False, False, False, True, False]
Current timestep = 118. State = [[-0.33245522 -0.06742403]]. Action = [[-0.00548008  0.03136968  0.          0.8506783 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 118 is [True, False, False, False, True, False]
Current timestep = 119. State = [[-0.32883832 -0.06211849]]. Action = [[ 0.07496005  0.0512901   0.         -0.5467224 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 119 is [True, False, False, False, True, False]
State prediction error at timestep 119 is 0.012
Human Feedback received at timestep 119 of None
Current timestep = 120. State = [[-0.32592055 -0.05939408]]. Action = [[ 0.01337998 -0.0130128   0.         -0.27900124]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 120 is [True, False, False, False, True, False]
Current timestep = 121. State = [[-0.3284565  -0.05521851]]. Action = [[-0.07190643  0.06262528  0.         -0.14114434]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 121 is [True, False, False, False, True, False]
Current timestep = 122. State = [[-0.32626262 -0.05257294]]. Action = [[ 0.08701735 -0.01347913  0.          0.5711534 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 122 is [True, False, False, False, True, False]
Current timestep = 123. State = [[-0.32382312 -0.0533673 ]]. Action = [[-0.01879687 -0.03573602  0.          0.10692334]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 123 is [True, False, False, False, True, False]
Current timestep = 124. State = [[-0.32203928 -0.05481014]]. Action = [[ 0.01601466 -0.02323282  0.          0.21763086]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 124 is [True, False, False, False, True, False]
State prediction error at timestep 124 is 0.012
Human Feedback received at timestep 124 of None
Current timestep = 125. State = [[-0.32391578 -0.05462665]]. Action = [[-0.07914612  0.01010527  0.         -0.05132365]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 125 is [True, False, False, False, True, False]
Current timestep = 126. State = [[-0.32169768 -0.05438175]]. Action = [[ 0.06825583 -0.00703262  0.         -0.04624939]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 126 is [True, False, False, False, True, False]
State prediction error at timestep 126 is 0.012
Human Feedback received at timestep 126 of None
Current timestep = 127. State = [[-0.32073015 -0.05401361]]. Action = [[-0.04754002  0.00680681  0.          0.01879144]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 127 is [True, False, False, False, True, False]
Current timestep = 128. State = [[-0.3252712  -0.05284323]]. Action = [[-0.09623236  0.02034541  0.          0.18736851]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 128 is [True, False, False, False, True, False]
Current timestep = 129. State = [[-0.33178008 -0.04842794]]. Action = [[-0.09710603  0.07774549  0.         -0.909334  ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 129 is [True, False, False, False, True, False]
Current timestep = 130. State = [[-0.33836505 -0.04988842]]. Action = [[-0.0848588  -0.08023626  0.          0.97973585]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 130 is [True, False, False, False, True, False]
Current timestep = 131. State = [[-0.34021637 -0.04807803]]. Action = [[ 0.02452739  0.08706162  0.         -0.33817333]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 131 is [True, False, False, False, True, False]
State prediction error at timestep 131 is 0.012
Human Feedback received at timestep 131 of None
Current timestep = 132. State = [[-0.34046638 -0.04849353]]. Action = [[-1.5713274e-04 -7.2476134e-02  0.0000000e+00 -9.3395925e-01]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 132 is [True, False, False, False, True, False]
Current timestep = 133. State = [[-0.34036136 -0.05365004]]. Action = [[ 0.01759513 -0.06927857  0.          0.3322369 ]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 133 is [True, False, False, False, True, False]
Current timestep = 134. State = [[-0.33654827 -0.06037531]]. Action = [[ 0.08368777 -0.08932294  0.         -0.1830532 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 134 is [True, False, False, False, True, False]
State prediction error at timestep 134 is 0.012
Human Feedback received at timestep 134 of None
Current timestep = 135. State = [[-0.3364084  -0.06236254]]. Action = [[-0.04159392  0.02638268  0.         -0.263579  ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 135 is [True, False, False, False, True, False]
Current timestep = 136. State = [[-0.33616808 -0.06324318]]. Action = [[ 0.04214465 -0.01857676  0.         -0.5455249 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 136 is [True, False, False, False, True, False]
State prediction error at timestep 136 is 0.012
Human Feedback received at timestep 136 of None
Current timestep = 137. State = [[-0.33360782 -0.06221341]]. Action = [[ 0.04537598  0.04021681  0.         -0.8251441 ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 137 is [True, False, False, False, True, False]
Current timestep = 138. State = [[-0.3333504  -0.06577211]]. Action = [[-0.00896082 -0.08648797  0.         -0.6011182 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 138 is [True, False, False, False, True, False]
Current timestep = 139. State = [[-0.33381993 -0.074048  ]]. Action = [[ 0.00144257 -0.09740138  0.          0.4732709 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 139 is [True, False, False, False, True, False]
State prediction error at timestep 139 is 0.012
Human Feedback received at timestep 139 of None
Current timestep = 140. State = [[-0.32989714 -0.07519073]]. Action = [[0.0879296  0.06759537 0.         0.75975275]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 140 is [True, False, False, False, True, False]
Current timestep = 141. State = [[-0.32558042 -0.06931984]]. Action = [[ 0.04135331  0.09023546  0.         -0.06988275]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 141 is [True, False, False, False, True, False]
Current timestep = 142. State = [[-0.3257608  -0.06314112]]. Action = [[-0.02416668  0.06962629  0.          0.17399645]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 142 is [True, False, False, False, True, False]
Current timestep = 143. State = [[-0.32485095 -0.05608462]]. Action = [[ 0.04110511  0.09079217  0.         -0.52428895]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 143 is [True, False, False, False, True, False]
Current timestep = 144. State = [[-0.3213053  -0.05278175]]. Action = [[ 0.06174278 -0.00877477  0.         -0.70893675]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 144 is [True, False, False, False, True, False]
Current timestep = 145. State = [[-0.31560606 -0.05307953]]. Action = [[ 0.08646726 -0.02543203  0.          0.4767716 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 145 is [True, False, False, False, True, False]
State prediction error at timestep 145 is 0.012
Human Feedback received at timestep 145 of None
Current timestep = 146. State = [[-0.31273177 -0.05484474]]. Action = [[ 0.00307836 -0.03747223  0.          0.24625003]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 146 is [True, False, False, False, True, False]
Current timestep = 147. State = [[-0.31539    -0.05461533]]. Action = [[-0.07419313  0.01984207  0.         -0.9420088 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 147 is [True, False, False, False, True, False]
Current timestep = 148. State = [[-0.31789812 -0.05322681]]. Action = [[-0.02395105  0.01243401  0.         -0.21106172]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 148 is [True, False, False, False, True, False]
State prediction error at timestep 148 is 0.012
Human Feedback received at timestep 148 of None
Current timestep = 149. State = [[-0.31916648 -0.0485487 ]]. Action = [[-0.01996619  0.07638253  0.         -0.31137848]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 149 is [True, False, False, False, True, False]
Current timestep = 150. State = [[-0.31912085 -0.04790635]]. Action = [[ 0.00639953 -0.04726395  0.         -0.23423773]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 150 is [True, False, False, False, True, False]
Current timestep = 151. State = [[-0.32033592 -0.04463446]]. Action = [[-0.03535977  0.077981    0.         -0.5698542 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 151 is [True, False, False, False, True, False]
Current timestep = 152. State = [[-0.3252392  -0.04382206]]. Action = [[-0.08546834 -0.04167936  0.         -0.30824268]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 152 is [True, False, False, False, True, False]
Current timestep = 153. State = [[-0.3283226 -0.0475811]]. Action = [[-0.01909339 -0.05993737  0.         -0.49667573]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 153 is [True, False, False, False, True, False]
Current timestep = 154. State = [[-0.32962275 -0.05398095]]. Action = [[-0.01765736 -0.09105944  0.          0.677847  ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 154 is [True, False, False, False, True, False]
State prediction error at timestep 154 is 0.012
Human Feedback received at timestep 154 of None
Current timestep = 155. State = [[-0.333075   -0.05868926]]. Action = [[-0.06454287 -0.02857007  0.         -0.58711743]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 155 is [True, False, False, False, True, False]
State prediction error at timestep 155 is 0.012
Human Feedback received at timestep 155 of None
Current timestep = 156. State = [[-0.3306322  -0.06359298]]. Action = [[ 0.09631538 -0.06606284  0.          0.2608112 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 156 is [True, False, False, False, True, False]
Current timestep = 157. State = [[-0.33016792 -0.07019156]]. Action = [[-0.05680401 -0.06990388  0.          0.16281736]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 157 is [True, False, False, False, True, False]
Current timestep = 158. State = [[-0.33218503 -0.0777284 ]]. Action = [[-0.01908929 -0.07745232  0.         -0.32034814]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 158 is [True, False, False, False, True, False]
State prediction error at timestep 158 is 0.012
Human Feedback received at timestep 158 of None
Current timestep = 159. State = [[-0.32876542 -0.08545782]]. Action = [[ 0.08050441 -0.07333989  0.          0.94406533]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 159 is [True, False, False, False, True, False]
State prediction error at timestep 159 is 0.012
Human Feedback received at timestep 159 of None
Current timestep = 160. State = [[-0.32507157 -0.08984529]]. Action = [[ 0.02443065 -0.00784156  0.         -0.8740796 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 160 is [True, False, False, False, True, False]
State prediction error at timestep 160 is 0.012
Human Feedback received at timestep 160 of None
Current timestep = 161. State = [[-0.32011837 -0.09009524]]. Action = [[0.07942613 0.03452214 0.         0.36968005]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 161 is [True, False, False, False, True, False]
Current timestep = 162. State = [[-0.31815332 -0.09082493]]. Action = [[-0.00881167 -0.00804116  0.         -0.33206046]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 162 is [True, False, False, False, True, False]
State prediction error at timestep 162 is 0.012
Human Feedback received at timestep 162 of None
Current timestep = 163. State = [[-0.31987438 -0.08945048]]. Action = [[-0.03323823  0.05922397  0.          0.6142738 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 163 is [True, False, False, False, True, False]
Current timestep = 164. State = [[-0.31934655 -0.08669081]]. Action = [[ 0.03466316  0.0387822   0.         -0.14046508]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 164 is [True, False, False, False, True, False]
Current timestep = 165. State = [[-0.31397054 -0.08246246]]. Action = [[ 0.09909924  0.05962933  0.         -0.28255308]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 165 is [True, False, False, False, True, False]
State prediction error at timestep 165 is 0.012
Human Feedback received at timestep 165 of None
Current timestep = 166. State = [[-0.3098394  -0.07921509]]. Action = [[ 0.03544044  0.01555784  0.         -0.71008694]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 166 is [True, False, False, False, True, False]
State prediction error at timestep 166 is 0.012
Human Feedback received at timestep 166 of None
Current timestep = 167. State = [[-0.30599573 -0.0788828 ]]. Action = [[ 0.06100287 -0.01755409  0.         -0.9477239 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 167 is [True, False, False, False, True, False]
Current timestep = 168. State = [[-0.30159238 -0.07522024]]. Action = [[0.05557228 0.06844025 0.         0.3619163 ]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 168 is [True, False, False, False, True, False]
State prediction error at timestep 168 is 0.012
Human Feedback received at timestep 168 of None
Current timestep = 169. State = [[-0.29555747 -0.07706189]]. Action = [[ 0.08749374 -0.09507672  0.         -0.6846394 ]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 169 is [True, False, False, False, True, False]
State prediction error at timestep 169 is 0.012
Human Feedback received at timestep 169 of None
Current timestep = 170. State = [[-0.292127   -0.07580077]]. Action = [[ 0.00155808  0.0683658   0.         -0.57995296]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 170 is [True, False, False, False, True, False]
Current timestep = 171. State = [[-0.2890537  -0.07224686]]. Action = [[ 0.04960083  0.02149124  0.         -0.50004685]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 171 is [True, False, False, False, True, False]
Current timestep = 172. State = [[-0.28927314 -0.06775602]]. Action = [[-0.04574952  0.06167934  0.         -0.32204366]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 172 is [True, False, False, False, True, False]
Current timestep = 173. State = [[-0.29184568 -0.07004771]]. Action = [[-0.0430637  -0.09628773  0.          0.6125511 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 173 is [True, False, False, False, True, False]
Current timestep = 174. State = [[-0.29551774 -0.07174634]]. Action = [[-0.07040967  0.01563574  0.          0.65946627]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 174 is [True, False, False, False, True, False]
Current timestep = 175. State = [[-0.2967067  -0.06941272]]. Action = [[-0.00135913  0.03624814  0.         -0.50893474]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 175 is [True, False, False, False, True, False]
State prediction error at timestep 175 is 0.012
Human Feedback received at timestep 175 of None
Current timestep = 176. State = [[-0.2927901 -0.068423 ]]. Action = [[ 0.07167061 -0.01313334  0.         -0.30285203]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 176 is [True, False, False, False, True, False]
State prediction error at timestep 176 is 0.012
Human Feedback received at timestep 176 of None
Current timestep = 177. State = [[-0.29026425 -0.06450999]]. Action = [[ 0.00078374  0.07220586  0.         -0.06658101]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 177 is [True, False, False, False, True, False]
Current timestep = 178. State = [[-0.288296   -0.05833368]]. Action = [[ 0.0339006   0.06569939  0.         -0.03266454]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 178 is [True, False, False, False, True, False]
Current timestep = 179. State = [[-0.28564802 -0.05962619]]. Action = [[ 0.0317174  -0.08609602  0.         -0.6378873 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 179 is [True, False, False, False, True, False]
Current timestep = 180. State = [[-0.28528652 -0.06387938]]. Action = [[-0.02266153 -0.04613214  0.          0.69155   ]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 180 is [True, False, False, False, True, False]
Current timestep = 181. State = [[-0.28766182 -0.06355577]]. Action = [[-0.05102316  0.03555208  0.          0.8183851 ]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 181 is [True, False, False, False, True, False]
Current timestep = 182. State = [[-0.28652522 -0.06697873]]. Action = [[ 0.04255792 -0.08809259  0.         -0.8239961 ]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 182 is [True, False, False, False, True, False]
Current timestep = 183. State = [[-0.28789344 -0.06554155]]. Action = [[-0.07077293  0.08616778  0.         -0.18445301]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 183 is [True, False, False, False, True, False]
State prediction error at timestep 183 is 0.012
Human Feedback received at timestep 183 of None
Current timestep = 184. State = [[-0.2884342  -0.06188855]]. Action = [[0.02589329 0.02521404 0.         0.8529171 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 184 is [True, False, False, False, True, False]
Current timestep = 185. State = [[-0.2847512  -0.05975501]]. Action = [[ 0.06569769  0.01783788  0.         -0.38379776]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 185 is [True, False, False, False, True, False]
Current timestep = 186. State = [[-0.28575414 -0.06221387]]. Action = [[-0.05819391 -0.06710884  0.         -0.94576174]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 186 is [True, False, False, False, True, False]
Current timestep = 187. State = [[-0.28383714 -0.0596551 ]]. Action = [[0.07454874 0.09273987 0.         0.47669947]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 187 is [True, False, False, False, True, False]
State prediction error at timestep 187 is 0.012
Human Feedback received at timestep 187 of None
Current timestep = 188. State = [[-0.27960598 -0.05633758]]. Action = [[ 0.05260085  0.0025412   0.         -0.57161003]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 188 is [True, False, False, False, True, False]
State prediction error at timestep 188 is 0.012
Human Feedback received at timestep 188 of None
Current timestep = 189. State = [[-0.27406687 -0.05061303]]. Action = [[0.0878674  0.09567057 0.         0.1119225 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 189 is [True, False, False, False, True, False]
Current timestep = 190. State = [[-0.27421707 -0.05066198]]. Action = [[-0.05437192 -0.08486065  0.          0.78376555]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 190 is [True, False, False, False, True, False]
Current timestep = 191. State = [[-0.2756834  -0.05309411]]. Action = [[-0.00622382 -0.00950444  0.         -0.7951282 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 191 is [True, False, False, False, True, False]
Current timestep = 192. State = [[-0.2718516  -0.05126519]]. Action = [[0.07846951 0.03925348 0.         0.23868382]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 192 is [True, False, False, False, True, False]
State prediction error at timestep 192 is 0.012
Human Feedback received at timestep 192 of None
Current timestep = 193. State = [[-0.26519394 -0.05462364]]. Action = [[ 0.08475376 -0.09730351  0.         -0.85029477]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 193 is [True, False, False, False, True, False]
Current timestep = 194. State = [[-0.26077172 -0.05266792]]. Action = [[ 0.02459947  0.09512203  0.         -0.0240348 ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 194 is [True, False, False, False, True, False]
Current timestep = 195. State = [[-0.2604729  -0.05332825]]. Action = [[-0.02676065 -0.06845657  0.          0.64145064]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 195 is [True, False, False, False, True, False]
Current timestep = 196. State = [[-0.26098123 -0.0586077 ]]. Action = [[-0.01997313 -0.0633789   0.         -0.46609902]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 196 is [True, False, False, False, True, False]
Current timestep = 197. State = [[-0.26182988 -0.05615171]]. Action = [[-0.02913294  0.09803899  0.         -0.04217392]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 197 is [True, False, False, False, True, False]
State prediction error at timestep 197 is 0.012
Human Feedback received at timestep 197 of None
Current timestep = 198. State = [[-0.26216164 -0.05238132]]. Action = [[-0.00518145  0.02210631  0.         -0.13174242]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 198 is [True, False, False, False, True, False]
Current timestep = 199. State = [[-0.26115856 -0.04977397]]. Action = [[0.01377072 0.03175464 0.         0.46658075]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 199 is [True, False, False, False, True, False]
Current timestep = 200. State = [[-0.25613797 -0.05159242]]. Action = [[ 0.08866837 -0.06372884  0.          0.8047106 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 200 is [True, False, False, False, True, False]
Current timestep = 201. State = [[-0.25739935 -0.05110197]]. Action = [[-0.09963728  0.04562307  0.         -0.7303585 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 201 is [True, False, False, False, True, False]
Current timestep = 202. State = [[-0.25971475 -0.04583406]]. Action = [[ 0.01372969  0.07401478  0.         -0.37497103]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 202 is [True, False, False, False, True, False]
Current timestep = 203. State = [[-0.25881273 -0.04137978]]. Action = [[0.03079679 0.02936555 0.         0.88116693]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 203 is [True, False, False, False, True, False]
State prediction error at timestep 203 is 0.012
Human Feedback received at timestep 203 of None
Current timestep = 204. State = [[-0.26325098 -0.03920305]]. Action = [[-0.09553662  0.0074361   0.          0.56615937]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 204 is [True, False, False, False, True, False]
Current timestep = 205. State = [[-0.26314884 -0.03863703]]. Action = [[ 0.07862469 -0.01221822  0.         -0.00350201]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 205 is [True, False, False, False, True, False]
State prediction error at timestep 205 is 0.012
Human Feedback received at timestep 205 of None
Current timestep = 206. State = [[-0.2627846  -0.03968672]]. Action = [[-0.02758104 -0.02839027  0.          0.43885493]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 206 is [True, False, False, False, True, False]
Current timestep = 207. State = [[-0.26661077 -0.04249676]]. Action = [[-0.06656671 -0.04742297  0.          0.9427171 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 207 is [True, False, False, False, True, False]
State prediction error at timestep 207 is 0.012
Human Feedback received at timestep 207 of None
Current timestep = 208. State = [[-0.26401705 -0.04649693]]. Action = [[ 0.09372016 -0.05449561  0.          0.99166226]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 208 is [True, False, False, False, True, False]
Current timestep = 209. State = [[-0.25998968 -0.05055672]]. Action = [[ 0.01848885 -0.04243303  0.          0.32107306]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 209 is [True, False, False, False, True, False]
Current timestep = 210. State = [[-0.25492895 -0.04856766]]. Action = [[0.07581138 0.07693285 0.         0.27240837]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 210 is [True, False, False, False, True, False]
Current timestep = 211. State = [[-0.25200364 -0.04738659]]. Action = [[ 0.00561909 -0.01224796  0.         -0.4178825 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 211 is [True, False, False, False, True, False]
Current timestep = 212. State = [[-0.25577775 -0.04380378]]. Action = [[-0.09821889  0.08508011  0.          0.60448813]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 212 is [True, False, False, False, True, False]
Current timestep = 213. State = [[-0.2601423  -0.03868705]]. Action = [[-0.03787294  0.05345585  0.         -0.6106347 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 213 is [True, False, False, False, True, False]
Current timestep = 214. State = [[-0.25788662 -0.03311647]]. Action = [[ 0.08194851  0.06537334  0.         -0.37116373]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 214 is [True, False, False, False, True, False]
Current timestep = 215. State = [[-0.25670663 -0.02896534]]. Action = [[-0.00999141  0.02379422  0.         -0.535717  ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 215 is [True, False, False, False, True, False]
Current timestep = 216. State = [[-0.25481623 -0.02400691]]. Action = [[ 0.05203732  0.06142607  0.         -0.7833507 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 216 is [True, False, False, False, True, False]
Current timestep = 217. State = [[-0.25826988 -0.02168971]]. Action = [[-0.09518235 -0.01473077  0.          0.03574967]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 217 is [True, False, False, False, True, False]
Current timestep = 218. State = [[-0.25813964 -0.0229524 ]]. Action = [[ 0.06755545 -0.04342345  0.         -0.55490094]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 218 is [True, False, False, False, True, False]
State prediction error at timestep 218 is 0.012
Human Feedback received at timestep 218 of None
Current timestep = 219. State = [[-0.2574342 -0.0224337]]. Action = [[-0.02191421  0.01703962  0.          0.1606834 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 219 is [True, False, False, False, True, False]
Current timestep = 220. State = [[-0.25709668 -0.0217813 ]]. Action = [[ 0.01412831 -0.01183335  0.         -0.653043  ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 220 is [True, False, False, False, True, False]
Current timestep = 221. State = [[-0.2587634  -0.01735832]]. Action = [[-0.044709    0.08114203  0.          0.81247103]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 221 is [True, False, False, False, True, False]
Current timestep = 222. State = [[-0.2642933  -0.01002232]]. Action = [[-0.08587576  0.08262318  0.          0.8246758 ]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 222 is [True, False, False, False, True, False]
Current timestep = 223. State = [[-0.27144128 -0.0023442 ]]. Action = [[-0.08651321  0.07867614  0.          0.93394005]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 223 is [True, False, False, False, True, False]
Current timestep = 224. State = [[-0.27681163  0.00641493]]. Action = [[-0.0363778   0.09473156  0.         -0.4123146 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 224 is [True, False, False, False, True, False]
State prediction error at timestep 224 is 0.012
Human Feedback received at timestep 224 of None
Current timestep = 225. State = [[-0.27504647  0.01119268]]. Action = [[ 9.7632639e-02 -2.2386014e-04  0.0000000e+00  5.1452816e-01]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 225 is [True, False, False, False, True, False]
Current timestep = 226. State = [[-0.2763855   0.01487385]]. Action = [[-0.05765215  0.03545868  0.          0.5289302 ]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 226 is [True, False, False, False, True, False]
Current timestep = 227. State = [[-0.27539372  0.01323935]]. Action = [[ 0.07703767 -0.08573862  0.          0.08602011]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 227 is [True, False, False, False, True, False]
Current timestep = 228. State = [[-0.27247435  0.00902725]]. Action = [[ 0.03076085 -0.05657064  0.         -0.70641214]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 228 is [True, False, False, False, True, False]
State prediction error at timestep 228 is 0.012
Human Feedback received at timestep 228 of None
Current timestep = 229. State = [[-0.27556634  0.01188353]]. Action = [[-0.08112167  0.0805572   0.         -0.54819727]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 229 is [True, False, False, False, True, False]
Current timestep = 230. State = [[-0.2790564   0.01239125]]. Action = [[-0.02027931 -0.04841634  0.          0.9498532 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 230 is [True, False, False, False, True, False]
State prediction error at timestep 230 is 0.012
Human Feedback received at timestep 230 of None
Current timestep = 231. State = [[-0.2758072   0.01329324]]. Action = [[ 0.08933201  0.03565674  0.         -0.5562528 ]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 231 is [True, False, False, False, True, False]
State prediction error at timestep 231 is 0.012
Human Feedback received at timestep 231 of None
Current timestep = 232. State = [[-0.26957363  0.01020595]]. Action = [[ 0.08178236 -0.08400054  0.          0.75736856]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 232 is [True, False, False, False, True, False]
Current timestep = 233. State = [[-0.2706412   0.01248191]]. Action = [[-0.08310437  0.09771391  0.          0.25492954]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 233 is [True, False, False, False, True, False]
Current timestep = 234. State = [[-0.2687248   0.01269033]]. Action = [[ 0.09362882 -0.05004777  0.          0.01931775]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 234 is [True, False, False, False, True, False]
State prediction error at timestep 234 is 0.012
Human Feedback received at timestep 234 of None
Current timestep = 235. State = [[-0.26842156  0.01305097]]. Action = [[-0.05275721  0.03627472  0.         -0.12875408]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 235 is [True, False, False, False, True, False]
State prediction error at timestep 235 is 0.012
Human Feedback received at timestep 235 of None
Current timestep = 236. State = [[-0.26700947  0.00903605]]. Action = [[ 0.05046607 -0.09847365  0.         -0.9721306 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 236 is [True, False, False, False, True, False]
Current timestep = 237. State = [[-0.26222003  0.0089357 ]]. Action = [[0.06234524 0.0633396  0.         0.4381032 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 237 is [True, False, False, False, True, False]
State prediction error at timestep 237 is 0.012
Human Feedback received at timestep 237 of None
Current timestep = 238. State = [[-0.25759855  0.01368046]]. Action = [[0.05353069 0.06746554 0.         0.43462968]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 238 is [True, False, False, False, True, False]
Current timestep = 239. State = [[-0.25383276  0.018617  ]]. Action = [[ 0.04239265  0.05968372  0.         -0.61793566]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 239 is [True, False, False, False, True, False]
Current timestep = 240. State = [[-0.25062674  0.01825021]]. Action = [[ 0.03337624 -0.046882    0.          0.7587408 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 240 is [True, False, False, False, True, False]
Current timestep = 241. State = [[-0.24862032  0.01666844]]. Action = [[ 0.00426346 -0.00932635  0.          0.20876658]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 241 is [True, False, False, False, True, False]
Current timestep = 242. State = [[-0.24908918  0.01319122]]. Action = [[-0.03706463 -0.06626555  0.          0.36524403]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 242 is [True, False, False, False, True, False]
Current timestep = 243. State = [[-0.25085416  0.01432383]]. Action = [[-0.04224936  0.05942445  0.         -0.5759227 ]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 243 is [True, False, False, False, True, False]
Current timestep = 244. State = [[-0.2525163   0.01844151]]. Action = [[-0.02609134  0.04302607  0.          0.02485895]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 244 is [True, False, False, False, True, False]
State prediction error at timestep 244 is 0.012
Human Feedback received at timestep 244 of None
Current timestep = 245. State = [[-0.25435874  0.02449529]]. Action = [[-0.0294378   0.08185606  0.          0.70086753]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 245 is [True, False, False, False, True, False]
Current timestep = 246. State = [[-0.25216538  0.02802126]]. Action = [[0.06492827 0.00351547 0.         0.01838219]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 246 is [True, False, False, False, True, False]
State prediction error at timestep 246 is 0.012
Human Feedback received at timestep 246 of None
Current timestep = 247. State = [[-0.2551543  0.0333625]]. Action = [[-0.09800553  0.08266083  0.          0.6473994 ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 247 is [True, False, False, False, True, False]
Current timestep = 248. State = [[-0.26174417  0.03918307]]. Action = [[-0.06673756  0.04162658  0.          0.14702559]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 248 is [True, False, False, False, True, False]
Current timestep = 249. State = [[-0.26613793  0.03717372]]. Action = [[-0.03351276 -0.09778798  0.         -0.7860285 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 249 is [True, False, False, False, True, False]
Current timestep = 250. State = [[-0.27069438  0.03117273]]. Action = [[-0.0643495  -0.08868106  0.          0.39860976]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 250 is [True, False, False, False, True, False]
Current timestep = 251. State = [[-0.26915696  0.03130565]]. Action = [[ 0.0872656   0.04713624  0.         -0.43543458]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 251 is [True, False, False, False, True, False]
Current timestep = 252. State = [[-0.27017647  0.03221026]]. Action = [[-0.06406257 -0.0146413   0.          0.7022412 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 252 is [True, False, False, False, True, False]
State prediction error at timestep 252 is 0.012
Human Feedback received at timestep 252 of None
Current timestep = 253. State = [[-0.27701676  0.0315654 ]]. Action = [[-0.09831903 -0.01400302  0.          0.02466536]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 253 is [True, False, False, False, True, False]
Current timestep = 254. State = [[-0.2781004   0.03020198]]. Action = [[ 0.05219635 -0.02322022  0.         -0.7885103 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 254 is [True, False, False, False, True, False]
Current timestep = 255. State = [[-0.27875164  0.03391379]]. Action = [[-0.02651195  0.0892221   0.         -0.8168889 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 255 is [True, False, False, False, True, False]
Current timestep = 256. State = [[-0.2815601   0.03857125]]. Action = [[-0.02270103  0.03821061  0.         -0.8023792 ]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 256 is [True, False, False, False, True, False]
State prediction error at timestep 256 is 0.012
Human Feedback received at timestep 256 of None
Current timestep = 257. State = [[-0.28168344  0.04469186]]. Action = [[ 0.03832378  0.09020045  0.         -0.8241176 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 257 is [True, False, False, False, True, False]
State prediction error at timestep 257 is 0.012
Human Feedback received at timestep 257 of None
Current timestep = 258. State = [[-0.2823777   0.04927888]]. Action = [[-0.00296441  0.02705752  0.         -0.7659553 ]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 258 is [True, False, False, False, True, False]
Current timestep = 259. State = [[-0.2865812   0.05383103]]. Action = [[-0.05658524  0.05703773  0.          0.68668246]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 259 is [True, False, False, False, True, False]
Current timestep = 260. State = [[-0.2866701   0.06134447]]. Action = [[0.06697123 0.09690454 0.         0.94628024]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 260 is [True, False, False, False, True, False]
Current timestep = 261. State = [[-0.28345323  0.0611476 ]]. Action = [[ 0.05872671 -0.08565628  0.          0.53379023]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 261 is [True, False, False, False, True, False]
Current timestep = 262. State = [[-0.28473762  0.05876284]]. Action = [[-0.05382015 -0.02013361  0.          0.30620217]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 262 is [True, False, False, False, True, False]
Current timestep = 263. State = [[-0.29091272  0.06372131]]. Action = [[-0.09326884  0.0934334   0.         -0.0293349 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 263 is [True, False, False, False, True, False]
State prediction error at timestep 263 is 0.012
Human Feedback received at timestep 263 of None
Current timestep = 264. State = [[-0.29716575  0.07052726]]. Action = [[-0.05873246  0.05696218  0.         -0.84896934]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 264 is [True, False, False, False, True, False]
Current timestep = 265. State = [[-0.30203298  0.06996173]]. Action = [[-0.04692098 -0.07746659  0.          0.10845613]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 265 is [True, False, False, False, True, False]
Current timestep = 266. State = [[-0.3044239   0.06447797]]. Action = [[-0.01355476 -0.09146859  0.          0.563499  ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 266 is [True, False, False, False, True, False]
Current timestep = 267. State = [[-0.30214015  0.05778148]]. Action = [[ 0.05679294 -0.08886103  0.         -0.20960104]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 267 is [True, False, False, False, True, False]
Current timestep = 268. State = [[-0.30423927  0.05585822]]. Action = [[-0.07766265  0.01920233  0.          0.76058364]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 268 is [True, False, False, False, True, False]
Current timestep = 269. State = [[-0.30645007  0.05713174]]. Action = [[0.00217776 0.0207987  0.         0.89136255]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 269 is [True, False, False, False, True, False]
State prediction error at timestep 269 is 0.012
Human Feedback received at timestep 269 of None
Current timestep = 270. State = [[-0.3079255   0.05722017]]. Action = [[-0.01824551 -0.0042288   0.          0.37617683]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 270 is [True, False, False, False, True, False]
Current timestep = 271. State = [[-0.30721372  0.05628859]]. Action = [[ 0.03740668 -0.0081032   0.          0.11308277]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 271 is [True, False, False, False, True, False]
Current timestep = 272. State = [[-0.30902824  0.05947851]]. Action = [[-0.04190005  0.07939287  0.          0.3330425 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 272 is [True, False, False, False, True, False]
Current timestep = 273. State = [[-0.31043318  0.05918268]]. Action = [[ 0.01360656 -0.04711839  0.          0.6510427 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 273 is [True, False, False, False, True, False]
Current timestep = 274. State = [[-0.3116755   0.06218117]]. Action = [[-0.01387528  0.09124922  0.         -0.71032465]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 274 is [True, False, False, False, True, False]
State prediction error at timestep 274 is 0.012
Human Feedback received at timestep 274 of None
Current timestep = 275. State = [[-0.31053293  0.06874306]]. Action = [[ 0.0596187   0.08101343  0.         -0.0348435 ]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 275 is [True, False, False, False, True, False]
State prediction error at timestep 275 is 0.012
Human Feedback received at timestep 275 of None
Current timestep = 276. State = [[-0.3136971   0.06910733]]. Action = [[-0.07890238 -0.04928231  0.         -0.3679859 ]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 276 is [True, False, False, False, True, False]
State prediction error at timestep 276 is 0.012
Human Feedback received at timestep 276 of None
Current timestep = 277. State = [[-0.3158841   0.06361549]]. Action = [[ 0.0207376  -0.09217788  0.          0.75566316]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 277 is [True, False, False, False, True, False]
Current timestep = 278. State = [[-0.31894943  0.06493405]]. Action = [[-0.05207764  0.08330765  0.          0.65749335]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 278 is [True, False, False, False, True, False]
Current timestep = 279. State = [[-0.32417113  0.06672224]]. Action = [[-0.05400294 -0.01759986  0.         -0.36770654]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 279 is [True, False, False, False, True, False]
Current timestep = 280. State = [[-0.32888597  0.06395723]]. Action = [[-0.04599093 -0.05814148  0.         -0.09917009]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 280 is [True, False, False, False, True, False]
Current timestep = 281. State = [[-0.32851973  0.06148602]]. Action = [[ 0.05087202 -0.01895991  0.          0.49590337]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 281 is [True, False, False, False, True, False]
State prediction error at timestep 281 is 0.012
Human Feedback received at timestep 281 of None
Current timestep = 282. State = [[-0.32422566  0.05611213]]. Action = [[ 0.07080226 -0.08798846  0.          0.41281605]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 282 is [True, False, False, False, True, False]
Current timestep = 283. State = [[-0.32356784  0.05285986]]. Action = [[-2.8187126e-02  6.4696372e-04  0.0000000e+00  8.1139421e-01]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 283 is [True, False, False, False, True, False]
Current timestep = 284. State = [[-0.32891694  0.05210605]]. Action = [[-0.09890959 -0.00117623  0.         -0.0380137 ]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 284 is [True, False, False, False, True, False]
Current timestep = 285. State = [[-0.32962367  0.05153176]]. Action = [[ 0.04869366  0.00047702  0.         -0.27904463]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 285 is [True, False, False, False, True, False]
Current timestep = 286. State = [[-0.33184755  0.0470554 ]]. Action = [[-0.07356026 -0.07800369  0.         -0.07798249]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 286 is [True, False, False, False, True, False]
Current timestep = 287. State = [[-0.33565742  0.0490003 ]]. Action = [[-0.03127161  0.09989857  0.         -0.5866436 ]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 287 is [True, False, False, False, True, False]
State prediction error at timestep 287 is 0.012
Human Feedback received at timestep 287 of None
Current timestep = 288. State = [[-0.3376639   0.05593571]]. Action = [[ 0.00411229  0.08926732  0.         -0.09009129]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 288 is [True, False, False, False, True, False]
Current timestep = 289. State = [[-0.34106845  0.05701596]]. Action = [[-0.04035716 -0.03542302  0.         -0.2635529 ]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 289 is [True, False, False, False, True, False]
Current timestep = 290. State = [[-0.33867323  0.05257513]]. Action = [[ 0.09734147 -0.07145954  0.         -0.02795124]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 290 is [True, False, False, False, True, False]
State prediction error at timestep 290 is 0.012
Human Feedback received at timestep 290 of None
Current timestep = 291. State = [[-0.33934304  0.05070234]]. Action = [[-0.05713931  0.01066504  0.         -0.7663967 ]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 291 is [True, False, False, False, True, False]
Current timestep = 292. State = [[-0.3443329   0.04722777]]. Action = [[-0.0625463  -0.07223548  0.          0.49005258]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 292 is [True, False, False, False, True, False]
Current timestep = 293. State = [[-0.34409702  0.04107144]]. Action = [[ 0.04731906 -0.07586887  0.          0.20205629]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 293 is [True, False, False, False, True, False]
Current timestep = 294. State = [[-0.3407475   0.04014534]]. Action = [[0.04698782 0.04513011 0.         0.29335082]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 294 is [True, False, False, False, True, False]
Current timestep = 295. State = [[-0.34339014  0.04069804]]. Action = [[-0.079163    0.00162347  0.          0.7200632 ]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 295 is [True, False, False, False, True, False]
Current timestep = 296. State = [[-0.35042593  0.04081953]]. Action = [[-0.09001391  0.00916243  0.          0.8843081 ]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 296 is [True, False, False, False, True, False]
Current timestep = 297. State = [[-0.35025927  0.04505273]]. Action = [[ 0.09163158  0.08728083  0.         -0.98925376]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 297 is [True, False, False, False, True, False]
State prediction error at timestep 297 is 0.012
Human Feedback received at timestep 297 of None
Current timestep = 298. State = [[-0.35206652  0.05168556]]. Action = [[-0.06739083  0.08127836  0.          0.87305737]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 298 is [True, False, False, False, True, False]
State prediction error at timestep 298 is 0.012
Human Feedback received at timestep 298 of None
Current timestep = 299. State = [[-0.35217538  0.05353411]]. Action = [[ 0.05995821 -0.02107758  0.         -0.16872978]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 299 is [True, False, False, False, True, False]
Current timestep = 300. State = [[-0.35036096  0.05214578]]. Action = [[ 0.02406726 -0.02474345  0.          0.8243147 ]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 300 is [True, False, False, False, True, False]
Current timestep = 301. State = [[-0.35238832  0.05004519]]. Action = [[-0.04933728 -0.03398766  0.         -0.41738147]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 301 is [True, False, False, False, True, False]
Current timestep = 302. State = [[-0.35451567  0.04460435]]. Action = [[-0.01862063 -0.09534556  0.         -0.6467637 ]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 302 is [True, False, False, False, True, False]
Current timestep = 303. State = [[-0.35500893  0.04608322]]. Action = [[0.00112841 0.09300032 0.         0.01337445]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 303 is [True, False, False, False, True, False]
Current timestep = 304. State = [[-0.35112584  0.05064994]]. Action = [[ 0.09127598  0.03858715  0.         -0.5939901 ]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 304 is [True, False, False, False, True, False]
State prediction error at timestep 304 is 0.012
Human Feedback received at timestep 304 of None
Current timestep = 305. State = [[-0.34843764  0.05144186]]. Action = [[ 0.01257388 -0.01067562  0.         -0.13458979]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 305 is [True, False, False, False, True, False]
State prediction error at timestep 305 is 0.012
Human Feedback received at timestep 305 of None
Current timestep = 306. State = [[-0.3472422   0.05032225]]. Action = [[ 0.0142207  -0.01958447  0.          0.42453074]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 306 is [True, False, False, False, True, False]
Current timestep = 307. State = [[-0.347805    0.05295533]]. Action = [[-0.02269419  0.06272305  0.         -0.7118628 ]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 307 is [True, False, False, False, True, False]
Current timestep = 308. State = [[-0.35210845  0.05452526]]. Action = [[-0.07670791 -0.01200892  0.         -0.57948595]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 308 is [True, False, False, False, True, False]
Current timestep = 309. State = [[-0.35501692  0.05374131]]. Action = [[-0.01899513 -0.02193917  0.         -0.24825007]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 309 is [True, False, False, False, True, False]
Current timestep = 310. State = [[-0.3562144   0.05805962]]. Action = [[-0.00771308  0.09098392  0.          0.89527404]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 310 is [True, False, False, False, True, False]
Current timestep = 311. State = [[-0.35275817  0.06583799]]. Action = [[ 0.09839325  0.09345367  0.         -0.2632689 ]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 311 is [True, False, False, False, True, False]
State prediction error at timestep 311 is 0.012
Human Feedback received at timestep 311 of None
Current timestep = 312. State = [[-0.34957457  0.07207994]]. Action = [[ 0.03474412  0.05695762  0.         -0.28462952]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 312 is [True, False, False, False, True, False]
State prediction error at timestep 312 is 0.012
Human Feedback received at timestep 312 of None
Current timestep = 313. State = [[-0.35124895  0.07680634]]. Action = [[-0.03894487  0.04155552  0.         -0.3176986 ]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 313 is [True, False, False, False, True, False]
State prediction error at timestep 313 is 0.012
Human Feedback received at timestep 313 of None
Current timestep = 314. State = [[-0.35027206  0.08374467]]. Action = [[0.0606556  0.09062483 0.         0.03274632]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 314 is [True, False, False, False, True, False]
Current timestep = 315. State = [[-0.34920782  0.09016749]]. Action = [[ 0.00686908  0.04994369  0.         -0.52691865]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 315 is [True, False, False, False, True, False]
Current timestep = 316. State = [[-0.34463894  0.08936868]]. Action = [[ 0.09516902 -0.07655267  0.          0.9859054 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 316 is [True, False, False, False, True, False]
Current timestep = 317. State = [[-0.3433256   0.09169412]]. Action = [[-0.03308152  0.06699195  0.         -0.44100857]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 317 is [True, False, False, False, True, False]
Current timestep = 318. State = [[-0.3437468   0.09097013]]. Action = [[-0.00384919 -0.08461466  0.          0.538484  ]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 318 is [True, False, False, False, True, False]
State prediction error at timestep 318 is 0.012
Human Feedback received at timestep 318 of None
Current timestep = 319. State = [[-0.33905095  0.09152488]]. Action = [[ 0.07944661  0.03174534  0.         -0.489398  ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 319 is [True, False, False, False, True, False]
Current timestep = 320. State = [[-0.33598065  0.09129915]]. Action = [[-0.0113832  -0.04154754  0.         -0.07388496]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 320 is [True, False, False, False, True, False]
Current timestep = 321. State = [[-0.33642134  0.08987838]]. Action = [[-0.03960497 -0.02587609  0.          0.7758266 ]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 321 is [True, False, False, False, True, False]
Current timestep = 322. State = [[-0.33151627  0.09090852]]. Action = [[0.09529164 0.02536049 0.         0.23380637]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 322 is [True, False, False, False, True, False]
Current timestep = 323. State = [[-0.32888788  0.09023276]]. Action = [[-0.0380289  -0.03560158  0.          0.73209715]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 323 is [True, False, False, False, True, False]
Current timestep = 324. State = [[-0.33236066  0.09184307]]. Action = [[-0.08567055  0.0413663   0.         -0.65301824]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 324 is [True, False, False, False, True, False]
State prediction error at timestep 324 is 0.012
Human Feedback received at timestep 324 of None
Current timestep = 325. State = [[-0.33325386  0.09027199]]. Action = [[ 0.00748942 -0.06792901  0.         -0.74373543]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 325 is [True, False, False, False, True, False]
Current timestep = 326. State = [[-0.33178052  0.09067179]]. Action = [[ 0.00927542  0.04223023  0.         -0.96729946]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 326 is [True, False, False, False, True, False]
Current timestep = 327. State = [[-0.33221158  0.0874107 ]]. Action = [[-0.027773   -0.09101842  0.          0.63733697]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 327 is [True, False, False, False, True, False]
Current timestep = 328. State = [[-0.336868    0.08209366]]. Action = [[-0.0977295  -0.05809113  0.         -0.22927636]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 328 is [True, False, False, False, True, False]
Current timestep = 329. State = [[-0.34319183  0.08371479]]. Action = [[-0.0802382   0.06772222  0.          0.21889639]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 329 is [True, False, False, False, True, False]
Current timestep = 330. State = [[-0.34222665  0.08231741]]. Action = [[ 0.0804474  -0.06525839  0.          0.34611845]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 330 is [True, False, False, False, True, False]
Current timestep = 331. State = [[-0.34543106  0.0833503 ]]. Action = [[-0.09573589  0.06936931  0.         -0.01418412]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 331 is [True, False, False, False, True, False]
Current timestep = 332. State = [[-0.34938562  0.08588295]]. Action = [[-0.00324064  0.01468589  0.         -0.9650372 ]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 332 is [True, False, False, False, True, False]
Current timestep = 333. State = [[-0.34885103  0.0907364 ]]. Action = [[ 0.05169832  0.09133273  0.         -0.9666131 ]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 333 is [True, False, False, False, True, False]
State prediction error at timestep 333 is 0.012
Human Feedback received at timestep 333 of None
Current timestep = 334. State = [[-0.3497134   0.08933888]]. Action = [[-0.01224783 -0.07963748  0.         -0.23841894]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 334 is [True, False, False, False, True, False]
Current timestep = 335. State = [[-0.3522648   0.08694872]]. Action = [[-0.02042683 -0.00158922  0.         -0.24857134]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 335 is [True, False, False, False, True, False]
Current timestep = 336. State = [[-0.35594785  0.08834986]]. Action = [[-0.03708806  0.03426159  0.          0.544919  ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 336 is [True, False, False, False, True, False]
State prediction error at timestep 336 is 0.012
Human Feedback received at timestep 336 of None
Current timestep = 337. State = [[-0.35911646  0.08506056]]. Action = [[-0.01980055 -0.08641309  0.         -0.21847332]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 337 is [True, False, False, False, True, False]
Current timestep = 338. State = [[-0.36401418  0.08692824]]. Action = [[-0.0661864   0.09364087  0.         -0.73228985]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 338 is [True, False, False, False, True, False]
Current timestep = 339. State = [[-0.369843    0.08562359]]. Action = [[-0.0546456  -0.08666154  0.         -0.43282878]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 339 is [True, False, False, False, True, False]
Current timestep = 340. State = [[-0.36995578  0.08485318]]. Action = [[ 0.056404    0.03266782  0.         -0.7109239 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 340 is [True, False, False, False, True, False]
Current timestep = 341. State = [[-0.36594865  0.08621364]]. Action = [[ 0.07224711  0.01855035  0.         -0.53498703]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 341 is [True, False, False, False, True, False]
State prediction error at timestep 341 is 0.012
Human Feedback received at timestep 341 of None
Current timestep = 342. State = [[-0.36454836  0.08659533]]. Action = [[0.00119704 0.00516788 0.         0.68729067]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 342 is [True, False, False, False, True, False]
State prediction error at timestep 342 is 0.012
Human Feedback received at timestep 342 of None
Current timestep = 343. State = [[-0.36236957  0.08481719]]. Action = [[ 0.04929963 -0.03291995  0.         -0.6164951 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 343 is [True, False, False, False, True, False]
State prediction error at timestep 343 is 0.012
Human Feedback received at timestep 343 of None
Current timestep = 344. State = [[-0.35867095  0.08207807]]. Action = [[ 0.04546113 -0.02658944  0.          0.604738  ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 344 is [True, False, False, False, True, False]
Current timestep = 345. State = [[-0.35568255  0.07638498]]. Action = [[ 0.02121743 -0.08684698  0.         -0.15997213]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 345 is [True, False, False, False, True, False]
Current timestep = 346. State = [[-0.35558847  0.07719953]]. Action = [[-0.02774825  0.08443392  0.         -0.35764176]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 346 is [True, False, False, False, True, False]
Current timestep = 347. State = [[-0.35571668  0.07953908]]. Action = [[0.00513898 0.00777678 0.         0.38699365]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 347 is [True, False, False, False, True, False]
Current timestep = 348. State = [[-0.35266098  0.07883345]]. Action = [[ 0.05342049 -0.01493974  0.         -0.44285524]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 348 is [True, False, False, False, True, False]
Current timestep = 349. State = [[-0.3500662   0.07488667]]. Action = [[ 0.00927167 -0.06272862  0.         -0.64070034]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 349 is [True, False, False, False, True, False]
Current timestep = 350. State = [[-0.35054007  0.07253195]]. Action = [[-0.03582796 -0.00322063  0.         -0.32054746]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 350 is [True, False, False, False, True, False]
Current timestep = 351. State = [[-0.35141608  0.0720816 ]]. Action = [[-1.43888295e-02 -1.32910907e-04  0.00000000e+00  5.37557602e-01]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 351 is [True, False, False, False, True, False]
Current timestep = 352. State = [[-0.35278296  0.07340892]]. Action = [[-0.0290448   0.03100079  0.         -0.9101254 ]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 352 is [True, False, False, False, True, False]
Current timestep = 353. State = [[-0.3550756  0.0693954]]. Action = [[-0.03787947 -0.0984361   0.         -0.48478913]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 353 is [True, False, False, False, True, False]
State prediction error at timestep 353 is 0.012
Human Feedback received at timestep 353 of None
Current timestep = 354. State = [[-0.35996768  0.06635852]]. Action = [[-0.08906347 -0.00326948  0.          0.7360873 ]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 354 is [True, False, False, False, True, False]
Current timestep = 355. State = [[-0.3640682   0.06679945]]. Action = [[-0.03239907  0.01451205  0.         -0.24832118]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 355 is [True, False, False, False, True, False]
State prediction error at timestep 355 is 0.012
Human Feedback received at timestep 355 of None
Current timestep = 356. State = [[-0.36242822  0.07002239]]. Action = [[0.07307122 0.06122526 0.         0.0860337 ]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 356 is [True, False, False, False, True, False]
Current timestep = 357. State = [[-0.35857967  0.06719621]]. Action = [[ 0.05739697 -0.08531006  0.          0.9602027 ]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 357 is [True, False, False, False, True, False]
Current timestep = 358. State = [[-0.35422635  0.06110889]]. Action = [[ 0.05734735 -0.06000493  0.          0.6758517 ]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 358 is [True, False, False, False, True, False]
State prediction error at timestep 358 is 0.012
Human Feedback received at timestep 358 of None
Current timestep = 359. State = [[-0.35141772  0.06028834]]. Action = [[0.02036209 0.04030734 0.         0.12570786]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 359 is [True, False, False, False, True, False]
Current timestep = 360. State = [[-0.34831643  0.06513827]]. Action = [[ 0.05384945  0.09314866  0.         -0.61892647]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 360 is [True, False, False, False, True, False]
Current timestep = 361. State = [[-0.3510981   0.07083277]]. Action = [[-0.08127633  0.06800442  0.          0.8156121 ]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 361 is [True, False, False, False, True, False]
Current timestep = 362. State = [[-0.35489887  0.07372958]]. Action = [[-0.01559198  0.01370113  0.         -0.35039037]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 362 is [True, False, False, False, True, False]
Current timestep = 363. State = [[-0.3526974   0.07196207]]. Action = [[ 0.07225939 -0.05020162  0.          0.3761872 ]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 363 is [True, False, False, False, True, False]
Current timestep = 364. State = [[-0.34882498  0.06874377]]. Action = [[ 0.04371256 -0.03554789  0.         -0.97263044]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 364 is [True, False, False, False, True, False]
Current timestep = 365. State = [[-0.34867492  0.06430349]]. Action = [[-0.03154184 -0.06682341  0.         -0.27600598]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 365 is [True, False, False, False, True, False]
Current timestep = 366. State = [[-0.34678882  0.06555623]]. Action = [[0.04600526 0.06810338 0.         0.84440506]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 366 is [True, False, False, False, True, False]
Current timestep = 367. State = [[-0.34644195  0.06345095]]. Action = [[-0.03018109 -0.07878159  0.          0.6478708 ]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 367 is [True, False, False, False, True, False]
Current timestep = 368. State = [[-0.34224492  0.06500922]]. Action = [[ 0.09539228  0.08254253  0.         -0.5728567 ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 368 is [True, False, False, False, True, False]
State prediction error at timestep 368 is 0.012
Human Feedback received at timestep 368 of None
Current timestep = 369. State = [[-0.3367227  0.0635817]]. Action = [[ 0.04097544 -0.06924746  0.          0.02762902]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 369 is [True, False, False, False, True, False]
Current timestep = 370. State = [[-0.33178395  0.06447186]]. Action = [[ 0.0486482   0.06333358  0.         -0.6584465 ]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 370 is [True, False, False, False, True, False]
Current timestep = 371. State = [[-0.33353782  0.06670264]]. Action = [[-0.0922754   0.01031687  0.          0.10843635]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 371 is [True, False, False, False, True, False]
Current timestep = 372. State = [[-0.33714998  0.06441103]]. Action = [[-0.04205335 -0.0609902   0.         -0.32867497]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 372 is [True, False, False, False, True, False]
Current timestep = 373. State = [[-0.3365799   0.06372833]]. Action = [[0.02417841 0.01743629 0.         0.37088263]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 373 is [True, False, False, False, True, False]
Current timestep = 374. State = [[-0.33432278  0.06667418]]. Action = [[0.02849316 0.05033054 0.         0.45122695]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 374 is [True, False, False, False, True, False]
Current timestep = 375. State = [[-0.33417523  0.06961629]]. Action = [[-0.01295059  0.02658694  0.         -0.46888477]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 375 is [True, False, False, False, True, False]
State prediction error at timestep 375 is 0.012
Human Feedback received at timestep 375 of None
Current timestep = 376. State = [[-0.33064598  0.06714275]]. Action = [[ 0.07793459 -0.07030288  0.         -0.7294052 ]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 376 is [True, False, False, False, True, False]
Current timestep = 377. State = [[-0.3274224   0.06780346]]. Action = [[ 0.01628248  0.05679289  0.         -0.41296673]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 377 is [True, False, False, False, True, False]
Current timestep = 378. State = [[-0.32521155  0.06506238]]. Action = [[ 0.02499916 -0.0865989   0.         -0.3394674 ]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 378 is [True, False, False, False, True, False]
Current timestep = 379. State = [[-0.32847795  0.06426197]]. Action = [[-0.09956655  0.03235096  0.         -0.5708886 ]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 379 is [True, False, False, False, True, False]
Current timestep = 380. State = [[-0.32631466  0.06185844]]. Action = [[ 0.09148902 -0.06600899  0.         -0.7401458 ]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 380 is [True, False, False, False, True, False]
Current timestep = 381. State = [[-0.32283393  0.06291752]]. Action = [[ 0.00433896  0.06511136  0.         -0.710396  ]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 381 is [True, False, False, False, True, False]
Current timestep = 382. State = [[-0.32337007  0.06148845]]. Action = [[-0.03280153 -0.06434791  0.          0.7218077 ]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 382 is [True, False, False, False, True, False]
Current timestep = 383. State = [[-0.32161453  0.05480698]]. Action = [[ 0.03060811 -0.09663288  0.         -0.47275913]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 383 is [True, False, False, False, True, False]
Current timestep = 384. State = [[-0.31505904  0.04685276]]. Action = [[ 0.09049081 -0.08724773  0.          0.09765232]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 384 is [True, False, False, False, True, False]
Current timestep = 385. State = [[-0.3140501   0.03831389]]. Action = [[-0.07005149 -0.09655289  0.          0.06793427]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 385 is [True, False, False, False, True, False]
Current timestep = 386. State = [[-0.314283    0.03753658]]. Action = [[ 0.00956962  0.07097002  0.         -0.30797338]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 386 is [True, False, False, False, True, False]
State prediction error at timestep 386 is 0.012
Human Feedback received at timestep 386 of None
Current timestep = 387. State = [[-0.3182015   0.04182135]]. Action = [[-0.09130742  0.07073156  0.         -0.82999414]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 387 is [True, False, False, False, True, False]
Current timestep = 388. State = [[-0.3237246   0.04075077]]. Action = [[-0.05873357 -0.05307183  0.          0.54345584]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 388 is [True, False, False, False, True, False]
Current timestep = 389. State = [[-0.328817   0.0417504]]. Action = [[-0.0576416   0.05809379  0.          0.0535357 ]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 389 is [True, False, False, False, True, False]
Current timestep = 390. State = [[-0.33175582  0.04330745]]. Action = [[-0.0017455   0.0031541   0.          0.12712479]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 390 is [True, False, False, False, True, False]
Current timestep = 391. State = [[-0.33310986  0.04180969]]. Action = [[ 0.00272062 -0.03047898  0.         -0.9681096 ]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 391 is [True, False, False, False, True, False]
Current timestep = 392. State = [[-0.33693156  0.039821  ]]. Action = [[-0.05441289 -0.01840308  0.         -0.70569754]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 392 is [True, False, False, False, True, False]
Current timestep = 393. State = [[-0.33597323  0.03737993]]. Action = [[ 0.07764467 -0.03144535  0.         -0.9625329 ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 393 is [True, False, False, False, True, False]
Current timestep = 394. State = [[-0.33869225  0.03394147]]. Action = [[-0.08598656 -0.04167542  0.          0.9566463 ]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 394 is [True, False, False, False, True, False]
State prediction error at timestep 394 is 0.012
Human Feedback received at timestep 394 of None
Current timestep = 395. State = [[-0.34262273  0.03099494]]. Action = [[-0.01231229 -0.02475339  0.          0.16604269]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 395 is [True, False, False, False, True, False]
Current timestep = 396. State = [[-0.34617206  0.02803189]]. Action = [[-0.04061718 -0.03182213  0.          0.74991536]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 396 is [True, False, False, False, True, False]
Current timestep = 397. State = [[-0.35088304  0.0233951 ]]. Action = [[-0.05308446 -0.06055566  0.          0.01375067]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 397 is [True, False, False, False, True, False]
Current timestep = 398. State = [[-0.35381696  0.02223618]]. Action = [[-0.00858318  0.02901501  0.          0.7597914 ]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 398 is [True, False, False, False, True, False]
Current timestep = 399. State = [[-0.35462976  0.02078272]]. Action = [[ 0.01578669 -0.02805732  0.          0.5673311 ]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 399 is [True, False, False, False, True, False]
Current timestep = 400. State = [[-0.35569826  0.01561108]]. Action = [[-0.00858404 -0.07072638  0.          0.90279615]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 400 is [True, False, False, False, True, False]
Current timestep = 401. State = [[-0.35734043  0.01271417]]. Action = [[-0.0122075   0.00387862  0.         -0.4020986 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 401 is [True, False, False, False, True, False]
State prediction error at timestep 401 is 0.012
Human Feedback received at timestep 401 of None
Current timestep = 402. State = [[-0.36203384  0.01040665]]. Action = [[-0.07188563 -0.0272503   0.         -0.3986498 ]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 402 is [True, False, False, False, True, False]
Current timestep = 403. State = [[-0.36255676  0.00824282]]. Action = [[ 0.05077463 -0.00888107  0.         -0.8169536 ]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 403 is [True, False, False, False, True, False]
Current timestep = 404. State = [[-0.3590057   0.00248029]]. Action = [[ 0.06155103 -0.08891229  0.          0.85012555]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 404 is [True, False, False, False, True, False]
Current timestep = 405. State = [[-0.35463834  0.00099126]]. Action = [[ 0.06424963  0.04745797  0.         -0.4720571 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 405 is [True, False, False, False, True, False]
State prediction error at timestep 405 is 0.012
Human Feedback received at timestep 405 of None
Current timestep = 406. State = [[-0.35239533  0.00047324]]. Action = [[ 0.01777609 -0.01467505  0.          0.31221056]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 406 is [True, False, False, False, True, False]
State prediction error at timestep 406 is 0.012
Human Feedback received at timestep 406 of None
Current timestep = 407. State = [[-3.5536486e-01 -3.6958965e-05]]. Action = [[-0.07007273  0.01543732  0.         -0.5621452 ]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 407 is [True, False, False, False, True, False]
Current timestep = 408. State = [[-0.35799628 -0.00323069]]. Action = [[-0.01275649 -0.05715167  0.          0.22244465]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 408 is [True, False, False, False, True, False]
Current timestep = 409. State = [[-0.35645148 -0.01032165]]. Action = [[ 0.0399354  -0.09178049  0.         -0.21691102]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 409 is [True, False, False, False, True, False]
Current timestep = 410. State = [[-0.35806724 -0.01914417]]. Action = [[-0.06606541 -0.09912776  0.          0.8801396 ]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 410 is [True, False, False, False, True, False]
Current timestep = 411. State = [[-0.36122864 -0.02707244]]. Action = [[-0.04080061 -0.06969124  0.          0.9302002 ]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 411 is [True, False, False, False, True, False]
Current timestep = 412. State = [[-0.3615966  -0.02644732]]. Action = [[ 0.01623962  0.09420358  0.         -0.9161777 ]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 412 is [True, False, False, False, True, False]
Current timestep = 413. State = [[-0.36021832 -0.02690069]]. Action = [[ 0.02643705 -0.04100062  0.         -0.70916575]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 413 is [True, False, False, False, True, False]
State prediction error at timestep 413 is 0.012
Human Feedback received at timestep 413 of None
Current timestep = 414. State = [[-0.36253068 -0.02762404]]. Action = [[-0.05646575  0.02577332  0.          0.9251492 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 414 is [True, False, False, False, True, False]
State prediction error at timestep 414 is 0.012
Human Feedback received at timestep 414 of None
Current timestep = 415. State = [[-0.36239523 -0.02949958]]. Action = [[ 0.04680907 -0.03598819  0.          0.98881316]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 415 is [True, False, False, False, True, False]
State prediction error at timestep 415 is 0.012
Human Feedback received at timestep 415 of None
Current timestep = 416. State = [[-0.36459813 -0.03142518]]. Action = [[-0.06226669 -0.0032639   0.         -0.4628172 ]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 416 is [True, False, False, False, True, False]
State prediction error at timestep 416 is 0.012
Human Feedback received at timestep 416 of None
Current timestep = 417. State = [[-0.36317503 -0.03211408]]. Action = [[ 0.08013058  0.00036044  0.         -0.21147603]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 417 is [True, False, False, False, True, False]
Current timestep = 418. State = [[-0.36512107 -0.03454143]]. Action = [[-0.08166286 -0.03781302  0.         -0.70637006]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 418 is [True, False, False, False, True, False]
Current timestep = 419. State = [[-0.36783186 -0.03133922]]. Action = [[0.00485333 0.0982404  0.         0.3252722 ]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 419 is [True, False, False, False, True, False]
State prediction error at timestep 419 is 0.012
Human Feedback received at timestep 419 of None
Current timestep = 420. State = [[-0.36706188 -0.02516878]]. Action = [[ 0.0420351   0.06197999  0.         -0.16977727]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 420 is [True, False, False, False, True, False]
Current timestep = 421. State = [[-0.36970407 -0.02368227]]. Action = [[-0.0509559  -0.02182326  0.          0.7509217 ]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 421 is [True, False, False, False, True, False]
Current timestep = 422. State = [[-0.36916333 -0.02340449]]. Action = [[ 0.06254528  0.0062324   0.         -0.98159015]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 422 is [True, False, False, False, True, False]
State prediction error at timestep 422 is 0.012
Human Feedback received at timestep 422 of None
Current timestep = 423. State = [[-0.36864904 -0.02126272]]. Action = [[-0.00323447  0.02758669  0.          0.7456614 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 423 is [True, False, False, False, True, False]
Current timestep = 424. State = [[-0.36515877 -0.01594013]]. Action = [[0.09256329 0.07457607 0.         0.90157545]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 424 is [True, False, False, False, True, False]
Current timestep = 425. State = [[-0.36336344 -0.01652349]]. Action = [[-0.00097075 -0.08202976  0.         -0.8076555 ]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 425 is [True, False, False, False, True, False]
State prediction error at timestep 425 is 0.012
Human Feedback received at timestep 425 of None
Current timestep = 426. State = [[-0.35994673 -0.01814227]]. Action = [[0.06958269 0.00295367 0.         0.488878  ]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 426 is [True, False, False, False, True, False]
Current timestep = 427. State = [[-0.3589651  -0.01513333]]. Action = [[-0.0228494   0.05357748  0.          0.5688182 ]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 427 is [True, False, False, False, True, False]
State prediction error at timestep 427 is 0.012
Human Feedback received at timestep 427 of None
Current timestep = 428. State = [[-0.3622025 -0.0158025]]. Action = [[-0.06203667 -0.05185557  0.         -0.68762636]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 428 is [True, False, False, False, True, False]
Current timestep = 429. State = [[-0.36155105 -0.01249103]]. Action = [[ 0.04346477  0.09320938  0.         -0.13253349]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 429 is [True, False, False, False, True, False]
Current timestep = 430. State = [[-0.3608176  -0.00825816]]. Action = [[-0.00771398  0.01826577  0.         -0.68535745]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 430 is [True, False, False, False, True, False]
State prediction error at timestep 430 is 0.012
Human Feedback received at timestep 430 of None
Current timestep = 431. State = [[-0.3580782  -0.00786435]]. Action = [[ 0.05677135 -0.02074119  0.         -0.34598404]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 431 is [True, False, False, False, True, False]
Current timestep = 432. State = [[-0.35403204 -0.00903219]]. Action = [[ 0.04193885 -0.02415978  0.         -0.7631167 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 432 is [True, False, False, False, True, False]
State prediction error at timestep 432 is 0.012
Human Feedback received at timestep 432 of None
Current timestep = 433. State = [[-0.35318196 -0.01420515]]. Action = [[-0.02686401 -0.09515855  0.          0.866186  ]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 433 is [True, False, False, False, True, False]
Current timestep = 434. State = [[-0.35655364 -0.01782571]]. Action = [[-0.08449087 -0.01299673  0.          0.6640625 ]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 434 is [True, False, False, False, True, False]
Current timestep = 435. State = [[-0.3610512  -0.02307456]]. Action = [[-0.07287253 -0.08499196  0.         -0.01479512]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 435 is [True, False, False, False, True, False]
State prediction error at timestep 435 is 0.012
Human Feedback received at timestep 435 of None
Current timestep = 436. State = [[-0.36509427 -0.02353628]]. Action = [[-0.05904313  0.05740508  0.         -0.5950826 ]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 436 is [True, False, False, False, True, False]
State prediction error at timestep 436 is 0.012
Human Feedback received at timestep 436 of None
Current timestep = 437. State = [[-0.37120637 -0.02241217]]. Action = [[-0.09654173  0.00264307  0.          0.5140873 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 437 is [True, False, False, False, True, False]
Current timestep = 438. State = [[-0.37423962 -0.02261515]]. Action = [[0.        0.        0.        0.5001869]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 438 is [True, False, False, False, True, False]
Current timestep = 439. State = [[-0.37192369 -0.02613119]]. Action = [[ 0.06668853 -0.0651292   0.          0.8095763 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 439 is [True, False, False, False, True, False]
Current timestep = 440. State = [[-0.36927092 -0.02752718]]. Action = [[ 0.03342762  0.01814346  0.         -0.2590834 ]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 440 is [True, False, False, False, True, False]
Current timestep = 441. State = [[-0.36897564 -0.02744454]]. Action = [[0.        0.        0.        0.4045037]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 441 is [True, False, False, False, True, False]
Current timestep = 442. State = [[-0.37223345 -0.02733713]]. Action = [[-0.05332578  0.0090837   0.         -0.8108663 ]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 442 is [True, False, False, False, True, False]
Current timestep = 443. State = [[-0.37450752 -0.02740416]]. Action = [[ 0.         0.         0.        -0.4437071]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 443 is [True, False, False, False, True, False]
Current timestep = 444. State = [[-0.37596697 -0.02249447]]. Action = [[-0.00712611  0.0995298   0.         -0.62653923]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 444 is [True, False, False, False, True, False]
Current timestep = 445. State = [[-0.3730843  -0.01626904]]. Action = [[ 0.09703413  0.05453553  0.         -0.4946915 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 445 is [True, False, False, False, True, False]
Current timestep = 446. State = [[-0.3728101  -0.00989246]]. Action = [[-0.01821793  0.07413789  0.          0.66037965]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 446 is [True, False, False, False, True, False]
Current timestep = 447. State = [[-0.3747597  -0.00377869]]. Action = [[ 0.00247018  0.05641594  0.         -0.25697613]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 447 is [True, False, False, False, True, False]
Current timestep = 448. State = [[-0.37777096 -0.00477185]]. Action = [[-0.0342971  -0.08106737  0.         -0.5842132 ]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 448 is [True, False, False, False, True, False]
Current timestep = 449. State = [[-0.37614483 -0.00356767]]. Action = [[0.07372297 0.05353268 0.         0.09421408]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 449 is [True, False, False, False, True, False]
Current timestep = 450. State = [[-0.3738005  -0.00470065]]. Action = [[ 0.01921485 -0.07225363  0.         -0.8079358 ]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 450 is [True, False, False, False, True, False]
Current timestep = 451. State = [[-0.37301576 -0.00606337]]. Action = [[ 0.        0.        0.       -0.043814]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 451 is [True, False, False, False, True, False]
Current timestep = 452. State = [[-0.37262186 -0.00574346]]. Action = [[0.      0.      0.      0.09428]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 452 is [True, False, False, False, True, False]
Current timestep = 453. State = [[-0.36904517 -0.00410677]]. Action = [[0.0647961 0.0260021 0.        0.7845838]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 453 is [True, False, False, False, True, False]
Current timestep = 454. State = [[-0.36544704 -0.00520116]]. Action = [[ 0.02510985 -0.04274772  0.         -0.248559  ]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 454 is [True, False, False, False, True, False]
State prediction error at timestep 454 is 0.012
Human Feedback received at timestep 454 of None
Current timestep = 455. State = [[-0.36046246 -0.0084879 ]]. Action = [[ 0.0651074  -0.04124139  0.         -0.12591517]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 455 is [True, False, False, False, True, False]
Current timestep = 456. State = [[-0.36166593 -0.01179615]]. Action = [[-0.097564   -0.03393858  0.         -0.76892203]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 456 is [True, False, False, False, True, False]
Current timestep = 457. State = [[-0.36400566 -0.01296987]]. Action = [[-0.01558197  0.00778686  0.          0.6488712 ]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 457 is [True, False, False, False, True, False]
Current timestep = 458. State = [[-0.36649442 -0.01502165]]. Action = [[-0.05210643 -0.03358372  0.         -0.6983514 ]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 458 is [True, False, False, False, True, False]
Current timestep = 459. State = [[-0.37181425 -0.01598896]]. Action = [[-0.08981835  0.01250692  0.         -0.62494725]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 459 is [True, False, False, False, True, False]
Current timestep = 460. State = [[-0.3711537  -0.01985288]]. Action = [[ 0.07024831 -0.07263957  0.          0.6815803 ]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 460 is [True, False, False, False, True, False]
State prediction error at timestep 460 is 0.012
Human Feedback received at timestep 460 of None
Current timestep = 461. State = [[-0.36530036 -0.01899508]]. Action = [[0.08062708 0.07491467 0.         0.7849951 ]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 461 is [True, False, False, False, True, False]
Current timestep = 462. State = [[-0.36115003 -0.02009026]]. Action = [[ 0.03488613 -0.05896032  0.         -0.9389544 ]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 462 is [True, False, False, False, True, False]
Current timestep = 463. State = [[-0.3580634  -0.02014936]]. Action = [[0.03403526 0.03993172 0.         0.9115062 ]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 463 is [True, False, False, False, True, False]
Current timestep = 464. State = [[-0.35806975 -0.02201936]]. Action = [[-0.0270206  -0.05123943  0.         -0.50400436]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 464 is [True, False, False, False, True, False]
Current timestep = 465. State = [[-0.3561234 -0.0218802]]. Action = [[0.04615731 0.04132345 0.         0.290493  ]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 465 is [True, False, False, False, True, False]
State prediction error at timestep 465 is 0.012
Human Feedback received at timestep 465 of None
Current timestep = 466. State = [[-0.3538775  -0.02124474]]. Action = [[ 0.01622567 -0.00485907  0.         -0.45286238]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 466 is [True, False, False, False, True, False]
State prediction error at timestep 466 is 0.012
Human Feedback received at timestep 466 of None
Current timestep = 467. State = [[-0.35010576 -0.02434914]]. Action = [[ 0.05855576 -0.05541181  0.          0.9220178 ]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 467 is [True, False, False, False, True, False]
Current timestep = 468. State = [[-0.35172835 -0.02462105]]. Action = [[-8.5717276e-02  3.6575012e-02  0.0000000e+00  3.2782555e-05]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 468 is [True, False, False, False, True, False]
Current timestep = 469. State = [[-0.35857943 -0.02379132]]. Action = [[-0.09894673  0.00388857  0.         -0.03090715]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 469 is [True, False, False, False, True, False]
State prediction error at timestep 469 is 0.012
Human Feedback received at timestep 469 of None
Current timestep = 470. State = [[-0.35896584 -0.02553253]]. Action = [[ 0.05917346 -0.03557009  0.          0.50279486]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 470 is [True, False, False, False, True, False]
Current timestep = 471. State = [[-0.35410348 -0.02522254]]. Action = [[0.06771555 0.0289024  0.         0.06915569]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 471 is [True, False, False, False, True, False]
Current timestep = 472. State = [[-0.34826264 -0.02655763]]. Action = [[ 0.07767337 -0.04328289  0.          0.86710835]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 472 is [True, False, False, False, True, False]
Current timestep = 473. State = [[-0.34902227 -0.03194844]]. Action = [[-0.08001698 -0.07751729  0.         -0.4200771 ]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 473 is [True, False, False, False, True, False]
State prediction error at timestep 473 is 0.012
Human Feedback received at timestep 473 of None
Current timestep = 474. State = [[-0.35164714 -0.03510323]]. Action = [[-0.02025385 -0.00455423  0.          0.59956586]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 474 is [True, False, False, False, True, False]
Current timestep = 475. State = [[-0.35388842 -0.03994995]]. Action = [[-0.03874698 -0.0768189   0.          0.22140479]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 475 is [True, False, False, False, True, False]
Current timestep = 476. State = [[-0.3557677  -0.03897161]]. Action = [[-0.01856872  0.08578249  0.          0.17878878]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 476 is [True, False, False, False, True, False]
Current timestep = 477. State = [[-0.35947764 -0.03525948]]. Action = [[-0.05779477  0.03662264  0.          0.28349924]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 477 is [True, False, False, False, True, False]
Current timestep = 478. State = [[-0.36059168 -0.03911236]]. Action = [[ 0.02176622 -0.09590584  0.         -0.93396616]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 478 is [True, False, False, False, True, False]
Current timestep = 479. State = [[-0.3571765  -0.04035413]]. Action = [[ 0.07070523  0.03852307  0.         -0.90368253]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 479 is [True, False, False, False, True, False]
Current timestep = 480. State = [[-0.3539942  -0.03840404]]. Action = [[ 0.03695448  0.01963146  0.         -0.05145156]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 480 is [True, False, False, False, True, False]
Current timestep = 481. State = [[-0.35481778 -0.0380028 ]]. Action = [[-0.02984937 -0.00442631  0.         -0.39157444]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 481 is [True, False, False, False, True, False]
State prediction error at timestep 481 is 0.012
Human Feedback received at timestep 481 of None
Current timestep = 482. State = [[-0.35992298 -0.04180792]]. Action = [[-0.08403208 -0.06928013  0.         -0.65935105]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 482 is [True, False, False, False, True, False]
Current timestep = 483. State = [[-0.3583227  -0.04082463]]. Action = [[ 0.0970461   0.07717503  0.         -0.646887  ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 483 is [True, False, False, False, True, False]
Current timestep = 484. State = [[-0.35792738 -0.03501464]]. Action = [[-0.03947439  0.06930763  0.         -0.07366562]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 484 is [True, False, False, False, True, False]
Current timestep = 485. State = [[-0.3634047  -0.02942301]]. Action = [[-0.08212     0.06020498  0.         -0.70521474]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 485 is [True, False, False, False, True, False]
Current timestep = 486. State = [[-0.36764738 -0.02792026]]. Action = [[-0.02526207 -0.02032774  0.         -0.6612668 ]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 486 is [True, False, False, False, True, False]
Current timestep = 487. State = [[-0.36533844 -0.02460698]]. Action = [[0.08378346 0.05852631 0.         0.6093693 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 487 is [True, False, False, False, True, False]
Current timestep = 488. State = [[-0.36352214 -0.01770848]]. Action = [[ 0.01520833  0.07900851  0.         -0.1810801 ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 488 is [True, False, False, False, True, False]
Current timestep = 489. State = [[-0.3603081  -0.01620639]]. Action = [[ 0.07807096 -0.04503169  0.         -0.40708613]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 489 is [True, False, False, False, True, False]
Current timestep = 490. State = [[-0.35593188 -0.01393763]]. Action = [[ 0.0590279   0.0456939   0.         -0.23237932]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 490 is [True, False, False, False, True, False]
State prediction error at timestep 490 is 0.012
Human Feedback received at timestep 490 of None
Current timestep = 491. State = [[-0.35123056 -0.01221474]]. Action = [[ 0.06803065 -0.01247806  0.         -0.24252224]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 491 is [True, False, False, False, True, False]
State prediction error at timestep 491 is 0.012
Human Feedback received at timestep 491 of None
Current timestep = 492. State = [[-0.3488468  -0.00911761]]. Action = [[ 0.0067096   0.04962393  0.         -0.35204238]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 492 is [True, False, False, False, True, False]
Current timestep = 493. State = [[-0.34804687 -0.00371094]]. Action = [[ 0.00767819  0.06155092  0.         -0.71714187]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 493 is [True, False, False, False, True, False]
State prediction error at timestep 493 is 0.012
Human Feedback received at timestep 493 of None
Current timestep = 494. State = [[-0.34777334 -0.00467709]]. Action = [[-0.007531   -0.07783411  0.         -0.20175159]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 494 is [True, False, False, False, True, False]
Current timestep = 495. State = [[-0.34593    -0.00511225]]. Action = [[0.0216864  0.01927565 0.         0.06876302]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 495 is [True, False, False, False, True, False]
Current timestep = 496. State = [[-0.3411484  -0.00762919]]. Action = [[ 0.06128144 -0.07179403  0.         -0.14420271]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 496 is [True, False, False, False, True, False]
Current timestep = 497. State = [[-0.3335483  -0.01037903]]. Action = [[ 0.08788811 -0.01873811  0.         -0.15000159]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 497 is [True, False, False, False, True, False]
State prediction error at timestep 497 is 0.012
Human Feedback received at timestep 497 of None
Current timestep = 498. State = [[-0.32442904 -0.01510521]]. Action = [[ 0.09660014 -0.07947445  0.         -0.6509905 ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 498 is [True, False, False, False, True, False]
Current timestep = 499. State = [[-0.3185898 -0.0138087]]. Action = [[ 0.01835684  0.08355958  0.         -0.0060041 ]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 499 is [True, False, False, False, True, False]
State prediction error at timestep 499 is 0.012
Human Feedback received at timestep 499 of None
Current timestep = 500. State = [[-0.3155643 -0.0127812]]. Action = [[ 0.00889243 -0.01560266  0.         -0.44918495]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 500 is [True, False, False, False, True, False]
Current timestep = 501. State = [[-0.3117886  -0.01219181]]. Action = [[0.03274115 0.02789339 0.         0.17022693]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 501 is [True, False, False, False, True, False]
State prediction error at timestep 501 is 0.012
Human Feedback received at timestep 501 of None
Current timestep = 502. State = [[-0.30433345 -0.01471975]]. Action = [[ 0.09677943 -0.05883095  0.          0.52146196]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 502 is [True, False, False, False, True, False]
Current timestep = 503. State = [[-0.29726344 -0.01346912]]. Action = [[ 0.05006734  0.0680356   0.         -0.11701512]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 503 is [True, False, False, False, True, False]
Current timestep = 504. State = [[-0.2968267  -0.00867416]]. Action = [[-0.05686605  0.06343009  0.          0.72881794]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 504 is [True, False, False, False, True, False]
State prediction error at timestep 504 is 0.012
Human Feedback received at timestep 504 of None
Current timestep = 505. State = [[-0.29935804 -0.00833182]]. Action = [[-0.0522093  -0.03428001  0.          0.7778163 ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 505 is [True, False, False, False, True, False]
Current timestep = 506. State = [[-0.30065563 -0.01004042]]. Action = [[-0.02516241 -0.02094136  0.          0.774933  ]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 506 is [True, False, False, False, True, False]
State prediction error at timestep 506 is 0.012
Human Feedback received at timestep 506 of None
Current timestep = 507. State = [[-0.3012351  -0.00662718]]. Action = [[-0.01832598  0.07522105  0.          0.9059336 ]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 507 is [True, False, False, False, True, False]
Current timestep = 508. State = [[-0.3022851  -0.00657017]]. Action = [[-0.02457923 -0.05363314  0.         -0.37792307]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 508 is [True, False, False, False, True, False]
State prediction error at timestep 508 is 0.012
Human Feedback received at timestep 508 of None
Current timestep = 509. State = [[-0.298169   -0.00527446]]. Action = [[ 0.09021027  0.04537129  0.         -0.7929649 ]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 509 is [True, False, False, False, True, False]
Current timestep = 510. State = [[-0.29081568 -0.00804586]]. Action = [[ 0.09514385 -0.08907235  0.          0.21174324]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 510 is [True, False, False, False, True, False]
State prediction error at timestep 510 is 0.012
Human Feedback received at timestep 510 of None
Current timestep = 511. State = [[-0.28375793 -0.01167461]]. Action = [[ 0.07141203 -0.02215929  0.         -0.3633207 ]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 511 is [True, False, False, False, True, False]
Current timestep = 512. State = [[-0.2768659  -0.01540359]]. Action = [[ 0.07312217 -0.05264485  0.          0.7472129 ]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 512 is [True, False, False, False, True, False]
Current timestep = 513. State = [[-0.27174598 -0.02098797]]. Action = [[ 0.02823288 -0.06740317  0.          0.34089684]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 513 is [True, False, False, False, True, False]
Current timestep = 514. State = [[-0.27271053 -0.02329177]]. Action = [[-0.07947282  0.01395305  0.         -0.17455852]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 514 is [True, False, False, False, True, False]
Current timestep = 515. State = [[-0.27561834 -0.02207148]]. Action = [[-0.05044181  0.03792246  0.         -0.8972438 ]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 515 is [True, False, False, False, True, False]
Current timestep = 516. State = [[-0.2777929  -0.02096176]]. Action = [[-0.03518949  0.01352175  0.         -0.97962   ]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 516 is [True, False, False, False, True, False]
Current timestep = 517. State = [[-0.27607745 -0.0182357 ]]. Action = [[ 0.04667943  0.05283295  0.         -0.28167975]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 517 is [True, False, False, False, True, False]
State prediction error at timestep 517 is 0.012
Human Feedback received at timestep 517 of None
Current timestep = 518. State = [[-0.27860162 -0.02015806]]. Action = [[-0.08400543 -0.0681702   0.          0.69756424]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 518 is [True, False, False, False, True, False]
State prediction error at timestep 518 is 0.012
Human Feedback received at timestep 518 of None
Current timestep = 519. State = [[-0.2847086  -0.01990137]]. Action = [[-0.08410473  0.0457414   0.         -0.5958358 ]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 519 is [True, False, False, False, True, False]
Current timestep = 520. State = [[-0.28436303 -0.01420439]]. Action = [[0.07279556 0.08518731 0.         0.5744257 ]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 520 is [True, False, False, False, True, False]
Current timestep = 521. State = [[-0.279889  -0.0130615]]. Action = [[ 0.06899785 -0.03888924  0.         -0.8461533 ]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 521 is [True, False, False, False, True, False]
Current timestep = 522. State = [[-0.27453417 -0.01222679]]. Action = [[0.07923584 0.02884784 0.         0.8008146 ]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 522 is [True, False, False, False, True, False]
Current timestep = 523. State = [[-0.2767679  -0.01078712]]. Action = [[-0.09534995  0.00646478  0.         -0.17469162]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 523 is [True, False, False, False, True, False]
Current timestep = 524. State = [[-0.27805558 -0.01344612]]. Action = [[ 0.03655665 -0.06649028  0.         -0.7645536 ]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 524 is [True, False, False, False, True, False]
Current timestep = 525. State = [[-0.27278507 -0.01849844]]. Action = [[ 0.09522197 -0.06534435  0.          0.04693067]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 525 is [True, False, False, False, True, False]
Current timestep = 526. State = [[-0.2716514  -0.02247132]]. Action = [[-0.03905302 -0.03439987  0.         -0.47537816]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 526 is [True, False, False, False, True, False]
Current timestep = 527. State = [[-0.2750944  -0.02159462]]. Action = [[-0.05733531  0.04862375  0.          0.57581973]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 527 is [True, False, False, False, True, False]
State prediction error at timestep 527 is 0.012
Human Feedback received at timestep 527 of None
Current timestep = 528. State = [[-0.2758942  -0.02198901]]. Action = [[ 0.01642083 -0.02727268  0.          0.18196094]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 528 is [True, False, False, False, True, False]
State prediction error at timestep 528 is 0.012
Human Feedback received at timestep 528 of None
Current timestep = 529. State = [[-0.27123109 -0.01981958]]. Action = [[0.09173387 0.06541219 0.         0.7012117 ]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 529 is [True, False, False, False, True, False]
State prediction error at timestep 529 is 0.012
Human Feedback received at timestep 529 of None
Current timestep = 530. State = [[-0.27252817 -0.01326063]]. Action = [[-0.07461113  0.09856474  0.         -0.6181594 ]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 530 is [True, False, False, False, True, False]
State prediction error at timestep 530 is 0.012
Human Feedback received at timestep 530 of None
Current timestep = 531. State = [[-0.2791811  -0.01300683]]. Action = [[-0.08068784 -0.05981946  0.         -0.479398  ]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 531 is [True, False, False, False, True, False]
Current timestep = 532. State = [[-0.28011525 -0.01224999]]. Action = [[0.04585969 0.04062837 0.         0.1331358 ]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 532 is [True, False, False, False, True, False]
Current timestep = 533. State = [[-0.280181  -0.0129002]]. Action = [[-0.00960327 -0.04289803  0.          0.34462285]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 533 is [True, False, False, False, True, False]
State prediction error at timestep 533 is 0.012
Human Feedback received at timestep 533 of None
Current timestep = 534. State = [[-0.28509364 -0.01570145]]. Action = [[-0.09030557 -0.03809397  0.         -0.5598222 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 534 is [True, False, False, False, True, False]
Current timestep = 535. State = [[-0.28632888 -0.02116225]]. Action = [[ 0.02972492 -0.08811817  0.          0.572804  ]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 535 is [True, False, False, False, True, False]
Current timestep = 536. State = [[-0.28161168 -0.02445582]]. Action = [[ 0.08292889 -0.00729389  0.          0.77230334]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 536 is [True, False, False, False, True, False]
State prediction error at timestep 536 is 0.012
Human Feedback received at timestep 536 of None
Current timestep = 537. State = [[-0.2759639  -0.02219441]]. Action = [[ 0.07094084  0.06247955  0.         -0.9806415 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 537 is [True, False, False, False, True, False]
Current timestep = 538. State = [[-0.27226794 -0.0257423 ]]. Action = [[ 0.03295118 -0.09910754  0.         -0.5560324 ]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 538 is [True, False, False, False, True, False]
Current timestep = 539. State = [[-0.27106643 -0.03291993]]. Action = [[-0.00840111 -0.07207593  0.         -0.2840904 ]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 539 is [True, False, False, False, True, False]
State prediction error at timestep 539 is 0.012
Human Feedback received at timestep 539 of None
Current timestep = 540. State = [[-0.2671132  -0.03253854]]. Action = [[ 0.07145392  0.07542294  0.         -0.42179275]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 540 is [True, False, False, False, True, False]
Current timestep = 541. State = [[-0.2677481  -0.02890852]]. Action = [[-0.06320062  0.05031686  0.         -0.83937025]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 541 is [True, False, False, False, True, False]
Current timestep = 542. State = [[-0.268281   -0.03220133]]. Action = [[ 0.01695845 -0.0847486   0.          0.9404931 ]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 542 is [True, False, False, False, True, False]
State prediction error at timestep 542 is 0.012
Human Feedback received at timestep 542 of None
Current timestep = 543. State = [[-0.26386905 -0.03617106]]. Action = [[ 0.07367922 -0.01790107  0.         -0.4721111 ]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 543 is [True, False, False, False, True, False]
State prediction error at timestep 543 is 0.012
Human Feedback received at timestep 543 of None
Current timestep = 544. State = [[-0.26308757 -0.03378585]]. Action = [[-0.03570401  0.07485887  0.          0.67991495]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 544 is [True, False, False, False, True, False]
Current timestep = 545. State = [[-0.26428685 -0.03576398]]. Action = [[-0.01100727 -0.07426924  0.          0.47194982]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 545 is [True, False, False, False, True, False]
Current timestep = 546. State = [[-0.2663965  -0.03477238]]. Action = [[-0.04275542  0.06937578  0.         -0.33416986]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 546 is [True, False, False, False, True, False]
Current timestep = 547. State = [[-0.26972646 -0.0376833 ]]. Action = [[-0.04833544 -0.09379338  0.          0.6217084 ]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 547 is [True, False, False, False, True, False]
Current timestep = 548. State = [[-0.26706025 -0.03699269]]. Action = [[0.08352182 0.07422017 0.         0.40902376]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 548 is [True, False, False, False, True, False]
Current timestep = 549. State = [[-0.26641232 -0.03173151]]. Action = [[-0.02799673  0.06321978  0.         -0.9365571 ]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 549 is [True, False, False, False, True, False]
State prediction error at timestep 549 is 0.012
Human Feedback received at timestep 549 of None
Current timestep = 550. State = [[-0.27009398 -0.02860031]]. Action = [[-0.05512981  0.01656814  0.         -0.13116324]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 550 is [True, False, False, False, True, False]
Current timestep = 551. State = [[-0.27364    -0.02457525]]. Action = [[-0.03146157  0.05766477  0.         -0.41768026]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 551 is [True, False, False, False, True, False]
Current timestep = 552. State = [[-0.2768945  -0.02016857]]. Action = [[-0.03157199  0.03697485  0.         -0.23048872]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 552 is [True, False, False, False, True, False]
State prediction error at timestep 552 is 0.012
Human Feedback received at timestep 552 of None
Current timestep = 553. State = [[-0.27839223 -0.02001485]]. Action = [[ 0.00421421 -0.04098063  0.         -0.13289559]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 553 is [True, False, False, False, True, False]
Current timestep = 554. State = [[-0.27572387 -0.0154603 ]]. Action = [[ 0.0723364   0.09494751  0.         -0.6156328 ]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 554 is [True, False, False, False, True, False]
Current timestep = 555. State = [[-0.27531043 -0.01097677]]. Action = [[-0.00902926  0.01379089  0.          0.25241554]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 555 is [True, False, False, False, True, False]
Current timestep = 556. State = [[-0.27923396 -0.01376125]]. Action = [[-0.06451979 -0.08811558  0.         -0.21468842]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 556 is [True, False, False, False, True, False]
State prediction error at timestep 556 is 0.012
Human Feedback received at timestep 556 of None
Current timestep = 557. State = [[-0.27983892 -0.01252169]]. Action = [[ 0.03168794  0.06054413  0.         -0.7844381 ]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 557 is [True, False, False, False, True, False]
Current timestep = 558. State = [[-0.27675503 -0.01283146]]. Action = [[ 0.05601392 -0.05366596  0.         -0.17573798]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 558 is [True, False, False, False, True, False]
Current timestep = 559. State = [[-0.27256146 -0.01841672]]. Action = [[ 0.05176198 -0.09039542  0.         -0.8369373 ]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 559 is [True, False, False, False, True, False]
Current timestep = 560. State = [[-0.272357   -0.01893458]]. Action = [[-0.03837786  0.04526607  0.          0.9375632 ]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 560 is [True, False, False, False, True, False]
Current timestep = 561. State = [[-0.27361596 -0.01735302]]. Action = [[-0.01419838  0.01155837  0.         -0.05836856]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 561 is [True, False, False, False, True, False]
Current timestep = 562. State = [[-0.27496618 -0.01729573]]. Action = [[-0.02549524 -0.00402541  0.         -0.59274405]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 562 is [True, False, False, False, True, False]
Current timestep = 563. State = [[-0.271025   -0.01745674]]. Action = [[ 0.09274534  0.00180402  0.         -0.06339782]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 563 is [True, False, False, False, True, False]
Current timestep = 564. State = [[-0.26469773 -0.0144986 ]]. Action = [[0.07493392 0.06214013 0.         0.3664478 ]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 564 is [True, False, False, False, True, False]
Current timestep = 565. State = [[-0.26128608 -0.00963916]]. Action = [[ 0.02352931  0.06240831  0.         -0.92032325]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 565 is [True, False, False, False, True, False]
Current timestep = 566. State = [[-0.2604174  -0.00797035]]. Action = [[-0.00052937 -0.00813042  0.         -0.08056515]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 566 is [True, False, False, False, True, False]
State prediction error at timestep 566 is 0.012
Human Feedback received at timestep 566 of None
Current timestep = 567. State = [[-0.25766915 -0.00637053]]. Action = [[0.04875293 0.02897847 0.         0.5677208 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 567 is [True, False, False, False, True, False]
Current timestep = 568. State = [[-0.2568008  -0.00354476]]. Action = [[-0.01737469  0.03130656  0.         -0.34987712]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 568 is [True, False, False, False, True, False]
Current timestep = 569. State = [[-0.25288486  0.00210826]]. Action = [[0.08407217 0.08135977 0.         0.7516494 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 569 is [True, False, False, False, True, False]
Current timestep = 570. State = [[-0.2496395   0.00391504]]. Action = [[ 0.01385465 -0.02873067  0.         -0.23393238]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 570 is [True, False, False, False, True, False]
Current timestep = 571. State = [[-0.24736258  0.00353103]]. Action = [[ 0.02122394 -0.01085789  0.          0.7352762 ]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 571 is [True, False, False, False, True, False]
Current timestep = 572. State = [[-0.24394232  0.00872532]]. Action = [[0.0414579  0.09466485 0.         0.7069384 ]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 572 is [True, False, False, False, True, False]
Current timestep = 573. State = [[-0.24584277  0.01168407]]. Action = [[-0.07910393 -0.01579689  0.          0.6663703 ]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 573 is [True, False, False, False, True, False]
Current timestep = 574. State = [[-0.24677375  0.00948821]]. Action = [[ 0.00518954 -0.06085864  0.          0.27689946]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 574 is [True, False, False, False, True, False]
Current timestep = 575. State = [[-0.24625765  0.00982579]]. Action = [[-0.01019163  0.02436092  0.          0.74184394]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 575 is [True, False, False, False, True, False]
Current timestep = 576. State = [[-0.24884538  0.01496054]]. Action = [[-0.06154616  0.0736055   0.         -0.4359668 ]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 576 is [True, False, False, False, True, False]
Current timestep = 577. State = [[-0.25310922  0.01597123]]. Action = [[-0.06189437 -0.04429758  0.          0.48023248]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 577 is [True, False, False, False, True, False]
Current timestep = 578. State = [[-0.25508207  0.01772076]]. Action = [[-0.01082579  0.03918456  0.         -0.76718426]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 578 is [True, False, False, False, True, False]
Current timestep = 579. State = [[-0.2537238   0.02315344]]. Action = [[ 0.04097646  0.06950911  0.         -0.5215869 ]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 579 is [True, False, False, False, True, False]
Current timestep = 580. State = [[-0.25583217  0.0212787 ]]. Action = [[-0.06010491 -0.09955843  0.         -0.52445275]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 580 is [True, False, False, False, True, False]
Current timestep = 581. State = [[-0.25535375  0.02176954]]. Action = [[ 0.04876661  0.05430878  0.         -0.16657639]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 581 is [True, False, False, False, True, False]
Current timestep = 582. State = [[-0.2532035   0.02051496]]. Action = [[ 0.0254392  -0.06244842  0.          0.7543514 ]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 582 is [True, False, False, False, True, False]
Current timestep = 583. State = [[-0.2563798   0.02357755]]. Action = [[-0.07820434  0.0916147   0.         -0.16540015]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 583 is [True, False, False, False, True, False]
State prediction error at timestep 583 is 0.012
Human Feedback received at timestep 583 of None
Current timestep = 584. State = [[-0.25695145  0.02873274]]. Action = [[0.04580378 0.04355856 0.         0.53009677]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 584 is [True, False, False, False, True, False]
Current timestep = 585. State = [[-0.2563031   0.02776927]]. Action = [[ 0.00155725 -0.05694128  0.         -0.6675591 ]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 585 is [True, False, False, False, True, False]
State prediction error at timestep 585 is 0.012
Human Feedback received at timestep 585 of None
Current timestep = 586. State = [[-0.25615904  0.02635727]]. Action = [[ 0.00535686 -0.0031271   0.         -0.9825558 ]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 586 is [True, False, False, False, True, False]
Current timestep = 587. State = [[-0.2588669   0.02545676]]. Action = [[-0.05737407 -0.01963631  0.          0.19064772]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 587 is [True, False, False, False, True, False]
Current timestep = 588. State = [[-0.25999707  0.02131033]]. Action = [[ 0.00677641 -0.0752698   0.         -0.74670553]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 588 is [True, False, False, False, True, False]
Current timestep = 589. State = [[-0.2575609   0.02012744]]. Action = [[0.04468635 0.0248066  0.         0.48469043]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 589 is [True, False, False, False, True, False]
State prediction error at timestep 589 is 0.012
Human Feedback received at timestep 589 of None
Current timestep = 590. State = [[-0.26077437  0.02523034]]. Action = [[-0.09052147  0.09564602  0.          0.5644152 ]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 590 is [True, False, False, False, True, False]
Current timestep = 591. State = [[-0.26703435  0.02892298]]. Action = [[-0.06523684  0.01513074  0.          0.4672519 ]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 591 is [True, False, False, False, True, False]
State prediction error at timestep 591 is 0.012
Human Feedback received at timestep 591 of None
Current timestep = 592. State = [[-0.27085572  0.02838492]]. Action = [[-0.02196235 -0.03009898  0.         -0.02628273]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 592 is [True, False, False, False, True, False]
State prediction error at timestep 592 is 0.012
Human Feedback received at timestep 592 of None
Current timestep = 593. State = [[-0.27327678  0.02652793]]. Action = [[-0.01901784 -0.02627609  0.          0.9892664 ]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 593 is [True, False, False, False, True, False]
Current timestep = 594. State = [[-0.27765986  0.02205031]]. Action = [[-0.06477769 -0.07747892  0.          0.07841158]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 594 is [True, False, False, False, True, False]
Current timestep = 595. State = [[-0.27889654  0.02221403]]. Action = [[ 0.02720527  0.05066619  0.         -0.49601126]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 595 is [True, False, False, False, True, False]
Current timestep = 596. State = [[-0.28080517  0.02793507]]. Action = [[-0.0278063   0.08954474  0.          0.9023584 ]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 596 is [True, False, False, False, True, False]
Current timestep = 597. State = [[-0.28768024  0.0328663 ]]. Action = [[-0.09457643  0.04094883  0.         -0.36075795]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 597 is [True, False, False, False, True, False]
Current timestep = 598. State = [[-0.2923779   0.03463099]]. Action = [[-0.00857156 -0.00180315  0.         -0.37717366]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 598 is [True, False, False, False, True, False]
State prediction error at timestep 598 is 0.012
Human Feedback received at timestep 598 of None
Current timestep = 599. State = [[-0.29548323  0.03669645]]. Action = [[-0.02096254  0.03001337  0.         -0.4948995 ]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 599 is [True, False, False, False, True, False]
Current timestep = 600. State = [[-0.2994953   0.04153017]]. Action = [[-0.03135657  0.06714403  0.          0.8964596 ]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 600 is [True, False, False, False, True, False]
State prediction error at timestep 600 is 0.012
Human Feedback received at timestep 600 of None
Current timestep = 601. State = [[-0.30363512  0.04334921]]. Action = [[-0.02650841 -0.01908581  0.         -0.8332626 ]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 601 is [True, False, False, False, True, False]
Current timestep = 602. State = [[-0.310675    0.03985796]]. Action = [[-0.09784143 -0.07845176  0.         -0.53988665]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 602 is [True, False, False, False, True, False]
Current timestep = 603. State = [[-0.31191745  0.03708103]]. Action = [[ 0.06057393 -0.02128365  0.          0.02834129]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 603 is [True, False, False, False, True, False]
Current timestep = 604. State = [[-0.30685377  0.03752916]]. Action = [[0.09332841 0.02251764 0.         0.6058736 ]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 604 is [True, False, False, False, True, False]
Current timestep = 605. State = [[-0.3069631   0.04168737]]. Action = [[-0.04041376  0.07312278  0.          0.3625015 ]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 605 is [True, False, False, False, True, False]
Current timestep = 606. State = [[-0.3092593  0.0434051]]. Action = [[-0.00737274 -0.01076124  0.          0.25468063]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 606 is [True, False, False, False, True, False]
Current timestep = 607. State = [[-0.30830842  0.04489248]]. Action = [[0.04117803 0.03161114 0.         0.14701807]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 607 is [True, False, False, False, True, False]
Current timestep = 608. State = [[-0.31256992  0.05093611]]. Action = [[-0.09439955  0.09989469  0.          0.16068304]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 608 is [True, False, False, False, True, False]
State prediction error at timestep 608 is 0.012
Human Feedback received at timestep 608 of None
Current timestep = 609. State = [[-0.31322205  0.05249938]]. Action = [[ 0.06396099 -0.03718161  0.          0.05816877]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 609 is [True, False, False, False, True, False]
State prediction error at timestep 609 is 0.012
Human Feedback received at timestep 609 of None
Current timestep = 610. State = [[-0.31602365  0.05671987]]. Action = [[-0.07346742  0.0928702   0.         -0.72642225]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 610 is [True, False, False, False, True, False]
Current timestep = 611. State = [[-0.31880125  0.0560474 ]]. Action = [[ 8.422509e-04 -8.657336e-02  0.000000e+00  8.458307e-01]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 611 is [True, False, False, False, True, False]
Current timestep = 612. State = [[-0.32035443  0.05879143]]. Action = [[-0.01633822  0.0903812   0.         -0.06595856]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 612 is [True, False, False, False, True, False]
Current timestep = 613. State = [[-0.32594004  0.06590664]]. Action = [[-0.08356193  0.07509466  0.         -0.32690245]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 613 is [True, False, False, False, True, False]
Current timestep = 614. State = [[-0.32855278  0.06892443]]. Action = [[ 0.01903339 -0.00937527  0.          0.22672677]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 614 is [True, False, False, False, True, False]
Current timestep = 615. State = [[-0.32675317  0.06700051]]. Action = [[ 0.04779836 -0.0562859   0.          0.3957746 ]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 615 is [True, False, False, False, True, False]
Current timestep = 616. State = [[-0.32326186  0.0627378 ]]. Action = [[ 0.05110728 -0.06561787  0.          0.7569829 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 616 is [True, False, False, False, True, False]
Current timestep = 617. State = [[-0.31771925  0.06577571]]. Action = [[ 0.0856423   0.09938668  0.         -0.47485673]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 617 is [True, False, False, False, True, False]
Current timestep = 618. State = [[-0.31088468  0.07001226]]. Action = [[ 0.09350535  0.03010996  0.         -0.97987205]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 618 is [True, False, False, False, True, False]
Current timestep = 619. State = [[-0.30608544  0.07288335]]. Action = [[0.03684215 0.03804659 0.         0.23448598]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 619 is [True, False, False, False, True, False]
Current timestep = 620. State = [[-0.29945707  0.07547291]]. Action = [[0.09896632 0.02823228 0.         0.98905706]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 620 is [True, False, False, False, True, False]
Current timestep = 621. State = [[-0.2919476   0.07665011]]. Action = [[ 0.07467472  0.00581938  0.         -0.9938354 ]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 621 is [True, False, False, False, True, False]
State prediction error at timestep 621 is 0.012
Human Feedback received at timestep 621 of None
Current timestep = 622. State = [[-0.28833032  0.08182313]]. Action = [[0.00098898 0.0966697  0.         0.7894455 ]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 622 is [True, False, False, False, True, False]
State prediction error at timestep 622 is 0.012
Human Feedback received at timestep 622 of None
Current timestep = 623. State = [[-0.28838745  0.08233249]]. Action = [[-0.03582539 -0.05948996  0.          0.44535136]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 623 is [True, False, False, False, True, False]
State prediction error at timestep 623 is 0.012
Human Feedback received at timestep 623 of None
Current timestep = 624. State = [[-0.28790188  0.08504312]]. Action = [[-0.00566722  0.06642725  0.          0.6773325 ]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 624 is [True, False, False, False, True, False]
Current timestep = 625. State = [[-0.2887475   0.08585394]]. Action = [[-0.04299963 -0.04385731  0.         -0.15665197]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 625 is [True, False, False, False, True, False]
Current timestep = 626. State = [[-0.28472573  0.0867622 ]]. Action = [[0.0787892  0.01992594 0.         0.95648146]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 626 is [True, False, False, False, True, False]
State prediction error at timestep 626 is 0.012
Human Feedback received at timestep 626 of None
Current timestep = 627. State = [[-0.27680382  0.08984698]]. Action = [[ 0.08844181  0.03697538  0.         -0.3434568 ]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 627 is [True, False, False, False, True, False]
State prediction error at timestep 627 is 0.012
Human Feedback received at timestep 627 of None
Current timestep = 628. State = [[-0.27504358  0.08794054]]. Action = [[-0.05698236 -0.07727917  0.         -0.55647093]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 628 is [True, False, False, False, True, False]
Current timestep = 629. State = [[-0.27263018  0.08825719]]. Action = [[ 0.05094697  0.03670716  0.         -0.05748993]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 629 is [True, False, False, False, True, False]
Current timestep = 630. State = [[-0.27281475  0.09410542]]. Action = [[-0.05336151  0.08737039  0.         -0.03152585]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 630 is [True, False, False, False, True, False]
Current timestep = 631. State = [[-0.2722451   0.09800951]]. Action = [[0.02723116 0.01036346 0.         0.4979713 ]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 631 is [True, False, False, False, True, False]
Current timestep = 632. State = [[-0.27039927  0.10413948]]. Action = [[0.01595028 0.09896594 0.         0.42594278]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 632 is [True, False, False, False, True, False]
Current timestep = 633. State = [[-0.27242014  0.10602239]]. Action = [[-0.05523187 -0.04066811  0.         -0.12818384]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 633 is [True, False, False, False, True, False]
State prediction error at timestep 633 is 0.012
Human Feedback received at timestep 633 of None
Current timestep = 634. State = [[-0.2740472   0.10401014]]. Action = [[-0.0094514  -0.04509208  0.         -0.60036016]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 634 is [True, False, False, False, True, False]
State prediction error at timestep 634 is 0.012
Human Feedback received at timestep 634 of None
Current timestep = 635. State = [[-0.27055833  0.09964339]]. Action = [[ 0.06842463 -0.07816436  0.         -0.2783476 ]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 635 is [True, False, False, False, True, False]
State prediction error at timestep 635 is 0.012
Human Feedback received at timestep 635 of None
Current timestep = 636. State = [[-0.2659543   0.09334982]]. Action = [[ 0.038228   -0.08503304  0.         -0.7730674 ]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 636 is [True, False, False, False, True, False]
State prediction error at timestep 636 is 0.012
Human Feedback received at timestep 636 of None
Current timestep = 637. State = [[-0.2604184   0.09521596]]. Action = [[0.07154364 0.0973851  0.         0.05149865]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 637 is [True, False, False, False, True, False]
State prediction error at timestep 637 is 0.012
Human Feedback received at timestep 637 of None
Current timestep = 638. State = [[-0.2611228   0.09357389]]. Action = [[-0.08196685 -0.08470008  0.         -0.17770249]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 638 is [True, False, False, False, True, False]
Current timestep = 639. State = [[-0.2631539   0.09223228]]. Action = [[-0.00391995  0.02402687  0.          0.28788435]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 639 is [True, False, False, False, True, False]
Current timestep = 640. State = [[-0.2607571   0.08871968]]. Action = [[ 0.05254122 -0.07084224  0.         -0.51357603]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 640 is [True, False, False, False, True, False]
Current timestep = 641. State = [[-0.25704128  0.08833849]]. Action = [[ 0.04348443  0.05216476  0.         -0.21810913]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 641 is [True, False, False, False, True, False]
Current timestep = 642. State = [[-0.25891688  0.0925745 ]]. Action = [[-0.06299232  0.07454646  0.         -0.2744394 ]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 642 is [True, False, False, False, True, False]
Current timestep = 643. State = [[-0.26331645  0.09129056]]. Action = [[-0.05120852 -0.06481425  0.          0.7658851 ]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 643 is [True, False, False, False, True, False]
State prediction error at timestep 643 is 0.012
Human Feedback received at timestep 643 of None
Current timestep = 644. State = [[-0.26281318  0.09143457]]. Action = [[ 0.04742465  0.04352032  0.         -0.6083065 ]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 644 is [True, False, False, False, True, False]
Current timestep = 645. State = [[-0.25706184  0.0871828 ]]. Action = [[ 0.09619214 -0.09881356  0.         -0.95769733]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 645 is [True, False, False, False, True, False]
Current timestep = 646. State = [[-0.25165233  0.08806584]]. Action = [[ 0.05239103  0.09305919  0.         -0.35257006]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 646 is [True, False, False, False, True, False]
Current timestep = 647. State = [[-0.24576727  0.09277216]]. Action = [[0.08820438 0.05861523 0.         0.40050292]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 647 is [True, False, False, False, True, False]
Current timestep = 648. State = [[-0.24462378  0.09060344]]. Action = [[-0.04115284 -0.07373197  0.          0.2803011 ]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 648 is [True, False, False, False, True, False]
Current timestep = 649. State = [[-0.24567334  0.08753445]]. Action = [[-0.01053555 -0.01893614  0.         -0.72565717]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 649 is [True, False, False, False, True, False]
Current timestep = 650. State = [[-0.24877532  0.08908948]]. Action = [[-0.06525794  0.04484237  0.         -0.3789481 ]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 650 is [True, False, False, False, True, False]
State prediction error at timestep 650 is 0.012
Human Feedback received at timestep 650 of None
Current timestep = 651. State = [[-0.24700186  0.09349289]]. Action = [[0.07618288 0.06207082 0.         0.34899652]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 651 is [True, False, False, False, True, False]
State prediction error at timestep 651 is 0.012
Human Feedback received at timestep 651 of None
Current timestep = 652. State = [[-0.24806     0.09898926]]. Action = [[-0.06342683  0.06878347  0.         -0.76596206]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 652 is [True, False, False, False, True, False]
Current timestep = 653. State = [[-0.24974811  0.10532019]]. Action = [[ 0.00789462  0.07249831  0.         -0.37702894]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 653 is [True, False, False, False, True, False]
Current timestep = 654. State = [[-0.24797936  0.11014633]]. Action = [[0.0474469  0.03703807 0.         0.26188624]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 654 is [True, False, False, False, True, False]
Current timestep = 655. State = [[-0.24551524  0.10783964]]. Action = [[ 0.02976342 -0.08831351  0.          0.3069737 ]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 655 is [True, False, False, False, True, False]
Current timestep = 656. State = [[-0.24646415  0.10934399]]. Action = [[-0.04010884  0.06209569  0.         -0.20109618]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 656 is [True, False, False, False, True, False]
State prediction error at timestep 656 is 0.012
Human Feedback received at timestep 656 of None
Current timestep = 657. State = [[-0.24571058  0.10749947]]. Action = [[ 0.03435377 -0.0926173   0.          0.18249917]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 657 is [True, False, False, False, True, False]
Current timestep = 658. State = [[-0.24577224  0.105302  ]]. Action = [[-0.03179321 -0.00979427  0.         -0.7875047 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 658 is [True, False, False, False, True, False]
State prediction error at timestep 658 is 0.012
Human Feedback received at timestep 658 of None
Current timestep = 659. State = [[-0.24379751  0.10250576]]. Action = [[ 0.043309   -0.06060323  0.          0.5375166 ]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 659 is [True, False, False, False, True, False]
State prediction error at timestep 659 is 0.012
Human Feedback received at timestep 659 of None
Current timestep = 660. State = [[-0.23715699  0.09987368]]. Action = [[ 0.09491216 -0.01704042  0.          0.4644935 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 660 is [True, False, False, False, True, False]
Current timestep = 661. State = [[-0.23449515  0.09584054]]. Action = [[-0.02479723 -0.06182852  0.          0.82555366]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 661 is [True, False, False, False, True, False]
Current timestep = 662. State = [[-0.23295912  0.09263118]]. Action = [[ 0.0182485  -0.01829763  0.         -0.8011281 ]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 662 is [True, False, False, False, True, False]
Current timestep = 663. State = [[-0.23117256  0.093535  ]]. Action = [[0.00739714 0.04684976 0.         0.51387954]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 663 is [True, False, False, False, True, False]
State prediction error at timestep 663 is 0.012
Human Feedback received at timestep 663 of None
Current timestep = 664. State = [[-0.22556308  0.09443528]]. Action = [[0.09729623 0.01106997 0.         0.60273874]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 664 is [True, False, False, False, True, False]
Current timestep = 665. State = [[-0.21994032  0.09505337]]. Action = [[ 0.04698556  0.02762476  0.         -0.0470311 ]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 665 is [True, False, False, False, True, False]
Current timestep = 666. State = [[-0.21340021  0.09369275]]. Action = [[ 0.08840128 -0.02307506  0.         -0.3390838 ]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 666 is [True, False, False, False, True, False]
Current timestep = 667. State = [[-0.20576343  0.09674209]]. Action = [[ 0.08647694  0.09624893  0.         -0.69255114]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 667 is [True, False, False, False, True, False]
State prediction error at timestep 667 is 0.012
Human Feedback received at timestep 667 of None
Current timestep = 668. State = [[-0.19758     0.10164344]]. Action = [[0.09992255 0.06365254 0.         0.5988679 ]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 668 is [True, False, False, False, True, False]
Current timestep = 669. State = [[-0.19187391  0.10357599]]. Action = [[0.03592481 0.01204173 0.         0.7943357 ]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 669 is [True, False, False, False, True, False]
Current timestep = 670. State = [[-0.19102436  0.10749085]]. Action = [[-0.03469252  0.07026207  0.         -0.45133263]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 670 is [True, False, False, False, True, False]
Current timestep = 671. State = [[-0.18935266  0.11396481]]. Action = [[ 0.02804438  0.07726803  0.         -0.16600358]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 671 is [True, False, False, False, True, False]
Current timestep = 672. State = [[-0.19079152  0.11959668]]. Action = [[-0.0650923   0.04410706  0.         -0.2180605 ]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 672 is [True, False, False, False, True, False]
Current timestep = 673. State = [[-0.18730105  0.1269579 ]]. Action = [[ 0.09875765  0.09084234  0.         -0.3289113 ]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 673 is [True, False, False, False, True, False]
Current timestep = 674. State = [[-0.18777372  0.12961939]]. Action = [[-0.09775459 -0.04352016  0.          0.19812512]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 674 is [True, False, False, False, False, True]
Current timestep = 675. State = [[-0.18536043  0.12583005]]. Action = [[ 0.0869179  -0.09575927  0.         -0.87877107]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 675 is [True, False, False, False, False, True]
Current timestep = 676. State = [[-0.1820669   0.12144004]]. Action = [[-0.00630052 -0.06255816  0.          0.4445219 ]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 676 is [True, False, False, False, False, True]
Current timestep = 677. State = [[-0.18065102  0.11586442]]. Action = [[-0.00451447 -0.09705857  0.         -0.04356968]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 677 is [True, False, False, False, True, False]
Current timestep = 678. State = [[-0.18206076  0.1121502 ]]. Action = [[-0.0660281  -0.03237283  0.          0.23532486]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 678 is [True, False, False, False, True, False]
State prediction error at timestep 678 is 0.012
Human Feedback received at timestep 678 of None
Current timestep = 679. State = [[-0.18237664  0.11583854]]. Action = [[0.00185739 0.08714854 0.         0.56651926]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 679 is [True, False, False, False, True, False]
State prediction error at timestep 679 is 0.012
Human Feedback received at timestep 679 of None
Current timestep = 680. State = [[-0.18474357  0.11710406]]. Action = [[-0.06586607 -0.03134788  0.         -0.2472384 ]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 680 is [True, False, False, False, True, False]
Current timestep = 681. State = [[-0.18582354  0.1202091 ]]. Action = [[ 0.00512733  0.07015779  0.         -0.14791906]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 681 is [True, False, False, False, True, False]
State prediction error at timestep 681 is 0.012
Human Feedback received at timestep 681 of None
Current timestep = 682. State = [[-0.1868821   0.12410303]]. Action = [[-0.02109624  0.0317814   0.          0.44601274]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 682 is [True, False, False, False, True, False]
State prediction error at timestep 682 is 0.012
Human Feedback received at timestep 682 of None
Current timestep = 683. State = [[-0.18426561  0.1243417 ]]. Action = [[ 0.07271525 -0.0215927   0.          0.024351  ]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 683 is [True, False, False, False, True, False]
State prediction error at timestep 683 is 0.012
Human Feedback received at timestep 683 of None
Current timestep = 684. State = [[-0.17947799  0.12176627]]. Action = [[ 0.06322425 -0.03688561  0.         -0.15575051]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 684 is [True, False, False, False, True, False]
State prediction error at timestep 684 is 0.012
Human Feedback received at timestep 684 of None
Current timestep = 685. State = [[-0.18022409  0.11684036]]. Action = [[-0.06083758 -0.07334603  0.          0.07509732]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 685 is [True, False, False, False, True, False]
Current timestep = 686. State = [[-0.17939207  0.11171016]]. Action = [[ 0.04273786 -0.05345914  0.         -0.43095022]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 686 is [True, False, False, False, True, False]
Current timestep = 687. State = [[-0.17319247  0.11058367]]. Action = [[ 0.09982011  0.03008839  0.         -0.7360014 ]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 687 is [True, False, False, False, True, False]
Current timestep = 688. State = [[-0.17070994  0.1123668 ]]. Action = [[-0.00995146  0.04514747  0.         -0.42158002]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 688 is [True, False, False, False, True, False]
State prediction error at timestep 688 is 0.012
Human Feedback received at timestep 688 of None
Current timestep = 689. State = [[-0.16944581  0.11743219]]. Action = [[ 0.02968646  0.09393749  0.         -0.4237852 ]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 689 is [True, False, False, False, True, False]
Current timestep = 690. State = [[-0.16880776  0.11626065]]. Action = [[-0.00245116 -0.06742518  0.         -0.7228733 ]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 690 is [True, False, False, False, True, False]
Current timestep = 691. State = [[-0.17307004  0.11859465]]. Action = [[-0.09258889  0.08759674  0.         -0.78427863]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 691 is [True, False, False, False, True, False]
Current timestep = 692. State = [[-0.17551248  0.11894725]]. Action = [[ 0.00231936 -0.04925582  0.         -0.5128294 ]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 692 is [True, False, False, False, True, False]
Current timestep = 693. State = [[-0.17463455  0.11958039]]. Action = [[ 0.02040564  0.03244578  0.         -0.6444013 ]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 693 is [True, False, False, False, True, False]
Current timestep = 694. State = [[-0.17366284  0.11664777]]. Action = [[ 0.00908263 -0.08148886  0.         -0.7098818 ]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 694 is [True, False, False, False, True, False]
Current timestep = 695. State = [[-0.16896117  0.11691931]]. Action = [[0.08978231 0.05359105 0.         0.5158378 ]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 695 is [True, False, False, False, True, False]
Current timestep = 696. State = [[-0.16651814  0.12065038]]. Action = [[-0.00170132  0.05154433  0.         -0.12882173]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 696 is [True, False, False, False, True, False]
Current timestep = 697. State = [[-0.16720891  0.123301  ]]. Action = [[-0.01753282  0.01963051  0.          0.9793967 ]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 697 is [True, False, False, False, True, False]
Current timestep = 698. State = [[-0.1704893   0.12516762]]. Action = [[-0.06120741  0.01466836  0.          0.10217381]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 698 is [True, False, False, False, True, False]
Current timestep = 699. State = [[-0.17584065  0.1260045 ]]. Action = [[-0.07940488 -0.0107099   0.          0.60022473]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 699 is [True, False, False, False, False, True]
Current timestep = 700. State = [[-0.18276407  0.12669794]]. Action = [[-0.09785821 -0.00499603  0.         -0.9246324 ]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 700 is [True, False, False, False, False, True]
Current timestep = 701. State = [[-0.19013923  0.12442166]]. Action = [[-0.09209645 -0.07136656  0.         -0.1754458 ]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 701 is [True, False, False, False, False, True]
Current timestep = 702. State = [[-0.18994011  0.12679183]]. Action = [[0.08345472 0.07465472 0.         0.30291736]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 702 is [True, False, False, False, True, False]
Current timestep = 703. State = [[-0.18627542  0.12852132]]. Action = [[ 0.03723919 -0.0176481   0.         -0.7877661 ]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 703 is [True, False, False, False, False, True]
State prediction error at timestep 703 is 0.012
Human Feedback received at timestep 703 of None
Current timestep = 704. State = [[-0.18812808  0.12691249]]. Action = [[-0.06697093 -0.03649393  0.         -0.1631676 ]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 704 is [True, False, False, False, False, True]
State prediction error at timestep 704 is 0.012
Human Feedback received at timestep 704 of None
Current timestep = 705. State = [[-0.18750632  0.12321918]]. Action = [[ 0.04376713 -0.0624591   0.          0.67180943]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 705 is [True, False, False, False, False, True]
Current timestep = 706. State = [[-0.1827209   0.11766754]]. Action = [[ 0.06720173 -0.06997086  0.          0.08968353]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 706 is [True, False, False, False, True, False]
Current timestep = 707. State = [[-0.18444021  0.11260657]]. Action = [[-0.09227987 -0.04977893  0.          0.1369803 ]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 707 is [True, False, False, False, True, False]
Current timestep = 708. State = [[-0.18917446  0.11231239]]. Action = [[-0.05337816  0.03426244  0.         -0.5549263 ]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 708 is [True, False, False, False, True, False]
Current timestep = 709. State = [[-0.19076282  0.1080058 ]]. Action = [[ 0.00307916 -0.09325156  0.          0.81189466]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 709 is [True, False, False, False, True, False]
State prediction error at timestep 709 is 0.012
Human Feedback received at timestep 709 of None
Current timestep = 710. State = [[-0.19287705  0.1008712 ]]. Action = [[-0.04367981 -0.07376806  0.         -0.3440084 ]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 710 is [True, False, False, False, True, False]
Current timestep = 711. State = [[-0.19333905  0.09351538]]. Action = [[ 0.01462279 -0.08083436  0.         -0.04511029]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 711 is [True, False, False, False, True, False]
Current timestep = 712. State = [[-0.18959354  0.09305903]]. Action = [[0.07666405 0.07467923 0.         0.33489728]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 712 is [True, False, False, False, True, False]
Current timestep = 713. State = [[-0.19150408  0.0946189 ]]. Action = [[-0.07389606  0.02351657  0.         -0.47716224]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 713 is [True, False, False, False, True, False]
Current timestep = 714. State = [[-0.19346015  0.09000015]]. Action = [[ 0.01956774 -0.08320484  0.         -0.07414454]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 714 is [True, False, False, False, True, False]
Current timestep = 715. State = [[-0.1960367   0.08547157]]. Action = [[-0.04545664 -0.01749237  0.          0.02751064]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 715 is [True, False, False, False, True, False]
State prediction error at timestep 715 is 0.012
Human Feedback received at timestep 715 of None
Current timestep = 716. State = [[-0.1996096   0.08707456]]. Action = [[-0.0273395   0.06836902  0.          0.3334744 ]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 716 is [True, False, False, False, True, False]
State prediction error at timestep 716 is 0.012
Human Feedback received at timestep 716 of None
Current timestep = 717. State = [[-0.20366172  0.08483332]]. Action = [[-0.04084251 -0.06687041  0.          0.08878958]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 717 is [True, False, False, False, True, False]
Current timestep = 718. State = [[-0.20417082  0.08061759]]. Action = [[ 0.03423097 -0.03215975  0.          0.04506803]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 718 is [True, False, False, False, True, False]
Current timestep = 719. State = [[-0.20259045  0.08086836]]. Action = [[0.03599738 0.04701794 0.         0.84846234]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 719 is [True, False, False, False, True, False]
Current timestep = 720. State = [[-0.20056604  0.08275278]]. Action = [[ 0.04528933  0.03282707  0.         -0.18432838]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 720 is [True, False, False, False, True, False]
State prediction error at timestep 720 is 0.012
Human Feedback received at timestep 720 of None
Current timestep = 721. State = [[-0.19572209  0.0794566 ]]. Action = [[ 0.09344276 -0.0664374   0.         -0.3738433 ]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 721 is [True, False, False, False, True, False]
Current timestep = 722. State = [[-0.1907697   0.07325035]]. Action = [[ 0.05374724 -0.06422956  0.         -0.09684998]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 722 is [True, False, False, False, True, False]
Current timestep = 723. State = [[-0.18419892  0.06834429]]. Action = [[ 0.09589332 -0.03247714  0.         -0.9610952 ]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 723 is [True, False, False, False, True, False]
Current timestep = 724. State = [[-0.17955664  0.06899529]]. Action = [[0.02752351 0.06490695 0.         0.9721887 ]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 724 is [True, False, False, False, True, False]
Current timestep = 725. State = [[-0.18063587  0.06792412]]. Action = [[-0.05867473 -0.03510105  0.          0.3132459 ]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 725 is [True, False, False, False, True, False]
Current timestep = 726. State = [[-0.17822985  0.06995192]]. Action = [[ 0.06737638  0.07668816  0.         -0.7576656 ]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 726 is [True, False, False, False, True, False]
Current timestep = 727. State = [[-0.17223133  0.07356574]]. Action = [[0.07252797 0.04423074 0.         0.20903766]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 727 is [True, False, False, False, True, False]
Current timestep = 728. State = [[-0.17149235  0.07138065]]. Action = [[-0.05104155 -0.06515346  0.         -0.22109938]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 728 is [True, False, False, False, True, False]
State prediction error at timestep 728 is 0.012
Human Feedback received at timestep 728 of None
Current timestep = 729. State = [[-0.17627284  0.06932003]]. Action = [[-0.09767909 -0.00771218  0.          0.26353765]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 729 is [True, False, False, False, True, False]
Current timestep = 730. State = [[-0.18051389  0.07278809]]. Action = [[-0.04933175  0.066714    0.          0.07376039]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 730 is [True, False, False, False, True, False]
Current timestep = 731. State = [[-0.18458526  0.07909339]]. Action = [[-0.05474791  0.07256094  0.         -0.6693413 ]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 731 is [True, False, False, False, True, False]
Current timestep = 732. State = [[-0.18884547  0.08012745]]. Action = [[-0.050009   -0.04691753  0.         -0.23385882]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 732 is [True, False, False, False, True, False]
Current timestep = 733. State = [[-0.18630403  0.08056929]]. Action = [[0.09495976 0.01469727 0.         0.0703851 ]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 733 is [True, False, False, False, True, False]
State prediction error at timestep 733 is 0.012
Human Feedback received at timestep 733 of None
Current timestep = 734. State = [[-0.17946073  0.08306633]]. Action = [[0.09816854 0.03344583 0.         0.63652277]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 734 is [True, False, False, False, True, False]
Current timestep = 735. State = [[-0.177161    0.08106329]]. Action = [[-0.01384691 -0.0677177   0.         -0.25449574]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 735 is [True, False, False, False, True, False]
Current timestep = 736. State = [[-0.18126188  0.07989144]]. Action = [[-0.08786596  0.00540759  0.          0.66461205]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 736 is [True, False, False, False, True, False]
Current timestep = 737. State = [[-0.18126203  0.08000285]]. Action = [[ 0.04611503 -0.00867917  0.         -0.8090815 ]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 737 is [True, False, False, False, True, False]
State prediction error at timestep 737 is 0.012
Human Feedback received at timestep 737 of None
Current timestep = 738. State = [[-0.18123813  0.0756508 ]]. Action = [[-0.03278945 -0.08802291  0.         -0.8233887 ]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 738 is [True, False, False, False, True, False]
Current timestep = 739. State = [[-0.17956439  0.07518743]]. Action = [[ 0.04054555  0.04270545  0.         -0.4175024 ]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 739 is [True, False, False, False, True, False]
Current timestep = 740. State = [[-0.17351003  0.07809369]]. Action = [[0.0997655  0.04433044 0.         0.7284478 ]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 740 is [True, False, False, False, True, False]
Current timestep = 741. State = [[-0.17198315  0.07572842]]. Action = [[-0.0362744  -0.0667589   0.         -0.42877495]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 741 is [True, False, False, False, True, False]
Current timestep = 742. State = [[-0.17179924  0.07672048]]. Action = [[ 0.01788559  0.06527161  0.         -0.30008316]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 742 is [True, False, False, False, True, False]
Current timestep = 743. State = [[-0.17584406  0.07684875]]. Action = [[-0.09505345 -0.03013795  0.         -0.3036222 ]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 743 is [True, False, False, False, True, False]
Current timestep = 744. State = [[-0.18128534  0.07507068]]. Action = [[-0.05945491 -0.02408413  0.          0.7404125 ]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 744 is [True, False, False, False, True, False]
Current timestep = 745. State = [[-0.18477263  0.07147457]]. Action = [[-0.03265084 -0.06120014  0.          0.08400738]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 745 is [True, False, False, False, True, False]
Current timestep = 746. State = [[-0.1871745   0.06495823]]. Action = [[-0.02743443 -0.09395974  0.          0.58146596]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 746 is [True, False, False, False, True, False]
Current timestep = 747. State = [[-0.18362461  0.06131987]]. Action = [[ 0.09577601 -0.00413854  0.         -0.2073139 ]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 747 is [True, False, False, False, True, False]
Current timestep = 748. State = [[-0.17942543  0.06349433]]. Action = [[0.03954966 0.07138895 0.         0.8553473 ]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 748 is [True, False, False, False, True, False]
Current timestep = 749. State = [[-0.18051766  0.06207605]]. Action = [[-0.04362353 -0.0516749   0.         -0.15699548]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 749 is [True, False, False, False, True, False]
Current timestep = 750. State = [[-0.1825422   0.05768132]]. Action = [[-0.01776645 -0.04611916  0.         -0.72059715]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 750 is [True, False, False, False, True, False]
Current timestep = 751. State = [[-0.18204308  0.05606703]]. Action = [[ 0.02259632  0.01253571  0.         -0.27660632]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 751 is [True, False, False, False, True, False]
Current timestep = 752. State = [[-0.18213625  0.05553325]]. Action = [[-0.00994236  0.0007353   0.          0.43566608]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 752 is [True, False, False, False, True, False]
Current timestep = 753. State = [[-0.18553376  0.05261574]]. Action = [[-0.06210102 -0.04646353  0.         -0.01682848]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 753 is [True, False, False, False, True, False]
Current timestep = 754. State = [[-0.18335044  0.05161461]]. Action = [[ 0.08916586  0.02082907  0.         -0.4560727 ]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 754 is [True, False, False, False, True, False]
Current timestep = 755. State = [[-0.17963775  0.05529509]]. Action = [[0.03245159 0.0794354  0.         0.46081185]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 755 is [True, False, False, False, True, False]
Current timestep = 756. State = [[-0.1809154   0.05789674]]. Action = [[-0.04210079  0.014102    0.         -0.8798099 ]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 756 is [True, False, False, False, True, False]
Current timestep = 757. State = [[-0.18078642  0.05794002]]. Action = [[ 0.02867126 -0.00846184  0.         -0.57500964]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 757 is [True, False, False, False, True, False]
Current timestep = 758. State = [[-0.17963074  0.06077139]]. Action = [[ 0.01301589  0.06184836  0.         -0.13088995]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 758 is [True, False, False, False, True, False]
State prediction error at timestep 758 is 0.012
Human Feedback received at timestep 758 of None
Current timestep = 759. State = [[-0.18072519  0.05969456]]. Action = [[-0.02689406 -0.06171781  0.         -0.41441768]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 759 is [True, False, False, False, True, False]
Current timestep = 760. State = [[-0.18513742  0.05418836]]. Action = [[-0.08373877 -0.08482928  0.         -0.47703707]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 760 is [True, False, False, False, True, False]
Current timestep = 761. State = [[-0.18593797  0.05209634]]. Action = [[0.02319938 0.00378259 0.         0.40574253]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 761 is [True, False, False, False, True, False]
Current timestep = 762. State = [[-0.18103147  0.05138109]]. Action = [[ 0.08613863 -0.0111784   0.          0.0889492 ]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 762 is [True, False, False, False, True, False]
Current timestep = 763. State = [[-0.17422058  0.05465633]]. Action = [[0.09175815 0.08290429 0.         0.16887808]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 763 is [True, False, False, False, True, False]
State prediction error at timestep 763 is 0.012
Human Feedback received at timestep 763 of None
Current timestep = 764. State = [[-0.16745742  0.05382213]]. Action = [[ 0.08441784 -0.05277661  0.          0.35092437]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 764 is [True, False, False, False, True, False]
Current timestep = 765. State = [[-0.15949644  0.04712795]]. Action = [[ 0.09889483 -0.09109934  0.         -0.9062925 ]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 765 is [True, False, False, False, True, False]
Current timestep = 766. State = [[-0.15673079  0.04307215]]. Action = [[-0.03031645 -0.00757559  0.         -0.3386684 ]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 766 is [True, False, False, False, True, False]
Current timestep = 767. State = [[-0.15189132  0.04234822]]. Action = [[0.08742791 0.01329206 0.         0.3423338 ]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 767 is [True, False, False, False, True, False]
Current timestep = 768. State = [[-0.15199317  0.04479174]]. Action = [[-0.08349542  0.06050854  0.         -0.71676725]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 768 is [True, False, False, False, True, False]
State prediction error at timestep 768 is 0.012
Human Feedback received at timestep 768 of None
Current timestep = 769. State = [[-0.1576873   0.04856493]]. Action = [[-0.09485385  0.04565816  0.          0.00723088]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 769 is [True, False, False, False, True, False]
Current timestep = 770. State = [[-0.16428505  0.04959306]]. Action = [[-0.09464572 -0.01559724  0.          0.98291266]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 770 is [True, False, False, False, True, False]
Current timestep = 771. State = [[-0.16313452  0.0485387 ]]. Action = [[ 0.08209168 -0.02330686  0.         -0.04953921]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 771 is [True, False, False, False, True, False]
State prediction error at timestep 771 is 0.012
Human Feedback received at timestep 771 of None
Current timestep = 772. State = [[-0.15780447  0.05163904]]. Action = [[ 0.06039479  0.07174834  0.         -0.8955244 ]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 772 is [True, False, False, False, True, False]
State prediction error at timestep 772 is 0.012
Human Feedback received at timestep 772 of None
Current timestep = 773. State = [[-0.15710919  0.0502039 ]]. Action = [[-0.03073711 -0.07670204  0.         -0.0803296 ]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 773 is [True, False, False, False, True, False]
Current timestep = 774. State = [[-0.15366915  0.05091136]]. Action = [[0.07833286 0.05247349 0.         0.6510874 ]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 774 is [True, False, False, False, True, False]
Current timestep = 775. State = [[-0.15157542  0.05500583]]. Action = [[-0.0064294   0.05095788  0.          0.5468526 ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 775 is [True, False, False, False, True, False]
State prediction error at timestep 775 is 0.012
Human Feedback received at timestep 775 of None
Current timestep = 776. State = [[-0.14918591  0.06061576]]. Action = [[ 0.04780822  0.07364369  0.         -0.09134418]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 776 is [True, False, False, False, True, False]
Current timestep = 777. State = [[-0.15038714  0.06510887]]. Action = [[-0.05271511  0.03255347  0.          0.31260288]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 777 is [True, False, False, False, True, False]
Current timestep = 778. State = [[-0.14731817  0.06415185]]. Action = [[ 0.09098675 -0.05786715  0.          0.64170885]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 778 is [True, False, False, False, True, False]
Current timestep = 779. State = [[-0.14615245  0.06128096]]. Action = [[-0.0404515 -0.0381982  0.        -0.8567645]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 779 is [True, False, False, False, True, False]
State prediction error at timestep 779 is 0.012
Human Feedback received at timestep 779 of None
Current timestep = 780. State = [[-0.14487267  0.05664609]]. Action = [[ 0.02826687 -0.07978947  0.          0.29480922]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 780 is [True, False, False, False, True, False]
Current timestep = 781. State = [[-0.14594945  0.05510238]]. Action = [[-0.05909122  0.01270431  0.         -0.4156394 ]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 781 is [True, False, False, False, True, False]
Current timestep = 782. State = [[-0.148765   0.0565072]]. Action = [[-0.04438443  0.01810564  0.          0.1762631 ]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 782 is [True, False, False, False, True, False]
Current timestep = 783. State = [[-0.15161332  0.06226762]]. Action = [[-0.04042704  0.09732001  0.         -0.01336288]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 783 is [True, False, False, False, True, False]
Current timestep = 784. State = [[-0.15685958  0.07051188]]. Action = [[-0.07758362  0.09354185  0.         -0.8942189 ]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 784 is [True, False, False, False, True, False]
Current timestep = 785. State = [[-0.161463    0.07880908]]. Action = [[-0.03111388  0.08416905  0.         -0.22903812]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 785 is [True, False, False, False, True, False]
Current timestep = 786. State = [[-0.16318783  0.08607947]]. Action = [[ 0.01375966  0.0640104   0.         -0.55082744]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 786 is [True, False, False, False, True, False]
Current timestep = 787. State = [[-0.1642903   0.08769075]]. Action = [[ 0.00127302 -0.03892101  0.          0.04489005]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 787 is [True, False, False, False, True, False]
State prediction error at timestep 787 is 0.012
Human Feedback received at timestep 787 of None
Current timestep = 788. State = [[-0.16321042  0.0848792 ]]. Action = [[ 0.0428882  -0.0631846   0.          0.23667431]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 788 is [True, False, False, False, True, False]
Current timestep = 789. State = [[-0.16107522  0.08337707]]. Action = [[ 0.03391647 -0.00922661  0.         -0.35315073]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 789 is [True, False, False, False, True, False]
Current timestep = 790. State = [[-0.15703218  0.08130748]]. Action = [[ 0.07092898 -0.0421159   0.         -0.5083091 ]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 790 is [True, False, False, False, True, False]
Current timestep = 791. State = [[-0.15865491  0.07870369]]. Action = [[-0.08103445 -0.03079488  0.         -0.17037821]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 791 is [True, False, False, False, True, False]
Current timestep = 792. State = [[-0.1641696   0.07964296]]. Action = [[-0.071275    0.03380396  0.         -0.2509128 ]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 792 is [True, False, False, False, True, False]
Current timestep = 793. State = [[-0.17016412  0.07721509]]. Action = [[-0.07818829 -0.07419064  0.         -0.45124555]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 793 is [True, False, False, False, True, False]
Current timestep = 794. State = [[-0.17520516  0.07793431]]. Action = [[-0.05157137  0.05190139  0.          0.83721507]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 794 is [True, False, False, False, True, False]
Current timestep = 795. State = [[-0.17828387  0.07772014]]. Action = [[-0.01654925 -0.03577612  0.          0.6436479 ]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 795 is [True, False, False, False, True, False]
Current timestep = 796. State = [[-0.17955622  0.08001536]]. Action = [[0.00435616 0.0657978  0.         0.34108114]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 796 is [True, False, False, False, True, False]
Current timestep = 797. State = [[-0.1816346   0.07980998]]. Action = [[-0.01961886 -0.04053861  0.          0.4180622 ]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 797 is [True, False, False, False, True, False]
Current timestep = 798. State = [[-0.18309064  0.07959151]]. Action = [[0.00348534 0.01959308 0.         0.9446156 ]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 798 is [True, False, False, False, True, False]
Current timestep = 799. State = [[-0.18875898  0.0829957 ]]. Action = [[-0.09237529  0.05989669  0.         -0.86301434]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 799 is [True, False, False, False, True, False]
Current timestep = 800. State = [[-0.19417757  0.08207397]]. Action = [[-0.0310057  -0.05955762  0.          0.42639923]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 800 is [True, False, False, False, True, False]
Current timestep = 801. State = [[-0.19500215  0.07683877]]. Action = [[ 0.02631459 -0.07459968  0.          0.64242697]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 801 is [True, False, False, False, True, False]
Current timestep = 802. State = [[-0.19479708  0.07806172]]. Action = [[ 0.01307043  0.07752425  0.         -0.45114148]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 802 is [True, False, False, False, True, False]
Current timestep = 803. State = [[-0.19663744  0.07832377]]. Action = [[-0.02002709 -0.03140248  0.         -0.79141146]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 803 is [True, False, False, False, True, False]
Current timestep = 804. State = [[-0.19426072  0.08153559]]. Action = [[ 0.08673374  0.08854715  0.         -0.23511785]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 804 is [True, False, False, False, True, False]
Current timestep = 805. State = [[-0.19008093  0.08758617]]. Action = [[ 0.06524015  0.08235817  0.         -0.8650296 ]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 805 is [True, False, False, False, True, False]
State prediction error at timestep 805 is 0.012
Human Feedback received at timestep 805 of None
Current timestep = 806. State = [[-0.19103602  0.09284588]]. Action = [[-0.03645007  0.05970483  0.         -0.29706693]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 806 is [True, False, False, False, True, False]
Current timestep = 807. State = [[-0.1929501   0.09774405]]. Action = [[0.00191204 0.0552044  0.         0.85993576]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 807 is [True, False, False, False, True, False]
Current timestep = 808. State = [[-0.19422193  0.09811968]]. Action = [[-0.00838102 -0.04010493  0.         -0.8830146 ]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 808 is [True, False, False, False, True, False]
Current timestep = 809. State = [[-0.19254377  0.10066368]]. Action = [[0.04964977 0.05710419 0.         0.22307944]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 809 is [True, False, False, False, True, False]
Current timestep = 810. State = [[-0.19583257  0.10115054]]. Action = [[-0.0951198  -0.04268194  0.          0.1658225 ]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 810 is [True, False, False, False, True, False]
Current timestep = 811. State = [[-0.20336549  0.10088862]]. Action = [[-0.09847884 -0.00873587  0.         -0.58889747]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 811 is [True, False, False, False, True, False]
Current timestep = 812. State = [[-0.2039476  0.0995621]]. Action = [[ 0.05778228 -0.04292473  0.          0.5534167 ]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 812 is [True, False, False, False, True, False]
State prediction error at timestep 812 is 0.012
Human Feedback received at timestep 812 of None
Current timestep = 813. State = [[-0.20562129  0.09979966]]. Action = [[-0.06169579  0.01521252  0.          0.14616466]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 813 is [True, False, False, False, True, False]
Current timestep = 814. State = [[-0.20465393  0.09773404]]. Action = [[ 0.05525187 -0.06137919  0.          0.6213716 ]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 814 is [True, False, False, False, True, False]
Current timestep = 815. State = [[-0.2069936   0.10008293]]. Action = [[-0.07648259  0.07835027  0.         -0.9107446 ]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 815 is [True, False, False, False, True, False]
State prediction error at timestep 815 is 0.012
Human Feedback received at timestep 815 of None
Current timestep = 816. State = [[-0.20800653  0.10636403]]. Action = [[0.0331305  0.07516041 0.         0.3436234 ]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 816 is [True, False, False, False, True, False]
Current timestep = 817. State = [[-0.20856012  0.10939439]]. Action = [[-0.01224626  0.00717163  0.          0.6208749 ]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 817 is [True, False, False, False, True, False]
State prediction error at timestep 817 is 0.012
Human Feedback received at timestep 817 of None
Current timestep = 818. State = [[-0.2125639  0.1134128]]. Action = [[-0.06181024  0.06185397  0.         -0.02620709]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 818 is [True, False, False, False, True, False]
Current timestep = 819. State = [[-0.2183306   0.11932239]]. Action = [[-0.06230352  0.06351162  0.         -0.5510592 ]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 819 is [True, False, False, False, True, False]
Current timestep = 820. State = [[-0.21929401  0.12034367]]. Action = [[ 0.0415346  -0.04034868  0.          0.20208788]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 820 is [True, False, False, False, True, False]
Current timestep = 821. State = [[-0.2179034   0.12326865]]. Action = [[ 0.02876069  0.06459723  0.         -0.1201269 ]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 821 is [True, False, False, False, True, False]
Current timestep = 822. State = [[-0.21820448  0.12510654]]. Action = [[-0.00275913 -0.01392561  0.          0.35883915]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 822 is [True, False, False, False, True, False]
Current timestep = 823. State = [[-0.21865156  0.12637298]]. Action = [[0.00610732 0.01621568 0.         0.2921095 ]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 823 is [True, False, False, False, False, True]
Current timestep = 824. State = [[-0.21462446  0.13149501]]. Action = [[ 0.09555947  0.08454406  0.         -0.63137627]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 824 is [True, False, False, False, False, True]
Current timestep = 825. State = [[-0.21649422  0.13596255]]. Action = [[-0.08850329  0.02734628  0.         -0.5202895 ]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 825 is [True, False, False, False, False, True]
Current timestep = 826. State = [[-0.21823683  0.139428  ]]. Action = [[ 0.03319474  0.03669318  0.         -0.20287979]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 826 is [True, False, False, False, False, True]
State prediction error at timestep 826 is 0.012
Human Feedback received at timestep 826 of None
Current timestep = 827. State = [[-0.21854924  0.1394588 ]]. Action = [[-0.0043386  -0.03547197  0.          0.21912348]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 827 is [True, False, False, False, False, True]
Current timestep = 828. State = [[-0.21991146  0.14267166]]. Action = [[-0.0134307   0.06923728  0.          0.42798185]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 828 is [True, False, False, False, False, True]
Current timestep = 829. State = [[-0.21603203  0.14145297]]. Action = [[ 0.09789347 -0.07627241  0.         -0.56486595]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 829 is [True, False, False, False, False, True]
Current timestep = 830. State = [[-0.21013956  0.14024451]]. Action = [[0.06310018 0.01439534 0.         0.6298704 ]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 830 is [True, False, False, False, False, True]
Current timestep = 831. State = [[-0.20811184  0.14217871]]. Action = [[-0.00596305  0.03171647  0.         -0.93713677]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 831 is [True, False, False, False, False, True]
Current timestep = 832. State = [[-0.20445578  0.13923508]]. Action = [[ 0.06129994 -0.08188109  0.          0.6372268 ]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 832 is [True, False, False, False, False, True]
Current timestep = 833. State = [[-0.19967677  0.13521917]]. Action = [[ 0.03703453 -0.03269438  0.         -0.84256804]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 833 is [True, False, False, False, False, True]
Current timestep = 834. State = [[-0.19888987  0.13510029]]. Action = [[-0.0366334   0.02324779  0.          0.645414  ]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 834 is [True, False, False, False, False, True]
Current timestep = 835. State = [[-0.19640642  0.13832611]]. Action = [[0.0458475  0.05581217 0.         0.7376232 ]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 835 is [True, False, False, False, False, True]
Current timestep = 836. State = [[-0.19423212  0.14077163]]. Action = [[-1.2346357e-04  2.0283543e-02  0.0000000e+00  5.3654909e-01]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 836 is [True, False, False, False, False, True]
Current timestep = 837. State = [[-0.19011495  0.14372358]]. Action = [[ 0.06566533  0.04771147  0.         -0.13291478]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 837 is [True, False, False, False, False, True]
State prediction error at timestep 837 is 0.012
Human Feedback received at timestep 837 of None
Current timestep = 838. State = [[-0.18376319  0.14496976]]. Action = [[0.07623284 0.00031461 0.         0.18038046]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 838 is [True, False, False, False, False, True]
Current timestep = 839. State = [[-0.1762521   0.14822833]]. Action = [[0.08962833 0.069745   0.         0.0684495 ]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 839 is [True, False, False, False, False, True]
Current timestep = 840. State = [[-0.17526314  0.14782295]]. Action = [[-0.06563804 -0.05295813  0.         -0.08991122]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 840 is [True, False, False, False, False, True]
Current timestep = 841. State = [[-0.17794883  0.14588255]]. Action = [[-0.04095739 -0.02058496  0.          0.6408386 ]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 841 is [True, False, False, False, False, True]
Current timestep = 842. State = [[-0.17976153  0.14270979]]. Action = [[-0.03072355 -0.06254348  0.          0.15673113]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 842 is [True, False, False, False, False, True]
Current timestep = 843. State = [[-0.17701517  0.1372196 ]]. Action = [[ 0.05418298 -0.08067755  0.         -0.43133378]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 843 is [True, False, False, False, False, True]
Current timestep = 844. State = [[-0.1696259   0.12946376]]. Action = [[ 0.09743606 -0.09903786  0.         -0.84396744]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 844 is [True, False, False, False, False, True]
Current timestep = 845. State = [[-0.16376995  0.12621154]]. Action = [[ 0.03497571  0.0171715   0.         -0.6419293 ]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 845 is [True, False, False, False, False, True]
Current timestep = 846. State = [[-0.15729406  0.12479022]]. Action = [[ 0.08368819 -0.00747488  0.          0.9522784 ]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 846 is [True, False, False, False, False, True]
Current timestep = 847. State = [[-0.15240999  0.12555364]]. Action = [[0.02626482 0.0515176  0.         0.37349308]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 847 is [True, False, False, False, True, False]
Current timestep = 848. State = [[-0.1521812   0.12523082]]. Action = [[-0.03699075 -0.01112098  0.         -0.90853995]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 848 is [True, False, False, False, False, True]
Current timestep = 849. State = [[-0.15569659  0.12194269]]. Action = [[-0.08058725 -0.04895262  0.          0.23734021]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 849 is [True, False, False, False, False, True]
Current timestep = 850. State = [[-0.15993218  0.12516326]]. Action = [[-0.06187503  0.09743608  0.         -0.9838493 ]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 850 is [True, False, False, False, True, False]
Current timestep = 851. State = [[-0.16490129  0.1295133 ]]. Action = [[-0.06701927  0.02729433  0.          0.50647426]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 851 is [True, False, False, False, False, True]
State prediction error at timestep 851 is 0.012
Human Feedback received at timestep 851 of None
Current timestep = 852. State = [[-0.16543809  0.13134423]]. Action = [[ 0.03594214  0.00758737  0.         -0.568202  ]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 852 is [True, False, False, False, False, True]
State prediction error at timestep 852 is 0.012
Human Feedback received at timestep 852 of None
Current timestep = 853. State = [[-0.16597705  0.13382858]]. Action = [[-0.01714475  0.03579705  0.          0.87571764]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 853 is [True, False, False, False, False, True]
Current timestep = 854. State = [[-0.16586861  0.13697544]]. Action = [[ 0.02747444  0.03136539  0.         -0.13461995]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 854 is [True, False, False, False, False, True]
Current timestep = 855. State = [[-0.1648092   0.13917446]]. Action = [[0.02528293 0.01547952 0.         0.35942578]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 855 is [True, False, False, False, False, True]
Current timestep = 856. State = [[-0.16325672  0.1424657 ]]. Action = [[0.03427506 0.04789763 0.         0.5365486 ]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 856 is [True, False, False, False, False, True]
Current timestep = 857. State = [[-0.15963937  0.1470746 ]]. Action = [[0.07210352 0.05834232 0.         0.21490633]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 857 is [True, False, False, False, False, True]
Current timestep = 858. State = [[-0.16045056  0.14794402]]. Action = [[-0.05137458 -0.02878148  0.          0.82392335]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 858 is [True, False, False, False, False, True]
State prediction error at timestep 858 is 0.012
Human Feedback received at timestep 858 of None
Current timestep = 859. State = [[-0.16413382  0.14974687]]. Action = [[-0.03935675  0.03478643  0.          0.81637096]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 859 is [True, False, False, False, False, True]
Current timestep = 860. State = [[-0.16643615  0.15117411]]. Action = [[-0.01270922 -0.0092575   0.          0.23814678]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 860 is [True, False, False, False, False, True]
Current timestep = 861. State = [[-0.17042243  0.15215476]]. Action = [[-0.06593549  0.00363239  0.         -0.3307966 ]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 861 is [True, False, False, False, False, True]
Current timestep = 862. State = [[-0.17490295  0.15752056]]. Action = [[-0.04328059  0.08309162  0.          0.8063748 ]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 862 is [True, False, False, False, False, True]
Current timestep = 863. State = [[-0.18190952  0.16402644]]. Action = [[-0.09652586  0.05571672  0.         -0.71435916]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 863 is [True, False, False, False, False, True]
Current timestep = 864. State = [[-0.1832433   0.16461562]]. Action = [[ 0.05222832 -0.05329921  0.          0.85693955]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 864 is [True, False, False, False, False, True]
State prediction error at timestep 864 is 0.012
Human Feedback received at timestep 864 of None
Current timestep = 865. State = [[-0.18627197  0.16649832]]. Action = [[-0.06917726  0.04367628  0.         -0.52012765]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 865 is [True, False, False, False, False, True]
Current timestep = 866. State = [[-0.1920562   0.17072059]]. Action = [[-0.05696666  0.03379955  0.          0.5667535 ]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 866 is [True, False, False, False, False, True]
Current timestep = 867. State = [[-0.19048871  0.17000401]]. Action = [[ 0.09219135 -0.05805593  0.          0.3958149 ]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 867 is [True, False, False, False, False, True]
Current timestep = 868. State = [[-0.19040047  0.17031999]]. Action = [[-0.03124291  0.0283972   0.         -0.32739675]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 868 is [True, False, False, False, False, True]
State prediction error at timestep 868 is 0.012
Human Feedback received at timestep 868 of None
Current timestep = 869. State = [[-0.18895032  0.17596413]]. Action = [[0.06472602 0.09197838 0.         0.41242588]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 869 is [True, False, False, False, False, True]
Current timestep = 870. State = [[-0.18866874  0.17445192]]. Action = [[-0.02139685 -0.09331255  0.          0.21802056]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 870 is [True, False, False, False, False, True]
Current timestep = 871. State = [[-0.18953384  0.17207375]]. Action = [[ 1.8365681e-04 -3.1995103e-03  0.0000000e+00  6.5077376e-01]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 871 is [True, False, False, False, False, True]
Current timestep = 872. State = [[-0.1892055   0.17329831]]. Action = [[0.0156481  0.02888759 0.         0.6373844 ]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 872 is [True, False, False, False, False, True]
State prediction error at timestep 872 is 0.012
Human Feedback received at timestep 872 of None
Current timestep = 873. State = [[-0.18811709  0.17743978]]. Action = [[ 0.02411852  0.07074206  0.         -0.96167463]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 873 is [True, False, False, False, False, True]
State prediction error at timestep 873 is 0.012
Human Feedback received at timestep 873 of None
Current timestep = 874. State = [[-0.18358468  0.18142498]]. Action = [[0.09080487 0.04582456 0.         0.30074644]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 874 is [True, False, False, False, False, True]
Current timestep = 875. State = [[-0.1821253   0.17915712]]. Action = [[-0.02477155 -0.0719272   0.          0.6413734 ]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 875 is [True, False, False, False, False, True]
Current timestep = 876. State = [[-0.17845577  0.17707986]]. Action = [[ 0.08695766  0.00340705  0.         -0.9982169 ]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 876 is [True, False, False, False, False, True]
State prediction error at timestep 876 is 0.012
Human Feedback received at timestep 876 of None
Current timestep = 877. State = [[-0.17963031  0.17882223]]. Action = [[-0.08156133  0.04030191  0.          0.81873894]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 877 is [True, False, False, False, False, True]
Current timestep = 878. State = [[-0.18340579  0.1793913 ]]. Action = [[-0.03815    -0.01683912  0.         -0.23263693]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 878 is [True, False, False, False, False, True]
State prediction error at timestep 878 is 0.012
Human Feedback received at timestep 878 of None
Current timestep = 879. State = [[-0.18307748  0.17841175]]. Action = [[ 0.0270442  -0.01787385  0.          0.17300022]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 879 is [True, False, False, False, False, True]
Current timestep = 880. State = [[-0.17938475  0.17686002]]. Action = [[ 0.05652063 -0.0201425   0.         -0.38552034]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 880 is [True, False, False, False, False, True]
Current timestep = 881. State = [[-0.18150595  0.17682287]]. Action = [[-0.08591688  0.01171925  0.         -0.30482107]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 881 is [True, False, False, False, False, True]
Current timestep = 882. State = [[-0.18178438  0.17823668]]. Action = [[0.03914043 0.01896606 0.         0.07608569]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 882 is [True, False, False, False, False, True]
State prediction error at timestep 882 is 0.012
Human Feedback received at timestep 882 of None
Current timestep = 883. State = [[-0.18532377  0.18247747]]. Action = [[-0.09166531  0.07043836  0.         -0.03199273]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 883 is [True, False, False, False, False, True]
Current timestep = 884. State = [[-0.18354307  0.18094127]]. Action = [[ 0.09288027 -0.08233316  0.          0.5820422 ]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 884 is [True, False, False, False, False, True]
Current timestep = 885. State = [[-0.17680241  0.17991683]]. Action = [[ 0.0878885   0.02983522  0.         -0.7006631 ]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 885 is [True, False, False, False, False, True]
Current timestep = 886. State = [[-0.17414635  0.17887416]]. Action = [[-0.00411619 -0.0275893   0.         -0.12688214]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 886 is [True, False, False, False, False, True]
State prediction error at timestep 886 is 0.012
Human Feedback received at timestep 886 of None
Current timestep = 887. State = [[-0.1731754  0.1756025]]. Action = [[ 0.00847441 -0.04633982  0.          0.7721385 ]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 887 is [True, False, False, False, False, True]
Current timestep = 888. State = [[-0.17089848  0.17355154]]. Action = [[ 0.0268695  -0.00736762  0.          0.246279  ]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 888 is [True, False, False, False, False, True]
Current timestep = 889. State = [[-0.16557649  0.1725161 ]]. Action = [[ 0.07847475 -0.0023205   0.          0.06501865]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 889 is [True, False, False, False, False, True]
Current timestep = 890. State = [[-0.16561401  0.17293741]]. Action = [[-0.06440885  0.02336283  0.          0.20854795]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 890 is [True, False, False, False, False, True]
Current timestep = 891. State = [[-0.16341263  0.17569338]]. Action = [[0.07114594 0.05211455 0.         0.72177327]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 891 is [True, False, False, False, False, True]
Current timestep = 892. State = [[-0.15991712  0.17758298]]. Action = [[ 0.02346541  0.01724808  0.         -0.26254362]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 892 is [True, False, False, False, False, True]
Current timestep = 893. State = [[-0.15750515  0.17664383]]. Action = [[ 0.02072918 -0.02557365  0.          0.60408294]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 893 is [True, False, False, False, False, True]
Current timestep = 894. State = [[-0.15669438  0.17853315]]. Action = [[-0.01080244  0.05403348  0.          0.23601127]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 894 is [True, False, False, False, False, True]
State prediction error at timestep 894 is 0.012
Human Feedback received at timestep 894 of None
Current timestep = 895. State = [[-0.15755762  0.18096864]]. Action = [[-0.02265695  0.01391633  0.         -0.7242096 ]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 895 is [True, False, False, False, False, True]
Current timestep = 896. State = [[-0.16078503  0.18029934]]. Action = [[-0.06514917 -0.03705639  0.         -0.66519666]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 896 is [True, False, False, False, False, True]
Current timestep = 897. State = [[-0.16593675  0.18308584]]. Action = [[-0.0784089   0.05580121  0.         -0.76408756]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 897 is [True, False, False, False, False, True]
State prediction error at timestep 897 is 0.012
Human Feedback received at timestep 897 of None
Current timestep = 898. State = [[-0.16960336  0.182055  ]]. Action = [[-0.03089613 -0.07806367  0.          0.647159  ]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 898 is [True, False, False, False, False, True]
Current timestep = 899. State = [[-0.17463312  0.07921308]]. Action = [[-0.09301739 -0.08689797  0.         -0.5352886 ]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 899 is [True, False, False, False, False, True]
Current timestep = 900. State = [[-0.1755085   0.07512537]]. Action = [[-0.08341965 -0.08956175  0.          0.42098212]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 900 is [True, False, False, False, True, False]
Current timestep = 901. State = [[-0.17521428  0.06833483]]. Action = [[ 0.03159811 -0.09614088  0.          0.41597986]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 901 is [True, False, False, False, True, False]
Current timestep = 902. State = [[-0.16911833  0.06819914]]. Action = [[ 0.09385409  0.06346265  0.         -0.73376685]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 902 is [True, False, False, False, True, False]
Current timestep = 903. State = [[-0.16923805  0.07034738]]. Action = [[-0.07935603  0.0167402   0.          0.57125115]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 903 is [True, False, False, False, True, False]
Current timestep = 904. State = [[-0.16743234  0.06758997]]. Action = [[ 0.07537896 -0.05933464  0.         -0.34267306]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 904 is [True, False, False, False, True, False]
Current timestep = 905. State = [[-0.16778739  0.06886975]]. Action = [[-0.05565983  0.07289916  0.          0.40900445]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 905 is [True, False, False, False, True, False]
Current timestep = 906. State = [[-0.17229931  0.07127406]]. Action = [[-0.0662068   0.01069977  0.         -0.8688945 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 906 is [True, False, False, False, True, False]
Current timestep = 907. State = [[-0.17802583  0.06988173]]. Action = [[-0.08059959 -0.04108346  0.          0.7860532 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 907 is [True, False, False, False, True, False]
Current timestep = 908. State = [[-0.17971197  0.07119281]]. Action = [[0.01806863 0.04568339 0.         0.87451863]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 908 is [True, False, False, False, True, False]
State prediction error at timestep 908 is 0.012
Human Feedback received at timestep 908 of None
Current timestep = 909. State = [[-0.17504737  0.0696516 ]]. Action = [[ 0.09899142 -0.05589607  0.          0.2814293 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 909 is [True, False, False, False, True, False]
Current timestep = 910. State = [[-0.17547342  0.06902354]]. Action = [[-0.06328503  0.02443359  0.          0.6967299 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 910 is [True, False, False, False, True, False]
Current timestep = 911. State = [[-0.17307092  0.0681084 ]]. Action = [[ 0.09653551 -0.02532632  0.          0.25446916]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 911 is [True, False, False, False, True, False]
Current timestep = 912. State = [[-0.16645057  0.06701157]]. Action = [[0.08972823 0.00527827 0.         0.0655055 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 912 is [True, False, False, False, True, False]
Current timestep = 913. State = [[-0.16066483  0.06936903]]. Action = [[ 0.0677987   0.06183898  0.         -0.93427217]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 913 is [True, False, False, False, True, False]
Current timestep = 914. State = [[-0.15798639  0.06651373]]. Action = [[ 0.00903265 -0.08073846  0.         -0.5293332 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 914 is [True, False, False, False, True, False]
Current timestep = 915. State = [[-0.1530934   0.06682885]]. Action = [[0.08118217 0.06520467 0.         0.6361582 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 915 is [True, False, False, False, True, False]
Current timestep = 916. State = [[-0.14844765  0.0676036 ]]. Action = [[ 0.03548845 -0.00778349  0.          0.35799026]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 916 is [True, False, False, False, True, False]
Current timestep = 917. State = [[-0.15066029  0.06472596]]. Action = [[-0.09790182 -0.05136839  0.          0.50291705]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 917 is [True, False, False, False, True, False]
Current timestep = 918. State = [[-0.15351132  0.06780492]]. Action = [[-0.02586622  0.0898725   0.          0.2557869 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 918 is [True, False, False, False, True, False]
Current timestep = 919. State = [[-0.15575577  0.0701191 ]]. Action = [[-0.03693535 -0.01333588  0.         -0.7058575 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 919 is [True, False, False, False, True, False]
Current timestep = 920. State = [[-0.1590824   0.07176466]]. Action = [[-0.05469064  0.02418448  0.          0.5819497 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 920 is [True, False, False, False, True, False]
Current timestep = 921. State = [[-0.15801008  0.0781119 ]]. Action = [[ 0.0597868   0.09788913  0.         -0.27533615]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 921 is [True, False, False, False, True, False]
Current timestep = 922. State = [[-0.15431795  0.07703201]]. Action = [[ 0.04750434 -0.09664341  0.         -0.7038536 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 922 is [True, False, False, False, True, False]
Current timestep = 923. State = [[-0.14947638  0.07079594]]. Action = [[ 0.06065626 -0.07862227  0.         -0.28851628]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 923 is [True, False, False, False, True, False]
Current timestep = 924. State = [[-0.14554588  0.07095708]]. Action = [[ 0.0300464   0.05586015  0.         -0.7354646 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 924 is [True, False, False, False, True, False]
Current timestep = 925. State = [[-0.14016731  0.07689079]]. Action = [[ 0.08316027  0.09315776  0.         -0.88165176]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 925 is [True, False, False, False, True, False]
Current timestep = 926. State = [[-0.1404821   0.08257522]]. Action = [[-0.06537471  0.05589854  0.          0.9782543 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 926 is [True, False, False, False, True, False]
Current timestep = 927. State = [[-0.14586617  0.08480962]]. Action = [[-0.07951075 -0.00536416  0.          0.484581  ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 927 is [True, False, False, False, True, False]
Current timestep = 928. State = [[-0.14959571  0.08630702]]. Action = [[-0.03264285  0.00968951  0.         -0.89557725]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 928 is [True, False, False, False, True, False]
Current timestep = 929. State = [[-0.15483503  0.08575725]]. Action = [[-0.08804687 -0.04126343  0.          0.3785901 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 929 is [True, False, False, False, True, False]
State prediction error at timestep 929 is 0.012
Human Feedback received at timestep 929 of None
Current timestep = 930. State = [[-0.16078313  0.0871637 ]]. Action = [[-0.07188775  0.02567974  0.         -0.9348801 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 930 is [True, False, False, False, True, False]
Current timestep = 931. State = [[-0.16468245  0.09130588]]. Action = [[-0.02623191  0.04378626  0.          0.8469348 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 931 is [True, False, False, False, True, False]
Current timestep = 932. State = [[-0.16302246  0.08994165]]. Action = [[ 0.06884205 -0.07363455  0.         -0.48603934]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 932 is [True, False, False, False, True, False]
State prediction error at timestep 932 is 0.012
Human Feedback received at timestep 932 of None
Current timestep = 933. State = [[-0.15988678  0.08771329]]. Action = [[ 0.04025096 -0.00834483  0.         -0.39977723]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 933 is [True, False, False, False, True, False]
State prediction error at timestep 933 is 0.012
Human Feedback received at timestep 933 of None
Current timestep = 934. State = [[-0.1610446   0.08538701]]. Action = [[-0.04115825 -0.03977817  0.         -0.7556489 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 934 is [True, False, False, False, True, False]
Current timestep = 935. State = [[-0.16645798  0.08384369]]. Action = [[-0.08550342 -0.00930098  0.          0.51018786]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 935 is [True, False, False, False, True, False]
Current timestep = 936. State = [[-0.17150725  0.08701146]]. Action = [[-0.04422996  0.06685717  0.          0.68021655]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 936 is [True, False, False, False, True, False]
Current timestep = 937. State = [[-0.17429686  0.08859324]]. Action = [[-0.01000511 -0.01128369  0.          0.46054518]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 937 is [True, False, False, False, True, False]
Current timestep = 938. State = [[-0.17245503  0.08900879]]. Action = [[0.06727143 0.0131681  0.         0.906888  ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 938 is [True, False, False, False, True, False]
Current timestep = 939. State = [[-0.17228872  0.08799825]]. Action = [[-0.01332896 -0.02220585  0.         -0.11340064]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 939 is [True, False, False, False, True, False]
Current timestep = 940. State = [[-0.1741949   0.08816673]]. Action = [[-0.01680029  0.02067788  0.          0.80609727]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 940 is [True, False, False, False, True, False]
Current timestep = 941. State = [[-0.17809251  0.08426148]]. Action = [[-0.05739452 -0.08833259  0.         -0.46496332]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 941 is [True, False, False, False, True, False]
Current timestep = 942. State = [[-0.18147305  0.08578055]]. Action = [[-0.02508176  0.08452003  0.         -0.29688525]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 942 is [True, False, False, False, True, False]
Current timestep = 943. State = [[-0.1798922   0.09219639]]. Action = [[0.07462993 0.08427846 0.         0.7790005 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 943 is [True, False, False, False, True, False]
Current timestep = 944. State = [[-0.17631218  0.09521977]]. Action = [[0.06055851 0.01179151 0.         0.97877383]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 944 is [True, False, False, False, True, False]
Current timestep = 945. State = [[-0.17597193  0.09444095]]. Action = [[-0.01235661 -0.02439753  0.         -0.45056152]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 945 is [True, False, False, False, True, False]
State prediction error at timestep 945 is 0.012
Human Feedback received at timestep 945 of None
Current timestep = 946. State = [[-0.17587997  0.09279161]]. Action = [[ 0.01561481 -0.02096728  0.          0.8735049 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 946 is [True, False, False, False, True, False]
Current timestep = 947. State = [[-0.17452836  0.0874605 ]]. Action = [[ 0.01918431 -0.09318873  0.         -0.3469535 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 947 is [True, False, False, False, True, False]
State prediction error at timestep 947 is 0.012
Human Feedback received at timestep 947 of None
Current timestep = 948. State = [[-0.17141807  0.08528547]]. Action = [[ 0.04498086  0.01954328  0.         -0.02904272]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 948 is [True, False, False, False, True, False]
Current timestep = 949. State = [[-0.17215289  0.08681424]]. Action = [[-0.04869395  0.03177086  0.         -0.28634965]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 949 is [True, False, False, False, True, False]
Current timestep = 950. State = [[-0.171425   0.0880674]]. Action = [[ 0.03578683  0.01071352  0.         -0.7555905 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 950 is [True, False, False, False, True, False]
Current timestep = 951. State = [[-0.16642423  0.09077515]]. Action = [[0.08200314 0.05443198 0.         0.6757114 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 951 is [True, False, False, False, True, False]
Current timestep = 952. State = [[-0.16690296  0.08773336]]. Action = [[-0.07424372 -0.09158712  0.          0.6195617 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 952 is [True, False, False, False, True, False]
Current timestep = 953. State = [[-0.1720067   0.08537382]]. Action = [[-0.069371    0.00381778  0.         -0.21495974]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 953 is [True, False, False, False, True, False]
Current timestep = 954. State = [[-0.17387974  0.08970518]]. Action = [[0.01090918 0.08659453 0.         0.38285136]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 954 is [True, False, False, False, True, False]
Current timestep = 955. State = [[-0.17424396  0.09213205]]. Action = [[ 0.00254086 -0.00507199  0.         -0.7048568 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 955 is [True, False, False, False, True, False]
Current timestep = 956. State = [[-0.17316958  0.09220784]]. Action = [[ 0.03166268 -0.00197843  0.          0.51603174]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 956 is [True, False, False, False, True, False]
State prediction error at timestep 956 is 0.012
Human Feedback received at timestep 956 of None
Current timestep = 957. State = [[-0.16933496  0.09699862]]. Action = [[0.07444104 0.09782951 0.         0.6951506 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 957 is [True, False, False, False, True, False]
Current timestep = 958. State = [[-0.16392775  0.09978405]]. Action = [[0.08405428 0.00096381 0.         0.50041604]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 958 is [True, False, False, False, True, False]
Current timestep = 959. State = [[-0.15863706  0.09871928]]. Action = [[ 0.06241379 -0.02273578  0.          0.04101753]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 959 is [True, False, False, False, True, False]
Current timestep = 960. State = [[-0.15244155  0.10190117]]. Action = [[ 0.08441157  0.0815258   0.         -0.523966  ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 960 is [True, False, False, False, True, False]
Current timestep = 961. State = [[-0.14875649  0.10804819]]. Action = [[ 0.0206154  0.079207   0.        -0.8064507]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 961 is [True, False, False, False, True, False]
Current timestep = 962. State = [[-0.14933148  0.10704244]]. Action = [[-0.04263875 -0.07917876  0.         -0.21784282]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 962 is [True, False, False, False, True, False]
Current timestep = 963. State = [[-0.1491846   0.10227298]]. Action = [[-0.00197476 -0.06882813  0.         -0.13169128]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 963 is [True, False, False, False, True, False]
Current timestep = 964. State = [[-0.14863567  0.10343456]]. Action = [[-0.01502205  0.05394488  0.          0.84701204]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 964 is [True, False, False, False, True, False]
State prediction error at timestep 964 is 0.012
Human Feedback received at timestep 964 of None
Current timestep = 965. State = [[-0.14332382  0.10701504]]. Action = [[0.09899279 0.03348307 0.         0.96536326]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 965 is [True, False, False, False, True, False]
State prediction error at timestep 965 is 0.012
Human Feedback received at timestep 965 of None
Current timestep = 966. State = [[-0.13617674  0.11010479]]. Action = [[0.07116457 0.03746688 0.         0.1969577 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 966 is [True, False, False, False, True, False]
State prediction error at timestep 966 is 0.012
Human Feedback received at timestep 966 of None
Current timestep = 967. State = [[-0.13036115  0.10849258]]. Action = [[ 0.04990234 -0.05827497  0.          0.75828576]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 967 is [True, False, False, False, True, False]
Current timestep = 968. State = [[-0.1296086   0.11048762]]. Action = [[-0.04811747  0.06874769  0.          0.5653417 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 968 is [True, False, False, False, True, False]
Current timestep = 969. State = [[-0.12470498  0.11058345]]. Action = [[ 0.09725779 -0.04575193  0.         -0.12988919]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 969 is [True, False, False, False, True, False]
Current timestep = 970. State = [[-0.12318584  0.11053003]]. Action = [[-0.06089608  0.0163299   0.         -0.80751985]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 970 is [True, False, False, False, True, False]
State prediction error at timestep 970 is 0.012
Human Feedback received at timestep 970 of None
Current timestep = 971. State = [[-0.12400652  0.11435236]]. Action = [[-0.01447992  0.05521802  0.          0.8585055 ]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 971 is [True, False, False, False, True, False]
State prediction error at timestep 971 is 0.012
Human Feedback received at timestep 971 of None
Current timestep = 972. State = [[-0.12283225  0.1212726 ]]. Action = [[ 0.01719111  0.08940654  0.         -0.01785398]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 972 is [True, False, False, False, True, False]
Current timestep = 973. State = [[-0.11891706  0.12581326]]. Action = [[ 0.0634846   0.01896201  0.         -0.5259989 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 973 is [True, False, False, False, True, False]
Current timestep = 974. State = [[-0.11606409  0.12917513]]. Action = [[0.01359548 0.03608038 0.         0.20189917]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 974 is [True, False, False, False, False, True]
Current timestep = 975. State = [[-0.11638793  0.12991078]]. Action = [[-0.02777552 -0.02939115  0.         -0.28144813]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 975 is [True, False, False, False, False, True]
Current timestep = 976. State = [[-0.12093297  0.130407  ]]. Action = [[-0.09690737 -0.00301504  0.          0.55649614]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 976 is [True, False, False, False, False, True]
State prediction error at timestep 976 is 0.012
Human Feedback received at timestep 976 of None
Current timestep = 977. State = [[-0.12312904  0.12729418]]. Action = [[-0.01011229 -0.09242389  0.         -0.50125897]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 977 is [True, False, False, False, False, True]
Current timestep = 978. State = [[-0.11832361  0.12657082]]. Action = [[ 0.09578169  0.02359129  0.         -0.3578788 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 978 is [True, False, False, False, False, True]
Current timestep = 979. State = [[-0.11040632  0.12930329]]. Action = [[ 0.09676328  0.0420832   0.         -0.45464778]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 979 is [True, False, False, False, False, True]
Current timestep = 980. State = [[-0.10711206  0.12734337]]. Action = [[-0.01192524 -0.06527869  0.          0.31549096]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 980 is [True, False, False, False, False, True]
State prediction error at timestep 980 is 0.012
Human Feedback received at timestep 980 of None
Current timestep = 981. State = [[-0.10245047  0.12334814]]. Action = [[ 0.07798595 -0.03863639  0.         -0.6364405 ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 981 is [True, False, False, False, False, True]
Current timestep = 982. State = [[-0.1011211   0.12072139]]. Action = [[-0.0427819  -0.01712835  0.          0.89997673]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 982 is [True, False, False, False, True, False]
State prediction error at timestep 982 is 0.012
Human Feedback received at timestep 982 of None
Current timestep = 983. State = [[-0.10036274  0.12351919]]. Action = [[ 0.01721631  0.0766285   0.         -0.6600516 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 983 is [True, False, False, False, True, False]
Current timestep = 984. State = [[-0.09577876  0.12503332]]. Action = [[ 0.07465675 -0.00395219  0.         -0.83267987]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 984 is [True, False, False, False, True, False]
Current timestep = 985. State = [[-0.09458878  0.12372053]]. Action = [[-0.03359612 -0.01797117  0.          0.8324299 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 985 is [True, False, False, False, False, True]
Current timestep = 986. State = [[-0.09445831  0.12215996]]. Action = [[ 0.0043617  -0.01707197  0.          0.7571852 ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 986 is [True, False, False, False, True, False]
Current timestep = 987. State = [[-0.09128989  0.12556267]]. Action = [[0.05393986 0.08451789 0.         0.91074586]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 987 is [True, False, False, False, True, False]
Current timestep = 988. State = [[-0.09342349  0.12440124]]. Action = [[-0.09513517 -0.07575029  0.          0.5027149 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 988 is [True, False, False, False, False, True]
Current timestep = 989. State = [[-0.09393582  0.12034896]]. Action = [[ 0.03991907 -0.04135776  0.          0.14787495]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 989 is [True, False, False, False, True, False]
State prediction error at timestep 989 is 0.012
Human Feedback received at timestep 989 of None
Current timestep = 990. State = [[-0.09232879  0.11853708]]. Action = [[ 0.01049151 -0.00351747  0.         -0.08527881]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 990 is [True, False, False, False, True, False]
Current timestep = 991. State = [[-0.09308257  0.11486947]]. Action = [[-0.02764587 -0.06312492  0.          0.650923  ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 991 is [True, False, False, False, True, False]
State prediction error at timestep 991 is 0.012
Human Feedback received at timestep 991 of None
Current timestep = 992. State = [[-0.09498535  0.113911  ]]. Action = [[-0.03136913  0.02429801  0.          0.6611495 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 992 is [True, False, False, False, True, False]
Current timestep = 993. State = [[-0.09146675  0.11277775]]. Action = [[ 0.09209859 -0.02520504  0.         -0.692278  ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 993 is [True, False, False, False, True, False]
Current timestep = 994. State = [[-0.09177025  0.11459894]]. Action = [[-0.06004525  0.06383594  0.          0.4478165 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 994 is [True, False, False, False, True, False]
Current timestep = 995. State = [[-0.09754324  0.1146182 ]]. Action = [[-0.08616318 -0.03452219  0.         -0.5358048 ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 995 is [True, False, False, False, True, False]
State prediction error at timestep 995 is 0.012
Human Feedback received at timestep 995 of None
Current timestep = 996. State = [[-0.09978438  0.11398407]]. Action = [[ 0.00700314  0.00219162  0.         -0.5991376 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 996 is [True, False, False, False, True, False]
Current timestep = 997. State = [[-0.10394139  0.11108261]]. Action = [[-0.08489864 -0.06169039  0.          0.7437209 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 997 is [True, False, False, False, True, False]
Current timestep = 998. State = [[-0.11087722  0.10505649]]. Action = [[-0.09520837 -0.0915528   0.          0.5565076 ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 998 is [True, False, False, False, True, False]
Current timestep = 999. State = [[-0.11136221  0.0994935 ]]. Action = [[ 0.05635961 -0.05256925  0.          0.8191378 ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 999 is [True, False, False, False, True, False]
Current timestep = 1000. State = [[-0.11088982  0.09386621]]. Action = [[-0.02084371 -0.06486428  0.          0.36910772]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 1000 is [True, False, False, False, True, False]
State prediction error at timestep 1000 is 0.012
Human Feedback received at timestep 1000 of None
Current timestep = 1001. State = [[-0.11303467  0.08694663]]. Action = [[-0.03861452 -0.08106516  0.         -0.37766755]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 1001 is [True, False, False, False, True, False]
Current timestep = 1002. State = [[-0.11255932  0.08228175]]. Action = [[ 0.02965219 -0.01920224  0.          0.7019793 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 1002 is [True, False, False, False, True, False]
Current timestep = 1003. State = [[-0.11222149  0.07508282]]. Action = [[-0.00776701 -0.09812682  0.          0.9466896 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 1003 is [True, False, False, False, True, False]
Current timestep = 1004. State = [[-0.11453635  0.06929614]]. Action = [[-0.0441862  -0.02287438  0.          0.22634363]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 1004 is [True, False, False, False, True, False]
Current timestep = 1005. State = [[-0.1177784   0.06302957]]. Action = [[-0.03817734 -0.07460159  0.         -0.77004814]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 1005 is [True, False, False, False, True, False]
Current timestep = 1006. State = [[-0.11727311  0.05694324]]. Action = [[ 0.03919714 -0.03906184  0.          0.87841535]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 1006 is [True, False, False, False, True, False]
State prediction error at timestep 1006 is 0.012
Human Feedback received at timestep 1006 of None
Current timestep = 1007. State = [[-0.11772471  0.05198858]]. Action = [[-0.02054184 -0.03128257  0.          0.90425086]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 1007 is [True, False, False, False, True, False]
State prediction error at timestep 1007 is 0.012
Human Feedback received at timestep 1007 of None
Current timestep = 1008. State = [[-0.11761151  0.05143966]]. Action = [[ 0.02725398  0.04996251  0.         -0.6225882 ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 1008 is [True, False, False, False, True, False]
Current timestep = 1009. State = [[-0.11356198  0.05360307]]. Action = [[0.09491577 0.0544657  0.         0.76703167]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 1009 is [True, False, False, False, True, False]
Current timestep = 1010. State = [[-0.11167067  0.05076107]]. Action = [[ 0.01019116 -0.05599188  0.         -0.68790007]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 1010 is [True, False, False, False, True, False]
Current timestep = 1011. State = [[-0.10858008  0.04905679]]. Action = [[ 0.07431579  0.02838691  0.         -0.03772992]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 1011 is [True, False, False, False, True, False]
Current timestep = 1012. State = [[-0.10608076  0.04888009]]. Action = [[0.0269706  0.01076402 0.         0.42734635]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 1012 is [True, False, False, False, True, False]
Current timestep = 1013. State = [[-0.11011705  0.04931031]]. Action = [[-0.0946182   0.02043293  0.         -0.2018624 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 1013 is [True, False, False, False, True, False]
State prediction error at timestep 1013 is 0.012
Human Feedback received at timestep 1013 of None
Current timestep = 1014. State = [[-0.10989784  0.05092245]]. Action = [[ 0.0751218   0.02965959  0.         -0.86963993]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 1014 is [True, False, False, False, True, False]
Current timestep = 1015. State = [[-0.10614147  0.05081174]]. Action = [[ 0.04310875 -0.01290338  0.          0.16432142]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 1015 is [True, False, False, False, True, False]
State prediction error at timestep 1015 is 0.012
Human Feedback received at timestep 1015 of None
Current timestep = 1016. State = [[-0.10575353  0.05460204]]. Action = [[-0.01784409  0.0863105   0.         -0.79304975]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 1016 is [True, False, False, False, True, False]
State prediction error at timestep 1016 is 0.012
Human Feedback received at timestep 1016 of None
Current timestep = 1017. State = [[-0.1032171   0.06169716]]. Action = [[ 0.06661092  0.08675348  0.         -0.05441201]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 1017 is [True, False, False, False, True, False]
Current timestep = 1018. State = [[-0.10193689  0.06288766]]. Action = [[-0.00794149 -0.0415217   0.          0.12224686]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 1018 is [True, False, False, False, True, False]
State prediction error at timestep 1018 is 0.012
Human Feedback received at timestep 1018 of None
Current timestep = 1019. State = [[-0.10561437  0.06481283]]. Action = [[-0.08073373  0.04130784  0.         -0.6694067 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 1019 is [True, False, False, False, True, False]
Current timestep = 1020. State = [[-0.11179961  0.07162617]]. Action = [[-0.08933624  0.08410076  0.         -0.6760888 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 1020 is [True, False, False, False, True, False]
State prediction error at timestep 1020 is 0.012
Human Feedback received at timestep 1020 of None
Current timestep = 1021. State = [[-0.11588252  0.07678837]]. Action = [[-0.030038    0.01414088  0.         -0.66972756]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 1021 is [True, False, False, False, True, False]
State prediction error at timestep 1021 is 0.012
Human Feedback received at timestep 1021 of None
Current timestep = 1022. State = [[-0.11748455  0.07789499]]. Action = [[-0.01067324 -0.02871726  0.          0.25382912]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 1022 is [True, False, False, False, True, False]
Current timestep = 1023. State = [[-0.11876905  0.07660843]]. Action = [[-0.01955844 -0.04419378  0.         -0.51790446]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 1023 is [True, False, False, False, True, False]
Current timestep = 1024. State = [[-0.12038306  0.07781783]]. Action = [[-0.0218103   0.02387957  0.         -0.04514879]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 1024 is [True, False, False, False, True, False]
State prediction error at timestep 1024 is 0.012
Human Feedback received at timestep 1024 of None
Current timestep = 1025. State = [[-0.11849897  0.08110186]]. Action = [[0.05867507 0.03275304 0.         0.53611016]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 1025 is [True, False, False, False, True, False]
Current timestep = 1026. State = [[-0.11551243  0.0814309 ]]. Action = [[ 0.03775021 -0.02569739  0.         -0.7047712 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 1026 is [True, False, False, False, True, False]
State prediction error at timestep 1026 is 0.012
Human Feedback received at timestep 1026 of None
Current timestep = 1027. State = [[-0.11506626  0.08296356]]. Action = [[-0.00988653  0.03807948  0.         -0.07900125]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 1027 is [True, False, False, False, True, False]
Current timestep = 1028. State = [[-0.1124602   0.08354037]]. Action = [[ 0.06175292 -0.01478218  0.          0.5770025 ]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 1028 is [True, False, False, False, True, False]
State prediction error at timestep 1028 is 0.012
Human Feedback received at timestep 1028 of None
Current timestep = 1029. State = [[-0.10816684  0.08455534]]. Action = [[ 0.05522948  0.02999835  0.         -0.56859726]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 1029 is [True, False, False, False, True, False]
State prediction error at timestep 1029 is 0.012
Human Feedback received at timestep 1029 of None
Current timestep = 1030. State = [[-0.1058265  0.0843266]]. Action = [[ 0.01319759 -0.01858497  0.          0.5714809 ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 1030 is [True, False, False, False, True, False]
Current timestep = 1031. State = [[-0.10809428  0.0871883 ]]. Action = [[-0.06280432  0.06686681  0.         -0.02139705]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 1031 is [True, False, False, False, True, False]
State prediction error at timestep 1031 is 0.012
Human Feedback received at timestep 1031 of None
Current timestep = 1032. State = [[-0.10947809  0.09256072]]. Action = [[ 0.00418463  0.06028608  0.         -0.4935966 ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 1032 is [True, False, False, False, True, False]
Current timestep = 1033. State = [[-0.113499    0.09049396]]. Action = [[-0.08997542 -0.09533142  0.         -0.24315941]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 1033 is [True, False, False, False, True, False]
State prediction error at timestep 1033 is 0.012
Human Feedback received at timestep 1033 of None
Current timestep = 1034. State = [[-0.11208943  0.08421322]]. Action = [[ 0.07782345 -0.08356238  0.          0.7948768 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 1034 is [True, False, False, False, True, False]
State prediction error at timestep 1034 is 0.012
Human Feedback received at timestep 1034 of None
Current timestep = 1035. State = [[-0.11315015  0.08270315]]. Action = [[-0.08291986  0.0194141   0.         -0.04008788]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 1035 is [True, False, False, False, True, False]
Current timestep = 1036. State = [[-0.11368313  0.07968489]]. Action = [[ 0.01904037 -0.07277864  0.          0.34697163]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 1036 is [True, False, False, False, True, False]
State prediction error at timestep 1036 is 0.012
Human Feedback received at timestep 1036 of None
Current timestep = 1037. State = [[-0.11335889  0.08032586]]. Action = [[-0.0129336   0.05921068  0.         -0.33567202]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 1037 is [True, False, False, False, True, False]
Current timestep = 1038. State = [[-0.11173155  0.08106302]]. Action = [[ 0.03766171 -0.01354218  0.          0.53323567]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 1038 is [True, False, False, False, True, False]
State prediction error at timestep 1038 is 0.012
Human Feedback received at timestep 1038 of None
Current timestep = 1039. State = [[-0.11091799  0.07703191]]. Action = [[-0.00844985 -0.06800191  0.         -0.6106459 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 1039 is [True, False, False, False, True, False]
State prediction error at timestep 1039 is 0.012
Human Feedback received at timestep 1039 of None
Current timestep = 1040. State = [[-0.10785332  0.07146518]]. Action = [[ 0.05811655 -0.05851182  0.         -0.12160766]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 1040 is [True, False, False, False, True, False]
Current timestep = 1041. State = [[-0.10869945  0.06671739]]. Action = [[-0.06372258 -0.04003153  0.          0.56736994]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 1041 is [True, False, False, False, True, False]
Current timestep = 1042. State = [[-0.11262862  0.06096492]]. Action = [[-0.05953641 -0.07325477  0.          0.3312087 ]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 1042 is [True, False, False, False, True, False]
Current timestep = 1043. State = [[-0.1130095  0.0586995]]. Action = [[ 0.01984215  0.01912104  0.         -0.55158883]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 1043 is [True, False, False, False, True, False]
Current timestep = 1044. State = [[-0.10808548  0.06274994]]. Action = [[ 0.09985802  0.09805235  0.         -0.29405463]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 1044 is [True, False, False, False, True, False]
Current timestep = 1045. State = [[-0.10492366  0.06229347]]. Action = [[ 0.02067767 -0.04399825  0.          0.9547901 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 1045 is [True, False, False, False, True, False]
Current timestep = 1046. State = [[-0.1072356   0.05963225]]. Action = [[-0.05967481 -0.01327957  0.          0.19046116]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 1046 is [True, False, False, False, True, False]
State prediction error at timestep 1046 is 0.012
Human Feedback received at timestep 1046 of None
Current timestep = 1047. State = [[-0.10731847  0.05500591]]. Action = [[ 0.03068823 -0.07041498  0.         -0.0634523 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 1047 is [True, False, False, False, True, False]
Current timestep = 1048. State = [[-0.10536672  0.049998  ]]. Action = [[ 0.02183378 -0.03973609  0.         -0.45328498]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 1048 is [True, False, False, False, True, False]
Current timestep = 1049. State = [[-0.10069636  0.05166095]]. Action = [[0.08375234 0.08233904 0.         0.5564741 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 1049 is [True, False, False, False, True, False]
State prediction error at timestep 1049 is 0.012
Human Feedback received at timestep 1049 of None
Current timestep = 1050. State = [[-0.10070105  0.05124347]]. Action = [[-0.05101869 -0.03691415  0.          0.22185814]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 1050 is [True, False, False, False, True, False]
Current timestep = 1051. State = [[-0.1015928  0.0470547]]. Action = [[ 0.00898547 -0.05141078  0.          0.99601007]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 1051 is [True, False, False, False, True, False]
Current timestep = 1052. State = [[-0.10272072  0.04806157]]. Action = [[-0.02541732  0.06571389  0.         -0.66212404]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 1052 is [True, False, False, False, True, False]
Current timestep = 1053. State = [[-0.10735261  0.04781778]]. Action = [[-0.07836245 -0.03584678  0.          0.6744528 ]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 1053 is [True, False, False, False, True, False]
Current timestep = 1054. State = [[-0.10976775  0.0504407 ]]. Action = [[-0.0005331   0.07210588  0.         -0.01992548]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 1054 is [True, False, False, False, True, False]
Current timestep = 1055. State = [[-0.11074518  0.05121381]]. Action = [[-0.00695431 -0.02911751  0.          0.3158083 ]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 1055 is [True, False, False, False, True, False]
State prediction error at timestep 1055 is 0.012
Human Feedback received at timestep 1055 of None
Current timestep = 1056. State = [[-0.10958435  0.05257226]]. Action = [[ 0.03859293  0.0391767   0.         -0.9458256 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 1056 is [True, False, False, False, True, False]
Current timestep = 1057. State = [[-0.10454451  0.05407992]]. Action = [[0.09889691 0.00837018 0.         0.3293903 ]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 1057 is [True, False, False, False, True, False]
Current timestep = 1058. State = [[-0.10422716  0.05120014]]. Action = [[-0.04780402 -0.06218441  0.         -0.4087019 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 1058 is [True, False, False, False, True, False]
Current timestep = 1059. State = [[-0.10791817  0.05088525]]. Action = [[-0.04498581  0.03062291  0.         -0.12226999]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 1059 is [True, False, False, False, True, False]
Current timestep = 1060. State = [[-0.11448519  0.05490728]]. Action = [[-0.09922152  0.05984075  0.          0.93935084]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 1060 is [True, False, False, False, True, False]
Current timestep = 1061. State = [[-0.12080501  0.05904512]]. Action = [[-0.05823983  0.03245046  0.         -0.31689984]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 1061 is [True, False, False, False, True, False]
State prediction error at timestep 1061 is 0.012
Human Feedback received at timestep 1061 of None
Current timestep = 1062. State = [[-0.12664811  0.0567809 ]]. Action = [[-0.06791382 -0.08552685  0.         -0.10924006]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 1062 is [True, False, False, False, True, False]
State prediction error at timestep 1062 is 0.012
Human Feedback received at timestep 1062 of None
Current timestep = 1063. State = [[-0.13116942  0.05548143]]. Action = [[-0.03835889  0.00760498  0.          0.1677171 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 1063 is [True, False, False, False, True, False]
Current timestep = 1064. State = [[-0.13462283  0.06091525]]. Action = [[-0.02342618  0.09562253  0.          0.474051  ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 1064 is [True, False, False, False, True, False]
State prediction error at timestep 1064 is 0.012
Human Feedback received at timestep 1064 of None
Current timestep = 1065. State = [[-0.13797767  0.06884538]]. Action = [[-0.01774765  0.08813121  0.          0.06256223]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 1065 is [True, False, False, False, True, False]
Current timestep = 1066. State = [[-0.14095189  0.0739653 ]]. Action = [[-0.00803383  0.02822735  0.          0.4917779 ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 1066 is [True, False, False, False, True, False]
Current timestep = 1067. State = [[-0.14585027  0.0791458 ]]. Action = [[-0.0532483   0.06201915  0.          0.33800828]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 1067 is [True, False, False, False, True, False]
Current timestep = 1068. State = [[-0.15326993  0.08538495]]. Action = [[-0.07800195  0.05984048  0.         -0.40752316]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 1068 is [True, False, False, False, True, False]
Current timestep = 1069. State = [[-0.15869851  0.08406187]]. Action = [[-0.02515301 -0.09613751  0.          0.06707072]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 1069 is [True, False, False, False, True, False]
Current timestep = 1070. State = [[-0.15948486  0.0854499 ]]. Action = [[0.03605817 0.05909397 0.         0.61523676]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 1070 is [True, False, False, False, True, False]
Current timestep = 1071. State = [[-0.15606615  0.09039073]]. Action = [[ 0.0924653   0.05312584  0.         -0.9475179 ]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 1071 is [True, False, False, False, True, False]
Current timestep = 1072. State = [[-0.15472922  0.0946752 ]]. Action = [[0.01154344 0.04442147 0.         0.25357187]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 1072 is [True, False, False, False, True, False]
Current timestep = 1073. State = [[-0.1524961  0.1004238]]. Action = [[0.06736618 0.07872456 0.         0.2754593 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 1073 is [True, False, False, False, True, False]
State prediction error at timestep 1073 is 0.012
Human Feedback received at timestep 1073 of None
Current timestep = 1074. State = [[-0.15121138  0.10386549]]. Action = [[0.01259811 0.01269738 0.         0.1009233 ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 1074 is [True, False, False, False, True, False]
Current timestep = 1075. State = [[-0.15108037  0.1095544 ]]. Action = [[ 0.0107735   0.09123055  0.         -0.13697726]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 1075 is [True, False, False, False, True, False]
Current timestep = 1076. State = [[-0.14858644  0.11448152]]. Action = [[0.05938841 0.0291119  0.         0.77140117]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 1076 is [True, False, False, False, True, False]
Current timestep = 1077. State = [[-0.15118788  0.11793067]]. Action = [[-0.08621898  0.02688188  0.         -0.8619108 ]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 1077 is [True, False, False, False, True, False]
Current timestep = 1078. State = [[-0.15801547  0.12475893]]. Action = [[-0.08683252  0.08754387  0.          0.14542413]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 1078 is [True, False, False, False, True, False]
Current timestep = 1079. State = [[-0.16218255  0.12459401]]. Action = [[-0.02500013 -0.09717063  0.         -0.745737  ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 1079 is [True, False, False, False, True, False]
State prediction error at timestep 1079 is 0.012
Human Feedback received at timestep 1079 of None
Current timestep = 1080. State = [[-0.15895768  0.12535745]]. Action = [[ 0.09249695  0.03867587  0.         -0.38111818]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 1080 is [True, False, False, False, True, False]
Current timestep = 1081. State = [[-0.15935944  0.12388514]]. Action = [[-0.07693987 -0.07844938  0.          0.26834846]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 1081 is [True, False, False, False, False, True]
State prediction error at timestep 1081 is 0.012
Human Feedback received at timestep 1081 of None
Current timestep = 1082. State = [[-0.15826969  0.12299705]]. Action = [[0.06343985 0.0085208  0.         0.05565238]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 1082 is [True, False, False, False, True, False]
Current timestep = 1083. State = [[-0.15267438  0.12446817]]. Action = [[ 0.07603764  0.02106241  0.         -0.5194232 ]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 1083 is [True, False, False, False, True, False]
Current timestep = 1084. State = [[-0.15329175  0.12092644]]. Action = [[-0.08025346 -0.09109644  0.         -0.26710796]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 1084 is [True, False, False, False, True, False]
Current timestep = 1085. State = [[-0.15432993  0.1210277 ]]. Action = [[ 0.01770906  0.05353705  0.         -0.7641356 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 1085 is [True, False, False, False, True, False]
State prediction error at timestep 1085 is 0.012
Human Feedback received at timestep 1085 of None
Current timestep = 1086. State = [[-0.15808707  0.11951865]]. Action = [[-0.09100384 -0.06055483  0.         -0.80686355]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 1086 is [True, False, False, False, True, False]
Current timestep = 1087. State = [[-0.16377765  0.11646593]]. Action = [[-0.06864703 -0.03243514  0.          0.4985633 ]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 1087 is [True, False, False, False, True, False]
Current timestep = 1088. State = [[-0.16458805  0.1149055 ]]. Action = [[ 0.02999561 -0.00999061  0.          0.92235494]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 1088 is [True, False, False, False, True, False]
Current timestep = 1089. State = [[-0.16844682  0.1115182 ]]. Action = [[-0.09123151 -0.05709622  0.         -0.7561028 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 1089 is [True, False, False, False, True, False]
State prediction error at timestep 1089 is 0.012
Human Feedback received at timestep 1089 of None
Current timestep = 1090. State = [[-0.17603569  0.10678233]]. Action = [[-0.0976013  -0.06005704  0.         -0.22185141]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 1090 is [True, False, False, False, True, False]
Current timestep = 1091. State = [[-0.17836939  0.10821842]]. Action = [[0.03577938 0.07468306 0.         0.04578471]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 1091 is [True, False, False, False, True, False]
State prediction error at timestep 1091 is 0.012
Human Feedback received at timestep 1091 of None
Current timestep = 1092. State = [[-0.17895706  0.10517787]]. Action = [[-0.01110975 -0.09286748  0.          0.9041778 ]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 1092 is [True, False, False, False, True, False]
Current timestep = 1093. State = [[-0.17813696  0.10052825]]. Action = [[ 0.03349041 -0.02681028  0.          0.29017448]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 1093 is [True, False, False, False, True, False]
State prediction error at timestep 1093 is 0.012
Human Feedback received at timestep 1093 of None
Current timestep = 1094. State = [[-0.17938331  0.1013985 ]]. Action = [[-0.0291583   0.05612025  0.          0.1264646 ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 1094 is [True, False, False, False, True, False]
State prediction error at timestep 1094 is 0.012
Human Feedback received at timestep 1094 of None
Current timestep = 1095. State = [[-0.17763416  0.10081613]]. Action = [[ 0.07225894 -0.02463444  0.          0.1765126 ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 1095 is [True, False, False, False, True, False]
Current timestep = 1096. State = [[-0.17536385  0.09449801]]. Action = [[ 0.02088772 -0.09108654  0.         -0.5975807 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 1096 is [True, False, False, False, True, False]
Current timestep = 1097. State = [[-0.17320335  0.09435517]]. Action = [[0.03884349 0.0787148  0.         0.54652596]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 1097 is [True, False, False, False, True, False]
Current timestep = 1098. State = [[-0.17535962  0.09750772]]. Action = [[-0.05422202  0.0421676   0.          0.96172357]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 1098 is [True, False, False, False, True, False]
Current timestep = 1099. State = [[-0.18017532  0.09450909]]. Action = [[-0.05876496 -0.07798339  0.          0.8623661 ]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 1099 is [True, False, False, False, True, False]
Current timestep = 1100. State = [[-0.1850338   0.09366511]]. Action = [[-0.05779624  0.03173969  0.          0.4973917 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 1100 is [True, False, False, False, True, False]
Current timestep = 1101. State = [[-0.1832579   0.09426772]]. Action = [[ 0.09027206  0.00228415  0.         -0.15932077]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 1101 is [True, False, False, False, True, False]
State prediction error at timestep 1101 is 0.012
Human Feedback received at timestep 1101 of None
Current timestep = 1102. State = [[-0.17980026  0.09030682]]. Action = [[ 0.03074531 -0.07073151  0.          0.4543202 ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 1102 is [True, False, False, False, True, False]
Current timestep = 1103. State = [[-0.17619053  0.08479626]]. Action = [[ 0.05133448 -0.05467787  0.          0.4729458 ]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 1103 is [True, False, False, False, True, False]
Current timestep = 1104. State = [[-0.1699646   0.07858681]]. Action = [[ 0.0881355  -0.06759397  0.         -0.03466082]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 1104 is [True, False, False, False, True, False]
Current timestep = 1105. State = [[-0.16253975  0.07717094]]. Action = [[0.08728664 0.04501427 0.         0.41396368]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 1105 is [True, False, False, False, True, False]
Current timestep = 1106. State = [[-0.16098255  0.07365623]]. Action = [[-0.04353527 -0.06529231  0.          0.97683465]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 1106 is [True, False, False, False, True, False]
Current timestep = 1107. State = [[-0.16118972  0.0682261 ]]. Action = [[-0.00163966 -0.04632018  0.          0.2010014 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 1107 is [True, False, False, False, True, False]
Current timestep = 1108. State = [[-0.16255511  0.06381464]]. Action = [[-0.04595179 -0.03363369  0.          0.6286193 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 1108 is [True, False, False, False, True, False]
Current timestep = 1109. State = [[-0.16125287  0.06579705]]. Action = [[ 0.04011657  0.08569717  0.         -0.29200697]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 1109 is [True, False, False, False, True, False]
Current timestep = 1110. State = [[-0.15636295  0.06237661]]. Action = [[ 0.07105752 -0.09536091  0.          0.05505395]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 1110 is [True, False, False, False, True, False]
Current timestep = 1111. State = [[-0.15595858  0.058737  ]]. Action = [[-0.04949622  0.00357267  0.         -0.8297745 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 1111 is [True, False, False, False, True, False]
State prediction error at timestep 1111 is 0.012
Human Feedback received at timestep 1111 of None
Current timestep = 1112. State = [[-0.1575089   0.05513385]]. Action = [[-0.02182097 -0.0537909   0.          0.39956987]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 1112 is [True, False, False, False, True, False]
Current timestep = 1113. State = [[-0.1589548   0.05188253]]. Action = [[-0.03127693 -0.01770736  0.          0.28102612]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 1113 is [True, False, False, False, True, False]
State prediction error at timestep 1113 is 0.012
Human Feedback received at timestep 1113 of None
Current timestep = 1114. State = [[-0.15952013  0.05539149]]. Action = [[-3.3889711e-04  9.6017815e-02  0.0000000e+00 -7.2028416e-01]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 1114 is [True, False, False, False, True, False]
State prediction error at timestep 1114 is 0.012
Human Feedback received at timestep 1114 of None
Current timestep = 1115. State = [[-0.15628448  0.05452622]]. Action = [[ 0.0705403  -0.06371776  0.         -0.64322686]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 1115 is [True, False, False, False, True, False]
Current timestep = 1116. State = [[-0.14970808  0.04722841]]. Action = [[ 0.09413608 -0.09612605  0.         -0.5761867 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 1116 is [True, False, False, False, True, False]
Current timestep = 1117. State = [[-0.14403746  0.04406952]]. Action = [[ 0.05263519  0.01932272  0.         -0.8410431 ]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 1117 is [True, False, False, False, True, False]
Current timestep = 1118. State = [[-0.14334558  0.04301149]]. Action = [[-0.03061829 -0.00665709  0.         -0.6764481 ]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 1118 is [True, False, False, False, True, False]
Current timestep = 1119. State = [[-0.13965634  0.04142392]]. Action = [[ 0.07936322 -0.00867285  0.         -0.27094448]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 1119 is [True, False, False, False, True, False]
Current timestep = 1120. State = [[-0.14011072  0.04313385]]. Action = [[-0.07138537  0.05758248  0.         -0.56213   ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 1120 is [True, False, False, False, True, False]
Current timestep = 1121. State = [[-0.14541595  0.04845327]]. Action = [[-0.07923868  0.0784171   0.          0.7685051 ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 1121 is [True, False, False, False, True, False]
Current timestep = 1122. State = [[-0.14867729  0.05219546]]. Action = [[-0.01872879  0.01940761  0.         -0.6331923 ]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 1122 is [True, False, False, False, True, False]
Current timestep = 1123. State = [[-0.15068917  0.05280355]]. Action = [[-0.0235596  -0.01566777  0.          0.5209148 ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 1123 is [True, False, False, False, True, False]
Current timestep = 1124. State = [[-0.15083243  0.04978044]]. Action = [[ 0.01431645 -0.06595671  0.         -0.64963424]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 1124 is [True, False, False, False, True, False]
Current timestep = 1125. State = [[-0.1531801   0.05122465]]. Action = [[-0.05302828  0.05865135  0.          0.1919713 ]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 1125 is [True, False, False, False, True, False]
State prediction error at timestep 1125 is 0.012
Human Feedback received at timestep 1125 of None
Current timestep = 1126. State = [[-0.15238938  0.05455569]]. Action = [[ 0.05706917  0.02305482  0.         -0.6911782 ]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 1126 is [True, False, False, False, True, False]
Current timestep = 1127. State = [[-0.15571839  0.05963759]]. Action = [[-0.08954783  0.07420962  0.         -0.946771  ]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 1127 is [True, False, False, False, True, False]
Current timestep = 1128. State = [[-0.16243327  0.06206665]]. Action = [[-0.07140861 -0.0160872   0.          0.27415884]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 1128 is [True, False, False, False, True, False]
Current timestep = 1129. State = [[-0.16183497  0.06251433]]. Action = [[ 0.08051687 -0.00306795  0.         -0.6425678 ]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 1129 is [True, False, False, False, True, False]
State prediction error at timestep 1129 is 0.012
Human Feedback received at timestep 1129 of None
Current timestep = 1130. State = [[-0.16095556  0.05807082]]. Action = [[-0.01558075 -0.0989446   0.          0.7079396 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 1130 is [True, False, False, False, True, False]
Current timestep = 1131. State = [[-0.16238551  0.05463962]]. Action = [[-0.02313057 -0.01685525  0.          0.60168076]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 1131 is [True, False, False, False, True, False]
Current timestep = 1132. State = [[-0.1676314   0.05202588]]. Action = [[-0.09658629 -0.04293556  0.         -0.6546779 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 1132 is [True, False, False, False, True, False]
Current timestep = 1133. State = [[-0.16950816  0.04993692]]. Action = [[ 0.01797029 -0.01677885  0.          0.25757754]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 1133 is [True, False, False, False, True, False]
State prediction error at timestep 1133 is 0.012
Human Feedback received at timestep 1133 of None
Current timestep = 1134. State = [[-0.16612983  0.04948385]]. Action = [[ 0.06729489  0.01073712  0.         -0.4664569 ]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 1134 is [True, False, False, False, True, False]
Current timestep = 1135. State = [[-0.16637443  0.0527865 ]]. Action = [[-0.03340343  0.07269412  0.         -0.6715493 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 1135 is [True, False, False, False, True, False]
Current timestep = 1136. State = [[-0.16981246  0.05442827]]. Action = [[-0.04082282 -0.00509984  0.          0.7397363 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 1136 is [True, False, False, False, True, False]
Current timestep = 1137. State = [[-0.17358051  0.05626208]]. Action = [[-0.03996485  0.03758051  0.         -0.04586554]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 1137 is [True, False, False, False, True, False]
State prediction error at timestep 1137 is 0.012
Human Feedback received at timestep 1137 of None
Current timestep = 1138. State = [[-0.17139748  0.05302951]]. Action = [[ 0.08587527 -0.08662061  0.         -0.7593437 ]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 1138 is [True, False, False, False, True, False]
Current timestep = 1139. State = [[-0.17179143  0.04684042]]. Action = [[-0.05228643 -0.06798575  0.          0.5707611 ]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 1139 is [True, False, False, False, True, False]
State prediction error at timestep 1139 is 0.012
Human Feedback received at timestep 1139 of None
Current timestep = 1140. State = [[-0.17660749  0.04417193]]. Action = [[-0.06898434 -0.00360665  0.          0.8766681 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 1140 is [True, False, False, False, True, False]
Current timestep = 1141. State = [[-0.17467785  0.0452201 ]]. Action = [[ 0.09820833  0.03642366  0.         -0.66993695]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 1141 is [True, False, False, False, True, False]
State prediction error at timestep 1141 is 0.012
Human Feedback received at timestep 1141 of None
Current timestep = 1142. State = [[-0.17248842  0.04853642]]. Action = [[-2.4718046e-04  5.7755463e-02  0.0000000e+00  7.6931596e-01]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 1142 is [True, False, False, False, True, False]
Current timestep = 1143. State = [[-0.1770894   0.05153024]]. Action = [[-0.09248409  0.02866315  0.          0.97019506]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 1143 is [True, False, False, False, True, False]
Current timestep = 1144. State = [[-0.18259844  0.05498809]]. Action = [[-0.05250495  0.04391243  0.         -0.14698052]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 1144 is [True, False, False, False, True, False]
Current timestep = 1145. State = [[-0.18382475  0.05885841]]. Action = [[ 0.02464922  0.03905082  0.         -0.9870381 ]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 1145 is [True, False, False, False, True, False]
Current timestep = 1146. State = [[-0.18792872  0.06021097]]. Action = [[-0.07858235 -0.01227967  0.          0.17743301]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 1146 is [True, False, False, False, True, False]
Current timestep = 1147. State = [[-0.19292197  0.057639  ]]. Action = [[-0.04224129 -0.06401781  0.         -0.159145  ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 1147 is [True, False, False, False, True, False]
Current timestep = 1148. State = [[-0.1917813   0.05945991]]. Action = [[0.07245492 0.06373066 0.         0.77017283]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 1148 is [True, False, False, False, True, False]
State prediction error at timestep 1148 is 0.012
Human Feedback received at timestep 1148 of None
Current timestep = 1149. State = [[-0.19288018  0.05747197]]. Action = [[-0.04964813 -0.08396882  0.         -0.8095371 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 1149 is [True, False, False, False, True, False]
State prediction error at timestep 1149 is 0.012
Human Feedback received at timestep 1149 of None
Current timestep = 1150. State = [[-0.19799654  0.05686916]]. Action = [[-0.06646751  0.02832193  0.          0.03666735]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 1150 is [True, False, False, False, True, False]
State prediction error at timestep 1150 is 0.012
Human Feedback received at timestep 1150 of None
Current timestep = 1151. State = [[-0.19947374  0.05358283]]. Action = [[ 0.02355964 -0.08496461  0.         -0.15142047]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 1151 is [True, False, False, False, True, False]
Current timestep = 1152. State = [[-0.19872345  0.04855361]]. Action = [[ 0.01373357 -0.04712833  0.          0.20297682]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 1152 is [True, False, False, False, True, False]
Current timestep = 1153. State = [[-0.19675809  0.05080612]]. Action = [[ 0.04309995  0.08856457  0.         -0.69664544]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 1153 is [True, False, False, False, True, False]
Current timestep = 1154. State = [[-0.19696233  0.05339608]]. Action = [[-0.01187576  0.01327537  0.          0.10056651]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 1154 is [True, False, False, False, True, False]
Current timestep = 1155. State = [[-0.20149094  0.05842364]]. Action = [[-0.07057953  0.09523118  0.         -0.1659224 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 1155 is [True, False, False, False, True, False]
Current timestep = 1156. State = [[-0.20350271  0.05948249]]. Action = [[ 0.01913317 -0.03857095  0.         -0.38425738]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 1156 is [True, False, False, False, True, False]
Current timestep = 1157. State = [[-0.20632552  0.06294917]]. Action = [[-0.04825215  0.08423954  0.          0.59904563]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 1157 is [True, False, False, False, True, False]
Current timestep = 1158. State = [[-0.204143    0.06430913]]. Action = [[ 0.09689566 -0.02903032  0.         -0.42680848]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 1158 is [True, False, False, False, True, False]
Current timestep = 1159. State = [[-0.20412824  0.06585049]]. Action = [[-0.03931854  0.03910338  0.         -0.1568563 ]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 1159 is [True, False, False, False, True, False]
State prediction error at timestep 1159 is 0.012
Human Feedback received at timestep 1159 of None
Current timestep = 1160. State = [[-0.20729211  0.06369443]]. Action = [[-0.03535128 -0.07635286  0.         -0.17043209]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 1160 is [True, False, False, False, True, False]
Current timestep = 1161. State = [[-0.21140495  0.06449766]]. Action = [[-0.0589258   0.04904784  0.         -0.07255864]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 1161 is [True, False, False, False, True, False]
Current timestep = 1162. State = [[-0.2088846   0.06288263]]. Action = [[ 0.0975137  -0.06678614  0.         -0.78244394]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 1162 is [True, False, False, False, True, False]
Current timestep = 1163. State = [[-0.20755751  0.0654589 ]]. Action = [[-0.02318844  0.08981019  0.          0.5769861 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 1163 is [True, False, False, False, True, False]
Current timestep = 1164. State = [[-0.21015716  0.06636977]]. Action = [[-0.04056261 -0.03936648  0.         -0.36371022]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 1164 is [True, False, False, False, True, False]
Current timestep = 1165. State = [[-0.21499746  0.06677242]]. Action = [[-0.07800238  0.0181192   0.         -0.6232807 ]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 1165 is [True, False, False, False, True, False]
State prediction error at timestep 1165 is 0.012
Human Feedback received at timestep 1165 of None
Current timestep = 1166. State = [[-0.21948205  0.06344499]]. Action = [[-0.04785875 -0.08873288  0.         -0.41338772]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 1166 is [True, False, False, False, True, False]
Current timestep = 1167. State = [[-0.21984436  0.0621291 ]]. Action = [[ 0.02232809  0.01917198  0.         -0.9816757 ]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 1167 is [True, False, False, False, True, False]
Current timestep = 1168. State = [[-0.21711144  0.06091481]]. Action = [[ 0.05065755 -0.03103263  0.          0.138242  ]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 1168 is [True, False, False, False, True, False]
State prediction error at timestep 1168 is 0.012
Human Feedback received at timestep 1168 of None
Current timestep = 1169. State = [[-0.21894461  0.06383669]]. Action = [[-0.05977918  0.08142114  0.         -0.4279381 ]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 1169 is [True, False, False, False, True, False]
Current timestep = 1170. State = [[-0.21959582  0.06760363]]. Action = [[ 0.03369343  0.02858546  0.         -0.35255313]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 1170 is [True, False, False, False, True, False]
State prediction error at timestep 1170 is 0.012
Human Feedback received at timestep 1170 of None
Current timestep = 1171. State = [[-0.21921082  0.06481215]]. Action = [[ 0.00316359 -0.07560721  0.         -0.39458627]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 1171 is [True, False, False, False, True, False]
State prediction error at timestep 1171 is 0.012
Human Feedback received at timestep 1171 of None
Current timestep = 1172. State = [[-0.22067432  0.06319079]]. Action = [[-0.02772601  0.01237582  0.          0.20669138]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 1172 is [True, False, False, False, True, False]
Current timestep = 1173. State = [[-0.21783058  0.06534185]]. Action = [[ 0.08514186  0.04224726  0.         -0.1713056 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 1173 is [True, False, False, False, True, False]
Current timestep = 1174. State = [[-0.21857965  0.0623791 ]]. Action = [[-0.06505192 -0.0820803   0.         -0.14446902]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 1174 is [True, False, False, False, True, False]
State prediction error at timestep 1174 is 0.012
Human Feedback received at timestep 1174 of None
Current timestep = 1175. State = [[-0.22109734  0.06125212]]. Action = [[-0.01051116  0.02723496  0.          0.5638639 ]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 1175 is [True, False, False, False, True, False]
Current timestep = 1176. State = [[-0.21945666  0.06020584]]. Action = [[ 0.05259062 -0.02832459  0.         -0.05899054]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 1176 is [True, False, False, False, True, False]
State prediction error at timestep 1176 is 0.012
Human Feedback received at timestep 1176 of None
Current timestep = 1177. State = [[-0.21475051  0.06253979]]. Action = [[ 0.07895314  0.07446537  0.         -0.6552356 ]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 1177 is [True, False, False, False, True, False]
Current timestep = 1178. State = [[-0.20987622  0.06318542]]. Action = [[ 0.06520637 -0.01699839  0.          0.7008686 ]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 1178 is [True, False, False, False, True, False]
Current timestep = 1179. State = [[-0.20926526  0.06550017]]. Action = [[-0.02348668  0.06426274  0.         -0.7174393 ]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 1179 is [True, False, False, False, True, False]
Current timestep = 1180. State = [[-0.20530981  0.06260976]]. Action = [[ 0.09113055 -0.08996395  0.         -0.80435956]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 1180 is [True, False, False, False, True, False]
Current timestep = 1181. State = [[-0.20028868  0.05988298]]. Action = [[0.03924585 0.00578091 0.         0.383466  ]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 1181 is [True, False, False, False, True, False]
Current timestep = 1182. State = [[-0.19384658  0.05433522]]. Action = [[ 0.08679216 -0.09958331  0.         -0.0943827 ]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 1182 is [True, False, False, False, True, False]
State prediction error at timestep 1182 is 0.012
Human Feedback received at timestep 1182 of None
Current timestep = 1183. State = [[-0.18817693  0.053507  ]]. Action = [[ 0.03790414  0.06055564  0.         -0.11962163]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 1183 is [True, False, False, False, True, False]
Current timestep = 1184. State = [[-0.18775877  0.05336425]]. Action = [[-0.04611162 -0.02117857  0.          0.46590507]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 1184 is [True, False, False, False, True, False]
State prediction error at timestep 1184 is 0.012
Human Feedback received at timestep 1184 of None
Current timestep = 1185. State = [[-0.18857752  0.05459053]]. Action = [[-0.02340569  0.04222097  0.         -0.14011174]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 1185 is [True, False, False, False, True, False]
State prediction error at timestep 1185 is 0.012
Human Feedback received at timestep 1185 of None
Current timestep = 1186. State = [[-0.18931769  0.05144973]]. Action = [[-0.02768666 -0.08546297  0.         -0.8443073 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 1186 is [True, False, False, False, True, False]
Current timestep = 1187. State = [[-0.19109653  0.04702471]]. Action = [[-0.05102943 -0.03864586  0.         -0.61022174]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 1187 is [True, False, False, False, True, False]
Current timestep = 1188. State = [[-0.18820746  0.04660908]]. Action = [[ 0.06776821  0.02213746  0.         -0.6257579 ]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 1188 is [True, False, False, False, True, False]
Current timestep = 1189. State = [[-0.1820143   0.04923543]]. Action = [[ 0.07395162  0.04953984  0.         -0.11819547]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 1189 is [True, False, False, False, True, False]
Current timestep = 1190. State = [[-0.17634152  0.04878643]]. Action = [[ 0.05872279 -0.03060351  0.         -0.9161533 ]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 1190 is [True, False, False, False, True, False]
Current timestep = 1191. State = [[-0.1777302   0.04624968]]. Action = [[-0.09103979 -0.0294226   0.         -0.12942147]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 1191 is [True, False, False, False, True, False]
Current timestep = 1192. State = [[-0.17922473  0.04540998]]. Action = [[ 0.00266577  0.00296424  0.         -0.46104348]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 1192 is [True, False, False, False, True, False]
State prediction error at timestep 1192 is 0.012
Human Feedback received at timestep 1192 of None
Current timestep = 1193. State = [[-0.18342745  0.04596931]]. Action = [[-0.09557049  0.01050104  0.         -0.47393084]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 1193 is [True, False, False, False, True, False]
State prediction error at timestep 1193 is 0.012
Human Feedback received at timestep 1193 of None
Current timestep = 1194. State = [[-0.18278459  0.04440902]]. Action = [[ 0.06762504 -0.03966258  0.          0.91911435]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 1194 is [True, False, False, False, True, False]
Current timestep = 1195. State = [[-0.17655545  0.04107627]]. Action = [[ 0.08577811 -0.03811693  0.         -0.07189494]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 1195 is [True, False, False, False, True, False]
Current timestep = 1196. State = [[-0.1691166  0.0389018]]. Action = [[ 0.09374674 -0.00563174  0.          0.63893235]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 1196 is [True, False, False, False, True, False]
Current timestep = 1197. State = [[-0.1664994   0.03487928]]. Action = [[-0.01914985 -0.05912358  0.         -0.75572693]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 1197 is [True, False, False, False, True, False]
Current timestep = 1198. State = [[-0.16400272  0.03573338]]. Action = [[ 0.04386733  0.06972534  0.         -0.2935878 ]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 1198 is [True, False, False, False, True, False]
Current timestep = 1199. State = [[-0.16305117  0.03310984]]. Action = [[-0.01766267 -0.07638313  0.          0.57641435]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 1199 is [True, False, False, False, True, False]
State prediction error at timestep 1199 is 0.012
Human Feedback received at timestep 1199 of None
Current timestep = 1200. State = [[-0.16709693  0.02578841]]. Action = [[-0.09959625 -0.09183607  0.         -0.16662353]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 1200 is [True, False, False, False, True, False]
Current timestep = 1201. State = [[-0.16516049  0.02276774]]. Action = [[ 0.08456298  0.01229987  0.         -0.8888753 ]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 1201 is [True, False, False, False, True, False]
State prediction error at timestep 1201 is 0.012
Human Feedback received at timestep 1201 of None
Current timestep = 1202. State = [[-0.16217224  0.02279782]]. Action = [[-0.00895485  0.01618524  0.          0.8810878 ]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 1202 is [True, False, False, False, True, False]
Current timestep = 1203. State = [[-0.15931796  0.02662529]]. Action = [[ 0.04097611  0.08161896  0.         -0.28707886]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 1203 is [True, False, False, False, True, False]
Current timestep = 1204. State = [[-0.15628918  0.03324327]]. Action = [[0.03083581 0.09143276 0.         0.10653341]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 1204 is [True, False, False, False, True, False]
Current timestep = 1205. State = [[-0.15527141  0.03209769]]. Action = [[-0.00451723 -0.08156063  0.         -0.19108975]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 1205 is [True, False, False, False, True, False]
Current timestep = 1206. State = [[-0.1515446   0.03113325]]. Action = [[0.06623238 0.02428977 0.         0.00244927]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 1206 is [True, False, False, False, True, False]
Current timestep = 1207. State = [[-0.15210474  0.03285087]]. Action = [[-0.06203815  0.02042093  0.          0.8999798 ]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 1207 is [True, False, False, False, True, False]
Current timestep = 1208. State = [[-0.1521561   0.03681403]]. Action = [[0.02685527 0.05834585 0.         0.02318394]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 1208 is [True, False, False, False, True, False]
State prediction error at timestep 1208 is 0.012
Human Feedback received at timestep 1208 of None
Current timestep = 1209. State = [[-0.14956722  0.03909288]]. Action = [[ 3.9757229e-02  2.3392588e-04  0.0000000e+00 -6.0654938e-01]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 1209 is [True, False, False, False, True, False]
Current timestep = 1210. State = [[-0.15203716  0.04269499]]. Action = [[-0.07771649  0.05678143  0.         -0.15295988]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 1210 is [True, False, False, False, True, False]
State prediction error at timestep 1210 is 0.012
Human Feedback received at timestep 1210 of None
Current timestep = 1211. State = [[-0.15012436  0.04780042]]. Action = [[0.09314633 0.05073106 0.         0.34403944]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 1211 is [True, False, False, False, True, False]
Current timestep = 1212. State = [[-0.15019034  0.05038257]]. Action = [[-5.805701e-02 -5.090833e-04  0.000000e+00  6.297126e-01]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 1212 is [True, False, False, False, True, False]
Current timestep = 1213. State = [[-0.15302351  0.05434421]]. Action = [[-0.02869364  0.05297277  0.          0.21037054]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 1213 is [True, False, False, False, True, False]
Current timestep = 1214. State = [[-0.15542927  0.06072058]]. Action = [[-0.02567997  0.0677413   0.         -0.20250857]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 1214 is [True, False, False, False, True, False]
Current timestep = 1215. State = [[-0.15414816  0.06654745]]. Action = [[ 0.05398668  0.04424935  0.         -0.3380177 ]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 1215 is [True, False, False, False, True, False]
Current timestep = 1216. State = [[-0.15046325  0.06908781]]. Action = [[ 0.05903711 -0.00469751  0.         -0.28513652]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 1216 is [True, False, False, False, True, False]
Current timestep = 1217. State = [[-0.15151578  0.07285849]]. Action = [[-0.05082498  0.05093341  0.         -0.47061217]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 1217 is [True, False, False, False, True, False]
State prediction error at timestep 1217 is 0.012
Human Feedback received at timestep 1217 of None
Current timestep = 1218. State = [[-0.15736663  0.07853869]]. Action = [[-0.08785949  0.05191519  0.         -0.91436535]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 1218 is [True, False, False, False, True, False]
State prediction error at timestep 1218 is 0.012
Human Feedback received at timestep 1218 of None
Current timestep = 1219. State = [[-0.1604329   0.07873653]]. Action = [[-0.00755008 -0.06515042  0.          0.35332608]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 1219 is [True, False, False, False, True, False]
State prediction error at timestep 1219 is 0.012
Human Feedback received at timestep 1219 of None
Current timestep = 1220. State = [[-0.15931565  0.0740899 ]]. Action = [[ 0.02832993 -0.08521143  0.          0.27900898]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 1220 is [True, False, False, False, True, False]
Current timestep = 1221. State = [[-0.1553652   0.07174567]]. Action = [[ 0.06028869 -0.00800046  0.         -0.21834117]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 1221 is [True, False, False, False, True, False]
Current timestep = 1222. State = [[-0.1568045  0.06804  ]]. Action = [[-0.07910683 -0.07261886  0.          0.13514662]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 1222 is [True, False, False, False, True, False]
Current timestep = 1223. State = [[-0.15666537  0.06838257]]. Action = [[0.04408183 0.0508813  0.         0.12459254]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 1223 is [True, False, False, False, True, False]
State prediction error at timestep 1223 is 0.012
Human Feedback received at timestep 1223 of None
Current timestep = 1224. State = [[-0.15968755  0.06975515]]. Action = [[-0.0901975   0.00275391  0.         -0.6626741 ]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 1224 is [True, False, False, False, True, False]
Current timestep = 1225. State = [[-0.15842558  0.07384025]]. Action = [[0.09334148 0.08266575 0.         0.18930972]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 1225 is [True, False, False, False, True, False]
Current timestep = 1226. State = [[-0.15327321  0.07367896]]. Action = [[ 0.05846379 -0.04723733  0.          0.7570331 ]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 1226 is [True, False, False, False, True, False]
Current timestep = 1227. State = [[-0.1487677   0.07401678]]. Action = [[0.05035827 0.03937294 0.         0.4539112 ]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 1227 is [True, False, False, False, True, False]
Current timestep = 1228. State = [[-0.14847478  0.07283096]]. Action = [[-0.03471596 -0.04092092  0.         -0.4642864 ]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 1228 is [True, False, False, False, True, False]
Current timestep = 1229. State = [[-0.14433976  0.07024891]]. Action = [[ 0.09199015 -0.02424978  0.         -0.3305667 ]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 1229 is [True, False, False, False, True, False]
Current timestep = 1230. State = [[-0.13643827  0.06757296]]. Action = [[ 0.09354141 -0.02519792  0.          0.4106437 ]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 1230 is [True, False, False, False, True, False]
Current timestep = 1231. State = [[-0.12867323  0.066908  ]]. Action = [[ 0.08174067  0.021322    0.         -0.08690995]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 1231 is [True, False, False, False, True, False]
Current timestep = 1232. State = [[-0.12811159  0.06726243]]. Action = [[-0.07076295  0.00997458  0.         -0.00348252]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 1232 is [True, False, False, False, True, False]
Current timestep = 1233. State = [[-0.12929074  0.0669285 ]]. Action = [[-0.0100954 -0.0073192  0.        -0.6261109]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 1233 is [True, False, False, False, True, False]
Current timestep = 1234. State = [[-0.12998438  0.06787685]]. Action = [[-0.02455227  0.02524509  0.          0.28205538]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 1234 is [True, False, False, False, True, False]
Current timestep = 1235. State = [[-0.13338426  0.06979153]]. Action = [[-0.0709611   0.01935426  0.         -0.91200346]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 1235 is [True, False, False, False, True, False]
State prediction error at timestep 1235 is 0.012
Human Feedback received at timestep 1235 of None
Current timestep = 1236. State = [[-0.1308282   0.06623386]]. Action = [[ 0.08370306 -0.09014303  0.          0.2991233 ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 1236 is [True, False, False, False, True, False]
State prediction error at timestep 1236 is 0.012
Human Feedback received at timestep 1236 of None
Current timestep = 1237. State = [[-0.12990993  0.06844301]]. Action = [[-0.04094183  0.09802067  0.          0.69071627]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 1237 is [True, False, False, False, True, False]
Current timestep = 1238. State = [[-0.13145591  0.07435734]]. Action = [[-0.01663379  0.0536755   0.         -0.42238128]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 1238 is [True, False, False, False, True, False]
Current timestep = 1239. State = [[-0.1312001   0.07799779]]. Action = [[ 0.01612483  0.022464    0.         -0.9162301 ]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 1239 is [True, False, False, False, True, False]
Current timestep = 1240. State = [[-0.13259524  0.07614192]]. Action = [[-0.03925073 -0.06965421  0.          0.7603221 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 1240 is [True, False, False, False, True, False]
State prediction error at timestep 1240 is 0.012
Human Feedback received at timestep 1240 of None
Current timestep = 1241. State = [[-0.13339859  0.07730673]]. Action = [[1.06073916e-04 4.79347333e-02 0.00000000e+00 2.44963169e-01]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 1241 is [True, False, False, False, True, False]
Current timestep = 1242. State = [[-0.13506877  0.07534052]]. Action = [[-0.03576937 -0.0799831   0.          0.5712428 ]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 1242 is [True, False, False, False, True, False]
Current timestep = 1243. State = [[-0.1314659   0.07562103]]. Action = [[0.09778795 0.04488686 0.         0.07393587]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 1243 is [True, False, False, False, True, False]
Current timestep = 1244. State = [[-0.12805611  0.08033316]]. Action = [[ 0.0144956   0.06945687  0.         -0.4620999 ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 1244 is [True, False, False, False, True, False]
State prediction error at timestep 1244 is 0.012
Human Feedback received at timestep 1244 of None
Current timestep = 1245. State = [[-0.12758523  0.08540967]]. Action = [[-0.00182009  0.05339917  0.          0.10577023]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 1245 is [True, False, False, False, True, False]
Current timestep = 1246. State = [[-0.12442529  0.08373146]]. Action = [[ 0.06283981 -0.07637893  0.         -0.01481837]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 1246 is [True, False, False, False, True, False]
State prediction error at timestep 1246 is 0.012
Human Feedback received at timestep 1246 of None
Current timestep = 1247. State = [[-0.12372045  0.07933261]]. Action = [[-0.03445781 -0.04990863  0.          0.04348361]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 1247 is [True, False, False, False, True, False]
Current timestep = 1248. State = [[-0.12647076  0.08215486]]. Action = [[-0.05420442  0.08303329  0.         -0.2788546 ]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 1248 is [True, False, False, False, True, False]
Current timestep = 1249. State = [[-0.12731238  0.08362986]]. Action = [[ 0.00663068 -0.02776474  0.          0.586884  ]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 1249 is [True, False, False, False, True, False]
Current timestep = 1250. State = [[-0.1282425   0.08408661]]. Action = [[-0.02880976  0.01401726  0.          0.2156806 ]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 1250 is [True, False, False, False, True, False]
Current timestep = 1251. State = [[-0.1276386   0.08521789]]. Action = [[ 0.02490727  0.007198    0.         -0.7663365 ]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 1251 is [True, False, False, False, True, False]
Current timestep = 1252. State = [[-0.12539287  0.08198104]]. Action = [[ 0.029343   -0.07320846  0.          0.817893  ]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 1252 is [True, False, False, False, True, False]
Current timestep = 1253. State = [[-0.12744656  0.07573611]]. Action = [[-0.07319859 -0.08267252  0.          0.10832012]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 1253 is [True, False, False, False, True, False]
Current timestep = 1254. State = [[-0.12842345  0.06929439]]. Action = [[ 0.00463655 -0.07427482  0.         -0.38514292]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 1254 is [True, False, False, False, True, False]
Current timestep = 1255. State = [[-0.13142489  0.06997572]]. Action = [[-0.07282946  0.07198533  0.         -0.30292296]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 1255 is [True, False, False, False, True, False]
Current timestep = 1256. State = [[-0.13333946  0.06805261]]. Action = [[ 3.8280338e-04 -7.0898637e-02  0.0000000e+00 -5.2204114e-01]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 1256 is [True, False, False, False, True, False]
Current timestep = 1257. State = [[-0.13574658  0.0615805 ]]. Action = [[-0.05022077 -0.07926138  0.          0.06362092]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 1257 is [True, False, False, False, True, False]
Current timestep = 1258. State = [[-0.1338313   0.05639992]]. Action = [[ 0.06914913 -0.03651958  0.          0.85710466]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 1258 is [True, False, False, False, True, False]
Current timestep = 1259. State = [[-0.13378994  0.05320373]]. Action = [[-0.03840571 -0.01443715  0.         -0.77575076]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 1259 is [True, False, False, False, True, False]
Current timestep = 1260. State = [[-0.13418873  0.05506582]]. Action = [[ 0.01580974  0.07111905  0.         -0.24379146]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 1260 is [True, False, False, False, True, False]
State prediction error at timestep 1260 is 0.012
Human Feedback received at timestep 1260 of None
Current timestep = 1261. State = [[-0.13463111  0.05436142]]. Action = [[-0.00546849 -0.03499616  0.          0.60538375]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 1261 is [True, False, False, False, True, False]
State prediction error at timestep 1261 is 0.012
Human Feedback received at timestep 1261 of None
Current timestep = 1262. State = [[-0.13987584  0.05259721]]. Action = [[-0.09687138 -0.00242212  0.          0.18789506]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 1262 is [True, False, False, False, True, False]
State prediction error at timestep 1262 is 0.012
Human Feedback received at timestep 1262 of None
Current timestep = 1263. State = [[-0.14795288  0.05712703]]. Action = [[-0.09684726  0.09870514  0.         -0.07440323]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 1263 is [True, False, False, False, True, False]
Current timestep = 1264. State = [[-0.15252066  0.06073225]]. Action = [[-0.00762248  0.01003029  0.          0.13596094]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 1264 is [True, False, False, False, True, False]
Current timestep = 1265. State = [[-0.15625282  0.06635636]]. Action = [[-0.03276556  0.09510132  0.         -0.8772502 ]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 1265 is [True, False, False, False, True, False]
Current timestep = 1266. State = [[-0.1617      0.07312575]]. Action = [[-0.04753257  0.06360576  0.          0.7481885 ]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 1266 is [True, False, False, False, True, False]
Current timestep = 1267. State = [[-0.16507123  0.07747568]]. Action = [[0.00724217 0.0251739  0.         0.6456461 ]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 1267 is [True, False, False, False, True, False]
State prediction error at timestep 1267 is 0.012
Human Feedback received at timestep 1267 of None
Current timestep = 1268. State = [[-0.16469805  0.07518849]]. Action = [[ 0.0498211  -0.08246744  0.         -0.7300975 ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 1268 is [True, False, False, False, True, False]
State prediction error at timestep 1268 is 0.012
Human Feedback received at timestep 1268 of None
Current timestep = 1269. State = [[-0.16705559  0.07449798]]. Action = [[-0.04378406  0.02083113  0.          0.63020027]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 1269 is [True, False, False, False, True, False]
Current timestep = 1270. State = [[-0.17022438  0.07888713]]. Action = [[-0.01027548  0.06558628  0.         -0.5775497 ]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 1270 is [True, False, False, False, True, False]
Current timestep = 1271. State = [[-0.16810496  0.08591966]]. Action = [[0.08828371 0.09105628 0.         0.57314944]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 1271 is [True, False, False, False, True, False]
Current timestep = 1272. State = [[-0.16446441  0.08751537]]. Action = [[ 0.05755972 -0.03159457  0.         -0.2901944 ]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 1272 is [True, False, False, False, True, False]
State prediction error at timestep 1272 is 0.012
Human Feedback received at timestep 1272 of None
Current timestep = 1273. State = [[-0.1628128   0.08865646]]. Action = [[0.01544635 0.03124531 0.         0.08981562]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 1273 is [True, False, False, False, True, False]
Current timestep = 1274. State = [[-0.16114919  0.09442114]]. Action = [[0.03650864 0.09022399 0.         0.6758778 ]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 1274 is [True, False, False, False, True, False]
Current timestep = 1275. State = [[-0.16480416  0.09597491]]. Action = [[-0.09608255 -0.0393926   0.         -0.08942634]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 1275 is [True, False, False, False, True, False]
Current timestep = 1276. State = [[-0.16780905  0.09670658]]. Action = [[-0.00229061  0.01370634  0.         -0.69039005]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 1276 is [True, False, False, False, True, False]
Current timestep = 1277. State = [[-0.17023957  0.09370866]]. Action = [[-0.04168146 -0.08636077  0.         -0.38025975]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 1277 is [True, False, False, False, True, False]
Current timestep = 1278. State = [[-0.1694711   0.09580381]]. Action = [[0.04249727 0.07971825 0.         0.16778636]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 1278 is [True, False, False, False, True, False]
Current timestep = 1279. State = [[-0.16785452  0.10075643]]. Action = [[0.01503237 0.04534595 0.         0.07079756]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 1279 is [True, False, False, False, True, False]
Current timestep = 1280. State = [[-0.17068873  0.10563072]]. Action = [[-0.06345694  0.054404    0.          0.36385715]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 1280 is [True, False, False, False, True, False]
State prediction error at timestep 1280 is 0.012
Human Feedback received at timestep 1280 of None
Current timestep = 1281. State = [[-0.16961375  0.1037984 ]]. Action = [[ 0.05955534 -0.0890491   0.         -0.0775497 ]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 1281 is [True, False, False, False, True, False]
State prediction error at timestep 1281 is 0.012
Human Feedback received at timestep 1281 of None
Current timestep = 1282. State = [[-0.1658647   0.09835606]]. Action = [[ 0.03682124 -0.06761397  0.         -0.0549354 ]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 1282 is [True, False, False, False, True, False]
Current timestep = 1283. State = [[-0.16473264  0.09892555]]. Action = [[-0.01118229  0.05323967  0.         -0.0306347 ]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 1283 is [True, False, False, False, True, False]
Current timestep = 1284. State = [[-0.16897814  0.09581311]]. Action = [[-0.09789691 -0.09768339  0.         -0.636119  ]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 1284 is [True, False, False, False, True, False]
Current timestep = 1285. State = [[-0.17162207  0.09104891]]. Action = [[-0.01374605 -0.04554693  0.         -0.97320706]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 1285 is [True, False, False, False, True, False]
Current timestep = 1286. State = [[-0.17243831  0.08863472]]. Action = [[-0.01542749 -0.01510416  0.         -0.42325926]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 1286 is [True, False, False, False, True, False]
Current timestep = 1287. State = [[-0.17148225  0.08489925]]. Action = [[ 0.02258272 -0.05481132  0.         -0.27124524]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 1287 is [True, False, False, False, True, False]
Current timestep = 1288. State = [[-0.16899203  0.08324368]]. Action = [[0.03432531 0.01719667 0.         0.37160897]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 1288 is [True, False, False, False, True, False]
Current timestep = 1289. State = [[-0.16915844  0.0848494 ]]. Action = [[-0.02166849  0.04372635  0.         -0.24219596]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 1289 is [True, False, False, False, True, False]
Current timestep = 1290. State = [[-0.17377445  0.08326861]]. Action = [[-0.07992344 -0.04617151  0.         -0.6550987 ]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 1290 is [True, False, False, False, True, False]
State prediction error at timestep 1290 is 0.012
Human Feedback received at timestep 1290 of None
Current timestep = 1291. State = [[-0.17667124  0.07798889]]. Action = [[-0.01195684 -0.07301186  0.         -0.3404389 ]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 1291 is [True, False, False, False, True, False]
Current timestep = 1292. State = [[-0.17807877  0.07832282]]. Action = [[-0.01387769  0.06345024  0.         -0.9780128 ]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 1292 is [True, False, False, False, True, False]
Current timestep = 1293. State = [[-0.1787999   0.07548962]]. Action = [[ 0.00583273 -0.08065763  0.         -0.5320191 ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 1293 is [True, False, False, False, True, False]
Current timestep = 1294. State = [[-0.17942485  0.07289331]]. Action = [[-0.00652527  0.00688358  0.          0.7329016 ]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 1294 is [True, False, False, False, True, False]
Current timestep = 1295. State = [[-0.17833453  0.07443123]]. Action = [[0.04015943 0.04472802 0.         0.9179089 ]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 1295 is [True, False, False, False, True, False]
Current timestep = 1296. State = [[-0.1733413   0.07447336]]. Action = [[ 0.09997737 -0.00802752  0.         -0.48044074]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 1296 is [True, False, False, False, True, False]
Current timestep = 1297. State = [[-0.16862994  0.06902471]]. Action = [[ 0.05091124 -0.08490042  0.         -0.8003256 ]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 1297 is [True, False, False, False, True, False]
Current timestep = 1298. State = [[-0.16223828  0.06210255]]. Action = [[ 0.0967493  -0.06305755  0.         -0.78788316]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 1298 is [True, False, False, False, True, False]
Current timestep = 1299. State = [[-0.15755855  0.05736345]]. Action = [[ 0.02763606 -0.0231946   0.          0.00145566]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 1299 is [True, False, False, False, True, False]
Current timestep = 1300. State = [[-0.15708344  0.05488872]]. Action = [[-0.02770929 -0.00337014  0.          0.48922706]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 1300 is [True, False, False, False, True, False]
Current timestep = 1301. State = [[-0.15299481  0.05253548]]. Action = [[ 0.0797228  -0.01532812  0.         -0.7819587 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 1301 is [True, False, False, False, True, False]
Current timestep = 1302. State = [[-0.15384921  0.0531155 ]]. Action = [[-0.08861167  0.04729845  0.         -0.2699204 ]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 1302 is [True, False, False, False, True, False]
Current timestep = 1303. State = [[-0.15612966  0.05367802]]. Action = [[-0.01274838 -0.00063702  0.         -0.6238828 ]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 1303 is [True, False, False, False, True, False]
Current timestep = 1304. State = [[-0.1553406   0.05184616]]. Action = [[ 0.01821826 -0.02753288  0.          0.1119504 ]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 1304 is [True, False, False, False, True, False]
Current timestep = 1305. State = [[-0.15095225  0.05039853]]. Action = [[ 0.07443871 -0.00161     0.         -0.6155399 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 1305 is [True, False, False, False, True, False]
Current timestep = 1306. State = [[-0.15212266  0.04974974]]. Action = [[-0.07887197 -0.00196435  0.          0.7709186 ]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 1306 is [True, False, False, False, True, False]
Current timestep = 1307. State = [[-0.15384325  0.05445929]]. Action = [[0.00939882 0.09845873 0.         0.48650444]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 1307 is [True, False, False, False, True, False]
Current timestep = 1308. State = [[-0.15647323  0.05926054]]. Action = [[-0.045295    0.03380703  0.         -0.09096175]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 1308 is [True, False, False, False, True, False]
Current timestep = 1309. State = [[-0.16032611  0.05691586]]. Action = [[-0.04565299 -0.08308155  0.         -0.5611831 ]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 1309 is [True, False, False, False, True, False]
Current timestep = 1310. State = [[-0.16517061  0.05426572]]. Action = [[-0.0706913  -0.01900997  0.          0.5172626 ]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 1310 is [True, False, False, False, True, False]
State prediction error at timestep 1310 is 0.012
Human Feedback received at timestep 1310 of None
Current timestep = 1311. State = [[-0.16477272  0.05563162]]. Action = [[ 0.06097292  0.03252973  0.         -0.91039985]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 1311 is [True, False, False, False, True, False]
State prediction error at timestep 1311 is 0.012
Human Feedback received at timestep 1311 of None
Current timestep = 1312. State = [[-0.16519067  0.05980219]]. Action = [[-0.03092336  0.0588269   0.          0.7023779 ]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 1312 is [True, False, False, False, True, False]
Current timestep = 1313. State = [[-0.16465914  0.06583119]]. Action = [[0.04191097 0.0749472  0.         0.00772476]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 1313 is [True, False, False, False, True, False]
Current timestep = 1314. State = [[-0.1670899   0.06991601]]. Action = [[-0.05562146  0.02166436  0.          0.8825166 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 1314 is [True, False, False, False, True, False]
State prediction error at timestep 1314 is 0.012
Human Feedback received at timestep 1314 of None
Current timestep = 1315. State = [[-0.16601384  0.0739717 ]]. Action = [[0.0749382  0.04915487 0.         0.60208917]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 1315 is [True, False, False, False, True, False]
State prediction error at timestep 1315 is 0.012
Human Feedback received at timestep 1315 of None
Current timestep = 1316. State = [[-0.16838096  0.07369687]]. Action = [[-0.08369975 -0.05499716  0.         -0.21673805]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 1316 is [True, False, False, False, True, False]
State prediction error at timestep 1316 is 0.012
Human Feedback received at timestep 1316 of None
Current timestep = 1317. State = [[-0.16746332  0.06837201]]. Action = [[ 0.07942948 -0.09177212  0.          0.18080604]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 1317 is [True, False, False, False, True, False]
Current timestep = 1318. State = [[-0.16570261  0.06854493]]. Action = [[-0.00081383  0.05638101  0.          0.48095524]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 1318 is [True, False, False, False, True, False]
State prediction error at timestep 1318 is 0.012
Human Feedback received at timestep 1318 of None
Current timestep = 1319. State = [[-0.16126838  0.07362828]]. Action = [[ 0.09910097  0.07120479  0.         -0.7963705 ]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 1319 is [True, False, False, False, True, False]
Current timestep = 1320. State = [[-0.15920311  0.07398408]]. Action = [[-0.01120223 -0.03655887  0.         -0.808341  ]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 1320 is [True, False, False, False, True, False]
Current timestep = 1321. State = [[-0.15807386  0.07431318]]. Action = [[0.02612198 0.02503137 0.         0.93912196]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 1321 is [True, False, False, False, True, False]
Current timestep = 1322. State = [[-0.16066748  0.07504597]]. Action = [[-0.07283255 -0.00131695  0.         -0.53354377]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 1322 is [True, False, False, False, True, False]
State prediction error at timestep 1322 is 0.012
Human Feedback received at timestep 1322 of None
Current timestep = 1323. State = [[-0.15994585  0.07322618]]. Action = [[ 0.04957988 -0.04208168  0.         -0.6401779 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 1323 is [True, False, False, False, True, False]
Current timestep = 1324. State = [[-0.15685813  0.07320029]]. Action = [[ 0.02919588  0.02487036  0.         -0.59076774]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 1324 is [True, False, False, False, True, False]
Current timestep = 1325. State = [[-0.15984847  0.07822836]]. Action = [[-0.08679947  0.0853573   0.          0.06811118]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 1325 is [True, False, False, False, True, False]
State prediction error at timestep 1325 is 0.012
Human Feedback received at timestep 1325 of None
Current timestep = 1326. State = [[-0.16541009  0.07671572]]. Action = [[-0.07224891 -0.09578875  0.         -0.30648577]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 1326 is [True, False, False, False, True, False]
Current timestep = 1327. State = [[-0.16547367  0.07627691]]. Action = [[ 0.0399142   0.03360719  0.         -0.58971083]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 1327 is [True, False, False, False, True, False]
State prediction error at timestep 1327 is 0.012
Human Feedback received at timestep 1327 of None
Current timestep = 1328. State = [[-0.16409297  0.07660715]]. Action = [[ 0.00411783 -0.01662638  0.         -0.2322911 ]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 1328 is [True, False, False, False, True, False]
Current timestep = 1329. State = [[-0.15990913  0.07797279]]. Action = [[0.08053821 0.03413849 0.         0.01439953]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 1329 is [True, False, False, False, True, False]
Current timestep = 1330. State = [[-0.15648882  0.07523933]]. Action = [[ 0.02113191 -0.07174744  0.         -0.5074935 ]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 1330 is [True, False, False, False, True, False]
Current timestep = 1331. State = [[-0.15606557  0.07576445]]. Action = [[-0.01524437  0.05579355  0.          0.6388998 ]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 1331 is [True, False, False, False, True, False]
State prediction error at timestep 1331 is 0.012
Human Feedback received at timestep 1331 of None
Current timestep = 1332. State = [[-0.15840906  0.073685  ]]. Action = [[-0.04965917 -0.07290787  0.         -0.8999266 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 1332 is [True, False, False, False, True, False]
Current timestep = 1333. State = [[-0.15602432  0.07493687]]. Action = [[ 0.07300488  0.06838811  0.         -0.33931935]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 1333 is [True, False, False, False, True, False]
Current timestep = 1334. State = [[-0.15572311  0.07759439]]. Action = [[-0.0434983   0.01641588  0.          0.97703195]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 1334 is [True, False, False, False, True, False]
Current timestep = 1335. State = [[-0.15810093  0.07564992]]. Action = [[-0.03678199 -0.05641267  0.          0.09468031]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 1335 is [True, False, False, False, True, False]
State prediction error at timestep 1335 is 0.012
Human Feedback received at timestep 1335 of None
Current timestep = 1336. State = [[-0.15535371  0.07174664]]. Action = [[ 0.06735697 -0.04780806  0.          0.24956536]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 1336 is [True, False, False, False, True, False]
Current timestep = 1337. State = [[-0.14857206  0.06888993]]. Action = [[ 0.0907458  -0.01774871  0.          0.2416246 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 1337 is [True, False, False, False, True, False]
Current timestep = 1338. State = [[-0.14556032  0.07091186]]. Action = [[-0.00278609  0.06738143  0.         -0.78855395]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 1338 is [True, False, False, False, True, False]
Current timestep = 1339. State = [[-0.14240706  0.07473857]]. Action = [[ 0.05631056  0.0480931   0.         -0.2902434 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 1339 is [True, False, False, False, True, False]
Current timestep = 1340. State = [[-0.13712536  0.0774202 ]]. Action = [[ 0.0711038   0.03206705  0.         -0.8651988 ]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 1340 is [True, False, False, False, True, False]
Current timestep = 1341. State = [[-0.13570134  0.07702514]]. Action = [[-0.02430455 -0.02380019  0.          0.04775751]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 1341 is [True, False, False, False, True, False]
Current timestep = 1342. State = [[-0.13719428  0.07827611]]. Action = [[-0.03380743  0.03583657  0.         -0.08299869]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 1342 is [True, False, False, False, True, False]
Current timestep = 1343. State = [[-0.13669637  0.08079001]]. Action = [[0.01879345 0.02275255 0.         0.6145762 ]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 1343 is [True, False, False, False, True, False]
Current timestep = 1344. State = [[-0.13380472  0.08020063]]. Action = [[ 0.03887411 -0.03411108  0.         -0.538831  ]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 1344 is [True, False, False, False, True, False]
Current timestep = 1345. State = [[-0.12745321  0.0810793 ]]. Action = [[ 0.09658834  0.03425591  0.         -0.01301718]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 1345 is [True, False, False, False, True, False]
Current timestep = 1346. State = [[-0.12642911  0.08515677]]. Action = [[-0.04868164  0.06049215  0.          0.08457184]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 1346 is [True, False, False, False, True, False]
Current timestep = 1347. State = [[-0.12441681  0.09034309]]. Action = [[ 0.06280153  0.05865633  0.         -0.12578547]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 1347 is [True, False, False, False, True, False]
Current timestep = 1348. State = [[-0.12453032  0.09432664]]. Action = [[-0.04076494  0.03063308  0.          0.29916036]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 1348 is [True, False, False, False, True, False]
Current timestep = 1349. State = [[-0.12897882  0.09199571]]. Action = [[-0.08174161 -0.09009288  0.         -0.87684935]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 1349 is [True, False, False, False, True, False]
Current timestep = 1350. State = [[-0.12977758  0.09214443]]. Action = [[0.01785628 0.03133153 0.         0.8024553 ]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 1350 is [True, False, False, False, True, False]
Current timestep = 1351. State = [[-0.1285053   0.09347876]]. Action = [[ 0.00665189 -0.00713105  0.         -0.84877074]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 1351 is [True, False, False, False, True, False]
Current timestep = 1352. State = [[-0.13025561  0.09003279]]. Action = [[-0.05530647 -0.08262116  0.         -0.2042833 ]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 1352 is [True, False, False, False, True, False]
Current timestep = 1353. State = [[-0.13059448  0.09026892]]. Action = [[ 0.00835256  0.04096492  0.         -0.4116683 ]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 1353 is [True, False, False, False, True, False]
Current timestep = 1354. State = [[-0.13042708  0.08751334]]. Action = [[-0.011365   -0.08476003  0.          0.97967863]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 1354 is [True, False, False, False, True, False]
Current timestep = 1355. State = [[-0.13400713  0.083577  ]]. Action = [[-0.08344683 -0.0352092   0.         -0.98970044]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 1355 is [True, False, False, False, True, False]
State prediction error at timestep 1355 is 0.012
Human Feedback received at timestep 1355 of None
Current timestep = 1356. State = [[-0.13822542  0.08615986]]. Action = [[-0.04790625  0.07091843  0.          0.39780867]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 1356 is [True, False, False, False, True, False]
Current timestep = 1357. State = [[-0.14285076  0.08497982]]. Action = [[-0.06255282 -0.07034178  0.         -0.75059944]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 1357 is [True, False, False, False, True, False]
Current timestep = 1358. State = [[-0.14610776  0.08735751]]. Action = [[-0.02210721  0.08252635  0.          0.51232433]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 1358 is [True, False, False, False, True, False]
Current timestep = 1359. State = [[-0.1441831   0.09368819]]. Action = [[0.08325567 0.07909279 0.         0.81603694]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 1359 is [True, False, False, False, True, False]
Current timestep = 1360. State = [[-0.14590977  0.09521408]]. Action = [[-0.05720695 -0.02242444  0.          0.9793464 ]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 1360 is [True, False, False, False, True, False]
State prediction error at timestep 1360 is 0.012
Human Feedback received at timestep 1360 of None
Current timestep = 1361. State = [[-0.15065269  0.09839658]]. Action = [[-0.03438852  0.06808115  0.          0.55365014]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 1361 is [True, False, False, False, True, False]
Current timestep = 1362. State = [[-0.15239805  0.09739418]]. Action = [[ 0.02037891 -0.06727406  0.         -0.6228031 ]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 1362 is [True, False, False, False, True, False]
Current timestep = 1363. State = [[-0.15672278  0.0949598 ]]. Action = [[-0.07310649 -0.01718231  0.          0.94984305]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 1363 is [True, False, False, False, True, False]
Current timestep = 1364. State = [[-0.16077481  0.09013121]]. Action = [[-0.02082989 -0.09030687  0.         -0.8478613 ]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 1364 is [True, False, False, False, True, False]
Current timestep = 1365. State = [[-0.16081512  0.08613954]]. Action = [[ 0.02976107 -0.02290957  0.         -0.8185639 ]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 1365 is [True, False, False, False, True, False]
Current timestep = 1366. State = [[-0.16379987  0.08915525]]. Action = [[-0.05737656  0.08766691  0.          0.61541736]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 1366 is [True, False, False, False, True, False]
Current timestep = 1367. State = [[-0.16737498  0.09018593]]. Action = [[-0.01633304 -0.02455796  0.         -0.2381354 ]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 1367 is [True, False, False, False, True, False]
State prediction error at timestep 1367 is 0.012
Human Feedback received at timestep 1367 of None
Current timestep = 1368. State = [[-0.16930148  0.08453572]]. Action = [[-0.00964285 -0.09709199  0.          0.8624433 ]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 1368 is [True, False, False, False, True, False]
Current timestep = 1369. State = [[-0.17462364  0.08294997]]. Action = [[-0.08953457  0.03362932  0.         -0.7963303 ]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 1369 is [True, False, False, False, True, False]
Current timestep = 1370. State = [[-0.17511758  0.08472464]]. Action = [[ 0.06735205  0.02731404  0.         -0.9273777 ]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 1370 is [True, False, False, False, True, False]
State prediction error at timestep 1370 is 0.012
Human Feedback received at timestep 1370 of None
Current timestep = 1371. State = [[-0.17287122  0.08198646]]. Action = [[ 0.02799638 -0.06080486  0.          0.4061731 ]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 1371 is [True, False, False, False, True, False]
Current timestep = 1372. State = [[-0.16814816  0.07638387]]. Action = [[ 0.0873739  -0.06073068  0.         -0.3770007 ]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 1372 is [True, False, False, False, True, False]
Current timestep = 1373. State = [[-0.16782583  0.07212044]]. Action = [[-0.04606115 -0.02598111  0.         -0.1553638 ]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 1373 is [True, False, False, False, True, False]
State prediction error at timestep 1373 is 0.012
Human Feedback received at timestep 1373 of None
Current timestep = 1374. State = [[-0.17307375  0.06666081]]. Action = [[-0.08933879 -0.07483695  0.          0.52405   ]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 1374 is [True, False, False, False, True, False]
State prediction error at timestep 1374 is 0.012
Human Feedback received at timestep 1374 of None
Current timestep = 1375. State = [[-0.1751934   0.06194667]]. Action = [[ 0.00362815 -0.03203637  0.         -0.4788034 ]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 1375 is [True, False, False, False, True, False]
Current timestep = 1376. State = [[-0.17620064  0.05523862]]. Action = [[-0.02286934 -0.08983714  0.          0.28832114]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 1376 is [True, False, False, False, True, False]
State prediction error at timestep 1376 is 0.012
Human Feedback received at timestep 1376 of None
Current timestep = 1377. State = [[-0.17860451  0.05231783]]. Action = [[-0.03891463  0.02126281  0.         -0.5160359 ]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 1377 is [True, False, False, False, True, False]
Current timestep = 1378. State = [[-0.1835153   0.05482574]]. Action = [[-0.07092306  0.06357951  0.          0.75354576]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 1378 is [True, False, False, False, True, False]
Current timestep = 1379. State = [[-0.19072835  0.0529204 ]]. Action = [[-0.09270854 -0.06346292  0.         -0.05879569]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 1379 is [True, False, False, False, True, False]
State prediction error at timestep 1379 is 0.012
Human Feedback received at timestep 1379 of None
Current timestep = 1380. State = [[-0.19438723  0.04883023]]. Action = [[-0.00398587 -0.03687873  0.         -0.8868394 ]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 1380 is [True, False, False, False, True, False]
Current timestep = 1381. State = [[-0.19824745  0.04640013]]. Action = [[-0.05233305 -0.01223671  0.         -0.87840056]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 1381 is [True, False, False, False, True, False]
Current timestep = 1382. State = [[-0.20209293  0.0493503 ]]. Action = [[-0.01906404  0.07875984  0.          0.9819441 ]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 1382 is [True, False, False, False, True, False]
Current timestep = 1383. State = [[-0.20728996  0.05251646]]. Action = [[-0.0536954   0.02373918  0.          0.9408665 ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 1383 is [True, False, False, False, True, False]
Current timestep = 1384. State = [[-0.21100873  0.05300212]]. Action = [[-0.00243955 -0.0058137   0.          0.5666753 ]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 1384 is [True, False, False, False, True, False]
State prediction error at timestep 1384 is 0.012
Human Feedback received at timestep 1384 of None
Current timestep = 1385. State = [[-0.21255285  0.04884864]]. Action = [[ 0.01184162 -0.07826535  0.          0.20017159]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 1385 is [True, False, False, False, True, False]
Current timestep = 1386. State = [[-0.21759154  0.04212027]]. Action = [[-0.08022024 -0.08339234  0.         -0.8977506 ]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 1386 is [True, False, False, False, True, False]
Current timestep = 1387. State = [[-0.22523093  0.03529386]]. Action = [[-0.08799522 -0.07842645  0.         -0.9963842 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 1387 is [True, False, False, False, True, False]
Current timestep = 1388. State = [[-0.22502309  0.0318163 ]]. Action = [[ 0.09249536 -0.0043783   0.          0.9168606 ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 1388 is [True, False, False, False, True, False]
State prediction error at timestep 1388 is 0.012
Human Feedback received at timestep 1388 of None
Current timestep = 1389. State = [[-0.2226154   0.03067272]]. Action = [[0.01715549 0.00634722 0.         0.79766417]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 1389 is [True, False, False, False, True, False]
Current timestep = 1390. State = [[-0.22689763  0.02895949]]. Action = [[-0.09060555 -0.01647343  0.          0.5601361 ]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 1390 is [True, False, False, False, True, False]
Current timestep = 1391. State = [[-0.22679025  0.0254442 ]]. Action = [[ 0.07214504 -0.04087989  0.          0.16784978]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 1391 is [True, False, False, False, True, False]
State prediction error at timestep 1391 is 0.012
Human Feedback received at timestep 1391 of None
Current timestep = 1392. State = [[-0.22466524  0.01892686]]. Action = [[ 0.01139067 -0.08105387  0.          0.42559135]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 1392 is [True, False, False, False, True, False]
State prediction error at timestep 1392 is 0.012
Human Feedback received at timestep 1392 of None
Current timestep = 1393. State = [[-0.22565158  0.0165569 ]]. Action = [[-0.02857415  0.02817435  0.         -0.32955217]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 1393 is [True, False, False, False, True, False]
Current timestep = 1394. State = [[-0.22660163  0.02041612]]. Action = [[0.00376779 0.08668541 0.         0.6636691 ]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 1394 is [True, False, False, False, True, False]
Current timestep = 1395. State = [[-0.22784743  0.02689876]]. Action = [[-0.00889074  0.09204846  0.         -0.04044628]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 1395 is [True, False, False, False, True, False]
Current timestep = 1396. State = [[-0.22695194  0.02948464]]. Action = [[ 0.04577649 -0.00168366  0.         -0.87016034]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 1396 is [True, False, False, False, True, False]
Current timestep = 1397. State = [[-0.22360262  0.02871943]]. Action = [[ 0.06131121 -0.0169672   0.          0.4939363 ]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 1397 is [True, False, False, False, True, False]
Current timestep = 1398. State = [[-0.22004871  0.02964507]]. Action = [[ 0.04881533  0.02942049  0.         -0.2559666 ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 1398 is [True, False, False, False, True, False]
State prediction error at timestep 1398 is 0.012
Human Feedback received at timestep 1398 of None
Current timestep = 1399. State = [[-0.21808645  0.02657987]]. Action = [[ 0.01431741 -0.07884362  0.         -0.7817924 ]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 1399 is [True, False, False, False, True, False]
Current timestep = 1400. State = [[-0.21611524  0.02092495]]. Action = [[ 0.02107056 -0.06649355  0.          0.8758739 ]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 1400 is [True, False, False, False, True, False]
Current timestep = 1401. State = [[-0.21799894  0.01987868]]. Action = [[-0.06924935  0.02562476  0.          0.4894439 ]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 1401 is [True, False, False, False, True, False]
State prediction error at timestep 1401 is 0.012
Human Feedback received at timestep 1401 of None
Current timestep = 1402. State = [[-0.21922362  0.02395234]]. Action = [[-3.7550926e-06  7.0956908e-02  0.0000000e+00 -4.0403998e-01]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 1402 is [True, False, False, False, True, False]
Current timestep = 1403. State = [[-0.22108373  0.02614599]]. Action = [[-0.04146097 -0.0014528   0.         -0.1231547 ]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 1403 is [True, False, False, False, True, False]
Current timestep = 1404. State = [[-0.22115381  0.03105588]]. Action = [[0.02110978 0.08991127 0.         0.6396694 ]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 1404 is [True, False, False, False, True, False]
Current timestep = 1405. State = [[-0.2194021   0.03149952]]. Action = [[ 0.02993507 -0.05450974  0.          0.43707693]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 1405 is [True, False, False, False, True, False]
State prediction error at timestep 1405 is 0.012
Human Feedback received at timestep 1405 of None
Current timestep = 1406. State = [[-0.21453914  0.02552333]]. Action = [[ 0.07886945 -0.09638596  0.         -0.06264794]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 1406 is [True, False, False, False, True, False]
Current timestep = 1407. State = [[-0.2071871   0.02671794]]. Action = [[0.09957605 0.08852243 0.         0.6311238 ]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 1407 is [True, False, False, False, True, False]
Current timestep = 1408. State = [[-0.20827588  0.03262836]]. Action = [[-0.0977416   0.06955356  0.         -0.17276174]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 1408 is [True, False, False, False, True, False]
State prediction error at timestep 1408 is 0.012
Human Feedback received at timestep 1408 of None
Current timestep = 1409. State = [[-0.20688458  0.0367026 ]]. Action = [[0.0980657 0.0315988 0.        0.7311609]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 1409 is [True, False, False, False, True, False]
Current timestep = 1410. State = [[-0.19977638  0.03643232]]. Action = [[ 0.09621989 -0.03177637  0.          0.8985534 ]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 1410 is [True, False, False, False, True, False]
State prediction error at timestep 1410 is 0.012
Human Feedback received at timestep 1410 of None
Current timestep = 1411. State = [[-0.19743119  0.03228882]]. Action = [[-0.0245947  -0.06921425  0.          0.2721405 ]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 1411 is [True, False, False, False, True, False]
State prediction error at timestep 1411 is 0.012
Human Feedback received at timestep 1411 of None
Current timestep = 1412. State = [[-0.19999304  0.02967383]]. Action = [[-0.06413773 -0.01465354  0.         -0.7957171 ]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 1412 is [True, False, False, False, True, False]
Current timestep = 1413. State = [[-0.20286854  0.03399036]]. Action = [[-0.04227979  0.09212511  0.         -0.14720547]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 1413 is [True, False, False, False, True, False]
Current timestep = 1414. State = [[-0.19996142  0.03634795]]. Action = [[ 0.0794687  -0.01427175  0.         -0.3311345 ]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 1414 is [True, False, False, False, True, False]
State prediction error at timestep 1414 is 0.012
Human Feedback received at timestep 1414 of None
Current timestep = 1415. State = [[-0.19796696  0.03490489]]. Action = [[-0.01525698 -0.02930223  0.          0.76297355]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 1415 is [True, False, False, False, True, False]
Current timestep = 1416. State = [[-0.20126642  0.03395313]]. Action = [[-0.07946975 -0.00814732  0.          0.8974395 ]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 1416 is [True, False, False, False, True, False]
Current timestep = 1417. State = [[-0.20103154  0.03244865]]. Action = [[ 0.03533287 -0.03138001  0.          0.6889317 ]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 1417 is [True, False, False, False, True, False]
State prediction error at timestep 1417 is 0.012
Human Feedback received at timestep 1417 of None
Current timestep = 1418. State = [[-0.1968558   0.02830821]]. Action = [[ 0.05290314 -0.06385575  0.          0.6466768 ]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 1418 is [True, False, False, False, True, False]
Current timestep = 1419. State = [[-0.19290961  0.02557793]]. Action = [[ 0.03326698 -0.00746664  0.          0.02020347]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 1419 is [True, False, False, False, True, False]
State prediction error at timestep 1419 is 0.012
Human Feedback received at timestep 1419 of None
Current timestep = 1420. State = [[-0.18741323  0.02052084]]. Action = [[ 0.07454645 -0.08024703  0.          0.52121985]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 1420 is [True, False, False, False, True, False]
Current timestep = 1421. State = [[-0.1831692   0.01720883]]. Action = [[ 0.02202912  0.00287689  0.         -0.7209237 ]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 1421 is [True, False, False, False, True, False]
Current timestep = 1422. State = [[-0.18504246  0.01718374]]. Action = [[-0.07699214  0.02174349  0.          0.87397575]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 1422 is [True, False, False, False, True, False]
Current timestep = 1423. State = [[-0.18319246  0.01820625]]. Action = [[ 0.06867474  0.02447222  0.         -0.6579847 ]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 1423 is [True, False, False, False, True, False]
Current timestep = 1424. State = [[-0.18494013  0.02254371]]. Action = [[-0.08992452  0.0835314   0.         -0.50027955]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 1424 is [True, False, False, False, True, False]
Current timestep = 1425. State = [[-0.18758386  0.02253375]]. Action = [[-0.01047666 -0.04972516  0.          0.03747094]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 1425 is [True, False, False, False, True, False]
Current timestep = 1426. State = [[-0.1893388   0.02337417]]. Action = [[-0.03007703  0.04126173  0.          0.5605725 ]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 1426 is [True, False, False, False, True, False]
Current timestep = 1427. State = [[-0.19528891  0.02920181]]. Action = [[-0.09888311  0.08562218  0.          0.26623762]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 1427 is [True, False, False, False, True, False]
Current timestep = 1428. State = [[-0.19685678  0.03754816]]. Action = [[0.04920072 0.09759351 0.         0.28033924]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 1428 is [True, False, False, False, True, False]
Current timestep = 1429. State = [[-0.19238609  0.04302379]]. Action = [[ 0.09525596  0.02716585  0.         -0.5006823 ]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 1429 is [True, False, False, False, True, False]
State prediction error at timestep 1429 is 0.012
Human Feedback received at timestep 1429 of None
Current timestep = 1430. State = [[-0.18875524  0.04875698]]. Action = [[ 0.04515011  0.07436245  0.         -0.4256335 ]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 1430 is [True, False, False, False, True, False]
Current timestep = 1431. State = [[-0.18357165  0.04810819]]. Action = [[ 0.09504066 -0.07940916  0.         -0.43949127]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 1431 is [True, False, False, False, True, False]
Current timestep = 1432. State = [[-0.18298435  0.04545772]]. Action = [[-0.04779181 -0.0276552   0.         -0.988659  ]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 1432 is [True, False, False, False, True, False]
Current timestep = 1433. State = [[-0.18218136  0.04468196]]. Action = [[ 0.03558128 -0.01287808  0.         -0.5083436 ]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 1433 is [True, False, False, False, True, False]
Current timestep = 1434. State = [[-0.18534933  0.04597676]]. Action = [[-0.09551231  0.02159266  0.         -0.6639996 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 1434 is [True, False, False, False, True, False]
Current timestep = 1435. State = [[-0.18998863  0.04596327]]. Action = [[-0.05192648 -0.02867284  0.          0.01325774]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 1435 is [True, False, False, False, True, False]
Current timestep = 1436. State = [[-0.19361725  0.04951747]]. Action = [[-0.04601244  0.07258233  0.          0.7110313 ]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 1436 is [True, False, False, False, True, False]
Current timestep = 1437. State = [[-0.19122034  0.05613863]]. Action = [[0.09199657 0.07723535 0.         0.8989066 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 1437 is [True, False, False, False, True, False]
State prediction error at timestep 1437 is 0.012
Human Feedback received at timestep 1437 of None
Current timestep = 1438. State = [[-0.18599239  0.0596163 ]]. Action = [[ 0.069328    0.01023887  0.         -0.28548503]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 1438 is [True, False, False, False, True, False]
Current timestep = 1439. State = [[-0.18131311  0.05950549]]. Action = [[ 0.0569798  -0.02015522  0.         -0.78481257]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 1439 is [True, False, False, False, True, False]
Current timestep = 1440. State = [[-0.17771608  0.0641849 ]]. Action = [[0.03654256 0.09824716 0.         0.94787943]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 1440 is [True, False, False, False, True, False]
State prediction error at timestep 1440 is 0.012
Human Feedback received at timestep 1440 of None
Current timestep = 1441. State = [[-0.17214622  0.07175169]]. Action = [[0.09415235 0.08618986 0.         0.99782217]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 1441 is [True, False, False, False, True, False]
Current timestep = 1442. State = [[-0.16932446  0.07866416]]. Action = [[0.00466397 0.07283901 0.         0.7400501 ]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 1442 is [True, False, False, False, True, False]
Current timestep = 1443. State = [[-0.16420902  0.08143527]]. Action = [[ 0.09495779 -0.0086472   0.          0.06040668]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 1443 is [True, False, False, False, True, False]
Current timestep = 1444. State = [[-0.16542855  0.08747307]]. Action = [[-0.09802181  0.09958883  0.         -0.41195744]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 1444 is [True, False, False, False, True, False]
Current timestep = 1445. State = [[-0.1682899   0.09387343]]. Action = [[-0.00877435  0.03620287  0.         -0.8476604 ]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 1445 is [True, False, False, False, True, False]
Current timestep = 1446. State = [[-0.17073108  0.09895846]]. Action = [[-0.04140748  0.03807371  0.          0.22029376]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 1446 is [True, False, False, False, True, False]
State prediction error at timestep 1446 is 0.012
Human Feedback received at timestep 1446 of None
Current timestep = 1447. State = [[-0.16782506  0.10559741]]. Action = [[0.09093412 0.0702224  0.         0.21291411]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 1447 is [True, False, False, False, True, False]
Current timestep = 1448. State = [[-0.16217859  0.10732388]]. Action = [[ 0.06243824 -0.04317779  0.         -0.15279043]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 1448 is [True, False, False, False, True, False]
Current timestep = 1449. State = [[-0.15862665  0.10346311]]. Action = [[ 0.01452906 -0.08672799  0.         -0.06629378]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 1449 is [True, False, False, False, True, False]
Current timestep = 1450. State = [[-0.15801181  0.09965467]]. Action = [[-0.03145377 -0.05201534  0.          0.79719496]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 1450 is [True, False, False, False, True, False]
State prediction error at timestep 1450 is 0.012
Human Feedback received at timestep 1450 of None
Current timestep = 1451. State = [[-0.15955716  0.10030308]]. Action = [[-0.05115435  0.02370457  0.          0.02246761]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 1451 is [True, False, False, False, True, False]
State prediction error at timestep 1451 is 0.012
Human Feedback received at timestep 1451 of None
Current timestep = 1452. State = [[-0.1548741   0.09966776]]. Action = [[ 0.09946845 -0.03949891  0.         -0.9870909 ]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 1452 is [True, False, False, False, True, False]
State prediction error at timestep 1452 is 0.012
Human Feedback received at timestep 1452 of None
Current timestep = 1453. State = [[-0.14670004  0.09472869]]. Action = [[ 0.07786062 -0.0765634   0.         -0.44438338]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 1453 is [True, False, False, False, True, False]
Current timestep = 1454. State = [[-0.14483158  0.08995648]]. Action = [[-0.05443884 -0.04240147  0.         -0.072501  ]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 1454 is [True, False, False, False, True, False]
Current timestep = 1455. State = [[-0.14350322  0.08503292]]. Action = [[ 0.01284233 -0.06171844  0.         -0.00874412]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 1455 is [True, False, False, False, True, False]
Current timestep = 1456. State = [[-0.14112017  0.08017749]]. Action = [[ 0.00434891 -0.04173073  0.         -0.7072774 ]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 1456 is [True, False, False, False, True, False]
Current timestep = 1457. State = [[-0.14081594  0.07440899]]. Action = [[-0.03299508 -0.06707994  0.         -0.67370635]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 1457 is [True, False, False, False, True, False]
Current timestep = 1458. State = [[-0.13658763  0.0660131 ]]. Action = [[ 0.07250696 -0.09917022  0.         -0.91014206]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 1458 is [True, False, False, False, True, False]
Current timestep = 1459. State = [[-0.13235746  0.05693933]]. Action = [[ 0.01373346 -0.08210485  0.          0.16473722]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 1459 is [True, False, False, False, True, False]
State prediction error at timestep 1459 is 0.012
Human Feedback received at timestep 1459 of None
Current timestep = 1460. State = [[-0.12809034  0.05570286]]. Action = [[ 0.05054506  0.07258459  0.         -0.3128065 ]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 1460 is [True, False, False, False, True, False]
Current timestep = 1461. State = [[-0.12623148  0.05517274]]. Action = [[-0.00653112 -0.00821     0.         -0.5485547 ]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 1461 is [True, False, False, False, True, False]
Current timestep = 1462. State = [[-0.12772907  0.05175589]]. Action = [[-0.04407373 -0.0329038   0.         -0.7705038 ]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 1462 is [True, False, False, False, True, False]
Current timestep = 1463. State = [[-0.12515146  0.04517741]]. Action = [[ 0.06510916 -0.08172795  0.          0.20010865]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 1463 is [True, False, False, False, True, False]
Current timestep = 1464. State = [[-0.11998391  0.04293348]]. Action = [[ 0.06047433  0.04030026  0.         -0.32192743]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 1464 is [True, False, False, False, True, False]
State prediction error at timestep 1464 is 0.012
Human Feedback received at timestep 1464 of None
Current timestep = 1465. State = [[-0.11348596  0.04072483]]. Action = [[ 0.09293183 -0.02970576  0.         -0.2254268 ]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 1465 is [True, False, False, False, True, False]
Current timestep = 1466. State = [[-0.10980206  0.03988577]]. Action = [[ 0.01461755  0.03365671  0.         -0.4078287 ]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 1466 is [True, False, False, False, True, False]
Current timestep = 1467. State = [[-0.10744274  0.03604882]]. Action = [[ 0.02725735 -0.06842694  0.         -0.9357827 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 1467 is [True, False, False, False, True, False]
Current timestep = 1468. State = [[-0.10787765  0.03379502]]. Action = [[-0.04094739  0.01792912  0.         -0.59644294]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 1468 is [True, False, False, False, True, False]
Current timestep = 1469. State = [[-0.10674489  0.03058413]]. Action = [[ 0.02921923 -0.05446581  0.         -0.8247469 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 1469 is [True, False, False, False, True, False]
Current timestep = 1470. State = [[-0.10898872  0.03275759]]. Action = [[-0.07754637  0.09048424  0.         -0.7957287 ]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 1470 is [True, False, False, False, True, False]
Current timestep = 1471. State = [[-0.11046654  0.03389989]]. Action = [[ 0.00339459 -0.02517307  0.          0.7863995 ]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 1471 is [True, False, False, False, True, False]
Current timestep = 1472. State = [[-0.10833862  0.03667523]]. Action = [[ 0.04135879  0.06855657  0.         -0.75910056]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 1472 is [True, False, False, False, True, False]
Current timestep = 1473. State = [[-0.10643984  0.03953699]]. Action = [[0.02003442 0.0149953  0.         0.8815112 ]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 1473 is [True, False, False, False, True, False]
Current timestep = 1474. State = [[-0.10720586  0.04202215]]. Action = [[-0.02483636  0.0315308   0.         -0.64845496]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 1474 is [True, False, False, False, True, False]
Current timestep = 1475. State = [[-0.11064489  0.04824004]]. Action = [[-0.0520349   0.09056451  0.          0.86356854]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 1475 is [True, False, False, False, True, False]
Current timestep = 1476. State = [[-0.11178767  0.04730501]]. Action = [[ 0.01294918 -0.09588278  0.         -0.629161  ]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 1476 is [True, False, False, False, True, False]
Current timestep = 1477. State = [[-0.11485704  0.04340489]]. Action = [[-0.07163114 -0.04327599  0.          0.87127304]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 1477 is [True, False, False, False, True, False]
State prediction error at timestep 1477 is 0.012
Human Feedback received at timestep 1477 of None
Current timestep = 1478. State = [[-0.11854214  0.04671854]]. Action = [[-0.03714044  0.07902806  0.         -0.59886295]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 1478 is [True, False, False, False, True, False]
Current timestep = 1479. State = [[-0.12466846  0.05181568]]. Action = [[-0.09472588  0.03701889  0.          0.6064873 ]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 1479 is [True, False, False, False, True, False]
Current timestep = 1480. State = [[-0.12698293  0.05815495]]. Action = [[ 0.02638624  0.07811161  0.         -0.9119801 ]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 1480 is [True, False, False, False, True, False]
Current timestep = 1481. State = [[-0.1265064   0.06399573]]. Action = [[0.02192883 0.04511494 0.         0.20268762]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 1481 is [True, False, False, False, True, False]
Current timestep = 1482. State = [[-0.12894972  0.06591035]]. Action = [[-0.04109452 -0.01608104  0.          0.6220615 ]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 1482 is [True, False, False, False, True, False]
State prediction error at timestep 1482 is 0.012
Human Feedback received at timestep 1482 of None
Current timestep = 1483. State = [[-0.13081561  0.06702265]]. Action = [[ 0.00178875  0.00552988  0.         -0.32596886]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 1483 is [True, False, False, False, True, False]
Current timestep = 1484. State = [[-0.12890317  0.06381841]]. Action = [[ 0.05477067 -0.08488029  0.          0.79768944]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 1484 is [True, False, False, False, True, False]
Current timestep = 1485. State = [[-0.12377289  0.06061214]]. Action = [[ 0.08368694 -0.01843051  0.          0.14830208]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 1485 is [True, False, False, False, True, False]
Current timestep = 1486. State = [[-0.12006447  0.0609213 ]]. Action = [[ 0.0323313   0.02650739  0.         -0.30198348]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 1486 is [True, False, False, False, True, False]
Current timestep = 1487. State = [[-0.12154794  0.06466146]]. Action = [[-0.04983088  0.06572866  0.          0.977036  ]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 1487 is [True, False, False, False, True, False]
Current timestep = 1488. State = [[-0.12311216  0.06311198]]. Action = [[-0.00635284 -0.07184473  0.          0.7691494 ]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 1488 is [True, False, False, False, True, False]
Current timestep = 1489. State = [[-0.11928056  0.05648205]]. Action = [[ 0.07561516 -0.08884475  0.          0.31140244]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 1489 is [True, False, False, False, True, False]
State prediction error at timestep 1489 is 0.012
Human Feedback received at timestep 1489 of None
Current timestep = 1490. State = [[-0.11455052  0.05037722]]. Action = [[ 0.04000457 -0.05141348  0.         -0.08418   ]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 1490 is [True, False, False, False, True, False]
Current timestep = 1491. State = [[-0.11125299  0.05101356]]. Action = [[ 0.02677006  0.06888027  0.         -0.33323383]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 1491 is [True, False, False, False, True, False]
Current timestep = 1492. State = [[-0.11390027  0.04810569]]. Action = [[-0.09256151 -0.07975104  0.         -0.3563043 ]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 1492 is [True, False, False, False, True, False]
Current timestep = 1493. State = [[-0.11177479  0.04566019]]. Action = [[ 0.09076568  0.01330201  0.         -0.31479347]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 1493 is [True, False, False, False, True, False]
Current timestep = 1494. State = [[-0.10935225  0.04817193]]. Action = [[-0.01608587  0.06358313  0.         -0.04412127]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 1494 is [True, False, False, False, True, False]
Current timestep = 1495. State = [[-0.10655511  0.04505979]]. Action = [[ 0.04592397 -0.08855481  0.         -0.5517558 ]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 1495 is [True, False, False, False, True, False]
Current timestep = 1496. State = [[-0.10611495  0.03798666]]. Action = [[-0.0417276  -0.07831103  0.         -0.32500124]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 1496 is [True, False, False, False, True, False]
State prediction error at timestep 1496 is 0.012
Human Feedback received at timestep 1496 of None
Current timestep = 1497. State = [[-0.1016632  0.0333669]]. Action = [[ 0.09240686 -0.02480613  0.         -0.8970027 ]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 1497 is [True, False, False, False, True, False]
Current timestep = 1498. State = [[-0.09882216  0.0271227 ]]. Action = [[-0.0231591  -0.08315104  0.         -0.36174238]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 1498 is [True, False, False, False, True, False]
Current timestep = 1499. State = [[-0.09819435  0.02514411]]. Action = [[-0.00619667  0.03559572  0.          0.8975308 ]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 1499 is [True, False, False, False, True, False]
Current timestep = 1500. State = [[-0.10002338  0.02467424]]. Action = [[-0.05689107 -0.00674983  0.          0.90320766]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 1500 is [True, False, False, False, True, False]
Current timestep = 1501. State = [[-0.10046702  0.02611307]]. Action = [[0.00575855 0.04613181 0.         0.9310291 ]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 1501 is [True, False, False, False, True, False]
Current timestep = 1502. State = [[-0.09853391  0.02955667]]. Action = [[0.03296951 0.05112977 0.         0.8240664 ]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 1502 is [True, False, False, False, True, False]
State prediction error at timestep 1502 is 0.012
Human Feedback received at timestep 1502 of None
Current timestep = 1503. State = [[-0.09804848  0.0326796 ]]. Action = [[-0.00648826  0.03357963  0.         -0.9310339 ]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 1503 is [True, False, False, False, True, False]
Current timestep = 1504. State = [[-0.09490404  0.02959088]]. Action = [[ 0.06991971 -0.08408426  0.          0.00847363]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 1504 is [True, False, False, False, True, False]
Current timestep = 1505. State = [[-0.09517763  0.02566665]]. Action = [[-0.05099543 -0.02657112  0.         -0.9698017 ]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 1505 is [True, False, False, False, True, False]
State prediction error at timestep 1505 is 0.012
Human Feedback received at timestep 1505 of None
Current timestep = 1506. State = [[-0.09351885  0.02354036]]. Action = [[ 0.05796783 -0.01895523  0.          0.83143306]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 1506 is [True, False, False, False, True, False]
State prediction error at timestep 1506 is 0.012
Human Feedback received at timestep 1506 of None
Current timestep = 1507. State = [[-0.09083959  0.02609935]]. Action = [[ 0.02275302  0.07198184  0.         -0.70894635]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 1507 is [True, False, False, False, True, False]
Current timestep = 1508. State = [[-0.09383741  0.02587484]]. Action = [[-0.08079199 -0.0437201   0.         -0.83088493]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 1508 is [True, False, False, False, True, False]
Current timestep = 1509. State = [[-0.09282511  0.02041657]]. Action = [[ 0.06355228 -0.08394178  0.          0.7132865 ]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 1509 is [True, False, False, False, True, False]
Current timestep = 1510. State = [[-0.08760945  0.01527149]]. Action = [[ 0.06391043 -0.03911279  0.         -0.46859086]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 1510 is [True, False, False, False, True, False]
Current timestep = 1511. State = [[-0.08248717  0.01025961]]. Action = [[ 0.05488581 -0.05302021  0.         -0.14648324]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 1511 is [True, False, False, False, True, False]
Current timestep = 1512. State = [[-0.08432353  0.00672967]]. Action = [[-0.09725835 -0.01462736  0.          0.59059656]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 1512 is [True, False, False, False, True, False]
Current timestep = 1513. State = [[-0.08554632  0.00692118]]. Action = [[0.01550321 0.0340425  0.         0.8842988 ]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 1513 is [True, False, False, False, True, False]
Current timestep = 1514. State = [[-0.0861865   0.00511343]]. Action = [[-0.02550063 -0.03828431  0.         -0.6723196 ]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 1514 is [True, False, False, False, True, False]
Current timestep = 1515. State = [[-0.08343391  0.00240671]]. Action = [[ 0.06626055 -0.01523694  0.          0.12458003]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 1515 is [True, False, False, False, True, False]
Current timestep = 1516. State = [[-0.07997486 -0.00192469]]. Action = [[ 0.0308539  -0.05551709  0.         -0.6315275 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 1516 is [True, False, False, False, True, False]
Current timestep = 1517. State = [[-0.07850986 -0.00931295]]. Action = [[ 0.00135176 -0.09047297  0.          0.99288607]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 1517 is [True, False, False, False, True, False]
Current timestep = 1518. State = [[-0.07440284 -0.01129885]]. Action = [[0.07262554 0.04486326 0.         0.03558469]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 1518 is [True, False, False, False, True, False]
Current timestep = 1519. State = [[-0.06945739 -0.00818683]]. Action = [[ 0.05801701  0.06714135  0.         -0.85930544]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 1519 is [True, False, False, False, True, False]
Current timestep = 1520. State = [[-0.06773046 -0.00515133]]. Action = [[-1.1099875e-04  3.9760880e-02  0.0000000e+00  4.3665123e-01]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 1520 is [True, False, False, False, True, False]
State prediction error at timestep 1520 is 0.012
Human Feedback received at timestep 1520 of None
Current timestep = 1521. State = [[-0.07191582 -0.00388516]]. Action = [[-0.09704787  0.00801373  0.         -0.8554255 ]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 1521 is [True, False, False, False, True, False]
State prediction error at timestep 1521 is 0.012
Human Feedback received at timestep 1521 of None
Current timestep = 1522. State = [[-0.07183336 -0.00317244]]. Action = [[ 0.05390195  0.00747881  0.         -0.05900693]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 1522 is [True, False, False, False, True, False]
Current timestep = 1523. State = [[-0.06623057 -0.00554932]]. Action = [[ 0.08014847 -0.0522943   0.         -0.34181857]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 1523 is [True, False, False, False, True, False]
Current timestep = 1524. State = [[-0.06214005 -0.00984738]]. Action = [[ 0.0242388  -0.05047288  0.          0.65645385]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 1524 is [True, False, False, False, True, False]
Current timestep = 1525. State = [[-0.06076724 -0.00839559]]. Action = [[-0.00498878  0.0677257   0.         -0.73916453]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 1525 is [True, False, False, False, True, False]
Current timestep = 1526. State = [[-0.05647671 -0.00436352]]. Action = [[ 0.07861339  0.04501147  0.         -0.8942284 ]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 1526 is [True, False, False, False, True, False]
Current timestep = 1527. State = [[-0.05588735 -0.00041458]]. Action = [[-0.04565468  0.04785227  0.          0.31896913]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 1527 is [True, False, False, False, True, False]
Current timestep = 1528. State = [[-0.05695724  0.00605981]]. Action = [[-0.00661106  0.08727213  0.         -0.36756432]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 1528 is [True, False, False, False, True, False]
Current timestep = 1529. State = [[-0.06004932  0.00549506]]. Action = [[-0.06700736 -0.08603155  0.         -0.6453821 ]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 1529 is [True, False, False, False, True, False]
Current timestep = 1530. State = [[-0.06435624  0.00469234]]. Action = [[-0.06848673  0.00927445  0.          0.21219873]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 1530 is [True, False, False, False, True, False]
Current timestep = 1531. State = [[-0.07037576  0.00491503]]. Action = [[-0.09998731 -0.0217493   0.          0.85832524]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 1531 is [True, False, False, False, True, False]
Current timestep = 1532. State = [[-0.07350142  0.00774544]]. Action = [[-0.01543546  0.04617348  0.          0.5494752 ]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 1532 is [True, False, False, False, True, False]
Current timestep = 1533. State = [[-0.0760316   0.00667967]]. Action = [[-0.04192669 -0.06941541  0.          0.48358107]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 1533 is [True, False, False, False, True, False]
State prediction error at timestep 1533 is 0.012
Human Feedback received at timestep 1533 of None
Current timestep = 1534. State = [[-0.07503168  0.00500589]]. Action = [[ 0.04704539 -0.00739501  0.         -0.45726693]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 1534 is [True, False, False, False, True, False]
Current timestep = 1535. State = [[-0.07815626  0.00046218]]. Action = [[-0.0907034  -0.08987199  0.          0.8673451 ]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 1535 is [True, False, False, False, True, False]
Current timestep = 1536. State = [[-0.07719458 -0.00334121]]. Action = [[ 0.08615773 -0.01955017  0.         -0.17868888]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 1536 is [True, False, False, False, True, False]
Current timestep = 1537. State = [[-7.6625325e-02  2.3781782e-05]]. Action = [[-0.02736311  0.09398948  0.          0.90798736]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 1537 is [True, False, False, False, True, False]
Current timestep = 1538. State = [[-0.0781605 -0.0019744]]. Action = [[-0.01009677 -0.08747928  0.         -0.56074566]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 1538 is [True, False, False, False, True, False]
State prediction error at timestep 1538 is 0.012
Human Feedback received at timestep 1538 of None
Current timestep = 1539. State = [[-0.0822172  -0.00529003]]. Action = [[-0.07407103 -0.00835108  0.         -0.55325544]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 1539 is [True, False, False, False, True, False]
Current timestep = 1540. State = [[-0.08809656 -0.00817433]]. Action = [[-0.07607559 -0.04183691  0.          0.6811545 ]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 1540 is [True, False, False, False, True, False]
Current timestep = 1541. State = [[-0.08906022 -0.01207657]]. Action = [[ 0.03438669 -0.04238901  0.          0.3542813 ]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 1541 is [True, False, False, False, True, False]
Current timestep = 1542. State = [[-0.08900621 -0.01491253]]. Action = [[-0.00581502 -0.01383828  0.          0.469761  ]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 1542 is [True, False, False, False, True, False]
Current timestep = 1543. State = [[-0.08955601 -0.01691986]]. Action = [[ 0.00285075 -0.01273906  0.         -0.3305968 ]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 1543 is [True, False, False, False, True, False]
State prediction error at timestep 1543 is 0.012
Human Feedback received at timestep 1543 of None
Current timestep = 1544. State = [[-0.09295473 -0.01640581]]. Action = [[-0.05688209  0.03529751  0.         -0.63738257]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 1544 is [True, False, False, False, True, False]
Current timestep = 1545. State = [[-0.09714841 -0.01409598]]. Action = [[-0.03573651  0.03651395  0.         -0.66707754]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 1545 is [True, False, False, False, True, False]
Current timestep = 1546. State = [[-0.10254329 -0.01595146]]. Action = [[-0.06900895 -0.05552404  0.          0.64923024]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 1546 is [True, False, False, False, True, False]
Current timestep = 1547. State = [[-0.10923957 -0.0194078 ]]. Action = [[-0.08047295 -0.03462649  0.         -0.6899819 ]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 1547 is [True, False, False, False, True, False]
Current timestep = 1548. State = [[-0.1113969  -0.01761498]]. Action = [[ 0.0274075   0.06178281  0.         -0.9139861 ]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 1548 is [True, False, False, False, True, False]
Current timestep = 1549. State = [[-0.11330858 -0.01931744]]. Action = [[-0.02410155 -0.06740824  0.          0.4761808 ]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 1549 is [True, False, False, False, True, False]
Current timestep = 1550. State = [[-0.11261164 -0.02208536]]. Action = [[ 0.05350747 -0.01165059  0.         -0.1555996 ]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 1550 is [True, False, False, False, True, False]
Current timestep = 1551. State = [[-0.11470158 -0.02079058]]. Action = [[-0.04562667  0.04379549  0.         -0.84251654]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 1551 is [True, False, False, False, True, False]
Current timestep = 1552. State = [[-0.11308634 -0.01791945]]. Action = [[ 0.09252688  0.0374304   0.         -0.7901166 ]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 1552 is [True, False, False, False, True, False]
State prediction error at timestep 1552 is 0.012
Human Feedback received at timestep 1552 of None
Current timestep = 1553. State = [[-0.11212906 -0.01681947]]. Action = [[-0.00364823  0.00331391  0.         -0.70551646]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 1553 is [True, False, False, False, True, False]
State prediction error at timestep 1553 is 0.012
Human Feedback received at timestep 1553 of None
Current timestep = 1554. State = [[-0.10964549 -0.01336641]]. Action = [[0.07420974 0.068991   0.         0.22089267]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 1554 is [True, False, False, False, True, False]
State prediction error at timestep 1554 is 0.012
Human Feedback received at timestep 1554 of None
Current timestep = 1555. State = [[-0.11240052 -0.01082818]]. Action = [[-0.08527251  0.00873367  0.         -0.5131773 ]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 1555 is [True, False, False, False, True, False]
Current timestep = 1556. State = [[-0.11703294 -0.00923916]]. Action = [[-0.02867537  0.01585113  0.         -0.15783286]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 1556 is [True, False, False, False, True, False]
State prediction error at timestep 1556 is 0.012
Human Feedback received at timestep 1556 of None
Current timestep = 1557. State = [[-0.11551588 -0.00454927]]. Action = [[ 0.07630657  0.07257321  0.         -0.21380079]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 1557 is [True, False, False, False, True, False]
Current timestep = 1558. State = [[-0.11309228  0.00078373]]. Action = [[0.03429561 0.04962646 0.         0.5663972 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 1558 is [True, False, False, False, True, False]
Current timestep = 1559. State = [[-0.10900266  0.00468088]]. Action = [[0.08484896 0.0307012  0.         0.35557103]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 1559 is [True, False, False, False, True, False]
Current timestep = 1560. State = [[-0.10834517  0.00848731]]. Action = [[-0.0214313   0.03997283  0.          0.3447293 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 1560 is [True, False, False, False, True, False]
Current timestep = 1561. State = [[-0.10485594  0.0100866 ]]. Action = [[ 0.09222563 -0.01151257  0.          0.34785795]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 1561 is [True, False, False, False, True, False]
Current timestep = 1562. State = [[-0.09971861  0.00561059]]. Action = [[ 0.05148353 -0.09874784  0.         -0.47278446]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 1562 is [True, False, False, False, True, False]
State prediction error at timestep 1562 is 0.012
Human Feedback received at timestep 1562 of None
Current timestep = 1563. State = [[-0.09572542  0.00143966]]. Action = [[ 0.03281083 -0.03119799  0.          0.75536084]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 1563 is [True, False, False, False, True, False]
Current timestep = 1564. State = [[-0.09429532  0.00386693]]. Action = [[-0.01499406  0.06981295  0.         -0.48162043]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 1564 is [True, False, False, False, True, False]
Current timestep = 1565. State = [[-0.09530584  0.00378153]]. Action = [[-0.04153795 -0.04592663  0.         -0.65664047]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 1565 is [True, False, False, False, True, False]
Current timestep = 1566. State = [[-0.09679534  0.00324405]]. Action = [[-0.03916536  0.00861093  0.         -0.7373053 ]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 1566 is [True, False, False, False, True, False]
Current timestep = 1567. State = [[-0.09305543  0.00522577]]. Action = [[ 0.0776385   0.03117692  0.         -0.20144552]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 1567 is [True, False, False, False, True, False]
Current timestep = 1568. State = [[-0.086879    0.00959087]]. Action = [[0.06479464 0.0654342  0.         0.4732356 ]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 1568 is [True, False, False, False, True, False]
Current timestep = 1569. State = [[-0.08443847  0.01457974]]. Action = [[-0.00549515  0.05282726  0.          0.37834978]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 1569 is [True, False, False, False, True, False]
State prediction error at timestep 1569 is 0.012
Human Feedback received at timestep 1569 of None
Current timestep = 1570. State = [[-0.08370684  0.01791514]]. Action = [[-0.00103794  0.01925635  0.         -0.08321935]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 1570 is [True, False, False, False, True, False]
Current timestep = 1571. State = [[-0.08332216  0.01935971]]. Action = [[-0.00963905 -0.00203442  0.          0.39519787]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 1571 is [True, False, False, False, True, False]
Current timestep = 1572. State = [[-0.08124019  0.02207372]]. Action = [[ 0.03063687  0.03583518  0.         -0.9918606 ]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 1572 is [True, False, False, False, True, False]
Current timestep = 1573. State = [[-0.08250625  0.02584313]]. Action = [[-0.05789649  0.03299067  0.          0.5921525 ]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 1573 is [True, False, False, False, True, False]
Current timestep = 1574. State = [[-0.08748712  0.0307006 ]]. Action = [[-0.08549201  0.04824985  0.         -0.3042485 ]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 1574 is [True, False, False, False, True, False]
Current timestep = 1575. State = [[-0.09183195  0.03036342]]. Action = [[-0.05274595 -0.07027635  0.         -0.23156142]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 1575 is [True, False, False, False, True, False]
Current timestep = 1576. State = [[-0.0928573   0.03210458]]. Action = [[ 0.00123967  0.04571851  0.         -0.57090026]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 1576 is [True, False, False, False, True, False]
Current timestep = 1577. State = [[-0.09449097  0.03774541]]. Action = [[-0.03154106  0.06151026  0.          0.13780665]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 1577 is [True, False, False, False, True, False]
Current timestep = 1578. State = [[-0.09690481  0.04549969]]. Action = [[-0.02149134  0.08806904  0.          0.51169   ]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 1578 is [True, False, False, False, True, False]
State prediction error at timestep 1578 is 0.012
Human Feedback received at timestep 1578 of None
Current timestep = 1579. State = [[-0.09552208  0.053368  ]]. Action = [[0.06419582 0.07201009 0.         0.62212944]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 1579 is [True, False, False, False, True, False]
Current timestep = 1580. State = [[-0.09882758  0.05995914]]. Action = [[-0.08332518  0.05322655  0.         -0.44816828]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 1580 is [True, False, False, False, True, False]
Current timestep = 1581. State = [[-0.1066977   0.06738374]]. Action = [[-0.08701854  0.07539187  0.          0.21832812]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 1581 is [True, False, False, False, True, False]
Current timestep = 1582. State = [[-0.11093721  0.07515284]]. Action = [[ 0.00139146  0.06540807  0.         -0.511785  ]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 1582 is [True, False, False, False, True, False]
State prediction error at timestep 1582 is 0.012
Human Feedback received at timestep 1582 of None
Current timestep = 1583. State = [[-0.11421295  0.08299069]]. Action = [[-0.02337611  0.0720438   0.          0.7690635 ]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 1583 is [True, False, False, False, True, False]
State prediction error at timestep 1583 is 0.012
Human Feedback received at timestep 1583 of None
Current timestep = 1584. State = [[-0.11608893  0.0845382 ]]. Action = [[ 0.01359774 -0.05711904  0.          0.5771655 ]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 1584 is [True, False, False, False, True, False]
State prediction error at timestep 1584 is 0.012
Human Feedback received at timestep 1584 of None
Current timestep = 1585. State = [[-0.11768474  0.08935284]]. Action = [[-0.00737277  0.09191979  0.         -0.5194509 ]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 1585 is [True, False, False, False, True, False]
State prediction error at timestep 1585 is 0.012
Human Feedback received at timestep 1585 of None
Current timestep = 1586. State = [[-0.11709598  0.09495845]]. Action = [[ 0.05148017  0.02715588  0.         -0.9118658 ]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 1586 is [True, False, False, False, True, False]
Current timestep = 1587. State = [[-0.11474753  0.09631553]]. Action = [[ 0.04822493 -0.01776174  0.         -0.19896579]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 1587 is [True, False, False, False, True, False]
Current timestep = 1588. State = [[-0.11208417  0.10171935]]. Action = [[ 0.04716688  0.09942881  0.         -0.7517694 ]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 1588 is [True, False, False, False, True, False]
Current timestep = 1589. State = [[-0.10798876  0.10772579]]. Action = [[0.07636086 0.048103   0.         0.84044373]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 1589 is [True, False, False, False, True, False]
Current timestep = 1590. State = [[-0.10500473  0.10651356]]. Action = [[ 0.0240189  -0.06965724  0.         -0.900024  ]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 1590 is [True, False, False, False, True, False]
Current timestep = 1591. State = [[-0.10137159  0.10893922]]. Action = [[ 0.05344509  0.07738144  0.         -0.8863841 ]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 1591 is [True, False, False, False, True, False]
Current timestep = 1592. State = [[-0.09578858  0.11181318]]. Action = [[ 0.07609994  0.00758734  0.         -0.02844095]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 1592 is [True, False, False, False, True, False]
Current timestep = 1593. State = [[-0.09348544  0.10796148]]. Action = [[-0.02114937 -0.09244832  0.         -0.5875644 ]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 1593 is [True, False, False, False, True, False]
Current timestep = 1594. State = [[-0.0920708   0.10789821]]. Action = [[ 0.00912396  0.04535068  0.         -0.30819112]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 1594 is [True, False, False, False, True, False]
Current timestep = 1595. State = [[-0.08688708  0.10565299]]. Action = [[ 0.07382973 -0.07218885  0.         -0.17006117]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 1595 is [True, False, False, False, True, False]
State prediction error at timestep 1595 is 0.012
Human Feedback received at timestep 1595 of None
Current timestep = 1596. State = [[-0.08632789  0.10532086]]. Action = [[-0.06656659  0.03479893  0.          0.9758394 ]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 1596 is [True, False, False, False, True, False]
Current timestep = 1597. State = [[-0.08243545  0.10970414]]. Action = [[ 0.09600129  0.06935512  0.         -0.32911998]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 1597 is [True, False, False, False, True, False]
Current timestep = 1598. State = [[-0.07919762  0.11079969]]. Action = [[-0.0182647  -0.02355801  0.         -0.11012316]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 1598 is [True, False, False, False, True, False]
Current timestep = 1599. State = [[-0.07407188  0.11321755]]. Action = [[0.0851488  0.05547728 0.         0.23487604]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 1599 is [True, False, False, False, True, False]
State prediction error at timestep 1599 is 0.012
Human Feedback received at timestep 1599 of None
Current timestep = 1600. State = [[-0.07298071  0.11044096]]. Action = [[-0.07022019 -0.0973137   0.         -0.99581367]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 1600 is [True, False, False, False, True, False]
Current timestep = 1601. State = [[-0.0771931   0.10916433]]. Action = [[-0.08316027  0.01786487  0.          0.17488277]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 1601 is [True, False, False, False, True, False]
State prediction error at timestep 1601 is 0.012
Human Feedback received at timestep 1601 of None
Current timestep = 1602. State = [[-0.07623129  0.10666597]]. Action = [[ 0.04660726 -0.06900749  0.          0.33055115]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 1602 is [True, False, False, False, True, False]
Current timestep = 1603. State = [[-0.07492276  0.10120104]]. Action = [[-0.02208587 -0.07231178  0.         -0.6190214 ]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 1603 is [True, False, False, False, True, False]
Current timestep = 1604. State = [[-0.07724098  0.09761211]]. Action = [[-0.06397487 -0.02682237  0.          0.33128715]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 1604 is [True, False, False, False, True, False]
Current timestep = 1605. State = [[-0.08073337  0.0930284 ]]. Action = [[-0.06012436 -0.0733377   0.         -0.03627282]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 1605 is [True, False, False, False, True, False]
Current timestep = 1606. State = [[-0.08037975  0.08865559]]. Action = [[ 0.02415691 -0.03650582  0.         -0.14097309]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 1606 is [True, False, False, False, True, False]
Current timestep = 1607. State = [[-0.08353301  0.0853536 ]]. Action = [[-0.09194881 -0.02990126  0.          0.29803514]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 1607 is [True, False, False, False, True, False]
Current timestep = 1608. State = [[-0.08297447  0.08145034]]. Action = [[ 0.06317379 -0.04353961  0.         -0.3538506 ]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 1608 is [True, False, False, False, True, False]
State prediction error at timestep 1608 is 0.012
Human Feedback received at timestep 1608 of None
Current timestep = 1609. State = [[-0.07876673  0.08351001]]. Action = [[0.05675899 0.09392119 0.         0.44186306]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 1609 is [True, False, False, False, True, False]
State prediction error at timestep 1609 is 0.012
Human Feedback received at timestep 1609 of None
Current timestep = 1610. State = [[-0.08146163  0.08258219]]. Action = [[-0.09185355 -0.05443493  0.         -0.53730845]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 1610 is [True, False, False, False, True, False]
Current timestep = 1611. State = [[-0.0822812   0.08254689]]. Action = [[0.05767635 0.04496387 0.         0.0437175 ]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 1611 is [True, False, False, False, True, False]
Current timestep = 1612. State = [[-0.08270807  0.08029108]]. Action = [[-0.02004377 -0.05413809  0.         -0.47565675]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 1612 is [True, False, False, False, True, False]
Current timestep = 1613. State = [[-0.08744449  0.07899901]]. Action = [[-0.07432035  0.01630358  0.         -0.69911927]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 1613 is [True, False, False, False, True, False]
Current timestep = 1614. State = [[-0.08973835  0.0788704 ]]. Action = [[ 0.01182995 -0.00352377  0.         -0.7524718 ]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 1614 is [True, False, False, False, True, False]
Current timestep = 1615. State = [[-0.08608849  0.07328961]]. Action = [[ 0.08961155 -0.09830888  0.          0.93678665]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 1615 is [True, False, False, False, True, False]
Current timestep = 1616. State = [[-0.08630738  0.0723474 ]]. Action = [[-0.04115922  0.06040014  0.         -0.6951791 ]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 1616 is [True, False, False, False, True, False]
Current timestep = 1617. State = [[-0.08715895  0.07090718]]. Action = [[ 0.01773216 -0.04698221  0.          0.7812964 ]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 1617 is [True, False, False, False, True, False]
Current timestep = 1618. State = [[-0.08374929  0.06900506]]. Action = [[ 0.07312848  0.00536193  0.         -0.37286294]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 1618 is [True, False, False, False, True, False]
Current timestep = 1619. State = [[-0.07989289  0.06439454]]. Action = [[ 0.04690848 -0.07110648  0.         -0.7875025 ]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 1619 is [True, False, False, False, True, False]
Current timestep = 1620. State = [[-0.0809295   0.05955883]]. Action = [[-0.05349733 -0.03136443  0.         -0.23892117]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 1620 is [True, False, False, False, True, False]
Current timestep = 1621. State = [[-0.08235468  0.06051628]]. Action = [[-0.00479132  0.06034371  0.         -0.38310277]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 1621 is [True, False, False, False, True, False]
Current timestep = 1622. State = [[-0.08106609  0.05834047]]. Action = [[ 0.03202135 -0.06055382  0.         -0.28399217]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 1622 is [True, False, False, False, True, False]
Current timestep = 1623. State = [[-0.07744366  0.05199787]]. Action = [[ 0.05256284 -0.07232735  0.         -0.84352326]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 1623 is [True, False, False, False, True, False]
Current timestep = 1624. State = [[-0.07159034  0.04671391]]. Action = [[ 0.08191251 -0.03223746  0.          0.9050915 ]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 1624 is [True, False, False, False, True, False]
State prediction error at timestep 1624 is 0.012
Human Feedback received at timestep 1624 of None
Current timestep = 1625. State = [[-0.0686411   0.04884218]]. Action = [[ 0.00572066  0.09661039  0.         -0.01303387]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 1625 is [True, False, False, False, True, False]
State prediction error at timestep 1625 is 0.012
Human Feedback received at timestep 1625 of None
Current timestep = 1626. State = [[-0.06482189  0.049751  ]]. Action = [[ 0.06891333 -0.01283159  0.          0.07748735]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 1626 is [True, False, False, False, True, False]
Current timestep = 1627. State = [[-0.06536695  0.04851021]]. Action = [[-0.06462065 -0.00251338  0.          0.11960971]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 1627 is [True, False, False, False, True, False]
Current timestep = 1628. State = [[-0.06474096  0.05052927]]. Action = [[0.04028495 0.0524487  0.         0.35668898]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 1628 is [True, False, False, False, True, False]
State prediction error at timestep 1628 is 0.012
Human Feedback received at timestep 1628 of None
Current timestep = 1629. State = [[-0.05966263  0.04868802]]. Action = [[ 0.0790096  -0.05968311  0.         -0.58716345]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 1629 is [True, False, False, False, True, False]
Current timestep = 1630. State = [[-0.05422605  0.04977713]]. Action = [[0.05860112 0.0667732  0.         0.46743882]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 1630 is [True, False, False, False, True, False]
Current timestep = 1631. State = [[-0.05496029  0.05340246]]. Action = [[-0.06300756  0.039465    0.         -0.33273357]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 1631 is [True, False, False, False, True, False]
Current timestep = 1632. State = [[-0.05296477  0.05441789]]. Action = [[ 0.0688987  -0.00955579  0.          0.9536979 ]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 1632 is [True, False, False, False, True, False]
Current timestep = 1633. State = [[-0.05445429  0.05479432]]. Action = [[-0.08740619  0.00385324  0.          0.03225243]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 1633 is [True, False, False, False, True, False]
Current timestep = 1634. State = [[-0.06025498  0.05329341]]. Action = [[-0.0898143  -0.04817659  0.          0.42465246]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 1634 is [True, False, False, False, True, False]
Current timestep = 1635. State = [[-0.06037512  0.05280864]]. Action = [[ 0.04229348  0.00367234  0.         -0.04878718]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 1635 is [True, False, False, False, True, False]
State prediction error at timestep 1635 is 0.012
Human Feedback received at timestep 1635 of None
Current timestep = 1636. State = [[-0.05447244  0.05496665]]. Action = [[ 0.09413358  0.03615323  0.         -0.17432445]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 1636 is [True, False, False, False, True, False]
Current timestep = 1637. State = [[-0.05063654  0.05597086]]. Action = [[ 0.02102898 -0.00280128  0.         -0.00671107]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 1637 is [True, False, False, False, True, False]
Current timestep = 1638. State = [[-0.05161207  0.05303495]]. Action = [[-0.04814641 -0.06143905  0.         -0.9111524 ]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 1638 is [True, False, False, False, True, False]
Current timestep = 1639. State = [[-0.05263964  0.0536153 ]]. Action = [[-0.01166666  0.04453904  0.         -0.05539638]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 1639 is [True, False, False, False, True, False]
Current timestep = 1640. State = [[-0.32761618  0.10383255]]. Action = [[ 0.06623768  0.04785422  0.         -0.71716523]]. Reward = [100.]
Curr episode timestep = 740
Scene graph at timestep 1640 is [True, False, False, False, True, False]
Current timestep = 1641. State = [[-0.33098957  0.09881854]]. Action = [[ 0.04846614 -0.06452547  0.         -0.34355152]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1641 is [True, False, False, False, True, False]
State prediction error at timestep 1641 is 0.012
Human Feedback received at timestep 1641 of None
Current timestep = 1642. State = [[-0.3335515   0.09211624]]. Action = [[-0.0166992  -0.06409699  0.         -0.74286115]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1642 is [True, False, False, False, True, False]
State prediction error at timestep 1642 is 0.012
Human Feedback received at timestep 1642 of None
Current timestep = 1643. State = [[-0.3405129   0.08684384]]. Action = [[-0.088772   -0.03894525  0.          0.6640246 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1643 is [True, False, False, False, True, False]
Current timestep = 1644. State = [[-0.3472678   0.08717249]]. Action = [[-0.04390135  0.05618494  0.          0.11461151]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1644 is [True, False, False, False, True, False]
Current timestep = 1645. State = [[-0.34661883  0.08272998]]. Action = [[ 0.08576285 -0.09707598  0.          0.567889  ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1645 is [True, False, False, False, True, False]
Current timestep = 1646. State = [[-0.3487738   0.07612351]]. Action = [[-0.06492718 -0.04707873  0.         -0.840912  ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1646 is [True, False, False, False, True, False]
State prediction error at timestep 1646 is 0.012
Human Feedback received at timestep 1646 of None
Current timestep = 1647. State = [[-0.35233092  0.07693504]]. Action = [[-0.00622446  0.07656641  0.          0.7214942 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1647 is [True, False, False, False, True, False]
Current timestep = 1648. State = [[-0.3529011   0.07350368]]. Action = [[ 0.02748735 -0.08763855  0.         -0.28674734]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1648 is [True, False, False, False, True, False]
State prediction error at timestep 1648 is 0.012
Human Feedback received at timestep 1648 of None
Current timestep = 1649. State = [[-0.35568258  0.07268049]]. Action = [[-0.04625107  0.06089827  0.          0.03275394]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 1649 is [True, False, False, False, True, False]
Current timestep = 1650. State = [[-0.35662913  0.07472315]]. Action = [[0.03655168 0.02793505 0.         0.31728196]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 1650 is [True, False, False, False, True, False]
Current timestep = 1651. State = [[-0.35353523  0.07169183]]. Action = [[ 0.07021508 -0.06008403  0.         -0.25170743]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1651 is [True, False, False, False, True, False]
Current timestep = 1652. State = [[-0.35707596  0.07329633]]. Action = [[-0.09786566  0.08521651  0.         -0.64890885]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 1652 is [True, False, False, False, True, False]
Current timestep = 1653. State = [[-0.36038512  0.07333965]]. Action = [[ 0.00766774 -0.04443889  0.          0.6883905 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 1653 is [True, False, False, False, True, False]
Current timestep = 1654. State = [[-0.36068863  0.07546091]]. Action = [[ 0.01305105  0.06965374  0.         -0.6443768 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 1654 is [True, False, False, False, True, False]
Current timestep = 1655. State = [[-0.3606833   0.07767126]]. Action = [[0.0166273  0.00574385 0.         0.30843842]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 1655 is [True, False, False, False, True, False]
Current timestep = 1656. State = [[-0.3594509   0.07321333]]. Action = [[ 0.02768887 -0.09596533  0.         -0.10255241]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 1656 is [True, False, False, False, True, False]
Current timestep = 1657. State = [[-0.3560365  0.0678011]]. Action = [[ 0.05013534 -0.04887119  0.         -0.21528304]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 1657 is [True, False, False, False, True, False]
State prediction error at timestep 1657 is 0.012
Human Feedback received at timestep 1657 of None
Current timestep = 1658. State = [[-0.3513041   0.06983422]]. Action = [[0.06194665 0.08499632 0.         0.23487806]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 1658 is [True, False, False, False, True, False]
Current timestep = 1659. State = [[-0.35374683  0.07551498]]. Action = [[-0.09254691  0.07057177  0.         -0.14825642]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 1659 is [True, False, False, False, True, False]
Current timestep = 1660. State = [[-0.3600403   0.07395238]]. Action = [[-0.07481259 -0.08373065  0.         -0.5912913 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 1660 is [True, False, False, False, True, False]
Current timestep = 1661. State = [[-0.36182645  0.07452124]]. Action = [[0.01557746 0.05321633 0.         0.01676667]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 1661 is [True, False, False, False, True, False]
State prediction error at timestep 1661 is 0.012
Human Feedback received at timestep 1661 of None
Current timestep = 1662. State = [[-0.36050233  0.07540032]]. Action = [[ 0.02828187 -0.01480464  0.          0.49417293]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 1662 is [True, False, False, False, True, False]
Current timestep = 1663. State = [[-0.35674578  0.07753458]]. Action = [[ 0.06692731  0.04968681  0.         -0.9387069 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 1663 is [True, False, False, False, True, False]
State prediction error at timestep 1663 is 0.012
Human Feedback received at timestep 1663 of None
Current timestep = 1664. State = [[-0.35854718  0.07731272]]. Action = [[-0.07902201 -0.03776725  0.         -0.04167175]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 1664 is [True, False, False, False, True, False]
Current timestep = 1665. State = [[-0.36528918  0.07236368]]. Action = [[-0.09246209 -0.08746035  0.          0.40793037]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 1665 is [True, False, False, False, True, False]
Current timestep = 1666. State = [[-0.36686826  0.06514641]]. Action = [[ 0.02223419 -0.09601351  0.         -0.37350094]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 1666 is [True, False, False, False, True, False]
Current timestep = 1667. State = [[-0.36819187  0.06600721]]. Action = [[-0.03197093  0.0955553   0.         -0.61297256]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 1667 is [True, False, False, False, True, False]
Current timestep = 1668. State = [[-0.3716436   0.06639378]]. Action = [[-0.03780412 -0.04209345  0.         -0.9659543 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 1668 is [True, False, False, False, True, False]
Current timestep = 1669. State = [[-0.37196118  0.06053941]]. Action = [[ 0.02451309 -0.09147425  0.         -0.59013903]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 1669 is [True, False, False, False, True, False]
Current timestep = 1670. State = [[-0.37113184  0.05293909]]. Action = [[ 0.00409816 -0.08389035  0.          0.40107584]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 1670 is [True, False, False, False, True, False]
Current timestep = 1671. State = [[-0.36787495  0.04514521]]. Action = [[ 0.05794273 -0.08121129  0.         -0.48994422]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 1671 is [True, False, False, False, True, False]
Current timestep = 1672. State = [[-0.36827636  0.03889656]]. Action = [[-0.0521296  -0.04570774  0.          0.35711658]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 1672 is [True, False, False, False, True, False]
Current timestep = 1673. State = [[-0.3715624   0.03375471]]. Action = [[-0.04837132 -0.04415559  0.          0.9682554 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 1673 is [True, False, False, False, True, False]
Current timestep = 1674. State = [[-0.3729136   0.03079091]]. Action = [[0.        0.        0.        0.5385126]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 1674 is [True, False, False, False, True, False]
Current timestep = 1675. State = [[-0.3693364   0.02427263]]. Action = [[ 0.0807459  -0.09412576  0.          0.48030353]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 1675 is [True, False, False, False, True, False]
Current timestep = 1676. State = [[-0.36593136  0.01477589]]. Action = [[ 0.02449362 -0.09568343  0.          0.49652314]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 1676 is [True, False, False, False, True, False]
Current timestep = 1677. State = [[-0.3673882   0.01337219]]. Action = [[-0.04619167  0.07526233  0.         -0.78129387]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 1677 is [True, False, False, False, True, False]
State prediction error at timestep 1677 is 0.012
Human Feedback received at timestep 1677 of None
Current timestep = 1678. State = [[-0.36968327  0.01062362]]. Action = [[-0.01699464 -0.06571168  0.          0.5153916 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 1678 is [True, False, False, False, True, False]
Current timestep = 1679. State = [[-0.36758116  0.00773563]]. Action = [[ 0.06109185  0.00880975  0.         -0.56542057]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 1679 is [True, False, False, False, True, False]
State prediction error at timestep 1679 is 0.012
Human Feedback received at timestep 1679 of None
Current timestep = 1680. State = [[-0.36291918  0.00181731]]. Action = [[ 0.06956065 -0.09238352  0.         -0.64511365]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 1680 is [True, False, False, False, True, False]
Current timestep = 1681. State = [[-0.35772967  0.00082938]]. Action = [[0.07091781 0.06744381 0.         0.27184558]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 1681 is [True, False, False, False, True, False]
Current timestep = 1682. State = [[-0.35162225  0.00596432]]. Action = [[ 0.09347703  0.08679914  0.         -0.74899167]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 1682 is [True, False, False, False, True, False]
Current timestep = 1683. State = [[-0.35133046  0.00420819]]. Action = [[-0.05056575 -0.08653894  0.         -0.76011175]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 1683 is [True, False, False, False, True, False]
Current timestep = 1684. State = [[-0.35601807 -0.00230684]]. Action = [[-0.07184376 -0.06866738  0.          0.5597789 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 1684 is [True, False, False, False, True, False]
Current timestep = 1685. State = [[-0.35852244 -0.00110643]]. Action = [[-0.00770409  0.08641093  0.          0.59883976]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 1685 is [True, False, False, False, True, False]
State prediction error at timestep 1685 is 0.012
Human Feedback received at timestep 1685 of None
Current timestep = 1686. State = [[-0.3616797   0.00573913]]. Action = [[-0.04352471  0.09324879  0.         -0.19850779]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 1686 is [True, False, False, False, True, False]
Current timestep = 1687. State = [[-0.36741617  0.01263793]]. Action = [[-0.06893685  0.07252338  0.         -0.09769779]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 1687 is [True, False, False, False, True, False]
Current timestep = 1688. State = [[-0.3707309   0.01579996]]. Action = [[0.        0.        0.        0.3802408]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 1688 is [True, False, False, False, True, False]
Current timestep = 1689. State = [[-0.36797544  0.01661352]]. Action = [[ 0.08817083 -0.00606167  0.         -0.35611665]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 1689 is [True, False, False, False, True, False]
Current timestep = 1690. State = [[-0.3623947   0.01311256]]. Action = [[ 0.08695786 -0.08182957  0.          0.8354368 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 1690 is [True, False, False, False, True, False]
Current timestep = 1691. State = [[-0.36355522  0.00617293]]. Action = [[-0.08785827 -0.09833588  0.         -0.0291959 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 1691 is [True, False, False, False, True, False]
Current timestep = 1692. State = [[-0.36779204  0.00756773]]. Action = [[-0.02952545  0.09985384  0.          0.03841424]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 1692 is [True, False, False, False, True, False]
State prediction error at timestep 1692 is 0.012
Human Feedback received at timestep 1692 of None
Current timestep = 1693. State = [[-0.36563724  0.00964947]]. Action = [[ 0.08581822 -0.01669133  0.          0.72429824]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 1693 is [True, False, False, False, True, False]
Current timestep = 1694. State = [[-0.36105648  0.00716142]]. Action = [[ 0.05687662 -0.04478177  0.         -0.84171414]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 1694 is [True, False, False, False, True, False]
Current timestep = 1695. State = [[-0.36052465  0.0009424 ]]. Action = [[-0.02959806 -0.09374854  0.          0.00583839]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 1695 is [True, False, False, False, True, False]
State prediction error at timestep 1695 is 0.012
Human Feedback received at timestep 1695 of None
Current timestep = 1696. State = [[-0.36064714 -0.00161019]]. Action = [[-0.00048345  0.01728419  0.         -0.34769374]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 1696 is [True, False, False, False, True, False]
State prediction error at timestep 1696 is 0.012
Human Feedback received at timestep 1696 of None
Current timestep = 1697. State = [[-0.3612023  -0.00145947]]. Action = [[-0.02053362  0.01029809  0.          0.31329632]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 1697 is [True, False, False, False, True, False]
Current timestep = 1698. State = [[-0.36463755  0.00293039]]. Action = [[-0.06322087  0.09290879  0.          0.82626224]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 1698 is [True, False, False, False, True, False]
Current timestep = 1699. State = [[-0.3674799   0.00635365]]. Action = [[-0.01433234  0.01579387  0.          0.6211436 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 1699 is [True, False, False, False, True, False]
Current timestep = 1700. State = [[-0.3706836   0.00778036]]. Action = [[-0.04488403  0.01286776  0.          0.27077866]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 1700 is [True, False, False, False, True, False]
Current timestep = 1701. State = [[-0.37044814  0.00854217]]. Action = [[ 0.04513345  0.00089148  0.         -0.60245746]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 1701 is [True, False, False, False, True, False]
Current timestep = 1702. State = [[-0.3687857   0.01392099]]. Action = [[0.03068585 0.09776481 0.         0.8291602 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 1702 is [True, False, False, False, True, False]
Current timestep = 1703. State = [[-0.371275    0.01608331]]. Action = [[-0.04785303 -0.02908176  0.         -0.6445944 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 1703 is [True, False, False, False, True, False]
Current timestep = 1704. State = [[-0.37549326  0.0126551 ]]. Action = [[-0.04889363 -0.06726149  0.         -0.9417914 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 1704 is [True, False, False, False, True, False]
State prediction error at timestep 1704 is 0.012
Human Feedback received at timestep 1704 of None
Current timestep = 1705. State = [[-0.37688598  0.01569655]]. Action = [[ 0.01425348  0.09952035  0.         -0.17685163]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 1705 is [True, False, False, False, True, False]
Current timestep = 1706. State = [[-0.3769027   0.01917771]]. Action = [[ 0.01356339 -0.00108007  0.          0.28601158]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 1706 is [True, False, False, False, True, False]
Current timestep = 1707. State = [[-0.37351778  0.01784985]]. Action = [[ 0.07682256 -0.042303    0.         -0.7853192 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 1707 is [True, False, False, False, True, False]
Current timestep = 1708. State = [[-0.3716631   0.01696784]]. Action = [[0.        0.        0.        0.3841014]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 1708 is [True, False, False, False, True, False]
Current timestep = 1709. State = [[-0.37236258  0.01634869]]. Action = [[-0.01694203 -0.01561052  0.          0.6972134 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 1709 is [True, False, False, False, True, False]
Current timestep = 1710. State = [[-0.36889163  0.01208291]]. Action = [[ 0.07416108 -0.07650431  0.          0.1637541 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 1710 is [True, False, False, False, True, False]
Current timestep = 1711. State = [[-0.36293396  0.01111894]]. Action = [[0.06822898 0.03408932 0.         0.86223197]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 1711 is [True, False, False, False, True, False]
Current timestep = 1712. State = [[-0.35591635  0.00949813]]. Action = [[ 0.08816113 -0.04046193  0.         -0.34440064]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 1712 is [True, False, False, False, True, False]
Current timestep = 1713. State = [[-0.35310125  0.01100853]]. Action = [[-0.01591974  0.06523462  0.         -0.5635049 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 1713 is [True, False, False, False, True, False]
Current timestep = 1714. State = [[-0.35707718  0.01325354]]. Action = [[-0.09597376  0.01608057  0.         -0.3203107 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 1714 is [True, False, False, False, True, False]
Current timestep = 1715. State = [[-0.36111706  0.01111492]]. Action = [[-0.04781587 -0.05116152  0.          0.25613427]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 1715 is [True, False, False, False, True, False]
Current timestep = 1716. State = [[-0.36262545  0.00592704]]. Action = [[-0.01863081 -0.0695814   0.         -0.94918835]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 1716 is [True, False, False, False, True, False]
Current timestep = 1717. State = [[-0.36220866  0.00553096]]. Action = [[ 0.00757823  0.04367711  0.         -0.54741305]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 1717 is [True, False, False, False, True, False]
Current timestep = 1718. State = [[-0.3621734   0.00988872]]. Action = [[-0.00419597  0.06701968  0.         -0.20560122]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 1718 is [True, False, False, False, True, False]
Current timestep = 1719. State = [[-0.36219084  0.01568654]]. Action = [[0.012239   0.0708173  0.         0.31010675]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 1719 is [True, False, False, False, True, False]
Current timestep = 1720. State = [[-0.36241436  0.02173521]]. Action = [[ 0.00825711  0.06564101  0.         -0.88126695]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 1720 is [True, False, False, False, True, False]
Current timestep = 1721. State = [[-0.358876    0.02849276]]. Action = [[0.09659236 0.07721693 0.         0.07327771]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 1721 is [True, False, False, False, True, False]
State prediction error at timestep 1721 is 0.012
Human Feedback received at timestep 1721 of None
Current timestep = 1722. State = [[-0.36025503  0.0288185 ]]. Action = [[-0.06912447 -0.06336971  0.         -0.4700048 ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 1722 is [True, False, False, False, True, False]
Current timestep = 1723. State = [[-0.35947096  0.03132694]]. Action = [[0.08338755 0.06777977 0.         0.97097135]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 1723 is [True, False, False, False, True, False]
Current timestep = 1724. State = [[-0.3570309   0.03043988]]. Action = [[ 0.022967   -0.0739797   0.          0.06477261]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 1724 is [True, False, False, False, True, False]
Current timestep = 1725. State = [[-0.35185277  0.03156627]]. Action = [[0.0951932  0.05121479 0.         0.14591539]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 1725 is [True, False, False, False, True, False]
Current timestep = 1726. State = [[-0.35135224  0.02889389]]. Action = [[-0.05743906 -0.09508307  0.         -0.62459326]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 1726 is [True, False, False, False, True, False]
Current timestep = 1727. State = [[-0.34846678  0.02167743]]. Action = [[ 0.07843759 -0.09731264  0.          0.31924355]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 1727 is [True, False, False, False, True, False]
Current timestep = 1728. State = [[-0.34268668  0.02104871]]. Action = [[ 0.05797043  0.05520499  0.         -0.9450787 ]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 1728 is [True, False, False, False, True, False]
Current timestep = 1729. State = [[-0.33910456  0.02237675]]. Action = [[ 0.01991578  0.00630568  0.         -0.12440169]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 1729 is [True, False, False, False, True, False]
State prediction error at timestep 1729 is 0.012
Human Feedback received at timestep 1729 of None
Current timestep = 1730. State = [[-0.34092075  0.01965148]]. Action = [[-0.07705384 -0.05208069  0.         -0.7694782 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 1730 is [True, False, False, False, True, False]
Current timestep = 1731. State = [[-0.3460958   0.01317651]]. Action = [[-0.09703176 -0.09209523  0.         -0.41083002]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 1731 is [True, False, False, False, True, False]
Current timestep = 1732. State = [[-0.34350502  0.00886906]]. Action = [[ 0.09572191 -0.0156287   0.          0.374992  ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 1732 is [True, False, False, False, True, False]
Current timestep = 1733. State = [[-0.34042326  0.01209905]]. Action = [[-0.01819371  0.09549988  0.         -0.44009387]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 1733 is [True, False, False, False, True, False]
State prediction error at timestep 1733 is 0.012
Human Feedback received at timestep 1733 of None
Current timestep = 1734. State = [[-0.34274295  0.01186782]]. Action = [[-0.06557462 -0.05127078  0.         -0.57514924]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 1734 is [True, False, False, False, True, False]
Current timestep = 1735. State = [[-0.3433976  0.0122399]]. Action = [[0.00366352 0.0434216  0.         0.46660173]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 1735 is [True, False, False, False, True, False]
State prediction error at timestep 1735 is 0.012
Human Feedback received at timestep 1735 of None
Current timestep = 1736. State = [[-0.34073645  0.00999494]]. Action = [[ 0.04496995 -0.06272867  0.          0.11957169]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 1736 is [True, False, False, False, True, False]
Current timestep = 1737. State = [[-0.3404695   0.01013882]]. Action = [[-0.02830257  0.04640221  0.          0.00282085]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 1737 is [True, False, False, False, True, False]
State prediction error at timestep 1737 is 0.012
Human Feedback received at timestep 1737 of None
Current timestep = 1738. State = [[-0.34013954  0.00651829]]. Action = [[ 0.01577685 -0.09320761  0.          0.07816386]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 1738 is [True, False, False, False, True, False]
State prediction error at timestep 1738 is 0.012
Human Feedback received at timestep 1738 of None
Current timestep = 1739. State = [[-0.33989695  0.00750243]]. Action = [[-0.00692618  0.084742    0.          0.652194  ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 1739 is [True, False, False, False, True, False]
Current timestep = 1740. State = [[-0.335679    0.00717764]]. Action = [[ 0.09410789 -0.05037607  0.         -0.496516  ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 1740 is [True, False, False, False, True, False]
State prediction error at timestep 1740 is 0.012
Human Feedback received at timestep 1740 of None
Current timestep = 1741. State = [[-0.334243    0.00299739]]. Action = [[-0.03035649 -0.05097604  0.          0.29891956]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 1741 is [True, False, False, False, True, False]
Current timestep = 1742. State = [[-0.33484593 -0.00398783]]. Action = [[-0.00950383 -0.09902347  0.          0.8790505 ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 1742 is [True, False, False, False, True, False]
Current timestep = 1743. State = [[-0.3365939  -0.00628471]]. Action = [[-0.04349864  0.02992711  0.         -0.06202251]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 1743 is [True, False, False, False, True, False]
Current timestep = 1744. State = [[-0.34029862 -0.00321466]]. Action = [[-0.05628148  0.06182446  0.         -0.73516315]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 1744 is [True, False, False, False, True, False]
Current timestep = 1745. State = [[-0.3449748  -0.00162733]]. Action = [[-0.0569757  0.0023407  0.         0.7308707]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 1745 is [True, False, False, False, True, False]
Current timestep = 1746. State = [[-0.34838143 -0.00367358]]. Action = [[-0.02603827 -0.04022497  0.          0.9874319 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 1746 is [True, False, False, False, True, False]
Current timestep = 1747. State = [[-0.34634423 -0.00398303]]. Action = [[0.07425658 0.02194657 0.         0.3338132 ]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 1747 is [True, False, False, False, True, False]
State prediction error at timestep 1747 is 0.012
Human Feedback received at timestep 1747 of None
Current timestep = 1748. State = [[-0.34511927 -0.00567236]]. Action = [[ 5.8822334e-04 -4.1980308e-02  0.0000000e+00  6.8858624e-01]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 1748 is [True, False, False, False, True, False]
State prediction error at timestep 1748 is 0.012
Human Feedback received at timestep 1748 of None
Current timestep = 1749. State = [[-0.3464242  -0.00317138]]. Action = [[-0.01574305  0.0788353   0.         -0.36030018]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 1749 is [True, False, False, False, True, False]
State prediction error at timestep 1749 is 0.012
Human Feedback received at timestep 1749 of None
Current timestep = 1750. State = [[-0.34858516 -0.00097429]]. Action = [[-0.01670779 -0.00161984  0.         -0.69173867]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 1750 is [True, False, False, False, True, False]
Current timestep = 1751. State = [[-0.35405308 -0.00464421]]. Action = [[-0.09031782 -0.07660237  0.          0.8682227 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 1751 is [True, False, False, False, True, False]
Current timestep = 1752. State = [[-0.3576845  -0.00822023]]. Action = [[-0.01614137 -0.02381063  0.         -0.4346351 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 1752 is [True, False, False, False, True, False]
Current timestep = 1753. State = [[-0.36299196 -0.0105438 ]]. Action = [[-0.08825959 -0.02412829  0.          0.63212514]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 1753 is [True, False, False, False, True, False]
Current timestep = 1754. State = [[-0.3684906  -0.00771447]]. Action = [[-0.04636723  0.07786018  0.          0.5513848 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 1754 is [True, False, False, False, True, False]
State prediction error at timestep 1754 is 0.012
Human Feedback received at timestep 1754 of None
Current timestep = 1755. State = [[-0.36911124 -0.00594917]]. Action = [[ 0.04648348 -0.01095081  0.         -0.08765185]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 1755 is [True, False, False, False, True, False]
Current timestep = 1756. State = [[-0.37190667 -0.00638095]]. Action = [[-0.05477068 -0.00665688  0.         -0.38110363]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 1756 is [True, False, False, False, True, False]
Current timestep = 1757. State = [[-0.374804   -0.00737495]]. Action = [[-0.00301284 -0.01590932  0.          0.19212437]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 1757 is [True, False, False, False, True, False]
Current timestep = 1758. State = [[-0.3739561  -0.00737122]]. Action = [[ 0.04838067  0.01017908  0.         -0.03108406]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 1758 is [True, False, False, False, True, False]
Current timestep = 1759. State = [[-0.36957404 -0.00541481]]. Action = [[0.09399762 0.0319856  0.         0.6351199 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 1759 is [True, False, False, False, True, False]
Current timestep = 1760. State = [[-0.36630172 -0.00402259]]. Action = [[0.04042246 0.00591005 0.         0.51727974]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 1760 is [True, False, False, False, True, False]
Current timestep = 1761. State = [[-0.36840022 -0.00083433]]. Action = [[-0.05003921  0.05780723  0.          0.9466145 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 1761 is [True, False, False, False, True, False]
Current timestep = 1762. State = [[-0.37067792  0.00110087]]. Action = [[0.        0.        0.        0.9887048]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 1762 is [True, False, False, False, True, False]
Current timestep = 1763. State = [[-3.6703703e-01 -2.2687590e-04]]. Action = [[ 0.09124406 -0.03500307  0.          0.22977698]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 1763 is [True, False, False, False, True, False]
State prediction error at timestep 1763 is 0.012
Human Feedback received at timestep 1763 of None
Current timestep = 1764. State = [[-0.363321    0.00237279]]. Action = [[0.03163054 0.06741779 0.         0.5547309 ]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 1764 is [True, False, False, False, True, False]
State prediction error at timestep 1764 is 0.012
Human Feedback received at timestep 1764 of None
Current timestep = 1765. State = [[-0.36600873  0.00476376]]. Action = [[-0.07374009  0.00240584  0.          0.38589776]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 1765 is [True, False, False, False, True, False]
Current timestep = 1766. State = [[-0.36913764  0.00244154]]. Action = [[-0.0259169  -0.0578509   0.         -0.72889966]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 1766 is [True, False, False, False, True, False]
State prediction error at timestep 1766 is 0.012
Human Feedback received at timestep 1766 of None
Current timestep = 1767. State = [[-0.3678034   0.00206945]]. Action = [[ 0.03922526  0.02155519  0.         -0.37455046]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 1767 is [True, False, False, False, True, False]
Current timestep = 1768. State = [[-0.37025324  0.00655925]]. Action = [[-0.07398352  0.07328402  0.          0.2144723 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 1768 is [True, False, False, False, True, False]
Current timestep = 1769. State = [[-0.3681148   0.00617686]]. Action = [[ 0.09438575 -0.06065816  0.          0.41742063]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 1769 is [True, False, False, False, True, False]
Current timestep = 1770. State = [[-0.36283022  0.0075798 ]]. Action = [[ 0.05007961  0.05579611  0.         -0.07271636]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 1770 is [True, False, False, False, True, False]
State prediction error at timestep 1770 is 0.012
Human Feedback received at timestep 1770 of None
Current timestep = 1771. State = [[-0.35803595  0.00781118]]. Action = [[ 0.05697889 -0.03317353  0.         -0.6158722 ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 1771 is [True, False, False, False, True, False]
Current timestep = 1772. State = [[-0.35846642  0.01070043]]. Action = [[-0.06037867  0.07066952  0.         -0.5504531 ]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 1772 is [True, False, False, False, True, False]
Current timestep = 1773. State = [[-0.36209947  0.0163064 ]]. Action = [[-0.04958912  0.06238439  0.         -0.42973542]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 1773 is [True, False, False, False, True, False]
Current timestep = 1774. State = [[-0.3595098   0.01832697]]. Action = [[ 0.08599373 -0.01364989  0.         -0.36483973]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 1774 is [True, False, False, False, True, False]
Current timestep = 1775. State = [[-0.35594422  0.02340644]]. Action = [[ 0.02278195  0.09153824  0.         -0.9625704 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 1775 is [True, False, False, False, True, False]
Current timestep = 1776. State = [[-0.35681772  0.0241989 ]]. Action = [[-0.03795169 -0.05873302  0.         -0.6483165 ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 1776 is [True, False, False, False, True, False]
Current timestep = 1777. State = [[-0.35602948  0.02827257]]. Action = [[0.03018337 0.09653267 0.         0.18843246]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 1777 is [True, False, False, False, True, False]
State prediction error at timestep 1777 is 0.012
Human Feedback received at timestep 1777 of None
Current timestep = 1778. State = [[-0.35164696  0.03240611]]. Action = [[0.07478749 0.00643063 0.         0.8803129 ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 1778 is [True, False, False, False, True, False]
Current timestep = 1779. State = [[-0.34563166  0.03745672]]. Action = [[0.07919938 0.07393175 0.         0.2367853 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 1779 is [True, False, False, False, True, False]
Current timestep = 1780. State = [[-0.34408352  0.04261477]]. Action = [[-0.01819468  0.03808714  0.         -0.8032513 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 1780 is [True, False, False, False, True, False]
Current timestep = 1781. State = [[-0.34434888  0.04595859]]. Action = [[-0.00301035  0.01667675  0.         -0.49801904]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 1781 is [True, False, False, False, True, False]
Current timestep = 1782. State = [[-0.3470443   0.04932824]]. Action = [[-0.0619335   0.02738775  0.          0.37807095]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 1782 is [True, False, False, False, True, False]
Current timestep = 1783. State = [[-0.34880716  0.05611786]]. Action = [[-0.00487617  0.08729549  0.          0.06356204]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 1783 is [True, False, False, False, True, False]
Current timestep = 1784. State = [[-0.35052678  0.05818159]]. Action = [[-0.02977648 -0.04496662  0.         -0.6610155 ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 1784 is [True, False, False, False, True, False]
Current timestep = 1785. State = [[-0.35091347  0.06173598]]. Action = [[ 0.00668412  0.06245621  0.         -0.21841449]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 1785 is [True, False, False, False, True, False]
Current timestep = 1786. State = [[-0.35199007  0.06536266]]. Action = [[-0.02185344  0.00674478  0.         -0.26141226]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 1786 is [True, False, False, False, True, False]
Current timestep = 1787. State = [[-0.34938487  0.06634582]]. Action = [[ 0.06717952 -0.01355167  0.          0.56604433]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 1787 is [True, False, False, False, True, False]
Current timestep = 1788. State = [[-0.34622666  0.06834926]]. Action = [[0.02509514 0.02810099 0.         0.05232263]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 1788 is [True, False, False, False, True, False]
Current timestep = 1789. State = [[-0.34293488  0.0698662 ]]. Action = [[ 0.04576727 -0.00190106  0.         -0.9704472 ]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 1789 is [True, False, False, False, True, False]
Current timestep = 1790. State = [[-0.34554598  0.06815209]]. Action = [[-0.09881818 -0.05167935  0.         -0.99042743]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 1790 is [True, False, False, False, True, False]
Current timestep = 1791. State = [[-0.3499784  0.0625516]]. Action = [[-0.05149957 -0.09926713  0.         -0.05182064]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 1791 is [True, False, False, False, True, False]
State prediction error at timestep 1791 is 0.012
Human Feedback received at timestep 1791 of None
Current timestep = 1792. State = [[-0.35551506  0.06174246]]. Action = [[-0.0926981   0.03564657  0.         -0.9041183 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 1792 is [True, False, False, False, True, False]
Current timestep = 1793. State = [[-0.35818323  0.06323218]]. Action = [[0.00241686 0.00663383 0.         0.4343866 ]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 1793 is [True, False, False, False, True, False]
Current timestep = 1794. State = [[-0.36107495  0.06427932]]. Action = [[-0.04634059  0.01442592  0.          0.03533292]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 1794 is [True, False, False, False, True, False]
Current timestep = 1795. State = [[-0.3645174   0.06458712]]. Action = [[-0.02703237 -0.00389381  0.          0.52578735]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 1795 is [True, False, False, False, True, False]
State prediction error at timestep 1795 is 0.012
Human Feedback received at timestep 1795 of None
Current timestep = 1796. State = [[-0.36555153  0.06847667]]. Action = [[0.02072515 0.08080316 0.         0.6454046 ]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 1796 is [True, False, False, False, True, False]
Current timestep = 1797. State = [[-0.36503398  0.07398747]]. Action = [[ 0.03750982  0.06529029  0.         -0.8316934 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 1797 is [True, False, False, False, True, False]
Current timestep = 1798. State = [[-0.3693591   0.08085646]]. Action = [[-0.06884582  0.09540395  0.         -0.6814844 ]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 1798 is [True, False, False, False, True, False]
State prediction error at timestep 1798 is 0.012
Human Feedback received at timestep 1798 of None
Current timestep = 1799. State = [[-0.3742644   0.08731353]]. Action = [[-0.01489967  0.06196361  0.         -0.4528246 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 1799 is [True, False, False, False, True, False]
Current timestep = 1800. State = [[-0.3762145   0.08733028]]. Action = [[ 0.01349102 -0.05437597  0.          0.3949399 ]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 1800 is [True, False, False, False, True, False]
Current timestep = 1801. State = [[-0.37732482  0.08662444]]. Action = [[ 0.         0.         0.        -0.9843183]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 1801 is [True, False, False, False, True, False]
Current timestep = 1802. State = [[-0.37440753  0.08513207]]. Action = [[ 0.08128881 -0.03983359  0.          0.15434706]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 1802 is [True, False, False, False, True, False]
State prediction error at timestep 1802 is 0.012
Human Feedback received at timestep 1802 of None
Current timestep = 1803. State = [[-0.37262908  0.08425637]]. Action = [[0.        0.        0.        0.7184806]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 1803 is [True, False, False, False, True, False]
Current timestep = 1804. State = [[-0.3681979   0.08424047]]. Action = [[ 0.0906306  -0.00247186  0.         -0.991932  ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 1804 is [True, False, False, False, True, False]
Current timestep = 1805. State = [[-0.36553693  0.08102575]]. Action = [[-0.00744805 -0.0629541   0.          0.43417978]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 1805 is [True, False, False, False, True, False]
State prediction error at timestep 1805 is 0.012
Human Feedback received at timestep 1805 of None
Current timestep = 1806. State = [[-0.36197066  0.08301257]]. Action = [[0.0625787  0.08107973 0.         0.20502663]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 1806 is [True, False, False, False, True, False]
Current timestep = 1807. State = [[-0.36263913  0.08719961]]. Action = [[-0.06206784  0.04076868  0.         -0.3216324 ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 1807 is [True, False, False, False, True, False]
State prediction error at timestep 1807 is 0.012
Human Feedback received at timestep 1807 of None
Current timestep = 1808. State = [[-0.36573425  0.08893333]]. Action = [[-0.0366398   0.00258908  0.         -0.14769137]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 1808 is [True, False, False, False, True, False]
Current timestep = 1809. State = [[-0.3695212   0.09196102]]. Action = [[-0.05759055  0.04749426  0.         -0.39111662]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 1809 is [True, False, False, False, True, False]
Current timestep = 1810. State = [[-0.36967325  0.09215747]]. Action = [[ 0.03354054 -0.03658297  0.         -0.18492502]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 1810 is [True, False, False, False, True, False]
Current timestep = 1811. State = [[-0.36417863  0.09258377]]. Action = [[ 0.09644672  0.02342035  0.         -0.58817244]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 1811 is [True, False, False, False, True, False]
Current timestep = 1812. State = [[-0.3607922   0.09472694]]. Action = [[0.01213177 0.03015963 0.         0.02520061]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 1812 is [True, False, False, False, True, False]
Current timestep = 1813. State = [[-0.36378402  0.10062739]]. Action = [[-0.07138712  0.09323476  0.         -0.86854815]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 1813 is [True, False, False, False, True, False]
Current timestep = 1814. State = [[-0.36807948  0.10395389]]. Action = [[-0.04104346 -0.00541902  0.         -0.7207546 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 1814 is [True, False, False, False, True, False]
State prediction error at timestep 1814 is 0.012
Human Feedback received at timestep 1814 of None
Current timestep = 1815. State = [[-0.37141278  0.10954769]]. Action = [[-0.03157756  0.09147208  0.         -0.43759048]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 1815 is [True, False, False, False, True, False]
Current timestep = 1816. State = [[-0.36875686  0.11414732]]. Action = [[0.09462284 0.02075914 0.         0.2780068 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 1816 is [True, False, False, False, True, False]
Current timestep = 1817. State = [[-0.3688073   0.11189687]]. Action = [[-0.04903604 -0.08053245  0.          0.9070289 ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 1817 is [True, False, False, False, True, False]
Current timestep = 1818. State = [[-0.37057722  0.10944831]]. Action = [[-0.00387849 -0.02268862  0.         -0.90705144]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 1818 is [True, False, False, False, True, False]
Current timestep = 1819. State = [[-0.36945686  0.10969907]]. Action = [[0.03291658 0.00855271 0.         0.08360457]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 1819 is [True, False, False, False, True, False]
State prediction error at timestep 1819 is 0.012
Human Feedback received at timestep 1819 of None
Current timestep = 1820. State = [[-0.36649585  0.1128944 ]]. Action = [[ 0.04818665  0.0563921   0.         -0.47734702]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 1820 is [True, False, False, False, True, False]
Current timestep = 1821. State = [[-0.3690598   0.11688267]]. Action = [[-0.07530857  0.04211379  0.         -0.9671959 ]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 1821 is [True, False, False, False, True, False]
Current timestep = 1822. State = [[-0.369197    0.11576997]]. Action = [[ 0.04602899 -0.05911312  0.          0.5169382 ]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 1822 is [True, False, False, False, True, False]
Current timestep = 1823. State = [[-0.3652055   0.11564426]]. Action = [[0.05768945 0.02828353 0.         0.04053569]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 1823 is [True, False, False, False, True, False]
Current timestep = 1824. State = [[-0.36478305  0.12109049]]. Action = [[-0.02322806  0.09609439  0.          0.03250098]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 1824 is [True, False, False, False, True, False]
Current timestep = 1825. State = [[-0.36427486  0.1236805 ]]. Action = [[ 0.02740896 -0.00915197  0.          0.33181524]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 1825 is [True, False, False, False, True, False]
State prediction error at timestep 1825 is 0.012
Human Feedback received at timestep 1825 of None
Current timestep = 1826. State = [[-0.35901594  0.12044847]]. Action = [[ 0.08712388 -0.0669388   0.          0.8758216 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 1826 is [True, False, False, False, True, False]
Current timestep = 1827. State = [[-0.35192597  0.12004942]]. Action = [[0.07874876 0.03414897 0.         0.5709851 ]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 1827 is [True, False, False, False, True, False]
State prediction error at timestep 1827 is 0.012
Human Feedback received at timestep 1827 of None
Current timestep = 1828. State = [[-0.34669667  0.11893547]]. Action = [[ 0.03739572 -0.03644697  0.          0.19752872]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 1828 is [True, False, False, False, True, False]
Current timestep = 1829. State = [[-0.3412654   0.12017682]]. Action = [[0.05866232 0.04822411 0.         0.23586345]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 1829 is [True, False, False, False, True, False]
Current timestep = 1830. State = [[-0.33578935  0.1202369 ]]. Action = [[ 0.04641841 -0.02160809  0.          0.45841348]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 1830 is [True, False, False, False, True, False]
Current timestep = 1831. State = [[-0.32824904  0.12325086]]. Action = [[ 0.09130531  0.07746329  0.         -0.41867483]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 1831 is [True, False, False, False, True, False]
Current timestep = 1832. State = [[-0.3231185   0.12590711]]. Action = [[ 0.01671152  0.0141819   0.         -0.7452286 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 1832 is [True, False, False, False, True, False]
Current timestep = 1833. State = [[-0.31783086  0.13021359]]. Action = [[ 0.06063879  0.07488015  0.         -0.15598786]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 1833 is [True, False, False, False, False, True]
Current timestep = 1834. State = [[-0.31779936  0.1355544 ]]. Action = [[-0.06709722  0.05512915  0.          0.53340125]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 1834 is [True, False, False, False, False, True]
Current timestep = 1835. State = [[-0.31442386  0.14118598]]. Action = [[ 0.08443912  0.06302353  0.         -0.69487464]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 1835 is [True, False, False, False, False, True]
Current timestep = 1836. State = [[-0.31030145  0.14797622]]. Action = [[0.01559015 0.08017962 0.         0.33564138]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 1836 is [True, False, False, False, False, True]
State prediction error at timestep 1836 is 0.012
Human Feedback received at timestep 1836 of None
Current timestep = 1837. State = [[-0.30874676  0.15625224]]. Action = [[0.00383469 0.09248757 0.         0.2138387 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 1837 is [True, False, False, False, False, True]
Current timestep = 1838. State = [[-0.30488268  0.16395608]]. Action = [[0.06436353 0.06778566 0.         0.04114521]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 1838 is [True, False, False, False, False, True]
State prediction error at timestep 1838 is 0.012
Human Feedback received at timestep 1838 of None
Current timestep = 1839. State = [[-0.30609447  0.16629556]]. Action = [[-0.08271053 -0.03912226  0.         -0.32096112]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 1839 is [True, False, False, False, False, True]
Current timestep = 1840. State = [[-0.30481628  0.16670455]]. Action = [[ 0.06186118 -0.01740701  0.         -0.90056103]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 1840 is [True, False, False, False, False, True]
Current timestep = 1841. State = [[-0.30089593  0.1639194 ]]. Action = [[ 0.02795469 -0.08490829  0.          0.34604418]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 1841 is [True, False, False, False, False, True]
Current timestep = 1842. State = [[-0.2972396   0.16377506]]. Action = [[0.02964889 0.01356101 0.         0.4591936 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 1842 is [True, False, False, False, False, True]
Current timestep = 1843. State = [[-0.293068    0.16198114]]. Action = [[ 0.03787532 -0.06632574  0.         -0.7867352 ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 1843 is [True, False, False, False, False, True]
Current timestep = 1844. State = [[-0.28850093  0.16028869]]. Action = [[ 0.03527138 -0.01205804  0.         -0.6131673 ]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 1844 is [True, False, False, False, False, True]
Current timestep = 1845. State = [[-0.28479904  0.1584669 ]]. Action = [[ 0.01771478 -0.03559149  0.         -0.87961894]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 1845 is [True, False, False, False, False, True]
Current timestep = 1846. State = [[-0.2827518   0.15520513]]. Action = [[-7.4027330e-03 -4.8104268e-02  0.0000000e+00 -7.9751015e-05]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 1846 is [True, False, False, False, False, True]
Current timestep = 1847. State = [[-0.27983585  0.15477896]]. Action = [[ 0.02784371  0.02328558  0.         -0.42326075]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 1847 is [True, False, False, False, False, True]
State prediction error at timestep 1847 is 0.012
Human Feedback received at timestep 1847 of None
Current timestep = 1848. State = [[-0.28204244  0.1565052 ]]. Action = [[-0.08879887  0.0276167   0.         -0.20932436]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 1848 is [True, False, False, False, False, True]
State prediction error at timestep 1848 is 0.012
Human Feedback received at timestep 1848 of None
Current timestep = 1849. State = [[-0.2800942   0.15412572]]. Action = [[ 0.07037305 -0.06292213  0.          0.05258882]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 1849 is [True, False, False, False, False, True]
State prediction error at timestep 1849 is 0.012
Human Feedback received at timestep 1849 of None
Current timestep = 1850. State = [[-0.27501807  0.14708261]]. Action = [[ 0.04369881 -0.09386579  0.         -0.48414242]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 1850 is [True, False, False, False, False, True]
Current timestep = 1851. State = [[-0.27044684  0.13946232]]. Action = [[ 0.03758117 -0.07887987  0.         -0.14457983]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 1851 is [True, False, False, False, False, True]
Current timestep = 1852. State = [[-0.27118963  0.13387385]]. Action = [[-0.06953683 -0.04428416  0.          0.29021597]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 1852 is [True, False, False, False, False, True]
State prediction error at timestep 1852 is 0.012
Human Feedback received at timestep 1852 of None
Current timestep = 1853. State = [[-0.27555904  0.13083775]]. Action = [[-0.07619123 -0.01757538  0.         -0.73973894]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 1853 is [True, False, False, False, False, True]
Current timestep = 1854. State = [[-0.27560064  0.12975541]]. Action = [[0.0345505  0.00962595 0.         0.5664904 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 1854 is [True, False, False, False, False, True]
Current timestep = 1855. State = [[-0.278193    0.12965228]]. Action = [[-0.07242259  0.01536945  0.         -0.3604843 ]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 1855 is [True, False, False, False, False, True]
Current timestep = 1856. State = [[-0.27835354  0.13338922]]. Action = [[ 0.05119494  0.08642676  0.         -0.4434569 ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 1856 is [True, False, False, False, False, True]
Current timestep = 1857. State = [[-0.27635527  0.13780494]]. Action = [[0.03477768 0.05856278 0.         0.3772328 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 1857 is [True, False, False, False, False, True]
State prediction error at timestep 1857 is 0.012
Human Feedback received at timestep 1857 of None
Current timestep = 1858. State = [[-0.27625287  0.13658674]]. Action = [[-0.00184292 -0.04806064  0.         -0.07136655]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 1858 is [True, False, False, False, False, True]
Current timestep = 1859. State = [[-0.2768554   0.13409814]]. Action = [[-0.00298283 -0.01793899  0.         -0.44386387]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 1859 is [True, False, False, False, False, True]
Current timestep = 1860. State = [[-0.27928075  0.13593611]]. Action = [[-0.03766451  0.05245527  0.         -0.8171003 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 1860 is [True, False, False, False, False, True]
Current timestep = 1861. State = [[-0.28323755  0.13298275]]. Action = [[-0.04816995 -0.09297175  0.         -0.02103025]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 1861 is [True, False, False, False, False, True]
Current timestep = 1862. State = [[-0.28567672  0.13322097]]. Action = [[-0.01249328  0.0531626   0.          0.2358551 ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 1862 is [True, False, False, False, False, True]
State prediction error at timestep 1862 is 0.012
Human Feedback received at timestep 1862 of None
Current timestep = 1863. State = [[-0.28343207  0.13422012]]. Action = [[ 0.06920462 -0.00684841  0.         -0.60320383]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 1863 is [True, False, False, False, False, True]
Current timestep = 1864. State = [[-0.27760798  0.13195007]]. Action = [[ 0.08988979 -0.03345097  0.         -0.98405915]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 1864 is [True, False, False, False, False, True]
State prediction error at timestep 1864 is 0.012
Human Feedback received at timestep 1864 of None
Current timestep = 1865. State = [[-0.271085    0.12807037]]. Action = [[ 0.07804721 -0.04306026  0.         -0.65278006]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 1865 is [True, False, False, False, False, True]
State prediction error at timestep 1865 is 0.012
Human Feedback received at timestep 1865 of None
Current timestep = 1866. State = [[-0.26796064  0.12419865]]. Action = [[ 0.00298209 -0.03608073  0.          0.68155754]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 1866 is [True, False, False, False, False, True]
Current timestep = 1867. State = [[-0.26439238  0.12415663]]. Action = [[ 0.0511562   0.03738513  0.         -0.21137404]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 1867 is [True, False, False, False, True, False]
State prediction error at timestep 1867 is 0.012
Human Feedback received at timestep 1867 of None
Current timestep = 1868. State = [[-0.26546368  0.12733395]]. Action = [[-0.06762303  0.05812337  0.         -0.960811  ]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 1868 is [True, False, False, False, True, False]
Current timestep = 1869. State = [[-0.27052197  0.12836939]]. Action = [[-0.07957749 -0.01261324  0.          0.67751694]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 1869 is [True, False, False, False, False, True]
State prediction error at timestep 1869 is 0.012
Human Feedback received at timestep 1869 of None
Current timestep = 1870. State = [[-0.27694204  0.13224351]]. Action = [[-0.08893022  0.07562464  0.         -0.7391579 ]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 1870 is [True, False, False, False, False, True]
Current timestep = 1871. State = [[-0.28065157  0.13823435]]. Action = [[-0.00970067  0.06441664  0.         -0.14355516]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 1871 is [True, False, False, False, False, True]
Current timestep = 1872. State = [[-0.28024286  0.138868  ]]. Action = [[ 0.03619605 -0.03966311  0.         -0.8220624 ]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 1872 is [True, False, False, False, False, True]
Current timestep = 1873. State = [[-0.28282464  0.14154041]]. Action = [[-0.05657351  0.06244377  0.          0.4753623 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 1873 is [True, False, False, False, False, True]
Current timestep = 1874. State = [[-0.2828963   0.14378695]]. Action = [[ 0.05077363 -0.00577509  0.          0.8824527 ]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 1874 is [True, False, False, False, False, True]
State prediction error at timestep 1874 is 0.012
Human Feedback received at timestep 1874 of None
Current timestep = 1875. State = [[-0.28141472  0.13975355]]. Action = [[ 0.01580151 -0.09228227  0.          0.6442177 ]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 1875 is [True, False, False, False, False, True]
Current timestep = 1876. State = [[-0.2789406   0.13284141]]. Action = [[ 0.03877131 -0.09492137  0.         -0.89780515]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 1876 is [True, False, False, False, False, True]
Current timestep = 1877. State = [[-0.27617344  0.13023119]]. Action = [[0.02559369 0.00660658 0.         0.13359904]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 1877 is [True, False, False, False, False, True]
State prediction error at timestep 1877 is 0.012
Human Feedback received at timestep 1877 of None
Current timestep = 1878. State = [[-0.27608678  0.13053177]]. Action = [[-0.02240995  0.01165972  0.         -0.2776661 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 1878 is [True, False, False, False, False, True]
State prediction error at timestep 1878 is 0.012
Human Feedback received at timestep 1878 of None
Current timestep = 1879. State = [[-0.27163532  0.13150682]]. Action = [[ 0.09767585  0.02392018  0.         -0.18599921]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 1879 is [True, False, False, False, False, True]
Current timestep = 1880. State = [[-0.271323    0.13055013]]. Action = [[-0.06369312 -0.02273779  0.         -0.40484488]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 1880 is [True, False, False, False, False, True]
Current timestep = 1881. State = [[-0.27661017  0.12909529]]. Action = [[-0.08065238 -0.01205684  0.          0.64593077]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 1881 is [True, False, False, False, False, True]
Current timestep = 1882. State = [[-0.27875048  0.12643996]]. Action = [[ 0.0034339  -0.04350882  0.         -0.736842  ]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 1882 is [True, False, False, False, False, True]
Current timestep = 1883. State = [[-0.28121653  0.12706237]]. Action = [[-0.04608045  0.04458355  0.         -0.74979585]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 1883 is [True, False, False, False, False, True]
Current timestep = 1884. State = [[-0.28233334  0.12715797]]. Action = [[ 0.01400308 -0.01732937  0.         -0.43846136]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 1884 is [True, False, False, False, False, True]
Current timestep = 1885. State = [[-0.2821909   0.12307497]]. Action = [[ 0.00386808 -0.06650314  0.         -0.6245581 ]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 1885 is [True, False, False, False, False, True]
State prediction error at timestep 1885 is 0.012
Human Feedback received at timestep 1885 of None
Current timestep = 1886. State = [[-0.28057623  0.12383719]]. Action = [[0.03701647 0.06609941 0.         0.5057864 ]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 1886 is [True, False, False, False, True, False]
Current timestep = 1887. State = [[-0.27704486  0.12224863]]. Action = [[ 0.0606866 -0.0532154  0.         0.5510063]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 1887 is [True, False, False, False, True, False]
Current timestep = 1888. State = [[-0.27535868  0.12212881]]. Action = [[0.00203433 0.04286683 0.         0.3914591 ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 1888 is [True, False, False, False, True, False]
Current timestep = 1889. State = [[-0.2786014   0.12676531]]. Action = [[-0.06286196  0.08027258  0.         -0.16862947]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 1889 is [True, False, False, False, True, False]
State prediction error at timestep 1889 is 0.012
Human Feedback received at timestep 1889 of None
Current timestep = 1890. State = [[-0.27644166  0.13266858]]. Action = [[0.09779207 0.07766003 0.         0.7569704 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 1890 is [True, False, False, False, False, True]
State prediction error at timestep 1890 is 0.012
Human Feedback received at timestep 1890 of None
Current timestep = 1891. State = [[-0.27429596  0.13728045]]. Action = [[0.00089165 0.04925784 0.         0.6255307 ]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 1891 is [True, False, False, False, False, True]
State prediction error at timestep 1891 is 0.012
Human Feedback received at timestep 1891 of None
Current timestep = 1892. State = [[-0.2736274   0.13511194]]. Action = [[ 0.01304398 -0.0819002   0.          0.2858565 ]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 1892 is [True, False, False, False, False, True]
Current timestep = 1893. State = [[-0.2741555   0.13387237]]. Action = [[-0.02587685  0.00798619  0.          0.52175903]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 1893 is [True, False, False, False, False, True]
Current timestep = 1894. State = [[-0.26985732  0.13412993]]. Action = [[ 0.09489652 -0.00722487  0.         -0.3664754 ]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 1894 is [True, False, False, False, False, True]
Current timestep = 1895. State = [[-0.26506707  0.12986758]]. Action = [[ 0.02675354 -0.0862484   0.          0.9247385 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 1895 is [True, False, False, False, False, True]
Current timestep = 1896. State = [[-0.26223218  0.13084242]]. Action = [[ 0.01605217  0.06849795  0.         -0.91669804]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 1896 is [True, False, False, False, False, True]
Current timestep = 1897. State = [[-0.2571189   0.13692431]]. Action = [[ 0.07841241  0.08684806  0.         -0.11962384]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 1897 is [True, False, False, False, False, True]
Current timestep = 1898. State = [[-0.25320157  0.14386629]]. Action = [[0.02268483 0.09008726 0.         0.9265833 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 1898 is [True, False, False, False, False, True]
Current timestep = 1899. State = [[-0.2505601  0.1449086]]. Action = [[ 0.02407628 -0.04015079  0.          0.0570097 ]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 1899 is [True, False, False, False, False, True]
State prediction error at timestep 1899 is 0.012
Human Feedback received at timestep 1899 of None
Current timestep = 1900. State = [[-0.2442782   0.14635298]]. Action = [[ 0.09174635  0.0409212   0.         -0.5168421 ]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 1900 is [True, False, False, False, False, True]
State prediction error at timestep 1900 is 0.012
Human Feedback received at timestep 1900 of None
Current timestep = 1901. State = [[-0.24374455  0.15151066]]. Action = [[-0.06696109  0.07042407  0.         -0.23200667]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 1901 is [True, False, False, False, False, True]
Current timestep = 1902. State = [[-0.24864179  0.15049249]]. Action = [[-0.08808067 -0.09017112  0.         -0.61228156]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 1902 is [True, False, False, False, False, True]
Current timestep = 1903. State = [[-0.24597915  0.14836222]]. Action = [[ 0.09093788 -0.01757411  0.          0.10127807]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 1903 is [True, False, False, False, False, True]
State prediction error at timestep 1903 is 0.012
Human Feedback received at timestep 1903 of None
Current timestep = 1904. State = [[-0.24533515  0.1486726 ]]. Action = [[-0.07061414 -0.00418192  0.         -0.63273686]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 1904 is [True, False, False, False, False, True]
Current timestep = 1905. State = [[-0.2458584   0.14697249]]. Action = [[-0.00463334 -0.05751845  0.          0.80519223]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 1905 is [True, False, False, False, False, True]
Current timestep = 1906. State = [[-0.24936183  0.14834347]]. Action = [[-0.09408499  0.03864474  0.          0.01888502]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 1906 is [True, False, False, False, False, True]
State prediction error at timestep 1906 is 0.012
Human Feedback received at timestep 1906 of None
Current timestep = 1907. State = [[-0.25459686  0.15554006]]. Action = [[-0.06185544  0.09969909  0.         -0.29132795]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 1907 is [True, False, False, False, False, True]
Current timestep = 1908. State = [[-0.25603986  0.15806627]]. Action = [[ 0.01525334 -0.03195626  0.          0.6241839 ]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 1908 is [True, False, False, False, False, True]
State prediction error at timestep 1908 is 0.012
Human Feedback received at timestep 1908 of None
Current timestep = 1909. State = [[-0.2513699   0.15377912]]. Action = [[ 0.09366953 -0.08412383  0.          0.79502475]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 1909 is [True, False, False, False, False, True]
Current timestep = 1910. State = [[-0.25191295  0.15265577]]. Action = [[-0.06623951  0.02556237  0.          0.16498303]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 1910 is [True, False, False, False, False, True]
Current timestep = 1911. State = [[-0.25056192  0.15156741]]. Action = [[ 0.06385676 -0.04012777  0.         -0.7955507 ]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 1911 is [True, False, False, False, False, True]
Current timestep = 1912. State = [[-0.24777555  0.15018673]]. Action = [[ 0.02132257 -0.00102261  0.         -0.0360083 ]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 1912 is [True, False, False, False, False, True]
State prediction error at timestep 1912 is 0.012
Human Feedback received at timestep 1912 of None
Current timestep = 1913. State = [[-0.24365486  0.14991392]]. Action = [[0.0682792  0.00648465 0.         0.8329289 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 1913 is [True, False, False, False, False, True]
Current timestep = 1914. State = [[-0.24545777  0.15136269]]. Action = [[-0.08153851  0.03538593  0.         -0.43288934]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 1914 is [True, False, False, False, False, True]
Current timestep = 1915. State = [[-0.24303155  0.15173236]]. Action = [[ 0.09907917 -0.00498179  0.          0.62182903]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 1915 is [True, False, False, False, False, True]
State prediction error at timestep 1915 is 0.012
Human Feedback received at timestep 1915 of None
Current timestep = 1916. State = [[-0.24034794  0.15412118]]. Action = [[-4.3962896e-04  6.2528215e-02  0.0000000e+00  8.3572268e-01]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 1916 is [True, False, False, False, False, True]
State prediction error at timestep 1916 is 0.012
Human Feedback received at timestep 1916 of None
Current timestep = 1917. State = [[-0.24205531  0.15936755]]. Action = [[-0.03505417  0.07484364  0.         -0.53706956]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 1917 is [True, False, False, False, False, True]
Current timestep = 1918. State = [[-0.24473718  0.15980047]]. Action = [[-0.03060722 -0.04244706  0.          0.01519597]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 1918 is [True, False, False, False, False, True]
State prediction error at timestep 1918 is 0.012
Human Feedback received at timestep 1918 of None
Current timestep = 1919. State = [[-0.24224336  0.15853901]]. Action = [[ 0.06920875 -0.01114453  0.         -0.44941175]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 1919 is [True, False, False, False, False, True]
Current timestep = 1920. State = [[-0.23575176  0.15366587]]. Action = [[ 0.08613317 -0.09012108  0.          0.7015209 ]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 1920 is [True, False, False, False, False, True]
Current timestep = 1921. State = [[-0.2369423   0.15114717]]. Action = [[-0.09654821  0.00291371  0.         -0.44221234]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 1921 is [True, False, False, False, False, True]
Current timestep = 1922. State = [[-0.23664524  0.15307774]]. Action = [[0.04927138 0.03770844 0.         0.025563  ]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 1922 is [True, False, False, False, False, True]
Current timestep = 1923. State = [[-0.23019415  0.14989753]]. Action = [[ 0.09267478 -0.08202213  0.         -0.8494651 ]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 1923 is [True, False, False, False, False, True]
Current timestep = 1924. State = [[-0.2247588   0.14405572]]. Action = [[ 0.0311018 -0.0605124  0.        -0.7527748]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 1924 is [True, False, False, False, False, True]
State prediction error at timestep 1924 is 0.012
Human Feedback received at timestep 1924 of None
Current timestep = 1925. State = [[-0.22585736  0.13752043]]. Action = [[-0.07933925 -0.08674709  0.          0.30174935]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 1925 is [True, False, False, False, False, True]
Current timestep = 1926. State = [[-0.22302835  0.1328375 ]]. Action = [[ 0.07382228 -0.02905688  0.         -0.9945331 ]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 1926 is [True, False, False, False, False, True]
Current timestep = 1927. State = [[-0.21993636  0.13202472]]. Action = [[-0.00975899  0.02412752  0.         -0.71156275]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 1927 is [True, False, False, False, False, True]
Current timestep = 1928. State = [[-0.21866114  0.13230093]]. Action = [[0.00307681 0.01195272 0.         0.13226604]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 1928 is [True, False, False, False, False, True]
Current timestep = 1929. State = [[-0.21731019  0.13113871]]. Action = [[ 0.00539738 -0.01365712  0.         -0.3632689 ]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 1929 is [True, False, False, False, False, True]
Current timestep = 1930. State = [[-0.21263424  0.1252536 ]]. Action = [[ 0.07193943 -0.09239832  0.         -0.40194207]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 1930 is [True, False, False, False, False, True]
Current timestep = 1931. State = [[-0.21098457  0.12213942]]. Action = [[-0.03093929  0.01418126  0.          0.9570453 ]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 1931 is [True, False, False, False, False, True]
Current timestep = 1932. State = [[-0.20647392  0.125483  ]]. Action = [[0.0978502  0.08563157 0.         0.35764384]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 1932 is [True, False, False, False, True, False]
State prediction error at timestep 1932 is 0.012
Human Feedback received at timestep 1932 of None
Current timestep = 1933. State = [[-0.20111044  0.12848964]]. Action = [[0.04541676 0.03324903 0.         0.18296921]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 1933 is [True, False, False, False, False, True]
Current timestep = 1934. State = [[-0.19816978  0.1269476 ]]. Action = [[ 0.01652548 -0.03880318  0.          0.10014617]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 1934 is [True, False, False, False, False, True]
State prediction error at timestep 1934 is 0.012
Human Feedback received at timestep 1934 of None
Current timestep = 1935. State = [[-0.20056283  0.12207295]]. Action = [[-0.08557072 -0.07341452  0.         -0.71858597]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 1935 is [True, False, False, False, False, True]
Current timestep = 1936. State = [[-0.19942066  0.11618526]]. Action = [[ 0.04710235 -0.07379484  0.          0.07728112]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 1936 is [True, False, False, False, True, False]
Current timestep = 1937. State = [[-0.20048122  0.10950938]]. Action = [[-0.07658699 -0.0832084   0.          0.06608105]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 1937 is [True, False, False, False, True, False]
State prediction error at timestep 1937 is 0.012
Human Feedback received at timestep 1937 of None
Current timestep = 1938. State = [[-0.2017334   0.11029022]]. Action = [[-0.00472566  0.0745702   0.         -0.2111175 ]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 1938 is [True, False, False, False, True, False]
Current timestep = 1939. State = [[-0.20439851  0.11269266]]. Action = [[-0.05895936  0.0134149   0.         -0.04310924]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 1939 is [True, False, False, False, True, False]
State prediction error at timestep 1939 is 0.012
Human Feedback received at timestep 1939 of None
Current timestep = 1940. State = [[-0.20928943  0.11600352]]. Action = [[-0.0662351   0.05515347  0.         -0.81402886]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 1940 is [True, False, False, False, True, False]
Current timestep = 1941. State = [[-0.21262863  0.11716522]]. Action = [[-0.01855498 -0.01604833  0.          0.6030483 ]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 1941 is [True, False, False, False, True, False]
Current timestep = 1942. State = [[-0.21698312  0.11989863]]. Action = [[-0.0602942   0.0547451   0.         -0.16989905]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 1942 is [True, False, False, False, True, False]
Current timestep = 1943. State = [[-0.22127452  0.12398376]]. Action = [[-0.02618461  0.03893939  0.          0.76405525]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 1943 is [True, False, False, False, True, False]
Current timestep = 1944. State = [[-0.22129865  0.12241831]]. Action = [[ 0.04616652 -0.06641525  0.         -0.32693553]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 1944 is [True, False, False, False, True, False]
Current timestep = 1945. State = [[-0.22406529  0.12490707]]. Action = [[-0.05458986  0.08401682  0.          0.69868803]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 1945 is [True, False, False, False, True, False]
Current timestep = 1946. State = [[-0.22982094  0.12446145]]. Action = [[-0.05897544 -0.06853777  0.         -0.17874587]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 1946 is [True, False, False, False, True, False]
Current timestep = 1947. State = [[-0.23372915  0.12541568]]. Action = [[-0.01922828  0.04356519  0.          0.8976617 ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 1947 is [True, False, False, False, True, False]
Current timestep = 1948. State = [[-0.23184748  0.12238637]]. Action = [[ 0.07862969 -0.08964047  0.         -0.43865162]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 1948 is [True, False, False, False, False, True]
Current timestep = 1949. State = [[-0.22911112  0.12220432]]. Action = [[0.03259947 0.05554215 0.         0.49738586]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 1949 is [True, False, False, False, True, False]
Current timestep = 1950. State = [[-0.22745441  0.12665676]]. Action = [[0.03464486 0.06982946 0.         0.06436622]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 1950 is [True, False, False, False, True, False]
Current timestep = 1951. State = [[-0.22316197  0.12594506]]. Action = [[ 0.08411709 -0.046608    0.         -0.9476278 ]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 1951 is [True, False, False, False, False, True]
Current timestep = 1952. State = [[-0.22503912  0.12023114]]. Action = [[-0.09589706 -0.08741461  0.          0.7396283 ]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 1952 is [True, False, False, False, False, True]
Current timestep = 1953. State = [[-0.23046228  0.11703134]]. Action = [[-0.05662218 -0.01103112  0.          0.02065635]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 1953 is [True, False, False, False, True, False]
Current timestep = 1954. State = [[-0.23073821  0.12078852]]. Action = [[0.04607844 0.09383021 0.         0.6761241 ]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 1954 is [True, False, False, False, True, False]
Current timestep = 1955. State = [[-0.23463842  0.12025763]]. Action = [[-0.09892078 -0.06180264  0.         -0.62611085]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 1955 is [True, False, False, False, True, False]
Current timestep = 1956. State = [[-0.23882627  0.1190311 ]]. Action = [[-0.01088499  0.01100235  0.          0.5186994 ]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 1956 is [True, False, False, False, True, False]
State prediction error at timestep 1956 is 0.012
Human Feedback received at timestep 1956 of None
Current timestep = 1957. State = [[-0.24183588  0.11893561]]. Action = [[-0.02811911 -0.00056319  0.         -0.3329451 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 1957 is [True, False, False, False, True, False]
Current timestep = 1958. State = [[-0.2473154   0.11679834]]. Action = [[-0.07295015 -0.0404799   0.         -0.9995785 ]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 1958 is [True, False, False, False, True, False]
Current timestep = 1959. State = [[-0.2472512   0.11656868]]. Action = [[ 0.07151241  0.02501645  0.         -0.08228993]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 1959 is [True, False, False, False, True, False]
Current timestep = 1960. State = [[-0.24358463  0.12098033]]. Action = [[ 0.06021162  0.08834418  0.         -0.7281508 ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 1960 is [True, False, False, False, True, False]
State prediction error at timestep 1960 is 0.012
Human Feedback received at timestep 1960 of None
Current timestep = 1961. State = [[-0.24426562  0.12445629]]. Action = [[-0.02883109  0.027193    0.          0.9162741 ]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 1961 is [True, False, False, False, True, False]
State prediction error at timestep 1961 is 0.012
Human Feedback received at timestep 1961 of None
Current timestep = 1962. State = [[-0.2415711  0.1221288]]. Action = [[ 0.08623254 -0.06153245  0.         -0.92893785]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 1962 is [True, False, False, False, True, False]
State prediction error at timestep 1962 is 0.012
Human Feedback received at timestep 1962 of None
Current timestep = 1963. State = [[-0.2354432   0.12074513]]. Action = [[ 0.0832713   0.01728003  0.         -0.14213955]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 1963 is [True, False, False, False, True, False]
Current timestep = 1964. State = [[-0.23407596  0.11863849]]. Action = [[-0.02734977 -0.04223218  0.         -0.9941507 ]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 1964 is [True, False, False, False, True, False]
Current timestep = 1965. State = [[-0.23859079  0.1214973 ]]. Action = [[-0.08573943  0.0831519   0.         -0.3595277 ]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 1965 is [True, False, False, False, True, False]
Current timestep = 1966. State = [[-0.24479772  0.1226951 ]]. Action = [[-0.07858781 -0.03216399  0.          0.6325824 ]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 1966 is [True, False, False, False, True, False]
Current timestep = 1967. State = [[-0.24972984  0.11849186]]. Action = [[-0.05571621 -0.08401032  0.          0.289719  ]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 1967 is [True, False, False, False, True, False]
Current timestep = 1968. State = [[-0.24826095  0.11237974]]. Action = [[ 0.06179097 -0.08074284  0.          0.96263146]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 1968 is [True, False, False, False, True, False]
State prediction error at timestep 1968 is 0.012
Human Feedback received at timestep 1968 of None
Current timestep = 1969. State = [[-0.25020897  0.10837308]]. Action = [[-0.08177754 -0.02898242  0.          0.05190408]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 1969 is [True, False, False, False, True, False]
Current timestep = 1970. State = [[-0.25339055  0.10240643]]. Action = [[-0.02630445 -0.09852359  0.         -0.2865715 ]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 1970 is [True, False, False, False, True, False]
Current timestep = 1971. State = [[-0.25444546  0.10061667]]. Action = [[-0.00678828  0.03349038  0.          0.25545692]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 1971 is [True, False, False, False, True, False]
Current timestep = 1972. State = [[-0.25202432  0.09953352]]. Action = [[ 0.06171777 -0.01913396  0.         -0.9253608 ]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 1972 is [True, False, False, False, True, False]
Current timestep = 1973. State = [[-0.24819452  0.10092251]]. Action = [[ 0.05530608  0.06522115  0.         -0.815568  ]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 1973 is [True, False, False, False, True, False]
State prediction error at timestep 1973 is 0.012
Human Feedback received at timestep 1973 of None
Current timestep = 1974. State = [[-0.2484628   0.10043174]]. Action = [[-0.02676042 -0.02309196  0.          0.83225536]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 1974 is [True, False, False, False, True, False]
Current timestep = 1975. State = [[-0.2509626   0.10336173]]. Action = [[-0.02317013  0.08794304  0.         -0.9756312 ]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 1975 is [True, False, False, False, True, False]
Current timestep = 1976. State = [[-0.25457847  0.10418118]]. Action = [[-0.04107112 -0.02426734  0.         -0.7285663 ]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 1976 is [True, False, False, False, True, False]
Current timestep = 1977. State = [[-0.25957152  0.10489023]]. Action = [[-0.06131309  0.02776629  0.         -0.168688  ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 1977 is [True, False, False, False, True, False]
Current timestep = 1978. State = [[-0.262034    0.10091973]]. Action = [[ 0.00266335 -0.09756752  0.          0.39189458]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 1978 is [True, False, False, False, True, False]
State prediction error at timestep 1978 is 0.012
Human Feedback received at timestep 1978 of None
Current timestep = 1979. State = [[-0.26659632  0.10103798]]. Action = [[-0.07858495  0.05939128  0.         -0.33743644]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 1979 is [True, False, False, False, True, False]
State prediction error at timestep 1979 is 0.012
Human Feedback received at timestep 1979 of None
Current timestep = 1980. State = [[-0.2706423   0.10008559]]. Action = [[-0.01755559 -0.05536267  0.          0.18342328]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 1980 is [True, False, False, False, True, False]
State prediction error at timestep 1980 is 0.012
Human Feedback received at timestep 1980 of None
Current timestep = 1981. State = [[-0.27341494  0.09616869]]. Action = [[-0.02782281 -0.05092774  0.         -0.4492985 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 1981 is [True, False, False, False, True, False]
State prediction error at timestep 1981 is 0.012
Human Feedback received at timestep 1981 of None
Current timestep = 1982. State = [[-0.27472585  0.09572964]]. Action = [[0.00643326 0.02504162 0.         0.45152557]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 1982 is [True, False, False, False, True, False]
Current timestep = 1983. State = [[-0.2730214   0.10078942]]. Action = [[0.05797102 0.09795932 0.         0.46332192]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 1983 is [True, False, False, False, True, False]
Current timestep = 1984. State = [[-0.26903155  0.10779958]]. Action = [[ 0.0843234   0.09696906  0.         -0.05535614]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 1984 is [True, False, False, False, True, False]
State prediction error at timestep 1984 is 0.012
Human Feedback received at timestep 1984 of None
Current timestep = 1985. State = [[-0.2704197   0.11303095]]. Action = [[-0.04989315  0.05250897  0.         -0.8506044 ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 1985 is [True, False, False, False, True, False]
Current timestep = 1986. State = [[-0.27651027  0.11825449]]. Action = [[-0.06515317  0.06683152  0.         -0.6935396 ]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 1986 is [True, False, False, False, True, False]
Current timestep = 1987. State = [[-0.2845647   0.12509526]]. Action = [[-0.08932364  0.08121385  0.         -0.4415728 ]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 1987 is [True, False, False, False, True, False]
State prediction error at timestep 1987 is 0.012
Human Feedback received at timestep 1987 of None
Current timestep = 1988. State = [[-0.28506154  0.1303884 ]]. Action = [[0.08779804 0.0373615  0.         0.9890914 ]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 1988 is [True, False, False, False, False, True]
State prediction error at timestep 1988 is 0.012
Human Feedback received at timestep 1988 of None
Current timestep = 1989. State = [[-0.28744408  0.13604283]]. Action = [[-0.06300542  0.06627289  0.          0.09720099]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 1989 is [True, False, False, False, False, True]
Current timestep = 1990. State = [[-0.2891796   0.13594355]]. Action = [[ 0.02671432 -0.07325352  0.          0.42938566]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 1990 is [True, False, False, False, False, True]
State prediction error at timestep 1990 is 0.012
Human Feedback received at timestep 1990 of None
Current timestep = 1991. State = [[-0.28943664  0.1384154 ]]. Action = [[-2.2873282e-05  6.1109401e-02  0.0000000e+00 -3.3126646e-01]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 1991 is [True, False, False, False, False, True]
Current timestep = 1992. State = [[-0.2919863   0.13921103]]. Action = [[-0.03624842 -0.04762504  0.          0.6087055 ]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 1992 is [True, False, False, False, False, True]
Current timestep = 1993. State = [[-0.29212132  0.13823569]]. Action = [[ 0.02517047 -0.0239355   0.         -0.5766648 ]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 1993 is [True, False, False, False, False, True]
Current timestep = 1994. State = [[-0.28720602  0.13515891]]. Action = [[ 0.08633845 -0.06458947  0.         -0.7368869 ]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 1994 is [True, False, False, False, False, True]
Current timestep = 1995. State = [[-0.28482482  0.13713837]]. Action = [[-0.0090774   0.07336681  0.         -0.9911474 ]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 1995 is [True, False, False, False, False, True]
Current timestep = 1996. State = [[-0.283987  0.139095]]. Action = [[ 0.01354609 -0.00864475  0.         -0.617622  ]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 1996 is [True, False, False, False, False, True]
Current timestep = 1997. State = [[-0.28593582  0.14021401]]. Action = [[-0.0570342   0.01608775  0.          0.42634094]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 1997 is [True, False, False, False, False, True]
Current timestep = 1998. State = [[-0.28282148  0.14092399]]. Action = [[ 0.08889634 -0.00260265  0.          0.78637934]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 1998 is [True, False, False, False, False, True]
Current timestep = 1999. State = [[-0.28104934  0.14569853]]. Action = [[-0.02187308  0.09617173  0.          0.33612144]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 1999 is [True, False, False, False, False, True]
Current timestep = 2000. State = [[-0.28208023  0.14500059]]. Action = [[-0.01839863 -0.07891796  0.         -0.75423366]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 2000 is [True, False, False, False, False, True]
State prediction error at timestep 2000 is 0.012
Human Feedback received at timestep 2000 of None
Current timestep = 2001. State = [[-0.27990496  0.14032565]]. Action = [[ 0.03930049 -0.06141946  0.          0.57055974]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 2001 is [True, False, False, False, False, True]
Current timestep = 2002. State = [[-0.2797476   0.14239526]]. Action = [[-0.03391091  0.07792436  0.         -0.6323316 ]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 2002 is [True, False, False, False, False, True]
State prediction error at timestep 2002 is 0.012
Human Feedback received at timestep 2002 of None
Current timestep = 2003. State = [[-0.27912024  0.14396487]]. Action = [[ 0.02462687 -0.01616882  0.         -0.05576843]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 2003 is [True, False, False, False, False, True]
Current timestep = 2004. State = [[-0.27873033  0.14141774]]. Action = [[-0.01502129 -0.04849185  0.         -0.99177885]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 2004 is [True, False, False, False, False, True]
State prediction error at timestep 2004 is 0.012
Human Feedback received at timestep 2004 of None
Current timestep = 2005. State = [[-0.27960983  0.14271645]]. Action = [[-0.01979528  0.05082167  0.         -0.30226696]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 2005 is [True, False, False, False, False, True]
Current timestep = 2006. State = [[-0.2773641   0.14714499]]. Action = [[ 0.0578438   0.06097554  0.         -0.549524  ]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 2006 is [True, False, False, False, False, True]
Current timestep = 2007. State = [[-0.27662706  0.14948454]]. Action = [[-0.01463958  0.01136246  0.         -0.37278426]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 2007 is [True, False, False, False, False, True]
Current timestep = 2008. State = [[-0.27357805  0.1534369 ]]. Action = [[ 0.0728705   0.07040425  0.         -0.23616749]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 2008 is [True, False, False, False, False, True]
Current timestep = 2009. State = [[-0.27609718  0.160416  ]]. Action = [[-0.08746175  0.09568875  0.         -0.56235707]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 2009 is [True, False, False, False, False, True]
Current timestep = 2010. State = [[-0.27593783  0.16764404]]. Action = [[0.06977964 0.07762892 0.         0.83541965]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 2010 is [True, False, False, False, False, True]
Current timestep = 2011. State = [[-0.2793352   0.17331466]]. Action = [[-0.09369901  0.04744057  0.          0.77844644]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 2011 is [True, False, False, False, False, True]
Current timestep = 2012. State = [[-0.28056     0.17921795]]. Action = [[ 0.05221251  0.06545901  0.         -0.3842436 ]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 2012 is [True, False, False, False, False, True]
Current timestep = 2013. State = [[-0.275977    0.18240145]]. Action = [[0.08648413 0.00299581 0.         0.43281794]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 2013 is [True, False, False, False, False, True]
Current timestep = 2014. State = [[-0.27123728  0.17985746]]. Action = [[ 0.04945626 -0.07804394  0.          0.75924635]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 2014 is [True, False, False, False, False, True]
Current timestep = 2015. State = [[-0.2728004   0.17646317]]. Action = [[-0.07688682 -0.05477712  0.         -0.13536572]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 2015 is [True, False, False, False, False, True]
Current timestep = 2016. State = [[-0.26945537  0.17444547]]. Action = [[ 0.09607419 -0.03323033  0.          0.6485381 ]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 2016 is [True, False, False, False, False, True]
Current timestep = 2017. State = [[-0.26622218  0.17560749]]. Action = [[-0.01414069  0.02801777  0.         -0.31246215]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 2017 is [True, False, False, False, False, True]
State prediction error at timestep 2017 is 0.012
Human Feedback received at timestep 2017 of None
Current timestep = 2018. State = [[-0.26520172  0.17226957]]. Action = [[-0.0040292  -0.09966716  0.         -0.91786206]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 2018 is [True, False, False, False, False, True]
Current timestep = 2019. State = [[-0.26364368  0.16575955]]. Action = [[-0.00383644 -0.08834316  0.         -0.00244194]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 2019 is [True, False, False, False, False, True]
Current timestep = 2020. State = [[-0.25863668  0.16507559]]. Action = [[0.07071521 0.04239567 0.         0.76328635]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 2020 is [True, False, False, False, False, True]
Current timestep = 2021. State = [[-0.25897834  0.1685554 ]]. Action = [[-0.07921267  0.05485348  0.         -0.26100504]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 2021 is [True, False, False, False, False, True]
Current timestep = 2022. State = [[-0.26496908  0.17315067]]. Action = [[-0.0970863   0.05533222  0.          0.53768444]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 2022 is [True, False, False, False, False, True]
Current timestep = 2023. State = [[-0.26560894  0.17391093]]. Action = [[ 0.04063847 -0.02677722  0.         -0.7612077 ]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 2023 is [True, False, False, False, False, True]
Current timestep = 2024. State = [[-0.26308995  0.17637445]]. Action = [[0.03314336 0.06433737 0.         0.0473088 ]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 2024 is [True, False, False, False, False, True]
Current timestep = 2025. State = [[-0.2607776   0.18209119]]. Action = [[ 0.03793526  0.08403831  0.         -0.49733347]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 2025 is [True, False, False, False, False, True]
Current timestep = 2026. State = [[-0.2559144   0.18669981]]. Action = [[ 0.09053963  0.04913909  0.         -0.63170516]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 2026 is [True, False, False, False, False, True]
Current timestep = 2027. State = [[-0.24906157  0.18949436]]. Action = [[ 0.09469592  0.03325505  0.         -0.94050926]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 2027 is [True, False, False, False, False, True]
Current timestep = 2028. State = [[-0.2457279   0.18815763]]. Action = [[ 0.00404576 -0.04816343  0.          0.4992628 ]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 2028 is [True, False, False, False, False, True]
Current timestep = 2029. State = [[-0.24705914  0.18840158]]. Action = [[-0.04438782  0.02204137  0.          0.87175775]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 2029 is [True, False, False, False, False, True]
State prediction error at timestep 2029 is 0.012
Human Feedback received at timestep 2029 of None
Current timestep = 2030. State = [[-0.24362063  0.19040613]]. Action = [[0.0850222  0.01840235 0.         0.6358783 ]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 2030 is [True, False, False, False, False, True]
State prediction error at timestep 2030 is 0.012
Human Feedback received at timestep 2030 of None
Current timestep = 2031. State = [[-0.23792937  0.1938119 ]]. Action = [[ 0.05322018  0.05312056  0.         -0.28732598]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 2031 is [True, False, False, False, False, True]
State prediction error at timestep 2031 is 0.012
Human Feedback received at timestep 2031 of None
Current timestep = 2032. State = [[-0.23328587  0.19778126]]. Action = [[ 0.04387265  0.04462973  0.         -0.38781798]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 2032 is [True, False, False, False, False, True]
Current timestep = 2033. State = [[-0.22930141  0.19494845]]. Action = [[ 0.02909092 -0.09468784  0.          0.93039596]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 2033 is [True, False, False, False, False, True]
Current timestep = 2034. State = [[-0.22613166  0.18941854]]. Action = [[ 0.00828792 -0.07334447  0.          0.294708  ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 2034 is [True, False, False, False, False, True]
Current timestep = 2035. State = [[-0.22212476  0.18787748]]. Action = [[0.03438329 0.00464197 0.         0.6922443 ]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 2035 is [True, False, False, False, False, True]
State prediction error at timestep 2035 is 0.012
Human Feedback received at timestep 2035 of None
Current timestep = 2036. State = [[-0.21912101  0.187681  ]]. Action = [[ 0.00246741 -0.0077998   0.          0.07935989]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 2036 is [True, False, False, False, False, True]
Current timestep = 2037. State = [[-0.21831316  0.1829599 ]]. Action = [[-0.02647235 -0.09619043  0.          0.99141645]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 2037 is [True, False, False, False, False, True]
State prediction error at timestep 2037 is 0.012
Human Feedback received at timestep 2037 of None
Current timestep = 2038. State = [[-0.21506819  0.17543732]]. Action = [[ 0.03620896 -0.09908145  0.          0.8792069 ]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 2038 is [True, False, False, False, False, True]
Current timestep = 2039. State = [[-0.20782784  0.17181854]]. Action = [[ 0.08604353  0.00109012  0.         -0.45563734]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 2039 is [True, False, False, False, False, True]
Current timestep = 2040. State = [[-0.20228335  0.1745644 ]]. Action = [[ 0.02912187  0.08428704  0.         -0.2897681 ]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 2040 is [True, False, False, False, False, True]
Current timestep = 2041. State = [[-0.20041901  0.17421286]]. Action = [[-0.00850163 -0.03436638  0.         -0.46610296]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 2041 is [True, False, False, False, False, True]
Current timestep = 2042. State = [[-0.19907661  0.17350383]]. Action = [[0.00536253 0.01823213 0.         0.86702156]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 2042 is [True, False, False, False, False, True]
State prediction error at timestep 2042 is 0.012
Human Feedback received at timestep 2042 of None
Current timestep = 2043. State = [[-0.19547231  0.17335086]]. Action = [[ 0.05132765  0.00251262  0.         -0.9757382 ]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 2043 is [True, False, False, False, False, True]
Current timestep = 2044. State = [[-0.19266067  0.16885734]]. Action = [[ 0.00770285 -0.07801752  0.          0.18623102]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 2044 is [True, False, False, False, False, True]
Current timestep = 2045. State = [[-0.19273078  0.16517411]]. Action = [[-0.03197693 -0.01840714  0.          0.784688  ]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 2045 is [True, False, False, False, False, True]
Current timestep = 2046. State = [[-0.19475792  0.16098005]]. Action = [[-0.04635211 -0.06516702  0.         -0.9895856 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 2046 is [True, False, False, False, False, True]
Current timestep = 2047. State = [[-0.19079289  0.15730664]]. Action = [[ 0.09330683 -0.02256862  0.          0.29008365]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 2047 is [True, False, False, False, False, True]
Current timestep = 2048. State = [[-0.18740006  0.15139644]]. Action = [[-0.00760085 -0.08560653  0.          0.8167281 ]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 2048 is [True, False, False, False, False, True]
Current timestep = 2049. State = [[-0.18773924  0.1528193 ]]. Action = [[-0.02709346  0.09850334  0.          0.42490292]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 2049 is [True, False, False, False, False, True]
Current timestep = 2050. State = [[-0.18716666  0.15268917]]. Action = [[ 0.01797979 -0.04370094  0.          0.38122118]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 2050 is [True, False, False, False, False, True]
State prediction error at timestep 2050 is 0.012
Human Feedback received at timestep 2050 of None
Current timestep = 2051. State = [[-0.189733    0.15388164]]. Action = [[-0.06998047  0.05629007  0.         -0.5972911 ]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 2051 is [True, False, False, False, False, True]
Current timestep = 2052. State = [[-0.19428642  0.15970996]]. Action = [[-0.04796627  0.0870749   0.          0.2823969 ]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 2052 is [True, False, False, False, False, True]
Current timestep = 2053. State = [[-0.19631056  0.16119203]]. Action = [[ 0.00329479 -0.02795465  0.         -0.25975764]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 2053 is [True, False, False, False, False, True]
State prediction error at timestep 2053 is 0.012
Human Feedback received at timestep 2053 of None
Current timestep = 2054. State = [[-0.20001549  0.15626776]]. Action = [[-0.0674829  -0.09609795  0.         -0.2942068 ]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 2054 is [True, False, False, False, False, True]
Current timestep = 2055. State = [[-0.20620055  0.14927691]]. Action = [[-0.08491066 -0.09889652  0.         -0.06949967]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 2055 is [True, False, False, False, False, True]
Current timestep = 2056. State = [[-0.20922673  0.14803459]]. Action = [[-0.00055161  0.02956853  0.          0.3672341 ]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 2056 is [True, False, False, False, False, True]
State prediction error at timestep 2056 is 0.012
Human Feedback received at timestep 2056 of None
Current timestep = 2057. State = [[-0.21083781  0.1511246 ]]. Action = [[-0.01247631  0.05019089  0.          0.8339248 ]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 2057 is [True, False, False, False, False, True]
Current timestep = 2058. State = [[-0.2123199   0.15553442]]. Action = [[ 0.00381799  0.06327616  0.         -0.7627143 ]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 2058 is [True, False, False, False, False, True]
State prediction error at timestep 2058 is 0.012
Human Feedback received at timestep 2058 of None
Current timestep = 2059. State = [[-0.21016636  0.15248738]]. Action = [[ 0.06952218 -0.09345634  0.         -0.20010078]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 2059 is [True, False, False, False, False, True]
Current timestep = 2060. State = [[-0.20845462  0.14952   ]]. Action = [[ 0.01081772  0.00519021  0.         -0.69107825]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 2060 is [True, False, False, False, False, True]
Current timestep = 2061. State = [[-0.20816821  0.1529082 ]]. Action = [[ 0.01327219  0.08197238  0.         -0.00707263]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 2061 is [True, False, False, False, False, True]
Current timestep = 2062. State = [[-0.21285807  0.15445012]]. Action = [[-0.08925298 -0.01020826  0.         -0.42405927]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 2062 is [True, False, False, False, False, True]
Current timestep = 2063. State = [[-0.22099483  0.15522197]]. Action = [[-0.09712283  0.01500343  0.          0.7074919 ]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 2063 is [True, False, False, False, False, True]
Current timestep = 2064. State = [[-0.22527508  0.15600406]]. Action = [[-4.2845309e-03 -6.8267435e-04  0.0000000e+00 -7.5204700e-01]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 2064 is [True, False, False, False, False, True]
Current timestep = 2065. State = [[-0.22324683  0.15955843]]. Action = [[0.07942521 0.07214466 0.         0.09679008]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 2065 is [True, False, False, False, False, True]
Current timestep = 2066. State = [[-0.22388226  0.16536935]]. Action = [[-0.0249116   0.07947754  0.         -0.79732025]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 2066 is [True, False, False, False, False, True]
Current timestep = 2067. State = [[-0.22995967  0.16744162]]. Action = [[-0.08479999 -0.01567537  0.         -0.6002094 ]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 2067 is [True, False, False, False, False, True]
Current timestep = 2068. State = [[-0.2356715   0.16375604]]. Action = [[-0.04612873 -0.08841201  0.          0.58801365]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 2068 is [True, False, False, False, False, True]
State prediction error at timestep 2068 is 0.012
Human Feedback received at timestep 2068 of None
Current timestep = 2069. State = [[-0.23959512  0.16188917]]. Action = [[-0.03387976 -0.00485943  0.          0.26109397]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 2069 is [True, False, False, False, False, True]
Current timestep = 2070. State = [[-0.24206448  0.15905395]]. Action = [[-0.01207107 -0.06386082  0.          0.17806613]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 2070 is [True, False, False, False, False, True]
Current timestep = 2071. State = [[-0.24387652  0.16064364]]. Action = [[-0.01264837  0.06477889  0.          0.54064584]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 2071 is [True, False, False, False, False, True]
Current timestep = 2072. State = [[-0.24177039  0.1611439 ]]. Action = [[ 0.07198595 -0.02315186  0.          0.90249157]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 2072 is [True, False, False, False, False, True]
Current timestep = 2073. State = [[-0.23649608  0.1642743 ]]. Action = [[ 0.08642692  0.08919137  0.         -0.6403414 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 2073 is [True, False, False, False, False, True]
Current timestep = 2074. State = [[-0.23757778  0.16694011]]. Action = [[-0.06364126  0.0129263   0.          0.4911661 ]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 2074 is [True, False, False, False, False, True]
Current timestep = 2075. State = [[-0.24332333  0.16322044]]. Action = [[-0.06753663 -0.08476651  0.          0.04979265]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 2075 is [True, False, False, False, False, True]
Current timestep = 2076. State = [[-0.24670324  0.15971786]]. Action = [[-0.01688158 -0.02573127  0.          0.12862206]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 2076 is [True, False, False, False, False, True]
State prediction error at timestep 2076 is 0.012
Human Feedback received at timestep 2076 of None
Current timestep = 2077. State = [[-0.24718979  0.16312388]]. Action = [[ 0.01884495  0.09113257  0.         -0.7956827 ]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 2077 is [True, False, False, False, False, True]
State prediction error at timestep 2077 is 0.012
Human Feedback received at timestep 2077 of None
Current timestep = 2078. State = [[-0.24946214  0.16526954]]. Action = [[-0.03569451 -0.00298496  0.         -0.23409432]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 2078 is [True, False, False, False, False, True]
Current timestep = 2079. State = [[-0.24913347  0.16886039]]. Action = [[ 0.04828318  0.07491278  0.         -0.75553083]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 2079 is [True, False, False, False, False, True]
Current timestep = 2080. State = [[-0.2480574   0.17479317]]. Action = [[0.01908378 0.08235524 0.         0.14143789]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 2080 is [True, False, False, False, False, True]
Current timestep = 2081. State = [[-0.24672237  0.17769821]]. Action = [[0.03548425 0.00995559 0.         0.46577454]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 2081 is [True, False, False, False, False, True]
Current timestep = 2082. State = [[-0.24533837  0.1783972 ]]. Action = [[ 0.01909287  0.0013235   0.         -0.7810366 ]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 2082 is [True, False, False, False, False, True]
State prediction error at timestep 2082 is 0.012
Human Feedback received at timestep 2082 of None
Current timestep = 2083. State = [[-0.24478449  0.18274662]]. Action = [[0.00714795 0.0786142  0.         0.58581245]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 2083 is [True, False, False, False, False, True]
Current timestep = 2084. State = [[-0.24130589  0.18659954]]. Action = [[ 0.07302672  0.02319044  0.         -0.231027  ]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 2084 is [True, False, False, False, False, True]
Current timestep = 2085. State = [[-0.23625524  0.19230974]]. Action = [[0.06189742 0.09252348 0.         0.13015485]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 2085 is [True, False, False, False, False, True]
Current timestep = 2086. State = [[-0.23851177  0.19976231]]. Action = [[-0.08600914  0.08094046  0.          0.5229237 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 2086 is [True, False, False, False, False, True]
Current timestep = 2087. State = [[-0.24533801  0.2015657 ]]. Action = [[-0.09133911 -0.04702509  0.         -0.6615395 ]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 2087 is [True, False, False, False, False, True]
Current timestep = 2088. State = [[-0.2523579   0.20684092]]. Action = [[-0.08454583  0.0859473   0.          0.21774268]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 2088 is [True, False, False, False, False, True]
Current timestep = 2089. State = [[-0.25439286  0.21178795]]. Action = [[0.02719059 0.00930081 0.         0.43241477]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 2089 is [True, False, False, False, False, True]
Current timestep = 2090. State = [[-0.25901058  0.21721406]]. Action = [[-0.08812159  0.06201402  0.         -0.6041136 ]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 2090 is [True, False, False, False, False, True]
Current timestep = 2091. State = [[-0.26611155  0.2239701 ]]. Action = [[-0.06860185  0.055356    0.          0.8060503 ]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 2091 is [True, False, False, False, False, True]
Current timestep = 2092. State = [[-0.2664148  0.2239117]]. Action = [[ 0.06271248 -0.07901291  0.          0.23205304]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 2092 is [True, False, False, False, False, True]
Current timestep = 2093. State = [[-0.26373467  0.22708133]]. Action = [[0.03984763 0.08020169 0.         0.6872227 ]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 2093 is [True, False, False, False, False, True]
Current timestep = 2094. State = [[-0.26522595  0.23426455]]. Action = [[-0.03348589  0.07903021  0.          0.02512085]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 2094 is [True, False, False, False, False, True]
State prediction error at timestep 2094 is 0.012
Human Feedback received at timestep 2094 of None
Current timestep = 2095. State = [[-0.2670379  0.235817 ]]. Action = [[-4.7914684e-05 -4.3858089e-02  0.0000000e+00 -8.9398676e-01]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 2095 is [True, False, False, False, False, True]
Current timestep = 2096. State = [[-0.2718245   0.23468637]]. Action = [[-0.08770762 -0.03324207  0.          0.63767314]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 2096 is [True, False, False, False, False, True]
State prediction error at timestep 2096 is 0.012
Human Feedback received at timestep 2096 of None
Current timestep = 2097. State = [[-0.2735154   0.23547678]]. Action = [[0.02519605 0.00515556 0.         0.557729  ]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 2097 is [True, False, False, False, False, True]
Current timestep = 2098. State = [[-0.27759463  0.23262899]]. Action = [[-0.09337558 -0.08931175  0.         -0.8784566 ]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 2098 is [True, False, False, False, False, True]
Current timestep = 2099. State = [[-0.2791761   0.22937292]]. Action = [[ 0.02708415 -0.03636526  0.          0.8979167 ]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 2099 is [True, False, False, False, False, True]
Current timestep = 2100. State = [[-0.28045264  0.22442366]]. Action = [[-0.03772509 -0.08753353  0.          0.6047181 ]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 2100 is [True, False, False, False, False, True]
Current timestep = 2101. State = [[-0.27950966  0.21935876]]. Action = [[ 0.03760134 -0.05399577  0.          0.81614864]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 2101 is [True, False, False, False, False, True]
Current timestep = 2102. State = [[-0.2801296   0.21692346]]. Action = [[-0.03594702 -0.00568358  0.          0.46291196]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 2102 is [True, False, False, False, False, True]
State prediction error at timestep 2102 is 0.012
Human Feedback received at timestep 2102 of None
Current timestep = 2103. State = [[-0.28178552  0.21892624]]. Action = [[-0.00899877  0.06152939  0.         -0.26625884]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 2103 is [True, False, False, False, False, True]
State prediction error at timestep 2103 is 0.012
Human Feedback received at timestep 2103 of None
Current timestep = 2104. State = [[-0.2827844   0.21595044]]. Action = [[-0.00399701 -0.07677948  0.         -0.11340195]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 2104 is [True, False, False, False, False, True]
Current timestep = 2105. State = [[-0.28413108  0.2176357 ]]. Action = [[-0.01372016  0.09794403  0.         -0.1266011 ]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 2105 is [True, False, False, False, False, True]
Current timestep = 2106. State = [[-0.28501743  0.22063394]]. Action = [[ 0.01041238  0.02890266  0.         -0.2645594 ]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 2106 is [True, False, False, False, False, True]
Current timestep = 2107. State = [[-0.28784323  0.21726556]]. Action = [[-0.04693658 -0.07427719  0.          0.06064236]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 2107 is [True, False, False, False, False, True]
Current timestep = 2108. State = [[-0.2889058   0.20994508]]. Action = [[ 0.01723653 -0.09827982  0.          0.5913948 ]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 2108 is [True, False, False, False, False, True]
Current timestep = 2109. State = [[-0.28760564  0.20820524]]. Action = [[ 0.02684069  0.04075518  0.         -0.8339719 ]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 2109 is [True, False, False, False, False, True]
Current timestep = 2110. State = [[-0.2919483   0.20747072]]. Action = [[-0.09535492 -0.01921127  0.          0.5150596 ]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 2110 is [True, False, False, False, False, True]
State prediction error at timestep 2110 is 0.012
Human Feedback received at timestep 2110 of None
Current timestep = 2111. State = [[-0.29349795  0.20362549]]. Action = [[ 0.03809368 -0.05488047  0.          0.5630684 ]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 2111 is [True, False, False, False, False, True]
Current timestep = 2112. State = [[-0.28965795  0.19974668]]. Action = [[ 0.07038253 -0.02325204  0.          0.42746723]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 2112 is [True, False, False, False, False, True]
State prediction error at timestep 2112 is 0.012
Human Feedback received at timestep 2112 of None
Current timestep = 2113. State = [[-0.28745872  0.20096572]]. Action = [[ 0.01142069  0.0710903   0.         -0.2682743 ]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 2113 is [True, False, False, False, False, True]
Current timestep = 2114. State = [[-0.28362507  0.20493552]]. Action = [[ 0.08129405  0.07338405  0.         -0.03155702]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 2114 is [True, False, False, False, False, True]
Current timestep = 2115. State = [[-0.2788949   0.20626819]]. Action = [[ 0.05692168  0.01460056  0.         -0.20085979]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 2115 is [True, False, False, False, False, True]
Current timestep = 2116. State = [[-0.27541196  0.20823763]]. Action = [[0.03510808 0.0531132  0.         0.11386538]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 2116 is [True, False, False, False, False, True]
Current timestep = 2117. State = [[-0.27081347  0.208626  ]]. Action = [[ 0.06578689 -0.00655939  0.          0.79923844]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 2117 is [True, False, False, False, False, True]
Current timestep = 2118. State = [[-0.27193096  0.20427635]]. Action = [[-0.08415264 -0.08743891  0.         -0.02850908]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 2118 is [True, False, False, False, False, True]
Current timestep = 2119. State = [[-0.27532095  0.20132443]]. Action = [[-0.03810517 -0.01832798  0.         -0.06442159]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 2119 is [True, False, False, False, False, True]
Current timestep = 2120. State = [[-0.27492654  0.20473874]]. Action = [[ 0.02938234  0.08158597  0.         -0.53980607]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 2120 is [True, False, False, False, False, True]
State prediction error at timestep 2120 is 0.012
Human Feedback received at timestep 2120 of None
Current timestep = 2121. State = [[-0.27592576  0.21124895]]. Action = [[-0.03316005  0.08673766  0.          0.8640981 ]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 2121 is [True, False, False, False, False, True]
Current timestep = 2122. State = [[-0.27403408  0.21405552]]. Action = [[ 6.2716536e-02  4.1247904e-04  0.0000000e+00 -9.1441858e-01]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 2122 is [True, False, False, False, False, True]
State prediction error at timestep 2122 is 0.012
Human Feedback received at timestep 2122 of None
Current timestep = 2123. State = [[-0.27136925  0.21605118]]. Action = [[ 0.01963191  0.03309912  0.         -0.9582584 ]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 2123 is [True, False, False, False, False, True]
Current timestep = 2124. State = [[-0.2667511   0.21261008]]. Action = [[ 0.07461343 -0.0964949   0.         -0.28582716]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 2124 is [True, False, False, False, False, True]
Current timestep = 2125. State = [[-0.26112553  0.20857109]]. Action = [[ 0.05158498 -0.03312008  0.         -0.9045368 ]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 2125 is [True, False, False, False, False, True]
Current timestep = 2126. State = [[-0.26303506  0.21157178]]. Action = [[-0.09235193  0.07860617  0.         -0.72759354]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 2126 is [True, False, False, False, False, True]
State prediction error at timestep 2126 is 0.012
Human Feedback received at timestep 2126 of None
Current timestep = 2127. State = [[-0.26982692  0.21601585]]. Action = [[-0.09873036  0.02687841  0.          0.04487443]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 2127 is [True, False, False, False, False, True]
Current timestep = 2128. State = [[-0.2704449   0.22030786]]. Action = [[0.04953674 0.05010436 0.         0.6937523 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 2128 is [True, False, False, False, False, True]
Current timestep = 2129. State = [[-0.26521987  0.22079003]]. Action = [[ 0.08015152 -0.03221275  0.          0.56379175]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 2129 is [True, False, False, False, False, True]
Current timestep = 2130. State = [[-0.26313072  0.22082075]]. Action = [[-0.01443454  0.00761379  0.          0.43078148]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 2130 is [True, False, False, False, False, True]
Current timestep = 2131. State = [[-0.26569825  0.21804719]]. Action = [[-0.06018874 -0.07872343  0.         -0.22877592]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 2131 is [True, False, False, False, False, True]
State prediction error at timestep 2131 is 0.012
Human Feedback received at timestep 2131 of None
Current timestep = 2132. State = [[-0.26379454  0.21658798]]. Action = [[ 6.2357567e-02 -1.3425946e-05  0.0000000e+00  5.4511690e-01]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 2132 is [True, False, False, False, False, True]
State prediction error at timestep 2132 is 0.012
Human Feedback received at timestep 2132 of None
Current timestep = 2133. State = [[-0.26353344  0.21977957]]. Action = [[-0.04296828  0.05776962  0.          0.42210066]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 2133 is [True, False, False, False, False, True]
State prediction error at timestep 2133 is 0.012
Human Feedback received at timestep 2133 of None
Current timestep = 2134. State = [[-0.26369956  0.21883966]]. Action = [[ 0.00925313 -0.06447069  0.         -0.02676791]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 2134 is [True, False, False, False, False, True]
State prediction error at timestep 2134 is 0.012
Human Feedback received at timestep 2134 of None
Current timestep = 2135. State = [[-0.26314518  0.21954231]]. Action = [[-0.00416955  0.04104768  0.         -0.83360785]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 2135 is [True, False, False, False, False, True]
Current timestep = 2136. State = [[-0.2626058   0.22367829]]. Action = [[ 0.01031815  0.05847088  0.         -0.66757333]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 2136 is [True, False, False, False, False, True]
Current timestep = 2137. State = [[-0.2595347  0.2211323]]. Action = [[ 0.05384942 -0.08836854  0.         -0.5978467 ]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 2137 is [True, False, False, False, False, True]
Current timestep = 2138. State = [[-0.25901616  0.22197597]]. Action = [[-0.0288768   0.06835943  0.          0.25242615]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 2138 is [True, False, False, False, False, True]
Current timestep = 2139. State = [[-0.26168138  0.22410761]]. Action = [[-0.03956805  0.0013177   0.         -0.6237473 ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 2139 is [True, False, False, False, False, True]
Current timestep = 2140. State = [[-0.2665569   0.22755869]]. Action = [[-0.07151026  0.05572807  0.          0.41017556]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 2140 is [True, False, False, False, False, True]
Current timestep = 2141. State = [[-0.26609787  0.23329966]]. Action = [[0.06896    0.07601687 0.         0.39526093]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 2141 is [True, False, False, False, False, True]
Current timestep = 2142. State = [[-0.2667117   0.23342505]]. Action = [[-0.04220512 -0.05536531  0.          0.3278165 ]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 2142 is [True, False, False, False, False, True]
Current timestep = 2143. State = [[-0.26375094  0.22985764]]. Action = [[ 0.09291696 -0.05070722  0.          0.25669396]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 2143 is [True, False, False, False, False, True]
State prediction error at timestep 2143 is 0.012
Human Feedback received at timestep 2143 of None
Current timestep = 2144. State = [[-0.2604741   0.22736903]]. Action = [[ 0.01636921 -0.01768158  0.         -0.4864266 ]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 2144 is [True, False, False, False, False, True]
Current timestep = 2145. State = [[-0.25591508  0.22245356]]. Action = [[ 0.07348531 -0.08379003  0.         -0.2483105 ]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 2145 is [True, False, False, False, False, True]
Current timestep = 2146. State = [[-0.25390136  0.21724267]]. Action = [[-0.01998878 -0.04899762  0.         -0.5657355 ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 2146 is [True, False, False, False, False, True]
Current timestep = 2147. State = [[-0.24988419  0.21482123]]. Action = [[ 0.07053687 -0.00601326  0.          0.5297451 ]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 2147 is [True, False, False, False, False, True]
Current timestep = 2148. State = [[-0.24770105  0.21652791]]. Action = [[-0.01530033  0.06094872  0.          0.08125448]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 2148 is [True, False, False, False, False, True]
Current timestep = 2149. State = [[-0.24745096  0.21565023]]. Action = [[-0.00475543 -0.03643501  0.         -0.05551994]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 2149 is [True, False, False, False, False, True]
State prediction error at timestep 2149 is 0.012
Human Feedback received at timestep 2149 of None
Current timestep = 2150. State = [[-0.24317053  0.21411443]]. Action = [[0.07247224 0.00432207 0.         0.4897406 ]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 2150 is [True, False, False, False, False, True]
Current timestep = 2151. State = [[-0.23574586  0.20889206]]. Action = [[ 0.08839937 -0.08401677  0.          0.5895183 ]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 2151 is [True, False, False, False, False, True]
Current timestep = 2152. State = [[-0.23255658  0.209986  ]]. Action = [[-0.0134855   0.09868839  0.          0.45355403]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 2152 is [True, False, False, False, False, True]
State prediction error at timestep 2152 is 0.012
Human Feedback received at timestep 2152 of None
Current timestep = 2153. State = [[-0.22987601  0.21384196]]. Action = [[0.04456922 0.04317381 0.         0.2850517 ]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 2153 is [True, False, False, False, False, True]
State prediction error at timestep 2153 is 0.012
Human Feedback received at timestep 2153 of None
Current timestep = 2154. State = [[-0.23152722  0.2125076 ]]. Action = [[-0.08008257 -0.04937217  0.          0.76049757]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 2154 is [True, False, False, False, False, True]
State prediction error at timestep 2154 is 0.012
Human Feedback received at timestep 2154 of None
Current timestep = 2155. State = [[-0.23172538  0.21576728]]. Action = [[ 0.03878041  0.09927567  0.         -0.9814966 ]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 2155 is [True, False, False, False, False, True]
Current timestep = 2156. State = [[-0.22576867  0.22103818]]. Action = [[0.09776752 0.05661976 0.         0.331236  ]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 2156 is [True, False, False, False, False, True]
Current timestep = 2157. State = [[-0.21928832  0.224922  ]]. Action = [[0.06724685 0.05025259 0.         0.6159346 ]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 2157 is [True, False, False, False, False, True]
Current timestep = 2158. State = [[-0.21982609  0.2286322 ]]. Action = [[-0.06641315  0.03898097  0.         -0.59012383]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 2158 is [True, False, False, False, False, True]
Current timestep = 2159. State = [[-0.22211076  0.23064747]]. Action = [[-0.01975887 -0.0033785   0.          0.24703228]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 2159 is [True, False, False, False, False, True]
Current timestep = 2160. State = [[-0.21928842  0.22944523]]. Action = [[ 0.05970449 -0.04719405  0.          0.6456208 ]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 2160 is [True, False, False, False, False, True]
State prediction error at timestep 2160 is 0.012
Human Feedback received at timestep 2160 of None
Current timestep = 2161. State = [[-0.21807897  0.23361152]]. Action = [[-0.02184076  0.09405845  0.          0.9785106 ]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 2161 is [True, False, False, False, False, True]
Current timestep = 2162. State = [[-0.22313534  0.23910494]]. Action = [[-0.09646246  0.03174914  0.          0.361583  ]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 2162 is [True, False, False, False, False, True]
State prediction error at timestep 2162 is 0.012
Human Feedback received at timestep 2162 of None
Current timestep = 2163. State = [[-0.22514184  0.24268925]]. Action = [[ 0.01687492  0.01660849  0.         -0.03141552]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 2163 is [True, False, False, False, False, True]
State prediction error at timestep 2163 is 0.012
Human Feedback received at timestep 2163 of None
Current timestep = 2164. State = [[-0.2217271   0.24141894]]. Action = [[ 0.06301934 -0.06489751  0.         -0.47294277]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 2164 is [True, False, False, False, False, True]
Current timestep = 2165. State = [[-0.21657737  0.24011448]]. Action = [[ 0.05986121 -0.00829853  0.         -0.28896034]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 2165 is [True, False, False, False, False, True]
Current timestep = 2166. State = [[-0.21659054  0.24161309]]. Action = [[-0.04854041  0.02268914  0.         -0.54068977]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 2166 is [True, False, False, False, False, True]
Current timestep = 2167. State = [[-0.216122    0.24141227]]. Action = [[ 0.0242283  -0.03462953  0.          0.10304976]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 2167 is [True, False, False, False, False, True]
State prediction error at timestep 2167 is 0.012
Human Feedback received at timestep 2167 of None
Current timestep = 2168. State = [[-0.21445961  0.24547172]]. Action = [[0.01124217 0.09120863 0.         0.54353046]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 2168 is [True, False, False, False, False, True]
State prediction error at timestep 2168 is 0.012
Human Feedback received at timestep 2168 of None
Current timestep = 2169. State = [[-0.21561448  0.25317273]]. Action = [[-0.02985559  0.09775985  0.         -0.45153636]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 2169 is [True, False, False, False, False, True]
Current timestep = 2170. State = [[-0.21414378  0.25319624]]. Action = [[ 0.04851419 -0.07157449  0.         -0.2613684 ]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 2170 is [True, False, False, False, False, True]
Current timestep = 2171. State = [[-0.20887263  0.25154033]]. Action = [[ 0.07137709 -0.00455793  0.         -0.02302194]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 2171 is [True, False, False, False, False, True]
Current timestep = 2172. State = [[-0.21021666  0.25573847]]. Action = [[-0.07926212  0.08448165  0.          0.3693819 ]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 2172 is [True, False, False, False, False, True]
State prediction error at timestep 2172 is 0.012
Human Feedback received at timestep 2172 of None
Current timestep = 2173. State = [[-0.20988415  0.25604174]]. Action = [[ 0.04550647 -0.05817968  0.         -0.60837436]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 2173 is [True, False, False, False, False, True]
Current timestep = 2174. State = [[-0.20517002  0.25942343]]. Action = [[0.06552555 0.09341943 0.         0.40819025]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 2174 is [True, False, False, False, False, True]
Current timestep = 2175. State = [[-0.19853072  0.2665101 ]]. Action = [[ 0.09247383  0.09551428  0.         -0.48320496]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 2175 is [True, False, False, False, False, True]
Current timestep = 2176. State = [[-0.19804493  0.2726877 ]]. Action = [[-0.05420593  0.06476235  0.          0.05744565]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 2176 is [True, False, False, False, False, True]
Current timestep = 2177. State = [[-0.2023427   0.27277622]]. Action = [[-0.06638507 -0.05968079  0.          0.6093099 ]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 2177 is [True, False, False, False, False, True]
Current timestep = 2178. State = [[-0.20083183  0.2735113 ]]. Action = [[ 0.0670745   0.02401278  0.         -0.92634344]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 2178 is [True, False, False, False, False, True]
Current timestep = 2179. State = [[-0.201716   0.2748773]]. Action = [[-0.06847395 -0.01095674  0.          0.7559736 ]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 2179 is [True, False, False, False, False, True]
Current timestep = 2180. State = [[-0.1993597   0.27220702]]. Action = [[ 0.07001721 -0.07807852  0.          0.7883053 ]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 2180 is [True, False, False, False, False, True]
State prediction error at timestep 2180 is 0.012
Human Feedback received at timestep 2180 of None
Current timestep = 2181. State = [[-0.19465536  0.27032307]]. Action = [[ 0.0357318  -0.01029079  0.          0.3796159 ]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 2181 is [True, False, False, False, False, True]
State prediction error at timestep 2181 is 0.012
Human Feedback received at timestep 2181 of None
Current timestep = 2182. State = [[-0.1925885   0.27498502]]. Action = [[ 0.00141038  0.09482007  0.         -0.9516715 ]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 2182 is [True, False, False, False, False, True]
State prediction error at timestep 2182 is 0.012
Human Feedback received at timestep 2182 of None
Current timestep = 2183. State = [[-0.18749852  0.2806364 ]]. Action = [[0.09319051 0.0594315  0.         0.43006313]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 2183 is [True, False, False, False, False, True]
Current timestep = 2184. State = [[-0.18472764  0.28520966]]. Action = [[-0.00672901  0.05735844  0.          0.35201216]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 2184 is [True, False, False, False, False, True]
Current timestep = 2185. State = [[-0.18678811  0.28467652]]. Action = [[-0.05660112 -0.06048581  0.         -0.07982153]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 2185 is [True, False, False, False, False, True]
Current timestep = 2186. State = [[-0.18706216  0.28728762]]. Action = [[ 0.01738654  0.06939717  0.         -0.5629725 ]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 2186 is [True, False, False, False, False, True]
Current timestep = 2187. State = [[-0.18816207  0.29050204]]. Action = [[-0.03891527  0.00776003  0.         -0.20655668]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 2187 is [True, False, False, False, False, True]
Current timestep = 2188. State = [[-0.18782322  0.29301688]]. Action = [[0.02181723 0.02126197 0.         0.6086421 ]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 2188 is [True, False, False, False, False, True]
State prediction error at timestep 2188 is 0.012
Human Feedback received at timestep 2188 of None
Current timestep = 2189. State = [[-0.18975708  0.29163682]]. Action = [[-0.06122531 -0.06775396  0.         -0.75148433]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 2189 is [True, False, False, False, False, True]
Current timestep = 2190. State = [[-0.19075172  0.2936476 ]]. Action = [[ 0.01093795  0.05523979  0.         -0.47878927]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 2190 is [True, False, False, False, False, True]
Current timestep = 2191. State = [[-0.18837617  0.29889768]]. Action = [[0.04472306 0.06014927 0.         0.18427753]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 2191 is [True, False, False, False, False, True]
Current timestep = 2192. State = [[-0.19048986  0.2982015 ]]. Action = [[-0.07895839 -0.07621697  0.         -0.16125149]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 2192 is [True, False, False, False, False, True]
Current timestep = 2193. State = [[-0.19310753  0.29814005]]. Action = [[-0.00521831  0.02264824  0.          0.14739466]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 2193 is [True, False, False, False, False, True]
State prediction error at timestep 2193 is 0.012
Human Feedback received at timestep 2193 of None
Current timestep = 2194. State = [[-0.19509496  0.29861978]]. Action = [[-0.02721325 -0.01403164  0.          0.6419735 ]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 2194 is [True, False, False, False, False, True]
Current timestep = 2195. State = [[-0.19531742  0.29418385]]. Action = [[ 0.01474936 -0.095116    0.          0.53708935]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 2195 is [True, False, False, False, False, True]
Current timestep = 2196. State = [[-0.1939969   0.28795704]]. Action = [[ 0.01325722 -0.07790892  0.          0.85433865]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 2196 is [True, False, False, False, False, True]
Current timestep = 2197. State = [[-0.18985686  0.2892265 ]]. Action = [[0.07691222 0.088214   0.         0.53582335]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 2197 is [True, False, False, False, False, True]
Current timestep = 2198. State = [[-0.18522668  0.28790396]]. Action = [[ 0.04145103 -0.05737317  0.          0.24095166]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 2198 is [True, False, False, False, False, True]
Current timestep = 2199. State = [[-0.18452352  0.28580496]]. Action = [[-0.02732033  0.00242265  0.          0.84162426]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 2199 is [True, False, False, False, False, True]
Current timestep = 2200. State = [[-0.18774113  0.28719485]]. Action = [[-0.06270257  0.03686138  0.          0.01620352]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 2200 is [True, False, False, False, False, True]
Current timestep = 2201. State = [[-0.19144975  0.29273793]]. Action = [[-0.03675807  0.09549242  0.          0.24134636]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 2201 is [True, False, False, False, False, True]
State prediction error at timestep 2201 is 0.012
Human Feedback received at timestep 2201 of None
Current timestep = 2202. State = [[-0.1921795   0.29373065]]. Action = [[ 0.01940708 -0.03420896  0.          0.35098505]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 2202 is [True, False, False, False, False, True]
Current timestep = 2203. State = [[-0.19621143  0.28896186]]. Action = [[-0.0917845  -0.08995259  0.          0.8220775 ]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 2203 is [True, False, False, False, False, True]
Current timestep = 2204. State = [[-0.20253499  0.28304613]]. Action = [[-0.07597549 -0.08514895  0.          0.11855435]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 2204 is [True, False, False, False, False, True]
Current timestep = 2205. State = [[-0.20966095  0.28111795]]. Action = [[-0.09093726 -0.00191461  0.          0.61165476]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 2205 is [True, False, False, False, False, True]
Current timestep = 2206. State = [[-0.21573852  0.2848626 ]]. Action = [[-0.04472684  0.07256316  0.          0.26886892]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 2206 is [True, False, False, False, False, True]
Current timestep = 2207. State = [[-0.21412441  0.28239498]]. Action = [[ 0.09536748 -0.09021842  0.         -0.55322117]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 2207 is [True, False, False, False, False, True]
Current timestep = 2208. State = [[-0.21118227  0.277238  ]]. Action = [[ 0.02679486 -0.03789933  0.         -0.689134  ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 2208 is [True, False, False, False, False, True]
Current timestep = 2209. State = [[-0.21128723  0.27087587]]. Action = [[-0.0102283  -0.08505902  0.         -0.519642  ]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 2209 is [True, False, False, False, False, True]
Current timestep = 2210. State = [[-0.2150993   0.27180392]]. Action = [[-0.06263811  0.09036031  0.          0.6644423 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 2210 is [True, False, False, False, False, True]
State prediction error at timestep 2210 is 0.012
Human Feedback received at timestep 2210 of None
Current timestep = 2211. State = [[-0.21891713  0.2757462 ]]. Action = [[-0.01660383  0.05124224  0.          0.98345995]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 2211 is [True, False, False, False, False, True]
Current timestep = 2212. State = [[-0.22361062  0.27963218]]. Action = [[-0.05288232  0.0641047   0.         -0.46247208]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 2212 is [True, False, False, False, False, True]
Current timestep = 2213. State = [[-0.22486009  0.28361815]]. Action = [[0.04269028 0.05644267 0.         0.19846761]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 2213 is [True, False, False, False, False, True]
Current timestep = 2214. State = [[-0.22936264  0.28465676]]. Action = [[-0.08217573 -0.00612653  0.         -0.93090284]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 2214 is [True, False, False, False, False, True]
State prediction error at timestep 2214 is 0.012
Human Feedback received at timestep 2214 of None
Current timestep = 2215. State = [[-0.2306978   0.28237662]]. Action = [[ 0.05314662 -0.04156662  0.          0.7906537 ]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 2215 is [True, False, False, False, False, True]
State prediction error at timestep 2215 is 0.012
Human Feedback received at timestep 2215 of None
Current timestep = 2216. State = [[-0.22755542  0.28442815]]. Action = [[ 0.06539222  0.07887372  0.         -0.15008253]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 2216 is [True, False, False, False, False, True]
Current timestep = 2217. State = [[-0.23130675  0.28748676]]. Action = [[-0.09449218  0.0254106   0.          0.6247692 ]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 2217 is [True, False, False, False, False, True]
Current timestep = 2218. State = [[-0.23822008  0.28934893]]. Action = [[-0.05789992  0.02028402  0.         -0.98727816]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 2218 is [True, False, False, False, False, True]
Current timestep = 2219. State = [[-0.24314182  0.29008177]]. Action = [[-0.03168727 -0.00468674  0.          0.13791227]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 2219 is [True, False, False, False, False, True]
Current timestep = 2220. State = [[-0.24454229  0.29158393]]. Action = [[0.02209785 0.02592232 0.         0.5096328 ]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 2220 is [True, False, False, False, False, True]
State prediction error at timestep 2220 is 0.012
Human Feedback received at timestep 2220 of None
Current timestep = 2221. State = [[-0.24907951  0.28922424]]. Action = [[-0.08255956 -0.07624217  0.         -0.7856792 ]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 2221 is [True, False, False, False, False, True]
State prediction error at timestep 2221 is 0.012
Human Feedback received at timestep 2221 of None
Current timestep = 2222. State = [[-0.25442007  0.29168513]]. Action = [[-0.03146069  0.08379654  0.         -0.6143121 ]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 2222 is [True, False, False, False, False, True]
Current timestep = 2223. State = [[-0.25935164  0.29743856]]. Action = [[-0.04550404  0.06263459  0.          0.13148558]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 2223 is [True, False, False, False, False, True]
Current timestep = 2224. State = [[-0.26514563  0.2995698 ]]. Action = [[-0.05539165 -0.00890218  0.          0.2870977 ]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 2224 is [True, False, False, False, False, True]
Current timestep = 2225. State = [[-0.27110422  0.2969989 ]]. Action = [[-0.0573772  -0.07226387  0.         -0.58858305]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 2225 is [True, False, False, False, False, True]
State prediction error at timestep 2225 is 0.012
Human Feedback received at timestep 2225 of None
Current timestep = 2226. State = [[-0.2751986   0.29949358]]. Action = [[-0.01612144  0.07343122  0.          0.7671554 ]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 2226 is [True, False, False, False, False, True]
State prediction error at timestep 2226 is 0.012
Human Feedback received at timestep 2226 of None
Current timestep = 2227. State = [[-0.27941912  0.30196637]]. Action = [[-0.04277722 -0.00607222  0.          0.11976123]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 2227 is [True, False, False, False, False, True]
Current timestep = 2228. State = [[-0.27716058  0.2994101 ]]. Action = [[ 0.09664273 -0.06411324  0.          0.3307836 ]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 2228 is [True, False, False, False, False, True]
Current timestep = 2229. State = [[-0.27396664  0.29404488]]. Action = [[ 0.02019181 -0.07599527  0.          0.22956169]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 2229 is [True, False, False, False, False, True]
Current timestep = 2230. State = [[-0.2750515  0.287511 ]]. Action = [[-0.03935992 -0.09345134  0.         -0.10525775]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 2230 is [True, False, False, False, False, True]
State prediction error at timestep 2230 is 0.012
Human Feedback received at timestep 2230 of None
Current timestep = 2231. State = [[-0.27424514  0.28527784]]. Action = [[0.03430512 0.0116668  0.         0.34746027]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 2231 is [True, False, False, False, False, True]
Current timestep = 2232. State = [[-0.27054065  0.28501853]]. Action = [[0.04856359 0.00487415 0.         0.11576641]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 2232 is [True, False, False, False, False, True]
State prediction error at timestep 2232 is 0.012
Human Feedback received at timestep 2232 of None
Current timestep = 2233. State = [[-0.27260393  0.28336316]]. Action = [[-0.08178643 -0.02239578  0.          0.8135123 ]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 2233 is [True, False, False, False, False, True]
Current timestep = 2234. State = [[-0.27578992  0.28454065]]. Action = [[-0.02066147  0.04734991  0.         -0.01213801]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 2234 is [True, False, False, False, False, True]
Current timestep = 2235. State = [[-0.2760111  0.2824469]]. Action = [[ 0.0142922 -0.05576    0.         0.544976 ]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 2235 is [True, False, False, False, False, True]
Current timestep = 2236. State = [[-0.27957192  0.2780727 ]]. Action = [[-0.07854549 -0.04964948  0.         -0.22006178]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 2236 is [True, False, False, False, False, True]
Current timestep = 2237. State = [[-0.28670746  0.27686965]]. Action = [[-0.0923435   0.00764368  0.         -0.9450005 ]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 2237 is [True, False, False, False, False, True]
Current timestep = 2238. State = [[-0.28652626  0.27201742]]. Action = [[ 0.07416674 -0.09686339  0.          0.94519615]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 2238 is [True, False, False, False, False, True]
State prediction error at timestep 2238 is 0.012
Human Feedback received at timestep 2238 of None
Current timestep = 2239. State = [[-0.2849291   0.26923576]]. Action = [[0.00145765 0.0182503  0.         0.44433236]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 2239 is [True, False, False, False, False, True]
Current timestep = 2240. State = [[-0.2876694   0.26821327]]. Action = [[-0.04626621 -0.00754888  0.          0.9868734 ]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 2240 is [True, False, False, False, False, True]
Current timestep = 2241. State = [[-0.28637695  0.2711735 ]]. Action = [[ 0.07428416  0.09165158  0.         -0.33000588]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 2241 is [True, False, False, False, False, True]
Current timestep = 2242. State = [[-0.2806512  0.2716686]]. Action = [[ 0.08927565 -0.01031891  0.         -0.00138092]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 2242 is [True, False, False, False, False, True]
Current timestep = 2243. State = [[-0.2803106   0.27394158]]. Action = [[-0.0417097   0.07680624  0.         -0.05976117]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 2243 is [True, False, False, False, False, True]
State prediction error at timestep 2243 is 0.012
Human Feedback received at timestep 2243 of None
Current timestep = 2244. State = [[-0.28166813  0.28004733]]. Action = [[0.00519427 0.09682132 0.         0.17915154]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 2244 is [True, False, False, False, False, True]
Current timestep = 2245. State = [[-0.2865433   0.28350654]]. Action = [[-0.08819863  0.0161766   0.         -0.20072961]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 2245 is [True, False, False, False, False, True]
State prediction error at timestep 2245 is 0.012
Human Feedback received at timestep 2245 of None
Current timestep = 2246. State = [[-0.28901893  0.28296596]]. Action = [[ 0.01695172 -0.03200039  0.          0.12186801]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 2246 is [True, False, False, False, False, True]
Current timestep = 2247. State = [[-0.2935205   0.28079635]]. Action = [[-0.08636139 -0.04252868  0.         -0.15935159]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 2247 is [True, False, False, False, False, True]
Current timestep = 2248. State = [[-0.29341358  0.27716202]]. Action = [[ 0.06142264 -0.06929091  0.          0.13776469]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 2248 is [True, False, False, False, False, True]
State prediction error at timestep 2248 is 0.012
Human Feedback received at timestep 2248 of None
Current timestep = 2249. State = [[-0.2923815  0.2761241]]. Action = [[-0.00734271  0.01138331  0.          0.69018304]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 2249 is [True, False, False, False, False, True]
Current timestep = 2250. State = [[-0.2964191   0.27481437]]. Action = [[-0.07548708 -0.04081119  0.          0.3256961 ]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 2250 is [True, False, False, False, False, True]
Current timestep = 2251. State = [[-0.29889128  0.27401525]]. Action = [[-1.7722696e-04 -4.6130195e-03  0.0000000e+00 -9.6771663e-01]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 2251 is [True, False, False, False, False, True]
Current timestep = 2252. State = [[-0.30193776  0.27482843]]. Action = [[-0.04998329  0.01545085  0.         -0.42129135]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 2252 is [True, False, False, False, False, True]
State prediction error at timestep 2252 is 0.012
Human Feedback received at timestep 2252 of None
Current timestep = 2253. State = [[-0.30089593  0.27767023]]. Action = [[ 0.06513049  0.05152097  0.         -0.6103716 ]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 2253 is [True, False, False, False, False, True]
Current timestep = 2254. State = [[-0.2994351   0.27625588]]. Action = [[ 0.00264634 -0.05168813  0.         -0.7831228 ]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 2254 is [True, False, False, False, False, True]
State prediction error at timestep 2254 is 0.012
Human Feedback received at timestep 2254 of None
Current timestep = 2255. State = [[-0.29927832  0.2722155 ]]. Action = [[ 0.00305556 -0.05044689  0.         -0.5419403 ]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 2255 is [True, False, False, False, False, True]
Current timestep = 2256. State = [[-0.2978942  0.2660881]]. Action = [[ 0.02348439 -0.09048343  0.          0.4746908 ]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 2256 is [True, False, False, False, False, True]
Current timestep = 2257. State = [[-0.29761407  0.26338965]]. Action = [[-0.01498366  0.007084    0.          0.8252821 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 2257 is [True, False, False, False, False, True]
State prediction error at timestep 2257 is 0.012
Human Feedback received at timestep 2257 of None
Current timestep = 2258. State = [[-0.2948438   0.26693243]]. Action = [[ 0.06401836  0.09205436  0.         -0.40211797]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 2258 is [True, False, False, False, False, True]
State prediction error at timestep 2258 is 0.012
Human Feedback received at timestep 2258 of None
Current timestep = 2259. State = [[-0.2940867  0.2688841]]. Action = [[-0.02236477  0.01000644  0.          0.53453565]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 2259 is [True, False, False, False, False, True]
Current timestep = 2260. State = [[-0.29356027  0.26606172]]. Action = [[ 0.01952764 -0.0525406   0.         -0.94425863]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 2260 is [True, False, False, False, False, True]
Current timestep = 2261. State = [[-0.29727376  0.2650999 ]]. Action = [[-0.09012935  0.01743986  0.         -0.29513443]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 2261 is [True, False, False, False, False, True]
Current timestep = 2262. State = [[-0.30395484  0.26370066]]. Action = [[-0.08086561 -0.04043504  0.         -0.39516294]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 2262 is [True, False, False, False, False, True]
Current timestep = 2263. State = [[-0.3111337   0.26580307]]. Action = [[-0.0827966   0.05830134  0.          0.15763283]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 2263 is [True, False, False, False, False, True]
Current timestep = 2264. State = [[-0.31462055  0.26338014]]. Action = [[ 0.00243056 -0.08804834  0.         -0.84402925]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 2264 is [True, False, False, False, False, True]
Current timestep = 2265. State = [[-0.31084305  0.25736755]]. Action = [[ 0.09343781 -0.07192077  0.          0.35346377]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 2265 is [True, False, False, False, False, True]
Current timestep = 2266. State = [[-0.30410796  0.2509227 ]]. Action = [[ 0.087105   -0.07009344  0.          0.22105277]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 2266 is [True, False, False, False, False, True]
Current timestep = 2267. State = [[-0.30405477  0.25156543]]. Action = [[-0.05593454  0.08325651  0.         -0.44499582]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 2267 is [True, False, False, False, False, True]
Current timestep = 2268. State = [[-0.30866757  0.24887586]]. Action = [[-0.06060249 -0.08999126  0.          0.48855495]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 2268 is [True, False, False, False, False, True]
Current timestep = 2269. State = [[-0.31331846  0.24652681]]. Action = [[-0.04841664  0.00912827  0.         -0.88927567]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 2269 is [True, False, False, False, False, True]
State prediction error at timestep 2269 is 0.012
Human Feedback received at timestep 2269 of None
Current timestep = 2270. State = [[-0.3137128   0.24141431]]. Action = [[ 0.03455582 -0.09377229  0.         -0.42840934]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 2270 is [True, False, False, False, False, True]
Current timestep = 2271. State = [[-0.31213984  0.23554872]]. Action = [[ 0.01899191 -0.04604753  0.         -0.330163  ]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 2271 is [True, False, False, False, False, True]
Current timestep = 2272. State = [[-0.3165174   0.23720278]]. Action = [[-0.09266695  0.08854491  0.         -0.80526674]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 2272 is [True, False, False, False, False, True]
State prediction error at timestep 2272 is 0.012
Human Feedback received at timestep 2272 of None
Current timestep = 2273. State = [[-0.3227864   0.23688403]]. Action = [[-0.05305844 -0.03870831  0.          0.8087342 ]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 2273 is [True, False, False, False, False, True]
Current timestep = 2274. State = [[-0.32990414  0.24010216]]. Action = [[-0.0830592   0.09827702  0.          0.43930912]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 2274 is [True, False, False, False, False, True]
Current timestep = 2275. State = [[-0.332365    0.24250431]]. Action = [[ 0.03865778  0.00807194  0.         -0.24899554]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 2275 is [True, False, False, False, False, True]
Current timestep = 2276. State = [[-0.3348156   0.24434398]]. Action = [[-0.03305889  0.04605905  0.          0.4388218 ]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 2276 is [True, False, False, False, False, True]
Current timestep = 2277. State = [[-0.33788875  0.24204612]]. Action = [[-0.01036134 -0.06538883  0.         -0.53306276]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 2277 is [True, False, False, False, False, True]
Current timestep = 2278. State = [[-0.336859    0.24123326]]. Action = [[0.05604554 0.02730016 0.         0.59412384]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 2278 is [True, False, False, False, False, True]
Current timestep = 2279. State = [[-0.33925557  0.23881026]]. Action = [[-0.06206317 -0.05847603  0.         -0.96148276]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 2279 is [True, False, False, False, False, True]
Current timestep = 2280. State = [[-0.3400425   0.23389749]]. Action = [[ 0.03651474 -0.06427637  0.         -0.3502559 ]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 2280 is [True, False, False, False, False, True]
State prediction error at timestep 2280 is 0.012
Human Feedback received at timestep 2280 of None
Current timestep = 2281. State = [[-0.3399078   0.22913623]]. Action = [[-0.00573517 -0.04963899  0.          0.7176914 ]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 2281 is [True, False, False, False, False, True]
Current timestep = 2282. State = [[-0.34526676  0.22738561]]. Action = [[-0.09826598  0.0015613   0.          0.5207255 ]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 2282 is [True, False, False, False, False, True]
Current timestep = 2283. State = [[-0.34701237  0.22366664]]. Action = [[ 0.0333399  -0.06962173  0.          0.24723577]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 2283 is [True, False, False, False, False, True]
Current timestep = 2284. State = [[-0.34739766  0.22187614]]. Action = [[-0.0153477   0.01804139  0.          0.85972583]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 2284 is [True, False, False, False, False, True]
State prediction error at timestep 2284 is 0.012
Human Feedback received at timestep 2284 of None
Current timestep = 2285. State = [[-0.34325007  0.21657208]]. Action = [[ 0.09877581 -0.09555823  0.         -0.8586029 ]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 2285 is [True, False, False, False, False, True]
Current timestep = 2286. State = [[-0.3370553   0.21450363]]. Action = [[ 0.06653913  0.04584988  0.         -0.29282844]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 2286 is [True, False, False, False, False, True]
Current timestep = 2287. State = [[-0.3394006   0.21627174]]. Action = [[-0.09294206  0.04281314  0.         -0.04683822]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 2287 is [True, False, False, False, False, True]
Current timestep = 2288. State = [[-0.34586832  0.2205678 ]]. Action = [[-0.07157394  0.08017635  0.         -0.3032838 ]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 2288 is [True, False, False, False, False, True]
Current timestep = 2289. State = [[-0.35200268  0.22425564]]. Action = [[-0.05998013  0.04003986  0.         -0.22781527]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 2289 is [True, False, False, False, False, True]
Current timestep = 2290. State = [[-0.35111767  0.22063048]]. Action = [[ 0.07649579 -0.09350207  0.          0.02441168]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 2290 is [True, False, False, False, False, True]
Current timestep = 2291. State = [[-0.3494305   0.22038451]]. Action = [[0.0047591  0.06250795 0.         0.6703582 ]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 2291 is [True, False, False, False, False, True]
Current timestep = 2292. State = [[-0.34646586  0.22399363]]. Action = [[0.06983127 0.05496725 0.         0.5641866 ]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 2292 is [True, False, False, False, False, True]
Current timestep = 2293. State = [[-0.34856322  0.22398266]]. Action = [[-0.07762267 -0.02940158  0.          0.09123755]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 2293 is [True, False, False, False, False, True]
Current timestep = 2294. State = [[-0.3497716   0.22053373]]. Action = [[ 0.03037029 -0.05556277  0.          0.30464077]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 2294 is [True, False, False, False, False, True]
Current timestep = 2295. State = [[-0.3484193   0.22276303]]. Action = [[0.02241232 0.08456574 0.         0.880244  ]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 2295 is [True, False, False, False, False, True]
Current timestep = 2296. State = [[-0.34819058  0.22174819]]. Action = [[-0.00240837 -0.06296054  0.          0.54886305]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 2296 is [True, False, False, False, False, True]
Current timestep = 2297. State = [[-0.34874648  0.22328325]]. Action = [[-0.00511412  0.06740902  0.          0.6565075 ]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 2297 is [True, False, False, False, False, True]
Current timestep = 2298. State = [[-0.34782287  0.22238639]]. Action = [[ 0.02696561 -0.05281019  0.         -0.20612621]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 2298 is [True, False, False, False, False, True]
Current timestep = 2299. State = [[-0.3481414   0.21657147]]. Action = [[-0.02641696 -0.09394173  0.          0.7254354 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 2299 is [True, False, False, False, False, True]
Current timestep = 2300. State = [[-0.3522592   0.21831447]]. Action = [[-0.07305241  0.08636021  0.         -0.56343734]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 2300 is [True, False, False, False, False, True]
Current timestep = 2301. State = [[-0.35712108  0.21643466]]. Action = [[-0.05046466 -0.09524062  0.         -0.94860715]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 2301 is [True, False, False, False, False, True]
State prediction error at timestep 2301 is 0.012
Human Feedback received at timestep 2301 of None
Current timestep = 2302. State = [[-0.35496342  0.20943776]]. Action = [[ 0.07714527 -0.0960577   0.          0.76327515]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 2302 is [True, False, False, False, False, True]
Current timestep = 2303. State = [[-0.34919307  0.20719287]]. Action = [[ 0.07070782  0.02616871  0.         -0.08575213]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 2303 is [True, False, False, False, False, True]
Current timestep = 2304. State = [[-0.35027716  0.21160756]]. Action = [[-0.06645343  0.09980627  0.         -0.25550914]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 2304 is [True, False, False, False, False, True]
Current timestep = 2305. State = [[-0.3571045  0.2156589]]. Action = [[-0.09348618  0.03294512  0.          0.82549095]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 2305 is [True, False, False, False, False, True]
State prediction error at timestep 2305 is 0.012
Human Feedback received at timestep 2305 of None
Current timestep = 2306. State = [[-0.356469    0.21536912]]. Action = [[ 0.08287837 -0.02445557  0.         -0.7340076 ]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 2306 is [True, False, False, False, False, True]
Current timestep = 2307. State = [[-0.3590492   0.21551469]]. Action = [[-0.08702638  0.02486233  0.          0.90922093]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 2307 is [True, False, False, False, False, True]
Current timestep = 2308. State = [[-0.36125502  0.21422282]]. Action = [[ 0.01666351 -0.04136099  0.          0.59108233]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 2308 is [True, False, False, False, False, True]
Current timestep = 2309. State = [[-0.36125582  0.21322277]]. Action = [[0.00369941 0.00367524 0.         0.43234515]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 2309 is [True, False, False, False, False, True]
Current timestep = 2310. State = [[-0.36558858  0.21259506]]. Action = [[-0.07985184 -0.01450821  0.         -0.4018578 ]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 2310 is [True, False, False, False, False, True]
Current timestep = 2311. State = [[-0.36383817  0.21333808]]. Action = [[0.0973038  0.02602721 0.         0.9175018 ]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 2311 is [True, False, False, False, False, True]
Current timestep = 2312. State = [[-0.35942498  0.21713896]]. Action = [[0.04218491 0.07381313 0.         0.5775633 ]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 2312 is [True, False, False, False, False, True]
Current timestep = 2313. State = [[-0.355023    0.22144453]]. Action = [[0.06392633 0.0562981  0.         0.25181973]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 2313 is [True, False, False, False, False, True]
Current timestep = 2314. State = [[-0.35416403  0.22142074]]. Action = [[-0.0271358  -0.03317375  0.          0.9624667 ]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 2314 is [True, False, False, False, False, True]
Current timestep = 2315. State = [[-0.35495403  0.22142036]]. Action = [[-0.00699009  0.01153319  0.          0.31357586]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 2315 is [True, False, False, False, False, True]
Current timestep = 2316. State = [[-0.3539202   0.22124387]]. Action = [[ 0.02074869 -0.01613846  0.          0.27028203]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 2316 is [True, False, False, False, False, True]
Current timestep = 2317. State = [[-0.35489312  0.2190836 ]]. Action = [[-0.04040482 -0.04482085  0.          0.7093508 ]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 2317 is [True, False, False, False, False, True]
Current timestep = 2318. State = [[-0.35648596  0.21630654]]. Action = [[-0.01960092 -0.04536472  0.         -0.54597336]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 2318 is [True, False, False, False, False, True]
State prediction error at timestep 2318 is 0.012
Human Feedback received at timestep 2318 of None
Current timestep = 2319. State = [[-0.3580266   0.21753077]]. Action = [[-0.02512838  0.04121558  0.          0.40857887]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 2319 is [True, False, False, False, False, True]
Current timestep = 2320. State = [[-0.35506728  0.22147259]]. Action = [[ 0.07600068  0.05689498  0.         -0.0902909 ]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 2320 is [True, False, False, False, False, True]
Current timestep = 2321. State = [[-0.34966817  0.21822679]]. Action = [[ 0.06092336 -0.09409198  0.         -0.956288  ]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 2321 is [True, False, False, False, False, True]
Current timestep = 2322. State = [[-0.34926718  0.21719083]]. Action = [[-0.04108746  0.03724103  0.         -0.31073022]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 2322 is [True, False, False, False, False, True]
Current timestep = 2323. State = [[-0.347404    0.21893413]]. Action = [[ 0.05433155  0.01886531  0.         -0.5636757 ]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 2323 is [True, False, False, False, False, True]
State prediction error at timestep 2323 is 0.012
Human Feedback received at timestep 2323 of None
Current timestep = 2324. State = [[-0.34552515  0.22246931]]. Action = [[ 0.00282794  0.06697469  0.         -0.7332104 ]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 2324 is [True, False, False, False, False, True]
Current timestep = 2325. State = [[-0.34075052  0.22794959]]. Action = [[0.09043626 0.0816962  0.         0.85945606]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 2325 is [True, False, False, False, False, True]
Current timestep = 2326. State = [[-0.33828855  0.23100364]]. Action = [[-0.01081508  0.0202715   0.          0.9154525 ]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 2326 is [True, False, False, False, False, True]
Current timestep = 2327. State = [[-0.33792835  0.23120007]]. Action = [[ 0.00157402 -0.0153629   0.         -0.02405816]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 2327 is [True, False, False, False, False, True]
Current timestep = 2328. State = [[-0.33551773  0.23543862]]. Action = [[0.03833845 0.08592691 0.         0.36813188]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 2328 is [True, False, False, False, False, True]
Current timestep = 2329. State = [[-0.3350782  0.2395341]]. Action = [[-0.02251694  0.02467199  0.          0.8946967 ]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 2329 is [True, False, False, False, False, True]
Current timestep = 2330. State = [[-0.33245853  0.2456088 ]]. Action = [[0.05751968 0.09260236 0.         0.01557839]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 2330 is [True, False, False, False, False, True]
State prediction error at timestep 2330 is 0.012
Human Feedback received at timestep 2330 of None
Current timestep = 2331. State = [[-0.33297202  0.25365132]]. Action = [[-0.04831669  0.09412663  0.         -0.47708952]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 2331 is [True, False, False, False, False, True]
Current timestep = 2332. State = [[-0.33629158  0.25978696]]. Action = [[-0.03994553  0.04025611  0.         -0.5783481 ]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 2332 is [True, False, False, False, False, True]
Current timestep = 2333. State = [[-0.34090757  0.25997642]]. Action = [[-0.06765082 -0.06593429  0.         -0.8676255 ]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 2333 is [True, False, False, False, False, True]
Current timestep = 2334. State = [[-0.34241873  0.26436123]]. Action = [[ 0.01874067  0.08309685  0.         -0.4082569 ]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 2334 is [True, False, False, False, False, True]
Current timestep = 2335. State = [[-0.34027186  0.26557514]]. Action = [[ 0.035416   -0.06497658  0.         -0.22705168]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 2335 is [True, False, False, False, False, True]
Current timestep = 2336. State = [[-0.33787665  0.2647028 ]]. Action = [[ 0.01846294 -0.02628643  0.         -0.51416993]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 2336 is [True, False, False, False, False, True]
Current timestep = 2337. State = [[-0.33602837  0.26408345]]. Action = [[ 0.01287749 -0.03345563  0.         -0.9002783 ]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 2337 is [True, False, False, False, False, True]
Current timestep = 2338. State = [[-0.337147    0.26759607]]. Action = [[-0.04259437  0.0603753   0.         -0.4977548 ]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 2338 is [True, False, False, False, False, True]
Current timestep = 2339. State = [[-0.33545774  0.26597214]]. Action = [[ 0.04990596 -0.09341368  0.         -0.92426467]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 2339 is [True, False, False, False, False, True]
Current timestep = 2340. State = [[-0.33429462  0.2632453 ]]. Action = [[-0.02115846 -0.02396329  0.         -0.43981493]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 2340 is [True, False, False, False, False, True]
Current timestep = 2341. State = [[-0.33496135  0.26669234]]. Action = [[-0.01425876  0.07380401  0.          0.70138836]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 2341 is [True, False, False, False, False, True]
Current timestep = 2342. State = [[-0.33171913  0.27270302]]. Action = [[ 0.07304008  0.08212043  0.         -0.80607766]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 2342 is [True, False, False, False, False, True]
State prediction error at timestep 2342 is 0.012
Human Feedback received at timestep 2342 of None
Current timestep = 2343. State = [[-0.3255302   0.27742133]]. Action = [[ 0.08086678  0.05910633  0.         -0.8053168 ]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 2343 is [True, False, False, False, False, True]
State prediction error at timestep 2343 is 0.012
Human Feedback received at timestep 2343 of None
Current timestep = 2344. State = [[-0.3207522   0.27919173]]. Action = [[ 0.03717662  0.00809582  0.         -0.79864454]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 2344 is [True, False, False, False, False, True]
Current timestep = 2345. State = [[-0.31482604  0.28235096]]. Action = [[0.08012735 0.06136293 0.         0.36159086]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 2345 is [True, False, False, False, False, True]
Current timestep = 2346. State = [[-0.3152325   0.28685972]]. Action = [[-0.073596    0.05516278  0.         -0.4256835 ]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 2346 is [True, False, False, False, False, True]
State prediction error at timestep 2346 is 0.012
Human Feedback received at timestep 2346 of None
Current timestep = 2347. State = [[-0.3194012   0.28502584]]. Action = [[-0.05995221 -0.09402306  0.          0.22681534]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 2347 is [True, False, False, False, False, True]
Current timestep = 2348. State = [[-0.31851527  0.2791903 ]]. Action = [[ 0.03823032 -0.09852887  0.         -0.1072644 ]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 2348 is [True, False, False, False, False, True]
State prediction error at timestep 2348 is 0.012
Human Feedback received at timestep 2348 of None
Current timestep = 2349. State = [[-0.31829515  0.2809939 ]]. Action = [[-0.03024271  0.08090889  0.          0.9980638 ]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 2349 is [True, False, False, False, False, True]
Current timestep = 2350. State = [[-0.31908244  0.2857495 ]]. Action = [[-0.00224464  0.04261672  0.          0.826308  ]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 2350 is [True, False, False, False, False, True]
Current timestep = 2351. State = [[-0.321127   0.2889817]]. Action = [[-0.0377613  0.0272759  0.        -0.9647839]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 2351 is [True, False, False, False, False, True]
State prediction error at timestep 2351 is 0.012
Human Feedback received at timestep 2351 of None
Current timestep = 2352. State = [[-0.31810492  0.29171705]]. Action = [[0.08750873 0.0292243  0.         0.21247113]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 2352 is [True, False, False, False, False, True]
Current timestep = 2353. State = [[-0.31606013  0.29268256]]. Action = [[-0.00876497 -0.00212985  0.         -0.11832917]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 2353 is [True, False, False, False, False, True]
Current timestep = 2354. State = [[-0.31118968  0.2962619 ]]. Action = [[0.09906807 0.07114483 0.         0.6701782 ]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 2354 is [True, False, False, False, False, True]
Current timestep = 2355. State = [[-0.30703315  0.29589924]]. Action = [[ 0.01346356 -0.0535861   0.          0.806762  ]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 2355 is [True, False, False, False, False, True]
Current timestep = 2356. State = [[-0.30837977  0.29885632]]. Action = [[-0.04915081  0.0818636   0.          0.4747938 ]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 2356 is [True, False, False, False, False, True]
Current timestep = 2357. State = [[-0.306645    0.30592257]]. Action = [[0.06169472 0.09400549 0.         0.9730718 ]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 2357 is [True, False, False, False, False, True]
Current timestep = 2358. State = [[-0.3041784   0.30514973]]. Action = [[ 0.00524668 -0.08387583  0.          0.8115201 ]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 2358 is [True, False, False, False, False, True]
Current timestep = 2359. State = [[-0.3020151   0.30448416]]. Action = [[ 0.03160543  0.02262847  0.         -0.34305614]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 2359 is [True, False, False, False, False, True]
State prediction error at timestep 2359 is 0.012
Human Feedback received at timestep 2359 of None
Current timestep = 2360. State = [[-0.29794222  0.3097152 ]]. Action = [[0.05775896 0.09639775 0.         0.5247146 ]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 2360 is [True, False, False, False, False, True]
Current timestep = 2361. State = [[-0.29681662  0.30927497]]. Action = [[-0.02668058 -0.07429716  0.          0.8307245 ]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 2361 is [True, False, False, False, False, True]
Current timestep = 2362. State = [[-0.30082816  0.31174693]]. Action = [[-0.07092889  0.08297082  0.         -0.4493041 ]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 2362 is [True, False, False, False, False, True]
Current timestep = 2363. State = [[-0.30763358  0.31502655]]. Action = [[-0.08703954  0.00982127  0.         -0.18475449]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 2363 is [True, False, False, False, False, True]
State prediction error at timestep 2363 is 0.012
Human Feedback received at timestep 2363 of None
Current timestep = 2364. State = [[-0.31234396  0.31631494]]. Action = [[-0.02764791 -0.00153889  0.         -0.5570759 ]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 2364 is [True, False, False, False, False, True]
Current timestep = 2365. State = [[-0.31704664  0.316493  ]]. Action = [[-0.05849793 -0.01765727  0.          0.69322205]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 2365 is [True, False, False, False, False, True]
State prediction error at timestep 2365 is 0.012
Human Feedback received at timestep 2365 of None
Current timestep = 2366. State = [[-0.31826156  0.31513247]]. Action = [[ 0.02883945 -0.03982197  0.         -0.844432  ]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 2366 is [True, False, False, False, False, True]
State prediction error at timestep 2366 is 0.012
Human Feedback received at timestep 2366 of None
Current timestep = 2367. State = [[-0.3196113   0.31910008]]. Action = [[-0.02366272  0.09225693  0.         -0.8611882 ]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 2367 is [True, False, False, False, False, True]
State prediction error at timestep 2367 is 0.012
Human Feedback received at timestep 2367 of None
Current timestep = 2368. State = [[-0.32055533  0.3262501 ]]. Action = [[0.02014063 0.09185966 0.         0.6071397 ]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 2368 is [True, False, False, False, False, True]
Current timestep = 2369. State = [[-0.32332313  0.32816917]]. Action = [[-0.04472286 -0.02417587  0.         -0.94164586]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 2369 is [True, False, False, False, False, True]
Current timestep = 2370. State = [[-0.32346314  0.32801184]]. Action = [[ 0.04452994 -0.00297095  0.          0.9962249 ]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 2370 is [True, False, False, False, False, True]
State prediction error at timestep 2370 is 0.012
Human Feedback received at timestep 2370 of None
Current timestep = 2371. State = [[-0.32162684  0.3273078 ]]. Action = [[ 0.02758519 -0.01825131  0.         -0.6632991 ]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 2371 is [True, False, False, False, False, True]
Current timestep = 2372. State = [[-0.3224054   0.32439932]]. Action = [[-0.02660791 -0.05845387  0.         -0.5220115 ]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 2372 is [True, False, False, False, False, True]
State prediction error at timestep 2372 is 0.012
Human Feedback received at timestep 2372 of None
Current timestep = 2373. State = [[-0.3204703   0.32146743]]. Action = [[ 0.05418826 -0.03702081  0.         -0.7863721 ]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 2373 is [True, False, False, False, False, True]
Current timestep = 2374. State = [[-0.32110208  0.31929126]]. Action = [[-0.0490205  -0.02631436  0.          0.3908074 ]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 2374 is [True, False, False, False, False, True]
Current timestep = 2375. State = [[-0.3239492  0.3231586]]. Action = [[-0.03148053  0.09281626  0.         -0.31398165]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 2375 is [True, False, False, False, False, True]
State prediction error at timestep 2375 is 0.012
Human Feedback received at timestep 2375 of None
Current timestep = 2376. State = [[-0.32602522  0.32189652]]. Action = [[-0.02006339 -0.08233061  0.          0.25026262]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 2376 is [True, False, False, False, False, True]
Current timestep = 2377. State = [[-0.32359824  0.3237461 ]]. Action = [[0.07068857 0.09312227 0.         0.46287155]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 2377 is [True, False, False, False, False, True]
State prediction error at timestep 2377 is 0.012
Human Feedback received at timestep 2377 of None
Current timestep = 2378. State = [[-0.31979954  0.32941958]]. Action = [[ 0.03509993  0.07545965  0.         -0.14438248]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 2378 is [True, False, False, False, False, True]
Current timestep = 2379. State = [[-0.32219526  0.33092374]]. Action = [[-0.07828412 -0.01901539  0.          0.8158958 ]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 2379 is [True, False, False, False, False, True]
Current timestep = 2380. State = [[-0.32052556  0.3292121 ]]. Action = [[ 0.07726573 -0.03390508  0.          0.6683686 ]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 2380 is [True, False, False, False, False, True]
Current timestep = 2381. State = [[-0.31754714  0.3249459 ]]. Action = [[ 0.0103392  -0.07095452  0.         -0.8518116 ]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 2381 is [True, False, False, False, False, True]
State prediction error at timestep 2381 is 0.012
Human Feedback received at timestep 2381 of None
Current timestep = 2382. State = [[-0.31854105  0.32055   ]]. Action = [[-0.04171988 -0.05806378  0.         -0.24271488]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 2382 is [True, False, False, False, False, True]
Current timestep = 2383. State = [[-0.3240234  0.3168874]]. Action = [[-0.09825765 -0.05424082  0.          0.46485102]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 2383 is [True, False, False, False, False, True]
Current timestep = 2384. State = [[-0.33081996  0.31780395]]. Action = [[-0.07839448  0.03814051  0.          0.93056357]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 2384 is [True, False, False, False, False, True]
State prediction error at timestep 2384 is 0.012
Human Feedback received at timestep 2384 of None
Current timestep = 2385. State = [[-0.3380704   0.32309386]]. Action = [[-0.0791234   0.08379922  0.          0.55188465]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 2385 is [True, False, False, False, False, True]
State prediction error at timestep 2385 is 0.012
Human Feedback received at timestep 2385 of None
Current timestep = 2386. State = [[-0.34035563  0.32125816]]. Action = [[ 0.03047008 -0.08818117  0.         -0.33770943]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 2386 is [True, False, False, False, False, True]
Current timestep = 2387. State = [[-0.3456824   0.32309178]]. Action = [[-0.09881979  0.09004798  0.          0.64115834]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 2387 is [True, False, False, False, False, True]
State prediction error at timestep 2387 is 0.012
Human Feedback received at timestep 2387 of None
Current timestep = 2388. State = [[-0.3458666   0.32218698]]. Action = [[ 0.09055009 -0.06761882  0.          0.60220385]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 2388 is [True, False, False, False, False, True]
Current timestep = 2389. State = [[-0.3436664   0.32302943]]. Action = [[ 0.01943702  0.066636    0.         -0.5176612 ]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 2389 is [True, False, False, False, False, True]
Current timestep = 2390. State = [[-0.34324276  0.32475767]]. Action = [[ 0.01590558  0.0165005   0.         -0.09305209]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 2390 is [True, False, False, False, False, True]
Current timestep = 2391. State = [[-0.3394421  0.3242122]]. Action = [[ 0.08075515 -0.00677566  0.          0.5170171 ]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 2391 is [True, False, False, False, False, True]
Current timestep = 2392. State = [[-0.33836105  0.32246217]]. Action = [[-0.02187475 -0.01918668  0.         -0.48815215]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 2392 is [True, False, False, False, False, True]
Current timestep = 2393. State = [[-0.34084165  0.32217687]]. Action = [[-0.03899578  0.0088925   0.          0.05336082]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 2393 is [True, False, False, False, False, True]
Current timestep = 2394. State = [[-0.34417585  0.3241234 ]]. Action = [[-0.04015666  0.03524367  0.          0.5789099 ]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 2394 is [True, False, False, False, False, True]
Current timestep = 2395. State = [[-0.3466518   0.32054666]]. Action = [[-0.02053104 -0.09983037  0.          0.64217937]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 2395 is [True, False, False, False, False, True]
Current timestep = 2396. State = [[-0.34401792  0.31546366]]. Action = [[ 0.06664365 -0.05443355  0.         -0.09744024]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 2396 is [True, False, False, False, False, True]
Current timestep = 2397. State = [[-0.34085235  0.30977902]]. Action = [[ 0.01817662 -0.07881986  0.          0.91097915]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 2397 is [True, False, False, False, False, True]
Current timestep = 2398. State = [[-0.34261093  0.30526242]]. Action = [[-0.05940844 -0.04304423  0.          0.93664956]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 2398 is [True, False, False, False, False, True]
Current timestep = 2399. State = [[-0.3456937   0.30378005]]. Action = [[-0.03380673  0.00111623  0.         -0.5151357 ]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 2399 is [True, False, False, False, False, True]
Current timestep = 2400. State = [[-0.34637633  0.30053154]]. Action = [[ 0.0073873  -0.05488168  0.         -0.9280269 ]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 2400 is [True, False, False, False, False, True]
Current timestep = 2401. State = [[-0.3423254   0.29969877]]. Action = [[0.07901739 0.0370153  0.         0.84771323]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 2401 is [True, False, False, False, False, True]
Current timestep = 2402. State = [[-0.3379176   0.30305636]]. Action = [[ 0.04245063  0.08609187  0.         -0.5855863 ]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 2402 is [True, False, False, False, False, True]
Current timestep = 2403. State = [[-0.33723685  0.30085889]]. Action = [[-0.02015957 -0.07031938  0.          0.25223148]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 2403 is [True, False, False, False, False, True]
Current timestep = 2404. State = [[-0.34157133  0.2955275 ]]. Action = [[-0.076619   -0.05352629  0.         -0.68146443]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 2404 is [True, False, False, False, False, True]
State prediction error at timestep 2404 is 0.012
Human Feedback received at timestep 2404 of None
Current timestep = 2405. State = [[-0.3423552   0.29182437]]. Action = [[ 0.03472339 -0.02801389  0.          0.01447785]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 2405 is [True, False, False, False, False, True]
State prediction error at timestep 2405 is 0.012
Human Feedback received at timestep 2405 of None
Current timestep = 2406. State = [[-0.34530938  0.2854864 ]]. Action = [[-0.0741579 -0.096813   0.         0.726493 ]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 2406 is [True, False, False, False, False, True]
State prediction error at timestep 2406 is 0.012
Human Feedback received at timestep 2406 of None
Current timestep = 2407. State = [[-0.34526974  0.28253272]]. Action = [[0.05347805 0.01746289 0.         0.21035254]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 2407 is [True, False, False, False, False, True]
Current timestep = 2408. State = [[-0.3395264   0.28455776]]. Action = [[0.09210413 0.06628018 0.         0.8668808 ]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 2408 is [True, False, False, False, False, True]
State prediction error at timestep 2408 is 0.012
Human Feedback received at timestep 2408 of None
Current timestep = 2409. State = [[-0.34173682  0.28928787]]. Action = [[-0.09635673  0.09398451  0.          0.9897475 ]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 2409 is [True, False, False, False, False, True]
Current timestep = 2410. State = [[-0.34343454  0.29360467]]. Action = [[ 0.03088256  0.05306634  0.         -0.5279586 ]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 2410 is [True, False, False, False, False, True]
Current timestep = 2411. State = [[-0.338488    0.29248318]]. Action = [[ 0.09361983 -0.03748996  0.          0.72778773]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 2411 is [True, False, False, False, False, True]
Current timestep = 2412. State = [[-0.3359814  0.2877835]]. Action = [[-0.00761814 -0.06612498  0.          0.17423868]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 2412 is [True, False, False, False, False, True]
State prediction error at timestep 2412 is 0.012
Human Feedback received at timestep 2412 of None
Current timestep = 2413. State = [[-0.33660775  0.2829699 ]]. Action = [[-0.0205195  -0.06279632  0.         -0.72144675]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 2413 is [True, False, False, False, False, True]
Current timestep = 2414. State = [[-0.33368227  0.2833255 ]]. Action = [[ 0.06364106  0.04860672  0.         -0.25697386]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 2414 is [True, False, False, False, False, True]
State prediction error at timestep 2414 is 0.012
Human Feedback received at timestep 2414 of None
Current timestep = 2415. State = [[-0.33613896  0.28709316]]. Action = [[-0.09692566  0.05414226  0.         -0.60349345]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 2415 is [True, False, False, False, False, True]
Current timestep = 2416. State = [[-0.33789468  0.2933888 ]]. Action = [[ 0.01876901  0.09368908  0.         -0.9196693 ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 2416 is [True, False, False, False, False, True]
Current timestep = 2417. State = [[-0.33284175  0.29784206]]. Action = [[ 0.09707861  0.03981548  0.         -0.02761453]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 2417 is [True, False, False, False, False, True]
Current timestep = 2418. State = [[-0.33145136  0.29506546]]. Action = [[-0.04052776 -0.09335016  0.         -0.17537403]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 2418 is [True, False, False, False, False, True]
Current timestep = 2419. State = [[-0.3327615  0.2902187]]. Action = [[-0.01042999 -0.05941982  0.         -0.97794604]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 2419 is [True, False, False, False, False, True]
Current timestep = 2420. State = [[-0.33644608  0.2885527 ]]. Action = [[-0.06893839 -0.00796469  0.          0.6896211 ]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 2420 is [True, False, False, False, False, True]
Current timestep = 2421. State = [[-0.34047312  0.2904485 ]]. Action = [[-0.03501669  0.03657534  0.          0.5412648 ]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 2421 is [True, False, False, False, False, True]
State prediction error at timestep 2421 is 0.012
Human Feedback received at timestep 2421 of None
Current timestep = 2422. State = [[-0.3423998  0.2934492]]. Action = [[-0.00392473  0.03766138  0.         -0.6353849 ]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 2422 is [True, False, False, False, False, True]
Current timestep = 2423. State = [[-0.34436023  0.2989937 ]]. Action = [[-0.01836281  0.09282362  0.          0.8649193 ]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 2423 is [True, False, False, False, False, True]
Current timestep = 2424. State = [[-0.34381914  0.30184385]]. Action = [[ 0.04234061  0.00768711  0.         -0.84886336]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 2424 is [True, False, False, False, False, True]
State prediction error at timestep 2424 is 0.012
Human Feedback received at timestep 2424 of None
Current timestep = 2425. State = [[-0.33960462  0.30400816]]. Action = [[ 0.07508499  0.04080915  0.         -0.11141467]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 2425 is [True, False, False, False, False, True]
Current timestep = 2426. State = [[-0.33982518  0.30465436]]. Action = [[-0.04330294 -0.01155502  0.         -0.26961815]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 2426 is [True, False, False, False, False, True]
State prediction error at timestep 2426 is 0.012
Human Feedback received at timestep 2426 of None
Current timestep = 2427. State = [[-0.34084505  0.30414128]]. Action = [[ 0.00790105 -0.01544893  0.          0.56721187]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 2427 is [True, False, False, False, False, True]
State prediction error at timestep 2427 is 0.012
Human Feedback received at timestep 2427 of None
Current timestep = 2428. State = [[-0.3366006   0.30409333]]. Action = [[8.3300374e-02 6.6073984e-04 0.0000000e+00 7.1810162e-01]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 2428 is [True, False, False, False, False, True]
Current timestep = 2429. State = [[-0.32950246  0.2993722 ]]. Action = [[ 0.08405294 -0.09796874  0.         -0.12211442]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 2429 is [True, False, False, False, False, True]
Current timestep = 2430. State = [[-0.32434183  0.29327795]]. Action = [[ 0.02794635 -0.07208474  0.         -0.407161  ]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 2430 is [True, False, False, False, False, True]
Current timestep = 2431. State = [[-0.3265967   0.29290715]]. Action = [[-0.0941916   0.03326016  0.         -0.65003383]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 2431 is [True, False, False, False, False, True]
Current timestep = 2432. State = [[-0.33152825  0.2952854 ]]. Action = [[-0.06335131  0.02354332  0.          0.12915635]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 2432 is [True, False, False, False, False, True]
Current timestep = 2433. State = [[-0.3292767   0.29821178]]. Action = [[ 0.0802226   0.04660242  0.         -0.01466256]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 2433 is [True, False, False, False, False, True]
Current timestep = 2434. State = [[-0.32241905  0.30092132]]. Action = [[ 0.08820087  0.0426931   0.         -0.8985079 ]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 2434 is [True, False, False, False, False, True]
Current timestep = 2435. State = [[-0.32172137  0.30309135]]. Action = [[-0.0499846   0.03014172  0.         -0.98121554]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 2435 is [True, False, False, False, False, True]
Current timestep = 2436. State = [[-0.31897292  0.30594876]]. Action = [[ 0.07475441  0.04369933  0.         -0.40803063]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 2436 is [True, False, False, False, False, True]
State prediction error at timestep 2436 is 0.012
Human Feedback received at timestep 2436 of None
Current timestep = 2437. State = [[-0.31394354  0.30801597]]. Action = [[ 0.04942719  0.02264275  0.         -0.21383548]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 2437 is [True, False, False, False, False, True]
State prediction error at timestep 2437 is 0.012
Human Feedback received at timestep 2437 of None
Current timestep = 2438. State = [[-0.30876577  0.31076166]]. Action = [[0.0591371  0.04530384 0.         0.23667109]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 2438 is [True, False, False, False, False, True]
Current timestep = 2439. State = [[-0.302521   0.3078952]]. Action = [[ 0.06878012 -0.08642062  0.         -0.09240472]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 2439 is [True, False, False, False, False, True]
Current timestep = 2440. State = [[-0.29814327  0.30281124]]. Action = [[ 0.0143939  -0.06474736  0.          0.6562693 ]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 2440 is [True, False, False, False, False, True]
Current timestep = 2441. State = [[-0.29705948  0.29996413]]. Action = [[-0.02508    -0.03056893  0.         -0.19696194]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 2441 is [True, False, False, False, False, True]
Current timestep = 2442. State = [[-0.29874003  0.29803145]]. Action = [[-0.05410562 -0.03345121  0.         -0.7522435 ]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 2442 is [True, False, False, False, False, True]
State prediction error at timestep 2442 is 0.012
Human Feedback received at timestep 2442 of None
Current timestep = 2443. State = [[-0.30066574  0.29479596]]. Action = [[-0.0351271  -0.0612717   0.         -0.12690389]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 2443 is [True, False, False, False, False, True]
Current timestep = 2444. State = [[-0.30217764  0.2981137 ]]. Action = [[-0.02395932  0.09769472  0.         -0.75348806]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 2444 is [True, False, False, False, False, True]
Current timestep = 2445. State = [[-0.298638   0.3033105]]. Action = [[ 0.0826213   0.05586606  0.         -0.53446203]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 2445 is [True, False, False, False, False, True]
Current timestep = 2446. State = [[-0.29687393  0.3010352 ]]. Action = [[-0.02322802 -0.08261093  0.          0.22086906]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 2446 is [True, False, False, False, False, True]
Current timestep = 2447. State = [[-0.29265535  0.295423  ]]. Action = [[ 0.08872321 -0.06441405  0.          0.4907186 ]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 2447 is [True, False, False, False, False, True]
State prediction error at timestep 2447 is 0.012
Human Feedback received at timestep 2447 of None
Current timestep = 2448. State = [[-0.28588086  0.29340407]]. Action = [[0.07455143 0.0164033  0.         0.15181231]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 2448 is [True, False, False, False, False, True]
State prediction error at timestep 2448 is 0.012
Human Feedback received at timestep 2448 of None
Current timestep = 2449. State = [[-0.28000155  0.29479   ]]. Action = [[0.058637   0.04842953 0.         0.200647  ]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 2449 is [True, False, False, False, False, True]
Current timestep = 2450. State = [[-0.27577105  0.29617712]]. Action = [[0.03307014 0.02791754 0.         0.54398346]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 2450 is [True, False, False, False, False, True]
Current timestep = 2451. State = [[-0.27637738  0.29386175]]. Action = [[-0.05474153 -0.05056291  0.         -0.6032784 ]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 2451 is [True, False, False, False, False, True]
Current timestep = 2452. State = [[-0.27903548  0.28825107]]. Action = [[-0.04393078 -0.08603159  0.         -0.45633996]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 2452 is [True, False, False, False, False, True]
Current timestep = 2453. State = [[-0.28159523  0.28521436]]. Action = [[-0.0412521  -0.01370853  0.         -0.9109053 ]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 2453 is [True, False, False, False, False, True]
State prediction error at timestep 2453 is 0.012
Human Feedback received at timestep 2453 of None
Current timestep = 2454. State = [[-0.28576392  0.28810492]]. Action = [[-0.06298713  0.07148411  0.          0.60763645]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 2454 is [True, False, False, False, False, True]
Current timestep = 2455. State = [[-0.290377    0.28989398]]. Action = [[-0.04604477 -0.00238461  0.         -0.4428718 ]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 2455 is [True, False, False, False, False, True]
Current timestep = 2456. State = [[-0.29640326  0.2913874 ]]. Action = [[-0.07665905  0.02640929  0.          0.7422123 ]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 2456 is [True, False, False, False, False, True]
Current timestep = 2457. State = [[-0.29689494  0.29252172]]. Action = [[0.06045704 0.00564126 0.         0.21503532]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 2457 is [True, False, False, False, False, True]
State prediction error at timestep 2457 is 0.012
Human Feedback received at timestep 2457 of None
Current timestep = 2458. State = [[-0.3005589   0.28897998]]. Action = [[-0.08904598 -0.08182979  0.          0.9315195 ]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 2458 is [True, False, False, False, False, True]
Current timestep = 2459. State = [[-0.30868196  0.29082888]]. Action = [[-0.08428339  0.08240848  0.          0.11611247]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 2459 is [True, False, False, False, False, True]
Current timestep = 2460. State = [[-0.31609058  0.2900782 ]]. Action = [[-0.05937393 -0.06294863  0.          0.1907047 ]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 2460 is [True, False, False, False, False, True]
Current timestep = 2461. State = [[-0.32144287  0.28636837]]. Action = [[-0.03360721 -0.04798552  0.         -0.51455176]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 2461 is [True, False, False, False, False, True]
Current timestep = 2462. State = [[-0.32222438  0.2860392 ]]. Action = [[0.04346342 0.02674108 0.         0.34980893]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 2462 is [True, False, False, False, False, True]
Current timestep = 2463. State = [[-0.32558137  0.28511098]]. Action = [[-0.05889683 -0.02140493  0.          0.01640713]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 2463 is [True, False, False, False, False, True]
Current timestep = 2464. State = [[-0.3257693   0.28571412]]. Action = [[0.06163125 0.03778655 0.         0.69222116]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 2464 is [True, False, False, False, False, True]
Current timestep = 2465. State = [[-0.3242336   0.28290185]]. Action = [[ 0.02045666 -0.05971645  0.          0.2591853 ]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 2465 is [True, False, False, False, False, True]
Current timestep = 2466. State = [[-0.3219939  0.282384 ]]. Action = [[0.04658171 0.04200033 0.         0.85855854]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 2466 is [True, False, False, False, False, True]
Current timestep = 2467. State = [[-0.32565472  0.2860963 ]]. Action = [[-0.08845646  0.07389956  0.         -0.491754  ]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 2467 is [True, False, False, False, False, True]
Current timestep = 2468. State = [[-0.32835612  0.28537488]]. Action = [[ 0.01071535 -0.04959334  0.         -0.57937807]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 2468 is [True, False, False, False, False, True]
State prediction error at timestep 2468 is 0.012
Human Feedback received at timestep 2468 of None
Current timestep = 2469. State = [[-0.3253411  0.2802363]]. Action = [[ 0.0650868  -0.07211231  0.         -0.810282  ]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 2469 is [True, False, False, False, False, True]
Current timestep = 2470. State = [[-0.32364976  0.28124267]]. Action = [[-0.00267693  0.07686727  0.          0.8029479 ]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 2470 is [True, False, False, False, False, True]
Current timestep = 2471. State = [[-0.32746795  0.2788607 ]]. Action = [[-0.0794424  -0.08958604  0.          0.76806307]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 2471 is [True, False, False, False, False, True]
Current timestep = 2472. State = [[-0.32773325  0.27754545]]. Action = [[ 0.05288374  0.03304908  0.         -0.12055641]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 2472 is [True, False, False, False, False, True]
Current timestep = 2473. State = [[-0.32640818  0.2824453 ]]. Action = [[ 0.00558335  0.09883272  0.         -0.4527114 ]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 2473 is [True, False, False, False, False, True]
Current timestep = 2474. State = [[-0.32534584  0.2847516 ]]. Action = [[ 0.02356808  0.00342873  0.         -0.2919948 ]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 2474 is [True, False, False, False, False, True]
State prediction error at timestep 2474 is 0.012
Human Feedback received at timestep 2474 of None
Current timestep = 2475. State = [[-0.32940888  0.2867974 ]]. Action = [[-0.09200524  0.03989174  0.          0.5029223 ]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 2475 is [True, False, False, False, False, True]
State prediction error at timestep 2475 is 0.012
Human Feedback received at timestep 2475 of None
Current timestep = 2476. State = [[-0.3275661   0.28535515]]. Action = [[ 0.09672358 -0.05836543  0.         -0.958554  ]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 2476 is [True, False, False, False, False, True]
State prediction error at timestep 2476 is 0.012
Human Feedback received at timestep 2476 of None
Current timestep = 2477. State = [[-0.32870668  0.28165716]]. Action = [[-0.07933022 -0.04838019  0.          0.55005765]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 2477 is [True, False, False, False, False, True]
State prediction error at timestep 2477 is 0.012
Human Feedback received at timestep 2477 of None
Current timestep = 2478. State = [[-0.33337465  0.2799256 ]]. Action = [[-0.05155972 -0.02093682  0.          0.09132564]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 2478 is [True, False, False, False, False, True]
State prediction error at timestep 2478 is 0.012
Human Feedback received at timestep 2478 of None
Current timestep = 2479. State = [[-0.33489817  0.28208905]]. Action = [[0.00832991 0.04906368 0.         0.82477355]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 2479 is [True, False, False, False, False, True]
Current timestep = 2480. State = [[-0.33044827  0.286189  ]]. Action = [[0.09729066 0.0619325  0.         0.81440556]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 2480 is [True, False, False, False, False, True]
Current timestep = 2481. State = [[-0.32518664  0.2916653 ]]. Action = [[0.05583026 0.09197094 0.         0.5779135 ]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 2481 is [True, False, False, False, False, True]
Current timestep = 2482. State = [[-0.3263022   0.29310444]]. Action = [[-0.06192089 -0.0237646   0.          0.12937653]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 2482 is [True, False, False, False, False, True]
Current timestep = 2483. State = [[-0.32410553  0.29165682]]. Action = [[ 0.08154116 -0.0190332   0.          0.6552421 ]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 2483 is [True, False, False, False, False, True]
Current timestep = 2484. State = [[-0.3166338   0.28632167]]. Action = [[ 0.09971523 -0.09196444  0.         -0.51828533]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 2484 is [True, False, False, False, False, True]
Current timestep = 2485. State = [[-0.3096426   0.27910152]]. Action = [[ 0.05987772 -0.08882756  0.         -0.00424856]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 2485 is [True, False, False, False, False, True]
Current timestep = 2486. State = [[-0.3075683   0.27855745]]. Action = [[-0.02510224  0.05111388  0.          0.61279464]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 2486 is [True, False, False, False, False, True]
Current timestep = 2487. State = [[-0.3049049  0.2815801]]. Action = [[ 0.04308525  0.04718003  0.         -0.8316215 ]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 2487 is [True, False, False, False, False, True]
Current timestep = 2488. State = [[-0.30464065  0.2852764 ]]. Action = [[-0.03954075  0.06048977  0.         -0.15047985]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 2488 is [True, False, False, False, False, True]
Current timestep = 2489. State = [[-0.30202714  0.28933358]]. Action = [[ 0.05962534  0.05615336  0.         -0.02655429]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 2489 is [True, False, False, False, False, True]
State prediction error at timestep 2489 is 0.012
Human Feedback received at timestep 2489 of None
Current timestep = 2490. State = [[-0.3047189   0.29465884]]. Action = [[-0.09909264  0.08023757  0.          0.6685997 ]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 2490 is [True, False, False, False, False, True]
Current timestep = 2491. State = [[-0.30509788  0.30014828]]. Action = [[ 0.0470944   0.05854041  0.         -0.79400724]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 2491 is [True, False, False, False, False, True]
Current timestep = 2492. State = [[-0.30837673  0.30330613]]. Action = [[-0.08865359  0.01597068  0.          0.27245915]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 2492 is [True, False, False, False, False, True]
Current timestep = 2493. State = [[-0.31273708  0.30404305]]. Action = [[-0.02895342 -0.02138888  0.          0.41795206]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 2493 is [True, False, False, False, False, True]
Current timestep = 2494. State = [[-0.31585607  0.30300322]]. Action = [[-0.0331724  -0.04114395  0.          0.5495231 ]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 2494 is [True, False, False, False, False, True]
Current timestep = 2495. State = [[-0.31253576  0.30055124]]. Action = [[ 0.09606998 -0.05346805  0.          0.40560603]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 2495 is [True, False, False, False, False, True]
State prediction error at timestep 2495 is 0.012
Human Feedback received at timestep 2495 of None
Current timestep = 2496. State = [[-0.30870223  0.29741988]]. Action = [[ 0.02229376 -0.04723297  0.          0.06957185]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 2496 is [True, False, False, False, False, True]
Current timestep = 2497. State = [[-0.30916592  0.29355592]]. Action = [[-0.03367813 -0.06572083  0.         -0.53409684]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 2497 is [True, False, False, False, False, True]
State prediction error at timestep 2497 is 0.012
Human Feedback received at timestep 2497 of None
Current timestep = 2498. State = [[-0.3060969   0.29427353]]. Action = [[0.07494538 0.04984338 0.         0.37210405]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 2498 is [True, False, False, False, False, True]
Current timestep = 2499. State = [[-0.3026879  0.2978245]]. Action = [[ 0.01387092  0.04992727  0.         -0.5771678 ]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 2499 is [True, False, False, False, False, True]
Current timestep = 2500. State = [[-0.30267307  0.29892325]]. Action = [[-0.02297712 -0.0067632   0.         -0.26800203]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 2500 is [True, False, False, False, False, True]
Current timestep = 2501. State = [[-0.29949722  0.30241764]]. Action = [[ 0.06736407  0.07585163  0.         -0.5362177 ]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 2501 is [True, False, False, False, False, True]
Current timestep = 2502. State = [[-0.29338878  0.30306736]]. Action = [[ 0.07183232 -0.02349694  0.          0.7064636 ]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 2502 is [True, False, False, False, False, True]
Current timestep = 2503. State = [[-0.28787586  0.3006068 ]]. Action = [[ 0.04529814 -0.03550876  0.          0.72235894]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 2503 is [True, False, False, False, False, True]
Current timestep = 2504. State = [[-0.28516647  0.3002724 ]]. Action = [[-0.00075436  0.0150954   0.         -0.02136475]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 2504 is [True, False, False, False, False, True]
Current timestep = 2505. State = [[-0.28036588  0.30420703]]. Action = [[0.07223295 0.07757183 0.         0.55881953]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 2505 is [True, False, False, False, False, True]
Current timestep = 2506. State = [[-0.2791492  0.3081113]]. Action = [[-0.03994068  0.03973765  0.          0.94584346]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 2506 is [True, False, False, False, False, True]
Current timestep = 2507. State = [[-0.28072685  0.3056074 ]]. Action = [[-0.0328664  -0.08841161  0.         -0.7322469 ]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 2507 is [True, False, False, False, False, True]
Current timestep = 2508. State = [[-0.28415096  0.3083553 ]]. Action = [[-0.06575899  0.08709728  0.          0.08922732]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 2508 is [True, False, False, False, False, True]
Current timestep = 2509. State = [[-0.2852973  0.3128417]]. Action = [[ 0.01324879  0.02728396  0.         -0.5005284 ]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 2509 is [True, False, False, False, False, True]
State prediction error at timestep 2509 is 0.012
Human Feedback received at timestep 2509 of None
Current timestep = 2510. State = [[-0.28683755  0.31268454]]. Action = [[-0.03762193 -0.03930878  0.          0.11264396]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 2510 is [True, False, False, False, False, True]
Current timestep = 2511. State = [[-0.2840894   0.31097943]]. Action = [[ 0.07545707 -0.03228705  0.         -0.26627207]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 2511 is [True, False, False, False, False, True]
Current timestep = 2512. State = [[-0.2784418  0.3133975]]. Action = [[0.06814118 0.06413461 0.         0.6473894 ]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 2512 is [True, False, False, False, False, True]
Current timestep = 2513. State = [[-0.27628392  0.31739014]]. Action = [[-0.00269742  0.04754543  0.         -0.27137804]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 2513 is [True, False, False, False, False, True]
Current timestep = 2514. State = [[-0.27469817  0.31543437]]. Action = [[ 0.02324804 -0.07562295  0.         -0.65067637]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 2514 is [True, False, False, False, False, True]
Current timestep = 2515. State = [[-0.27767873  0.3112586 ]]. Action = [[-0.09053507 -0.06111649  0.         -0.90296096]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 2515 is [True, False, False, False, False, True]
Current timestep = 2516. State = [[-0.28297636  0.30647022]]. Action = [[-0.07104401 -0.08812059  0.          0.26077783]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 2516 is [True, False, False, False, False, True]
State prediction error at timestep 2516 is 0.012
Human Feedback received at timestep 2516 of None
Current timestep = 2517. State = [[-0.2887738  0.3025159]]. Action = [[-0.08172693 -0.05365809  0.          0.00019622]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 2517 is [True, False, False, False, False, True]
Current timestep = 2518. State = [[-0.29120088  0.30098593]]. Action = [[ 0.00307196 -0.01179592  0.         -0.6565775 ]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 2518 is [True, False, False, False, False, True]
Current timestep = 2519. State = [[-0.28801885  0.29822043]]. Action = [[ 0.07182088 -0.04489848  0.          0.9515178 ]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 2519 is [True, False, False, False, False, True]
Current timestep = 2520. State = [[-0.28518122  0.29449058]]. Action = [[ 0.01751642 -0.03354778  0.         -0.6092942 ]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 2520 is [True, False, False, False, False, True]
Current timestep = 2521. State = [[-0.28139654  0.29407296]]. Action = [[ 0.06464966  0.03744145  0.         -0.6941138 ]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 2521 is [True, False, False, False, False, True]
Current timestep = 2522. State = [[-0.2745605   0.28939578]]. Action = [[ 0.09766505 -0.08002679  0.         -0.2172162 ]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 2522 is [True, False, False, False, False, True]
Current timestep = 2523. State = [[-0.26784417  0.28198925]]. Action = [[ 0.06134438 -0.06935532  0.         -0.03076357]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 2523 is [True, False, False, False, False, True]
State prediction error at timestep 2523 is 0.012
Human Feedback received at timestep 2523 of None
Current timestep = 2524. State = [[-0.26890704  0.27821183]]. Action = [[-0.08352374 -0.00159074  0.          0.37601972]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 2524 is [True, False, False, False, False, True]
Current timestep = 2525. State = [[-0.27110237  0.27383462]]. Action = [[-0.01608428 -0.06289852  0.          0.6577717 ]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 2525 is [True, False, False, False, False, True]
State prediction error at timestep 2525 is 0.012
Human Feedback received at timestep 2525 of None
Current timestep = 2526. State = [[-0.27327162  0.2682157 ]]. Action = [[-0.04605728 -0.05620641  0.          0.19644606]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 2526 is [True, False, False, False, False, True]
Current timestep = 2527. State = [[-0.2692974   0.26168442]]. Action = [[ 0.09660821 -0.0718448   0.          0.40642428]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 2527 is [True, False, False, False, False, True]
State prediction error at timestep 2527 is 0.012
Human Feedback received at timestep 2527 of None
Current timestep = 2528. State = [[-0.270385    0.25660148]]. Action = [[-0.09032939 -0.02654378  0.          0.15026045]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 2528 is [True, False, False, False, False, True]
Current timestep = 2529. State = [[-0.2739913   0.25914252]]. Action = [[-0.02276158  0.0996205   0.         -0.02858669]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 2529 is [True, False, False, False, False, True]
Current timestep = 2530. State = [[-0.27208307  0.25759685]]. Action = [[ 0.06298012 -0.05705231  0.          0.03777456]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 2530 is [True, False, False, False, False, True]
Current timestep = 2531. State = [[-0.2654741   0.25001216]]. Action = [[ 0.09857438 -0.09036615  0.         -0.4335091 ]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 2531 is [True, False, False, False, False, True]
Current timestep = 2532. State = [[-0.26025197  0.24383035]]. Action = [[ 0.03669675 -0.03517904  0.          0.7084638 ]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 2532 is [True, False, False, False, False, True]
Current timestep = 2533. State = [[-0.25794652  0.24534728]]. Action = [[ 0.01144709  0.09231686  0.         -0.5575656 ]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 2533 is [True, False, False, False, False, True]
Current timestep = 2534. State = [[-0.26159084  0.24802925]]. Action = [[-0.0869782   0.03379255  0.         -0.7527542 ]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 2534 is [True, False, False, False, False, True]
Current timestep = 2535. State = [[-0.26288435  0.25074223]]. Action = [[ 0.02824966  0.05416553  0.         -0.802934  ]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 2535 is [True, False, False, False, False, True]
Current timestep = 2536. State = [[-0.25896624  0.25443235]]. Action = [[0.07574569 0.06689285 0.         0.6036782 ]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 2536 is [True, False, False, False, False, True]
State prediction error at timestep 2536 is 0.012
Human Feedback received at timestep 2536 of None
Current timestep = 2537. State = [[-0.2545964   0.25648248]]. Action = [[0.05110849 0.024142   0.         0.7198541 ]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 2537 is [True, False, False, False, False, True]
State prediction error at timestep 2537 is 0.012
Human Feedback received at timestep 2537 of None
Current timestep = 2538. State = [[-0.25686917  0.25991088]]. Action = [[-0.07560706  0.06336381  0.         -0.9550939 ]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 2538 is [True, False, False, False, False, True]
Current timestep = 2539. State = [[-0.2599415  0.2595496]]. Action = [[-0.01684398 -0.0541528   0.         -0.915445  ]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 2539 is [True, False, False, False, False, True]
Current timestep = 2540. State = [[-0.3144836   0.02684411]]. Action = [[0.0447379  0.05272678 0.         0.435076  ]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 2540 is [True, False, False, False, False, True]
State prediction error at timestep 2540 is 0.012
Human Feedback received at timestep 2540 of None
Current timestep = 2541. State = [[-0.3130991   0.02590716]]. Action = [[ 6.7786209e-02  7.2964653e-03  0.0000000e+00 -8.9347363e-05]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2541 is [True, False, False, False, True, False]
Current timestep = 2542. State = [[-0.31031764  0.02068054]]. Action = [[ 0.00192456 -0.0934234   0.         -0.15835506]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2542 is [True, False, False, False, True, False]
Current timestep = 2543. State = [[-0.3045109   0.01924112]]. Action = [[ 0.09923411  0.04716451  0.         -0.6326416 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2543 is [True, False, False, False, True, False]
State prediction error at timestep 2543 is 0.012
Human Feedback received at timestep 2543 of None
Current timestep = 2544. State = [[-0.30380458  0.01647353]]. Action = [[-0.06457782 -0.06147104  0.         -0.79091513]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2544 is [True, False, False, False, True, False]
Current timestep = 2545. State = [[-0.30681905  0.01531554]]. Action = [[-0.03714322  0.02863654  0.         -0.6379385 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2545 is [True, False, False, False, True, False]
State prediction error at timestep 2545 is 0.012
Human Feedback received at timestep 2545 of None
Current timestep = 2546. State = [[-0.30817202  0.01451834]]. Action = [[-0.00383114 -0.01616748  0.         -0.56745934]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2546 is [True, False, False, False, True, False]
Current timestep = 2547. State = [[-0.30628124  0.00972147]]. Action = [[ 0.04430804 -0.07239065  0.         -0.9918813 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2547 is [True, False, False, False, True, False]
State prediction error at timestep 2547 is 0.012
Human Feedback received at timestep 2547 of None
Current timestep = 2548. State = [[-0.3023016   0.01090516]]. Action = [[0.06282391 0.08632474 0.         0.5664115 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2548 is [True, False, False, False, True, False]
Current timestep = 2549. State = [[-0.30492964  0.0090299 ]]. Action = [[-0.09120311 -0.07692756  0.         -0.7973538 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2549 is [True, False, False, False, True, False]
State prediction error at timestep 2549 is 0.012
Human Feedback received at timestep 2549 of None
Current timestep = 2550. State = [[-0.3057038   0.01073422]]. Action = [[0.0520914  0.08957741 0.         0.03378201]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2550 is [True, False, False, False, True, False]
Current timestep = 2551. State = [[-0.3005124   0.01028301]]. Action = [[ 0.09931316 -0.05216818  0.         -0.07224518]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2551 is [True, False, False, False, True, False]
Current timestep = 2552. State = [[-0.29565778  0.00519053]]. Action = [[ 0.04946329 -0.06422348  0.         -0.6918456 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2552 is [True, False, False, False, True, False]
Current timestep = 2553. State = [[-0.29667208  0.00720249]]. Action = [[-0.0551806   0.09213647  0.          0.53416157]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2553 is [True, False, False, False, True, False]
Current timestep = 2554. State = [[-0.3021184   0.01324966]]. Action = [[-0.07821932  0.07447176  0.          0.6995411 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2554 is [True, False, False, False, True, False]
Current timestep = 2555. State = [[-0.30753782  0.02026601]]. Action = [[-0.05134135  0.08803927  0.          0.75725126]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2555 is [True, False, False, False, True, False]
Current timestep = 2556. State = [[-0.3067166  0.0257225]]. Action = [[0.07649138 0.03910147 0.         0.97829413]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2556 is [True, False, False, False, True, False]
State prediction error at timestep 2556 is 0.012
Human Feedback received at timestep 2556 of None
Current timestep = 2557. State = [[-0.30940378  0.02525229]]. Action = [[-0.08540265 -0.05635485  0.         -0.5595941 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2557 is [True, False, False, False, True, False]
Current timestep = 2558. State = [[-0.31650898  0.02766847]]. Action = [[-0.08143903  0.05873451  0.         -0.51650596]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2558 is [True, False, False, False, True, False]
Current timestep = 2559. State = [[-0.31805518  0.03516935]]. Action = [[0.05103941 0.09391075 0.         0.28436637]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2559 is [True, False, False, False, True, False]
Current timestep = 2560. State = [[-0.32034355  0.03733216]]. Action = [[-0.04533143 -0.04045446  0.         -0.60807735]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2560 is [True, False, False, False, True, False]
State prediction error at timestep 2560 is 0.012
Human Feedback received at timestep 2560 of None
Current timestep = 2561. State = [[-0.318966    0.03982661]]. Action = [[0.07788431 0.0466292  0.         0.5240011 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2561 is [True, False, False, False, True, False]
Current timestep = 2562. State = [[-0.3155296   0.04607783]]. Action = [[ 0.05139964  0.07858501  0.         -0.9671297 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2562 is [True, False, False, False, True, False]
Current timestep = 2563. State = [[-0.31401658  0.05251604]]. Action = [[ 0.02153163  0.06083132  0.         -0.39905018]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2563 is [True, False, False, False, True, False]
State prediction error at timestep 2563 is 0.012
Human Feedback received at timestep 2563 of None
Current timestep = 2564. State = [[-0.30949566  0.05166945]]. Action = [[ 0.09125074 -0.07698212  0.         -0.7971611 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2564 is [True, False, False, False, True, False]
Current timestep = 2565. State = [[-0.3028481   0.04857784]]. Action = [[ 0.07675322 -0.03490134  0.         -0.657499  ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2565 is [True, False, False, False, True, False]
State prediction error at timestep 2565 is 0.012
Human Feedback received at timestep 2565 of None
Current timestep = 2566. State = [[-0.2999701   0.04890425]]. Action = [[-0.00643039  0.01836254  0.         -0.5861041 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2566 is [True, False, False, False, True, False]
State prediction error at timestep 2566 is 0.012
Human Feedback received at timestep 2566 of None
Current timestep = 2567. State = [[-0.29827031  0.04945972]]. Action = [[ 0.01135556 -0.00902545  0.          0.7787981 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2567 is [True, False, False, False, True, False]
Current timestep = 2568. State = [[-0.29222536  0.05098281]]. Action = [[0.09051616 0.02819719 0.         0.02482343]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2568 is [True, False, False, False, True, False]
State prediction error at timestep 2568 is 0.012
Human Feedback received at timestep 2568 of None
Current timestep = 2569. State = [[-0.28750995  0.05564387]]. Action = [[ 0.01846631  0.07323799  0.         -0.44352007]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2569 is [True, False, False, False, True, False]
Current timestep = 2570. State = [[-0.2901273   0.06025181]]. Action = [[-0.09437373  0.03764521  0.          0.8275516 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2570 is [True, False, False, False, True, False]
Current timestep = 2571. State = [[-0.2933281   0.06340592]]. Action = [[-0.03339154  0.01878385  0.          0.84840536]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 2571 is [True, False, False, False, True, False]
Current timestep = 2572. State = [[-0.29659367  0.06778127]]. Action = [[-0.05634991  0.05139285  0.         -0.99972737]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 2572 is [True, False, False, False, True, False]
Current timestep = 2573. State = [[-0.2938889   0.07211934]]. Action = [[ 0.09058746  0.03160246  0.         -0.73716635]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 2573 is [True, False, False, False, True, False]
State prediction error at timestep 2573 is 0.012
Human Feedback received at timestep 2573 of None
Current timestep = 2574. State = [[-0.29151806  0.07700709]]. Action = [[-0.00371307  0.05459454  0.          0.85959077]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 2574 is [True, False, False, False, True, False]
State prediction error at timestep 2574 is 0.012
Human Feedback received at timestep 2574 of None
Current timestep = 2575. State = [[-0.29330876  0.08186615]]. Action = [[-0.03891621  0.03665919  0.          0.459795  ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 2575 is [True, False, False, False, True, False]
Current timestep = 2576. State = [[-0.29642144  0.08003663]]. Action = [[-0.0464953  -0.09281005  0.          0.77468705]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 2576 is [True, False, False, False, True, False]
Current timestep = 2577. State = [[-0.29308876  0.0753129 ]]. Action = [[ 0.08507904 -0.06688679  0.         -0.8999358 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 2577 is [True, False, False, False, True, False]
State prediction error at timestep 2577 is 0.012
Human Feedback received at timestep 2577 of None
Current timestep = 2578. State = [[-0.2944086   0.07736671]]. Action = [[-0.09270083  0.06973765  0.         -0.8047031 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 2578 is [True, False, False, False, True, False]
Current timestep = 2579. State = [[-0.29539934  0.07683951]]. Action = [[ 0.01935105 -0.06793118  0.          0.867067  ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 2579 is [True, False, False, False, True, False]
Current timestep = 2580. State = [[-0.2944944   0.07596099]]. Action = [[-0.00114103  0.01014098  0.         -0.05585432]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 2580 is [True, False, False, False, True, False]
State prediction error at timestep 2580 is 0.012
Human Feedback received at timestep 2580 of None
Current timestep = 2581. State = [[-0.29734945  0.07399007]]. Action = [[-0.0680416  -0.05053934  0.         -0.07857317]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 2581 is [True, False, False, False, True, False]
Current timestep = 2582. State = [[-0.2979139   0.07634354]]. Action = [[0.02435271 0.07295408 0.         0.85501313]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 2582 is [True, False, False, False, True, False]
Current timestep = 2583. State = [[-0.29887983  0.07586301]]. Action = [[-0.03077353 -0.05331792  0.         -0.8750507 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 2583 is [True, False, False, False, True, False]
State prediction error at timestep 2583 is 0.012
Human Feedback received at timestep 2583 of None
Current timestep = 2584. State = [[-0.29908285  0.07293493]]. Action = [[ 0.01015295 -0.03049848  0.         -0.0878284 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 2584 is [True, False, False, False, True, False]
Current timestep = 2585. State = [[-0.3007214   0.07305346]]. Action = [[-0.03824205  0.02552994  0.          0.34365392]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 2585 is [True, False, False, False, True, False]
State prediction error at timestep 2585 is 0.012
Human Feedback received at timestep 2585 of None
Current timestep = 2586. State = [[-0.30013305  0.07007543]]. Action = [[ 0.03677043 -0.06941297  0.          0.7800448 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 2586 is [True, False, False, False, True, False]
Current timestep = 2587. State = [[-0.30035052  0.06293178]]. Action = [[-0.02816925 -0.094105    0.         -0.97149146]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 2587 is [True, False, False, False, True, False]
State prediction error at timestep 2587 is 0.012
Human Feedback received at timestep 2587 of None
Current timestep = 2588. State = [[-0.3036744   0.05913127]]. Action = [[-0.06030887 -0.00681705  0.          0.7661772 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 2588 is [True, False, False, False, True, False]
Current timestep = 2589. State = [[-0.3047033   0.05783335]]. Action = [[ 0.01445346 -0.00387549  0.          0.6900823 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 2589 is [True, False, False, False, True, False]
Current timestep = 2590. State = [[-0.30262378  0.05281835]]. Action = [[ 0.04018807 -0.07735898  0.          0.72432876]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 2590 is [True, False, False, False, True, False]
Current timestep = 2591. State = [[-0.29730907  0.05187123]]. Action = [[0.09180773 0.0550748  0.         0.25117922]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 2591 is [True, False, False, False, True, False]
Current timestep = 2592. State = [[-0.299057   0.0534282]]. Action = [[-0.08781127  0.02610192  0.         -0.8848199 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 2592 is [True, False, False, False, True, False]
State prediction error at timestep 2592 is 0.012
Human Feedback received at timestep 2592 of None
Current timestep = 2593. State = [[-0.3021783   0.04865314]]. Action = [[ 0.00241275 -0.09467621  0.         -0.3386742 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 2593 is [True, False, False, False, True, False]
Current timestep = 2594. State = [[-0.30204165  0.04020308]]. Action = [[ 0.0159563  -0.09479726  0.          0.41449797]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 2594 is [True, False, False, False, True, False]
Current timestep = 2595. State = [[-0.30284604  0.03487582]]. Action = [[-0.01976925 -0.02315635  0.         -0.7950017 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 2595 is [True, False, False, False, True, False]
Current timestep = 2596. State = [[-0.3006743   0.03199662]]. Action = [[ 0.06119519 -0.01246996  0.          0.6627672 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 2596 is [True, False, False, False, True, False]
State prediction error at timestep 2596 is 0.012
Human Feedback received at timestep 2596 of None
Current timestep = 2597. State = [[-0.3008579   0.02935695]]. Action = [[-0.03311571 -0.01483737  0.          0.1107111 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 2597 is [True, False, False, False, True, False]
State prediction error at timestep 2597 is 0.012
Human Feedback received at timestep 2597 of None
Current timestep = 2598. State = [[-0.30382437  0.02941041]]. Action = [[-0.03779849  0.03630274  0.          0.15228307]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 2598 is [True, False, False, False, True, False]
Current timestep = 2599. State = [[-0.30679786  0.02705164]]. Action = [[-0.02862072 -0.04756336  0.          0.9462832 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 2599 is [True, False, False, False, True, False]
Current timestep = 2600. State = [[-0.308507    0.02549468]]. Action = [[-0.00743602  0.0135143   0.         -0.37767065]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 2600 is [True, False, False, False, True, False]
Current timestep = 2601. State = [[-0.31404224  0.02463218]]. Action = [[-0.09609375 -0.01005115  0.          0.268713  ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 2601 is [True, False, False, False, True, False]
Current timestep = 2602. State = [[-0.3133926   0.02592222]]. Action = [[0.09744131 0.04178739 0.         0.30444694]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 2602 is [True, False, False, False, True, False]
Current timestep = 2603. State = [[-0.30981445  0.02910429]]. Action = [[ 0.03531342  0.04675456  0.         -0.9674787 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 2603 is [True, False, False, False, True, False]
State prediction error at timestep 2603 is 0.012
Human Feedback received at timestep 2603 of None
Current timestep = 2604. State = [[-0.3116048  0.0314377]]. Action = [[-0.05025612  0.01900183  0.          0.43475735]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 2604 is [True, False, False, False, True, False]
Current timestep = 2605. State = [[-0.31452107  0.0369321 ]]. Action = [[-0.02003688  0.09143948  0.         -0.13779122]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 2605 is [True, False, False, False, True, False]
State prediction error at timestep 2605 is 0.012
Human Feedback received at timestep 2605 of None
Current timestep = 2606. State = [[-0.31400633  0.04220745]]. Action = [[ 0.04520815  0.03838622  0.         -0.10884106]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 2606 is [True, False, False, False, True, False]
Current timestep = 2607. State = [[-0.31381494  0.04750079]]. Action = [[ 0.00222869  0.06364542  0.         -0.41356897]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 2607 is [True, False, False, False, True, False]
Current timestep = 2608. State = [[-0.31202817  0.0523592 ]]. Action = [[0.05730867 0.03791385 0.         0.73309517]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 2608 is [True, False, False, False, True, False]
Current timestep = 2609. State = [[-0.3123708   0.05645914]]. Action = [[-0.02086469  0.03454267  0.          0.4541328 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 2609 is [True, False, False, False, True, False]
Current timestep = 2610. State = [[-0.3160003   0.05928733]]. Action = [[-0.05112137  0.00643644  0.          0.7684703 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 2610 is [True, False, False, False, True, False]
Current timestep = 2611. State = [[-0.31989405  0.06377226]]. Action = [[-0.03941045  0.05236191  0.          0.7693281 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 2611 is [True, False, False, False, True, False]
Current timestep = 2612. State = [[-0.32597768  0.06445268]]. Action = [[-0.09218778 -0.0532886   0.          0.06071043]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 2612 is [True, False, False, False, True, False]
Current timestep = 2613. State = [[-0.333318    0.06569804]]. Action = [[-0.09357575  0.01774736  0.          0.90855813]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 2613 is [True, False, False, False, True, False]
Current timestep = 2614. State = [[-0.33318758  0.06361187]]. Action = [[ 0.07063303 -0.0791987   0.         -0.12485981]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 2614 is [True, False, False, False, True, False]
Current timestep = 2615. State = [[-0.33522195  0.06154662]]. Action = [[-0.08011799 -0.01282573  0.          0.26100945]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 2615 is [True, False, False, False, True, False]
Current timestep = 2616. State = [[-0.33598942  0.06419662]]. Action = [[ 0.03525629  0.0512361   0.         -0.26843584]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 2616 is [True, False, False, False, True, False]
Current timestep = 2617. State = [[-0.333828    0.06686193]]. Action = [[0.03828212 0.01787511 0.         0.68371224]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 2617 is [True, False, False, False, True, False]
Current timestep = 2618. State = [[-0.33390626  0.06555089]]. Action = [[-0.01633684 -0.04180548  0.         -0.22385496]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 2618 is [True, False, False, False, True, False]
State prediction error at timestep 2618 is 0.012
Human Feedback received at timestep 2618 of None
Current timestep = 2619. State = [[-0.3331342   0.06777725]]. Action = [[ 0.02952572  0.06774678  0.         -0.1860627 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 2619 is [True, False, False, False, True, False]
Current timestep = 2620. State = [[-0.329683    0.07347805]]. Action = [[0.06973446 0.07770395 0.         0.91513085]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 2620 is [True, False, False, False, True, False]
Current timestep = 2621. State = [[-0.3308552   0.07969865]]. Action = [[-0.0468082   0.07598712  0.         -0.65554297]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 2621 is [True, False, False, False, True, False]
Current timestep = 2622. State = [[-0.33331317  0.07988599]]. Action = [[-0.00817117 -0.05374116  0.          0.10221803]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 2622 is [True, False, False, False, True, False]
State prediction error at timestep 2622 is 0.012
Human Feedback received at timestep 2622 of None
Current timestep = 2623. State = [[-0.33551058  0.07638916]]. Action = [[-0.03347253 -0.05456258  0.         -0.00683254]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 2623 is [True, False, False, False, True, False]
Current timestep = 2624. State = [[-0.33312216  0.07312536]]. Action = [[ 0.06745952 -0.04041811  0.         -0.47296858]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 2624 is [True, False, False, False, True, False]
Current timestep = 2625. State = [[-0.3349403   0.07473785]]. Action = [[-0.07983069  0.05538937  0.          0.12349665]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 2625 is [True, False, False, False, True, False]
Current timestep = 2626. State = [[-0.34158942  0.0746782 ]]. Action = [[-0.09436534 -0.04268039  0.          0.94088364]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 2626 is [True, False, False, False, True, False]
Current timestep = 2627. State = [[-0.34157917  0.07013202]]. Action = [[ 0.05700622 -0.07525401  0.         -0.68911844]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 2627 is [True, False, False, False, True, False]
Current timestep = 2628. State = [[-0.34390736  0.07054089]]. Action = [[-0.08047704  0.05684546  0.          0.62243915]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 2628 is [True, False, False, False, True, False]
Current timestep = 2629. State = [[-0.34461483  0.07278445]]. Action = [[ 0.03615425  0.01193281  0.         -0.21321326]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 2629 is [True, False, False, False, True, False]
State prediction error at timestep 2629 is 0.012
Human Feedback received at timestep 2629 of None
Current timestep = 2630. State = [[-0.3488353   0.07779828]]. Action = [[-0.09161243  0.08966782  0.         -0.07420415]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 2630 is [True, False, False, False, True, False]
Current timestep = 2631. State = [[-0.34910667  0.08178093]]. Action = [[0.07364165 0.02088568 0.         0.65735245]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 2631 is [True, False, False, False, True, False]
Current timestep = 2632. State = [[-0.34426463  0.07858095]]. Action = [[ 0.07970615 -0.08072736  0.          0.34012926]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 2632 is [True, False, False, False, True, False]
Current timestep = 2633. State = [[-0.34099904  0.07837453]]. Action = [[0.0262957  0.04777073 0.         0.28261745]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 2633 is [True, False, False, False, True, False]
Current timestep = 2634. State = [[-0.33899233  0.07724877]]. Action = [[ 0.02530656 -0.0468563   0.          0.80982256]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 2634 is [True, False, False, False, True, False]
Current timestep = 2635. State = [[-0.3346987   0.07768165]]. Action = [[0.06712166 0.03820676 0.         0.3760054 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 2635 is [True, False, False, False, True, False]
Current timestep = 2636. State = [[-0.33070335  0.07726724]]. Action = [[ 0.03399881 -0.02370676  0.         -0.24417591]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 2636 is [True, False, False, False, True, False]
Current timestep = 2637. State = [[-0.32417879  0.07370363]]. Action = [[ 0.09377176 -0.05160435  0.         -0.06922531]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 2637 is [True, False, False, False, True, False]
State prediction error at timestep 2637 is 0.012
Human Feedback received at timestep 2637 of None
Current timestep = 2638. State = [[-0.3237864  0.0678347]]. Action = [[-0.08481625 -0.08111911  0.          0.06523848]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 2638 is [True, False, False, False, True, False]
State prediction error at timestep 2638 is 0.012
Human Feedback received at timestep 2638 of None
Current timestep = 2639. State = [[-0.32711464  0.0606891 ]]. Action = [[-0.05295442 -0.08907643  0.          0.66792893]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 2639 is [True, False, False, False, True, False]
Current timestep = 2640. State = [[-0.32553563  0.05889399]]. Action = [[0.04602399 0.03441685 0.         0.05681074]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 2640 is [True, False, False, False, True, False]
State prediction error at timestep 2640 is 0.012
Human Feedback received at timestep 2640 of None
Current timestep = 2641. State = [[-0.3210173  0.0567273]]. Action = [[ 0.05079971 -0.03863513  0.         -0.61440694]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 2641 is [True, False, False, False, True, False]
State prediction error at timestep 2641 is 0.012
Human Feedback received at timestep 2641 of None
Current timestep = 2642. State = [[-0.31650954  0.05555202]]. Action = [[ 0.044784    0.02320962  0.         -0.17053127]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 2642 is [True, False, False, False, True, False]
Current timestep = 2643. State = [[-0.3169129   0.05905903]]. Action = [[-0.04700018  0.0798512   0.          0.12731218]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 2643 is [True, False, False, False, True, False]
Current timestep = 2644. State = [[-0.31539074  0.06170873]]. Action = [[0.05462601 0.01880367 0.         0.7677164 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 2644 is [True, False, False, False, True, False]
Current timestep = 2645. State = [[-0.31424427  0.05932576]]. Action = [[-0.00972153 -0.05195362  0.         -0.5150837 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 2645 is [True, False, False, False, True, False]
Current timestep = 2646. State = [[-0.31205565  0.05566566]]. Action = [[ 0.03889156 -0.0360129   0.         -0.82983935]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 2646 is [True, False, False, False, True, False]
Current timestep = 2647. State = [[-0.30845663  0.053573  ]]. Action = [[ 0.03976142 -0.00885347  0.          0.34248316]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 2647 is [True, False, False, False, True, False]
Current timestep = 2648. State = [[-0.30785975  0.05341065]]. Action = [[-0.02412615  0.01295424  0.         -0.5800099 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 2648 is [True, False, False, False, True, False]
State prediction error at timestep 2648 is 0.012
Human Feedback received at timestep 2648 of None
Current timestep = 2649. State = [[-0.3089118  0.0548556]]. Action = [[-0.01873663  0.02691817  0.         -0.66368353]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 2649 is [True, False, False, False, True, False]
Current timestep = 2650. State = [[-0.30596778  0.05692863]]. Action = [[ 0.06775641  0.02843194  0.         -0.4256171 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 2650 is [True, False, False, False, True, False]
Current timestep = 2651. State = [[-0.30228877  0.06068955]]. Action = [[0.03685483 0.06102853 0.         0.8003371 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 2651 is [True, False, False, False, True, False]
Current timestep = 2652. State = [[-0.3005044   0.06242063]]. Action = [[ 0.01244096 -0.00360619  0.          0.5887494 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 2652 is [True, False, False, False, True, False]
Current timestep = 2653. State = [[-0.2997284   0.06108353]]. Action = [[ 9.3117356e-05 -3.2588705e-02  0.0000000e+00  6.5414584e-01]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 2653 is [True, False, False, False, True, False]
Current timestep = 2654. State = [[-0.30393237  0.06382737]]. Action = [[-0.09803479  0.06459785  0.         -0.80800843]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 2654 is [True, False, False, False, True, False]
State prediction error at timestep 2654 is 0.012
Human Feedback received at timestep 2654 of None
Current timestep = 2655. State = [[-0.30797753  0.06463237]]. Action = [[-0.0338202  -0.03791616  0.         -0.38134873]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 2655 is [True, False, False, False, True, False]
Current timestep = 2656. State = [[-0.30916122  0.0662201 ]]. Action = [[-0.00531147  0.03537742  0.          0.18052149]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 2656 is [True, False, False, False, True, False]
Current timestep = 2657. State = [[-0.3086695   0.07137045]]. Action = [[0.02139749 0.06910784 0.         0.47679985]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 2657 is [True, False, False, False, True, False]
Current timestep = 2658. State = [[-0.30474946  0.07003535]]. Action = [[ 0.07821696 -0.08136755  0.         -0.30824643]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 2658 is [True, False, False, False, True, False]
Current timestep = 2659. State = [[-0.2980378   0.06540774]]. Action = [[ 0.08982613 -0.05023884  0.         -0.71907306]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 2659 is [True, False, False, False, True, False]
Current timestep = 2660. State = [[-0.29736006  0.06694541]]. Action = [[-0.05073107  0.06497984  0.          0.8243017 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 2660 is [True, False, False, False, True, False]
Current timestep = 2661. State = [[-0.29965276  0.07227572]]. Action = [[-0.02463651  0.06642801  0.         -0.42757303]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 2661 is [True, False, False, False, True, False]
State prediction error at timestep 2661 is 0.012
Human Feedback received at timestep 2661 of None
Current timestep = 2662. State = [[-0.3009884   0.07612278]]. Action = [[-0.00830514  0.02768468  0.          0.87010264]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 2662 is [True, False, False, False, True, False]
Current timestep = 2663. State = [[-0.29947516  0.07392618]]. Action = [[ 0.03706434 -0.07250385  0.          0.79797506]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 2663 is [True, False, False, False, True, False]
Current timestep = 2664. State = [[-0.2945152   0.06769139]]. Action = [[ 0.07108166 -0.08691988  0.         -0.7418033 ]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 2664 is [True, False, False, False, True, False]
Current timestep = 2665. State = [[-0.29636025  0.06823771]]. Action = [[-0.09575077  0.06766436  0.         -0.12293863]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 2665 is [True, False, False, False, True, False]
State prediction error at timestep 2665 is 0.012
Human Feedback received at timestep 2665 of None
Current timestep = 2666. State = [[-0.29770038  0.07419199]]. Action = [[0.02380659 0.0789827  0.         0.44548154]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 2666 is [True, False, False, False, True, False]
State prediction error at timestep 2666 is 0.012
Human Feedback received at timestep 2666 of None
Current timestep = 2667. State = [[-0.29331517  0.08041286]]. Action = [[ 0.08888509  0.07348437  0.         -0.79280114]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 2667 is [True, False, False, False, True, False]
Current timestep = 2668. State = [[-0.2919994   0.08497925]]. Action = [[-0.01430362  0.04151841  0.          0.2848308 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 2668 is [True, False, False, False, True, False]
Current timestep = 2669. State = [[-0.29347864  0.09182876]]. Action = [[-0.01270804  0.09886063  0.          0.9223201 ]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 2669 is [True, False, False, False, True, False]
Current timestep = 2670. State = [[-0.2949785   0.09558778]]. Action = [[-0.00822467 -0.00278039  0.         -0.09119451]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 2670 is [True, False, False, False, True, False]
Current timestep = 2671. State = [[-0.2933229   0.09702506]]. Action = [[0.04714616 0.00406706 0.         0.28771257]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 2671 is [True, False, False, False, True, False]
Current timestep = 2672. State = [[-0.2901052   0.09803782]]. Action = [[ 0.04164604 -0.00319796  0.          0.598976  ]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 2672 is [True, False, False, False, True, False]
Current timestep = 2673. State = [[-0.2899193  0.1030859]]. Action = [[-0.02158137  0.08270022  0.         -0.5013866 ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 2673 is [True, False, False, False, True, False]
State prediction error at timestep 2673 is 0.012
Human Feedback received at timestep 2673 of None
Current timestep = 2674. State = [[-0.28879094  0.10700065]]. Action = [[ 0.03575433  0.00723626  0.         -0.05578923]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 2674 is [True, False, False, False, True, False]
Current timestep = 2675. State = [[-0.29074138  0.11026458]]. Action = [[-0.06270213  0.03331242  0.          0.06199205]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 2675 is [True, False, False, False, True, False]
Current timestep = 2676. State = [[-0.29552475  0.11256456]]. Action = [[-0.06708786 -0.00632971  0.         -0.6067143 ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 2676 is [True, False, False, False, True, False]
State prediction error at timestep 2676 is 0.012
Human Feedback received at timestep 2676 of None
Current timestep = 2677. State = [[-0.30172417  0.11180963]]. Action = [[-0.0929039  -0.05009789  0.          0.9811382 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 2677 is [True, False, False, False, True, False]
Current timestep = 2678. State = [[-0.30194455  0.11119697]]. Action = [[ 0.05063116 -0.01329562  0.         -0.57310766]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 2678 is [True, False, False, False, True, False]
Current timestep = 2679. State = [[-0.30424002  0.1155135 ]]. Action = [[-0.07626657  0.07390868  0.          0.35741305]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 2679 is [True, False, False, False, True, False]
Current timestep = 2680. State = [[-0.30710366  0.12318818]]. Action = [[-0.00640015  0.08781656  0.         -0.3678316 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 2680 is [True, False, False, False, True, False]
Current timestep = 2681. State = [[-0.31156266  0.12640241]]. Action = [[-0.06847132 -0.01404825  0.          0.276438  ]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 2681 is [True, False, False, False, True, False]
State prediction error at timestep 2681 is 0.012
Human Feedback received at timestep 2681 of None
Current timestep = 2682. State = [[-0.31175396  0.12288877]]. Action = [[ 0.04837849 -0.08990174  0.          0.96364665]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 2682 is [True, False, False, False, False, True]
State prediction error at timestep 2682 is 0.012
Human Feedback received at timestep 2682 of None
Current timestep = 2683. State = [[-0.31098613  0.11753627]]. Action = [[-0.00629111 -0.06801194  0.         -0.8542386 ]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 2683 is [True, False, False, False, True, False]
Current timestep = 2684. State = [[-0.30900595  0.11107703]]. Action = [[ 0.03785165 -0.09221184  0.          0.540535  ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 2684 is [True, False, False, False, True, False]
Current timestep = 2685. State = [[-0.30342683  0.10307033]]. Action = [[ 0.0797926  -0.0952734   0.          0.13374424]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 2685 is [True, False, False, False, True, False]
Current timestep = 2686. State = [[-0.30305636  0.09916344]]. Action = [[-5.7003766e-02  7.7233464e-04  0.0000000e+00 -7.9559767e-01]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 2686 is [True, False, False, False, True, False]
Current timestep = 2687. State = [[-0.30002922  0.09464585]]. Action = [[ 0.07650676 -0.06561924  0.          0.4318732 ]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 2687 is [True, False, False, False, True, False]
State prediction error at timestep 2687 is 0.012
Human Feedback received at timestep 2687 of None
Current timestep = 2688. State = [[-0.2990973   0.09261217]]. Action = [[-0.03838865  0.02852624  0.          0.21275723]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 2688 is [True, False, False, False, True, False]
Current timestep = 2689. State = [[-0.2956406   0.09402169]]. Action = [[0.08473103 0.04586797 0.         0.702803  ]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 2689 is [True, False, False, False, True, False]
Current timestep = 2690. State = [[-0.2965532   0.09719697]]. Action = [[-0.07085129  0.06511516  0.         -0.4407581 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 2690 is [True, False, False, False, True, False]
State prediction error at timestep 2690 is 0.012
Human Feedback received at timestep 2690 of None
Current timestep = 2691. State = [[-0.3013665   0.10232334]]. Action = [[-0.04949867  0.08001491  0.         -0.56361985]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 2691 is [True, False, False, False, True, False]
Current timestep = 2692. State = [[-0.30158085  0.10449247]]. Action = [[ 0.04696449  0.00285725  0.         -0.35360658]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 2692 is [True, False, False, False, True, False]
Current timestep = 2693. State = [[-0.29827452  0.09938093]]. Action = [[ 0.05790351 -0.099506    0.         -0.7129658 ]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 2693 is [True, False, False, False, True, False]
State prediction error at timestep 2693 is 0.012
Human Feedback received at timestep 2693 of None
Current timestep = 2694. State = [[-0.29924867  0.09559705]]. Action = [[-0.05226266 -0.01196411  0.          0.78860104]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 2694 is [True, False, False, False, True, False]
Current timestep = 2695. State = [[-0.30412576  0.09984045]]. Action = [[-0.06701688  0.09521248  0.         -0.810299  ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 2695 is [True, False, False, False, True, False]
Current timestep = 2696. State = [[-0.3057519   0.10540999]]. Action = [[0.02499284 0.05237799 0.         0.70144486]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 2696 is [True, False, False, False, True, False]
Current timestep = 2697. State = [[-0.30541462  0.11072708]]. Action = [[0.01870461 0.06820067 0.         0.63283205]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 2697 is [True, False, False, False, True, False]
Current timestep = 2698. State = [[-0.3042589   0.11127759]]. Action = [[ 0.03359877 -0.03844787  0.          0.53180194]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 2698 is [True, False, False, False, True, False]
Current timestep = 2699. State = [[-0.30337834  0.11160989]]. Action = [[ 0.00938477  0.01722326  0.         -0.92509604]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 2699 is [True, False, False, False, True, False]
Current timestep = 2700. State = [[-0.30759346  0.11226914]]. Action = [[-0.08649355 -0.01063247  0.          0.01087904]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 2700 is [True, False, False, False, True, False]
State prediction error at timestep 2700 is 0.012
Human Feedback received at timestep 2700 of None
Current timestep = 2701. State = [[-0.30736163  0.11346299]]. Action = [[0.06374484 0.01398732 0.         0.75572133]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 2701 is [True, False, False, False, True, False]
Current timestep = 2702. State = [[-0.30789658  0.11290152]]. Action = [[-0.04630033 -0.03339317  0.          0.93778324]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 2702 is [True, False, False, False, True, False]
Current timestep = 2703. State = [[-0.31009686  0.11663461]]. Action = [[-0.02044272  0.07900562  0.         -0.3019727 ]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 2703 is [True, False, False, False, True, False]
State prediction error at timestep 2703 is 0.012
Human Feedback received at timestep 2703 of None
Current timestep = 2704. State = [[-0.30831206  0.120335  ]]. Action = [[0.05802291 0.01748355 0.         0.7820828 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 2704 is [True, False, False, False, True, False]
Current timestep = 2705. State = [[-0.31054422  0.12425227]]. Action = [[-0.07132298  0.05472117  0.          0.16383386]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 2705 is [True, False, False, False, True, False]
State prediction error at timestep 2705 is 0.012
Human Feedback received at timestep 2705 of None
Current timestep = 2706. State = [[-0.31730986  0.12871805]]. Action = [[-0.08736702  0.03627693  0.         -0.92897356]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 2706 is [True, False, False, False, True, False]
Current timestep = 2707. State = [[-0.32012787  0.1307578 ]]. Action = [[ 0.01085661 -0.00709767  0.         -0.6352171 ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 2707 is [True, False, False, False, False, True]
State prediction error at timestep 2707 is 0.012
Human Feedback received at timestep 2707 of None
Current timestep = 2708. State = [[-0.32119188  0.13042592]]. Action = [[-0.01095378 -0.02526438  0.         -0.679761  ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 2708 is [True, False, False, False, False, True]
Current timestep = 2709. State = [[-0.3200334   0.13376676]]. Action = [[0.0443883  0.0662962  0.         0.41012943]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 2709 is [True, False, False, False, False, True]
Current timestep = 2710. State = [[-0.31535172  0.13713986]]. Action = [[ 0.08762088  0.02345296  0.         -0.11763901]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 2710 is [True, False, False, False, False, True]
State prediction error at timestep 2710 is 0.012
Human Feedback received at timestep 2710 of None
Current timestep = 2711. State = [[-0.3149747   0.13613607]]. Action = [[-0.0410904  -0.04470474  0.          0.8657315 ]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 2711 is [True, False, False, False, False, True]
Current timestep = 2712. State = [[-0.3192123   0.13879725]]. Action = [[-0.05890632  0.06708232  0.          0.62803364]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 2712 is [True, False, False, False, False, True]
Current timestep = 2713. State = [[-0.3240092   0.14513865]]. Action = [[-0.04619068  0.07561233  0.          0.16204894]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 2713 is [True, False, False, False, False, True]
Current timestep = 2714. State = [[-0.32670018  0.14711796]]. Action = [[-0.00619543 -0.02345888  0.          0.96322906]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 2714 is [True, False, False, False, False, True]
Current timestep = 2715. State = [[-0.32298055  0.14382643]]. Action = [[ 0.09357958 -0.06816004  0.          0.056301  ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 2715 is [True, False, False, False, False, True]
Current timestep = 2716. State = [[-0.31755444  0.14439398]]. Action = [[0.0611015 0.0520793 0.        0.3213141]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 2716 is [True, False, False, False, False, True]
Current timestep = 2717. State = [[-0.3178383   0.15004231]]. Action = [[-0.04003083  0.0851186   0.         -0.588984  ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 2717 is [True, False, False, False, False, True]
Current timestep = 2718. State = [[-0.32151404  0.1483611 ]]. Action = [[-0.05466161 -0.09994055  0.          0.82860947]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 2718 is [True, False, False, False, False, True]
Current timestep = 2719. State = [[-0.32696036  0.14571568]]. Action = [[-0.08511171 -0.01848625  0.         -0.8036489 ]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 2719 is [True, False, False, False, False, True]
Current timestep = 2720. State = [[-0.33310464  0.1469163 ]]. Action = [[-0.07315074  0.01911249  0.         -0.05546844]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 2720 is [True, False, False, False, False, True]
Current timestep = 2721. State = [[-0.33584788  0.14536895]]. Action = [[-0.0018387  -0.05622892  0.          0.1951487 ]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 2721 is [True, False, False, False, False, True]
State prediction error at timestep 2721 is 0.012
Human Feedback received at timestep 2721 of None
Current timestep = 2722. State = [[-0.33566186  0.14524968]]. Action = [[0.0169505  0.02518994 0.         0.66831446]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 2722 is [True, False, False, False, False, True]
Current timestep = 2723. State = [[-0.33321542  0.14619556]]. Action = [[ 0.05449351  0.01130066  0.         -0.02923751]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 2723 is [True, False, False, False, False, True]
Current timestep = 2724. State = [[-0.33669826  0.14792633]]. Action = [[-0.08996402  0.03267353  0.         -0.03341711]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 2724 is [True, False, False, False, False, True]
Current timestep = 2725. State = [[-0.33831698  0.14783157]]. Action = [[ 0.0351439  -0.02107851  0.          0.692173  ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 2725 is [True, False, False, False, False, True]
State prediction error at timestep 2725 is 0.012
Human Feedback received at timestep 2725 of None
Current timestep = 2726. State = [[-0.33495542  0.14269741]]. Action = [[ 0.06279782 -0.08462653  0.          0.8399378 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 2726 is [True, False, False, False, False, True]
Current timestep = 2727. State = [[-0.3314906   0.14007464]]. Action = [[ 0.03573257  0.01184007  0.         -0.481462  ]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 2727 is [True, False, False, False, False, True]
Current timestep = 2728. State = [[-0.32856846  0.1433506 ]]. Action = [[ 0.03990399  0.08079735  0.         -0.6240837 ]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 2728 is [True, False, False, False, False, True]
Current timestep = 2729. State = [[-0.32722306  0.14624296]]. Action = [[ 0.00825392  0.0287485   0.         -0.81028014]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 2729 is [True, False, False, False, False, True]
State prediction error at timestep 2729 is 0.012
Human Feedback received at timestep 2729 of None
Current timestep = 2730. State = [[-0.32608053  0.14762749]]. Action = [[ 0.01884545  0.01956664  0.         -0.123294  ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 2730 is [True, False, False, False, False, True]
Current timestep = 2731. State = [[-0.3231809   0.14513597]]. Action = [[ 0.04345996 -0.0554686   0.         -0.27159083]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 2731 is [True, False, False, False, False, True]
Current timestep = 2732. State = [[-0.32341197  0.14192353]]. Action = [[-0.04388141 -0.03055923  0.          0.46640635]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 2732 is [True, False, False, False, False, True]
Current timestep = 2733. State = [[-0.31948683  0.13895239]]. Action = [[ 0.08794599 -0.03835739  0.         -0.771493  ]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 2733 is [True, False, False, False, False, True]
Current timestep = 2734. State = [[-0.3128439   0.13261335]]. Action = [[ 0.06071142 -0.09365758  0.         -0.61388224]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 2734 is [True, False, False, False, False, True]
Current timestep = 2735. State = [[-0.31130466  0.12708436]]. Action = [[-0.04116434 -0.04479733  0.          0.13192165]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 2735 is [True, False, False, False, False, True]
State prediction error at timestep 2735 is 0.012
Human Feedback received at timestep 2735 of None
Current timestep = 2736. State = [[-0.30850026  0.1222553 ]]. Action = [[ 0.04327024 -0.05628767  0.          0.83427334]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 2736 is [True, False, False, False, False, True]
State prediction error at timestep 2736 is 0.012
Human Feedback received at timestep 2736 of None
Current timestep = 2737. State = [[-0.30830827  0.12029977]]. Action = [[-0.05289738  0.01298714  0.         -0.8728494 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 2737 is [True, False, False, False, True, False]
Current timestep = 2738. State = [[-0.31075126  0.11590107]]. Action = [[-0.04866627 -0.08083374  0.          0.84891343]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 2738 is [True, False, False, False, True, False]
Current timestep = 2739. State = [[-0.31537628  0.10857446]]. Action = [[-0.09132522 -0.09065353  0.          0.30952   ]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 2739 is [True, False, False, False, True, False]
Current timestep = 2740. State = [[-0.31768042  0.10854073]]. Action = [[-0.00255706  0.0711382   0.         -0.89631915]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 2740 is [True, False, False, False, True, False]
Current timestep = 2741. State = [[-0.3197476  0.1138595]]. Action = [[-0.03322322  0.08439327  0.         -0.52309   ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 2741 is [True, False, False, False, True, False]
Current timestep = 2742. State = [[-0.32558239  0.1176312 ]]. Action = [[-0.07995929  0.03235682  0.          0.3300705 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 2742 is [True, False, False, False, True, False]
Current timestep = 2743. State = [[-0.324829   0.1140897]]. Action = [[ 0.08692684 -0.09046286  0.          0.809443  ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 2743 is [True, False, False, False, True, False]
Current timestep = 2744. State = [[-0.32446998  0.10745654]]. Action = [[-0.02477759 -0.07008799  0.          0.38511384]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 2744 is [True, False, False, False, True, False]
State prediction error at timestep 2744 is 0.012
Human Feedback received at timestep 2744 of None
Current timestep = 2745. State = [[-0.3257955   0.10241932]]. Action = [[-0.00754303 -0.04672647  0.          0.79781616]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 2745 is [True, False, False, False, True, False]
Current timestep = 2746. State = [[-0.3304662   0.10011666]]. Action = [[-0.0822862  -0.00530951  0.          0.4932841 ]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 2746 is [True, False, False, False, True, False]
Current timestep = 2747. State = [[-0.33113536  0.10089467]]. Action = [[0.05233785 0.03425481 0.         0.2912644 ]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 2747 is [True, False, False, False, True, False]
State prediction error at timestep 2747 is 0.012
Human Feedback received at timestep 2747 of None
Current timestep = 2748. State = [[-0.33224446  0.10482065]]. Action = [[-0.02918882  0.07527824  0.          0.7836579 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 2748 is [True, False, False, False, True, False]
State prediction error at timestep 2748 is 0.012
Human Feedback received at timestep 2748 of None
Current timestep = 2749. State = [[-0.33180848  0.10269173]]. Action = [[ 0.04527139 -0.07858258  0.         -0.39988542]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 2749 is [True, False, False, False, True, False]
Current timestep = 2750. State = [[-0.33274826  0.10029443]]. Action = [[-0.03239698  0.00727025  0.          0.9710295 ]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 2750 is [True, False, False, False, True, False]
State prediction error at timestep 2750 is 0.012
Human Feedback received at timestep 2750 of None
Current timestep = 2751. State = [[-0.33120716  0.10025779]]. Action = [[ 0.06146463  0.00850042  0.         -0.5641043 ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 2751 is [True, False, False, False, True, False]
Current timestep = 2752. State = [[-0.33306345  0.09657378]]. Action = [[-0.06814504 -0.07064238  0.          0.1178894 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 2752 is [True, False, False, False, True, False]
Current timestep = 2753. State = [[-0.33653703  0.09668877]]. Action = [[-0.02229362  0.05068263  0.          0.27799237]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 2753 is [True, False, False, False, True, False]
Current timestep = 2754. State = [[-0.33887592  0.09492142]]. Action = [[-0.01628052 -0.05589363  0.         -0.40494668]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 2754 is [True, False, False, False, True, False]
Current timestep = 2755. State = [[-0.3396219   0.09612473]]. Action = [[0.00988247 0.06372558 0.         0.603421  ]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 2755 is [True, False, False, False, True, False]
State prediction error at timestep 2755 is 0.012
Human Feedback received at timestep 2755 of None
Current timestep = 2756. State = [[-0.33902183  0.10152341]]. Action = [[ 0.0314443   0.08288597  0.         -0.64952296]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 2756 is [True, False, False, False, True, False]
Current timestep = 2757. State = [[-0.3378907   0.10148898]]. Action = [[ 0.02908426 -0.04383078  0.          0.2390753 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 2757 is [True, False, False, False, True, False]
Current timestep = 2758. State = [[-0.33474338  0.09738672]]. Action = [[ 0.05705773 -0.0537163   0.         -0.03368843]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 2758 is [True, False, False, False, True, False]
Current timestep = 2759. State = [[-0.3367142   0.09976645]]. Action = [[-0.06915023  0.08818876  0.         -0.82009655]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 2759 is [True, False, False, False, True, False]
State prediction error at timestep 2759 is 0.012
Human Feedback received at timestep 2759 of None
Current timestep = 2760. State = [[-0.34303507  0.10375386]]. Action = [[-0.08180982  0.02359945  0.         -0.68190455]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 2760 is [True, False, False, False, True, False]
Current timestep = 2761. State = [[-0.34809867  0.10071327]]. Action = [[-0.04642468 -0.09389655  0.         -0.7378843 ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 2761 is [True, False, False, False, True, False]
State prediction error at timestep 2761 is 0.012
Human Feedback received at timestep 2761 of None
Current timestep = 2762. State = [[-0.34924147  0.09911771]]. Action = [[ 0.01084479  0.0098876   0.         -0.04620987]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 2762 is [True, False, False, False, True, False]
Current timestep = 2763. State = [[-0.35325024  0.10024264]]. Action = [[-0.07821853  0.01260778  0.         -0.36245006]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 2763 is [True, False, False, False, True, False]
State prediction error at timestep 2763 is 0.012
Human Feedback received at timestep 2763 of None
Current timestep = 2764. State = [[-0.3521823  0.0968632]]. Action = [[ 0.07625573 -0.08138631  0.         -0.6063938 ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 2764 is [True, False, False, False, True, False]
Current timestep = 2765. State = [[-0.35294917  0.09074105]]. Action = [[-0.0579674  -0.0736837   0.         -0.95038116]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 2765 is [True, False, False, False, True, False]
Current timestep = 2766. State = [[-0.3536023   0.08618239]]. Action = [[ 0.01503904 -0.0405248   0.         -0.87822706]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 2766 is [True, False, False, False, True, False]
State prediction error at timestep 2766 is 0.012
Human Feedback received at timestep 2766 of None
Current timestep = 2767. State = [[-0.35782927  0.08394852]]. Action = [[-0.09466544 -0.00829067  0.         -0.6255229 ]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 2767 is [True, False, False, False, True, False]
Current timestep = 2768. State = [[-0.3591602   0.08275515]]. Action = [[ 0.03399517 -0.00571497  0.         -0.22105908]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 2768 is [True, False, False, False, True, False]
Current timestep = 2769. State = [[-0.35555282  0.07969911]]. Action = [[ 0.06616687 -0.03669579  0.          0.6342242 ]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 2769 is [True, False, False, False, True, False]
Current timestep = 2770. State = [[-0.3496497   0.07866052]]. Action = [[ 0.09101789  0.02977767  0.         -0.8909727 ]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 2770 is [True, False, False, False, True, False]
Current timestep = 2771. State = [[-0.34345254  0.07985524]]. Action = [[ 0.08210699  0.04031367  0.         -0.7761109 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 2771 is [True, False, False, False, True, False]
Current timestep = 2772. State = [[-0.34401605  0.08181   ]]. Action = [[-0.05939452  0.03965769  0.          0.13627315]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 2772 is [True, False, False, False, True, False]
Current timestep = 2773. State = [[-0.34204078  0.08106429]]. Action = [[ 0.08134615 -0.02201577  0.          0.81789136]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 2773 is [True, False, False, False, True, False]
State prediction error at timestep 2773 is 0.012
Human Feedback received at timestep 2773 of None
Current timestep = 2774. State = [[-0.34104386  0.0806599 ]]. Action = [[-0.02109032  0.01952931  0.         -0.6613146 ]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 2774 is [True, False, False, False, True, False]
State prediction error at timestep 2774 is 0.012
Human Feedback received at timestep 2774 of None
Current timestep = 2775. State = [[-0.33674437  0.07887777]]. Action = [[ 0.09681579 -0.03484135  0.         -0.91825944]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 2775 is [True, False, False, False, True, False]
State prediction error at timestep 2775 is 0.012
Human Feedback received at timestep 2775 of None
Current timestep = 2776. State = [[-0.3344871   0.07909735]]. Action = [[-0.01696784  0.03620049  0.         -0.7407212 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 2776 is [True, False, False, False, True, False]
Current timestep = 2777. State = [[-0.33514476  0.08122617]]. Action = [[-0.01518965  0.02698503  0.         -0.9968195 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 2777 is [True, False, False, False, True, False]
State prediction error at timestep 2777 is 0.012
Human Feedback received at timestep 2777 of None
Current timestep = 2778. State = [[-0.33600122  0.08047425]]. Action = [[-0.01801159 -0.03425851  0.         -0.24254602]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 2778 is [True, False, False, False, True, False]
Current timestep = 2779. State = [[-0.33195934  0.07630255]]. Action = [[ 0.07794446 -0.06632297  0.          0.97712564]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 2779 is [True, False, False, False, True, False]
Current timestep = 2780. State = [[-0.32908323  0.07811096]]. Action = [[-0.00178895  0.08228608  0.          0.10792255]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 2780 is [True, False, False, False, True, False]
Current timestep = 2781. State = [[-0.32878315  0.08072679]]. Action = [[-0.0057619   0.00546743  0.          0.02683735]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 2781 is [True, False, False, False, True, False]
State prediction error at timestep 2781 is 0.012
Human Feedback received at timestep 2781 of None
Current timestep = 2782. State = [[-0.33064184  0.08119375]]. Action = [[-0.04675236 -0.00282943  0.          0.3562752 ]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 2782 is [True, False, False, False, True, False]
Current timestep = 2783. State = [[-0.32855996  0.08033491]]. Action = [[ 0.05771341 -0.02338574  0.         -0.06932986]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 2783 is [True, False, False, False, True, False]
Current timestep = 2784. State = [[-0.32906446  0.07790884]]. Action = [[-0.05791276 -0.03993405  0.         -0.329854  ]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 2784 is [True, False, False, False, True, False]
Current timestep = 2785. State = [[-0.32930782  0.08083526]]. Action = [[0.01674552 0.07800294 0.         0.5013808 ]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 2785 is [True, False, False, False, True, False]
Current timestep = 2786. State = [[-0.3321179   0.07877721]]. Action = [[-0.07415871 -0.094441    0.         -0.90174854]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 2786 is [True, False, False, False, True, False]
Current timestep = 2787. State = [[-0.33028105  0.07953062]]. Action = [[ 0.0864478   0.06833937  0.         -0.04746723]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 2787 is [True, False, False, False, True, False]
Current timestep = 2788. State = [[-0.3254361   0.07798516]]. Action = [[ 0.04147009 -0.06771854  0.          0.5159576 ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 2788 is [True, False, False, False, True, False]
Current timestep = 2789. State = [[-0.3273337   0.07559343]]. Action = [[-0.0885117  -0.01210083  0.          0.36519408]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 2789 is [True, False, False, False, True, False]
State prediction error at timestep 2789 is 0.012
Human Feedback received at timestep 2789 of None
Current timestep = 2790. State = [[-0.32854912  0.07260443]]. Action = [[ 0.00456236 -0.05462791  0.         -0.5453553 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 2790 is [True, False, False, False, True, False]
State prediction error at timestep 2790 is 0.012
Human Feedback received at timestep 2790 of None
Current timestep = 2791. State = [[-0.3264472   0.07018804]]. Action = [[ 0.02673598 -0.01193046  0.         -0.8190418 ]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 2791 is [True, False, False, False, True, False]
Current timestep = 2792. State = [[-0.32212198  0.06608753]]. Action = [[ 0.05969562 -0.0618124   0.         -0.3836245 ]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 2792 is [True, False, False, False, True, False]
Current timestep = 2793. State = [[-0.321906   0.0622024]]. Action = [[-0.0481133  -0.02602474  0.          0.7454214 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 2793 is [True, False, False, False, True, False]
State prediction error at timestep 2793 is 0.012
Human Feedback received at timestep 2793 of None
Current timestep = 2794. State = [[-0.32626256  0.05919367]]. Action = [[-0.08043726 -0.03106777  0.         -0.51389384]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 2794 is [True, False, False, False, True, False]
State prediction error at timestep 2794 is 0.012
Human Feedback received at timestep 2794 of None
Current timestep = 2795. State = [[-0.3273625   0.05670412]]. Action = [[ 0.01530546 -0.01761063  0.         -0.25842887]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 2795 is [True, False, False, False, True, False]
Current timestep = 2796. State = [[-0.32385945  0.05287737]]. Action = [[ 0.06192369 -0.04508866  0.          0.8152212 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 2796 is [True, False, False, False, True, False]
Current timestep = 2797. State = [[-0.3224137   0.05472176]]. Action = [[-0.00458619  0.08893215  0.          0.80981326]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 2797 is [True, False, False, False, True, False]
Current timestep = 2798. State = [[-0.32574558  0.05200262]]. Action = [[-0.06366722 -0.09295467  0.         -0.03186578]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 2798 is [True, False, False, False, True, False]
Current timestep = 2799. State = [[-0.33088288  0.04874206]]. Action = [[-0.06730834 -0.0018798   0.         -0.42569113]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 2799 is [True, False, False, False, True, False]
State prediction error at timestep 2799 is 0.012
Human Feedback received at timestep 2799 of None
Current timestep = 2800. State = [[-0.33660713  0.04488438]]. Action = [[-0.0698835  -0.06275879  0.          0.21886504]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 2800 is [True, False, False, False, True, False]
Current timestep = 2801. State = [[-0.33803642  0.04012624]]. Action = [[ 0.02325016 -0.04506734  0.         -0.46651077]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 2801 is [True, False, False, False, True, False]
Current timestep = 2802. State = [[-0.34223527  0.03501226]]. Action = [[-0.08654648 -0.0571706   0.         -0.24548435]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 2802 is [True, False, False, False, True, False]
State prediction error at timestep 2802 is 0.012
Human Feedback received at timestep 2802 of None
Current timestep = 2803. State = [[-0.34431687  0.03153699]]. Action = [[ 0.02197697 -0.01630203  0.         -0.02381325]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 2803 is [True, False, False, False, True, False]
State prediction error at timestep 2803 is 0.012
Human Feedback received at timestep 2803 of None
Current timestep = 2804. State = [[-0.34183753  0.03441734]]. Action = [[ 0.0675214   0.09219288  0.         -0.57898825]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 2804 is [True, False, False, False, True, False]
Current timestep = 2805. State = [[-0.33771247  0.03184521]]. Action = [[ 0.07748269 -0.08927371  0.          0.68384635]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 2805 is [True, False, False, False, True, False]
Current timestep = 2806. State = [[-0.33846217  0.0303699 ]]. Action = [[-0.04260641  0.04211511  0.         -0.5495646 ]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 2806 is [True, False, False, False, True, False]
Current timestep = 2807. State = [[-0.3376698   0.03018063]]. Action = [[ 0.05940133 -0.0070677   0.         -0.9779847 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 2807 is [True, False, False, False, True, False]
State prediction error at timestep 2807 is 0.012
Human Feedback received at timestep 2807 of None
Current timestep = 2808. State = [[-0.33601218  0.03212003]]. Action = [[0.02177481 0.05884915 0.         0.17088938]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 2808 is [True, False, False, False, True, False]
Current timestep = 2809. State = [[-0.33461717  0.03319053]]. Action = [[ 0.03400911 -0.00075848  0.         -0.6442592 ]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 2809 is [True, False, False, False, True, False]
Current timestep = 2810. State = [[-0.33036166  0.03357228]]. Action = [[ 0.07954315  0.01580553  0.         -0.77026814]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 2810 is [True, False, False, False, True, False]
State prediction error at timestep 2810 is 0.012
Human Feedback received at timestep 2810 of None
Current timestep = 2811. State = [[-0.32899928  0.03073085]]. Action = [[-0.01671933 -0.0591886   0.          0.6380911 ]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 2811 is [True, False, False, False, True, False]
State prediction error at timestep 2811 is 0.012
Human Feedback received at timestep 2811 of None
Current timestep = 2812. State = [[-0.32727665  0.02782348]]. Action = [[ 0.03463753 -0.01872935  0.         -0.75298506]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 2812 is [True, False, False, False, True, False]
Current timestep = 2813. State = [[-0.32377002  0.03126492]]. Action = [[ 0.04441547  0.08884034  0.         -0.9448709 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 2813 is [True, False, False, False, True, False]
Current timestep = 2814. State = [[-0.3240788   0.03338438]]. Action = [[-0.03818944 -0.00648931  0.         -0.5459041 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 2814 is [True, False, False, False, True, False]
Current timestep = 2815. State = [[-0.3288259   0.03545791]]. Action = [[-0.08815454  0.03777444  0.          0.01396871]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 2815 is [True, False, False, False, True, False]
Current timestep = 2816. State = [[-0.3291313  0.0368541]]. Action = [[ 0.04074564 -0.00402907  0.         -0.91794205]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 2816 is [True, False, False, False, True, False]
Current timestep = 2817. State = [[-0.32587758  0.03788143]]. Action = [[0.04072361 0.01223846 0.         0.85704255]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 2817 is [True, False, False, False, True, False]
State prediction error at timestep 2817 is 0.012
Human Feedback received at timestep 2817 of None
Current timestep = 2818. State = [[-0.32286555  0.04136261]]. Action = [[0.03314569 0.05336376 0.         0.13874137]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 2818 is [True, False, False, False, True, False]
Current timestep = 2819. State = [[-0.31800887  0.04352752]]. Action = [[0.07618874 0.00167219 0.         0.91784596]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 2819 is [True, False, False, False, True, False]
Current timestep = 2820. State = [[-0.3116846   0.04373567]]. Action = [[ 0.07543265 -0.00691817  0.         -0.16651613]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 2820 is [True, False, False, False, True, False]
Current timestep = 2821. State = [[-0.31020007  0.04075859]]. Action = [[-0.03786297 -0.06448203  0.          0.49380958]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 2821 is [True, False, False, False, True, False]
State prediction error at timestep 2821 is 0.012
Human Feedback received at timestep 2821 of None
Current timestep = 2822. State = [[-0.3061545   0.03839104]]. Action = [[ 0.07646476 -0.01566736  0.          0.13592744]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 2822 is [True, False, False, False, True, False]
Current timestep = 2823. State = [[-0.30475128  0.04244343]]. Action = [[-0.04020966  0.09076076  0.         -0.8956546 ]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 2823 is [True, False, False, False, True, False]
Current timestep = 2824. State = [[-0.3090882  0.0426675]]. Action = [[-0.09378593 -0.05696677  0.          0.37162423]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 2824 is [True, False, False, False, True, False]
State prediction error at timestep 2824 is 0.012
Human Feedback received at timestep 2824 of None
Current timestep = 2825. State = [[-0.30725783  0.03955206]]. Action = [[ 0.07134559 -0.03953507  0.          0.72220325]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 2825 is [True, False, False, False, True, False]
State prediction error at timestep 2825 is 0.012
Human Feedback received at timestep 2825 of None
Current timestep = 2826. State = [[-0.30493668  0.03443547]]. Action = [[-0.02403579 -0.07888034  0.          0.20413482]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 2826 is [True, False, False, False, True, False]
Current timestep = 2827. State = [[-0.29920623  0.02978672]]. Action = [[ 0.09515297 -0.03912665  0.         -0.01943666]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 2827 is [True, False, False, False, True, False]
Current timestep = 2828. State = [[-0.29402882  0.03221563]]. Action = [[ 0.02076384  0.08863341  0.         -0.5196221 ]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 2828 is [True, False, False, False, True, False]
State prediction error at timestep 2828 is 0.012
Human Feedback received at timestep 2828 of None
Current timestep = 2829. State = [[-0.28819558  0.03751305]]. Action = [[ 0.08438579  0.06643137  0.         -0.3931111 ]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 2829 is [True, False, False, False, True, False]
Current timestep = 2830. State = [[-0.28659633  0.0346585 ]]. Action = [[-0.0400084  -0.09448317  0.         -0.34591103]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 2830 is [True, False, False, False, True, False]
Current timestep = 2831. State = [[-0.2817042   0.02952048]]. Action = [[ 0.09963266 -0.04111672  0.          0.30898094]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 2831 is [True, False, False, False, True, False]
Current timestep = 2832. State = [[-0.27464065  0.02309566]]. Action = [[ 0.05861878 -0.08575968  0.         -0.22500867]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 2832 is [True, False, False, False, True, False]
Current timestep = 2833. State = [[-0.27038983  0.01569597]]. Action = [[ 0.0114419  -0.07605794  0.          0.59583163]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 2833 is [True, False, False, False, True, False]
Current timestep = 2834. State = [[-0.2705056   0.01600743]]. Action = [[-0.05083156  0.07800474  0.         -0.9319833 ]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 2834 is [True, False, False, False, True, False]
Current timestep = 2835. State = [[-0.2745454   0.01327962]]. Action = [[-0.08976077 -0.08046663  0.          0.18760419]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 2835 is [True, False, False, False, True, False]
Current timestep = 2836. State = [[-0.27499902  0.01451463]]. Action = [[0.01973967 0.08724626 0.         0.20820463]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 2836 is [True, False, False, False, True, False]
State prediction error at timestep 2836 is 0.012
Human Feedback received at timestep 2836 of None
Current timestep = 2837. State = [[-0.2701837   0.01953659]]. Action = [[0.08401012 0.06237905 0.         0.42645943]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 2837 is [True, False, False, False, True, False]
State prediction error at timestep 2837 is 0.012
Human Feedback received at timestep 2837 of None
Current timestep = 2838. State = [[-0.26919872  0.02006974]]. Action = [[-0.02965529 -0.02407035  0.         -0.06846267]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 2838 is [True, False, False, False, True, False]
Current timestep = 2839. State = [[-0.27119026  0.01738611]]. Action = [[-0.0317248  -0.04072195  0.          0.4592842 ]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 2839 is [True, False, False, False, True, False]
Current timestep = 2840. State = [[-0.26805663  0.01312252]]. Action = [[ 0.07820006 -0.05787431  0.          0.8641069 ]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 2840 is [True, False, False, False, True, False]
State prediction error at timestep 2840 is 0.012
Human Feedback received at timestep 2840 of None
Current timestep = 2841. State = [[-0.2688506   0.01176475]]. Action = [[-0.07180932  0.01490501  0.          0.773139  ]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 2841 is [True, False, False, False, True, False]
Current timestep = 2842. State = [[-0.27340928  0.01528622]]. Action = [[-0.05561684  0.06710478  0.          0.11019707]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 2842 is [True, False, False, False, True, False]
Current timestep = 2843. State = [[-0.27728188  0.01638589]]. Action = [[-0.03716358 -0.02030725  0.          0.73834395]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 2843 is [True, False, False, False, True, False]
Current timestep = 2844. State = [[-0.27590564  0.0117883 ]]. Action = [[ 0.06041247 -0.08406696  0.          0.6420597 ]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 2844 is [True, False, False, False, True, False]
State prediction error at timestep 2844 is 0.012
Human Feedback received at timestep 2844 of None
Current timestep = 2845. State = [[-0.27177468  0.00802629]]. Action = [[ 0.05791887 -0.01897822  0.         -0.38445473]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 2845 is [True, False, False, False, True, False]
Current timestep = 2846. State = [[-0.26954156  0.00505232]]. Action = [[ 0.0130861  -0.03458457  0.         -0.92470443]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 2846 is [True, False, False, False, True, False]
State prediction error at timestep 2846 is 0.012
Human Feedback received at timestep 2846 of None
Current timestep = 2847. State = [[-0.26965043  0.00805519]]. Action = [[-0.01077629  0.09416851  0.          0.8435991 ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 2847 is [True, False, False, False, True, False]
Current timestep = 2848. State = [[-0.2674741   0.01121197]]. Action = [[0.05900755 0.01794361 0.         0.77986765]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 2848 is [True, False, False, False, True, False]
Current timestep = 2849. State = [[-0.26401356  0.00903841]]. Action = [[ 0.04339083 -0.05021323  0.          0.5928004 ]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 2849 is [True, False, False, False, True, False]
Current timestep = 2850. State = [[-0.2641963   0.01132192]]. Action = [[-0.03005417  0.08160051  0.          0.87916005]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 2850 is [True, False, False, False, True, False]
State prediction error at timestep 2850 is 0.012
Human Feedback received at timestep 2850 of None
Current timestep = 2851. State = [[-0.26897416  0.01156187]]. Action = [[-0.08351289 -0.04112583  0.         -0.09306729]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 2851 is [True, False, False, False, True, False]
Current timestep = 2852. State = [[-0.27197358  0.01485442]]. Action = [[-0.01416779  0.08377206  0.         -0.61180717]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 2852 is [True, False, False, False, True, False]
State prediction error at timestep 2852 is 0.012
Human Feedback received at timestep 2852 of None
Current timestep = 2853. State = [[-0.26939797  0.01605022]]. Action = [[ 0.073038   -0.0320827   0.          0.12460256]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 2853 is [True, False, False, False, True, False]
State prediction error at timestep 2853 is 0.012
Human Feedback received at timestep 2853 of None
Current timestep = 2854. State = [[-0.26696187  0.01790324]]. Action = [[ 0.01610794  0.04636381  0.         -0.29176986]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 2854 is [True, False, False, False, True, False]
State prediction error at timestep 2854 is 0.012
Human Feedback received at timestep 2854 of None
Current timestep = 2855. State = [[-0.26776204  0.01881412]]. Action = [[-0.02298452 -0.01703602  0.         -0.20380038]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 2855 is [True, False, False, False, True, False]
Current timestep = 2856. State = [[-0.2688903   0.02219727]]. Action = [[-0.00732831  0.06591538  0.          0.19127882]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 2856 is [True, False, False, False, True, False]
Current timestep = 2857. State = [[-0.27168715  0.02337093]]. Action = [[-0.04775634 -0.02846345  0.         -0.8625185 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 2857 is [True, False, False, False, True, False]
State prediction error at timestep 2857 is 0.012
Human Feedback received at timestep 2857 of None
Current timestep = 2858. State = [[-0.2739218   0.01853475]]. Action = [[-0.02129827 -0.09642497  0.          0.24378991]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 2858 is [True, False, False, False, True, False]
Current timestep = 2859. State = [[-0.27449748  0.01724373]]. Action = [[-0.0044131   0.0244662   0.          0.93224645]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 2859 is [True, False, False, False, True, False]
State prediction error at timestep 2859 is 0.012
Human Feedback received at timestep 2859 of None
Current timestep = 2860. State = [[-0.27121633  0.01787449]]. Action = [[ 0.07043766 -0.00175197  0.         -0.22272646]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 2860 is [True, False, False, False, True, False]
Current timestep = 2861. State = [[-0.27387655  0.01983081]]. Action = [[-0.0993869   0.03809624  0.          0.2989323 ]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 2861 is [True, False, False, False, True, False]
Current timestep = 2862. State = [[-0.28123403  0.02110137]]. Action = [[-0.0871528  -0.00227851  0.          0.94303286]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 2862 is [True, False, False, False, True, False]
Current timestep = 2863. State = [[-0.28729585  0.02343601]]. Action = [[-0.05466788  0.03943451  0.         -0.20011157]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 2863 is [True, False, False, False, True, False]
State prediction error at timestep 2863 is 0.012
Human Feedback received at timestep 2863 of None
Current timestep = 2864. State = [[-0.29072472  0.02770143]]. Action = [[-0.00872032  0.05312651  0.         -0.91688293]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 2864 is [True, False, False, False, True, False]
Current timestep = 2865. State = [[-0.28877637  0.02596833]]. Action = [[ 0.08030119 -0.07642142  0.         -0.54981667]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 2865 is [True, False, False, False, True, False]
State prediction error at timestep 2865 is 0.012
Human Feedback received at timestep 2865 of None
Current timestep = 2866. State = [[-0.2908298   0.02749489]]. Action = [[-0.06125431  0.07055775  0.          0.6344043 ]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 2866 is [True, False, False, False, True, False]
State prediction error at timestep 2866 is 0.012
Human Feedback received at timestep 2866 of None
Current timestep = 2867. State = [[-0.29742056  0.03471895]]. Action = [[-0.06831578  0.09900456  0.          0.7860851 ]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 2867 is [True, False, False, False, True, False]
Current timestep = 2868. State = [[-0.2998143   0.03905842]]. Action = [[0.03291511 0.01389082 0.         0.9575908 ]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 2868 is [True, False, False, False, True, False]
Current timestep = 2869. State = [[-0.30075336  0.0375202 ]]. Action = [[-0.00080974 -0.05651418  0.          0.21001291]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 2869 is [True, False, False, False, True, False]
Current timestep = 2870. State = [[-0.2980675   0.04026529]]. Action = [[0.08462148 0.07808747 0.         0.32948828]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 2870 is [True, False, False, False, True, False]
Current timestep = 2871. State = [[-0.29918277  0.04611862]]. Action = [[-0.04308444  0.06374668  0.          0.281039  ]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 2871 is [True, False, False, False, True, False]
Current timestep = 2872. State = [[-0.3011351  0.0520377]]. Action = [[0.0138493  0.06512003 0.         0.21258307]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 2872 is [True, False, False, False, True, False]
Current timestep = 2873. State = [[-0.30074626  0.05502966]]. Action = [[ 0.03033925  0.00312974  0.         -0.08714581]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 2873 is [True, False, False, False, True, False]
Current timestep = 2874. State = [[-0.30205375  0.05329996]]. Action = [[-0.02771155 -0.05792408  0.          0.96487486]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 2874 is [True, False, False, False, True, False]
Current timestep = 2875. State = [[-0.3045085   0.05341773]]. Action = [[-0.02947526  0.01646952  0.         -0.52888167]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 2875 is [True, False, False, False, True, False]
Current timestep = 2876. State = [[-0.3102123   0.05299142]]. Action = [[-0.09881472 -0.03657147  0.          0.37047863]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 2876 is [True, False, False, False, True, False]
Current timestep = 2877. State = [[-0.31242642  0.0497795 ]]. Action = [[ 0.0086048  -0.06173895  0.          0.26148772]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 2877 is [True, False, False, False, True, False]
Current timestep = 2878. State = [[-0.31094983  0.04769598]]. Action = [[ 0.02415378 -0.01201545  0.         -0.97788966]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 2878 is [True, False, False, False, True, False]
Current timestep = 2879. State = [[-0.31503296  0.05072744]]. Action = [[-0.09928407  0.0668998   0.          0.4836607 ]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 2879 is [True, False, False, False, True, False]
Current timestep = 2880. State = [[-0.31598678  0.04983282]]. Action = [[ 0.04352557 -0.06116438  0.          0.24985349]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 2880 is [True, False, False, False, True, False]
State prediction error at timestep 2880 is 0.012
Human Feedback received at timestep 2880 of None
Current timestep = 2881. State = [[-0.31082484  0.04571454]]. Action = [[ 0.08831223 -0.04414525  0.          0.5365522 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 2881 is [True, False, False, False, True, False]
Current timestep = 2882. State = [[-0.31028295  0.04337762]]. Action = [[-0.04332246 -0.00841836  0.         -0.07083112]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 2882 is [True, False, False, False, True, False]
State prediction error at timestep 2882 is 0.012
Human Feedback received at timestep 2882 of None
Current timestep = 2883. State = [[-0.31136224  0.04262334]]. Action = [[-3.4995377e-04  2.1078959e-03  0.0000000e+00  6.3222504e-01]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 2883 is [True, False, False, False, True, False]
Current timestep = 2884. State = [[-0.30921954  0.04261212]]. Action = [[0.04799844 0.01226594 0.         0.4422102 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 2884 is [True, False, False, False, True, False]
Current timestep = 2885. State = [[-0.30583858  0.04574156]]. Action = [[ 0.04891122  0.07035556  0.         -0.80817634]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 2885 is [True, False, False, False, True, False]
State prediction error at timestep 2885 is 0.012
Human Feedback received at timestep 2885 of None
Current timestep = 2886. State = [[-0.30877876  0.04361372]]. Action = [[-0.09055342 -0.07635029  0.         -0.25132918]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 2886 is [True, False, False, False, True, False]
Current timestep = 2887. State = [[-0.31636938  0.04479057]]. Action = [[-0.09779035  0.07034696  0.          0.22889733]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 2887 is [True, False, False, False, True, False]
Current timestep = 2888. State = [[-0.3242446   0.04969537]]. Action = [[-0.08047329  0.05782095  0.         -0.6700587 ]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 2888 is [True, False, False, False, True, False]
Current timestep = 2889. State = [[-0.3309705   0.05040683]]. Action = [[-0.05781619 -0.0306798   0.          0.78193355]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 2889 is [True, False, False, False, True, False]
Current timestep = 2890. State = [[-0.3306771   0.05272598]]. Action = [[ 0.08125294  0.05487185  0.         -0.9514756 ]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 2890 is [True, False, False, False, True, False]
Current timestep = 2891. State = [[-0.32965475  0.0513653 ]]. Action = [[ 0.00716519 -0.06442706  0.          0.01348615]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 2891 is [True, False, False, False, True, False]
State prediction error at timestep 2891 is 0.012
Human Feedback received at timestep 2891 of None
Current timestep = 2892. State = [[-0.33147717  0.04666848]]. Action = [[-0.02991144 -0.06334147  0.         -0.20295483]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 2892 is [True, False, False, False, True, False]
Current timestep = 2893. State = [[-0.32928494  0.03991879]]. Action = [[ 0.06648477 -0.09598911  0.          0.13839614]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 2893 is [True, False, False, False, True, False]
Current timestep = 2894. State = [[-0.32435232  0.03723025]]. Action = [[0.06367447 0.01702617 0.         0.00148177]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 2894 is [True, False, False, False, True, False]
Current timestep = 2895. State = [[-0.31788534  0.03194477]]. Action = [[ 0.08915704 -0.09388638  0.          0.67748475]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 2895 is [True, False, False, False, True, False]
Current timestep = 2896. State = [[-0.31362996  0.03096255]]. Action = [[ 0.02170537  0.06035794  0.         -0.8301707 ]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 2896 is [True, False, False, False, True, False]
State prediction error at timestep 2896 is 0.012
Human Feedback received at timestep 2896 of None
Current timestep = 2897. State = [[-0.31460196  0.03526542]]. Action = [[-0.04512536  0.07727876  0.          0.57252   ]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 2897 is [True, False, False, False, True, False]
Current timestep = 2898. State = [[-0.31952387  0.03224309]]. Action = [[-0.08810958 -0.0991945   0.          0.00902581]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 2898 is [True, False, False, False, True, False]
State prediction error at timestep 2898 is 0.012
Human Feedback received at timestep 2898 of None
Current timestep = 2899. State = [[-0.3200662   0.03175415]]. Action = [[ 0.03326385  0.05831862  0.         -0.46203536]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 2899 is [True, False, False, False, True, False]
Current timestep = 2900. State = [[-0.3192697   0.03742375]]. Action = [[0.00083441 0.09137148 0.         0.8341582 ]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 2900 is [True, False, False, False, True, False]
Current timestep = 2901. State = [[-0.3182974   0.04172603]]. Action = [[ 0.02854916  0.03178822  0.         -0.06780511]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 2901 is [True, False, False, False, True, False]
Current timestep = 2902. State = [[-0.31651017  0.04387623]]. Action = [[ 0.03050398  0.01725502  0.         -0.42991185]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 2902 is [True, False, False, False, True, False]
Current timestep = 2903. State = [[-0.32032204  0.04171709]]. Action = [[-0.09647069 -0.06481621  0.          0.3905486 ]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 2903 is [True, False, False, False, True, False]
Current timestep = 2904. State = [[-0.32284346  0.04444286]]. Action = [[0.01025063 0.08070741 0.         0.6280632 ]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 2904 is [True, False, False, False, True, False]
State prediction error at timestep 2904 is 0.012
Human Feedback received at timestep 2904 of None
Current timestep = 2905. State = [[-0.32233375  0.04724929]]. Action = [[ 0.02150066 -0.00231255  0.          0.87490225]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 2905 is [True, False, False, False, True, False]
Current timestep = 2906. State = [[-0.32348898  0.04912369]]. Action = [[-0.02549762  0.02219699  0.         -0.7616906 ]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 2906 is [True, False, False, False, True, False]
Current timestep = 2907. State = [[-0.32297152  0.04731983]]. Action = [[ 0.03170725 -0.06376389  0.          0.94102097]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 2907 is [True, False, False, False, True, False]
Current timestep = 2908. State = [[-0.31849575  0.04691318]]. Action = [[0.07573598 0.02067329 0.         0.06265306]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 2908 is [True, False, False, False, True, False]
Current timestep = 2909. State = [[-0.3207325   0.04811698]]. Action = [[-0.09736284  0.0075654   0.         -0.6391844 ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 2909 is [True, False, False, False, True, False]
State prediction error at timestep 2909 is 0.012
Human Feedback received at timestep 2909 of None
Current timestep = 2910. State = [[-0.32460275  0.05013848]]. Action = [[-0.01851562  0.02746814  0.          0.21206689]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 2910 is [True, False, False, False, True, False]
Current timestep = 2911. State = [[-0.32603043  0.05029711]]. Action = [[-0.00354794 -0.02057995  0.          0.61577296]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 2911 is [True, False, False, False, True, False]
Current timestep = 2912. State = [[-0.32639173  0.0532862 ]]. Action = [[0.00714501 0.06596679 0.         0.14187169]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 2912 is [True, False, False, False, True, False]
Current timestep = 2913. State = [[-0.3250498   0.05560304]]. Action = [[0.03951051 0.00366678 0.         0.50870335]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 2913 is [True, False, False, False, True, False]
Current timestep = 2914. State = [[-0.32307667  0.0556412 ]]. Action = [[ 0.02889372 -0.00747639  0.          0.9172714 ]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 2914 is [True, False, False, False, True, False]
State prediction error at timestep 2914 is 0.012
Human Feedback received at timestep 2914 of None
Current timestep = 2915. State = [[-0.31929162  0.05757746]]. Action = [[ 0.06651988  0.04123037  0.         -0.11869466]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 2915 is [True, False, False, False, True, False]
Current timestep = 2916. State = [[-0.31319046  0.0624608 ]]. Action = [[0.09309619 0.07507246 0.         0.7838421 ]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 2916 is [True, False, False, False, True, False]
Current timestep = 2917. State = [[-0.3129502   0.06427567]]. Action = [[-0.05397778 -0.01264715  0.         -0.5215442 ]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 2917 is [True, False, False, False, True, False]
Current timestep = 2918. State = [[-0.31686935  0.06727074]]. Action = [[-0.04871184  0.05465933  0.         -0.9396186 ]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 2918 is [True, False, False, False, True, False]
Current timestep = 2919. State = [[-0.31719908  0.07281788]]. Action = [[0.03338813 0.06597202 0.         0.45267546]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 2919 is [True, False, False, False, True, False]
Current timestep = 2920. State = [[-0.31878808  0.07418689]]. Action = [[-0.03999225 -0.02995142  0.         -0.38589346]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 2920 is [True, False, False, False, True, False]
State prediction error at timestep 2920 is 0.012
Human Feedback received at timestep 2920 of None
Current timestep = 2921. State = [[-0.31979564  0.07686772]]. Action = [[0.00684018 0.04824639 0.         0.23995161]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 2921 is [True, False, False, False, True, False]
State prediction error at timestep 2921 is 0.012
Human Feedback received at timestep 2921 of None
Current timestep = 2922. State = [[-0.31969967  0.08227683]]. Action = [[0.00890039 0.06098091 0.         0.08633482]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 2922 is [True, False, False, False, True, False]
State prediction error at timestep 2922 is 0.012
Human Feedback received at timestep 2922 of None
Current timestep = 2923. State = [[-0.32357487  0.08460227]]. Action = [[-0.07593767 -0.01447944  0.         -0.07669169]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 2923 is [True, False, False, False, True, False]
Current timestep = 2924. State = [[-0.32431442  0.08282734]]. Action = [[ 0.03233055 -0.05618107  0.          0.43243086]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 2924 is [True, False, False, False, True, False]
State prediction error at timestep 2924 is 0.012
Human Feedback received at timestep 2924 of None
Current timestep = 2925. State = [[-0.32556623  0.07915062]]. Action = [[-0.04459542 -0.06194936  0.         -0.21815461]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 2925 is [True, False, False, False, True, False]
Current timestep = 2926. State = [[-0.32644686  0.07734472]]. Action = [[-0.00034329 -0.01470304  0.         -0.3129617 ]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 2926 is [True, False, False, False, True, False]
State prediction error at timestep 2926 is 0.012
Human Feedback received at timestep 2926 of None
Current timestep = 2927. State = [[-0.32245046  0.07576435]]. Action = [[ 0.07793755 -0.02667196  0.          0.5843452 ]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 2927 is [True, False, False, False, True, False]
State prediction error at timestep 2927 is 0.012
Human Feedback received at timestep 2927 of None
Current timestep = 2928. State = [[-0.31780866  0.07015043]]. Action = [[ 0.03977009 -0.09185674  0.         -0.83958703]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 2928 is [True, False, False, False, True, False]
Current timestep = 2929. State = [[-0.3136658   0.06790066]]. Action = [[ 0.04181812  0.02176429  0.         -0.32616526]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 2929 is [True, False, False, False, True, False]
Current timestep = 2930. State = [[-0.30718142  0.06949983]]. Action = [[ 0.09289201  0.04242169  0.         -0.2953936 ]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 2930 is [True, False, False, False, True, False]
Current timestep = 2931. State = [[-0.3049485   0.07289959]]. Action = [[-0.02122203  0.06429633  0.          0.68931043]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 2931 is [True, False, False, False, True, False]
Current timestep = 2932. State = [[-0.30758286  0.07364295]]. Action = [[-0.05587148 -0.01217561  0.          0.06934333]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 2932 is [True, False, False, False, True, False]
State prediction error at timestep 2932 is 0.012
Human Feedback received at timestep 2932 of None
Current timestep = 2933. State = [[-0.3077306   0.07479834]]. Action = [[0.02019043 0.03361704 0.         0.71248364]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 2933 is [True, False, False, False, True, False]
Current timestep = 2934. State = [[-0.3078153   0.07590099]]. Action = [[-0.01540485  0.00617709  0.          0.573755  ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 2934 is [True, False, False, False, True, False]
Current timestep = 2935. State = [[-0.30990693  0.07501985]]. Action = [[-0.03898748 -0.02447931  0.          0.6337433 ]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 2935 is [True, False, False, False, True, False]
Current timestep = 2936. State = [[-0.3132494   0.07673932]]. Action = [[-0.04856363  0.04273503  0.         -0.02064693]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 2936 is [True, False, False, False, True, False]
Current timestep = 2937. State = [[-0.31437242  0.07723231]]. Action = [[ 0.00948638 -0.02269305  0.          0.6810894 ]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 2937 is [True, False, False, False, True, False]
Current timestep = 2938. State = [[-0.31397745  0.07399324]]. Action = [[ 0.0048971  -0.0597124   0.          0.35941637]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 2938 is [True, False, False, False, True, False]
Current timestep = 2939. State = [[-0.31194913  0.06848256]]. Action = [[ 0.03348606 -0.07692319  0.          0.48990297]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 2939 is [True, False, False, False, True, False]
Current timestep = 2940. State = [[-0.30844456  0.06450032]]. Action = [[ 0.04301893 -0.02649803  0.          0.61806214]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 2940 is [True, False, False, False, True, False]
Current timestep = 2941. State = [[-0.30472842  0.06580456]]. Action = [[ 0.04263107  0.05808211  0.         -0.85291415]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 2941 is [True, False, False, False, True, False]
Current timestep = 2942. State = [[-0.30207777  0.06801222]]. Action = [[ 0.02556729  0.02662558  0.         -0.70926946]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 2942 is [True, False, False, False, True, False]
State prediction error at timestep 2942 is 0.012
Human Feedback received at timestep 2942 of None
Current timestep = 2943. State = [[-0.3041614   0.07185242]]. Action = [[-0.06037896  0.07017975  0.          0.52074456]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 2943 is [True, False, False, False, True, False]
Current timestep = 2944. State = [[-0.30181253  0.07567917]]. Action = [[0.08869766 0.03977553 0.         0.4470278 ]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 2944 is [True, False, False, False, True, False]
State prediction error at timestep 2944 is 0.012
Human Feedback received at timestep 2944 of None
Current timestep = 2945. State = [[-0.3028062   0.07509109]]. Action = [[-0.07551841 -0.03876625  0.         -0.6174039 ]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 2945 is [True, False, False, False, True, False]
State prediction error at timestep 2945 is 0.012
Human Feedback received at timestep 2945 of None
Current timestep = 2946. State = [[-0.30276445  0.07647451]]. Action = [[ 0.04760148  0.04541043  0.         -0.64484537]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 2946 is [True, False, False, False, True, False]
Current timestep = 2947. State = [[-0.3024001   0.08139168]]. Action = [[-0.00887313  0.06939926  0.          0.65410995]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 2947 is [True, False, False, False, True, False]
Current timestep = 2948. State = [[-0.2992552   0.08125111]]. Action = [[ 0.07607851 -0.05207597  0.         -0.64861923]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 2948 is [True, False, False, False, True, False]
Current timestep = 2949. State = [[-0.29927608  0.07775597]]. Action = [[-0.04926298 -0.05056071  0.         -0.06579494]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 2949 is [True, False, False, False, True, False]
Current timestep = 2950. State = [[-0.29787308  0.07655147]]. Action = [[ 0.04636949 -0.00161853  0.          0.7055924 ]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 2950 is [True, False, False, False, True, False]
State prediction error at timestep 2950 is 0.012
Human Feedback received at timestep 2950 of None
Current timestep = 2951. State = [[-0.30036372  0.07997154]]. Action = [[-0.08383703  0.06532306  0.         -0.8508439 ]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 2951 is [True, False, False, False, True, False]
Current timestep = 2952. State = [[-0.30566078  0.08178324]]. Action = [[-0.06460999 -0.01435646  0.         -0.53620857]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 2952 is [True, False, False, False, True, False]
Current timestep = 2953. State = [[-0.31121603  0.08286298]]. Action = [[-0.07340866  0.01191877  0.         -0.82877386]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 2953 is [True, False, False, False, True, False]
Current timestep = 2954. State = [[-0.3100201   0.07937285]]. Action = [[ 0.07488038 -0.08914082  0.          0.6923971 ]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 2954 is [True, False, False, False, True, False]
Current timestep = 2955. State = [[-0.30509982  0.07564257]]. Action = [[ 0.06107343 -0.02273978  0.          0.65110373]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 2955 is [True, False, False, False, True, False]
State prediction error at timestep 2955 is 0.012
Human Feedback received at timestep 2955 of None
Current timestep = 2956. State = [[-0.29916564  0.07257504]]. Action = [[ 0.08028968 -0.03609734  0.         -0.59904724]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 2956 is [True, False, False, False, True, False]
Current timestep = 2957. State = [[-0.29550788  0.06884351]]. Action = [[ 0.01552071 -0.03876147  0.          0.11678922]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 2957 is [True, False, False, False, True, False]
State prediction error at timestep 2957 is 0.012
Human Feedback received at timestep 2957 of None
Current timestep = 2958. State = [[-0.29488838  0.06823058]]. Action = [[-0.01450435  0.02680328  0.         -0.7666258 ]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 2958 is [True, False, False, False, True, False]
Current timestep = 2959. State = [[-0.2944145   0.07214153]]. Action = [[0.00856243 0.07964282 0.         0.6150453 ]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 2959 is [True, False, False, False, True, False]
Current timestep = 2960. State = [[-0.2898454   0.07557429]]. Action = [[ 0.0890915   0.03637344  0.         -0.21102965]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 2960 is [True, False, False, False, True, False]
State prediction error at timestep 2960 is 0.012
Human Feedback received at timestep 2960 of None
Current timestep = 2961. State = [[-0.2869306   0.07311857]]. Action = [[ 0.00336701 -0.06095182  0.          0.52601457]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 2961 is [True, False, False, False, True, False]
Current timestep = 2962. State = [[-0.28336862  0.06609656]]. Action = [[ 0.05273772 -0.09796072  0.         -0.5022703 ]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 2962 is [True, False, False, False, True, False]
Current timestep = 2963. State = [[-0.2816289   0.05931395]]. Action = [[-0.01960149 -0.06579062  0.          0.6273129 ]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 2963 is [True, False, False, False, True, False]
Current timestep = 2964. State = [[-0.28489426  0.0597976 ]]. Action = [[-0.08430059  0.06328673  0.         -0.6407362 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 2964 is [True, False, False, False, True, False]
Current timestep = 2965. State = [[-0.2913547   0.06353853]]. Action = [[-0.09915994  0.04602354  0.         -0.39816093]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 2965 is [True, False, False, False, True, False]
Current timestep = 2966. State = [[-0.2977948   0.06731786]]. Action = [[-0.07177845  0.04504255  0.         -0.5599484 ]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 2966 is [True, False, False, False, True, False]
Current timestep = 2967. State = [[-0.29701084  0.06752696]]. Action = [[ 0.07710346 -0.02750418  0.         -0.3744129 ]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 2967 is [True, False, False, False, True, False]
State prediction error at timestep 2967 is 0.012
Human Feedback received at timestep 2967 of None
Current timestep = 2968. State = [[-0.29485846  0.06420084]]. Action = [[ 0.01386263 -0.05156479  0.          0.1300149 ]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 2968 is [True, False, False, False, True, False]
Current timestep = 2969. State = [[-0.2979806   0.05928112]]. Action = [[-0.07344715 -0.0680891   0.          0.30649757]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 2969 is [True, False, False, False, True, False]
Current timestep = 2970. State = [[-0.3022604   0.05674017]]. Action = [[-0.04586687 -0.01003776  0.          0.23939729]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 2970 is [True, False, False, False, True, False]
Current timestep = 2971. State = [[-0.30040896  0.05646822]]. Action = [[ 0.07682795  0.00855111  0.         -0.4736793 ]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 2971 is [True, False, False, False, True, False]
State prediction error at timestep 2971 is 0.012
Human Feedback received at timestep 2971 of None
Current timestep = 2972. State = [[-0.30300152  0.05917843]]. Action = [[-0.08676451  0.05822017  0.         -0.00286871]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 2972 is [True, False, False, False, True, False]
Current timestep = 2973. State = [[-0.3063441   0.05670064]]. Action = [[-0.00388992 -0.08084828  0.          0.56413054]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 2973 is [True, False, False, False, True, False]
Current timestep = 2974. State = [[-0.31022605  0.05254359]]. Action = [[-0.0618374  -0.03341357  0.         -0.45826864]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 2974 is [True, False, False, False, True, False]
State prediction error at timestep 2974 is 0.012
Human Feedback received at timestep 2974 of None
Current timestep = 2975. State = [[-0.3111958   0.05221882]]. Action = [[0.0318472  0.02318932 0.         0.00772071]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 2975 is [True, False, False, False, True, False]
Current timestep = 2976. State = [[-0.30809104  0.04950354]]. Action = [[ 0.06583609 -0.05424813  0.         -0.32237792]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 2976 is [True, False, False, False, True, False]
State prediction error at timestep 2976 is 0.012
Human Feedback received at timestep 2976 of None
Current timestep = 2977. State = [[-0.30501598  0.04601818]]. Action = [[ 0.03618792 -0.02164286  0.         -0.796281  ]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 2977 is [True, False, False, False, True, False]
Current timestep = 2978. State = [[-0.30868807  0.04726094]]. Action = [[-0.09143034  0.05582847  0.         -0.842971  ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 2978 is [True, False, False, False, True, False]
State prediction error at timestep 2978 is 0.012
Human Feedback received at timestep 2978 of None
Current timestep = 2979. State = [[-0.3097976   0.04817121]]. Action = [[ 0.04412579 -0.00137893  0.          0.89448917]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 2979 is [True, False, False, False, True, False]
Current timestep = 2980. State = [[-0.3085053   0.04578268]]. Action = [[ 0.01629336 -0.03711028  0.         -0.04064888]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 2980 is [True, False, False, False, True, False]
State prediction error at timestep 2980 is 0.012
Human Feedback received at timestep 2980 of None
Current timestep = 2981. State = [[-0.3042501   0.04189322]]. Action = [[ 0.08242    -0.04288486  0.          0.90323555]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 2981 is [True, False, False, False, True, False]
Current timestep = 2982. State = [[-0.30181617  0.03980438]]. Action = [[0.0021976  0.00109313 0.         0.3738817 ]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 2982 is [True, False, False, False, True, False]
Current timestep = 2983. State = [[-0.29851487  0.03498958]]. Action = [[ 0.05775376 -0.07942689  0.         -0.53049433]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 2983 is [True, False, False, False, True, False]
Current timestep = 2984. State = [[-0.29161552  0.03001187]]. Action = [[ 0.09363972 -0.03186898  0.         -0.9788873 ]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 2984 is [True, False, False, False, True, False]
Current timestep = 2985. State = [[-0.28892642  0.02788395]]. Action = [[-0.02084513  0.00354847  0.         -0.8850242 ]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 2985 is [True, False, False, False, True, False]
Current timestep = 2986. State = [[-0.2849863   0.02854764]]. Action = [[0.07137559 0.03719973 0.         0.68752146]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 2986 is [True, False, False, False, True, False]
State prediction error at timestep 2986 is 0.012
Human Feedback received at timestep 2986 of None
Current timestep = 2987. State = [[-0.2775234   0.02953237]]. Action = [[ 0.09791742  0.02314825  0.         -0.72854906]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 2987 is [True, False, False, False, True, False]
State prediction error at timestep 2987 is 0.012
Human Feedback received at timestep 2987 of None
Current timestep = 2988. State = [[-0.27328008  0.0321459 ]]. Action = [[ 0.01311302  0.05963082  0.         -0.33557057]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 2988 is [True, False, False, False, True, False]
Current timestep = 2989. State = [[-0.27488092  0.0318272 ]]. Action = [[-0.06360528 -0.03029365  0.          0.78585315]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 2989 is [True, False, False, False, True, False]
State prediction error at timestep 2989 is 0.012
Human Feedback received at timestep 2989 of None
Current timestep = 2990. State = [[-0.27391064  0.02760335]]. Action = [[ 0.03001822 -0.06446657  0.         -0.65224767]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 2990 is [True, False, False, False, True, False]
State prediction error at timestep 2990 is 0.012
Human Feedback received at timestep 2990 of None
Current timestep = 2991. State = [[-0.27599207  0.02172052]]. Action = [[-0.089276   -0.07573356  0.          0.60543704]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 2991 is [True, False, False, False, True, False]
Current timestep = 2992. State = [[-0.28158212  0.01942197]]. Action = [[-0.09689713  0.0024208   0.         -0.53654855]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 2992 is [True, False, False, False, True, False]
Current timestep = 2993. State = [[-0.2830628   0.02247434]]. Action = [[ 0.01288049  0.06419802  0.         -0.22693217]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 2993 is [True, False, False, False, True, False]
Current timestep = 2994. State = [[-0.28239453  0.02082396]]. Action = [[ 0.0034642  -0.0703121   0.         -0.43575144]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 2994 is [True, False, False, False, True, False]
Current timestep = 2995. State = [[-0.28444588  0.019532  ]]. Action = [[-0.05057778  0.01554527  0.          0.9433844 ]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 2995 is [True, False, False, False, True, False]
Current timestep = 2996. State = [[-0.28823927  0.01791488]]. Action = [[-0.05010027 -0.03855805  0.          0.90343714]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 2996 is [True, False, False, False, True, False]
Current timestep = 2997. State = [[-0.28737843  0.01356216]]. Action = [[ 0.04930159 -0.06169039  0.          0.88315773]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 2997 is [True, False, False, False, True, False]
Current timestep = 2998. State = [[-0.29088804  0.01121011]]. Action = [[-0.09998835 -0.00162631  0.          0.11141753]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 2998 is [True, False, False, False, True, False]
State prediction error at timestep 2998 is 0.012
Human Feedback received at timestep 2998 of None
Current timestep = 2999. State = [[-0.29472893  0.00827546]]. Action = [[-0.01417574 -0.04803657  0.          0.2868383 ]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 2999 is [True, False, False, False, True, False]
Current timestep = 3000. State = [[-0.2963997   0.00370759]]. Action = [[-0.01149047 -0.05155348  0.         -0.1612637 ]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 3000 is [True, False, False, False, True, False]
Current timestep = 3001. State = [[-0.29433924  0.00087607]]. Action = [[ 0.06376626 -0.00825875  0.          0.12372327]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 3001 is [True, False, False, False, True, False]
Current timestep = 3002. State = [[-0.292217   -0.00232013]]. Action = [[ 0.02316032 -0.03697425  0.          0.01855946]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 3002 is [True, False, False, False, True, False]
Current timestep = 3003. State = [[-0.29280347 -0.00287036]]. Action = [[-0.01418868  0.0332083   0.         -0.10993016]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 3003 is [True, False, False, False, True, False]
State prediction error at timestep 3003 is 0.012
Human Feedback received at timestep 3003 of None
Current timestep = 3004. State = [[-0.2986158  -0.00107324]]. Action = [[-0.09654845  0.03733893  0.          0.2685076 ]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 3004 is [True, False, False, False, True, False]
State prediction error at timestep 3004 is 0.012
Human Feedback received at timestep 3004 of None
Current timestep = 3005. State = [[-0.29972714 -0.00446763]]. Action = [[ 0.05380272 -0.07701646  0.          0.44162273]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 3005 is [True, False, False, False, True, False]
Current timestep = 3006. State = [[-0.29849508 -0.00262828]]. Action = [[ 0.01219958  0.09683325  0.         -0.55772704]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 3006 is [True, False, False, False, True, False]
Current timestep = 3007. State = [[-0.29969552 -0.00243463]]. Action = [[-0.01540823 -0.04164323  0.         -0.883029  ]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 3007 is [True, False, False, False, True, False]
Current timestep = 3008. State = [[-0.30120662 -0.00706466]]. Action = [[-0.01308693 -0.06453219  0.          0.29067743]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 3008 is [True, False, False, False, True, False]
Current timestep = 3009. State = [[-0.3016158  -0.01236288]]. Action = [[ 0.00167941 -0.05791301  0.         -0.00214571]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 3009 is [True, False, False, False, True, False]
State prediction error at timestep 3009 is 0.012
Human Feedback received at timestep 3009 of None
Current timestep = 3010. State = [[-0.30295578 -0.0117064 ]]. Action = [[-0.02689973  0.06173023  0.          0.61070275]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 3010 is [True, False, False, False, True, False]
State prediction error at timestep 3010 is 0.012
Human Feedback received at timestep 3010 of None
Current timestep = 3011. State = [[-0.30648047 -0.01177751]]. Action = [[-0.05069232 -0.02626137  0.          0.49877048]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 3011 is [True, False, False, False, True, False]
Current timestep = 3012. State = [[-0.3045264  -0.01170959]]. Action = [[0.08031946 0.02233847 0.         0.9637008 ]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 3012 is [True, False, False, False, True, False]
Current timestep = 3013. State = [[-0.30679902 -0.01009625]]. Action = [[-0.08590695  0.02642184  0.          0.28332508]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 3013 is [True, False, False, False, True, False]
Current timestep = 3014. State = [[-0.3081325  -0.01347262]]. Action = [[ 0.03363206 -0.08113182  0.         -0.92711425]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 3014 is [True, False, False, False, True, False]
Current timestep = 3015. State = [[-0.31085977 -0.01162899]]. Action = [[-0.06132736  0.08885112  0.         -0.10440511]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 3015 is [True, False, False, False, True, False]
State prediction error at timestep 3015 is 0.012
Human Feedback received at timestep 3015 of None
Current timestep = 3016. State = [[-0.31661695 -0.01341741]]. Action = [[-0.06970875 -0.08903399  0.          0.67327714]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 3016 is [True, False, False, False, True, False]
Current timestep = 3017. State = [[-0.3178017  -0.01511734]]. Action = [[ 0.03012351  0.01748829  0.         -0.6064128 ]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 3017 is [True, False, False, False, True, False]
Current timestep = 3018. State = [[-0.31694153 -0.01005599]]. Action = [[0.02330287 0.09555652 0.         0.5006182 ]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 3018 is [True, False, False, False, True, False]
Current timestep = 3019. State = [[-0.3215739  -0.00799692]]. Action = [[-0.08445354 -0.01857416  0.         -0.67540467]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 3019 is [True, False, False, False, True, False]
State prediction error at timestep 3019 is 0.012
Human Feedback received at timestep 3019 of None
Current timestep = 3020. State = [[-0.32196477 -0.01262382]]. Action = [[ 0.06231245 -0.08922744  0.          0.7929783 ]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 3020 is [True, False, False, False, True, False]
Current timestep = 3021. State = [[-0.3201515  -0.01847577]]. Action = [[ 0.01216976 -0.0625025   0.          0.24706912]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 3021 is [True, False, False, False, True, False]
State prediction error at timestep 3021 is 0.012
Human Feedback received at timestep 3021 of None
Current timestep = 3022. State = [[-0.31635427 -0.02160203]]. Action = [[ 0.06953717 -0.01464842  0.          0.34534526]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 3022 is [True, False, False, False, True, False]
Current timestep = 3023. State = [[-0.31515998 -0.02740058]]. Action = [[-0.02058483 -0.09241585  0.         -0.30612946]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 3023 is [True, False, False, False, True, False]
State prediction error at timestep 3023 is 0.012
Human Feedback received at timestep 3023 of None
Current timestep = 3024. State = [[-0.3181236  -0.02863649]]. Action = [[-0.06323619  0.04893316  0.         -0.8069214 ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 3024 is [True, False, False, False, True, False]
State prediction error at timestep 3024 is 0.012
Human Feedback received at timestep 3024 of None
Current timestep = 3025. State = [[-0.31686282 -0.03141702]]. Action = [[ 0.05898651 -0.06165546  0.          0.12079024]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 3025 is [True, False, False, False, True, False]
State prediction error at timestep 3025 is 0.012
Human Feedback received at timestep 3025 of None
Current timestep = 3026. State = [[-0.31583092 -0.03128034]]. Action = [[-0.01895482  0.05876806  0.         -0.18824422]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 3026 is [True, False, False, False, True, False]
State prediction error at timestep 3026 is 0.012
Human Feedback received at timestep 3026 of None
Current timestep = 3027. State = [[-0.3185967  -0.02983084]]. Action = [[-0.0501359   0.01391067  0.         -0.13668585]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 3027 is [True, False, False, False, True, False]
Current timestep = 3028. State = [[-0.3221269  -0.02816306]]. Action = [[-0.04072555  0.03530515  0.          0.8888705 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 3028 is [True, False, False, False, True, False]
Current timestep = 3029. State = [[-0.32214335 -0.02954782]]. Action = [[ 0.03204168 -0.04332377  0.          0.4844358 ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 3029 is [True, False, False, False, True, False]
Current timestep = 3030. State = [[-0.32042205 -0.03383845]]. Action = [[ 0.02400015 -0.05641509  0.         -0.47395617]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 3030 is [True, False, False, False, True, False]
Current timestep = 3031. State = [[-0.3211206  -0.03445522]]. Action = [[-0.02655125  0.02991959  0.          0.62059474]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 3031 is [True, False, False, False, True, False]
Current timestep = 3032. State = [[-0.32326463 -0.03760798]]. Action = [[-0.02714456 -0.07143514  0.          0.5449245 ]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 3032 is [True, False, False, False, True, False]
State prediction error at timestep 3032 is 0.012
Human Feedback received at timestep 3032 of None
Current timestep = 3033. State = [[-0.32592186 -0.03848523]]. Action = [[-0.03772458  0.03316683  0.          0.75128114]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 3033 is [True, False, False, False, True, False]
State prediction error at timestep 3033 is 0.012
Human Feedback received at timestep 3033 of None
Current timestep = 3034. State = [[-0.32669848 -0.03403755]]. Action = [[0.01590212 0.07832672 0.         0.9034884 ]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 3034 is [True, False, False, False, True, False]
Current timestep = 3035. State = [[-0.32320663 -0.02790546]]. Action = [[ 0.08586923  0.07224938  0.         -0.08312005]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 3035 is [True, False, False, False, True, False]
Current timestep = 3036. State = [[-0.32481894 -0.02767837]]. Action = [[-0.06174206 -0.05158878  0.          0.46257043]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 3036 is [True, False, False, False, True, False]
State prediction error at timestep 3036 is 0.012
Human Feedback received at timestep 3036 of None
Current timestep = 3037. State = [[-0.33029574 -0.0257111 ]]. Action = [[-0.06126333  0.06079035  0.         -0.27562672]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 3037 is [True, False, False, False, True, False]
Current timestep = 3038. State = [[-0.33269608 -0.02124032]]. Action = [[0.01204012 0.04512431 0.         0.9358301 ]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 3038 is [True, False, False, False, True, False]
Current timestep = 3039. State = [[-0.3340216  -0.01707399]]. Action = [[-0.00451075  0.03899617  0.          0.45098186]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 3039 is [True, False, False, False, True, False]
Current timestep = 3040. State = [[-0.33569223 -0.01620349]]. Action = [[-0.00710249 -0.02562667  0.         -0.7048223 ]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 3040 is [True, False, False, False, True, False]
Current timestep = 3041. State = [[-0.33551365 -0.0111204 ]]. Action = [[ 0.03113803  0.09729769  0.         -0.05266768]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 3041 is [True, False, False, False, True, False]
Current timestep = 3042. State = [[-0.3383075  -0.00266118]]. Action = [[-0.044419    0.09277757  0.          0.91018105]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 3042 is [True, False, False, False, True, False]
State prediction error at timestep 3042 is 0.012
Human Feedback received at timestep 3042 of None
Current timestep = 3043. State = [[-0.33928862  0.00159782]]. Action = [[ 0.03608499  0.00264188  0.         -0.02972215]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 3043 is [True, False, False, False, True, False]
State prediction error at timestep 3043 is 0.012
Human Feedback received at timestep 3043 of None
Current timestep = 3044. State = [[-0.33956748  0.0006042 ]]. Action = [[-0.00271944 -0.05219316  0.         -0.6326675 ]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 3044 is [True, False, False, False, True, False]
State prediction error at timestep 3044 is 0.012
Human Feedback received at timestep 3044 of None
Current timestep = 3045. State = [[-0.34289557  0.00456338]]. Action = [[-0.05374201  0.0858004   0.          0.5968399 ]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 3045 is [True, False, False, False, True, False]
Current timestep = 3046. State = [[-0.34800762  0.01239926]]. Action = [[-0.05443517  0.0842718   0.         -0.5727654 ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 3046 is [True, False, False, False, True, False]
State prediction error at timestep 3046 is 0.012
Human Feedback received at timestep 3046 of None
Current timestep = 3047. State = [[-0.3531488   0.02063715]]. Action = [[-0.04574675  0.08478723  0.          0.08184135]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 3047 is [True, False, False, False, True, False]
Current timestep = 3048. State = [[-0.355944    0.02332012]]. Action = [[-0.00078736 -0.03187103  0.         -0.78586334]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 3048 is [True, False, False, False, True, False]
Current timestep = 3049. State = [[-0.35850558  0.02262498]]. Action = [[-0.03165862 -0.03072178  0.         -0.06553704]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 3049 is [True, False, False, False, True, False]
Current timestep = 3050. State = [[-0.3585788   0.02645877]]. Action = [[ 0.03423291  0.06838503  0.         -0.95160025]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 3050 is [True, False, False, False, True, False]
Current timestep = 3051. State = [[-0.35645345  0.03159801]]. Action = [[ 0.04840409  0.03985647  0.         -0.07664555]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 3051 is [True, False, False, False, True, False]
Current timestep = 3052. State = [[-0.3595894   0.03095569]]. Action = [[-0.08097395 -0.06210563  0.         -0.23227036]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 3052 is [True, False, False, False, True, False]
State prediction error at timestep 3052 is 0.012
Human Feedback received at timestep 3052 of None
Current timestep = 3053. State = [[-0.36219615  0.02636844]]. Action = [[-0.00179533 -0.0778831   0.         -0.3531705 ]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 3053 is [True, False, False, False, True, False]
Current timestep = 3054. State = [[-0.35889694  0.02531289]]. Action = [[0.07475921 0.01658193 0.         0.07048833]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 3054 is [True, False, False, False, True, False]
State prediction error at timestep 3054 is 0.012
Human Feedback received at timestep 3054 of None
Current timestep = 3055. State = [[-0.35459238  0.02414586]]. Action = [[ 0.04708122 -0.03232715  0.          0.49505663]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 3055 is [True, False, False, False, True, False]
Current timestep = 3056. State = [[-0.35562652  0.02648065]]. Action = [[-0.05523206  0.06769081  0.         -0.34401727]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 3056 is [True, False, False, False, True, False]
Current timestep = 3057. State = [[-0.3553899   0.03213195]]. Action = [[ 0.03958686  0.07665186  0.         -0.5598531 ]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 3057 is [True, False, False, False, True, False]
Current timestep = 3058. State = [[-0.35075757  0.03867603]]. Action = [[0.08888688 0.08447678 0.         0.52341294]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 3058 is [True, False, False, False, True, False]
Current timestep = 3059. State = [[-0.35197675  0.04362048]]. Action = [[-0.06489308  0.04299212  0.         -0.28153813]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 3059 is [True, False, False, False, True, False]
Current timestep = 3060. State = [[-0.35323107  0.04437678]]. Action = [[ 0.02610856 -0.02390458  0.         -0.9115642 ]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 3060 is [True, False, False, False, True, False]
State prediction error at timestep 3060 is 0.012
Human Feedback received at timestep 3060 of None
Current timestep = 3061. State = [[-0.3523382   0.04409987]]. Action = [[ 0.01576661 -0.00662646  0.         -0.58210486]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 3061 is [True, False, False, False, True, False]
Current timestep = 3062. State = [[-0.34881875  0.04427763]]. Action = [[ 0.06687149 -0.00446219  0.         -0.3419789 ]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 3062 is [True, False, False, False, True, False]
State prediction error at timestep 3062 is 0.012
Human Feedback received at timestep 3062 of None
Current timestep = 3063. State = [[-0.34539205  0.04026595]]. Action = [[ 0.02493878 -0.08798358  0.         -0.95264125]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 3063 is [True, False, False, False, True, False]
Current timestep = 3064. State = [[-0.34719998  0.04170358]]. Action = [[-0.06890298  0.07437164  0.          0.45762098]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 3064 is [True, False, False, False, True, False]
Current timestep = 3065. State = [[-0.34587064  0.04112167]]. Action = [[ 0.05232754 -0.06148351  0.         -0.6755893 ]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 3065 is [True, False, False, False, True, False]
State prediction error at timestep 3065 is 0.012
Human Feedback received at timestep 3065 of None
Current timestep = 3066. State = [[-0.34686285  0.03723293]]. Action = [[-0.06932256 -0.05035777  0.          0.07737243]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 3066 is [True, False, False, False, True, False]
Current timestep = 3067. State = [[-0.34753108  0.03535196]]. Action = [[ 0.0031489  -0.00925008  0.         -0.14180195]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 3067 is [True, False, False, False, True, False]
Current timestep = 3068. State = [[-0.34721872  0.0345463 ]]. Action = [[-0.00947928 -0.00660595  0.         -0.6567737 ]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 3068 is [True, False, False, False, True, False]
Current timestep = 3069. State = [[-0.34383443  0.0357463 ]]. Action = [[0.06516873 0.0346987  0.         0.96020854]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 3069 is [True, False, False, False, True, False]
Current timestep = 3070. State = [[-0.3419703   0.03703202]]. Action = [[-0.00239095  0.01370813  0.          0.27133417]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 3070 is [True, False, False, False, True, False]
Current timestep = 3071. State = [[-0.3463315   0.04047705]]. Action = [[-0.09199385  0.06385892  0.          0.41072154]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 3071 is [True, False, False, False, True, False]
Current timestep = 3072. State = [[-0.34916753  0.04530812]]. Action = [[ 0.00306787  0.05638015  0.         -0.39239675]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 3072 is [True, False, False, False, True, False]
Current timestep = 3073. State = [[-0.3485572   0.04850649]]. Action = [[0.03115777 0.02249448 0.         0.6759033 ]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 3073 is [True, False, False, False, True, False]
Current timestep = 3074. State = [[-0.34846446  0.05001925]]. Action = [[0.00166972 0.00669332 0.         0.7546712 ]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 3074 is [True, False, False, False, True, False]
Current timestep = 3075. State = [[-0.3455613   0.04844311]]. Action = [[ 0.06995245 -0.04590033  0.         -0.7972009 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 3075 is [True, False, False, False, True, False]
Current timestep = 3076. State = [[-0.3443624   0.04589181]]. Action = [[-0.01332127 -0.03190542  0.         -0.98557454]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 3076 is [True, False, False, False, True, False]
Current timestep = 3077. State = [[-0.3436414  0.0459588]]. Action = [[ 0.0170183   0.01554819  0.         -0.99504375]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 3077 is [True, False, False, False, True, False]
Current timestep = 3078. State = [[-0.34702358  0.04390426]]. Action = [[-0.08660313 -0.05575731  0.          0.6451957 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 3078 is [True, False, False, False, True, False]
Current timestep = 3079. State = [[-0.34814218  0.04661934]]. Action = [[ 0.02391269  0.08207788  0.         -0.6074826 ]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 3079 is [True, False, False, False, True, False]
State prediction error at timestep 3079 is 0.012
Human Feedback received at timestep 3079 of None
Current timestep = 3080. State = [[-0.34420788  0.04827454]]. Action = [[ 0.07296982 -0.0154584   0.         -0.9651902 ]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 3080 is [True, False, False, False, True, False]
Current timestep = 3081. State = [[-0.34287742  0.04908129]]. Action = [[-0.0159316   0.02231779  0.          0.2280916 ]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 3081 is [True, False, False, False, True, False]
Current timestep = 3082. State = [[-0.3433801   0.05152331]]. Action = [[-0.00372489  0.03380039  0.         -0.01878327]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 3082 is [True, False, False, False, True, False]
Current timestep = 3083. State = [[-0.3395304   0.05319957]]. Action = [[ 0.08317875  0.01028468  0.         -0.9493933 ]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 3083 is [True, False, False, False, True, False]
Current timestep = 3084. State = [[-0.3365912   0.04949852]]. Action = [[ 0.00718711 -0.08330927  0.         -0.40119278]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 3084 is [True, False, False, False, True, False]
Current timestep = 3085. State = [[-0.33532593  0.05002601]]. Action = [[0.00690918 0.05818165 0.         0.65533483]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 3085 is [True, False, False, False, True, False]
Current timestep = 3086. State = [[-0.3319576   0.05630932]]. Action = [[0.06032925 0.09441317 0.         0.24552739]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 3086 is [True, False, False, False, True, False]
Current timestep = 3087. State = [[-0.33327577  0.05497942]]. Action = [[-0.07254857 -0.0939492   0.          0.9036751 ]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 3087 is [True, False, False, False, True, False]
State prediction error at timestep 3087 is 0.012
Human Feedback received at timestep 3087 of None
Current timestep = 3088. State = [[-0.3365129   0.04940867]]. Action = [[-0.03742551 -0.06893219  0.         -0.64698994]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 3088 is [True, False, False, False, True, False]
Current timestep = 3089. State = [[-0.33611518  0.04369304]]. Action = [[ 0.01866813 -0.07458268  0.          0.6241245 ]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 3089 is [True, False, False, False, True, False]
State prediction error at timestep 3089 is 0.012
Human Feedback received at timestep 3089 of None
Current timestep = 3090. State = [[-0.3326215   0.03842003]]. Action = [[ 0.04692573 -0.05303913  0.         -0.02315265]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 3090 is [True, False, False, False, True, False]
Current timestep = 3091. State = [[-0.32765695  0.03878374]]. Action = [[0.06124543 0.05722397 0.         0.72509146]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 3091 is [True, False, False, False, True, False]
Current timestep = 3092. State = [[-0.32389504  0.03949078]]. Action = [[0.03246752 0.00193788 0.         0.3516581 ]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 3092 is [True, False, False, False, True, False]
Current timestep = 3093. State = [[-0.32548925  0.04246366]]. Action = [[-0.06106006  0.07336669  0.         -0.45142925]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 3093 is [True, False, False, False, True, False]
State prediction error at timestep 3093 is 0.012
Human Feedback received at timestep 3093 of None
Current timestep = 3094. State = [[-0.32277304  0.04218093]]. Action = [[ 0.08850352 -0.03733045  0.          0.479208  ]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 3094 is [True, False, False, False, True, False]
Current timestep = 3095. State = [[-0.3161351   0.03977954]]. Action = [[ 0.07918138 -0.01582677  0.         -0.87134117]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 3095 is [True, False, False, False, True, False]
Current timestep = 3096. State = [[-0.3166884   0.04100433]]. Action = [[-0.07513431  0.04567509  0.          0.4553306 ]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 3096 is [True, False, False, False, True, False]
Current timestep = 3097. State = [[-0.31894636  0.04554933]]. Action = [[-0.00866736  0.06927448  0.         -0.81074315]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 3097 is [True, False, False, False, True, False]
Current timestep = 3098. State = [[-0.31933746  0.04678996]]. Action = [[ 0.00382359 -0.01875042  0.         -0.12414968]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 3098 is [True, False, False, False, True, False]
Current timestep = 3099. State = [[-0.3155959   0.04159849]]. Action = [[ 0.07314057 -0.09889373  0.          0.14407527]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 3099 is [True, False, False, False, True, False]
Current timestep = 3100. State = [[-0.31282565  0.03377516]]. Action = [[ 4.6620518e-04 -9.8520182e-02  0.0000000e+00  6.2120366e-01]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 3100 is [True, False, False, False, True, False]
Current timestep = 3101. State = [[-0.30804375  0.03326309]]. Action = [[0.07774409 0.0587853  0.         0.7386234 ]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 3101 is [True, False, False, False, True, False]
Current timestep = 3102. State = [[-0.30395782  0.03789919]]. Action = [[0.026819   0.07326313 0.         0.5379417 ]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 3102 is [True, False, False, False, True, False]
Current timestep = 3103. State = [[-0.299785    0.03544516]]. Action = [[ 0.0539309  -0.08727603  0.          0.8647542 ]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 3103 is [True, False, False, False, True, False]
State prediction error at timestep 3103 is 0.012
Human Feedback received at timestep 3103 of None
Current timestep = 3104. State = [[-0.29473478  0.03066043]]. Action = [[ 0.04731665 -0.03739948  0.          0.54914474]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 3104 is [True, False, False, False, True, False]
Current timestep = 3105. State = [[-0.29360533  0.02923781]]. Action = [[-0.03355091  0.00846924  0.          0.22239625]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 3105 is [True, False, False, False, True, False]
Current timestep = 3106. State = [[-0.28980085  0.03041022]]. Action = [[ 0.0713504   0.0321091   0.         -0.68296474]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 3106 is [True, False, False, False, True, False]
Current timestep = 3107. State = [[-0.28695413  0.02925807]]. Action = [[-0.00460202 -0.03061417  0.          0.8252244 ]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 3107 is [True, False, False, False, True, False]
Current timestep = 3108. State = [[-0.29023358  0.0236531 ]]. Action = [[-0.09877887 -0.08883055  0.          0.6183559 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 3108 is [True, False, False, False, True, False]
Current timestep = 3109. State = [[-0.28871566  0.02162234]]. Action = [[ 0.06311003  0.02052583  0.         -0.95989054]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 3109 is [True, False, False, False, True, False]
Current timestep = 3110. State = [[-0.28654048  0.01706325]]. Action = [[-0.01879413 -0.08926498  0.         -0.9965943 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 3110 is [True, False, False, False, True, False]
Current timestep = 3111. State = [[-0.2868217   0.01557306]]. Action = [[-0.02823609  0.03486549  0.          0.44014096]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 3111 is [True, False, False, False, True, False]
Current timestep = 3112. State = [[-0.28944778  0.01515951]]. Action = [[-0.05958042 -0.01475339  0.          0.6840985 ]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 3112 is [True, False, False, False, True, False]
Current timestep = 3113. State = [[-0.28949064  0.0169565 ]]. Action = [[0.02144966 0.05243228 0.         0.21599197]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 3113 is [True, False, False, False, True, False]
Current timestep = 3114. State = [[-0.28842014  0.01894328]]. Action = [[ 0.01109674  0.01572895  0.         -0.0818572 ]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 3114 is [True, False, False, False, True, False]
Current timestep = 3115. State = [[-0.29084548  0.0213063 ]]. Action = [[-0.05196645  0.03886699  0.         -0.47805238]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 3115 is [True, False, False, False, True, False]
State prediction error at timestep 3115 is 0.012
Human Feedback received at timestep 3115 of None
Current timestep = 3116. State = [[-0.29724813  0.02064462]]. Action = [[-0.09505019 -0.04082897  0.          0.59841895]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 3116 is [True, False, False, False, True, False]
Current timestep = 3117. State = [[-0.30060852  0.01994545]]. Action = [[-0.00409166  0.00233968  0.          0.37302268]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 3117 is [True, False, False, False, True, False]
Current timestep = 3118. State = [[-0.29893988  0.02503143]]. Action = [[0.06118415 0.09765979 0.         0.53740215]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 3118 is [True, False, False, False, True, False]
Current timestep = 3119. State = [[-0.30047044  0.02883763]]. Action = [[-0.0360133   0.01274872  0.          0.56939363]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 3119 is [True, False, False, False, True, False]
Current timestep = 3120. State = [[-0.30159903  0.02513888]]. Action = [[ 0.01813529 -0.09436447  0.          0.97248507]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 3120 is [True, False, False, False, True, False]
Current timestep = 3121. State = [[-0.3045412   0.02216796]]. Action = [[-0.05733384 -0.01163461  0.          0.02954471]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 3121 is [True, False, False, False, True, False]
State prediction error at timestep 3121 is 0.012
Human Feedback received at timestep 3121 of None
Current timestep = 3122. State = [[-0.3061903   0.01947934]]. Action = [[ 0.00831623 -0.04811178  0.          0.31864512]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 3122 is [True, False, False, False, True, False]
Current timestep = 3123. State = [[-0.30468842  0.01312951]]. Action = [[ 0.03155591 -0.09683271  0.          0.20018637]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 3123 is [True, False, False, False, True, False]
Current timestep = 3124. State = [[-0.30530387  0.00985931]]. Action = [[-0.03341011  0.00180999  0.          0.46462595]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 3124 is [True, False, False, False, True, False]
Current timestep = 3125. State = [[-0.30182254  0.01016932]]. Action = [[0.09237396 0.023425   0.         0.740934  ]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 3125 is [True, False, False, False, True, False]
Current timestep = 3126. State = [[-0.29605803  0.00566272]]. Action = [[ 0.06613892 -0.08478954  0.          0.9216943 ]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 3126 is [True, False, False, False, True, False]
Current timestep = 3127. State = [[-0.29502374  0.00409143]]. Action = [[-0.02924168  0.03953766  0.          0.46341133]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 3127 is [True, False, False, False, True, False]
Current timestep = 3128. State = [[-0.29773065  0.00093181]]. Action = [[-0.05133484 -0.06304783  0.          0.6541624 ]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 3128 is [True, False, False, False, True, False]
Current timestep = 3129. State = [[-0.30207437 -0.00294263]]. Action = [[-0.07228255 -0.02282704  0.         -0.27398694]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 3129 is [True, False, False, False, True, False]
State prediction error at timestep 3129 is 0.012
Human Feedback received at timestep 3129 of None
Current timestep = 3130. State = [[-0.3051295  -0.00651513]]. Action = [[-0.02861308 -0.0374945   0.          0.5263139 ]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 3130 is [True, False, False, False, True, False]
Current timestep = 3131. State = [[-0.30362803 -0.00919091]]. Action = [[ 0.04655049 -0.01098207  0.         -0.64913946]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 3131 is [True, False, False, False, True, False]
State prediction error at timestep 3131 is 0.012
Human Feedback received at timestep 3131 of None
Current timestep = 3132. State = [[-0.3015242  -0.01378669]]. Action = [[ 0.01710276 -0.06348875  0.         -0.71617323]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 3132 is [True, False, False, False, True, False]
Current timestep = 3133. State = [[-0.29803434 -0.01280057]]. Action = [[0.06215293 0.08004152 0.         0.7310289 ]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 3133 is [True, False, False, False, True, False]
Current timestep = 3134. State = [[-0.29902476 -0.00777628]]. Action = [[-0.04501164  0.07381511  0.          0.45218885]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 3134 is [True, False, False, False, True, False]
State prediction error at timestep 3134 is 0.012
Human Feedback received at timestep 3134 of None
Current timestep = 3135. State = [[-0.30501208 -0.00497248]]. Action = [[-0.08290124  0.0195583   0.          0.93676484]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 3135 is [True, False, False, False, True, False]
Current timestep = 3136. State = [[-0.30393127 -0.00718765]]. Action = [[ 0.09377714 -0.05659307  0.         -0.10310102]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 3136 is [True, False, False, False, True, False]
Current timestep = 3137. State = [[-0.2979944  -0.01083729]]. Action = [[ 0.07636935 -0.03671876  0.         -0.30895114]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 3137 is [True, False, False, False, True, False]
State prediction error at timestep 3137 is 0.012
Human Feedback received at timestep 3137 of None
Current timestep = 3138. State = [[-0.30009624 -0.00802927]]. Action = [[-0.09829874  0.08569079  0.         -0.5597426 ]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 3138 is [True, False, False, False, True, False]
Current timestep = 3139. State = [[-0.30281034 -0.01025782]]. Action = [[ 0.00686173 -0.09613964  0.         -0.6619484 ]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 3139 is [True, False, False, False, True, False]
Current timestep = 3140. State = [[-0.3016815  -0.00950335]]. Action = [[0.03082068 0.0705939  0.         0.1502254 ]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 3140 is [True, False, False, False, True, False]
Current timestep = 3141. State = [[-0.3043034  -0.00707675]]. Action = [[-0.05988825  0.00912099  0.         -0.80698866]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 3141 is [True, False, False, False, True, False]
State prediction error at timestep 3141 is 0.012
Human Feedback received at timestep 3141 of None
Current timestep = 3142. State = [[-0.3023903  -0.00812527]]. Action = [[ 0.08438192 -0.03209618  0.          0.23845732]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 3142 is [True, False, False, False, True, False]
Current timestep = 3143. State = [[-0.30045012 -0.00887698]]. Action = [[-0.00481188  0.00237056  0.          0.8560039 ]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 3143 is [True, False, False, False, True, False]
Current timestep = 3144. State = [[-0.30373797 -0.00444046]]. Action = [[-0.06675862  0.08804984  0.         -0.08671427]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 3144 is [True, False, False, False, True, False]
Current timestep = 3145. State = [[-0.30343038 -0.00329328]]. Action = [[ 0.0512962  -0.03410237  0.         -0.4086957 ]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 3145 is [True, False, False, False, True, False]
Current timestep = 3146. State = [[-0.3057307  -0.00320178]]. Action = [[-0.07605407  0.01240283  0.         -0.4481604 ]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 3146 is [True, False, False, False, True, False]
Current timestep = 3147. State = [[-0.30554265 -0.00055459]]. Action = [[0.05100901 0.03872805 0.         0.72962356]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 3147 is [True, False, False, False, True, False]
State prediction error at timestep 3147 is 0.012
Human Feedback received at timestep 3147 of None
Current timestep = 3148. State = [[-0.30899033  0.00351109]]. Action = [[-0.09250989  0.04860973  0.         -0.17479962]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 3148 is [True, False, False, False, True, False]
Current timestep = 3149. State = [[-0.31662688  0.01051131]]. Action = [[-0.08989904  0.09643143  0.          0.9373827 ]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 3149 is [True, False, False, False, True, False]
State prediction error at timestep 3149 is 0.012
Human Feedback received at timestep 3149 of None
Current timestep = 3150. State = [[-0.31849858  0.01180577]]. Action = [[ 0.04199984 -0.05285343  0.          0.7888465 ]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 3150 is [True, False, False, False, True, False]
Current timestep = 3151. State = [[-0.3191349   0.01238459]]. Action = [[-0.01552079  0.01942517  0.          0.70701504]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 3151 is [True, False, False, False, True, False]
Current timestep = 3152. State = [[-0.32327792  0.01037833]]. Action = [[-0.0639056  -0.06880874  0.         -0.23082817]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 3152 is [True, False, False, False, True, False]
Current timestep = 3153. State = [[-0.32564464  0.01019706]]. Action = [[-0.002399    0.02147212  0.          0.0924499 ]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 3153 is [True, False, False, False, True, False]
Current timestep = 3154. State = [[-0.32244098  0.01315727]]. Action = [[0.08583487 0.03908708 0.         0.84505653]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 3154 is [True, False, False, False, True, False]
Current timestep = 3155. State = [[-0.31739402  0.0194529 ]]. Action = [[ 0.07810938  0.09622755  0.         -0.6424367 ]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 3155 is [True, False, False, False, True, False]
Current timestep = 3156. State = [[-0.31594273  0.0264831 ]]. Action = [[ 0.00773709  0.07678422  0.         -0.50052273]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 3156 is [True, False, False, False, True, False]
State prediction error at timestep 3156 is 0.012
Human Feedback received at timestep 3156 of None
Current timestep = 3157. State = [[-0.31404316  0.03307015]]. Action = [[0.05625512 0.07357382 0.         0.4182731 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 3157 is [True, False, False, False, True, False]
State prediction error at timestep 3157 is 0.012
Human Feedback received at timestep 3157 of None
Current timestep = 3158. State = [[-0.31767127  0.03446982]]. Action = [[-0.09431338 -0.03496975  0.          0.8181045 ]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 3158 is [True, False, False, False, True, False]
Current timestep = 3159. State = [[-0.32246748  0.03916476]]. Action = [[-0.02921029  0.08930989  0.          0.21261096]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 3159 is [True, False, False, False, True, False]
Current timestep = 3160. State = [[-0.32701734  0.03902641]]. Action = [[-0.05465564 -0.0831302   0.          0.06440413]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 3160 is [True, False, False, False, True, False]
Current timestep = 3161. State = [[-0.32675278  0.03600861]]. Action = [[ 0.04578867 -0.04104164  0.         -0.6930645 ]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 3161 is [True, False, False, False, True, False]
Current timestep = 3162. State = [[-0.32491094  0.03693637]]. Action = [[ 0.01668129  0.02787707  0.         -0.9610242 ]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 3162 is [True, False, False, False, True, False]
Current timestep = 3163. State = [[-0.3201462   0.03353943]]. Action = [[ 0.08562269 -0.09458992  0.          0.9720688 ]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 3163 is [True, False, False, False, True, False]
Current timestep = 3164. State = [[-0.31794515  0.03116565]]. Action = [[-0.01705223  0.00288409  0.          0.88839746]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 3164 is [True, False, False, False, True, False]
State prediction error at timestep 3164 is 0.012
Human Feedback received at timestep 3164 of None
Current timestep = 3165. State = [[-0.31295443  0.03002034]]. Action = [[ 0.09453013 -0.0195534   0.         -0.83859754]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 3165 is [True, False, False, False, True, False]
Current timestep = 3166. State = [[-0.31111708  0.02952795]]. Action = [[-0.03662509  0.00950225  0.          0.0907892 ]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 3166 is [True, False, False, False, True, False]
Current timestep = 3167. State = [[-0.31315976  0.03017135]]. Action = [[-0.04290066  0.01535425  0.         -0.9224766 ]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 3167 is [True, False, False, False, True, False]
State prediction error at timestep 3167 is 0.012
Human Feedback received at timestep 3167 of None
Current timestep = 3168. State = [[-0.31351846  0.0262903 ]]. Action = [[ 0.00107141 -0.08104678  0.         -0.16004479]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 3168 is [True, False, False, False, True, False]
Current timestep = 3169. State = [[-0.30932704  0.02438002]]. Action = [[ 0.07006391  0.01954713  0.         -0.1924786 ]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 3169 is [True, False, False, False, True, False]
Current timestep = 3170. State = [[-0.3070515   0.02108317]]. Action = [[-0.00820969 -0.06088423  0.          0.46409357]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 3170 is [True, False, False, False, True, False]
State prediction error at timestep 3170 is 0.012
Human Feedback received at timestep 3170 of None
Current timestep = 3171. State = [[-0.30852452  0.02077851]]. Action = [[-0.0449699   0.04297505  0.         -0.71192735]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 3171 is [True, False, False, False, True, False]
State prediction error at timestep 3171 is 0.012
Human Feedback received at timestep 3171 of None
Current timestep = 3172. State = [[-0.30658653  0.02522839]]. Action = [[ 0.06067557  0.0782804   0.         -0.2952494 ]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 3172 is [True, False, False, False, True, False]
Current timestep = 3173. State = [[-0.30817452  0.02498806]]. Action = [[-0.0683836  -0.04488425  0.          0.20441222]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 3173 is [True, False, False, False, True, False]
Current timestep = 3174. State = [[-0.31400794  0.02829215]]. Action = [[-0.08069692  0.09236332  0.          0.04786789]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 3174 is [True, False, False, False, True, False]
State prediction error at timestep 3174 is 0.012
Human Feedback received at timestep 3174 of None
Current timestep = 3175. State = [[-0.3174778   0.03552745]]. Action = [[-0.00439607  0.08825117  0.          0.04989386]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 3175 is [True, False, False, False, True, False]
Current timestep = 3176. State = [[-0.32208073  0.03925209]]. Action = [[-0.06185652  0.00805335  0.          0.70061374]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 3176 is [True, False, False, False, True, False]
Current timestep = 3177. State = [[-0.3219837   0.04146006]]. Action = [[0.06788897 0.02021937 0.         0.16083813]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 3177 is [True, False, False, False, True, False]
Current timestep = 3178. State = [[-0.32518658  0.04168341]]. Action = [[-0.08032072 -0.02578834  0.         -0.85612935]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 3178 is [True, False, False, False, True, False]
Current timestep = 3179. State = [[-0.32704264  0.0381079 ]]. Action = [[ 0.02699444 -0.07594188  0.          0.06825483]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 3179 is [True, False, False, False, True, False]
Current timestep = 3180. State = [[-0.3281349   0.03346024]]. Action = [[-0.02278644 -0.06051027  0.          0.8885622 ]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 3180 is [True, False, False, False, True, False]
Current timestep = 3181. State = [[-0.33201143  0.02875663]]. Action = [[-0.06253871 -0.06412331  0.          0.12377799]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 3181 is [True, False, False, False, True, False]
Current timestep = 3182. State = [[-0.33184028  0.02893623]]. Action = [[ 0.04588979  0.04381245  0.         -0.55174696]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 3182 is [True, False, False, False, True, False]
State prediction error at timestep 3182 is 0.012
Human Feedback received at timestep 3182 of None
Current timestep = 3183. State = [[-0.33331934  0.02858842]]. Action = [[-0.04737654 -0.02500376  0.          0.48406172]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 3183 is [True, False, False, False, True, False]
State prediction error at timestep 3183 is 0.012
Human Feedback received at timestep 3183 of None
Current timestep = 3184. State = [[-0.33946934  0.03017207]]. Action = [[-0.09251119  0.05001088  0.         -0.907294  ]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 3184 is [True, False, False, False, True, False]
Current timestep = 3185. State = [[-0.34262165  0.03565579]]. Action = [[ 0.01145081  0.08489368  0.         -0.8604153 ]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 3185 is [True, False, False, False, True, False]
Current timestep = 3186. State = [[-0.3445774   0.03702217]]. Action = [[-0.0142136  -0.02404816  0.         -0.08014882]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 3186 is [True, False, False, False, True, False]
State prediction error at timestep 3186 is 0.012
Human Feedback received at timestep 3186 of None
Current timestep = 3187. State = [[-0.34581518  0.0335785 ]]. Action = [[ 0.00545271 -0.05964365  0.         -0.48500037]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 3187 is [True, False, False, False, True, False]
Current timestep = 3188. State = [[-0.3505127   0.03421176]]. Action = [[-0.07972723  0.04819744  0.         -0.78738886]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 3188 is [True, False, False, False, True, False]
Current timestep = 3189. State = [[-0.35752678  0.03515417]]. Action = [[-0.07492111 -0.0103566   0.          0.6212666 ]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 3189 is [True, False, False, False, True, False]
Current timestep = 3190. State = [[-0.35960242  0.03492642]]. Action = [[ 0.02921312 -0.00378615  0.          0.91503215]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 3190 is [True, False, False, False, True, False]
State prediction error at timestep 3190 is 0.012
Human Feedback received at timestep 3190 of None
Current timestep = 3191. State = [[-0.35890236  0.03723589]]. Action = [[ 0.02959386  0.04906782  0.         -0.10841423]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 3191 is [True, False, False, False, True, False]
Current timestep = 3192. State = [[-0.35764226  0.03757779]]. Action = [[ 0.0377093  -0.02086832  0.         -0.3163957 ]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 3192 is [True, False, False, False, True, False]
Current timestep = 3193. State = [[-0.35330525  0.03557633]]. Action = [[ 0.08791887 -0.02658044  0.          0.70959866]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 3193 is [True, False, False, False, True, False]
Current timestep = 3194. State = [[-0.3552396  0.0361719]]. Action = [[-0.08279522  0.03205358  0.          0.8389485 ]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 3194 is [True, False, False, False, True, False]
Current timestep = 3195. State = [[-0.36066064  0.04032496]]. Action = [[-0.04577915  0.06703565  0.          0.2017901 ]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 3195 is [True, False, False, False, True, False]
Current timestep = 3196. State = [[-0.36722955  0.04398288]]. Action = [[-0.07827203  0.03025465  0.         -0.8001256 ]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 3196 is [True, False, False, False, True, False]
State prediction error at timestep 3196 is 0.012
Human Feedback received at timestep 3196 of None
Current timestep = 3197. State = [[-0.36878815  0.04358998]]. Action = [[ 0.04215118 -0.03564846  0.          0.72312367]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 3197 is [True, False, False, False, True, False]
Current timestep = 3198. State = [[-0.36918247  0.04632211]]. Action = [[-0.00522259  0.0686577   0.          0.5052197 ]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 3198 is [True, False, False, False, True, False]
Current timestep = 3199. State = [[-0.37052348  0.0486475 ]]. Action = [[ 0.         0.         0.        -0.5163718]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 3199 is [True, False, False, False, True, False]
Current timestep = 3200. State = [[-0.3680817   0.05256125]]. Action = [[ 0.07384352  0.06822292  0.         -0.86987346]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 3200 is [True, False, False, False, True, False]
Current timestep = 3201. State = [[-0.36595792  0.05217586]]. Action = [[ 0.01991037 -0.05574684  0.         -0.60296637]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 3201 is [True, False, False, False, True, False]
Current timestep = 3202. State = [[-0.3639243   0.05194719]]. Action = [[0.03289073 0.01646218 0.         0.48466754]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 3202 is [True, False, False, False, True, False]
Current timestep = 3203. State = [[-0.35884628  0.05665965]]. Action = [[0.08762174 0.08087792 0.         0.7308688 ]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 3203 is [True, False, False, False, True, False]
Current timestep = 3204. State = [[-0.35885337  0.0585612 ]]. Action = [[-0.05534218 -0.01750837  0.         -0.48140556]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 3204 is [True, False, False, False, True, False]
State prediction error at timestep 3204 is 0.012
Human Feedback received at timestep 3204 of None
Current timestep = 3205. State = [[-0.3594938   0.05583815]]. Action = [[ 0.01235481 -0.05979298  0.         -0.10521007]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 3205 is [True, False, False, False, True, False]
Current timestep = 3206. State = [[-0.35579935  0.05826078]]. Action = [[ 0.06395864  0.07624865  0.         -0.7091991 ]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 3206 is [True, False, False, False, True, False]
Current timestep = 3207. State = [[-0.34936184  0.06218725]]. Action = [[0.09020569 0.03251674 0.         0.88183177]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 3207 is [True, False, False, False, True, False]
State prediction error at timestep 3207 is 0.012
Human Feedback received at timestep 3207 of None
Current timestep = 3208. State = [[-0.34131625  0.06273107]]. Action = [[ 0.0975629  -0.01313315  0.          0.67761207]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 3208 is [True, False, False, False, True, False]
Current timestep = 3209. State = [[-0.33610982  0.0610332 ]]. Action = [[ 0.02184888 -0.03156925  0.         -0.61637443]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 3209 is [True, False, False, False, True, False]
Current timestep = 3210. State = [[-0.32944205  0.06073985]]. Action = [[0.08609428 0.00840659 0.         0.21973062]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 3210 is [True, False, False, False, True, False]
Current timestep = 3211. State = [[-0.32092914  0.06504532]]. Action = [[0.08751557 0.08285221 0.         0.9889231 ]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 3211 is [True, False, False, False, True, False]
State prediction error at timestep 3211 is 0.012
Human Feedback received at timestep 3211 of None
Current timestep = 3212. State = [[-0.31523842  0.06784282]]. Action = [[0.0263279  0.00733061 0.         0.47423208]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 3212 is [True, False, False, False, True, False]
Current timestep = 3213. State = [[-0.31390738  0.06378391]]. Action = [[-0.03950869 -0.0973077   0.          0.3889966 ]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 3213 is [True, False, False, False, True, False]
Current timestep = 3214. State = [[-0.3147316  0.0570791]]. Action = [[-0.05441708 -0.09228947  0.          0.14157546]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 3214 is [True, False, False, False, True, False]
Current timestep = 3215. State = [[-0.3131786  0.0519052]]. Action = [[ 0.00780903 -0.05440461  0.         -0.56123936]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 3215 is [True, False, False, False, True, False]
Current timestep = 3216. State = [[-0.31210065  0.04527181]]. Action = [[-0.03228042 -0.09651905  0.         -0.6027029 ]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 3216 is [True, False, False, False, True, False]
Current timestep = 3217. State = [[-0.3111498  0.0460901]]. Action = [[-0.00518242  0.0866925   0.         -0.4519198 ]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 3217 is [True, False, False, False, True, False]
Current timestep = 3218. State = [[-0.3069401   0.04613542]]. Action = [[ 0.06421857 -0.0344112   0.         -0.95845336]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 3218 is [True, False, False, False, True, False]
Current timestep = 3219. State = [[-0.30392307  0.04862194]]. Action = [[ 0.00728742  0.08247613  0.         -0.47867352]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 3219 is [True, False, False, False, True, False]
Current timestep = 3220. State = [[-0.30383897  0.04830042]]. Action = [[-0.01524732 -0.04324063  0.          0.02234232]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 3220 is [True, False, False, False, True, False]
Current timestep = 3221. State = [[-0.30559316  0.04279123]]. Action = [[-0.0419175  -0.08139696  0.          0.78694606]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 3221 is [True, False, False, False, True, False]
Current timestep = 3222. State = [[-0.30811337  0.03858262]]. Action = [[-0.04211717 -0.02850448  0.          0.44653082]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 3222 is [True, False, False, False, True, False]
Current timestep = 3223. State = [[-0.3136657   0.04031572]]. Action = [[-0.09438664  0.06225728  0.         -0.89409727]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 3223 is [True, False, False, False, True, False]
Current timestep = 3224. State = [[-0.3142659   0.03996347]]. Action = [[ 0.05273161 -0.03648365  0.         -0.96330583]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 3224 is [True, False, False, False, True, False]
Current timestep = 3225. State = [[-0.31062093  0.03987284]]. Action = [[ 0.0598167   0.02741776  0.         -0.8800788 ]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 3225 is [True, False, False, False, True, False]
State prediction error at timestep 3225 is 0.012
Human Feedback received at timestep 3225 of None
Current timestep = 3226. State = [[-0.30904037  0.04443008]]. Action = [[0.01385077 0.08696323 0.         0.22604048]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 3226 is [True, False, False, False, True, False]
Current timestep = 3227. State = [[-0.31265548  0.04721547]]. Action = [[-0.06444485  0.00829911  0.         -0.47951174]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 3227 is [True, False, False, False, True, False]
Current timestep = 3228. State = [[-0.3139808   0.05158039]]. Action = [[0.03159466 0.07783752 0.         0.24873483]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 3228 is [True, False, False, False, True, False]
Current timestep = 3229. State = [[-0.31468266  0.05436912]]. Action = [[-0.00389439  0.00494619  0.          0.19107461]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 3229 is [True, False, False, False, True, False]
Current timestep = 3230. State = [[-0.3164985   0.05054697]]. Action = [[-0.01869635 -0.09293545  0.          0.33469462]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 3230 is [True, False, False, False, True, False]
Current timestep = 3231. State = [[-0.31572023  0.05263626]]. Action = [[0.03964805 0.08969351 0.         0.23558474]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 3231 is [True, False, False, False, True, False]
Current timestep = 3232. State = [[-0.31514385  0.05775845]]. Action = [[ 0.00775965  0.04541198  0.         -0.1549992 ]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 3232 is [True, False, False, False, True, False]
Current timestep = 3233. State = [[-0.3187654   0.06118012]]. Action = [[-0.06464635  0.02670424  0.         -0.1396544 ]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 3233 is [True, False, False, False, True, False]
State prediction error at timestep 3233 is 0.012
Human Feedback received at timestep 3233 of None
Current timestep = 3234. State = [[-0.31681207  0.06771877]]. Action = [[0.09918869 0.0999722  0.         0.5451145 ]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 3234 is [True, False, False, False, True, False]
State prediction error at timestep 3234 is 0.012
Human Feedback received at timestep 3234 of None
Current timestep = 3235. State = [[-0.31304067  0.07043272]]. Action = [[ 0.03302235 -0.02019225  0.         -0.8248205 ]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 3235 is [True, False, False, False, True, False]
Current timestep = 3236. State = [[-0.31294346  0.06820309]]. Action = [[-0.02470498 -0.05722386  0.         -0.81615686]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 3236 is [True, False, False, False, True, False]
Current timestep = 3237. State = [[-0.31081593  0.0630461 ]]. Action = [[ 0.03988507 -0.09152477  0.          0.6928377 ]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 3237 is [True, False, False, False, True, False]
Current timestep = 3238. State = [[-0.30551422  0.06475225]]. Action = [[ 0.06661692  0.07950976  0.         -0.23345041]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 3238 is [True, False, False, False, True, False]
Current timestep = 3239. State = [[-0.2986391  0.0709107]]. Action = [[0.08729836 0.07535661 0.         0.32532084]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 3239 is [True, False, False, False, True, False]
Current timestep = 3240. State = [[-0.291186    0.06981023]]. Action = [[ 0.08058596 -0.07231152  0.          0.22932124]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 3240 is [True, False, False, False, True, False]
Current timestep = 3241. State = [[-0.28635603  0.06842265]]. Action = [[0.01731636 0.00859203 0.         0.23271501]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 3241 is [True, False, False, False, True, False]
Current timestep = 3242. State = [[-0.28603852  0.06493316]]. Action = [[-0.04643601 -0.07893755  0.          0.19714451]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 3242 is [True, False, False, False, True, False]
State prediction error at timestep 3242 is 0.012
Human Feedback received at timestep 3242 of None
Current timestep = 3243. State = [[-0.28739318  0.05897459]]. Action = [[-0.04980825 -0.08152984  0.         -0.19086182]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 3243 is [True, False, False, False, True, False]
Current timestep = 3244. State = [[-0.28582373  0.05174561]]. Action = [[ 0.01559374 -0.09570044  0.         -0.01964635]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 3244 is [True, False, False, False, True, False]
Current timestep = 3245. State = [[-0.28121957  0.04520175]]. Action = [[ 0.04375068 -0.06072445  0.          0.36617315]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 3245 is [True, False, False, False, True, False]
Current timestep = 3246. State = [[-0.28146556  0.04414264]]. Action = [[-0.0690365   0.03753453  0.         -0.71563476]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 3246 is [True, False, False, False, True, False]
Current timestep = 3247. State = [[-0.28153595  0.04537053]]. Action = [[ 0.01113397  0.02461448  0.         -0.74349874]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 3247 is [True, False, False, False, True, False]
Current timestep = 3248. State = [[-0.28112692  0.04466651]]. Action = [[-0.01046861 -0.01038183  0.          0.7741904 ]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 3248 is [True, False, False, False, True, False]
Current timestep = 3249. State = [[-0.27711436  0.04707206]]. Action = [[0.0845645  0.07246693 0.         0.95526004]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 3249 is [True, False, False, False, True, False]
Current timestep = 3250. State = [[-0.27687454  0.0527519 ]]. Action = [[-0.03648084  0.08783441  0.         -0.01419115]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 3250 is [True, False, False, False, True, False]
Current timestep = 3251. State = [[-0.28253302  0.0551273 ]]. Action = [[-0.08671647 -0.00221653  0.          0.7812835 ]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 3251 is [True, False, False, False, True, False]
Current timestep = 3252. State = [[-0.28913242  0.05827954]]. Action = [[-0.07142335  0.0546644   0.          0.76581025]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 3252 is [True, False, False, False, True, False]
Current timestep = 3253. State = [[-0.2966051   0.06421007]]. Action = [[-0.08430836  0.07308605  0.          0.91188455]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 3253 is [True, False, False, False, True, False]
Current timestep = 3254. State = [[-0.29993594  0.06674965]]. Action = [[ 0.01645181 -0.0132973   0.         -0.25607014]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 3254 is [True, False, False, False, True, False]
Current timestep = 3255. State = [[-0.30330917  0.06786712]]. Action = [[-0.04182656  0.00754906  0.          0.10637009]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 3255 is [True, False, False, False, True, False]
Current timestep = 3256. State = [[-0.30691618  0.06614572]]. Action = [[-0.02029587 -0.05979262  0.          0.05184472]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 3256 is [True, False, False, False, True, False]
State prediction error at timestep 3256 is 0.012
Human Feedback received at timestep 3256 of None
Current timestep = 3257. State = [[-0.30894554  0.06457977]]. Action = [[-0.00417474 -0.01408508  0.          0.8555112 ]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 3257 is [True, False, False, False, True, False]
Current timestep = 3258. State = [[-0.31209677  0.06020058]]. Action = [[-0.04169277 -0.0905852   0.          0.8681377 ]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 3258 is [True, False, False, False, True, False]
Current timestep = 3259. State = [[-0.31792638  0.05885922]]. Action = [[-0.08053613  0.01802348  0.          0.87885594]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 3259 is [True, False, False, False, True, False]
State prediction error at timestep 3259 is 0.012
Human Feedback received at timestep 3259 of None
Current timestep = 3260. State = [[-0.3260487   0.06096276]]. Action = [[-0.09753633  0.02894176  0.         -0.4668615 ]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 3260 is [True, False, False, False, True, False]
Current timestep = 3261. State = [[-0.33499286  0.0650173 ]]. Action = [[-0.0926116   0.05843706  0.          0.939054  ]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 3261 is [True, False, False, False, True, False]
State prediction error at timestep 3261 is 0.012
Human Feedback received at timestep 3261 of None
Current timestep = 3262. State = [[-0.3429353   0.07041715]]. Action = [[-0.06111003  0.06696152  0.         -0.57794577]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 3262 is [True, False, False, False, True, False]
Current timestep = 3263. State = [[-0.34698448  0.07583807]]. Action = [[0.01304393 0.06135935 0.         0.31687987]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 3263 is [True, False, False, False, True, False]
Current timestep = 3264. State = [[-0.34969378  0.07396121]]. Action = [[-0.0026559  -0.08223753  0.          0.8383043 ]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 3264 is [True, False, False, False, True, False]
Current timestep = 3265. State = [[-0.35633215  0.07407885]]. Action = [[-0.08652297  0.04304544  0.         -0.15505493]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 3265 is [True, False, False, False, True, False]
Current timestep = 3266. State = [[-0.35828677  0.07839061]]. Action = [[ 0.06354874  0.0598786   0.         -0.92114973]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 3266 is [True, False, False, False, True, False]
Current timestep = 3267. State = [[-0.3616971   0.08144041]]. Action = [[-0.05689713  0.02106752  0.          0.6058185 ]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 3267 is [True, False, False, False, True, False]
Current timestep = 3268. State = [[-0.3608806   0.08614742]]. Action = [[ 0.09694874  0.07712396  0.         -0.6512843 ]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 3268 is [True, False, False, False, True, False]
Current timestep = 3269. State = [[-0.35787895  0.08716244]]. Action = [[ 0.04350983 -0.02763913  0.          0.778075  ]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 3269 is [True, False, False, False, True, False]
Current timestep = 3270. State = [[-0.35550162  0.09056702]]. Action = [[ 0.04198007  0.0771478   0.         -0.01836544]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 3270 is [True, False, False, False, True, False]
State prediction error at timestep 3270 is 0.012
Human Feedback received at timestep 3270 of None
Current timestep = 3271. State = [[-0.35509753  0.09455111]]. Action = [[-0.00096626  0.02823492  0.         -0.8761946 ]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 3271 is [True, False, False, False, True, False]
State prediction error at timestep 3271 is 0.012
Human Feedback received at timestep 3271 of None
Current timestep = 3272. State = [[-0.35122114  0.09310067]]. Action = [[ 0.08337566 -0.06085914  0.          0.6315893 ]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 3272 is [True, False, False, False, True, False]
State prediction error at timestep 3272 is 0.012
Human Feedback received at timestep 3272 of None
Current timestep = 3273. State = [[-0.3506888   0.09500594]]. Action = [[-0.04350778  0.06048653  0.         -0.07609874]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 3273 is [True, False, False, False, True, False]
Current timestep = 3274. State = [[-0.34885782  0.09973069]]. Action = [[0.05350544 0.04553842 0.         0.2211889 ]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 3274 is [True, False, False, False, True, False]
Current timestep = 3275. State = [[-0.3440708   0.10422999]]. Action = [[0.05950917 0.04846898 0.         0.67205167]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 3275 is [True, False, False, False, True, False]
Current timestep = 3276. State = [[-0.33730313  0.10657766]]. Action = [[ 0.0875325   0.00469812  0.         -0.09476721]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 3276 is [True, False, False, False, True, False]
State prediction error at timestep 3276 is 0.012
Human Feedback received at timestep 3276 of None
Current timestep = 3277. State = [[-0.33007896  0.10526705]]. Action = [[ 0.06920084 -0.04391919  0.          0.34331548]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 3277 is [True, False, False, False, True, False]
Current timestep = 3278. State = [[-0.33006814  0.10595497]]. Action = [[-0.0797867   0.02090205  0.          0.74931026]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 3278 is [True, False, False, False, True, False]
Current timestep = 3279. State = [[-0.32922998  0.10694346]]. Action = [[ 0.02538035 -0.01409294  0.         -0.6526109 ]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 3279 is [True, False, False, False, True, False]
State prediction error at timestep 3279 is 0.012
Human Feedback received at timestep 3279 of None
Current timestep = 3280. State = [[-0.33035138  0.10358305]]. Action = [[-0.07144164 -0.08233026  0.          0.72740436]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 3280 is [True, False, False, False, True, False]
Current timestep = 3281. State = [[-0.33482417  0.099783  ]]. Action = [[-0.08998806 -0.05253982  0.          0.5014553 ]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 3281 is [True, False, False, False, True, False]
Current timestep = 3282. State = [[-0.33198586  0.10087281]]. Action = [[0.09535535 0.04582756 0.         0.488315  ]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 3282 is [True, False, False, False, True, False]
Current timestep = 3283. State = [[-0.32502308  0.10593472]]. Action = [[ 0.06444926  0.0737694   0.         -0.03933358]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 3283 is [True, False, False, False, True, False]
Current timestep = 3284. State = [[-0.32000566  0.11229674]]. Action = [[0.04168234 0.08225783 0.         0.23161077]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 3284 is [True, False, False, False, True, False]
Current timestep = 3285. State = [[-0.3131918   0.11614385]]. Action = [[ 0.09542175  0.02491845  0.         -0.24071538]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 3285 is [True, False, False, False, True, False]
Current timestep = 3286. State = [[-0.30840212  0.11510912]]. Action = [[ 0.01726522 -0.0428609   0.         -0.09992242]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 3286 is [True, False, False, False, True, False]
Current timestep = 3287. State = [[-0.30620998  0.11313852]]. Action = [[ 0.00061677 -0.02632059  0.         -0.2945336 ]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 3287 is [True, False, False, False, True, False]
Current timestep = 3288. State = [[-0.30862457  0.10867611]]. Action = [[-0.08765906 -0.08982257  0.         -0.3741663 ]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 3288 is [True, False, False, False, True, False]
Current timestep = 3289. State = [[-0.3074358   0.10996825]]. Action = [[ 0.04938129  0.0682027   0.         -0.5908869 ]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 3289 is [True, False, False, False, True, False]
Current timestep = 3290. State = [[-0.30158812  0.10797256]]. Action = [[ 0.06005026 -0.08495027  0.          0.52559805]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 3290 is [True, False, False, False, True, False]
Current timestep = 3291. State = [[-0.2970222  0.1034218]]. Action = [[ 0.0166996  -0.04577986  0.          0.673337  ]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 3291 is [True, False, False, False, True, False]
Current timestep = 3292. State = [[-0.2935479   0.10187906]]. Action = [[0.02072673 0.00159498 0.         0.93703437]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 3292 is [True, False, False, False, True, False]
State prediction error at timestep 3292 is 0.012
Human Feedback received at timestep 3292 of None
Current timestep = 3293. State = [[-0.29172605  0.09947864]]. Action = [[-0.00942984 -0.04094053  0.         -0.98213255]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 3293 is [True, False, False, False, True, False]
Current timestep = 3294. State = [[-0.28636503  0.09502359]]. Action = [[ 0.08155078 -0.05419532  0.          0.8504269 ]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 3294 is [True, False, False, False, True, False]
Current timestep = 3295. State = [[-0.28221115  0.0920151 ]]. Action = [[ 0.00679294 -0.00824732  0.         -0.10650617]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 3295 is [True, False, False, False, True, False]
Current timestep = 3296. State = [[-0.27704644  0.0908729 ]]. Action = [[ 0.07120623  0.00543196  0.         -0.83211565]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 3296 is [True, False, False, False, True, False]
Current timestep = 3297. State = [[-0.2780006   0.08858304]]. Action = [[-0.09156633 -0.02950685  0.         -0.77518374]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 3297 is [True, False, False, False, True, False]
Current timestep = 3298. State = [[-0.2800073   0.08693391]]. Action = [[-0.00719252 -0.00097358  0.         -0.18248713]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 3298 is [True, False, False, False, True, False]
State prediction error at timestep 3298 is 0.012
Human Feedback received at timestep 3298 of None
Current timestep = 3299. State = [[-0.28191575  0.08340836]]. Action = [[-0.04093692 -0.05428227  0.         -0.6427774 ]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 3299 is [True, False, False, False, True, False]
Current timestep = 3300. State = [[-0.28290468  0.08175414]]. Action = [[-0.00142586  0.01293323  0.          0.08642268]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 3300 is [True, False, False, False, True, False]
State prediction error at timestep 3300 is 0.012
Human Feedback received at timestep 3300 of None
Current timestep = 3301. State = [[-0.27837393  0.07708892]]. Action = [[ 0.09605806 -0.08065877  0.          0.72177243]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 3301 is [True, False, False, False, True, False]
State prediction error at timestep 3301 is 0.012
Human Feedback received at timestep 3301 of None
Current timestep = 3302. State = [[-0.27463627  0.07588326]]. Action = [[ 0.02213562  0.04863336  0.         -0.04408473]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 3302 is [True, False, False, False, True, False]
Current timestep = 3303. State = [[-0.27055946  0.07609107]]. Action = [[ 0.06977413  0.00311395  0.         -0.28777313]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 3303 is [True, False, False, False, True, False]
Current timestep = 3304. State = [[-0.26394716  0.07545398]]. Action = [[0.09479954 0.00969663 0.         0.64044714]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 3304 is [True, False, False, False, True, False]
Current timestep = 3305. State = [[-0.25630158  0.07132566]]. Action = [[ 0.09279718 -0.06255631  0.          0.9322412 ]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 3305 is [True, False, False, False, True, False]
Current timestep = 3306. State = [[-0.24938637  0.06954695]]. Action = [[0.06711284 0.02689848 0.         0.2603773 ]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 3306 is [True, False, False, False, True, False]
Current timestep = 3307. State = [[-0.24612965  0.06627777]]. Action = [[ 0.0005885  -0.05597166  0.          0.19348562]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 3307 is [True, False, False, False, True, False]
Current timestep = 3308. State = [[-0.24739413  0.06701648]]. Action = [[-0.06034236  0.06337451  0.         -0.78951025]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 3308 is [True, False, False, False, True, False]
Current timestep = 3309. State = [[-0.2522883   0.07316792]]. Action = [[-0.08979739  0.09544221  0.          0.39774036]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 3309 is [True, False, False, False, True, False]
Current timestep = 3310. State = [[-0.25611085  0.076597  ]]. Action = [[-0.0349222   0.00617002  0.          0.22094977]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 3310 is [True, False, False, False, True, False]
Current timestep = 3311. State = [[-0.25451028  0.07783317]]. Action = [[0.05367114 0.00792898 0.         0.8057444 ]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 3311 is [True, False, False, False, True, False]
State prediction error at timestep 3311 is 0.012
Human Feedback received at timestep 3311 of None
Current timestep = 3312. State = [[-0.25158128  0.07856275]]. Action = [[3.1096138e-02 5.4092705e-04 0.0000000e+00 6.1511087e-01]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 3312 is [True, False, False, False, True, False]
Current timestep = 3313. State = [[-0.24868834  0.08288136]]. Action = [[0.04099789 0.0769804  0.         0.17659438]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 3313 is [True, False, False, False, True, False]
State prediction error at timestep 3313 is 0.012
Human Feedback received at timestep 3313 of None
Current timestep = 3314. State = [[-0.24979833  0.08241305]]. Action = [[-0.04869575 -0.06829678  0.          0.57233834]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 3314 is [True, False, False, False, True, False]
Current timestep = 3315. State = [[-0.25102812  0.08286387]]. Action = [[-0.00208956  0.02965844  0.          0.4269135 ]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 3315 is [True, False, False, False, True, False]
Current timestep = 3316. State = [[-0.25192094  0.08002909]]. Action = [[-0.01904911 -0.08761276  0.          0.6184219 ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 3316 is [True, False, False, False, True, False]
State prediction error at timestep 3316 is 0.012
Human Feedback received at timestep 3316 of None
Current timestep = 3317. State = [[-0.25401217  0.07528564]]. Action = [[-0.04329527 -0.05850896  0.          0.6014476 ]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 3317 is [True, False, False, False, True, False]
Current timestep = 3318. State = [[-0.25290966  0.07330784]]. Action = [[ 0.03696326 -0.0088186   0.         -0.3033353 ]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 3318 is [True, False, False, False, True, False]
Current timestep = 3319. State = [[-0.2502018   0.07726262]]. Action = [[ 0.0321491   0.09025387  0.         -0.34238303]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 3319 is [True, False, False, False, True, False]
Current timestep = 3320. State = [[-0.25034246  0.0796316 ]]. Action = [[-0.01947922 -0.0007929   0.         -0.13471699]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 3320 is [True, False, False, False, True, False]
State prediction error at timestep 3320 is 0.012
Human Feedback received at timestep 3320 of None
Current timestep = 3321. State = [[-0.24606566  0.07539494]]. Action = [[ 0.09647895 -0.08401719  0.          0.73902893]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 3321 is [True, False, False, False, True, False]
Current timestep = 3322. State = [[-0.24697292  0.07541236]]. Action = [[-0.08195302  0.05725903  0.          0.4109099 ]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 3322 is [True, False, False, False, True, False]
Current timestep = 3323. State = [[-0.2524071   0.08028372]]. Action = [[-0.06559862  0.06784808  0.          0.94321704]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 3323 is [True, False, False, False, True, False]
Current timestep = 3324. State = [[-0.25279382  0.08005191]]. Action = [[ 0.04162001 -0.04950032  0.          0.52879477]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 3324 is [True, False, False, False, True, False]
Current timestep = 3325. State = [[-0.25485092  0.07979129]]. Action = [[-0.05655865  0.0196083   0.         -0.83188355]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 3325 is [True, False, False, False, True, False]
Current timestep = 3326. State = [[-0.25974882  0.07989103]]. Action = [[-0.06077137 -0.01416983  0.          0.9503658 ]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 3326 is [True, False, False, False, True, False]
State prediction error at timestep 3326 is 0.012
Human Feedback received at timestep 3326 of None
Current timestep = 3327. State = [[-0.26368734  0.0764154 ]]. Action = [[-0.03601616 -0.07046448  0.          0.55134666]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 3327 is [True, False, False, False, True, False]
State prediction error at timestep 3327 is 0.012
Human Feedback received at timestep 3327 of None
Current timestep = 3328. State = [[-0.26229396  0.07562757]]. Action = [[0.06233429 0.02463444 0.         0.10166264]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 3328 is [True, False, False, False, True, False]
Current timestep = 3329. State = [[-0.2573413  0.079822 ]]. Action = [[0.08451267 0.08031132 0.         0.4464712 ]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 3329 is [True, False, False, False, True, False]
State prediction error at timestep 3329 is 0.012
Human Feedback received at timestep 3329 of None
Current timestep = 3330. State = [[-0.25897518  0.08073425]]. Action = [[-0.07532047 -0.02484785  0.          0.6674477 ]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 3330 is [True, False, False, False, True, False]
Current timestep = 3331. State = [[-0.25717708  0.0753389 ]]. Action = [[ 0.09567448 -0.09218249  0.          0.49370933]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 3331 is [True, False, False, False, True, False]
Current timestep = 3332. State = [[-0.2582564   0.07548606]]. Action = [[-0.06549951  0.06811368  0.          0.29046106]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 3332 is [True, False, False, False, True, False]
State prediction error at timestep 3332 is 0.012
Human Feedback received at timestep 3332 of None
Current timestep = 3333. State = [[-0.25715208  0.08132517]]. Action = [[0.07543235 0.08868106 0.         0.69296587]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 3333 is [True, False, False, False, True, False]
Current timestep = 3334. State = [[-0.25161085  0.08535824]]. Action = [[ 0.08919092  0.03645618  0.         -0.03955531]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 3334 is [True, False, False, False, True, False]
Current timestep = 3335. State = [[-0.25302985  0.08956756]]. Action = [[-0.07674787  0.06319296  0.          0.4705701 ]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 3335 is [True, False, False, False, True, False]
State prediction error at timestep 3335 is 0.012
Human Feedback received at timestep 3335 of None
Current timestep = 3336. State = [[-0.26009136  0.08823206]]. Action = [[-0.09593922 -0.07596192  0.          0.22074842]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 3336 is [True, False, False, False, True, False]
Current timestep = 3337. State = [[-0.2620567   0.08735463]]. Action = [[0.02411096 0.00858344 0.         0.5210123 ]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 3337 is [True, False, False, False, True, False]
Current timestep = 3338. State = [[-0.26097408  0.08572505]]. Action = [[ 0.01461545 -0.04687924  0.         -0.8148171 ]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 3338 is [True, False, False, False, True, False]
State prediction error at timestep 3338 is 0.012
Human Feedback received at timestep 3338 of None
Current timestep = 3339. State = [[-0.26350597  0.08846112]]. Action = [[-0.0595823  0.0730878  0.         0.9407511]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 3339 is [True, False, False, False, True, False]
Current timestep = 3340. State = [[-0.2637657  0.0880922]]. Action = [[ 0.03333499 -0.05965374  0.          0.6068244 ]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 3340 is [True, False, False, False, True, False]
Current timestep = 3341. State = [[-0.26404113  0.08827642]]. Action = [[-0.02205137  0.02926048  0.         -0.0049293 ]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 3341 is [True, False, False, False, True, False]
State prediction error at timestep 3341 is 0.012
Human Feedback received at timestep 3341 of None
Current timestep = 3342. State = [[-0.2674361   0.09366575]]. Action = [[-0.05159444  0.08562832  0.          0.70427847]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 3342 is [True, False, False, False, True, False]
Current timestep = 3343. State = [[-0.2688987  0.0984273]]. Action = [[0.01533289 0.03451986 0.         0.29244018]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 3343 is [True, False, False, False, True, False]
Current timestep = 3344. State = [[-0.2727332   0.09721765]]. Action = [[-0.07381122 -0.06187186  0.         -0.58760065]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 3344 is [True, False, False, False, True, False]
Current timestep = 3345. State = [[-0.27899253  0.09253865]]. Action = [[-0.07951356 -0.07860713  0.         -0.3124962 ]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 3345 is [True, False, False, False, True, False]
Current timestep = 3346. State = [[-0.28280824  0.09464279]]. Action = [[-0.01794798  0.07702055  0.          0.8111577 ]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 3346 is [True, False, False, False, True, False]
Current timestep = 3347. State = [[-0.2857409   0.09620429]]. Action = [[-0.02673227 -0.02076025  0.         -0.13152283]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 3347 is [True, False, False, False, True, False]
Current timestep = 3348. State = [[-0.2912964   0.09318609]]. Action = [[-0.07993776 -0.06151107  0.          0.10503876]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 3348 is [True, False, False, False, True, False]
Current timestep = 3349. State = [[-0.2918486   0.09305707]]. Action = [[0.0584737 0.0299454 0.        0.6940179]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 3349 is [True, False, False, False, True, False]
Current timestep = 3350. State = [[-0.28809938  0.09114374]]. Action = [[ 0.06295816 -0.04953391  0.         -0.3755899 ]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 3350 is [True, False, False, False, True, False]
Current timestep = 3351. State = [[-0.28991476  0.08474477]]. Action = [[-0.07246548 -0.09609379  0.          0.06700253]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 3351 is [True, False, False, False, True, False]
Current timestep = 3352. State = [[-0.29175502  0.08585069]]. Action = [[0.01299913 0.09015795 0.         0.56929994]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 3352 is [True, False, False, False, True, False]
Current timestep = 3353. State = [[-0.2932927   0.08416749]]. Action = [[-0.02354819 -0.07299241  0.         -0.00324619]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 3353 is [True, False, False, False, True, False]
State prediction error at timestep 3353 is 0.012
Human Feedback received at timestep 3353 of None
Current timestep = 3354. State = [[-0.29596007  0.08159277]]. Action = [[-0.03318173 -0.00271546  0.         -0.91135234]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 3354 is [True, False, False, False, True, False]
Current timestep = 3355. State = [[-0.2935049   0.07616288]]. Action = [[ 0.07706749 -0.09217773  0.         -0.28362846]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 3355 is [True, False, False, False, True, False]
Current timestep = 3356. State = [[-0.29570305  0.07352825]]. Action = [[-0.08675986  0.01919006  0.         -0.74125355]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 3356 is [True, False, False, False, True, False]
Current timestep = 3357. State = [[-0.2975614   0.07623419]]. Action = [[0.02082385 0.06315204 0.         0.26361632]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 3357 is [True, False, False, False, True, False]
State prediction error at timestep 3357 is 0.012
Human Feedback received at timestep 3357 of None
Current timestep = 3358. State = [[-0.2972226   0.07419042]]. Action = [[ 0.01259245 -0.06157539  0.          0.37876427]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 3358 is [True, False, False, False, True, False]
Current timestep = 3359. State = [[-0.29634157  0.07062401]]. Action = [[ 0.01859347 -0.02136804  0.         -0.83867764]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 3359 is [True, False, False, False, True, False]
State prediction error at timestep 3359 is 0.012
Human Feedback received at timestep 3359 of None
Current timestep = 3360. State = [[-0.2950804   0.06688353]]. Action = [[ 0.01931076 -0.04321801  0.         -0.22137254]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 3360 is [True, False, False, False, True, False]
Current timestep = 3361. State = [[-0.29170534  0.06784914]]. Action = [[0.06150567 0.06594523 0.         0.02193165]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 3361 is [True, False, False, False, True, False]
Current timestep = 3362. State = [[-0.28783834  0.0730342 ]]. Action = [[ 0.05373966  0.08955907  0.         -0.22694892]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 3362 is [True, False, False, False, True, False]
State prediction error at timestep 3362 is 0.012
Human Feedback received at timestep 3362 of None
Current timestep = 3363. State = [[-0.28396666  0.07250407]]. Action = [[ 0.05415117 -0.0475776   0.         -0.5458623 ]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 3363 is [True, False, False, False, True, False]
Current timestep = 3364. State = [[-0.28236637  0.06692509]]. Action = [[-0.0064832 -0.0764495  0.         0.9290054]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 3364 is [True, False, False, False, True, False]
Current timestep = 3365. State = [[-0.27829912  0.06745916]]. Action = [[0.07344993 0.06748401 0.         0.88595057]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 3365 is [True, False, False, False, True, False]
State prediction error at timestep 3365 is 0.012
Human Feedback received at timestep 3365 of None
Current timestep = 3366. State = [[-0.27316383  0.06386429]]. Action = [[ 0.04698765 -0.0988327   0.          0.926394  ]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 3366 is [True, False, False, False, True, False]
Current timestep = 3367. State = [[-0.27202594  0.06367825]]. Action = [[-0.03076123  0.06183865  0.          0.74206376]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 3367 is [True, False, False, False, True, False]
Current timestep = 3368. State = [[-0.27521393  0.0654886 ]]. Action = [[-0.07258193  0.00645231  0.          0.06925786]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 3368 is [True, False, False, False, True, False]
Current timestep = 3369. State = [[-0.27676344  0.06628091]]. Action = [[-0.00805634  0.00719342  0.         -0.40371156]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 3369 is [True, False, False, False, True, False]
State prediction error at timestep 3369 is 0.012
Human Feedback received at timestep 3369 of None
Current timestep = 3370. State = [[-0.28066942  0.06403037]]. Action = [[-0.08870029 -0.05596439  0.          0.22804523]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 3370 is [True, False, False, False, True, False]
Current timestep = 3371. State = [[-0.28236705  0.06264012]]. Action = [[ 0.00292674 -0.00314031  0.          0.20471716]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 3371 is [True, False, False, False, True, False]
Current timestep = 3372. State = [[-0.28444144  0.05936338]]. Action = [[-0.05028088 -0.06709883  0.          0.3878076 ]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 3372 is [True, False, False, False, True, False]
Current timestep = 3373. State = [[-0.28834847  0.0545257 ]]. Action = [[-0.06006604 -0.06146934  0.          0.87833107]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 3373 is [True, False, False, False, True, False]
State prediction error at timestep 3373 is 0.012
Human Feedback received at timestep 3373 of None
Current timestep = 3374. State = [[-0.29159176  0.05742165]]. Action = [[-0.0290687   0.09840556  0.          0.7786598 ]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 3374 is [True, False, False, False, True, False]
Current timestep = 3375. State = [[-0.28995037  0.05559294]]. Action = [[ 0.06644522 -0.09392949  0.          0.04591286]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 3375 is [True, False, False, False, True, False]
Current timestep = 3376. State = [[-0.29048324  0.04972485]]. Action = [[-0.04004992 -0.05713822  0.         -0.6182846 ]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 3376 is [True, False, False, False, True, False]
Current timestep = 3377. State = [[-0.28994277  0.04729624]]. Action = [[ 3.7800275e-02  1.7799437e-04  0.0000000e+00 -7.5436318e-01]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 3377 is [True, False, False, False, True, False]
Current timestep = 3378. State = [[-0.2928504   0.04749586]]. Action = [[-0.07052744  0.02188981  0.         -0.37311852]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 3378 is [True, False, False, False, True, False]
Current timestep = 3379. State = [[-0.29195443  0.05166285]]. Action = [[0.07993674 0.08631802 0.         0.24246514]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 3379 is [True, False, False, False, True, False]
State prediction error at timestep 3379 is 0.012
Human Feedback received at timestep 3379 of None
Current timestep = 3380. State = [[-0.28864512  0.05103637]]. Action = [[ 0.04351943 -0.04931305  0.         -0.5668986 ]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 3380 is [True, False, False, False, True, False]
Current timestep = 3381. State = [[-0.29181123  0.04842433]]. Action = [[-0.08685533 -0.01663318  0.          0.0058372 ]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 3381 is [True, False, False, False, True, False]
Current timestep = 3382. State = [[-0.29886672  0.04805633]]. Action = [[-0.08885308  0.0076888   0.          0.543113  ]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 3382 is [True, False, False, False, True, False]
Current timestep = 3383. State = [[-0.30288276  0.0432726 ]]. Action = [[-0.0178009  -0.09936921  0.          0.6936697 ]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 3383 is [True, False, False, False, True, False]
Current timestep = 3384. State = [[-0.29944068  0.03771905]]. Action = [[ 0.0948269  -0.04584929  0.         -0.52346283]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 3384 is [True, False, False, False, True, False]
Current timestep = 3385. State = [[-0.2954365   0.03809027]]. Action = [[ 0.037674    0.05500107  0.         -0.10606897]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 3385 is [True, False, False, False, True, False]
Current timestep = 3386. State = [[-0.2907514  0.0403127]]. Action = [[0.08220314 0.03301486 0.         0.5054537 ]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 3386 is [True, False, False, False, True, False]
Current timestep = 3387. State = [[-0.28763795  0.03971237]]. Action = [[ 0.02274354 -0.01518542  0.         -0.529584  ]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 3387 is [True, False, False, False, True, False]
State prediction error at timestep 3387 is 0.012
Human Feedback received at timestep 3387 of None
Current timestep = 3388. State = [[-0.28731632  0.03551342]]. Action = [[-0.01148658 -0.06301525  0.         -0.20002759]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 3388 is [True, False, False, False, True, False]
Current timestep = 3389. State = [[-0.28653088  0.02909895]]. Action = [[ 0.00998901 -0.07936929  0.          0.2741449 ]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 3389 is [True, False, False, False, True, False]
State prediction error at timestep 3389 is 0.012
Human Feedback received at timestep 3389 of None
Current timestep = 3390. State = [[-0.28960705  0.02151376]]. Action = [[-0.09010454 -0.09077039  0.          0.66495204]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 3390 is [True, False, False, False, True, False]
Current timestep = 3391. State = [[-0.29220176  0.02133756]]. Action = [[-0.02108979  0.06879389  0.         -0.22648925]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 3391 is [True, False, False, False, True, False]
State prediction error at timestep 3391 is 0.012
Human Feedback received at timestep 3391 of None
Current timestep = 3392. State = [[-0.29731178  0.01856182]]. Action = [[-0.0982481  -0.07840446  0.          0.15239358]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 3392 is [True, False, False, False, True, False]
State prediction error at timestep 3392 is 0.012
Human Feedback received at timestep 3392 of None
Current timestep = 3393. State = [[-0.30167344  0.01098718]]. Action = [[-0.04139613 -0.09522424  0.          0.19524252]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 3393 is [True, False, False, False, True, False]
State prediction error at timestep 3393 is 0.012
Human Feedback received at timestep 3393 of None
Current timestep = 3394. State = [[-0.29972914  0.00498849]]. Action = [[ 0.06386178 -0.04193443  0.         -0.1012271 ]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 3394 is [True, False, False, False, True, False]
State prediction error at timestep 3394 is 0.012
Human Feedback received at timestep 3394 of None
Current timestep = 3395. State = [[-0.30038837  0.0019539 ]]. Action = [[-0.04909013 -0.00732867  0.          0.9665202 ]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 3395 is [True, False, False, False, True, False]
State prediction error at timestep 3395 is 0.012
Human Feedback received at timestep 3395 of None
Current timestep = 3396. State = [[-0.29821488  0.00038691]]. Action = [[ 0.07763749  0.00080149  0.         -0.1996913 ]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 3396 is [True, False, False, False, True, False]
Current timestep = 3397. State = [[-0.29857272  0.00079561]]. Action = [[-0.04103049  0.0351109   0.          0.00913823]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 3397 is [True, False, False, False, True, False]
Current timestep = 3398. State = [[-0.30298474 -0.00261931]]. Action = [[-0.05744764 -0.06789288  0.          0.58849406]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 3398 is [True, False, False, False, True, False]
State prediction error at timestep 3398 is 0.012
Human Feedback received at timestep 3398 of None
Current timestep = 3399. State = [[-0.30468097 -0.00139492]]. Action = [[0.01379206 0.08248096 0.         0.08450234]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 3399 is [True, False, False, False, True, False]
Current timestep = 3400. State = [[-0.30585435  0.00286949]]. Action = [[-0.0035082   0.05276114  0.         -0.45423597]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 3400 is [True, False, False, False, True, False]
Current timestep = 3401. State = [[-0.30324987 -0.00056299]]. Action = [[ 0.08352462 -0.09540652  0.          0.8536773 ]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 3401 is [True, False, False, False, True, False]
State prediction error at timestep 3401 is 0.012
Human Feedback received at timestep 3401 of None
Current timestep = 3402. State = [[-0.30557817 -0.00045979]]. Action = [[-0.08018321  0.06459682  0.         -0.64440906]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 3402 is [True, False, False, False, True, False]
Current timestep = 3403. State = [[-0.31385064  0.00370533]]. Action = [[-0.09740752  0.05277213  0.          0.21826172]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 3403 is [True, False, False, False, True, False]
State prediction error at timestep 3403 is 0.012
Human Feedback received at timestep 3403 of None
Current timestep = 3404. State = [[-0.31764713  0.00425642]]. Action = [[ 0.01461174 -0.0250608   0.         -0.09749973]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 3404 is [True, False, False, False, True, False]
Current timestep = 3405. State = [[-0.31739205  0.00148054]]. Action = [[ 0.02954052 -0.04718747  0.          0.20177579]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 3405 is [True, False, False, False, True, False]
Current timestep = 3406. State = [[-0.3147499  -0.00130121]]. Action = [[ 0.05935044 -0.0284716   0.         -0.9972185 ]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 3406 is [True, False, False, False, True, False]
State prediction error at timestep 3406 is 0.012
Human Feedback received at timestep 3406 of None
Current timestep = 3407. State = [[-0.31633464 -0.00183344]]. Action = [[-0.05276759  0.00982668  0.          0.874558  ]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 3407 is [True, False, False, False, True, False]
Current timestep = 3408. State = [[-0.31658354 -0.00651349]]. Action = [[ 0.03422242 -0.09615681  0.         -0.3956982 ]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 3408 is [True, False, False, False, True, False]
Current timestep = 3409. State = [[-0.31360003 -0.01078359]]. Action = [[ 0.04517294 -0.02201953  0.         -0.03974599]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 3409 is [True, False, False, False, True, False]
Current timestep = 3410. State = [[-0.31379968 -0.01520449]]. Action = [[-0.03542805 -0.05974858  0.         -0.1573081 ]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 3410 is [True, False, False, False, True, False]
Current timestep = 3411. State = [[-0.31700793 -0.01696747]]. Action = [[-0.05684022  0.01713187  0.          0.6105778 ]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 3411 is [True, False, False, False, True, False]
State prediction error at timestep 3411 is 0.012
Human Feedback received at timestep 3411 of None
Current timestep = 3412. State = [[-0.3174115  -0.01689747]]. Action = [[ 0.02173635  0.01179866  0.         -0.3386606 ]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 3412 is [True, False, False, False, True, False]
State prediction error at timestep 3412 is 0.012
Human Feedback received at timestep 3412 of None
Current timestep = 3413. State = [[-0.3196301  -0.01830383]]. Action = [[-0.05563287 -0.01892453  0.          0.33213305]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 3413 is [True, False, False, False, True, False]
Current timestep = 3414. State = [[-0.31935343 -0.02165912]]. Action = [[ 0.03734728 -0.04117412  0.         -0.7045198 ]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 3414 is [True, False, False, False, True, False]
Current timestep = 3415. State = [[-0.32212225 -0.02444146]]. Action = [[-0.07777008 -0.01508458  0.         -0.9102677 ]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 3415 is [True, False, False, False, True, False]
State prediction error at timestep 3415 is 0.012
Human Feedback received at timestep 3415 of None
Current timestep = 3416. State = [[-0.3218629  -0.03065308]]. Action = [[ 0.05056638 -0.09889609  0.         -0.14981389]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 3416 is [True, False, False, False, True, False]
Current timestep = 3417. State = [[-0.32300696 -0.03849898]]. Action = [[-0.05810883 -0.07961427  0.         -0.11641568]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 3417 is [True, False, False, False, True, False]
State prediction error at timestep 3417 is 0.012
Human Feedback received at timestep 3417 of None
Current timestep = 3418. State = [[-0.32753935 -0.04172549]]. Action = [[-0.07069637  0.00882106  0.         -0.6787917 ]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 3418 is [True, False, False, False, True, False]
Current timestep = 3419. State = [[-0.32884955 -0.04176281]]. Action = [[ 0.0160429   0.02174314  0.         -0.74370456]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 3419 is [True, False, False, False, True, False]
Current timestep = 3420. State = [[-0.3325157  -0.03896578]]. Action = [[-0.06946095  0.06357346  0.          0.85886145]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 3420 is [True, False, False, False, True, False]
Current timestep = 3421. State = [[-0.3328087  -0.03334229]]. Action = [[0.06129149 0.08545322 0.         0.71337533]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 3421 is [True, False, False, False, True, False]
State prediction error at timestep 3421 is 0.012
Human Feedback received at timestep 3421 of None
Current timestep = 3422. State = [[-0.3337272  -0.03506399]]. Action = [[-0.0239806  -0.09805886  0.         -0.6302417 ]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 3422 is [True, False, False, False, True, False]
State prediction error at timestep 3422 is 0.012
Human Feedback received at timestep 3422 of None
Current timestep = 3423. State = [[-0.33123213 -0.03865768]]. Action = [[ 0.08606037 -0.01384621  0.         -0.048015  ]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 3423 is [True, False, False, False, True, False]
State prediction error at timestep 3423 is 0.012
Human Feedback received at timestep 3423 of None
Current timestep = 3424. State = [[-0.3337324  -0.03929181]]. Action = [[-0.08413213  0.00545956  0.         -0.6690725 ]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 3424 is [True, False, False, False, True, False]
Current timestep = 3425. State = [[-0.33764    -0.03452537]]. Action = [[-0.00415515  0.09671519  0.         -0.90462196]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 3425 is [True, False, False, False, True, False]
Current timestep = 3426. State = [[-0.33772153 -0.03479042]]. Action = [[ 0.03905063 -0.06650148  0.         -0.804376  ]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 3426 is [True, False, False, False, True, False]
Current timestep = 3427. State = [[-0.33557957 -0.03909163]]. Action = [[ 0.04660235 -0.05351201  0.         -0.3143747 ]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 3427 is [True, False, False, False, True, False]
Current timestep = 3428. State = [[-0.331228   -0.04394744]]. Action = [[ 0.07386377 -0.062686    0.         -0.40318632]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 3428 is [True, False, False, False, True, False]
State prediction error at timestep 3428 is 0.012
Human Feedback received at timestep 3428 of None
Current timestep = 3429. State = [[-0.33264145 -0.04727245]]. Action = [[-0.07649747 -0.01997029  0.         -0.18156725]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 3429 is [True, False, False, False, True, False]
Current timestep = 3430. State = [[-0.33070657 -0.05002537]]. Action = [[ 0.08590176 -0.03141252  0.          0.5074626 ]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 3430 is [True, False, False, False, True, False]
State prediction error at timestep 3430 is 0.012
Human Feedback received at timestep 3430 of None
Current timestep = 3431. State = [[-0.32576734 -0.04986091]]. Action = [[0.05204266 0.0365965  0.         0.7158344 ]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 3431 is [True, False, False, False, True, False]
Current timestep = 3432. State = [[-0.32187706 -0.05152639]]. Action = [[ 0.04355877 -0.03871141  0.          0.1021235 ]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 3432 is [True, False, False, False, True, False]
Current timestep = 3433. State = [[-0.31543443 -0.05132482]]. Action = [[0.09835418 0.04143592 0.         0.61770475]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 3433 is [True, False, False, False, True, False]
State prediction error at timestep 3433 is 0.012
Human Feedback received at timestep 3433 of None
Current timestep = 3434. State = [[-0.3167697  -0.04770252]]. Action = [[-0.09602433  0.06669354  0.         -0.85310674]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 3434 is [True, False, False, False, True, False]
Current timestep = 3435. State = [[-0.31580216 -0.0411702 ]]. Action = [[ 0.08717515  0.09750884  0.         -0.7862683 ]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 3435 is [True, False, False, False, True, False]
Current timestep = 3436. State = [[-0.3130132  -0.04144796]]. Action = [[ 0.022122   -0.07386522  0.         -0.121171  ]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 3436 is [True, False, False, False, True, False]
Current timestep = 3437. State = [[-0.308559   -0.04815013]]. Action = [[ 0.07248936 -0.09807072  0.         -0.4458238 ]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 3437 is [True, False, False, False, True, False]
Current timestep = 3438. State = [[-0.3028563  -0.04677822]]. Action = [[0.06244477 0.09309507 0.         0.6345662 ]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 3438 is [True, False, False, False, True, False]
State prediction error at timestep 3438 is 0.012
Human Feedback received at timestep 3438 of None
Current timestep = 3439. State = [[-0.2995498  -0.04092905]]. Action = [[ 0.0227481   0.06668013  0.         -0.71397936]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 3439 is [True, False, False, False, True, False]
Current timestep = 3440. State = [[-0.31901145  0.00670897]]. Action = [[-0.088457   -0.05096425  0.          0.15369022]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 3440 is [True, False, False, False, True, False]
State prediction error at timestep 3440 is 0.012
Human Feedback received at timestep 3440 of None
Current timestep = 3441. State = [[-0.32113653  0.00679777]]. Action = [[ 0.03758224  0.02809206  0.         -0.94353527]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 3441 is [True, False, False, False, True, False]
Current timestep = 3442. State = [[-0.323444   0.0126484]]. Action = [[-0.04222048  0.07923413  0.          0.23783374]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 3442 is [True, False, False, False, True, False]
Current timestep = 3443. State = [[-0.33085737  0.01983337]]. Action = [[-0.09913652  0.06981944  0.          0.74856424]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 3443 is [True, False, False, False, True, False]
Current timestep = 3444. State = [[-0.33558026  0.02559265]]. Action = [[-0.00108661  0.04191575  0.         -0.93162334]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3444 is [True, False, False, False, True, False]
Current timestep = 3445. State = [[-0.34118018  0.02982341]]. Action = [[-0.06857041  0.02777835  0.          0.3055849 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 3445 is [True, False, False, False, True, False]
Current timestep = 3446. State = [[-0.34225082  0.02743702]]. Action = [[ 0.05882173 -0.09086454  0.         -0.6492977 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 3446 is [True, False, False, False, True, False]
Current timestep = 3447. State = [[-0.34103635  0.02787843]]. Action = [[ 0.02999837  0.05088992  0.         -0.08379412]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 3447 is [True, False, False, False, True, False]
Current timestep = 3448. State = [[-0.34142596  0.02834325]]. Action = [[ 0.00270157 -0.02970437  0.         -0.75423974]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 3448 is [True, False, False, False, True, False]
Current timestep = 3449. State = [[-0.34064966  0.03156612]]. Action = [[0.03714795 0.07285432 0.         0.27378988]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 3449 is [True, False, False, False, True, False]
State prediction error at timestep 3449 is 0.012
Human Feedback received at timestep 3449 of None
Current timestep = 3450. State = [[-0.3394678   0.03380818]]. Action = [[ 0.02736901 -0.00477319  0.         -0.0455727 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 3450 is [True, False, False, False, True, False]
Current timestep = 3451. State = [[-0.33541036  0.03293605]]. Action = [[ 0.08144904 -0.02141612  0.          0.19614851]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 3451 is [True, False, False, False, True, False]
State prediction error at timestep 3451 is 0.012
Human Feedback received at timestep 3451 of None
Current timestep = 3452. State = [[-0.33692142  0.0358507 ]]. Action = [[-0.07703786  0.06883862  0.          0.05389261]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 3452 is [True, False, False, False, True, False]
Current timestep = 3453. State = [[-0.33766717  0.04214904]]. Action = [[0.04616452 0.08007549 0.         0.8785274 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 3453 is [True, False, False, False, True, False]
State prediction error at timestep 3453 is 0.012
Human Feedback received at timestep 3453 of None
Current timestep = 3454. State = [[-0.33311707  0.04970294]]. Action = [[0.09444838 0.09132271 0.         0.8872156 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 3454 is [True, False, False, False, True, False]
Current timestep = 3455. State = [[-0.33006117  0.05318299]]. Action = [[2.8080173e-02 5.2705407e-05 0.0000000e+00 9.6600509e-01]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 3455 is [True, False, False, False, True, False]
Current timestep = 3456. State = [[-0.32857642  0.05423741]]. Action = [[ 0.01741754  0.00161149  0.         -0.14454997]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 3456 is [True, False, False, False, True, False]
Current timestep = 3457. State = [[-0.3273992   0.05542841]]. Action = [[ 0.00894983  0.00420319  0.         -0.83055925]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 3457 is [True, False, False, False, True, False]
Current timestep = 3458. State = [[-0.3304028   0.05716031]]. Action = [[-0.08061835  0.01020744  0.         -0.41807663]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 3458 is [True, False, False, False, True, False]
State prediction error at timestep 3458 is 0.012
Human Feedback received at timestep 3458 of None
Current timestep = 3459. State = [[-0.3358159  0.058939 ]]. Action = [[-0.08260231  0.00237073  0.         -0.9452232 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 3459 is [True, False, False, False, True, False]
Current timestep = 3460. State = [[-0.33699363  0.0589851 ]]. Action = [[ 0.01319202 -0.02688915  0.         -0.48121798]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 3460 is [True, False, False, False, True, False]
Current timestep = 3461. State = [[-0.33931354  0.05740505]]. Action = [[-0.06537497 -0.03587835  0.         -0.00880402]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 3461 is [True, False, False, False, True, False]
State prediction error at timestep 3461 is 0.012
Human Feedback received at timestep 3461 of None
Current timestep = 3462. State = [[-0.33738568  0.05872431]]. Action = [[ 0.0732223   0.03605991  0.         -0.9112931 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 3462 is [True, False, False, False, True, False]
Current timestep = 3463. State = [[-0.33481637  0.06450031]]. Action = [[ 0.0080836   0.08596142  0.         -0.7189687 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 3463 is [True, False, False, False, True, False]
Current timestep = 3464. State = [[-0.33560875  0.07044496]]. Action = [[-0.02020402  0.05324482  0.         -0.0136655 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 3464 is [True, False, False, False, True, False]
Current timestep = 3465. State = [[-0.3382261   0.07263124]]. Action = [[-0.03894452 -0.00971671  0.          0.07903183]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 3465 is [True, False, False, False, True, False]
State prediction error at timestep 3465 is 0.012
Human Feedback received at timestep 3465 of None
Current timestep = 3466. State = [[-0.3351106   0.07105255]]. Action = [[ 0.08828115 -0.04414904  0.         -0.10915351]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 3466 is [True, False, False, False, True, False]
Current timestep = 3467. State = [[-0.33018687  0.06707139]]. Action = [[ 0.04252283 -0.0594618   0.         -0.7813416 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 3467 is [True, False, False, False, True, False]
State prediction error at timestep 3467 is 0.012
Human Feedback received at timestep 3467 of None
Current timestep = 3468. State = [[-0.32694694  0.06109004]]. Action = [[ 0.01749755 -0.08310291  0.         -0.8759085 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 3468 is [True, False, False, False, True, False]
Current timestep = 3469. State = [[-0.32962883  0.06240386]]. Action = [[-0.09021705  0.08544686  0.          0.46514177]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 3469 is [True, False, False, False, True, False]
State prediction error at timestep 3469 is 0.012
Human Feedback received at timestep 3469 of None
Current timestep = 3470. State = [[-0.32897386  0.06769463]]. Action = [[0.05902825 0.05665728 0.         0.18805623]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 3470 is [True, False, False, False, True, False]
Current timestep = 3471. State = [[-0.3286073   0.07396782]]. Action = [[-0.02460308  0.08420169  0.          0.10843992]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 3471 is [True, False, False, False, True, False]
Current timestep = 3472. State = [[-0.33278188  0.07340705]]. Action = [[-0.07608225 -0.07823452  0.         -0.6103995 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 3472 is [True, False, False, False, True, False]
Current timestep = 3473. State = [[-0.3312719   0.07356192]]. Action = [[ 0.08045181  0.03676417  0.         -0.5557888 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 3473 is [True, False, False, False, True, False]
Current timestep = 3474. State = [[-0.33173692  0.07261682]]. Action = [[-0.0719759  -0.05027713  0.          0.48943782]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 3474 is [True, False, False, False, True, False]
Current timestep = 3475. State = [[-0.33451843  0.07121133]]. Action = [[-0.0302748  -0.0109599   0.          0.34589994]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 3475 is [True, False, False, False, True, False]
Current timestep = 3476. State = [[-0.33604813  0.0730223 ]]. Action = [[-0.0152918   0.03632718  0.         -0.8570243 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 3476 is [True, False, False, False, True, False]
Current timestep = 3477. State = [[-0.33211145  0.07368983]]. Action = [[ 0.09777691 -0.01093557  0.         -0.32677746]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 3477 is [True, False, False, False, True, False]
Current timestep = 3478. State = [[-0.3319412   0.07754199]]. Action = [[-0.04476849  0.08414229  0.         -0.73091286]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 3478 is [True, False, False, False, True, False]
Current timestep = 3479. State = [[-0.33127534  0.08422837]]. Action = [[ 0.05359783  0.07935881  0.         -0.35427868]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 3479 is [True, False, False, False, True, False]
Current timestep = 3480. State = [[-0.3340205  0.0860371]]. Action = [[-0.07445474 -0.02546787  0.          0.5655749 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 3480 is [True, False, False, False, True, False]
Current timestep = 3481. State = [[-0.33864683  0.08848887]]. Action = [[-0.03402217  0.04567786  0.          0.30962563]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 3481 is [True, False, False, False, True, False]
Current timestep = 3482. State = [[-0.33894697  0.08715823]]. Action = [[ 0.03717533 -0.06777091  0.          0.9808965 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 3482 is [True, False, False, False, True, False]
State prediction error at timestep 3482 is 0.012
Human Feedback received at timestep 3482 of None
Current timestep = 3483. State = [[-0.33509755  0.08767369]]. Action = [[ 0.07408517  0.04389123  0.         -0.13356185]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 3483 is [True, False, False, False, True, False]
Current timestep = 3484. State = [[-0.3376982   0.08981456]]. Action = [[-0.09139651  0.01220485  0.          0.23140585]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 3484 is [True, False, False, False, True, False]
State prediction error at timestep 3484 is 0.012
Human Feedback received at timestep 3484 of None
Current timestep = 3485. State = [[-0.33868796  0.08803309]]. Action = [[ 0.04764988 -0.05119354  0.          0.84460473]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 3485 is [True, False, False, False, True, False]
Current timestep = 3486. State = [[-0.34033668  0.08624554]]. Action = [[-0.04712205 -0.00760885  0.          0.14724588]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 3486 is [True, False, False, False, True, False]
Current timestep = 3487. State = [[-0.33917955  0.08952364]]. Action = [[ 0.06504589  0.07324006  0.         -0.1495471 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 3487 is [True, False, False, False, True, False]
Current timestep = 3488. State = [[-0.33754218  0.09155285]]. Action = [[0.00907262 0.0001706  0.         0.02423096]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 3488 is [True, False, False, False, True, False]
Current timestep = 3489. State = [[-0.3339209   0.09359927]]. Action = [[0.07240512 0.04030596 0.         0.2205652 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 3489 is [True, False, False, False, True, False]
Current timestep = 3490. State = [[-0.33133507  0.09958664]]. Action = [[0.01812701 0.099341   0.         0.10273778]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 3490 is [True, False, False, False, True, False]
Current timestep = 3491. State = [[-0.33322167  0.10759282]]. Action = [[-0.03873135  0.09571365  0.          0.47133458]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 3491 is [True, False, False, False, True, False]
State prediction error at timestep 3491 is 0.012
Human Feedback received at timestep 3491 of None
Current timestep = 3492. State = [[-0.337944   0.1147025]]. Action = [[-0.05859833  0.06463399  0.         -0.4242438 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 3492 is [True, False, False, False, True, False]
Current timestep = 3493. State = [[-0.33726627  0.11546094]]. Action = [[ 0.06183731 -0.05356933  0.          0.5929973 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 3493 is [True, False, False, False, True, False]
State prediction error at timestep 3493 is 0.012
Human Feedback received at timestep 3493 of None
Current timestep = 3494. State = [[-0.33908975  0.11898755]]. Action = [[-0.06374793  0.07696644  0.          0.22457683]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 3494 is [True, False, False, False, True, False]
Current timestep = 3495. State = [[-0.34101897  0.12511425]]. Action = [[0.00903971 0.04696151 0.         0.64640236]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 3495 is [True, False, False, False, True, False]
Current timestep = 3496. State = [[-0.34499392  0.13240694]]. Action = [[-0.0667346   0.082182    0.         -0.15655601]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 3496 is [True, False, False, False, False, True]
Current timestep = 3497. State = [[-0.35137329  0.13685037]]. Action = [[-0.07166182 -0.00199621  0.         -0.74080765]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 3497 is [True, False, False, False, False, True]
State prediction error at timestep 3497 is 0.012
Human Feedback received at timestep 3497 of None
Current timestep = 3498. State = [[-0.3506934   0.14128886]]. Action = [[ 0.0827006   0.05116006  0.         -0.6318694 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 3498 is [True, False, False, False, False, True]
Current timestep = 3499. State = [[-0.3515412  0.1482648]]. Action = [[-0.04826098  0.07573613  0.          0.38228583]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 3499 is [True, False, False, False, False, True]
State prediction error at timestep 3499 is 0.012
Human Feedback received at timestep 3499 of None
Current timestep = 3500. State = [[-0.35830224  0.15252842]]. Action = [[-0.09935544 -0.00444675  0.          0.09750056]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 3500 is [True, False, False, False, False, True]
Current timestep = 3501. State = [[-0.35839212  0.15343975]]. Action = [[ 0.07009243 -0.02490911  0.         -0.610652  ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 3501 is [True, False, False, False, False, True]
State prediction error at timestep 3501 is 0.012
Human Feedback received at timestep 3501 of None
Current timestep = 3502. State = [[-0.35907197  0.15852602]]. Action = [[-0.04387419  0.08660714  0.          0.07859457]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 3502 is [True, False, False, False, False, True]
State prediction error at timestep 3502 is 0.012
Human Feedback received at timestep 3502 of None
Current timestep = 3503. State = [[-0.35696146  0.16552575]]. Action = [[0.08244547 0.06164915 0.         0.6044047 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 3503 is [True, False, False, False, False, True]
Current timestep = 3504. State = [[-0.35678753  0.1704004 ]]. Action = [[-0.03121185  0.03476078  0.          0.02992237]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 3504 is [True, False, False, False, False, True]
Current timestep = 3505. State = [[-0.3538563   0.17134044]]. Action = [[ 0.08123016 -0.02989224  0.          0.75760555]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 3505 is [True, False, False, False, False, True]
State prediction error at timestep 3505 is 0.012
Human Feedback received at timestep 3505 of None
Current timestep = 3506. State = [[-0.3523428   0.17568618]]. Action = [[-0.01649585  0.08639353  0.          0.45943987]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 3506 is [True, False, False, False, False, True]
Current timestep = 3507. State = [[-0.35116053  0.18377589]]. Action = [[ 0.03724206  0.0932942   0.         -0.87307966]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 3507 is [True, False, False, False, False, True]
Current timestep = 3508. State = [[-0.35482493  0.18666224]]. Action = [[-0.09878553 -0.03160026  0.         -0.6712033 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 3508 is [True, False, False, False, False, True]
Current timestep = 3509. State = [[-0.3587787   0.18824024]]. Action = [[-0.01298042  0.01463058  0.         -0.46932113]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 3509 is [True, False, False, False, False, True]
Current timestep = 3510. State = [[-0.3560159   0.19427809]]. Action = [[0.08698083 0.09755012 0.         0.23310995]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 3510 is [True, False, False, False, False, True]
Current timestep = 3511. State = [[-0.34938     0.19813089]]. Action = [[0.09412313 0.01296376 0.         0.34117055]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 3511 is [True, False, False, False, False, True]
State prediction error at timestep 3511 is 0.012
Human Feedback received at timestep 3511 of None
Current timestep = 3512. State = [[-0.34465557  0.1974406 ]]. Action = [[ 0.03016592 -0.0361499   0.         -0.42594934]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 3512 is [True, False, False, False, False, True]
Current timestep = 3513. State = [[-0.34364274  0.19464518]]. Action = [[-0.02111946 -0.05832492  0.         -0.1884458 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 3513 is [True, False, False, False, False, True]
Current timestep = 3514. State = [[-0.34499797  0.19093046]]. Action = [[-0.04532594 -0.06991623  0.          0.9943832 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 3514 is [True, False, False, False, False, True]
State prediction error at timestep 3514 is 0.012
Human Feedback received at timestep 3514 of None
Current timestep = 3515. State = [[-0.34866744  0.18771085]]. Action = [[-0.07808872 -0.05382675  0.          0.06814408]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 3515 is [True, False, False, False, False, True]
Current timestep = 3516. State = [[-0.34713006  0.19055527]]. Action = [[ 0.06836585  0.0813401   0.         -0.03348035]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 3516 is [True, False, False, False, False, True]
Current timestep = 3517. State = [[-0.34192362  0.197708  ]]. Action = [[ 0.05014237  0.09354871  0.         -0.5681025 ]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 3517 is [True, False, False, False, False, True]
State prediction error at timestep 3517 is 0.012
Human Feedback received at timestep 3517 of None
Current timestep = 3518. State = [[-0.33569708  0.20537458]]. Action = [[0.08153529 0.0986849  0.         0.13779855]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 3518 is [True, False, False, False, False, True]
State prediction error at timestep 3518 is 0.012
Human Feedback received at timestep 3518 of None
Current timestep = 3519. State = [[-0.32771093  0.21148255]]. Action = [[0.09933915 0.06767669 0.         0.34383833]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 3519 is [True, False, False, False, False, True]
Current timestep = 3520. State = [[-0.32135487  0.2143193 ]]. Action = [[ 0.04688569  0.01382695  0.         -0.6245257 ]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 3520 is [True, False, False, False, False, True]
Current timestep = 3521. State = [[-0.32212085  0.21302544]]. Action = [[-0.08009746 -0.06012518  0.          0.46066022]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 3521 is [True, False, False, False, False, True]
Current timestep = 3522. State = [[-0.32557502  0.21019687]]. Action = [[-0.05405725 -0.05916316  0.          0.28870034]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 3522 is [True, False, False, False, False, True]
Current timestep = 3523. State = [[-0.32789534  0.20830385]]. Action = [[-0.03665649 -0.03608892  0.          0.8623265 ]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 3523 is [True, False, False, False, False, True]
State prediction error at timestep 3523 is 0.012
Human Feedback received at timestep 3523 of None
Current timestep = 3524. State = [[-0.3281198   0.20913863]]. Action = [[ 0.00275484  0.0155821   0.         -0.5340454 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 3524 is [True, False, False, False, False, True]
Current timestep = 3525. State = [[-0.3272109   0.20810208]]. Action = [[ 0.00671132 -0.04423503  0.          0.8787044 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 3525 is [True, False, False, False, False, True]
Current timestep = 3526. State = [[-0.32574573  0.20495792]]. Action = [[ 0.01156857 -0.04877479  0.          0.9955611 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 3526 is [True, False, False, False, False, True]
Current timestep = 3527. State = [[-0.32490444  0.19944817]]. Action = [[-0.00778438 -0.08761826  0.         -0.4551947 ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 3527 is [True, False, False, False, False, True]
State prediction error at timestep 3527 is 0.012
Human Feedback received at timestep 3527 of None
Current timestep = 3528. State = [[-0.32283828  0.200453  ]]. Action = [[0.03405761 0.0793227  0.         0.52393675]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 3528 is [True, False, False, False, False, True]
State prediction error at timestep 3528 is 0.012
Human Feedback received at timestep 3528 of None
Current timestep = 3529. State = [[-0.32182267  0.20341733]]. Action = [[-0.00646058  0.02685624  0.          0.03873813]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 3529 is [True, False, False, False, False, True]
Current timestep = 3530. State = [[-0.31894648  0.2060321 ]]. Action = [[ 0.05739167  0.04501175  0.         -0.5861325 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 3530 is [True, False, False, False, False, True]
Current timestep = 3531. State = [[-0.32035643  0.20949432]]. Action = [[-0.06143276  0.0524246   0.         -0.1216346 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 3531 is [True, False, False, False, False, True]
Current timestep = 3532. State = [[-0.3232462   0.20725568]]. Action = [[-0.0224288  -0.08172236  0.          0.17494464]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 3532 is [True, False, False, False, False, True]
Current timestep = 3533. State = [[-0.3226747   0.20467725]]. Action = [[ 0.02399494 -0.01284729  0.          0.17322421]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 3533 is [True, False, False, False, False, True]
Current timestep = 3534. State = [[-0.32662594  0.20659873]]. Action = [[-0.09181949  0.0462599   0.         -0.24759912]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 3534 is [True, False, False, False, False, True]
Current timestep = 3535. State = [[-0.32809022  0.20584853]]. Action = [[ 0.03146315 -0.04976387  0.         -0.75012773]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 3535 is [True, False, False, False, False, True]
State prediction error at timestep 3535 is 0.012
Human Feedback received at timestep 3535 of None
Current timestep = 3536. State = [[-0.33119622  0.20501417]]. Action = [[-0.07246423  0.00634035  0.         -0.81755227]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 3536 is [True, False, False, False, False, True]
Current timestep = 3537. State = [[-0.33454984  0.20566612]]. Action = [[-0.01475287  0.00404875  0.         -0.90020126]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 3537 is [True, False, False, False, False, True]
State prediction error at timestep 3537 is 0.012
Human Feedback received at timestep 3537 of None
Current timestep = 3538. State = [[-0.33857927  0.20418108]]. Action = [[-0.0568106  -0.03850342  0.          0.81579924]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 3538 is [True, False, False, False, False, True]
Current timestep = 3539. State = [[-0.34446794  0.20537448]]. Action = [[-0.06755255  0.03863656  0.          0.33517814]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 3539 is [True, False, False, False, False, True]
Current timestep = 3540. State = [[-0.344046    0.20546272]]. Action = [[ 0.07505196 -0.02100901  0.          0.6021751 ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 3540 is [True, False, False, False, False, True]
Current timestep = 3541. State = [[-0.34639683  0.20049629]]. Action = [[-0.07619379 -0.08906862  0.          0.63934827]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 3541 is [True, False, False, False, False, True]
Current timestep = 3542. State = [[-0.35039496  0.19927007]]. Action = [[-0.01600069  0.03300828  0.         -0.8173078 ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 3542 is [True, False, False, False, False, True]
Current timestep = 3543. State = [[-0.34831414  0.2002916 ]]. Action = [[0.08121877 0.02138577 0.         0.30437446]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 3543 is [True, False, False, False, False, True]
Current timestep = 3544. State = [[-0.347222   0.2042382]]. Action = [[ 0.00210987  0.09487934  0.         -0.08588946]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 3544 is [True, False, False, False, False, True]
State prediction error at timestep 3544 is 0.012
Human Feedback received at timestep 3544 of None
Current timestep = 3545. State = [[-0.35269067  0.20732321]]. Action = [[-0.08853276  0.02225945  0.         -0.4561113 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 3545 is [True, False, False, False, False, True]
State prediction error at timestep 3545 is 0.012
Human Feedback received at timestep 3545 of None
Current timestep = 3546. State = [[-0.3542173   0.20299913]]. Action = [[ 0.04688243 -0.09982529  0.         -0.2863196 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 3546 is [True, False, False, False, False, True]
State prediction error at timestep 3546 is 0.012
Human Feedback received at timestep 3546 of None
Current timestep = 3547. State = [[-0.3559198   0.20015171]]. Action = [[-0.04377297  0.00792763  0.          0.24251533]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 3547 is [True, False, False, False, False, True]
Current timestep = 3548. State = [[-0.3606643   0.19545604]]. Action = [[-0.05794038 -0.09738964  0.          0.25772464]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 3548 is [True, False, False, False, False, True]
Current timestep = 3549. State = [[-0.35954052  0.1943815 ]]. Action = [[0.07820254 0.04554882 0.         0.7946559 ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 3549 is [True, False, False, False, False, True]
State prediction error at timestep 3549 is 0.012
Human Feedback received at timestep 3549 of None
Current timestep = 3550. State = [[-0.3600413   0.19388594]]. Action = [[-0.05612766 -0.03023602  0.         -0.16083294]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 3550 is [True, False, False, False, False, True]
Current timestep = 3551. State = [[-0.35741577  0.19469829]]. Action = [[0.08866497 0.04169302 0.         0.00956571]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 3551 is [True, False, False, False, False, True]
State prediction error at timestep 3551 is 0.012
Human Feedback received at timestep 3551 of None
Current timestep = 3552. State = [[-0.35158604  0.19919524]]. Action = [[0.06728876 0.08545008 0.         0.14857852]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 3552 is [True, False, False, False, False, True]
Current timestep = 3553. State = [[-0.35378277  0.20365867]]. Action = [[-0.09119777  0.04637706  0.         -0.28490496]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 3553 is [True, False, False, False, False, True]
Current timestep = 3554. State = [[-0.36048338  0.20323564]]. Action = [[-0.07841691 -0.04725247  0.          0.5022532 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 3554 is [True, False, False, False, False, True]
Current timestep = 3555. State = [[-0.35990903  0.2022588 ]]. Action = [[ 0.07109194 -0.00314927  0.         -0.41444808]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 3555 is [True, False, False, False, False, True]
Current timestep = 3556. State = [[-0.36257115  0.20009309]]. Action = [[-0.09623821 -0.0540555   0.          0.20464456]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 3556 is [True, False, False, False, False, True]
Current timestep = 3557. State = [[-0.36125353  0.19645274]]. Action = [[ 0.08431724 -0.05051155  0.         -0.9075777 ]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 3557 is [True, False, False, False, False, True]
State prediction error at timestep 3557 is 0.012
Human Feedback received at timestep 3557 of None
Current timestep = 3558. State = [[-0.3571291   0.19708924]]. Action = [[0.03421857 0.05071598 0.         0.97363317]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 3558 is [True, False, False, False, False, True]
Current timestep = 3559. State = [[-0.3575782   0.20070773]]. Action = [[-0.03070433  0.05379143  0.         -0.7250777 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 3559 is [True, False, False, False, False, True]
Current timestep = 3560. State = [[-0.36335894  0.20517989]]. Action = [[-0.09315259  0.05481043  0.          0.35348487]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 3560 is [True, False, False, False, False, True]
Current timestep = 3561. State = [[-0.36958084  0.20542984]]. Action = [[-0.05728401 -0.04366224  0.          0.05443728]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 3561 is [True, False, False, False, False, True]
Current timestep = 3562. State = [[-0.36738056  0.20469145]]. Action = [[0.09744807 0.00096156 0.         0.46345663]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 3562 is [True, False, False, False, False, True]
Current timestep = 3563. State = [[-0.36484817  0.20470577]]. Action = [[ 0.         0.         0.        -0.9193249]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 3563 is [True, False, False, False, False, True]
Current timestep = 3564. State = [[-0.3670374   0.20488083]]. Action = [[-0.04800716 -0.00415847  0.         -0.527146  ]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 3564 is [True, False, False, False, False, True]
Current timestep = 3565. State = [[-0.3684653  0.2053417]]. Action = [[ 0.         0.         0.        -0.3294012]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 3565 is [True, False, False, False, False, True]
Current timestep = 3566. State = [[-0.364333    0.20292586]]. Action = [[ 0.08384513 -0.05210948  0.         -0.5271395 ]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 3566 is [True, False, False, False, False, True]
State prediction error at timestep 3566 is 0.012
Human Feedback received at timestep 3566 of None
Current timestep = 3567. State = [[-0.36548862  0.20029275]]. Action = [[-0.08249076 -0.0218088   0.          0.10214794]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 3567 is [True, False, False, False, False, True]
Current timestep = 3568. State = [[-0.37016475  0.19541664]]. Action = [[-0.05726074 -0.09803906  0.          0.8077333 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 3568 is [True, False, False, False, False, True]
Current timestep = 3569. State = [[-0.36824155  0.19570345]]. Action = [[ 0.08269193  0.07123064  0.         -0.23624599]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 3569 is [True, False, False, False, False, True]
State prediction error at timestep 3569 is 0.012
Human Feedback received at timestep 3569 of None
Current timestep = 3570. State = [[-0.3645757   0.19537616]]. Action = [[ 0.0118473  -0.04281002  0.          0.8391857 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 3570 is [True, False, False, False, False, True]
Current timestep = 3571. State = [[-0.3615376   0.19187625]]. Action = [[ 0.02808958 -0.04803818  0.          0.7131157 ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 3571 is [True, False, False, False, False, True]
Current timestep = 3572. State = [[-0.35980287  0.19378312]]. Action = [[-0.00255083  0.07413929  0.          0.5716467 ]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 3572 is [True, False, False, False, False, True]
Current timestep = 3573. State = [[-0.3598879   0.19825836]]. Action = [[-0.00798637  0.05636274  0.          0.00649679]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 3573 is [True, False, False, False, False, True]
Current timestep = 3574. State = [[-0.3629344   0.20020235]]. Action = [[-0.05774696  0.00443282  0.          0.21763921]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 3574 is [True, False, False, False, False, True]
Current timestep = 3575. State = [[-0.3639578  0.1975264]]. Action = [[ 0.01252104 -0.0669615   0.         -0.6978139 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 3575 is [True, False, False, False, False, True]
State prediction error at timestep 3575 is 0.012
Human Feedback received at timestep 3575 of None
Current timestep = 3576. State = [[-0.3660472   0.19350043]]. Action = [[-0.05305618 -0.05172341  0.          0.1894877 ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 3576 is [True, False, False, False, False, True]
Current timestep = 3577. State = [[-0.36371648  0.19324853]]. Action = [[0.08060621 0.0281757  0.         0.6184795 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 3577 is [True, False, False, False, False, True]
Current timestep = 3578. State = [[-0.3563507   0.19177936]]. Action = [[ 0.09609165 -0.03279669  0.          0.18289924]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 3578 is [True, False, False, False, False, True]
State prediction error at timestep 3578 is 0.012
Human Feedback received at timestep 3578 of None
Current timestep = 3579. State = [[-0.35313076  0.18553431]]. Action = [[-0.01737409 -0.09920742  0.         -0.32727635]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 3579 is [True, False, False, False, False, True]
Current timestep = 3580. State = [[-0.35654107  0.1858868 ]]. Action = [[-0.08179898  0.07474031  0.         -0.42644167]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 3580 is [True, False, False, False, False, True]
Current timestep = 3581. State = [[-0.35515758  0.19223662]]. Action = [[0.08364981 0.09949832 0.         0.14450479]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 3581 is [True, False, False, False, False, True]
Current timestep = 3582. State = [[-0.35740587  0.19574083]]. Action = [[-0.09408116  0.01146974  0.         -0.8995262 ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 3582 is [True, False, False, False, False, True]
Current timestep = 3583. State = [[-0.35683355  0.19635506]]. Action = [[0.08089756 0.00699072 0.         0.49690914]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 3583 is [True, False, False, False, False, True]
Current timestep = 3584. State = [[-0.3546639   0.19257581]]. Action = [[ 0.00763174 -0.07315255  0.         -0.0130204 ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 3584 is [True, False, False, False, False, True]
Current timestep = 3585. State = [[-0.35360497  0.19437447]]. Action = [[0.01946472 0.08757805 0.         0.15918148]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 3585 is [True, False, False, False, False, True]
Current timestep = 3586. State = [[-0.35732973  0.19391613]]. Action = [[-0.08828274 -0.06364644  0.         -0.59240204]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 3586 is [True, False, False, False, False, True]
Current timestep = 3587. State = [[-0.3619185   0.19586328]]. Action = [[-0.02432657  0.07125657  0.          0.5845597 ]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 3587 is [True, False, False, False, False, True]
Current timestep = 3588. State = [[-0.36209488  0.20160578]]. Action = [[0.04018752 0.08055117 0.         0.09983277]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 3588 is [True, False, False, False, False, True]
Current timestep = 3589. State = [[-0.36394894  0.20458877]]. Action = [[-0.03381712  0.01577326  0.         -0.68390906]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 3589 is [True, False, False, False, False, True]
Current timestep = 3590. State = [[-0.36934012  0.20608008]]. Action = [[-0.06630734  0.01013927  0.         -0.6444321 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 3590 is [True, False, False, False, False, True]
Current timestep = 3591. State = [[-0.37002218  0.20668337]]. Action = [[ 0.04974905 -0.00675362  0.          0.9697385 ]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 3591 is [True, False, False, False, False, True]
State prediction error at timestep 3591 is 0.012
Human Feedback received at timestep 3591 of None
Current timestep = 3592. State = [[-0.36954743  0.20683031]]. Action = [[ 0.         0.         0.        -0.4961726]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 3592 is [True, False, False, False, False, True]
Current timestep = 3593. State = [[-0.37007824  0.2072244 ]]. Action = [[0.         0.         0.         0.70486534]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 3593 is [True, False, False, False, False, True]
Current timestep = 3594. State = [[-0.37050298  0.2076417 ]]. Action = [[0.         0.         0.         0.53818345]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 3594 is [True, False, False, False, False, True]
Current timestep = 3595. State = [[-0.3703065   0.21172327]]. Action = [[ 0.01251141  0.07758885  0.         -0.35390025]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 3595 is [True, False, False, False, False, True]
Current timestep = 3596. State = [[-0.3730006   0.21556897]]. Action = [[-0.04979671  0.02771174  0.          0.8609679 ]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 3596 is [True, False, False, False, False, True]
Current timestep = 3597. State = [[-0.37171686  0.21861161]]. Action = [[ 0.0670323   0.03451905  0.         -0.5800547 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 3597 is [True, False, False, False, False, True]
Current timestep = 3598. State = [[-0.3703213   0.22409417]]. Action = [[3.755316e-04 8.748784e-02 0.000000e+00 9.028610e-01]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 3598 is [True, False, False, False, False, True]
Current timestep = 3599. State = [[-0.3706596  0.2270765]]. Action = [[ 0.          0.          0.         -0.07876366]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 3599 is [True, False, False, False, False, True]
Current timestep = 3600. State = [[-0.36597145  0.22928032]]. Action = [[ 0.09710019  0.03057275  0.         -0.29011458]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 3600 is [True, False, False, False, False, True]
Current timestep = 3601. State = [[-0.36394128  0.2281903 ]]. Action = [[-0.02702417 -0.05559903  0.         -0.5425733 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 3601 is [True, False, False, False, False, True]
State prediction error at timestep 3601 is 0.012
Human Feedback received at timestep 3601 of None
Current timestep = 3602. State = [[-0.3594076   0.22601722]]. Action = [[ 0.09171223 -0.02792643  0.         -0.95890373]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 3602 is [True, False, False, False, False, True]
Current timestep = 3603. State = [[-0.35674912  0.22548021]]. Action = [[-0.0193477  -0.00094752  0.         -0.71798015]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 3603 is [True, False, False, False, False, True]
Current timestep = 3604. State = [[-0.3529697   0.22419916]]. Action = [[ 0.06154693 -0.03449697  0.         -0.8532207 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 3604 is [True, False, False, False, False, True]
Current timestep = 3605. State = [[-0.35020497  0.2203668 ]]. Action = [[-0.01000373 -0.06437701  0.          0.30023074]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 3605 is [True, False, False, False, False, True]
Current timestep = 3606. State = [[-0.35050324  0.22333127]]. Action = [[-0.02982501  0.09288847  0.          0.05376065]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 3606 is [True, False, False, False, False, True]
Current timestep = 3607. State = [[-0.34765384  0.22832441]]. Action = [[0.06063376 0.04911143 0.         0.35967684]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 3607 is [True, False, False, False, False, True]
Current timestep = 3608. State = [[-0.34983695  0.23447452]]. Action = [[-0.08759663  0.09408148  0.         -0.6039493 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 3608 is [True, False, False, False, False, True]
Current timestep = 3609. State = [[-0.34826547  0.23400125]]. Action = [[ 0.08109771 -0.08486432  0.         -0.8727584 ]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 3609 is [True, False, False, False, False, True]
Current timestep = 3610. State = [[-0.34645295  0.23232329]]. Action = [[-0.02219829  0.00535108  0.          0.33765042]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 3610 is [True, False, False, False, False, True]
Current timestep = 3611. State = [[-0.3425783   0.23696388]]. Action = [[ 0.08231702  0.09318527  0.         -0.55860615]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 3611 is [True, False, False, False, False, True]
Current timestep = 3612. State = [[-0.3402181   0.23658155]]. Action = [[-0.01962031 -0.07206564  0.          0.6039543 ]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 3612 is [True, False, False, False, False, True]
State prediction error at timestep 3612 is 0.012
Human Feedback received at timestep 3612 of None
Current timestep = 3613. State = [[-0.34206146  0.23331036]]. Action = [[-0.04001445 -0.03856369  0.          0.15299678]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 3613 is [True, False, False, False, False, True]
Current timestep = 3614. State = [[-0.34655803  0.23142636]]. Action = [[-0.0745977  -0.02914801  0.         -0.7198796 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 3614 is [True, False, False, False, False, True]
Current timestep = 3615. State = [[-0.35334468  0.23454697]]. Action = [[-0.08871222  0.06453947  0.         -0.7321782 ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 3615 is [True, False, False, False, False, True]
Current timestep = 3616. State = [[-0.3610957  0.2331384]]. Action = [[-0.08743886 -0.08462416  0.         -0.8515425 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 3616 is [True, False, False, False, False, True]
Current timestep = 3617. State = [[-0.3684062  0.2283735]]. Action = [[-0.07666951 -0.07231954  0.          0.9368992 ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 3617 is [True, False, False, False, False, True]
Current timestep = 3618. State = [[-0.3726717   0.22254974]]. Action = [[-0.01804636 -0.08869004  0.         -0.28841925]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 3618 is [True, False, False, False, False, True]
Current timestep = 3619. State = [[-0.37441638  0.21985243]]. Action = [[ 0.         0.         0.        -0.5766472]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 3619 is [True, False, False, False, False, True]
Current timestep = 3620. State = [[-0.3710608   0.21493159]]. Action = [[ 0.09150889 -0.07743741  0.          0.91513145]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 3620 is [True, False, False, False, False, True]
Current timestep = 3621. State = [[-0.37107775  0.21132588]]. Action = [[-0.04024636  0.00507899  0.         -0.92309576]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 3621 is [True, False, False, False, False, True]
Current timestep = 3622. State = [[-0.37118056  0.2127239 ]]. Action = [[ 0.03844287  0.05917879  0.         -0.89014184]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 3622 is [True, False, False, False, False, True]
Current timestep = 3623. State = [[-0.3711927  0.2084894]]. Action = [[-0.00590459 -0.08948053  0.         -0.30222273]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 3623 is [True, False, False, False, False, True]
Current timestep = 3624. State = [[-0.37425512  0.20271939]]. Action = [[-0.04434357 -0.04012591  0.         -0.6258863 ]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 3624 is [True, False, False, False, False, True]
State prediction error at timestep 3624 is 0.012
Human Feedback received at timestep 3624 of None
Current timestep = 3625. State = [[-0.3752391   0.20107979]]. Action = [[ 0.02305828  0.02066092  0.         -0.4926985 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 3625 is [True, False, False, False, False, True]
State prediction error at timestep 3625 is 0.012
Human Feedback received at timestep 3625 of None
Current timestep = 3626. State = [[-0.37440082  0.20203978]]. Action = [[0.02348341 0.04556835 0.         0.24396157]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 3626 is [True, False, False, False, False, True]
Current timestep = 3627. State = [[-0.3747531   0.20237464]]. Action = [[-0.00263029  0.01571908  0.         -0.43140376]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 3627 is [True, False, False, False, False, True]
State prediction error at timestep 3627 is 0.012
Human Feedback received at timestep 3627 of None
Current timestep = 3628. State = [[-0.37563938  0.20153928]]. Action = [[0.         0.         0.         0.46133494]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 3628 is [True, False, False, False, False, True]
Current timestep = 3629. State = [[-0.3739362   0.19705567]]. Action = [[ 0.04470756 -0.07023159  0.          0.30172837]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 3629 is [True, False, False, False, False, True]
State prediction error at timestep 3629 is 0.012
Human Feedback received at timestep 3629 of None
Current timestep = 3630. State = [[-0.37314337  0.19731766]]. Action = [[-0.00599054  0.06872385  0.          0.5864222 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 3630 is [True, False, False, False, False, True]
Current timestep = 3631. State = [[-0.37121817  0.20136935]]. Action = [[0.0514233  0.06616626 0.         0.04365468]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 3631 is [True, False, False, False, False, True]
Current timestep = 3632. State = [[-0.3676855   0.20480841]]. Action = [[ 0.0496996   0.05179492  0.         -0.7790682 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 3632 is [True, False, False, False, False, True]
Current timestep = 3633. State = [[-0.36479136  0.20164508]]. Action = [[ 0.02456842 -0.08474554  0.          0.32510543]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 3633 is [True, False, False, False, False, True]
Current timestep = 3634. State = [[-0.36820742  0.2031455 ]]. Action = [[-0.09199263  0.084944    0.         -0.33881104]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 3634 is [True, False, False, False, False, True]
Current timestep = 3635. State = [[-0.36624825  0.20663835]]. Action = [[0.09854154 0.01807289 0.         0.5372331 ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 3635 is [True, False, False, False, False, True]
Current timestep = 3636. State = [[-0.36367518  0.20714028]]. Action = [[-0.0045987  -0.0039205   0.          0.21379995]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 3636 is [True, False, False, False, False, True]
State prediction error at timestep 3636 is 0.012
Human Feedback received at timestep 3636 of None
Current timestep = 3637. State = [[-0.36790955  0.20386364]]. Action = [[-0.09849034 -0.08536541  0.         -0.18349868]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 3637 is [True, False, False, False, False, True]
Current timestep = 3638. State = [[-0.36814442  0.2029587 ]]. Action = [[0.0507431  0.01474662 0.         0.01351368]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 3638 is [True, False, False, False, False, True]
State prediction error at timestep 3638 is 0.012
Human Feedback received at timestep 3638 of None
Current timestep = 3639. State = [[-0.36837837  0.20577952]]. Action = [[-0.04125503  0.03638213  0.         -0.73331624]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 3639 is [True, False, False, False, False, True]
Current timestep = 3640. State = [[-0.37211516  0.20418224]]. Action = [[-0.06217634 -0.07633546  0.         -0.6051695 ]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 3640 is [True, False, False, False, False, True]
Current timestep = 3641. State = [[-0.37173113  0.2068567 ]]. Action = [[ 0.0482005   0.08684518  0.         -0.8835748 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 3641 is [True, False, False, False, False, True]
Current timestep = 3642. State = [[-0.36918056  0.214464  ]]. Action = [[ 0.0220428   0.09642123  0.         -0.30592346]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 3642 is [True, False, False, False, False, True]
Current timestep = 3643. State = [[-0.36590713  0.21868399]]. Action = [[0.04902407 0.0181913  0.         0.34777677]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 3643 is [True, False, False, False, False, True]
Current timestep = 3644. State = [[-0.3625624   0.21904945]]. Action = [[ 0.02812564 -0.01849079  0.         -0.46017045]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 3644 is [True, False, False, False, False, True]
State prediction error at timestep 3644 is 0.012
Human Feedback received at timestep 3644 of None
Current timestep = 3645. State = [[-0.35610718  0.22069196]]. Action = [[ 0.09742291  0.03289961  0.         -0.3924414 ]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 3645 is [True, False, False, False, False, True]
Current timestep = 3646. State = [[-0.35010847  0.21845096]]. Action = [[ 0.03871112 -0.07158984  0.         -0.6424609 ]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 3646 is [True, False, False, False, False, True]
Current timestep = 3647. State = [[-0.35090154  0.21590291]]. Action = [[-0.07346565 -0.02715193  0.          0.76301813]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 3647 is [True, False, False, False, False, True]
Current timestep = 3648. State = [[-0.34926462  0.21254304]]. Action = [[ 0.04476269 -0.07162335  0.         -0.66849935]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 3648 is [True, False, False, False, False, True]
Current timestep = 3649. State = [[-0.3480129   0.21416494]]. Action = [[-0.02607637  0.06830119  0.         -0.8026365 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 3649 is [True, False, False, False, False, True]
Current timestep = 3650. State = [[-0.34546095  0.21591538]]. Action = [[ 0.04871724 -0.00600545  0.         -0.44090986]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 3650 is [True, False, False, False, False, True]
Current timestep = 3651. State = [[-0.34207907  0.2121864 ]]. Action = [[ 0.01969104 -0.07496945  0.          0.7285297 ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 3651 is [True, False, False, False, False, True]
Current timestep = 3652. State = [[-0.3355203   0.21010122]]. Action = [[ 0.09498469  0.00758042  0.         -0.6036077 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 3652 is [True, False, False, False, False, True]
Current timestep = 3653. State = [[-0.33228874  0.21195915]]. Action = [[-0.01653335  0.04919118  0.         -0.9738969 ]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 3653 is [True, False, False, False, False, True]
Current timestep = 3654. State = [[-0.33210245  0.2123321 ]]. Action = [[-0.01066177 -0.01590098  0.          0.92966104]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 3654 is [True, False, False, False, False, True]
Current timestep = 3655. State = [[-0.3340706   0.21269144]]. Action = [[-0.05113684  0.01320934  0.         -0.2978053 ]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 3655 is [True, False, False, False, False, True]
State prediction error at timestep 3655 is 0.012
Human Feedback received at timestep 3655 of None
Current timestep = 3656. State = [[-0.3344638   0.21068384]]. Action = [[ 0.0092694  -0.05412231  0.         -0.99343854]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 3656 is [True, False, False, False, False, True]
Current timestep = 3657. State = [[-0.33506557  0.21388222]]. Action = [[-0.02375384  0.0949757   0.          0.52597094]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 3657 is [True, False, False, False, False, True]
Current timestep = 3658. State = [[-0.33790636  0.22080141]]. Action = [[-0.03359877  0.08637881  0.         -0.7366683 ]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 3658 is [True, False, False, False, False, True]
Current timestep = 3659. State = [[-0.33971864  0.22174528]]. Action = [[-0.00094877 -0.04064945  0.         -0.07257968]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 3659 is [True, False, False, False, False, True]
Current timestep = 3660. State = [[-0.33798465  0.2243054 ]]. Action = [[ 0.05001732  0.06696216  0.         -0.15726393]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 3660 is [True, False, False, False, False, True]
Current timestep = 3661. State = [[-0.34036312  0.22692342]]. Action = [[-0.06610821  0.00677527  0.          0.8049085 ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 3661 is [True, False, False, False, False, True]
Current timestep = 3662. State = [[-0.34111518  0.22731997]]. Action = [[ 0.03603918 -0.01179919  0.          0.21811187]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 3662 is [True, False, False, False, False, True]
Current timestep = 3663. State = [[-0.33715108  0.22939745]]. Action = [[ 0.07210325  0.04364764  0.         -0.80762726]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 3663 is [True, False, False, False, False, True]
Current timestep = 3664. State = [[-0.34016567  0.23246911]]. Action = [[-0.09858508  0.03013518  0.          0.09858131]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 3664 is [True, False, False, False, False, True]
Current timestep = 3665. State = [[-0.3471842   0.23311721]]. Action = [[-0.07347946 -0.0257428   0.          0.56568635]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 3665 is [True, False, False, False, False, True]
Current timestep = 3666. State = [[-0.347688    0.22922015]]. Action = [[ 0.04712542 -0.08824219  0.         -0.0091005 ]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 3666 is [True, False, False, False, False, True]
Current timestep = 3667. State = [[-0.34358722  0.22380126]]. Action = [[ 0.05869447 -0.06723181  0.          0.09487271]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 3667 is [True, False, False, False, False, True]
Current timestep = 3668. State = [[-0.33907703  0.2172524 ]]. Action = [[ 0.04420059 -0.08976229  0.         -0.88959515]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 3668 is [True, False, False, False, False, True]
Current timestep = 3669. State = [[-0.33773696  0.21471176]]. Action = [[-0.01954111  0.01004522  0.         -0.616497  ]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 3669 is [True, False, False, False, False, True]
Current timestep = 3670. State = [[-0.34192088  0.21821079]]. Action = [[-0.08512859  0.07450937  0.          0.96338725]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 3670 is [True, False, False, False, False, True]
State prediction error at timestep 3670 is 0.012
Human Feedback received at timestep 3670 of None
Current timestep = 3671. State = [[-0.34135455  0.22024955]]. Action = [[0.06372664 0.00479071 0.         0.7225561 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 3671 is [True, False, False, False, False, True]
Current timestep = 3672. State = [[-0.33599022  0.2227339 ]]. Action = [[0.07725508 0.06684173 0.         0.15008116]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 3672 is [True, False, False, False, False, True]
State prediction error at timestep 3672 is 0.012
Human Feedback received at timestep 3672 of None
Current timestep = 3673. State = [[-0.33478785  0.2238704 ]]. Action = [[-0.02246318  0.0048488   0.          0.44259787]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 3673 is [True, False, False, False, False, True]
State prediction error at timestep 3673 is 0.012
Human Feedback received at timestep 3673 of None
Current timestep = 3674. State = [[-0.33621484  0.21904045]]. Action = [[-0.02071913 -0.09663969  0.         -0.09554225]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 3674 is [True, False, False, False, False, True]
Current timestep = 3675. State = [[-0.33953246  0.21259189]]. Action = [[-0.06381731 -0.08075405  0.          0.0024879 ]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 3675 is [True, False, False, False, False, True]
Current timestep = 3676. State = [[-0.3418842  0.2102211]]. Action = [[-0.01518913 -0.00243599  0.          0.6448927 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 3676 is [True, False, False, False, False, True]
Current timestep = 3677. State = [[-0.3405087   0.21374829]]. Action = [[ 0.04452113  0.08675852  0.         -0.4343295 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 3677 is [True, False, False, False, False, True]
Current timestep = 3678. State = [[-0.34177482  0.22000395]]. Action = [[-0.03704944  0.09365793  0.          0.12888992]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 3678 is [True, False, False, False, False, True]
State prediction error at timestep 3678 is 0.012
Human Feedback received at timestep 3678 of None
Current timestep = 3679. State = [[-0.34728312  0.21925715]]. Action = [[-0.07922278 -0.07477973  0.         -0.46637368]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 3679 is [True, False, False, False, False, True]
Current timestep = 3680. State = [[-0.34649536  0.21772715]]. Action = [[ 0.08770143  0.01468983  0.         -0.34521103]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 3680 is [True, False, False, False, False, True]
Current timestep = 3681. State = [[-0.34454057  0.21586987]]. Action = [[-0.0020092  -0.03903082  0.          0.91845846]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 3681 is [True, False, False, False, False, True]
Current timestep = 3682. State = [[-0.34065527  0.21480592]]. Action = [[ 0.0766662   0.00525479  0.         -0.11572468]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 3682 is [True, False, False, False, False, True]
Current timestep = 3683. State = [[-0.33554107  0.21705669]]. Action = [[ 0.05498386  0.05807143  0.         -0.21171749]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 3683 is [True, False, False, False, False, True]
State prediction error at timestep 3683 is 0.012
Human Feedback received at timestep 3683 of None
Current timestep = 3684. State = [[-0.33664623  0.21816054]]. Action = [[-0.06533913 -0.00491512  0.         -0.3055302 ]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 3684 is [True, False, False, False, False, True]
State prediction error at timestep 3684 is 0.012
Human Feedback received at timestep 3684 of None
Current timestep = 3685. State = [[-0.3362057   0.21450005]]. Action = [[ 0.04048326 -0.07458464  0.         -0.53464085]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 3685 is [True, False, False, False, False, True]
Current timestep = 3686. State = [[-0.3350534   0.21248277]]. Action = [[-0.0078641   0.00438555  0.          0.51350534]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 3686 is [True, False, False, False, False, True]
State prediction error at timestep 3686 is 0.012
Human Feedback received at timestep 3686 of None
Current timestep = 3687. State = [[-0.33779794  0.21063553]]. Action = [[-0.06113476 -0.03889204  0.          0.07380819]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 3687 is [True, False, False, False, False, True]
Current timestep = 3688. State = [[-0.33836797  0.20745692]]. Action = [[ 0.01571812 -0.04666714  0.          0.30009234]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 3688 is [True, False, False, False, False, True]
Current timestep = 3689. State = [[-0.33594623  0.20102282]]. Action = [[ 0.02919888 -0.09962822  0.          0.80607414]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 3689 is [True, False, False, False, False, True]
Current timestep = 3690. State = [[-0.3392637   0.20199232]]. Action = [[-0.09799464  0.09650738  0.         -0.5221347 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 3690 is [True, False, False, False, False, True]
Current timestep = 3691. State = [[-0.34083265  0.20618744]]. Action = [[0.03476467 0.03651898 0.         0.14573312]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 3691 is [True, False, False, False, False, True]
Current timestep = 3692. State = [[-0.3454249   0.21109954]]. Action = [[-0.09164061  0.08100509  0.         -0.65387106]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 3692 is [True, False, False, False, False, True]
Current timestep = 3693. State = [[-0.34829274  0.2148689 ]]. Action = [[ 0.02174236  0.02663129  0.         -0.99244714]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 3693 is [True, False, False, False, False, True]
Current timestep = 3694. State = [[-0.3490299   0.21966061]]. Action = [[0.00523988 0.08119554 0.         0.35920537]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 3694 is [True, False, False, False, False, True]
Current timestep = 3695. State = [[-0.35520244  0.22558083]]. Action = [[-0.09437621  0.06890398  0.         -0.42239344]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 3695 is [True, False, False, False, False, True]
State prediction error at timestep 3695 is 0.012
Human Feedback received at timestep 3695 of None
Current timestep = 3696. State = [[-0.3574024   0.23197994]]. Action = [[0.05155828 0.07868763 0.         0.70671356]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 3696 is [True, False, False, False, False, True]
State prediction error at timestep 3696 is 0.012
Human Feedback received at timestep 3696 of None
Current timestep = 3697. State = [[-0.35870275  0.23254678]]. Action = [[-0.02240414 -0.05019388  0.          0.20624185]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 3697 is [True, False, False, False, False, True]
State prediction error at timestep 3697 is 0.012
Human Feedback received at timestep 3697 of None
Current timestep = 3698. State = [[-0.3566092   0.23371625]]. Action = [[0.08318827 0.03930425 0.         0.13644636]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 3698 is [True, False, False, False, False, True]
Current timestep = 3699. State = [[-0.3574615   0.23124675]]. Action = [[-0.05742233 -0.09409074  0.         -0.56020117]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 3699 is [True, False, False, False, False, True]
Current timestep = 3700. State = [[-0.35512397  0.2298386 ]]. Action = [[ 0.09661784  0.0183928   0.         -0.9517094 ]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 3700 is [True, False, False, False, False, True]
Current timestep = 3701. State = [[-0.3575012  0.2341041]]. Action = [[-0.09929857  0.07536077  0.         -0.3469339 ]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 3701 is [True, False, False, False, False, True]
State prediction error at timestep 3701 is 0.012
Human Feedback received at timestep 3701 of None
Current timestep = 3702. State = [[-0.36117655  0.24067666]]. Action = [[-0.006527    0.0730051   0.         -0.34241647]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 3702 is [True, False, False, False, False, True]
State prediction error at timestep 3702 is 0.012
Human Feedback received at timestep 3702 of None
Current timestep = 3703. State = [[-0.3651839   0.24696027]]. Action = [[-0.05506812  0.06745661  0.         -0.09724176]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 3703 is [True, False, False, False, False, True]
State prediction error at timestep 3703 is 0.012
Human Feedback received at timestep 3703 of None
Current timestep = 3704. State = [[-0.36466774  0.25013435]]. Action = [[0.06239834 0.00541331 0.         0.7512162 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 3704 is [True, False, False, False, False, True]
Current timestep = 3705. State = [[-0.36431152  0.24901195]]. Action = [[-0.01816568 -0.04674996  0.          0.81213903]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 3705 is [True, False, False, False, False, True]
Current timestep = 3706. State = [[-0.36517364  0.24926008]]. Action = [[-0.00424081  0.00759538  0.          0.4613073 ]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 3706 is [True, False, False, False, False, True]
State prediction error at timestep 3706 is 0.012
Human Feedback received at timestep 3706 of None
Current timestep = 3707. State = [[-0.3668015  0.252535 ]]. Action = [[-0.02435829  0.0430116   0.         -0.8089987 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 3707 is [True, False, False, False, False, True]
Current timestep = 3708. State = [[-0.36910453  0.25490797]]. Action = [[-0.02385406  0.00326093  0.         -0.31597388]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 3708 is [True, False, False, False, False, True]
Current timestep = 3709. State = [[-0.3690151   0.25439617]]. Action = [[ 0.02229027 -0.03360627  0.          0.44590402]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 3709 is [True, False, False, False, False, True]
Current timestep = 3710. State = [[-0.37168127  0.25263375]]. Action = [[-0.06602699 -0.03687997  0.         -0.3585273 ]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 3710 is [True, False, False, False, False, True]
Current timestep = 3711. State = [[-0.3763964   0.25601828]]. Action = [[-0.05136944  0.06954562  0.          0.20318413]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 3711 is [True, False, False, False, False, True]
Current timestep = 3712. State = [[-0.37931213  0.2541656 ]]. Action = [[-0.01620083 -0.09690199  0.         -0.580383  ]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 3712 is [True, False, False, False, False, True]
State prediction error at timestep 3712 is 0.012
Human Feedback received at timestep 3712 of None
Current timestep = 3713. State = [[-0.3802021   0.25228605]]. Action = [[0.        0.        0.        0.9259286]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 3713 is [True, False, False, False, False, True]
Current timestep = 3714. State = [[-0.38061243  0.25237086]]. Action = [[0.         0.         0.         0.48744524]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 3714 is [True, False, False, False, False, True]
Current timestep = 3715. State = [[-0.37732276  0.24885502]]. Action = [[ 0.07079778 -0.06903939  0.         -0.9515236 ]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 3715 is [True, False, False, False, False, True]
Current timestep = 3716. State = [[-0.37504748  0.24644807]]. Action = [[ 0.          0.          0.         -0.06358284]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 3716 is [True, False, False, False, False, True]
Current timestep = 3717. State = [[-0.37473053  0.24585854]]. Action = [[0.         0.         0.         0.45283496]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 3717 is [True, False, False, False, False, True]
Current timestep = 3718. State = [[-0.37018883  0.24406295]]. Action = [[ 0.08568149 -0.02105047  0.         -0.4738717 ]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 3718 is [True, False, False, False, False, True]
Current timestep = 3719. State = [[-0.36349297  0.24144796]]. Action = [[ 0.07119926 -0.01558476  0.         -0.33704603]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 3719 is [True, False, False, False, False, True]
Current timestep = 3720. State = [[-0.36331135  0.23633814]]. Action = [[-0.06426845 -0.07855074  0.         -0.23195046]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 3720 is [True, False, False, False, False, True]
Current timestep = 3721. State = [[-0.36289898  0.23624222]]. Action = [[0.0335223  0.06452035 0.         0.7512833 ]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 3721 is [True, False, False, False, False, True]
Current timestep = 3722. State = [[-0.36626455  0.23779438]]. Action = [[-0.09804172  0.01000768  0.          0.5819893 ]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 3722 is [True, False, False, False, False, True]
Current timestep = 3723. State = [[-0.36847016  0.23862427]]. Action = [[0.01049886 0.01582529 0.         0.18173814]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 3723 is [True, False, False, False, False, True]
Current timestep = 3724. State = [[-0.36846957  0.23860261]]. Action = [[0.        0.        0.        0.6884898]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 3724 is [True, False, False, False, False, True]
Current timestep = 3725. State = [[-0.36597773  0.23990005]]. Action = [[ 0.05470956  0.0382713   0.         -0.05931568]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 3725 is [True, False, False, False, False, True]
Current timestep = 3726. State = [[-0.36143893  0.23662494]]. Action = [[ 0.05964071 -0.07245017  0.          0.6114085 ]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 3726 is [True, False, False, False, False, True]
Current timestep = 3727. State = [[-0.3590561   0.23011024]]. Action = [[-0.00079885 -0.08310898  0.         -0.2737007 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 3727 is [True, False, False, False, False, True]
Current timestep = 3728. State = [[-0.35626075  0.22971371]]. Action = [[0.04162357 0.05269385 0.         0.19651747]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 3728 is [True, False, False, False, False, True]
Current timestep = 3729. State = [[-0.35580903  0.22756559]]. Action = [[-0.03385253 -0.06429456  0.          0.35614502]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 3729 is [True, False, False, False, False, True]
Current timestep = 3730. State = [[-0.35377112  0.22207898]]. Action = [[ 0.04148761 -0.07049092  0.          0.2218492 ]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 3730 is [True, False, False, False, False, True]
Current timestep = 3731. State = [[-0.35485315  0.21814983]]. Action = [[-0.06492992 -0.02897429  0.         -0.9341432 ]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 3731 is [True, False, False, False, False, True]
State prediction error at timestep 3731 is 0.012
Human Feedback received at timestep 3731 of None
Current timestep = 3732. State = [[-0.361127    0.21932223]]. Action = [[-0.09998016  0.04494252  0.          0.44190788]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 3732 is [True, False, False, False, False, True]
Current timestep = 3733. State = [[-0.36449525  0.22440338]]. Action = [[ 0.00372623  0.08451138  0.         -0.8095213 ]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 3733 is [True, False, False, False, False, True]
State prediction error at timestep 3733 is 0.012
Human Feedback received at timestep 3733 of None
Current timestep = 3734. State = [[-0.3644655   0.22485532]]. Action = [[ 0.0195763  -0.02934813  0.          0.5322492 ]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 3734 is [True, False, False, False, False, True]
Current timestep = 3735. State = [[-0.36133054  0.22144252]]. Action = [[ 0.06249141 -0.04273495  0.         -0.527813  ]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 3735 is [True, False, False, False, False, True]
Current timestep = 3736. State = [[-0.3630441   0.21986862]]. Action = [[-0.06689803  0.00580879  0.         -0.72214854]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 3736 is [True, False, False, False, False, True]
State prediction error at timestep 3736 is 0.012
Human Feedback received at timestep 3736 of None
Current timestep = 3737. State = [[-0.36127043  0.2232081 ]]. Action = [[0.08786526 0.07914612 0.         0.21414614]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 3737 is [True, False, False, False, False, True]
Current timestep = 3738. State = [[-0.36365327  0.2244297 ]]. Action = [[-0.09952277 -0.02254931  0.         -0.4364946 ]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 3738 is [True, False, False, False, False, True]
Current timestep = 3739. State = [[-0.36901867  0.22648674]]. Action = [[-0.03360371  0.05318093  0.         -0.6911675 ]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 3739 is [True, False, False, False, False, True]
State prediction error at timestep 3739 is 0.012
Human Feedback received at timestep 3739 of None
Current timestep = 3740. State = [[-0.37147158  0.22781806]]. Action = [[0.        0.        0.        0.5412402]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 3740 is [True, False, False, False, False, True]
State prediction error at timestep 3740 is 0.012
Human Feedback received at timestep 3740 of None
Current timestep = 3741. State = [[-0.37239495  0.2314448 ]]. Action = [[ 0.00889204  0.07678091  0.         -0.6431345 ]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 3741 is [True, False, False, False, False, True]
Current timestep = 3742. State = [[-0.369153    0.22920112]]. Action = [[ 0.08233466 -0.08380958  0.          0.6762934 ]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 3742 is [True, False, False, False, False, True]
Current timestep = 3743. State = [[-0.36393845  0.23086551]]. Action = [[0.06559617 0.09394775 0.         0.9784653 ]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 3743 is [True, False, False, False, False, True]
Current timestep = 3744. State = [[-0.3600576   0.23438717]]. Action = [[0.03914153 0.03149705 0.         0.9020448 ]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 3744 is [True, False, False, False, False, True]
Current timestep = 3745. State = [[-0.36142206  0.23254879]]. Action = [[-0.06318755 -0.06632003  0.          0.84522986]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 3745 is [True, False, False, False, False, True]
State prediction error at timestep 3745 is 0.012
Human Feedback received at timestep 3745 of None
Current timestep = 3746. State = [[-0.36746812  0.23026398]]. Action = [[-0.09354973 -0.02974607  0.         -0.19977093]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 3746 is [True, False, False, False, False, True]
Current timestep = 3747. State = [[-0.36629254  0.2327703 ]]. Action = [[0.08967436 0.06551758 0.         0.03038132]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 3747 is [True, False, False, False, False, True]
Current timestep = 3748. State = [[-0.36079878  0.23583105]]. Action = [[ 0.05204987  0.02051628  0.         -0.86030006]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 3748 is [True, False, False, False, False, True]
Current timestep = 3749. State = [[-0.35875887  0.2401883 ]]. Action = [[-0.00749396  0.06729729  0.          0.23335052]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 3749 is [True, False, False, False, False, True]
Current timestep = 3750. State = [[-0.35685793  0.24586794]]. Action = [[0.03004613 0.06555843 0.         0.4387815 ]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 3750 is [True, False, False, False, False, True]
Current timestep = 3751. State = [[-0.35492924  0.2528493 ]]. Action = [[0.01356117 0.09196983 0.         0.09906018]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 3751 is [True, False, False, False, False, True]
Current timestep = 3752. State = [[-0.3537122   0.25495276]]. Action = [[ 0.00775079 -0.02916025  0.          0.00051308]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 3752 is [True, False, False, False, False, True]
Current timestep = 3753. State = [[-0.35156143  0.2517393 ]]. Action = [[ 0.02302562 -0.07954039  0.          0.06468856]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 3753 is [True, False, False, False, False, True]
State prediction error at timestep 3753 is 0.012
Human Feedback received at timestep 3753 of None
Current timestep = 3754. State = [[-0.35073686  0.25079057]]. Action = [[-0.01800091 -0.00277779  0.          0.26091552]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 3754 is [True, False, False, False, False, True]
Current timestep = 3755. State = [[-0.3482742   0.24845882]]. Action = [[ 0.03874879 -0.06962729  0.         -0.784397  ]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 3755 is [True, False, False, False, False, True]
Current timestep = 3756. State = [[-0.3442079   0.25080207]]. Action = [[0.03770656 0.0741136  0.         0.2713492 ]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 3756 is [True, False, False, False, False, True]
State prediction error at timestep 3756 is 0.012
Human Feedback received at timestep 3756 of None
Current timestep = 3757. State = [[-0.33881125  0.25586012]]. Action = [[ 0.06609309  0.05867475  0.         -0.13545871]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 3757 is [True, False, False, False, False, True]
State prediction error at timestep 3757 is 0.012
Human Feedback received at timestep 3757 of None
Current timestep = 3758. State = [[-0.3307727  0.257928 ]]. Action = [[0.09951299 0.00801859 0.         0.24067712]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 3758 is [True, False, False, False, False, True]
Current timestep = 3759. State = [[-0.32927254  0.2561435 ]]. Action = [[-0.06502226 -0.05276278  0.          0.46585906]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 3759 is [True, False, False, False, False, True]
Current timestep = 3760. State = [[-0.32969126  0.259716  ]]. Action = [[0.00802139 0.09563521 0.         0.7616656 ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 3760 is [True, False, False, False, False, True]
Current timestep = 3761. State = [[-0.32588294  0.26587534]]. Action = [[0.05980901 0.06757491 0.         0.19329512]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 3761 is [True, False, False, False, False, True]
State prediction error at timestep 3761 is 0.012
Human Feedback received at timestep 3761 of None
Current timestep = 3762. State = [[-0.32211873  0.2646523 ]]. Action = [[ 0.01943491 -0.07551029  0.         -0.4154048 ]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 3762 is [True, False, False, False, False, True]
Current timestep = 3763. State = [[-0.31969297  0.2602871 ]]. Action = [[ 0.01084366 -0.06122726  0.          0.53885436]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 3763 is [True, False, False, False, False, True]
Current timestep = 3764. State = [[-0.3185921   0.25904462]]. Action = [[-0.01038584 -0.0006496   0.         -0.2176035 ]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 3764 is [True, False, False, False, False, True]
Current timestep = 3765. State = [[-0.31882146  0.25507772]]. Action = [[-0.02349827 -0.09167647  0.          0.17511964]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 3765 is [True, False, False, False, False, True]
Current timestep = 3766. State = [[-0.32228896  0.25565684]]. Action = [[-0.07772544  0.05047729  0.         -0.23154628]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 3766 is [True, False, False, False, False, True]
State prediction error at timestep 3766 is 0.012
Human Feedback received at timestep 3766 of None
Current timestep = 3767. State = [[-0.32045296  0.25829116]]. Action = [[ 0.07822093  0.02092437  0.         -0.00082761]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 3767 is [True, False, False, False, False, True]
Current timestep = 3768. State = [[-0.32073918  0.25831157]]. Action = [[-0.05459937 -0.01249735  0.          0.24044013]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 3768 is [True, False, False, False, False, True]
Current timestep = 3769. State = [[-0.3210513   0.25335154]]. Action = [[ 0.01823603 -0.09942378  0.         -0.87827075]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 3769 is [True, False, False, False, False, True]
Current timestep = 3770. State = [[-0.32511833  0.25492552]]. Action = [[-0.09575664  0.0932105   0.         -0.00295073]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 3770 is [True, False, False, False, False, True]
Current timestep = 3771. State = [[-0.33014145  0.25487   ]]. Action = [[-0.03176762 -0.05877065  0.          0.58868647]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 3771 is [True, False, False, False, False, True]
Current timestep = 3772. State = [[-0.32977182  0.24960092]]. Action = [[ 0.04006683 -0.08183628  0.          0.62185335]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 3772 is [True, False, False, False, False, True]
Current timestep = 3773. State = [[-0.32700354  0.25094858]]. Action = [[0.04441644 0.0893187  0.         0.7639617 ]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 3773 is [True, False, False, False, False, True]
Current timestep = 3774. State = [[-0.32934168  0.2517909 ]]. Action = [[-0.06785807 -0.02354527  0.         -0.93841714]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 3774 is [True, False, False, False, False, True]
State prediction error at timestep 3774 is 0.012
Human Feedback received at timestep 3774 of None
Current timestep = 3775. State = [[-0.32904062  0.25133833]]. Action = [[ 0.05978896  0.01298797  0.         -0.97443086]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 3775 is [True, False, False, False, False, True]
Current timestep = 3776. State = [[-0.32556203  0.24990912]]. Action = [[ 0.04885649 -0.01567019  0.         -0.14186662]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 3776 is [True, False, False, False, False, True]
State prediction error at timestep 3776 is 0.012
Human Feedback received at timestep 3776 of None
Current timestep = 3777. State = [[-0.3264842   0.24541862]]. Action = [[-0.04731622 -0.06838534  0.         -0.10539973]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 3777 is [True, False, False, False, False, True]
Current timestep = 3778. State = [[-0.32982916  0.24374445]]. Action = [[-0.03855946  0.01340176  0.         -0.8073894 ]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 3778 is [True, False, False, False, False, True]
Current timestep = 3779. State = [[-0.32871807  0.24297129]]. Action = [[ 0.05349045 -0.0087264   0.          0.14376533]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 3779 is [True, False, False, False, False, True]
State prediction error at timestep 3779 is 0.012
Human Feedback received at timestep 3779 of None
Current timestep = 3780. State = [[-0.32817206  0.24129373]]. Action = [[-0.01517344 -0.0114428   0.          0.61284256]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 3780 is [True, False, False, False, False, True]
Current timestep = 3781. State = [[-0.32593843  0.24102202]]. Action = [[0.05506534 0.01860757 0.         0.15829158]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 3781 is [True, False, False, False, False, True]
Current timestep = 3782. State = [[-0.325519    0.23738894]]. Action = [[-0.02619261 -0.06852689  0.         -0.51627433]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 3782 is [True, False, False, False, False, True]
Current timestep = 3783. State = [[-0.32972923  0.23463427]]. Action = [[-0.07360953 -0.00917952  0.          0.8802004 ]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 3783 is [True, False, False, False, False, True]
Current timestep = 3784. State = [[-0.33139476  0.23493499]]. Action = [[ 0.01549681  0.02115377  0.         -0.9447341 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 3784 is [True, False, False, False, False, True]
Current timestep = 3785. State = [[-0.3362557   0.23639402]]. Action = [[-0.0938248   0.02707391  0.          0.0849936 ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 3785 is [True, False, False, False, False, True]
Current timestep = 3786. State = [[-0.34209606  0.23983753]]. Action = [[-0.04241651  0.05571683  0.          0.2710917 ]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 3786 is [True, False, False, False, False, True]
State prediction error at timestep 3786 is 0.012
Human Feedback received at timestep 3786 of None
Current timestep = 3787. State = [[-0.3430468  0.2438174]]. Action = [[ 0.0390852   0.05382281  0.         -0.45068657]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 3787 is [True, False, False, False, False, True]
Current timestep = 3788. State = [[-0.3428267   0.24054116]]. Action = [[ 0.00610618 -0.09505843  0.          0.21933854]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 3788 is [True, False, False, False, False, True]
Current timestep = 3789. State = [[-0.34455782  0.235597  ]]. Action = [[-0.02318384 -0.04701881  0.         -0.66613626]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 3789 is [True, False, False, False, False, True]
Current timestep = 3790. State = [[-0.34765905  0.23775792]]. Action = [[-0.03097128  0.07668947  0.         -0.16433185]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 3790 is [True, False, False, False, False, True]
Current timestep = 3791. State = [[-0.34875768  0.23883708]]. Action = [[ 0.01886228 -0.01473529  0.          0.8683747 ]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 3791 is [True, False, False, False, False, True]
State prediction error at timestep 3791 is 0.012
Human Feedback received at timestep 3791 of None
Current timestep = 3792. State = [[-0.346013    0.23735468]]. Action = [[ 0.06012484 -0.01477724  0.          0.56397295]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 3792 is [True, False, False, False, False, True]
Current timestep = 3793. State = [[-0.34890175  0.23608887]]. Action = [[-0.0870619  -0.00998602  0.          0.93116   ]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 3793 is [True, False, False, False, False, True]
Current timestep = 3794. State = [[-0.3552657   0.23777701]]. Action = [[-0.06700824  0.03619359  0.         -0.33696526]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 3794 is [True, False, False, False, False, True]
Current timestep = 3795. State = [[-0.36312416  0.2438805 ]]. Action = [[-0.09110731  0.09875769  0.          0.69799113]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 3795 is [True, False, False, False, False, True]
Current timestep = 3796. State = [[-0.36689675  0.24853913]]. Action = [[ 0.01638211  0.03315996  0.         -0.86876225]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 3796 is [True, False, False, False, False, True]
Current timestep = 3797. State = [[-0.36896122  0.24577878]]. Action = [[-0.01852941 -0.08549852  0.         -0.14734179]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 3797 is [True, False, False, False, False, True]
Current timestep = 3798. State = [[-0.3659593   0.24376325]]. Action = [[ 0.09619147  0.00614177  0.         -0.914121  ]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 3798 is [True, False, False, False, False, True]
Current timestep = 3799. State = [[-0.36344928  0.24812609]]. Action = [[0.0093957  0.09654468 0.         0.78539395]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 3799 is [True, False, False, False, False, True]
Current timestep = 3800. State = [[-0.36344385  0.25020933]]. Action = [[ 0.00351705 -0.00981621  0.         -0.8760254 ]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 3800 is [True, False, False, False, False, True]
State prediction error at timestep 3800 is 0.012
Human Feedback received at timestep 3800 of None
Current timestep = 3801. State = [[-0.35987726  0.25264186]]. Action = [[0.07536861 0.05271789 0.         0.26615047]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 3801 is [True, False, False, False, False, True]
State prediction error at timestep 3801 is 0.012
Human Feedback received at timestep 3801 of None
Current timestep = 3802. State = [[-0.35412356  0.24986413]]. Action = [[ 0.06531275 -0.08494525  0.         -0.02556181]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 3802 is [True, False, False, False, False, True]
Current timestep = 3803. State = [[-0.3488857   0.25114408]]. Action = [[ 0.0495416   0.07759615  0.         -0.7063848 ]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 3803 is [True, False, False, False, False, True]
Current timestep = 3804. State = [[-0.34984225  0.24949989]]. Action = [[-0.07853328 -0.09053146  0.         -0.02727169]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 3804 is [True, False, False, False, False, True]
Current timestep = 3805. State = [[-0.3497979  0.2469857]]. Action = [[ 0.0348822  -0.00655692  0.         -0.7257742 ]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 3805 is [True, False, False, False, False, True]
Current timestep = 3806. State = [[-0.352004    0.24990372]]. Action = [[-0.06966759  0.06773328  0.          0.41071582]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 3806 is [True, False, False, False, False, True]
Current timestep = 3807. State = [[-0.35220665  0.2554648 ]]. Action = [[ 0.03954371  0.07700474  0.         -0.78350395]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 3807 is [True, False, False, False, False, True]
Current timestep = 3808. State = [[-0.35528392  0.25580037]]. Action = [[-0.08263572 -0.04524341  0.          0.02255273]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 3808 is [True, False, False, False, False, True]
Current timestep = 3809. State = [[-0.3622498   0.25967234]]. Action = [[-0.07592352  0.09672862  0.          0.29089665]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 3809 is [True, False, False, False, False, True]
Current timestep = 3810. State = [[-0.36579338  0.262826  ]]. Action = [[0.00476424 0.00478264 0.         0.958987  ]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 3810 is [True, False, False, False, False, True]
Current timestep = 3811. State = [[-0.3680149  0.2619924]]. Action = [[-0.01978293 -0.03091804  0.         -0.78690773]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 3811 is [True, False, False, False, False, True]
Current timestep = 3812. State = [[-0.3715597   0.26260978]]. Action = [[-0.03711137  0.01690093  0.         -0.11822969]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 3812 is [True, False, False, False, False, True]
State prediction error at timestep 3812 is 0.012
Human Feedback received at timestep 3812 of None
Current timestep = 3813. State = [[-0.36980787  0.2599592 ]]. Action = [[ 0.07841089 -0.07298554  0.         -0.1875071 ]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 3813 is [True, False, False, False, False, True]
State prediction error at timestep 3813 is 0.012
Human Feedback received at timestep 3813 of None
Current timestep = 3814. State = [[-0.36891797  0.25526226]]. Action = [[-0.019435   -0.06024227  0.          0.5858443 ]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 3814 is [True, False, False, False, False, True]
Current timestep = 3815. State = [[-0.36511946  0.25410548]]. Action = [[ 0.08797418  0.01322623  0.         -0.5752434 ]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 3815 is [True, False, False, False, False, True]
State prediction error at timestep 3815 is 0.012
Human Feedback received at timestep 3815 of None
Current timestep = 3816. State = [[-0.36471534  0.25084153]]. Action = [[-0.05372717 -0.07286932  0.         -0.77150005]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 3816 is [True, False, False, False, False, True]
State prediction error at timestep 3816 is 0.012
Human Feedback received at timestep 3816 of None
Current timestep = 3817. State = [[-0.365963    0.25314727]]. Action = [[ 0.00436531  0.09738044  0.         -0.87173355]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 3817 is [True, False, False, False, False, True]
Current timestep = 3818. State = [[-0.37006113  0.25992844]]. Action = [[-0.07892545  0.09209772  0.         -0.26341307]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 3818 is [True, False, False, False, False, True]
Current timestep = 3819. State = [[-0.36823097  0.26708654]]. Action = [[ 0.09767958  0.09970882  0.         -0.0358507 ]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 3819 is [True, False, False, False, False, True]
Current timestep = 3820. State = [[-0.36933702  0.26801786]]. Action = [[-0.07792839 -0.04758628  0.         -0.27747303]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 3820 is [True, False, False, False, False, True]
Current timestep = 3821. State = [[-0.37188652  0.26452366]]. Action = [[ 0.00821285 -0.04827775  0.          0.2080828 ]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 3821 is [True, False, False, False, False, True]
Current timestep = 3822. State = [[-0.3694054   0.25824168]]. Action = [[ 0.06009651 -0.09741839  0.         -0.03481346]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 3822 is [True, False, False, False, False, True]
Current timestep = 3823. State = [[-0.3667831  0.2563284]]. Action = [[ 0.02030779  0.02725209  0.         -0.5217751 ]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 3823 is [True, False, False, False, False, True]
Current timestep = 3824. State = [[-0.3622074   0.25257957]]. Action = [[ 0.07663362 -0.07467289  0.          0.719236  ]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 3824 is [True, False, False, False, False, True]
Current timestep = 3825. State = [[-0.3609247   0.24647748]]. Action = [[-0.0335824  -0.07091892  0.          0.514451  ]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 3825 is [True, False, False, False, False, True]
State prediction error at timestep 3825 is 0.012
Human Feedback received at timestep 3825 of None
Current timestep = 3826. State = [[-0.36440206  0.24507025]]. Action = [[-0.0675682   0.01863854  0.         -0.5671832 ]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 3826 is [True, False, False, False, False, True]
State prediction error at timestep 3826 is 0.012
Human Feedback received at timestep 3826 of None
Current timestep = 3827. State = [[-0.36842158  0.24417366]]. Action = [[-0.04558286 -0.02146161  0.          0.95364296]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 3827 is [True, False, False, False, False, True]
Current timestep = 3828. State = [[-0.36796564  0.23931964]]. Action = [[ 0.03629839 -0.07844565  0.         -0.45625567]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 3828 is [True, False, False, False, False, True]
Current timestep = 3829. State = [[-0.366748    0.23629816]]. Action = [[ 0.        0.        0.       -0.812633]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 3829 is [True, False, False, False, False, True]
Current timestep = 3830. State = [[-0.37089035  0.2385338 ]]. Action = [[-0.08204098  0.06605273  0.          0.13776827]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 3830 is [True, False, False, False, False, True]
State prediction error at timestep 3830 is 0.012
Human Feedback received at timestep 3830 of None
Current timestep = 3831. State = [[-0.37606174  0.23628324]]. Action = [[-0.04364154 -0.07316907  0.         -0.8907489 ]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 3831 is [True, False, False, False, False, True]
Current timestep = 3832. State = [[-0.37817758  0.23386036]]. Action = [[ 0.          0.          0.         -0.13585293]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 3832 is [True, False, False, False, False, True]
State prediction error at timestep 3832 is 0.012
Human Feedback received at timestep 3832 of None
Current timestep = 3833. State = [[-0.37814906  0.2342132 ]]. Action = [[0.02005033 0.02745409 0.         0.61518717]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 3833 is [True, False, False, False, False, True]
Current timestep = 3834. State = [[-0.3777243   0.23624493]]. Action = [[0.01637243 0.04994244 0.         0.9914992 ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 3834 is [True, False, False, False, False, True]
Current timestep = 3835. State = [[-0.37471405  0.23863177]]. Action = [[0.06994704 0.04676855 0.         0.895746  ]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 3835 is [True, False, False, False, False, True]
Current timestep = 3836. State = [[-0.36899486  0.24134389]]. Action = [[0.08743378 0.05849116 0.         0.05737174]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 3836 is [True, False, False, False, False, True]
Current timestep = 3837. State = [[-0.36757085  0.23833968]]. Action = [[-0.02850753 -0.08334009  0.         -0.6466423 ]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 3837 is [True, False, False, False, False, True]
Current timestep = 3838. State = [[-0.36663982  0.23503149]]. Action = [[ 0.03740507 -0.00791384  0.          0.20857394]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 3838 is [True, False, False, False, False, True]
Current timestep = 3839. State = [[-0.36718804  0.23150782]]. Action = [[-0.03105428 -0.05172053  0.         -0.22395808]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 3839 is [True, False, False, False, False, True]
Current timestep = 3840. State = [[-0.37178445  0.23201057]]. Action = [[-0.07586026  0.0441597   0.          0.21188664]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 3840 is [True, False, False, False, False, True]
Current timestep = 3841. State = [[-0.37245122  0.23279643]]. Action = [[ 0.03884947 -0.00396968  0.         -0.30162823]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 3841 is [True, False, False, False, False, True]
Current timestep = 3842. State = [[-0.3737108   0.23175156]]. Action = [[-0.04145065 -0.01407713  0.         -0.00848591]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 3842 is [True, False, False, False, False, True]
Current timestep = 3843. State = [[-0.3720358  0.2300885]]. Action = [[ 0.05997217 -0.02166011  0.         -0.44425398]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 3843 is [True, False, False, False, False, True]
Current timestep = 3844. State = [[-0.3716494  0.2322129]]. Action = [[-0.02457199  0.0663598   0.          0.19028318]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 3844 is [True, False, False, False, False, True]
State prediction error at timestep 3844 is 0.012
Human Feedback received at timestep 3844 of None
Current timestep = 3845. State = [[-0.36840144  0.23620299]]. Action = [[ 0.08392822  0.05485975  0.         -0.04443896]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 3845 is [True, False, False, False, False, True]
State prediction error at timestep 3845 is 0.012
Human Feedback received at timestep 3845 of None
Current timestep = 3846. State = [[-0.3658359   0.23848112]]. Action = [[0.00433011 0.0257381  0.         0.6972983 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 3846 is [True, False, False, False, False, True]
State prediction error at timestep 3846 is 0.012
Human Feedback received at timestep 3846 of None
Current timestep = 3847. State = [[-0.36489347  0.24019398]]. Action = [[0.01124634 0.02151611 0.         0.729776  ]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 3847 is [True, False, False, False, False, True]
Current timestep = 3848. State = [[-0.3639706  0.245559 ]]. Action = [[0.00963913 0.09534913 0.         0.4023466 ]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 3848 is [True, False, False, False, False, True]
Current timestep = 3849. State = [[-0.367916    0.24776404]]. Action = [[-0.08825184 -0.02406733  0.         -0.40924633]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 3849 is [True, False, False, False, False, True]
Current timestep = 3850. State = [[-0.37117937  0.24905095]]. Action = [[-0.0065389   0.01830952  0.         -0.7067475 ]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 3850 is [True, False, False, False, False, True]
State prediction error at timestep 3850 is 0.012
Human Feedback received at timestep 3850 of None
Current timestep = 3851. State = [[-0.3698031  0.2496578]]. Action = [[ 0.04410832 -0.01173422  0.          0.24720573]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 3851 is [True, False, False, False, False, True]
Current timestep = 3852. State = [[-0.37164816  0.24623565]]. Action = [[-0.06130675 -0.08262233  0.         -0.2447626 ]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 3852 is [True, False, False, False, False, True]
Current timestep = 3853. State = [[-0.37347057  0.24491863]]. Action = [[ 0.         0.         0.        -0.8660712]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 3853 is [True, False, False, False, False, True]
Current timestep = 3854. State = [[-0.37588865  0.24866855]]. Action = [[-0.040321    0.06685641  0.          0.9192945 ]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 3854 is [True, False, False, False, False, True]
Current timestep = 3855. State = [[-0.37625626  0.2520091 ]]. Action = [[ 0.02870119  0.0229216   0.         -0.51767516]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 3855 is [True, False, False, False, False, True]
Current timestep = 3856. State = [[-0.37594602  0.25293782]]. Action = [[ 0.          0.          0.         -0.84533083]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 3856 is [True, False, False, False, False, True]
Current timestep = 3857. State = [[-0.37623277  0.25325626]]. Action = [[0.         0.         0.         0.17969704]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 3857 is [True, False, False, False, False, True]
State prediction error at timestep 3857 is 0.012
Human Feedback received at timestep 3857 of None
Current timestep = 3858. State = [[-0.37461698  0.25817433]]. Action = [[ 0.04058867  0.09990823  0.         -0.25036395]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 3858 is [True, False, False, False, False, True]
Current timestep = 3859. State = [[-0.37022865  0.25683138]]. Action = [[ 0.0657336  -0.08422371  0.          0.90402174]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 3859 is [True, False, False, False, False, True]
Current timestep = 3860. State = [[-0.36417833  0.25761232]]. Action = [[0.07596702 0.06723251 0.         0.7613988 ]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 3860 is [True, False, False, False, False, True]
Current timestep = 3861. State = [[-0.3567599   0.25905055]]. Action = [[0.08769903 0.00199511 0.         0.5229316 ]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 3861 is [True, False, False, False, False, True]
State prediction error at timestep 3861 is 0.012
Human Feedback received at timestep 3861 of None
Current timestep = 3862. State = [[-0.35519436  0.26033786]]. Action = [[-0.04554353  0.02601474  0.         -0.74969906]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 3862 is [True, False, False, False, False, True]
Current timestep = 3863. State = [[-0.35554755  0.26544744]]. Action = [[-0.00236066  0.08106267  0.         -0.16699362]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 3863 is [True, False, False, False, False, True]
Current timestep = 3864. State = [[-0.3573276   0.26955676]]. Action = [[-0.04564058  0.02559135  0.          0.8033011 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 3864 is [True, False, False, False, False, True]
Current timestep = 3865. State = [[-0.36164364  0.2737958 ]]. Action = [[-0.06597498  0.0483724   0.          0.02708709]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 3865 is [True, False, False, False, False, True]
State prediction error at timestep 3865 is 0.012
Human Feedback received at timestep 3865 of None
Current timestep = 3866. State = [[-0.36452922  0.28004813]]. Action = [[-0.0127931   0.07439073  0.         -0.5576296 ]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 3866 is [True, False, False, False, False, True]
State prediction error at timestep 3866 is 0.012
Human Feedback received at timestep 3866 of None
Current timestep = 3867. State = [[-0.36751068  0.28563285]]. Action = [[-0.03766498  0.04569639  0.          0.85775506]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 3867 is [True, False, False, False, False, True]
State prediction error at timestep 3867 is 0.012
Human Feedback received at timestep 3867 of None
Current timestep = 3868. State = [[-0.37030667  0.2911938 ]]. Action = [[-0.01559345  0.05723207  0.          0.15496457]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 3868 is [True, False, False, False, False, True]
Current timestep = 3869. State = [[-0.3687605   0.29291308]]. Action = [[ 0.05960879 -0.0270903   0.          0.81703687]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 3869 is [True, False, False, False, False, True]
State prediction error at timestep 3869 is 0.012
Human Feedback received at timestep 3869 of None
Current timestep = 3870. State = [[-0.3682165  0.2939535]]. Action = [[-0.01328073  0.00593521  0.          0.43240833]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 3870 is [True, False, False, False, False, True]
Current timestep = 3871. State = [[-0.37207803  0.2914244 ]]. Action = [[-0.06687313 -0.09463757  0.          0.48265016]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 3871 is [True, False, False, False, False, True]
Current timestep = 3872. State = [[-0.37433708  0.29073107]]. Action = [[0.         0.         0.         0.99866223]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 3872 is [True, False, False, False, False, True]
Current timestep = 3873. State = [[-0.37472215  0.29191393]]. Action = [[0.         0.         0.         0.84664655]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 3873 is [True, False, False, False, False, True]
Current timestep = 3874. State = [[-0.3760467  0.2925256]]. Action = [[-0.02321353 -0.00752034  0.         -0.29310572]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 3874 is [True, False, False, False, False, True]
Current timestep = 3875. State = [[-0.3774277   0.29247102]]. Action = [[-0.01105596 -0.01354788  0.          0.405643  ]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 3875 is [True, False, False, False, False, True]
Current timestep = 3876. State = [[-0.3779223   0.29265803]]. Action = [[ 0.         0.         0.        -0.5391452]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 3876 is [True, False, False, False, False, True]
Current timestep = 3877. State = [[-0.37806565  0.29294828]]. Action = [[ 0.          0.          0.         -0.98053265]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 3877 is [True, False, False, False, False, True]
Current timestep = 3878. State = [[-0.37830815  0.2890252 ]]. Action = [[-0.00409511 -0.08637264  0.          0.8755866 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 3878 is [True, False, False, False, False, True]
Current timestep = 3879. State = [[-0.378336    0.28683951]]. Action = [[0.         0.         0.         0.80197906]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 3879 is [True, False, False, False, False, True]
Current timestep = 3880. State = [[-0.37520778  0.28164995]]. Action = [[ 0.05899423 -0.09994192  0.          0.46974444]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 3880 is [True, False, False, False, False, True]
State prediction error at timestep 3880 is 0.012
Human Feedback received at timestep 3880 of None
Current timestep = 3881. State = [[-0.37120095  0.27434665]]. Action = [[ 0.03213539 -0.08339778  0.         -0.9004546 ]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 3881 is [True, False, False, False, False, True]
Current timestep = 3882. State = [[-0.364614    0.27059427]]. Action = [[ 0.09219154 -0.00617526  0.          0.25034928]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 3882 is [True, False, False, False, False, True]
Current timestep = 3883. State = [[-0.3580887   0.27000454]]. Action = [[0.05300092 0.02935865 0.         0.08334446]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 3883 is [True, False, False, False, False, True]
Current timestep = 3884. State = [[-0.3597271   0.26983887]]. Action = [[-0.09065145  0.01050059  0.          0.6476152 ]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 3884 is [True, False, False, False, False, True]
Current timestep = 3885. State = [[-0.36059594  0.27082714]]. Action = [[0.02111342 0.0362753  0.         0.06411147]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 3885 is [True, False, False, False, False, True]
Current timestep = 3886. State = [[-0.35571682  0.2686015 ]]. Action = [[ 0.07978319 -0.03684055  0.         -0.4848652 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 3886 is [True, False, False, False, False, True]
Current timestep = 3887. State = [[-0.34856385  0.2685431 ]]. Action = [[0.08318054 0.05393098 0.         0.9838567 ]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 3887 is [True, False, False, False, False, True]
Current timestep = 3888. State = [[-0.34445018  0.26407728]]. Action = [[ 0.00877433 -0.09489756  0.         -0.11399174]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 3888 is [True, False, False, False, False, True]
Current timestep = 3889. State = [[-0.33945477  0.26183164]]. Action = [[0.07658028 0.03813022 0.         0.23451662]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 3889 is [True, False, False, False, False, True]
Current timestep = 3890. State = [[-0.33675444  0.2574136 ]]. Action = [[-0.01654878 -0.08614111  0.         -0.15969485]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 3890 is [True, False, False, False, False, True]
Current timestep = 3891. State = [[-0.33134657  0.2524178 ]]. Action = [[ 0.09376846 -0.0285855   0.          0.5963607 ]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 3891 is [True, False, False, False, False, True]
Current timestep = 3892. State = [[-0.32650417  0.24699815]]. Action = [[ 0.014854   -0.06238005  0.         -0.11510193]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 3892 is [True, False, False, False, False, True]
State prediction error at timestep 3892 is 0.012
Human Feedback received at timestep 3892 of None
Current timestep = 3893. State = [[-0.32695583  0.2396517 ]]. Action = [[-0.05467476 -0.09563537  0.         -0.6953756 ]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 3893 is [True, False, False, False, False, True]
Current timestep = 3894. State = [[-0.33127427  0.23479669]]. Action = [[-0.0865216  -0.03422175  0.         -0.95813775]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 3894 is [True, False, False, False, False, True]
Current timestep = 3895. State = [[-0.33545896  0.23756777]]. Action = [[-0.04276405  0.09320956  0.          0.6353345 ]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 3895 is [True, False, False, False, False, True]
State prediction error at timestep 3895 is 0.012
Human Feedback received at timestep 3895 of None
Current timestep = 3896. State = [[-0.33820632  0.24255772]]. Action = [[-0.02057917  0.06710311  0.         -0.86753154]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 3896 is [True, False, False, False, False, True]
Current timestep = 3897. State = [[-0.33519372  0.24297701]]. Action = [[ 0.08908286 -0.01277566  0.         -0.4318831 ]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 3897 is [True, False, False, False, False, True]
Current timestep = 3898. State = [[-0.33249366  0.24188678]]. Action = [[ 0.01287315  0.00574744  0.         -0.9648341 ]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 3898 is [True, False, False, False, False, True]
Current timestep = 3899. State = [[-0.3289317   0.24147448]]. Action = [[0.06716218 0.00710589 0.         0.94018614]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 3899 is [True, False, False, False, False, True]
Current timestep = 3900. State = [[-0.32551694  0.2440151 ]]. Action = [[ 0.03148564  0.06722829  0.         -0.18890446]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 3900 is [True, False, False, False, False, True]
Current timestep = 3901. State = [[-0.326938   0.2437986]]. Action = [[-0.05159477 -0.0353824   0.         -0.3491099 ]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 3901 is [True, False, False, False, False, True]
Current timestep = 3902. State = [[-0.33164755  0.24152686]]. Action = [[-0.06587158 -0.03203013  0.         -0.26039636]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 3902 is [True, False, False, False, False, True]
State prediction error at timestep 3902 is 0.012
Human Feedback received at timestep 3902 of None
Current timestep = 3903. State = [[-0.33751482  0.2400553 ]]. Action = [[-0.07442538 -0.02211707  0.         -0.10294437]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 3903 is [True, False, False, False, False, True]
Current timestep = 3904. State = [[-0.34374225  0.24389033]]. Action = [[-0.0654085   0.08049577  0.          0.32955432]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 3904 is [True, False, False, False, False, True]
State prediction error at timestep 3904 is 0.012
Human Feedback received at timestep 3904 of None
Current timestep = 3905. State = [[-0.35038483  0.24950626]]. Action = [[-0.06450219  0.0600054   0.          0.9528034 ]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 3905 is [True, False, False, False, False, True]
Current timestep = 3906. State = [[-0.35344493  0.24994677]]. Action = [[ 0.01104035 -0.0385143   0.          0.8857825 ]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 3906 is [True, False, False, False, False, True]
State prediction error at timestep 3906 is 0.012
Human Feedback received at timestep 3906 of None
Current timestep = 3907. State = [[-0.35826     0.24884416]]. Action = [[-0.07324992 -0.01547598  0.         -0.44306397]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 3907 is [True, False, False, False, False, True]
State prediction error at timestep 3907 is 0.012
Human Feedback received at timestep 3907 of None
Current timestep = 3908. State = [[-0.35974374  0.2515483 ]]. Action = [[0.04554426 0.05585065 0.         0.3889295 ]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 3908 is [True, False, False, False, False, True]
Current timestep = 3909. State = [[-0.3599189   0.25554025]]. Action = [[ 0.00152644  0.04759371  0.         -0.60315853]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 3909 is [True, False, False, False, False, True]
Current timestep = 3910. State = [[-0.3605041   0.25308698]]. Action = [[ 0.00676123 -0.08701403  0.          0.6525161 ]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 3910 is [True, False, False, False, False, True]
Current timestep = 3911. State = [[-0.36366528  0.2546266 ]]. Action = [[-0.05206222  0.0714874   0.         -0.60042226]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 3911 is [True, False, False, False, False, True]
Current timestep = 3912. State = [[-0.36952722  0.25877032]]. Action = [[-0.06410242  0.03497104  0.         -0.72620064]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 3912 is [True, False, False, False, False, True]
State prediction error at timestep 3912 is 0.012
Human Feedback received at timestep 3912 of None
Current timestep = 3913. State = [[-0.37275255  0.26051027]]. Action = [[ 0.          0.          0.         -0.64876634]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 3913 is [True, False, False, False, False, True]
Current timestep = 3914. State = [[-0.37397116  0.2610809 ]]. Action = [[0.         0.         0.         0.62084806]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 3914 is [True, False, False, False, False, True]
Current timestep = 3915. State = [[-0.37491164  0.26152128]]. Action = [[0.        0.        0.        0.5393996]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 3915 is [True, False, False, False, False, True]
Current timestep = 3916. State = [[-0.373433    0.25713742]]. Action = [[ 0.04096315 -0.09855421  0.         -0.06136447]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 3916 is [True, False, False, False, False, True]
Current timestep = 3917. State = [[-0.3722955   0.25468755]]. Action = [[0.         0.         0.         0.02171111]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 3917 is [True, False, False, False, False, True]
Current timestep = 3918. State = [[-0.3718541  0.2593102]]. Action = [[0.01089855 0.09989413 0.         0.1728096 ]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 3918 is [True, False, False, False, False, True]
Current timestep = 3919. State = [[-0.37178147  0.2617719 ]]. Action = [[ 0.        0.        0.       -0.832494]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 3919 is [True, False, False, False, False, True]
Current timestep = 3920. State = [[-0.37182167  0.2618557 ]]. Action = [[0.         0.         0.         0.20591784]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 3920 is [True, False, False, False, False, True]
Current timestep = 3921. State = [[-0.37308022  0.26326847]]. Action = [[-0.0243851   0.02790705  0.          0.3467878 ]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 3921 is [True, False, False, False, False, True]
State prediction error at timestep 3921 is 0.012
Human Feedback received at timestep 3921 of None
Current timestep = 3922. State = [[-0.37395266  0.2641822 ]]. Action = [[ 0.          0.          0.         -0.14697325]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 3922 is [True, False, False, False, False, True]
Current timestep = 3923. State = [[-0.37199455  0.26834962]]. Action = [[0.04442082 0.08609038 0.         0.34527564]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 3923 is [True, False, False, False, False, True]
Current timestep = 3924. State = [[-0.37139314  0.26846817]]. Action = [[-0.01434144 -0.04830332  0.         -0.5142006 ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 3924 is [True, False, False, False, False, True]
Current timestep = 3925. State = [[-0.37160504  0.26861995]]. Action = [[ 0.00427367  0.02461295  0.         -0.17563891]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 3925 is [True, False, False, False, False, True]
Current timestep = 3926. State = [[-0.3693146   0.26699263]]. Action = [[ 0.04396579 -0.04775655  0.         -0.71319914]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 3926 is [True, False, False, False, False, True]
Current timestep = 3927. State = [[-0.3706093   0.26634023]]. Action = [[-0.05710615  0.00976814  0.         -0.14392662]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 3927 is [True, False, False, False, False, True]
Current timestep = 3928. State = [[-0.37214664  0.26694092]]. Action = [[ 0.          0.          0.         -0.53905416]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 3928 is [True, False, False, False, False, True]
Current timestep = 3929. State = [[-0.37342715  0.2666209 ]]. Action = [[-0.02434658 -0.01308346  0.          0.9174478 ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 3929 is [True, False, False, False, False, True]
Current timestep = 3930. State = [[-0.3726009  0.2695242]]. Action = [[ 0.03336336  0.06456255  0.         -0.5452796 ]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 3930 is [True, False, False, False, False, True]
Current timestep = 3931. State = [[-0.3738103  0.2700828]]. Action = [[-0.0415983  -0.02677514  0.         -0.7371687 ]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 3931 is [True, False, False, False, False, True]
Current timestep = 3932. State = [[-0.3743351  0.2679779]]. Action = [[ 0.01495685 -0.0360663   0.          0.74460673]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 3932 is [True, False, False, False, False, True]
Current timestep = 3933. State = [[-0.37302393  0.2632947 ]]. Action = [[ 0.01665583 -0.07961824  0.         -0.9726789 ]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 3933 is [True, False, False, False, False, True]
Current timestep = 3934. State = [[-0.37221324  0.26111475]]. Action = [[ 0.          0.          0.         -0.50676006]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 3934 is [True, False, False, False, False, True]
Current timestep = 3935. State = [[-0.37166172  0.26218867]]. Action = [[0.0063115  0.02880841 0.         0.8363658 ]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 3935 is [True, False, False, False, False, True]
Current timestep = 3936. State = [[-0.37293905  0.26410946]]. Action = [[-0.03021364  0.0300382   0.         -0.79660034]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 3936 is [True, False, False, False, False, True]
State prediction error at timestep 3936 is 0.012
Human Feedback received at timestep 3936 of None
Current timestep = 3937. State = [[-0.3742326   0.26537284]]. Action = [[-0.00534555  0.01272181  0.          0.22475886]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 3937 is [True, False, False, False, False, True]
State prediction error at timestep 3937 is 0.012
Human Feedback received at timestep 3937 of None
Current timestep = 3938. State = [[-0.37541816  0.26744545]]. Action = [[-0.01432733  0.03868251  0.          0.2004534 ]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 3938 is [True, False, False, False, False, True]
State prediction error at timestep 3938 is 0.012
Human Feedback received at timestep 3938 of None
Current timestep = 3939. State = [[-0.3762575   0.26838452]]. Action = [[0.         0.         0.         0.67265916]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 3939 is [True, False, False, False, False, True]
Current timestep = 3940. State = [[-0.37612998  0.27114972]]. Action = [[ 0.01182561  0.05857319  0.         -0.49479514]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 3940 is [True, False, False, False, False, True]
State prediction error at timestep 3940 is 0.012
Human Feedback received at timestep 3940 of None
Current timestep = 3941. State = [[-0.37676173  0.26990137]]. Action = [[-0.01255476 -0.05970635  0.         -0.06006628]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 3941 is [True, False, False, False, False, True]
State prediction error at timestep 3941 is 0.012
Human Feedback received at timestep 3941 of None
Current timestep = 3942. State = [[-0.3763474   0.26997277]]. Action = [[0.0211065  0.03105382 0.         0.25592232]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 3942 is [True, False, False, False, False, True]
Current timestep = 3943. State = [[-0.37114537  0.2674654 ]]. Action = [[ 0.09396698 -0.06375255  0.         -0.89181143]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 3943 is [True, False, False, False, False, True]
Current timestep = 3944. State = [[-0.36787072  0.26265755]]. Action = [[-6.0579181e-04 -5.8955517e-02  0.0000000e+00  7.7317047e-01]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 3944 is [True, False, False, False, False, True]
State prediction error at timestep 3944 is 0.012
Human Feedback received at timestep 3944 of None
Current timestep = 3945. State = [[-0.3669751   0.26094368]]. Action = [[0.         0.         0.         0.09764242]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 3945 is [True, False, False, False, False, True]
State prediction error at timestep 3945 is 0.012
Human Feedback received at timestep 3945 of None
Current timestep = 3946. State = [[-0.3638639   0.26026326]]. Action = [[ 0.04757588 -0.00653245  0.         -0.5964527 ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 3946 is [True, False, False, False, False, True]
Current timestep = 3947. State = [[-0.36531568  0.26065388]]. Action = [[-0.07313116  0.01880096  0.         -0.06118679]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 3947 is [True, False, False, False, False, True]
Current timestep = 3948. State = [[-0.36182025  0.257857  ]]. Action = [[ 0.09986427 -0.06430033  0.         -0.55208284]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 3948 is [True, False, False, False, False, True]
Current timestep = 3949. State = [[-0.35350764  0.25045744]]. Action = [[ 0.08931056 -0.09909516  0.          0.23104846]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 3949 is [True, False, False, False, False, True]
Current timestep = 3950. State = [[-0.3451231   0.24748512]]. Action = [[0.08250498 0.0218505  0.         0.360224  ]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 3950 is [True, False, False, False, False, True]
State prediction error at timestep 3950 is 0.012
Human Feedback received at timestep 3950 of None
Current timestep = 3951. State = [[-0.3433249   0.24619384]]. Action = [[-0.04920183 -0.01187101  0.         -0.3266114 ]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 3951 is [True, False, False, False, False, True]
State prediction error at timestep 3951 is 0.012
Human Feedback received at timestep 3951 of None
Current timestep = 3952. State = [[-0.341321    0.24364994]]. Action = [[ 0.03704151 -0.02744936  0.         -0.48539567]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 3952 is [True, False, False, False, False, True]
Current timestep = 3953. State = [[-0.34148598  0.24451531]]. Action = [[-0.04821543  0.05423214  0.          0.08608079]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 3953 is [True, False, False, False, False, True]
State prediction error at timestep 3953 is 0.012
Human Feedback received at timestep 3953 of None
Current timestep = 3954. State = [[-0.34154713  0.24096878]]. Action = [[ 0.00784288 -0.0890172   0.         -0.51752144]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 3954 is [True, False, False, False, False, True]
State prediction error at timestep 3954 is 0.012
Human Feedback received at timestep 3954 of None
Current timestep = 3955. State = [[-0.3451113   0.23552959]]. Action = [[-0.09400618 -0.05594935  0.         -0.01654649]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 3955 is [True, False, False, False, False, True]
Current timestep = 3956. State = [[-0.3460158   0.23262696]]. Action = [[ 0.02683388 -0.0193918   0.         -0.26867282]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 3956 is [True, False, False, False, False, True]
State prediction error at timestep 3956 is 0.012
Human Feedback received at timestep 3956 of None
Current timestep = 3957. State = [[-0.3438743  0.2307811]]. Action = [[ 0.02457257 -0.00954718  0.          0.06097364]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 3957 is [True, False, False, False, False, True]
Current timestep = 3958. State = [[-0.3415311   0.23406999]]. Action = [[ 0.03281339  0.09703638  0.         -0.9349029 ]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 3958 is [True, False, False, False, False, True]
State prediction error at timestep 3958 is 0.012
Human Feedback received at timestep 3958 of None
Current timestep = 3959. State = [[-0.34058923  0.24001127]]. Action = [[ 0.00948115  0.09419157  0.         -0.7357979 ]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 3959 is [True, False, False, False, False, True]
Current timestep = 3960. State = [[-0.34513685  0.24528815]]. Action = [[-0.08359502  0.06721642  0.         -0.59172386]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 3960 is [True, False, False, False, False, True]
State prediction error at timestep 3960 is 0.012
Human Feedback received at timestep 3960 of None
Current timestep = 3961. State = [[-0.3484443  0.2500295]]. Action = [[ 0.0044686   0.05839657  0.         -0.38191593]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 3961 is [True, False, False, False, False, True]
Current timestep = 3962. State = [[-0.3494456   0.25377497]]. Action = [[ 0.00484433  0.04040488  0.         -0.39358526]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 3962 is [True, False, False, False, False, True]
State prediction error at timestep 3962 is 0.012
Human Feedback received at timestep 3962 of None
Current timestep = 3963. State = [[-0.35113025  0.2537343 ]]. Action = [[-0.01483835 -0.03494766  0.          0.57335544]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 3963 is [True, False, False, False, False, True]
Current timestep = 3964. State = [[-0.3474248   0.25048393]]. Action = [[ 0.09712089 -0.06231556  0.          0.08047199]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 3964 is [True, False, False, False, False, True]
Current timestep = 3965. State = [[-0.34424466  0.24833003]]. Action = [[ 0.00973865 -0.01655249  0.          0.59972966]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 3965 is [True, False, False, False, False, True]
Current timestep = 3966. State = [[-0.3401394  0.2475539]]. Action = [[ 0.06853028 -0.01297002  0.          0.3405198 ]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 3966 is [True, False, False, False, False, True]
State prediction error at timestep 3966 is 0.012
Human Feedback received at timestep 3966 of None
Current timestep = 3967. State = [[-0.33910245  0.24770492]]. Action = [[-0.03167263  0.00601349  0.         -0.05684412]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 3967 is [True, False, False, False, False, True]
Current timestep = 3968. State = [[-0.33628798  0.25026995]]. Action = [[0.06104878 0.04489201 0.         0.7829869 ]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 3968 is [True, False, False, False, False, True]
Current timestep = 3969. State = [[-0.33038425  0.25122625]]. Action = [[ 0.0683771  -0.00341262  0.          0.28449714]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 3969 is [True, False, False, False, False, True]
Current timestep = 3970. State = [[-0.32898006  0.2495668 ]]. Action = [[-0.03680062 -0.0343435   0.         -0.09260005]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 3970 is [True, False, False, False, False, True]
State prediction error at timestep 3970 is 0.012
Human Feedback received at timestep 3970 of None
Current timestep = 3971. State = [[-0.32939515  0.24730887]]. Action = [[-0.01264182 -0.03600959  0.         -0.5058286 ]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 3971 is [True, False, False, False, False, True]
Current timestep = 3972. State = [[-0.32693535  0.24548176]]. Action = [[ 0.03555068 -0.02189612  0.          0.5080583 ]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 3972 is [True, False, False, False, False, True]
Current timestep = 3973. State = [[-0.32131353  0.24371496]]. Action = [[ 0.06961004 -0.01871963  0.          0.5119858 ]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 3973 is [True, False, False, False, False, True]
Current timestep = 3974. State = [[-0.3205829   0.24055055]]. Action = [[-0.05457714 -0.04873325  0.          0.464998  ]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 3974 is [True, False, False, False, False, True]
State prediction error at timestep 3974 is 0.012
Human Feedback received at timestep 3974 of None
Current timestep = 3975. State = [[-0.31841204  0.24076323]]. Action = [[0.0531813  0.03864463 0.         0.9385178 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 3975 is [True, False, False, False, False, True]
Current timestep = 3976. State = [[-0.31804317  0.2440841 ]]. Action = [[-0.03919891  0.05604311  0.          0.6108053 ]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 3976 is [True, False, False, False, False, True]
Current timestep = 3977. State = [[-0.32209614  0.24981973]]. Action = [[-0.06744207  0.08472323  0.          0.934924  ]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 3977 is [True, False, False, False, False, True]
Current timestep = 3978. State = [[-0.32587323  0.25463426]]. Action = [[-0.02900223  0.04219344  0.         -0.50835985]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 3978 is [True, False, False, False, False, True]
Current timestep = 3979. State = [[-0.3273178  0.2550949]]. Action = [[ 0.00180818 -0.02688213  0.         -0.8003554 ]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 3979 is [True, False, False, False, False, True]
State prediction error at timestep 3979 is 0.012
Human Feedback received at timestep 3979 of None
Current timestep = 3980. State = [[-0.33085716  0.25077444]]. Action = [[-0.06404679 -0.09203794  0.         -0.42166257]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 3980 is [True, False, False, False, False, True]
Current timestep = 3981. State = [[-0.33395943  0.24491294]]. Action = [[-0.02024648 -0.08984043  0.         -0.35037196]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 3981 is [True, False, False, False, False, True]
Current timestep = 3982. State = [[-0.33296898  0.24514556]]. Action = [[0.04472705 0.0533744  0.         0.5241817 ]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 3982 is [True, False, False, False, False, True]
Current timestep = 3983. State = [[-0.33711293  0.24970427]]. Action = [[-0.09889301  0.062467    0.         -0.478549  ]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 3983 is [True, False, False, False, False, True]
Current timestep = 3984. State = [[-0.34327725  0.2546828 ]]. Action = [[-0.04808856  0.0544415   0.          0.12151408]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 3984 is [True, False, False, False, False, True]
Current timestep = 3985. State = [[-0.35070226  0.2576378 ]]. Action = [[-0.0906994   0.01418903  0.          0.6667118 ]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 3985 is [True, False, False, False, False, True]
Current timestep = 3986. State = [[-0.35921708  0.261523  ]]. Action = [[-0.08111722  0.05204623  0.          0.39475882]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 3986 is [True, False, False, False, False, True]
State prediction error at timestep 3986 is 0.012
Human Feedback received at timestep 3986 of None
Current timestep = 3987. State = [[-0.36046532  0.2672394 ]]. Action = [[ 0.07227393  0.0788727   0.         -0.2917912 ]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 3987 is [True, False, False, False, False, True]
Current timestep = 3988. State = [[-0.3620553   0.27119493]]. Action = [[-0.02989934  0.03216765  0.         -0.20504045]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 3988 is [True, False, False, False, False, True]
State prediction error at timestep 3988 is 0.012
Human Feedback received at timestep 3988 of None
Current timestep = 3989. State = [[-0.36869535  0.27166957]]. Action = [[-0.08238498 -0.02663379  0.         -0.80941516]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 3989 is [True, False, False, False, False, True]
State prediction error at timestep 3989 is 0.012
Human Feedback received at timestep 3989 of None
Current timestep = 3990. State = [[-0.3693117   0.27310345]]. Action = [[0.07344922 0.02715064 0.         0.01086068]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 3990 is [True, False, False, False, False, True]
Current timestep = 3991. State = [[-0.36544916  0.2765025 ]]. Action = [[ 0.06311005  0.04725707  0.         -0.05133587]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 3991 is [True, False, False, False, False, True]
Current timestep = 3992. State = [[-0.35995573  0.281029  ]]. Action = [[0.0856734  0.06358106 0.         0.90938663]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 3992 is [True, False, False, False, False, True]
Current timestep = 3993. State = [[-0.35480386  0.2830299 ]]. Action = [[0.05272105 0.00136147 0.         0.2658236 ]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 3993 is [True, False, False, False, False, True]
State prediction error at timestep 3993 is 0.012
Human Feedback received at timestep 3993 of None
Current timestep = 3994. State = [[-0.35125366  0.28156143]]. Action = [[ 0.02691445 -0.04434594  0.          0.14130592]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 3994 is [True, False, False, False, False, True]
State prediction error at timestep 3994 is 0.012
Human Feedback received at timestep 3994 of None
Current timestep = 3995. State = [[-0.35382098  0.27919   ]]. Action = [[-0.09012962 -0.04871475  0.         -0.7461171 ]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 3995 is [True, False, False, False, False, True]
Current timestep = 3996. State = [[-0.3549543  0.2785579]]. Action = [[ 0.01057275 -0.01404753  0.         -0.9008284 ]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 3996 is [True, False, False, False, False, True]
Current timestep = 3997. State = [[-0.35423815  0.27562463]]. Action = [[-0.00648974 -0.07160166  0.          0.41283178]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 3997 is [True, False, False, False, False, True]
State prediction error at timestep 3997 is 0.012
Human Feedback received at timestep 3997 of None
Current timestep = 3998. State = [[-0.35153538  0.27141872]]. Action = [[ 0.03590869 -0.06110567  0.         -0.1108197 ]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 3998 is [True, False, False, False, False, True]
Current timestep = 3999. State = [[-0.34431908  0.26658607]]. Action = [[ 0.09822448 -0.06376122  0.         -0.37731296]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 3999 is [True, False, False, False, False, True]
Current timestep = 4000. State = [[-0.33930933  0.26551846]]. Action = [[0.01123443 0.02913538 0.         0.5103495 ]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 4000 is [True, False, False, False, False, True]
State prediction error at timestep 4000 is 0.012
Human Feedback received at timestep 4000 of None
Current timestep = 4001. State = [[-0.34074113  0.26116452]]. Action = [[-0.07021108 -0.09951734  0.          0.14108467]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 4001 is [True, False, False, False, False, True]
Current timestep = 4002. State = [[-0.33793    0.2587088]]. Action = [[ 0.08208524  0.02525272  0.         -0.68716854]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 4002 is [True, False, False, False, False, True]
State prediction error at timestep 4002 is 0.012
Human Feedback received at timestep 4002 of None
Current timestep = 4003. State = [[-0.337217    0.25634217]]. Action = [[-0.05797068 -0.04593489  0.          0.8564211 ]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 4003 is [True, False, False, False, False, True]
Current timestep = 4004. State = [[-0.33772868  0.25425208]]. Action = [[ 0.0023319  -0.00549918  0.         -0.00415486]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 4004 is [True, False, False, False, False, True]
Current timestep = 4005. State = [[-0.3347171   0.25716686]]. Action = [[ 0.05297866  0.08786543  0.         -0.15170544]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 4005 is [True, False, False, False, False, True]
Current timestep = 4006. State = [[-0.329122    0.25543997]]. Action = [[ 0.07561796 -0.05512558  0.          0.29653096]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 4006 is [True, False, False, False, False, True]
Current timestep = 4007. State = [[-0.3287182   0.25688007]]. Action = [[-0.0486407   0.08577354  0.          0.61961365]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 4007 is [True, False, False, False, False, True]
Current timestep = 4008. State = [[-0.32628775  0.25750986]]. Action = [[ 0.07264007 -0.01833871  0.          0.5897747 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 4008 is [True, False, False, False, False, True]
Current timestep = 4009. State = [[-0.32424262  0.2529502 ]]. Action = [[-0.00957205 -0.07288788  0.         -0.32309854]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 4009 is [True, False, False, False, False, True]
Current timestep = 4010. State = [[-0.32369936  0.25210258]]. Action = [[0.00283794 0.03138567 0.         0.72998047]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 4010 is [True, False, False, False, False, True]
State prediction error at timestep 4010 is 0.012
Human Feedback received at timestep 4010 of None
Current timestep = 4011. State = [[-0.31912807  0.2519681 ]]. Action = [[ 0.08214065 -0.00673729  0.         -0.34160256]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 4011 is [True, False, False, False, False, True]
Current timestep = 4012. State = [[-0.31128615  0.25270367]]. Action = [[ 0.09697288  0.03836576  0.         -0.47013974]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 4012 is [True, False, False, False, False, True]
State prediction error at timestep 4012 is 0.012
Human Feedback received at timestep 4012 of None
Current timestep = 4013. State = [[-0.31142676  0.25107536]]. Action = [[-0.08830703 -0.04870147  0.          0.789016  ]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 4013 is [True, False, False, False, False, True]
Current timestep = 4014. State = [[-0.31194496  0.24591105]]. Action = [[ 0.02624082 -0.07256763  0.          0.23374867]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 4014 is [True, False, False, False, False, True]
Current timestep = 4015. State = [[-0.31412458  0.24707527]]. Action = [[-0.06389566  0.07883184  0.         -0.49982947]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 4015 is [True, False, False, False, False, True]
Current timestep = 4016. State = [[-0.3146281   0.24660668]]. Action = [[ 0.02817231 -0.04507514  0.         -0.95601535]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 4016 is [True, False, False, False, False, True]
Current timestep = 4017. State = [[-0.31770426  0.24143678]]. Action = [[-0.08021398 -0.08007786  0.          0.6570151 ]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 4017 is [True, False, False, False, False, True]
Current timestep = 4018. State = [[-0.3189943   0.23936577]]. Action = [[ 0.02178687  0.00621058  0.         -0.17028499]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 4018 is [True, False, False, False, False, True]
Current timestep = 4019. State = [[-0.31687245  0.23857133]]. Action = [[ 0.03377431 -0.00911597  0.         -0.26534057]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 4019 is [True, False, False, False, False, True]
Current timestep = 4020. State = [[-0.31759715  0.2338747 ]]. Action = [[-0.0380692  -0.08251147  0.          0.29289317]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 4020 is [True, False, False, False, False, True]
State prediction error at timestep 4020 is 0.012
Human Feedback received at timestep 4020 of None
Current timestep = 4021. State = [[-0.31384102  0.22730158]]. Action = [[ 0.0914503  -0.07613296  0.         -0.5348002 ]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 4021 is [True, False, False, False, False, True]
State prediction error at timestep 4021 is 0.012
Human Feedback received at timestep 4021 of None
Current timestep = 4022. State = [[-0.30938682  0.21913846]]. Action = [[ 0.02359439 -0.09884165  0.         -0.2141251 ]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 4022 is [True, False, False, False, False, True]
Current timestep = 4023. State = [[-0.31072325  0.21880132]]. Action = [[-0.05994392  0.07813718  0.          0.17330813]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 4023 is [True, False, False, False, False, True]
State prediction error at timestep 4023 is 0.012
Human Feedback received at timestep 4023 of None
Current timestep = 4024. State = [[-0.31092027  0.2223403 ]]. Action = [[ 0.02949045  0.05366484  0.         -0.12352264]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 4024 is [True, False, False, False, False, True]
Current timestep = 4025. State = [[-0.3117844   0.22532295]]. Action = [[-0.02699725  0.05222566  0.         -0.459122  ]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 4025 is [True, False, False, False, False, True]
Current timestep = 4026. State = [[-0.3131198   0.22499867]]. Action = [[-0.00388584 -0.02214107  0.         -0.6126565 ]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 4026 is [True, False, False, False, False, True]
Current timestep = 4027. State = [[-0.3091836   0.21962205]]. Action = [[ 0.08618762 -0.08380632  0.          0.8078613 ]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 4027 is [True, False, False, False, False, True]
Current timestep = 4028. State = [[-0.31069204  0.21589985]]. Action = [[-0.0854991  -0.01117631  0.          0.13004947]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 4028 is [True, False, False, False, False, True]
State prediction error at timestep 4028 is 0.012
Human Feedback received at timestep 4028 of None
Current timestep = 4029. State = [[-0.31131187  0.2118291 ]]. Action = [[ 0.031556   -0.06934749  0.          0.22504008]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 4029 is [True, False, False, False, False, True]
Current timestep = 4030. State = [[-0.31235963  0.21359284]]. Action = [[-0.03792931  0.08849669  0.          0.33980834]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 4030 is [True, False, False, False, False, True]
Current timestep = 4031. State = [[-0.3107136   0.21174176]]. Action = [[ 0.06033494 -0.07671556  0.         -0.06048948]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 4031 is [True, False, False, False, False, True]
Current timestep = 4032. State = [[-0.30394134  0.20771377]]. Action = [[ 0.09974598 -0.02109794  0.         -0.9034037 ]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 4032 is [True, False, False, False, False, True]
State prediction error at timestep 4032 is 0.012
Human Feedback received at timestep 4032 of None
Current timestep = 4033. State = [[-0.2983584  0.2101989]]. Action = [[0.0459929  0.09419238 0.         0.6525254 ]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 4033 is [True, False, False, False, False, True]
State prediction error at timestep 4033 is 0.012
Human Feedback received at timestep 4033 of None
Current timestep = 4034. State = [[-0.29983264  0.2081734 ]]. Action = [[-0.07846633 -0.08388089  0.         -0.8088068 ]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 4034 is [True, False, False, False, False, True]
Current timestep = 4035. State = [[-0.29981056  0.20865168]]. Action = [[0.05367204 0.0776894  0.         0.36146593]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 4035 is [True, False, False, False, False, True]
Current timestep = 4036. State = [[-0.29366797  0.21046323]]. Action = [[ 0.09686481  0.01751776  0.         -0.2391839 ]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 4036 is [True, False, False, False, False, True]
Current timestep = 4037. State = [[-0.29042652  0.2101276 ]]. Action = [[-0.00012108  0.00062063  0.         -0.03523296]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 4037 is [True, False, False, False, False, True]
Current timestep = 4038. State = [[-0.28702313  0.20511389]]. Action = [[ 0.05043381 -0.09356964  0.          0.2685219 ]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 4038 is [True, False, False, False, False, True]
State prediction error at timestep 4038 is 0.012
Human Feedback received at timestep 4038 of None
Current timestep = 4039. State = [[-0.28513154  0.20089701]]. Action = [[-0.01563321 -0.02588192  0.         -0.54497033]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 4039 is [True, False, False, False, False, True]
Current timestep = 4040. State = [[-0.28701377  0.20385712]]. Action = [[-0.0517647   0.08093282  0.          0.7809799 ]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 4040 is [True, False, False, False, False, True]
Current timestep = 4041. State = [[-0.29072896  0.20738988]]. Action = [[-0.05426592  0.02358536  0.          0.757324  ]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 4041 is [True, False, False, False, False, True]
Current timestep = 4042. State = [[-0.29468787  0.2112335 ]]. Action = [[-0.04760791  0.05325819  0.         -0.04133618]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 4042 is [True, False, False, False, False, True]
Current timestep = 4043. State = [[-0.29703435  0.21690582]]. Action = [[-0.00621133  0.07305356  0.         -0.85658675]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 4043 is [True, False, False, False, False, True]
Current timestep = 4044. State = [[-0.30178377  0.21842009]]. Action = [[-0.07548647 -0.02936415  0.          0.40317082]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 4044 is [True, False, False, False, False, True]
Current timestep = 4045. State = [[-0.3039279   0.21640153]]. Action = [[ 0.01699617 -0.04825345  0.          0.9126959 ]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 4045 is [True, False, False, False, False, True]
Current timestep = 4046. State = [[-0.30094892  0.21425131]]. Action = [[ 0.06706124 -0.02700016  0.          0.55105793]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 4046 is [True, False, False, False, False, True]
Current timestep = 4047. State = [[-0.2954475   0.21333818]]. Action = [[ 8.028763e-02 -6.091669e-04  0.000000e+00 -9.809922e-01]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 4047 is [True, False, False, False, False, True]
Current timestep = 4048. State = [[-0.29650545  0.21508265]]. Action = [[-0.06855355  0.03950457  0.         -0.9803052 ]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 4048 is [True, False, False, False, False, True]
Current timestep = 4049. State = [[-0.29551035  0.21319157]]. Action = [[ 0.05857142 -0.06539884  0.         -0.57536685]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 4049 is [True, False, False, False, False, True]
Current timestep = 4050. State = [[-0.29457527  0.20778528]]. Action = [[-0.02142147 -0.07420645  0.         -0.20531005]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 4050 is [True, False, False, False, False, True]
Current timestep = 4051. State = [[-0.29831505  0.20984198]]. Action = [[-0.07371338  0.08568769  0.          0.7816031 ]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 4051 is [True, False, False, False, False, True]
Current timestep = 4052. State = [[-0.29706743  0.20910339]]. Action = [[ 0.07020646 -0.06436595  0.          0.5942702 ]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 4052 is [True, False, False, False, False, True]
Current timestep = 4053. State = [[-0.29167995  0.2087341 ]]. Action = [[ 0.06680729  0.03956359  0.         -0.55738926]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 4053 is [True, False, False, False, False, True]
Current timestep = 4054. State = [[-0.28888312  0.20957074]]. Action = [[ 0.01077865  0.01317407  0.         -0.51202255]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 4054 is [True, False, False, False, False, True]
Current timestep = 4055. State = [[-0.2918711   0.21309228]]. Action = [[-0.07378868  0.07113569  0.          0.3950925 ]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 4055 is [True, False, False, False, False, True]
Current timestep = 4056. State = [[-0.29405248  0.21679224]]. Action = [[0.0020449  0.03348482 0.         0.19128728]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 4056 is [True, False, False, False, False, True]
Current timestep = 4057. State = [[-0.2962651  0.2194209]]. Action = [[-0.03532612  0.02894429  0.         -0.8422556 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 4057 is [True, False, False, False, False, True]
Current timestep = 4058. State = [[-0.3027886   0.22218935]]. Action = [[-0.09946068  0.02605847  0.          0.5252366 ]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 4058 is [True, False, False, False, False, True]
Current timestep = 4059. State = [[-0.305964    0.22060399]]. Action = [[ 0.00924124 -0.06916061  0.          0.81259716]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 4059 is [True, False, False, False, False, True]
Current timestep = 4060. State = [[-0.30764234  0.2239022 ]]. Action = [[-0.02020509  0.09154176  0.          0.737129  ]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 4060 is [True, False, False, False, False, True]
Current timestep = 4061. State = [[-0.31212106  0.22459325]]. Action = [[-0.05856276 -0.05414684  0.          0.06671107]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 4061 is [True, False, False, False, False, True]
Current timestep = 4062. State = [[-0.31588918  0.22096683]]. Action = [[-0.02285165 -0.06626347  0.          0.6542344 ]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 4062 is [True, False, False, False, False, True]
State prediction error at timestep 4062 is 0.012
Human Feedback received at timestep 4062 of None
Current timestep = 4063. State = [[-0.3220485   0.21865347]]. Action = [[-0.09235211 -0.02571262  0.         -0.58766764]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 4063 is [True, False, False, False, False, True]
State prediction error at timestep 4063 is 0.012
Human Feedback received at timestep 4063 of None
Current timestep = 4064. State = [[-0.3296248   0.21441326]]. Action = [[-0.07916721 -0.08797645  0.          0.29137063]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 4064 is [True, False, False, False, False, True]
Current timestep = 4065. State = [[-0.3333905  0.2103207]]. Action = [[-0.00570939 -0.04271767  0.          0.46117818]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 4065 is [True, False, False, False, False, True]
Current timestep = 4066. State = [[-0.33215758  0.21166967]]. Action = [[0.05950765 0.06619256 0.         0.35867977]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 4066 is [True, False, False, False, False, True]
Current timestep = 4067. State = [[-0.32983062  0.21066973]]. Action = [[ 0.03798615 -0.03439467  0.         -0.73920333]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 4067 is [True, False, False, False, False, True]
Current timestep = 4068. State = [[-0.3320569   0.20952287]]. Action = [[-0.05240173  0.01361714  0.          0.70233274]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 4068 is [True, False, False, False, False, True]
Current timestep = 4069. State = [[-0.33350387  0.20991191]]. Action = [[ 0.01811129  0.01695131  0.         -0.48348325]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 4069 is [True, False, False, False, False, True]
State prediction error at timestep 4069 is 0.012
Human Feedback received at timestep 4069 of None
Current timestep = 4070. State = [[-0.333715    0.21267748]]. Action = [[0.00592055 0.06608628 0.         0.44214737]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 4070 is [True, False, False, False, False, True]
Current timestep = 4071. State = [[-0.33699116  0.21515597]]. Action = [[-0.04919595  0.02831178  0.         -0.4100176 ]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 4071 is [True, False, False, False, False, True]
State prediction error at timestep 4071 is 0.012
Human Feedback received at timestep 4071 of None
Current timestep = 4072. State = [[-0.33615926  0.21351694]]. Action = [[ 0.06428265 -0.04163454  0.          0.36988795]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 4072 is [True, False, False, False, False, True]
State prediction error at timestep 4072 is 0.012
Human Feedback received at timestep 4072 of None
Current timestep = 4073. State = [[-0.33057418  0.20746161]]. Action = [[ 0.08458235 -0.08580286  0.         -0.20976269]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 4073 is [True, False, False, False, False, True]
State prediction error at timestep 4073 is 0.012
Human Feedback received at timestep 4073 of None
Current timestep = 4074. State = [[-0.33030927  0.20789972]]. Action = [[-0.04830607  0.07982894  0.          0.32000196]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 4074 is [True, False, False, False, False, True]
Current timestep = 4075. State = [[-0.33589724  0.20769049]]. Action = [[-0.08606058 -0.04828889  0.         -0.17818987]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 4075 is [True, False, False, False, False, True]
Current timestep = 4076. State = [[-0.3405648   0.20232907]]. Action = [[-0.03984868 -0.09381076  0.         -0.04039162]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 4076 is [True, False, False, False, False, True]
State prediction error at timestep 4076 is 0.012
Human Feedback received at timestep 4076 of None
Current timestep = 4077. State = [[-0.34603697  0.19796003]]. Action = [[-0.0808241  -0.04246011  0.         -0.20961744]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 4077 is [True, False, False, False, False, True]
State prediction error at timestep 4077 is 0.012
Human Feedback received at timestep 4077 of None
Current timestep = 4078. State = [[-0.35060787  0.19911824]]. Action = [[-0.03052527  0.04901355  0.         -0.19669557]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 4078 is [True, False, False, False, False, True]
State prediction error at timestep 4078 is 0.012
Human Feedback received at timestep 4078 of None
Current timestep = 4079. State = [[-0.3555097  0.1982719]]. Action = [[-0.05757979 -0.04036558  0.          0.9476322 ]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 4079 is [True, False, False, False, False, True]
State prediction error at timestep 4079 is 0.012
Human Feedback received at timestep 4079 of None
Current timestep = 4080. State = [[-0.35744482  0.1930074 ]]. Action = [[ 0.01573719 -0.08086877  0.         -0.79163253]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 4080 is [True, False, False, False, False, True]
Current timestep = 4081. State = [[-0.35344836  0.19340035]]. Action = [[ 0.0980682   0.07971575  0.         -0.11052197]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 4081 is [True, False, False, False, False, True]
Current timestep = 4082. State = [[-0.35068202  0.19179949]]. Action = [[ 0.00763875 -0.05307201  0.         -0.20100683]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 4082 is [True, False, False, False, False, True]
Current timestep = 4083. State = [[-0.3495142   0.19240284]]. Action = [[0.02448659 0.06311954 0.         0.21254647]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 4083 is [True, False, False, False, False, True]
Current timestep = 4084. State = [[-0.34619153  0.19326079]]. Action = [[0.06250288 0.00832923 0.         0.2587825 ]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 4084 is [True, False, False, False, False, True]
Current timestep = 4085. State = [[-0.33996215  0.18970351]]. Action = [[ 0.08966964 -0.05229498  0.         -0.4490251 ]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 4085 is [True, False, False, False, False, True]
Current timestep = 4086. State = [[-0.33794358  0.18572615]]. Action = [[-0.02455575 -0.02956954  0.          0.76679134]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 4086 is [True, False, False, False, False, True]
Current timestep = 4087. State = [[-0.3410625   0.18754782]]. Action = [[-0.06496201  0.06577509  0.          0.5875726 ]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 4087 is [True, False, False, False, False, True]
Current timestep = 4088. State = [[-0.34646094  0.1902786 ]]. Action = [[-0.07455006  0.02089942  0.         -0.27412212]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 4088 is [True, False, False, False, False, True]
Current timestep = 4089. State = [[-0.35282487  0.18954277]]. Action = [[-0.08055778 -0.03531716  0.          0.24182224]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 4089 is [True, False, False, False, False, True]
Current timestep = 4090. State = [[-0.3512354   0.18847397]]. Action = [[ 0.09249302 -0.00335493  0.          0.90632856]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 4090 is [True, False, False, False, False, True]
State prediction error at timestep 4090 is 0.012
Human Feedback received at timestep 4090 of None
Current timestep = 4091. State = [[-0.35297891  0.19026026]]. Action = [[-0.08300987  0.040434    0.          0.14637697]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 4091 is [True, False, False, False, False, True]
Current timestep = 4092. State = [[-0.3587853   0.18979688]]. Action = [[-0.06450163 -0.04484349  0.         -0.15720159]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 4092 is [True, False, False, False, False, True]
Current timestep = 4093. State = [[-0.35972476  0.18546158]]. Action = [[ 0.02825647 -0.07689159  0.         -0.50285   ]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 4093 is [True, False, False, False, False, True]
Current timestep = 4094. State = [[-0.35483342  0.18422171]]. Action = [[0.09178103 0.02408712 0.         0.27692842]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 4094 is [True, False, False, False, False, True]
State prediction error at timestep 4094 is 0.012
Human Feedback received at timestep 4094 of None
Current timestep = 4095. State = [[-0.34751195  0.18779026]]. Action = [[ 0.09918629  0.08018286  0.         -0.64188886]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 4095 is [True, False, False, False, False, True]
Current timestep = 4096. State = [[-0.34727097  0.18752319]]. Action = [[-0.0658615  -0.04512144  0.          0.5142007 ]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 4096 is [True, False, False, False, False, True]
Current timestep = 4097. State = [[-0.35141137  0.18812172]]. Action = [[-0.03880934  0.04430539  0.         -0.40771723]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 4097 is [True, False, False, False, False, True]
State prediction error at timestep 4097 is 0.012
Human Feedback received at timestep 4097 of None
Current timestep = 4098. State = [[-0.3537347   0.19310139]]. Action = [[-0.00220363  0.0872113   0.          0.03963268]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 4098 is [True, False, False, False, False, True]
State prediction error at timestep 4098 is 0.012
Human Feedback received at timestep 4098 of None
Current timestep = 4099. State = [[-0.3589982   0.19573778]]. Action = [[-0.08123098  0.00695972  0.         -0.05884814]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 4099 is [True, False, False, False, False, True]
State prediction error at timestep 4099 is 0.012
Human Feedback received at timestep 4099 of None
Current timestep = 4100. State = [[-0.36659396  0.20004703]]. Action = [[-0.0778785   0.07582422  0.         -0.4505328 ]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 4100 is [True, False, False, False, False, True]
State prediction error at timestep 4100 is 0.012
Human Feedback received at timestep 4100 of None
Current timestep = 4101. State = [[-0.37273967  0.20104155]]. Action = [[-0.04173271 -0.03444459  0.          0.4022671 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 4101 is [True, False, False, False, False, True]
State prediction error at timestep 4101 is 0.012
Human Feedback received at timestep 4101 of None
Current timestep = 4102. State = [[-0.37633634  0.19846982]]. Action = [[-0.01546536 -0.05036032  0.          0.5314362 ]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 4102 is [True, False, False, False, False, True]
State prediction error at timestep 4102 is 0.012
Human Feedback received at timestep 4102 of None
Current timestep = 4103. State = [[-0.37826547  0.19805367]]. Action = [[-0.00100198  0.00941612  0.          0.01751184]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 4103 is [True, False, False, False, False, True]
Current timestep = 4104. State = [[-0.3794168   0.20088987]]. Action = [[0.00554077 0.04811393 0.         0.77846277]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 4104 is [True, False, False, False, False, True]
Current timestep = 4105. State = [[-0.38053644  0.20241341]]. Action = [[0.         0.         0.         0.54579866]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 4105 is [True, False, False, False, False, True]
Current timestep = 4106. State = [[-0.37861314  0.19795391]]. Action = [[ 0.05522617 -0.0958738   0.         -0.1629039 ]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 4106 is [True, False, False, False, False, True]
Current timestep = 4107. State = [[-0.3727471   0.19798164]]. Action = [[ 0.09389471  0.06312833  0.         -0.21998096]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 4107 is [True, False, False, False, False, True]
Current timestep = 4108. State = [[-0.370897   0.2034957]]. Action = [[-0.01976443  0.08833533  0.          0.8240197 ]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 4108 is [True, False, False, False, False, True]
Current timestep = 4109. State = [[-0.36860007  0.2015791 ]]. Action = [[ 0.04967611 -0.09444275  0.         -0.03238797]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 4109 is [True, False, False, False, False, True]
Current timestep = 4110. State = [[-0.36668953  0.19995473]]. Action = [[-0.00589394  0.01616937  0.          0.51712704]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 4110 is [True, False, False, False, False, True]
State prediction error at timestep 4110 is 0.012
Human Feedback received at timestep 4110 of None
Current timestep = 4111. State = [[-0.36532003  0.20365018]]. Action = [[ 0.01595552  0.06743187  0.         -0.67056686]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 4111 is [True, False, False, False, False, True]
State prediction error at timestep 4111 is 0.012
Human Feedback received at timestep 4111 of None
Current timestep = 4112. State = [[-0.35973102  0.20315763]]. Action = [[ 0.08919106 -0.04724672  0.         -0.846745  ]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 4112 is [True, False, False, False, False, True]
Current timestep = 4113. State = [[-0.35453135  0.19713174]]. Action = [[ 0.02645714 -0.09523442  0.         -0.5604148 ]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 4113 is [True, False, False, False, False, True]
Current timestep = 4114. State = [[-0.3546929   0.19017345]]. Action = [[-0.05755556 -0.0922946   0.          0.98253345]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 4114 is [True, False, False, False, False, True]
Current timestep = 4115. State = [[-0.35531956  0.18636078]]. Action = [[-0.01475439 -0.02927646  0.         -0.7735849 ]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 4115 is [True, False, False, False, False, True]
Current timestep = 4116. State = [[-0.3508794   0.18094583]]. Action = [[ 0.07034873 -0.08411808  0.         -0.04692221]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 4116 is [True, False, False, False, False, True]
Current timestep = 4117. State = [[-0.3513731  0.1786662]]. Action = [[-0.07953255  0.02064131  0.          0.6044016 ]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 4117 is [True, False, False, False, False, True]
Current timestep = 4118. State = [[-0.35285527  0.1830919 ]]. Action = [[0.00192471 0.09329581 0.         0.6465517 ]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 4118 is [True, False, False, False, False, True]
Current timestep = 4119. State = [[-0.35532403  0.18664874]]. Action = [[-0.04729126  0.03163866  0.          0.13907921]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 4119 is [True, False, False, False, False, True]
State prediction error at timestep 4119 is 0.012
Human Feedback received at timestep 4119 of None
Current timestep = 4120. State = [[-0.3528299   0.18976258]]. Action = [[ 0.08784433  0.05581874  0.         -0.57957536]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 4120 is [True, False, False, False, False, True]
Current timestep = 4121. State = [[-0.35408172  0.1925845 ]]. Action = [[-0.06662539  0.03596846  0.          0.0827806 ]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 4121 is [True, False, False, False, False, True]
Current timestep = 4122. State = [[-0.35215402  0.19681396]]. Action = [[0.0927522  0.0723212  0.         0.31388438]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 4122 is [True, False, False, False, False, True]
Current timestep = 4123. State = [[-0.35402521  0.1986062 ]]. Action = [[-0.08322917 -0.0081976   0.         -0.6861366 ]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 4123 is [True, False, False, False, False, True]
Current timestep = 4124. State = [[-0.35580364  0.19886398]]. Action = [[ 0.02846339  0.00275122  0.         -0.54873675]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 4124 is [True, False, False, False, False, True]
State prediction error at timestep 4124 is 0.012
Human Feedback received at timestep 4124 of None
Current timestep = 4125. State = [[-0.3577662   0.20273812]]. Action = [[-0.03245675  0.07382541  0.         -0.49883735]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 4125 is [True, False, False, False, False, True]
State prediction error at timestep 4125 is 0.012
Human Feedback received at timestep 4125 of None
Current timestep = 4126. State = [[-0.35935307  0.20080814]]. Action = [[ 0.00544056 -0.0920595   0.         -0.02254927]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 4126 is [True, False, False, False, False, True]
Current timestep = 4127. State = [[-0.36148804  0.1947639 ]]. Action = [[-0.03836736 -0.08945888  0.         -0.73735964]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 4127 is [True, False, False, False, False, True]
Current timestep = 4128. State = [[-0.36545557  0.19528037]]. Action = [[-0.05156699  0.04962135  0.         -0.55894697]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 4128 is [True, False, False, False, False, True]
Current timestep = 4129. State = [[-0.36323926  0.20125186]]. Action = [[ 0.09525346  0.09503879  0.         -0.6469235 ]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 4129 is [True, False, False, False, False, True]
Current timestep = 4130. State = [[-0.3627728   0.20006396]]. Action = [[-0.04420284 -0.0881922   0.         -0.9599216 ]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 4130 is [True, False, False, False, False, True]
Current timestep = 4131. State = [[-0.36358753  0.20207526]]. Action = [[ 0.02536736  0.09640151  0.         -0.55844223]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 4131 is [True, False, False, False, False, True]
Current timestep = 4132. State = [[-0.36031067  0.20135432]]. Action = [[ 0.06607988 -0.05914245  0.         -0.6873301 ]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 4132 is [True, False, False, False, False, True]
Current timestep = 4133. State = [[-0.36046553  0.19838734]]. Action = [[-0.0417891  -0.02503593  0.         -0.6327896 ]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 4133 is [True, False, False, False, False, True]
Current timestep = 4134. State = [[-0.36146784  0.19483618]]. Action = [[-0.00136941 -0.05930405  0.         -0.24535257]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 4134 is [True, False, False, False, False, True]
Current timestep = 4135. State = [[-0.36465412  0.19325279]]. Action = [[-0.06732942 -0.00059536  0.         -0.09710509]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 4135 is [True, False, False, False, False, True]
Current timestep = 4136. State = [[-0.3650895   0.18964717]]. Action = [[ 0.02816433 -0.07329093  0.         -0.5419658 ]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 4136 is [True, False, False, False, False, True]
Current timestep = 4137. State = [[-0.36027518  0.18766826]]. Action = [[0.07856218 0.01318596 0.         0.8822758 ]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 4137 is [True, False, False, False, False, True]
Current timestep = 4138. State = [[-0.356349    0.18234497]]. Action = [[ 0.02167942 -0.0958887   0.          0.46909928]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 4138 is [True, False, False, False, False, True]
Current timestep = 4139. State = [[-0.35541493  0.1743998 ]]. Action = [[-0.0142684  -0.09264085  0.         -0.16414654]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 4139 is [True, False, False, False, False, True]
Current timestep = 4140. State = [[-0.3590459   0.17313926]]. Action = [[-0.08201395  0.0461603   0.         -0.7873079 ]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 4140 is [True, False, False, False, False, True]
Current timestep = 4141. State = [[-0.35996774  0.17112637]]. Action = [[ 0.02470703 -0.04963592  0.         -0.4250977 ]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 4141 is [True, False, False, False, False, True]
Current timestep = 4142. State = [[-0.3619252   0.16859639]]. Action = [[-0.05385869 -0.00431597  0.          0.6934978 ]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 4142 is [True, False, False, False, False, True]
State prediction error at timestep 4142 is 0.012
Human Feedback received at timestep 4142 of None
Current timestep = 4143. State = [[-0.36001477  0.17095444]]. Action = [[ 0.07894524  0.0782082   0.         -0.82617134]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 4143 is [True, False, False, False, False, True]
State prediction error at timestep 4143 is 0.012
Human Feedback received at timestep 4143 of None
Current timestep = 4144. State = [[-0.3611134   0.17383623]]. Action = [[-0.05898286  0.03762022  0.          0.9709023 ]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 4144 is [True, False, False, False, False, True]
State prediction error at timestep 4144 is 0.012
Human Feedback received at timestep 4144 of None
Current timestep = 4145. State = [[-0.3629721   0.17513175]]. Action = [[ 0.00756369  0.01703559  0.         -0.17923313]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 4145 is [True, False, False, False, False, True]
Current timestep = 4146. State = [[-0.36827788  0.17906848]]. Action = [[-0.09246707  0.0777883   0.          0.64003634]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 4146 is [True, False, False, False, False, True]
Current timestep = 4147. State = [[-0.36774477  0.17842065]]. Action = [[ 0.08825942 -0.06104906  0.          0.14583218]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 4147 is [True, False, False, False, False, True]
Current timestep = 4148. State = [[-0.36600733  0.17640595]]. Action = [[0.         0.         0.         0.17603421]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 4148 is [True, False, False, False, False, True]
State prediction error at timestep 4148 is 0.012
Human Feedback received at timestep 4148 of None
Current timestep = 4149. State = [[-0.36247164  0.17616174]]. Action = [[0.07710823 0.00389767 0.         0.91460514]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 4149 is [True, False, False, False, False, True]
Current timestep = 4150. State = [[-0.35745415  0.1744231 ]]. Action = [[ 0.05708658 -0.02682701  0.         -0.3807155 ]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 4150 is [True, False, False, False, False, True]
Current timestep = 4151. State = [[-0.35801488  0.1735926 ]]. Action = [[-0.05460516  0.00308744  0.          0.9481758 ]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 4151 is [True, False, False, False, False, True]
Current timestep = 4152. State = [[-0.35978273  0.17419367]]. Action = [[-0.01306425  0.0073145   0.          0.89509976]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 4152 is [True, False, False, False, False, True]
State prediction error at timestep 4152 is 0.012
Human Feedback received at timestep 4152 of None
Current timestep = 4153. State = [[-0.36365715  0.17088413]]. Action = [[-0.07696091 -0.08038113  0.          0.97996974]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 4153 is [True, False, False, False, False, True]
Current timestep = 4154. State = [[-0.36852592  0.17032154]]. Action = [[-0.05801851  0.02202457  0.          0.6024817 ]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 4154 is [True, False, False, False, False, True]
State prediction error at timestep 4154 is 0.012
Human Feedback received at timestep 4154 of None
Current timestep = 4155. State = [[-0.36872497  0.17515813]]. Action = [[0.04339763 0.0863375  0.         0.15502477]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 4155 is [True, False, False, False, False, True]
State prediction error at timestep 4155 is 0.012
Human Feedback received at timestep 4155 of None
Current timestep = 4156. State = [[-0.36823204  0.17746207]]. Action = [[0.         0.         0.         0.16168725]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 4156 is [True, False, False, False, False, True]
Current timestep = 4157. State = [[-0.3686447   0.17763734]]. Action = [[0.        0.        0.        0.9409139]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 4157 is [True, False, False, False, False, True]
Current timestep = 4158. State = [[-0.37237662  0.18197465]]. Action = [[-0.0636566   0.08390485  0.         -0.78318685]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 4158 is [True, False, False, False, False, True]
State prediction error at timestep 4158 is 0.012
Human Feedback received at timestep 4158 of None
Current timestep = 4159. State = [[-0.37512684  0.1847914 ]]. Action = [[ 0.          0.          0.         -0.08684146]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 4159 is [True, False, False, False, False, True]
Current timestep = 4160. State = [[-0.3760648   0.18536805]]. Action = [[0.        0.        0.        0.3344128]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 4160 is [True, False, False, False, False, True]
Current timestep = 4161. State = [[-0.37185374  0.18518269]]. Action = [[ 0.09922429 -0.00835823  0.          0.06435585]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 4161 is [True, False, False, False, False, True]
Current timestep = 4162. State = [[-0.36606866  0.18326643]]. Action = [[ 0.06308504 -0.03074785  0.         -0.9322376 ]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 4162 is [True, False, False, False, False, True]
Current timestep = 4163. State = [[-0.36342314  0.17990151]]. Action = [[ 0.00544105 -0.0507242   0.          0.2246257 ]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 4163 is [True, False, False, False, False, True]
Current timestep = 4164. State = [[-0.36034134  0.18273139]]. Action = [[ 0.04622292  0.08855855  0.         -0.9781104 ]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 4164 is [True, False, False, False, False, True]
Current timestep = 4165. State = [[-0.36105633  0.18590963]]. Action = [[-0.05482621  0.01344346  0.          0.15821588]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 4165 is [True, False, False, False, False, True]
Current timestep = 4166. State = [[-0.3667049   0.18229996]]. Action = [[-0.09850711 -0.09995041  0.          0.31150746]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 4166 is [True, False, False, False, False, True]
Current timestep = 4167. State = [[-0.36967358  0.17928228]]. Action = [[-0.01015235 -0.02235857  0.         -0.47777045]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 4167 is [True, False, False, False, False, True]
Current timestep = 4168. State = [[-0.37112293  0.17473333]]. Action = [[-0.026302   -0.08643088  0.         -0.34666967]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 4168 is [True, False, False, False, False, True]
State prediction error at timestep 4168 is 0.012
Human Feedback received at timestep 4168 of None
Current timestep = 4169. State = [[-0.37183434  0.17324047]]. Action = [[-0.00313108  0.01735274  0.          0.35224926]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 4169 is [True, False, False, False, False, True]
Current timestep = 4170. State = [[-0.37235406  0.17357855]]. Action = [[-0.00559452  0.00533144  0.          0.63300955]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 4170 is [True, False, False, False, False, True]
Current timestep = 4171. State = [[-0.36910573  0.17617327]]. Action = [[ 0.07808604  0.06419297  0.         -0.82629406]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 4171 is [True, False, False, False, False, True]
State prediction error at timestep 4171 is 0.012
Human Feedback received at timestep 4171 of None
Current timestep = 4172. State = [[-0.36850134  0.17995384]]. Action = [[-0.02152218  0.05949473  0.         -0.6461122 ]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 4172 is [True, False, False, False, False, True]
State prediction error at timestep 4172 is 0.012
Human Feedback received at timestep 4172 of None
Current timestep = 4173. State = [[-0.37309384  0.18457596]]. Action = [[-0.06915595  0.06552709  0.          0.44027352]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 4173 is [True, False, False, False, False, True]
State prediction error at timestep 4173 is 0.012
Human Feedback received at timestep 4173 of None
Current timestep = 4174. State = [[-0.37407604  0.18447378]]. Action = [[ 0.03778221 -0.04240622  0.          0.6349387 ]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 4174 is [True, False, False, False, False, True]
Current timestep = 4175. State = [[-0.3725946  0.1786696]]. Action = [[ 0.01764556 -0.09611029  0.         -0.53506243]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 4175 is [True, False, False, False, False, True]
State prediction error at timestep 4175 is 0.012
Human Feedback received at timestep 4175 of None
Current timestep = 4176. State = [[-0.36766782  0.17381941]]. Action = [[ 0.08667513 -0.03887765  0.          0.21545625]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 4176 is [True, False, False, False, False, True]
State prediction error at timestep 4176 is 0.012
Human Feedback received at timestep 4176 of None
Current timestep = 4177. State = [[-0.36189952  0.16894051]]. Action = [[ 0.05561764 -0.0612872   0.         -0.48396373]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 4177 is [True, False, False, False, False, True]
Current timestep = 4178. State = [[-0.35837698  0.17070304]]. Action = [[0.02119832 0.0900123  0.         0.455078  ]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 4178 is [True, False, False, False, False, True]
Current timestep = 4179. State = [[-0.35325122  0.16801435]]. Action = [[ 0.07424795 -0.09023166  0.          0.25324345]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 4179 is [True, False, False, False, False, True]
Current timestep = 4180. State = [[-0.3474037   0.16607305]]. Action = [[0.04921057 0.02912655 0.         0.32195628]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 4180 is [True, False, False, False, False, True]
Current timestep = 4181. State = [[-0.34416208  0.16270216]]. Action = [[ 0.0059969  -0.06433839  0.         -0.05178338]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 4181 is [True, False, False, False, False, True]
Current timestep = 4182. State = [[-0.34527832  0.15793751]]. Action = [[-0.06194276 -0.05069115  0.          0.36575234]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 4182 is [True, False, False, False, False, True]
Current timestep = 4183. State = [[-0.3462044   0.15648349]]. Action = [[-0.0126498   0.0088046   0.          0.49316478]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 4183 is [True, False, False, False, False, True]
State prediction error at timestep 4183 is 0.012
Human Feedback received at timestep 4183 of None
Current timestep = 4184. State = [[-0.3453167   0.15368804]]. Action = [[ 0.00591763 -0.04780298  0.          0.422711  ]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 4184 is [True, False, False, False, False, True]
Current timestep = 4185. State = [[-0.3418771   0.14854196]]. Action = [[ 0.04567096 -0.06052736  0.          0.8693538 ]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 4185 is [True, False, False, False, False, True]
Current timestep = 4186. State = [[-0.33702177  0.1414665 ]]. Action = [[ 0.04794445 -0.08500285  0.          0.30120325]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 4186 is [True, False, False, False, False, True]
Current timestep = 4187. State = [[-0.33830333  0.13365366]]. Action = [[-0.08437034 -0.08831296  0.         -0.859274  ]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 4187 is [True, False, False, False, False, True]
Current timestep = 4188. State = [[-0.33781683  0.13219629]]. Action = [[ 0.04153565  0.04743589  0.         -0.02052176]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 4188 is [True, False, False, False, False, True]
Current timestep = 4189. State = [[-0.33334774  0.12801954]]. Action = [[ 0.04964653 -0.08165123  0.          0.28388047]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 4189 is [True, False, False, False, False, True]
Current timestep = 4190. State = [[-0.33557874  0.12507461]]. Action = [[-0.09705405  0.01223811  0.          0.28071547]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 4190 is [True, False, False, False, False, True]
Current timestep = 4191. State = [[-0.3379367  0.1232403]]. Action = [[-0.0049251  -0.02410001  0.         -0.63956296]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 4191 is [True, False, False, False, False, True]
Current timestep = 4192. State = [[-0.3370276  0.116984 ]]. Action = [[ 0.01771115 -0.09202983  0.         -0.6659844 ]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 4192 is [True, False, False, False, True, False]
Current timestep = 4193. State = [[-0.33461836  0.11101495]]. Action = [[ 0.03102534 -0.04089034  0.          0.96383834]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 4193 is [True, False, False, False, True, False]
Current timestep = 4194. State = [[-0.33416086  0.11302197]]. Action = [[-0.0101411   0.09833438  0.          0.70061874]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 4194 is [True, False, False, False, True, False]
State prediction error at timestep 4194 is 0.012
Human Feedback received at timestep 4194 of None
Current timestep = 4195. State = [[-0.33860782  0.11947502]]. Action = [[-0.0702052   0.09882041  0.          0.13946068]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 4195 is [True, False, False, False, True, False]
Current timestep = 4196. State = [[-0.34268156  0.11798307]]. Action = [[-0.0212702  -0.08342507  0.          0.33406365]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 4196 is [True, False, False, False, True, False]
State prediction error at timestep 4196 is 0.012
Human Feedback received at timestep 4196 of None
Current timestep = 4197. State = [[-0.34792322  0.11825646]]. Action = [[-0.07322343  0.05873222  0.         -0.7663417 ]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 4197 is [True, False, False, False, True, False]
Current timestep = 4198. State = [[-0.3538202   0.12439137]]. Action = [[-0.04444842  0.09484453  0.          0.5061989 ]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 4198 is [True, False, False, False, True, False]
Current timestep = 4199. State = [[-0.35471755  0.12507544]]. Action = [[ 0.04908066 -0.04419253  0.          0.76398325]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 4199 is [True, False, False, False, True, False]
Current timestep = 4200. State = [[-0.35379145  0.11945841]]. Action = [[ 0.01994604 -0.08888842  0.          0.581743  ]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 4200 is [True, False, False, False, False, True]
Current timestep = 4201. State = [[-0.3552926   0.12131219]]. Action = [[-0.02241635  0.09838559  0.          0.32735693]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 4201 is [True, False, False, False, True, False]
Current timestep = 4202. State = [[-0.35755786  0.12704106]]. Action = [[-0.00439627  0.0604504   0.          0.5315683 ]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 4202 is [True, False, False, False, True, False]
Current timestep = 4203. State = [[-0.36333856  0.12539728]]. Action = [[-0.09281996 -0.08318055  0.          0.01271904]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 4203 is [True, False, False, False, False, True]
State prediction error at timestep 4203 is 0.012
Human Feedback received at timestep 4203 of None
Current timestep = 4204. State = [[-0.36627346  0.12510322]]. Action = [[0.021082   0.02987195 0.         0.34465086]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 4204 is [True, False, False, False, False, True]
Current timestep = 4205. State = [[-0.36272815  0.12276907]]. Action = [[ 0.08245095 -0.06458564  0.         -0.5323629 ]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 4205 is [True, False, False, False, False, True]
Current timestep = 4206. State = [[-0.3648427   0.11802711]]. Action = [[-0.08783693 -0.06174251  0.         -0.48940587]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 4206 is [True, False, False, False, True, False]
Current timestep = 4207. State = [[-0.37013257  0.11588555]]. Action = [[-0.05303954 -0.01067346  0.         -0.7813506 ]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 4207 is [True, False, False, False, True, False]
Current timestep = 4208. State = [[-0.36822525  0.11538926]]. Action = [[0.08611018 0.00391287 0.         0.42753553]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 4208 is [True, False, False, False, True, False]
State prediction error at timestep 4208 is 0.012
Human Feedback received at timestep 4208 of None
Current timestep = 4209. State = [[-0.36935452  0.11231484]]. Action = [[-0.06823076 -0.05501639  0.          0.6751008 ]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 4209 is [True, False, False, False, True, False]
State prediction error at timestep 4209 is 0.012
Human Feedback received at timestep 4209 of None
Current timestep = 4210. State = [[-0.37381312  0.10584211]]. Action = [[-0.04803903 -0.09263562  0.          0.9162129 ]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 4210 is [True, False, False, False, True, False]
Current timestep = 4211. State = [[-0.37475348  0.10704663]]. Action = [[0.02532618 0.09701353 0.         0.54299176]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 4211 is [True, False, False, False, True, False]
Current timestep = 4212. State = [[-0.37627658  0.11208808]]. Action = [[-0.02579988  0.06430089  0.         -0.03257364]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 4212 is [True, False, False, False, True, False]
Current timestep = 4213. State = [[-0.377299    0.10903306]]. Action = [[ 0.00983723 -0.09451465  0.          0.34568417]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 4213 is [True, False, False, False, True, False]
Current timestep = 4214. State = [[-0.37802842  0.10731693]]. Action = [[-0.01061925  0.02899202  0.         -0.9324307 ]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 4214 is [True, False, False, False, True, False]
Current timestep = 4215. State = [[-0.37720668  0.10476881]]. Action = [[ 0.03218888 -0.05456463  0.         -0.6693599 ]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 4215 is [True, False, False, False, True, False]
State prediction error at timestep 4215 is 0.012
Human Feedback received at timestep 4215 of None
Current timestep = 4216. State = [[-0.3765086   0.10262754]]. Action = [[0.        0.        0.        0.9748659]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 4216 is [True, False, False, False, True, False]
Current timestep = 4217. State = [[-0.37663797  0.10197595]]. Action = [[ 0.          0.          0.         -0.27089393]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 4217 is [True, False, False, False, True, False]
Current timestep = 4218. State = [[-0.37483144  0.10327942]]. Action = [[0.0412849  0.03880938 0.         0.673499  ]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 4218 is [True, False, False, False, True, False]
Current timestep = 4219. State = [[-0.3739216   0.10378458]]. Action = [[0.         0.         0.         0.14251351]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 4219 is [True, False, False, False, True, False]
Current timestep = 4220. State = [[-0.37090045  0.1073242 ]]. Action = [[0.06593528 0.08089276 0.         0.96947026]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 4220 is [True, False, False, False, True, False]
State prediction error at timestep 4220 is 0.012
Human Feedback received at timestep 4220 of None
Current timestep = 4221. State = [[-0.36928043  0.10921568]]. Action = [[ 0.          0.          0.         -0.12003762]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 4221 is [True, False, False, False, True, False]
Current timestep = 4222. State = [[-0.3653887   0.10867782]]. Action = [[ 0.07558448 -0.00999161  0.          0.28101635]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 4222 is [True, False, False, False, True, False]
Current timestep = 4223. State = [[-0.35824877  0.10652597]]. Action = [[ 0.09146779 -0.03169104  0.          0.08333397]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 4223 is [True, False, False, False, True, False]
Current timestep = 4224. State = [[-0.35546273  0.10863248]]. Action = [[-0.01534552  0.06649867  0.         -0.49607182]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 4224 is [True, False, False, False, True, False]
Current timestep = 4225. State = [[-0.35780147  0.10946316]]. Action = [[-0.0600855  -0.02718908  0.          0.23320508]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 4225 is [True, False, False, False, True, False]
State prediction error at timestep 4225 is 0.012
Human Feedback received at timestep 4225 of None
Current timestep = 4226. State = [[-0.3577246   0.11033799]]. Action = [[ 0.01832636  0.01959135  0.         -0.7539104 ]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 4226 is [True, False, False, False, True, False]
State prediction error at timestep 4226 is 0.012
Human Feedback received at timestep 4226 of None
Current timestep = 4227. State = [[-0.35512775  0.10997052]]. Action = [[ 0.0277751  -0.02639452  0.         -0.6184505 ]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 4227 is [True, False, False, False, True, False]
Current timestep = 4228. State = [[-0.35582098  0.10958733]]. Action = [[-0.04900853 -0.00141747  0.         -0.85212135]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 4228 is [True, False, False, False, True, False]
State prediction error at timestep 4228 is 0.012
Human Feedback received at timestep 4228 of None
Current timestep = 4229. State = [[-0.35631087  0.10783841]]. Action = [[ 0.0003866  -0.04517044  0.         -0.16070831]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 4229 is [True, False, False, False, True, False]
State prediction error at timestep 4229 is 0.012
Human Feedback received at timestep 4229 of None
Current timestep = 4230. State = [[-0.35233128  0.10777736]]. Action = [[0.06740392 0.02060809 0.         0.10093141]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 4230 is [True, False, False, False, True, False]
Current timestep = 4231. State = [[-0.34775978  0.10570374]]. Action = [[ 0.03879347 -0.05002228  0.         -0.28092563]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 4231 is [True, False, False, False, True, False]
State prediction error at timestep 4231 is 0.012
Human Feedback received at timestep 4231 of None
Current timestep = 4232. State = [[-0.34733585  0.10749761]]. Action = [[-0.03322949  0.06790823  0.          0.6900513 ]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 4232 is [True, False, False, False, True, False]
Current timestep = 4233. State = [[-0.3441712   0.11178339]]. Action = [[ 0.0743799   0.05028612  0.         -0.40494698]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 4233 is [True, False, False, False, True, False]
Current timestep = 4234. State = [[-0.33793393  0.1150955 ]]. Action = [[0.07948681 0.04211148 0.         0.35247278]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 4234 is [True, False, False, False, True, False]
State prediction error at timestep 4234 is 0.012
Human Feedback received at timestep 4234 of None
Current timestep = 4235. State = [[-0.3360605   0.11827967]]. Action = [[-0.01925401  0.04120702  0.          0.58820105]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 4235 is [True, False, False, False, True, False]
Current timestep = 4236. State = [[-0.3404426   0.12029457]]. Action = [[-0.09184622  0.00494944  0.          0.04555321]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 4236 is [True, False, False, False, True, False]
State prediction error at timestep 4236 is 0.012
Human Feedback received at timestep 4236 of None
Current timestep = 4237. State = [[-0.34102166  0.12474636]]. Action = [[0.03895628 0.06925976 0.         0.8325834 ]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 4237 is [True, False, False, False, True, False]
Current timestep = 4238. State = [[-0.33621597  0.1244809 ]]. Action = [[ 0.07206633 -0.06095255  0.          0.865306  ]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 4238 is [True, False, False, False, True, False]
State prediction error at timestep 4238 is 0.012
Human Feedback received at timestep 4238 of None
Current timestep = 4239. State = [[-0.3368873   0.12376954]]. Action = [[-0.07187162  0.00261092  0.         -0.20628077]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 4239 is [True, False, False, False, True, False]
Current timestep = 4240. State = [[-0.33412096  0.12468418]]. Action = [[ 0.08342748  0.00083391  0.         -0.03171229]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 4240 is [True, False, False, False, True, False]
Current timestep = 4241. State = [[-0.3297638  0.1257182]]. Action = [[0.02465274 0.00839199 0.         0.89640284]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 4241 is [True, False, False, False, True, False]
Current timestep = 4242. State = [[-0.32630086  0.12700374]]. Action = [[ 0.03327324  0.01039349  0.         -0.09990335]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 4242 is [True, False, False, False, False, True]
Current timestep = 4243. State = [[-0.32115012  0.12397083]]. Action = [[ 0.06049091 -0.07560794  0.         -0.4893334 ]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 4243 is [True, False, False, False, False, True]
Current timestep = 4244. State = [[-0.32028925  0.12050491]]. Action = [[-0.05039945 -0.03316454  0.         -0.51983213]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 4244 is [True, False, False, False, True, False]
Current timestep = 4245. State = [[-0.32379836  0.12359907]]. Action = [[-0.07329276  0.0738287   0.         -0.3133893 ]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 4245 is [True, False, False, False, True, False]
Current timestep = 4246. State = [[-0.32846096  0.12249947]]. Action = [[-0.06911651 -0.07814918  0.         -0.6312403 ]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 4246 is [True, False, False, False, True, False]
Current timestep = 4247. State = [[-0.33014458  0.11808422]]. Action = [[-0.00826783 -0.05809833  0.         -0.9797836 ]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 4247 is [True, False, False, False, True, False]
Current timestep = 4248. State = [[-0.3314335   0.11188284]]. Action = [[-0.03270633 -0.0926286   0.         -0.3902601 ]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 4248 is [True, False, False, False, True, False]
Current timestep = 4249. State = [[-0.32796702  0.10973582]]. Action = [[ 0.08463456  0.02214997  0.         -0.3611945 ]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 4249 is [True, False, False, False, True, False]
Current timestep = 4250. State = [[-0.3280958   0.11124514]]. Action = [[-0.05726874  0.03534649  0.         -0.90188146]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 4250 is [True, False, False, False, True, False]
State prediction error at timestep 4250 is 0.012
Human Feedback received at timestep 4250 of None
Current timestep = 4251. State = [[-0.3337587   0.11353773]]. Action = [[-0.08321124  0.03239521  0.         -0.9169128 ]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 4251 is [True, False, False, False, True, False]
Current timestep = 4252. State = [[-0.33937     0.11169934]]. Action = [[-0.05510126 -0.05596637  0.          0.08680367]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 4252 is [True, False, False, False, True, False]
Current timestep = 4253. State = [[-0.34394175  0.10547798]]. Action = [[-0.04849858 -0.09343429  0.         -0.72209007]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 4253 is [True, False, False, False, True, False]
Current timestep = 4254. State = [[-0.35091302  0.10547283]]. Action = [[-0.09585837  0.06228436  0.         -0.69572777]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 4254 is [True, False, False, False, True, False]
Current timestep = 4255. State = [[-0.35276952  0.10919306]]. Action = [[ 0.05622714  0.04962648  0.         -0.6729631 ]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 4255 is [True, False, False, False, True, False]
Current timestep = 4256. State = [[-0.3555611   0.11214562]]. Action = [[-0.04580389  0.03901608  0.         -0.33801937]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 4256 is [True, False, False, False, True, False]
Current timestep = 4257. State = [[-0.35856196  0.1160643 ]]. Action = [[ 0.00578046  0.06025667  0.         -0.16984296]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 4257 is [True, False, False, False, True, False]
Current timestep = 4258. State = [[-0.36248785  0.12065051]]. Action = [[-0.03572246  0.05990217  0.         -0.500547  ]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 4258 is [True, False, False, False, True, False]
Current timestep = 4259. State = [[-0.36983493  0.11819815]]. Action = [[-0.0898131  -0.09364548  0.         -0.24395359]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 4259 is [True, False, False, False, True, False]
Current timestep = 4260. State = [[-0.3702112   0.11401838]]. Action = [[ 0.08623623 -0.03531191  0.          0.57877254]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 4260 is [True, False, False, False, True, False]
State prediction error at timestep 4260 is 0.012
Human Feedback received at timestep 4260 of None
Current timestep = 4261. State = [[-0.3707164   0.11221609]]. Action = [[-0.03582294 -0.01211972  0.         -0.8769512 ]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 4261 is [True, False, False, False, True, False]
State prediction error at timestep 4261 is 0.012
Human Feedback received at timestep 4261 of None
Current timestep = 4262. State = [[-0.36760777  0.11322943]]. Action = [[ 0.09999897  0.0325385   0.         -0.8125984 ]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 4262 is [True, False, False, False, True, False]
Current timestep = 4263. State = [[-0.36184412  0.11063405]]. Action = [[ 0.0672492  -0.06054715  0.          0.02331054]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 4263 is [True, False, False, False, True, False]
Current timestep = 4264. State = [[-0.35999036  0.10942055]]. Action = [[-0.01063867  0.01908405  0.         -0.5232295 ]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 4264 is [True, False, False, False, True, False]
State prediction error at timestep 4264 is 0.012
Human Feedback received at timestep 4264 of None
Current timestep = 4265. State = [[-0.35682276  0.1064839 ]]. Action = [[ 0.05710851 -0.06098976  0.          0.96461225]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 4265 is [True, False, False, False, True, False]
Current timestep = 4266. State = [[-0.3497544   0.10559924]]. Action = [[0.09358705 0.03191932 0.         0.48589945]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 4266 is [True, False, False, False, True, False]
Current timestep = 4267. State = [[-0.3434449   0.10889275]]. Action = [[ 0.05419575  0.07043164  0.         -0.6509914 ]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 4267 is [True, False, False, False, True, False]
State prediction error at timestep 4267 is 0.012
Human Feedback received at timestep 4267 of None
Current timestep = 4268. State = [[-0.3413658   0.11407018]]. Action = [[-0.00979043  0.07800625  0.          0.30428338]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 4268 is [True, False, False, False, True, False]
Current timestep = 4269. State = [[-0.34322214  0.11473307]]. Action = [[-0.052773   -0.03230078  0.         -0.33302748]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 4269 is [True, False, False, False, True, False]
Current timestep = 4270. State = [[-0.34215963  0.1146286 ]]. Action = [[ 0.03240641  0.0077965   0.         -0.30072784]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 4270 is [True, False, False, False, True, False]
Current timestep = 4271. State = [[-0.33666262  0.11982235]]. Action = [[0.0812887  0.09972882 0.         0.41317225]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 4271 is [True, False, False, False, True, False]
Current timestep = 4272. State = [[-0.3313445   0.12352075]]. Action = [[ 0.0490615   0.01555147  0.         -0.9474585 ]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 4272 is [True, False, False, False, True, False]
Current timestep = 4273. State = [[-0.33277997  0.121388  ]]. Action = [[-0.08521409 -0.07036334  0.          0.72784877]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 4273 is [True, False, False, False, True, False]
Current timestep = 4274. State = [[-0.3312292   0.11850856]]. Action = [[ 0.06146402 -0.03475413  0.         -0.18890595]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 4274 is [True, False, False, False, True, False]
Current timestep = 4275. State = [[-0.32950526  0.11882292]]. Action = [[-0.01925904  0.01749375  0.          0.5189762 ]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 4275 is [True, False, False, False, True, False]
Current timestep = 4276. State = [[-0.33221373  0.11942907]]. Action = [[-0.06540672 -0.01132811  0.         -0.696401  ]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 4276 is [True, False, False, False, True, False]
Current timestep = 4277. State = [[-0.33205274  0.12267008]]. Action = [[ 0.02957802  0.05725215  0.         -0.55575943]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 4277 is [True, False, False, False, True, False]
State prediction error at timestep 4277 is 0.012
Human Feedback received at timestep 4277 of None
Current timestep = 4278. State = [[-0.3320549  0.1283236]]. Action = [[-0.01871482  0.07031158  0.         -0.07734978]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 4278 is [True, False, False, False, True, False]
State prediction error at timestep 4278 is 0.012
Human Feedback received at timestep 4278 of None
Current timestep = 4279. State = [[-0.32867754  0.12806848]]. Action = [[ 0.07748758 -0.05940815  0.          0.20781219]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 4279 is [True, False, False, False, False, True]
Current timestep = 4280. State = [[-0.32336715  0.12877056]]. Action = [[ 0.05631631  0.04214289  0.         -0.16834462]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 4280 is [True, False, False, False, False, True]
Current timestep = 4281. State = [[-0.32452226  0.13077816]]. Action = [[-0.06924085  0.01022772  0.         -0.9408392 ]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 4281 is [True, False, False, False, False, True]
Current timestep = 4282. State = [[-0.32884717  0.12706795]]. Action = [[-0.06069618 -0.09958395  0.         -0.28577447]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 4282 is [True, False, False, False, False, True]
Current timestep = 4283. State = [[-0.3301184  0.129312 ]]. Action = [[0.00769933 0.09130725 0.         0.18860269]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 4283 is [True, False, False, False, False, True]
Current timestep = 4284. State = [[-0.32756022  0.13702011]]. Action = [[ 0.05399358  0.09746646  0.         -0.7583294 ]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 4284 is [True, False, False, False, False, True]
State prediction error at timestep 4284 is 0.012
Human Feedback received at timestep 4284 of None
Current timestep = 4285. State = [[-0.32426035  0.14119491]]. Action = [[ 0.04340103  0.0197074   0.         -0.23069346]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 4285 is [True, False, False, False, False, True]
State prediction error at timestep 4285 is 0.012
Human Feedback received at timestep 4285 of None
Current timestep = 4286. State = [[-0.32434064  0.14537683]]. Action = [[-0.02532244  0.05977262  0.         -0.35576606]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 4286 is [True, False, False, False, False, True]
State prediction error at timestep 4286 is 0.012
Human Feedback received at timestep 4286 of None
Current timestep = 4287. State = [[-0.32032362  0.14687058]]. Action = [[ 0.09771387 -0.01872288  0.         -0.03163409]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 4287 is [True, False, False, False, False, True]
Current timestep = 4288. State = [[-0.31801087  0.1460629 ]]. Action = [[-0.01552128 -0.01978452  0.         -0.0783388 ]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 4288 is [True, False, False, False, False, True]
Current timestep = 4289. State = [[-0.31311586  0.14997476]]. Action = [[ 0.0978485   0.07953315  0.         -0.02118975]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 4289 is [True, False, False, False, False, True]
Current timestep = 4290. State = [[-0.31171235  0.15657537]]. Action = [[-0.04140724  0.07567369  0.         -0.2933426 ]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 4290 is [True, False, False, False, False, True]
Current timestep = 4291. State = [[-0.31582886  0.16435106]]. Action = [[-7.0243046e-02  8.7994687e-02  0.0000000e+00 -1.1920929e-06]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 4291 is [True, False, False, False, False, True]
Current timestep = 4292. State = [[-0.3213087  0.1681207]]. Action = [[-0.07057486 -0.01167727  0.          0.96929073]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 4292 is [True, False, False, False, False, True]
Current timestep = 4293. State = [[-0.3192217   0.16665938]]. Action = [[ 0.08351659 -0.06276964  0.         -0.8972954 ]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 4293 is [True, False, False, False, False, True]
Current timestep = 4294. State = [[-0.31474635  0.16370057]]. Action = [[ 0.03420349 -0.04951438  0.          0.92153525]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 4294 is [True, False, False, False, False, True]
Current timestep = 4295. State = [[-0.31113625  0.16496927]]. Action = [[0.03558349 0.03683346 0.         0.21161008]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 4295 is [True, False, False, False, False, True]
Current timestep = 4296. State = [[-0.30966032  0.16784653]]. Action = [[-0.00548548  0.02337507  0.         -0.46596843]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 4296 is [True, False, False, False, False, True]
Current timestep = 4297. State = [[-0.3074423   0.16984586]]. Action = [[0.03364066 0.01154395 0.         0.6829479 ]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 4297 is [True, False, False, False, False, True]
Current timestep = 4298. State = [[-0.30537364  0.1679892 ]]. Action = [[ 0.00614103 -0.05687407  0.         -0.47265917]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 4298 is [True, False, False, False, False, True]
State prediction error at timestep 4298 is 0.012
Human Feedback received at timestep 4298 of None
Current timestep = 4299. State = [[-0.30487707  0.16747001]]. Action = [[-0.01416219  0.01107223  0.         -0.6111821 ]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 4299 is [True, False, False, False, False, True]
State prediction error at timestep 4299 is 0.012
Human Feedback received at timestep 4299 of None
Current timestep = 4300. State = [[-0.30572468  0.16565067]]. Action = [[-0.02733072 -0.05219929  0.         -0.85339147]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 4300 is [True, False, False, False, False, True]
Current timestep = 4301. State = [[-0.30134693  0.16046163]]. Action = [[ 0.08482157 -0.08013229  0.          0.9222429 ]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 4301 is [True, False, False, False, False, True]
Current timestep = 4302. State = [[-0.30158007  0.15762076]]. Action = [[-0.07689287 -0.00484467  0.         -0.68450075]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 4302 is [True, False, False, False, False, True]
Current timestep = 4303. State = [[-0.30319303  0.15961863]]. Action = [[-0.00644678  0.04684886  0.         -0.83454704]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 4303 is [True, False, False, False, False, True]
Current timestep = 4304. State = [[-0.30269468  0.16343409]]. Action = [[0.01293924 0.05668979 0.         0.42371416]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 4304 is [True, False, False, False, False, True]
State prediction error at timestep 4304 is 0.012
Human Feedback received at timestep 4304 of None
Current timestep = 4305. State = [[-0.30001095  0.16486803]]. Action = [[0.05046397 0.00412647 0.         0.16316366]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 4305 is [True, False, False, False, False, True]
State prediction error at timestep 4305 is 0.012
Human Feedback received at timestep 4305 of None
Current timestep = 4306. State = [[-0.30193532  0.16878662]]. Action = [[-0.06448923  0.08278456  0.          0.5758021 ]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 4306 is [True, False, False, False, False, True]
State prediction error at timestep 4306 is 0.012
Human Feedback received at timestep 4306 of None
Current timestep = 4307. State = [[-0.30053586  0.16935033]]. Action = [[ 0.07313275 -0.0360757   0.          0.91702676]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 4307 is [True, False, False, False, False, True]
State prediction error at timestep 4307 is 0.012
Human Feedback received at timestep 4307 of None
Current timestep = 4308. State = [[-0.3035121  0.1708517]]. Action = [[-0.09598907  0.04906065  0.         -0.6752805 ]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 4308 is [True, False, False, False, False, True]
Current timestep = 4309. State = [[-0.305753    0.17210707]]. Action = [[ 0.01752846 -0.01214455  0.         -0.2083208 ]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 4309 is [True, False, False, False, False, True]
Current timestep = 4310. State = [[-0.31047043  0.17597733]]. Action = [[-0.0901348   0.07295605  0.         -0.13371658]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 4310 is [True, False, False, False, False, True]
State prediction error at timestep 4310 is 0.012
Human Feedback received at timestep 4310 of None
Current timestep = 4311. State = [[-0.30967656  0.18293595]]. Action = [[0.09621208 0.09066173 0.         0.17433047]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 4311 is [True, False, False, False, False, True]
Current timestep = 4312. State = [[-0.30372727  0.18672265]]. Action = [[0.08656435 0.01716451 0.         0.37866473]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 4312 is [True, False, False, False, False, True]
Current timestep = 4313. State = [[-0.3001516   0.19087553]]. Action = [[ 0.0252078   0.06306653  0.         -0.5468336 ]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 4313 is [True, False, False, False, False, True]
State prediction error at timestep 4313 is 0.012
Human Feedback received at timestep 4313 of None
Current timestep = 4314. State = [[-0.2964338   0.19049215]]. Action = [[ 0.05541015 -0.06023417  0.         -0.10377216]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 4314 is [True, False, False, False, False, True]
Current timestep = 4315. State = [[-0.29102087  0.18715818]]. Action = [[ 0.05992154 -0.0528172   0.          0.7819257 ]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 4315 is [True, False, False, False, False, True]
State prediction error at timestep 4315 is 0.012
Human Feedback received at timestep 4315 of None
Current timestep = 4316. State = [[-0.28717    0.1885967]]. Action = [[ 0.0169111   0.04695482  0.         -0.81411886]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 4316 is [True, False, False, False, False, True]
Current timestep = 4317. State = [[-0.28438288  0.19042878]]. Action = [[ 0.01905699 -0.00231826  0.          0.5994736 ]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 4317 is [True, False, False, False, False, True]
Current timestep = 4318. State = [[-0.28074753  0.19107899]]. Action = [[ 3.3132412e-02 -7.4804574e-04  0.0000000e+00  9.8408556e-01]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 4318 is [True, False, False, False, False, True]
Current timestep = 4319. State = [[-0.27869442  0.1917588 ]]. Action = [[-0.00904789  0.00119486  0.         -0.0751164 ]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 4319 is [True, False, False, False, False, True]
State prediction error at timestep 4319 is 0.012
Human Feedback received at timestep 4319 of None
Current timestep = 4320. State = [[-0.27803898  0.1938458 ]]. Action = [[-0.01148268  0.02638408  0.         -0.34878528]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 4320 is [True, False, False, False, False, True]
Current timestep = 4321. State = [[-0.27597076  0.19544436]]. Action = [[0.02423235 0.00234874 0.         0.03234243]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 4321 is [True, False, False, False, False, True]
Current timestep = 4322. State = [[-0.27083606  0.19155881]]. Action = [[ 0.06351399 -0.09157845  0.          0.17634869]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 4322 is [True, False, False, False, False, True]
State prediction error at timestep 4322 is 0.012
Human Feedback received at timestep 4322 of None
Current timestep = 4323. State = [[-0.26579592  0.19176583]]. Action = [[0.03412161 0.05509488 0.         0.232445  ]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 4323 is [True, False, False, False, False, True]
Current timestep = 4324. State = [[-0.26540378  0.1925544 ]]. Action = [[-0.04002311 -0.01623103  0.         -0.01075435]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 4324 is [True, False, False, False, False, True]
State prediction error at timestep 4324 is 0.012
Human Feedback received at timestep 4324 of None
Current timestep = 4325. State = [[-0.2655315   0.19059123]]. Action = [[-0.00503033 -0.04059252  0.          0.1362387 ]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 4325 is [True, False, False, False, False, True]
Current timestep = 4326. State = [[-0.26503912  0.18591177]]. Action = [[-0.01122222 -0.07845095  0.         -0.4350736 ]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 4326 is [True, False, False, False, False, True]
Current timestep = 4327. State = [[-0.26270154  0.18531528]]. Action = [[0.03159397 0.03414089 0.         0.32399964]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 4327 is [True, False, False, False, False, True]
Current timestep = 4328. State = [[-0.2616274   0.18614794]]. Action = [[-0.01223567  0.00523701  0.          0.44586515]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 4328 is [True, False, False, False, False, True]
Current timestep = 4329. State = [[-0.26629913  0.18928343]]. Action = [[-0.09887861  0.05923042  0.          0.08726227]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 4329 is [True, False, False, False, False, True]
Current timestep = 4330. State = [[-0.2724094  0.1884531]]. Action = [[-0.06729806 -0.06170551  0.          0.5722753 ]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 4330 is [True, False, False, False, False, True]
Current timestep = 4331. State = [[-0.27563405  0.18531407]]. Action = [[-0.02078798 -0.04139465  0.          0.05978143]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 4331 is [True, False, False, False, False, True]
Current timestep = 4332. State = [[-0.28015718  0.18717726]]. Action = [[-0.06663267  0.05807743  0.         -0.5899673 ]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 4332 is [True, False, False, False, False, True]
Current timestep = 4333. State = [[-0.28308994  0.18669857]]. Action = [[ 0.00085036 -0.04615165  0.          0.17341518]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 4333 is [True, False, False, False, False, True]
Current timestep = 4334. State = [[-0.2798779   0.18959968]]. Action = [[0.09696343 0.09421308 0.         0.57331216]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 4334 is [True, False, False, False, False, True]
Current timestep = 4335. State = [[-0.28188285  0.19312337]]. Action = [[-0.07894323  0.02428038  0.         -0.81557167]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 4335 is [True, False, False, False, False, True]
State prediction error at timestep 4335 is 0.012
Human Feedback received at timestep 4335 of None
Current timestep = 4336. State = [[-0.28924888  0.19848673]]. Action = [[-0.07342186  0.09333964  0.         -0.72332674]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 4336 is [True, False, False, False, False, True]
Current timestep = 4337. State = [[-0.29519802  0.19831277]]. Action = [[-0.03708295 -0.06465779  0.         -0.20861769]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 4337 is [True, False, False, False, False, True]
Current timestep = 4338. State = [[-0.29751462  0.19406016]]. Action = [[ 0.00724503 -0.06153381  0.          0.9992075 ]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 4338 is [True, False, False, False, False, True]
Current timestep = 4339. State = [[-0.30268165  0.18805556]]. Action = [[-0.08554425 -0.09370387  0.         -0.53649044]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 4339 is [True, False, False, False, False, True]
Current timestep = 4340. State = [[-0.00181705 -0.02150046]]. Action = [[ 0.00250848 -0.0122296   0.         -0.56930137]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 4340 is [True, False, False, False, False, True]
Current timestep = 4341. State = [[-0.31826273  0.07868843]]. Action = [[ 0.02242456  0.05138827  0.         -0.4285426 ]]. Reward = [100.]
Curr episode timestep = 0
Scene graph at timestep 4341 is [False, True, False, False, True, False]
Current timestep = 4342. State = [[-0.31888437  0.08011875]]. Action = [[-0.09083531 -0.05621548  0.          0.18003201]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 4342 is [True, False, False, False, True, False]
Current timestep = 4343. State = [[-0.32340455  0.08135215]]. Action = [[-0.05574546  0.01948973  0.         -0.82853466]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 4343 is [True, False, False, False, True, False]
Current timestep = 4344. State = [[-0.32705745  0.08560766]]. Action = [[-0.04200128  0.0395864   0.          0.46637154]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 4344 is [True, False, False, False, True, False]
Current timestep = 4345. State = [[-0.3265613   0.08804686]]. Action = [[ 0.03948136 -0.00890478  0.         -0.06430006]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 4345 is [True, False, False, False, True, False]
Current timestep = 4346. State = [[-0.32790396  0.09257611]]. Action = [[-0.04442639  0.06524187  0.          0.33805382]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4346 is [True, False, False, False, True, False]
Current timestep = 4347. State = [[-0.33329293  0.09384499]]. Action = [[-0.08068386 -0.0456087   0.         -0.63245606]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 4347 is [True, False, False, False, True, False]
Current timestep = 4348. State = [[-0.33777064  0.09908397]]. Action = [[-0.03569623  0.09796908  0.          0.27812755]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 4348 is [True, False, False, False, True, False]
Current timestep = 4349. State = [[-0.34096912  0.09933472]]. Action = [[-0.02767081 -0.08421282  0.          0.4452454 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 4349 is [True, False, False, False, True, False]
Current timestep = 4350. State = [[-0.34369874  0.09570231]]. Action = [[-0.03367551 -0.05234016  0.          0.48001373]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 4350 is [True, False, False, False, True, False]
State prediction error at timestep 4350 is 0.012
Human Feedback received at timestep 4350 of None
Current timestep = 4351. State = [[-0.34258285  0.08975866]]. Action = [[ 0.04432695 -0.09994944  0.         -0.02683169]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 4351 is [True, False, False, False, True, False]
Current timestep = 4352. State = [[-0.34475932  0.08226611]]. Action = [[-0.07653581 -0.09295446  0.          0.7453127 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 4352 is [True, False, False, False, True, False]
Current timestep = 4353. State = [[-0.34770596  0.08366328]]. Action = [[-0.01560246  0.09514298  0.         -0.79171133]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 4353 is [True, False, False, False, True, False]
Current timestep = 4354. State = [[-0.3504181   0.08269516]]. Action = [[-0.03348414 -0.0661203   0.         -0.04342389]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 4354 is [True, False, False, False, True, False]
Current timestep = 4355. State = [[-0.349377    0.08015157]]. Action = [[ 0.05094854 -0.00318409  0.         -0.74022746]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 4355 is [True, False, False, False, True, False]
State prediction error at timestep 4355 is 0.012
Human Feedback received at timestep 4355 of None
Current timestep = 4356. State = [[-0.34731695  0.07612848]]. Action = [[ 0.02317484 -0.05679414  0.          0.51679385]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 4356 is [True, False, False, False, True, False]
Current timestep = 4357. State = [[-0.34533206  0.07279626]]. Action = [[ 0.02971344 -0.01017311  0.          0.13068676]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 4357 is [True, False, False, False, True, False]
Current timestep = 4358. State = [[-0.34355596  0.07498728]]. Action = [[0.02597211 0.0777437  0.         0.77577186]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 4358 is [True, False, False, False, True, False]
Current timestep = 4359. State = [[-0.33980876  0.07261167]]. Action = [[ 0.07120592 -0.06931679  0.          0.6916952 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 4359 is [True, False, False, False, True, False]
State prediction error at timestep 4359 is 0.012
Human Feedback received at timestep 4359 of None
Current timestep = 4360. State = [[-0.3357593   0.06735836]]. Action = [[ 0.04048058 -0.04103559  0.          0.6325717 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 4360 is [True, False, False, False, True, False]
Current timestep = 4361. State = [[-0.33579567  0.06781039]]. Action = [[-0.03159159  0.0602157   0.          0.12676907]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 4361 is [True, False, False, False, True, False]
Current timestep = 4362. State = [[-0.33180982  0.06645773]]. Action = [[ 0.09602197 -0.04028753  0.          0.43952322]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 4362 is [True, False, False, False, True, False]
State prediction error at timestep 4362 is 0.012
Human Feedback received at timestep 4362 of None
Current timestep = 4363. State = [[-0.32689026  0.06536285]]. Action = [[0.03864285 0.02265255 0.         0.33048272]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 4363 is [True, False, False, False, True, False]
State prediction error at timestep 4363 is 0.012
Human Feedback received at timestep 4363 of None
Current timestep = 4364. State = [[-0.3234943   0.06273597]]. Action = [[ 0.03145774 -0.04567711  0.          0.8711592 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 4364 is [True, False, False, False, True, False]
Current timestep = 4365. State = [[-0.3198251  0.0626903]]. Action = [[0.03783619 0.04240779 0.         0.19716918]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 4365 is [True, False, False, False, True, False]
Current timestep = 4366. State = [[-0.31481534  0.05864143]]. Action = [[ 0.05939493 -0.08943968  0.          0.08974135]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 4366 is [True, False, False, False, True, False]
Current timestep = 4367. State = [[-0.31255502  0.05423468]]. Action = [[-0.01951133 -0.02218659  0.          0.21903789]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 4367 is [True, False, False, False, True, False]
Current timestep = 4368. State = [[-0.31209305  0.05566768]]. Action = [[-0.01061651  0.0574384   0.         -0.8774866 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 4368 is [True, False, False, False, True, False]
State prediction error at timestep 4368 is 0.012
Human Feedback received at timestep 4368 of None
Current timestep = 4369. State = [[-0.3088771   0.06057577]]. Action = [[ 0.05565702  0.07487614  0.         -0.65886134]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 4369 is [True, False, False, False, True, False]
Current timestep = 4370. State = [[-0.30443022  0.06196478]]. Action = [[ 0.04811677 -0.01230139  0.         -0.6035295 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 4370 is [True, False, False, False, True, False]
Current timestep = 4371. State = [[-0.30357355  0.05796486]]. Action = [[-0.03195978 -0.07438926  0.          0.8331313 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 4371 is [True, False, False, False, True, False]
Current timestep = 4372. State = [[-0.30707288  0.05967568]]. Action = [[-0.077783    0.07597255  0.         -0.24722499]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 4372 is [True, False, False, False, True, False]
Current timestep = 4373. State = [[-0.3130872   0.06155428]]. Action = [[-0.09214111 -0.01677722  0.          0.47537374]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 4373 is [True, False, False, False, True, False]
Current timestep = 4374. State = [[-0.31342998  0.06344333]]. Action = [[ 0.04684123  0.03159431  0.         -0.07837039]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 4374 is [True, False, False, False, True, False]
State prediction error at timestep 4374 is 0.012
Human Feedback received at timestep 4374 of None
Current timestep = 4375. State = [[-0.31039682  0.06491223]]. Action = [[3.6111377e-02 1.3495982e-04 0.0000000e+00 6.9877565e-01]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 4375 is [True, False, False, False, True, False]
Current timestep = 4376. State = [[-0.307946    0.06452519]]. Action = [[ 0.02394332 -0.01769351  0.          0.53389704]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 4376 is [True, False, False, False, True, False]
Current timestep = 4377. State = [[-0.30487072  0.06916822]]. Action = [[0.04606272 0.0975614  0.         0.9180021 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 4377 is [True, False, False, False, True, False]
Current timestep = 4378. State = [[-0.30280903  0.07230587]]. Action = [[ 0.01853494 -0.00126268  0.         -0.9874041 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 4378 is [True, False, False, False, True, False]
Current timestep = 4379. State = [[-0.2983      0.07568158]]. Action = [[0.08053573 0.05714706 0.         0.9609165 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 4379 is [True, False, False, False, True, False]
Current timestep = 4380. State = [[-0.29572114  0.08192635]]. Action = [[0.00855025 0.08353709 0.         0.45483673]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 4380 is [True, False, False, False, True, False]
Current timestep = 4381. State = [[-0.2976739   0.08890201]]. Action = [[-0.04267928  0.07326215  0.         -0.21603   ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 4381 is [True, False, False, False, True, False]
Current timestep = 4382. State = [[-0.29947123  0.0957845 ]]. Action = [[-0.00483448  0.06748297  0.         -0.78591454]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 4382 is [True, False, False, False, True, False]
Current timestep = 4383. State = [[-0.3039505   0.10050604]]. Action = [[-0.07865004  0.0200658   0.         -0.6730823 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 4383 is [True, False, False, False, True, False]
Current timestep = 4384. State = [[-0.3053204   0.10639149]]. Action = [[0.02909384 0.06596201 0.         0.11140454]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 4384 is [True, False, False, False, True, False]
State prediction error at timestep 4384 is 0.012
Human Feedback received at timestep 4384 of None
Current timestep = 4385. State = [[-0.30207962  0.11134984]]. Action = [[0.06489374 0.02508795 0.         0.4763553 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 4385 is [True, False, False, False, True, False]
Current timestep = 4386. State = [[-0.3016002   0.11098975]]. Action = [[-0.0263804  -0.05937597  0.         -0.88082904]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 4386 is [True, False, False, False, True, False]
Current timestep = 4387. State = [[-0.29824975  0.10925695]]. Action = [[ 0.07519176 -0.03338686  0.         -0.05694747]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 4387 is [True, False, False, False, True, False]
Current timestep = 4388. State = [[-0.29586986  0.11222494]]. Action = [[-0.00523444  0.05918791  0.          0.06995666]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 4388 is [True, False, False, False, True, False]
Current timestep = 4389. State = [[-0.29789734  0.11358488]]. Action = [[-0.05268458 -0.02998124  0.          0.49283338]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 4389 is [True, False, False, False, True, False]
Current timestep = 4390. State = [[-0.2946795   0.11464705]]. Action = [[ 0.08439448  0.01763481  0.         -0.7985157 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 4390 is [True, False, False, False, True, False]
State prediction error at timestep 4390 is 0.012
Human Feedback received at timestep 4390 of None
Current timestep = 4391. State = [[-0.29485628  0.11531746]]. Action = [[-0.07482153 -0.01304945  0.         -0.5020809 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 4391 is [True, False, False, False, True, False]
State prediction error at timestep 4391 is 0.012
Human Feedback received at timestep 4391 of None
Current timestep = 4392. State = [[-0.29421008  0.11214273]]. Action = [[ 0.03466444 -0.07310872  0.         -0.5542712 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 4392 is [True, False, False, False, True, False]
State prediction error at timestep 4392 is 0.012
Human Feedback received at timestep 4392 of None
Current timestep = 4393. State = [[-0.29649034  0.10989199]]. Action = [[-0.08529614 -0.01203146  0.          0.7321763 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 4393 is [True, False, False, False, True, False]
Current timestep = 4394. State = [[-0.29839507  0.11077765]]. Action = [[-0.00503874  0.01812339  0.         -0.95968896]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 4394 is [True, False, False, False, True, False]
State prediction error at timestep 4394 is 0.012
Human Feedback received at timestep 4394 of None
Current timestep = 4395. State = [[-0.29478237  0.1091831 ]]. Action = [[ 0.07306708 -0.04229424  0.          0.46984386]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 4395 is [True, False, False, False, True, False]
State prediction error at timestep 4395 is 0.012
Human Feedback received at timestep 4395 of None
Current timestep = 4396. State = [[-0.29608655  0.1083891 ]]. Action = [[-0.07665759  0.01358619  0.         -0.909949  ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 4396 is [True, False, False, False, True, False]
Current timestep = 4397. State = [[-0.29768464  0.10726584]]. Action = [[ 0.00743197 -0.02679064  0.          0.77415967]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 4397 is [True, False, False, False, True, False]
Current timestep = 4398. State = [[-0.29556826  0.1104541 ]]. Action = [[0.04672941 0.08812898 0.         0.67385316]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 4398 is [True, False, False, False, True, False]
Current timestep = 4399. State = [[-0.29565826  0.11223151]]. Action = [[-0.01687089 -0.00570687  0.          0.7728785 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 4399 is [True, False, False, False, True, False]
State prediction error at timestep 4399 is 0.012
Human Feedback received at timestep 4399 of None
Current timestep = 4400. State = [[-0.2967815   0.10750248]]. Action = [[-0.00982592 -0.09139704  0.         -0.48970604]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 4400 is [True, False, False, False, True, False]
State prediction error at timestep 4400 is 0.012
Human Feedback received at timestep 4400 of None
Current timestep = 4401. State = [[-0.29981175  0.10176435]]. Action = [[-0.05953819 -0.06022209  0.          0.15401208]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 4401 is [True, False, False, False, True, False]
Current timestep = 4402. State = [[-0.29680008  0.09731146]]. Action = [[ 0.09671628 -0.04105169  0.         -0.25384748]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 4402 is [True, False, False, False, True, False]
Current timestep = 4403. State = [[-0.2942861   0.09540989]]. Action = [[-0.01230965  0.00579909  0.         -0.9607331 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 4403 is [True, False, False, False, True, False]
Current timestep = 4404. State = [[-0.29309237  0.09435204]]. Action = [[ 0.01794972 -0.00683139  0.          0.56275773]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 4404 is [True, False, False, False, True, False]
Current timestep = 4405. State = [[-0.29343462  0.09499395]]. Action = [[-0.02515809  0.03279494  0.         -0.7664917 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 4405 is [True, False, False, False, True, False]
Current timestep = 4406. State = [[-0.2920385   0.09915931]]. Action = [[0.04350013 0.07831322 0.         0.9626868 ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 4406 is [True, False, False, False, True, False]
Current timestep = 4407. State = [[-0.29411495  0.10174754]]. Action = [[-0.06073033  0.01333787  0.          0.4012072 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 4407 is [True, False, False, False, True, False]
Current timestep = 4408. State = [[-0.29529426  0.10257453]]. Action = [[ 0.01931019  0.00695854  0.         -0.4218349 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 4408 is [True, False, False, False, True, False]
Current timestep = 4409. State = [[-0.29557467  0.10303921]]. Action = [[-0.00417799  0.0045075   0.          0.3471098 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 4409 is [True, False, False, False, True, False]
Current timestep = 4410. State = [[-0.29445264  0.10730842]]. Action = [[ 0.03807793  0.08133509  0.         -0.8956872 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 4410 is [True, False, False, False, True, False]
Current timestep = 4411. State = [[-0.29356936  0.10882135]]. Action = [[ 0.01126678 -0.02055029  0.          0.45121694]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 4411 is [True, False, False, False, True, False]
State prediction error at timestep 4411 is 0.012
Human Feedback received at timestep 4411 of None
Current timestep = 4412. State = [[-0.29163626  0.11078012]]. Action = [[0.04055399 0.04320144 0.         0.91184115]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 4412 is [True, False, False, False, True, False]
Current timestep = 4413. State = [[-0.2868569   0.10919921]]. Action = [[ 0.0774452  -0.06064288  0.         -0.27369094]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 4413 is [True, False, False, False, True, False]
State prediction error at timestep 4413 is 0.012
Human Feedback received at timestep 4413 of None
Current timestep = 4414. State = [[-0.28874367  0.10976518]]. Action = [[-0.09373847  0.03961904  0.         -0.36178935]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 4414 is [True, False, False, False, True, False]
Current timestep = 4415. State = [[-0.29065788  0.10809315]]. Action = [[ 0.00578402 -0.06888536  0.         -0.536415  ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 4415 is [True, False, False, False, True, False]
State prediction error at timestep 4415 is 0.012
Human Feedback received at timestep 4415 of None
Current timestep = 4416. State = [[-0.29372     0.11135813]]. Action = [[-0.06752185  0.09535193  0.          0.73572755]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 4416 is [True, False, False, False, True, False]
Current timestep = 4417. State = [[-0.29762056  0.11866041]]. Action = [[-0.03174783  0.07760925  0.         -0.855019  ]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 4417 is [True, False, False, False, True, False]
Current timestep = 4418. State = [[-0.29688     0.12184051]]. Action = [[ 0.0516357  -0.00114687  0.         -0.14910543]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 4418 is [True, False, False, False, True, False]
Current timestep = 4419. State = [[-0.29882026  0.12424741]]. Action = [[-0.05549501  0.03019118  0.         -0.5059366 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 4419 is [True, False, False, False, True, False]
State prediction error at timestep 4419 is 0.012
Human Feedback received at timestep 4419 of None
Current timestep = 4420. State = [[-0.3023925   0.12485035]]. Action = [[-0.03141577 -0.02804     0.         -0.6058234 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 4420 is [True, False, False, False, True, False]
Current timestep = 4421. State = [[-0.3072867   0.12599422]]. Action = [[-0.07064671  0.01404025  0.          0.97666264]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 4421 is [True, False, False, False, True, False]
State prediction error at timestep 4421 is 0.012
Human Feedback received at timestep 4421 of None
Current timestep = 4422. State = [[-0.30985853  0.13222167]]. Action = [[0.00852784 0.09625547 0.         0.49169695]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 4422 is [True, False, False, False, False, True]
Current timestep = 4423. State = [[-0.31391165  0.14083055]]. Action = [[-0.05553851  0.09735339  0.         -0.62014365]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 4423 is [True, False, False, False, False, True]
Current timestep = 4424. State = [[-0.31527892  0.14851043]]. Action = [[ 0.04106142  0.07333552  0.         -0.27880865]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 4424 is [True, False, False, False, False, True]
Current timestep = 4425. State = [[-0.31770647  0.14817636]]. Action = [[-0.0441432  -0.07865033  0.         -0.18690038]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 4425 is [True, False, False, False, False, True]
State prediction error at timestep 4425 is 0.012
Human Feedback received at timestep 4425 of None
Current timestep = 4426. State = [[-0.31935018  0.1449594 ]]. Action = [[ 0.01279312 -0.04761493  0.          0.7374344 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 4426 is [True, False, False, False, False, True]
Current timestep = 4427. State = [[-0.32362887  0.14691485]]. Action = [[-0.07337613  0.05026364  0.          0.8829675 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 4427 is [True, False, False, False, False, True]
Current timestep = 4428. State = [[-0.32589597  0.1519774 ]]. Action = [[ 0.02243192  0.05584588  0.         -0.18265265]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 4428 is [True, False, False, False, False, True]
Current timestep = 4429. State = [[-0.32759628  0.15699062]]. Action = [[-0.01613668  0.05395781  0.         -0.30821776]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 4429 is [True, False, False, False, False, True]
Current timestep = 4430. State = [[-0.32484066  0.16021171]]. Action = [[ 0.09168907  0.0219093   0.         -0.7307177 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 4430 is [True, False, False, False, False, True]
Current timestep = 4431. State = [[-0.3273553   0.15880348]]. Action = [[-0.09745042 -0.06005781  0.         -0.91473407]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 4431 is [True, False, False, False, False, True]
Current timestep = 4432. State = [[-0.33430612  0.15434584]]. Action = [[-0.06957165 -0.07358126  0.         -0.44110787]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 4432 is [True, False, False, False, False, True]
Current timestep = 4433. State = [[-0.33448753  0.1531805 ]]. Action = [[ 0.06409312  0.0158391   0.         -0.9436776 ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 4433 is [True, False, False, False, False, True]
Current timestep = 4434. State = [[-0.32887724  0.14887631]]. Action = [[ 0.08758786 -0.08814152  0.          0.5547898 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 4434 is [True, False, False, False, False, True]
Current timestep = 4435. State = [[-0.32876348  0.14140056]]. Action = [[-0.06170304 -0.09433053  0.         -0.1394136 ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 4435 is [True, False, False, False, False, True]
State prediction error at timestep 4435 is 0.012
Human Feedback received at timestep 4435 of None
Current timestep = 4436. State = [[-0.32828486  0.13373972]]. Action = [[ 0.02863672 -0.08975074  0.         -0.9120833 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 4436 is [True, False, False, False, False, True]
Current timestep = 4437. State = [[-0.32509354  0.13405114]]. Action = [[ 0.03933316  0.08736669  0.         -0.6214035 ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 4437 is [True, False, False, False, False, True]
Current timestep = 4438. State = [[-0.32350028  0.13233799]]. Action = [[ 0.00155805 -0.05510575  0.         -0.5437629 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 4438 is [True, False, False, False, False, True]
Current timestep = 4439. State = [[-0.3215513   0.12570266]]. Action = [[ 0.02464868 -0.07977717  0.         -0.09071767]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 4439 is [True, False, False, False, False, True]
Current timestep = 4440. State = [[-0.32305264  0.12647201]]. Action = [[-0.05632967  0.09311574  0.         -0.49475324]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 4440 is [True, False, False, False, False, True]
State prediction error at timestep 4440 is 0.012
Human Feedback received at timestep 4440 of None
Current timestep = 4441. State = [[-0.32197848  0.13106729]]. Action = [[0.05798829 0.06349847 0.         0.40811598]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 4441 is [True, False, False, False, False, True]
Current timestep = 4442. State = [[-0.32112536  0.1294768 ]]. Action = [[-0.00961033 -0.05258768  0.          0.5951741 ]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 4442 is [True, False, False, False, False, True]
Current timestep = 4443. State = [[-0.32100937  0.12805139]]. Action = [[ 0.00800677  0.01365447  0.         -0.6819753 ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 4443 is [True, False, False, False, False, True]
State prediction error at timestep 4443 is 0.012
Human Feedback received at timestep 4443 of None
Current timestep = 4444. State = [[-0.31794906  0.12586822]]. Action = [[ 0.06010107 -0.03625358  0.         -0.23890728]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 4444 is [True, False, False, False, False, True]
State prediction error at timestep 4444 is 0.012
Human Feedback received at timestep 4444 of None
Current timestep = 4445. State = [[-0.31951004  0.12161095]]. Action = [[-0.07428042 -0.05528164  0.          0.25522614]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 4445 is [True, False, False, False, False, True]
Current timestep = 4446. State = [[-0.3221104   0.11559985]]. Action = [[-0.01934033 -0.08387977  0.          0.62710786]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 4446 is [True, False, False, False, True, False]
Current timestep = 4447. State = [[-0.32659557  0.10983881]]. Action = [[-0.0867837  -0.06033653  0.          0.05472624]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 4447 is [True, False, False, False, True, False]
State prediction error at timestep 4447 is 0.012
Human Feedback received at timestep 4447 of None
Current timestep = 4448. State = [[-0.32505888  0.11146757]]. Action = [[ 0.09589436  0.08897545  0.         -0.36361575]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 4448 is [True, False, False, False, True, False]
Current timestep = 4449. State = [[-0.32129502  0.11772691]]. Action = [[0.02306509 0.09214171 0.         0.10713065]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 4449 is [True, False, False, False, True, False]
State prediction error at timestep 4449 is 0.012
Human Feedback received at timestep 4449 of None
Current timestep = 4450. State = [[-0.31951335  0.12137099]]. Action = [[ 0.0196759   0.02540971  0.         -0.08466232]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 4450 is [True, False, False, False, True, False]
Current timestep = 4451. State = [[-0.31949374  0.12300027]]. Action = [[-0.01368047  0.01612346  0.          0.48106766]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 4451 is [True, False, False, False, True, False]
State prediction error at timestep 4451 is 0.012
Human Feedback received at timestep 4451 of None
Current timestep = 4452. State = [[-0.3151784   0.12770891]]. Action = [[0.09959035 0.08473205 0.         0.34041584]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 4452 is [True, False, False, False, True, False]
State prediction error at timestep 4452 is 0.012
Human Feedback received at timestep 4452 of None
Current timestep = 4453. State = [[-0.30818847  0.13263136]]. Action = [[0.08754455 0.05179129 0.         0.20827675]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 4453 is [True, False, False, False, False, True]
Current timestep = 4454. State = [[-0.3009031   0.13693851]]. Action = [[0.08902503 0.05374656 0.         0.5436039 ]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 4454 is [True, False, False, False, False, True]
Current timestep = 4455. State = [[-0.29906145  0.13708128]]. Action = [[-0.03771071 -0.04333121  0.          0.5260787 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 4455 is [True, False, False, False, False, True]
Current timestep = 4456. State = [[-0.29523712  0.13694246]]. Action = [[0.0799639  0.00357194 0.         0.89128935]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 4456 is [True, False, False, False, False, True]
Current timestep = 4457. State = [[-0.28786314  0.13730896]]. Action = [[ 0.08083998 -0.00506565  0.         -0.3346436 ]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 4457 is [True, False, False, False, False, True]
State prediction error at timestep 4457 is 0.012
Human Feedback received at timestep 4457 of None
Current timestep = 4458. State = [[-0.28556618  0.14152102]]. Action = [[-0.03145225  0.07600465  0.          0.91521776]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 4458 is [True, False, False, False, False, True]
State prediction error at timestep 4458 is 0.012
Human Feedback received at timestep 4458 of None
Current timestep = 4459. State = [[-0.28235543  0.14414673]]. Action = [[ 0.05269323 -0.00970522  0.         -0.6117785 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 4459 is [True, False, False, False, False, True]
State prediction error at timestep 4459 is 0.012
Human Feedback received at timestep 4459 of None
Current timestep = 4460. State = [[-0.27598932  0.14756063]]. Action = [[ 0.06890007  0.05688664  0.         -0.5523713 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 4460 is [True, False, False, False, False, True]
Current timestep = 4461. State = [[-0.2760908   0.15498139]]. Action = [[-0.07155716  0.09950655  0.          0.70018244]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 4461 is [True, False, False, False, False, True]
Current timestep = 4462. State = [[-0.2787755   0.15827684]]. Action = [[-0.03740776 -0.02406695  0.         -0.25825572]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 4462 is [True, False, False, False, False, True]
Current timestep = 4463. State = [[-0.2784185   0.15589204]]. Action = [[ 0.00657678 -0.07402861  0.         -0.31617236]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 4463 is [True, False, False, False, False, True]
Current timestep = 4464. State = [[-0.27660114  0.15304478]]. Action = [[ 0.00597169 -0.04497043  0.          0.8658644 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 4464 is [True, False, False, False, False, True]
State prediction error at timestep 4464 is 0.012
Human Feedback received at timestep 4464 of None
Current timestep = 4465. State = [[-0.27410728  0.15588559]]. Action = [[ 0.02270553  0.06415784  0.         -0.44775045]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 4465 is [True, False, False, False, False, True]
Current timestep = 4466. State = [[-0.2716881   0.16290814]]. Action = [[ 0.02378418  0.0915136   0.         -0.00883609]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 4466 is [True, False, False, False, False, True]
Current timestep = 4467. State = [[-0.27293977  0.1692772 ]]. Action = [[-0.04375749  0.05736921  0.         -0.37736362]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 4467 is [True, False, False, False, False, True]
Current timestep = 4468. State = [[-0.27360028  0.16897906]]. Action = [[ 0.00742928 -0.06603224  0.          0.781911  ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 4468 is [True, False, False, False, False, True]
State prediction error at timestep 4468 is 0.012
Human Feedback received at timestep 4468 of None
Current timestep = 4469. State = [[-0.27133805  0.17042539]]. Action = [[ 0.03563114  0.04548939  0.         -0.63379955]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 4469 is [True, False, False, False, False, True]
State prediction error at timestep 4469 is 0.012
Human Feedback received at timestep 4469 of None
Current timestep = 4470. State = [[-0.274841    0.17684045]]. Action = [[-0.0926718   0.08658909  0.          0.82152355]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 4470 is [True, False, False, False, False, True]
Current timestep = 4471. State = [[-0.275994    0.18183124]]. Action = [[0.03771643 0.02501038 0.         0.743806  ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 4471 is [True, False, False, False, False, True]
Current timestep = 4472. State = [[-0.27105406  0.1796337 ]]. Action = [[ 0.08710802 -0.07898952  0.         -0.16020048]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 4472 is [True, False, False, False, False, True]
Current timestep = 4473. State = [[-0.2670821   0.17442422]]. Action = [[ 0.01949425 -0.07208335  0.          0.4027574 ]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 4473 is [True, False, False, False, False, True]
Current timestep = 4474. State = [[-0.26788482  0.17490572]]. Action = [[-0.0462428   0.04389413  0.          0.53447413]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 4474 is [True, False, False, False, False, True]
Current timestep = 4475. State = [[-0.2687123   0.17432885]]. Action = [[-0.0029959  -0.04748591  0.          0.99157834]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 4475 is [True, False, False, False, False, True]
State prediction error at timestep 4475 is 0.012
Human Feedback received at timestep 4475 of None
Current timestep = 4476. State = [[-0.26538765  0.17709439]]. Action = [[ 0.06259523  0.07882278  0.         -0.547939  ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 4476 is [True, False, False, False, False, True]
Current timestep = 4477. State = [[-0.26593557  0.17795569]]. Action = [[-0.06071037 -0.03200609  0.          0.91457605]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 4477 is [True, False, False, False, False, True]
Current timestep = 4478. State = [[-0.26269078  0.17762941]]. Action = [[ 0.09797678  0.00971331  0.         -0.6858098 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 4478 is [True, False, False, False, False, True]
State prediction error at timestep 4478 is 0.012
Human Feedback received at timestep 4478 of None
Current timestep = 4479. State = [[-0.25844127  0.17285717]]. Action = [[ 0.01690742 -0.0976301   0.         -0.4406222 ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 4479 is [True, False, False, False, False, True]
Current timestep = 4480. State = [[-0.25511235  0.1704506 ]]. Action = [[0.03469404 0.01416    0.         0.24146736]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 4480 is [True, False, False, False, False, True]
Current timestep = 4481. State = [[-0.25212094  0.1716625 ]]. Action = [[0.02304532 0.03164711 0.         0.29230392]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 4481 is [True, False, False, False, False, True]
Current timestep = 4482. State = [[-0.25294253  0.17667045]]. Action = [[-0.04259701  0.09256309  0.         -0.17927378]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 4482 is [True, False, False, False, False, True]
Current timestep = 4483. State = [[-0.25272465  0.17647573]]. Action = [[ 0.02199997 -0.05682162  0.         -0.16345578]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 4483 is [True, False, False, False, False, True]
Current timestep = 4484. State = [[-0.24936394  0.17001434]]. Action = [[ 0.04184998 -0.0984937   0.          0.48205376]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 4484 is [True, False, False, False, False, True]
State prediction error at timestep 4484 is 0.012
Human Feedback received at timestep 4484 of None
Current timestep = 4485. State = [[-0.24614754  0.16394737]]. Action = [[ 0.01785018 -0.05700131  0.          0.35579228]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 4485 is [True, False, False, False, False, True]
State prediction error at timestep 4485 is 0.012
Human Feedback received at timestep 4485 of None
Current timestep = 4486. State = [[-0.24109691  0.16516735]]. Action = [[ 0.07234859  0.07732607  0.         -0.3501585 ]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 4486 is [True, False, False, False, False, True]
Current timestep = 4487. State = [[-0.24111679  0.16914947]]. Action = [[-0.05862144  0.05277561  0.          0.08915627]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 4487 is [True, False, False, False, False, True]
Current timestep = 4488. State = [[-0.24018309  0.16725734]]. Action = [[ 0.03978152 -0.06517208  0.         -0.74324393]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 4488 is [True, False, False, False, False, True]
Current timestep = 4489. State = [[-0.2341247   0.16286597]]. Action = [[ 0.08693957 -0.04093438  0.          0.09593117]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 4489 is [True, False, False, False, False, True]
Current timestep = 4490. State = [[-0.23058948  0.1563824 ]]. Action = [[-0.00210831 -0.08945767  0.          0.62560964]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 4490 is [True, False, False, False, False, True]
Current timestep = 4491. State = [[-0.22604166  0.15025102]]. Action = [[ 0.06240463 -0.05322585  0.          0.38946033]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 4491 is [True, False, False, False, False, True]
Current timestep = 4492. State = [[-0.22500603  0.14720307]]. Action = [[-0.0450602  -0.00590061  0.          0.9509523 ]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 4492 is [True, False, False, False, False, True]
State prediction error at timestep 4492 is 0.012
Human Feedback received at timestep 4492 of None
Current timestep = 4493. State = [[-0.22296484  0.14478192]]. Action = [[ 0.03891734 -0.02349234  0.         -0.87242657]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 4493 is [True, False, False, False, False, True]
State prediction error at timestep 4493 is 0.012
Human Feedback received at timestep 4493 of None
Current timestep = 4494. State = [[-0.21783842  0.14015892]]. Action = [[ 0.05900242 -0.05238952  0.         -0.18150282]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 4494 is [True, False, False, False, False, True]
Current timestep = 4495. State = [[-0.2126305   0.13597922]]. Action = [[ 0.04531022 -0.02130479  0.          0.45707905]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 4495 is [True, False, False, False, False, True]
Current timestep = 4496. State = [[-0.2121179   0.13742094]]. Action = [[-0.04015305  0.07308262  0.         -0.82471836]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 4496 is [True, False, False, False, False, True]
Current timestep = 4497. State = [[-0.21612647  0.13704579]]. Action = [[-0.0768275  -0.03268344  0.         -0.6246657 ]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 4497 is [True, False, False, False, False, True]
State prediction error at timestep 4497 is 0.012
Human Feedback received at timestep 4497 of None
Current timestep = 4498. State = [[-0.22135068  0.13239418]]. Action = [[-0.07721175 -0.07294599  0.          0.62717795]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 4498 is [True, False, False, False, False, True]
Current timestep = 4499. State = [[-0.22369559  0.13015272]]. Action = [[-0.00955805  0.00139292  0.         -0.47845364]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 4499 is [True, False, False, False, False, True]
Current timestep = 4500. State = [[-0.2288126  0.1348183]]. Action = [[-0.09036543  0.09957755  0.          0.19409132]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 4500 is [True, False, False, False, False, True]
State prediction error at timestep 4500 is 0.012
Human Feedback received at timestep 4500 of None
Current timestep = 4501. State = [[-0.23403534  0.14145963]]. Action = [[-0.02970158  0.07187783  0.         -0.15057945]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 4501 is [True, False, False, False, False, True]
State prediction error at timestep 4501 is 0.012
Human Feedback received at timestep 4501 of None
Current timestep = 4502. State = [[-0.24128817  0.14529552]]. Action = [[-0.09382442  0.02092595  0.         -0.3765416 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 4502 is [True, False, False, False, False, True]
Current timestep = 4503. State = [[-0.24493     0.14943695]]. Action = [[0.02281592 0.05350082 0.         0.22262025]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 4503 is [True, False, False, False, False, True]
Current timestep = 4504. State = [[-0.24940716  0.15097715]]. Action = [[-0.05961201 -0.01664377  0.         -0.5717944 ]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 4504 is [True, False, False, False, False, True]
State prediction error at timestep 4504 is 0.012
Human Feedback received at timestep 4504 of None
Current timestep = 4505. State = [[-0.25215203  0.15425952]]. Action = [[0.01968154 0.05755218 0.         0.63445973]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 4505 is [True, False, False, False, False, True]
Current timestep = 4506. State = [[-0.25823689  0.1554489 ]]. Action = [[-0.09576563 -0.02766696  0.         -0.9462577 ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 4506 is [True, False, False, False, False, True]
Current timestep = 4507. State = [[-0.2605219   0.15568416]]. Action = [[ 0.05177579  0.00370876  0.         -0.50230885]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 4507 is [True, False, False, False, False, True]
Current timestep = 4508. State = [[-0.25645956  0.15541115]]. Action = [[ 0.09199803 -0.01069497  0.          0.83902156]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 4508 is [True, False, False, False, False, True]
Current timestep = 4509. State = [[-0.2589485   0.15781087]]. Action = [[-0.08154742  0.05436454  0.          0.88481903]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 4509 is [True, False, False, False, False, True]
Current timestep = 4510. State = [[-0.2611226   0.16008008]]. Action = [[ 0.0262581   0.00908605  0.         -0.48926926]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 4510 is [True, False, False, False, False, True]
Current timestep = 4511. State = [[-0.26489934  0.16173844]]. Action = [[-0.06713952  0.02094116  0.          0.9230648 ]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 4511 is [True, False, False, False, False, True]
Current timestep = 4512. State = [[-0.26424384  0.16400093]]. Action = [[0.07430769 0.02720297 0.         0.69099057]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 4512 is [True, False, False, False, False, True]
Current timestep = 4513. State = [[-0.25859547  0.15992625]]. Action = [[ 0.08501933 -0.09770261  0.          0.76980627]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 4513 is [True, False, False, False, False, True]
Current timestep = 4514. State = [[-0.25357768  0.15837745]]. Action = [[ 0.04635208  0.03178906  0.         -0.79387337]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 4514 is [True, False, False, False, False, True]
Current timestep = 4515. State = [[-0.24779023  0.1548365 ]]. Action = [[ 0.0758679  -0.077962    0.         -0.60927397]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 4515 is [True, False, False, False, False, True]
State prediction error at timestep 4515 is 0.012
Human Feedback received at timestep 4515 of None
Current timestep = 4516. State = [[-0.24766372  0.15482722]]. Action = [[-0.0648382   0.05464857  0.          0.29048133]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 4516 is [True, False, False, False, False, True]
Current timestep = 4517. State = [[-0.24641     0.15171523]]. Action = [[ 0.03818763 -0.09086817  0.          0.9984238 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 4517 is [True, False, False, False, False, True]
State prediction error at timestep 4517 is 0.012
Human Feedback received at timestep 4517 of None
Current timestep = 4518. State = [[-0.24470177  0.15117909]]. Action = [[-0.00974729  0.04779587  0.         -0.46262383]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 4518 is [True, False, False, False, False, True]
Current timestep = 4519. State = [[-0.24150912  0.15672953]]. Action = [[ 0.05545343  0.0967155   0.         -0.4526453 ]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 4519 is [True, False, False, False, False, True]
State prediction error at timestep 4519 is 0.012
Human Feedback received at timestep 4519 of None
Current timestep = 4520. State = [[-0.24037024  0.15769018]]. Action = [[-0.02073296 -0.03192825  0.          0.72312415]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 4520 is [True, False, False, False, False, True]
Current timestep = 4521. State = [[-0.24351     0.15861338]]. Action = [[-0.06536374  0.03154074  0.          0.13030612]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 4521 is [True, False, False, False, False, True]
State prediction error at timestep 4521 is 0.012
Human Feedback received at timestep 4521 of None
Current timestep = 4522. State = [[-0.24453208  0.15975773]]. Action = [[ 0.01183239 -0.00301208  0.         -0.53002626]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 4522 is [True, False, False, False, False, True]
Current timestep = 4523. State = [[-0.24403203  0.15823318]]. Action = [[ 0.00087693 -0.03743643  0.          0.64581966]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 4523 is [True, False, False, False, False, True]
State prediction error at timestep 4523 is 0.012
Human Feedback received at timestep 4523 of None
Current timestep = 4524. State = [[-0.2395936   0.15985866]]. Action = [[0.08796207 0.05365669 0.         0.20935166]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 4524 is [True, False, False, False, False, True]
Current timestep = 4525. State = [[-0.23999031  0.1625381 ]]. Action = [[-0.0656613   0.02224734  0.         -0.9923777 ]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 4525 is [True, False, False, False, False, True]
Current timestep = 4526. State = [[-0.24621615  0.16135868]]. Action = [[-0.09404421 -0.05121996  0.         -0.26433188]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 4526 is [True, False, False, False, False, True]
Current timestep = 4527. State = [[-0.24604174  0.16063659]]. Action = [[0.06548726 0.00354852 0.         0.79441786]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 4527 is [True, False, False, False, False, True]
Current timestep = 4528. State = [[-0.23979285  0.15944985]]. Action = [[ 0.08834308 -0.02640671  0.         -0.9497853 ]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 4528 is [True, False, False, False, False, True]
Current timestep = 4529. State = [[-0.23510534  0.1609465 ]]. Action = [[0.03336731 0.05148653 0.         0.46327484]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 4529 is [True, False, False, False, False, True]
Current timestep = 4530. State = [[-0.23832683  0.16637243]]. Action = [[-0.09596147  0.07945599  0.         -0.45845735]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 4530 is [True, False, False, False, False, True]
Current timestep = 4531. State = [[-0.23875728  0.16604307]]. Action = [[ 0.04245352 -0.06595088  0.         -0.6364673 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 4531 is [True, False, False, False, False, True]
Current timestep = 4532. State = [[-0.2403971   0.16754887]]. Action = [[-0.05954095  0.0586498   0.          0.47729743]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 4532 is [True, False, False, False, False, True]
State prediction error at timestep 4532 is 0.012
Human Feedback received at timestep 4532 of None
Current timestep = 4533. State = [[-0.24239294  0.16554652]]. Action = [[-0.00928964 -0.08712456  0.          0.14888418]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 4533 is [True, False, False, False, False, True]
Current timestep = 4534. State = [[-0.24539648  0.16153164]]. Action = [[-0.06193104 -0.04742642  0.         -0.35642928]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 4534 is [True, False, False, False, False, True]
State prediction error at timestep 4534 is 0.012
Human Feedback received at timestep 4534 of None
Current timestep = 4535. State = [[-0.24587366  0.16220121]]. Action = [[ 0.02432762  0.03429557  0.         -0.96452415]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 4535 is [True, False, False, False, False, True]
Current timestep = 4536. State = [[-0.24918513  0.16201489]]. Action = [[-0.08045469 -0.02932677  0.         -0.35748065]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 4536 is [True, False, False, False, False, True]
Current timestep = 4537. State = [[-0.25311095  0.15766115]]. Action = [[-0.03243032 -0.08174437  0.          0.37554288]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 4537 is [True, False, False, False, False, True]
State prediction error at timestep 4537 is 0.012
Human Feedback received at timestep 4537 of None
Current timestep = 4538. State = [[-0.2497162  0.153691 ]]. Action = [[ 0.0968936  -0.02774614  0.         -0.94408566]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 4538 is [True, False, False, False, False, True]
Current timestep = 4539. State = [[-0.2507604   0.14888424]]. Action = [[-0.08565323 -0.07037488  0.         -0.4892465 ]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 4539 is [True, False, False, False, False, True]
State prediction error at timestep 4539 is 0.012
Human Feedback received at timestep 4539 of None
Current timestep = 4540. State = [[-0.24926566  0.1475964 ]]. Action = [[0.09028032 0.03627048 0.         0.39052558]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 4540 is [True, False, False, False, False, True]
Current timestep = 4541. State = [[-0.24392694  0.14252624]]. Action = [[ 0.05686367 -0.09542384  0.          0.9071739 ]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 4541 is [True, False, False, False, False, True]
Current timestep = 4542. State = [[-0.2396702   0.13362822]]. Action = [[ 0.03400446 -0.09731487  0.         -0.9853682 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 4542 is [True, False, False, False, False, True]
Current timestep = 4543. State = [[-0.24084564  0.12688045]]. Action = [[-0.07034484 -0.04940809  0.          0.42906094]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 4543 is [True, False, False, False, False, True]
Current timestep = 4544. State = [[-0.24646942  0.12649831]]. Action = [[-0.09587533  0.04655736  0.         -0.07347417]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 4544 is [True, False, False, False, False, True]
Current timestep = 4545. State = [[-0.24574675  0.13103312]]. Action = [[0.08269703 0.0936885  0.         0.13980293]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 4545 is [True, False, False, False, False, True]
Current timestep = 4546. State = [[-0.24136128  0.12977283]]. Action = [[ 0.04811873 -0.05652621  0.         -0.95504934]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 4546 is [True, False, False, False, False, True]
Current timestep = 4547. State = [[-0.23658013  0.13148397]]. Action = [[ 0.06521621  0.0888428   0.         -0.98024166]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 4547 is [True, False, False, False, False, True]
State prediction error at timestep 4547 is 0.012
Human Feedback received at timestep 4547 of None
Current timestep = 4548. State = [[-0.23132694  0.13483869]]. Action = [[ 0.07191371  0.0401243   0.         -0.89836985]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 4548 is [True, False, False, False, False, True]
State prediction error at timestep 4548 is 0.012
Human Feedback received at timestep 4548 of None
Current timestep = 4549. State = [[-0.23329918  0.13291465]]. Action = [[-0.0984717 -0.0584165  0.        -0.8417218]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 4549 is [True, False, False, False, False, True]
Current timestep = 4550. State = [[-0.24039203  0.13007234]]. Action = [[-0.08946182 -0.02642644  0.          0.39936948]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 4550 is [True, False, False, False, False, True]
Current timestep = 4551. State = [[-0.24084893  0.12853953]]. Action = [[ 0.05796411 -0.01293691  0.          0.8210058 ]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 4551 is [True, False, False, False, False, True]
Current timestep = 4552. State = [[-0.24232475  0.12861182]]. Action = [[-0.05387894  0.01347204  0.          0.88193583]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 4552 is [True, False, False, False, False, True]
State prediction error at timestep 4552 is 0.012
Human Feedback received at timestep 4552 of None
Current timestep = 4553. State = [[-0.23972917  0.12955761]]. Action = [[0.09373515 0.01558323 0.         0.5136726 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 4553 is [True, False, False, False, False, True]
Current timestep = 4554. State = [[-0.23786761  0.13447334]]. Action = [[-0.00562739  0.09730097  0.          0.26572   ]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 4554 is [True, False, False, False, False, True]
Current timestep = 4555. State = [[-0.24252386  0.13813648]]. Action = [[-0.08666099  0.01267286  0.          0.6992402 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 4555 is [True, False, False, False, False, True]
State prediction error at timestep 4555 is 0.012
Human Feedback received at timestep 4555 of None
Current timestep = 4556. State = [[-0.2430635   0.13764387]]. Action = [[ 0.04841679 -0.03223976  0.          0.90128684]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 4556 is [True, False, False, False, False, True]
Current timestep = 4557. State = [[-0.24507569  0.13800615]]. Action = [[-0.06018682  0.01548819  0.          0.6064677 ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 4557 is [True, False, False, False, False, True]
State prediction error at timestep 4557 is 0.012
Human Feedback received at timestep 4557 of None
Current timestep = 4558. State = [[-0.24564779  0.1351723 ]]. Action = [[ 0.02484785 -0.07855433  0.          0.0075978 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 4558 is [True, False, False, False, False, True]
Current timestep = 4559. State = [[-0.24133138  0.13173467]]. Action = [[ 0.07347212 -0.02743683  0.         -0.10042369]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 4559 is [True, False, False, False, False, True]
State prediction error at timestep 4559 is 0.012
Human Feedback received at timestep 4559 of None
Current timestep = 4560. State = [[-0.24122165  0.13231996]]. Action = [[-0.04520011  0.03388362  0.         -0.49164295]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 4560 is [True, False, False, False, False, True]
Current timestep = 4561. State = [[-0.23972689  0.13370891]]. Action = [[ 0.05232015  0.01108699  0.         -0.5761923 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 4561 is [True, False, False, False, False, True]
Current timestep = 4562. State = [[-0.24157308  0.13771135]]. Action = [[-0.06605086  0.07562942  0.          0.3804407 ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 4562 is [True, False, False, False, False, True]
State prediction error at timestep 4562 is 0.012
Human Feedback received at timestep 4562 of None
Current timestep = 4563. State = [[-0.24568406  0.13995506]]. Action = [[-0.04280874 -0.00655112  0.          0.19600022]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 4563 is [True, False, False, False, False, True]
Current timestep = 4564. State = [[-0.24337938  0.1420856 ]]. Action = [[0.08400967 0.03866314 0.         0.84082294]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 4564 is [True, False, False, False, False, True]
Current timestep = 4565. State = [[-0.2412681   0.14468275]]. Action = [[ 0.00131178  0.0270199   0.         -0.18490529]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 4565 is [True, False, False, False, False, True]
Current timestep = 4566. State = [[-0.24114716  0.14867114]]. Action = [[0.00273933 0.05544656 0.         0.32549715]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 4566 is [True, False, False, False, False, True]
Current timestep = 4567. State = [[-0.24609305  0.15413217]]. Action = [[-0.095991    0.06151225  0.         -0.19524896]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 4567 is [True, False, False, False, False, True]
Current timestep = 4568. State = [[-0.2509719   0.15689942]]. Action = [[-0.03417121 -0.00842722  0.          0.10279059]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 4568 is [True, False, False, False, False, True]
State prediction error at timestep 4568 is 0.012
Human Feedback received at timestep 4568 of None
Current timestep = 4569. State = [[-0.24842124  0.15536867]]. Action = [[ 0.08443519 -0.05182643  0.         -0.77540934]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 4569 is [True, False, False, False, False, True]
State prediction error at timestep 4569 is 0.012
Human Feedback received at timestep 4569 of None
Current timestep = 4570. State = [[-0.24436547  0.15626852]]. Action = [[ 0.03966125  0.03669941  0.         -0.02487653]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 4570 is [True, False, False, False, False, True]
Current timestep = 4571. State = [[-0.24201398  0.15631528]]. Action = [[ 0.02161898 -0.02837248  0.         -0.31425452]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 4571 is [True, False, False, False, False, True]
Current timestep = 4572. State = [[-0.23871757  0.15191078]]. Action = [[ 0.04246803 -0.0812361   0.         -0.06223631]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 4572 is [True, False, False, False, False, True]
State prediction error at timestep 4572 is 0.012
Human Feedback received at timestep 4572 of None
Current timestep = 4573. State = [[-0.23893051  0.14923118]]. Action = [[-0.0493     -0.01040962  0.         -0.668296  ]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 4573 is [True, False, False, False, False, True]
Current timestep = 4574. State = [[-0.23569635  0.15095556]]. Action = [[0.07937054 0.04468029 0.         0.36329436]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 4574 is [True, False, False, False, False, True]
Current timestep = 4575. State = [[-0.23554862  0.1498169 ]]. Action = [[-0.06631706 -0.04920304  0.          0.42055857]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 4575 is [True, False, False, False, False, True]
Current timestep = 4576. State = [[-0.23423386  0.15082082]]. Action = [[ 0.05289952  0.05095128  0.         -0.80476576]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 4576 is [True, False, False, False, False, True]
Current timestep = 4577. State = [[-0.23069365  0.15424956]]. Action = [[0.03552201 0.04806542 0.         0.40925217]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 4577 is [True, False, False, False, False, True]
Current timestep = 4578. State = [[-0.22956313  0.1513206 ]]. Action = [[-0.0108655  -0.08584814  0.         -0.58174896]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 4578 is [True, False, False, False, False, True]
Current timestep = 4579. State = [[-0.22911906  0.14684507]]. Action = [[-0.00393543 -0.0419131   0.          0.13418746]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 4579 is [True, False, False, False, False, True]
Current timestep = 4580. State = [[-0.23198768  0.14671642]]. Action = [[-0.07326071  0.02439539  0.         -0.06255728]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 4580 is [True, False, False, False, False, True]
Current timestep = 4581. State = [[-0.23164007  0.14459924]]. Action = [[ 0.03802731 -0.05722448  0.          0.11093092]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 4581 is [True, False, False, False, False, True]
Current timestep = 4582. State = [[-0.23472495  0.14754954]]. Action = [[-0.08860832  0.09629946  0.         -0.45461118]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 4582 is [True, False, False, False, False, True]
Current timestep = 4583. State = [[-0.24170296  0.1536081 ]]. Action = [[-0.08298908  0.05928164  0.          0.31479645]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 4583 is [True, False, False, False, False, True]
Current timestep = 4584. State = [[-0.24524342  0.15367538]]. Action = [[-0.00423866 -0.05109724  0.         -0.29306906]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 4584 is [True, False, False, False, False, True]
Current timestep = 4585. State = [[-0.24410689  0.1568789 ]]. Action = [[ 0.05091409  0.08477662  0.         -0.8915175 ]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 4585 is [True, False, False, False, False, True]
State prediction error at timestep 4585 is 0.012
Human Feedback received at timestep 4585 of None
Current timestep = 4586. State = [[-0.24370342  0.15733717]]. Action = [[ 0.00190149 -0.04305861  0.         -0.39488804]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 4586 is [True, False, False, False, False, True]
Current timestep = 4587. State = [[-0.24166898  0.15573664]]. Action = [[ 0.05302951 -0.01350588  0.          0.04135394]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 4587 is [True, False, False, False, False, True]
Current timestep = 4588. State = [[-0.23831098  0.15333912]]. Action = [[ 0.04581984 -0.03618943  0.          0.72162604]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 4588 is [True, False, False, False, False, True]
Current timestep = 4589. State = [[-0.23892649  0.1565466 ]]. Action = [[-0.0364099   0.09184026  0.          0.06101656]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 4589 is [True, False, False, False, False, True]
Current timestep = 4590. State = [[-0.23589197  0.15639308]]. Action = [[ 0.08723547 -0.05375756  0.          0.03129768]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 4590 is [True, False, False, False, False, True]
Current timestep = 4591. State = [[-0.22860348  0.15101492]]. Action = [[ 0.09318402 -0.06955999  0.         -0.5597247 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 4591 is [True, False, False, False, False, True]
Current timestep = 4592. State = [[-0.22416417  0.14690827]]. Action = [[ 0.01512579 -0.02570999  0.         -0.2774999 ]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 4592 is [True, False, False, False, False, True]
Current timestep = 4593. State = [[-0.22003014  0.14890985]]. Action = [[ 0.05113835  0.07423367  0.         -0.8266041 ]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 4593 is [True, False, False, False, False, True]
Current timestep = 4594. State = [[-0.22160497  0.15259384]]. Action = [[-0.08307512  0.04361849  0.          0.02394772]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 4594 is [True, False, False, False, False, True]
Current timestep = 4595. State = [[-0.22328371  0.15820622]]. Action = [[ 0.00362234  0.08701832  0.         -0.22064668]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 4595 is [True, False, False, False, False, True]
Current timestep = 4596. State = [[-0.21850765  0.16019881]]. Action = [[ 0.09805959 -0.01060165  0.          0.10523748]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 4596 is [True, False, False, False, False, True]
Current timestep = 4597. State = [[-0.21354139  0.15627319]]. Action = [[ 0.03538605 -0.07316894  0.          0.64172935]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 4597 is [True, False, False, False, False, True]
Current timestep = 4598. State = [[-0.2131643   0.15329923]]. Action = [[-0.03661778 -0.02000075  0.          0.08633399]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 4598 is [True, False, False, False, False, True]
Current timestep = 4599. State = [[-0.21692088  0.1489175 ]]. Action = [[-0.08414306 -0.08601101  0.          0.025105  ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 4599 is [True, False, False, False, False, True]
State prediction error at timestep 4599 is 0.012
Human Feedback received at timestep 4599 of None
Current timestep = 4600. State = [[-0.21628197  0.14282227]]. Action = [[ 0.03443304 -0.08278621  0.         -0.82177144]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 4600 is [True, False, False, False, False, True]
Current timestep = 4601. State = [[-0.21451537  0.13633087]]. Action = [[-0.01105847 -0.07767554  0.         -0.02919799]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 4601 is [True, False, False, False, False, True]
State prediction error at timestep 4601 is 0.012
Human Feedback received at timestep 4601 of None
Current timestep = 4602. State = [[-0.20907639  0.13456224]]. Action = [[ 0.09451684  0.02815155  0.         -0.42911947]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 4602 is [True, False, False, False, False, True]
Current timestep = 4603. State = [[-0.20222121  0.13178602]]. Action = [[ 0.06241373 -0.04397108  0.          0.8950112 ]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 4603 is [True, False, False, False, False, True]
Current timestep = 4604. State = [[-0.1981595   0.13342671]]. Action = [[ 0.02019066  0.08654282  0.         -0.41952825]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 4604 is [True, False, False, False, False, True]
Current timestep = 4605. State = [[-0.1994196   0.13877916]]. Action = [[-0.05317178  0.07934263  0.          0.13964593]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 4605 is [True, False, False, False, False, True]
Current timestep = 4606. State = [[-0.20230046  0.14278868]]. Action = [[-0.03524446  0.03737963  0.         -0.7759716 ]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 4606 is [True, False, False, False, False, True]
Current timestep = 4607. State = [[-0.20414029  0.1424676 ]]. Action = [[-0.01843706 -0.03506435  0.         -0.63764364]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 4607 is [True, False, False, False, False, True]
Current timestep = 4608. State = [[-0.20034575  0.13817787]]. Action = [[ 0.08496725 -0.07024745  0.         -0.8763411 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 4608 is [True, False, False, False, False, True]
State prediction error at timestep 4608 is 0.012
Human Feedback received at timestep 4608 of None
Current timestep = 4609. State = [[-0.1959577   0.14058515]]. Action = [[0.03835649 0.09906321 0.         0.0955236 ]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 4609 is [True, False, False, False, False, True]
State prediction error at timestep 4609 is 0.012
Human Feedback received at timestep 4609 of None
Current timestep = 4610. State = [[-0.1965533   0.13853592]]. Action = [[-0.04544817 -0.09863606  0.         -0.04755723]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 4610 is [True, False, False, False, False, True]
Current timestep = 4611. State = [[-0.19797984  0.13592167]]. Action = [[-0.01007692 -0.00142387  0.          0.6118288 ]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 4611 is [True, False, False, False, False, True]
State prediction error at timestep 4611 is 0.012
Human Feedback received at timestep 4611 of None
Current timestep = 4612. State = [[-0.19636086  0.13160503]]. Action = [[ 0.03588843 -0.08122308  0.          0.28987157]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 4612 is [True, False, False, False, False, True]
Current timestep = 4613. State = [[-0.1959521   0.12665544]]. Action = [[-0.02282877 -0.04449108  0.          0.78096485]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 4613 is [True, False, False, False, False, True]
Current timestep = 4614. State = [[-0.19266988  0.12726721]]. Action = [[0.07281391 0.05530327 0.         0.2751708 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 4614 is [True, False, False, False, False, True]
State prediction error at timestep 4614 is 0.012
Human Feedback received at timestep 4614 of None
Current timestep = 4615. State = [[-0.19284466  0.13268235]]. Action = [[-0.04711381  0.09436531  0.          0.4406849 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 4615 is [True, False, False, False, False, True]
Current timestep = 4616. State = [[-0.19478807  0.13841255]]. Action = [[-0.0089097   0.06374522  0.         -0.9236261 ]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 4616 is [True, False, False, False, False, True]
State prediction error at timestep 4616 is 0.012
Human Feedback received at timestep 4616 of None
Current timestep = 4617. State = [[-0.1978809   0.14026031]]. Action = [[-0.04815061 -0.00748583  0.          0.6225084 ]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 4617 is [True, False, False, False, False, True]
Current timestep = 4618. State = [[-0.2007804   0.13883483]]. Action = [[-0.02663686 -0.03918461  0.          0.6978185 ]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 4618 is [True, False, False, False, False, True]
Current timestep = 4619. State = [[-0.20128456  0.13642444]]. Action = [[ 0.00851341 -0.03767423  0.         -0.14474392]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 4619 is [True, False, False, False, False, True]
Current timestep = 4620. State = [[-0.20010957  0.13620962]]. Action = [[0.02246924 0.01317082 0.         0.7110553 ]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 4620 is [True, False, False, False, False, True]
Current timestep = 4621. State = [[-0.19738561  0.13413134]]. Action = [[ 0.04504832 -0.04799209  0.         -0.32320893]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 4621 is [True, False, False, False, False, True]
Current timestep = 4622. State = [[-0.19507976  0.13660082]]. Action = [[0.02155592 0.08381362 0.         0.08939219]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 4622 is [True, False, False, False, False, True]
State prediction error at timestep 4622 is 0.012
Human Feedback received at timestep 4622 of None
Current timestep = 4623. State = [[-0.19497503  0.13772783]]. Action = [[-0.00763816 -0.0208213   0.         -0.46048772]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 4623 is [True, False, False, False, False, True]
Current timestep = 4624. State = [[-0.19672832  0.13917273]]. Action = [[-0.0321616  0.0377342  0.        -0.0535593]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 4624 is [True, False, False, False, False, True]
Current timestep = 4625. State = [[-0.19904776  0.1436494 ]]. Action = [[-0.02419163  0.06332584  0.         -0.25892556]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 4625 is [True, False, False, False, False, True]
Current timestep = 4626. State = [[-0.20155539  0.1447664 ]]. Action = [[-0.02854645 -0.02650778  0.          0.63939834]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 4626 is [True, False, False, False, False, True]
Current timestep = 4627. State = [[-0.19841406  0.14591962]]. Action = [[ 0.09107354  0.02868281  0.         -0.5206423 ]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 4627 is [True, False, False, False, False, True]
Current timestep = 4628. State = [[-0.19458157  0.149464  ]]. Action = [[0.03223705 0.0531451  0.         0.7484901 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 4628 is [True, False, False, False, False, True]
Current timestep = 4629. State = [[-0.19144635  0.15334043]]. Action = [[0.04536452 0.04224264 0.         0.64074755]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 4629 is [True, False, False, False, False, True]
Current timestep = 4630. State = [[-0.19067532  0.15287732]]. Action = [[-0.01551216 -0.04421572  0.         -0.6506794 ]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 4630 is [True, False, False, False, False, True]
Current timestep = 4631. State = [[-0.19436163  0.15511036]]. Action = [[-0.07765652  0.05350966  0.         -0.98627657]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 4631 is [True, False, False, False, False, True]
State prediction error at timestep 4631 is 0.012
Human Feedback received at timestep 4631 of None
Current timestep = 4632. State = [[-0.19553967  0.15828128]]. Action = [[0.01696309 0.01281482 0.         0.7881167 ]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 4632 is [True, False, False, False, False, True]
State prediction error at timestep 4632 is 0.012
Human Feedback received at timestep 4632 of None
Current timestep = 4633. State = [[-0.19436643  0.16341588]]. Action = [[ 0.01822279  0.07667824  0.         -0.31652248]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 4633 is [True, False, False, False, False, True]
Current timestep = 4634. State = [[-0.19727552  0.16895637]]. Action = [[-0.06336419  0.0460036   0.         -0.6895671 ]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 4634 is [True, False, False, False, False, True]
Current timestep = 4635. State = [[-0.19896765  0.17314956]]. Action = [[ 0.01059271  0.02793842  0.         -0.5775445 ]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 4635 is [True, False, False, False, False, True]
Current timestep = 4636. State = [[-0.19654253  0.17661081]]. Action = [[ 0.05640612  0.02843305  0.         -0.43157429]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 4636 is [True, False, False, False, False, True]
Current timestep = 4637. State = [[-0.19737038  0.17633657]]. Action = [[-0.04620639 -0.04734775  0.         -0.9772843 ]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 4637 is [True, False, False, False, False, True]
Current timestep = 4638. State = [[-0.19863045  0.17207004]]. Action = [[-0.00368276 -0.08615519  0.          0.676036  ]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 4638 is [True, False, False, False, False, True]
Current timestep = 4639. State = [[-0.19709735  0.17146897]]. Action = [[ 0.02823041  0.02253641  0.         -0.7035775 ]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 4639 is [True, False, False, False, False, True]
State prediction error at timestep 4639 is 0.012
Human Feedback received at timestep 4639 of None
Current timestep = 4640. State = [[-0.19436316  0.16842736]]. Action = [[ 0.0322359  -0.07868277  0.          0.22222626]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 4640 is [True, False, False, False, False, True]
Current timestep = 4641. State = [[-0.19449954  0.16141045]]. Action = [[-0.04087649 -0.09939743  0.          0.800823  ]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 4641 is [True, False, False, False, False, True]
Current timestep = 4642. State = [[-0.19658986  0.15953289]]. Action = [[-0.04153013  0.0222803   0.          0.04387438]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 4642 is [True, False, False, False, False, True]
State prediction error at timestep 4642 is 0.012
Human Feedback received at timestep 4642 of None
Current timestep = 4643. State = [[-0.19734807  0.15676963]]. Action = [[-0.00369344 -0.06047845  0.          0.00063694]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 4643 is [True, False, False, False, False, True]
Current timestep = 4644. State = [[-0.20122156  0.15701033]]. Action = [[-0.08519982  0.04760482  0.         -0.08875096]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 4644 is [True, False, False, False, False, True]
Current timestep = 4645. State = [[-0.20259914  0.15751682]]. Action = [[ 0.02290796 -0.00957716  0.         -0.24424326]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 4645 is [True, False, False, False, False, True]
Current timestep = 4646. State = [[-0.2056566   0.15782242]]. Action = [[-0.06468207  0.01873274  0.         -0.9602413 ]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 4646 is [True, False, False, False, False, True]
State prediction error at timestep 4646 is 0.012
Human Feedback received at timestep 4646 of None
Current timestep = 4647. State = [[-0.21150638  0.15530975]]. Action = [[-0.07093567 -0.0599888   0.          0.33288252]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 4647 is [True, False, False, False, False, True]
Current timestep = 4648. State = [[-0.21279828  0.15146638]]. Action = [[ 0.03001697 -0.04016773  0.          0.02969873]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 4648 is [True, False, False, False, False, True]
State prediction error at timestep 4648 is 0.012
Human Feedback received at timestep 4648 of None
Current timestep = 4649. State = [[-0.21667813  0.15392186]]. Action = [[-0.07471755  0.08573589  0.          0.4185177 ]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 4649 is [True, False, False, False, False, True]
Current timestep = 4650. State = [[-0.22084354  0.15344694]]. Action = [[-0.01496428 -0.05401099  0.         -0.01038682]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 4650 is [True, False, False, False, False, True]
State prediction error at timestep 4650 is 0.012
Human Feedback received at timestep 4650 of None
Current timestep = 4651. State = [[-0.22243325  0.15269348]]. Action = [[ 0.00500213  0.0201563   0.         -0.73015857]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 4651 is [True, False, False, False, False, True]
State prediction error at timestep 4651 is 0.012
Human Feedback received at timestep 4651 of None
Current timestep = 4652. State = [[-0.22723971  0.15087274]]. Action = [[-0.07307073 -0.03974235  0.         -0.78612196]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 4652 is [True, False, False, False, False, True]
Current timestep = 4653. State = [[-0.23159888  0.15180041]]. Action = [[-0.01740932  0.04667052  0.         -0.32237297]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 4653 is [True, False, False, False, False, True]
Current timestep = 4654. State = [[-0.23737638  0.15323289]]. Action = [[-0.06989564  0.00850113  0.         -0.62764716]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 4654 is [True, False, False, False, False, True]
Current timestep = 4655. State = [[-0.24496636  0.15580785]]. Action = [[-0.07489653  0.04529848  0.          0.67982185]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 4655 is [True, False, False, False, False, True]
Current timestep = 4656. State = [[-0.25307557  0.15847383]]. Action = [[-0.07491504  0.02148931  0.         -0.9359845 ]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 4656 is [True, False, False, False, False, True]
Current timestep = 4657. State = [[-0.25702474  0.16038738]]. Action = [[ 0.01371703  0.01820699  0.         -0.02890873]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 4657 is [True, False, False, False, False, True]
State prediction error at timestep 4657 is 0.012
Human Feedback received at timestep 4657 of None
Current timestep = 4658. State = [[-0.26165783  0.16409661]]. Action = [[-0.04882632  0.06049686  0.         -0.42004776]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 4658 is [True, False, False, False, False, True]
Current timestep = 4659. State = [[-0.26202524  0.16145377]]. Action = [[ 0.06788149 -0.09348556  0.          0.04719257]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 4659 is [True, False, False, False, False, True]
Current timestep = 4660. State = [[-0.2660325   0.16310334]]. Action = [[-0.08154039  0.09447596  0.          0.49392128]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 4660 is [True, False, False, False, False, True]
State prediction error at timestep 4660 is 0.012
Human Feedback received at timestep 4660 of None
Current timestep = 4661. State = [[-0.26819092  0.16211112]]. Action = [[ 0.03954156 -0.0794861   0.         -0.9752238 ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 4661 is [True, False, False, False, False, True]
State prediction error at timestep 4661 is 0.012
Human Feedback received at timestep 4661 of None
Current timestep = 4662. State = [[-0.27191406  0.15936667]]. Action = [[-0.07107897 -0.01700284  0.          0.68406856]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 4662 is [True, False, False, False, False, True]
Current timestep = 4663. State = [[-0.27459005  0.16256051]]. Action = [[ 0.01138469  0.0733349   0.         -0.42190003]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 4663 is [True, False, False, False, False, True]
State prediction error at timestep 4663 is 0.012
Human Feedback received at timestep 4663 of None
Current timestep = 4664. State = [[-0.27963996  0.16911599]]. Action = [[-0.07685666  0.08853471  0.         -0.5921456 ]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 4664 is [True, False, False, False, False, True]
Current timestep = 4665. State = [[-0.2853236   0.17656109]]. Action = [[-0.03420543  0.08797298  0.          0.80598176]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 4665 is [True, False, False, False, False, True]
State prediction error at timestep 4665 is 0.012
Human Feedback received at timestep 4665 of None
Current timestep = 4666. State = [[-0.2900794   0.18186243]]. Action = [[-0.03361512  0.03952395  0.          0.04199266]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 4666 is [True, False, False, False, False, True]
Current timestep = 4667. State = [[-0.29662415  0.18439713]]. Action = [[-0.07421914  0.0039778   0.         -0.8489416 ]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 4667 is [True, False, False, False, False, True]
Current timestep = 4668. State = [[-0.29850635  0.18856421]]. Action = [[ 0.04644831  0.05860267  0.         -0.22334772]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 4668 is [True, False, False, False, False, True]
State prediction error at timestep 4668 is 0.012
Human Feedback received at timestep 4668 of None
Current timestep = 4669. State = [[-0.30047637  0.1882195 ]]. Action = [[-0.03558823 -0.06471974  0.         -0.48873675]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 4669 is [True, False, False, False, False, True]
State prediction error at timestep 4669 is 0.012
Human Feedback received at timestep 4669 of None
Current timestep = 4670. State = [[-0.30682406  0.19123337]]. Action = [[-0.08207544  0.07226556  0.         -0.5299205 ]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 4670 is [True, False, False, False, False, True]
Current timestep = 4671. State = [[-0.30749682  0.18974383]]. Action = [[ 0.06526294 -0.09856976  0.         -0.44022286]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 4671 is [True, False, False, False, False, True]
Current timestep = 4672. State = [[-0.30493098  0.18451251]]. Action = [[ 0.02986995 -0.06349698  0.          0.37536788]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 4672 is [True, False, False, False, False, True]
Current timestep = 4673. State = [[-0.30225003  0.17830265]]. Action = [[ 0.0336253  -0.09112053  0.         -0.44502658]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 4673 is [True, False, False, False, False, True]
State prediction error at timestep 4673 is 0.012
Human Feedback received at timestep 4673 of None
Current timestep = 4674. State = [[-0.29942125  0.17908116]]. Action = [[ 0.03045068  0.07887491  0.         -0.7870223 ]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 4674 is [True, False, False, False, False, True]
Current timestep = 4675. State = [[-0.30243328  0.18257008]]. Action = [[-0.08305017  0.03503273  0.          0.2477547 ]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 4675 is [True, False, False, False, False, True]
Current timestep = 4676. State = [[-0.303654   0.1820338]]. Action = [[ 0.0243315  -0.03168055  0.         -0.501115  ]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 4676 is [True, False, False, False, False, True]
State prediction error at timestep 4676 is 0.012
Human Feedback received at timestep 4676 of None
Current timestep = 4677. State = [[-0.30077112  0.18227313]]. Action = [[0.04843632 0.03123515 0.         0.15782058]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 4677 is [True, False, False, False, False, True]
State prediction error at timestep 4677 is 0.012
Human Feedback received at timestep 4677 of None
Current timestep = 4678. State = [[-0.30085385  0.17814898]]. Action = [[-0.03561174 -0.09328114  0.         -0.76989603]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 4678 is [True, False, False, False, False, True]
Current timestep = 4679. State = [[-0.29707673  0.17453055]]. Action = [[ 0.09503477 -0.00586922  0.         -0.1208061 ]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 4679 is [True, False, False, False, False, True]
Current timestep = 4680. State = [[-0.29577008  0.17339207]]. Action = [[-3.8831770e-02 -5.5246055e-05  0.0000000e+00 -9.5473289e-02]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 4680 is [True, False, False, False, False, True]
Current timestep = 4681. State = [[-0.29704267  0.17508633]]. Action = [[-0.01494872  0.04507922  0.          0.03845704]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 4681 is [True, False, False, False, False, True]
State prediction error at timestep 4681 is 0.012
Human Feedback received at timestep 4681 of None
Current timestep = 4682. State = [[-0.3014493   0.17715275]]. Action = [[-0.08148662  0.02074836  0.          0.3897215 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 4682 is [True, False, False, False, False, True]
Current timestep = 4683. State = [[-0.3045742   0.17582268]]. Action = [[-0.01338471 -0.04363308  0.         -0.04513496]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 4683 is [True, False, False, False, False, True]
Current timestep = 4684. State = [[-0.30342975  0.17341499]]. Action = [[ 0.03584673 -0.02372283  0.          0.48044813]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 4684 is [True, False, False, False, False, True]
Current timestep = 4685. State = [[-0.30732724  0.17137833]]. Action = [[-0.09869551 -0.02516256  0.         -0.48392093]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 4685 is [True, False, False, False, False, True]
Current timestep = 4686. State = [[-0.30975515  0.17221253]]. Action = [[0.01711843 0.03190579 0.         0.7488725 ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 4686 is [True, False, False, False, False, True]
Current timestep = 4687. State = [[-0.30558324  0.17535909]]. Action = [[ 0.09427352  0.05596118  0.         -0.717242  ]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 4687 is [True, False, False, False, False, True]
State prediction error at timestep 4687 is 0.012
Human Feedback received at timestep 4687 of None
Current timestep = 4688. State = [[-0.30121773  0.17431673]]. Action = [[ 0.04591403 -0.03761759  0.         -0.30317175]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 4688 is [True, False, False, False, False, True]
Current timestep = 4689. State = [[-0.29801455  0.17091918]]. Action = [[ 0.03473485 -0.03602218  0.         -0.38998324]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 4689 is [True, False, False, False, False, True]
Current timestep = 4690. State = [[-0.29338118  0.17184202]]. Action = [[ 0.06679984  0.05524722  0.         -0.3722707 ]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 4690 is [True, False, False, False, False, True]
Current timestep = 4691. State = [[-0.29274976  0.174301  ]]. Action = [[-0.0330857   0.03257493  0.          0.14731288]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 4691 is [True, False, False, False, False, True]
Current timestep = 4692. State = [[-0.2903256   0.17691055]]. Action = [[ 0.06130233  0.03912764  0.         -0.51513445]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 4692 is [True, False, False, False, False, True]
Current timestep = 4693. State = [[-0.29179478  0.1803842 ]]. Action = [[-0.06997582  0.04966886  0.         -0.75607836]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 4693 is [True, False, False, False, False, True]
State prediction error at timestep 4693 is 0.012
Human Feedback received at timestep 4693 of None
Current timestep = 4694. State = [[-0.29486933  0.18045011]]. Action = [[-0.02677285 -0.03916743  0.         -0.629396  ]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 4694 is [True, False, False, False, False, True]
State prediction error at timestep 4694 is 0.012
Human Feedback received at timestep 4694 of None
Current timestep = 4695. State = [[-0.2991731   0.17720181]]. Action = [[-0.07724816 -0.06431177  0.         -0.18957603]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 4695 is [True, False, False, False, False, True]
Current timestep = 4696. State = [[-0.2989807   0.17340973]]. Action = [[ 0.04147846 -0.05695158  0.         -0.61168903]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 4696 is [True, False, False, False, False, True]
State prediction error at timestep 4696 is 0.012
Human Feedback received at timestep 4696 of None
Current timestep = 4697. State = [[-0.2963655   0.17004828]]. Action = [[ 0.02109897 -0.03855442  0.          0.7167014 ]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 4697 is [True, False, False, False, False, True]
Current timestep = 4698. State = [[-0.2952564   0.17217395]]. Action = [[ 1.3806671e-04  6.8811409e-02  0.0000000e+00 -2.1020120e-01]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 4698 is [True, False, False, False, False, True]
Current timestep = 4699. State = [[-0.29314357  0.17266114]]. Action = [[ 0.03992742 -0.02435013  0.         -0.59407526]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 4699 is [True, False, False, False, False, True]
Current timestep = 4700. State = [[-0.29505092  0.16890754]]. Action = [[-0.07125075 -0.06295991  0.         -0.4192444 ]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 4700 is [True, False, False, False, False, True]
State prediction error at timestep 4700 is 0.012
Human Feedback received at timestep 4700 of None
Current timestep = 4701. State = [[-0.29578298  0.16872865]]. Action = [[ 0.02193324  0.03496122  0.         -0.9631895 ]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 4701 is [True, False, False, False, False, True]
State prediction error at timestep 4701 is 0.012
Human Feedback received at timestep 4701 of None
Current timestep = 4702. State = [[-0.29350007  0.17183875]]. Action = [[ 0.03748675  0.05274583  0.         -0.7629124 ]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 4702 is [True, False, False, False, False, True]
Current timestep = 4703. State = [[-0.295629    0.17791507]]. Action = [[-0.05699163  0.09906956  0.         -0.11832589]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 4703 is [True, False, False, False, False, True]
Current timestep = 4704. State = [[-0.30133575  0.1857492 ]]. Action = [[-0.06498818  0.09601866  0.          0.44132233]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 4704 is [True, False, False, False, False, True]
Current timestep = 4705. State = [[-0.3045813   0.19176738]]. Action = [[ 0.00243952  0.05193626  0.         -0.5883604 ]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 4705 is [True, False, False, False, False, True]
Current timestep = 4706. State = [[-0.3092488   0.19670251]]. Action = [[-0.0628055   0.05006307  0.          0.16519201]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 4706 is [True, False, False, False, False, True]
State prediction error at timestep 4706 is 0.012
Human Feedback received at timestep 4706 of None
Current timestep = 4707. State = [[-0.31315488  0.20286138]]. Action = [[-0.00722781  0.07065284  0.          0.19073117]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 4707 is [True, False, False, False, False, True]
Current timestep = 4708. State = [[-0.31061977  0.20198618]]. Action = [[ 0.0900886  -0.08340707  0.          0.99888086]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 4708 is [True, False, False, False, False, True]
State prediction error at timestep 4708 is 0.012
Human Feedback received at timestep 4708 of None
Current timestep = 4709. State = [[-0.3065009  0.1979577]]. Action = [[ 0.04476187 -0.05328424  0.          0.5842891 ]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 4709 is [True, False, False, False, False, True]
Current timestep = 4710. State = [[-0.30177802  0.19553417]]. Action = [[ 0.06618603 -0.02889166  0.          0.0345701 ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 4710 is [True, False, False, False, False, True]
State prediction error at timestep 4710 is 0.012
Human Feedback received at timestep 4710 of None
Current timestep = 4711. State = [[-0.30238777  0.1930202 ]]. Action = [[-0.06451811 -0.04508835  0.          0.47490168]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 4711 is [True, False, False, False, False, True]
State prediction error at timestep 4711 is 0.012
Human Feedback received at timestep 4711 of None
Current timestep = 4712. State = [[-0.29887387  0.19319677]]. Action = [[ 0.09880387  0.02575169  0.         -0.43476146]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 4712 is [True, False, False, False, False, True]
Current timestep = 4713. State = [[-0.2940557   0.19807269]]. Action = [[ 0.02375511  0.08799159  0.         -0.20978624]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 4713 is [True, False, False, False, False, True]
State prediction error at timestep 4713 is 0.012
Human Feedback received at timestep 4713 of None
Current timestep = 4714. State = [[-0.29446334  0.20110463]]. Action = [[-0.04411487  0.00670459  0.          0.8171742 ]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 4714 is [True, False, False, False, False, True]
Current timestep = 4715. State = [[-0.2996981  0.2032519]]. Action = [[-0.09837859  0.02072859  0.         -0.8967826 ]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 4715 is [True, False, False, False, False, True]
Current timestep = 4716. State = [[-0.30239588  0.20361848]]. Action = [[-0.00555087 -0.02795453  0.          0.63507795]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 4716 is [True, False, False, False, False, True]
Current timestep = 4717. State = [[-0.29865795  0.20348279]]. Action = [[ 0.07685021 -0.00081092  0.          0.5442493 ]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 4717 is [True, False, False, False, False, True]
Current timestep = 4718. State = [[-0.30049923  0.20847061]]. Action = [[-0.08427523  0.09739687  0.         -0.7436653 ]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 4718 is [True, False, False, False, False, True]
State prediction error at timestep 4718 is 0.012
Human Feedback received at timestep 4718 of None
Current timestep = 4719. State = [[-0.30061007  0.21262641]]. Action = [[0.0521323 0.0142927 0.        0.8964727]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 4719 is [True, False, False, False, False, True]
Current timestep = 4720. State = [[-0.30343705  0.21544343]]. Action = [[-0.07761578  0.03130654  0.         -0.97023886]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 4720 is [True, False, False, False, False, True]
State prediction error at timestep 4720 is 0.012
Human Feedback received at timestep 4720 of None
Current timestep = 4721. State = [[-0.30330524  0.22183314]]. Action = [[ 0.06390376  0.0967376   0.         -0.6084075 ]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 4721 is [True, False, False, False, False, True]
Current timestep = 4722. State = [[-0.2970512   0.22139004]]. Action = [[ 0.09994509 -0.07708088  0.          0.21812952]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 4722 is [True, False, False, False, False, True]
Current timestep = 4723. State = [[-0.29405743  0.22051053]]. Action = [[-0.00834339  0.01316452  0.          0.85593426]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 4723 is [True, False, False, False, False, True]
State prediction error at timestep 4723 is 0.012
Human Feedback received at timestep 4723 of None
Current timestep = 4724. State = [[-0.29690462  0.21899864]]. Action = [[-0.07020988 -0.05826912  0.          0.6874713 ]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 4724 is [True, False, False, False, False, True]
State prediction error at timestep 4724 is 0.012
Human Feedback received at timestep 4724 of None
Current timestep = 4725. State = [[-0.30030125  0.22150192]]. Action = [[-0.03871694  0.0570054   0.          0.58284986]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 4725 is [True, False, False, False, False, True]
Current timestep = 4726. State = [[-0.3038723   0.22587013]]. Action = [[-0.04724637  0.03424496  0.          0.01515067]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 4726 is [True, False, False, False, False, True]
Current timestep = 4727. State = [[-0.30548683  0.22455585]]. Action = [[-0.00141091 -0.07164403  0.          0.8223264 ]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 4727 is [True, False, False, False, False, True]
Current timestep = 4728. State = [[-0.30997965  0.22282924]]. Action = [[-0.08950496 -0.0178823   0.          0.16277564]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 4728 is [True, False, False, False, False, True]
State prediction error at timestep 4728 is 0.012
Human Feedback received at timestep 4728 of None
Current timestep = 4729. State = [[-0.31769383  0.22498424]]. Action = [[-0.09561182  0.03131977  0.         -0.20074558]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 4729 is [True, False, False, False, False, True]
Current timestep = 4730. State = [[-0.3208973   0.22457314]]. Action = [[ 0.01233338 -0.04603035  0.          0.3077321 ]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 4730 is [True, False, False, False, False, True]
State prediction error at timestep 4730 is 0.012
Human Feedback received at timestep 4730 of None
Current timestep = 4731. State = [[-0.32319975  0.22279023]]. Action = [[-0.0329152  -0.02118676  0.          0.41990387]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 4731 is [True, False, False, False, False, True]
Current timestep = 4732. State = [[-0.32370624  0.21979508]]. Action = [[ 0.02561932 -0.05120822  0.         -0.5352205 ]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 4732 is [True, False, False, False, False, True]
Current timestep = 4733. State = [[-0.3242842   0.21719207]]. Action = [[-0.01187376 -0.0178166   0.          0.6638855 ]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 4733 is [True, False, False, False, False, True]
Current timestep = 4734. State = [[-0.32903156  0.22099   ]]. Action = [[-0.07064033  0.09835715  0.         -0.49333322]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 4734 is [True, False, False, False, False, True]
Current timestep = 4735. State = [[-0.32930908  0.22224708]]. Action = [[ 0.06448793 -0.02068571  0.         -0.578988  ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 4735 is [True, False, False, False, False, True]
Current timestep = 4736. State = [[-0.32895124  0.22088045]]. Action = [[-0.00777244 -0.00280707  0.          0.82088065]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 4736 is [True, False, False, False, False, True]
State prediction error at timestep 4736 is 0.012
Human Feedback received at timestep 4736 of None
Current timestep = 4737. State = [[-0.32886478  0.21805169]]. Action = [[ 0.0190406  -0.04225489  0.         -0.6690625 ]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 4737 is [True, False, False, False, False, True]
Current timestep = 4738. State = [[-0.3252922   0.21982898]]. Action = [[ 0.07393604  0.08077279  0.         -0.8767858 ]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 4738 is [True, False, False, False, False, True]
Current timestep = 4739. State = [[-0.32325047  0.22100157]]. Action = [[ 0.00448994 -0.00096517  0.          0.85591006]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 4739 is [True, False, False, False, False, True]
State prediction error at timestep 4739 is 0.012
Human Feedback received at timestep 4739 of None
Current timestep = 4740. State = [[-0.3247215   0.22414406]]. Action = [[-0.02921899  0.0739009   0.          0.52695096]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 4740 is [True, False, False, False, False, True]
Current timestep = 4741. State = [[-0.32399386  0.22449398]]. Action = [[ 0.03833402 -0.02932255  0.          0.50824857]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 4741 is [True, False, False, False, False, True]
Current timestep = 4742. State = [[-0.32254547  0.22064188]]. Action = [[ 0.00554427 -0.06142217  0.          0.55316615]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 4742 is [True, False, False, False, False, True]
State prediction error at timestep 4742 is 0.012
Human Feedback received at timestep 4742 of None
Current timestep = 4743. State = [[-0.31974122  0.21716782]]. Action = [[ 0.04245133 -0.03419375  0.         -0.8881166 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 4743 is [True, False, False, False, False, True]
Current timestep = 4744. State = [[-0.31473526  0.2154996 ]]. Action = [[ 0.06159703 -0.00454873  0.          0.9522196 ]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 4744 is [True, False, False, False, False, True]
Current timestep = 4745. State = [[-0.31382257  0.21896105]]. Action = [[-0.03370593  0.08532069  0.          0.99617434]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 4745 is [True, False, False, False, False, True]
Current timestep = 4746. State = [[-0.3151773   0.22229765]]. Action = [[-0.01743428  0.0218906   0.         -0.43761444]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 4746 is [True, False, False, False, False, True]
State prediction error at timestep 4746 is 0.012
Human Feedback received at timestep 4746 of None
Current timestep = 4747. State = [[-0.31645352  0.22524321]]. Action = [[-0.01849394  0.04203444  0.         -0.4773723 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 4747 is [True, False, False, False, False, True]
Current timestep = 4748. State = [[-0.3131386   0.22627215]]. Action = [[ 0.07687049 -0.00692833  0.          0.2469213 ]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 4748 is [True, False, False, False, False, True]
Current timestep = 4749. State = [[-0.31178558  0.22871946]]. Action = [[-0.0219091   0.05156877  0.          0.06997812]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 4749 is [True, False, False, False, False, True]
Current timestep = 4750. State = [[-0.30860054  0.23481369]]. Action = [[ 0.07452043  0.0918064   0.         -0.32770026]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 4750 is [True, False, False, False, False, True]
State prediction error at timestep 4750 is 0.012
Human Feedback received at timestep 4750 of None
Current timestep = 4751. State = [[-0.3048      0.23342034]]. Action = [[ 0.02374635 -0.09078123  0.          0.9294257 ]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 4751 is [True, False, False, False, False, True]
State prediction error at timestep 4751 is 0.012
Human Feedback received at timestep 4751 of None
Current timestep = 4752. State = [[-0.30844235  0.23523389]]. Action = [[-0.09800243  0.07895982  0.         -0.5818854 ]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 4752 is [True, False, False, False, False, True]
Current timestep = 4753. State = [[-0.31386247  0.23888089]]. Action = [[-0.0479018   0.00821879  0.          0.32067657]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 4753 is [True, False, False, False, False, True]
Current timestep = 4754. State = [[-0.31191084  0.24030496]]. Action = [[0.07923064 0.00039639 0.         0.0985533 ]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 4754 is [True, False, False, False, False, True]
Current timestep = 4755. State = [[-0.31006894  0.23826256]]. Action = [[-0.00689668 -0.05755912  0.          0.9510418 ]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 4755 is [True, False, False, False, False, True]
State prediction error at timestep 4755 is 0.012
Human Feedback received at timestep 4755 of None
Current timestep = 4756. State = [[-0.30687854  0.24138872]]. Action = [[0.06588127 0.08779419 0.         0.77338934]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 4756 is [True, False, False, False, False, True]
Current timestep = 4757. State = [[-0.30347905  0.24347417]]. Action = [[ 0.02133535 -0.01497503  0.          0.47692895]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 4757 is [True, False, False, False, False, True]
Current timestep = 4758. State = [[-0.30373254  0.24655811]]. Action = [[-0.03229569  0.05534769  0.         -0.28752977]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 4758 is [True, False, False, False, False, True]
Current timestep = 4759. State = [[-0.30174387  0.25197604]]. Action = [[ 0.05100702  0.06534448  0.         -0.24281573]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 4759 is [True, False, False, False, False, True]
State prediction error at timestep 4759 is 0.012
Human Feedback received at timestep 4759 of None
Current timestep = 4760. State = [[-0.2965886   0.25866428]]. Action = [[0.06981913 0.09160476 0.         0.45236945]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 4760 is [True, False, False, False, False, True]
Current timestep = 4761. State = [[-0.29009148  0.2645805 ]]. Action = [[0.08040934 0.06341282 0.         0.30927753]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 4761 is [True, False, False, False, False, True]
Current timestep = 4762. State = [[-0.28209174  0.26392874]]. Action = [[ 0.09349477 -0.05968769  0.          0.5623988 ]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 4762 is [True, False, False, False, False, True]
Current timestep = 4763. State = [[-0.28103247  0.26741162]]. Action = [[-0.06520151  0.09119081  0.         -0.6909679 ]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 4763 is [True, False, False, False, False, True]
Current timestep = 4764. State = [[-0.2840864   0.27339453]]. Action = [[-0.0456018   0.03973439  0.         -0.7999196 ]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 4764 is [True, False, False, False, False, True]
Current timestep = 4765. State = [[-0.2897002  0.2808524]]. Action = [[-0.09409751  0.08543911  0.         -0.4688927 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 4765 is [True, False, False, False, False, True]
Current timestep = 4766. State = [[-0.29538718  0.28824547]]. Action = [[-0.05330813  0.05306495  0.         -0.7145759 ]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 4766 is [True, False, False, False, False, True]
Current timestep = 4767. State = [[-0.29380247  0.29446864]]. Action = [[ 0.07949639  0.05024347  0.         -0.9890287 ]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 4767 is [True, False, False, False, False, True]
State prediction error at timestep 4767 is 0.012
Human Feedback received at timestep 4767 of None
Current timestep = 4768. State = [[-0.29200715  0.3004636 ]]. Action = [[0.0020576  0.05534659 0.         0.41002798]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 4768 is [True, False, False, False, False, True]
Current timestep = 4769. State = [[-0.28782424  0.30005863]]. Action = [[ 0.08360832 -0.08082765  0.         -0.99429744]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 4769 is [True, False, False, False, False, True]
Current timestep = 4770. State = [[-0.28132075  0.2955893 ]]. Action = [[ 0.06771458 -0.08412993  0.         -0.8259963 ]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 4770 is [True, False, False, False, False, True]
State prediction error at timestep 4770 is 0.012
Human Feedback received at timestep 4770 of None
Current timestep = 4771. State = [[-0.28027225  0.29881454]]. Action = [[-0.04513646  0.08934673  0.          0.26696634]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 4771 is [True, False, False, False, False, True]
Current timestep = 4772. State = [[-0.27870417  0.30524188]]. Action = [[ 0.04397594  0.05607563  0.         -0.8625098 ]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 4772 is [True, False, False, False, False, True]
Current timestep = 4773. State = [[-0.28029668  0.30411473]]. Action = [[-0.07898627 -0.09462836  0.         -0.34962225]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 4773 is [True, False, False, False, False, True]
State prediction error at timestep 4773 is 0.012
Human Feedback received at timestep 4773 of None
Current timestep = 4774. State = [[-0.28292915  0.30245322]]. Action = [[-0.01890064 -0.0099906   0.         -0.8808653 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 4774 is [True, False, False, False, False, True]
Current timestep = 4775. State = [[-0.2881025   0.30765256]]. Action = [[-0.08961317  0.09555682  0.         -0.20524192]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 4775 is [True, False, False, False, False, True]
Current timestep = 4776. State = [[-0.2891147  0.3100477]]. Action = [[ 0.04606872 -0.02144475  0.          0.48219895]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 4776 is [True, False, False, False, False, True]
Current timestep = 4777. State = [[-0.28344196  0.3095467 ]]. Action = [[ 0.09842145 -0.00473864  0.          0.67600155]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 4777 is [True, False, False, False, False, True]
Current timestep = 4778. State = [[-0.28166443  0.30962265]]. Action = [[-0.02319146  0.00786072  0.          0.6132686 ]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 4778 is [True, False, False, False, False, True]
State prediction error at timestep 4778 is 0.012
Human Feedback received at timestep 4778 of None
Current timestep = 4779. State = [[-0.28278655  0.30680937]]. Action = [[-0.01666822 -0.06749456  0.         -0.4922831 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 4779 is [True, False, False, False, False, True]
State prediction error at timestep 4779 is 0.012
Human Feedback received at timestep 4779 of None
Current timestep = 4780. State = [[-0.28022632  0.30120018]]. Action = [[ 0.05109737 -0.08364551  0.          0.9294951 ]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 4780 is [True, False, False, False, False, True]
State prediction error at timestep 4780 is 0.012
Human Feedback received at timestep 4780 of None
Current timestep = 4781. State = [[-0.28066576  0.29817498]]. Action = [[-0.05441856 -0.01241271  0.         -0.348518  ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 4781 is [True, False, False, False, False, True]
Current timestep = 4782. State = [[-0.2864041  0.3015791]]. Action = [[-0.09210654  0.07706272  0.         -0.9100147 ]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 4782 is [True, False, False, False, False, True]
Current timestep = 4783. State = [[-0.2941438   0.30175796]]. Action = [[-0.09374722 -0.04667733  0.          0.3341787 ]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 4783 is [True, False, False, False, False, True]
Current timestep = 4784. State = [[-0.29376245  0.30054396]]. Action = [[ 8.261546e-02 -4.518628e-04  0.000000e+00  5.179119e-01]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 4784 is [True, False, False, False, False, True]
Current timestep = 4785. State = [[-0.28981063  0.29692188]]. Action = [[ 0.04119767 -0.06518663  0.         -0.69985926]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 4785 is [True, False, False, False, False, True]
State prediction error at timestep 4785 is 0.012
Human Feedback received at timestep 4785 of None
Current timestep = 4786. State = [[-0.29196748  0.29150137]]. Action = [[-0.07382465 -0.07028958  0.          0.13624752]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 4786 is [True, False, False, False, False, True]
State prediction error at timestep 4786 is 0.012
Human Feedback received at timestep 4786 of None
Current timestep = 4787. State = [[-0.29098818  0.28751042]]. Action = [[ 0.05969437 -0.03520376  0.          0.6257591 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 4787 is [True, False, False, False, False, True]
Current timestep = 4788. State = [[-0.28681713  0.289852  ]]. Action = [[ 0.05110156  0.09270903  0.         -0.6901676 ]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 4788 is [True, False, False, False, False, True]
Current timestep = 4789. State = [[-0.28213763  0.29015777]]. Action = [[ 0.06357067 -0.01445044  0.          0.852705  ]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 4789 is [True, False, False, False, False, True]
Current timestep = 4790. State = [[-0.28282547  0.28798974]]. Action = [[-0.0604779  -0.01699696  0.         -0.08330536]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 4790 is [True, False, False, False, False, True]
Current timestep = 4791. State = [[-0.27959222  0.28653294]]. Action = [[ 0.09327241 -0.00135843  0.          0.5081997 ]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 4791 is [True, False, False, False, False, True]
Current timestep = 4792. State = [[-0.2795929  0.283298 ]]. Action = [[-0.06675027 -0.04981522  0.          0.7475774 ]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 4792 is [True, False, False, False, False, True]
Current timestep = 4793. State = [[-0.28193626  0.27853516]]. Action = [[-0.02021897 -0.05981375  0.         -0.0107097 ]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 4793 is [True, False, False, False, False, True]
State prediction error at timestep 4793 is 0.012
Human Feedback received at timestep 4793 of None
Current timestep = 4794. State = [[-0.2794845   0.27465844]]. Action = [[ 0.05574154 -0.0297192   0.          0.899724  ]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 4794 is [True, False, False, False, False, True]
Current timestep = 4795. State = [[-0.2764303   0.27262688]]. Action = [[0.02087204 0.00032505 0.         0.0738101 ]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 4795 is [True, False, False, False, False, True]
Current timestep = 4796. State = [[-0.27227908  0.26686466]]. Action = [[ 0.05775531 -0.09225764  0.          0.76098084]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 4796 is [True, False, False, False, False, True]
State prediction error at timestep 4796 is 0.012
Human Feedback received at timestep 4796 of None
Current timestep = 4797. State = [[-0.26658526  0.2611056 ]]. Action = [[ 0.06042347 -0.03618988  0.         -0.16790915]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 4797 is [True, False, False, False, False, True]
Current timestep = 4798. State = [[-0.2637659   0.25810292]]. Action = [[-0.00304747 -0.00605206  0.          0.660553  ]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 4798 is [True, False, False, False, False, True]
Current timestep = 4799. State = [[-0.25872236  0.25718942]]. Action = [[0.08114094 0.01971216 0.         0.25548863]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 4799 is [True, False, False, False, False, True]
Current timestep = 4800. State = [[-0.25381988  0.25350028]]. Action = [[ 0.02973407 -0.04839049  0.         -0.05805397]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 4800 is [True, False, False, False, False, True]
Current timestep = 4801. State = [[-0.24882458  0.25348312]]. Action = [[0.05797251 0.06297336 0.         0.1838044 ]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 4801 is [True, False, False, False, False, True]
Current timestep = 4802. State = [[-0.24377915  0.25008994]]. Action = [[ 0.04349809 -0.06872939  0.          0.93389773]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 4802 is [True, False, False, False, False, True]
State prediction error at timestep 4802 is 0.012
Human Feedback received at timestep 4802 of None
Current timestep = 4803. State = [[-0.23755586  0.24666071]]. Action = [[ 0.06997729 -0.00028732  0.         -0.08044147]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 4803 is [True, False, False, False, False, True]
Current timestep = 4804. State = [[-0.23062563  0.24715447]]. Action = [[ 0.06987821  0.0471297   0.         -0.56672853]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 4804 is [True, False, False, False, False, True]
Current timestep = 4805. State = [[-0.22680672  0.24679616]]. Action = [[ 0.00604004 -0.00418877  0.         -0.8658227 ]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 4805 is [True, False, False, False, False, True]
Current timestep = 4806. State = [[-0.22090973  0.24810441]]. Action = [[0.08585577 0.05102389 0.         0.69064355]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 4806 is [True, False, False, False, False, True]
Current timestep = 4807. State = [[-0.21406403  0.24649271]]. Action = [[ 0.05877673 -0.0400974   0.          0.30222797]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 4807 is [True, False, False, False, False, True]
Current timestep = 4808. State = [[-0.21421026  0.24900442]]. Action = [[-0.07354339  0.08480605  0.         -0.907025  ]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 4808 is [True, False, False, False, False, True]
Current timestep = 4809. State = [[-0.21738313  0.24892035]]. Action = [[-0.05079241 -0.05909287  0.          0.30245376]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 4809 is [True, False, False, False, False, True]
Current timestep = 4810. State = [[-0.2149373   0.24736428]]. Action = [[ 0.05726188 -0.01474983  0.         -0.30660725]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 4810 is [True, False, False, False, False, True]
Current timestep = 4811. State = [[-0.2092942  0.2504004]]. Action = [[0.06135162 0.06639374 0.         0.8014152 ]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 4811 is [True, False, False, False, False, True]
Current timestep = 4812. State = [[-0.20964612  0.2502206 ]]. Action = [[-0.07229878 -0.05531417  0.          0.8564632 ]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 4812 is [True, False, False, False, False, True]
Current timestep = 4813. State = [[-0.21027176  0.25158274]]. Action = [[ 0.01719634  0.04785495  0.         -0.82544965]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 4813 is [True, False, False, False, False, True]
Current timestep = 4814. State = [[-0.2069684   0.25778475]]. Action = [[ 0.05827831  0.09663715  0.         -0.05682999]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 4814 is [True, False, False, False, False, True]
Current timestep = 4815. State = [[-0.20119603  0.26407588]]. Action = [[ 0.08825039  0.0752487   0.         -0.4859863 ]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 4815 is [True, False, False, False, False, True]
Current timestep = 4816. State = [[-0.19883373  0.26765686]]. Action = [[-0.00604919  0.02609795  0.         -0.39142394]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 4816 is [True, False, False, False, False, True]
State prediction error at timestep 4816 is 0.012
Human Feedback received at timestep 4816 of None
Current timestep = 4817. State = [[-0.19810982  0.26935616]]. Action = [[0.01099231 0.00624256 0.         0.65479803]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 4817 is [True, False, False, False, False, True]
State prediction error at timestep 4817 is 0.012
Human Feedback received at timestep 4817 of None
Current timestep = 4818. State = [[-0.19302621  0.2701202 ]]. Action = [[ 0.0875501  -0.00188536  0.          0.46954072]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 4818 is [True, False, False, False, False, True]
Current timestep = 4819. State = [[-0.18703093  0.27196   ]]. Action = [[ 0.05515864  0.03082477  0.         -0.48748106]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 4819 is [True, False, False, False, False, True]
Current timestep = 4820. State = [[-0.18631414  0.27190712]]. Action = [[-0.04419521 -0.03318984  0.          0.96558774]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 4820 is [True, False, False, False, False, True]
Current timestep = 4821. State = [[-0.19037785  0.26981142]]. Action = [[-0.08762549 -0.05224523  0.         -0.6109681 ]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 4821 is [True, False, False, False, False, True]
Current timestep = 4822. State = [[-0.19088648  0.26822865]]. Action = [[ 0.01640165 -0.03220339  0.         -0.8562213 ]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 4822 is [True, False, False, False, False, True]
State prediction error at timestep 4822 is 0.012
Human Feedback received at timestep 4822 of None
Current timestep = 4823. State = [[-0.19392367  0.26732302]]. Action = [[-0.09065206 -0.02420253  0.         -0.12408084]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 4823 is [True, False, False, False, False, True]
State prediction error at timestep 4823 is 0.012
Human Feedback received at timestep 4823 of None
Current timestep = 4824. State = [[-0.19626461  0.26749825]]. Action = [[-0.01199243 -0.00886437  0.          0.48000896]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 4824 is [True, False, False, False, False, True]
Current timestep = 4825. State = [[-0.19854046  0.26996064]]. Action = [[-0.0432841   0.0355373   0.          0.92737365]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 4825 is [True, False, False, False, False, True]
Current timestep = 4826. State = [[-0.20035559  0.26776838]]. Action = [[-0.01265785 -0.08373366  0.          0.22045743]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 4826 is [True, False, False, False, False, True]
Current timestep = 4827. State = [[-0.19671726  0.26484415]]. Action = [[ 0.08054916 -0.01967444  0.         -0.06827259]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 4827 is [True, False, False, False, False, True]
Current timestep = 4828. State = [[-0.19110571  0.26601803]]. Action = [[0.06641368 0.04871707 0.         0.03907967]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 4828 is [True, False, False, False, False, True]
Current timestep = 4829. State = [[-0.18613689  0.2688098 ]]. Action = [[0.06080548 0.05097211 0.         0.6518085 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 4829 is [True, False, False, False, False, True]
Current timestep = 4830. State = [[-0.18363923  0.27292234]]. Action = [[ 0.01464657  0.07442673  0.         -0.88914746]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 4830 is [True, False, False, False, False, True]
Current timestep = 4831. State = [[-0.18297869  0.27253678]]. Action = [[ 0.00208445 -0.0402017   0.         -0.55428404]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 4831 is [True, False, False, False, False, True]
Current timestep = 4832. State = [[-0.18629609  0.27080014]]. Action = [[-0.0779653  -0.01443731  0.         -0.7964528 ]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 4832 is [True, False, False, False, False, True]
Current timestep = 4833. State = [[-0.18646792  0.27075475]]. Action = [[ 0.03568269  0.00286237  0.         -0.54788226]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 4833 is [True, False, False, False, False, True]
Current timestep = 4834. State = [[-0.18374494  0.27156338]]. Action = [[ 0.03313815  0.01540048  0.         -0.9432381 ]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 4834 is [True, False, False, False, False, True]
State prediction error at timestep 4834 is 0.012
Human Feedback received at timestep 4834 of None
Current timestep = 4835. State = [[-0.1857733   0.27130318]]. Action = [[-0.06810646 -0.01697963  0.          0.56388783]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 4835 is [True, False, False, False, False, True]
State prediction error at timestep 4835 is 0.012
Human Feedback received at timestep 4835 of None
Current timestep = 4836. State = [[-0.18372741  0.2716925 ]]. Action = [[ 0.07916787  0.01462028  0.         -0.8137484 ]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 4836 is [True, False, False, False, False, True]
State prediction error at timestep 4836 is 0.012
Human Feedback received at timestep 4836 of None
Current timestep = 4837. State = [[-0.1775212   0.27237335]]. Action = [[0.07671373 0.01077341 0.         0.80880356]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 4837 is [True, False, False, False, False, True]
Current timestep = 4838. State = [[-0.17663233  0.27724877]]. Action = [[-0.03575154  0.0994306   0.         -0.46388972]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 4838 is [True, False, False, False, False, True]
State prediction error at timestep 4838 is 0.012
Human Feedback received at timestep 4838 of None
Current timestep = 4839. State = [[-0.17397904  0.27674183]]. Action = [[ 0.06660595 -0.06978796  0.          0.13033605]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 4839 is [True, False, False, False, False, True]
Current timestep = 4840. State = [[-0.16854544  0.2781403 ]]. Action = [[0.05990251 0.06849597 0.         0.8335998 ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 4840 is [True, False, False, False, False, True]
Current timestep = 4841. State = [[-0.16338873  0.27745336]]. Action = [[ 0.05320334 -0.04599122  0.         -0.4474244 ]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 4841 is [True, False, False, False, False, True]
Current timestep = 4842. State = [[-0.15843654  0.2718511 ]]. Action = [[ 0.04017533 -0.08724169  0.          0.27914977]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 4842 is [True, False, False, False, False, True]
Current timestep = 4843. State = [[-0.1572409  0.2721271]]. Action = [[-0.03541862  0.05959683  0.         -0.8820771 ]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 4843 is [True, False, False, False, False, True]
Current timestep = 4844. State = [[-0.1612727  0.2695435]]. Action = [[-0.09993081 -0.09847191  0.         -0.9257148 ]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 4844 is [True, False, False, False, False, True]
State prediction error at timestep 4844 is 0.012
Human Feedback received at timestep 4844 of None
Current timestep = 4845. State = [[-0.16021046  0.26754895]]. Action = [[ 0.0642791   0.01022427  0.         -0.02313834]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 4845 is [True, False, False, False, False, True]
Current timestep = 4846. State = [[-0.15834562  0.2696608 ]]. Action = [[-0.02190725  0.03301088  0.         -0.4796033 ]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 4846 is [True, False, False, False, False, True]
Current timestep = 4847. State = [[-0.15455337  0.27349848]]. Action = [[ 0.07024793  0.05312652  0.         -0.040236  ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 4847 is [True, False, False, False, False, True]
Current timestep = 4848. State = [[-0.14775932  0.27318394]]. Action = [[ 0.08335479 -0.03533638  0.          0.9102386 ]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 4848 is [True, False, False, False, False, True]
Current timestep = 4849. State = [[-0.14760323  0.2689307 ]]. Action = [[-0.08050293 -0.07383643  0.          0.23659551]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 4849 is [True, False, False, False, False, True]
Current timestep = 4850. State = [[-0.14516558  0.2638196 ]]. Action = [[ 0.06946781 -0.06188301  0.          0.4632163 ]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 4850 is [True, False, False, False, False, True]
Current timestep = 4851. State = [[-0.13817431  0.2592211 ]]. Action = [[ 0.0774251  -0.04258174  0.          0.06383979]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 4851 is [True, False, False, False, False, True]
State prediction error at timestep 4851 is 0.012
Human Feedback received at timestep 4851 of None
Current timestep = 4852. State = [[-0.13082698  0.25901178]]. Action = [[0.07636132 0.04857    0.         0.37591434]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 4852 is [True, False, False, False, False, True]
Current timestep = 4853. State = [[-0.12393966  0.260682  ]]. Action = [[ 0.07270274  0.04178878  0.         -0.08755809]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 4853 is [True, False, False, False, False, True]
State prediction error at timestep 4853 is 0.012
Human Feedback received at timestep 4853 of None
Current timestep = 4854. State = [[-0.1202159   0.26109242]]. Action = [[ 0.00992265  0.01338229  0.         -0.8537009 ]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 4854 is [True, False, False, False, False, True]
Current timestep = 4855. State = [[-0.1213932  0.2605375]]. Action = [[-0.05701762 -0.00361361  0.          0.38522255]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 4855 is [True, False, False, False, False, True]
Current timestep = 4856. State = [[-0.11827788  0.26088983]]. Action = [[ 0.07710429  0.0186132   0.         -0.43653488]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 4856 is [True, False, False, False, False, True]
Current timestep = 4857. State = [[-0.11587775  0.25976753]]. Action = [[-0.01645673 -0.02697463  0.          0.08622825]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 4857 is [True, False, False, False, False, True]
Current timestep = 4858. State = [[-0.11634442  0.26085177]]. Action = [[-0.024552    0.03588905  0.         -0.56252414]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 4858 is [True, False, False, False, False, True]
Current timestep = 4859. State = [[-0.11472475  0.2642105 ]]. Action = [[0.03413679 0.04343165 0.         0.8713534 ]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 4859 is [True, False, False, False, False, True]
Current timestep = 4860. State = [[-0.10955284  0.26597843]]. Action = [[0.07871222 0.00909127 0.         0.15436411]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 4860 is [True, False, False, False, False, True]
Current timestep = 4861. State = [[-0.11113886  0.26674506]]. Action = [[-9.7947478e-02  2.1147728e-04  0.0000000e+00 -7.6777726e-01]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 4861 is [True, False, False, False, False, True]
Current timestep = 4862. State = [[-0.11372733  0.2694001 ]]. Action = [[-0.00376353  0.03946122  0.          0.57674766]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 4862 is [True, False, False, False, False, True]
Current timestep = 4863. State = [[-0.11520476  0.2684579 ]]. Action = [[-0.0256926  -0.05802182  0.          0.50552917]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 4863 is [True, False, False, False, False, True]
Current timestep = 4864. State = [[-0.11554743  0.27014744]]. Action = [[ 0.00591463  0.05059066  0.         -0.13222677]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 4864 is [True, False, False, False, False, True]
Current timestep = 4865. State = [[-0.11976255  0.2681297 ]]. Action = [[-0.09882435 -0.09340312  0.          0.09048772]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 4865 is [True, False, False, False, False, True]
Current timestep = 4866. State = [[-0.12403326  0.26701897]]. Action = [[-0.02905618  0.0101303   0.         -0.05906606]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 4866 is [True, False, False, False, False, True]
State prediction error at timestep 4866 is 0.012
Human Feedback received at timestep 4866 of None
Current timestep = 4867. State = [[-0.12245618  0.26764703]]. Action = [[ 6.2102892e-02  2.8161705e-04  0.0000000e+00 -7.7094179e-01]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 4867 is [True, False, False, False, False, True]
Current timestep = 4868. State = [[-0.12506302  0.27018762]]. Action = [[-0.07496474  0.05008591  0.          0.02305722]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 4868 is [True, False, False, False, False, True]
Current timestep = 4869. State = [[-0.1307894   0.27024886]]. Action = [[-0.06078071 -0.03826706  0.         -0.78657454]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 4869 is [True, False, False, False, False, True]
Current timestep = 4870. State = [[-0.1354031   0.26626462]]. Action = [[-0.0464185  -0.07563257  0.          0.8029994 ]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 4870 is [True, False, False, False, False, True]
Current timestep = 4871. State = [[-0.13986793  0.2651258 ]]. Action = [[-0.05177234  0.01030929  0.         -0.6909388 ]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 4871 is [True, False, False, False, False, True]
Current timestep = 4872. State = [[-0.14096539  0.2674248 ]]. Action = [[0.03024391 0.04045863 0.         0.5907972 ]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 4872 is [True, False, False, False, False, True]
Current timestep = 4873. State = [[-0.14097229  0.268164  ]]. Action = [[ 0.0101067  -0.00245484  0.          0.7960985 ]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 4873 is [True, False, False, False, False, True]
Current timestep = 4874. State = [[-0.1431857   0.26894727]]. Action = [[-0.0285427   0.02363928  0.          0.60779023]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 4874 is [True, False, False, False, False, True]
State prediction error at timestep 4874 is 0.012
Human Feedback received at timestep 4874 of None
Current timestep = 4875. State = [[-0.14866017  0.27062747]]. Action = [[-0.0703003   0.02376233  0.          0.4730314 ]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 4875 is [True, False, False, False, False, True]
Current timestep = 4876. State = [[-0.14794824  0.27284992]]. Action = [[ 0.08945405  0.03697524  0.         -0.22905773]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 4876 is [True, False, False, False, False, True]
Current timestep = 4877. State = [[-0.14772257  0.2695379 ]]. Action = [[-0.03196289 -0.08790059  0.         -0.5929374 ]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 4877 is [True, False, False, False, False, True]
Current timestep = 4878. State = [[-0.14642596  0.26367897]]. Action = [[ 0.05517104 -0.05977247  0.          0.61481285]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 4878 is [True, False, False, False, False, True]
Current timestep = 4879. State = [[-0.14998783  0.2610363 ]]. Action = [[-0.09624333 -0.00153726  0.         -0.08544624]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 4879 is [True, False, False, False, False, True]
Current timestep = 4880. State = [[-0.15639167  0.26416507]]. Action = [[-0.06241905  0.07249675  0.          0.6838044 ]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 4880 is [True, False, False, False, False, True]
Current timestep = 4881. State = [[-0.16316204  0.2639783 ]]. Action = [[-0.07599276 -0.04509697  0.          0.16320252]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 4881 is [True, False, False, False, False, True]
Current timestep = 4882. State = [[-0.17035429  0.2651854 ]]. Action = [[-0.07537091  0.0427021   0.          0.820812  ]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 4882 is [True, False, False, False, False, True]
State prediction error at timestep 4882 is 0.012
Human Feedback received at timestep 4882 of None
Current timestep = 4883. State = [[-0.17167611  0.26378852]]. Action = [[ 0.05088418 -0.05491083  0.          0.29776347]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 4883 is [True, False, False, False, False, True]
Current timestep = 4884. State = [[-0.17437282  0.2640773 ]]. Action = [[-0.05283704  0.04200541  0.         -0.2598896 ]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 4884 is [True, False, False, False, False, True]
State prediction error at timestep 4884 is 0.012
Human Feedback received at timestep 4884 of None
Current timestep = 4885. State = [[-0.17304644  0.26621702]]. Action = [[0.09130066 0.0298254  0.         0.29231954]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 4885 is [True, False, False, False, False, True]
Current timestep = 4886. State = [[-0.17424236  0.26470214]]. Action = [[-0.05377395 -0.04122793  0.          0.5224596 ]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 4886 is [True, False, False, False, False, True]
Current timestep = 4887. State = [[-0.18117158  0.25891584]]. Action = [[-0.09193892 -0.0914295   0.          0.13040054]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 4887 is [True, False, False, False, False, True]
Current timestep = 4888. State = [[-0.18521976  0.25888154]]. Action = [[ 0.00068697  0.06066775  0.         -0.6724989 ]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 4888 is [True, False, False, False, False, True]
State prediction error at timestep 4888 is 0.012
Human Feedback received at timestep 4888 of None
Current timestep = 4889. State = [[-0.18335494  0.25935054]]. Action = [[ 0.06369535 -0.01226351  0.          0.30397773]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 4889 is [True, False, False, False, False, True]
Current timestep = 4890. State = [[-0.18644975  0.25716048]]. Action = [[-0.08756599 -0.03072472  0.         -0.15800357]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 4890 is [True, False, False, False, False, True]
Current timestep = 4891. State = [[-0.19041485  0.25282568]]. Action = [[-0.01681145 -0.06534589  0.         -0.23775434]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 4891 is [True, False, False, False, False, True]
Current timestep = 4892. State = [[-0.19004604  0.2530574 ]]. Action = [[ 0.03881834  0.05696697  0.         -0.5546557 ]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 4892 is [True, False, False, False, False, True]
State prediction error at timestep 4892 is 0.012
Human Feedback received at timestep 4892 of None
Current timestep = 4893. State = [[-0.1937258   0.25666496]]. Action = [[-0.07556736  0.05724778  0.          0.92047346]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 4893 is [True, False, False, False, False, True]
Current timestep = 4894. State = [[-0.20191193  0.26025307]]. Action = [[-0.09783273  0.04005251  0.         -0.73944247]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 4894 is [True, False, False, False, False, True]
Current timestep = 4895. State = [[-0.20977704  0.2597897 ]]. Action = [[-0.07099325 -0.04427489  0.          0.91451585]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 4895 is [True, False, False, False, False, True]
State prediction error at timestep 4895 is 0.012
Human Feedback received at timestep 4895 of None
Current timestep = 4896. State = [[-0.21576382  0.25889984]]. Action = [[-0.0465589  -0.00738598  0.         -0.22252905]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 4896 is [True, False, False, False, False, True]
Current timestep = 4897. State = [[-0.22046426  0.2583456 ]]. Action = [[-0.03247268 -0.01594021  0.          0.2615769 ]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 4897 is [True, False, False, False, False, True]
Current timestep = 4898. State = [[-0.2193927   0.26206088]]. Action = [[ 0.08587917  0.08983418  0.         -0.3865733 ]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 4898 is [True, False, False, False, False, True]
State prediction error at timestep 4898 is 0.012
Human Feedback received at timestep 4898 of None
Current timestep = 4899. State = [[-0.21955161  0.2600707 ]]. Action = [[-0.03216655 -0.09556858  0.         -0.33878767]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 4899 is [True, False, False, False, False, True]
Current timestep = 4900. State = [[-0.22353521  0.2585659 ]]. Action = [[-0.03632346  0.02778275  0.          0.2121507 ]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 4900 is [True, False, False, False, False, True]
Current timestep = 4901. State = [[-0.22984178  0.26005718]]. Action = [[-0.07226475  0.02411638  0.          0.7279873 ]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 4901 is [True, False, False, False, False, True]
Current timestep = 4902. State = [[-0.23719709  0.26191193]]. Action = [[-0.06942694  0.0247121   0.         -0.95955306]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 4902 is [True, False, False, False, False, True]
Current timestep = 4903. State = [[-0.24171767  0.2628233 ]]. Action = [[-0.00995231  0.00284942  0.          0.18653071]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 4903 is [True, False, False, False, False, True]
Current timestep = 4904. State = [[-0.24144083  0.26312816]]. Action = [[ 0.05083484  0.00834262  0.         -0.57846296]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 4904 is [True, False, False, False, False, True]
Current timestep = 4905. State = [[-0.23708312  0.26184693]]. Action = [[ 0.0898835  -0.01592173  0.         -0.01495486]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 4905 is [True, False, False, False, False, True]
State prediction error at timestep 4905 is 0.012
Human Feedback received at timestep 4905 of None
Current timestep = 4906. State = [[-0.23411663  0.25977018]]. Action = [[ 0.02411018 -0.01347984  0.          0.8333738 ]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 4906 is [True, False, False, False, False, True]
State prediction error at timestep 4906 is 0.012
Human Feedback received at timestep 4906 of None
Current timestep = 4907. State = [[-0.2332378  0.25585  ]]. Action = [[ 0.0063133  -0.05680157  0.          0.63742864]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 4907 is [True, False, False, False, False, True]
Current timestep = 4908. State = [[-0.23156087  0.25167128]]. Action = [[ 0.02485069 -0.03961363  0.          0.02618802]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 4908 is [True, False, False, False, False, True]
Current timestep = 4909. State = [[-0.23032938  0.2467375 ]]. Action = [[-0.00162122 -0.06187618  0.         -0.44042003]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 4909 is [True, False, False, False, False, True]
Current timestep = 4910. State = [[-0.22790064  0.24744418]]. Action = [[0.03731883 0.07040327 0.         0.816762  ]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 4910 is [True, False, False, False, False, True]
Current timestep = 4911. State = [[-0.23123428  0.2508614 ]]. Action = [[-0.09973927  0.04624524  0.          0.75988626]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 4911 is [True, False, False, False, False, True]
Current timestep = 4912. State = [[-0.23687941  0.2477825 ]]. Action = [[-0.06288634 -0.09151544  0.          0.34397423]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 4912 is [True, False, False, False, False, True]
Current timestep = 4913. State = [[-0.23572138  0.24416058]]. Action = [[ 0.06247558 -0.02070681  0.          0.28116095]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 4913 is [True, False, False, False, False, True]
Current timestep = 4914. State = [[-0.2327872   0.24653044]]. Action = [[0.02304395 0.07358264 0.         0.60691357]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 4914 is [True, False, False, False, False, True]
Current timestep = 4915. State = [[-0.23302032  0.24832407]]. Action = [[-0.0179036   0.00511836  0.         -0.44584548]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 4915 is [True, False, False, False, False, True]
Current timestep = 4916. State = [[-0.23603575  0.24990429]]. Action = [[-0.04901114  0.02811056  0.         -0.70360774]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 4916 is [True, False, False, False, False, True]
Current timestep = 4917. State = [[-0.23991485  0.25169608]]. Action = [[-0.04176437  0.01375456  0.          0.01422572]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 4917 is [True, False, False, False, False, True]
Current timestep = 4918. State = [[-0.24295446  0.25129026]]. Action = [[-0.02517845 -0.02766679  0.          0.5761366 ]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 4918 is [True, False, False, False, False, True]
Current timestep = 4919. State = [[-0.2440977   0.24727029]]. Action = [[ 2.5679916e-04 -7.7960715e-02  0.0000000e+00  6.3616085e-01]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 4919 is [True, False, False, False, False, True]
Current timestep = 4920. State = [[-0.24156827  0.24937846]]. Action = [[ 0.06428465  0.09111824  0.         -0.05033922]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 4920 is [True, False, False, False, False, True]
State prediction error at timestep 4920 is 0.012
Human Feedback received at timestep 4920 of None
Current timestep = 4921. State = [[-0.23938683  0.24901992]]. Action = [[ 0.00931378 -0.0556152   0.          0.9127476 ]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 4921 is [True, False, False, False, False, True]
Current timestep = 4922. State = [[-0.24298184  0.24726155]]. Action = [[-0.08270423 -0.00966702  0.         -0.97805727]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 4922 is [True, False, False, False, False, True]
State prediction error at timestep 4922 is 0.012
Human Feedback received at timestep 4922 of None
Current timestep = 4923. State = [[-0.24718669  0.2518655 ]]. Action = [[-0.03108531  0.09351742  0.         -0.2734961 ]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 4923 is [True, False, False, False, False, True]
Current timestep = 4924. State = [[-0.24615239  0.25217843]]. Action = [[ 0.05494749 -0.0512977   0.         -0.60383725]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 4924 is [True, False, False, False, False, True]
Current timestep = 4925. State = [[-0.24894913  0.25288707]]. Action = [[-0.08055643  0.03918076  0.         -0.0016315 ]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 4925 is [True, False, False, False, False, True]
Current timestep = 4926. State = [[-0.2497485   0.25299817]]. Action = [[ 0.04012946 -0.02739304  0.         -0.58507776]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 4926 is [True, False, False, False, False, True]
Current timestep = 4927. State = [[-0.24636588  0.2540091 ]]. Action = [[ 0.05724875  0.03558557  0.         -0.8943571 ]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 4927 is [True, False, False, False, False, True]
Current timestep = 4928. State = [[-0.24461162  0.259326  ]]. Action = [[0.01137708 0.09676161 0.         0.36659026]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 4928 is [True, False, False, False, False, True]
Current timestep = 4929. State = [[-0.2403008   0.25736457]]. Action = [[ 0.0853345  -0.09122075  0.          0.639045  ]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 4929 is [True, False, False, False, False, True]
State prediction error at timestep 4929 is 0.012
Human Feedback received at timestep 4929 of None
Current timestep = 4930. State = [[-0.23810318  0.25285518]]. Action = [[-0.01540596 -0.03918186  0.         -0.04916275]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 4930 is [True, False, False, False, False, True]
State prediction error at timestep 4930 is 0.012
Human Feedback received at timestep 4930 of None
Current timestep = 4931. State = [[-0.2374893   0.25518265]]. Action = [[0.00747786 0.0737155  0.         0.34397614]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 4931 is [True, False, False, False, False, True]
State prediction error at timestep 4931 is 0.012
Human Feedback received at timestep 4931 of None
Current timestep = 4932. State = [[-0.2330307  0.2543377]]. Action = [[ 0.07627644 -0.05364419  0.         -0.29948962]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 4932 is [True, False, False, False, False, True]
Current timestep = 4933. State = [[-0.23098952  0.24872069]]. Action = [[-0.02557626 -0.08243273  0.         -0.24769396]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 4933 is [True, False, False, False, False, True]
Current timestep = 4934. State = [[-0.2340957   0.24412976]]. Action = [[-0.07933019 -0.05042115  0.          0.06515372]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 4934 is [True, False, False, False, False, True]
Current timestep = 4935. State = [[-0.23694457  0.2394599 ]]. Action = [[-0.03591763 -0.0722097   0.          0.08766079]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 4935 is [True, False, False, False, False, True]
Current timestep = 4936. State = [[-0.23587792  0.23437   ]]. Action = [[ 0.02465029 -0.06031319  0.          0.2099272 ]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 4936 is [True, False, False, False, False, True]
Current timestep = 4937. State = [[-0.23741724  0.23173656]]. Action = [[-0.06050375 -0.00808661  0.         -0.2874571 ]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 4937 is [True, False, False, False, False, True]
State prediction error at timestep 4937 is 0.012
Human Feedback received at timestep 4937 of None
Current timestep = 4938. State = [[-0.2401213   0.22731492]]. Action = [[-0.02957396 -0.07566057  0.         -0.741699  ]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 4938 is [True, False, False, False, False, True]
Current timestep = 4939. State = [[-0.23780116  0.2203146 ]]. Action = [[ 0.05796986 -0.08359239  0.         -0.3712597 ]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 4939 is [True, False, False, False, False, True]
State prediction error at timestep 4939 is 0.012
Human Feedback received at timestep 4939 of None
Current timestep = 4940. State = [[-0.23252822  0.21232142]]. Action = [[ 0.06425264 -0.08175657  0.          0.7326219 ]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 4940 is [True, False, False, False, False, True]
Current timestep = 4941. State = [[-0.22679669  0.20735756]]. Action = [[ 0.06489836 -0.00878457  0.         -0.12460071]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 4941 is [True, False, False, False, False, True]
Current timestep = 4942. State = [[-0.22463109  0.20645155]]. Action = [[-0.00493872  0.03744989  0.         -0.2760496 ]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 4942 is [True, False, False, False, False, True]
Current timestep = 4943. State = [[-0.22187556  0.20294376]]. Action = [[ 0.05011072 -0.04756865  0.         -0.23921847]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 4943 is [True, False, False, False, False, True]
State prediction error at timestep 4943 is 0.012
Human Feedback received at timestep 4943 of None
Current timestep = 4944. State = [[-0.2172519   0.20188454]]. Action = [[0.05813948 0.05205841 0.         0.2844057 ]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 4944 is [True, False, False, False, False, True]
Current timestep = 4945. State = [[-0.21536584  0.20078216]]. Action = [[-0.00108021 -0.0059812   0.          0.9198401 ]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 4945 is [True, False, False, False, False, True]
State prediction error at timestep 4945 is 0.012
Human Feedback received at timestep 4945 of None
Current timestep = 4946. State = [[-0.21161076  0.20307627]]. Action = [[ 0.07335829  0.08793203  0.         -0.77548885]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 4946 is [True, False, False, False, False, True]
Current timestep = 4947. State = [[-0.20776336  0.20295683]]. Action = [[ 0.03365579 -0.01837073  0.         -0.36049652]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 4947 is [True, False, False, False, False, True]
Current timestep = 4948. State = [[-0.20391828  0.20210563]]. Action = [[ 0.0480468   0.01604231  0.         -0.5184789 ]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 4948 is [True, False, False, False, False, True]
Current timestep = 4949. State = [[-0.20035926  0.20344138]]. Action = [[0.03317408 0.03847446 0.         0.45615375]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 4949 is [True, False, False, False, False, True]
Current timestep = 4950. State = [[-0.19791596  0.20672609]]. Action = [[0.01885559 0.05730393 0.         0.4744662 ]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 4950 is [True, False, False, False, False, True]
State prediction error at timestep 4950 is 0.012
Human Feedback received at timestep 4950 of None
Current timestep = 4951. State = [[-0.19815515  0.21179111]]. Action = [[-0.02477127  0.07157194  0.          0.00605154]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 4951 is [True, False, False, False, False, True]
State prediction error at timestep 4951 is 0.012
Human Feedback received at timestep 4951 of None
Current timestep = 4952. State = [[-0.19676545  0.21181254]]. Action = [[ 0.0332334  -0.05137142  0.         -0.2881651 ]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 4952 is [True, False, False, False, False, True]
Current timestep = 4953. State = [[-0.19279939  0.21574008]]. Action = [[ 0.04989516  0.09702668  0.         -0.56015664]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 4953 is [True, False, False, False, False, True]
State prediction error at timestep 4953 is 0.012
Human Feedback received at timestep 4953 of None
Current timestep = 4954. State = [[-0.19383845  0.22181983]]. Action = [[-0.06006768  0.05299897  0.         -0.69019055]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 4954 is [True, False, False, False, False, True]
Current timestep = 4955. State = [[-0.1954685   0.22452562]]. Action = [[-0.00583369 -0.0062963   0.          0.48717713]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 4955 is [True, False, False, False, False, True]
Current timestep = 4956. State = [[-0.1946822   0.23016624]]. Action = [[ 0.01742287  0.08630513  0.         -0.24860287]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 4956 is [True, False, False, False, False, True]
Current timestep = 4957. State = [[-0.19794391  0.23610884]]. Action = [[-0.07418229  0.03735309  0.          0.24064457]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 4957 is [True, False, False, False, False, True]
Current timestep = 4958. State = [[-0.19882336  0.24385531]]. Action = [[ 0.03539211  0.09560689  0.         -0.9783287 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 4958 is [True, False, False, False, False, True]
Current timestep = 4959. State = [[-0.19463214  0.2453737 ]]. Action = [[ 0.07411506 -0.06040057  0.          0.44709182]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 4959 is [True, False, False, False, False, True]
State prediction error at timestep 4959 is 0.012
Human Feedback received at timestep 4959 of None
Current timestep = 4960. State = [[-0.1939898   0.24965388]]. Action = [[-0.03400388  0.08768111  0.         -0.28283894]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 4960 is [True, False, False, False, False, True]
Current timestep = 4961. State = [[-0.18997832  0.2537793 ]]. Action = [[0.09928431 0.00096107 0.         0.90612245]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 4961 is [True, False, False, False, False, True]
State prediction error at timestep 4961 is 0.012
Human Feedback received at timestep 4961 of None
Current timestep = 4962. State = [[-0.18874222  0.252905  ]]. Action = [[-0.04579953 -0.05496116  0.         -0.44999087]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 4962 is [True, False, False, False, False, True]
Current timestep = 4963. State = [[-0.19221424  0.2549828 ]]. Action = [[-0.0595412   0.03917991  0.          0.18156254]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 4963 is [True, False, False, False, False, True]
Current timestep = 4964. State = [[-0.18899739  0.257056  ]]. Action = [[ 0.09592815 -0.00587063  0.          0.39374042]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 4964 is [True, False, False, False, False, True]
Current timestep = 4965. State = [[-0.18848798  0.25340864]]. Action = [[-0.06645367 -0.09884493  0.          0.85484326]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 4965 is [True, False, False, False, False, True]
Current timestep = 4966. State = [[-0.18685208  0.24795385]]. Action = [[ 0.05182254 -0.07000241  0.          0.00076485]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 4966 is [True, False, False, False, False, True]
Current timestep = 4967. State = [[-0.18781856  0.24576116]]. Action = [[-0.06633462 -0.00557247  0.          0.20292151]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 4967 is [True, False, False, False, False, True]
State prediction error at timestep 4967 is 0.012
Human Feedback received at timestep 4967 of None
Current timestep = 4968. State = [[-0.18438181  0.24131006]]. Action = [[ 0.08991732 -0.08485121  0.          0.7090733 ]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 4968 is [True, False, False, False, False, True]
Current timestep = 4969. State = [[-0.18063657  0.24165711]]. Action = [[ 0.00967357  0.07536795  0.         -0.8309622 ]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 4969 is [True, False, False, False, False, True]
Current timestep = 4970. State = [[-0.18012047  0.24502878]]. Action = [[-0.00404109  0.04652274  0.          0.83218336]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 4970 is [True, False, False, False, False, True]
Current timestep = 4971. State = [[-0.18059786  0.24720985]]. Action = [[-0.00953785  0.02837882  0.          0.27438438]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 4971 is [True, False, False, False, False, True]
State prediction error at timestep 4971 is 0.012
Human Feedback received at timestep 4971 of None
Current timestep = 4972. State = [[-0.18026476  0.24959892]]. Action = [[0.01431896 0.04000887 0.         0.9927757 ]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 4972 is [True, False, False, False, False, True]
Current timestep = 4973. State = [[-0.18150361  0.24605314]]. Action = [[-0.03586466 -0.09420603  0.         -0.0653559 ]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 4973 is [True, False, False, False, False, True]
Current timestep = 4974. State = [[-0.1788108   0.23946989]]. Action = [[ 0.06790011 -0.07813235  0.         -0.11544478]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 4974 is [True, False, False, False, False, True]
Current timestep = 4975. State = [[-0.17203398  0.23784518]]. Action = [[ 0.09175914  0.03422233  0.         -0.1067782 ]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 4975 is [True, False, False, False, False, True]
State prediction error at timestep 4975 is 0.012
Human Feedback received at timestep 4975 of None
Current timestep = 4976. State = [[-0.1707418  0.2355693]]. Action = [[-0.04546268 -0.04479923  0.          0.06439817]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 4976 is [True, False, False, False, False, True]
Current timestep = 4977. State = [[-0.17263462  0.23423046]]. Action = [[-0.02397338  0.01385199  0.         -0.5458755 ]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 4977 is [True, False, False, False, False, True]
Current timestep = 4978. State = [[-0.17184386  0.23353708]]. Action = [[ 0.02842139 -0.00417063  0.          0.86972296]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 4978 is [True, False, False, False, False, True]
Current timestep = 4979. State = [[-0.16964659  0.23522756]]. Action = [[ 0.02995963  0.05671441  0.         -0.93356603]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 4979 is [True, False, False, False, False, True]
State prediction error at timestep 4979 is 0.012
Human Feedback received at timestep 4979 of None
Current timestep = 4980. State = [[-0.16542216  0.23297891]]. Action = [[ 0.06969031 -0.05704093  0.          0.07165849]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 4980 is [True, False, False, False, False, True]
Current timestep = 4981. State = [[-0.16357176  0.22569005]]. Action = [[-0.01557881 -0.09928074  0.          0.61020637]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 4981 is [True, False, False, False, False, True]
Current timestep = 4982. State = [[-0.1643495   0.22560424]]. Action = [[-0.02439194  0.07177181  0.          0.45977223]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 4982 is [True, False, False, False, False, True]
Current timestep = 4983. State = [[-0.16403127  0.23139435]]. Action = [[0.02055876 0.09358796 0.         0.31234825]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 4983 is [True, False, False, False, False, True]
Current timestep = 4984. State = [[-0.16631     0.23648511]]. Action = [[-0.04911305  0.05611973  0.         -0.6050762 ]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 4984 is [True, False, False, False, False, True]
Current timestep = 4985. State = [[-0.1686569   0.23965634]]. Action = [[-0.00858817  0.02524524  0.          0.89573646]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 4985 is [True, False, False, False, False, True]
Current timestep = 4986. State = [[-0.17043364  0.24126713]]. Action = [[-0.01721326  0.00674293  0.         -0.41970623]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 4986 is [True, False, False, False, False, True]
State prediction error at timestep 4986 is 0.012
Human Feedback received at timestep 4986 of None
Current timestep = 4987. State = [[-0.1725475   0.23936005]]. Action = [[-0.02430394 -0.05968896  0.         -0.5440533 ]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 4987 is [True, False, False, False, False, True]
Current timestep = 4988. State = [[-0.17320365  0.23444198]]. Action = [[ 6.709099e-04 -8.455366e-02  0.000000e+00  7.041595e-01]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 4988 is [True, False, False, False, False, True]
Current timestep = 4989. State = [[-0.16837427  0.23096566]]. Action = [[ 0.09560043 -0.02575566  0.         -0.86410224]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 4989 is [True, False, False, False, False, True]
Current timestep = 4990. State = [[-0.16029257  0.22555777]]. Action = [[ 0.09807818 -0.08123525  0.         -0.7811532 ]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 4990 is [True, False, False, False, False, True]
Current timestep = 4991. State = [[-0.15832192  0.22498235]]. Action = [[-0.04022149  0.05622555  0.          0.50267076]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 4991 is [True, False, False, False, False, True]
Current timestep = 4992. State = [[-0.15568295  0.23026279]]. Action = [[ 0.06357373  0.09302265  0.         -0.21047348]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 4992 is [True, False, False, False, False, True]
Current timestep = 4993. State = [[-0.15476136  0.22876807]]. Action = [[-0.03534085 -0.07808496  0.         -0.58366054]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 4993 is [True, False, False, False, False, True]
Current timestep = 4994. State = [[-0.15807891  0.22527434]]. Action = [[-0.06232557 -0.02491208  0.         -0.20067787]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 4994 is [True, False, False, False, False, True]
Current timestep = 4995. State = [[-0.16293815  0.22662377]]. Action = [[-0.06858699  0.04235478  0.          0.03840578]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 4995 is [True, False, False, False, False, True]
Current timestep = 4996. State = [[-0.16430221  0.229945  ]]. Action = [[0.02050315 0.04108026 0.         0.73262525]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 4996 is [True, False, False, False, False, True]
Current timestep = 4997. State = [[-0.16005266  0.22872993]]. Action = [[ 0.08914494 -0.04471712  0.          0.2805103 ]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 4997 is [True, False, False, False, False, True]
Current timestep = 4998. State = [[-0.15606871  0.23003508]]. Action = [[0.03716626 0.06487351 0.         0.12348962]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 4998 is [True, False, False, False, False, True]
Current timestep = 4999. State = [[-0.15605316  0.2335596 ]]. Action = [[-0.01520351  0.04637092  0.          0.01177192]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 4999 is [True, False, False, False, False, True]
Current timestep = 5000. State = [[-0.15955986  0.23456602]]. Action = [[-0.05805321 -0.00951654  0.         -0.7094685 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 5000 is [True, False, False, False, False, True]
State prediction error at timestep 5000 is 0.012
Human Feedback received at timestep 5000 of None
Current timestep = 5001. State = [[-0.15972836  0.23806205]]. Action = [[0.03940243 0.06901964 0.         0.5301795 ]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 5001 is [True, False, False, False, False, True]
Current timestep = 5002. State = [[-0.16382785  0.24426748]]. Action = [[-0.0943585   0.07516103  0.          0.6765189 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 5002 is [True, False, False, False, False, True]
Current timestep = 5003. State = [[-0.16883941  0.24639645]]. Action = [[-0.03515244 -0.02701104  0.         -0.18542206]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 5003 is [True, False, False, False, False, True]
Current timestep = 5004. State = [[-0.16676328  0.25124523]]. Action = [[ 0.08975389  0.09435251  0.         -0.34137875]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 5004 is [True, False, False, False, False, True]
Current timestep = 5005. State = [[-0.16832677  0.25862497]]. Action = [[-0.06957749  0.07245969  0.          0.140998  ]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 5005 is [True, False, False, False, False, True]
State prediction error at timestep 5005 is 0.012
Human Feedback received at timestep 5005 of None
Current timestep = 5006. State = [[-0.166561    0.26155964]]. Action = [[ 0.08900387 -0.01272263  0.         -0.23418415]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 5006 is [True, False, False, False, False, True]
Current timestep = 5007. State = [[-0.16296007  0.2640926 ]]. Action = [[0.03268341 0.03626171 0.         0.2880814 ]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 5007 is [True, False, False, False, False, True]
Current timestep = 5008. State = [[-0.15779066  0.26550046]]. Action = [[ 0.08525684 -0.00896683  0.          0.42451453]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 5008 is [True, False, False, False, False, True]
Current timestep = 5009. State = [[-0.15724185  0.26459053]]. Action = [[-0.05212478 -0.03358271  0.          0.01685035]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 5009 is [True, False, False, False, False, True]
State prediction error at timestep 5009 is 0.012
Human Feedback received at timestep 5009 of None
Current timestep = 5010. State = [[-0.15358466  0.26638657]]. Action = [[0.09498664 0.04370751 0.         0.6410105 ]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 5010 is [True, False, False, False, False, True]
State prediction error at timestep 5010 is 0.012
Human Feedback received at timestep 5010 of None
Current timestep = 5011. State = [[-0.14731191  0.26839846]]. Action = [[ 0.05531415  0.00809015  0.         -0.11424887]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 5011 is [True, False, False, False, False, True]
Current timestep = 5012. State = [[-0.13997361  0.26718783]]. Action = [[ 0.08653838 -0.03616505  0.          0.405151  ]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 5012 is [True, False, False, False, False, True]
State prediction error at timestep 5012 is 0.012
Human Feedback received at timestep 5012 of None
Current timestep = 5013. State = [[-0.13844648  0.2663847 ]]. Action = [[-0.05962104 -0.00194853  0.          0.59308314]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 5013 is [True, False, False, False, False, True]
Current timestep = 5014. State = [[-0.14126013  0.27006552]]. Action = [[-0.06228128  0.05958905  0.          0.80409193]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 5014 is [True, False, False, False, False, True]
Current timestep = 5015. State = [[-0.14187291  0.27583468]]. Action = [[0.00420706 0.06117367 0.         0.7789545 ]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 5015 is [True, False, False, False, False, True]
Current timestep = 5016. State = [[-0.13683565  0.28197116]]. Action = [[0.09481136 0.07316843 0.         0.79558754]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 5016 is [True, False, False, False, False, True]
Current timestep = 5017. State = [[-0.13351008  0.2850676 ]]. Action = [[0.00467704 0.00760566 0.         0.4389274 ]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 5017 is [True, False, False, False, False, True]
Current timestep = 5018. State = [[-0.13153309  0.28534186]]. Action = [[ 0.02147983 -0.01788694  0.         -0.1632095 ]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 5018 is [True, False, False, False, False, True]
Current timestep = 5019. State = [[-0.13388996  0.2858261 ]]. Action = [[-0.07929958 -0.0030036   0.          0.8474258 ]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 5019 is [True, False, False, False, False, True]
Current timestep = 5020. State = [[-0.13545382  0.289372  ]]. Action = [[-0.00091965  0.04451128  0.         -0.8121607 ]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 5020 is [True, False, False, False, False, True]
State prediction error at timestep 5020 is 0.012
Human Feedback received at timestep 5020 of None
Current timestep = 5021. State = [[-0.13648704  0.2887057 ]]. Action = [[-0.02962884 -0.06938742  0.          0.0672518 ]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 5021 is [True, False, False, False, False, True]
State prediction error at timestep 5021 is 0.012
Human Feedback received at timestep 5021 of None
Current timestep = 5022. State = [[-0.13407402  0.28650576]]. Action = [[ 0.04963171 -0.03297371  0.         -0.35362262]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 5022 is [True, False, False, False, False, True]
Current timestep = 5023. State = [[-0.13654041  0.28943512]]. Action = [[-0.09270685  0.06201332  0.          0.10065174]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 5023 is [True, False, False, False, False, True]
Current timestep = 5024. State = [[-0.13993831  0.2935573 ]]. Action = [[-0.02029266  0.02149574  0.          0.61200726]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 5024 is [True, False, False, False, False, True]
Current timestep = 5025. State = [[-0.13637446  0.29188898]]. Action = [[ 0.0874899  -0.06827626  0.          0.14929688]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 5025 is [True, False, False, False, False, True]
Current timestep = 5026. State = [[-0.1314973   0.28758013]]. Action = [[ 0.04120075 -0.05388157  0.         -0.71795595]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 5026 is [True, False, False, False, False, True]
Current timestep = 5027. State = [[-0.12895349  0.28322393]]. Action = [[ 0.00687345 -0.05421723  0.          0.18541169]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 5027 is [True, False, False, False, False, True]
State prediction error at timestep 5027 is 0.012
Human Feedback received at timestep 5027 of None
Current timestep = 5028. State = [[-0.12720393  0.28302026]]. Action = [[0.01093128 0.03504042 0.         0.49819088]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 5028 is [True, False, False, False, False, True]
Current timestep = 5029. State = [[-0.12887879  0.28237766]]. Action = [[-0.05600561 -0.02510104  0.         -0.2314521 ]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 5029 is [True, False, False, False, False, True]
Current timestep = 5030. State = [[-0.13225338  0.28128204]]. Action = [[-0.05042109 -0.0094593   0.         -0.13561147]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 5030 is [True, False, False, False, False, True]
Current timestep = 5031. State = [[-0.13337646  0.28042227]]. Action = [[ 0.00119753 -0.01273955  0.          0.7920146 ]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 5031 is [True, False, False, False, False, True]
Current timestep = 5032. State = [[-0.1335693   0.27750102]]. Action = [[-0.00671305 -0.04968707  0.         -0.5170739 ]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 5032 is [True, False, False, False, False, True]
State prediction error at timestep 5032 is 0.012
Human Feedback received at timestep 5032 of None
Current timestep = 5033. State = [[-0.13417813  0.27418047]]. Action = [[-0.01320636 -0.03419099  0.          0.70908666]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 5033 is [True, False, False, False, False, True]
State prediction error at timestep 5033 is 0.012
Human Feedback received at timestep 5033 of None
Current timestep = 5034. State = [[-0.1331768   0.27730927]]. Action = [[0.03378183 0.09698807 0.         0.810699  ]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 5034 is [True, False, False, False, False, True]
Current timestep = 5035. State = [[-0.13028741  0.28374735]]. Action = [[0.05857977 0.09577923 0.         0.0549345 ]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 5035 is [True, False, False, False, False, True]
Current timestep = 5036. State = [[-0.13331409  0.2840187 ]]. Action = [[-0.09667309 -0.05404884  0.         -0.61087656]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 5036 is [True, False, False, False, False, True]
Current timestep = 5037. State = [[-0.14072506  0.28602168]]. Action = [[-0.07112078  0.0722665   0.         -0.53023857]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 5037 is [True, False, False, False, False, True]
Current timestep = 5038. State = [[-0.1421005  0.2910972]]. Action = [[ 0.06146764  0.07080539  0.         -0.45506108]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 5038 is [True, False, False, False, False, True]
Current timestep = 5039. State = [[-0.14533517  0.2940284 ]]. Action = [[-0.05754403  0.02128677  0.         -0.6462062 ]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 5039 is [True, False, False, False, False, True]
Current timestep = 5040. State = [[-0.1525036   0.29355684]]. Action = [[-0.07595213 -0.03034353  0.          0.35887933]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 5040 is [True, False, False, False, False, True]
Current timestep = 5041. State = [[-0.15197918  0.29334167]]. Action = [[0.09752756 0.00966624 0.         0.1782726 ]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 5041 is [True, False, False, False, False, True]
Current timestep = 5042. State = [[-0.14757544  0.29035068]]. Action = [[ 0.05825134 -0.06264863  0.         -0.5986012 ]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 5042 is [True, False, False, False, False, True]
Current timestep = 5043. State = [[-0.14579707  0.28970152]]. Action = [[0.0064614  0.02781848 0.         0.84080386]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 5043 is [True, False, False, False, False, True]
Current timestep = 5044. State = [[-0.14188206  0.29028568]]. Action = [[0.07827332 0.00612068 0.         0.7927593 ]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 5044 is [True, False, False, False, False, True]
Current timestep = 5045. State = [[-0.13906847  0.29434127]]. Action = [[ 0.01355517  0.09337436  0.         -0.36887622]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 5045 is [True, False, False, False, False, True]
Current timestep = 5046. State = [[-0.1362213  0.2934599]]. Action = [[ 0.04632051 -0.06096501  0.         -0.40827423]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 5046 is [True, False, False, False, False, True]
Current timestep = 5047. State = [[-0.13177606  0.29425344]]. Action = [[0.05156618 0.05834321 0.         0.01207697]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 5047 is [True, False, False, False, False, True]
Current timestep = 5048. State = [[-0.12831655  0.2943165 ]]. Action = [[ 0.02614006 -0.02040046  0.         -0.807176  ]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 5048 is [True, False, False, False, False, True]
Current timestep = 5049. State = [[-0.1227455  0.293773 ]]. Action = [[0.0766191  0.0070285  0.         0.45973814]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 5049 is [True, False, False, False, False, True]
Current timestep = 5050. State = [[-0.11874502  0.2958851 ]]. Action = [[0.0143577  0.05024987 0.         0.55515957]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 5050 is [True, False, False, False, False, True]
Current timestep = 5051. State = [[-0.11927831  0.2946124 ]]. Action = [[-0.0504684  -0.05732831  0.         -0.22356248]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 5051 is [True, False, False, False, False, True]
Current timestep = 5052. State = [[-0.11819683  0.29476818]]. Action = [[0.02420416 0.02722689 0.         0.7418511 ]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 5052 is [True, False, False, False, False, True]
Current timestep = 5053. State = [[-0.11157253  0.2937948 ]]. Action = [[ 0.09907716 -0.03636877  0.          0.24074185]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 5053 is [True, False, False, False, False, True]
State prediction error at timestep 5053 is 0.012
Human Feedback received at timestep 5053 of None
Current timestep = 5054. State = [[-0.11011862  0.2944145 ]]. Action = [[-0.05516894  0.03439855  0.          0.79220915]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 5054 is [True, False, False, False, False, True]
Current timestep = 5055. State = [[-0.11252123  0.2922296 ]]. Action = [[-0.04899151 -0.0779827   0.         -0.14721751]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 5055 is [True, False, False, False, False, True]
Current timestep = 5056. State = [[-0.11092015  0.29299322]]. Action = [[ 0.04117808  0.0472733   0.         -0.9289016 ]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 5056 is [True, False, False, False, False, True]
Current timestep = 5057. State = [[-0.10397871  0.29482594]]. Action = [[0.09873945 0.00522538 0.         0.0331707 ]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 5057 is [True, False, False, False, False, True]
Current timestep = 5058. State = [[-0.09674666  0.2908556 ]]. Action = [[ 0.06310793 -0.08342497  0.         -0.43305433]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 5058 is [True, False, False, False, False, True]
Current timestep = 5059. State = [[-0.09178843  0.29052448]]. Action = [[0.02671733 0.04771284 0.         0.04412031]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 5059 is [True, False, False, False, False, True]
Current timestep = 5060. State = [[-0.08676811  0.29601392]]. Action = [[0.06152961 0.09849688 0.         0.492509  ]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 5060 is [True, False, False, False, False, True]
State prediction error at timestep 5060 is 0.012
Human Feedback received at timestep 5060 of None
Current timestep = 5061. State = [[-0.08581314  0.298153  ]]. Action = [[-0.04162375 -0.01203001  0.         -0.38834244]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 5061 is [True, False, False, False, False, True]
Current timestep = 5062. State = [[-0.08159871  0.29663488]]. Action = [[ 0.09090637 -0.02538507  0.         -0.19391537]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 5062 is [True, False, False, False, False, True]
Current timestep = 5063. State = [[-0.07799605  0.29133484]]. Action = [[-0.00438121 -0.08976235  0.         -0.70086616]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 5063 is [True, False, False, False, False, True]
Current timestep = 5064. State = [[-0.07978779  0.28544107]]. Action = [[-0.07515256 -0.07066099  0.          0.42495131]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 5064 is [True, False, False, False, False, True]
Current timestep = 5065. State = [[-0.08077341  0.28757137]]. Action = [[-0.00195114  0.08563184  0.         -0.9490989 ]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 5065 is [True, False, False, False, False, True]
Current timestep = 5066. State = [[-0.08259363  0.2930095 ]]. Action = [[-0.05031908  0.05402573  0.          0.6574905 ]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 5066 is [True, False, False, False, False, True]
Current timestep = 5067. State = [[-0.08230146  0.29201972]]. Action = [[ 0.02157025 -0.07090214  0.          0.45999205]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 5067 is [True, False, False, False, False, True]
Current timestep = 5068. State = [[-0.08452144  0.29171878]]. Action = [[-0.07378291  0.01644888  0.          0.23937786]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 5068 is [True, False, False, False, False, True]
Current timestep = 5069. State = [[-0.08538659  0.29247984]]. Action = [[ 0.01369168 -0.01282898  0.          0.12722206]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 5069 is [True, False, False, False, False, True]
Current timestep = 5070. State = [[-0.0849028   0.28860283]]. Action = [[-0.0068369  -0.08766472  0.          0.5439409 ]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 5070 is [True, False, False, False, False, True]
Current timestep = 5071. State = [[-0.08387785  0.2896883 ]]. Action = [[0.01549298 0.06563305 0.         0.05609906]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 5071 is [True, False, False, False, False, True]
State prediction error at timestep 5071 is 0.012
Human Feedback received at timestep 5071 of None
Current timestep = 5072. State = [[-0.07944961  0.29404968]]. Action = [[0.08745185 0.05650645 0.         0.11515737]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 5072 is [True, False, False, False, False, True]
Current timestep = 5073. State = [[-0.0758829   0.29390466]]. Action = [[ 0.0282983  -0.02730609  0.         -0.08498794]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 5073 is [True, False, False, False, False, True]
Current timestep = 5074. State = [[-0.07901088  0.29132947]]. Action = [[-0.09250157 -0.03767032  0.          0.30110204]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 5074 is [True, False, False, False, False, True]
State prediction error at timestep 5074 is 0.012
Human Feedback received at timestep 5074 of None
Current timestep = 5075. State = [[-0.08611505  0.2937352 ]]. Action = [[-0.09917638  0.06116559  0.         -0.776475  ]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 5075 is [True, False, False, False, False, True]
Current timestep = 5076. State = [[-0.08579348  0.29872906]]. Action = [[0.09056046 0.06453042 0.         0.4356358 ]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 5076 is [True, False, False, False, False, True]
Current timestep = 5077. State = [[-0.0852236   0.30176902]]. Action = [[-0.02267888  0.01646833  0.         -0.74018997]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 5077 is [True, False, False, False, False, True]
State prediction error at timestep 5077 is 0.012
Human Feedback received at timestep 5077 of None
Current timestep = 5078. State = [[-0.08830868  0.30233106]]. Action = [[-0.0433254  -0.01357059  0.         -0.12553358]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 5078 is [True, False, False, False, False, True]
Current timestep = 5079. State = [[-0.09387414  0.30559045]]. Action = [[-0.07964674  0.05217641  0.          0.70377326]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 5079 is [True, False, False, False, False, True]
State prediction error at timestep 5079 is 0.012
Human Feedback received at timestep 5079 of None
Current timestep = 5080. State = [[-0.09529774  0.3073373 ]]. Action = [[ 0.03336244 -0.01863738  0.         -0.09075004]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 5080 is [True, False, False, False, False, True]
Current timestep = 5081. State = [[-0.09235319  0.30781475]]. Action = [[ 0.05886561  0.00527023  0.         -0.9496487 ]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 5081 is [True, False, False, False, False, True]
Current timestep = 5082. State = [[-0.09210165  0.3112826 ]]. Action = [[-0.01455598  0.06279238  0.          0.27342713]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 5082 is [True, False, False, False, False, True]
Current timestep = 5083. State = [[-0.0949719   0.31531873]]. Action = [[-0.03505438  0.03620955  0.         -0.2986396 ]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 5083 is [True, False, False, False, False, True]
Current timestep = 5084. State = [[-0.09586817  0.31257457]]. Action = [[ 0.01212643 -0.09402002  0.          0.4009087 ]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 5084 is [True, False, False, False, False, True]
State prediction error at timestep 5084 is 0.012
Human Feedback received at timestep 5084 of None
Current timestep = 5085. State = [[-0.09213119  0.31083515]]. Action = [[ 0.07252087  0.01163862  0.         -0.13436258]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 5085 is [True, False, False, False, False, True]
Current timestep = 5086. State = [[-0.0897191   0.31118304]]. Action = [[0.00518467 0.00590446 0.         0.00041914]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 5086 is [True, False, False, False, False, True]
Current timestep = 5087. State = [[-0.08544729  0.31447366]]. Action = [[ 0.08280899  0.07199591  0.         -0.98375523]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 5087 is [True, False, False, False, False, True]
State prediction error at timestep 5087 is 0.012
Human Feedback received at timestep 5087 of None
Current timestep = 5088. State = [[-0.08035851  0.3136921 ]]. Action = [[ 0.05317623 -0.04460401  0.          0.3299837 ]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 5088 is [True, False, False, False, False, True]
Current timestep = 5089. State = [[-0.07563806  0.31507272]]. Action = [[ 0.05305699  0.06733563  0.         -0.24187177]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 5089 is [True, False, False, False, False, True]
Current timestep = 5090. State = [[-0.07578817  0.31667188]]. Action = [[-0.04868874  0.00443913  0.          0.8700273 ]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 5090 is [True, False, False, False, False, True]
Current timestep = 5091. State = [[-0.08060923  0.31716284]]. Action = [[-0.08680212  0.00054719  0.         -0.19037569]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 5091 is [True, False, False, False, False, True]
Current timestep = 5092. State = [[-0.08346019  0.31348583]]. Action = [[-0.02536016 -0.09579869  0.          0.17565262]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 5092 is [True, False, False, False, False, True]
State prediction error at timestep 5092 is 0.012
Human Feedback received at timestep 5092 of None
Current timestep = 5093. State = [[-0.08567195  0.30853543]]. Action = [[-0.0528828  -0.06934036  0.          0.79361105]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 5093 is [True, False, False, False, False, True]
Current timestep = 5094. State = [[-0.08408076  0.3072014 ]]. Action = [[0.04789732 0.00269993 0.         0.811404  ]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 5094 is [True, False, False, False, False, True]
Current timestep = 5095. State = [[-0.08596025  0.3110917 ]]. Action = [[-0.07714773  0.06946901  0.          0.9689957 ]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 5095 is [True, False, False, False, False, True]
Current timestep = 5096. State = [[-0.08627523  0.31586778]]. Action = [[0.03697055 0.04213711 0.         0.10851431]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 5096 is [True, False, False, False, False, True]
Current timestep = 5097. State = [[-0.08559267  0.3196753 ]]. Action = [[ 0.00352298  0.04166377  0.         -0.7003392 ]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 5097 is [True, False, False, False, False, True]
State prediction error at timestep 5097 is 0.012
Human Feedback received at timestep 5097 of None
Current timestep = 5098. State = [[-0.08293357  0.32147446]]. Action = [[ 0.06184093  0.00507124  0.         -0.28569245]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 5098 is [True, False, False, False, False, True]
Current timestep = 5099. State = [[-0.08185    0.3194959]]. Action = [[-0.01069216 -0.04777759  0.         -0.3885439 ]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 5099 is [True, False, False, False, False, True]
Current timestep = 5100. State = [[-0.08612694  0.31480214]]. Action = [[-0.0954418  -0.08127506  0.         -0.2843809 ]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 5100 is [True, False, False, False, False, True]
Current timestep = 5101. State = [[-0.0900669  0.3171182]]. Action = [[-0.02549489  0.08483957  0.         -0.44354618]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 5101 is [True, False, False, False, False, True]
Current timestep = 5102. State = [[-0.08757843  0.32025185]]. Action = [[ 0.073169    0.00623722  0.         -0.12469679]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 5102 is [True, False, False, False, False, True]
State prediction error at timestep 5102 is 0.012
Human Feedback received at timestep 5102 of None
Current timestep = 5103. State = [[-0.08259278  0.32353568]]. Action = [[ 0.0692263   0.06308659  0.         -0.7652308 ]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 5103 is [True, False, False, False, False, True]
Current timestep = 5104. State = [[-0.07855046  0.32915297]]. Action = [[ 0.05396441  0.09000557  0.         -0.71083087]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 5104 is [True, False, False, False, False, True]
Current timestep = 5105. State = [[-0.08073493  0.32941428]]. Action = [[-0.09177499 -0.06134063  0.          0.20526028]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 5105 is [True, False, False, False, False, True]
Current timestep = 5106. State = [[-0.08851133  0.33240822]]. Action = [[-0.09780743  0.08568089  0.         -0.6006637 ]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 5106 is [True, False, False, False, False, True]
State prediction error at timestep 5106 is 0.012
Human Feedback received at timestep 5106 of None
Current timestep = 5107. State = [[-0.08931817  0.3371639 ]]. Action = [[ 0.07828959  0.04573979  0.         -0.2970376 ]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 5107 is [True, False, False, False, False, True]
Current timestep = 5108. State = [[-0.08879648  0.33864304]]. Action = [[ 0.          0.          0.         -0.34283626]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 5108 is [True, False, False, False, False, True]
State prediction error at timestep 5108 is 0.012
Human Feedback received at timestep 5108 of None
Current timestep = 5109. State = [[-0.09300507  0.3358638 ]]. Action = [[-0.07513207 -0.07220501  0.         -0.49848378]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 5109 is [True, False, False, False, False, True]
Current timestep = 5110. State = [[-0.0937393   0.33074692]]. Action = [[ 0.03198136 -0.07922067  0.          0.6999917 ]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 5110 is [True, False, False, False, False, True]
Current timestep = 5111. State = [[-0.08995987  0.33097878]]. Action = [[0.06890819 0.05705897 0.         0.6672449 ]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 5111 is [True, False, False, False, False, True]
Current timestep = 5112. State = [[-0.0837011   0.32741192]]. Action = [[ 0.08994862 -0.08791141  0.         -0.25519836]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 5112 is [True, False, False, False, False, True]
Current timestep = 5113. State = [[-0.07690638  0.32136592]]. Action = [[ 0.07000326 -0.05020545  0.          0.11476076]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 5113 is [True, False, False, False, False, True]
Current timestep = 5114. State = [[-0.07853442  0.3219314 ]]. Action = [[-0.09996582  0.06951993  0.         -0.7707422 ]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 5114 is [True, False, False, False, False, True]
Current timestep = 5115. State = [[-0.07613242  0.32360408]]. Action = [[0.0961872  0.01134541 0.         0.13935208]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 5115 is [True, False, False, False, False, True]
Current timestep = 5116. State = [[-0.07150672  0.31886956]]. Action = [[ 0.02397008 -0.0888042   0.         -0.35534155]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 5116 is [True, False, False, False, False, True]
State prediction error at timestep 5116 is 0.012
Human Feedback received at timestep 5116 of None
Current timestep = 5117. State = [[-0.06544404  0.31737775]]. Action = [[0.09163856 0.04842598 0.         0.3848971 ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 5117 is [True, False, False, False, False, True]
Current timestep = 5118. State = [[-0.05774315  0.32172334]]. Action = [[0.09203713 0.09979814 0.         0.79910326]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 5118 is [True, False, False, False, False, True]
Current timestep = 5119. State = [[-0.05047552  0.32461214]]. Action = [[ 0.08759912  0.03836625  0.         -0.513871  ]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 5119 is [True, False, False, False, False, True]
Current timestep = 5120. State = [[-0.0485645   0.32070038]]. Action = [[-0.05376165 -0.09537379  0.         -0.16236109]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 5120 is [True, False, False, False, False, True]
State prediction error at timestep 5120 is 0.012
Human Feedback received at timestep 5120 of None
Current timestep = 5121. State = [[-0.04968456  0.31933185]]. Action = [[-0.01624952  0.03988986  0.          0.26331663]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 5121 is [False, True, False, False, False, True]
State prediction error at timestep 5121 is 0.012
Human Feedback received at timestep 5121 of None
Current timestep = 5122. State = [[-0.04854659  0.32029667]]. Action = [[0.02672181 0.01370688 0.         0.6422372 ]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 5122 is [False, True, False, False, False, True]
Current timestep = 5123. State = [[-0.04358325  0.31901392]]. Action = [[ 0.08120266 -0.01964889  0.         -0.12327319]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 5123 is [False, True, False, False, False, True]
State prediction error at timestep 5123 is 0.012
Human Feedback received at timestep 5123 of None
Current timestep = 5124. State = [[-0.04203336  0.31711695]]. Action = [[-0.02732798 -0.01275075  0.          0.09265959]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 5124 is [False, True, False, False, False, True]
Current timestep = 5125. State = [[-0.03978618  0.3149877 ]]. Action = [[ 0.0433351 -0.0267649  0.         0.9876512]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 5125 is [False, True, False, False, False, True]
Current timestep = 5126. State = [[-0.04154452  0.31356162]]. Action = [[-0.08223546 -0.00923654  0.         -0.4765228 ]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 5126 is [False, True, False, False, False, True]
State prediction error at timestep 5126 is 0.012
Human Feedback received at timestep 5126 of None
Current timestep = 5127. State = [[-0.04756439  0.31862983]]. Action = [[-0.0953788   0.09757657  0.          0.4690094 ]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 5127 is [False, True, False, False, False, True]
Current timestep = 5128. State = [[-0.05394059  0.31900606]]. Action = [[-0.08224174 -0.07795773  0.          0.2446444 ]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 5128 is [False, True, False, False, False, True]
Current timestep = 5129. State = [[-0.05930192  0.32193035]]. Action = [[-0.06430633  0.06495591  0.         -0.22210401]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 5129 is [True, False, False, False, False, True]
State prediction error at timestep 5129 is 0.012
Human Feedback received at timestep 5129 of None
Current timestep = 5130. State = [[-0.05927116  0.32252043]]. Action = [[ 0.04661597 -0.0572664   0.         -0.8574849 ]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 5130 is [True, False, False, False, False, True]
Current timestep = 5131. State = [[-0.06178957  0.32006875]]. Action = [[-0.07843394 -0.04741547  0.         -0.6148753 ]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 5131 is [True, False, False, False, False, True]
Current timestep = 5132. State = [[-0.06420445  0.31885058]]. Action = [[-0.00892463 -0.02369165  0.         -0.95048   ]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 5132 is [True, False, False, False, False, True]
State prediction error at timestep 5132 is 0.012
Human Feedback received at timestep 5132 of None
Current timestep = 5133. State = [[-0.06406346  0.31930938]]. Action = [[ 0.01256968  0.0075113   0.         -0.2657439 ]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 5133 is [True, False, False, False, False, True]
State prediction error at timestep 5133 is 0.012
Human Feedback received at timestep 5133 of None
Current timestep = 5134. State = [[-0.06543577  0.32464468]]. Action = [[-0.02173544  0.09851887  0.         -0.2775514 ]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 5134 is [True, False, False, False, False, True]
Current timestep = 5135. State = [[-0.06482548  0.32876936]]. Action = [[0.05104088 0.02492715 0.         0.9215971 ]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 5135 is [True, False, False, False, False, True]
Current timestep = 5136. State = [[-0.06564996  0.3302701 ]]. Action = [[-0.02045845  0.01453002  0.          0.9953989 ]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 5136 is [True, False, False, False, False, True]
Current timestep = 5137. State = [[-0.0706674   0.33102268]]. Action = [[-0.07367598  0.00068643  0.          0.29367208]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 5137 is [True, False, False, False, False, True]
State prediction error at timestep 5137 is 0.012
Human Feedback received at timestep 5137 of None
Current timestep = 5138. State = [[-0.07157511  0.33257952]]. Action = [[ 0.04564431  0.02406447  0.         -0.26387906]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 5138 is [True, False, False, False, False, True]
Current timestep = 5139. State = [[-0.07006277  0.32988262]]. Action = [[ 0.02167509 -0.07081451  0.         -0.29233295]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 5139 is [True, False, False, False, False, True]
Current timestep = 5140. State = [[-0.06891144  0.32346147]]. Action = [[ 0.00787346 -0.09060896  0.         -0.2580403 ]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 5140 is [True, False, False, False, False, True]
State prediction error at timestep 5140 is 0.012
Human Feedback received at timestep 5140 of None
Current timestep = 5141. State = [[-0.0654309   0.32122228]]. Action = [[ 0.06067403  0.02034302  0.         -0.41846645]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 5141 is [True, False, False, False, False, True]
State prediction error at timestep 5141 is 0.012
Human Feedback received at timestep 5141 of None
Current timestep = 5142. State = [[-0.06475256  0.31887224]]. Action = [[-0.03323068 -0.04330898  0.         -0.2442618 ]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 5142 is [True, False, False, False, False, True]
Current timestep = 5143. State = [[-0.06493465  0.31776914]]. Action = [[0.00220057 0.01446392 0.         0.7329527 ]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 5143 is [True, False, False, False, False, True]
State prediction error at timestep 5143 is 0.012
Human Feedback received at timestep 5143 of None
Current timestep = 5144. State = [[-0.06938531  0.32113957]]. Action = [[-0.095118    0.07063498  0.          0.4536823 ]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 5144 is [True, False, False, False, False, True]
Current timestep = 5145. State = [[-0.07588325  0.32576331]]. Action = [[-0.07114345  0.04743973  0.         -0.9701967 ]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 5145 is [True, False, False, False, False, True]
Current timestep = 5146. State = [[-0.07795025  0.32668772]]. Action = [[ 0.01698824 -0.02269977  0.          0.8061092 ]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 5146 is [True, False, False, False, False, True]
Current timestep = 5147. State = [[-0.08105417  0.32383466]]. Action = [[-0.06131718 -0.06006544  0.         -0.3929656 ]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 5147 is [True, False, False, False, False, True]
Current timestep = 5148. State = [[-0.08526564  0.31987974]]. Action = [[-0.04811627 -0.06344065  0.         -0.70998985]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 5148 is [True, False, False, False, False, True]
Current timestep = 5149. State = [[-0.09135892  0.3147623 ]]. Action = [[-0.09695527 -0.0857863   0.         -0.86602557]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 5149 is [True, False, False, False, False, True]
Current timestep = 5150. State = [[-0.09850978  0.31726754]]. Action = [[-0.08099607  0.08505411  0.          0.07293463]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 5150 is [True, False, False, False, False, True]
Current timestep = 5151. State = [[-0.09875733  0.3176705 ]]. Action = [[ 0.06631126 -0.05235047  0.          0.5377886 ]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 5151 is [True, False, False, False, False, True]
Current timestep = 5152. State = [[-0.09874093  0.32049078]]. Action = [[-0.0105394   0.0895577   0.         -0.82426673]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 5152 is [True, False, False, False, False, True]
Current timestep = 5153. State = [[-0.09691725  0.32104084]]. Action = [[ 0.07349379 -0.02869613  0.         -0.0842306 ]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 5153 is [True, False, False, False, False, True]
Current timestep = 5154. State = [[-0.0967095   0.31735396]]. Action = [[-0.01753491 -0.04601452  0.          0.18557858]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 5154 is [True, False, False, False, False, True]
Current timestep = 5155. State = [[-0.10268746  0.31996766]]. Action = [[-0.09676753  0.09238522  0.          0.7864113 ]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 5155 is [True, False, False, False, False, True]
Current timestep = 5156. State = [[-0.10533023  0.32508212]]. Action = [[0.03465193 0.05818398 0.         0.3385942 ]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 5156 is [True, False, False, False, False, True]
Current timestep = 5157. State = [[-0.1056463  0.330697 ]]. Action = [[0.01716964 0.08882851 0.         0.5323427 ]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 5157 is [True, False, False, False, False, True]
State prediction error at timestep 5157 is 0.012
Human Feedback received at timestep 5157 of None
Current timestep = 5158. State = [[-0.10263874  0.32990384]]. Action = [[ 0.08876597 -0.05613903  0.         -0.32447392]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 5158 is [True, False, False, False, False, True]
Current timestep = 5159. State = [[-0.10246772  0.32767278]]. Action = [[-0.02770726 -0.00252426  0.         -0.2956301 ]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 5159 is [True, False, False, False, False, True]
Current timestep = 5160. State = [[-0.1037652   0.33195698]]. Action = [[ 0.00562425  0.09837814  0.         -0.18475276]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 5160 is [True, False, False, False, False, True]
Current timestep = 5161. State = [[-0.10624334  0.3332655 ]]. Action = [[-0.0357571  -0.02937169  0.          0.36398315]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 5161 is [True, False, False, False, False, True]
Current timestep = 5162. State = [[-0.11141234  0.32902652]]. Action = [[-0.0806918  -0.08594085  0.          0.605917  ]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 5162 is [True, False, False, False, False, True]
Current timestep = 5163. State = [[-0.11735184  0.32573202]]. Action = [[-0.07843377 -0.04042475  0.         -0.35432678]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 5163 is [True, False, False, False, False, True]
Current timestep = 5164. State = [[-0.11894345  0.32175732]]. Action = [[ 0.01300563 -0.0750256   0.         -0.35283804]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 5164 is [True, False, False, False, False, True]
Current timestep = 5165. State = [[-0.12216777  0.31967726]]. Action = [[-0.07295583 -0.0095499   0.         -0.10298538]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 5165 is [True, False, False, False, False, True]
State prediction error at timestep 5165 is 0.012
Human Feedback received at timestep 5165 of None
Current timestep = 5166. State = [[-0.1205862   0.31887186]]. Action = [[ 0.0813305  -0.01178262  0.         -0.05161065]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 5166 is [True, False, False, False, False, True]
State prediction error at timestep 5166 is 0.012
Human Feedback received at timestep 5166 of None
Current timestep = 5167. State = [[-0.11902172  0.32110995]]. Action = [[-0.00589645  0.06172242  0.          0.05556381]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 5167 is [True, False, False, False, False, True]
Current timestep = 5168. State = [[-0.1231494   0.31860656]]. Action = [[-0.08577882 -0.09054322  0.          0.9158118 ]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 5168 is [True, False, False, False, False, True]
Current timestep = 5169. State = [[-0.12824933  0.3120272 ]]. Action = [[-0.0517349  -0.08800697  0.          0.43540335]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 5169 is [True, False, False, False, False, True]
Current timestep = 5170. State = [[-0.12684682  0.31021324]]. Action = [[0.08117621 0.03380398 0.         0.6810682 ]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 5170 is [True, False, False, False, False, True]
Current timestep = 5171. State = [[-0.12854804  0.31286237]]. Action = [[-0.07036527  0.05189735  0.         -0.10648781]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 5171 is [True, False, False, False, False, True]
Current timestep = 5172. State = [[-0.12744804  0.31003287]]. Action = [[ 0.06983527 -0.07992207  0.         -0.3320763 ]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 5172 is [True, False, False, False, False, True]
Current timestep = 5173. State = [[-0.12408839  0.30741793]]. Action = [[0.03241228 0.01035497 0.         0.13718307]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 5173 is [True, False, False, False, False, True]
Current timestep = 5174. State = [[-0.12213191  0.30434963]]. Action = [[ 0.01935691 -0.04260177  0.         -0.28914332]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 5174 is [True, False, False, False, False, True]
Current timestep = 5175. State = [[-0.1210328  0.2980795]]. Action = [[ 0.0022336  -0.08118753  0.         -0.24550033]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 5175 is [True, False, False, False, False, True]
Current timestep = 5176. State = [[-0.12000245  0.29454923]]. Action = [[ 0.00653076 -0.00132208  0.         -0.176539  ]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 5176 is [True, False, False, False, False, True]
State prediction error at timestep 5176 is 0.012
Human Feedback received at timestep 5176 of None
Current timestep = 5177. State = [[-0.11591245  0.29520398]]. Action = [[ 0.0746155   0.04788909  0.         -0.626721  ]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 5177 is [True, False, False, False, False, True]
Current timestep = 5178. State = [[-0.11099995  0.2909882 ]]. Action = [[ 0.05158872 -0.07637958  0.         -0.7800528 ]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 5178 is [True, False, False, False, False, True]
Current timestep = 5179. State = [[-0.1070618   0.28937107]]. Action = [[0.03668924 0.04703104 0.         0.46091712]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 5179 is [True, False, False, False, False, True]
Current timestep = 5180. State = [[-0.10522791  0.28880447]]. Action = [[ 0.00657642 -0.00106005  0.          0.41063535]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 5180 is [True, False, False, False, False, True]
State prediction error at timestep 5180 is 0.012
Human Feedback received at timestep 5180 of None
Current timestep = 5181. State = [[-0.10654549  0.28975415]]. Action = [[-0.0399479   0.04386293  0.         -0.19608814]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 5181 is [True, False, False, False, False, True]
Current timestep = 5182. State = [[-0.1111341  0.2878464]]. Action = [[-0.0803628  -0.05565807  0.         -0.30518007]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 5182 is [True, False, False, False, False, True]
Current timestep = 5183. State = [[-0.11298998  0.28859946]]. Action = [[ 0.00801442  0.04869079  0.         -0.7688837 ]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 5183 is [True, False, False, False, False, True]
State prediction error at timestep 5183 is 0.012
Human Feedback received at timestep 5183 of None
Current timestep = 5184. State = [[-0.11629888  0.29067937]]. Action = [[-0.06752512  0.01137739  0.         -0.46051455]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 5184 is [True, False, False, False, False, True]
State prediction error at timestep 5184 is 0.012
Human Feedback received at timestep 5184 of None
Current timestep = 5185. State = [[-0.11626277  0.29319438]]. Action = [[ 0.04871308  0.03512146  0.         -0.2633503 ]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 5185 is [True, False, False, False, False, True]
Current timestep = 5186. State = [[-0.11666046  0.29250902]]. Action = [[-0.02819627 -0.04345918  0.          0.929363  ]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 5186 is [True, False, False, False, False, True]
Current timestep = 5187. State = [[-0.1187594   0.29442516]]. Action = [[-0.02245603  0.05156895  0.          0.28803837]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 5187 is [True, False, False, False, False, True]
Current timestep = 5188. State = [[-0.11619514  0.29724064]]. Action = [[0.0801244  0.02223279 0.         0.25321972]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 5188 is [True, False, False, False, False, True]
Current timestep = 5189. State = [[-0.11191802  0.29627743]]. Action = [[ 0.05305212 -0.03054709  0.         -0.6948913 ]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 5189 is [True, False, False, False, False, True]
Current timestep = 5190. State = [[-0.11402739  0.29746154]]. Action = [[-0.07480546  0.04238299  0.         -0.8130905 ]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 5190 is [True, False, False, False, False, True]
Current timestep = 5191. State = [[-0.11277053  0.30329865]]. Action = [[ 0.08242891  0.09633761  0.         -0.23381078]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 5191 is [True, False, False, False, False, True]
Current timestep = 5192. State = [[-0.11154509  0.30968913]]. Action = [[-0.01010884  0.07085935  0.         -0.01108921]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 5192 is [True, False, False, False, False, True]
Current timestep = 5193. State = [[-0.11620153  0.31444675]]. Action = [[-0.08510255  0.03532521  0.          0.35396862]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 5193 is [True, False, False, False, False, True]
Current timestep = 5194. State = [[-0.11952492  0.3184189 ]]. Action = [[-0.01042026  0.02753972  0.          0.5421982 ]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 5194 is [True, False, False, False, False, True]
Current timestep = 5195. State = [[-0.12344298  0.3246185 ]]. Action = [[-0.05687862  0.07527683  0.          0.26385343]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 5195 is [True, False, False, False, False, True]
Current timestep = 5196. State = [[-0.12896678  0.3276154 ]]. Action = [[-0.06203585 -0.02592151  0.         -0.29481602]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 5196 is [True, False, False, False, False, True]
Current timestep = 5197. State = [[-0.12915407  0.32987213]]. Action = [[ 0.04973959  0.016424    0.         -0.43889725]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 5197 is [True, False, False, False, False, True]
Current timestep = 5198. State = [[-0.12751225  0.32966423]]. Action = [[ 0.01562871 -0.04735353  0.         -0.68707556]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 5198 is [True, False, False, False, False, True]
Current timestep = 5199. State = [[-0.13009247  0.32644588]]. Action = [[-0.06946351 -0.07566335  0.         -0.7125522 ]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 5199 is [True, False, False, False, False, True]
Current timestep = 5200. State = [[-0.12809895  0.32474   ]]. Action = [[ 0.07551029 -0.01553266  0.         -0.26557618]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 5200 is [True, False, False, False, False, True]
Current timestep = 5201. State = [[-0.12351295  0.3277871 ]]. Action = [[ 0.04033359  0.06067302  0.         -0.3174609 ]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 5201 is [True, False, False, False, False, True]
Current timestep = 5202. State = [[-0.11704809  0.32870793]]. Action = [[ 0.09643321 -0.01639219  0.          0.6306046 ]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 5202 is [True, False, False, False, False, True]
Current timestep = 5203. State = [[-0.11172952  0.332161  ]]. Action = [[0.03837404 0.08849292 0.         0.8447497 ]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 5203 is [True, False, False, False, False, True]
Current timestep = 5204. State = [[-0.10945734  0.33865568]]. Action = [[ 0.01527146  0.09474616  0.         -0.98068386]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 5204 is [True, False, False, False, False, True]
State prediction error at timestep 5204 is 0.012
Human Feedback received at timestep 5204 of None
Current timestep = 5205. State = [[-0.11058658  0.33990666]]. Action = [[-0.04502324 -0.03543068  0.         -0.45269704]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 5205 is [True, False, False, False, False, True]
Current timestep = 5206. State = [[-0.112394   0.3405489]]. Action = [[-0.02153189  0.02006301  0.         -0.09597611]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 5206 is [True, False, False, False, False, True]
State prediction error at timestep 5206 is 0.012
Human Feedback received at timestep 5206 of None
Current timestep = 5207. State = [[-0.11204353  0.34408674]]. Action = [[ 0.01767029  0.0505463   0.         -0.4898482 ]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 5207 is [True, False, False, False, False, True]
Current timestep = 5208. State = [[-0.11558007  0.34765217]]. Action = [[-0.08034385  0.0279359   0.          0.3856275 ]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 5208 is [True, False, False, False, False, True]
Current timestep = 5209. State = [[-0.11908787  0.34910136]]. Action = [[-0.02234308 -0.01415848  0.          0.70749474]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 5209 is [True, False, False, False, False, True]
Current timestep = 5210. State = [[-0.1200013   0.35005444]]. Action = [[0.         0.         0.         0.16588104]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 5210 is [True, False, False, False, False, True]
Current timestep = 5211. State = [[-0.122182   0.3498444]]. Action = [[-0.04156717 -0.03050508  0.         -0.39318967]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 5211 is [True, False, False, False, False, True]
Current timestep = 5212. State = [[-0.12335056  0.35031822]]. Action = [[0.        0.        0.        0.9378222]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 5212 is [True, False, False, False, False, True]
Current timestep = 5213. State = [[-0.12688795  0.3479282 ]]. Action = [[-0.07519682 -0.07584879  0.          0.27301002]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 5213 is [True, False, False, False, False, True]
Current timestep = 5214. State = [[-0.12887436  0.34699494]]. Action = [[0.         0.         0.         0.02171135]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 5214 is [True, False, False, False, False, True]
State prediction error at timestep 5214 is 0.012
Human Feedback received at timestep 5214 of None
Current timestep = 5215. State = [[-0.12900048  0.34764838]]. Action = [[0.         0.         0.         0.38643956]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 5215 is [True, False, False, False, False, True]
Current timestep = 5216. State = [[-0.12913695  0.34807897]]. Action = [[ 0.          0.          0.         -0.83612293]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 5216 is [True, False, False, False, False, True]
State prediction error at timestep 5216 is 0.012
Human Feedback received at timestep 5216 of None
Current timestep = 5217. State = [[-0.12932938  0.3482769 ]]. Action = [[0.        0.        0.        0.6575742]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 5217 is [True, False, False, False, False, True]
State prediction error at timestep 5217 is 0.012
Human Feedback received at timestep 5217 of None
Current timestep = 5218. State = [[-0.13136701  0.3474107 ]]. Action = [[-0.03722902 -0.02064977  0.          0.18538678]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 5218 is [True, False, False, False, False, True]
Current timestep = 5219. State = [[-0.13263138  0.34700024]]. Action = [[ 0.         0.         0.        -0.6381442]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 5219 is [True, False, False, False, False, True]
Current timestep = 5220. State = [[-0.13549145  0.34634885]]. Action = [[-0.05118107 -0.01390295  0.          0.6045916 ]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 5220 is [True, False, False, False, False, True]
Current timestep = 5221. State = [[-0.13624364  0.34326693]]. Action = [[ 0.01888223 -0.05724464  0.          0.54130256]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 5221 is [True, False, False, False, False, True]
Current timestep = 5222. State = [[-0.13511002  0.340284  ]]. Action = [[ 0.014387   -0.02259726  0.          0.5615841 ]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 5222 is [True, False, False, False, False, True]
Current timestep = 5223. State = [[-0.1380882   0.34089473]]. Action = [[-0.06581138  0.03481815  0.         -0.51171285]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 5223 is [True, False, False, False, False, True]
State prediction error at timestep 5223 is 0.012
Human Feedback received at timestep 5223 of None
Current timestep = 5224. State = [[-0.14356105  0.33940893]]. Action = [[-0.06542757 -0.04947573  0.         -0.3186195 ]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 5224 is [True, False, False, False, False, True]
Current timestep = 5225. State = [[-0.14611527  0.33591446]]. Action = [[-0.00457215 -0.0468671   0.          0.4596963 ]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 5225 is [True, False, False, False, False, True]
Current timestep = 5226. State = [[-0.1482475  0.3342951]]. Action = [[-0.02921944 -0.00165416  0.         -0.33266914]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 5226 is [True, False, False, False, False, True]
Current timestep = 5227. State = [[-0.15218347  0.33684528]]. Action = [[-0.04515261  0.06060142  0.         -0.8313709 ]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 5227 is [True, False, False, False, False, True]
Current timestep = 5228. State = [[-0.15121348  0.33320898]]. Action = [[ 0.06933592 -0.09960873  0.          0.2716943 ]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 5228 is [True, False, False, False, False, True]
State prediction error at timestep 5228 is 0.012
Human Feedback received at timestep 5228 of None
Current timestep = 5229. State = [[-0.15166122  0.33323434]]. Action = [[-0.03317127  0.07651361  0.          0.22125351]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 5229 is [True, False, False, False, False, True]
State prediction error at timestep 5229 is 0.012
Human Feedback received at timestep 5229 of None
Current timestep = 5230. State = [[-0.15714702  0.33559927]]. Action = [[-0.06871135  0.01986785  0.          0.09881246]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 5230 is [True, False, False, False, False, True]
State prediction error at timestep 5230 is 0.012
Human Feedback received at timestep 5230 of None
Current timestep = 5231. State = [[-0.15608685  0.33254743]]. Action = [[ 0.08678227 -0.06686984  0.         -0.55687755]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 5231 is [True, False, False, False, False, True]
Current timestep = 5232. State = [[-0.15429838  0.32848564]]. Action = [[ 0.00236611 -0.02642762  0.          0.26923954]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 5232 is [True, False, False, False, False, True]
Current timestep = 5233. State = [[-0.15712662  0.32322353]]. Action = [[-0.05668696 -0.07686643  0.         -0.9847189 ]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 5233 is [True, False, False, False, False, True]
Current timestep = 5234. State = [[-0.15971065  0.3207353 ]]. Action = [[-0.01674219  0.00357584  0.          0.13783455]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 5234 is [True, False, False, False, False, True]
State prediction error at timestep 5234 is 0.012
Human Feedback received at timestep 5234 of None
Current timestep = 5235. State = [[-0.16326727  0.32253715]]. Action = [[-0.04947459  0.04982018  0.         -0.60007674]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 5235 is [True, False, False, False, False, True]
Current timestep = 5236. State = [[-0.16371767  0.32063657]]. Action = [[ 0.03615069 -0.05491392  0.         -0.1796382 ]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 5236 is [True, False, False, False, False, True]
Current timestep = 5237. State = [[-0.16029356  0.31902266]]. Action = [[ 0.06182005  0.01743056  0.         -0.37883377]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 5237 is [True, False, False, False, False, True]
Current timestep = 5238. State = [[-0.16341716  0.32245702]]. Action = [[-0.08578782  0.08592273  0.          0.8885517 ]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 5238 is [True, False, False, False, False, True]
Current timestep = 5239. State = [[-0.17141046  0.32926732]]. Action = [[-0.08899317  0.09763014  0.          0.512553  ]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 5239 is [True, False, False, False, False, True]
Current timestep = 5240. State = [[-0.17371668  0.333061  ]]. Action = [[0.04339559 0.01891316 0.         0.60500336]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 5240 is [True, False, False, False, False, True]
Current timestep = 5241. State = [[-0.22579567 -0.00631506]]. Action = [[-0.02949607 -0.05524256  0.         -0.71542954]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 5241 is [True, False, False, False, False, True]
Current timestep = 5242. State = [[-0.2194329  -0.00239423]]. Action = [[0.09143656 0.08111731 0.         0.38792157]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 5242 is [True, False, False, False, True, False]
Current timestep = 5243. State = [[-0.21476999 -0.00502399]]. Action = [[ 0.0525554  -0.0990138   0.         -0.10437238]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 5243 is [True, False, False, False, True, False]
Current timestep = 5244. State = [[-0.21694542 -0.00558113]]. Action = [[-0.08515578  0.0534577   0.          0.93802667]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 5244 is [True, False, False, False, True, False]
State prediction error at timestep 5244 is 0.012
Human Feedback received at timestep 5244 of None
Current timestep = 5245. State = [[-0.21648288 -0.00590301]]. Action = [[ 0.06321659 -0.02836451  0.          0.00102866]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 5245 is [True, False, False, False, True, False]
State prediction error at timestep 5245 is 0.012
Human Feedback received at timestep 5245 of None
Current timestep = 5246. State = [[-0.21693657 -0.00667178]]. Action = [[-0.04551319  0.00688962  0.          0.63541245]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 5246 is [True, False, False, False, True, False]
Current timestep = 5247. State = [[-0.21360031 -0.00912753]]. Action = [[ 0.09161185 -0.0456681   0.         -0.73754686]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5247 is [True, False, False, False, True, False]
Current timestep = 5248. State = [[-0.20761344 -0.01082303]]. Action = [[0.0614375  0.00418006 0.         0.1255107 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 5248 is [True, False, False, False, True, False]
State prediction error at timestep 5248 is 0.012
Human Feedback received at timestep 5248 of None
Current timestep = 5249. State = [[-0.20044868 -0.00926908]]. Action = [[0.09669139 0.04251077 0.         0.32973754]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 5249 is [True, False, False, False, True, False]
Current timestep = 5250. State = [[-0.1955692  -0.00546205]]. Action = [[ 0.03030539  0.06090214  0.         -0.38887286]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 5250 is [True, False, False, False, True, False]
Current timestep = 5251. State = [[-0.19450891 -0.00243786]]. Action = [[-0.01411077  0.02660538  0.         -0.42888248]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 5251 is [True, False, False, False, True, False]
Current timestep = 5252. State = [[-0.19084588  0.00316975]]. Action = [[0.066516   0.09042921 0.         0.1928469 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 5252 is [True, False, False, False, True, False]
State prediction error at timestep 5252 is 0.012
Human Feedback received at timestep 5252 of None
Current timestep = 5253. State = [[-0.19270407  0.00659059]]. Action = [[-0.09639868  0.00177566  0.         -0.7052611 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 5253 is [True, False, False, False, True, False]
Current timestep = 5254. State = [[-0.1931983   0.01003251]]. Action = [[ 0.03423809  0.04430109  0.         -0.5810901 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 5254 is [True, False, False, False, True, False]
Current timestep = 5255. State = [[-0.19442345  0.01448215]]. Action = [[-0.04802715  0.03765712  0.         -0.49829543]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 5255 is [True, False, False, False, True, False]
Current timestep = 5256. State = [[-0.19491078  0.01815296]]. Action = [[ 0.01106453  0.02026248  0.         -0.14100659]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 5256 is [True, False, False, False, True, False]
Current timestep = 5257. State = [[-0.19930167  0.02520267]]. Action = [[-0.09865922  0.09528729  0.         -0.901841  ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 5257 is [True, False, False, False, True, False]
Current timestep = 5258. State = [[-0.20330562  0.02760209]]. Action = [[-0.02472049 -0.04721488  0.          0.58427095]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 5258 is [True, False, False, False, True, False]
State prediction error at timestep 5258 is 0.012
Human Feedback received at timestep 5258 of None
Current timestep = 5259. State = [[-0.19952226  0.0231571 ]]. Action = [[ 0.09808182 -0.09586184  0.         -0.73267215]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 5259 is [True, False, False, False, True, False]
Current timestep = 5260. State = [[-0.20046858  0.02178437]]. Action = [[-0.08855153  0.01190151  0.         -0.86121875]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 5260 is [True, False, False, False, True, False]
Current timestep = 5261. State = [[-0.20732535  0.02265947]]. Action = [[-0.09452684 -0.00278718  0.         -0.39043152]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 5261 is [True, False, False, False, True, False]
Current timestep = 5262. State = [[-0.20893982  0.02205977]]. Action = [[ 0.0312859  -0.0239864   0.         -0.01608813]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 5262 is [True, False, False, False, True, False]
Current timestep = 5263. State = [[-0.2076023   0.02389279]]. Action = [[0.0211805  0.04498307 0.         0.39185035]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 5263 is [True, False, False, False, True, False]
Current timestep = 5264. State = [[-0.2110374   0.02316923]]. Action = [[-0.07480118 -0.04541847  0.          0.20616055]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 5264 is [True, False, False, False, True, False]
Current timestep = 5265. State = [[-0.2122046  0.0252993]]. Action = [[ 0.03125072  0.06482299  0.         -0.8578882 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 5265 is [True, False, False, False, True, False]
Current timestep = 5266. State = [[-0.21412241  0.02922874]]. Action = [[-0.0361504   0.03826574  0.         -0.1025005 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 5266 is [True, False, False, False, True, False]
Current timestep = 5267. State = [[-0.22032192  0.0289079 ]]. Action = [[-0.09062208 -0.03919181  0.         -0.8427163 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 5267 is [True, False, False, False, True, False]
State prediction error at timestep 5267 is 0.012
Human Feedback received at timestep 5267 of None
Current timestep = 5268. State = [[-0.21950258  0.02494359]]. Action = [[ 0.09268772 -0.06223211  0.          0.22799253]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 5268 is [True, False, False, False, True, False]
Current timestep = 5269. State = [[-0.22144687  0.01989769]]. Action = [[-0.09772447 -0.06055299  0.          0.11982548]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 5269 is [True, False, False, False, True, False]
Current timestep = 5270. State = [[-0.22808918  0.02235704]]. Action = [[-0.07484586  0.09176863  0.          0.7105708 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 5270 is [True, False, False, False, True, False]
Current timestep = 5271. State = [[-0.23507155  0.02128796]]. Action = [[-0.0784194  -0.07512955  0.          0.7776995 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 5271 is [True, False, False, False, True, False]
State prediction error at timestep 5271 is 0.012
Human Feedback received at timestep 5271 of None
Current timestep = 5272. State = [[-0.23722373  0.02154779]]. Action = [[0.02824857 0.04793807 0.         0.71131086]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 5272 is [True, False, False, False, True, False]
Current timestep = 5273. State = [[-0.23870784  0.02056871]]. Action = [[-0.01608463 -0.04339201  0.         -0.8578556 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 5273 is [True, False, False, False, True, False]
Current timestep = 5274. State = [[-0.24410874  0.01615994]]. Action = [[-0.08013707 -0.0605952   0.         -0.5443625 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 5274 is [True, False, False, False, True, False]
State prediction error at timestep 5274 is 0.012
Human Feedback received at timestep 5274 of None
Current timestep = 5275. State = [[-0.24538837  0.01193084]]. Action = [[ 0.04258319 -0.03898187  0.          0.1262201 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 5275 is [True, False, False, False, True, False]
State prediction error at timestep 5275 is 0.012
Human Feedback received at timestep 5275 of None
Current timestep = 5276. State = [[-0.24886657  0.01095077]]. Action = [[-0.07423019  0.01892831  0.         -0.06673461]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 5276 is [True, False, False, False, True, False]
State prediction error at timestep 5276 is 0.012
Human Feedback received at timestep 5276 of None
Current timestep = 5277. State = [[-0.24892879  0.00723792]]. Action = [[ 0.06590786 -0.07014624  0.          0.0421834 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 5277 is [True, False, False, False, True, False]
Current timestep = 5278. State = [[-0.24800825  0.00076691]]. Action = [[-0.00126632 -0.06844959  0.          0.79382324]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 5278 is [True, False, False, False, True, False]
Current timestep = 5279. State = [[-0.2491      0.00222304]]. Action = [[-0.00993846  0.09595986  0.          0.9050448 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 5279 is [True, False, False, False, True, False]
Current timestep = 5280. State = [[-0.2529792   0.00229462]]. Action = [[-0.05627294 -0.03639511  0.          0.32020724]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 5280 is [True, False, False, False, True, False]
Current timestep = 5281. State = [[-0.25330836  0.00383429]]. Action = [[ 0.04421159  0.06198733  0.         -0.89996165]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 5281 is [True, False, False, False, True, False]
State prediction error at timestep 5281 is 0.012
Human Feedback received at timestep 5281 of None
Current timestep = 5282. State = [[-0.25299722  0.0070622 ]]. Action = [[0.00564998 0.03645273 0.         0.7392448 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 5282 is [True, False, False, False, True, False]
Current timestep = 5283. State = [[-0.2573345   0.00868063]]. Action = [[-0.07301923  0.0102051   0.          0.95056283]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 5283 is [True, False, False, False, True, False]
Current timestep = 5284. State = [[-0.25716653  0.01099856]]. Action = [[ 0.07010483  0.03555388  0.         -0.3636216 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 5284 is [True, False, False, False, True, False]
Current timestep = 5285. State = [[-0.25823376  0.01558625]]. Action = [[-0.04123826  0.06284379  0.          0.91405547]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 5285 is [True, False, False, False, True, False]
Current timestep = 5286. State = [[-0.2619665  0.0228488]]. Action = [[-0.03313676  0.09230923  0.         -0.9542605 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 5286 is [True, False, False, False, True, False]
Current timestep = 5287. State = [[-0.26362348  0.02978144]]. Action = [[0.01403107 0.0592105  0.         0.68871784]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 5287 is [True, False, False, False, True, False]
Current timestep = 5288. State = [[-0.26566276  0.03107235]]. Action = [[-0.02371632 -0.04006865  0.          0.04527938]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 5288 is [True, False, False, False, True, False]
State prediction error at timestep 5288 is 0.012
Human Feedback received at timestep 5288 of None
Current timestep = 5289. State = [[-0.26246002  0.02672981]]. Action = [[ 0.09434066 -0.08943011  0.         -0.8088639 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 5289 is [True, False, False, False, True, False]
Current timestep = 5290. State = [[-0.2617072   0.02366289]]. Action = [[-0.03863663 -0.02136441  0.          0.76677954]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 5290 is [True, False, False, False, True, False]
Current timestep = 5291. State = [[-0.2651356   0.02700331]]. Action = [[-0.05221681  0.07185949  0.          0.7375797 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 5291 is [True, False, False, False, True, False]
Current timestep = 5292. State = [[-0.2635835   0.03041744]]. Action = [[ 0.07074615  0.01559733  0.         -0.42508447]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 5292 is [True, False, False, False, True, False]
Current timestep = 5293. State = [[-0.25773776  0.02786654]]. Action = [[ 0.08240063 -0.06914922  0.          0.6621258 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 5293 is [True, False, False, False, True, False]
State prediction error at timestep 5293 is 0.012
Human Feedback received at timestep 5293 of None
Current timestep = 5294. State = [[-0.25658256  0.02950037]]. Action = [[-0.03338746  0.0728016   0.          0.9806355 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 5294 is [True, False, False, False, True, False]
Current timestep = 5295. State = [[-0.25274482  0.03572297]]. Action = [[0.09670045 0.08026236 0.         0.45587778]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 5295 is [True, False, False, False, True, False]
Current timestep = 5296. State = [[-0.24644408  0.04118759]]. Action = [[ 0.0745764   0.05397586  0.         -0.7708803 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 5296 is [True, False, False, False, True, False]
Current timestep = 5297. State = [[-0.24621855  0.04547706]]. Action = [[-0.04989048  0.04049449  0.          0.20800471]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 5297 is [True, False, False, False, True, False]
State prediction error at timestep 5297 is 0.012
Human Feedback received at timestep 5297 of None
Current timestep = 5298. State = [[-0.24564606  0.04743841]]. Action = [[ 0.0310343  -0.00380193  0.          0.38878345]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 5298 is [True, False, False, False, True, False]
Current timestep = 5299. State = [[-0.24717136  0.04826482]]. Action = [[-0.0588117  -0.00239036  0.          0.3427012 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 5299 is [True, False, False, False, True, False]
Current timestep = 5300. State = [[-0.25137207  0.05149757]]. Action = [[-0.06711541  0.0417022   0.          0.3941338 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 5300 is [True, False, False, False, True, False]
Current timestep = 5301. State = [[-0.25052315  0.05129845]]. Action = [[ 0.04858205 -0.05399863  0.          0.01983321]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 5301 is [True, False, False, False, True, False]
Current timestep = 5302. State = [[-0.24629968  0.04976463]]. Action = [[ 0.04827907 -0.01713214  0.         -0.62907255]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 5302 is [True, False, False, False, True, False]
Current timestep = 5303. State = [[-0.24249738  0.04886597]]. Action = [[ 0.0334234  -0.01575022  0.          0.34356117]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 5303 is [True, False, False, False, True, False]
Current timestep = 5304. State = [[-0.24472973  0.05051518]]. Action = [[-0.08614633  0.03517643  0.          0.31206942]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 5304 is [True, False, False, False, True, False]
Current timestep = 5305. State = [[-0.24911225  0.05201366]]. Action = [[-0.05562016 -0.00203214  0.         -0.16577917]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 5305 is [True, False, False, False, True, False]
State prediction error at timestep 5305 is 0.012
Human Feedback received at timestep 5305 of None
Current timestep = 5306. State = [[-0.2547795   0.05690552]]. Action = [[-0.08647004  0.08387531  0.         -0.28539324]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 5306 is [True, False, False, False, True, False]
Current timestep = 5307. State = [[-0.25760365  0.05574832]]. Action = [[-0.00271085 -0.09188973  0.          0.01817334]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 5307 is [True, False, False, False, True, False]
Current timestep = 5308. State = [[-0.25893492  0.05832916]]. Action = [[-0.01482251  0.09504988  0.          0.7039919 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 5308 is [True, False, False, False, True, False]
State prediction error at timestep 5308 is 0.012
Human Feedback received at timestep 5308 of None
Current timestep = 5309. State = [[-0.26396814  0.0615495 ]]. Action = [[-0.07692786 -0.00394204  0.          0.9421208 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 5309 is [True, False, False, False, True, False]
Current timestep = 5310. State = [[-0.26871827  0.06246272]]. Action = [[-3.41580436e-02 -1.15424395e-04  0.00000000e+00 -6.30063295e-01]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 5310 is [True, False, False, False, True, False]
Current timestep = 5311. State = [[-0.27043235  0.05944515]]. Action = [[ 0.00634988 -0.07372448  0.          0.31879425]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 5311 is [True, False, False, False, True, False]
Current timestep = 5312. State = [[-0.2729224   0.05392475]]. Action = [[-0.03943411 -0.07205853  0.          0.7044568 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 5312 is [True, False, False, False, True, False]
Current timestep = 5313. State = [[-0.27098808  0.05623285]]. Action = [[0.08611917 0.09821763 0.         0.37832177]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 5313 is [True, False, False, False, True, False]
Current timestep = 5314. State = [[-0.27164337  0.05656919]]. Action = [[-0.05035935 -0.04592323  0.         -0.9834155 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 5314 is [True, False, False, False, True, False]
State prediction error at timestep 5314 is 0.012
Human Feedback received at timestep 5314 of None
Current timestep = 5315. State = [[-0.27814078  0.0559325 ]]. Action = [[-0.09173796  0.0120308   0.          0.81750774]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 5315 is [True, False, False, False, True, False]
Current timestep = 5316. State = [[-0.2832043   0.05136427]]. Action = [[-0.0336066  -0.09777129  0.         -0.93855375]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 5316 is [True, False, False, False, True, False]
State prediction error at timestep 5316 is 0.012
Human Feedback received at timestep 5316 of None
Current timestep = 5317. State = [[-0.28117248  0.04390471]]. Action = [[ 0.07912134 -0.08230069  0.          0.16430318]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 5317 is [True, False, False, False, True, False]
Current timestep = 5318. State = [[-0.27852193  0.04181517]]. Action = [[0.02045872 0.03257928 0.         0.04571223]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 5318 is [True, False, False, False, True, False]
Current timestep = 5319. State = [[-0.2795891   0.04010146]]. Action = [[-0.0264906  -0.02925111  0.         -0.6839546 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 5319 is [True, False, False, False, True, False]
Current timestep = 5320. State = [[-0.2795908   0.04143931]]. Action = [[ 0.02409037  0.06328621  0.         -0.5989365 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 5320 is [True, False, False, False, True, False]
State prediction error at timestep 5320 is 0.012
Human Feedback received at timestep 5320 of None
Current timestep = 5321. State = [[-0.2784356  0.0434198]]. Action = [[ 0.02660402  0.0206125   0.         -0.11421114]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 5321 is [True, False, False, False, True, False]
Current timestep = 5322. State = [[-0.28272077  0.04306602]]. Action = [[-0.0933973  -0.01052773  0.         -0.58296037]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 5322 is [True, False, False, False, True, False]
Current timestep = 5323. State = [[-0.2841637   0.04535845]]. Action = [[0.04502302 0.05768377 0.         0.68878794]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 5323 is [True, False, False, False, True, False]
Current timestep = 5324. State = [[-0.28704417  0.04411967]]. Action = [[-0.06836687 -0.05703375  0.          0.7309294 ]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 5324 is [True, False, False, False, True, False]
State prediction error at timestep 5324 is 0.012
Human Feedback received at timestep 5324 of None
Current timestep = 5325. State = [[-0.2892023   0.04466609]]. Action = [[0.0081194  0.04274497 0.         0.33134246]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 5325 is [True, False, False, False, True, False]
Current timestep = 5326. State = [[-0.29476386  0.04772307]]. Action = [[-0.09843116  0.03442287  0.         -0.48517823]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 5326 is [True, False, False, False, True, False]
Current timestep = 5327. State = [[-0.30190772  0.04646462]]. Action = [[-0.07061021 -0.05699586  0.          0.20972776]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 5327 is [True, False, False, False, True, False]
Current timestep = 5328. State = [[-0.30390158  0.04292514]]. Action = [[ 0.02135082 -0.04535269  0.          0.72497654]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 5328 is [True, False, False, False, True, False]
Current timestep = 5329. State = [[-0.3009611   0.04234782]]. Action = [[ 0.07206271  0.01943048  0.         -0.57054085]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 5329 is [True, False, False, False, True, False]
Current timestep = 5330. State = [[-0.2969418  0.0470009]]. Action = [[ 0.0688336   0.08988094  0.         -0.23348963]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 5330 is [True, False, False, False, True, False]
Current timestep = 5331. State = [[-0.29992288  0.04803597]]. Action = [[-0.08891712 -0.03242684  0.          0.7431632 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 5331 is [True, False, False, False, True, False]
Current timestep = 5332. State = [[-0.30290964  0.04696252]]. Action = [[ 0.01657231 -0.0056468   0.          0.05327308]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 5332 is [True, False, False, False, True, False]
Current timestep = 5333. State = [[-0.3044541   0.04511799]]. Action = [[-0.01116867 -0.03008697  0.         -0.7481339 ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 5333 is [True, False, False, False, True, False]
Current timestep = 5334. State = [[-0.30385625  0.04754855]]. Action = [[0.04226806 0.07114037 0.         0.43565297]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 5334 is [True, False, False, False, True, False]
Current timestep = 5335. State = [[-0.30160087  0.04758242]]. Action = [[ 0.04656377 -0.03601425  0.          0.8571348 ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 5335 is [True, False, False, False, True, False]
State prediction error at timestep 5335 is 0.012
Human Feedback received at timestep 5335 of None
Current timestep = 5336. State = [[-0.3004296   0.05038484]]. Action = [[ 0.01307925  0.08031341  0.         -0.10959446]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 5336 is [True, False, False, False, True, False]
Current timestep = 5337. State = [[-0.29879817  0.05411024]]. Action = [[ 0.04166473  0.0293937   0.         -0.6810449 ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 5337 is [True, False, False, False, True, False]
Current timestep = 5338. State = [[-0.29587308  0.0518949 ]]. Action = [[ 0.04263448 -0.06577042  0.         -0.20046055]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 5338 is [True, False, False, False, True, False]
Current timestep = 5339. State = [[-0.29107556  0.0450107 ]]. Action = [[ 0.06270342 -0.09871532  0.          0.34891367]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 5339 is [True, False, False, False, True, False]
Current timestep = 5340. State = [[-0.29252517  0.04287685]]. Action = [[-0.09258432  0.0231197   0.         -0.9817638 ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 5340 is [True, False, False, False, True, False]
State prediction error at timestep 5340 is 0.012
Human Feedback received at timestep 5340 of None
Current timestep = 5341. State = [[-0.29349643  0.04677354]]. Action = [[0.01791151 0.07065236 0.         0.8230611 ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 5341 is [True, False, False, False, True, False]
Current timestep = 5342. State = [[-0.29542118  0.04814089]]. Action = [[-0.05289057 -0.01553534  0.          0.48620355]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 5342 is [True, False, False, False, True, False]
State prediction error at timestep 5342 is 0.012
Human Feedback received at timestep 5342 of None
Current timestep = 5343. State = [[-0.30111352  0.04826255]]. Action = [[-0.09706403  0.00337051  0.          0.7486329 ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 5343 is [True, False, False, False, True, False]
State prediction error at timestep 5343 is 0.012
Human Feedback received at timestep 5343 of None
Current timestep = 5344. State = [[-0.30013     0.04674422]]. Action = [[ 0.07967102 -0.03696338  0.         -0.18846166]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 5344 is [True, False, False, False, True, False]
Current timestep = 5345. State = [[-0.2969501  0.0455724]]. Action = [[ 0.01138743 -0.00183012  0.         -0.39983833]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 5345 is [True, False, False, False, True, False]
Current timestep = 5346. State = [[-0.29458883  0.04638916]]. Action = [[0.02794389 0.01942153 0.         0.2951566 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 5346 is [True, False, False, False, True, False]
Current timestep = 5347. State = [[-0.29717466  0.04576967]]. Action = [[-0.08293475 -0.02577321  0.          0.15042436]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 5347 is [True, False, False, False, True, False]
Current timestep = 5348. State = [[-0.30034885  0.04877293]]. Action = [[-0.02419805  0.06986674  0.         -0.92751867]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 5348 is [True, False, False, False, True, False]
State prediction error at timestep 5348 is 0.012
Human Feedback received at timestep 5348 of None
Current timestep = 5349. State = [[-0.30619642  0.05339118]]. Action = [[-0.09597749  0.04238992  0.          0.22979987]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 5349 is [True, False, False, False, True, False]
Current timestep = 5350. State = [[-0.31346756  0.06038667]]. Action = [[-0.07530395  0.09525416  0.         -0.70913595]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 5350 is [True, False, False, False, True, False]
Current timestep = 5351. State = [[-0.31588134  0.06261183]]. Action = [[ 0.02621784 -0.0359805   0.         -0.8896902 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 5351 is [True, False, False, False, True, False]
Current timestep = 5352. State = [[-0.32070157  0.06483195]]. Action = [[-0.08264421  0.04240932  0.         -0.13344753]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 5352 is [True, False, False, False, True, False]
State prediction error at timestep 5352 is 0.012
Human Feedback received at timestep 5352 of None
Current timestep = 5353. State = [[-0.32172674  0.06955145]]. Action = [[ 0.06538381  0.0509145   0.         -0.75894463]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 5353 is [True, False, False, False, True, False]
Current timestep = 5354. State = [[-0.31783843  0.06834834]]. Action = [[ 0.07780219 -0.07008988  0.          0.9538276 ]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 5354 is [True, False, False, False, True, False]
Current timestep = 5355. State = [[-0.318054    0.06814057]]. Action = [[-0.03431229  0.0276952   0.          0.20561719]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 5355 is [True, False, False, False, True, False]
State prediction error at timestep 5355 is 0.012
Human Feedback received at timestep 5355 of None
Current timestep = 5356. State = [[-0.3177186   0.07106169]]. Action = [[ 0.03827063  0.03506499  0.         -0.31775188]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 5356 is [True, False, False, False, True, False]
State prediction error at timestep 5356 is 0.012
Human Feedback received at timestep 5356 of None
Current timestep = 5357. State = [[-0.31849393  0.07527323]]. Action = [[-0.02174678  0.05421536  0.          0.05478239]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 5357 is [True, False, False, False, True, False]
State prediction error at timestep 5357 is 0.012
Human Feedback received at timestep 5357 of None
Current timestep = 5358. State = [[-0.32427046  0.08175039]]. Action = [[-0.0903371   0.08200585  0.         -0.34339285]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 5358 is [True, False, False, False, True, False]
Current timestep = 5359. State = [[-0.32440102  0.08210204]]. Action = [[ 0.06766602 -0.06474105  0.          0.27691507]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 5359 is [True, False, False, False, True, False]
State prediction error at timestep 5359 is 0.012
Human Feedback received at timestep 5359 of None
Current timestep = 5360. State = [[-0.3211986   0.07927934]]. Action = [[ 0.03576445 -0.03270902  0.         -0.14427304]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 5360 is [True, False, False, False, True, False]
Current timestep = 5361. State = [[-0.3231825   0.07870036]]. Action = [[-0.0663867   0.00059251  0.          0.47541904]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 5361 is [True, False, False, False, True, False]
Current timestep = 5362. State = [[-0.3257972   0.07643576]]. Action = [[-0.02296945 -0.05623558  0.         -0.13941514]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 5362 is [True, False, False, False, True, False]
Current timestep = 5363. State = [[-0.3248159   0.07586999]]. Action = [[0.02900549 0.01689974 0.         0.07739687]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 5363 is [True, False, False, False, True, False]
Current timestep = 5364. State = [[-0.3224938   0.07592484]]. Action = [[ 0.02970173 -0.00517324  0.         -0.6022549 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 5364 is [True, False, False, False, True, False]
Current timestep = 5365. State = [[-0.3206153   0.07269086]]. Action = [[ 0.01496066 -0.05721983  0.          0.08358026]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 5365 is [True, False, False, False, True, False]
Current timestep = 5366. State = [[-0.32282564  0.06844045]]. Action = [[-0.06847525 -0.04514066  0.         -0.466352  ]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 5366 is [True, False, False, False, True, False]
Current timestep = 5367. State = [[-0.32166782  0.06479041]]. Action = [[ 0.05023745 -0.0350455   0.          0.879578  ]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 5367 is [True, False, False, False, True, False]
Current timestep = 5368. State = [[-0.31892616  0.06763032]]. Action = [[ 0.02217101  0.09676173  0.         -0.2694466 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 5368 is [True, False, False, False, True, False]
State prediction error at timestep 5368 is 0.012
Human Feedback received at timestep 5368 of None
Current timestep = 5369. State = [[-0.32246298  0.06867796]]. Action = [[-0.09082118 -0.02661847  0.         -0.05863529]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 5369 is [True, False, False, False, True, False]
State prediction error at timestep 5369 is 0.012
Human Feedback received at timestep 5369 of None
Current timestep = 5370. State = [[-0.32673767  0.06312513]]. Action = [[-0.03509957 -0.09579853  0.          0.47687423]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 5370 is [True, False, False, False, True, False]
Current timestep = 5371. State = [[-0.3243345   0.05732548]]. Action = [[ 0.07530842 -0.04703943  0.         -0.4304458 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 5371 is [True, False, False, False, True, False]
State prediction error at timestep 5371 is 0.012
Human Feedback received at timestep 5371 of None
Current timestep = 5372. State = [[-0.3216178   0.05671146]]. Action = [[0.01427432 0.03935554 0.         0.4852531 ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 5372 is [True, False, False, False, True, False]
Current timestep = 5373. State = [[-0.32386667  0.06197818]]. Action = [[-0.04849321  0.09952103  0.         -0.24282908]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 5373 is [True, False, False, False, True, False]
Current timestep = 5374. State = [[-0.32545263  0.06543686]]. Action = [[ 0.0121148   0.01490358  0.         -0.29939675]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 5374 is [True, False, False, False, True, False]
Current timestep = 5375. State = [[-0.3279452   0.06758449]]. Action = [[-0.03918275  0.03075374  0.         -0.74813133]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 5375 is [True, False, False, False, True, False]
State prediction error at timestep 5375 is 0.012
Human Feedback received at timestep 5375 of None
Current timestep = 5376. State = [[-0.33202508  0.06484461]]. Action = [[-0.04753811 -0.07992934  0.         -0.5633745 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 5376 is [True, False, False, False, True, False]
Current timestep = 5377. State = [[-0.32981288  0.06314929]]. Action = [[0.08894921 0.010946   0.         0.40245366]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 5377 is [True, False, False, False, True, False]
Current timestep = 5378. State = [[-0.33087578  0.05948709]]. Action = [[-0.08134402 -0.07853976  0.          0.9362507 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 5378 is [True, False, False, False, True, False]
State prediction error at timestep 5378 is 0.012
Human Feedback received at timestep 5378 of None
Current timestep = 5379. State = [[-0.33665365  0.0554468 ]]. Action = [[-0.07394914 -0.03461013  0.         -0.4910971 ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 5379 is [True, False, False, False, True, False]
Current timestep = 5380. State = [[-0.34232664  0.05750427]]. Action = [[-0.06091967  0.06698278  0.         -0.1898129 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 5380 is [True, False, False, False, True, False]
Current timestep = 5381. State = [[-0.34566382  0.05892853]]. Action = [[-0.00695029 -0.00883395  0.          0.1985892 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 5381 is [True, False, False, False, True, False]
Current timestep = 5382. State = [[-0.34322304  0.05882717]]. Action = [[0.08600714 0.00586224 0.         0.85057557]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 5382 is [True, False, False, False, True, False]
Current timestep = 5383. State = [[-0.34472877  0.0589947 ]]. Action = [[-0.05601516  0.0073676   0.         -0.15788984]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 5383 is [True, False, False, False, True, False]
State prediction error at timestep 5383 is 0.012
Human Feedback received at timestep 5383 of None
Current timestep = 5384. State = [[-0.34309378  0.05934893]]. Action = [[0.0963788  0.01041988 0.         0.82800794]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 5384 is [True, False, False, False, True, False]
State prediction error at timestep 5384 is 0.012
Human Feedback received at timestep 5384 of None
Current timestep = 5385. State = [[-0.33741137  0.06115961]]. Action = [[ 0.08888874  0.04174329  0.         -0.8826059 ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 5385 is [True, False, False, False, True, False]
Current timestep = 5386. State = [[-0.33847523  0.06540377]]. Action = [[-0.06083504  0.0673007   0.         -0.31274682]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 5386 is [True, False, False, False, True, False]
Current timestep = 5387. State = [[-0.33968493  0.07239841]]. Action = [[0.03723053 0.09919056 0.         0.7035315 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 5387 is [True, False, False, False, True, False]
Current timestep = 5388. State = [[-0.34299153  0.07219028]]. Action = [[-0.06659052 -0.07618479  0.         -0.66506475]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 5388 is [True, False, False, False, True, False]
Current timestep = 5389. State = [[-0.3415563   0.06751216]]. Action = [[ 0.08614748 -0.06019542  0.          0.9233031 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 5389 is [True, False, False, False, True, False]
Current timestep = 5390. State = [[-0.3371703   0.06579694]]. Action = [[0.04499307 0.00364976 0.         0.7655995 ]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 5390 is [True, False, False, False, True, False]
Current timestep = 5391. State = [[-0.33687794  0.07058645]]. Action = [[-0.0223543   0.09666397  0.         -0.9727441 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 5391 is [True, False, False, False, True, False]
Current timestep = 5392. State = [[-0.33837026  0.07470102]]. Action = [[-0.01508792  0.0190932   0.         -0.772228  ]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 5392 is [True, False, False, False, True, False]
Current timestep = 5393. State = [[-0.33672124  0.07922711]]. Action = [[0.04724313 0.06594511 0.         0.84989667]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 5393 is [True, False, False, False, True, False]
State prediction error at timestep 5393 is 0.012
Human Feedback received at timestep 5393 of None
Current timestep = 5394. State = [[-0.33323056  0.08062052]]. Action = [[ 0.04761346 -0.02210789  0.          0.44276702]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 5394 is [True, False, False, False, True, False]
Current timestep = 5395. State = [[-0.3345732   0.08183352]]. Action = [[-0.06343982  0.0214569   0.         -0.9777005 ]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 5395 is [True, False, False, False, True, False]
State prediction error at timestep 5395 is 0.012
Human Feedback received at timestep 5395 of None
Current timestep = 5396. State = [[-0.33937413  0.08099646]]. Action = [[-0.07522839 -0.05080697  0.         -0.8098501 ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 5396 is [True, False, False, False, True, False]
Current timestep = 5397. State = [[-0.34183937  0.08146888]]. Action = [[-0.01784389  0.01641895  0.         -0.5376441 ]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 5397 is [True, False, False, False, True, False]
Current timestep = 5398. State = [[-0.34455392  0.08019982]]. Action = [[-0.05042715 -0.05187646  0.          0.7606627 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 5398 is [True, False, False, False, True, False]
Current timestep = 5399. State = [[-0.3448259   0.07528683]]. Action = [[ 0.01249348 -0.08106385  0.         -0.17201883]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 5399 is [True, False, False, False, True, False]
Current timestep = 5400. State = [[-0.34138167  0.07658362]]. Action = [[ 0.06045368  0.07920479  0.         -0.2633661 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 5400 is [True, False, False, False, True, False]
Current timestep = 5401. State = [[-0.33656907  0.0799367 ]]. Action = [[0.06868293 0.02868164 0.         0.8413526 ]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 5401 is [True, False, False, False, True, False]
State prediction error at timestep 5401 is 0.012
Human Feedback received at timestep 5401 of None
Current timestep = 5402. State = [[-0.33771905  0.07896719]]. Action = [[-0.07133047 -0.03840385  0.          0.86767364]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 5402 is [True, False, False, False, True, False]
Current timestep = 5403. State = [[-0.3352817   0.07326756]]. Action = [[ 0.09095021 -0.08864626  0.          0.21416974]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 5403 is [True, False, False, False, True, False]
Current timestep = 5404. State = [[-0.33466572  0.07118323]]. Action = [[-0.04416106  0.02527047  0.         -0.8741187 ]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 5404 is [True, False, False, False, True, False]
Current timestep = 5405. State = [[-0.3377973   0.07271443]]. Action = [[-0.0458962   0.02559032  0.          0.9580277 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 5405 is [True, False, False, False, True, False]
Current timestep = 5406. State = [[-0.33556014  0.0709221 ]]. Action = [[ 0.07410739 -0.04490073  0.         -0.19252121]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 5406 is [True, False, False, False, True, False]
Current timestep = 5407. State = [[-0.33796033  0.07213204]]. Action = [[-0.09310122  0.05949565  0.          0.0196377 ]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 5407 is [True, False, False, False, True, False]
Current timestep = 5408. State = [[-0.3419759   0.07721535]]. Action = [[-0.01829744  0.06896164  0.         -0.2751568 ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 5408 is [True, False, False, False, True, False]
Current timestep = 5409. State = [[-0.34686515  0.07758785]]. Action = [[-0.06771505 -0.04069998  0.          0.34635007]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 5409 is [True, False, False, False, True, False]
Current timestep = 5410. State = [[-0.35371706  0.07587676]]. Action = [[-0.08674791 -0.02340691  0.          0.5485585 ]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 5410 is [True, False, False, False, True, False]
State prediction error at timestep 5410 is 0.012
Human Feedback received at timestep 5410 of None
Current timestep = 5411. State = [[-0.3604799   0.07367317]]. Action = [[-0.07129166 -0.040499    0.          0.76546633]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 5411 is [True, False, False, False, True, False]
Current timestep = 5412. State = [[-0.36104068  0.07496724]]. Action = [[ 0.06214838  0.0484496   0.         -0.0271554 ]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 5412 is [True, False, False, False, True, False]
Current timestep = 5413. State = [[-0.35754004  0.07727364]]. Action = [[0.06601942 0.02211084 0.         0.3694936 ]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 5413 is [True, False, False, False, True, False]
Current timestep = 5414. State = [[-0.35912287  0.07993644]]. Action = [[-0.05019835  0.04106724  0.         -0.28681087]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 5414 is [True, False, False, False, True, False]
Current timestep = 5415. State = [[-0.3576867   0.08061246]]. Action = [[ 0.07972192 -0.0121966   0.          0.23449934]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 5415 is [True, False, False, False, True, False]
Current timestep = 5416. State = [[-0.36038822  0.08057882]]. Action = [[-0.0895184   0.00335158  0.         -0.5667982 ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 5416 is [True, False, False, False, True, False]
Current timestep = 5417. State = [[-0.36504608  0.07791607]]. Action = [[-0.02935238 -0.06007225  0.          0.07698774]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 5417 is [True, False, False, False, True, False]
State prediction error at timestep 5417 is 0.012
Human Feedback received at timestep 5417 of None
Current timestep = 5418. State = [[-0.36808833  0.07877991]]. Action = [[-0.02506628  0.05134993  0.         -0.69846004]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 5418 is [True, False, False, False, True, False]
Current timestep = 5419. State = [[-0.37212417  0.08076889]]. Action = [[-0.04321237  0.00888731  0.          0.48370457]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 5419 is [True, False, False, False, True, False]
Current timestep = 5420. State = [[-0.37452212  0.0813166 ]]. Action = [[0.         0.         0.         0.24754095]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 5420 is [True, False, False, False, True, False]
State prediction error at timestep 5420 is 0.012
Human Feedback received at timestep 5420 of None
Current timestep = 5421. State = [[-0.37249294  0.08029116]]. Action = [[ 0.06499403 -0.02003018  0.          0.4604752 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 5421 is [True, False, False, False, True, False]
Current timestep = 5422. State = [[-0.36821654  0.08080265]]. Action = [[0.0695729  0.0311534  0.         0.06180763]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 5422 is [True, False, False, False, True, False]
Current timestep = 5423. State = [[-0.36551133  0.07943545]]. Action = [[ 0.02583342 -0.03498592  0.          0.07665086]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 5423 is [True, False, False, False, True, False]
Current timestep = 5424. State = [[-0.36712998  0.07778854]]. Action = [[-0.05044806 -0.00784943  0.          0.89522076]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 5424 is [True, False, False, False, True, False]
State prediction error at timestep 5424 is 0.012
Human Feedback received at timestep 5424 of None
Current timestep = 5425. State = [[-0.36536816  0.07829572]]. Action = [[ 0.0636278   0.02053656  0.         -0.57928425]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 5425 is [True, False, False, False, True, False]
State prediction error at timestep 5425 is 0.012
Human Feedback received at timestep 5425 of None
Current timestep = 5426. State = [[-0.36253914  0.07567088]]. Action = [[ 0.01574467 -0.05730833  0.          0.51752734]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 5426 is [True, False, False, False, True, False]
State prediction error at timestep 5426 is 0.012
Human Feedback received at timestep 5426 of None
Current timestep = 5427. State = [[-0.36465     0.07722718]]. Action = [[-0.06622587  0.07041916  0.          0.7907672 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 5427 is [True, False, False, False, True, False]
Current timestep = 5428. State = [[-0.36368468  0.08013774]]. Action = [[ 0.05458123  0.01729421  0.         -0.9157709 ]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 5428 is [True, False, False, False, True, False]
State prediction error at timestep 5428 is 0.012
Human Feedback received at timestep 5428 of None
Current timestep = 5429. State = [[-0.36404052  0.07885036]]. Action = [[-0.04280937 -0.04073411  0.          0.4140774 ]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 5429 is [True, False, False, False, True, False]
Current timestep = 5430. State = [[-0.36782983  0.0740634 ]]. Action = [[-0.06799494 -0.07923587  0.         -0.36482167]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 5430 is [True, False, False, False, True, False]
State prediction error at timestep 5430 is 0.012
Human Feedback received at timestep 5430 of None
Current timestep = 5431. State = [[-0.3658045   0.07466194]]. Action = [[ 0.08294529  0.06296619  0.         -0.24454975]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 5431 is [True, False, False, False, True, False]
State prediction error at timestep 5431 is 0.012
Human Feedback received at timestep 5431 of None
Current timestep = 5432. State = [[-0.36388174  0.07522353]]. Action = [[-0.02287718 -0.02408642  0.         -0.81067365]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 5432 is [True, False, False, False, True, False]
State prediction error at timestep 5432 is 0.012
Human Feedback received at timestep 5432 of None
Current timestep = 5433. State = [[-0.36136782  0.07875901]]. Action = [[ 0.04896533  0.08118241  0.         -0.4433419 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 5433 is [True, False, False, False, True, False]
Current timestep = 5434. State = [[-0.36002246  0.08180888]]. Action = [[-0.00558335  0.01025482  0.          0.56979394]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 5434 is [True, False, False, False, True, False]
Current timestep = 5435. State = [[-0.36246148  0.08592739]]. Action = [[-0.05203995  0.06390228  0.          0.67700887]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 5435 is [True, False, False, False, True, False]
Current timestep = 5436. State = [[-0.35939172  0.08715422]]. Action = [[ 0.09580999 -0.02624567  0.         -0.8731373 ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 5436 is [True, False, False, False, True, False]
Current timestep = 5437. State = [[-0.35773617  0.08258846]]. Action = [[-0.03224616 -0.08742961  0.          0.7662276 ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 5437 is [True, False, False, False, True, False]
Current timestep = 5438. State = [[-0.36120003  0.08433919]]. Action = [[-0.06427098  0.08347528  0.          0.6648352 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 5438 is [True, False, False, False, True, False]
Current timestep = 5439. State = [[-0.36523676  0.08598616]]. Action = [[-0.04365989 -0.02913567  0.          0.12247372]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 5439 is [True, False, False, False, True, False]
State prediction error at timestep 5439 is 0.012
Human Feedback received at timestep 5439 of None
Current timestep = 5440. State = [[-0.36759332  0.08760339]]. Action = [[-0.0181645   0.03120413  0.          0.3089428 ]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 5440 is [True, False, False, False, True, False]
Current timestep = 5441. State = [[-0.37062553  0.09092423]]. Action = [[-0.03870109  0.03496218  0.          0.5197513 ]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 5441 is [True, False, False, False, True, False]
State prediction error at timestep 5441 is 0.012
Human Feedback received at timestep 5441 of None
Current timestep = 5442. State = [[-0.37250936  0.09272859]]. Action = [[0.        0.        0.        0.2588513]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 5442 is [True, False, False, False, True, False]
Current timestep = 5443. State = [[-0.37329215  0.09335608]]. Action = [[0.         0.         0.         0.28654683]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 5443 is [True, False, False, False, True, False]
Current timestep = 5444. State = [[-0.37519637  0.09553292]]. Action = [[-0.02343397  0.03405254  0.          0.05199683]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 5444 is [True, False, False, False, True, False]
Current timestep = 5445. State = [[-0.37435275  0.09359556]]. Action = [[ 0.0448762  -0.06710513  0.         -0.35880172]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 5445 is [True, False, False, False, True, False]
Current timestep = 5446. State = [[-0.37335432  0.09172317]]. Action = [[ 0.          0.          0.         -0.95847917]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 5446 is [True, False, False, False, True, False]
Current timestep = 5447. State = [[-0.36955622  0.09594627]]. Action = [[0.08658233 0.09150996 0.         0.70284534]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 5447 is [True, False, False, False, True, False]
Current timestep = 5448. State = [[-0.3675009   0.09839702]]. Action = [[ 0.         0.         0.        -0.8182257]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 5448 is [True, False, False, False, True, False]
Current timestep = 5449. State = [[-0.36705747  0.10150614]]. Action = [[ 0.01223595  0.05949771  0.         -0.37257445]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 5449 is [True, False, False, False, True, False]
Current timestep = 5450. State = [[-0.36392903  0.10221432]]. Action = [[ 0.06159703 -0.02237413  0.         -0.59771276]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 5450 is [True, False, False, False, True, False]
Current timestep = 5451. State = [[-0.36616585  0.10601415]]. Action = [[-0.08171725  0.08458521  0.         -0.18429416]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 5451 is [True, False, False, False, True, False]
Current timestep = 5452. State = [[-0.36516786  0.11160976]]. Action = [[0.07552957 0.05124015 0.         0.07990861]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 5452 is [True, False, False, False, True, False]
Current timestep = 5453. State = [[-0.35895604  0.11779781]]. Action = [[ 0.09350952  0.0827489   0.         -0.14574516]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 5453 is [True, False, False, False, True, False]
Current timestep = 5454. State = [[-0.36027738  0.12185462]]. Action = [[-0.09138942  0.01115967  0.         -0.57244223]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 5454 is [True, False, False, False, True, False]
Current timestep = 5455. State = [[-0.36316082  0.12445989]]. Action = [[ 0.00476317  0.0202144   0.         -0.97982   ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 5455 is [True, False, False, False, True, False]
Current timestep = 5456. State = [[-0.36094645  0.12158342]]. Action = [[ 0.05527329 -0.09063885  0.          0.7262764 ]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 5456 is [True, False, False, False, True, False]
Current timestep = 5457. State = [[-0.36165935  0.11587141]]. Action = [[-0.05514414 -0.08173246  0.         -0.42657578]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 5457 is [True, False, False, False, True, False]
Current timestep = 5458. State = [[-0.3650952   0.11244299]]. Action = [[-0.05711594 -0.03894977  0.          0.26894557]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 5458 is [True, False, False, False, True, False]
State prediction error at timestep 5458 is 0.012
Human Feedback received at timestep 5458 of None
Current timestep = 5459. State = [[-0.36806047  0.1165758 ]]. Action = [[-0.03293847  0.0961151   0.         -0.83483857]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 5459 is [True, False, False, False, True, False]
State prediction error at timestep 5459 is 0.012
Human Feedback received at timestep 5459 of None
Current timestep = 5460. State = [[-0.36942583  0.11977426]]. Action = [[0.         0.         0.         0.38984537]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 5460 is [True, False, False, False, True, False]
Current timestep = 5461. State = [[-0.36765066  0.12055485]]. Action = [[0.04399996 0.00814811 0.         0.64395475]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 5461 is [True, False, False, False, True, False]
Current timestep = 5462. State = [[-0.36668184  0.1207767 ]]. Action = [[0.         0.         0.         0.43026447]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 5462 is [True, False, False, False, True, False]
Current timestep = 5463. State = [[-0.36753055  0.11663352]]. Action = [[-0.02020162 -0.08582891  0.          0.8586657 ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 5463 is [True, False, False, False, True, False]
State prediction error at timestep 5463 is 0.012
Human Feedback received at timestep 5463 of None
Current timestep = 5464. State = [[-0.37024045  0.11784013]]. Action = [[-0.04645512  0.07526775  0.         -0.50617796]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 5464 is [True, False, False, False, True, False]
Current timestep = 5465. State = [[-0.37389967  0.11542016]]. Action = [[-0.04359528 -0.09827986  0.         -0.8669142 ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 5465 is [True, False, False, False, True, False]
Current timestep = 5466. State = [[-0.37515754  0.11284953]]. Action = [[ 0.         0.         0.        -0.7605116]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 5466 is [True, False, False, False, True, False]
Current timestep = 5467. State = [[-0.37455687  0.10811028]]. Action = [[ 0.01354317 -0.08755729  0.          0.9951891 ]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 5467 is [True, False, False, False, True, False]
Current timestep = 5468. State = [[-0.37317997  0.1032989 ]]. Action = [[ 0.01430292 -0.03339524  0.         -0.36296666]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 5468 is [True, False, False, False, True, False]
Current timestep = 5469. State = [[-0.37446043  0.10513648]]. Action = [[-0.03462374  0.07713648  0.          0.65592813]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 5469 is [True, False, False, False, True, False]
Current timestep = 5470. State = [[-0.37350616  0.11048655]]. Action = [[ 0.05605228  0.07909416  0.         -0.04895514]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 5470 is [True, False, False, False, True, False]
State prediction error at timestep 5470 is 0.012
Human Feedback received at timestep 5470 of None
Current timestep = 5471. State = [[-0.3730325   0.11217151]]. Action = [[0.         0.         0.         0.62067294]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 5471 is [True, False, False, False, True, False]
Current timestep = 5472. State = [[-0.3753472   0.11557534]]. Action = [[-0.02970279  0.07312211  0.          0.1348629 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 5472 is [True, False, False, False, True, False]
State prediction error at timestep 5472 is 0.012
Human Feedback received at timestep 5472 of None
Current timestep = 5473. State = [[-0.37727848  0.11374643]]. Action = [[-0.00443427 -0.08200727  0.         -0.31350207]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 5473 is [True, False, False, False, True, False]
Current timestep = 5474. State = [[-0.37776074  0.11158473]]. Action = [[0.        0.        0.        0.7132051]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 5474 is [True, False, False, False, True, False]
State prediction error at timestep 5474 is 0.012
Human Feedback received at timestep 5474 of None
Current timestep = 5475. State = [[-0.37667412  0.1146053 ]]. Action = [[0.03234393 0.06519466 0.         0.32511127]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 5475 is [True, False, False, False, True, False]
Current timestep = 5476. State = [[-0.37719044  0.11601985]]. Action = [[-0.01626522 -0.00813638  0.         -0.9110125 ]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 5476 is [True, False, False, False, True, False]
Current timestep = 5477. State = [[-0.37798178  0.11605041]]. Action = [[ 0.          0.          0.         -0.55565083]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 5477 is [True, False, False, False, True, False]
Current timestep = 5478. State = [[-0.3767509  0.1133805]]. Action = [[ 0.02787598 -0.05633512  0.          0.7699406 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 5478 is [True, False, False, False, True, False]
State prediction error at timestep 5478 is 0.012
Human Feedback received at timestep 5478 of None
Current timestep = 5479. State = [[-0.3757399   0.11172168]]. Action = [[0.        0.        0.        0.7793937]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 5479 is [True, False, False, False, True, False]
State prediction error at timestep 5479 is 0.012
Human Feedback received at timestep 5479 of None
Current timestep = 5480. State = [[-0.37256587  0.10993341]]. Action = [[ 0.05787788 -0.03044226  0.         -0.00858986]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 5480 is [True, False, False, False, True, False]
Current timestep = 5481. State = [[-0.36781135  0.10918365]]. Action = [[0.05317076 0.01369443 0.         0.02818525]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 5481 is [True, False, False, False, True, False]
Current timestep = 5482. State = [[-0.3664481   0.11087923]]. Action = [[-0.01526964  0.03787401  0.          0.30553102]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 5482 is [True, False, False, False, True, False]
Current timestep = 5483. State = [[-0.3614168   0.11111522]]. Action = [[ 0.09993329 -0.00912343  0.          0.5216441 ]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 5483 is [True, False, False, False, True, False]
Current timestep = 5484. State = [[-0.35357368  0.11001678]]. Action = [[ 0.08686098 -0.00247558  0.          0.58712935]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 5484 is [True, False, False, False, True, False]
State prediction error at timestep 5484 is 0.012
Human Feedback received at timestep 5484 of None
Current timestep = 5485. State = [[-0.347446    0.11375755]]. Action = [[ 0.05216982  0.09307738  0.         -0.88695675]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 5485 is [True, False, False, False, True, False]
Current timestep = 5486. State = [[-0.3419878   0.11702517]]. Action = [[ 0.05949046  0.02192213  0.         -0.3188852 ]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 5486 is [True, False, False, False, True, False]
Current timestep = 5487. State = [[-0.33719796  0.1166401 ]]. Action = [[ 0.03493839 -0.019852    0.         -0.59889466]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 5487 is [True, False, False, False, True, False]
Current timestep = 5488. State = [[-0.33560517  0.11636072]]. Action = [[-0.02449241  0.00041534  0.          0.17970729]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 5488 is [True, False, False, False, True, False]
Current timestep = 5489. State = [[-0.333798    0.12174034]]. Action = [[ 0.01902203  0.09814223  0.         -0.8919055 ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 5489 is [True, False, False, False, True, False]
Current timestep = 5490. State = [[-0.336812    0.13010645]]. Action = [[-0.08870637  0.09470079  0.          0.9457736 ]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 5490 is [True, False, False, False, True, False]
Current timestep = 5491. State = [[-0.33732516  0.1343105 ]]. Action = [[ 0.03235539 -0.00154707  0.          0.05452752]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 5491 is [True, False, False, False, False, True]
Current timestep = 5492. State = [[-0.33553773  0.13617846]]. Action = [[ 0.01173772  0.00790976  0.         -0.43811786]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 5492 is [True, False, False, False, False, True]
Current timestep = 5493. State = [[-0.3363097   0.14001866]]. Action = [[-0.03018057  0.04308324  0.          0.55007076]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 5493 is [True, False, False, False, False, True]
Current timestep = 5494. State = [[-0.3398403   0.14586963]]. Action = [[-0.05391356  0.05808317  0.          0.5942892 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 5494 is [True, False, False, False, False, True]
Current timestep = 5495. State = [[-0.3391427   0.14564212]]. Action = [[ 0.04832166 -0.07637418  0.         -0.13002777]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 5495 is [True, False, False, False, False, True]
Current timestep = 5496. State = [[-0.33466145  0.14155559]]. Action = [[ 0.05473416 -0.06456903  0.         -0.7255446 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 5496 is [True, False, False, False, False, True]
Current timestep = 5497. State = [[-0.33112553  0.14211409]]. Action = [[ 0.02363934  0.03797012  0.         -0.1766954 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 5497 is [True, False, False, False, False, True]
Current timestep = 5498. State = [[-0.32517594  0.14308912]]. Action = [[ 0.09164802 -0.00754423  0.         -0.3235873 ]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 5498 is [True, False, False, False, False, True]
Current timestep = 5499. State = [[-0.32494414  0.14466834]]. Action = [[-0.06901959  0.03007937  0.          0.9858215 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 5499 is [True, False, False, False, False, True]
Current timestep = 5500. State = [[-0.32580063  0.1448642 ]]. Action = [[ 0.00501027 -0.0244138   0.         -0.45081604]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 5500 is [True, False, False, False, False, True]
State prediction error at timestep 5500 is 0.012
Human Feedback received at timestep 5500 of None
Current timestep = 5501. State = [[-0.3220692   0.14680678]]. Action = [[ 0.06354179  0.04853698  0.         -0.77491754]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 5501 is [True, False, False, False, False, True]
Current timestep = 5502. State = [[-0.323763    0.14971383]]. Action = [[-0.0829592  0.0263649  0.         0.5226872]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 5502 is [True, False, False, False, False, True]
Current timestep = 5503. State = [[-0.3247929   0.14931566]]. Action = [[ 0.02138972 -0.03519761  0.         -0.37890375]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 5503 is [True, False, False, False, False, True]
Current timestep = 5504. State = [[-0.32754076  0.15183328]]. Action = [[-0.067006    0.06268302  0.          0.29231215]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 5504 is [True, False, False, False, False, True]
Current timestep = 5505. State = [[-0.33283126  0.15722594]]. Action = [[-0.05880773  0.05917915  0.         -0.10286373]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 5505 is [True, False, False, False, False, True]
Current timestep = 5506. State = [[-0.33428058  0.16452292]]. Action = [[ 0.03119921  0.09707566  0.         -0.9885426 ]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 5506 is [True, False, False, False, False, True]
Current timestep = 5507. State = [[-0.33186498  0.16568907]]. Action = [[ 0.0586363  -0.04455028  0.         -0.96542627]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 5507 is [True, False, False, False, False, True]
Current timestep = 5508. State = [[-0.3277413   0.16222149]]. Action = [[ 0.05808521 -0.05510808  0.          0.92483234]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 5508 is [True, False, False, False, False, True]
Current timestep = 5509. State = [[-0.32092077  0.15601456]]. Action = [[ 0.09669717 -0.09492198  0.          0.19116831]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 5509 is [True, False, False, False, False, True]
Current timestep = 5510. State = [[-0.3211566   0.15037294]]. Action = [[-0.08652282 -0.05986571  0.          0.06970572]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 5510 is [True, False, False, False, False, True]
Current timestep = 5511. State = [[-0.32695472  0.14505392]]. Action = [[-0.09488456 -0.08144921  0.         -0.39870954]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 5511 is [True, False, False, False, False, True]
State prediction error at timestep 5511 is 0.012
Human Feedback received at timestep 5511 of None
Current timestep = 5512. State = [[-0.3247226   0.13800336]]. Action = [[ 0.08774491 -0.09105213  0.          0.60234   ]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 5512 is [True, False, False, False, False, True]
Current timestep = 5513. State = [[-0.3206944   0.13849658]]. Action = [[ 0.01320603  0.08980098  0.         -0.6658172 ]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 5513 is [True, False, False, False, False, True]
Current timestep = 5514. State = [[-0.32147744  0.13628414]]. Action = [[-0.04225131 -0.07950859  0.         -0.81058604]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 5514 is [True, False, False, False, False, True]
State prediction error at timestep 5514 is 0.012
Human Feedback received at timestep 5514 of None
Current timestep = 5515. State = [[-0.32437742  0.13118108]]. Action = [[-0.04735998 -0.04828591  0.         -0.7322848 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 5515 is [True, False, False, False, False, True]
Current timestep = 5516. State = [[-0.32559317  0.12409923]]. Action = [[-0.00546733 -0.09821217  0.          0.9295031 ]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 5516 is [True, False, False, False, False, True]
Current timestep = 5517. State = [[-0.32389593  0.11940758]]. Action = [[ 0.03090932 -0.01235861  0.          0.10662019]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 5517 is [True, False, False, False, True, False]
Current timestep = 5518. State = [[-0.32251042  0.11561996]]. Action = [[ 0.00730159 -0.03484861  0.          0.27656734]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 5518 is [True, False, False, False, True, False]
State prediction error at timestep 5518 is 0.012
Human Feedback received at timestep 5518 of None
Current timestep = 5519. State = [[-0.3246536   0.11168022]]. Action = [[-0.05030165 -0.02919804  0.         -0.39307648]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 5519 is [True, False, False, False, True, False]
State prediction error at timestep 5519 is 0.012
Human Feedback received at timestep 5519 of None
Current timestep = 5520. State = [[-0.3226667   0.11071838]]. Action = [[ 0.0769472   0.03039701  0.         -0.9638663 ]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 5520 is [True, False, False, False, True, False]
Current timestep = 5521. State = [[-0.3232096   0.10658675]]. Action = [[-0.05571282 -0.07120021  0.          0.9502114 ]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 5521 is [True, False, False, False, True, False]
State prediction error at timestep 5521 is 0.012
Human Feedback received at timestep 5521 of None
Current timestep = 5522. State = [[-0.32351905  0.10241554]]. Action = [[ 0.03045291 -0.01566839  0.          0.43655312]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 5522 is [True, False, False, False, True, False]
Current timestep = 5523. State = [[-0.31834617  0.09748147]]. Action = [[ 0.09894898 -0.05279533  0.          0.3497132 ]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 5523 is [True, False, False, False, True, False]
Current timestep = 5524. State = [[-0.3166613   0.09372676]]. Action = [[-0.01990569 -0.00660031  0.         -0.31097245]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 5524 is [True, False, False, False, True, False]
Current timestep = 5525. State = [[-0.31509814  0.09202987]]. Action = [[ 0.04251666  0.00397778  0.         -0.628325  ]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 5525 is [True, False, False, False, True, False]
Current timestep = 5526. State = [[-0.31246626  0.08825321]]. Action = [[ 0.03061736 -0.04538015  0.          0.40746927]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 5526 is [True, False, False, False, True, False]
State prediction error at timestep 5526 is 0.012
Human Feedback received at timestep 5526 of None
Current timestep = 5527. State = [[-0.31019163  0.08232249]]. Action = [[ 0.02093612 -0.06233232  0.         -0.8645933 ]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 5527 is [True, False, False, False, True, False]
Current timestep = 5528. State = [[-0.3088693   0.08022972]]. Action = [[0.00333434 0.02510139 0.         0.1534481 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 5528 is [True, False, False, False, True, False]
Current timestep = 5529. State = [[-0.31040835  0.08259919]]. Action = [[-0.03922393  0.05965538  0.         -0.15176809]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 5529 is [True, False, False, False, True, False]
State prediction error at timestep 5529 is 0.012
Human Feedback received at timestep 5529 of None
Current timestep = 5530. State = [[-0.31149164  0.086357  ]]. Action = [[0.0050266  0.05570414 0.         0.7127049 ]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 5530 is [True, False, False, False, True, False]
State prediction error at timestep 5530 is 0.012
Human Feedback received at timestep 5530 of None
Current timestep = 5531. State = [[-0.30931428  0.08622591]]. Action = [[ 0.05154877 -0.02648514  0.          0.24717772]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 5531 is [True, False, False, False, True, False]
Current timestep = 5532. State = [[-0.3120073   0.08858946]]. Action = [[-0.07995174  0.06689637  0.          0.19113612]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 5532 is [True, False, False, False, True, False]
Current timestep = 5533. State = [[-0.31190196  0.09332655]]. Action = [[0.0619569  0.05387133 0.         0.72904944]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 5533 is [True, False, False, False, True, False]
Current timestep = 5534. State = [[-0.30802238  0.093494  ]]. Action = [[ 0.05709385 -0.03461196  0.          0.92060554]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 5534 is [True, False, False, False, True, False]
State prediction error at timestep 5534 is 0.012
Human Feedback received at timestep 5534 of None
Current timestep = 5535. State = [[-0.30570197  0.09699994]]. Action = [[ 0.01605024  0.08378913  0.         -0.18882293]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 5535 is [True, False, False, False, True, False]
Current timestep = 5536. State = [[-0.30780447  0.10414501]]. Action = [[-0.04573649  0.08293397  0.          0.95807064]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 5536 is [True, False, False, False, True, False]
Current timestep = 5537. State = [[-0.3056243   0.10625116]]. Action = [[ 0.07805584 -0.0287459   0.          0.9709264 ]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 5537 is [True, False, False, False, True, False]
Current timestep = 5538. State = [[-0.29992208  0.10341865]]. Action = [[ 0.06856253 -0.05891876  0.          0.20128334]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 5538 is [True, False, False, False, True, False]
Current timestep = 5539. State = [[-0.30148062  0.1037505 ]]. Action = [[-0.09099458  0.02511188  0.          0.5800214 ]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 5539 is [True, False, False, False, True, False]
Current timestep = 5540. State = [[-0.3058054   0.10313509]]. Action = [[-0.05504096 -0.05084543  0.         -0.8889032 ]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 5540 is [True, False, False, False, True, False]
Current timestep = 5541. State = [[-0.3116143   0.10604464]]. Action = [[-0.09682047  0.06240944  0.         -0.23386216]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 5541 is [True, False, False, False, True, False]
State prediction error at timestep 5541 is 0.012
Human Feedback received at timestep 5541 of None
Current timestep = 5542. State = [[-0.31017822  0.10595205]]. Action = [[ 0.08774268 -0.0577973   0.         -0.40956742]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 5542 is [True, False, False, False, True, False]
State prediction error at timestep 5542 is 0.012
Human Feedback received at timestep 5542 of None
Current timestep = 5543. State = [[-0.3037017   0.10208707]]. Action = [[ 0.0773522  -0.05033838  0.         -0.3125273 ]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 5543 is [True, False, False, False, True, False]
Current timestep = 5544. State = [[-0.29586306  0.09695432]]. Action = [[ 0.09584942 -0.06481513  0.          0.57236767]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 5544 is [True, False, False, False, True, False]
State prediction error at timestep 5544 is 0.012
Human Feedback received at timestep 5544 of None
Current timestep = 5545. State = [[-0.28883186  0.08990496]]. Action = [[ 0.05774856 -0.08615923  0.         -0.4700235 ]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 5545 is [True, False, False, False, True, False]
State prediction error at timestep 5545 is 0.012
Human Feedback received at timestep 5545 of None
Current timestep = 5546. State = [[-0.28727865  0.08631828]]. Action = [[-0.04105175 -0.00087231  0.          0.16000307]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 5546 is [True, False, False, False, True, False]
Current timestep = 5547. State = [[-0.2915016   0.09038303]]. Action = [[-0.09653146  0.09971815  0.         -0.31540835]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 5547 is [True, False, False, False, True, False]
Current timestep = 5548. State = [[-0.28997645  0.09654686]]. Action = [[ 0.08549634  0.0784043   0.         -0.3059638 ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 5548 is [True, False, False, False, True, False]
Current timestep = 5549. State = [[-0.29083043  0.09857209]]. Action = [[-0.07676311 -0.0050808   0.          0.47671175]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 5549 is [True, False, False, False, True, False]
Current timestep = 5550. State = [[-0.29743794  0.10013222]]. Action = [[-0.09443722  0.02554259  0.         -0.13744044]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 5550 is [True, False, False, False, True, False]
Current timestep = 5551. State = [[-0.30516648  0.10412073]]. Action = [[-0.09035069  0.05045445  0.         -0.7283503 ]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 5551 is [True, False, False, False, True, False]
State prediction error at timestep 5551 is 0.012
Human Feedback received at timestep 5551 of None
Current timestep = 5552. State = [[-0.30592838  0.10655092]]. Action = [[ 0.06686235  0.00333371  0.         -0.4766615 ]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 5552 is [True, False, False, False, True, False]
Current timestep = 5553. State = [[-0.3025106   0.10791949]]. Action = [[0.06031003 0.0155708  0.         0.5146631 ]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 5553 is [True, False, False, False, True, False]
Current timestep = 5554. State = [[-0.29971096  0.10767003]]. Action = [[ 0.03878336 -0.01914132  0.         -0.16711557]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 5554 is [True, False, False, False, True, False]
State prediction error at timestep 5554 is 0.012
Human Feedback received at timestep 5554 of None
Current timestep = 5555. State = [[-0.2990652   0.10391538]]. Action = [[-0.00534179 -0.07033176  0.         -0.37726057]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 5555 is [True, False, False, False, True, False]
State prediction error at timestep 5555 is 0.012
Human Feedback received at timestep 5555 of None
Current timestep = 5556. State = [[-0.30138355  0.09991515]]. Action = [[-0.05105001 -0.04572682  0.          0.05882454]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 5556 is [True, False, False, False, True, False]
Current timestep = 5557. State = [[-0.2987518  0.1007477]]. Action = [[ 0.08382919  0.04669409  0.         -0.6730137 ]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 5557 is [True, False, False, False, True, False]
Current timestep = 5558. State = [[-0.2938533   0.10132464]]. Action = [[ 0.04483867 -0.00791552  0.         -0.5340391 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 5558 is [True, False, False, False, True, False]
Current timestep = 5559. State = [[-0.28712443  0.10366981]]. Action = [[ 0.09708027  0.06004875  0.         -0.25362253]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 5559 is [True, False, False, False, True, False]
State prediction error at timestep 5559 is 0.012
Human Feedback received at timestep 5559 of None
Current timestep = 5560. State = [[-0.28455186  0.10790553]]. Action = [[-0.01612385  0.05931262  0.         -0.6997658 ]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 5560 is [True, False, False, False, True, False]
Current timestep = 5561. State = [[-0.28884995  0.11312298]]. Action = [[-0.09075078  0.06438331  0.         -0.9185929 ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 5561 is [True, False, False, False, True, False]
State prediction error at timestep 5561 is 0.012
Human Feedback received at timestep 5561 of None
Current timestep = 5562. State = [[-0.29115793  0.11382031]]. Action = [[-3.0362606e-04 -4.1883577e-02  0.0000000e+00  3.1812787e-01]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 5562 is [True, False, False, False, True, False]
State prediction error at timestep 5562 is 0.012
Human Feedback received at timestep 5562 of None
Current timestep = 5563. State = [[-0.293009   0.1129931]]. Action = [[-0.04196317 -0.01239961  0.         -0.10032427]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 5563 is [True, False, False, False, True, False]
State prediction error at timestep 5563 is 0.012
Human Feedback received at timestep 5563 of None
Current timestep = 5564. State = [[-0.29219487  0.11378493]]. Action = [[0.0355941  0.00786717 0.         0.40286398]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 5564 is [True, False, False, False, True, False]
Current timestep = 5565. State = [[-0.28630447  0.1119591 ]]. Action = [[ 0.09664918 -0.04812765  0.          0.7139733 ]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 5565 is [True, False, False, False, True, False]
Current timestep = 5566. State = [[-0.27824     0.10545046]]. Action = [[ 0.09339093 -0.09910247  0.          0.56581426]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 5566 is [True, False, False, False, True, False]
Current timestep = 5567. State = [[-0.27158725  0.10370999]]. Action = [[ 0.0538002   0.03790384  0.         -0.03462809]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 5567 is [True, False, False, False, True, False]
State prediction error at timestep 5567 is 0.012
Human Feedback received at timestep 5567 of None
Current timestep = 5568. State = [[-0.2688172   0.10606581]]. Action = [[-0.00228329  0.04079717  0.         -0.7574706 ]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 5568 is [True, False, False, False, True, False]
Current timestep = 5569. State = [[-0.2631039   0.10836435]]. Action = [[ 0.09356911  0.03229528  0.         -0.93543565]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 5569 is [True, False, False, False, True, False]
Current timestep = 5570. State = [[-0.25920594  0.11084862]]. Action = [[0.0029328  0.04113878 0.         0.28558087]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 5570 is [True, False, False, False, True, False]
State prediction error at timestep 5570 is 0.012
Human Feedback received at timestep 5570 of None
Current timestep = 5571. State = [[-0.25916398  0.11512326]]. Action = [[-0.02525654  0.06252118  0.         -0.70994747]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 5571 is [True, False, False, False, True, False]
Current timestep = 5572. State = [[-0.258593    0.11591072]]. Action = [[ 0.00698185 -0.02973189  0.         -0.5213922 ]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 5572 is [True, False, False, False, True, False]
Current timestep = 5573. State = [[-0.25716105  0.11991277]]. Action = [[ 0.00804398  0.08511501  0.         -0.19639027]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 5573 is [True, False, False, False, True, False]
State prediction error at timestep 5573 is 0.012
Human Feedback received at timestep 5573 of None
Current timestep = 5574. State = [[-0.25859737  0.11960617]]. Action = [[-0.04911102 -0.07229389  0.          0.8561506 ]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 5574 is [True, False, False, False, True, False]
Current timestep = 5575. State = [[-0.2595592   0.11453869]]. Action = [[-0.01237258 -0.08349055  0.          0.17492282]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 5575 is [True, False, False, False, True, False]
Current timestep = 5576. State = [[-0.26277694  0.11273401]]. Action = [[-0.07896335 -0.00236992  0.         -0.37113273]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 5576 is [True, False, False, False, True, False]
Current timestep = 5577. State = [[-0.26493588  0.1132729 ]]. Action = [[-1.1744820e-02 -2.9405206e-04  0.0000000e+00  7.7964211e-01]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 5577 is [True, False, False, False, True, False]
Current timestep = 5578. State = [[-0.2697622   0.11428415]]. Action = [[-0.09431986  0.00788321  0.         -0.33591765]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 5578 is [True, False, False, False, True, False]
Current timestep = 5579. State = [[-0.2739116   0.11245302]]. Action = [[-0.02852564 -0.05571761  0.          0.54902005]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 5579 is [True, False, False, False, True, False]
Current timestep = 5580. State = [[-0.27935228  0.11468925]]. Action = [[-0.08230542  0.06883805  0.          0.9918387 ]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 5580 is [True, False, False, False, True, False]
Current timestep = 5581. State = [[-0.28403902  0.11841358]]. Action = [[-0.02253735  0.02654489  0.         -0.17131948]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 5581 is [True, False, False, False, True, False]
Current timestep = 5582. State = [[-0.28318474  0.11603677]]. Action = [[ 0.06338631 -0.06958807  0.         -0.39389783]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 5582 is [True, False, False, False, True, False]
State prediction error at timestep 5582 is 0.012
Human Feedback received at timestep 5582 of None
Current timestep = 5583. State = [[-0.28544158  0.11264014]]. Action = [[-0.05868398 -0.02512805  0.          0.944782  ]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 5583 is [True, False, False, False, True, False]
Current timestep = 5584. State = [[-0.28488404  0.10834845]]. Action = [[ 0.062957   -0.06357014  0.          0.74686575]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 5584 is [True, False, False, False, True, False]
Current timestep = 5585. State = [[-0.28643385  0.10959212]]. Action = [[-0.04705346  0.07961091  0.         -0.31536663]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 5585 is [True, False, False, False, True, False]
Current timestep = 5586. State = [[-0.28523433  0.11184829]]. Action = [[0.07550798 0.01362757 0.         0.77924347]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 5586 is [True, False, False, False, True, False]
Current timestep = 5587. State = [[-0.2848121   0.11110792]]. Action = [[-0.0119913  -0.01122043  0.          0.47121692]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 5587 is [True, False, False, False, True, False]
Current timestep = 5588. State = [[-0.28387663  0.10647965]]. Action = [[ 0.0359617  -0.07599477  0.          0.5462767 ]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 5588 is [True, False, False, False, True, False]
State prediction error at timestep 5588 is 0.012
Human Feedback received at timestep 5588 of None
Current timestep = 5589. State = [[-0.279784    0.10034798]]. Action = [[ 0.06431942 -0.06236622  0.         -0.31074882]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 5589 is [True, False, False, False, True, False]
State prediction error at timestep 5589 is 0.012
Human Feedback received at timestep 5589 of None
Current timestep = 5590. State = [[-0.27854502  0.0983428 ]]. Action = [[-0.0187434   0.01980444  0.          0.20255959]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 5590 is [True, False, False, False, True, False]
Current timestep = 5591. State = [[-0.28039074  0.09756475]]. Action = [[-0.0358442  -0.00805276  0.          0.43417585]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 5591 is [True, False, False, False, True, False]
Current timestep = 5592. State = [[-0.27989125  0.10015735]]. Action = [[ 0.0293945   0.07160541  0.         -0.10570568]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 5592 is [True, False, False, False, True, False]
Current timestep = 5593. State = [[-0.2802812   0.10084861]]. Action = [[-0.02063016 -0.01484764  0.         -0.91670924]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 5593 is [True, False, False, False, True, False]
Current timestep = 5594. State = [[-0.28506446  0.10109058]]. Action = [[-0.08682695  0.0154744   0.         -0.5599336 ]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 5594 is [True, False, False, False, True, False]
Current timestep = 5595. State = [[-0.28756925  0.10104781]]. Action = [[ 0.00289285 -0.01220554  0.          0.59263563]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 5595 is [True, False, False, False, True, False]
State prediction error at timestep 5595 is 0.012
Human Feedback received at timestep 5595 of None
Current timestep = 5596. State = [[-0.29160583  0.10453295]]. Action = [[-0.07139604  0.07332889  0.         -0.8671883 ]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 5596 is [True, False, False, False, True, False]
State prediction error at timestep 5596 is 0.012
Human Feedback received at timestep 5596 of None
Current timestep = 5597. State = [[-0.29880336  0.10646036]]. Action = [[-0.08831651 -0.01573679  0.          0.9982662 ]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 5597 is [True, False, False, False, True, False]
Current timestep = 5598. State = [[-0.30108124  0.10252412]]. Action = [[ 0.02290593 -0.08668869  0.          0.44517696]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 5598 is [True, False, False, False, True, False]
Current timestep = 5599. State = [[-0.29657114  0.09750328]]. Action = [[ 0.09667375 -0.04951474  0.         -0.84961843]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 5599 is [True, False, False, False, True, False]
Current timestep = 5600. State = [[-0.2967808   0.09857325]]. Action = [[-0.04828611  0.06467941  0.          0.25033498]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 5600 is [True, False, False, False, True, False]
State prediction error at timestep 5600 is 0.012
Human Feedback received at timestep 5600 of None
Current timestep = 5601. State = [[-0.298969    0.10293288]]. Action = [[-0.00297753  0.05477824  0.          0.8163638 ]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 5601 is [True, False, False, False, True, False]
Current timestep = 5602. State = [[-0.296747    0.10406377]]. Action = [[ 0.06743493 -0.00816358  0.         -0.44966984]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 5602 is [True, False, False, False, True, False]
State prediction error at timestep 5602 is 0.012
Human Feedback received at timestep 5602 of None
Current timestep = 5603. State = [[-0.29801753  0.09889486]]. Action = [[-0.06101648 -0.09982603  0.          0.28095317]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 5603 is [True, False, False, False, True, False]
State prediction error at timestep 5603 is 0.012
Human Feedback received at timestep 5603 of None
Current timestep = 5604. State = [[-0.30016565  0.09394745]]. Action = [[-0.00598762 -0.03870881  0.          0.4414947 ]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 5604 is [True, False, False, False, True, False]
State prediction error at timestep 5604 is 0.012
Human Feedback received at timestep 5604 of None
Current timestep = 5605. State = [[-0.30014423  0.0914203 ]]. Action = [[ 0.01094747 -0.01543942  0.         -0.70505947]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 5605 is [True, False, False, False, True, False]
Current timestep = 5606. State = [[-0.2975321   0.08921292]]. Action = [[ 0.05144424 -0.01816814  0.         -0.98351455]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 5606 is [True, False, False, False, True, False]
Current timestep = 5607. State = [[-0.29926002  0.08704156]]. Action = [[-0.06528139 -0.0156225   0.         -0.75758266]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 5607 is [True, False, False, False, True, False]
Current timestep = 5608. State = [[-0.30546224  0.08488268]]. Action = [[-0.09020131 -0.02362653  0.          0.23701155]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 5608 is [True, False, False, False, True, False]
Current timestep = 5609. State = [[-0.30463818  0.08524181]]. Action = [[ 0.08836951  0.03621843  0.         -0.8425248 ]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 5609 is [True, False, False, False, True, False]
Current timestep = 5610. State = [[-0.30361894  0.0870404 ]]. Action = [[-0.02310195  0.0293012   0.         -0.744125  ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 5610 is [True, False, False, False, True, False]
Current timestep = 5611. State = [[-0.29946953  0.08475702]]. Action = [[ 0.09688517 -0.05372725  0.          0.99164796]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 5611 is [True, False, False, False, True, False]
State prediction error at timestep 5611 is 0.012
Human Feedback received at timestep 5611 of None
Current timestep = 5612. State = [[-0.29278412  0.08518625]]. Action = [[0.08053304 0.05688854 0.         0.7881341 ]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 5612 is [True, False, False, False, True, False]
Current timestep = 5613. State = [[-0.2863499   0.08574457]]. Action = [[ 0.0789557  -0.00325999  0.          0.30471492]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 5613 is [True, False, False, False, True, False]
Current timestep = 5614. State = [[-0.28356674  0.08078571]]. Action = [[-0.0081232  -0.08736243  0.         -0.55437833]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 5614 is [True, False, False, False, True, False]
Current timestep = 5615. State = [[-0.28181624  0.0793904 ]]. Action = [[ 0.01545628  0.033295    0.         -0.56784296]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 5615 is [True, False, False, False, True, False]
Current timestep = 5616. State = [[-0.2763163   0.08059491]]. Action = [[0.08535156 0.01984652 0.         0.7367189 ]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 5616 is [True, False, False, False, True, False]
Current timestep = 5617. State = [[-0.27224967  0.08283904]]. Action = [[ 0.01541971  0.04498439  0.         -0.56604487]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 5617 is [True, False, False, False, True, False]
State prediction error at timestep 5617 is 0.012
Human Feedback received at timestep 5617 of None
Current timestep = 5618. State = [[-0.2749621  0.0832292]]. Action = [[-0.0909259  -0.01770899  0.          0.7317265 ]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 5618 is [True, False, False, False, True, False]
State prediction error at timestep 5618 is 0.012
Human Feedback received at timestep 5618 of None
Current timestep = 5619. State = [[-0.27759838  0.08667384]]. Action = [[-0.0188541   0.07086106  0.         -0.35160112]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 5619 is [True, False, False, False, True, False]
Current timestep = 5620. State = [[-0.2774211   0.09134798]]. Action = [[0.01519593 0.04266924 0.         0.72306335]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 5620 is [True, False, False, False, True, False]
Current timestep = 5621. State = [[-0.27358574  0.09123042]]. Action = [[ 0.07038655 -0.04023415  0.          0.94646764]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 5621 is [True, False, False, False, True, False]
Current timestep = 5622. State = [[-0.27476728  0.08891676]]. Action = [[-0.0772422  -0.03623302  0.          0.5209093 ]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 5622 is [True, False, False, False, True, False]
Current timestep = 5623. State = [[-0.2798475   0.08651814]]. Action = [[-0.07253487 -0.04186175  0.         -0.9562433 ]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 5623 is [True, False, False, False, True, False]
Current timestep = 5624. State = [[-0.27784923  0.08897378]]. Action = [[ 0.09180837  0.06782513  0.         -0.83453196]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 5624 is [True, False, False, False, True, False]
State prediction error at timestep 5624 is 0.012
Human Feedback received at timestep 5624 of None
Current timestep = 5625. State = [[-0.27969643  0.09393001]]. Action = [[-0.09987258  0.04983044  0.          0.1586113 ]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 5625 is [True, False, False, False, True, False]
State prediction error at timestep 5625 is 0.012
Human Feedback received at timestep 5625 of None
Current timestep = 5626. State = [[-0.2845963   0.09948215]]. Action = [[-0.0388426   0.06297886  0.          0.05239093]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 5626 is [True, False, False, False, True, False]
State prediction error at timestep 5626 is 0.012
Human Feedback received at timestep 5626 of None
Current timestep = 5627. State = [[-0.2873367  0.0976392]]. Action = [[-0.01951033 -0.09649564  0.         -0.8265681 ]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 5627 is [True, False, False, False, True, False]
Current timestep = 5628. State = [[-0.2850623   0.09635455]]. Action = [[0.06790545 0.01663896 0.         0.75514054]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 5628 is [True, False, False, False, True, False]
State prediction error at timestep 5628 is 0.012
Human Feedback received at timestep 5628 of None
Current timestep = 5629. State = [[-0.27917236  0.09509102]]. Action = [[ 0.08927377 -0.03276869  0.         -0.96462595]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 5629 is [True, False, False, False, True, False]
Current timestep = 5630. State = [[-0.27892414  0.09589868]]. Action = [[-0.04994213  0.03774985  0.          0.3173883 ]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 5630 is [True, False, False, False, True, False]
Current timestep = 5631. State = [[-0.2801701  0.0921139]]. Action = [[-0.00347494 -0.09980301  0.          0.58717036]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 5631 is [True, False, False, False, True, False]
Current timestep = 5632. State = [[-0.2768641   0.09061104]]. Action = [[ 0.0638482   0.03195263  0.         -0.46010262]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 5632 is [True, False, False, False, True, False]
State prediction error at timestep 5632 is 0.012
Human Feedback received at timestep 5632 of None
Current timestep = 5633. State = [[-0.27492487  0.09274033]]. Action = [[-0.00209887  0.03711843  0.         -0.15945631]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 5633 is [True, False, False, False, True, False]
Current timestep = 5634. State = [[-0.27423725  0.09092905]]. Action = [[ 0.00666972 -0.05297337  0.          0.98218524]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 5634 is [True, False, False, False, True, False]
Current timestep = 5635. State = [[-0.27037027  0.08721744]]. Action = [[ 0.06282898 -0.03597515  0.          0.713855  ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 5635 is [True, False, False, False, True, False]
Current timestep = 5636. State = [[-0.27016366  0.08096598]]. Action = [[-0.05328062 -0.09172502  0.          0.31613576]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 5636 is [True, False, False, False, True, False]
State prediction error at timestep 5636 is 0.012
Human Feedback received at timestep 5636 of None
Current timestep = 5637. State = [[-0.26878336  0.07803212]]. Action = [[ 0.03857902  0.00971754  0.         -0.79939276]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 5637 is [True, False, False, False, True, False]
Current timestep = 5638. State = [[-0.26810446  0.0798089 ]]. Action = [[-0.01969489  0.05093481  0.          0.7595954 ]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 5638 is [True, False, False, False, True, False]
Current timestep = 5639. State = [[-0.2667928   0.08066029]]. Action = [[0.0307154  0.00153236 0.         0.4798404 ]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 5639 is [True, False, False, False, True, False]
Current timestep = 5640. State = [[-0.26632294  0.08389549]]. Action = [[-0.00883369  0.07463156  0.         -0.33524126]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 5640 is [True, False, False, False, True, False]
Current timestep = 5641. State = [[-0.2694071   0.08662716]]. Action = [[-0.05490047  0.01442388  0.         -0.29608274]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 5641 is [True, False, False, False, True, False]
State prediction error at timestep 5641 is 0.012
Human Feedback received at timestep 5641 of None
Current timestep = 5642. State = [[-0.27096102  0.08645993]]. Action = [[ 0.00343778 -0.01878449  0.         -0.53858227]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 5642 is [True, False, False, False, True, False]
Current timestep = 5643. State = [[-0.27572125  0.08415778]]. Action = [[-0.09712605 -0.04378172  0.         -0.06213748]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 5643 is [True, False, False, False, True, False]
State prediction error at timestep 5643 is 0.012
Human Feedback received at timestep 5643 of None
Current timestep = 5644. State = [[-0.27698812  0.0863818 ]]. Action = [[ 0.04123207  0.06385785  0.         -0.79682904]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 5644 is [True, False, False, False, True, False]
Current timestep = 5645. State = [[-0.27292892  0.08621044]]. Action = [[ 0.07003007 -0.04368637  0.         -0.99219114]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 5645 is [True, False, False, False, True, False]
Current timestep = 5646. State = [[-0.26990175  0.08310886]]. Action = [[ 0.0189661  -0.03794659  0.          0.13297343]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 5646 is [True, False, False, False, True, False]
Current timestep = 5647. State = [[-0.2723794   0.07982904]]. Action = [[-0.07481799 -0.04294285  0.          0.22182453]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 5647 is [True, False, False, False, True, False]
Current timestep = 5648. State = [[-0.2726849   0.08029388]]. Action = [[0.02898348 0.03569976 0.         0.03493989]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 5648 is [True, False, False, False, True, False]
Current timestep = 5649. State = [[-0.27629778  0.08493684]]. Action = [[-0.0895585   0.07340413  0.         -0.49094045]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 5649 is [True, False, False, False, True, False]
Current timestep = 5650. State = [[-0.2766752   0.09100622]]. Action = [[ 0.05789457  0.07268334  0.         -0.1270656 ]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 5650 is [True, False, False, False, True, False]
State prediction error at timestep 5650 is 0.012
Human Feedback received at timestep 5650 of None
Current timestep = 5651. State = [[-0.27603164  0.09191858]]. Action = [[-0.00537721 -0.03420284  0.         -0.81480265]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 5651 is [True, False, False, False, True, False]
Current timestep = 5652. State = [[-0.27179196  0.09002807]]. Action = [[ 0.09293845 -0.02645468  0.         -0.02317983]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 5652 is [True, False, False, False, True, False]
Current timestep = 5653. State = [[-0.26624313  0.09345961]]. Action = [[ 0.06346806  0.08772776  0.         -0.72588724]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 5653 is [True, False, False, False, True, False]
State prediction error at timestep 5653 is 0.012
Human Feedback received at timestep 5653 of None
Current timestep = 5654. State = [[-0.26709697  0.09711366]]. Action = [[-0.0579362   0.01919772  0.         -0.23084891]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 5654 is [True, False, False, False, True, False]
Current timestep = 5655. State = [[-0.27081078  0.09933939]]. Action = [[-0.04187446  0.01828419  0.         -0.44131148]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 5655 is [True, False, False, False, True, False]
Current timestep = 5656. State = [[-0.27210405  0.09971629]]. Action = [[ 0.00302885 -0.01976701  0.          0.6434078 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 5656 is [True, False, False, False, True, False]
State prediction error at timestep 5656 is 0.012
Human Feedback received at timestep 5656 of None
Current timestep = 5657. State = [[-0.26784807  0.0993561 ]]. Action = [[ 0.08863602 -0.00695307  0.          0.2311337 ]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 5657 is [True, False, False, False, True, False]
Current timestep = 5658. State = [[-0.26239088  0.09652753]]. Action = [[ 0.0554801  -0.05447178  0.          0.55747724]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 5658 is [True, False, False, False, True, False]
Current timestep = 5659. State = [[-0.2591433   0.09660935]]. Action = [[ 0.01748075  0.03477287  0.         -0.7597113 ]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 5659 is [True, False, False, False, True, False]
Current timestep = 5660. State = [[-0.25485924  0.10037584]]. Action = [[0.06344768 0.0594897  0.         0.25561452]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 5660 is [True, False, False, False, True, False]
Current timestep = 5661. State = [[-0.2535336   0.10248777]]. Action = [[-0.02329237  0.00717775  0.         -0.84340084]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 5661 is [True, False, False, False, True, False]
State prediction error at timestep 5661 is 0.012
Human Feedback received at timestep 5661 of None
Current timestep = 5662. State = [[-0.25739536  0.10673188]]. Action = [[-0.08213362  0.07033291  0.          0.05924308]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 5662 is [True, False, False, False, True, False]
Current timestep = 5663. State = [[-0.25755468  0.10720338]]. Action = [[ 0.03483012 -0.04822052  0.          0.45281827]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 5663 is [True, False, False, False, True, False]
Current timestep = 5664. State = [[-0.25244904  0.11102809]]. Action = [[0.08107363 0.09366725 0.         0.7088654 ]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 5664 is [True, False, False, False, True, False]
Current timestep = 5665. State = [[-0.24709325  0.10925258]]. Action = [[ 0.05411937 -0.09698978  0.          0.99651897]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 5665 is [True, False, False, False, True, False]
Current timestep = 5666. State = [[-0.2445244   0.10315255]]. Action = [[-0.00574896 -0.07581034  0.         -0.69014215]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 5666 is [True, False, False, False, True, False]
State prediction error at timestep 5666 is 0.012
Human Feedback received at timestep 5666 of None
Current timestep = 5667. State = [[-0.23902841  0.10152656]]. Action = [[ 0.08571274  0.01442751  0.         -0.27643758]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 5667 is [True, False, False, False, True, False]
Current timestep = 5668. State = [[-0.23229527  0.09819277]]. Action = [[ 0.05531264 -0.06453333  0.         -0.31856596]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 5668 is [True, False, False, False, True, False]
Current timestep = 5669. State = [[-0.2311626   0.09839742]]. Action = [[-0.0491227   0.05122525  0.          0.3025434 ]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 5669 is [True, False, False, False, True, False]
Current timestep = 5670. State = [[-0.2283443  0.1028422]]. Action = [[0.05597641 0.06690942 0.         0.6500946 ]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 5670 is [True, False, False, False, True, False]
State prediction error at timestep 5670 is 0.012
Human Feedback received at timestep 5670 of None
Current timestep = 5671. State = [[-0.22581415  0.10500097]]. Action = [[-0.0016711   0.00663382  0.         -0.7555358 ]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 5671 is [True, False, False, False, True, False]
Current timestep = 5672. State = [[-0.22962748  0.10975392]]. Action = [[-0.09988155  0.08393953  0.          0.39274812]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 5672 is [True, False, False, False, True, False]
Current timestep = 5673. State = [[-0.23636092  0.10852363]]. Action = [[-0.09872749 -0.09609567  0.          0.12440693]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 5673 is [True, False, False, False, True, False]
Current timestep = 5674. State = [[-0.23910663  0.10355003]]. Action = [[-0.01515611 -0.06977493  0.         -0.8350783 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 5674 is [True, False, False, False, True, False]
State prediction error at timestep 5674 is 0.012
Human Feedback received at timestep 5674 of None
Current timestep = 5675. State = [[-0.23516218  0.10120907]]. Action = [[ 0.08494698 -0.01098698  0.          0.53653026]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 5675 is [True, False, False, False, True, False]
Current timestep = 5676. State = [[-0.2281021   0.10256008]]. Action = [[0.0938639  0.04273375 0.         0.915045  ]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 5676 is [True, False, False, False, True, False]
Current timestep = 5677. State = [[-0.22681768  0.10185038]]. Action = [[-0.04023672 -0.0322184   0.          0.7808955 ]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 5677 is [True, False, False, False, True, False]
Current timestep = 5678. State = [[-0.2257501   0.10543544]]. Action = [[0.04335963 0.09612446 0.         0.4054222 ]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 5678 is [True, False, False, False, True, False]
State prediction error at timestep 5678 is 0.012
Human Feedback received at timestep 5678 of None
Current timestep = 5679. State = [[-0.2269865   0.10860664]]. Action = [[-0.04301334  0.01206492  0.          0.7267802 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 5679 is [True, False, False, False, True, False]
Current timestep = 5680. State = [[-0.2284071   0.10987916]]. Action = [[ 5.8765709e-04  1.2207709e-02  0.0000000e+00 -7.1584839e-01]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 5680 is [True, False, False, False, True, False]
Current timestep = 5681. State = [[-0.2283693  0.1063934]]. Action = [[ 0.00534964 -0.08185051  0.          0.68797386]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 5681 is [True, False, False, False, True, False]
Current timestep = 5682. State = [[-0.22804345  0.1032903 ]]. Action = [[-4.7013909e-04 -1.6493186e-02  0.0000000e+00  7.8894448e-01]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 5682 is [True, False, False, False, True, False]
State prediction error at timestep 5682 is 0.012
Human Feedback received at timestep 5682 of None
Current timestep = 5683. State = [[-0.22577144  0.09932788]]. Action = [[ 0.04112629 -0.06394926  0.          0.04004717]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 5683 is [True, False, False, False, True, False]
State prediction error at timestep 5683 is 0.012
Human Feedback received at timestep 5683 of None
Current timestep = 5684. State = [[-0.22195584  0.09885911]]. Action = [[0.04723556 0.04032779 0.         0.4326501 ]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 5684 is [True, False, False, False, True, False]
Current timestep = 5685. State = [[-0.22157376  0.10268856]]. Action = [[-0.02264088  0.06829368  0.          0.33069992]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 5685 is [True, False, False, False, True, False]
State prediction error at timestep 5685 is 0.012
Human Feedback received at timestep 5685 of None
Current timestep = 5686. State = [[-0.22066031  0.1083902 ]]. Action = [[ 0.03483113  0.08040413  0.         -0.5716285 ]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 5686 is [True, False, False, False, True, False]
State prediction error at timestep 5686 is 0.012
Human Feedback received at timestep 5686 of None
Current timestep = 5687. State = [[-0.22005221  0.11471514]]. Action = [[0.00349049 0.07996839 0.         0.6550579 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 5687 is [True, False, False, False, True, False]
Current timestep = 5688. State = [[-0.21732813  0.12060875]]. Action = [[ 0.06611576  0.0648681   0.         -0.27125865]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 5688 is [True, False, False, False, True, False]
Current timestep = 5689. State = [[-0.21294193  0.11947968]]. Action = [[ 0.05849697 -0.07057109  0.          0.8300085 ]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 5689 is [True, False, False, False, True, False]
State prediction error at timestep 5689 is 0.012
Human Feedback received at timestep 5689 of None
Current timestep = 5690. State = [[-0.20898516  0.11425005]]. Action = [[ 0.03477324 -0.0756526   0.          0.6146023 ]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 5690 is [True, False, False, False, True, False]
Current timestep = 5691. State = [[-0.20508458  0.10878102]]. Action = [[ 0.03448344 -0.07025061  0.         -0.13786685]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 5691 is [True, False, False, False, True, False]
Current timestep = 5692. State = [[-0.20485127  0.10195284]]. Action = [[-0.05188748 -0.09727644  0.         -0.34719825]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 5692 is [True, False, False, False, True, False]
Current timestep = 5693. State = [[-0.2049317   0.09510241]]. Action = [[-0.01615077 -0.079015    0.         -0.5130371 ]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 5693 is [True, False, False, False, True, False]
Current timestep = 5694. State = [[-0.20243226  0.09442999]]. Action = [[ 0.02584042  0.04723505  0.         -0.13008732]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 5694 is [True, False, False, False, True, False]
Current timestep = 5695. State = [[-0.19892149  0.09896751]]. Action = [[0.03602875 0.08375447 0.         0.54590154]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 5695 is [True, False, False, False, True, False]
Current timestep = 5696. State = [[-0.19959345  0.10027485]]. Action = [[-0.05031864 -0.01237707  0.         -0.04456151]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 5696 is [True, False, False, False, True, False]
State prediction error at timestep 5696 is 0.012
Human Feedback received at timestep 5696 of None
Current timestep = 5697. State = [[-0.20249915  0.09833413]]. Action = [[-0.04554862 -0.03197391  0.         -0.7402612 ]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 5697 is [True, False, False, False, True, False]
Current timestep = 5698. State = [[-0.2073019   0.10173021]]. Action = [[-0.07758443  0.0852439   0.          0.8825537 ]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 5698 is [True, False, False, False, True, False]
Current timestep = 5699. State = [[-0.21104555  0.10017805]]. Action = [[-0.02778104 -0.08964231  0.         -0.8596179 ]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 5699 is [True, False, False, False, True, False]
State prediction error at timestep 5699 is 0.012
Human Feedback received at timestep 5699 of None
Current timestep = 5700. State = [[-0.20804723  0.09398202]]. Action = [[ 0.08288925 -0.07575993  0.         -0.26505744]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 5700 is [True, False, False, False, True, False]
Current timestep = 5701. State = [[-0.2033146  0.0951515]]. Action = [[ 0.0562103   0.08509482  0.         -0.58030397]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 5701 is [True, False, False, False, True, False]
Current timestep = 5702. State = [[-0.20418714  0.09736809]]. Action = [[-0.04609803  0.00672142  0.         -0.7465118 ]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 5702 is [True, False, False, False, True, False]
Current timestep = 5703. State = [[-0.20718525  0.10182508]]. Action = [[-0.02420721  0.08553275  0.         -0.34666568]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 5703 is [True, False, False, False, True, False]
Current timestep = 5704. State = [[-0.20437078  0.10380444]]. Action = [[ 0.09261014 -0.0099901   0.          0.9797988 ]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 5704 is [True, False, False, False, True, False]
Current timestep = 5705. State = [[-0.20666493  0.10414764]]. Action = [[-0.09302612  0.00798772  0.         -0.77173233]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 5705 is [True, False, False, False, True, False]
Current timestep = 5706. State = [[-0.21447359  0.10822565]]. Action = [[-0.08921567  0.06894562  0.          0.5942404 ]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 5706 is [True, False, False, False, True, False]
Current timestep = 5707. State = [[-0.21859913  0.11137132]]. Action = [[-0.00103259  0.00845882  0.         -0.8319098 ]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 5707 is [True, False, False, False, True, False]
Current timestep = 5708. State = [[-0.22066602  0.11004189]]. Action = [[-0.01137103 -0.0478228   0.          0.3921299 ]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 5708 is [True, False, False, False, True, False]
State prediction error at timestep 5708 is 0.012
Human Feedback received at timestep 5708 of None
Current timestep = 5709. State = [[-0.22508691  0.10509717]]. Action = [[-0.06596816 -0.08563861  0.         -0.8739407 ]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 5709 is [True, False, False, False, True, False]
Current timestep = 5710. State = [[-0.22456355  0.10126431]]. Action = [[ 0.06413507 -0.03180894  0.         -0.7592307 ]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 5710 is [True, False, False, False, True, False]
Current timestep = 5711. State = [[-0.22666202  0.0990195 ]]. Action = [[-0.07336903 -0.0225428   0.          0.92220426]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 5711 is [True, False, False, False, True, False]
Current timestep = 5712. State = [[-0.22465381  0.0939132 ]]. Action = [[ 0.08889633 -0.08167607  0.         -0.7636697 ]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 5712 is [True, False, False, False, True, False]
Current timestep = 5713. State = [[-0.22566551  0.09398968]]. Action = [[-0.0685995   0.06737641  0.         -0.13882428]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 5713 is [True, False, False, False, True, False]
State prediction error at timestep 5713 is 0.012
Human Feedback received at timestep 5713 of None
Current timestep = 5714. State = [[-0.22282048  0.09050087]]. Action = [[ 0.09996713 -0.09355901  0.         -0.63343716]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 5714 is [True, False, False, False, True, False]
Current timestep = 5715. State = [[-0.21716857  0.08930982]]. Action = [[0.06104485 0.05532112 0.         0.1144768 ]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 5715 is [True, False, False, False, True, False]
State prediction error at timestep 5715 is 0.012
Human Feedback received at timestep 5715 of None
Current timestep = 5716. State = [[-0.21119623  0.08643975]]. Action = [[ 0.08284905 -0.05855969  0.         -0.45148265]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 5716 is [True, False, False, False, True, False]
Current timestep = 5717. State = [[-0.20987102  0.07883251]]. Action = [[-0.03980744 -0.0940483   0.          0.97863805]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 5717 is [True, False, False, False, True, False]
State prediction error at timestep 5717 is 0.012
Human Feedback received at timestep 5717 of None
Current timestep = 5718. State = [[-0.21346739  0.0724763 ]]. Action = [[-0.0758277  -0.04886792  0.         -0.67966866]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 5718 is [True, False, False, False, True, False]
Current timestep = 5719. State = [[-0.2131514   0.07044797]]. Action = [[ 0.03648856  0.01548239  0.         -0.6756511 ]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 5719 is [True, False, False, False, True, False]
Current timestep = 5720. State = [[-0.2085077   0.07388866]]. Action = [[0.07094751 0.09112804 0.         0.88278675]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 5720 is [True, False, False, False, True, False]
State prediction error at timestep 5720 is 0.012
Human Feedback received at timestep 5720 of None
Current timestep = 5721. State = [[-0.20649363  0.0745912 ]]. Action = [[ 2.2678077e-04 -1.4809310e-02  0.0000000e+00 -9.2828375e-01]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 5721 is [True, False, False, False, True, False]
Current timestep = 5722. State = [[-0.20238502  0.07752191]]. Action = [[ 0.08303104  0.08372854  0.         -0.48068547]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 5722 is [True, False, False, False, True, False]
Current timestep = 5723. State = [[-0.19756988  0.07505309]]. Action = [[ 0.05063651 -0.08249057  0.         -0.81671554]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 5723 is [True, False, False, False, True, False]
Current timestep = 5724. State = [[-0.19162905  0.07619909]]. Action = [[0.08150586 0.08434532 0.         0.06942725]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 5724 is [True, False, False, False, True, False]
Current timestep = 5725. State = [[-0.19007997  0.08269669]]. Action = [[-0.02203736  0.09313395  0.          0.8577045 ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 5725 is [True, False, False, False, True, False]
Current timestep = 5726. State = [[-0.18707165  0.09033257]]. Action = [[0.07086691 0.09407308 0.         0.12263119]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 5726 is [True, False, False, False, True, False]
State prediction error at timestep 5726 is 0.012
Human Feedback received at timestep 5726 of None
Current timestep = 5727. State = [[-0.18544278  0.09472639]]. Action = [[-0.00797994  0.01977907  0.          0.68098915]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 5727 is [True, False, False, False, True, False]
Current timestep = 5728. State = [[-0.18144602  0.09812561]]. Action = [[ 0.07767879  0.03482533  0.         -0.5730064 ]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 5728 is [True, False, False, False, True, False]
State prediction error at timestep 5728 is 0.012
Human Feedback received at timestep 5728 of None
Current timestep = 5729. State = [[-0.17802382  0.10475513]]. Action = [[ 0.01822845  0.09071966  0.         -0.18275678]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 5729 is [True, False, False, False, True, False]
Current timestep = 5730. State = [[-0.1762385   0.10931698]]. Action = [[0.01484468 0.00867257 0.         0.600898  ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 5730 is [True, False, False, False, True, False]
Current timestep = 5731. State = [[-0.17065693  0.11531688]]. Action = [[ 0.09244811  0.08108265  0.         -0.18659759]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 5731 is [True, False, False, False, True, False]
State prediction error at timestep 5731 is 0.012
Human Feedback received at timestep 5731 of None
Current timestep = 5732. State = [[-0.16303183  0.12342819]]. Action = [[ 0.09072014  0.08699093  0.         -0.10503548]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 5732 is [True, False, False, False, True, False]
Current timestep = 5733. State = [[-0.16142613  0.12791401]]. Action = [[-0.0459629   0.00146841  0.          0.4124391 ]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 5733 is [True, False, False, False, True, False]
Current timestep = 5734. State = [[-0.16332866  0.1278977 ]]. Action = [[-0.0402512  -0.04914106  0.          0.4500258 ]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 5734 is [True, False, False, False, False, True]
State prediction error at timestep 5734 is 0.012
Human Feedback received at timestep 5734 of None
Current timestep = 5735. State = [[-0.15872504  0.13060445]]. Action = [[0.09948199 0.04410657 0.         0.306939  ]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 5735 is [True, False, False, False, False, True]
Current timestep = 5736. State = [[-0.15836968  0.1311094 ]]. Action = [[-0.09537055 -0.05581071  0.         -0.22485286]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 5736 is [True, False, False, False, False, True]
Current timestep = 5737. State = [[-0.1612955   0.13461104]]. Action = [[-0.03652025  0.06289621  0.          0.60648966]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 5737 is [True, False, False, False, False, True]
Current timestep = 5738. State = [[-0.16388921  0.13643433]]. Action = [[-0.04569129 -0.03455658  0.         -0.5728691 ]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 5738 is [True, False, False, False, False, True]
Current timestep = 5739. State = [[-0.16220365  0.14064722]]. Action = [[ 0.05320244  0.07388823  0.         -0.34943825]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 5739 is [True, False, False, False, False, True]
Current timestep = 5740. State = [[-0.15615834  0.14743206]]. Action = [[ 0.09250247  0.07510082  0.         -0.44298053]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 5740 is [True, False, False, False, False, True]
State prediction error at timestep 5740 is 0.012
Human Feedback received at timestep 5740 of None
Current timestep = 5741. State = [[-0.1528781   0.15171261]]. Action = [[ 0.00991489  0.02499084  0.         -0.09679818]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 5741 is [True, False, False, False, False, True]
Current timestep = 5742. State = [[-0.15619417  0.1495916 ]]. Action = [[-0.09481635 -0.08565903  0.         -0.98959476]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 5742 is [True, False, False, False, False, True]
Current timestep = 5743. State = [[-0.16025285  0.15097706]]. Action = [[-0.04254081  0.04961043  0.         -0.10208642]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 5743 is [True, False, False, False, False, True]
Current timestep = 5744. State = [[-0.1576396   0.15589759]]. Action = [[0.0860674  0.05436011 0.         0.0110718 ]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 5744 is [True, False, False, False, False, True]
Current timestep = 5745. State = [[-0.15745655  0.16038688]]. Action = [[-0.0414996   0.04190394  0.         -0.7436982 ]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 5745 is [True, False, False, False, False, True]
Current timestep = 5746. State = [[-0.15774861  0.16216378]]. Action = [[ 0.01867547 -0.00932734  0.         -0.86535656]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 5746 is [True, False, False, False, False, True]
Current timestep = 5747. State = [[-0.1590755   0.16495885]]. Action = [[-0.03364751  0.04244473  0.          0.5099014 ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 5747 is [True, False, False, False, False, True]
Current timestep = 5748. State = [[-0.15713783  0.166171  ]]. Action = [[ 0.06346902 -0.01704026  0.          0.9620149 ]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 5748 is [True, False, False, False, False, True]
Current timestep = 5749. State = [[-0.15118693  0.17082092]]. Action = [[0.09308466 0.09683112 0.         0.7657434 ]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 5749 is [True, False, False, False, False, True]
Current timestep = 5750. State = [[-0.14417243  0.17193726]]. Action = [[ 0.09329688 -0.03166216  0.          0.18022943]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 5750 is [True, False, False, False, False, True]
State prediction error at timestep 5750 is 0.012
Human Feedback received at timestep 5750 of None
Current timestep = 5751. State = [[-0.14372037  0.1753147 ]]. Action = [[-0.055072   0.0829558  0.         0.6645973]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 5751 is [True, False, False, False, False, True]
Current timestep = 5752. State = [[-0.14342678  0.18177655]]. Action = [[ 0.03047539  0.07138624  0.         -0.10214221]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 5752 is [True, False, False, False, False, True]
Current timestep = 5753. State = [[-0.14170456  0.18005207]]. Action = [[ 0.01155065 -0.09455398  0.         -0.42170596]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 5753 is [True, False, False, False, False, True]
State prediction error at timestep 5753 is 0.012
Human Feedback received at timestep 5753 of None
Current timestep = 5754. State = [[-0.14470814  0.17466229]]. Action = [[-0.09573626 -0.08014048  0.          0.18862414]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 5754 is [True, False, False, False, False, True]
Current timestep = 5755. State = [[-0.14414676  0.17436895]]. Action = [[0.04790645 0.02576566 0.         0.6446291 ]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 5755 is [True, False, False, False, False, True]
Current timestep = 5756. State = [[-0.14047143  0.17816344]]. Action = [[0.02695278 0.0509404  0.         0.84808016]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 5756 is [True, False, False, False, False, True]
Current timestep = 5757. State = [[-0.14090176  0.17700045]]. Action = [[-0.05233292 -0.07051391  0.          0.999372  ]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 5757 is [True, False, False, False, False, True]
Current timestep = 5758. State = [[-0.14281677  0.17808515]]. Action = [[-0.03434818  0.04289838  0.         -0.05805737]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 5758 is [True, False, False, False, False, True]
Current timestep = 5759. State = [[-0.14274989  0.18005112]]. Action = [[ 0.00964104  0.00099161  0.         -0.03389204]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 5759 is [True, False, False, False, False, True]
Current timestep = 5760. State = [[-0.14020537  0.1761975 ]]. Action = [[ 0.03505006 -0.08934429  0.         -0.14978772]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 5760 is [True, False, False, False, False, True]
State prediction error at timestep 5760 is 0.012
Human Feedback received at timestep 5760 of None
Current timestep = 5761. State = [[-0.13729616  0.17163141]]. Action = [[ 0.02068403 -0.04088844  0.         -0.1510424 ]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 5761 is [True, False, False, False, False, True]
Current timestep = 5762. State = [[-0.13669875  0.1699073 ]]. Action = [[-0.01955647 -0.00358572  0.         -0.09272975]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 5762 is [True, False, False, False, False, True]
Current timestep = 5763. State = [[-0.13196702  0.16711134]]. Action = [[ 0.09231559 -0.04216036  0.          0.13338232]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 5763 is [True, False, False, False, False, True]
State prediction error at timestep 5763 is 0.012
Human Feedback received at timestep 5763 of None
Current timestep = 5764. State = [[-0.1296422   0.16342781]]. Action = [[-0.02278615 -0.03052972  0.         -0.9988386 ]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 5764 is [True, False, False, False, False, True]
Current timestep = 5765. State = [[-0.13290381  0.16636042]]. Action = [[-0.07132746  0.09233581  0.          0.29802978]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 5765 is [True, False, False, False, False, True]
Current timestep = 5766. State = [[-0.13290428  0.16794161]]. Action = [[ 0.03913511 -0.01344264  0.         -0.4871223 ]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 5766 is [True, False, False, False, False, True]
Current timestep = 5767. State = [[-0.13424     0.16465507]]. Action = [[-0.05125606 -0.05509269  0.         -0.17290598]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 5767 is [True, False, False, False, False, True]
State prediction error at timestep 5767 is 0.012
Human Feedback received at timestep 5767 of None
Current timestep = 5768. State = [[-0.13900347  0.16119601]]. Action = [[-0.07476757 -0.03707879  0.         -0.3797233 ]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 5768 is [True, False, False, False, False, True]
Current timestep = 5769. State = [[-0.14435567  0.16410424]]. Action = [[-0.06208017  0.07893442  0.          0.5668771 ]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 5769 is [True, False, False, False, False, True]
Current timestep = 5770. State = [[-0.15142107  0.16946617]]. Action = [[-0.08673775  0.05511019  0.          0.14760959]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 5770 is [True, False, False, False, False, True]
Current timestep = 5771. State = [[-0.15873295  0.17377217]]. Action = [[-0.06777254  0.03528301  0.          0.9218898 ]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 5771 is [True, False, False, False, False, True]
State prediction error at timestep 5771 is 0.012
Human Feedback received at timestep 5771 of None
Current timestep = 5772. State = [[-0.1671982  0.1769192]]. Action = [[-0.09421153  0.01864158  0.         -0.06350052]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 5772 is [True, False, False, False, False, True]
Current timestep = 5773. State = [[-0.17072074  0.18040264]]. Action = [[0.03146974 0.03692809 0.         0.9816297 ]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 5773 is [True, False, False, False, False, True]
State prediction error at timestep 5773 is 0.012
Human Feedback received at timestep 5773 of None
Current timestep = 5774. State = [[-0.17131223  0.17957063]]. Action = [[ 0.01818997 -0.05301193  0.         -0.64901084]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 5774 is [True, False, False, False, False, True]
Current timestep = 5775. State = [[-0.17430867  0.17967287]]. Action = [[-0.03712293  0.02200605  0.         -0.38683522]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 5775 is [True, False, False, False, False, True]
State prediction error at timestep 5775 is 0.012
Human Feedback received at timestep 5775 of None
Current timestep = 5776. State = [[-0.17670123  0.17575166]]. Action = [[ 0.00190105 -0.09904641  0.          0.6400001 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 5776 is [True, False, False, False, False, True]
Current timestep = 5777. State = [[-0.17956251  0.1746731 ]]. Action = [[-0.03612459  0.03318477  0.          0.2599492 ]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 5777 is [True, False, False, False, False, True]
State prediction error at timestep 5777 is 0.012
Human Feedback received at timestep 5777 of None
Current timestep = 5778. State = [[-0.18489909  0.17539527]]. Action = [[-0.06276075 -0.00362304  0.          0.67390347]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 5778 is [True, False, False, False, False, True]
State prediction error at timestep 5778 is 0.012
Human Feedback received at timestep 5778 of None
Current timestep = 5779. State = [[-0.18509574  0.17263232]]. Action = [[ 0.05647225 -0.05436791  0.         -0.9633904 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 5779 is [True, False, False, False, False, True]
Current timestep = 5780. State = [[-0.18491814  0.17118178]]. Action = [[-0.00838608  0.01320569  0.          0.13309133]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 5780 is [True, False, False, False, False, True]
Current timestep = 5781. State = [[-0.18456902  0.17238548]]. Action = [[0.02887806 0.03212915 0.         0.6543095 ]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 5781 is [True, False, False, False, False, True]
Current timestep = 5782. State = [[-0.18199478  0.17460333]]. Action = [[0.05674209 0.04414328 0.         0.54780185]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 5782 is [True, False, False, False, False, True]
Current timestep = 5783. State = [[-0.18492     0.17128654]]. Action = [[-0.08964466 -0.08617909  0.          0.7592653 ]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 5783 is [True, False, False, False, False, True]
State prediction error at timestep 5783 is 0.012
Human Feedback received at timestep 5783 of None
Current timestep = 5784. State = [[-0.19042966  0.17297055]]. Action = [[-0.0397575   0.09198763  0.         -0.42841542]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 5784 is [True, False, False, False, False, True]
Current timestep = 5785. State = [[-0.19258182  0.17930005]]. Action = [[0.01818161 0.08673974 0.         0.7994971 ]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 5785 is [True, False, False, False, False, True]
State prediction error at timestep 5785 is 0.012
Human Feedback received at timestep 5785 of None
Current timestep = 5786. State = [[-0.19215626  0.18521287]]. Action = [[ 0.0413154   0.07573121  0.         -0.003474  ]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 5786 is [True, False, False, False, False, True]
Current timestep = 5787. State = [[-0.19502226  0.1900318 ]]. Action = [[-0.0440376   0.05359542  0.          0.02422452]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 5787 is [True, False, False, False, False, True]
Current timestep = 5788. State = [[-0.20271999  0.19464482]]. Action = [[-0.0978009   0.04727843  0.          0.67036307]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 5788 is [True, False, False, False, False, True]
Current timestep = 5789. State = [[-0.21217842  0.2005548 ]]. Action = [[-0.09866182  0.06311639  0.         -0.9491424 ]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 5789 is [True, False, False, False, False, True]
Current timestep = 5790. State = [[-0.21879944  0.20443827]]. Action = [[-0.03373576  0.0054674   0.         -0.32903194]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 5790 is [True, False, False, False, False, True]
State prediction error at timestep 5790 is 0.012
Human Feedback received at timestep 5790 of None
Current timestep = 5791. State = [[-0.2188975   0.20970492]]. Action = [[0.06617861 0.07215566 0.         0.41193593]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 5791 is [True, False, False, False, False, True]
Current timestep = 5792. State = [[-0.21933731  0.21390429]]. Action = [[-0.00672825  0.01842266  0.          0.22271562]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 5792 is [True, False, False, False, False, True]
Current timestep = 5793. State = [[-0.21740915  0.21661209]]. Action = [[ 0.07063555  0.01730685  0.         -0.4788735 ]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 5793 is [True, False, False, False, False, True]
Current timestep = 5794. State = [[-0.21912573  0.22296073]]. Action = [[-0.05178307  0.09649359  0.          0.61356044]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 5794 is [True, False, False, False, False, True]
State prediction error at timestep 5794 is 0.012
Human Feedback received at timestep 5794 of None
Current timestep = 5795. State = [[-0.22219868  0.2259429 ]]. Action = [[-0.01322123 -0.02558934  0.         -0.70867026]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 5795 is [True, False, False, False, False, True]
Current timestep = 5796. State = [[-0.22268996  0.22350544]]. Action = [[ 0.00845088 -0.07101591  0.          0.36952758]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 5796 is [True, False, False, False, False, True]
Current timestep = 5797. State = [[-0.22428387  0.21908833]]. Action = [[-0.04114787 -0.07985402  0.         -0.47610188]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 5797 is [True, False, False, False, False, True]
Current timestep = 5798. State = [[-0.22487764  0.21316777]]. Action = [[-0.0023164  -0.09954225  0.          0.9174216 ]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 5798 is [True, False, False, False, False, True]
Current timestep = 5799. State = [[-0.2233442   0.20834658]]. Action = [[ 0.01464142 -0.05129898  0.         -0.5750655 ]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 5799 is [True, False, False, False, False, True]
Current timestep = 5800. State = [[-0.22652918  0.20999819]]. Action = [[-0.08864722  0.06400903  0.          0.4031248 ]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 5800 is [True, False, False, False, False, True]
Current timestep = 5801. State = [[-0.23272556  0.2169206 ]]. Action = [[-0.07298436  0.09947138  0.         -0.40774977]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 5801 is [True, False, False, False, False, True]
Current timestep = 5802. State = [[-0.23300122  0.21870552]]. Action = [[ 0.05461626 -0.0283434   0.          0.40793455]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 5802 is [True, False, False, False, False, True]
Current timestep = 5803. State = [[-0.22996207  0.21352445]]. Action = [[ 0.04086345 -0.08742823  0.          0.11057448]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 5803 is [True, False, False, False, False, True]
Current timestep = 5804. State = [[-0.22447897  0.21240622]]. Action = [[ 0.08938234  0.04379442  0.         -0.5155659 ]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 5804 is [True, False, False, False, False, True]
State prediction error at timestep 5804 is 0.012
Human Feedback received at timestep 5804 of None
Current timestep = 5805. State = [[-0.21864934  0.21618846]]. Action = [[0.06939033 0.08005922 0.         0.95594287]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 5805 is [True, False, False, False, False, True]
Current timestep = 5806. State = [[-0.21766636  0.21340716]]. Action = [[-0.03455249 -0.0910152   0.         -0.16894239]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 5806 is [True, False, False, False, False, True]
Current timestep = 5807. State = [[-0.21983902  0.21477786]]. Action = [[-0.02414102  0.09302463  0.          0.9888654 ]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 5807 is [True, False, False, False, False, True]
State prediction error at timestep 5807 is 0.012
Human Feedback received at timestep 5807 of None
Current timestep = 5808. State = [[-0.22389302  0.21599805]]. Action = [[-0.05704796 -0.01724402  0.          0.79215693]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 5808 is [True, False, False, False, False, True]
Current timestep = 5809. State = [[-0.23060419  0.21253926]]. Action = [[-0.09672689 -0.06781641  0.         -0.5512389 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 5809 is [True, False, False, False, False, True]
Current timestep = 5810. State = [[-0.23222832  0.20730616]]. Action = [[ 0.02937869 -0.07414947  0.         -0.45937824]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 5810 is [True, False, False, False, False, True]
Current timestep = 5811. State = [[-0.23483908  0.20090975]]. Action = [[-0.06598104 -0.08499288  0.          0.99184203]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 5811 is [True, False, False, False, False, True]
State prediction error at timestep 5811 is 0.012
Human Feedback received at timestep 5811 of None
Current timestep = 5812. State = [[-0.23614429  0.19536631]]. Action = [[ 0.01091702 -0.05812076  0.         -0.16508448]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 5812 is [True, False, False, False, False, True]
Current timestep = 5813. State = [[-0.23261316  0.19012988]]. Action = [[ 0.06827088 -0.05218498  0.         -0.5253386 ]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 5813 is [True, False, False, False, False, True]
Current timestep = 5814. State = [[-0.22829856  0.18282336]]. Action = [[ 0.04441024 -0.08543433  0.         -0.26092422]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 5814 is [True, False, False, False, False, True]
Current timestep = 5815. State = [[-0.22835483  0.18002991]]. Action = [[-0.03614401  0.02908096  0.         -0.7646714 ]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 5815 is [True, False, False, False, False, True]
Current timestep = 5816. State = [[-0.23019987  0.18056703]]. Action = [[-0.0172113  0.0283391  0.         0.5156038]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 5816 is [True, False, False, False, False, True]
Current timestep = 5817. State = [[-0.2279102   0.18460405]]. Action = [[0.06996179 0.09937855 0.         0.61216664]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 5817 is [True, False, False, False, False, True]
Current timestep = 5818. State = [[-0.22421427  0.18595114]]. Action = [[ 0.05102604  0.00429765  0.         -0.65625894]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 5818 is [True, False, False, False, False, True]
Current timestep = 5819. State = [[-0.22113743  0.18729432]]. Action = [[ 0.0403248   0.05060025  0.         -0.78709394]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 5819 is [True, False, False, False, False, True]
Current timestep = 5820. State = [[-0.21792363  0.1888746 ]]. Action = [[ 0.04695351  0.02608242  0.         -0.73251283]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 5820 is [True, False, False, False, False, True]
Current timestep = 5821. State = [[-0.21877627  0.19177347]]. Action = [[-0.04274799  0.05642604  0.         -0.6516523 ]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 5821 is [True, False, False, False, False, True]
State prediction error at timestep 5821 is 0.012
Human Feedback received at timestep 5821 of None
Current timestep = 5822. State = [[-0.22053857  0.19404538]]. Action = [[-0.00922725  0.01273234  0.          0.74686635]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 5822 is [True, False, False, False, False, True]
Current timestep = 5823. State = [[-0.22206791  0.19173515]]. Action = [[-0.02554426 -0.06578163  0.          0.04444635]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 5823 is [True, False, False, False, False, True]
Current timestep = 5824. State = [[-0.21997786  0.19055828]]. Action = [[ 0.05123184  0.00214402  0.         -0.05677301]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 5824 is [True, False, False, False, False, True]
Current timestep = 5825. State = [[-0.21757258  0.19131698]]. Action = [[ 0.01157598  0.01000649  0.         -0.10235322]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 5825 is [True, False, False, False, False, True]
Current timestep = 5826. State = [[-0.21231982  0.189998  ]]. Action = [[ 0.08716818 -0.03538565  0.         -0.2766558 ]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 5826 is [True, False, False, False, False, True]
State prediction error at timestep 5826 is 0.012
Human Feedback received at timestep 5826 of None
Current timestep = 5827. State = [[-0.20605752  0.1889909 ]]. Action = [[ 0.05864478  0.00432366  0.         -0.52628696]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 5827 is [True, False, False, False, False, True]
Current timestep = 5828. State = [[-0.20756252  0.19113831]]. Action = [[-0.0901454   0.04195371  0.          0.9404167 ]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 5828 is [True, False, False, False, False, True]
State prediction error at timestep 5828 is 0.012
Human Feedback received at timestep 5828 of None
Current timestep = 5829. State = [[-0.21124999  0.19767256]]. Action = [[-0.03683387  0.09720778  0.          0.11968851]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 5829 is [True, False, False, False, False, True]
Current timestep = 5830. State = [[-0.21289867  0.19934797]]. Action = [[-0.01014724 -0.03845386  0.          0.6018727 ]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 5830 is [True, False, False, False, False, True]
Current timestep = 5831. State = [[-0.2088081   0.20303379]]. Action = [[ 0.09500059  0.08495095  0.         -0.7785927 ]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 5831 is [True, False, False, False, False, True]
Current timestep = 5832. State = [[-0.20954955  0.20806387]]. Action = [[-0.07627213  0.03790284  0.          0.54797864]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 5832 is [True, False, False, False, False, True]
Current timestep = 5833. State = [[-0.21526594  0.21166524]]. Action = [[-0.07074322  0.02345057  0.          0.40602303]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 5833 is [True, False, False, False, False, True]
Current timestep = 5834. State = [[-0.2214423   0.21778485]]. Action = [[-0.06955338  0.07668967  0.          0.26350367]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 5834 is [True, False, False, False, False, True]
Current timestep = 5835. State = [[-0.2260156   0.22405002]]. Action = [[-0.02628156  0.04686741  0.          0.03211844]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 5835 is [True, False, False, False, False, True]
Current timestep = 5836. State = [[-0.2304635   0.22378811]]. Action = [[-0.04974935 -0.07312646  0.         -0.5482179 ]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 5836 is [True, False, False, False, False, True]
Current timestep = 5837. State = [[-0.23421638  0.22746207]]. Action = [[-0.02430034  0.07800557  0.          0.2561636 ]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 5837 is [True, False, False, False, False, True]
Current timestep = 5838. State = [[-0.23975125  0.2281119 ]]. Action = [[-0.07340674 -0.06703506  0.         -0.43905115]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 5838 is [True, False, False, False, False, True]
Current timestep = 5839. State = [[-0.24726446  0.23168288]]. Action = [[-0.08260141  0.07314446  0.         -0.818925  ]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 5839 is [True, False, False, False, False, True]
Current timestep = 5840. State = [[-0.24919504  0.23679708]]. Action = [[0.05013964 0.03656042 0.         0.9545407 ]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 5840 is [True, False, False, False, False, True]
State prediction error at timestep 5840 is 0.012
Human Feedback received at timestep 5840 of None
Current timestep = 5841. State = [[-0.2545136   0.23992616]]. Action = [[-0.09835821  0.01810758  0.         -0.09784931]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 5841 is [True, False, False, False, False, True]
Current timestep = 5842. State = [[-0.2594612   0.23904325]]. Action = [[-0.00827423 -0.05345133  0.          0.13582695]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 5842 is [True, False, False, False, False, True]
State prediction error at timestep 5842 is 0.012
Human Feedback received at timestep 5842 of None
Current timestep = 5843. State = [[-0.26203755  0.23799737]]. Action = [[-0.01344616 -0.00849853  0.          0.610306  ]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 5843 is [True, False, False, False, False, True]
Current timestep = 5844. State = [[-0.2640192   0.23809819]]. Action = [[-0.00398049 -0.00131562  0.         -0.3094011 ]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 5844 is [True, False, False, False, False, True]
Current timestep = 5845. State = [[-0.26525646  0.24296255]]. Action = [[0.00641774 0.0987862  0.         0.36309075]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 5845 is [True, False, False, False, False, True]
Current timestep = 5846. State = [[-0.26242647  0.24186115]]. Action = [[ 0.08172735 -0.07339825  0.          0.8198776 ]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 5846 is [True, False, False, False, False, True]
Current timestep = 5847. State = [[-0.2626139   0.23604102]]. Action = [[-0.04270717 -0.07483618  0.         -0.9801196 ]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 5847 is [True, False, False, False, False, True]
State prediction error at timestep 5847 is 0.012
Human Feedback received at timestep 5847 of None
Current timestep = 5848. State = [[-0.26333925  0.23793535]]. Action = [[ 0.01723625  0.09077325  0.         -0.89438915]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 5848 is [True, False, False, False, False, True]
Current timestep = 5849. State = [[-0.26472536  0.23763461]]. Action = [[-0.03344098 -0.05274528  0.         -0.6357687 ]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 5849 is [True, False, False, False, False, True]
Current timestep = 5850. State = [[-0.26851174  0.2326209 ]]. Action = [[-0.05831808 -0.0777991   0.          0.98243344]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 5850 is [True, False, False, False, False, True]
State prediction error at timestep 5850 is 0.012
Human Feedback received at timestep 5850 of None
Current timestep = 5851. State = [[-0.27459246  0.22853447]]. Action = [[-0.08996035 -0.04518581  0.          0.12975025]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 5851 is [True, False, False, False, False, True]
Current timestep = 5852. State = [[-0.28258702  0.23200186]]. Action = [[-0.097017    0.09277489  0.          0.44874752]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 5852 is [True, False, False, False, False, True]
Current timestep = 5853. State = [[-0.28758883  0.23382567]]. Action = [[-0.01452194 -0.01781971  0.          0.53057134]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 5853 is [True, False, False, False, False, True]
Current timestep = 5854. State = [[-0.28561106  0.22950175]]. Action = [[ 0.0781415  -0.07527803  0.          0.30364192]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 5854 is [True, False, False, False, False, True]
Current timestep = 5855. State = [[-0.2888112   0.22279404]]. Action = [[-0.09592693 -0.08545515  0.         -0.1573782 ]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 5855 is [True, False, False, False, False, True]
Current timestep = 5856. State = [[-0.28788757  0.21619275]]. Action = [[ 0.0913165  -0.06835667  0.          0.9524646 ]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 5856 is [True, False, False, False, False, True]
Current timestep = 5857. State = [[-0.28388536  0.20804523]]. Action = [[ 0.03558438 -0.09756432  0.          0.29156482]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 5857 is [True, False, False, False, False, True]
Current timestep = 5858. State = [[-0.28068456  0.20033292]]. Action = [[ 0.03534403 -0.06724592  0.          0.37026417]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 5858 is [True, False, False, False, False, True]
State prediction error at timestep 5858 is 0.012
Human Feedback received at timestep 5858 of None
Current timestep = 5859. State = [[-0.2744461   0.19351196]]. Action = [[ 0.09331473 -0.05559432  0.         -0.6313703 ]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 5859 is [True, False, False, False, False, True]
State prediction error at timestep 5859 is 0.012
Human Feedback received at timestep 5859 of None
Current timestep = 5860. State = [[-0.2669049   0.18871222]]. Action = [[ 0.08248194 -0.00919095  0.          0.5876391 ]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 5860 is [True, False, False, False, False, True]
State prediction error at timestep 5860 is 0.012
Human Feedback received at timestep 5860 of None
Current timestep = 5861. State = [[-0.25887614  0.1882869 ]]. Action = [[0.09691342 0.06118556 0.         0.2641499 ]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 5861 is [True, False, False, False, False, True]
Current timestep = 5862. State = [[-0.25059885  0.18887502]]. Action = [[0.09416307 0.04297688 0.         0.9068384 ]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 5862 is [True, False, False, False, False, True]
State prediction error at timestep 5862 is 0.012
Human Feedback received at timestep 5862 of None
Current timestep = 5863. State = [[-0.24535808  0.18438789]]. Action = [[ 0.02424055 -0.06234056  0.         -0.5828015 ]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 5863 is [True, False, False, False, False, True]
Current timestep = 5864. State = [[-0.24705459  0.18320301]]. Action = [[-0.07939241  0.05119307  0.         -0.543101  ]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 5864 is [True, False, False, False, False, True]
State prediction error at timestep 5864 is 0.012
Human Feedback received at timestep 5864 of None
Current timestep = 5865. State = [[-0.24520355  0.18366037]]. Action = [[0.06364577 0.01036315 0.         0.5468085 ]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 5865 is [True, False, False, False, False, True]
Current timestep = 5866. State = [[-0.2386458   0.18228978]]. Action = [[ 0.0823172  -0.00522567  0.          0.24170244]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 5866 is [True, False, False, False, False, True]
State prediction error at timestep 5866 is 0.012
Human Feedback received at timestep 5866 of None
Current timestep = 5867. State = [[-0.23152635  0.1780757 ]]. Action = [[ 0.07245182 -0.05469275  0.         -0.20864874]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 5867 is [True, False, False, False, False, True]
Current timestep = 5868. State = [[-0.22492144  0.17657357]]. Action = [[ 0.06046062  0.02645764  0.         -0.8964389 ]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 5868 is [True, False, False, False, False, True]
Current timestep = 5869. State = [[-0.21799691  0.17831953]]. Action = [[0.07435285 0.04524808 0.         0.3892305 ]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 5869 is [True, False, False, False, False, True]
Current timestep = 5870. State = [[-0.21363612  0.17902355]]. Action = [[ 0.013482    0.00486274  0.         -0.18816644]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 5870 is [True, False, False, False, False, True]
Current timestep = 5871. State = [[-0.21527527  0.1824403 ]]. Action = [[-0.07590326  0.06739549  0.          0.13974023]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 5871 is [True, False, False, False, False, True]
State prediction error at timestep 5871 is 0.012
Human Feedback received at timestep 5871 of None
Current timestep = 5872. State = [[-0.21721636  0.18034944]]. Action = [[-0.02612188 -0.09632383  0.         -0.9657287 ]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 5872 is [True, False, False, False, False, True]
Current timestep = 5873. State = [[-0.21764107  0.17626946]]. Action = [[-0.02371957 -0.04798994  0.         -0.5832667 ]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 5873 is [True, False, False, False, False, True]
Current timestep = 5874. State = [[-0.21741551  0.17570561]]. Action = [[-0.00778177  0.00434013  0.         -0.3670655 ]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 5874 is [True, False, False, False, False, True]
Current timestep = 5875. State = [[-0.22050145  0.17827275]]. Action = [[-0.07541993  0.03651296  0.          0.5771755 ]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 5875 is [True, False, False, False, False, True]
Current timestep = 5876. State = [[-0.21855368  0.17980562]]. Action = [[ 0.07798479 -0.00361204  0.         -0.8552545 ]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 5876 is [True, False, False, False, False, True]
State prediction error at timestep 5876 is 0.012
Human Feedback received at timestep 5876 of None
Current timestep = 5877. State = [[-0.21643247  0.18331258]]. Action = [[-0.00261506  0.06667309  0.          0.7706251 ]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 5877 is [True, False, False, False, False, True]
Current timestep = 5878. State = [[-0.22033654  0.18574856]]. Action = [[-0.08136358 -0.00183312  0.          0.14042544]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 5878 is [True, False, False, False, False, True]
Current timestep = 5879. State = [[-0.22445805  0.18323168]]. Action = [[-0.03709769 -0.07289241  0.         -0.09934217]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 5879 is [True, False, False, False, False, True]
State prediction error at timestep 5879 is 0.012
Human Feedback received at timestep 5879 of None
Current timestep = 5880. State = [[-0.22711843  0.18031894]]. Action = [[-0.03118171 -0.03512967  0.          0.91822135]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 5880 is [True, False, False, False, False, True]
Current timestep = 5881. State = [[-0.22702143  0.18339695]]. Action = [[0.02912144 0.0770172  0.         0.98317885]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 5881 is [True, False, False, False, False, True]
Current timestep = 5882. State = [[-0.22857146  0.184136  ]]. Action = [[-0.03612008 -0.03310423  0.         -0.9475499 ]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 5882 is [True, False, False, False, False, True]
Current timestep = 5883. State = [[-0.2293603   0.18429257]]. Action = [[ 0.01444618  0.0155886   0.         -0.35476303]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 5883 is [True, False, False, False, False, True]
Current timestep = 5884. State = [[-0.2338153   0.18110847]]. Action = [[-0.09167672 -0.07875843  0.          0.06715   ]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 5884 is [True, False, False, False, False, True]
Current timestep = 5885. State = [[-0.24051139  0.18077286]]. Action = [[-0.06990651  0.03172391  0.          0.5048257 ]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 5885 is [True, False, False, False, False, True]
Current timestep = 5886. State = [[-0.24645966  0.17876565]]. Action = [[-0.05513147 -0.06149825  0.         -0.6954043 ]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 5886 is [True, False, False, False, False, True]
Current timestep = 5887. State = [[-0.24574569  0.17305633]]. Action = [[ 0.07017217 -0.07794599  0.          0.1863432 ]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 5887 is [True, False, False, False, False, True]
Current timestep = 5888. State = [[-0.24325633  0.16501884]]. Action = [[ 0.02534688 -0.09803524  0.         -0.7776703 ]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 5888 is [True, False, False, False, False, True]
Current timestep = 5889. State = [[-0.23797649  0.15842137]]. Action = [[ 0.09536137 -0.04555562  0.          0.03565001]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 5889 is [True, False, False, False, False, True]
State prediction error at timestep 5889 is 0.012
Human Feedback received at timestep 5889 of None
Current timestep = 5890. State = [[-0.23545788  0.15712981]]. Action = [[-0.00241243  0.04359312  0.          0.88803554]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 5890 is [True, False, False, False, False, True]
Current timestep = 5891. State = [[-0.23671998  0.15972796]]. Action = [[-0.02084356  0.0655246   0.         -0.48042417]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 5891 is [True, False, False, False, False, True]
Current timestep = 5892. State = [[-0.23619072  0.16448878]]. Action = [[ 0.03686119  0.08943137  0.         -0.8537982 ]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 5892 is [True, False, False, False, False, True]
Current timestep = 5893. State = [[-0.23101671  0.1627326 ]]. Action = [[ 0.09949332 -0.05836747  0.         -0.12162107]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 5893 is [True, False, False, False, False, True]
Current timestep = 5894. State = [[-0.22466062  0.16033563]]. Action = [[0.07373067 0.01417986 0.         0.2075721 ]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 5894 is [True, False, False, False, False, True]
Current timestep = 5895. State = [[-0.22221616  0.156836  ]]. Action = [[-0.00372161 -0.05211625  0.         -0.76462734]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 5895 is [True, False, False, False, False, True]
Current timestep = 5896. State = [[-0.22074744  0.15409045]]. Action = [[ 0.0151334  -0.00811122  0.          0.46764314]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 5896 is [True, False, False, False, False, True]
State prediction error at timestep 5896 is 0.012
Human Feedback received at timestep 5896 of None
Current timestep = 5897. State = [[-0.22103176  0.15738733]]. Action = [[-0.0272438   0.08711278  0.         -0.23831809]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 5897 is [True, False, False, False, False, True]
Current timestep = 5898. State = [[-0.21997395  0.15851308]]. Action = [[ 0.02903823 -0.02003673  0.         -0.57023144]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 5898 is [True, False, False, False, False, True]
Current timestep = 5899. State = [[-0.2174609   0.16217075]]. Action = [[ 0.02732206  0.08871397  0.         -0.6820269 ]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 5899 is [True, False, False, False, False, True]
Current timestep = 5900. State = [[-0.21508287  0.16582105]]. Action = [[0.02819578 0.02505558 0.         0.3223424 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 5900 is [True, False, False, False, False, True]
Current timestep = 5901. State = [[-0.20902814  0.16228873]]. Action = [[ 0.0958994  -0.08980777  0.          0.4851334 ]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 5901 is [True, False, False, False, False, True]
Current timestep = 5902. State = [[-0.20920733  0.1639377 ]]. Action = [[-0.07792486  0.08600395  0.         -0.9103391 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 5902 is [True, False, False, False, False, True]
State prediction error at timestep 5902 is 0.012
Human Feedback received at timestep 5902 of None
Current timestep = 5903. State = [[-0.2092568   0.17052107]]. Action = [[ 0.03205841  0.07124516  0.         -0.46149158]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 5903 is [True, False, False, False, False, True]
State prediction error at timestep 5903 is 0.012
Human Feedback received at timestep 5903 of None
Current timestep = 5904. State = [[-0.21098366  0.17707232]]. Action = [[-0.05353112  0.0696492   0.          0.11746407]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 5904 is [True, False, False, False, False, True]
Current timestep = 5905. State = [[-0.2161038   0.18463781]]. Action = [[-0.07030071  0.08023205  0.          0.6891054 ]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 5905 is [True, False, False, False, False, True]
Current timestep = 5906. State = [[-0.21737279  0.1877306 ]]. Action = [[ 0.02530333 -0.02323369  0.         -0.68198025]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 5906 is [True, False, False, False, False, True]
State prediction error at timestep 5906 is 0.012
Human Feedback received at timestep 5906 of None
Current timestep = 5907. State = [[-0.21832475  0.1869621 ]]. Action = [[-0.02823883 -0.0420545   0.         -0.220878  ]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 5907 is [True, False, False, False, False, True]
Current timestep = 5908. State = [[-0.2156884   0.18954428]]. Action = [[0.07382693 0.0464559  0.         0.24631166]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 5908 is [True, False, False, False, False, True]
Current timestep = 5909. State = [[-0.2170233   0.19651829]]. Action = [[-0.06602868  0.08882617  0.         -0.75749236]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 5909 is [True, False, False, False, False, True]
State prediction error at timestep 5909 is 0.012
Human Feedback received at timestep 5909 of None
Current timestep = 5910. State = [[-0.21712914  0.19712149]]. Action = [[ 0.03681063 -0.07316671  0.          0.93427444]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 5910 is [True, False, False, False, False, True]
Current timestep = 5911. State = [[-0.21629915  0.19980597]]. Action = [[-0.00570119  0.06812745  0.          0.08460617]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 5911 is [True, False, False, False, False, True]
Current timestep = 5912. State = [[-0.21621615  0.20753063]]. Action = [[0.00981345 0.09670717 0.         0.6538389 ]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 5912 is [True, False, False, False, False, True]
Current timestep = 5913. State = [[-0.2200396   0.20869635]]. Action = [[-0.08306005 -0.06546352  0.          0.8187156 ]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 5913 is [True, False, False, False, False, True]
State prediction error at timestep 5913 is 0.012
Human Feedback received at timestep 5913 of None
Current timestep = 5914. State = [[-0.22192416  0.20698036]]. Action = [[ 0.01429732 -0.0299857   0.          0.6488359 ]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 5914 is [True, False, False, False, False, True]
Current timestep = 5915. State = [[-0.22625357  0.20435527]]. Action = [[-0.09129804 -0.05881823  0.          0.45185912]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 5915 is [True, False, False, False, False, True]
State prediction error at timestep 5915 is 0.012
Human Feedback received at timestep 5915 of None
Current timestep = 5916. State = [[-0.23296198  0.2026525 ]]. Action = [[-0.08151279 -0.02533684  0.         -0.7223674 ]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 5916 is [True, False, False, False, False, True]
Current timestep = 5917. State = [[-0.23324075  0.20159048]]. Action = [[ 0.05555066 -0.01978184  0.         -0.350446  ]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 5917 is [True, False, False, False, False, True]
Current timestep = 5918. State = [[-0.23168471  0.19754441]]. Action = [[ 0.008008   -0.07125978  0.         -0.5333682 ]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 5918 is [True, False, False, False, False, True]
Current timestep = 5919. State = [[-0.22788249  0.198108  ]]. Action = [[ 0.07688465  0.06483566  0.         -0.28615505]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 5919 is [True, False, False, False, False, True]
Current timestep = 5920. State = [[-0.22229908  0.2014096 ]]. Action = [[ 0.07662686  0.05527567  0.         -0.2183708 ]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 5920 is [True, False, False, False, False, True]
Current timestep = 5921. State = [[-0.22201638  0.19765383]]. Action = [[-0.05116653 -0.09765535  0.          0.47227836]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 5921 is [True, False, False, False, False, True]
State prediction error at timestep 5921 is 0.012
Human Feedback received at timestep 5921 of None
Current timestep = 5922. State = [[-0.22532865  0.1951416 ]]. Action = [[-0.03690976  0.0174497   0.         -0.5703549 ]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 5922 is [True, False, False, False, False, True]
Current timestep = 5923. State = [[-0.22932684  0.1979835 ]]. Action = [[-0.04500825  0.06487157  0.         -0.761263  ]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 5923 is [True, False, False, False, False, True]
Current timestep = 5924. State = [[-0.23431607  0.19976892]]. Action = [[-0.05411962  0.00740723  0.          0.03444052]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 5924 is [True, False, False, False, False, True]
Current timestep = 5925. State = [[-0.23905206  0.19560492]]. Action = [[-0.0455818  -0.09001639  0.          0.16588831]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 5925 is [True, False, False, False, False, True]
Current timestep = 5926. State = [[-0.23835841  0.19629337]]. Action = [[ 0.06725617  0.07524966  0.         -0.7298987 ]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 5926 is [True, False, False, False, False, True]
Current timestep = 5927. State = [[-0.2390364   0.20205489]]. Action = [[-0.03375105  0.0841906   0.          0.23493385]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 5927 is [True, False, False, False, False, True]
Current timestep = 5928. State = [[-0.24267998  0.20407249]]. Action = [[-0.03957045 -0.0131098   0.          0.03598881]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 5928 is [True, False, False, False, False, True]
Current timestep = 5929. State = [[-0.24184437  0.2043963 ]]. Action = [[0.05570001 0.00446658 0.         0.7775178 ]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 5929 is [True, False, False, False, False, True]
State prediction error at timestep 5929 is 0.012
Human Feedback received at timestep 5929 of None
Current timestep = 5930. State = [[-0.24258694  0.20399328]]. Action = [[-0.03521811 -0.01532441  0.          0.07384717]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 5930 is [True, False, False, False, False, True]
Current timestep = 5931. State = [[-0.24621204  0.20857836]]. Action = [[-0.04337347  0.09196763  0.          0.27357936]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 5931 is [True, False, False, False, False, True]
Current timestep = 5932. State = [[-0.24965611  0.2128482 ]]. Action = [[-0.02458756  0.02064426  0.          0.02297652]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 5932 is [True, False, False, False, False, True]
Current timestep = 5933. State = [[-0.24819697  0.21443127]]. Action = [[0.06386925 0.00435416 0.         0.95870245]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 5933 is [True, False, False, False, False, True]
Current timestep = 5934. State = [[-0.24574916  0.21120223]]. Action = [[ 0.02350952 -0.07721065  0.          0.7414584 ]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 5934 is [True, False, False, False, False, True]
Current timestep = 5935. State = [[-0.24163523  0.210043  ]]. Action = [[ 0.06771334  0.01576589  0.         -0.37573195]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 5935 is [True, False, False, False, False, True]
Current timestep = 5936. State = [[-0.2381141   0.20635355]]. Action = [[ 0.02347924 -0.08097596  0.         -0.46805352]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 5936 is [True, False, False, False, False, True]
Current timestep = 5937. State = [[-0.23656635  0.2011393 ]]. Action = [[-0.003416   -0.05898421  0.          0.7709681 ]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 5937 is [True, False, False, False, False, True]
Current timestep = 5938. State = [[-0.23713657  0.19649155]]. Action = [[-0.03579336 -0.05691012  0.         -0.48513198]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 5938 is [True, False, False, False, False, True]
Current timestep = 5939. State = [[-0.23683187  0.19901852]]. Action = [[ 0.00868527  0.09310841  0.         -0.807454  ]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 5939 is [True, False, False, False, False, True]
State prediction error at timestep 5939 is 0.012
Human Feedback received at timestep 5939 of None
Current timestep = 5940. State = [[-0.2372246   0.20586859]]. Action = [[-0.01767727  0.0974628   0.          0.12242973]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 5940 is [True, False, False, False, False, True]
Current timestep = 5941. State = [[-0.2383998  0.2114848]]. Action = [[-0.00967929  0.05943351  0.         -0.6956302 ]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 5941 is [True, False, False, False, False, True]
State prediction error at timestep 5941 is 0.012
Human Feedback received at timestep 5941 of None
Current timestep = 5942. State = [[-0.24043876  0.21444768]]. Action = [[-0.0274215   0.01888029  0.          0.4788611 ]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 5942 is [True, False, False, False, False, True]
State prediction error at timestep 5942 is 0.012
Human Feedback received at timestep 5942 of None
Current timestep = 5943. State = [[-0.24382947  0.21744795]]. Action = [[-0.04242844  0.03579449  0.         -0.03560519]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 5943 is [True, False, False, False, False, True]
Current timestep = 5944. State = [[-0.24772324  0.22421835]]. Action = [[-0.03448129  0.09869593  0.          0.9650459 ]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 5944 is [True, False, False, False, False, True]
Current timestep = 5945. State = [[-0.24604015  0.23161566]]. Action = [[ 0.0859149   0.07756662  0.         -0.04909074]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 5945 is [True, False, False, False, False, True]
Current timestep = 5946. State = [[-0.24701712  0.23565777]]. Action = [[-0.04466659  0.01724873  0.          0.61842704]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 5946 is [True, False, False, False, False, True]
State prediction error at timestep 5946 is 0.012
Human Feedback received at timestep 5946 of None
Current timestep = 5947. State = [[-0.249602    0.23479922]]. Action = [[-0.00721189 -0.05577198  0.         -0.36963224]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 5947 is [True, False, False, False, False, True]
Current timestep = 5948. State = [[-0.25303406  0.23345241]]. Action = [[-0.05087805 -0.02707287  0.         -0.7131445 ]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 5948 is [True, False, False, False, False, True]
Current timestep = 5949. State = [[-0.25905377  0.23849311]]. Action = [[-0.07712586  0.08811321  0.          0.8595209 ]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 5949 is [True, False, False, False, False, True]
State prediction error at timestep 5949 is 0.012
Human Feedback received at timestep 5949 of None
Current timestep = 5950. State = [[-0.2606143   0.23770465]]. Action = [[ 0.03449326 -0.09824449  0.         -0.33679104]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 5950 is [True, False, False, False, False, True]
Current timestep = 5951. State = [[-0.25909054  0.23381524]]. Action = [[ 0.01940876 -0.04656764  0.          0.74561906]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 5951 is [True, False, False, False, False, True]
Current timestep = 5952. State = [[-0.26026568  0.23486489]]. Action = [[-0.03290134  0.03825141  0.         -0.02026629]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 5952 is [True, False, False, False, False, True]
Current timestep = 5953. State = [[-0.26008704  0.23256214]]. Action = [[ 0.02537429 -0.07760016  0.         -0.7686466 ]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 5953 is [True, False, False, False, False, True]
Current timestep = 5954. State = [[-0.25790328  0.22921416]]. Action = [[ 0.02573752 -0.02713556  0.         -0.13869727]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 5954 is [True, False, False, False, False, True]
Current timestep = 5955. State = [[-0.2587018  0.2248854]]. Action = [[-0.0410275  -0.06846659  0.          0.7926847 ]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 5955 is [True, False, False, False, False, True]
Current timestep = 5956. State = [[-0.26214442  0.22014785]]. Action = [[-0.0580897  -0.05682345  0.          0.5769187 ]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 5956 is [True, False, False, False, False, True]
State prediction error at timestep 5956 is 0.012
Human Feedback received at timestep 5956 of None
Current timestep = 5957. State = [[-0.26458412  0.21954893]]. Action = [[-0.01931242  0.02694403  0.         -0.7614959 ]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 5957 is [True, False, False, False, False, True]
State prediction error at timestep 5957 is 0.012
Human Feedback received at timestep 5957 of None
Current timestep = 5958. State = [[-0.26577234  0.21733733]]. Action = [[-0.00814807 -0.04717569  0.         -0.61421144]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 5958 is [True, False, False, False, False, True]
Current timestep = 5959. State = [[-0.26467055  0.21356346]]. Action = [[ 0.03047632 -0.03373393  0.          0.37899113]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 5959 is [True, False, False, False, False, True]
Current timestep = 5960. State = [[-0.2679295   0.21271218]]. Action = [[-0.07809289  0.02341004  0.         -0.39852828]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 5960 is [True, False, False, False, False, True]
State prediction error at timestep 5960 is 0.012
Human Feedback received at timestep 5960 of None
Current timestep = 5961. State = [[-0.2729067   0.21477947]]. Action = [[-0.04104161  0.04418046  0.          0.7163173 ]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 5961 is [True, False, False, False, False, True]
Current timestep = 5962. State = [[-0.27361605  0.21103139]]. Action = [[ 0.03203412 -0.08760419  0.          0.28204083]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 5962 is [True, False, False, False, False, True]
Current timestep = 5963. State = [[-0.27273023  0.20598404]]. Action = [[ 0.01393481 -0.03431938  0.          0.5545087 ]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 5963 is [True, False, False, False, False, True]
Current timestep = 5964. State = [[-0.270575    0.20619173]]. Action = [[0.04780401 0.05209825 0.         0.20201659]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 5964 is [True, False, False, False, False, True]
Current timestep = 5965. State = [[-0.2722843   0.20908375]]. Action = [[-0.0454418   0.05725846  0.          0.9463413 ]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 5965 is [True, False, False, False, False, True]
Current timestep = 5966. State = [[-0.27733928  0.208653  ]]. Action = [[-0.05952585 -0.02888338  0.         -0.18154454]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 5966 is [True, False, False, False, False, True]
State prediction error at timestep 5966 is 0.012
Human Feedback received at timestep 5966 of None
Current timestep = 5967. State = [[-0.27677506  0.20461428]]. Action = [[ 0.06194966 -0.05819191  0.         -0.13795888]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 5967 is [True, False, False, False, False, True]
State prediction error at timestep 5967 is 0.012
Human Feedback received at timestep 5967 of None
Current timestep = 5968. State = [[-0.28023428  0.20690662]]. Action = [[-0.09066233  0.09770583  0.          0.785781  ]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 5968 is [True, False, False, False, False, True]
Current timestep = 5969. State = [[-0.27943698  0.20655051]]. Action = [[ 0.08819301 -0.05886731  0.          0.6414597 ]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 5969 is [True, False, False, False, False, True]
Current timestep = 5970. State = [[-0.27678156  0.2008406 ]]. Action = [[ 0.01347779 -0.07384421  0.         -0.86392206]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 5970 is [True, False, False, False, False, True]
Current timestep = 5971. State = [[-0.27936935  0.1947654 ]]. Action = [[-0.0664754  -0.07435508  0.         -0.64196837]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 5971 is [True, False, False, False, False, True]
Current timestep = 5972. State = [[-0.28294754  0.19715253]]. Action = [[-0.03290202  0.09838486  0.         -0.16018295]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 5972 is [True, False, False, False, False, True]
Current timestep = 5973. State = [[-0.28750673  0.2008418 ]]. Action = [[-0.05989218  0.0238587   0.          0.447343  ]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 5973 is [True, False, False, False, False, True]
Current timestep = 5974. State = [[-0.28683004  0.2020708 ]]. Action = [[0.06469675 0.01043751 0.         0.33853793]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 5974 is [True, False, False, False, False, True]
Current timestep = 5975. State = [[-0.2830984   0.20587152]]. Action = [[ 0.05661569  0.08247974  0.         -0.753591  ]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 5975 is [True, False, False, False, False, True]
Current timestep = 5976. State = [[-0.28329697  0.20835479]]. Action = [[-0.02485704  0.01194473  0.          0.12651098]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 5976 is [True, False, False, False, False, True]
Current timestep = 5977. State = [[-0.28327036  0.20841098]]. Action = [[ 0.02479039 -0.00724208  0.         -0.19715172]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 5977 is [True, False, False, False, False, True]
State prediction error at timestep 5977 is 0.012
Human Feedback received at timestep 5977 of None
Current timestep = 5978. State = [[-0.2835107   0.20915079]]. Action = [[-0.01081137  0.01749965  0.         -0.7689055 ]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 5978 is [True, False, False, False, False, True]
State prediction error at timestep 5978 is 0.012
Human Feedback received at timestep 5978 of None
Current timestep = 5979. State = [[-0.28095716  0.20828463]]. Action = [[ 0.06148759 -0.02999992  0.          0.59249043]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 5979 is [True, False, False, False, False, True]
Current timestep = 5980. State = [[-0.28099468  0.21220963]]. Action = [[-0.03523835  0.09727748  0.         -0.1436516 ]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 5980 is [True, False, False, False, False, True]
Current timestep = 5981. State = [[-0.28706175  0.21896398]]. Action = [[-0.09556212  0.0722192   0.         -0.06482643]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 5981 is [True, False, False, False, False, True]
State prediction error at timestep 5981 is 0.012
Human Feedback received at timestep 5981 of None
Current timestep = 5982. State = [[-0.28817496  0.22191304]]. Action = [[ 0.04807556 -0.00285929  0.         -0.49948668]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 5982 is [True, False, False, False, False, True]
Current timestep = 5983. State = [[-0.29118946  0.21909133]]. Action = [[-0.08110405 -0.08241929  0.         -0.60531014]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 5983 is [True, False, False, False, False, True]
Current timestep = 5984. State = [[-0.29717222  0.21583927]]. Action = [[-0.06883931 -0.04817624  0.          0.5518336 ]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 5984 is [True, False, False, False, False, True]
Current timestep = 5985. State = [[-0.3025936   0.21615805]]. Action = [[-0.05457876  0.01265224  0.         -0.6423784 ]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 5985 is [True, False, False, False, False, True]
Current timestep = 5986. State = [[-0.30514106  0.21273619]]. Action = [[-0.00142627 -0.09230735  0.         -0.3733499 ]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 5986 is [True, False, False, False, False, True]
Current timestep = 5987. State = [[-0.31047538  0.20690325]]. Action = [[-0.09530313 -0.07949214  0.         -0.05577874]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 5987 is [True, False, False, False, False, True]
Current timestep = 5988. State = [[-0.31384274  0.20443729]]. Action = [[ 0.00206666 -0.00883515  0.         -0.921606  ]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 5988 is [True, False, False, False, False, True]
Current timestep = 5989. State = [[-0.3170457   0.20431346]]. Action = [[-0.04464392  0.0092226   0.          0.37651956]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 5989 is [True, False, False, False, False, True]
State prediction error at timestep 5989 is 0.012
Human Feedback received at timestep 5989 of None
Current timestep = 5990. State = [[-0.3165957   0.20026262]]. Action = [[ 0.05577617 -0.07630149  0.          0.33367252]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 5990 is [True, False, False, False, False, True]
Current timestep = 5991. State = [[-0.31223133  0.19559348]]. Action = [[ 0.07174402 -0.02631959  0.         -0.57775986]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 5991 is [True, False, False, False, False, True]
Current timestep = 5992. State = [[-0.31471834  0.19603215]]. Action = [[-0.08177368  0.05819043  0.         -0.44228184]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 5992 is [True, False, False, False, False, True]
Current timestep = 5993. State = [[-0.321178   0.2004308]]. Action = [[-0.06354456  0.07708337  0.         -0.7647818 ]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 5993 is [True, False, False, False, False, True]
State prediction error at timestep 5993 is 0.012
Human Feedback received at timestep 5993 of None
Current timestep = 5994. State = [[-0.3245669   0.20167923]]. Action = [[ 4.6472251e-04 -4.4544339e-03  0.0000000e+00 -9.5292675e-01]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 5994 is [True, False, False, False, False, True]
State prediction error at timestep 5994 is 0.012
Human Feedback received at timestep 5994 of None
Current timestep = 5995. State = [[-0.32134867  0.1977146 ]]. Action = [[ 0.09199978 -0.06118776  0.          0.38589036]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 5995 is [True, False, False, False, False, True]
Current timestep = 5996. State = [[-0.32117322  0.19245957]]. Action = [[-0.0369174  -0.05119966  0.         -0.16637719]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 5996 is [True, False, False, False, False, True]
Current timestep = 5997. State = [[-0.32269213  0.18615343]]. Action = [[-0.00611288 -0.08455519  0.         -0.8878051 ]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 5997 is [True, False, False, False, False, True]
State prediction error at timestep 5997 is 0.012
Human Feedback received at timestep 5997 of None
Current timestep = 5998. State = [[-0.32270896  0.18158989]]. Action = [[ 0.00610857 -0.02768109  0.          0.85713553]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 5998 is [True, False, False, False, False, True]
State prediction error at timestep 5998 is 0.012
Human Feedback received at timestep 5998 of None
Current timestep = 5999. State = [[-0.3226377   0.17775105]]. Action = [[-0.00168125 -0.03982475  0.          0.40211844]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 5999 is [True, False, False, False, False, True]
Current timestep = 6000. State = [[-0.32609633  0.17734444]]. Action = [[-0.06822542  0.03492581  0.          0.93435454]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 6000 is [True, False, False, False, False, True]
Current timestep = 6001. State = [[-0.33079892  0.18055695]]. Action = [[-0.04415735  0.0621737   0.         -0.4466201 ]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 6001 is [True, False, False, False, False, True]
Current timestep = 6002. State = [[-0.3365246   0.18433058]]. Action = [[-0.06528454  0.05234366  0.          0.47673035]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 6002 is [True, False, False, False, False, True]
Current timestep = 6003. State = [[-0.3393681   0.18244831]]. Action = [[ 0.00827231 -0.06360368  0.          0.88913965]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 6003 is [True, False, False, False, False, True]
Current timestep = 6004. State = [[-0.3424024   0.18202601]]. Action = [[-0.04081101  0.03297736  0.          0.87243545]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 6004 is [True, False, False, False, False, True]
Current timestep = 6005. State = [[-0.3443279   0.18203503]]. Action = [[ 0.01106533 -0.01195604  0.         -0.70485955]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 6005 is [True, False, False, False, False, True]
Current timestep = 6006. State = [[-0.34985045  0.17799488]]. Action = [[-0.09674465 -0.07701766  0.         -0.94357044]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 6006 is [True, False, False, False, False, True]
Current timestep = 6007. State = [[-0.35309657  0.1767387 ]]. Action = [[0.01665701 0.02085688 0.         0.37279773]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 6007 is [True, False, False, False, False, True]
Current timestep = 6008. State = [[-0.35599777  0.18001783]]. Action = [[-0.03940921  0.06278231  0.         -0.22956216]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 6008 is [True, False, False, False, False, True]
State prediction error at timestep 6008 is 0.012
Human Feedback received at timestep 6008 of None
Current timestep = 6009. State = [[-0.35398886  0.18323095]]. Action = [[0.09402009 0.03875748 0.         0.81327724]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 6009 is [True, False, False, False, False, True]
State prediction error at timestep 6009 is 0.012
Human Feedback received at timestep 6009 of None
Current timestep = 6010. State = [[-0.34813726  0.18161999]]. Action = [[ 0.08774479 -0.03755236  0.          0.91664124]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 6010 is [True, False, False, False, False, True]
Current timestep = 6011. State = [[-0.34403273  0.17627555]]. Action = [[ 0.03370293 -0.07274744  0.         -0.99812526]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 6011 is [True, False, False, False, False, True]
Current timestep = 6012. State = [[-0.34442753  0.1727828 ]]. Action = [[-0.03786501 -0.0211098   0.          0.92853856]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 6012 is [True, False, False, False, False, True]
Current timestep = 6013. State = [[-0.34500623  0.16842294]]. Action = [[-0.00254795 -0.07187562  0.          0.14741468]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 6013 is [True, False, False, False, False, True]
Current timestep = 6014. State = [[-0.34531552  0.16267793]]. Action = [[-0.02020621 -0.07033534  0.         -0.96770436]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 6014 is [True, False, False, False, False, True]
Current timestep = 6015. State = [[-0.34728912  0.15937367]]. Action = [[-0.04488422 -0.01788308  0.         -0.9039113 ]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 6015 is [True, False, False, False, False, True]
Current timestep = 6016. State = [[-0.34394073  0.15795588]]. Action = [[ 8.5229956e-02 -3.2760203e-05  0.0000000e+00 -2.3022735e-01]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 6016 is [True, False, False, False, False, True]
Current timestep = 6017. State = [[-0.33985248  0.15997855]]. Action = [[0.02727591 0.06928962 0.         0.6483636 ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 6017 is [True, False, False, False, False, True]
Current timestep = 6018. State = [[-0.3371781   0.16519092]]. Action = [[0.03475707 0.0927789  0.         0.9435779 ]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 6018 is [True, False, False, False, False, True]
State prediction error at timestep 6018 is 0.012
Human Feedback received at timestep 6018 of None
Current timestep = 6019. State = [[-0.33199123  0.1631771 ]]. Action = [[ 0.08188071 -0.07499248  0.         -0.7052768 ]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 6019 is [True, False, False, False, False, True]
Current timestep = 6020. State = [[-0.32615608  0.15604839]]. Action = [[ 0.05288126 -0.08471268  0.          0.5453769 ]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 6020 is [True, False, False, False, False, True]
Current timestep = 6021. State = [[-0.32764995  0.1513094 ]]. Action = [[-0.09063711 -0.03372771  0.         -0.20680022]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 6021 is [True, False, False, False, False, True]
State prediction error at timestep 6021 is 0.012
Human Feedback received at timestep 6021 of None
Current timestep = 6022. State = [[-0.3264829   0.15112509]]. Action = [[ 0.05576361  0.02805495  0.         -0.79440796]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 6022 is [True, False, False, False, False, True]
Current timestep = 6023. State = [[-0.32853308  0.15378004]]. Action = [[-0.09057255  0.04635533  0.          0.59300303]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 6023 is [True, False, False, False, False, True]
Current timestep = 6024. State = [[-0.33097598  0.15271309]]. Action = [[-0.0110624  -0.05125133  0.          0.09459174]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 6024 is [True, False, False, False, False, True]
Current timestep = 6025. State = [[-0.3323652  0.1493937]]. Action = [[-0.02986238 -0.04124781  0.         -0.15333456]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 6025 is [True, False, False, False, False, True]
Current timestep = 6026. State = [[-0.3360426   0.15142725]]. Action = [[-0.05994397  0.06480574  0.         -0.2176559 ]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 6026 is [True, False, False, False, False, True]
Current timestep = 6027. State = [[-0.33374086  0.14934114]]. Action = [[ 0.08893912 -0.0810717   0.          0.6783503 ]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 6027 is [True, False, False, False, False, True]
State prediction error at timestep 6027 is 0.012
Human Feedback received at timestep 6027 of None
Current timestep = 6028. State = [[-0.3295234   0.14885958]]. Action = [[0.03893925 0.05013771 0.         0.9303107 ]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 6028 is [True, False, False, False, False, True]
State prediction error at timestep 6028 is 0.012
Human Feedback received at timestep 6028 of None
Current timestep = 6029. State = [[-0.33316946  0.15066059]]. Action = [[-0.09718533  0.01726989  0.         -0.12193763]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 6029 is [True, False, False, False, False, True]
State prediction error at timestep 6029 is 0.012
Human Feedback received at timestep 6029 of None
Current timestep = 6030. State = [[-0.33390376  0.15257053]]. Action = [[0.05478377 0.03134381 0.         0.70004296]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 6030 is [True, False, False, False, False, True]
State prediction error at timestep 6030 is 0.012
Human Feedback received at timestep 6030 of None
Current timestep = 6031. State = [[-0.33651343  0.15817551]]. Action = [[-0.0644258   0.09985761  0.          0.0163815 ]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 6031 is [True, False, False, False, False, True]
Current timestep = 6032. State = [[-0.34356627  0.16337776]]. Action = [[-0.0828369   0.04028579  0.          0.6688299 ]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 6032 is [True, False, False, False, False, True]
Current timestep = 6033. State = [[-0.3486033  0.1642393]]. Action = [[-0.02564193 -0.02510247  0.          0.6342747 ]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 6033 is [True, False, False, False, False, True]
Current timestep = 6034. State = [[-0.34611797  0.16677046]]. Action = [[0.09889162 0.05564678 0.         0.9743216 ]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 6034 is [True, False, False, False, False, True]
Current timestep = 6035. State = [[-0.34452727  0.17313021]]. Action = [[-3.8957596e-04  9.2347123e-02  0.0000000e+00 -5.7595891e-01]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 6035 is [True, False, False, False, False, True]
Current timestep = 6036. State = [[-0.34721082  0.17443992]]. Action = [[-0.04055453 -0.04546424  0.         -0.02606416]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 6036 is [True, False, False, False, False, True]
Current timestep = 6037. State = [[-0.34455156  0.17432523]]. Action = [[0.09104346 0.0030702  0.         0.6518407 ]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 6037 is [True, False, False, False, False, True]
Current timestep = 6038. State = [[-0.3391083  0.1788746]]. Action = [[0.06310832 0.08242377 0.         0.7945131 ]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 6038 is [True, False, False, False, False, True]
State prediction error at timestep 6038 is 0.012
Human Feedback received at timestep 6038 of None
Current timestep = 6039. State = [[-0.33397007  0.17948669]]. Action = [[ 0.06030806 -0.04405419  0.          0.29262233]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 6039 is [True, False, False, False, False, True]
Current timestep = 6040. State = [[-0.32995588  0.17588   ]]. Action = [[ 0.02502667 -0.06396875  0.         -0.3788408 ]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 6040 is [True, False, False, False, False, True]
State prediction error at timestep 6040 is 0.012
Human Feedback received at timestep 6040 of None
Current timestep = 6041. State = [[-0.33024272  0.17445447]]. Action = [[-0.05061339 -0.00879908  0.          0.5069804 ]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 6041 is [True, False, False, False, False, True]
Current timestep = 6042. State = [[-0.3328017   0.17357723]]. Action = [[-0.05158738 -0.0325207   0.         -0.3992558 ]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 6042 is [True, False, False, False, False, True]
Current timestep = 6043. State = [[-0.3364076   0.17219703]]. Action = [[-0.06602377 -0.03052393  0.         -0.11175001]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 6043 is [True, False, False, False, False, True]
Current timestep = 6044. State = [[-0.33777872  0.16867495]]. Action = [[-0.00675908 -0.07037251  0.         -0.42343062]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 6044 is [True, False, False, False, False, True]
Current timestep = 6045. State = [[-0.33900988  0.16412811]]. Action = [[-0.03576842 -0.05931786  0.         -0.77189314]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 6045 is [True, False, False, False, False, True]
Current timestep = 6046. State = [[-0.34253713  0.16501941]]. Action = [[-0.05874937  0.05192215  0.         -0.93553257]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 6046 is [True, False, False, False, False, True]
Current timestep = 6047. State = [[-0.34117073  0.16972597]]. Action = [[0.07489609 0.07531448 0.         0.22276247]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 6047 is [True, False, False, False, False, True]
Current timestep = 6048. State = [[-0.3348049   0.16717482]]. Action = [[ 0.09949427 -0.07823589  0.          0.19234133]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 6048 is [True, False, False, False, False, True]
Current timestep = 6049. State = [[-0.32950407  0.16851628]]. Action = [[ 0.04894289  0.09670185  0.         -0.25555503]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 6049 is [True, False, False, False, False, True]
Current timestep = 6050. State = [[-0.3243409   0.17037134]]. Action = [[0.07520732 0.00584438 0.         0.6515727 ]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 6050 is [True, False, False, False, False, True]
Current timestep = 6051. State = [[-0.31921908  0.17422025]]. Action = [[ 0.05479897  0.09127333  0.         -0.13779688]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 6051 is [True, False, False, False, False, True]
Current timestep = 6052. State = [[-0.31340718  0.17350492]]. Action = [[ 0.07425316 -0.05286185  0.          0.02235854]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 6052 is [True, False, False, False, False, True]
State prediction error at timestep 6052 is 0.012
Human Feedback received at timestep 6052 of None
Current timestep = 6053. State = [[-0.3086695   0.16769327]]. Action = [[ 0.02703328 -0.08362311  0.          0.1778295 ]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 6053 is [True, False, False, False, False, True]
Current timestep = 6054. State = [[-0.3064163   0.16796012]]. Action = [[-0.00347395  0.05805518  0.         -0.19418544]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 6054 is [True, False, False, False, False, True]
State prediction error at timestep 6054 is 0.012
Human Feedback received at timestep 6054 of None
Current timestep = 6055. State = [[-0.30912146  0.17362496]]. Action = [[-0.07772671  0.08077305  0.          0.92966306]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 6055 is [True, False, False, False, False, True]
Current timestep = 6056. State = [[-0.30682227  0.17808823]]. Action = [[0.07864537 0.03478947 0.         0.7205219 ]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 6056 is [True, False, False, False, False, True]
State prediction error at timestep 6056 is 0.012
Human Feedback received at timestep 6056 of None
Current timestep = 6057. State = [[-0.30721644  0.18382004]]. Action = [[-0.06131852  0.0863122   0.          0.7168286 ]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 6057 is [True, False, False, False, False, True]
State prediction error at timestep 6057 is 0.012
Human Feedback received at timestep 6057 of None
Current timestep = 6058. State = [[-0.3121147   0.19166824]]. Action = [[-0.06560813  0.08837362  0.          0.25337362]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 6058 is [True, False, False, False, False, True]
State prediction error at timestep 6058 is 0.012
Human Feedback received at timestep 6058 of None
Current timestep = 6059. State = [[-0.3177962   0.19153193]]. Action = [[-0.07143126 -0.09109581  0.          0.23941207]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 6059 is [True, False, False, False, False, True]
State prediction error at timestep 6059 is 0.012
Human Feedback received at timestep 6059 of None
Current timestep = 6060. State = [[-0.32329816  0.19080451]]. Action = [[-0.0651796  -0.0070795   0.         -0.01385629]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 6060 is [True, False, False, False, False, True]
State prediction error at timestep 6060 is 0.012
Human Feedback received at timestep 6060 of None
Current timestep = 6061. State = [[-0.32350555  0.19155595]]. Action = [[ 0.04758172 -0.01122024  0.         -0.05413508]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 6061 is [True, False, False, False, False, True]
Current timestep = 6062. State = [[-0.32206717  0.19422896]]. Action = [[ 0.01653577  0.04122948  0.         -0.8472112 ]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 6062 is [True, False, False, False, False, True]
Current timestep = 6063. State = [[-0.3207903   0.19361018]]. Action = [[ 0.02491687 -0.05112894  0.          0.7831352 ]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 6063 is [True, False, False, False, False, True]
State prediction error at timestep 6063 is 0.012
Human Feedback received at timestep 6063 of None
Current timestep = 6064. State = [[-0.32313773  0.19526045]]. Action = [[-0.057957    0.04813678  0.          0.74372506]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 6064 is [True, False, False, False, False, True]
Current timestep = 6065. State = [[-0.32520056  0.19537994]]. Action = [[-0.00089946 -0.04028899  0.         -0.38963532]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 6065 is [True, False, False, False, False, True]
Current timestep = 6066. State = [[-0.33032122  0.19907926]]. Action = [[-0.09192871  0.08384263  0.         -0.872951  ]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 6066 is [True, False, False, False, False, True]
State prediction error at timestep 6066 is 0.012
Human Feedback received at timestep 6066 of None
Current timestep = 6067. State = [[-0.33867338  0.20671085]]. Action = [[-0.09090553  0.09055417  0.          0.8343086 ]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 6067 is [True, False, False, False, False, True]
State prediction error at timestep 6067 is 0.012
Human Feedback received at timestep 6067 of None
Current timestep = 6068. State = [[-0.34264073  0.2098608 ]]. Action = [[ 0.00873324 -0.0095407   0.         -0.26251197]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 6068 is [True, False, False, False, False, True]
Current timestep = 6069. State = [[-0.34113356  0.2080442 ]]. Action = [[ 0.05650843 -0.04715792  0.         -0.9307281 ]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 6069 is [True, False, False, False, False, True]
Current timestep = 6070. State = [[-0.33975965  0.20790692]]. Action = [[0.01405559 0.0182458  0.         0.5845393 ]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 6070 is [True, False, False, False, False, True]
State prediction error at timestep 6070 is 0.012
Human Feedback received at timestep 6070 of None
Current timestep = 6071. State = [[-0.3433373   0.20542519]]. Action = [[-0.07075403 -0.07134262  0.         -0.6800039 ]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 6071 is [True, False, False, False, False, True]
State prediction error at timestep 6071 is 0.012
Human Feedback received at timestep 6071 of None
Current timestep = 6072. State = [[-0.34251902  0.20812699]]. Action = [[ 0.08067178  0.0978859   0.         -0.9791034 ]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 6072 is [True, False, False, False, False, True]
Current timestep = 6073. State = [[-0.33962527  0.21183504]]. Action = [[ 0.01599602  0.01816555  0.         -0.9575916 ]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 6073 is [True, False, False, False, False, True]
State prediction error at timestep 6073 is 0.012
Human Feedback received at timestep 6073 of None
Current timestep = 6074. State = [[-0.33914074  0.20830467]]. Action = [[-0.01193889 -0.09739777  0.          0.33033955]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 6074 is [True, False, False, False, False, True]
Current timestep = 6075. State = [[-0.34325963  0.20857924]]. Action = [[-0.08965018  0.04562034  0.         -0.13786298]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 6075 is [True, False, False, False, False, True]
Current timestep = 6076. State = [[-0.3447095   0.21481766]]. Action = [[ 0.02777625  0.09050647  0.         -0.10116786]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 6076 is [True, False, False, False, False, True]
Current timestep = 6077. State = [[-0.34511477  0.21639508]]. Action = [[-0.01589408 -0.03138977  0.          0.8464577 ]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 6077 is [True, False, False, False, False, True]
Current timestep = 6078. State = [[-0.34811583  0.21506879]]. Action = [[-0.04961964 -0.02710059  0.          0.4249854 ]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 6078 is [True, False, False, False, False, True]
State prediction error at timestep 6078 is 0.012
Human Feedback received at timestep 6078 of None
Current timestep = 6079. State = [[-0.34605366  0.21141016]]. Action = [[ 0.07244732 -0.07119468  0.          0.6804744 ]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 6079 is [True, False, False, False, False, True]
Current timestep = 6080. State = [[-0.34528643  0.21256721]]. Action = [[-0.02725411  0.06622095  0.          0.15478611]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 6080 is [True, False, False, False, False, True]
State prediction error at timestep 6080 is 0.012
Human Feedback received at timestep 6080 of None
Current timestep = 6081. State = [[-0.3479998  0.2163199]]. Action = [[-0.03467718  0.03634235  0.         -0.5542131 ]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 6081 is [True, False, False, False, False, True]
Current timestep = 6082. State = [[-0.35182512  0.21559519]]. Action = [[-0.04808423 -0.04736895  0.         -0.2293973 ]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 6082 is [True, False, False, False, False, True]
State prediction error at timestep 6082 is 0.012
Human Feedback received at timestep 6082 of None
Current timestep = 6083. State = [[-0.34968573  0.21231124]]. Action = [[ 0.07765774 -0.04853225  0.          0.4235053 ]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 6083 is [True, False, False, False, False, True]
Current timestep = 6084. State = [[-0.3472602   0.20899434]]. Action = [[ 0.00347601 -0.03485434  0.          0.6967765 ]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 6084 is [True, False, False, False, False, True]
Current timestep = 6085. State = [[-0.34868896  0.20417243]]. Action = [[-0.04034493 -0.07620484  0.         -0.26522267]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 6085 is [True, False, False, False, False, True]
Current timestep = 6086. State = [[-0.35074216  0.19839163]]. Action = [[-0.02726075 -0.0747046   0.         -0.9692235 ]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 6086 is [True, False, False, False, False, True]
Current timestep = 6087. State = [[-0.34704736  0.19586635]]. Action = [[ 0.08711251  0.00729753  0.         -0.11004108]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 6087 is [True, False, False, False, False, True]
State prediction error at timestep 6087 is 0.012
Human Feedback received at timestep 6087 of None
Current timestep = 6088. State = [[-0.34494966  0.19686407]]. Action = [[-0.01654176  0.04102276  0.         -0.796785  ]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 6088 is [True, False, False, False, False, True]
Current timestep = 6089. State = [[-0.34303024  0.19254102]]. Action = [[ 0.03617909 -0.09307827  0.          0.4905826 ]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 6089 is [True, False, False, False, False, True]
Current timestep = 6090. State = [[-0.3453535   0.18476437]]. Action = [[-0.085317   -0.09343081  0.         -0.6827036 ]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 6090 is [True, False, False, False, False, True]
State prediction error at timestep 6090 is 0.012
Human Feedback received at timestep 6090 of None
Current timestep = 6091. State = [[-0.35100603  0.17948577]]. Action = [[-0.07973798 -0.04513118  0.          0.37764084]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 6091 is [True, False, False, False, False, True]
Current timestep = 6092. State = [[-0.35481784  0.17363583]]. Action = [[-0.03111006 -0.07913959  0.         -0.6764614 ]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 6092 is [True, False, False, False, False, True]
State prediction error at timestep 6092 is 0.012
Human Feedback received at timestep 6092 of None
Current timestep = 6093. State = [[-0.352878    0.17100006]]. Action = [[ 0.0669575   0.02029449  0.         -0.69603956]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 6093 is [True, False, False, False, False, True]
Current timestep = 6094. State = [[-0.3542246   0.16848493]]. Action = [[-0.06048879 -0.03037585  0.         -0.00047708]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 6094 is [True, False, False, False, False, True]
State prediction error at timestep 6094 is 0.012
Human Feedback received at timestep 6094 of None
Current timestep = 6095. State = [[-0.35826868  0.16699009]]. Action = [[-0.03572995  0.01202802  0.          0.29881525]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 6095 is [True, False, False, False, False, True]
State prediction error at timestep 6095 is 0.012
Human Feedback received at timestep 6095 of None
Current timestep = 6096. State = [[-0.3563848   0.16318223]]. Action = [[ 0.07980203 -0.05360015  0.         -0.1687361 ]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 6096 is [True, False, False, False, False, True]
State prediction error at timestep 6096 is 0.012
Human Feedback received at timestep 6096 of None
Current timestep = 6097. State = [[-0.3504152   0.16136123]]. Action = [[ 0.09321005  0.03674386  0.         -0.82983536]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 6097 is [True, False, False, False, False, True]
Current timestep = 6098. State = [[-0.34536722  0.15538068]]. Action = [[ 0.05425397 -0.0969219   0.         -0.08666813]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 6098 is [True, False, False, False, False, True]
Current timestep = 6099. State = [[-0.34577322  0.15299463]]. Action = [[-0.04145124  0.04574469  0.         -0.87456244]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 6099 is [True, False, False, False, False, True]
Current timestep = 6100. State = [[-0.34261078  0.1481113 ]]. Action = [[ 0.08759888 -0.09403291  0.          0.09245706]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 6100 is [True, False, False, False, False, True]
Current timestep = 6101. State = [[-0.33944595  0.14116876]]. Action = [[ 0.00387786 -0.05539402  0.          0.72755265]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 6101 is [True, False, False, False, False, True]
State prediction error at timestep 6101 is 0.012
Human Feedback received at timestep 6101 of None
Current timestep = 6102. State = [[-0.33799252  0.14205292]]. Action = [[0.01286177 0.08453105 0.         0.48150015]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 6102 is [True, False, False, False, False, True]
State prediction error at timestep 6102 is 0.012
Human Feedback received at timestep 6102 of None
Current timestep = 6103. State = [[-0.3390262   0.14519002]]. Action = [[-0.03228123  0.04446822  0.         -0.34285736]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 6103 is [True, False, False, False, False, True]
Current timestep = 6104. State = [[-0.33589226  0.14722776]]. Action = [[ 0.08271068  0.03527532  0.         -0.5003012 ]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 6104 is [True, False, False, False, False, True]
Current timestep = 6105. State = [[-0.33378696  0.14560157]]. Action = [[-0.00772087 -0.03525587  0.         -0.37164307]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 6105 is [True, False, False, False, False, True]
Current timestep = 6106. State = [[-0.33365226  0.14412367]]. Action = [[-1.3550520e-03 -2.3467094e-04  0.0000000e+00  7.5987458e-01]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 6106 is [True, False, False, False, False, True]
Current timestep = 6107. State = [[-0.3349976   0.14294685]]. Action = [[-0.03283805 -0.0185137   0.          0.03133368]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 6107 is [True, False, False, False, False, True]
Current timestep = 6108. State = [[-0.33272266  0.1423205 ]]. Action = [[ 0.05896678  0.00026872  0.         -0.22054213]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 6108 is [True, False, False, False, False, True]
Current timestep = 6109. State = [[-0.33061704  0.14014174]]. Action = [[ 0.00080945 -0.03856084  0.         -0.14360553]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 6109 is [True, False, False, False, False, True]
State prediction error at timestep 6109 is 0.012
Human Feedback received at timestep 6109 of None
Current timestep = 6110. State = [[-0.33025107  0.13803922]]. Action = [[-0.00707806 -0.018194    0.          0.39514196]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 6110 is [True, False, False, False, False, True]
Current timestep = 6111. State = [[-0.33402473  0.1423854 ]]. Action = [[-0.07991386  0.09906053  0.         -0.7630505 ]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 6111 is [True, False, False, False, False, True]
Current timestep = 6112. State = [[-0.33701995  0.14830309]]. Action = [[-0.0061279   0.05618607  0.          0.6508924 ]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 6112 is [True, False, False, False, False, True]
State prediction error at timestep 6112 is 0.012
Human Feedback received at timestep 6112 of None
Current timestep = 6113. State = [[-0.34123927  0.14858176]]. Action = [[-0.06868456 -0.04198554  0.          0.3373599 ]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 6113 is [True, False, False, False, False, True]
State prediction error at timestep 6113 is 0.012
Human Feedback received at timestep 6113 of None
Current timestep = 6114. State = [[-0.34200102  0.15062065]]. Action = [[0.04044431 0.0515841  0.         0.6810572 ]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 6114 is [True, False, False, False, False, True]
State prediction error at timestep 6114 is 0.012
Human Feedback received at timestep 6114 of None
Current timestep = 6115. State = [[-0.3404405   0.15145674]]. Action = [[ 0.02325146 -0.0207134   0.         -0.4691217 ]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 6115 is [True, False, False, False, False, True]
Current timestep = 6116. State = [[-0.3394636   0.15271536]]. Action = [[ 0.01256107  0.02746504  0.         -0.19191217]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 6116 is [True, False, False, False, False, True]
State prediction error at timestep 6116 is 0.012
Human Feedback received at timestep 6116 of None
Current timestep = 6117. State = [[-0.33733672  0.15609078]]. Action = [[0.04262397 0.04622621 0.         0.23139608]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 6117 is [True, False, False, False, False, True]
State prediction error at timestep 6117 is 0.012
Human Feedback received at timestep 6117 of None
Current timestep = 6118. State = [[-0.3406649   0.15482745]]. Action = [[-0.09585742 -0.06901003  0.          0.5527694 ]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 6118 is [True, False, False, False, False, True]
State prediction error at timestep 6118 is 0.012
Human Feedback received at timestep 6118 of None
Current timestep = 6119. State = [[-0.34590176  0.15747985]]. Action = [[-0.03936334  0.07826584  0.          0.3657875 ]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 6119 is [True, False, False, False, False, True]
Current timestep = 6120. State = [[-0.35080117  0.1589772 ]]. Action = [[-0.0534142  -0.02666039  0.          0.30842495]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 6120 is [True, False, False, False, False, True]
Current timestep = 6121. State = [[-0.35426113  0.15617715]]. Action = [[-0.02176508 -0.05966709  0.         -0.27495587]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 6121 is [True, False, False, False, False, True]
Current timestep = 6122. State = [[-0.3537882   0.15652874]]. Action = [[ 0.03952102  0.0349327   0.         -0.86618936]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 6122 is [True, False, False, False, False, True]
State prediction error at timestep 6122 is 0.012
Human Feedback received at timestep 6122 of None
Current timestep = 6123. State = [[-0.3569733   0.15572129]]. Action = [[-0.07461087 -0.03902278  0.         -0.5308799 ]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 6123 is [True, False, False, False, False, True]
Current timestep = 6124. State = [[-0.3569956  0.1591122]]. Action = [[0.0672661  0.09464391 0.         0.24585366]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 6124 is [True, False, False, False, False, True]
State prediction error at timestep 6124 is 0.012
Human Feedback received at timestep 6124 of None
Current timestep = 6125. State = [[-0.35446128  0.15949331]]. Action = [[ 0.02643435 -0.04267353  0.         -0.81402993]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 6125 is [True, False, False, False, False, True]
Current timestep = 6126. State = [[-0.3550468   0.15975764]]. Action = [[-0.02672356  0.02682591  0.          0.8251307 ]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 6126 is [True, False, False, False, False, True]
Current timestep = 6127. State = [[-0.35230497  0.1602968 ]]. Action = [[ 0.07312038 -0.00374904  0.         -0.24974954]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 6127 is [True, False, False, False, False, True]
Current timestep = 6128. State = [[-0.3486312   0.16365391]]. Action = [[0.03323656 0.07622417 0.         0.2946993 ]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 6128 is [True, False, False, False, False, True]
Current timestep = 6129. State = [[-0.34384885  0.16398187]]. Action = [[ 0.07247254 -0.03122199  0.          0.04283679]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 6129 is [True, False, False, False, False, True]
Current timestep = 6130. State = [[-0.34391573  0.16259548]]. Action = [[-0.05780613 -0.01246064  0.         -0.7995942 ]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 6130 is [True, False, False, False, False, True]
Current timestep = 6131. State = [[-0.3459024   0.16283463]]. Action = [[-0.02195434  0.00347217  0.          0.990644  ]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 6131 is [True, False, False, False, False, True]
Current timestep = 6132. State = [[-0.34320113  0.16622677]]. Action = [[ 0.0625936   0.06227978  0.         -0.49582565]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 6132 is [True, False, False, False, False, True]
Current timestep = 6133. State = [[-0.34056222  0.16864772]]. Action = [[ 0.0100344   0.01156797  0.         -0.5422495 ]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 6133 is [True, False, False, False, False, True]
State prediction error at timestep 6133 is 0.012
Human Feedback received at timestep 6133 of None
Current timestep = 6134. State = [[-0.33533913  0.17168216]]. Action = [[ 0.08806559  0.05130797  0.         -0.93018454]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 6134 is [True, False, False, False, False, True]
State prediction error at timestep 6134 is 0.012
Human Feedback received at timestep 6134 of None
Current timestep = 6135. State = [[-0.3305194   0.17374708]]. Action = [[ 0.03244243  0.01201071  0.         -0.85306025]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 6135 is [True, False, False, False, False, True]
Current timestep = 6136. State = [[-0.32750568  0.172057  ]]. Action = [[ 0.01838215 -0.0499121   0.         -0.41413552]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 6136 is [True, False, False, False, False, True]
Current timestep = 6137. State = [[-0.3258973   0.16895378]]. Action = [[-0.00796489 -0.04743389  0.          0.33591497]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 6137 is [True, False, False, False, False, True]
Current timestep = 6138. State = [[-0.32349476  0.17117316]]. Action = [[ 0.02497605  0.06285777  0.         -0.7090401 ]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 6138 is [True, False, False, False, False, True]
State prediction error at timestep 6138 is 0.012
Human Feedback received at timestep 6138 of None
Current timestep = 6139. State = [[-0.31720018  0.16843586]]. Action = [[ 0.08625557 -0.09637996  0.          0.96402884]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 6139 is [True, False, False, False, False, True]
Current timestep = 6140. State = [[-0.30796763  0.1623221 ]]. Action = [[ 0.09821152 -0.06586055  0.          0.6228256 ]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 6140 is [True, False, False, False, False, True]
Current timestep = 6141. State = [[-0.28675553  0.03266111]]. Action = [[-0.030413   -0.03913185  0.         -0.06234926]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 6141 is [True, False, False, False, False, True]
State prediction error at timestep 6141 is 0.012
Human Feedback received at timestep 6141 of None
Current timestep = 6142. State = [[-0.27923235  0.03163109]]. Action = [[ 0.0824049  -0.05571177  0.         -0.8906258 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 6142 is [True, False, False, False, True, False]
Current timestep = 6143. State = [[-0.27273262  0.03509954]]. Action = [[ 0.05984161  0.08932234  0.         -0.56250226]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 6143 is [True, False, False, False, True, False]
Current timestep = 6144. State = [[-0.27194032  0.03459501]]. Action = [[-0.05076665 -0.07660887  0.          0.14098191]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 6144 is [True, False, False, False, True, False]
State prediction error at timestep 6144 is 0.012
Human Feedback received at timestep 6144 of None
Current timestep = 6145. State = [[-0.27389476  0.02981107]]. Action = [[-0.04946461 -0.06764708  0.          0.18515098]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 6145 is [True, False, False, False, True, False]
State prediction error at timestep 6145 is 0.012
Human Feedback received at timestep 6145 of None
Current timestep = 6146. State = [[-0.27418184  0.03156919]]. Action = [[-0.00807302  0.0698066   0.         -0.1681894 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 6146 is [True, False, False, False, True, False]
Current timestep = 6147. State = [[-0.26983932  0.03497418]]. Action = [[ 0.07729677  0.02240696  0.         -0.10550797]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 6147 is [True, False, False, False, True, False]
Current timestep = 6148. State = [[-0.2706438   0.03503523]]. Action = [[-0.08391857 -0.02120882  0.          0.05682385]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6148 is [True, False, False, False, True, False]
State prediction error at timestep 6148 is 0.012
Human Feedback received at timestep 6148 of None
Current timestep = 6149. State = [[-0.2706058   0.03213488]]. Action = [[ 0.03412124 -0.05213126  0.         -0.4912318 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 6149 is [True, False, False, False, True, False]
Current timestep = 6150. State = [[-0.2721505   0.03513172]]. Action = [[-0.05675313  0.09081455  0.          0.37472987]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 6150 is [True, False, False, False, True, False]
Current timestep = 6151. State = [[-0.27022848  0.03378053]]. Action = [[ 0.07021549 -0.08431479  0.          0.7755666 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 6151 is [True, False, False, False, True, False]
State prediction error at timestep 6151 is 0.012
Human Feedback received at timestep 6151 of None
Current timestep = 6152. State = [[-0.26711154  0.02832745]]. Action = [[ 0.01752441 -0.05873433  0.          0.4651227 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 6152 is [True, False, False, False, True, False]
Current timestep = 6153. State = [[-0.26821482  0.02197936]]. Action = [[-0.05083642 -0.08107629  0.         -0.75128096]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 6153 is [True, False, False, False, True, False]
Current timestep = 6154. State = [[-0.2697701   0.02057584]]. Action = [[-0.02033911  0.0347211   0.         -0.9189885 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 6154 is [True, False, False, False, True, False]
Current timestep = 6155. State = [[-0.26643652  0.02185242]]. Action = [[ 0.07749411  0.02270652  0.         -0.57650185]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 6155 is [True, False, False, False, True, False]
Current timestep = 6156. State = [[-0.2618443   0.02317833]]. Action = [[0.05176181 0.02762037 0.         0.33006465]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 6156 is [True, False, False, False, True, False]
State prediction error at timestep 6156 is 0.012
Human Feedback received at timestep 6156 of None
Current timestep = 6157. State = [[-0.26165587  0.02657238]]. Action = [[-0.02588703  0.0624863   0.         -0.9879257 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 6157 is [True, False, False, False, True, False]
Current timestep = 6158. State = [[-0.26319894  0.02799358]]. Action = [[-0.01557437 -0.0055999   0.          0.93701625]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 6158 is [True, False, False, False, True, False]
Current timestep = 6159. State = [[-0.26345733  0.03048115]]. Action = [[ 0.00831262  0.05006307  0.         -0.02736342]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 6159 is [True, False, False, False, True, False]
Current timestep = 6160. State = [[-0.26341498  0.03374011]]. Action = [[0.00531177 0.03029246 0.         0.380296  ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 6160 is [True, False, False, False, True, False]
Current timestep = 6161. State = [[-0.2622293   0.03318182]]. Action = [[ 0.02764767 -0.03940661  0.          0.7886077 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 6161 is [True, False, False, False, True, False]
Current timestep = 6162. State = [[-0.26069257  0.03587721]]. Action = [[0.01888158 0.06837303 0.         0.11731172]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 6162 is [True, False, False, False, True, False]
Current timestep = 6163. State = [[-0.25790283  0.0355091 ]]. Action = [[ 0.04859383 -0.05568729  0.          0.7257905 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 6163 is [True, False, False, False, True, False]
Current timestep = 6164. State = [[-0.25643817  0.03308504]]. Action = [[-0.0056524  -0.02474101  0.         -0.20628607]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 6164 is [True, False, False, False, True, False]
Current timestep = 6165. State = [[-0.25188053  0.03331899]]. Action = [[ 0.0848467   0.01801984  0.         -0.76941395]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 6165 is [True, False, False, False, True, False]
Current timestep = 6166. State = [[-0.24792331  0.03179952]]. Action = [[ 0.01841786 -0.04002682  0.         -0.56500095]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 6166 is [True, False, False, False, True, False]
Current timestep = 6167. State = [[-0.24629278  0.02889074]]. Action = [[-0.00213334 -0.03328887  0.          0.159652  ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 6167 is [True, False, False, False, True, False]
Current timestep = 6168. State = [[-0.24845113  0.03002189]]. Action = [[-0.06961451  0.04617292  0.          0.90440273]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 6168 is [True, False, False, False, True, False]
Current timestep = 6169. State = [[-0.2502398  0.0319066]]. Action = [[-0.01687592  0.00994738  0.         -0.9414334 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 6169 is [True, False, False, False, True, False]
Current timestep = 6170. State = [[-0.24916208  0.03175773]]. Action = [[ 0.02057864 -0.01338606  0.          0.78329515]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 6170 is [True, False, False, False, True, False]
Current timestep = 6171. State = [[-0.24708015  0.03008807]]. Action = [[ 0.01966961 -0.0267401   0.          0.02561283]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 6171 is [True, False, False, False, True, False]
Current timestep = 6172. State = [[-0.2507287   0.03283764]]. Action = [[-0.09861312  0.07022206  0.         -0.6311997 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 6172 is [True, False, False, False, True, False]
State prediction error at timestep 6172 is 0.012
Human Feedback received at timestep 6172 of None
Current timestep = 6173. State = [[-0.25107142  0.03064447]]. Action = [[ 0.04627638 -0.08991323  0.         -0.45315027]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 6173 is [True, False, False, False, True, False]
Current timestep = 6174. State = [[-0.2453816   0.02781738]]. Action = [[ 0.08859291 -0.00289383  0.         -0.9385656 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 6174 is [True, False, False, False, True, False]
Current timestep = 6175. State = [[-0.24221542  0.02245603]]. Action = [[ 0.00468657 -0.09401972  0.         -0.57309204]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 6175 is [True, False, False, False, True, False]
Current timestep = 6176. State = [[-0.2454918   0.01529887]]. Action = [[-0.09422584 -0.07630277  0.         -0.33984637]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 6176 is [True, False, False, False, True, False]
State prediction error at timestep 6176 is 0.012
Human Feedback received at timestep 6176 of None
Current timestep = 6177. State = [[-0.25040337  0.01002951]]. Action = [[-0.06922937 -0.04295721  0.         -0.86194086]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 6177 is [True, False, False, False, True, False]
State prediction error at timestep 6177 is 0.012
Human Feedback received at timestep 6177 of None
Current timestep = 6178. State = [[-0.25213927  0.01218284]]. Action = [[-0.00103215  0.08992427  0.         -0.78284365]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 6178 is [True, False, False, False, True, False]
State prediction error at timestep 6178 is 0.012
Human Feedback received at timestep 6178 of None
Current timestep = 6179. State = [[-0.25161204  0.01216373]]. Action = [[ 0.0201228  -0.03692938  0.          0.87088585]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 6179 is [True, False, False, False, True, False]
State prediction error at timestep 6179 is 0.012
Human Feedback received at timestep 6179 of None
Current timestep = 6180. State = [[-0.24856947  0.00707892]]. Action = [[ 0.05845665 -0.06644838  0.         -0.6215657 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 6180 is [True, False, False, False, True, False]
Current timestep = 6181. State = [[-0.2517802  0.0072754]]. Action = [[-0.09886194  0.06290212  0.         -0.09647816]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 6181 is [True, False, False, False, True, False]
Current timestep = 6182. State = [[-0.25845444  0.0079491 ]]. Action = [[-0.06451379 -0.00980059  0.          0.3541987 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 6182 is [True, False, False, False, True, False]
Current timestep = 6183. State = [[-0.25846362  0.00277397]]. Action = [[ 0.06414738 -0.0903137   0.         -0.4003359 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 6183 is [True, False, False, False, True, False]
Current timestep = 6184. State = [[-0.25816947  0.00419768]]. Action = [[-0.00767963  0.0978655   0.          0.8361511 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 6184 is [True, False, False, False, True, False]
State prediction error at timestep 6184 is 0.012
Human Feedback received at timestep 6184 of None
Current timestep = 6185. State = [[-0.2618222   0.00486746]]. Action = [[-0.05026772 -0.03430521  0.          0.15295887]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 6185 is [True, False, False, False, True, False]
Current timestep = 6186. State = [[-0.2640507   0.00389244]]. Action = [[ 0.00177747  0.0019737   0.         -0.4649908 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 6186 is [True, False, False, False, True, False]
State prediction error at timestep 6186 is 0.012
Human Feedback received at timestep 6186 of None
Current timestep = 6187. State = [[-0.26668656  0.00837833]]. Action = [[-0.03062221  0.09217422  0.          0.63882256]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 6187 is [True, False, False, False, True, False]
State prediction error at timestep 6187 is 0.012
Human Feedback received at timestep 6187 of None
Current timestep = 6188. State = [[-0.2682151   0.01062973]]. Action = [[ 0.01358247 -0.01315258  0.         -0.5134079 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 6188 is [True, False, False, False, True, False]
Current timestep = 6189. State = [[-0.26984826  0.00834295]]. Action = [[-0.01884469 -0.04615689  0.          0.5321045 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 6189 is [True, False, False, False, True, False]
Current timestep = 6190. State = [[-0.27183372  0.00666866]]. Action = [[-0.01508879 -0.00880517  0.          0.97523594]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 6190 is [True, False, False, False, True, False]
Current timestep = 6191. State = [[-0.27080405  0.01101615]]. Action = [[0.04765946 0.09197669 0.         0.9682586 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 6191 is [True, False, False, False, True, False]
State prediction error at timestep 6191 is 0.012
Human Feedback received at timestep 6191 of None
Current timestep = 6192. State = [[-0.26902428  0.01155276]]. Action = [[ 0.03049601 -0.04752886  0.         -0.97766846]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 6192 is [True, False, False, False, True, False]
Current timestep = 6193. State = [[-0.2675836   0.00596936]]. Action = [[ 0.01899312 -0.08809933  0.          0.42201114]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 6193 is [True, False, False, False, True, False]
Current timestep = 6194. State = [[-0.2674226   0.00726415]]. Action = [[-0.00604744  0.08459584  0.          0.7342304 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 6194 is [True, False, False, False, True, False]
Current timestep = 6195. State = [[-0.27181622  0.01029315]]. Action = [[-0.08391472  0.01365914  0.         -0.7980358 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 6195 is [True, False, False, False, True, False]
Current timestep = 6196. State = [[-0.27040613  0.01508935]]. Action = [[ 0.09263592  0.0803191   0.         -0.7073511 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 6196 is [True, False, False, False, True, False]
Current timestep = 6197. State = [[-0.267743    0.01557051]]. Action = [[ 0.00496097 -0.04631264  0.          0.7928195 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 6197 is [True, False, False, False, True, False]
Current timestep = 6198. State = [[-0.26709855  0.01590343]]. Action = [[-0.00155734  0.02371351  0.          0.9584031 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 6198 is [True, False, False, False, True, False]
Current timestep = 6199. State = [[-0.27080318  0.0160737 ]]. Action = [[-0.08739015 -0.01867817  0.         -0.18311894]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 6199 is [True, False, False, False, True, False]
State prediction error at timestep 6199 is 0.012
Human Feedback received at timestep 6199 of None
Current timestep = 6200. State = [[-0.27427244  0.01463436]]. Action = [[-0.0351216  -0.02921191  0.          0.44455504]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 6200 is [True, False, False, False, True, False]
Current timestep = 6201. State = [[-0.27642974  0.01713137]]. Action = [[-0.02867524  0.05904212  0.         -0.04466373]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 6201 is [True, False, False, False, True, False]
Current timestep = 6202. State = [[-0.27879465  0.01860132]]. Action = [[-0.02936385 -0.01536492  0.         -0.21864915]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 6202 is [True, False, False, False, True, False]
Current timestep = 6203. State = [[-0.28444684  0.01512311]]. Action = [[-0.09893999 -0.07270605  0.         -0.39969993]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 6203 is [True, False, False, False, True, False]
Current timestep = 6204. State = [[-0.29103178  0.00948708]]. Action = [[-0.08085094 -0.07533447  0.          0.74979675]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 6204 is [True, False, False, False, True, False]
Current timestep = 6205. State = [[-0.29491225  0.00224725]]. Action = [[-0.02979951 -0.09492152  0.         -0.72122675]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 6205 is [True, False, False, False, True, False]
Current timestep = 6206. State = [[-0.29644403 -0.00421218]]. Action = [[-0.00657381 -0.05654476  0.         -0.77229846]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 6206 is [True, False, False, False, True, False]
State prediction error at timestep 6206 is 0.012
Human Feedback received at timestep 6206 of None
Current timestep = 6207. State = [[-0.29856658 -0.00633327]]. Action = [[-0.0270564   0.0148126   0.         -0.90217394]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 6207 is [True, False, False, False, True, False]
Current timestep = 6208. State = [[-0.30451688 -0.00530916]]. Action = [[-0.08523595  0.03397127  0.         -0.45750993]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 6208 is [True, False, False, False, True, False]
Current timestep = 6209. State = [[-0.30686513 -0.0023191 ]]. Action = [[0.03655028 0.05434041 0.         0.43369806]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 6209 is [True, False, False, False, True, False]
Current timestep = 6210. State = [[-0.3034346   0.00068349]]. Action = [[0.0975218  0.03495171 0.         0.00080335]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 6210 is [True, False, False, False, True, False]
Current timestep = 6211. State = [[-0.30635354 -0.00076638]]. Action = [[-0.08675871 -0.04583672  0.          0.18202853]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 6211 is [True, False, False, False, True, False]
Current timestep = 6212. State = [[-0.31439343 -0.00491004]]. Action = [[-0.07545783 -0.05199505  0.         -0.31222737]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 6212 is [True, False, False, False, True, False]
State prediction error at timestep 6212 is 0.012
Human Feedback received at timestep 6212 of None
Current timestep = 6213. State = [[-0.31759167 -0.00676582]]. Action = [[ 0.02407473  0.00252075  0.         -0.14907163]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 6213 is [True, False, False, False, True, False]
Current timestep = 6214. State = [[-0.3226632  -0.00238582]]. Action = [[-0.06889139  0.09479778  0.          0.04879642]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 6214 is [True, False, False, False, True, False]
Current timestep = 6215. State = [[-0.3277516  0.0005979]]. Action = [[-0.01440131  0.00397857  0.         -0.79818827]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 6215 is [True, False, False, False, True, False]
State prediction error at timestep 6215 is 0.012
Human Feedback received at timestep 6215 of None
Current timestep = 6216. State = [[-0.3280576  -0.00132152]]. Action = [[ 0.05089775 -0.04669819  0.         -0.8252777 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 6216 is [True, False, False, False, True, False]
Current timestep = 6217. State = [[-0.32805672 -0.0075033 ]]. Action = [[ 0.00664268 -0.0951159   0.         -0.96953857]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 6217 is [True, False, False, False, True, False]
Current timestep = 6218. State = [[-0.32597065 -0.00810624]]. Action = [[ 0.06349047  0.05494779  0.         -0.43871182]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 6218 is [True, False, False, False, True, False]
Current timestep = 6219. State = [[-0.32091004 -0.00420609]]. Action = [[0.09371149 0.05404139 0.         0.84197474]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 6219 is [True, False, False, False, True, False]
Current timestep = 6220. State = [[-0.3147211  -0.00719862]]. Action = [[ 0.08973017 -0.09030335  0.         -0.21173853]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 6220 is [True, False, False, False, True, False]
Current timestep = 6221. State = [[-0.31317875 -0.01376361]]. Action = [[-0.02809793 -0.0705721   0.          0.684669  ]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 6221 is [True, False, False, False, True, False]
Current timestep = 6222. State = [[-0.31250814 -0.01596679]]. Action = [[0.01800247 0.01602868 0.         0.3112173 ]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 6222 is [True, False, False, False, True, False]
Current timestep = 6223. State = [[-0.31048197 -0.01530712]]. Action = [[0.02417994 0.02343072 0.         0.6097604 ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 6223 is [True, False, False, False, True, False]
Current timestep = 6224. State = [[-0.3137341  -0.01382251]]. Action = [[-0.09322328  0.03038607  0.          0.61488104]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 6224 is [True, False, False, False, True, False]
Current timestep = 6225. State = [[-0.31945086 -0.01797297]]. Action = [[-0.07688976 -0.09094995  0.         -0.36841762]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 6225 is [True, False, False, False, True, False]
Current timestep = 6226. State = [[-0.32396692 -0.02134084]]. Action = [[-0.0564163  -0.00291996  0.          0.58935356]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 6226 is [True, False, False, False, True, False]
Current timestep = 6227. State = [[-0.3289354  -0.02357142]]. Action = [[-0.07152561 -0.02864327  0.          0.3761505 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 6227 is [True, False, False, False, True, False]
Current timestep = 6228. State = [[-0.3306759  -0.02866319]]. Action = [[ 0.00748426 -0.07234607  0.         -0.32509452]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 6228 is [True, False, False, False, True, False]
Current timestep = 6229. State = [[-0.32959828 -0.03126316]]. Action = [[0.02484834 0.00697227 0.         0.13174844]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 6229 is [True, False, False, False, True, False]
Current timestep = 6230. State = [[-0.32982486 -0.03399448]]. Action = [[-0.01106759 -0.04136228  0.         -0.25318515]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 6230 is [True, False, False, False, True, False]
State prediction error at timestep 6230 is 0.012
Human Feedback received at timestep 6230 of None
Current timestep = 6231. State = [[-0.33192778 -0.03793358]]. Action = [[-0.03056814 -0.03681339  0.          0.3198583 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 6231 is [True, False, False, False, True, False]
State prediction error at timestep 6231 is 0.012
Human Feedback received at timestep 6231 of None
Current timestep = 6232. State = [[-0.32953966 -0.03809705]]. Action = [[0.07742908 0.0375253  0.         0.9129267 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 6232 is [True, False, False, False, True, False]
Current timestep = 6233. State = [[-0.32656363 -0.03262767]]. Action = [[ 0.03433584  0.09758116  0.         -0.45088845]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 6233 is [True, False, False, False, True, False]
Current timestep = 6234. State = [[-0.32943156 -0.02965035]]. Action = [[-0.06123975  0.00274514  0.          0.5563822 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 6234 is [True, False, False, False, True, False]
Current timestep = 6235. State = [[-0.32790485 -0.032994  ]]. Action = [[ 0.08649532 -0.0712284   0.         -0.92354643]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 6235 is [True, False, False, False, True, False]
State prediction error at timestep 6235 is 0.012
Human Feedback received at timestep 6235 of None
Current timestep = 6236. State = [[-0.3228447  -0.03994324]]. Action = [[ 0.05871377 -0.09186634  0.          0.7500423 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 6236 is [True, False, False, False, True, False]
Current timestep = 6237. State = [[-0.31732127 -0.04692047]]. Action = [[ 0.06601391 -0.07040433  0.          0.61636245]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 6237 is [True, False, False, False, True, False]
Current timestep = 6238. State = [[-0.31685308 -0.05027718]]. Action = [[-0.05293886 -0.00157629  0.         -0.8308563 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 6238 is [True, False, False, False, True, False]
State prediction error at timestep 6238 is 0.012
Human Feedback received at timestep 6238 of None
Current timestep = 6239. State = [[-0.32171693 -0.05092202]]. Action = [[-0.09001576  0.01566734  0.          0.28378594]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 6239 is [True, False, False, False, True, False]
Current timestep = 6240. State = [[-0.32539287 -0.0505861 ]]. Action = [[-0.03256103  0.02059369  0.          0.6838634 ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 6240 is [True, False, False, False, True, False]
Current timestep = 6241. State = [[-0.32541263 -0.047039  ]]. Action = [[ 0.02230641  0.0710476   0.         -0.20931065]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 6241 is [True, False, False, False, True, False]
Current timestep = 6242. State = [[-0.3214615  -0.04376498]]. Action = [[0.0804811  0.02098875 0.         0.198699  ]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 6242 is [True, False, False, False, True, False]
Current timestep = 6243. State = [[-0.31979096 -0.04704936]]. Action = [[-0.00254577 -0.08598194  0.         -0.5375518 ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 6243 is [True, False, False, False, True, False]
State prediction error at timestep 6243 is 0.012
Human Feedback received at timestep 6243 of None
Current timestep = 6244. State = [[-0.31838846 -0.04908497]]. Action = [[ 0.02934016  0.01159884  0.         -0.63533455]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 6244 is [True, False, False, False, True, False]
Current timestep = 6245. State = [[-0.32087156 -0.05248065]]. Action = [[-0.07044246 -0.06704078  0.         -0.08197826]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 6245 is [True, False, False, False, True, False]
Current timestep = 6246. State = [[-0.3178886  -0.05669808]]. Action = [[ 0.09957587 -0.03678998  0.         -0.383767  ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 6246 is [True, False, False, False, True, False]
Current timestep = 6247. State = [[-0.31551632 -0.05654355]]. Action = [[-0.02260242  0.0386911   0.          0.18606341]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 6247 is [True, False, False, False, True, False]
State prediction error at timestep 6247 is 0.012
Human Feedback received at timestep 6247 of None
Current timestep = 6248. State = [[-0.31524208 -0.05893633]]. Action = [[ 0.00301093 -0.05788904  0.         -0.34144032]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 6248 is [True, False, False, False, True, False]
Current timestep = 6249. State = [[-0.31754008 -0.06222745]]. Action = [[-0.06259782 -0.01697991  0.         -0.8077508 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 6249 is [True, False, False, False, True, False]
Current timestep = 6250. State = [[-0.31559566 -0.06407402]]. Action = [[ 0.06611937 -0.0091573   0.         -0.4662423 ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 6250 is [True, False, False, False, True, False]
State prediction error at timestep 6250 is 0.012
Human Feedback received at timestep 6250 of None
Current timestep = 6251. State = [[-0.311917   -0.06077687]]. Action = [[0.02945209 0.08210843 0.         0.536181  ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 6251 is [True, False, False, False, True, False]
Current timestep = 6252. State = [[-0.3139815  -0.05603731]]. Action = [[-0.06612114  0.0502113   0.          0.13574874]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 6252 is [True, False, False, False, True, False]
Current timestep = 6253. State = [[-0.31642902 -0.0575347 ]]. Action = [[-0.01617245 -0.06071394  0.         -0.3624611 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 6253 is [True, False, False, False, True, False]
Current timestep = 6254. State = [[-0.3181802  -0.06241388]]. Action = [[-0.02909181 -0.05900571  0.         -0.93850327]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 6254 is [True, False, False, False, True, False]
Current timestep = 6255. State = [[-0.3179483  -0.06548448]]. Action = [[ 0.01708716 -0.01691637  0.          0.3481406 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 6255 is [True, False, False, False, True, False]
Current timestep = 6256. State = [[-0.31701756 -0.06423669]]. Action = [[0.00787953 0.04262853 0.         0.796319  ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 6256 is [True, False, False, False, True, False]
Current timestep = 6257. State = [[-0.31660855 -0.06273182]]. Action = [[ 0.00456975  0.00695236  0.         -0.19374049]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 6257 is [True, False, False, False, True, False]
Current timestep = 6258. State = [[-0.31670785 -0.06593686]]. Action = [[-0.00377648 -0.0676681   0.         -0.96987116]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 6258 is [True, False, False, False, True, False]
Current timestep = 6259. State = [[-0.3200518  -0.06706815]]. Action = [[-0.06802681  0.02505676  0.         -0.25217748]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 6259 is [True, False, False, False, True, False]
Current timestep = 6260. State = [[-0.3266861  -0.06445683]]. Action = [[-0.09434136  0.04881623  0.          0.67874765]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 6260 is [True, False, False, False, True, False]
Current timestep = 6261. State = [[-0.33082685 -0.06512671]]. Action = [[-0.01848544 -0.03877011  0.         -0.68883014]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 6261 is [True, False, False, False, True, False]
Current timestep = 6262. State = [[-0.333597   -0.06973198]]. Action = [[-0.03128345 -0.06678113  0.         -0.48536587]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 6262 is [True, False, False, False, True, False]
Current timestep = 6263. State = [[-0.33157682 -0.07490532]]. Action = [[ 0.0743027  -0.05633023  0.          0.08366501]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 6263 is [True, False, False, False, True, False]
Current timestep = 6264. State = [[-0.3314608  -0.07791207]]. Action = [[-0.03012791 -0.01557576  0.         -0.71564776]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 6264 is [True, False, False, False, True, False]
State prediction error at timestep 6264 is 0.012
Human Feedback received at timestep 6264 of None
Current timestep = 6265. State = [[-0.33568656 -0.07815199]]. Action = [[-0.06118682  0.02058355  0.         -0.7787302 ]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 6265 is [True, False, False, False, True, False]
Current timestep = 6266. State = [[-0.33911362 -0.07548974]]. Action = [[-0.01864196  0.0549447   0.         -0.25900626]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 6266 is [True, False, False, False, True, False]
Current timestep = 6267. State = [[-0.3444557  -0.07178383]]. Action = [[-0.0748351   0.04681035  0.         -0.8629247 ]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 6267 is [True, False, False, False, True, False]
Current timestep = 6268. State = [[-0.35026202 -0.07256737]]. Action = [[-0.04912657 -0.04225132  0.          0.08879387]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 6268 is [True, False, False, False, True, False]
Current timestep = 6269. State = [[-0.35287648 -0.06960309]]. Action = [[0.00740029 0.0826514  0.         0.4961822 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 6269 is [True, False, False, False, True, False]
Current timestep = 6270. State = [[-0.35316852 -0.06612153]]. Action = [[ 0.02464278  0.00767714  0.         -0.36155236]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 6270 is [True, False, False, False, True, False]
Current timestep = 6271. State = [[-0.35477316 -0.0637136 ]]. Action = [[-0.01434688  0.02311953  0.         -0.95012814]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 6271 is [True, False, False, False, True, False]
Current timestep = 6272. State = [[-0.35216528 -0.05962687]]. Action = [[ 0.09450314  0.04568755  0.         -0.47092223]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 6272 is [True, False, False, False, True, False]
Current timestep = 6273. State = [[-0.3551271 -0.0607766]]. Action = [[-0.09947845 -0.08726983  0.         -0.7083583 ]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 6273 is [True, False, False, False, True, False]
Current timestep = 6274. State = [[-0.3578031 -0.0628816]]. Action = [[ 0.03025655 -0.00204601  0.         -0.5247445 ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 6274 is [True, False, False, False, True, False]
Current timestep = 6275. State = [[-0.35474318 -0.05860835]]. Action = [[0.07775531 0.07618804 0.         0.43659687]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 6275 is [True, False, False, False, True, False]
Current timestep = 6276. State = [[-0.35084546 -0.05045129]]. Action = [[0.06420439 0.0949316  0.         0.8161962 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 6276 is [True, False, False, False, True, False]
Current timestep = 6277. State = [[-0.3516404  -0.04368265]]. Action = [[-0.02572348  0.05174371  0.          0.03162301]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 6277 is [True, False, False, False, True, False]
Current timestep = 6278. State = [[-0.34944695 -0.04091619]]. Action = [[ 0.08535304 -0.00373361  0.          0.50082874]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 6278 is [True, False, False, False, True, False]
Current timestep = 6279. State = [[-0.34951156 -0.04418328]]. Action = [[-0.03802588 -0.08746345  0.         -0.1615653 ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 6279 is [True, False, False, False, True, False]
State prediction error at timestep 6279 is 0.012
Human Feedback received at timestep 6279 of None
Current timestep = 6280. State = [[-0.35399157 -0.04858925]]. Action = [[-0.0741415  -0.04471571  0.         -0.6498929 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 6280 is [True, False, False, False, True, False]
Current timestep = 6281. State = [[-0.3556763  -0.04603326]]. Action = [[0.00530891 0.08084292 0.         0.71776533]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 6281 is [True, False, False, False, True, False]
Current timestep = 6282. State = [[-0.35384592 -0.04672584]]. Action = [[ 0.03476851 -0.0685506   0.         -0.10437447]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 6282 is [True, False, False, False, True, False]
State prediction error at timestep 6282 is 0.012
Human Feedback received at timestep 6282 of None
Current timestep = 6283. State = [[-0.35500792 -0.04793622]]. Action = [[-0.05354815  0.01116367  0.         -0.05112237]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 6283 is [True, False, False, False, True, False]
Current timestep = 6284. State = [[-0.35799566 -0.04279206]]. Action = [[-0.0361803   0.09799253  0.         -0.04325342]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 6284 is [True, False, False, False, True, False]
State prediction error at timestep 6284 is 0.012
Human Feedback received at timestep 6284 of None
Current timestep = 6285. State = [[-0.36098698 -0.04353373]]. Action = [[-0.0409366  -0.08639272  0.          0.91334593]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 6285 is [True, False, False, False, True, False]
Current timestep = 6286. State = [[-0.35841253 -0.04239396]]. Action = [[0.08792204 0.07778836 0.         0.48212183]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 6286 is [True, False, False, False, True, False]
State prediction error at timestep 6286 is 0.012
Human Feedback received at timestep 6286 of None
Current timestep = 6287. State = [[-0.3522861  -0.03463853]]. Action = [[0.08980467 0.09345951 0.         0.7656554 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 6287 is [True, False, False, False, True, False]
Current timestep = 6288. State = [[-0.34581766 -0.03189357]]. Action = [[ 0.0934638  -0.02846745  0.         -0.4564098 ]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 6288 is [True, False, False, False, True, False]
State prediction error at timestep 6288 is 0.012
Human Feedback received at timestep 6288 of None
Current timestep = 6289. State = [[-0.34688142 -0.03454246]]. Action = [[-0.08639446 -0.05392551  0.          0.75097585]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 6289 is [True, False, False, False, True, False]
Current timestep = 6290. State = [[-0.34677514 -0.03352914]]. Action = [[ 0.06007647  0.04308432  0.         -0.7931258 ]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 6290 is [True, False, False, False, True, False]
Current timestep = 6291. State = [[-0.34275496 -0.02680232]]. Action = [[ 0.06621825  0.09596198  0.         -0.47849393]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 6291 is [True, False, False, False, True, False]
State prediction error at timestep 6291 is 0.012
Human Feedback received at timestep 6291 of None
Current timestep = 6292. State = [[-0.34198704 -0.01942579]]. Action = [[-0.0051573   0.07066088  0.         -0.4653358 ]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 6292 is [True, False, False, False, True, False]
Current timestep = 6293. State = [[-0.34231824 -0.01389852]]. Action = [[0.01164225 0.0443818  0.         0.9534515 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 6293 is [True, False, False, False, True, False]
Current timestep = 6294. State = [[-0.34399974 -0.01568472]]. Action = [[-0.03172322 -0.08876409  0.         -0.94476587]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 6294 is [True, False, False, False, True, False]
Current timestep = 6295. State = [[-0.3491221  -0.01559471]]. Action = [[-0.09240742  0.03575381  0.         -0.4183179 ]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 6295 is [True, False, False, False, True, False]
Current timestep = 6296. State = [[-0.34915897 -0.01050062]]. Action = [[0.05736347 0.06543469 0.         0.86257243]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 6296 is [True, False, False, False, True, False]
Current timestep = 6297. State = [[-0.34811512 -0.00815082]]. Action = [[-0.01021924 -0.01454429  0.          0.54712903]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 6297 is [True, False, False, False, True, False]
Current timestep = 6298. State = [[-0.34949392 -0.0075869 ]]. Action = [[-0.0312134  -0.00097685  0.          0.2963103 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 6298 is [True, False, False, False, True, False]
State prediction error at timestep 6298 is 0.012
Human Feedback received at timestep 6298 of None
Current timestep = 6299. State = [[-0.35033926 -0.01010733]]. Action = [[-0.00939259 -0.06373505  0.          0.6723733 ]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 6299 is [True, False, False, False, True, False]
Current timestep = 6300. State = [[-0.3518711 -0.0091025]]. Action = [[-0.03656225  0.04975373  0.          0.867857  ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 6300 is [True, False, False, False, True, False]
Current timestep = 6301. State = [[-0.35209426 -0.00866504]]. Action = [[ 0.010478   -0.02690936  0.          0.03935015]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 6301 is [True, False, False, False, True, False]
Current timestep = 6302. State = [[-0.35214528 -0.00421616]]. Action = [[-0.00700726  0.09623759  0.          0.358433  ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 6302 is [True, False, False, False, True, False]
Current timestep = 6303. State = [[-0.35302895 -0.00062644]]. Action = [[-0.00728913  0.00397358  0.          0.6175045 ]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 6303 is [True, False, False, False, True, False]
State prediction error at timestep 6303 is 0.012
Human Feedback received at timestep 6303 of None
Current timestep = 6304. State = [[-0.34925094 -0.00097834]]. Action = [[ 0.08933049 -0.02459969  0.         -0.11288834]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 6304 is [True, False, False, False, True, False]
State prediction error at timestep 6304 is 0.012
Human Feedback received at timestep 6304 of None
Current timestep = 6305. State = [[-0.34467256 -0.00284404]]. Action = [[ 0.04484764 -0.03083508  0.          0.30246246]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 6305 is [True, False, False, False, True, False]
Current timestep = 6306. State = [[-0.33895835 -0.00412235]]. Action = [[ 0.08201426 -0.00885192  0.         -0.41129303]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 6306 is [True, False, False, False, True, False]
Current timestep = 6307. State = [[-0.33778477 -0.00909328]]. Action = [[-0.04242713 -0.09099759  0.          0.4001274 ]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 6307 is [True, False, False, False, True, False]
Current timestep = 6308. State = [[-0.3354264  -0.01539621]]. Action = [[ 0.0478025  -0.06265057  0.         -0.5687451 ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 6308 is [True, False, False, False, True, False]
State prediction error at timestep 6308 is 0.012
Human Feedback received at timestep 6308 of None
Current timestep = 6309. State = [[-0.3344538  -0.01607547]]. Action = [[-0.02933054  0.0433738   0.          0.74580884]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 6309 is [True, False, False, False, True, False]
Current timestep = 6310. State = [[-0.3374196  -0.01599013]]. Action = [[-0.06560335 -0.00442322  0.          0.39979577]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 6310 is [True, False, False, False, True, False]
Current timestep = 6311. State = [[-0.33942586 -0.01710682]]. Action = [[-0.01803026 -0.00568371  0.          0.6956427 ]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 6311 is [True, False, False, False, True, False]
Current timestep = 6312. State = [[-0.33717874 -0.01528196]]. Action = [[ 0.05290242  0.0512163   0.         -0.2695428 ]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 6312 is [True, False, False, False, True, False]
Current timestep = 6313. State = [[-0.339679   -0.00994842]]. Action = [[-0.07827191  0.08061891  0.         -0.13518053]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 6313 is [True, False, False, False, True, False]
Current timestep = 6314. State = [[-0.34623578 -0.01122157]]. Action = [[-0.08218753 -0.08115593  0.          0.6992345 ]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 6314 is [True, False, False, False, True, False]
Current timestep = 6315. State = [[-0.34698683 -0.01210804]]. Action = [[0.04767012 0.02703197 0.         0.38734198]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 6315 is [True, False, False, False, True, False]
Current timestep = 6316. State = [[-0.34391862 -0.01405937]]. Action = [[ 0.05268117 -0.05505961  0.         -0.59547853]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 6316 is [True, False, False, False, True, False]
Current timestep = 6317. State = [[-0.34663406 -0.02038795]]. Action = [[-0.08736429 -0.09212847  0.         -0.6525456 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 6317 is [True, False, False, False, True, False]
Current timestep = 6318. State = [[-0.34828326 -0.01968987]]. Action = [[0.02729232 0.08690219 0.         0.25404036]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 6318 is [True, False, False, False, True, False]
Current timestep = 6319. State = [[-0.35275388 -0.01695783]]. Action = [[-0.08762521  0.00883281  0.         -0.7534995 ]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 6319 is [True, False, False, False, True, False]
Current timestep = 6320. State = [[-0.35575318 -0.0140897 ]]. Action = [[ 0.0099813   0.04763698  0.         -0.90151036]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 6320 is [True, False, False, False, True, False]
Current timestep = 6321. State = [[-0.3583894  -0.01172489]]. Action = [[-0.02970698  0.01225947  0.          0.5401454 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 6321 is [True, False, False, False, True, False]
State prediction error at timestep 6321 is 0.012
Human Feedback received at timestep 6321 of None
Current timestep = 6322. State = [[-0.36067492 -0.01477213]]. Action = [[-0.00631596 -0.07583889  0.          0.81917334]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 6322 is [True, False, False, False, True, False]
State prediction error at timestep 6322 is 0.012
Human Feedback received at timestep 6322 of None
Current timestep = 6323. State = [[-0.3628509 -0.0173594]]. Action = [[-0.02308712 -0.00790621  0.         -0.17108214]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 6323 is [True, False, False, False, True, False]
Current timestep = 6324. State = [[-0.36107838 -0.01717521]]. Action = [[0.06791457 0.01197207 0.         0.88313544]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 6324 is [True, False, False, False, True, False]
Current timestep = 6325. State = [[-0.36442053 -0.0123793 ]]. Action = [[-0.09273234  0.089638    0.         -0.98727196]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 6325 is [True, False, False, False, True, False]
Current timestep = 6326. State = [[-0.37112826 -0.01155347]]. Action = [[-0.05551083 -0.04097644  0.         -0.55831534]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 6326 is [True, False, False, False, True, False]
Current timestep = 6327. State = [[-0.37467653 -0.00905173]]. Action = [[-0.00449534  0.06671496  0.         -0.16464198]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 6327 is [True, False, False, False, True, False]
Current timestep = 6328. State = [[-0.37593037 -0.00408184]]. Action = [[ 0.01933168  0.05019464  0.         -0.35481924]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 6328 is [True, False, False, False, True, False]
State prediction error at timestep 6328 is 0.012
Human Feedback received at timestep 6328 of None
Current timestep = 6329. State = [[-0.37735277 -0.00174091]]. Action = [[ 0.         0.         0.        -0.9897179]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 6329 is [True, False, False, False, True, False]
State prediction error at timestep 6329 is 0.012
Human Feedback received at timestep 6329 of None
Current timestep = 6330. State = [[-0.3757115   0.00382689]]. Action = [[ 0.07226943  0.09350797  0.         -0.25744247]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 6330 is [True, False, False, False, True, False]
Current timestep = 6331. State = [[-0.37336934  0.0098187 ]]. Action = [[ 0.04952557  0.04437698  0.         -0.9200064 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 6331 is [True, False, False, False, True, False]
Current timestep = 6332. State = [[-0.37352076  0.0123235 ]]. Action = [[ 0.          0.          0.         -0.19664943]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 6332 is [True, False, False, False, True, False]
Current timestep = 6333. State = [[-0.3743759   0.01005989]]. Action = [[-0.00073279 -0.06696217  0.          0.33809388]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 6333 is [True, False, False, False, True, False]
Current timestep = 6334. State = [[-0.37511924  0.0113248 ]]. Action = [[-0.00876461  0.04889854  0.          0.8518841 ]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 6334 is [True, False, False, False, True, False]
Current timestep = 6335. State = [[-0.3755673   0.01344135]]. Action = [[0.         0.         0.         0.64768994]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 6335 is [True, False, False, False, True, False]
Current timestep = 6336. State = [[-0.3738799   0.00917511]]. Action = [[ 0.02906983 -0.09984543  0.         -0.724734  ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 6336 is [True, False, False, False, True, False]
State prediction error at timestep 6336 is 0.012
Human Feedback received at timestep 6336 of None
Current timestep = 6337. State = [[-0.37225527  0.00645172]]. Action = [[0.         0.         0.         0.20258677]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 6337 is [True, False, False, False, True, False]
State prediction error at timestep 6337 is 0.012
Human Feedback received at timestep 6337 of None
Current timestep = 6338. State = [[-0.3735843   0.00869366]]. Action = [[-0.04471512  0.04766989  0.          0.5122757 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 6338 is [True, False, False, False, True, False]
State prediction error at timestep 6338 is 0.012
Human Feedback received at timestep 6338 of None
Current timestep = 6339. State = [[-0.372226    0.00668939]]. Action = [[ 0.0398413  -0.06851687  0.          0.28481603]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 6339 is [True, False, False, False, True, False]
Current timestep = 6340. State = [[-0.37062937  0.0031937 ]]. Action = [[-0.00634454 -0.02576671  0.          0.6090872 ]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 6340 is [True, False, False, False, True, False]
Current timestep = 6341. State = [[-3.6961895e-01  2.7346090e-04]]. Action = [[ 0.00503622 -0.03135984  0.          0.47736657]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 6341 is [True, False, False, False, True, False]
Current timestep = 6342. State = [[-0.36416265  0.00211702]]. Action = [[0.09791806 0.068345   0.         0.96265054]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 6342 is [True, False, False, False, True, False]
Current timestep = 6343. State = [[-0.3627805   0.00475358]]. Action = [[-0.03502219  0.02136789  0.         -0.63833696]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 6343 is [True, False, False, False, True, False]
Current timestep = 6344. State = [[-0.36568028  0.00866828]]. Action = [[-0.04274074  0.06734034  0.         -0.8245172 ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 6344 is [True, False, False, False, True, False]
State prediction error at timestep 6344 is 0.012
Human Feedback received at timestep 6344 of None
Current timestep = 6345. State = [[-0.36802375  0.01210727]]. Action = [[-0.01541281  0.0248837   0.         -0.17267698]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 6345 is [True, False, False, False, True, False]
State prediction error at timestep 6345 is 0.012
Human Feedback received at timestep 6345 of None
Current timestep = 6346. State = [[-0.3645975  0.0146452]]. Action = [[ 0.09455092  0.02491979  0.         -0.5874639 ]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 6346 is [True, False, False, False, True, False]
State prediction error at timestep 6346 is 0.012
Human Feedback received at timestep 6346 of None
Current timestep = 6347. State = [[-0.35924676  0.01354206]]. Action = [[ 0.06589331 -0.04743968  0.          0.02123523]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 6347 is [True, False, False, False, True, False]
Current timestep = 6348. State = [[-0.3564862   0.01520925]]. Action = [[ 0.01407997  0.05340024  0.         -0.56039673]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 6348 is [True, False, False, False, True, False]
Current timestep = 6349. State = [[-0.35546854  0.01998174]]. Action = [[ 0.01034107  0.05632763  0.         -0.9390453 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 6349 is [True, False, False, False, True, False]
Current timestep = 6350. State = [[-0.35202911  0.02217004]]. Action = [[ 0.06311514 -0.00345588  0.         -0.1032601 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 6350 is [True, False, False, False, True, False]
State prediction error at timestep 6350 is 0.012
Human Feedback received at timestep 6350 of None
Current timestep = 6351. State = [[-0.34606385  0.02720696]]. Action = [[ 0.08252735  0.08803038  0.         -0.16748768]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 6351 is [True, False, False, False, True, False]
Current timestep = 6352. State = [[-0.3477528   0.03299161]]. Action = [[-0.09318146  0.04760542  0.          0.53375673]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 6352 is [True, False, False, False, True, False]
Current timestep = 6353. State = [[-0.34733328  0.03566548]]. Action = [[ 0.06733011  0.0014424   0.         -0.36339867]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 6353 is [True, False, False, False, True, False]
Current timestep = 6354. State = [[-0.3454311   0.04120546]]. Action = [[0.00611146 0.08545902 0.         0.35674262]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 6354 is [True, False, False, False, True, False]
State prediction error at timestep 6354 is 0.012
Human Feedback received at timestep 6354 of None
Current timestep = 6355. State = [[-0.34097221  0.04137188]]. Action = [[ 0.08527043 -0.07361645  0.          0.7615776 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 6355 is [True, False, False, False, True, False]
Current timestep = 6356. State = [[-0.34193042  0.04426866]]. Action = [[-0.08302237  0.07609677  0.          0.65591717]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 6356 is [True, False, False, False, True, False]
State prediction error at timestep 6356 is 0.012
Human Feedback received at timestep 6356 of None
Current timestep = 6357. State = [[-0.34154153  0.04430512]]. Action = [[ 0.044557   -0.06753413  0.          0.02313828]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 6357 is [True, False, False, False, True, False]
Current timestep = 6358. State = [[-0.335529    0.04450431]]. Action = [[ 0.08591216  0.02233484  0.         -0.8638053 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 6358 is [True, False, False, False, True, False]
Current timestep = 6359. State = [[-0.3359114   0.04743344]]. Action = [[-0.07882944  0.03215053  0.          0.44815052]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 6359 is [True, False, False, False, True, False]
Current timestep = 6360. State = [[-0.33780524  0.05208439]]. Action = [[-0.00272618  0.05719031  0.         -0.53387666]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 6360 is [True, False, False, False, True, False]
Current timestep = 6361. State = [[-0.34130204  0.0565696 ]]. Action = [[-0.06640874  0.03693994  0.          0.37931395]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 6361 is [True, False, False, False, True, False]
Current timestep = 6362. State = [[-0.34109047  0.06259987]]. Action = [[ 0.05187552  0.07686279  0.         -0.6719732 ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 6362 is [True, False, False, False, True, False]
Current timestep = 6363. State = [[-0.3397152   0.07051709]]. Action = [[ 0.01527785  0.09196647  0.         -0.16742331]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 6363 is [True, False, False, False, True, False]
State prediction error at timestep 6363 is 0.012
Human Feedback received at timestep 6363 of None
Current timestep = 6364. State = [[-0.34483275  0.07847854]]. Action = [[-0.09782241  0.0778578   0.         -0.26510882]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 6364 is [True, False, False, False, True, False]
Current timestep = 6365. State = [[-0.34580445  0.08270033]]. Action = [[0.0593233 0.0048653 0.        0.7492292]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 6365 is [True, False, False, False, True, False]
Current timestep = 6366. State = [[-0.3458248   0.08394062]]. Action = [[-0.01638573 -0.01278806  0.          0.2425251 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 6366 is [True, False, False, False, True, False]
State prediction error at timestep 6366 is 0.012
Human Feedback received at timestep 6366 of None
Current timestep = 6367. State = [[-0.34982932  0.08649597]]. Action = [[-0.06538005  0.02423682  0.          0.2731732 ]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 6367 is [True, False, False, False, True, False]
State prediction error at timestep 6367 is 0.012
Human Feedback received at timestep 6367 of None
Current timestep = 6368. State = [[-0.34873363  0.08961849]]. Action = [[ 0.07208767  0.01694828  0.         -0.9931842 ]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 6368 is [True, False, False, False, True, False]
Current timestep = 6369. State = [[-0.34256056  0.09599388]]. Action = [[ 0.09704583  0.09483662  0.         -0.831758  ]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 6369 is [True, False, False, False, True, False]
Current timestep = 6370. State = [[-0.34427464  0.10425164]]. Action = [[-0.08822694  0.08664905  0.         -0.422709  ]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 6370 is [True, False, False, False, True, False]
Current timestep = 6371. State = [[-0.34811062  0.10487241]]. Action = [[-0.01496432 -0.07133658  0.          0.9818455 ]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 6371 is [True, False, False, False, True, False]
Current timestep = 6372. State = [[-0.3495103  0.0999394]]. Action = [[-0.01333672 -0.09004666  0.         -0.48599792]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 6372 is [True, False, False, False, True, False]
Current timestep = 6373. State = [[-0.34898153  0.09347643]]. Action = [[ 0.01065107 -0.09778702  0.         -0.5442876 ]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 6373 is [True, False, False, False, True, False]
Current timestep = 6374. State = [[-0.35125285  0.09516703]]. Action = [[-0.06032908  0.09009584  0.          0.49263668]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 6374 is [True, False, False, False, True, False]
Current timestep = 6375. State = [[-0.3499446   0.09894875]]. Action = [[0.06601899 0.01834154 0.         0.33312154]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 6375 is [True, False, False, False, True, False]
Current timestep = 6376. State = [[-0.35236108  0.0967525 ]]. Action = [[-0.08914968 -0.06671095  0.         -0.6611051 ]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 6376 is [True, False, False, False, True, False]
State prediction error at timestep 6376 is 0.012
Human Feedback received at timestep 6376 of None
Current timestep = 6377. State = [[-0.35242566  0.09709535]]. Action = [[ 0.0617382   0.04464909  0.         -0.86874324]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 6377 is [True, False, False, False, True, False]
State prediction error at timestep 6377 is 0.012
Human Feedback received at timestep 6377 of None
Current timestep = 6378. State = [[-0.3524341   0.09508889]]. Action = [[-0.03118955 -0.06330071  0.          0.87500274]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 6378 is [True, False, False, False, True, False]
Current timestep = 6379. State = [[-0.35481033  0.08996511]]. Action = [[-0.03617255 -0.06736413  0.         -0.8588029 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 6379 is [True, False, False, False, True, False]
Current timestep = 6380. State = [[-0.35750964  0.09018451]]. Action = [[-0.03457216  0.05033683  0.          0.3572271 ]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 6380 is [True, False, False, False, True, False]
Current timestep = 6381. State = [[-0.35454592  0.09294089]]. Action = [[0.0941915 0.0390522 0.        0.8657875]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 6381 is [True, False, False, False, True, False]
Current timestep = 6382. State = [[-0.3547474   0.09689921]]. Action = [[-0.04367154  0.06808352  0.          0.47567058]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 6382 is [True, False, False, False, True, False]
Current timestep = 6383. State = [[-0.3557416   0.10059124]]. Action = [[0.02044211 0.03888308 0.         0.04233682]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 6383 is [True, False, False, False, True, False]
State prediction error at timestep 6383 is 0.012
Human Feedback received at timestep 6383 of None
Current timestep = 6384. State = [[-0.35818118  0.10504958]]. Action = [[-0.03964037  0.0658732   0.          0.5539489 ]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 6384 is [True, False, False, False, True, False]
Current timestep = 6385. State = [[-0.35812744  0.10389418]]. Action = [[ 0.04227792 -0.06900412  0.          0.03776968]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 6385 is [True, False, False, False, True, False]
State prediction error at timestep 6385 is 0.012
Human Feedback received at timestep 6385 of None
Current timestep = 6386. State = [[-0.35501713  0.09936894]]. Action = [[ 0.0472161  -0.05596728  0.          0.7014735 ]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 6386 is [True, False, False, False, True, False]
State prediction error at timestep 6386 is 0.012
Human Feedback received at timestep 6386 of None
Current timestep = 6387. State = [[-0.35460958  0.09761997]]. Action = [[-0.02181356 -0.00145815  0.         -0.26601088]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 6387 is [True, False, False, False, True, False]
Current timestep = 6388. State = [[-0.3563791   0.09279706]]. Action = [[-0.0329062  -0.09885436  0.          0.78898096]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 6388 is [True, False, False, False, True, False]
Current timestep = 6389. State = [[-0.35679838  0.08890205]]. Action = [[-0.00314888 -0.022545    0.          0.8790939 ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 6389 is [True, False, False, False, True, False]
Current timestep = 6390. State = [[-0.35272583  0.08775119]]. Action = [[ 0.07557786  0.00215324  0.         -0.53392875]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 6390 is [True, False, False, False, True, False]
Current timestep = 6391. State = [[-0.34892538  0.0855801 ]]. Action = [[ 0.02365549 -0.02720146  0.          0.9829719 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 6391 is [True, False, False, False, True, False]
Current timestep = 6392. State = [[-0.3486709   0.08140301]]. Action = [[-0.0271771  -0.05293708  0.          0.92744446]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 6392 is [True, False, False, False, True, False]
Current timestep = 6393. State = [[-0.34456384  0.07519152]]. Action = [[ 0.07895049 -0.07550657  0.          0.97965   ]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 6393 is [True, False, False, False, True, False]
Current timestep = 6394. State = [[-0.34426996  0.07267898]]. Action = [[-0.06068873  0.01890401  0.         -0.36911893]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 6394 is [True, False, False, False, True, False]
Current timestep = 6395. State = [[-0.34591332  0.06911459]]. Action = [[-0.01947049 -0.0612503   0.          0.97080207]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 6395 is [True, False, False, False, True, False]
Current timestep = 6396. State = [[-0.34241176  0.06349268]]. Action = [[ 0.06852212 -0.05450493  0.          0.17606914]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 6396 is [True, False, False, False, True, False]
Current timestep = 6397. State = [[-0.3440156   0.05949795]]. Action = [[-0.08993642 -0.02101328  0.         -0.34854925]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 6397 is [True, False, False, False, True, False]
Current timestep = 6398. State = [[-0.34810212  0.05611131]]. Action = [[-0.04207258 -0.03249862  0.         -0.76244247]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 6398 is [True, False, False, False, True, False]
Current timestep = 6399. State = [[-0.35020816  0.05835109]]. Action = [[-0.01068895  0.08739535  0.         -0.64132255]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 6399 is [True, False, False, False, True, False]
Current timestep = 6400. State = [[-0.35361043  0.06341708]]. Action = [[-0.0379246   0.06953185  0.          0.42902482]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 6400 is [True, False, False, False, True, False]
Current timestep = 6401. State = [[-0.3532668   0.06592607]]. Action = [[0.06351324 0.01808431 0.         0.45895994]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 6401 is [True, False, False, False, True, False]
Current timestep = 6402. State = [[-0.35618895  0.07096376]]. Action = [[-0.05711448  0.09608484  0.         -0.6218601 ]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 6402 is [True, False, False, False, True, False]
Current timestep = 6403. State = [[-0.36401772  0.0744621 ]]. Action = [[-0.08900823  0.00991111  0.         -0.25460374]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 6403 is [True, False, False, False, True, False]
State prediction error at timestep 6403 is 0.012
Human Feedback received at timestep 6403 of None
Current timestep = 6404. State = [[-0.3675778   0.07712841]]. Action = [[ 0.02022381  0.03297736  0.         -0.62574255]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 6404 is [True, False, False, False, True, False]
Current timestep = 6405. State = [[-0.37024638  0.08001173]]. Action = [[-0.02303839  0.02530391  0.         -0.6699524 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 6405 is [True, False, False, False, True, False]
Current timestep = 6406. State = [[-0.37262163  0.0815939 ]]. Action = [[ 0.         0.         0.        -0.6157118]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 6406 is [True, False, False, False, True, False]
Current timestep = 6407. State = [[-0.3746112   0.08735874]]. Action = [[-0.00454686  0.0992497   0.         -0.18672323]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 6407 is [True, False, False, False, True, False]
Current timestep = 6408. State = [[-0.37462822  0.09393052]]. Action = [[0.04221819 0.0588557  0.         0.9465035 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 6408 is [True, False, False, False, True, False]
Current timestep = 6409. State = [[-0.37504488  0.0966588 ]]. Action = [[ 0.         0.         0.        -0.6416609]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 6409 is [True, False, False, False, True, False]
Current timestep = 6410. State = [[-0.37148592  0.0938034 ]]. Action = [[ 0.0893948  -0.07919799  0.          0.4964093 ]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 6410 is [True, False, False, False, True, False]
Current timestep = 6411. State = [[-0.36907843  0.09226516]]. Action = [[0.        0.        0.        0.4531716]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 6411 is [True, False, False, False, True, False]
State prediction error at timestep 6411 is 0.012
Human Feedback received at timestep 6411 of None
Current timestep = 6412. State = [[-0.36909315  0.09475864]]. Action = [[-0.00636177  0.03673247  0.         -0.07618231]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 6412 is [True, False, False, False, True, False]
Current timestep = 6413. State = [[-0.37240142  0.09651116]]. Action = [[-0.07000636 -0.00419758  0.          0.22648895]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 6413 is [True, False, False, False, True, False]
Current timestep = 6414. State = [[-0.37602037  0.09565523]]. Action = [[-0.04317896 -0.03802653  0.          0.7133665 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 6414 is [True, False, False, False, True, False]
Current timestep = 6415. State = [[-0.37483147  0.09232781]]. Action = [[ 0.04029716 -0.06039757  0.          0.12938023]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 6415 is [True, False, False, False, True, False]
Current timestep = 6416. State = [[-0.37312254  0.09074646]]. Action = [[0.        0.        0.        0.3427322]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 6416 is [True, False, False, False, True, False]
Current timestep = 6417. State = [[-0.37250084  0.09066737]]. Action = [[ 0.          0.          0.         -0.73890173]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 6417 is [True, False, False, False, True, False]
State prediction error at timestep 6417 is 0.012
Human Feedback received at timestep 6417 of None
Current timestep = 6418. State = [[-0.3678772   0.09024303]]. Action = [[ 0.0850135  -0.00304469  0.         -0.54335755]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 6418 is [True, False, False, False, True, False]
Current timestep = 6419. State = [[-0.36101592  0.08641281]]. Action = [[ 0.07849436 -0.06145165  0.         -0.2744981 ]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 6419 is [True, False, False, False, True, False]
Current timestep = 6420. State = [[-0.3529498   0.08627117]]. Action = [[ 0.09802557  0.05330367  0.         -0.77205384]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 6420 is [True, False, False, False, True, False]
Current timestep = 6421. State = [[-0.3469119   0.09116674]]. Action = [[0.04775029 0.09222265 0.         0.42215753]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 6421 is [True, False, False, False, True, False]
Current timestep = 6422. State = [[-0.3444207   0.08880297]]. Action = [[-0.00185203 -0.09199244  0.          0.37736   ]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 6422 is [True, False, False, False, True, False]
Current timestep = 6423. State = [[-0.33954394  0.08237941]]. Action = [[ 0.06816513 -0.06819652  0.          0.40333366]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 6423 is [True, False, False, False, True, False]
Current timestep = 6424. State = [[-0.33539933  0.0762521 ]]. Action = [[ 0.00824889 -0.06584786  0.         -0.1278944 ]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 6424 is [True, False, False, False, True, False]
Current timestep = 6425. State = [[-0.33585137  0.07231558]]. Action = [[-0.05835226 -0.02491418  0.          0.7609948 ]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 6425 is [True, False, False, False, True, False]
State prediction error at timestep 6425 is 0.012
Human Feedback received at timestep 6425 of None
Current timestep = 6426. State = [[-0.33321607  0.06768245]]. Action = [[ 0.04855023 -0.0610031   0.         -0.49262357]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 6426 is [True, False, False, False, True, False]
Current timestep = 6427. State = [[-0.3312865   0.06338278]]. Action = [[-0.02229937 -0.02853463  0.          0.447523  ]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 6427 is [True, False, False, False, True, False]
State prediction error at timestep 6427 is 0.012
Human Feedback received at timestep 6427 of None
Current timestep = 6428. State = [[-0.3263441   0.06190865]]. Action = [[ 0.0844465   0.01369462  0.         -0.9903899 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 6428 is [True, False, False, False, True, False]
State prediction error at timestep 6428 is 0.012
Human Feedback received at timestep 6428 of None
Current timestep = 6429. State = [[-0.32412368  0.05944126]]. Action = [[-0.02871395 -0.03060389  0.          0.7290468 ]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 6429 is [True, False, False, False, True, False]
Current timestep = 6430. State = [[-0.32441267  0.06090534]]. Action = [[-0.01210906  0.06835025  0.         -0.7275472 ]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 6430 is [True, False, False, False, True, False]
Current timestep = 6431. State = [[-0.32923514  0.06530981]]. Action = [[-0.09723851  0.0631957   0.         -0.03851432]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 6431 is [True, False, False, False, True, False]
Current timestep = 6432. State = [[-0.33633178  0.06498601]]. Action = [[-0.08761815 -0.04508186  0.         -0.02818042]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 6432 is [True, False, False, False, True, False]
Current timestep = 6433. State = [[-0.33973062  0.06876381]]. Action = [[-0.00254163  0.09717914  0.          0.68923414]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 6433 is [True, False, False, False, True, False]
Current timestep = 6434. State = [[-0.3423959   0.07046789]]. Action = [[-0.02649287 -0.02871221  0.         -0.08671093]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 6434 is [True, False, False, False, True, False]
Current timestep = 6435. State = [[-0.34804517  0.06969468]]. Action = [[-0.07953046 -0.01346313  0.         -0.26469642]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 6435 is [True, False, False, False, True, False]
State prediction error at timestep 6435 is 0.012
Human Feedback received at timestep 6435 of None
Current timestep = 6436. State = [[-0.34823453  0.07284903]]. Action = [[0.0751695  0.06306473 0.         0.7396594 ]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 6436 is [True, False, False, False, True, False]
Current timestep = 6437. State = [[-0.3464379   0.07869466]]. Action = [[0.0270453  0.07418867 0.         0.08026922]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 6437 is [True, False, False, False, True, False]
Current timestep = 6438. State = [[-0.3515437   0.08171006]]. Action = [[-0.09930597  0.00165452  0.         -0.19261944]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 6438 is [True, False, False, False, True, False]
Current timestep = 6439. State = [[-0.35388777  0.0859106 ]]. Action = [[ 0.04267579  0.06539651  0.         -0.83888096]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 6439 is [True, False, False, False, True, False]
Current timestep = 6440. State = [[-0.354018    0.08902112]]. Action = [[0.00696769 0.00903585 0.         0.26133382]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 6440 is [True, False, False, False, True, False]
Current timestep = 6441. State = [[-0.3571093  0.0883728]]. Action = [[-0.04721513 -0.03972525  0.          0.22315633]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 6441 is [True, False, False, False, True, False]
Current timestep = 6442. State = [[-0.35735044  0.09011107]]. Action = [[ 0.03804397  0.03840765  0.         -0.03349441]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 6442 is [True, False, False, False, True, False]
Current timestep = 6443. State = [[-0.35281402  0.0937362 ]]. Action = [[0.08815356 0.04002305 0.         0.2705114 ]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 6443 is [True, False, False, False, True, False]
Current timestep = 6444. State = [[-0.34692165  0.10011563]]. Action = [[ 0.08194088  0.09878509  0.         -0.00802237]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 6444 is [True, False, False, False, True, False]
Current timestep = 6445. State = [[-0.34544176  0.10153017]]. Action = [[-0.01828377 -0.04070081  0.         -0.24079669]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 6445 is [True, False, False, False, True, False]
Current timestep = 6446. State = [[-0.34314665  0.10380296]]. Action = [[0.05552668 0.05342893 0.         0.10487521]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 6446 is [True, False, False, False, True, False]
Current timestep = 6447. State = [[-0.34015682  0.10659775]]. Action = [[0.0265395  0.01497276 0.         0.9596298 ]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 6447 is [True, False, False, False, True, False]
Current timestep = 6448. State = [[-0.3422077   0.10375389]]. Action = [[-0.07537467 -0.08749333  0.          0.5139425 ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 6448 is [True, False, False, False, True, False]
Current timestep = 6449. State = [[-0.3426617  0.1053076]]. Action = [[ 0.0205123   0.06277456  0.         -0.78268695]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 6449 is [True, False, False, False, True, False]
Current timestep = 6450. State = [[-0.34231937  0.1114213 ]]. Action = [[-0.0113878   0.07329088  0.         -0.8520069 ]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 6450 is [True, False, False, False, True, False]
Current timestep = 6451. State = [[-0.3412571   0.11104416]]. Action = [[ 0.01915084 -0.07006995  0.         -0.504424  ]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 6451 is [True, False, False, False, True, False]
Current timestep = 6452. State = [[-0.34178483  0.11128049]]. Action = [[-0.03606293  0.02668554  0.         -0.7400755 ]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 6452 is [True, False, False, False, True, False]
Current timestep = 6453. State = [[-0.34220108  0.11414106]]. Action = [[0.00279512 0.02784356 0.         0.08235085]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 6453 is [True, False, False, False, True, False]
State prediction error at timestep 6453 is 0.012
Human Feedback received at timestep 6453 of None
Current timestep = 6454. State = [[-0.34502572  0.11787417]]. Action = [[-0.06158695  0.0418539   0.          0.42524183]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 6454 is [True, False, False, False, True, False]
State prediction error at timestep 6454 is 0.012
Human Feedback received at timestep 6454 of None
Current timestep = 6455. State = [[-0.3455002   0.12441751]]. Action = [[ 0.03314658  0.08977144  0.         -0.25281584]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 6455 is [True, False, False, False, True, False]
Current timestep = 6456. State = [[-0.34362203  0.12529667]]. Action = [[ 0.03006194 -0.05085813  0.         -0.9920162 ]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 6456 is [True, False, False, False, True, False]
Current timestep = 6457. State = [[-0.34544677  0.1296    ]]. Action = [[-0.04984951  0.09987029  0.          0.26328886]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 6457 is [True, False, False, False, False, True]
Current timestep = 6458. State = [[-0.34545586  0.1348048 ]]. Action = [[0.0423725  0.02975165 0.         0.852623  ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 6458 is [True, False, False, False, False, True]
State prediction error at timestep 6458 is 0.012
Human Feedback received at timestep 6458 of None
Current timestep = 6459. State = [[-0.34470564  0.14085236]]. Action = [[ 0.00719943  0.08430227  0.         -0.54471755]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 6459 is [True, False, False, False, False, True]
Current timestep = 6460. State = [[-0.34865195  0.14476703]]. Action = [[-0.07128578  0.00546195  0.          0.791042  ]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 6460 is [True, False, False, False, False, True]
Current timestep = 6461. State = [[-0.3466117   0.14664929]]. Action = [[0.0982305  0.00708763 0.         0.20132113]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 6461 is [True, False, False, False, False, True]
Current timestep = 6462. State = [[-0.34035632  0.14817145]]. Action = [[ 0.07596468  0.00803347  0.         -0.09787422]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 6462 is [True, False, False, False, False, True]
State prediction error at timestep 6462 is 0.012
Human Feedback received at timestep 6462 of None
Current timestep = 6463. State = [[-0.33810955  0.15019234]]. Action = [[-0.0085315   0.01726586  0.          0.8916409 ]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 6463 is [True, False, False, False, False, True]
State prediction error at timestep 6463 is 0.012
Human Feedback received at timestep 6463 of None
Current timestep = 6464. State = [[-0.34034076  0.14787957]]. Action = [[-0.05877266 -0.08540541  0.         -0.88128364]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 6464 is [True, False, False, False, False, True]
Current timestep = 6465. State = [[-0.33966812  0.14725529]]. Action = [[0.03003896 0.00952817 0.         0.7714479 ]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 6465 is [True, False, False, False, False, True]
Current timestep = 6466. State = [[-0.33401835  0.14646602]]. Action = [[ 0.07889023 -0.03373801  0.          0.7869673 ]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 6466 is [True, False, False, False, False, True]
Current timestep = 6467. State = [[-0.3273628   0.14125927]]. Action = [[ 0.05973961 -0.0904806   0.          0.47051382]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 6467 is [True, False, False, False, False, True]
Current timestep = 6468. State = [[-0.32152098  0.14050943]]. Action = [[ 0.04694573  0.04264603  0.         -0.684097  ]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 6468 is [True, False, False, False, False, True]
Current timestep = 6469. State = [[-0.321985    0.14331827]]. Action = [[-0.0700049   0.03907388  0.         -0.59352297]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 6469 is [True, False, False, False, False, True]
Current timestep = 6470. State = [[-0.31914246  0.14824565]]. Action = [[0.07821061 0.07932616 0.         0.62111926]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 6470 is [True, False, False, False, False, True]
Current timestep = 6471. State = [[-0.31272593  0.14764835]]. Action = [[ 0.06551126 -0.05311394  0.          0.14902341]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 6471 is [True, False, False, False, False, True]
Current timestep = 6472. State = [[-0.3097635   0.14251846]]. Action = [[-0.01226307 -0.07304595  0.          0.16249955]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 6472 is [True, False, False, False, False, True]
Current timestep = 6473. State = [[-0.30567527  0.13540402]]. Action = [[ 0.04971499 -0.09954835  0.          0.71489346]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 6473 is [True, False, False, False, False, True]
Current timestep = 6474. State = [[-0.3043243   0.13132115]]. Action = [[-0.04184267 -0.01615012  0.         -0.39453328]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 6474 is [True, False, False, False, False, True]
Current timestep = 6475. State = [[-0.3069546  0.1260557]]. Action = [[-0.06971125 -0.09035137  0.         -0.4749806 ]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 6475 is [True, False, False, False, False, True]
Current timestep = 6476. State = [[-0.31158832  0.1204675 ]]. Action = [[-0.08762745 -0.05782056  0.         -0.6952891 ]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 6476 is [True, False, False, False, False, True]
Current timestep = 6477. State = [[-0.31468794  0.12154692]]. Action = [[-0.02663595  0.06663849  0.         -0.40624464]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 6477 is [True, False, False, False, True, False]
Current timestep = 6478. State = [[-0.32031932  0.120979  ]]. Action = [[-0.09673799 -0.03927574  0.         -0.6043317 ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 6478 is [True, False, False, False, True, False]
State prediction error at timestep 6478 is 0.012
Human Feedback received at timestep 6478 of None
Current timestep = 6479. State = [[-0.32366133  0.12156627]]. Action = [[ 0.00243918  0.04114879  0.         -0.59629434]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 6479 is [True, False, False, False, True, False]
Current timestep = 6480. State = [[-0.32741666  0.11956746]]. Action = [[-0.05336193 -0.05339113  0.          0.70226836]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 6480 is [True, False, False, False, True, False]
State prediction error at timestep 6480 is 0.012
Human Feedback received at timestep 6480 of None
Current timestep = 6481. State = [[-0.33146885  0.11523227]]. Action = [[-0.02975055 -0.04954403  0.          0.49943876]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 6481 is [True, False, False, False, True, False]
Current timestep = 6482. State = [[-0.33288231  0.11140253]]. Action = [[ 0.01502935 -0.03352677  0.          0.72523797]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 6482 is [True, False, False, False, True, False]
Current timestep = 6483. State = [[-0.33561832  0.11252455]]. Action = [[-0.03290982  0.06339102  0.          0.7063811 ]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 6483 is [True, False, False, False, True, False]
Current timestep = 6484. State = [[-0.3400452   0.11590591]]. Action = [[-0.03170037  0.0497848   0.          0.9442954 ]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 6484 is [True, False, False, False, True, False]
State prediction error at timestep 6484 is 0.012
Human Feedback received at timestep 6484 of None
Current timestep = 6485. State = [[-0.3432679   0.11730999]]. Action = [[-0.00281578  0.01122026  0.          0.5896745 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 6485 is [True, False, False, False, True, False]
Current timestep = 6486. State = [[-0.34377083  0.11999774]]. Action = [[0.03625616 0.05996978 0.         0.3121376 ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 6486 is [True, False, False, False, True, False]
Current timestep = 6487. State = [[-0.34621966  0.11671194]]. Action = [[-0.03485221 -0.09234709  0.          0.8597281 ]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 6487 is [True, False, False, False, True, False]
Current timestep = 6488. State = [[-0.34513792  0.11816896]]. Action = [[ 0.08178785  0.09602489  0.         -0.8487093 ]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 6488 is [True, False, False, False, True, False]
Current timestep = 6489. State = [[-0.34277827  0.11881583]]. Action = [[ 0.02604254 -0.02901486  0.         -0.4503337 ]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 6489 is [True, False, False, False, True, False]
Current timestep = 6490. State = [[-0.34418312  0.11980558]]. Action = [[-0.03299099  0.0381045   0.          0.01392233]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 6490 is [True, False, False, False, True, False]
Current timestep = 6491. State = [[-0.3462019   0.11668482]]. Action = [[-0.01599898 -0.08832109  0.         -0.08511794]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 6491 is [True, False, False, False, True, False]
State prediction error at timestep 6491 is 0.012
Human Feedback received at timestep 6491 of None
Current timestep = 6492. State = [[-0.34937283  0.11463702]]. Action = [[-0.05620237  0.0016642   0.          0.24430978]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 6492 is [True, False, False, False, True, False]
Current timestep = 6493. State = [[-0.3499886   0.11148831]]. Action = [[ 0.01855204 -0.06782135  0.          0.02127206]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 6493 is [True, False, False, False, True, False]
State prediction error at timestep 6493 is 0.012
Human Feedback received at timestep 6493 of None
Current timestep = 6494. State = [[-0.347306    0.10721292]]. Action = [[ 0.03933256 -0.04413588  0.         -0.14019883]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 6494 is [True, False, False, False, True, False]
Current timestep = 6495. State = [[-0.3488969   0.10435063]]. Action = [[-0.06544782 -0.02344794  0.         -0.92652166]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 6495 is [True, False, False, False, True, False]
Current timestep = 6496. State = [[-0.3523453   0.10660889]]. Action = [[-0.03805316  0.06521603  0.          0.94357   ]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 6496 is [True, False, False, False, True, False]
Current timestep = 6497. State = [[-0.35022274  0.10882375]]. Action = [[0.07571644 0.01661868 0.         0.5324359 ]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 6497 is [True, False, False, False, True, False]
State prediction error at timestep 6497 is 0.012
Human Feedback received at timestep 6497 of None
Current timestep = 6498. State = [[-0.3505134   0.11270741]]. Action = [[-0.03623729  0.07885902  0.          0.954255  ]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 6498 is [True, False, False, False, True, False]
Current timestep = 6499. State = [[-0.3499449   0.11855685]]. Action = [[0.04930497 0.07830649 0.         0.54476213]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 6499 is [True, False, False, False, True, False]
Current timestep = 6500. State = [[-0.35097596  0.12136082]]. Action = [[-0.02858385  0.01104249  0.         -0.94584984]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 6500 is [True, False, False, False, True, False]
State prediction error at timestep 6500 is 0.012
Human Feedback received at timestep 6500 of None
Current timestep = 6501. State = [[-0.35305685  0.11980765]]. Action = [[-0.01252011 -0.04755357  0.         -0.47500277]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 6501 is [True, False, False, False, True, False]
Current timestep = 6502. State = [[-0.35778543  0.11927851]]. Action = [[-0.07966054  0.00292803  0.          0.68318534]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 6502 is [True, False, False, False, True, False]
Current timestep = 6503. State = [[-0.35822988  0.11541194]]. Action = [[ 0.04400464 -0.09347949  0.         -0.70066375]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 6503 is [True, False, False, False, True, False]
Current timestep = 6504. State = [[-0.3560351   0.11194758]]. Action = [[ 0.02213372 -0.02015136  0.         -0.53001904]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 6504 is [True, False, False, False, True, False]
Current timestep = 6505. State = [[-0.35159788  0.11155049]]. Action = [[ 0.07468113  0.01089837  0.         -0.91884947]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 6505 is [True, False, False, False, True, False]
Current timestep = 6506. State = [[-0.3493514   0.11058272]]. Action = [[-0.00254212 -0.0158956   0.          0.9341247 ]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 6506 is [True, False, False, False, True, False]
State prediction error at timestep 6506 is 0.012
Human Feedback received at timestep 6506 of None
Current timestep = 6507. State = [[-0.35232148  0.11281418]]. Action = [[-0.06808795  0.05820397  0.          0.46111453]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 6507 is [True, False, False, False, True, False]
Current timestep = 6508. State = [[-0.35499114  0.10979717]]. Action = [[-0.01935661 -0.09764025  0.          0.5572574 ]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 6508 is [True, False, False, False, True, False]
State prediction error at timestep 6508 is 0.012
Human Feedback received at timestep 6508 of None
Current timestep = 6509. State = [[-0.35538077  0.10392296]]. Action = [[-0.00462548 -0.06277196  0.         -0.3559445 ]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 6509 is [True, False, False, False, True, False]
Current timestep = 6510. State = [[-0.35941845  0.10069449]]. Action = [[-0.08864523 -0.0212683   0.         -0.36638772]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 6510 is [True, False, False, False, True, False]
Current timestep = 6511. State = [[-0.35818052  0.1027749 ]]. Action = [[ 0.08521172  0.06868844  0.         -0.25772488]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 6511 is [True, False, False, False, True, False]
Current timestep = 6512. State = [[-0.35657266  0.10594549]]. Action = [[-0.01304325  0.03633105  0.         -0.45171833]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 6512 is [True, False, False, False, True, False]
Current timestep = 6513. State = [[-0.35424596  0.1054289 ]]. Action = [[ 0.05109312 -0.0266606   0.          0.6913173 ]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 6513 is [True, False, False, False, True, False]
State prediction error at timestep 6513 is 0.012
Human Feedback received at timestep 6513 of None
Current timestep = 6514. State = [[-0.35248306  0.09955587]]. Action = [[-0.00178391 -0.09682428  0.          0.5298941 ]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 6514 is [True, False, False, False, True, False]
Current timestep = 6515. State = [[-0.34839746  0.09331954]]. Action = [[ 0.06622418 -0.05915059  0.          0.18260837]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 6515 is [True, False, False, False, True, False]
Current timestep = 6516. State = [[-0.34855753  0.08708318]]. Action = [[-0.06460766 -0.07513949  0.          0.35968554]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 6516 is [True, False, False, False, True, False]
Current timestep = 6517. State = [[-0.34812844  0.08128591]]. Action = [[ 0.02245651 -0.05682718  0.          0.9764024 ]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 6517 is [True, False, False, False, True, False]
Current timestep = 6518. State = [[-0.34580925  0.07652982]]. Action = [[ 0.0171629  -0.0368517   0.          0.35591412]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 6518 is [True, False, False, False, True, False]
Current timestep = 6519. State = [[-0.34772578  0.07232139]]. Action = [[-0.06742814 -0.03641426  0.          0.09088004]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 6519 is [True, False, False, False, True, False]
Current timestep = 6520. State = [[-0.34955472  0.06805506]]. Action = [[-0.01219773 -0.0398952   0.         -0.8070467 ]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 6520 is [True, False, False, False, True, False]
Current timestep = 6521. State = [[-0.34602612  0.06862511]]. Action = [[0.08079962 0.06660234 0.         0.9401804 ]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 6521 is [True, False, False, False, True, False]
State prediction error at timestep 6521 is 0.012
Human Feedback received at timestep 6521 of None
Current timestep = 6522. State = [[-0.3426751   0.07315932]]. Action = [[0.03291477 0.08560472 0.         0.87610006]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 6522 is [True, False, False, False, True, False]
Current timestep = 6523. State = [[-0.34475797  0.07352283]]. Action = [[-0.05331017 -0.02356892  0.         -0.38977063]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 6523 is [True, False, False, False, True, False]
Current timestep = 6524. State = [[-0.34274524  0.07246945]]. Action = [[0.08479329 0.00543038 0.         0.37449038]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 6524 is [True, False, False, False, True, False]
Current timestep = 6525. State = [[-0.3359231  0.0690872]]. Action = [[ 0.09927691 -0.05215304  0.          0.08094132]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 6525 is [True, False, False, False, True, False]
Current timestep = 6526. State = [[-0.33623782  0.06537285]]. Action = [[-0.07791035 -0.0310185   0.          0.10709524]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 6526 is [True, False, False, False, True, False]
Current timestep = 6527. State = [[-0.33407664  0.05896738]]. Action = [[ 0.0812807  -0.09727199  0.          0.884784  ]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 6527 is [True, False, False, False, True, False]
Current timestep = 6528. State = [[-0.32879376  0.05293271]]. Action = [[ 0.05005678 -0.0441827   0.         -0.71852475]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 6528 is [True, False, False, False, True, False]
Current timestep = 6529. State = [[-0.32895023  0.04597367]]. Action = [[-0.05857768 -0.09082294  0.          0.6322864 ]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 6529 is [True, False, False, False, True, False]
State prediction error at timestep 6529 is 0.012
Human Feedback received at timestep 6529 of None
Current timestep = 6530. State = [[-0.3268851   0.03831954]]. Action = [[ 0.04820166 -0.07681     0.         -0.23236418]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 6530 is [True, False, False, False, True, False]
State prediction error at timestep 6530 is 0.012
Human Feedback received at timestep 6530 of None
Current timestep = 6531. State = [[-0.32553592  0.03162863]]. Action = [[-0.02572566 -0.0563961   0.          0.51406014]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 6531 is [True, False, False, False, True, False]
Current timestep = 6532. State = [[-0.3247274   0.03009317]]. Action = [[0.00604502 0.03854425 0.         0.33004034]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 6532 is [True, False, False, False, True, False]
Current timestep = 6533. State = [[-0.3279136   0.02726763]]. Action = [[-0.08453752 -0.04543396  0.          0.8633082 ]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 6533 is [True, False, False, False, True, False]
Current timestep = 6534. State = [[-0.33189017  0.02757432]]. Action = [[-0.04169285  0.05829789  0.          0.96965575]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 6534 is [True, False, False, False, True, False]
Current timestep = 6535. State = [[-0.33625975  0.02371041]]. Action = [[-0.05940815 -0.09091757  0.         -0.72672564]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 6535 is [True, False, False, False, True, False]
Current timestep = 6536. State = [[-0.34248605  0.02029088]]. Action = [[-0.08739995  0.00067236  0.         -0.40389502]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 6536 is [True, False, False, False, True, False]
Current timestep = 6537. State = [[-0.34944767  0.01900006]]. Action = [[-0.0756142  -0.00893779  0.         -0.21587616]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 6537 is [True, False, False, False, True, False]
Current timestep = 6538. State = [[-0.3534449   0.01616385]]. Action = [[-0.01174289 -0.03935079  0.          0.9658835 ]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 6538 is [True, False, False, False, True, False]
State prediction error at timestep 6538 is 0.012
Human Feedback received at timestep 6538 of None
Current timestep = 6539. State = [[-0.3525023   0.01045951]]. Action = [[ 0.05896997 -0.07607809  0.          0.6922233 ]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 6539 is [True, False, False, False, True, False]
State prediction error at timestep 6539 is 0.012
Human Feedback received at timestep 6539 of None
Current timestep = 6540. State = [[-0.352423    0.00223763]]. Action = [[-0.00709142 -0.0998628   0.          0.49553633]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 6540 is [True, False, False, False, True, False]
Current timestep = 6541. State = [[-0.35577872 -0.00085232]]. Action = [[-0.04913866  0.02182803  0.         -0.56509465]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 6541 is [True, False, False, False, True, False]
State prediction error at timestep 6541 is 0.012
Human Feedback received at timestep 6541 of None
Current timestep = 6542. State = [[-0.35730132 -0.0007218 ]]. Action = [[ 0.02033089  0.01644315  0.         -0.3667369 ]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 6542 is [True, False, False, False, True, False]
Current timestep = 6543. State = [[-0.35973385 -0.00446295]]. Action = [[-0.03475332 -0.06419599  0.          0.5983616 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 6543 is [True, False, False, False, True, False]
Current timestep = 6544. State = [[-0.364293   -0.00732801]]. Action = [[-5.2983224e-02  1.9349158e-05  0.0000000e+00 -6.4138460e-01]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 6544 is [True, False, False, False, True, False]
Current timestep = 6545. State = [[-0.36543185 -0.0099703 ]]. Action = [[ 0.03116072 -0.03107055  0.         -0.27563572]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 6545 is [True, False, False, False, True, False]
Current timestep = 6546. State = [[-0.36880293 -0.00870126]]. Action = [[-0.05994153  0.06247523  0.         -0.27278078]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 6546 is [True, False, False, False, True, False]
Current timestep = 6547. State = [[-0.37008417 -0.0032756 ]]. Action = [[ 0.04469889  0.08432891  0.         -0.7575427 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 6547 is [True, False, False, False, True, False]
Current timestep = 6548. State = [[-0.36948392 -0.00260998]]. Action = [[ 0.02983778 -0.03591272  0.          0.729154  ]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 6548 is [True, False, False, False, True, False]
State prediction error at timestep 6548 is 0.012
Human Feedback received at timestep 6548 of None
Current timestep = 6549. State = [[-0.3717522  -0.00360037]]. Action = [[-3.3169046e-02  9.6857548e-07  0.0000000e+00  8.8896179e-01]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 6549 is [True, False, False, False, True, False]
Current timestep = 6550. State = [[-0.37267464 -0.00718143]]. Action = [[ 0.02245921 -0.069236    0.          0.88678086]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 6550 is [True, False, False, False, True, False]
Current timestep = 6551. State = [[-0.37300715 -0.00814777]]. Action = [[-0.00407653  0.0251582   0.          0.43171525]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 6551 is [True, False, False, False, True, False]
Current timestep = 6552. State = [[-0.37145066 -0.00918942]]. Action = [[ 0.04643939 -0.02982489  0.          0.05042124]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 6552 is [True, False, False, False, True, False]
Current timestep = 6553. State = [[-0.3667359  -0.00635819]]. Action = [[0.08119106 0.07719167 0.         0.9803587 ]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 6553 is [True, False, False, False, True, False]
Current timestep = 6554. State = [[-0.3623613  -0.00316037]]. Action = [[0.05580581 0.02042238 0.         0.0778774 ]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 6554 is [True, False, False, False, True, False]
Current timestep = 6555. State = [[-0.36467332 -0.00081632]]. Action = [[-0.07737015  0.03198833  0.         -0.16017848]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 6555 is [True, False, False, False, True, False]
Current timestep = 6556. State = [[-0.37156045 -0.00314516]]. Action = [[-0.0961041  -0.07056151  0.         -0.6510856 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 6556 is [True, False, False, False, True, False]
Current timestep = 6557. State = [[-0.37273884 -0.00611775]]. Action = [[ 0.03292105 -0.02342341  0.          0.74040055]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 6557 is [True, False, False, False, True, False]
Current timestep = 6558. State = [[-0.36995    -0.00696741]]. Action = [[ 0.03852802 -0.00238574  0.          0.4613893 ]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 6558 is [True, False, False, False, True, False]
Current timestep = 6559. State = [[-0.37142822 -0.01126361]]. Action = [[-0.06195867 -0.08309561  0.         -0.86387926]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 6559 is [True, False, False, False, True, False]
Current timestep = 6560. State = [[-0.37243083 -0.01400764]]. Action = [[ 0.          0.          0.         -0.38641918]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 6560 is [True, False, False, False, True, False]
Current timestep = 6561. State = [[-0.36826771 -0.01851685]]. Action = [[ 0.07699161 -0.07724468  0.         -0.5412303 ]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 6561 is [True, False, False, False, True, False]
State prediction error at timestep 6561 is 0.012
Human Feedback received at timestep 6561 of None
Current timestep = 6562. State = [[-0.36546934 -0.02573177]]. Action = [[-0.00342648 -0.08325498  0.          0.84584963]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 6562 is [True, False, False, False, True, False]
Current timestep = 6563. State = [[-0.36491266 -0.03209468]]. Action = [[-0.0125129  -0.05324337  0.          0.28580773]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 6563 is [True, False, False, False, True, False]
Current timestep = 6564. State = [[-0.36089963 -0.03656357]]. Action = [[ 0.06755107 -0.02631813  0.         -0.44160622]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 6564 is [True, False, False, False, True, False]
State prediction error at timestep 6564 is 0.012
Human Feedback received at timestep 6564 of None
Current timestep = 6565. State = [[-0.35355055 -0.03987769]]. Action = [[ 0.09422565 -0.01766133  0.          0.3044685 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 6565 is [True, False, False, False, True, False]
State prediction error at timestep 6565 is 0.012
Human Feedback received at timestep 6565 of None
Current timestep = 6566. State = [[-0.35433507 -0.03778403]]. Action = [[-0.09668902  0.08789548  0.         -0.963099  ]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 6566 is [True, False, False, False, True, False]
State prediction error at timestep 6566 is 0.012
Human Feedback received at timestep 6566 of None
Current timestep = 6567. State = [[-0.35488927 -0.03731016]]. Action = [[ 0.05575524 -0.0185362   0.         -0.06392491]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 6567 is [True, False, False, False, True, False]
State prediction error at timestep 6567 is 0.012
Human Feedback received at timestep 6567 of None
Current timestep = 6568. State = [[-0.35109174 -0.03604706]]. Action = [[0.0609506  0.04956659 0.         0.95483565]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 6568 is [True, False, False, False, True, False]
Current timestep = 6569. State = [[-0.35032243 -0.0392685 ]]. Action = [[-0.01022974 -0.08572505  0.         -0.7952554 ]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 6569 is [True, False, False, False, True, False]
Current timestep = 6570. State = [[-0.35069102 -0.04106258]]. Action = [[-1.5668571e-05  2.6235633e-02  0.0000000e+00  3.2232630e-01]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 6570 is [True, False, False, False, True, False]
Current timestep = 6571. State = [[-0.34923792 -0.04302773]]. Action = [[ 0.03355195 -0.04075186  0.          0.4477055 ]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 6571 is [True, False, False, False, True, False]
Current timestep = 6572. State = [[-0.35247535 -0.04261832]]. Action = [[-0.08885269  0.04346787  0.          0.97061896]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 6572 is [True, False, False, False, True, False]
Current timestep = 6573. State = [[-0.3580052 -0.0385039]]. Action = [[-0.05481844  0.06577126  0.         -0.1666748 ]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 6573 is [True, False, False, False, True, False]
Current timestep = 6574. State = [[-0.3620998  -0.03896097]]. Action = [[-0.0341095  -0.04977093  0.          0.6158726 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 6574 is [True, False, False, False, True, False]
Current timestep = 6575. State = [[-0.36397156 -0.03699056]]. Action = [[-0.00149735  0.06366647  0.          0.15197217]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 6575 is [True, False, False, False, True, False]
Current timestep = 6576. State = [[-0.3609361  -0.03212586]]. Action = [[0.08985703 0.04988588 0.         0.5015371 ]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 6576 is [True, False, False, False, True, False]
Current timestep = 6577. State = [[-0.3580802  -0.03313684]]. Action = [[ 0.03239263 -0.06886458  0.          0.26628494]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 6577 is [True, False, False, False, True, False]
Current timestep = 6578. State = [[-0.35797554 -0.03155486]]. Action = [[-0.00469958  0.05996985  0.         -0.8519681 ]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 6578 is [True, False, False, False, True, False]
Current timestep = 6579. State = [[-0.3558057  -0.03408448]]. Action = [[ 0.05734309 -0.09442307  0.         -0.21116918]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 6579 is [True, False, False, False, True, False]
Current timestep = 6580. State = [[-0.3578769  -0.03694494]]. Action = [[-0.0828725  -0.00677877  0.          0.27577567]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 6580 is [True, False, False, False, True, False]
Current timestep = 6581. State = [[-0.3636358  -0.03517606]]. Action = [[-0.07157788  0.04306195  0.          0.7455282 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 6581 is [True, False, False, False, True, False]
Current timestep = 6582. State = [[-0.3665045  -0.03536961]]. Action = [[-0.00821735 -0.03012162  0.          0.55859387]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 6582 is [True, False, False, False, True, False]
State prediction error at timestep 6582 is 0.012
Human Feedback received at timestep 6582 of None
Current timestep = 6583. State = [[-0.3656473  -0.03754878]]. Action = [[ 0.03006751 -0.02868259  0.          0.873965  ]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 6583 is [True, False, False, False, True, False]
Current timestep = 6584. State = [[-0.36313906 -0.03814512]]. Action = [[ 0.03895729  0.0061964   0.         -0.7896379 ]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 6584 is [True, False, False, False, True, False]
Current timestep = 6585. State = [[-0.36379308 -0.04199535]]. Action = [[-0.03626996 -0.07706267  0.          0.90115833]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 6585 is [True, False, False, False, True, False]
Current timestep = 6586. State = [[-0.36255458 -0.0445879 ]]. Action = [[ 0.03977611  0.00198601  0.         -0.55124766]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 6586 is [True, False, False, False, True, False]
State prediction error at timestep 6586 is 0.012
Human Feedback received at timestep 6586 of None
Current timestep = 6587. State = [[-0.36226174 -0.04260054]]. Action = [[-0.01806553  0.0513773   0.         -0.11711955]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 6587 is [True, False, False, False, True, False]
State prediction error at timestep 6587 is 0.012
Human Feedback received at timestep 6587 of None
Current timestep = 6588. State = [[-0.3668136 -0.0375213]]. Action = [[-0.07887934  0.07964014  0.         -0.14074928]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 6588 is [True, False, False, False, True, False]
State prediction error at timestep 6588 is 0.012
Human Feedback received at timestep 6588 of None
Current timestep = 6589. State = [[-0.3734468  -0.03774318]]. Action = [[-0.0796151  -0.05116399  0.          0.97711134]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 6589 is [True, False, False, False, True, False]
State prediction error at timestep 6589 is 0.012
Human Feedback received at timestep 6589 of None
Current timestep = 6590. State = [[-0.37634602 -0.03920301]]. Action = [[ 0.         0.         0.        -0.7578119]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 6590 is [True, False, False, False, True, False]
Current timestep = 6591. State = [[-0.37719628 -0.03922308]]. Action = [[0.        0.        0.        0.8150983]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 6591 is [True, False, False, False, True, False]
Current timestep = 6592. State = [[-0.37799793 -0.03908667]]. Action = [[ 0.         0.         0.        -0.7220305]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 6592 is [True, False, False, False, True, False]
Current timestep = 6593. State = [[-0.3788005 -0.0389417]]. Action = [[0.        0.        0.        0.1778574]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 6593 is [True, False, False, False, True, False]
Current timestep = 6594. State = [[-0.37533507 -0.04235505]]. Action = [[ 0.08602979 -0.07133281  0.         -0.02936202]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 6594 is [True, False, False, False, True, False]
Current timestep = 6595. State = [[-0.3721758  -0.04206017]]. Action = [[ 0.02338004  0.04786661  0.         -0.26758188]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 6595 is [True, False, False, False, True, False]
State prediction error at timestep 6595 is 0.012
Human Feedback received at timestep 6595 of None
Current timestep = 6596. State = [[-0.3727053  -0.03775006]]. Action = [[-0.01631743  0.06096712  0.          0.376194  ]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 6596 is [True, False, False, False, True, False]
Current timestep = 6597. State = [[-0.36987177 -0.03603524]]. Action = [[ 0.08171665 -0.00648996  0.         -0.80695695]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 6597 is [True, False, False, False, True, False]
Current timestep = 6598. State = [[-0.370657   -0.03665035]]. Action = [[-0.05733446 -0.01357029  0.         -0.15951723]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 6598 is [True, False, False, False, True, False]
Current timestep = 6599. State = [[-0.37135544 -0.03935312]]. Action = [[ 0.01962932 -0.04644771  0.         -0.8262099 ]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 6599 is [True, False, False, False, True, False]
Current timestep = 6600. State = [[-0.36929327 -0.03993564]]. Action = [[ 0.03157146  0.01706191  0.         -0.5431805 ]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 6600 is [True, False, False, False, True, False]
Current timestep = 6601. State = [[-0.36667794 -0.0424431 ]]. Action = [[ 0.03109763 -0.0579298   0.         -0.7467217 ]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 6601 is [True, False, False, False, True, False]
Current timestep = 6602. State = [[-0.3623844  -0.04385588]]. Action = [[ 0.05855044  0.0094838   0.         -0.48459363]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 6602 is [True, False, False, False, True, False]
State prediction error at timestep 6602 is 0.012
Human Feedback received at timestep 6602 of None
Current timestep = 6603. State = [[-0.36363372 -0.04673922]]. Action = [[-0.07580541 -0.05396699  0.          0.96534574]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 6603 is [True, False, False, False, True, False]
State prediction error at timestep 6603 is 0.012
Human Feedback received at timestep 6603 of None
Current timestep = 6604. State = [[-0.36420342 -0.04583355]]. Action = [[ 0.01534854  0.06175881  0.         -0.7740623 ]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 6604 is [True, False, False, False, True, False]
Current timestep = 6605. State = [[-0.36010492 -0.04449244]]. Action = [[ 0.07186664 -0.00240292  0.          0.7159767 ]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 6605 is [True, False, False, False, True, False]
State prediction error at timestep 6605 is 0.012
Human Feedback received at timestep 6605 of None
Current timestep = 6606. State = [[-0.35969335 -0.04846469]]. Action = [[-4.2326268e-02 -7.5802714e-02  0.0000000e+00 -4.3392181e-05]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 6606 is [True, False, False, False, True, False]
State prediction error at timestep 6606 is 0.012
Human Feedback received at timestep 6606 of None
Current timestep = 6607. State = [[-0.35611156 -0.05362129]]. Action = [[ 0.07956349 -0.04854786  0.          0.7749901 ]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 6607 is [True, False, False, False, True, False]
Current timestep = 6608. State = [[-0.35376176 -0.05526786]]. Action = [[-0.01622479  0.01189641  0.         -0.68928975]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 6608 is [True, False, False, False, True, False]
Current timestep = 6609. State = [[-0.35231623 -0.05133801]]. Action = [[0.02327405 0.08683845 0.         0.34704244]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 6609 is [True, False, False, False, True, False]
Current timestep = 6610. State = [[-0.35532418 -0.05161082]]. Action = [[-0.08321019 -0.05615645  0.          0.43055522]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 6610 is [True, False, False, False, True, False]
Current timestep = 6611. State = [[-0.3548155  -0.05231994]]. Action = [[ 0.05098682  0.0247886   0.         -0.90415424]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 6611 is [True, False, False, False, True, False]
Current timestep = 6612. State = [[-0.3555372  -0.05218096]]. Action = [[-0.0443413  -0.00534968  0.          0.25945044]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 6612 is [True, False, False, False, True, False]
Current timestep = 6613. State = [[-0.35249552 -0.05426769]]. Action = [[ 0.0853739  -0.03625019  0.          0.79813313]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 6613 is [True, False, False, False, True, False]
Current timestep = 6614. State = [[-0.35321397 -0.05260236]]. Action = [[-0.07249363  0.06023727  0.         -0.40987766]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 6614 is [True, False, False, False, True, False]
Current timestep = 6615. State = [[-0.35115346 -0.04707876]]. Action = [[ 0.09591018  0.07239943  0.         -0.44901478]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 6615 is [True, False, False, False, True, False]
Current timestep = 6616. State = [[-0.35213357 -0.04324333]]. Action = [[-0.05973185  0.02242027  0.          0.19236898]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 6616 is [True, False, False, False, True, False]
State prediction error at timestep 6616 is 0.012
Human Feedback received at timestep 6616 of None
Current timestep = 6617. State = [[-0.35791525 -0.03811565]]. Action = [[-0.07138533  0.07683649  0.          0.46798944]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 6617 is [True, False, False, False, True, False]
Current timestep = 6618. State = [[-0.36460224 -0.03313867]]. Action = [[-0.07265946  0.03861599  0.          0.9964329 ]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 6618 is [True, False, False, False, True, False]
Current timestep = 6619. State = [[-0.36536932 -0.0297264 ]]. Action = [[0.05632048 0.02004375 0.         0.13278735]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 6619 is [True, False, False, False, True, False]
Current timestep = 6620. State = [[-0.36616495 -0.02314929]]. Action = [[-0.0176217   0.09157716  0.         -0.7469979 ]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 6620 is [True, False, False, False, True, False]
State prediction error at timestep 6620 is 0.012
Human Feedback received at timestep 6620 of None
Current timestep = 6621. State = [[-0.3633376  -0.02305668]]. Action = [[ 0.09761935 -0.08487979  0.          0.28798342]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 6621 is [True, False, False, False, True, False]
Current timestep = 6622. State = [[-0.36277744 -0.02321549]]. Action = [[-0.03430913  0.01947483  0.          0.07742321]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 6622 is [True, False, False, False, True, False]
Current timestep = 6623. State = [[-0.3604462  -0.02361304]]. Action = [[ 0.07407936 -0.03716365  0.          0.08673573]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 6623 is [True, False, False, False, True, False]
Current timestep = 6624. State = [[-0.35946095 -0.02140782]]. Action = [[-0.01950198  0.04957654  0.          0.31816626]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 6624 is [True, False, False, False, True, False]
Current timestep = 6625. State = [[-0.3558811  -0.02205876]]. Action = [[ 0.08281337 -0.054469    0.          0.1616826 ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 6625 is [True, False, False, False, True, False]
Current timestep = 6626. State = [[-0.35396868 -0.02383436]]. Action = [[-0.02111512 -0.01389851  0.          0.9501505 ]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 6626 is [True, False, False, False, True, False]
Current timestep = 6627. State = [[-0.35659495 -0.02711594]]. Action = [[-0.06504451 -0.05911594  0.          0.49358046]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 6627 is [True, False, False, False, True, False]
State prediction error at timestep 6627 is 0.012
Human Feedback received at timestep 6627 of None
Current timestep = 6628. State = [[-0.35865313 -0.0294584 ]]. Action = [[-0.02974864 -0.00886533  0.         -0.1523602 ]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 6628 is [True, False, False, False, True, False]
State prediction error at timestep 6628 is 0.012
Human Feedback received at timestep 6628 of None
Current timestep = 6629. State = [[-0.3603848  -0.02812153]]. Action = [[-0.03559717  0.04017671  0.          0.6359329 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 6629 is [True, False, False, False, True, False]
Current timestep = 6630. State = [[-0.36174026 -0.02485685]]. Action = [[-0.01473241  0.04601658  0.          0.2183758 ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 6630 is [True, False, False, False, True, False]
Current timestep = 6631. State = [[-0.36216834 -0.02620961]]. Action = [[-0.00167405 -0.05530594  0.          0.15835238]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 6631 is [True, False, False, False, True, False]
Current timestep = 6632. State = [[-0.36043656 -0.0230267 ]]. Action = [[ 0.03829261  0.09842149  0.         -0.5158894 ]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 6632 is [True, False, False, False, True, False]
Current timestep = 6633. State = [[-0.35598648 -0.01923276]]. Action = [[0.08335834 0.01359904 0.         0.12368262]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 6633 is [True, False, False, False, True, False]
Current timestep = 6634. State = [[-0.35481977 -0.01502299]]. Action = [[-0.00950108  0.06446644  0.          0.7030084 ]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 6634 is [True, False, False, False, True, False]
State prediction error at timestep 6634 is 0.012
Human Feedback received at timestep 6634 of None
Current timestep = 6635. State = [[-0.35355043 -0.01403369]]. Action = [[ 0.0442354  -0.02931815  0.         -0.9243151 ]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 6635 is [True, False, False, False, True, False]
Current timestep = 6636. State = [[-0.35373586 -0.01360676]]. Action = [[-0.02112654  0.01277633  0.          0.11709547]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 6636 is [True, False, False, False, True, False]
Current timestep = 6637. State = [[-0.35768712 -0.01141507]]. Action = [[-0.06587526  0.02684201  0.         -0.36677027]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 6637 is [True, False, False, False, True, False]
Current timestep = 6638. State = [[-0.35696578 -0.00516181]]. Action = [[ 0.06444445  0.09591346  0.         -0.20719689]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 6638 is [True, False, False, False, True, False]
Current timestep = 6639. State = [[-0.35361677  0.0020431 ]]. Action = [[ 0.05307587  0.06915154  0.         -0.09088993]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 6639 is [True, False, False, False, True, False]
Current timestep = 6640. State = [[-0.3523761   0.00085414]]. Action = [[ 0.00529148 -0.09510724  0.         -0.11909729]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 6640 is [True, False, False, False, True, False]
Current timestep = 6641. State = [[-0.34915346 -0.00270247]]. Action = [[ 0.05600462 -0.03687017  0.         -0.17817324]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 6641 is [True, False, False, False, True, False]
Current timestep = 6642. State = [[-0.3486884  -0.00377925]]. Action = [[-0.03687838 -0.01014132  0.         -0.07667345]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 6642 is [True, False, False, False, True, False]
Current timestep = 6643. State = [[-0.34775338 -0.00404496]]. Action = [[ 0.02127042 -0.00769264  0.         -0.14777255]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 6643 is [True, False, False, False, True, False]
State prediction error at timestep 6643 is 0.012
Human Feedback received at timestep 6643 of None
Current timestep = 6644. State = [[-0.34913084 -0.00827309]]. Action = [[-0.06134354 -0.08610956  0.         -0.28536308]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 6644 is [True, False, False, False, True, False]
State prediction error at timestep 6644 is 0.012
Human Feedback received at timestep 6644 of None
Current timestep = 6645. State = [[-0.35049736 -0.0081283 ]]. Action = [[-0.01871713  0.05346545  0.         -0.48623574]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 6645 is [True, False, False, False, True, False]
Current timestep = 6646. State = [[-0.34995106 -0.00190034]]. Action = [[0.01319852 0.09651607 0.         0.02189302]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 6646 is [True, False, False, False, True, False]
Current timestep = 6647. State = [[-0.3501398   0.00352451]]. Action = [[-0.00712935  0.04559878  0.         -0.7135769 ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 6647 is [True, False, False, False, True, False]
State prediction error at timestep 6647 is 0.012
Human Feedback received at timestep 6647 of None
Current timestep = 6648. State = [[-0.35209078  0.00690907]]. Action = [[-0.0290454   0.02813584  0.          0.87133265]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 6648 is [True, False, False, False, True, False]
State prediction error at timestep 6648 is 0.012
Human Feedback received at timestep 6648 of None
Current timestep = 6649. State = [[-0.3543047   0.01007142]]. Action = [[-0.0182607   0.03195428  0.         -0.9410408 ]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 6649 is [True, False, False, False, True, False]
Current timestep = 6650. State = [[-0.3537494   0.00917452]]. Action = [[ 0.03385665 -0.05345272  0.         -0.7625577 ]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 6650 is [True, False, False, False, True, False]
Current timestep = 6651. State = [[-0.34907028  0.00669474]]. Action = [[ 0.08230721 -0.03168011  0.          0.42451727]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 6651 is [True, False, False, False, True, False]
Current timestep = 6652. State = [[-0.35109246  0.0094502 ]]. Action = [[-0.09418896  0.06787846  0.          0.41385996]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 6652 is [True, False, False, False, True, False]
State prediction error at timestep 6652 is 0.012
Human Feedback received at timestep 6652 of None
Current timestep = 6653. State = [[-0.3515991   0.01014278]]. Action = [[ 0.05387668 -0.03338134  0.          0.40731406]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 6653 is [True, False, False, False, True, False]
Current timestep = 6654. State = [[-0.350887    0.00921349]]. Action = [[-0.00799357 -0.0082102   0.         -0.69986045]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 6654 is [True, False, False, False, True, False]
Current timestep = 6655. State = [[-0.3487073   0.00731061]]. Action = [[ 0.048046   -0.0365754   0.         -0.38759696]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 6655 is [True, False, False, False, True, False]
State prediction error at timestep 6655 is 0.012
Human Feedback received at timestep 6655 of None
Current timestep = 6656. State = [[-0.34282115  0.00677125]]. Action = [[0.0896908  0.01186999 0.         0.8001733 ]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 6656 is [True, False, False, False, True, False]
Current timestep = 6657. State = [[-0.3428983   0.00274873]]. Action = [[-0.06925482 -0.08345816  0.          0.01407528]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 6657 is [True, False, False, False, True, False]
State prediction error at timestep 6657 is 0.012
Human Feedback received at timestep 6657 of None
Current timestep = 6658. State = [[-0.343066    0.00152605]]. Action = [[ 0.02230062  0.02959331  0.         -0.22094244]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 6658 is [True, False, False, False, True, False]
Current timestep = 6659. State = [[-0.34436828  0.00158284]]. Action = [[-0.04304763 -0.00489685  0.         -0.8552268 ]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 6659 is [True, False, False, False, True, False]
Current timestep = 6660. State = [[-0.3493391   0.00521091]]. Action = [[-0.08060152  0.08228562  0.          0.7153802 ]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 6660 is [True, False, False, False, True, False]
Current timestep = 6661. State = [[-0.349495    0.00277734]]. Action = [[ 0.0504617  -0.09855983  0.          0.8312814 ]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 6661 is [True, False, False, False, True, False]
Current timestep = 6662. State = [[-0.35248628  0.00253389]]. Action = [[-0.0902442   0.05489977  0.         -0.4424382 ]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 6662 is [True, False, False, False, True, False]
State prediction error at timestep 6662 is 0.012
Human Feedback received at timestep 6662 of None
Current timestep = 6663. State = [[-0.35796174  0.00190777]]. Action = [[-0.05519141 -0.03988549  0.          0.00586712]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 6663 is [True, False, False, False, True, False]
Current timestep = 6664. State = [[-0.36035907  0.00424979]]. Action = [[-0.00144958  0.06946806  0.         -0.2064237 ]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 6664 is [True, False, False, False, True, False]
Current timestep = 6665. State = [[-0.36154115  0.00399372]]. Action = [[-1.8034130e-04 -4.6574015e-02  0.0000000e+00  6.7085600e-01]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 6665 is [True, False, False, False, True, False]
Current timestep = 6666. State = [[-0.3631541   0.00266397]]. Action = [[-0.01544531 -0.00278166  0.         -0.16322672]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 6666 is [True, False, False, False, True, False]
Current timestep = 6667. State = [[-0.3611613   0.00310841]]. Action = [[ 0.06920227  0.01225375  0.         -0.03583318]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 6667 is [True, False, False, False, True, False]
Current timestep = 6668. State = [[-0.3574486   0.00339261]]. Action = [[0.05785843 0.0003889  0.         0.2642374 ]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 6668 is [True, False, False, False, True, False]
State prediction error at timestep 6668 is 0.012
Human Feedback received at timestep 6668 of None
Current timestep = 6669. State = [[-0.3530816   0.00475612]]. Action = [[0.07043167 0.02984216 0.         0.581828  ]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 6669 is [True, False, False, False, True, False]
Current timestep = 6670. State = [[-0.35596663  0.00570654]]. Action = [[-0.09561018  0.00418745  0.          0.403059  ]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 6670 is [True, False, False, False, True, False]
Current timestep = 6671. State = [[-0.35470465  0.00315097]]. Action = [[ 0.09542974 -0.05462901  0.          0.7835398 ]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 6671 is [True, False, False, False, True, False]
Current timestep = 6672. State = [[-0.3490709  -0.00077579]]. Action = [[ 0.06056916 -0.04337517  0.         -0.1438098 ]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 6672 is [True, False, False, False, True, False]
Current timestep = 6673. State = [[-0.3486661  -0.00500855]]. Action = [[-0.04580393 -0.05117565  0.          0.45975924]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 6673 is [True, False, False, False, True, False]
Current timestep = 6674. State = [[-0.3529672  -0.00951835]]. Action = [[-0.08915432 -0.05038387  0.          0.19893193]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 6674 is [True, False, False, False, True, False]
Current timestep = 6675. State = [[-0.3571594  -0.01468308]]. Action = [[-0.05925982 -0.06039565  0.          0.2364918 ]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 6675 is [True, False, False, False, True, False]
Current timestep = 6676. State = [[-0.35918227 -0.0167989 ]]. Action = [[-0.02288583  0.01135144  0.          0.6794603 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 6676 is [True, False, False, False, True, False]
Current timestep = 6677. State = [[-0.36218503 -0.01636293]]. Action = [[-0.0530985   0.0219031   0.         -0.90877855]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 6677 is [True, False, False, False, True, False]
Current timestep = 6678. State = [[-0.3674404  -0.01206111]]. Action = [[-0.0696101   0.08688981  0.         -0.30080998]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 6678 is [True, False, False, False, True, False]
Current timestep = 6679. State = [[-0.37158856 -0.00542601]]. Action = [[-0.01740698  0.0857439   0.          0.9021156 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 6679 is [True, False, False, False, True, False]
Current timestep = 6680. State = [[-0.37407994 -0.00248845]]. Action = [[0.        0.        0.        0.8113929]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 6680 is [True, False, False, False, True, False]
Current timestep = 6681. State = [[-0.37604427 -0.00186581]]. Action = [[ 0.          0.          0.         -0.57956856]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 6681 is [True, False, False, False, True, False]
Current timestep = 6682. State = [[-0.37787378 -0.00296259]]. Action = [[-0.00152379 -0.03187656  0.          0.6759653 ]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 6682 is [True, False, False, False, True, False]
State prediction error at timestep 6682 is 0.012
Human Feedback received at timestep 6682 of None
Current timestep = 6683. State = [[-0.37935796 -0.00349776]]. Action = [[ 0.          0.          0.         -0.99882185]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 6683 is [True, False, False, False, True, False]
Current timestep = 6684. State = [[-0.38062912 -0.0032279 ]]. Action = [[0.        0.        0.        0.2303561]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 6684 is [True, False, False, False, True, False]
Current timestep = 6685. State = [[-0.3817079  -0.00299254]]. Action = [[0.         0.         0.         0.68522966]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 6685 is [True, False, False, False, True, False]
State prediction error at timestep 6685 is 0.012
Human Feedback received at timestep 6685 of None
Current timestep = 6686. State = [[-0.3790984  -0.00447335]]. Action = [[ 0.07058779 -0.03283955  0.          0.8124008 ]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 6686 is [True, False, False, False, True, False]
Current timestep = 6687. State = [[-0.3774834  -0.01000895]]. Action = [[-0.00186513 -0.0922445   0.          0.8917365 ]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 6687 is [True, False, False, False, True, False]
State prediction error at timestep 6687 is 0.012
Human Feedback received at timestep 6687 of None
Current timestep = 6688. State = [[-0.37710217 -0.01300721]]. Action = [[0.        0.        0.        0.5276116]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 6688 is [True, False, False, False, True, False]
Current timestep = 6689. State = [[-0.37673014 -0.01370826]]. Action = [[ 0.          0.          0.         -0.39882886]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 6689 is [True, False, False, False, True, False]
Current timestep = 6690. State = [[-0.37639695 -0.01435858]]. Action = [[ 0.          0.          0.         -0.80575126]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 6690 is [True, False, False, False, True, False]
Current timestep = 6691. State = [[-0.37278166 -0.01471631]]. Action = [[0.06969773 0.0058642  0.         0.50520253]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 6691 is [True, False, False, False, True, False]
Current timestep = 6692. State = [[-0.37271222 -0.01431175]]. Action = [[-0.04211327  0.0169883   0.         -0.9532796 ]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 6692 is [True, False, False, False, True, False]
Current timestep = 6693. State = [[-0.3721733  -0.01380004]]. Action = [[ 0.03299134  0.0099406   0.         -0.06170821]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 6693 is [True, False, False, False, True, False]
Current timestep = 6694. State = [[-0.3676598 -0.0112386]]. Action = [[0.07947885 0.05117586 0.         0.5684645 ]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 6694 is [True, False, False, False, True, False]
Current timestep = 6695. State = [[-0.3629877  -0.01260751]]. Action = [[ 0.05367313 -0.0548132   0.          0.34912086]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 6695 is [True, False, False, False, True, False]
State prediction error at timestep 6695 is 0.012
Human Feedback received at timestep 6695 of None
Current timestep = 6696. State = [[-0.36370614 -0.0138604 ]]. Action = [[-0.05623228  0.00915676  0.          0.29888904]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 6696 is [True, False, False, False, True, False]
State prediction error at timestep 6696 is 0.012
Human Feedback received at timestep 6696 of None
Current timestep = 6697. State = [[-0.36693403 -0.01509848]]. Action = [[-0.04498905 -0.02535392  0.          0.3879267 ]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 6697 is [True, False, False, False, True, False]
Current timestep = 6698. State = [[-0.36452654 -0.01406235]]. Action = [[ 0.07046767  0.03745591  0.         -0.8738509 ]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 6698 is [True, False, False, False, True, False]
Current timestep = 6699. State = [[-0.3603687  -0.01610327]]. Action = [[ 0.03999134 -0.06154833  0.         -0.8575036 ]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 6699 is [True, False, False, False, True, False]
Current timestep = 6700. State = [[-0.3608969  -0.01866219]]. Action = [[-0.05219488 -0.0134396   0.         -0.02167904]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 6700 is [True, False, False, False, True, False]
Current timestep = 6701. State = [[-0.3587287  -0.01891101]]. Action = [[ 0.05776557  0.00966016  0.         -0.49992818]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 6701 is [True, False, False, False, True, False]
State prediction error at timestep 6701 is 0.012
Human Feedback received at timestep 6701 of None
Current timestep = 6702. State = [[-0.35764226 -0.02234435]]. Action = [[-0.02529821 -0.06882014  0.          0.03600407]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 6702 is [True, False, False, False, True, False]
State prediction error at timestep 6702 is 0.012
Human Feedback received at timestep 6702 of None
Current timestep = 6703. State = [[-0.35337266 -0.02610278]]. Action = [[ 0.07931527 -0.02666204  0.         -0.06056613]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 6703 is [True, False, False, False, True, False]
State prediction error at timestep 6703 is 0.012
Human Feedback received at timestep 6703 of None
Current timestep = 6704. State = [[-0.34714505 -0.02715096]]. Action = [[0.06220191 0.00922431 0.         0.2982812 ]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 6704 is [True, False, False, False, True, False]
State prediction error at timestep 6704 is 0.012
Human Feedback received at timestep 6704 of None
Current timestep = 6705. State = [[-0.34512198 -0.02436631]]. Action = [[-0.01390544  0.0649017   0.          0.7192135 ]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 6705 is [True, False, False, False, True, False]
Current timestep = 6706. State = [[-0.34419906 -0.02432484]]. Action = [[ 0.01270218 -0.02706752  0.          0.00361311]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 6706 is [True, False, False, False, True, False]
State prediction error at timestep 6706 is 0.012
Human Feedback received at timestep 6706 of None
Current timestep = 6707. State = [[-0.33895662 -0.02421979]]. Action = [[0.08833256 0.02407442 0.         0.5163779 ]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 6707 is [True, False, False, False, True, False]
Current timestep = 6708. State = [[-0.33955762 -0.02187273]]. Action = [[-0.07636416  0.04020815  0.         -0.40367752]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 6708 is [True, False, False, False, True, False]
Current timestep = 6709. State = [[-0.341657  -0.0248641]]. Action = [[-0.00754616 -0.08270441  0.         -0.10555297]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 6709 is [True, False, False, False, True, False]
Current timestep = 6710. State = [[-0.3449191  -0.02260227]]. Action = [[-0.06615728  0.09631377  0.          0.6219058 ]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 6710 is [True, False, False, False, True, False]
Current timestep = 6711. State = [[-0.34647667 -0.02349088]]. Action = [[ 0.00663371 -0.07653533  0.          0.9646486 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 6711 is [True, False, False, False, True, False]
State prediction error at timestep 6711 is 0.012
Human Feedback received at timestep 6711 of None
Current timestep = 6712. State = [[-0.34243542 -0.02664881]]. Action = [[ 0.07788881 -0.02382102  0.          0.71605885]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 6712 is [True, False, False, False, True, False]
Current timestep = 6713. State = [[-0.34292883 -0.02938299]]. Action = [[-0.06365169 -0.03728841  0.          0.4487332 ]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 6713 is [True, False, False, False, True, False]
State prediction error at timestep 6713 is 0.012
Human Feedback received at timestep 6713 of None
Current timestep = 6714. State = [[-0.34589073 -0.02621903]]. Action = [[-0.02994636  0.08979928  0.          0.6929015 ]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 6714 is [True, False, False, False, True, False]
Current timestep = 6715. State = [[-0.35110867 -0.02695451]]. Action = [[-0.08424301 -0.0706542   0.         -0.32809508]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 6715 is [True, False, False, False, True, False]
State prediction error at timestep 6715 is 0.012
Human Feedback received at timestep 6715 of None
Current timestep = 6716. State = [[-0.35453957 -0.03207351]]. Action = [[-0.02098254 -0.06253563  0.          0.66860664]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 6716 is [True, False, False, False, True, False]
State prediction error at timestep 6716 is 0.012
Human Feedback received at timestep 6716 of None
Current timestep = 6717. State = [[-0.35737592 -0.02970096]]. Action = [[-0.03793345  0.09393943  0.         -0.28027356]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 6717 is [True, False, False, False, True, False]
Current timestep = 6718. State = [[-0.36130804 -0.02577598]]. Action = [[-0.03913504  0.0272259   0.         -0.810236  ]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 6718 is [True, False, False, False, True, False]
State prediction error at timestep 6718 is 0.012
Human Feedback received at timestep 6718 of None
Current timestep = 6719. State = [[-0.3682702  -0.02542095]]. Action = [[-0.09659456 -0.01482343  0.          0.20074022]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 6719 is [True, False, False, False, True, False]
Current timestep = 6720. State = [[-0.37338862 -0.02366091]]. Action = [[-0.02271863  0.03922883  0.          0.3751762 ]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 6720 is [True, False, False, False, True, False]
Current timestep = 6721. State = [[-0.37661836 -0.02002129]]. Action = [[-0.01436005  0.0429865   0.          0.06785583]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 6721 is [True, False, False, False, True, False]
Current timestep = 6722. State = [[-0.37906584 -0.01815105]]. Action = [[0.        0.        0.        0.7514231]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 6722 is [True, False, False, False, True, False]
Current timestep = 6723. State = [[-0.37868154 -0.01372948]]. Action = [[0.05290576 0.07473069 0.         0.04230297]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 6723 is [True, False, False, False, True, False]
Current timestep = 6724. State = [[-0.37913913 -0.01059515]]. Action = [[0.00815805 0.004701   0.         0.5905204 ]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 6724 is [True, False, False, False, True, False]
Current timestep = 6725. State = [[-0.37983963 -0.00522077]]. Action = [[ 0.02373309  0.08847662  0.         -0.66549647]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 6725 is [True, False, False, False, True, False]
Current timestep = 6726. State = [[-0.37773708 -0.00175467]]. Action = [[0.07573196 0.00178902 0.         0.856303  ]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 6726 is [True, False, False, False, True, False]
Current timestep = 6727. State = [[-0.37729484 -0.00069077]]. Action = [[0.         0.         0.         0.59111357]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 6727 is [True, False, False, False, True, False]
Current timestep = 6728. State = [[-0.3778874  -0.00263769]]. Action = [[ 0.00603004 -0.05689865  0.          0.7970989 ]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 6728 is [True, False, False, False, True, False]
State prediction error at timestep 6728 is 0.012
Human Feedback received at timestep 6728 of None
Current timestep = 6729. State = [[-0.37799075 -0.00352309]]. Action = [[0.         0.         0.         0.08639562]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 6729 is [True, False, False, False, True, False]
State prediction error at timestep 6729 is 0.012
Human Feedback received at timestep 6729 of None
Current timestep = 6730. State = [[-0.3779289  -0.00303204]]. Action = [[0.        0.        0.        0.4647832]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 6730 is [True, False, False, False, True, False]
Current timestep = 6731. State = [[-0.37484974 -0.00285245]]. Action = [[ 0.0563952  -0.00499956  0.         -0.836343  ]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 6731 is [True, False, False, False, True, False]
Current timestep = 6732. State = [[-0.37040436 -0.00435765]]. Action = [[ 0.04528833 -0.0328924   0.         -0.38914877]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 6732 is [True, False, False, False, True, False]
Current timestep = 6733. State = [[-0.36888853 -0.00989068]]. Action = [[-0.02046584 -0.09404976  0.         -0.6574668 ]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 6733 is [True, False, False, False, True, False]
State prediction error at timestep 6733 is 0.012
Human Feedback received at timestep 6733 of None
Current timestep = 6734. State = [[-0.36392164 -0.01033932]]. Action = [[0.08371084 0.05439875 0.         0.22751188]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 6734 is [True, False, False, False, True, False]
Current timestep = 6735. State = [[-0.36396098 -0.01226893]]. Action = [[-0.07834876 -0.06076897  0.         -0.90555567]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 6735 is [True, False, False, False, True, False]
State prediction error at timestep 6735 is 0.012
Human Feedback received at timestep 6735 of None
Current timestep = 6736. State = [[-0.3650016 -0.0159962]]. Action = [[-0.0085683  -0.03127335  0.         -0.21684533]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 6736 is [True, False, False, False, True, False]
State prediction error at timestep 6736 is 0.012
Human Feedback received at timestep 6736 of None
Current timestep = 6737. State = [[-0.36746272 -0.01299542]]. Action = [[-0.06445695  0.09366529  0.         -0.57316977]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 6737 is [True, False, False, False, True, False]
State prediction error at timestep 6737 is 0.012
Human Feedback received at timestep 6737 of None
Current timestep = 6738. State = [[-0.37101722 -0.00959866]]. Action = [[-0.04049236  0.02293663  0.         -0.570274  ]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 6738 is [True, False, False, False, True, False]
Current timestep = 6739. State = [[-0.37240562 -0.00888545]]. Action = [[ 0.          0.          0.         -0.24549925]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 6739 is [True, False, False, False, True, False]
Current timestep = 6740. State = [[-0.369363  -0.0038105]]. Action = [[0.07836073 0.0993072  0.         0.27043998]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 6740 is [True, False, False, False, True, False]
Current timestep = 6741. State = [[-0.36843854 -0.00058552]]. Action = [[ 0.         0.         0.        -0.9363201]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 6741 is [True, False, False, False, True, False]
Current timestep = 6742. State = [[-0.3711621  -0.00276169]]. Action = [[-0.04202439 -0.05605235  0.         -0.25683415]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 6742 is [True, False, False, False, True, False]
Current timestep = 6743. State = [[-0.3736838  -0.00057558]]. Action = [[-0.01626319  0.06824682  0.         -0.6303494 ]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 6743 is [True, False, False, False, True, False]
Current timestep = 6744. State = [[-0.37392485  0.00521308]]. Action = [[0.0270674  0.06799229 0.         0.35090697]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 6744 is [True, False, False, False, True, False]
Current timestep = 6745. State = [[-0.3744049   0.00798447]]. Action = [[0.        0.        0.        0.7041763]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 6745 is [True, False, False, False, True, False]
Current timestep = 6746. State = [[-0.37526911  0.00889696]]. Action = [[ 0.        0.        0.       -0.207564]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 6746 is [True, False, False, False, True, False]
Current timestep = 6747. State = [[-0.3759337   0.00971304]]. Action = [[ 0.          0.          0.         -0.29448587]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 6747 is [True, False, False, False, True, False]
Current timestep = 6748. State = [[-0.3719348   0.01259698]]. Action = [[0.09481166 0.04310182 0.         0.29843593]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 6748 is [True, False, False, False, True, False]
Current timestep = 6749. State = [[-0.36977112  0.01450028]]. Action = [[ 0.          0.          0.         -0.45521677]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 6749 is [True, False, False, False, True, False]
Current timestep = 6750. State = [[-0.3706067   0.01827145]]. Action = [[-0.01511905  0.06106461  0.         -0.3644303 ]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 6750 is [True, False, False, False, True, False]
Current timestep = 6751. State = [[-0.37295762  0.02308326]]. Action = [[-0.0316795   0.04629164  0.          0.79121494]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 6751 is [True, False, False, False, True, False]
State prediction error at timestep 6751 is 0.012
Human Feedback received at timestep 6751 of None
Current timestep = 6752. State = [[-0.3742402   0.02544704]]. Action = [[ 0.         0.         0.        -0.9461372]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 6752 is [True, False, False, False, True, False]
State prediction error at timestep 6752 is 0.012
Human Feedback received at timestep 6752 of None
Current timestep = 6753. State = [[-0.37340575  0.02436499]]. Action = [[ 0.01926863 -0.04361652  0.         -0.80167365]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 6753 is [True, False, False, False, True, False]
State prediction error at timestep 6753 is 0.012
Human Feedback received at timestep 6753 of None
Current timestep = 6754. State = [[-0.3725836   0.02399037]]. Action = [[ 0.         0.         0.        -0.1249873]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 6754 is [True, False, False, False, True, False]
State prediction error at timestep 6754 is 0.012
Human Feedback received at timestep 6754 of None
Current timestep = 6755. State = [[-0.36997235  0.02842303]]. Action = [[0.04957751 0.07640792 0.         0.18458915]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 6755 is [True, False, False, False, True, False]
Current timestep = 6756. State = [[-0.36527345  0.02772295]]. Action = [[ 0.06450903 -0.07247309  0.          0.8834038 ]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 6756 is [True, False, False, False, True, False]
Current timestep = 6757. State = [[-0.36035648  0.02782195]]. Action = [[ 0.04733606  0.03335609  0.         -0.7030156 ]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 6757 is [True, False, False, False, True, False]
State prediction error at timestep 6757 is 0.012
Human Feedback received at timestep 6757 of None
Current timestep = 6758. State = [[-0.3592295   0.02827768]]. Action = [[-0.02320736 -0.01481723  0.         -0.18268347]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 6758 is [True, False, False, False, True, False]
Current timestep = 6759. State = [[-0.35800797  0.02691095]]. Action = [[ 0.01483073 -0.02696464  0.         -0.90943974]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 6759 is [True, False, False, False, True, False]
Current timestep = 6760. State = [[-0.35734636  0.02786924]]. Action = [[-0.01661331  0.0310806   0.         -0.7793135 ]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 6760 is [True, False, False, False, True, False]
Current timestep = 6761. State = [[-0.36127296  0.03077217]]. Action = [[-0.08950036  0.03598096  0.         -0.7243239 ]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 6761 is [True, False, False, False, True, False]
Current timestep = 6762. State = [[-0.36074784  0.03431289]]. Action = [[ 0.05625396  0.04171393  0.         -0.36560792]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 6762 is [True, False, False, False, True, False]
Current timestep = 6763. State = [[-0.3587176   0.03851764]]. Action = [[0.00914191 0.05047513 0.         0.3858266 ]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 6763 is [True, False, False, False, True, False]
State prediction error at timestep 6763 is 0.012
Human Feedback received at timestep 6763 of None
Current timestep = 6764. State = [[-0.35878608  0.04316475]]. Action = [[-0.00670068  0.05134112  0.          0.05430615]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 6764 is [True, False, False, False, True, False]
Current timestep = 6765. State = [[-0.36025536  0.04534438]]. Action = [[-0.02186561 -0.00315784  0.         -0.17283118]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 6765 is [True, False, False, False, True, False]
Current timestep = 6766. State = [[-0.35808057  0.0474282 ]]. Action = [[ 0.0620139   0.02483533  0.         -0.39857465]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 6766 is [True, False, False, False, True, False]
Current timestep = 6767. State = [[-0.3611856   0.04803082]]. Action = [[-0.0994397  -0.02132878  0.          0.21381903]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 6767 is [True, False, False, False, True, False]
State prediction error at timestep 6767 is 0.012
Human Feedback received at timestep 6767 of None
Current timestep = 6768. State = [[-0.36629096  0.04821752]]. Action = [[-0.04392966 -0.00589111  0.          0.27935886]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 6768 is [True, False, False, False, True, False]
State prediction error at timestep 6768 is 0.012
Human Feedback received at timestep 6768 of None
Current timestep = 6769. State = [[-0.36390603  0.05102555]]. Action = [[0.09203982 0.04442469 0.         0.6605284 ]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 6769 is [True, False, False, False, True, False]
State prediction error at timestep 6769 is 0.012
Human Feedback received at timestep 6769 of None
Current timestep = 6770. State = [[-0.3606791   0.05548064]]. Action = [[0.02736459 0.05252448 0.         0.40080833]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 6770 is [True, False, False, False, True, False]
Current timestep = 6771. State = [[-0.35612297  0.06108564]]. Action = [[ 0.08606376  0.07056319  0.         -0.5932142 ]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 6771 is [True, False, False, False, True, False]
Current timestep = 6772. State = [[-0.35719427  0.06084552]]. Action = [[-0.07289533 -0.06213326  0.          0.99934006]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 6772 is [True, False, False, False, True, False]
Current timestep = 6773. State = [[-0.3556795   0.05708165]]. Action = [[ 0.07441644 -0.05710986  0.          0.03784108]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 6773 is [True, False, False, False, True, False]
Current timestep = 6774. State = [[-0.35733718  0.05457789]]. Action = [[-0.08232618 -0.02733525  0.         -0.8664047 ]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 6774 is [True, False, False, False, True, False]
Current timestep = 6775. State = [[-0.36385977  0.05527075]]. Action = [[-0.0951273   0.01959471  0.          0.35544276]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 6775 is [True, False, False, False, True, False]
State prediction error at timestep 6775 is 0.012
Human Feedback received at timestep 6775 of None
Current timestep = 6776. State = [[-0.3633021   0.06099196]]. Action = [[0.08182003 0.09853222 0.         0.47010827]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 6776 is [True, False, False, False, True, False]
Current timestep = 6777. State = [[-0.35835892  0.06483357]]. Action = [[ 0.0644147   0.01529549  0.         -0.77644515]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 6777 is [True, False, False, False, True, False]
Current timestep = 6778. State = [[-0.36037704  0.06490711]]. Action = [[-0.0861227  -0.01901234  0.          0.95726633]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 6778 is [True, False, False, False, True, False]
State prediction error at timestep 6778 is 0.012
Human Feedback received at timestep 6778 of None
Current timestep = 6779. State = [[-0.36297524  0.06731112]]. Action = [[-0.00333875  0.04747166  0.          0.70168626]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 6779 is [True, False, False, False, True, False]
State prediction error at timestep 6779 is 0.012
Human Feedback received at timestep 6779 of None
Current timestep = 6780. State = [[-0.36552167  0.06863321]]. Action = [[-0.03925837 -0.01166185  0.          0.9306164 ]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 6780 is [True, False, False, False, True, False]
Current timestep = 6781. State = [[-0.37013736  0.07324643]]. Action = [[-0.0604616   0.08513512  0.         -0.7933334 ]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 6781 is [True, False, False, False, True, False]
Current timestep = 6782. State = [[-0.3724308   0.07731743]]. Action = [[ 0.00980822  0.01843677  0.         -0.8421556 ]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 6782 is [True, False, False, False, True, False]
Current timestep = 6783. State = [[-0.36857873  0.0786306 ]]. Action = [[0.09718024 0.00083037 0.         0.38573003]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 6783 is [True, False, False, False, True, False]
Current timestep = 6784. State = [[-0.36225772  0.08073796]]. Action = [[ 0.09014844  0.0352275   0.         -0.883562  ]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 6784 is [True, False, False, False, True, False]
Current timestep = 6785. State = [[-0.3607953   0.08643948]]. Action = [[-0.01511183  0.08798382  0.          0.7505878 ]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 6785 is [True, False, False, False, True, False]
Current timestep = 6786. State = [[-0.36303878  0.08991104]]. Action = [[-0.03221174  0.00390114  0.          0.4525131 ]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 6786 is [True, False, False, False, True, False]
Current timestep = 6787. State = [[-0.36322632  0.09251972]]. Action = [[0.0186676  0.02751448 0.         0.44878972]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 6787 is [True, False, False, False, True, False]
Current timestep = 6788. State = [[-0.36614096  0.09706006]]. Action = [[-0.06529058  0.05329876  0.         -0.8122369 ]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 6788 is [True, False, False, False, True, False]
Current timestep = 6789. State = [[-0.37063703  0.09976076]]. Action = [[-0.0487981  -0.00509848  0.          0.51825047]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 6789 is [True, False, False, False, True, False]
Current timestep = 6790. State = [[-0.37300813  0.10153248]]. Action = [[-0.01193821  0.00720488  0.          0.9653945 ]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 6790 is [True, False, False, False, True, False]
Current timestep = 6791. State = [[-0.37378174  0.10307226]]. Action = [[ 0.         0.         0.        -0.5582684]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 6791 is [True, False, False, False, True, False]
Current timestep = 6792. State = [[-0.37508276  0.10855145]]. Action = [[-0.01509621  0.08731499  0.         -0.7451428 ]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 6792 is [True, False, False, False, True, False]
Current timestep = 6793. State = [[-0.37627903  0.11213682]]. Action = [[ 0.          0.          0.         -0.83966124]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 6793 is [True, False, False, False, True, False]
Current timestep = 6794. State = [[-0.37688994  0.11334862]]. Action = [[ 0.         0.         0.        -0.2703547]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 6794 is [True, False, False, False, True, False]
Current timestep = 6795. State = [[-0.37799582  0.11703958]]. Action = [[-0.01025145  0.0544083   0.          0.38733566]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 6795 is [True, False, False, False, True, False]
Current timestep = 6796. State = [[-0.37605453  0.11649454]]. Action = [[ 0.05609763 -0.06057224  0.          0.6748675 ]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 6796 is [True, False, False, False, True, False]
Current timestep = 6797. State = [[-0.3703794   0.11767813]]. Action = [[ 0.08642166  0.04704759  0.         -0.9814236 ]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 6797 is [True, False, False, False, True, False]
Current timestep = 6798. State = [[-0.36308953  0.12171951]]. Action = [[ 0.09530642  0.05358496  0.         -0.63594025]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 6798 is [True, False, False, False, True, False]
Current timestep = 6799. State = [[-0.35902777  0.1259032 ]]. Action = [[0.01535849 0.04946416 0.         0.91434884]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 6799 is [True, False, False, False, True, False]
State prediction error at timestep 6799 is 0.012
Human Feedback received at timestep 6799 of None
Current timestep = 6800. State = [[-0.35824046  0.12851267]]. Action = [[-0.01086025  0.01216515  0.         -0.9746741 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 6800 is [True, False, False, False, False, True]
Current timestep = 6801. State = [[-0.35801753  0.13387613]]. Action = [[-0.00531773  0.08443243  0.          0.8619449 ]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 6801 is [True, False, False, False, False, True]
Current timestep = 6802. State = [[-0.3587457   0.13423271]]. Action = [[-0.02604695 -0.06247545  0.          0.6277034 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 6802 is [True, False, False, False, False, True]
Current timestep = 6803. State = [[-0.36118755  0.13684426]]. Action = [[-0.05053374  0.06097481  0.          0.4530301 ]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 6803 is [True, False, False, False, False, True]
Current timestep = 6804. State = [[-0.36038667  0.14426507]]. Action = [[ 0.04251529  0.09371036  0.         -0.61527085]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 6804 is [True, False, False, False, False, True]
Current timestep = 6805. State = [[-0.3622405   0.14659344]]. Action = [[-0.06450492 -0.03418258  0.          0.72020936]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 6805 is [True, False, False, False, False, True]
Current timestep = 6806. State = [[-0.36417782  0.14381237]]. Action = [[-0.00436842 -0.06851666  0.          0.925246  ]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 6806 is [True, False, False, False, False, True]
Current timestep = 6807. State = [[-0.36917013  0.14709371]]. Action = [[-0.09457896  0.08369511  0.          0.41071057]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 6807 is [True, False, False, False, False, True]
State prediction error at timestep 6807 is 0.012
Human Feedback received at timestep 6807 of None
Current timestep = 6808. State = [[-0.37302047  0.14748207]]. Action = [[-0.01172046 -0.06647322  0.         -0.7666046 ]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 6808 is [True, False, False, False, False, True]
Current timestep = 6809. State = [[-0.369181    0.14242761]]. Action = [[ 0.09534147 -0.0840537   0.          0.5874517 ]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 6809 is [True, False, False, False, False, True]
State prediction error at timestep 6809 is 0.012
Human Feedback received at timestep 6809 of None
Current timestep = 6810. State = [[-0.3663161   0.13543566]]. Action = [[ 0.0012144  -0.09653356  0.         -0.35957545]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 6810 is [True, False, False, False, False, True]
Current timestep = 6811. State = [[-0.36614957  0.13687138]]. Action = [[-0.00543563  0.09085431  0.         -0.31120038]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 6811 is [True, False, False, False, False, True]
State prediction error at timestep 6811 is 0.012
Human Feedback received at timestep 6811 of None
Current timestep = 6812. State = [[-0.36270592  0.14184299]]. Action = [[ 0.07717132  0.05936836  0.         -0.8908585 ]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 6812 is [True, False, False, False, False, True]
State prediction error at timestep 6812 is 0.012
Human Feedback received at timestep 6812 of None
Current timestep = 6813. State = [[-0.36161125  0.14729907]]. Action = [[-0.01677376  0.08562083  0.         -0.23497367]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 6813 is [True, False, False, False, False, True]
Current timestep = 6814. State = [[-0.36301908  0.14574882]]. Action = [[-0.01927433 -0.0807766   0.          0.27559698]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 6814 is [True, False, False, False, False, True]
Current timestep = 6815. State = [[-0.35937425  0.13944013]]. Action = [[ 0.07959237 -0.08374429  0.         -0.6176452 ]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 6815 is [True, False, False, False, False, True]
Current timestep = 6816. State = [[-0.36085093  0.1399916 ]]. Action = [[-0.08422107  0.07402081  0.         -0.70371515]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 6816 is [True, False, False, False, False, True]
Current timestep = 6817. State = [[-0.36280996  0.13908586]]. Action = [[ 0.00450077 -0.06063875  0.         -0.04831088]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 6817 is [True, False, False, False, False, True]
Current timestep = 6818. State = [[-0.36511746  0.13555712]]. Action = [[-0.05085852 -0.04105756  0.          0.20878434]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 6818 is [True, False, False, False, False, True]
State prediction error at timestep 6818 is 0.012
Human Feedback received at timestep 6818 of None
Current timestep = 6819. State = [[-0.36896417  0.13115902]]. Action = [[-0.05167957 -0.06676397  0.          0.95745945]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 6819 is [True, False, False, False, False, True]
Current timestep = 6820. State = [[-0.3720515   0.13132659]]. Action = [[-0.0284102   0.04468819  0.          0.54001665]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 6820 is [True, False, False, False, False, True]
Current timestep = 6821. State = [[-0.3731825   0.12941773]]. Action = [[ 0.00544211 -0.05550515  0.         -0.60594285]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 6821 is [True, False, False, False, False, True]
Current timestep = 6822. State = [[-0.3735522   0.12735572]]. Action = [[0.         0.         0.         0.39619207]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 6822 is [True, False, False, False, False, True]
Current timestep = 6823. State = [[-0.37414855  0.1265882 ]]. Action = [[0.         0.         0.         0.41968346]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 6823 is [True, False, False, False, False, True]
Current timestep = 6824. State = [[-0.3747393   0.12448744]]. Action = [[ 0.00057455 -0.02787224  0.          0.21971929]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 6824 is [True, False, False, False, False, True]
Current timestep = 6825. State = [[-0.37528083  0.12296095]]. Action = [[0.      0.      0.      0.53738]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 6825 is [True, False, False, False, True, False]
Current timestep = 6826. State = [[-0.37176594  0.12528051]]. Action = [[ 0.08564096  0.06758564  0.         -0.30841893]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 6826 is [True, False, False, False, True, False]
Current timestep = 6827. State = [[-0.36780673  0.12534653]]. Action = [[ 0.04220722 -0.01511925  0.         -0.19738233]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 6827 is [True, False, False, False, False, True]
Current timestep = 6828. State = [[-0.36889553  0.12102043]]. Action = [[-0.04979659 -0.06875873  0.         -0.50558144]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 6828 is [True, False, False, False, False, True]
Current timestep = 6829. State = [[-0.36696568  0.12057099]]. Action = [[0.06691589 0.04161558 0.         0.7005204 ]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 6829 is [True, False, False, False, True, False]
Current timestep = 6830. State = [[-0.36625123  0.12056169]]. Action = [[-0.02919037 -0.01191281  0.          0.24659216]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 6830 is [True, False, False, False, True, False]
Current timestep = 6831. State = [[-0.36282718  0.11825115]]. Action = [[ 0.07500937 -0.03388115  0.          0.5420356 ]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 6831 is [True, False, False, False, True, False]
Current timestep = 6832. State = [[-0.3553604   0.12041264]]. Action = [[ 0.09782224  0.07879408  0.         -0.11648345]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 6832 is [True, False, False, False, True, False]
State prediction error at timestep 6832 is 0.012
Human Feedback received at timestep 6832 of None
Current timestep = 6833. State = [[-0.35037532  0.1220579 ]]. Action = [[0.02814666 0.00406818 0.         0.40546334]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 6833 is [True, False, False, False, True, False]
State prediction error at timestep 6833 is 0.012
Human Feedback received at timestep 6833 of None
Current timestep = 6834. State = [[-0.34661993  0.12311344]]. Action = [[ 0.03748512  0.02479567  0.         -0.604895  ]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 6834 is [True, False, False, False, True, False]
Current timestep = 6835. State = [[-0.34236407  0.12421151]]. Action = [[ 0.0417703   0.01189394  0.         -0.24631071]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 6835 is [True, False, False, False, True, False]
State prediction error at timestep 6835 is 0.012
Human Feedback received at timestep 6835 of None
Current timestep = 6836. State = [[-0.34365106  0.12675443]]. Action = [[-0.07570088  0.04097278  0.          0.6378838 ]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 6836 is [True, False, False, False, True, False]
Current timestep = 6837. State = [[-0.34412536  0.129867  ]]. Action = [[0.01388185 0.02748384 0.         0.5807178 ]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 6837 is [True, False, False, False, False, True]
Current timestep = 6838. State = [[-0.34053332  0.12973051]]. Action = [[ 0.05069654 -0.03092964  0.          0.6593845 ]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 6838 is [True, False, False, False, False, True]
Current timestep = 6839. State = [[-0.338005    0.12960535]]. Action = [[ 0.00186945  0.00382795  0.         -0.7433081 ]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 6839 is [True, False, False, False, False, True]
State prediction error at timestep 6839 is 0.012
Human Feedback received at timestep 6839 of None
Current timestep = 6840. State = [[-0.33972308  0.12923259]]. Action = [[-0.05777716 -0.02363595  0.         -0.32700682]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 6840 is [True, False, False, False, False, True]
State prediction error at timestep 6840 is 0.012
Human Feedback received at timestep 6840 of None
Current timestep = 6841. State = [[-0.33917946  0.12532192]]. Action = [[ 0.02364477 -0.08271891  0.         -0.4041463 ]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 6841 is [True, False, False, False, False, True]
State prediction error at timestep 6841 is 0.012
Human Feedback received at timestep 6841 of None
Current timestep = 6842. State = [[-0.33964083  0.12101901]]. Action = [[-0.044063   -0.0504116   0.          0.06978822]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 6842 is [True, False, False, False, False, True]
Current timestep = 6843. State = [[-0.3399794   0.12180395]]. Action = [[2.450496e-04 4.046958e-02 0.000000e+00 6.105565e-01]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 6843 is [True, False, False, False, True, False]
Current timestep = 6844. State = [[-0.33810136  0.12474518]]. Action = [[ 0.03232449  0.03818899  0.         -0.36185634]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 6844 is [True, False, False, False, True, False]
State prediction error at timestep 6844 is 0.012
Human Feedback received at timestep 6844 of None
Current timestep = 6845. State = [[-0.33836302  0.12778719]]. Action = [[-0.02516824  0.04113091  0.          0.5546659 ]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 6845 is [True, False, False, False, True, False]
Current timestep = 6846. State = [[-0.34257892  0.12673838]]. Action = [[-0.07187432 -0.05005756  0.          0.65123844]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 6846 is [True, False, False, False, False, True]
Current timestep = 6847. State = [[-0.34138626  0.12494554]]. Action = [[ 0.06988456 -0.01160571  0.         -0.09172046]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 6847 is [True, False, False, False, False, True]
State prediction error at timestep 6847 is 0.012
Human Feedback received at timestep 6847 of None
Current timestep = 6848. State = [[-0.33511177  0.12146658]]. Action = [[ 0.0876454  -0.05558214  0.          0.6596613 ]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 6848 is [True, False, False, False, True, False]
State prediction error at timestep 6848 is 0.012
Human Feedback received at timestep 6848 of None
Current timestep = 6849. State = [[-0.3327449   0.11849011]]. Action = [[-0.01481793 -0.01803695  0.          0.7710949 ]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 6849 is [True, False, False, False, True, False]
Current timestep = 6850. State = [[-0.3357214   0.11855971]]. Action = [[-0.06678769  0.01831739  0.          0.57154465]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 6850 is [True, False, False, False, True, False]
Current timestep = 6851. State = [[-0.3367731   0.12330549]]. Action = [[0.0156729  0.09044763 0.         0.3476956 ]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 6851 is [True, False, False, False, True, False]
State prediction error at timestep 6851 is 0.012
Human Feedback received at timestep 6851 of None
Current timestep = 6852. State = [[-0.33864605  0.12256508]]. Action = [[-0.04280025 -0.06495354  0.         -0.4489497 ]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 6852 is [True, False, False, False, True, False]
State prediction error at timestep 6852 is 0.012
Human Feedback received at timestep 6852 of None
Current timestep = 6853. State = [[-0.33658758  0.12132943]]. Action = [[ 0.07004633  0.0137058   0.         -0.36124742]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 6853 is [True, False, False, False, True, False]
Current timestep = 6854. State = [[-0.33874702  0.11678161]]. Action = [[-0.09067881 -0.09778395  0.          0.368479  ]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 6854 is [True, False, False, False, True, False]
Current timestep = 6855. State = [[-0.3440494  0.114452 ]]. Action = [[-0.05246531  0.00958421  0.         -0.04867035]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 6855 is [True, False, False, False, True, False]
Current timestep = 6856. State = [[-0.35050935  0.11444104]]. Action = [[-8.2846060e-02  5.1127374e-04  0.0000000e+00  5.8342218e-01]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 6856 is [True, False, False, False, True, False]
State prediction error at timestep 6856 is 0.012
Human Feedback received at timestep 6856 of None
Current timestep = 6857. State = [[-0.3555482   0.11544371]]. Action = [[-0.02991427  0.02317508  0.         -0.03352386]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 6857 is [True, False, False, False, True, False]
Current timestep = 6858. State = [[-0.36169234  0.11663367]]. Action = [[-0.07473455  0.01521917  0.         -0.03922421]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 6858 is [True, False, False, False, True, False]
Current timestep = 6859. State = [[-0.37010324  0.12078144]]. Action = [[-0.08818572  0.07646488  0.          0.8611202 ]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 6859 is [True, False, False, False, True, False]
State prediction error at timestep 6859 is 0.012
Human Feedback received at timestep 6859 of None
Current timestep = 6860. State = [[-0.37217817  0.12637156]]. Action = [[0.06433066 0.07305089 0.         0.27301562]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 6860 is [True, False, False, False, True, False]
Current timestep = 6861. State = [[-0.37409     0.12525137]]. Action = [[-0.02636629 -0.06345323  0.         -0.02929419]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 6861 is [True, False, False, False, False, True]
Current timestep = 6862. State = [[-0.3772535   0.12142814]]. Action = [[-0.01104058 -0.04303844  0.         -0.8017819 ]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 6862 is [True, False, False, False, False, True]
Current timestep = 6863. State = [[-0.37716478  0.11617827]]. Action = [[ 0.04100776 -0.07807621  0.         -0.04844993]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 6863 is [True, False, False, False, True, False]
Current timestep = 6864. State = [[-0.37375617  0.11776695]]. Action = [[0.07332519 0.09107392 0.         0.8542342 ]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 6864 is [True, False, False, False, True, False]
Current timestep = 6865. State = [[-0.37266222  0.11963169]]. Action = [[ 0.          0.          0.         -0.61222875]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 6865 is [True, False, False, False, True, False]
Current timestep = 6866. State = [[-0.36867127  0.12154163]]. Action = [[0.09372828 0.04654016 0.         0.5137739 ]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 6866 is [True, False, False, False, True, False]
Current timestep = 6867. State = [[-0.3697929   0.12186275]]. Action = [[-0.07496761 -0.01508535  0.          0.9588101 ]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 6867 is [True, False, False, False, True, False]
Current timestep = 6868. State = [[-0.36922938  0.12200876]]. Action = [[ 0.06221216  0.01379643  0.         -0.21017808]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 6868 is [True, False, False, False, True, False]
State prediction error at timestep 6868 is 0.012
Human Feedback received at timestep 6868 of None
Current timestep = 6869. State = [[-0.36289883  0.12059338]]. Action = [[ 0.09830325 -0.02782506  0.          0.45821047]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 6869 is [True, False, False, False, True, False]
State prediction error at timestep 6869 is 0.012
Human Feedback received at timestep 6869 of None
Current timestep = 6870. State = [[-0.363857    0.11873279]]. Action = [[-0.08934476 -0.01893256  0.         -0.39800614]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 6870 is [True, False, False, False, True, False]
Current timestep = 6871. State = [[-0.3680692  0.1223156]]. Action = [[-0.0409765   0.08192297  0.         -0.06122112]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 6871 is [True, False, False, False, True, False]
Current timestep = 6872. State = [[-0.3674581   0.12096499]]. Action = [[ 0.04155516 -0.07850214  0.         -0.48268664]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 6872 is [True, False, False, False, True, False]
Current timestep = 6873. State = [[-0.3659789   0.11702051]]. Action = [[ 0.00174101 -0.03585855  0.         -0.576045  ]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 6873 is [True, False, False, False, True, False]
Current timestep = 6874. State = [[-0.36504018  0.11941464]]. Action = [[0.0117235  0.07538661 0.         0.64940584]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 6874 is [True, False, False, False, True, False]
State prediction error at timestep 6874 is 0.012
Human Feedback received at timestep 6874 of None
Current timestep = 6875. State = [[-0.36520767  0.12380353]]. Action = [[-0.00930364  0.05087262  0.         -0.8165511 ]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 6875 is [True, False, False, False, True, False]
State prediction error at timestep 6875 is 0.012
Human Feedback received at timestep 6875 of None
Current timestep = 6876. State = [[-0.36945304  0.12344051]]. Action = [[-0.08132406 -0.04263661  0.         -0.34555185]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 6876 is [True, False, False, False, True, False]
Current timestep = 6877. State = [[-0.36938658  0.12451901]]. Action = [[0.05380569 0.03978883 0.         0.9880197 ]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 6877 is [True, False, False, False, True, False]
Current timestep = 6878. State = [[-0.36659753  0.12553567]]. Action = [[ 0.02859943 -0.00393037  0.         -0.2762435 ]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 6878 is [True, False, False, False, True, False]
Current timestep = 6879. State = [[-0.36686167  0.12223061]]. Action = [[-0.02929088 -0.07193886  0.         -0.65911996]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 6879 is [True, False, False, False, False, True]
State prediction error at timestep 6879 is 0.012
Human Feedback received at timestep 6879 of None
Current timestep = 6880. State = [[-0.36297002  0.11989268]]. Action = [[ 0.08658352 -0.01015846  0.         -0.26528668]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 6880 is [True, False, False, False, True, False]
Current timestep = 6881. State = [[-0.36254582  0.11557652]]. Action = [[-0.05910913 -0.08223967  0.          0.12708831]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 6881 is [True, False, False, False, True, False]
Current timestep = 6882. State = [[-0.3619799   0.11699472]]. Action = [[0.03397804 0.07872423 0.         0.17201698]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 6882 is [True, False, False, False, True, False]
Current timestep = 6883. State = [[-0.36033392  0.11946216]]. Action = [[ 0.00786839  0.01163203  0.         -0.9319257 ]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 6883 is [True, False, False, False, True, False]
Current timestep = 6884. State = [[-0.3605316   0.11910244]]. Action = [[-0.01830096 -0.01413528  0.          0.10915339]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 6884 is [True, False, False, False, True, False]
State prediction error at timestep 6884 is 0.012
Human Feedback received at timestep 6884 of None
Current timestep = 6885. State = [[-0.36517957  0.11472568]]. Action = [[-0.09569033 -0.08574774  0.         -0.6496539 ]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 6885 is [True, False, False, False, True, False]
Current timestep = 6886. State = [[-0.3701332   0.11319941]]. Action = [[-0.05182511  0.01214935  0.          0.28806782]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 6886 is [True, False, False, False, True, False]
Current timestep = 6887. State = [[-0.3720128   0.11342014]]. Action = [[0.         0.         0.         0.05455256]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 6887 is [True, False, False, False, True, False]
State prediction error at timestep 6887 is 0.012
Human Feedback received at timestep 6887 of None
Current timestep = 6888. State = [[-0.37397584  0.10863026]]. Action = [[-0.03018837 -0.0941278   0.         -0.8713237 ]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 6888 is [True, False, False, False, True, False]
Current timestep = 6889. State = [[-0.37274465  0.1098269 ]]. Action = [[ 0.05657371  0.09031593  0.         -0.19277453]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 6889 is [True, False, False, False, True, False]
Current timestep = 6890. State = [[-0.37018272  0.11237385]]. Action = [[ 0.03411978  0.01522015  0.         -0.7021164 ]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 6890 is [True, False, False, False, True, False]
Current timestep = 6891. State = [[-0.36872596  0.11308531]]. Action = [[0.01736702 0.01403649 0.         0.9106152 ]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 6891 is [True, False, False, False, True, False]
Current timestep = 6892. State = [[-0.3715296   0.11544851]]. Action = [[-0.06022083  0.04562379  0.          0.6916542 ]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 6892 is [True, False, False, False, True, False]
State prediction error at timestep 6892 is 0.012
Human Feedback received at timestep 6892 of None
Current timestep = 6893. State = [[-0.3737378   0.11676731]]. Action = [[0.        0.        0.        0.8163841]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 6893 is [True, False, False, False, True, False]
Current timestep = 6894. State = [[-0.3743672   0.11688825]]. Action = [[ 0.          0.          0.         -0.73410463]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 6894 is [True, False, False, False, True, False]
Current timestep = 6895. State = [[-0.374329    0.11439374]]. Action = [[ 0.00882064 -0.05241642  0.         -0.59301865]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 6895 is [True, False, False, False, True, False]
Current timestep = 6896. State = [[-0.3739748   0.11715502]]. Action = [[0.00901793 0.08681159 0.         0.61906874]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 6896 is [True, False, False, False, True, False]
State prediction error at timestep 6896 is 0.012
Human Feedback received at timestep 6896 of None
Current timestep = 6897. State = [[-0.37612087  0.12296156]]. Action = [[-0.0350455   0.06871968  0.         -0.9047896 ]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 6897 is [True, False, False, False, True, False]
Current timestep = 6898. State = [[-0.37788013  0.12534136]]. Action = [[0.         0.         0.         0.45893085]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 6898 is [True, False, False, False, True, False]
Current timestep = 6899. State = [[-0.37835944  0.12141448]]. Action = [[ 0.00138788 -0.09170815  0.         -0.60232854]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 6899 is [True, False, False, False, False, True]
Current timestep = 6900. State = [[-0.37680897  0.11748467]]. Action = [[ 0.03271248 -0.03579169  0.         -0.6632653 ]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 6900 is [True, False, False, False, True, False]
Current timestep = 6901. State = [[-0.3758222  0.1165068]]. Action = [[0.        0.        0.        0.3350122]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 6901 is [True, False, False, False, True, False]
State prediction error at timestep 6901 is 0.012
Human Feedback received at timestep 6901 of None
Current timestep = 6902. State = [[-0.3733591   0.12022933]]. Action = [[0.04882585 0.07691259 0.         0.77015185]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 6902 is [True, False, False, False, True, False]
Current timestep = 6903. State = [[-0.37416396  0.12643363]]. Action = [[-0.04041871  0.08374258  0.          0.19564462]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 6903 is [True, False, False, False, True, False]
Current timestep = 6904. State = [[-0.3710059   0.13336386]]. Action = [[0.09550954 0.09051377 0.         0.08201015]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 6904 is [True, False, False, False, False, True]
State prediction error at timestep 6904 is 0.012
Human Feedback received at timestep 6904 of None
Current timestep = 6905. State = [[-0.3714998   0.13890518]]. Action = [[-0.05944047  0.05418598  0.          0.34174192]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 6905 is [True, False, False, False, False, True]
Current timestep = 6906. State = [[-0.37351164  0.14121425]]. Action = [[ 0.         0.         0.        -0.7071212]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 6906 is [True, False, False, False, False, True]
Current timestep = 6907. State = [[-0.37590462  0.13811259]]. Action = [[-0.04239359 -0.0863023   0.         -0.77156323]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 6907 is [True, False, False, False, False, True]
Current timestep = 6908. State = [[-0.37766853  0.13699193]]. Action = [[-0.01112872  0.00146718  0.          0.8531387 ]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 6908 is [True, False, False, False, False, True]
Current timestep = 6909. State = [[-0.37816885  0.13788325]]. Action = [[0.         0.         0.         0.16072166]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 6909 is [True, False, False, False, False, True]
Current timestep = 6910. State = [[-0.37451255  0.13418184]]. Action = [[ 0.07376232 -0.08825161  0.          0.56921625]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 6910 is [True, False, False, False, False, True]
Current timestep = 6911. State = [[-0.3688351   0.13578297]]. Action = [[0.06713574 0.08352192 0.         0.9703388 ]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 6911 is [True, False, False, False, False, True]
Current timestep = 6912. State = [[-0.36566648  0.13654153]]. Action = [[ 0.01504918 -0.02989849  0.          0.10130024]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 6912 is [True, False, False, False, False, True]
State prediction error at timestep 6912 is 0.012
Human Feedback received at timestep 6912 of None
Current timestep = 6913. State = [[-0.36452428  0.13126984]]. Action = [[-0.0033747  -0.09634633  0.         -0.9386912 ]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 6913 is [True, False, False, False, False, True]
State prediction error at timestep 6913 is 0.012
Human Feedback received at timestep 6913 of None
Current timestep = 6914. State = [[-0.36698708  0.13225213]]. Action = [[-0.06651834  0.07501065  0.         -0.28702247]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 6914 is [True, False, False, False, False, True]
State prediction error at timestep 6914 is 0.012
Human Feedback received at timestep 6914 of None
Current timestep = 6915. State = [[-0.3698901   0.13574642]]. Action = [[-0.02694413  0.02634002  0.         -0.6192137 ]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 6915 is [True, False, False, False, False, True]
Current timestep = 6916. State = [[-0.3677864   0.13495068]]. Action = [[ 0.05834829 -0.03422152  0.         -0.94766796]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 6916 is [True, False, False, False, False, True]
Current timestep = 6917. State = [[-0.36768192  0.13809666]]. Action = [[-0.03201766  0.08774928  0.          0.3373834 ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 6917 is [True, False, False, False, False, True]
State prediction error at timestep 6917 is 0.012
Human Feedback received at timestep 6917 of None
Current timestep = 6918. State = [[-0.36401382  0.13932829]]. Action = [[ 0.09431525 -0.02159373  0.          0.6843476 ]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 6918 is [True, False, False, False, False, True]
Current timestep = 6919. State = [[-0.36226773  0.14041607]]. Action = [[-0.02051669  0.03696368  0.         -0.04822397]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 6919 is [True, False, False, False, False, True]
Current timestep = 6920. State = [[-0.3647186  0.143297 ]]. Action = [[-0.04155387  0.03539688  0.          0.89643645]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 6920 is [True, False, False, False, False, True]
State prediction error at timestep 6920 is 0.012
Human Feedback received at timestep 6920 of None
Current timestep = 6921. State = [[-0.36670852  0.148467  ]]. Action = [[-0.01080277  0.07656338  0.         -0.04852349]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 6921 is [True, False, False, False, False, True]
State prediction error at timestep 6921 is 0.012
Human Feedback received at timestep 6921 of None
Current timestep = 6922. State = [[-0.36863402  0.15146138]]. Action = [[-0.02161158  0.00608051  0.         -0.8383029 ]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 6922 is [True, False, False, False, False, True]
Current timestep = 6923. State = [[-0.36758363  0.15316388]]. Action = [[0.04350784 0.01629458 0.         0.99670243]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 6923 is [True, False, False, False, False, True]
Current timestep = 6924. State = [[-0.3689968   0.15901935]]. Action = [[-0.04253617  0.09703904  0.         -0.24595243]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 6924 is [True, False, False, False, False, True]
Current timestep = 6925. State = [[-0.3724488   0.16231017]]. Action = [[-0.03154788 -0.00794794  0.          0.9169512 ]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 6925 is [True, False, False, False, False, True]
Current timestep = 6926. State = [[-0.37591138  0.16432792]]. Action = [[-0.03635245  0.01800324  0.         -0.21730655]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 6926 is [True, False, False, False, False, True]
State prediction error at timestep 6926 is 0.012
Human Feedback received at timestep 6926 of None
Current timestep = 6927. State = [[-0.37776932  0.1660903 ]]. Action = [[ 0.          0.          0.         -0.05974787]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 6927 is [True, False, False, False, False, True]
Current timestep = 6928. State = [[-0.3775812  0.1642584]]. Action = [[ 0.01705402 -0.06143485  0.          0.41776955]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 6928 is [True, False, False, False, False, True]
Current timestep = 6929. State = [[-0.37284023  0.1610695 ]]. Action = [[ 0.09106009 -0.04586294  0.          0.41580653]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 6929 is [True, False, False, False, False, True]
Current timestep = 6930. State = [[-0.36582723  0.16202   ]]. Action = [[ 0.08613303  0.04380082  0.         -0.72097   ]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 6930 is [True, False, False, False, False, True]
Current timestep = 6931. State = [[-0.36191392  0.15882675]]. Action = [[ 0.0131693  -0.09130134  0.         -0.24856275]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 6931 is [True, False, False, False, False, True]
Current timestep = 6932. State = [[-0.3598082  0.1584098]]. Action = [[ 0.01691487  0.04284873  0.         -0.6557502 ]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 6932 is [True, False, False, False, False, True]
Current timestep = 6933. State = [[-0.35365608  0.1611679 ]]. Action = [[0.09943374 0.04272711 0.         0.9387301 ]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 6933 is [True, False, False, False, False, True]
Current timestep = 6934. State = [[-0.34522274  0.16462412]]. Action = [[0.09345499 0.06153912 0.         0.3142867 ]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 6934 is [True, False, False, False, False, True]
Current timestep = 6935. State = [[-0.33806655  0.16502157]]. Action = [[ 0.06064995 -0.01354415  0.         -0.12877524]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 6935 is [True, False, False, False, False, True]
Current timestep = 6936. State = [[-0.33232272  0.16792391]]. Action = [[0.04494738 0.07447296 0.         0.11473107]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 6936 is [True, False, False, False, False, True]
Current timestep = 6937. State = [[-0.33076173  0.16523106]]. Action = [[-0.03699861 -0.09923861  0.          0.39253438]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 6937 is [True, False, False, False, False, True]
Current timestep = 6938. State = [[-0.32698318  0.16222978]]. Action = [[ 0.06144278 -0.00870918  0.          0.10571849]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 6938 is [True, False, False, False, False, True]
State prediction error at timestep 6938 is 0.012
Human Feedback received at timestep 6938 of None
Current timestep = 6939. State = [[-0.32206887  0.15690657]]. Action = [[ 0.02648946 -0.09857575  0.         -0.63267225]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 6939 is [True, False, False, False, False, True]
Current timestep = 6940. State = [[-0.31497785  0.15490305]]. Action = [[0.08531194 0.02309121 0.         0.37578058]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 6940 is [True, False, False, False, False, True]
Current timestep = 6941. State = [[-0.31437016  0.15083481]]. Action = [[-0.08887158 -0.09008785  0.          0.08675945]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 6941 is [True, False, False, False, False, True]
Current timestep = 6942. State = [[-0.31458288  0.14784797]]. Action = [[ 0.01106496 -0.00308993  0.          0.58641624]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 6942 is [True, False, False, False, False, True]
Current timestep = 6943. State = [[-0.3083202   0.14288186]]. Action = [[ 0.09674957 -0.07893036  0.         -0.65429986]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 6943 is [True, False, False, False, False, True]
Current timestep = 6944. State = [[-0.30003896  0.14207357]]. Action = [[0.08657048 0.0594782  0.         0.39360487]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 6944 is [True, False, False, False, False, True]
State prediction error at timestep 6944 is 0.012
Human Feedback received at timestep 6944 of None
Current timestep = 6945. State = [[-0.2984087   0.14573492]]. Action = [[-0.04166288  0.07232525  0.          0.98317087]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 6945 is [True, False, False, False, False, True]
Current timestep = 6946. State = [[-0.30281672  0.15127341]]. Action = [[-0.08242812  0.08559664  0.          0.916651  ]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 6946 is [True, False, False, False, False, True]
Current timestep = 6947. State = [[-0.308421    0.15450257]]. Action = [[-0.0675302   0.01773916  0.         -0.07888079]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 6947 is [True, False, False, False, False, True]
Current timestep = 6948. State = [[-0.3127666   0.15799837]]. Action = [[-0.03908614  0.05303209  0.          0.17362642]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 6948 is [True, False, False, False, False, True]
Current timestep = 6949. State = [[-0.31390718  0.1614458 ]]. Action = [[ 0.01971543  0.0312359   0.         -0.6158019 ]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 6949 is [True, False, False, False, False, True]
Current timestep = 6950. State = [[-0.31473118  0.16502987]]. Action = [[-0.00471382  0.04431643  0.          0.5854101 ]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 6950 is [True, False, False, False, False, True]
Current timestep = 6951. State = [[-0.31672028  0.17137389]]. Action = [[-0.01228651  0.08964401  0.         -0.10106122]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 6951 is [True, False, False, False, False, True]
Current timestep = 6952. State = [[-0.31482035  0.17032808]]. Action = [[ 0.07058478 -0.09382887  0.          0.13675785]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 6952 is [True, False, False, False, False, True]
State prediction error at timestep 6952 is 0.012
Human Feedback received at timestep 6952 of None
Current timestep = 6953. State = [[-0.31245056  0.17004216]]. Action = [[ 0.01964273  0.03028478  0.         -0.40694404]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 6953 is [True, False, False, False, False, True]
Current timestep = 6954. State = [[-0.31535774  0.16801588]]. Action = [[-0.06813642 -0.07732735  0.         -0.39402878]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 6954 is [True, False, False, False, False, True]
State prediction error at timestep 6954 is 0.012
Human Feedback received at timestep 6954 of None
Current timestep = 6955. State = [[-0.31299418  0.16655734]]. Action = [[ 0.09386834 -0.00195616  0.         -0.17382401]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 6955 is [True, False, False, False, False, True]
Current timestep = 6956. State = [[-0.31142765  0.16940108]]. Action = [[-0.02568427  0.05041533  0.          0.66577864]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 6956 is [True, False, False, False, False, True]
Current timestep = 6957. State = [[-0.31009546  0.1701492 ]]. Action = [[ 0.0321536  -0.02571798  0.         -0.01528257]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 6957 is [True, False, False, False, False, True]
Current timestep = 6958. State = [[-0.31143633  0.16575967]]. Action = [[-0.05957863 -0.08956251  0.          0.81550205]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 6958 is [True, False, False, False, False, True]
State prediction error at timestep 6958 is 0.012
Human Feedback received at timestep 6958 of None
Current timestep = 6959. State = [[-0.31406295  0.1628521 ]]. Action = [[-0.03554965 -0.02153149  0.          0.4393977 ]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 6959 is [True, False, False, False, False, True]
Current timestep = 6960. State = [[-0.31499287  0.1577035 ]]. Action = [[-0.00883421 -0.09733878  0.         -0.502946  ]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 6960 is [True, False, False, False, False, True]
Current timestep = 6961. State = [[-0.31914467  0.15353514]]. Action = [[-0.09023079 -0.03094276  0.          0.72656417]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 6961 is [True, False, False, False, False, True]
State prediction error at timestep 6961 is 0.012
Human Feedback received at timestep 6961 of None
Current timestep = 6962. State = [[-0.31675553  0.1502869 ]]. Action = [[ 0.09928399 -0.0368065   0.          0.9599757 ]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 6962 is [True, False, False, False, False, True]
Current timestep = 6963. State = [[-0.31644467  0.15182464]]. Action = [[-0.05269126  0.07258543  0.         -0.96915454]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 6963 is [True, False, False, False, False, True]
Current timestep = 6964. State = [[-0.3201233   0.15188189]]. Action = [[-0.04473532 -0.02746852  0.          0.444363  ]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 6964 is [True, False, False, False, False, True]
Current timestep = 6965. State = [[-0.3175055   0.14574899]]. Action = [[ 0.08318596 -0.09832256  0.         -0.37801784]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 6965 is [True, False, False, False, False, True]
State prediction error at timestep 6965 is 0.012
Human Feedback received at timestep 6965 of None
Current timestep = 6966. State = [[-0.31055644  0.1376157 ]]. Action = [[ 0.09202426 -0.08336857  0.         -0.8358623 ]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 6966 is [True, False, False, False, False, True]
State prediction error at timestep 6966 is 0.012
Human Feedback received at timestep 6966 of None
Current timestep = 6967. State = [[-0.30799663  0.12950821]]. Action = [[-0.01562745 -0.08570658  0.         -0.7465747 ]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 6967 is [True, False, False, False, False, True]
Current timestep = 6968. State = [[-0.308398    0.12512368]]. Action = [[-0.01737557 -0.01074205  0.          0.11829782]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 6968 is [True, False, False, False, False, True]
Current timestep = 6969. State = [[-0.30880076  0.12380481]]. Action = [[-0.00852941  0.01275592  0.          0.10719657]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 6969 is [True, False, False, False, False, True]
State prediction error at timestep 6969 is 0.012
Human Feedback received at timestep 6969 of None
Current timestep = 6970. State = [[-0.3074548   0.11927536]]. Action = [[ 0.02512603 -0.06615863  0.          0.37128818]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 6970 is [True, False, False, False, True, False]
Current timestep = 6971. State = [[-0.30490422  0.1188391 ]]. Action = [[0.0309648  0.06460386 0.         0.00967669]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 6971 is [True, False, False, False, True, False]
Current timestep = 6972. State = [[-0.30139846  0.11410009]]. Action = [[ 0.04894962 -0.09586801  0.          0.36850488]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 6972 is [True, False, False, False, True, False]
Current timestep = 6973. State = [[-0.29481512  0.11291511]]. Action = [[ 0.09899778  0.06814868  0.         -0.33520424]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 6973 is [True, False, False, False, True, False]
State prediction error at timestep 6973 is 0.012
Human Feedback received at timestep 6973 of None
Current timestep = 6974. State = [[-0.29015833  0.11714291]]. Action = [[ 0.03236225  0.08895322  0.         -0.62662005]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 6974 is [True, False, False, False, True, False]
State prediction error at timestep 6974 is 0.012
Human Feedback received at timestep 6974 of None
Current timestep = 6975. State = [[-0.2896313   0.12310832]]. Action = [[-0.01291166  0.0971416   0.          0.48350763]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 6975 is [True, False, False, False, True, False]
Current timestep = 6976. State = [[-0.28761777  0.12164244]]. Action = [[ 0.04426198 -0.07419781  0.          0.7217643 ]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 6976 is [True, False, False, False, True, False]
Current timestep = 6977. State = [[-0.28890878  0.11686555]]. Action = [[-0.06642713 -0.0518938   0.         -0.22324169]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 6977 is [True, False, False, False, True, False]
Current timestep = 6978. State = [[-0.29439613  0.12040384]]. Action = [[-0.08895084  0.0993936   0.          0.43721843]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 6978 is [True, False, False, False, True, False]
State prediction error at timestep 6978 is 0.012
Human Feedback received at timestep 6978 of None
Current timestep = 6979. State = [[-0.30063927  0.12644729]]. Action = [[-0.07094608  0.05524541  0.         -0.33911526]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 6979 is [True, False, False, False, True, False]
Current timestep = 6980. State = [[-0.30806008  0.12877615]]. Action = [[-0.09554448 -0.00763717  0.         -0.21905577]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 6980 is [True, False, False, False, False, True]
State prediction error at timestep 6980 is 0.012
Human Feedback received at timestep 6980 of None
Current timestep = 6981. State = [[-0.30733436  0.13078187]]. Action = [[ 0.09722652  0.02526005  0.         -0.68212765]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 6981 is [True, False, False, False, False, True]
Current timestep = 6982. State = [[-0.30369374  0.12874585]]. Action = [[ 0.03203578 -0.07130726  0.          0.03548861]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 6982 is [True, False, False, False, False, True]
Current timestep = 6983. State = [[-0.30400005  0.13021944]]. Action = [[-0.02655485  0.05453485  0.         -0.07211256]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 6983 is [True, False, False, False, False, True]
Current timestep = 6984. State = [[-0.3061879   0.13452101]]. Action = [[-0.02332684  0.03981512  0.         -0.57054746]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 6984 is [True, False, False, False, False, True]
Current timestep = 6985. State = [[-0.3116901   0.13883223]]. Action = [[-0.08696552  0.04199394  0.          0.33392274]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 6985 is [True, False, False, False, False, True]
Current timestep = 6986. State = [[-0.31923243  0.13944426]]. Action = [[-0.08941586 -0.04037727  0.          0.37915337]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 6986 is [True, False, False, False, False, True]
Current timestep = 6987. State = [[-0.3253699   0.14018984]]. Action = [[-0.05390633  0.00876333  0.         -0.4880005 ]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 6987 is [True, False, False, False, False, True]
Current timestep = 6988. State = [[-0.32897094  0.14473641]]. Action = [[-0.01281758  0.06641623  0.          0.8062806 ]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 6988 is [True, False, False, False, False, True]
Current timestep = 6989. State = [[-0.32831538  0.14719953]]. Action = [[ 0.05592709 -0.00201865  0.         -0.7931665 ]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 6989 is [True, False, False, False, False, True]
Current timestep = 6990. State = [[-0.3237745   0.15070678]]. Action = [[0.09194828 0.06720305 0.         0.7381451 ]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 6990 is [True, False, False, False, False, True]
Current timestep = 6991. State = [[-0.32018423  0.14908373]]. Action = [[ 0.03837242 -0.07215385  0.         -0.4117006 ]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 6991 is [True, False, False, False, False, True]
Current timestep = 6992. State = [[-0.3201369   0.15176792]]. Action = [[-0.01200885  0.09283751  0.          0.903816  ]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 6992 is [True, False, False, False, False, True]
Current timestep = 6993. State = [[-0.32263544  0.15881152]]. Action = [[-0.0293861   0.08606433  0.         -0.80188453]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 6993 is [True, False, False, False, False, True]
Current timestep = 6994. State = [[-0.32614395  0.15796642]]. Action = [[-0.04216367 -0.08395907  0.          0.33536506]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 6994 is [True, False, False, False, False, True]
Current timestep = 6995. State = [[-0.32605383  0.15649131]]. Action = [[ 0.03294385 -0.00155095  0.          0.7820966 ]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 6995 is [True, False, False, False, False, True]
Current timestep = 6996. State = [[-0.3262054   0.16012037]]. Action = [[-0.01537286  0.06611203  0.          0.03036296]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 6996 is [True, False, False, False, False, True]
Current timestep = 6997. State = [[-0.32675716  0.15936436]]. Action = [[ 0.00182621 -0.0652      0.          0.41114783]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 6997 is [True, False, False, False, False, True]
Current timestep = 6998. State = [[-0.33099815  0.15874179]]. Action = [[-0.08758891  0.00783326  0.         -0.08831799]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 6998 is [True, False, False, False, False, True]
Current timestep = 6999. State = [[-0.32889974  0.15968795]]. Action = [[ 0.09878805  0.00610995  0.         -0.25270593]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 6999 is [True, False, False, False, False, True]
State prediction error at timestep 6999 is 0.012
Human Feedback received at timestep 6999 of None
Current timestep = 7000. State = [[-0.32361618  0.15751092]]. Action = [[ 0.04776695 -0.05038641  0.          0.69168246]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 7000 is [True, False, False, False, False, True]
Current timestep = 7001. State = [[-0.31975272  0.15562458]]. Action = [[ 0.03368881 -0.00992554  0.         -0.24758995]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 7001 is [True, False, False, False, False, True]
Current timestep = 7002. State = [[-0.3213462   0.15911584]]. Action = [[-0.06772709  0.07738017  0.         -0.68446183]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 7002 is [True, False, False, False, False, True]
Current timestep = 7003. State = [[-0.31985605  0.1572255 ]]. Action = [[ 0.05850706 -0.09082972  0.         -0.5470868 ]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 7003 is [True, False, False, False, False, True]
Current timestep = 7004. State = [[-0.31560907  0.15264037]]. Action = [[ 0.03699999 -0.03997383  0.          0.29375255]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 7004 is [True, False, False, False, False, True]
State prediction error at timestep 7004 is 0.012
Human Feedback received at timestep 7004 of None
Current timestep = 7005. State = [[-0.3146747   0.14928962]]. Action = [[-0.02484336 -0.03626902  0.          0.8593787 ]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 7005 is [True, False, False, False, False, True]
Current timestep = 7006. State = [[-0.3129874  0.151901 ]]. Action = [[0.03125148 0.08377933 0.         0.6970804 ]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 7006 is [True, False, False, False, False, True]
Current timestep = 7007. State = [[-0.3120509   0.15382402]]. Action = [[-0.0088066   0.00287852  0.          0.6310755 ]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 7007 is [True, False, False, False, False, True]
State prediction error at timestep 7007 is 0.012
Human Feedback received at timestep 7007 of None
Current timestep = 7008. State = [[-0.31327045  0.15345657]]. Action = [[-0.03079697 -0.0062914   0.         -0.7362095 ]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 7008 is [True, False, False, False, False, True]
State prediction error at timestep 7008 is 0.012
Human Feedback received at timestep 7008 of None
Current timestep = 7009. State = [[-0.3130947   0.15747622]]. Action = [[0.01798733 0.08850675 0.         0.11328423]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 7009 is [True, False, False, False, False, True]
Current timestep = 7010. State = [[-0.30866453  0.16050439]]. Action = [[ 0.08377067  0.01722342  0.         -0.77570236]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 7010 is [True, False, False, False, False, True]
Current timestep = 7011. State = [[-0.30429938  0.15815796]]. Action = [[ 0.03584117 -0.0542889   0.          0.75969887]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 7011 is [True, False, False, False, False, True]
Current timestep = 7012. State = [[-0.29879224  0.15224169]]. Action = [[ 0.07360626 -0.08717797  0.          0.76697874]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 7012 is [True, False, False, False, False, True]
Current timestep = 7013. State = [[-0.2996255  0.1537833]]. Action = [[-0.07998519  0.09139144  0.          0.916173  ]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 7013 is [True, False, False, False, False, True]
Current timestep = 7014. State = [[-0.29914507  0.1582669 ]]. Action = [[ 0.04449626  0.03730278  0.         -0.5686169 ]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 7014 is [True, False, False, False, False, True]
Current timestep = 7015. State = [[-0.2996642   0.16208163]]. Action = [[-0.03932353  0.04967251  0.         -0.5252239 ]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 7015 is [True, False, False, False, False, True]
Current timestep = 7016. State = [[-0.29978076  0.16868746]]. Action = [[0.01993783 0.09656491 0.         0.18455076]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 7016 is [True, False, False, False, False, True]
Current timestep = 7017. State = [[-0.3027635   0.17104957]]. Action = [[-0.06873781 -0.02322375  0.         -0.4862479 ]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 7017 is [True, False, False, False, False, True]
Current timestep = 7018. State = [[-0.30673552  0.17340572]]. Action = [[-0.03470313  0.03653235  0.         -0.96721375]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 7018 is [True, False, False, False, False, True]
Current timestep = 7019. State = [[-0.31200182  0.17504545]]. Action = [[-0.07255624 -0.01225983  0.          0.39045274]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 7019 is [True, False, False, False, False, True]
Current timestep = 7020. State = [[-0.31015277  0.1726974 ]]. Action = [[ 0.0935877  -0.06539202  0.          0.8068105 ]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 7020 is [True, False, False, False, False, True]
Current timestep = 7021. State = [[-0.30694917  0.17561242]]. Action = [[ 0.02285238  0.08796313  0.         -0.80334324]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 7021 is [True, False, False, False, False, True]
Current timestep = 7022. State = [[-0.3100358   0.17771381]]. Action = [[-0.07172557 -0.02155306  0.         -0.5525039 ]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 7022 is [True, False, False, False, False, True]
Current timestep = 7023. State = [[-0.31013888  0.17908749]]. Action = [[ 0.05028332  0.0229186   0.         -0.81617385]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 7023 is [True, False, False, False, False, True]
Current timestep = 7024. State = [[-0.3053029  0.1767546]]. Action = [[ 0.0772528  -0.06645432  0.         -0.61020243]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 7024 is [True, False, False, False, False, True]
Current timestep = 7025. State = [[-0.3000565   0.17592694]]. Action = [[ 0.05578581  0.02055232  0.         -0.7695196 ]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 7025 is [True, False, False, False, False, True]
State prediction error at timestep 7025 is 0.012
Human Feedback received at timestep 7025 of None
Current timestep = 7026. State = [[-0.29626772  0.17841278]]. Action = [[0.03317194 0.04423683 0.         0.26883626]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 7026 is [True, False, False, False, False, True]
State prediction error at timestep 7026 is 0.012
Human Feedback received at timestep 7026 of None
Current timestep = 7027. State = [[-0.28974384  0.17880899]]. Action = [[ 0.09780105 -0.01272257  0.         -0.61278385]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 7027 is [True, False, False, False, False, True]
Current timestep = 7028. State = [[-0.2861804   0.18299726]]. Action = [[-0.00444487  0.09864273  0.         -0.2996251 ]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 7028 is [True, False, False, False, False, True]
State prediction error at timestep 7028 is 0.012
Human Feedback received at timestep 7028 of None
Current timestep = 7029. State = [[-0.28516656  0.18240039]]. Action = [[-5.2540749e-04 -7.0049733e-02  0.0000000e+00 -9.3838227e-01]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 7029 is [True, False, False, False, False, True]
Current timestep = 7030. State = [[-0.28801274  0.18194552]]. Action = [[-0.08368488  0.016968    0.         -0.2872069 ]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 7030 is [True, False, False, False, False, True]
Current timestep = 7031. State = [[-0.2898431   0.18746224]]. Action = [[-0.00387503  0.09044524  0.         -0.26861668]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 7031 is [True, False, False, False, False, True]
State prediction error at timestep 7031 is 0.012
Human Feedback received at timestep 7031 of None
Current timestep = 7032. State = [[-0.29029596  0.18623263]]. Action = [[-0.01396991 -0.0922944   0.          0.69149816]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 7032 is [True, False, False, False, False, True]
State prediction error at timestep 7032 is 0.012
Human Feedback received at timestep 7032 of None
Current timestep = 7033. State = [[-0.2946094   0.18739462]]. Action = [[-0.0896382   0.05648058  0.          0.8006549 ]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 7033 is [True, False, False, False, False, True]
Current timestep = 7034. State = [[-0.29675984  0.19110751]]. Action = [[ 0.01156714  0.02599593  0.         -0.47893786]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 7034 is [True, False, False, False, False, True]
Current timestep = 7035. State = [[-0.2960149   0.19426562]]. Action = [[0.02053555 0.03406277 0.         0.81428313]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 7035 is [True, False, False, False, False, True]
Current timestep = 7036. State = [[-0.29484093  0.1943448 ]]. Action = [[ 0.02066199 -0.03000622  0.         -0.51179606]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 7036 is [True, False, False, False, False, True]
Current timestep = 7037. State = [[-0.2985345   0.19629999]]. Action = [[-0.08125899  0.04220933  0.          0.22893882]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 7037 is [True, False, False, False, False, True]
Current timestep = 7038. State = [[-0.30574185  0.19429211]]. Action = [[-0.09164721 -0.08756479  0.          0.8735118 ]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 7038 is [True, False, False, False, False, True]
Current timestep = 7039. State = [[-0.30905202  0.19609764]]. Action = [[ 0.00497083  0.0670863   0.         -0.10544497]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 7039 is [True, False, False, False, False, True]
Current timestep = 7040. State = [[-0.31319475  0.19754122]]. Action = [[-0.07065396 -0.02566051  0.         -0.40339434]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 7040 is [True, False, False, False, False, True]
State prediction error at timestep 7040 is 0.012
Human Feedback received at timestep 7040 of None
Current timestep = 7041. State = [[-0.23985936 -0.06104388]]. Action = [[0.04475953 0.08290794 0.         0.46891403]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 7041 is [True, False, False, False, False, True]
Current timestep = 7042. State = [[-0.24326274 -0.06620041]]. Action = [[ 0.00332904 -0.05961703  0.         -0.41381192]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 7042 is [True, False, False, False, True, False]
State prediction error at timestep 7042 is 0.012
Human Feedback received at timestep 7042 of None
Current timestep = 7043. State = [[-0.24831821 -0.06711153]]. Action = [[-0.08695429  0.01768984  0.         -0.6819748 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 7043 is [True, False, False, False, True, False]
State prediction error at timestep 7043 is 0.012
Human Feedback received at timestep 7043 of None
Current timestep = 7044. State = [[-0.25570226 -0.06223788]]. Action = [[-0.08132742  0.08788215  0.         -0.6347894 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 7044 is [True, False, False, False, True, False]
Current timestep = 7045. State = [[-0.25722942 -0.06008835]]. Action = [[ 0.05231061 -0.01983911  0.          0.66017747]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 7045 is [True, False, False, False, True, False]
Current timestep = 7046. State = [[-0.25414726 -0.05943891]]. Action = [[ 0.05892094  0.01052056  0.         -0.54584366]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 7046 is [True, False, False, False, True, False]
Current timestep = 7047. State = [[-0.2572854  -0.05791569]]. Action = [[-0.08706466  0.01712599  0.          0.2243309 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 7047 is [True, False, False, False, True, False]
Current timestep = 7048. State = [[-0.25639778 -0.05830062]]. Action = [[ 0.09934779 -0.0289683   0.          0.8385999 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 7048 is [True, False, False, False, True, False]
Current timestep = 7049. State = [[-0.25391552 -0.05636509]]. Action = [[0.00937422 0.04885329 0.         0.46312225]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7049 is [True, False, False, False, True, False]
State prediction error at timestep 7049 is 0.012
Human Feedback received at timestep 7049 of None
Current timestep = 7050. State = [[-0.2552196  -0.05068983]]. Action = [[-0.02562986  0.0783697   0.          0.4856453 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 7050 is [True, False, False, False, True, False]
Current timestep = 7051. State = [[-0.25368193 -0.04598842]]. Action = [[0.057446   0.03226254 0.         0.68254733]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 7051 is [True, False, False, False, True, False]
State prediction error at timestep 7051 is 0.012
Human Feedback received at timestep 7051 of None
Current timestep = 7052. State = [[-0.24875161 -0.04243548]]. Action = [[0.07988807 0.02962797 0.         0.7330369 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 7052 is [True, False, False, False, True, False]
Current timestep = 7053. State = [[-0.25058985 -0.03935992]]. Action = [[-0.08826856  0.02509653  0.          0.35684097]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 7053 is [True, False, False, False, True, False]
Current timestep = 7054. State = [[-0.25393707 -0.03650828]]. Action = [[-0.00933462  0.02140151  0.          0.28370667]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 7054 is [True, False, False, False, True, False]
State prediction error at timestep 7054 is 0.012
Human Feedback received at timestep 7054 of None
Current timestep = 7055. State = [[-0.25152665 -0.03925323]]. Action = [[ 0.0697596  -0.08945558  0.          0.22204089]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 7055 is [True, False, False, False, True, False]
Current timestep = 7056. State = [[-0.25066477 -0.03717037]]. Action = [[-0.01796492  0.08008667  0.         -0.9169503 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 7056 is [True, False, False, False, True, False]
Current timestep = 7057. State = [[-0.24738967 -0.03852285]]. Action = [[ 0.0801506  -0.08537295  0.          0.7935705 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 7057 is [True, False, False, False, True, False]
State prediction error at timestep 7057 is 0.012
Human Feedback received at timestep 7057 of None
Current timestep = 7058. State = [[-0.24019924 -0.04046449]]. Action = [[ 0.09565219  0.00275077  0.         -0.6470914 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 7058 is [True, False, False, False, True, False]
Current timestep = 7059. State = [[-0.23929287 -0.03558757]]. Action = [[-0.0568622   0.09779171  0.         -0.78431624]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 7059 is [True, False, False, False, True, False]
Current timestep = 7060. State = [[-0.24214426 -0.02804341]]. Action = [[-0.02889777  0.08656918  0.         -0.53804064]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 7060 is [True, False, False, False, True, False]
Current timestep = 7061. State = [[-0.24692869 -0.02820394]]. Action = [[-0.07912587 -0.07268215  0.          0.46676123]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 7061 is [True, False, False, False, True, False]
Current timestep = 7062. State = [[-0.25217742 -0.02651625]]. Action = [[-0.06457287  0.06191321  0.         -0.63856316]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 7062 is [True, False, False, False, True, False]
Current timestep = 7063. State = [[-0.25482804 -0.01892101]]. Action = [[-0.00781108  0.09979578  0.          0.39172924]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 7063 is [True, False, False, False, True, False]
Current timestep = 7064. State = [[-0.2517434  -0.01027279]]. Action = [[ 0.09297105  0.0834538   0.         -0.6044595 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 7064 is [True, False, False, False, True, False]
Current timestep = 7065. State = [[-0.24707487 -0.00698197]]. Action = [[ 0.06724016 -0.01911526  0.         -0.8029056 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 7065 is [True, False, False, False, True, False]
Current timestep = 7066. State = [[-0.24493806 -0.00728429]]. Action = [[ 0.01331817 -0.02457856  0.         -0.57200605]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 7066 is [True, False, False, False, True, False]
Current timestep = 7067. State = [[-0.24589804 -0.00998526]]. Action = [[-0.03072237 -0.05959264  0.          0.15680611]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 7067 is [True, False, False, False, True, False]
Current timestep = 7068. State = [[-0.2466608  -0.00697535]]. Action = [[-0.00399201  0.08225197  0.          0.18125224]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 7068 is [True, False, False, False, True, False]
Current timestep = 7069. State = [[-0.2507624  -0.00532356]]. Action = [[-0.08619897 -0.02977514  0.          0.33604443]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 7069 is [True, False, False, False, True, False]
Current timestep = 7070. State = [[-0.24852782 -0.00478271]]. Action = [[0.09870265 0.01127622 0.         0.67235374]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 7070 is [True, False, False, False, True, False]
Current timestep = 7071. State = [[-0.24177729 -0.00180607]]. Action = [[0.0721968  0.04336154 0.         0.938957  ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 7071 is [True, False, False, False, True, False]
Current timestep = 7072. State = [[-0.24180365 -0.00393947]]. Action = [[-0.06929074 -0.0773911   0.         -0.63262177]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 7072 is [True, False, False, False, True, False]
Current timestep = 7073. State = [[-0.2397557  -0.00638641]]. Action = [[ 0.06133654 -0.00812989  0.         -0.333695  ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 7073 is [True, False, False, False, True, False]
Current timestep = 7074. State = [[-0.24142648 -0.0116366 ]]. Action = [[-0.0960334  -0.09546271  0.          0.69119287]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 7074 is [True, False, False, False, True, False]
Current timestep = 7075. State = [[-0.2470285  -0.01275693]]. Action = [[-0.08300006  0.04131263  0.          0.24292982]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 7075 is [True, False, False, False, True, False]
Current timestep = 7076. State = [[-0.25289482 -0.01487359]]. Action = [[-0.08072478 -0.05774092  0.          0.05227971]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 7076 is [True, False, False, False, True, False]
Current timestep = 7077. State = [[-0.2565756  -0.01644771]]. Action = [[-0.02913129  0.00898337  0.          0.6694119 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 7077 is [True, False, False, False, True, False]
Current timestep = 7078. State = [[-0.25376305 -0.01502275]]. Action = [[ 0.09233937  0.03164231  0.         -0.22920626]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 7078 is [True, False, False, False, True, False]
State prediction error at timestep 7078 is 0.012
Human Feedback received at timestep 7078 of None
Current timestep = 7079. State = [[-0.2531011  -0.01858964]]. Action = [[-0.02609871 -0.08355735  0.          0.842016  ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 7079 is [True, False, False, False, True, False]
Current timestep = 7080. State = [[-0.2581877  -0.01657631]]. Action = [[-0.08256456  0.09995725  0.         -0.04118276]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 7080 is [True, False, False, False, True, False]
Current timestep = 7081. State = [[-0.2613657  -0.01417778]]. Action = [[ 0.00107358 -0.005776    0.         -0.76079553]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 7081 is [True, False, False, False, True, False]
Current timestep = 7082. State = [[-0.26669943 -0.01431839]]. Action = [[-0.08768489 -0.00346926  0.         -0.8324398 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 7082 is [True, False, False, False, True, False]
Current timestep = 7083. State = [[-0.26976177 -0.01685928]]. Action = [[ 0.0094953  -0.04914541  0.          0.45902658]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 7083 is [True, False, False, False, True, False]
Current timestep = 7084. State = [[-0.27168635 -0.01860366]]. Action = [[-0.01948131 -0.00302766  0.         -0.8661532 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 7084 is [True, False, False, False, True, False]
Current timestep = 7085. State = [[-0.2720691  -0.02378353]]. Action = [[ 0.02473768 -0.09481212  0.         -0.604535  ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 7085 is [True, False, False, False, True, False]
Current timestep = 7086. State = [[-0.2761352  -0.03189821]]. Action = [[-0.08437049 -0.09294543  0.          0.08770299]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 7086 is [True, False, False, False, True, False]
Current timestep = 7087. State = [[-0.28150767 -0.03868552]]. Action = [[-0.04951953 -0.05678397  0.          0.637303  ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 7087 is [True, False, False, False, True, False]
Current timestep = 7088. State = [[-0.28391695 -0.04456741]]. Action = [[-0.002422   -0.05388365  0.         -0.4818849 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 7088 is [True, False, False, False, True, False]
Current timestep = 7089. State = [[-0.28628257 -0.04337366]]. Action = [[-0.02442987  0.08672338  0.          0.61189866]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 7089 is [True, False, False, False, True, False]
Current timestep = 7090. State = [[-0.28442097 -0.04621382]]. Action = [[ 0.08304369 -0.08585885  0.         -0.7121393 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 7090 is [True, False, False, False, True, False]
Current timestep = 7091. State = [[-0.28625107 -0.04815541]]. Action = [[-0.07315272  0.03335396  0.          0.37626195]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 7091 is [True, False, False, False, True, False]
State prediction error at timestep 7091 is 0.012
Human Feedback received at timestep 7091 of None
Current timestep = 7092. State = [[-0.29263172 -0.04351304]]. Action = [[-0.05983099  0.09360483  0.         -0.52879447]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 7092 is [True, False, False, False, True, False]
Current timestep = 7093. State = [[-0.2985729  -0.04441765]]. Action = [[-0.04736006 -0.06737152  0.          0.16204429]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 7093 is [True, False, False, False, True, False]
State prediction error at timestep 7093 is 0.012
Human Feedback received at timestep 7093 of None
Current timestep = 7094. State = [[-0.2988765  -0.04335463]]. Action = [[ 0.06345657  0.06366428  0.         -0.35191983]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 7094 is [True, False, False, False, True, False]
Current timestep = 7095. State = [[-0.30204892 -0.0365693 ]]. Action = [[-0.06049137  0.09481656  0.          0.38703156]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 7095 is [True, False, False, False, True, False]
Current timestep = 7096. State = [[-0.30332866 -0.03269269]]. Action = [[ 0.05477517  0.0047157   0.         -0.5687888 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 7096 is [True, False, False, False, True, False]
State prediction error at timestep 7096 is 0.012
Human Feedback received at timestep 7096 of None
Current timestep = 7097. State = [[-0.30108684 -0.03614471]]. Action = [[ 0.05526408 -0.09194344  0.         -0.63455844]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 7097 is [True, False, False, False, True, False]
Current timestep = 7098. State = [[-0.29692158 -0.03990792]]. Action = [[ 0.07700979 -0.03013505  0.         -0.05559283]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 7098 is [True, False, False, False, True, False]
State prediction error at timestep 7098 is 0.012
Human Feedback received at timestep 7098 of None
Current timestep = 7099. State = [[-0.2915849  -0.04452062]]. Action = [[ 0.07492691 -0.07365195  0.          0.40255606]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 7099 is [True, False, False, False, True, False]
Current timestep = 7100. State = [[-0.28981596 -0.0520947 ]]. Action = [[-0.01387001 -0.09896354  0.         -0.01283908]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 7100 is [True, False, False, False, True, False]
Current timestep = 7101. State = [[-0.28494114 -0.06066369]]. Action = [[ 0.09078536 -0.09086796  0.         -0.22397202]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 7101 is [True, False, False, False, True, False]
State prediction error at timestep 7101 is 0.012
Human Feedback received at timestep 7101 of None
Current timestep = 7102. State = [[-0.28520858 -0.06668968]]. Action = [[-0.09393002 -0.02990554  0.          0.5433965 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 7102 is [True, False, False, False, True, False]
Current timestep = 7103. State = [[-0.2872659  -0.07435597]]. Action = [[-0.00558301 -0.09552367  0.         -0.7602312 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 7103 is [True, False, False, False, True, False]
State prediction error at timestep 7103 is 0.012
Human Feedback received at timestep 7103 of None
Current timestep = 7104. State = [[-0.29106316 -0.07630721]]. Action = [[-0.08260318  0.06081986  0.          0.99125147]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 7104 is [True, False, False, False, True, False]
State prediction error at timestep 7104 is 0.012
Human Feedback received at timestep 7104 of None
Current timestep = 7105. State = [[-0.28928524 -0.08039925]]. Action = [[ 0.09833165 -0.08238339  0.          0.11570644]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 7105 is [True, False, False, False, True, False]
Current timestep = 7106. State = [[-0.28491262 -0.08875149]]. Action = [[ 0.01767655 -0.08132675  0.         -0.09182006]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 7106 is [True, False, False, False, True, False]
State prediction error at timestep 7106 is 0.012
Human Feedback received at timestep 7106 of None
Current timestep = 7107. State = [[-0.2791927  -0.09823602]]. Action = [[ 0.07872865 -0.09568056  0.         -0.33045173]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 7107 is [True, False, False, False, True, False]
Current timestep = 7108. State = [[-0.27928975 -0.10427386]]. Action = [[-0.08431483 -0.01006416  0.         -0.08545047]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 7108 is [True, False, False, False, True, False]
Current timestep = 7109. State = [[-0.2819683  -0.10420801]]. Action = [[-0.02100922  0.05714641  0.         -0.17124486]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 7109 is [True, False, False, False, True, False]
Current timestep = 7110. State = [[-0.28699577 -0.10425806]]. Action = [[-0.08979943  0.00278835  0.         -0.47776586]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 7110 is [True, False, False, False, True, False]
Current timestep = 7111. State = [[-0.29161066 -0.1047281 ]]. Action = [[-0.03697776  0.01722155  0.          0.9272883 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 7111 is [True, False, False, False, True, False]
Current timestep = 7112. State = [[-0.29474688 -0.10402481]]. Action = [[-0.02834662  0.02206473  0.         -0.98493946]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 7112 is [True, False, False, False, True, False]
Current timestep = 7113. State = [[-0.2927716  -0.10579237]]. Action = [[ 0.07748564 -0.04464242  0.          0.37541115]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 7113 is [True, False, False, False, True, False]
State prediction error at timestep 7113 is 0.012
Human Feedback received at timestep 7113 of None
Current timestep = 7114. State = [[-0.29569066 -0.10870694]]. Action = [[-0.09837203 -0.02410246  0.          0.5251188 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 7114 is [True, False, False, False, True, False]
Current timestep = 7115. State = [[-0.29987943 -0.10944635]]. Action = [[-0.00882491  0.0081565   0.          0.51291776]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 7115 is [True, False, False, False, True, False]
State prediction error at timestep 7115 is 0.012
Human Feedback received at timestep 7115 of None
Current timestep = 7116. State = [[-0.29809496 -0.10800371]]. Action = [[0.07070386 0.02272705 0.         0.14508581]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 7116 is [True, False, False, False, True, False]
Current timestep = 7117. State = [[-0.2965447  -0.10345703]]. Action = [[ 0.01655672  0.06485983  0.         -0.754635  ]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 7117 is [True, False, False, False, True, False]
Current timestep = 7118. State = [[-0.29359794 -0.10116351]]. Action = [[ 0.07288656 -0.01024443  0.         -0.31551206]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 7118 is [True, False, False, False, True, False]
Current timestep = 7119. State = [[-0.29636565 -0.09841174]]. Action = [[-0.08735684  0.04874659  0.         -0.18812716]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 7119 is [True, False, False, False, True, False]
Current timestep = 7120. State = [[-0.29843622 -0.09831483]]. Action = [[ 0.03938758 -0.04230651  0.          0.7412815 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 7120 is [True, False, False, False, True, False]
Current timestep = 7121. State = [[-0.29904735 -0.10064712]]. Action = [[-0.009656   -0.03624216  0.          0.19112146]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 7121 is [True, False, False, False, True, False]
State prediction error at timestep 7121 is 0.012
Human Feedback received at timestep 7121 of None
Current timestep = 7122. State = [[-0.29719386 -0.09743841]]. Action = [[ 0.05954594  0.07687327  0.         -0.41871142]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 7122 is [True, False, False, False, True, False]
State prediction error at timestep 7122 is 0.012
Human Feedback received at timestep 7122 of None
Current timestep = 7123. State = [[-0.30006808 -0.09492476]]. Action = [[-0.08009739 -0.0057383   0.         -0.20504332]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 7123 is [True, False, False, False, True, False]
State prediction error at timestep 7123 is 0.012
Human Feedback received at timestep 7123 of None
Current timestep = 7124. State = [[-0.30275905 -0.09357477]]. Action = [[0.00101571 0.02198501 0.         0.75632477]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 7124 is [True, False, False, False, True, False]
State prediction error at timestep 7124 is 0.012
Human Feedback received at timestep 7124 of None
Current timestep = 7125. State = [[-0.3021208  -0.09201247]]. Action = [[0.02631963 0.00773709 0.         0.45911217]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 7125 is [True, False, False, False, True, False]
Current timestep = 7126. State = [[-0.30091497 -0.09589978]]. Action = [[ 0.01711397 -0.0938216   0.          0.35675168]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 7126 is [True, False, False, False, True, False]
State prediction error at timestep 7126 is 0.012
Human Feedback received at timestep 7126 of None
Current timestep = 7127. State = [[-0.3015031  -0.09570799]]. Action = [[-0.02148568  0.05729692  0.         -0.9853315 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 7127 is [True, False, False, False, True, False]
Current timestep = 7128. State = [[-0.30098814 -0.09744443]]. Action = [[ 0.02440904 -0.06694607  0.         -0.42376226]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 7128 is [True, False, False, False, True, False]
Current timestep = 7129. State = [[-0.30003807 -0.09898592]]. Action = [[0.00384291 0.00922956 0.         0.9318557 ]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 7129 is [True, False, False, False, True, False]
State prediction error at timestep 7129 is 0.012
Human Feedback received at timestep 7129 of None
Current timestep = 7130. State = [[-0.2997408  -0.10030642]]. Action = [[-2.1593273e-04 -2.4923697e-02  0.0000000e+00  3.0676663e-01]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 7130 is [True, False, False, False, True, False]
Current timestep = 7131. State = [[-0.30188304 -0.0985764 ]]. Action = [[-0.04806487  0.05750982  0.          0.9777715 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 7131 is [True, False, False, False, True, False]
Current timestep = 7132. State = [[-0.30122513 -0.0942454 ]]. Action = [[ 0.04078748  0.05635432  0.         -0.6758159 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 7132 is [True, False, False, False, True, False]
State prediction error at timestep 7132 is 0.012
Human Feedback received at timestep 7132 of None
Current timestep = 7133. State = [[-0.30412182 -0.09601328]]. Action = [[-0.0828684  -0.07931511  0.          0.26761818]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 7133 is [True, False, False, False, True, False]
State prediction error at timestep 7133 is 0.012
Human Feedback received at timestep 7133 of None
Current timestep = 7134. State = [[-0.30217597 -0.10200071]]. Action = [[ 0.09266948 -0.07252488  0.         -0.06610328]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 7134 is [True, False, False, False, True, False]
Current timestep = 7135. State = [[-0.30227253 -0.10158611]]. Action = [[-0.07229216  0.06793097  0.         -0.17984658]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 7135 is [True, False, False, False, True, False]
Current timestep = 7136. State = [[-0.30126718 -0.09525411]]. Action = [[ 0.06753271  0.08894274  0.         -0.95196575]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 7136 is [True, False, False, False, True, False]
Current timestep = 7137. State = [[-0.30246377 -0.09506512]]. Action = [[-0.05438809 -0.06987632  0.         -0.50914156]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 7137 is [True, False, False, False, True, False]
Current timestep = 7138. State = [[-0.30493778 -0.09603663]]. Action = [[-0.01203122  0.01813312  0.          0.33836865]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 7138 is [True, False, False, False, True, False]
Current timestep = 7139. State = [[-0.30340376 -0.0960646 ]]. Action = [[ 0.0498273  -0.01145139  0.         -0.8602944 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 7139 is [True, False, False, False, True, False]
Current timestep = 7140. State = [[-0.29815054 -0.09964639]]. Action = [[ 0.08738282 -0.07251482  0.         -0.7338449 ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 7140 is [True, False, False, False, True, False]
State prediction error at timestep 7140 is 0.012
Human Feedback received at timestep 7140 of None
Current timestep = 7141. State = [[-0.2923235  -0.10013639]]. Action = [[ 0.0687507   0.02821503  0.         -0.93953806]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 7141 is [True, False, False, False, True, False]
State prediction error at timestep 7141 is 0.012
Human Feedback received at timestep 7141 of None
Current timestep = 7142. State = [[-0.2902194  -0.09514378]]. Action = [[-0.00098041  0.08267269  0.          0.1688888 ]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 7142 is [True, False, False, False, True, False]
Current timestep = 7143. State = [[-0.28774062 -0.09354046]]. Action = [[ 0.04912847 -0.02195446  0.         -0.70299506]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 7143 is [True, False, False, False, True, False]
Current timestep = 7144. State = [[-0.28765795 -0.09189265]]. Action = [[-0.03123306  0.03983555  0.         -0.06493354]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 7144 is [True, False, False, False, True, False]
Current timestep = 7145. State = [[-0.29054037 -0.09082019]]. Action = [[-0.04703435 -0.00300664  0.          0.31086826]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 7145 is [True, False, False, False, True, False]
Current timestep = 7146. State = [[-0.29339808 -0.09368824]]. Action = [[-0.03645947 -0.05619956  0.          0.5886828 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 7146 is [True, False, False, False, True, False]
Current timestep = 7147. State = [[-0.29845947 -0.09993573]]. Action = [[-0.08947678 -0.08467203  0.          0.54606676]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 7147 is [True, False, False, False, True, False]
State prediction error at timestep 7147 is 0.012
Human Feedback received at timestep 7147 of None
Current timestep = 7148. State = [[-0.299478   -0.09874278]]. Action = [[0.03147744 0.09760343 0.         0.6553445 ]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 7148 is [True, False, False, False, True, False]
State prediction error at timestep 7148 is 0.012
Human Feedback received at timestep 7148 of None
Current timestep = 7149. State = [[-0.29959333 -0.09196185]]. Action = [[-0.01909357  0.07786503  0.         -0.30223382]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 7149 is [True, False, False, False, True, False]
Current timestep = 7150. State = [[-0.30486017 -0.08688366]]. Action = [[-0.09376151  0.042936    0.         -0.89568037]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 7150 is [True, False, False, False, True, False]
Current timestep = 7151. State = [[-0.31129614 -0.08227152]]. Action = [[-0.06720802  0.05409231  0.          0.32226515]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 7151 is [True, False, False, False, True, False]
Current timestep = 7152. State = [[-0.3122357  -0.08313884]]. Action = [[ 0.04499229 -0.07000006  0.         -0.7072436 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 7152 is [True, False, False, False, True, False]
Current timestep = 7153. State = [[-0.31368774 -0.08299302]]. Action = [[-0.04174868  0.02811287  0.         -0.09986198]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 7153 is [True, False, False, False, True, False]
State prediction error at timestep 7153 is 0.012
Human Feedback received at timestep 7153 of None
Current timestep = 7154. State = [[-0.31771037 -0.08581331]]. Action = [[-0.04639501 -0.07968738  0.         -0.25820863]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 7154 is [True, False, False, False, True, False]
Current timestep = 7155. State = [[-0.31787473 -0.08391505]]. Action = [[0.04389004 0.08487638 0.         0.380136  ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 7155 is [True, False, False, False, True, False]
Current timestep = 7156. State = [[-0.31378978 -0.08077547]]. Action = [[ 0.07844933 -0.00311206  0.         -0.3844881 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 7156 is [True, False, False, False, True, False]
Current timestep = 7157. State = [[-0.31123754 -0.08368997]]. Action = [[ 0.0209531  -0.07725449  0.          0.82693696]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 7157 is [True, False, False, False, True, False]
Current timestep = 7158. State = [[-0.31538936 -0.09077646]]. Action = [[-0.09592894 -0.09645151  0.         -0.18554848]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 7158 is [True, False, False, False, True, False]
State prediction error at timestep 7158 is 0.012
Human Feedback received at timestep 7158 of None
Current timestep = 7159. State = [[-0.315993   -0.09529518]]. Action = [[ 0.05003064 -0.01940728  0.         -0.5602913 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 7159 is [True, False, False, False, True, False]
Current timestep = 7160. State = [[-0.31825817 -0.09770259]]. Action = [[-0.07002319 -0.01806141  0.          0.3882588 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 7160 is [True, False, False, False, True, False]
Current timestep = 7161. State = [[-0.31594828 -0.100848  ]]. Action = [[ 0.09794074 -0.03754211  0.          0.5019002 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 7161 is [True, False, False, False, True, False]
Current timestep = 7162. State = [[-0.31408802 -0.09905629]]. Action = [[-0.02583948  0.07746343  0.          0.7129605 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 7162 is [True, False, False, False, True, False]
Current timestep = 7163. State = [[-0.31776974 -0.09737571]]. Action = [[-0.06149109  0.00470112  0.          0.58266544]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 7163 is [True, False, False, False, True, False]
State prediction error at timestep 7163 is 0.012
Human Feedback received at timestep 7163 of None
Current timestep = 7164. State = [[-0.3241328 -0.0936437]]. Action = [[-0.08703554  0.08505993  0.         -0.3392284 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 7164 is [True, False, False, False, True, False]
Current timestep = 7165. State = [[-0.33043915 -0.08972318]]. Action = [[-0.06281494  0.03537919  0.          0.06630635]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 7165 is [True, False, False, False, True, False]
State prediction error at timestep 7165 is 0.012
Human Feedback received at timestep 7165 of None
Current timestep = 7166. State = [[-0.3317302  -0.08329993]]. Action = [[ 0.03440177  0.09683786  0.         -0.36126512]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 7166 is [True, False, False, False, True, False]
Current timestep = 7167. State = [[-0.33164296 -0.07839496]]. Action = [[ 0.01101457  0.01352809  0.         -0.44320035]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 7167 is [True, False, False, False, True, False]
Current timestep = 7168. State = [[-0.33477446 -0.07331836]]. Action = [[-0.04298024  0.0628882   0.          0.17811072]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 7168 is [True, False, False, False, True, False]
Current timestep = 7169. State = [[-0.34083185 -0.06935167]]. Action = [[-0.06923901  0.01641519  0.          0.97872996]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 7169 is [True, False, False, False, True, False]
Current timestep = 7170. State = [[-0.3461203  -0.06886811]]. Action = [[-0.03612507 -0.02473962  0.         -0.4600941 ]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 7170 is [True, False, False, False, True, False]
Current timestep = 7171. State = [[-0.34462282 -0.06872302]]. Action = [[ 0.08759692 -0.00885227  0.         -0.8083399 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 7171 is [True, False, False, False, True, False]
Current timestep = 7172. State = [[-0.34407976 -0.06477731]]. Action = [[-0.01375715  0.05735945  0.         -0.79516923]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 7172 is [True, False, False, False, True, False]
Current timestep = 7173. State = [[-0.3479536  -0.05961191]]. Action = [[-0.04942518  0.04590405  0.          0.8432324 ]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 7173 is [True, False, False, False, True, False]
Current timestep = 7174. State = [[-0.3469537  -0.06062231]]. Action = [[ 0.07792947 -0.07359203  0.         -0.3525344 ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 7174 is [True, False, False, False, True, False]
State prediction error at timestep 7174 is 0.012
Human Feedback received at timestep 7174 of None
Current timestep = 7175. State = [[-0.34298503 -0.06070943]]. Action = [[0.04717579 0.02178626 0.         0.04065502]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 7175 is [True, False, False, False, True, False]
Current timestep = 7176. State = [[-0.34312728 -0.05968688]]. Action = [[-0.03086734 -0.00356875  0.         -0.5965746 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 7176 is [True, False, False, False, True, False]
Current timestep = 7177. State = [[-0.34714252 -0.06193328]]. Action = [[-0.07006074 -0.04565391  0.          0.11525714]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 7177 is [True, False, False, False, True, False]
Current timestep = 7178. State = [[-0.3460949  -0.06702238]]. Action = [[ 0.06101609 -0.07012223  0.          0.66340375]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 7178 is [True, False, False, False, True, False]
Current timestep = 7179. State = [[-0.34450915 -0.07421236]]. Action = [[-0.01426067 -0.08885013  0.          0.46704197]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 7179 is [True, False, False, False, True, False]
State prediction error at timestep 7179 is 0.012
Human Feedback received at timestep 7179 of None
Current timestep = 7180. State = [[-0.34099275 -0.07607044]]. Action = [[ 0.06416733  0.03803527  0.         -0.17317873]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 7180 is [True, False, False, False, True, False]
Current timestep = 7181. State = [[-0.33438888 -0.08001003]]. Action = [[ 0.08204626 -0.08538648  0.          0.9468725 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 7181 is [True, False, False, False, True, False]
Current timestep = 7182. State = [[-0.32861334 -0.08039398]]. Action = [[0.04928019 0.05717772 0.         0.48743248]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 7182 is [True, False, False, False, True, False]
Current timestep = 7183. State = [[-0.32199976 -0.0769348 ]]. Action = [[0.08624937 0.04839597 0.         0.7637744 ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 7183 is [True, False, False, False, True, False]
Current timestep = 7184. State = [[-0.31381825 -0.07497717]]. Action = [[ 0.09992374  0.01066042  0.         -0.17968714]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 7184 is [True, False, False, False, True, False]
Current timestep = 7185. State = [[-0.30665818 -0.07213045]]. Action = [[ 0.06922217  0.04789736  0.         -0.59173256]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 7185 is [True, False, False, False, True, False]
Current timestep = 7186. State = [[-0.3077355 -0.0748228]]. Action = [[-0.09173977 -0.09060439  0.         -0.7819601 ]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 7186 is [True, False, False, False, True, False]
Current timestep = 7187. State = [[-0.31013247 -0.08240213]]. Action = [[-0.02107073 -0.08294907  0.          0.14486384]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 7187 is [True, False, False, False, True, False]
Current timestep = 7188. State = [[-0.31382522 -0.08628146]]. Action = [[-0.08482271 -0.0013798   0.          0.6935346 ]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 7188 is [True, False, False, False, True, False]
Current timestep = 7189. State = [[-0.31412914 -0.08271074]]. Action = [[ 0.02326663  0.09632113  0.         -0.46550906]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 7189 is [True, False, False, False, True, False]
State prediction error at timestep 7189 is 0.012
Human Feedback received at timestep 7189 of None
Current timestep = 7190. State = [[-0.3121363  -0.08407056]]. Action = [[ 0.01657703 -0.08071437  0.          0.45825934]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 7190 is [True, False, False, False, True, False]
Current timestep = 7191. State = [[-0.30990613 -0.0837165 ]]. Action = [[0.0252521  0.05683251 0.         0.6630113 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 7191 is [True, False, False, False, True, False]
Current timestep = 7192. State = [[-0.31239146 -0.08481392]]. Action = [[-0.07472361 -0.04975943  0.          0.85372293]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 7192 is [True, False, False, False, True, False]
Current timestep = 7193. State = [[-0.31364363 -0.08975913]]. Action = [[ 0.00936061 -0.06035748  0.          0.56663406]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 7193 is [True, False, False, False, True, False]
Current timestep = 7194. State = [[-0.31591925 -0.09738946]]. Action = [[-0.05632004 -0.0998917   0.         -0.55726653]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 7194 is [True, False, False, False, True, False]
State prediction error at timestep 7194 is 0.012
Human Feedback received at timestep 7194 of None
Current timestep = 7195. State = [[-0.31763312 -0.09966084]]. Action = [[-0.00733707  0.03856715  0.          0.3492787 ]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 7195 is [True, False, False, False, True, False]
State prediction error at timestep 7195 is 0.012
Human Feedback received at timestep 7195 of None
Current timestep = 7196. State = [[-0.31551412 -0.09603114]]. Action = [[0.04797219 0.06679773 0.         0.9921925 ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 7196 is [True, False, False, False, True, False]
Current timestep = 7197. State = [[-0.31296784 -0.0967661 ]]. Action = [[ 0.02817992 -0.05345295  0.          0.8865831 ]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 7197 is [True, False, False, False, True, False]
Current timestep = 7198. State = [[-0.3152825  -0.09742495]]. Action = [[-0.06342111  0.02404907  0.         -0.25126457]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 7198 is [True, False, False, False, True, False]
Current timestep = 7199. State = [[-0.3187928  -0.09608621]]. Action = [[-0.02599669  0.02228801  0.         -0.99617344]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 7199 is [True, False, False, False, True, False]
Current timestep = 7200. State = [[-0.31737688 -0.09153814]]. Action = [[0.06000603 0.07501053 0.         0.937536  ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 7200 is [True, False, False, False, True, False]
Current timestep = 7201. State = [[-0.31260398 -0.08579265]]. Action = [[0.08172259 0.05019713 0.         0.4889567 ]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 7201 is [True, False, False, False, True, False]
Current timestep = 7202. State = [[-0.30634752 -0.08645145]]. Action = [[ 0.09688172 -0.07228284  0.          0.1915425 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 7202 is [True, False, False, False, True, False]
Current timestep = 7203. State = [[-0.30676636 -0.0885429 ]]. Action = [[-0.06900728 -0.0118162   0.          0.20117402]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 7203 is [True, False, False, False, True, False]
Current timestep = 7204. State = [[-0.31313926 -0.08664227]]. Action = [[-0.0763441   0.04160481  0.         -0.19775307]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 7204 is [True, False, False, False, True, False]
Current timestep = 7205. State = [[-0.32006717 -0.08129475]]. Action = [[-0.07411931  0.07845456  0.         -0.5616966 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 7205 is [True, False, False, False, True, False]
Current timestep = 7206. State = [[-0.32738048 -0.08150442]]. Action = [[-0.08012858 -0.06004068  0.         -0.09577566]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 7206 is [True, False, False, False, True, False]
Current timestep = 7207. State = [[-0.32963374 -0.08770165]]. Action = [[ 0.02776403 -0.09713136  0.          0.38941514]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 7207 is [True, False, False, False, True, False]
State prediction error at timestep 7207 is 0.012
Human Feedback received at timestep 7207 of None
Current timestep = 7208. State = [[-0.33256444 -0.09215824]]. Action = [[-0.05729213 -0.02867015  0.          0.7313249 ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 7208 is [True, False, False, False, True, False]
Current timestep = 7209. State = [[-0.33900207 -0.08920538]]. Action = [[-0.08285803  0.08755385  0.         -0.36217403]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 7209 is [True, False, False, False, True, False]
Current timestep = 7210. State = [[-0.3404504  -0.08758982]]. Action = [[ 0.05064585 -0.02043495  0.         -0.993296  ]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 7210 is [True, False, False, False, True, False]
Current timestep = 7211. State = [[-0.33530512 -0.08570202]]. Action = [[ 0.09398165  0.03840394  0.         -0.13809949]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 7211 is [True, False, False, False, True, False]
Current timestep = 7212. State = [[-0.33685333 -0.08310845]]. Action = [[-0.08230021  0.02233746  0.          0.26556063]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 7212 is [True, False, False, False, True, False]
State prediction error at timestep 7212 is 0.012
Human Feedback received at timestep 7212 of None
Current timestep = 7213. State = [[-0.34106132 -0.07980423]]. Action = [[-0.01764429  0.04537479  0.         -0.04581153]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 7213 is [True, False, False, False, True, False]
Current timestep = 7214. State = [[-0.3462254  -0.08001635]]. Action = [[-0.0656556  -0.03982782  0.          0.03719223]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 7214 is [True, False, False, False, True, False]
Current timestep = 7215. State = [[-0.35295656 -0.08217926]]. Action = [[-0.072789   -0.02190278  0.          0.46359944]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 7215 is [True, False, False, False, True, False]
State prediction error at timestep 7215 is 0.012
Human Feedback received at timestep 7215 of None
Current timestep = 7216. State = [[-0.36093274 -0.0790078 ]]. Action = [[-0.09166498  0.07991994  0.         -0.9603032 ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 7216 is [True, False, False, False, True, False]
Current timestep = 7217. State = [[-0.3652932  -0.07361122]]. Action = [[1.21191144e-04 5.41556403e-02 0.00000000e+00 4.04101253e-01]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 7217 is [True, False, False, False, True, False]
Current timestep = 7218. State = [[-0.36722162 -0.07530946]]. Action = [[-0.00070792 -0.08616728  0.         -0.6643468 ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 7218 is [True, False, False, False, True, False]
Current timestep = 7219. State = [[-0.36441657 -0.07579066]]. Action = [[0.09729453 0.02550032 0.         0.08691478]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 7219 is [True, False, False, False, True, False]
Current timestep = 7220. State = [[-0.3660531  -0.07484824]]. Action = [[-0.06617812 -0.00996178  0.          0.87217164]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 7220 is [True, False, False, False, True, False]
Current timestep = 7221. State = [[-0.37183893 -0.07188736]]. Action = [[-0.04858456  0.05468722  0.         -0.16550237]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 7221 is [True, False, False, False, True, False]
Current timestep = 7222. State = [[-0.3750656  -0.07213019]]. Action = [[ 2.4005771e-05 -4.6844125e-02  0.0000000e+00  2.6245117e-03]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 7222 is [True, False, False, False, True, False]
Current timestep = 7223. State = [[-0.3766786  -0.07302006]]. Action = [[ 0.          0.          0.         -0.36253995]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 7223 is [True, False, False, False, True, False]
Current timestep = 7224. State = [[-0.37687767 -0.07493733]]. Action = [[ 0.0218696  -0.04372922  0.         -0.7216572 ]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 7224 is [True, False, False, False, True, False]
Current timestep = 7225. State = [[-0.37723285 -0.07607296]]. Action = [[ 0.         0.         0.        -0.2489413]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 7225 is [True, False, False, False, True, False]
Current timestep = 7226. State = [[-0.37617832 -0.07622475]]. Action = [[ 0.03601634 -0.00345114  0.          0.90927565]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 7226 is [True, False, False, False, True, False]
State prediction error at timestep 7226 is 0.012
Human Feedback received at timestep 7226 of None
Current timestep = 7227. State = [[-0.37656397 -0.07679016]]. Action = [[-0.01837248 -0.00981358  0.          0.92327106]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 7227 is [True, False, False, False, True, False]
State prediction error at timestep 7227 is 0.012
Human Feedback received at timestep 7227 of None
Current timestep = 7228. State = [[-0.37672105 -0.07757022]]. Action = [[ 0.01370381 -0.00549303  0.         -0.5376145 ]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 7228 is [True, False, False, False, True, False]
Current timestep = 7229. State = [[-0.3766215  -0.07793851]]. Action = [[0.       0.       0.       0.919863]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 7229 is [True, False, False, False, True, False]
Current timestep = 7230. State = [[-0.37677488 -0.07816327]]. Action = [[ 0.         0.         0.        -0.2543981]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 7230 is [True, False, False, False, True, False]
Current timestep = 7231. State = [[-0.37209436 -0.07860142]]. Action = [[ 0.09827336 -0.00986624  0.         -0.21193862]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 7231 is [True, False, False, False, True, False]
Current timestep = 7232. State = [[-0.36429718 -0.07452994]]. Action = [[0.09763705 0.07493149 0.         0.7000375 ]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 7232 is [True, False, False, False, True, False]
Current timestep = 7233. State = [[-0.36301932 -0.06702181]]. Action = [[-0.04216924  0.09277897  0.          0.8151295 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 7233 is [True, False, False, False, True, False]
Current timestep = 7234. State = [[-0.36507788 -0.06778377]]. Action = [[-0.01866583 -0.09131755  0.          0.31718302]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 7234 is [True, False, False, False, True, False]
Current timestep = 7235. State = [[-0.3643341  -0.07109169]]. Action = [[ 0.03129681 -0.01825309  0.          0.35129213]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 7235 is [True, False, False, False, True, False]
State prediction error at timestep 7235 is 0.012
Human Feedback received at timestep 7235 of None
Current timestep = 7236. State = [[-0.365664   -0.07310203]]. Action = [[-0.04596489 -0.02559078  0.         -0.08688211]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 7236 is [True, False, False, False, True, False]
Current timestep = 7237. State = [[-0.36436456 -0.0701807 ]]. Action = [[ 0.0500524   0.07742863  0.         -0.05448604]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 7237 is [True, False, False, False, True, False]
Current timestep = 7238. State = [[-0.36425325 -0.06282795]]. Action = [[-0.02621961  0.09139805  0.          0.7845762 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 7238 is [True, False, False, False, True, False]
State prediction error at timestep 7238 is 0.012
Human Feedback received at timestep 7238 of None
Current timestep = 7239. State = [[-0.3651854 -0.0561492]]. Action = [[-0.00219771  0.06025658  0.          0.38019443]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 7239 is [True, False, False, False, True, False]
Current timestep = 7240. State = [[-0.36440605 -0.05182292]]. Action = [[0.02548452 0.02373935 0.         0.30725288]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 7240 is [True, False, False, False, True, False]
Current timestep = 7241. State = [[-0.36028832 -0.04876917]]. Action = [[0.07828163 0.01535144 0.         0.88326144]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 7241 is [True, False, False, False, True, False]
Current timestep = 7242. State = [[-0.36218882 -0.0426375 ]]. Action = [[-0.08655825  0.08719609  0.          0.46449447]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 7242 is [True, False, False, False, True, False]
State prediction error at timestep 7242 is 0.012
Human Feedback received at timestep 7242 of None
Current timestep = 7243. State = [[-0.36783367 -0.03923318]]. Action = [[-0.04726169 -0.00990772  0.         -0.07917589]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 7243 is [True, False, False, False, True, False]
State prediction error at timestep 7243 is 0.012
Human Feedback received at timestep 7243 of None
Current timestep = 7244. State = [[-0.3703187  -0.03810749]]. Action = [[ 0.         0.         0.        -0.6278949]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 7244 is [True, False, False, False, True, False]
Current timestep = 7245. State = [[-0.3712723  -0.03689042]]. Action = [[0.         0.         0.         0.61204267]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 7245 is [True, False, False, False, True, False]
Current timestep = 7246. State = [[-0.37277186 -0.03571951]]. Action = [[-0.01715162  0.00227724  0.          0.84160566]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 7246 is [True, False, False, False, True, False]
Current timestep = 7247. State = [[-0.3728116 -0.035514 ]]. Action = [[ 0.01968966 -0.01478363  0.          0.08187044]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 7247 is [True, False, False, False, True, False]
State prediction error at timestep 7247 is 0.012
Human Feedback received at timestep 7247 of None
Current timestep = 7248. State = [[-0.3726323  -0.03527721]]. Action = [[0.        0.        0.        0.8893807]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 7248 is [True, False, False, False, True, False]
Current timestep = 7249. State = [[-0.37134454 -0.03943658]]. Action = [[ 0.02788346 -0.08973636  0.          0.12739909]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 7249 is [True, False, False, False, True, False]
Current timestep = 7250. State = [[-0.3693476  -0.03777424]]. Action = [[0.02771177 0.09381635 0.         0.4875164 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 7250 is [True, False, False, False, True, False]
Current timestep = 7251. State = [[-0.3648626  -0.03952973]]. Action = [[ 0.07307004 -0.09764117  0.         -0.29455757]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 7251 is [True, False, False, False, True, False]
State prediction error at timestep 7251 is 0.012
Human Feedback received at timestep 7251 of None
Current timestep = 7252. State = [[-0.3597782  -0.03963749]]. Action = [[0.05348413 0.0532041  0.         0.68533814]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 7252 is [True, False, False, False, True, False]
Current timestep = 7253. State = [[-0.35954645 -0.04257358]]. Action = [[-0.04316537 -0.08998573  0.         -0.20684302]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 7253 is [True, False, False, False, True, False]
Current timestep = 7254. State = [[-0.35529205 -0.04892998]]. Action = [[ 0.09259308 -0.06228394  0.         -0.67216045]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 7254 is [True, False, False, False, True, False]
Current timestep = 7255. State = [[-0.34804618 -0.05565399]]. Action = [[ 0.06769656 -0.07519351  0.         -0.8806857 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 7255 is [True, False, False, False, True, False]
Current timestep = 7256. State = [[-0.345765   -0.05809176]]. Action = [[-0.03214935  0.02566042  0.          0.14389038]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 7256 is [True, False, False, False, True, False]
Current timestep = 7257. State = [[-0.34593463 -0.05764026]]. Action = [[-0.01486492  0.02608503  0.         -0.04342151]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 7257 is [True, False, False, False, True, False]
State prediction error at timestep 7257 is 0.012
Human Feedback received at timestep 7257 of None
Current timestep = 7258. State = [[-0.3429563 -0.0598829]]. Action = [[ 0.05060501 -0.03686277  0.          0.01088107]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 7258 is [True, False, False, False, True, False]
State prediction error at timestep 7258 is 0.012
Human Feedback received at timestep 7258 of None
Current timestep = 7259. State = [[-0.34265432 -0.06292371]]. Action = [[-0.0426646  -0.01663157  0.         -0.14278978]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 7259 is [True, False, False, False, True, False]
Current timestep = 7260. State = [[-0.3435213  -0.06093113]]. Action = [[-0.01161728  0.07329177  0.         -0.6904138 ]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 7260 is [True, False, False, False, True, False]
Current timestep = 7261. State = [[-0.34254968 -0.06367172]]. Action = [[ 0.01728652 -0.08538783  0.         -0.20181054]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 7261 is [True, False, False, False, True, False]
Current timestep = 7262. State = [[-0.34333175 -0.06413223]]. Action = [[-0.03621245  0.05333418  0.         -0.80006295]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 7262 is [True, False, False, False, True, False]
Current timestep = 7263. State = [[-0.34169605 -0.06682824]]. Action = [[ 0.0499626  -0.07412619  0.         -0.48141593]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 7263 is [True, False, False, False, True, False]
Current timestep = 7264. State = [[-0.33908275 -0.06485641]]. Action = [[0.0189722  0.08915647 0.         0.21308243]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 7264 is [True, False, False, False, True, False]
Current timestep = 7265. State = [[-0.3382925  -0.05824734]]. Action = [[0.00194509 0.07886606 0.         0.64249015]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 7265 is [True, False, False, False, True, False]
Current timestep = 7266. State = [[-0.33520526 -0.05043353]]. Action = [[0.06855262 0.09166213 0.         0.3137262 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 7266 is [True, False, False, False, True, False]
Current timestep = 7267. State = [[-0.33247852 -0.0462523 ]]. Action = [[0.02889579 0.00144925 0.         0.7481979 ]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 7267 is [True, False, False, False, True, False]
Current timestep = 7268. State = [[-0.32922214 -0.04622652]]. Action = [[ 0.05608868 -0.02785429  0.         -0.00264561]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 7268 is [True, False, False, False, True, False]
Current timestep = 7269. State = [[-0.3261586  -0.04781564]]. Action = [[ 0.02894109 -0.0358194   0.          0.29361582]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 7269 is [True, False, False, False, True, False]
State prediction error at timestep 7269 is 0.012
Human Feedback received at timestep 7269 of None
Current timestep = 7270. State = [[-0.32910034 -0.04682332]]. Action = [[-0.09196389  0.03041079  0.          0.77322495]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 7270 is [True, False, False, False, True, False]
State prediction error at timestep 7270 is 0.012
Human Feedback received at timestep 7270 of None
Current timestep = 7271. State = [[-0.3340638 -0.0452782]]. Action = [[-0.05637801  0.00480314  0.         -0.2344721 ]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 7271 is [True, False, False, False, True, False]
State prediction error at timestep 7271 is 0.012
Human Feedback received at timestep 7271 of None
Current timestep = 7272. State = [[-0.3371427 -0.0404387]]. Action = [[-0.02818245  0.08129168  0.         -0.07933366]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 7272 is [True, False, False, False, True, False]
Current timestep = 7273. State = [[-0.33838362 -0.03460963]]. Action = [[ 0.00090551  0.04918789  0.         -0.12728512]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 7273 is [True, False, False, False, True, False]
Current timestep = 7274. State = [[-0.3375852 -0.0348709]]. Action = [[ 0.02668142 -0.0598468   0.         -0.9330465 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 7274 is [True, False, False, False, True, False]
State prediction error at timestep 7274 is 0.012
Human Feedback received at timestep 7274 of None
Current timestep = 7275. State = [[-0.33837542 -0.03516009]]. Action = [[-0.02715633  0.01108883  0.          0.18836558]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 7275 is [True, False, False, False, True, False]
Current timestep = 7276. State = [[-0.3437998  -0.03457722]]. Action = [[-0.09481333 -0.00419724  0.         -0.02273107]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 7276 is [True, False, False, False, True, False]
Current timestep = 7277. State = [[-0.34245962 -0.03101299]]. Action = [[0.09934617 0.06064304 0.         0.5788255 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 7277 is [True, False, False, False, True, False]
State prediction error at timestep 7277 is 0.012
Human Feedback received at timestep 7277 of None
Current timestep = 7278. State = [[-0.33990863 -0.03116913]]. Action = [[-0.00322751 -0.05362419  0.         -0.25887048]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 7278 is [True, False, False, False, True, False]
Current timestep = 7279. State = [[-0.33732778 -0.02754834]]. Action = [[ 0.04612213  0.09446513  0.         -0.9186351 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 7279 is [True, False, False, False, True, False]
Current timestep = 7280. State = [[-0.338448   -0.01930142]]. Action = [[-0.04755155  0.09587761  0.          0.6773367 ]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 7280 is [True, False, False, False, True, False]
Current timestep = 7281. State = [[-0.33538365 -0.01799264]]. Action = [[ 0.09995005 -0.05467778  0.         -0.7004872 ]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 7281 is [True, False, False, False, True, False]
Current timestep = 7282. State = [[-0.3318704  -0.01539882]]. Action = [[ 0.00943915  0.06208337  0.         -0.22984844]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 7282 is [True, False, False, False, True, False]
Current timestep = 7283. State = [[-0.3271828  -0.01503292]]. Action = [[ 0.07835271 -0.04631505  0.          0.50413835]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 7283 is [True, False, False, False, True, False]
Current timestep = 7284. State = [[-0.325212   -0.02063307]]. Action = [[-0.02651357 -0.09930318  0.          0.76378417]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 7284 is [True, False, False, False, True, False]
Current timestep = 7285. State = [[-0.32695928 -0.02757883]]. Action = [[-0.05540049 -0.08040883  0.         -0.879461  ]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 7285 is [True, False, False, False, True, False]
Current timestep = 7286. State = [[-0.33073115 -0.02836346]]. Action = [[-0.07982917  0.04412469  0.         -0.09895003]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 7286 is [True, False, False, False, True, False]
Current timestep = 7287. State = [[-0.33600038 -0.02985253]]. Action = [[-0.0872082  -0.04268688  0.          0.5150044 ]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 7287 is [True, False, False, False, True, False]
Current timestep = 7288. State = [[-0.3396775  -0.03506155]]. Action = [[-0.04117199 -0.06680824  0.          0.65539074]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 7288 is [True, False, False, False, True, False]
State prediction error at timestep 7288 is 0.012
Human Feedback received at timestep 7288 of None
Current timestep = 7289. State = [[-0.3431663  -0.03949363]]. Action = [[-0.05494698 -0.02941971  0.         -0.10620606]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 7289 is [True, False, False, False, True, False]
Current timestep = 7290. State = [[-0.34637374 -0.03907704]]. Action = [[-0.03271562  0.04678144  0.          0.88554144]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 7290 is [True, False, False, False, True, False]
Current timestep = 7291. State = [[-0.34539634 -0.04215552]]. Action = [[ 0.05479056 -0.07489607  0.          0.7357564 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 7291 is [True, False, False, False, True, False]
Current timestep = 7292. State = [[-0.34801006 -0.04279438]]. Action = [[-0.07408161  0.04576804  0.          0.63765216]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 7292 is [True, False, False, False, True, False]
Current timestep = 7293. State = [[-0.34846458 -0.04308515]]. Action = [[ 0.0604812  -0.02108023  0.          0.4995364 ]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 7293 is [True, False, False, False, True, False]
Current timestep = 7294. State = [[-0.34521103 -0.04219529]]. Action = [[ 0.05950969  0.03386564  0.         -0.48666215]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 7294 is [True, False, False, False, True, False]
Current timestep = 7295. State = [[-0.3425541 -0.0439178]]. Action = [[ 0.04153416 -0.05208299  0.         -0.9879315 ]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 7295 is [True, False, False, False, True, False]
Current timestep = 7296. State = [[-0.33793035 -0.04205066]]. Action = [[ 0.08798947  0.06969113  0.         -0.9817362 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 7296 is [True, False, False, False, True, False]
Current timestep = 7297. State = [[-0.33638766 -0.04137753]]. Action = [[-0.00296824 -0.02754444  0.         -0.1351062 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 7297 is [True, False, False, False, True, False]
Current timestep = 7298. State = [[-0.33954373 -0.04676231]]. Action = [[-0.05940808 -0.08821087  0.          0.07803226]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 7298 is [True, False, False, False, True, False]
State prediction error at timestep 7298 is 0.012
Human Feedback received at timestep 7298 of None
Current timestep = 7299. State = [[-0.33938536 -0.04614615]]. Action = [[ 0.04286889  0.08499023  0.         -0.38187486]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 7299 is [True, False, False, False, True, False]
Current timestep = 7300. State = [[-0.3414438  -0.03984824]]. Action = [[-0.05867773  0.08044919  0.          0.4287225 ]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 7300 is [True, False, False, False, True, False]
Current timestep = 7301. State = [[-0.3441492  -0.03961549]]. Action = [[-0.01579687 -0.04993712  0.          0.4633323 ]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 7301 is [True, False, False, False, True, False]
Current timestep = 7302. State = [[-0.34445614 -0.04447836]]. Action = [[ 0.00776617 -0.07283859  0.         -0.11939937]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 7302 is [True, False, False, False, True, False]
State prediction error at timestep 7302 is 0.012
Human Feedback received at timestep 7302 of None
Current timestep = 7303. State = [[-0.34161144 -0.0482305 ]]. Action = [[ 0.05263702 -0.02820777  0.         -0.9524233 ]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 7303 is [True, False, False, False, True, False]
State prediction error at timestep 7303 is 0.012
Human Feedback received at timestep 7303 of None
Current timestep = 7304. State = [[-0.33633932 -0.04631013]]. Action = [[0.07505872 0.05860113 0.         0.00610232]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 7304 is [True, False, False, False, True, False]
State prediction error at timestep 7304 is 0.012
Human Feedback received at timestep 7304 of None
Current timestep = 7305. State = [[-0.32993937 -0.04924676]]. Action = [[ 0.08239519 -0.09512223  0.         -0.75966775]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 7305 is [True, False, False, False, True, False]
Current timestep = 7306. State = [[-0.32497266 -0.04888861]]. Action = [[ 0.04045369  0.06636982  0.         -0.43088722]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 7306 is [True, False, False, False, True, False]
State prediction error at timestep 7306 is 0.012
Human Feedback received at timestep 7306 of None
Current timestep = 7307. State = [[-0.32337162 -0.05194573]]. Action = [[-0.00856359 -0.0948462   0.         -0.88889444]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 7307 is [True, False, False, False, True, False]
Current timestep = 7308. State = [[-0.322073   -0.05076101]]. Action = [[ 0.01316103  0.09452126  0.         -0.9354205 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 7308 is [True, False, False, False, True, False]
Current timestep = 7309. State = [[-0.31963822 -0.05196567]]. Action = [[ 0.02622061 -0.06966211  0.          0.151685  ]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 7309 is [True, False, False, False, True, False]
Current timestep = 7310. State = [[-0.31404358 -0.05141465]]. Action = [[ 0.08068927  0.05639606  0.         -0.9855285 ]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 7310 is [True, False, False, False, True, False]
State prediction error at timestep 7310 is 0.012
Human Feedback received at timestep 7310 of None
Current timestep = 7311. State = [[-0.31207943 -0.04887058]]. Action = [[-0.02309083  0.02200551  0.         -0.2700529 ]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 7311 is [True, False, False, False, True, False]
State prediction error at timestep 7311 is 0.012
Human Feedback received at timestep 7311 of None
Current timestep = 7312. State = [[-0.31151867 -0.05119979]]. Action = [[ 0.00372306 -0.05829833  0.          0.05423856]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 7312 is [True, False, False, False, True, False]
State prediction error at timestep 7312 is 0.012
Human Feedback received at timestep 7312 of None
Current timestep = 7313. State = [[-0.31229302 -0.05329068]]. Action = [[-0.039434   -0.00200944  0.          0.6310482 ]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 7313 is [True, False, False, False, True, False]
Current timestep = 7314. State = [[-0.31573322 -0.0565833 ]]. Action = [[-0.07144743 -0.05395845  0.          0.27263308]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 7314 is [True, False, False, False, True, False]
Current timestep = 7315. State = [[-0.31255957 -0.06015249]]. Action = [[ 0.09161461 -0.03033393  0.         -0.15768981]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 7315 is [True, False, False, False, True, False]
State prediction error at timestep 7315 is 0.012
Human Feedback received at timestep 7315 of None
Current timestep = 7316. State = [[-0.31267685 -0.05892214]]. Action = [[-0.08458304  0.05753193  0.          0.612571  ]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 7316 is [True, False, False, False, True, False]
Current timestep = 7317. State = [[-0.31391445 -0.05438825]]. Action = [[ 0.01228575  0.06300964  0.         -0.5662632 ]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 7317 is [True, False, False, False, True, False]
Current timestep = 7318. State = [[-0.316481   -0.05493227]]. Action = [[-0.05693179 -0.05217594  0.          0.6626475 ]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 7318 is [True, False, False, False, True, False]
Current timestep = 7319. State = [[-0.31520572 -0.05758573]]. Action = [[ 0.06040914 -0.02402255  0.         -0.917425  ]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 7319 is [True, False, False, False, True, False]
Current timestep = 7320. State = [[-0.3143887  -0.05977793]]. Action = [[-0.01518326 -0.02699997  0.          0.77169585]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 7320 is [True, False, False, False, True, False]
Current timestep = 7321. State = [[-0.31406328 -0.05798493]]. Action = [[ 0.01387791  0.05577125  0.         -0.83748305]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 7321 is [True, False, False, False, True, False]
Current timestep = 7322. State = [[-0.31552237 -0.05136216]]. Action = [[-0.0305107   0.09812736  0.          0.45930672]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 7322 is [True, False, False, False, True, False]
State prediction error at timestep 7322 is 0.012
Human Feedback received at timestep 7322 of None
Current timestep = 7323. State = [[-0.31458488 -0.04368981]]. Action = [[ 0.05289607  0.08124923  0.         -0.29251266]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 7323 is [True, False, False, False, True, False]
State prediction error at timestep 7323 is 0.012
Human Feedback received at timestep 7323 of None
Current timestep = 7324. State = [[-0.3134388  -0.04032544]]. Action = [[ 0.01464579 -0.00592935  0.          0.45026565]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 7324 is [True, False, False, False, True, False]
Current timestep = 7325. State = [[-0.31537417 -0.03490388]]. Action = [[-0.03170919  0.08752293  0.          0.9615495 ]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 7325 is [True, False, False, False, True, False]
State prediction error at timestep 7325 is 0.012
Human Feedback received at timestep 7325 of None
Current timestep = 7326. State = [[-0.31913954 -0.03174572]]. Action = [[-0.04098157 -0.01215707  0.         -0.779544  ]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 7326 is [True, False, False, False, True, False]
Current timestep = 7327. State = [[-0.32330868 -0.03024121]]. Action = [[-0.04719939  0.01039302  0.         -0.0264737 ]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 7327 is [True, False, False, False, True, False]
Current timestep = 7328. State = [[-0.3281483  -0.02399563]]. Action = [[-0.05508766  0.09513395  0.         -0.8361446 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 7328 is [True, False, False, False, True, False]
Current timestep = 7329. State = [[-0.32745117 -0.01566919]]. Action = [[ 0.07748278  0.0785731   0.         -0.5940589 ]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 7329 is [True, False, False, False, True, False]
Current timestep = 7330. State = [[-0.3276996  -0.01253374]]. Action = [[-0.02377827 -0.02222809  0.         -0.9799431 ]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 7330 is [True, False, False, False, True, False]
Current timestep = 7331. State = [[-0.32701334 -0.011444  ]]. Action = [[ 0.03978925  0.00156055  0.         -0.04048401]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 7331 is [True, False, False, False, True, False]
Current timestep = 7332. State = [[-0.32863796 -0.01276367]]. Action = [[-0.04797417 -0.0523489   0.         -0.85750204]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 7332 is [True, False, False, False, True, False]
Current timestep = 7333. State = [[-0.33346808 -0.0162729 ]]. Action = [[-0.07613834 -0.05642597  0.         -0.2258147 ]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 7333 is [True, False, False, False, True, False]
Current timestep = 7334. State = [[-0.33942792 -0.0190626 ]]. Action = [[-0.08535194 -0.02900796  0.          0.49340892]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 7334 is [True, False, False, False, True, False]
State prediction error at timestep 7334 is 0.012
Human Feedback received at timestep 7334 of None
Current timestep = 7335. State = [[-0.34084874 -0.01945953]]. Action = [[0.02105089 0.00892775 0.         0.96300113]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 7335 is [True, False, False, False, True, False]
State prediction error at timestep 7335 is 0.012
Human Feedback received at timestep 7335 of None
Current timestep = 7336. State = [[-0.33872104 -0.01607998]]. Action = [[0.04074646 0.06148174 0.         0.29282427]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 7336 is [True, False, False, False, True, False]
State prediction error at timestep 7336 is 0.012
Human Feedback received at timestep 7336 of None
Current timestep = 7337. State = [[-0.33342034 -0.01842437]]. Action = [[ 0.09770902 -0.08732884  0.          0.8464862 ]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 7337 is [True, False, False, False, True, False]
Current timestep = 7338. State = [[-0.32912338 -0.02099913]]. Action = [[ 0.03566479  0.00190248  0.         -0.6562204 ]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 7338 is [True, False, False, False, True, False]
Current timestep = 7339. State = [[-0.3309406  -0.02528426]]. Action = [[-0.06655949 -0.07407787  0.          0.20730078]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 7339 is [True, False, False, False, True, False]
State prediction error at timestep 7339 is 0.012
Human Feedback received at timestep 7339 of None
Current timestep = 7340. State = [[-0.32969785 -0.02580214]]. Action = [[ 0.0579155   0.04867091  0.         -0.8717293 ]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 7340 is [True, False, False, False, True, False]
State prediction error at timestep 7340 is 0.012
Human Feedback received at timestep 7340 of None
Current timestep = 7341. State = [[-0.3271895  -0.02800367]]. Action = [[ 0.0170538  -0.05738912  0.          0.95385253]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 7341 is [True, False, False, False, True, False]
Current timestep = 7342. State = [[-0.3255123  -0.03214419]]. Action = [[ 0.01371889 -0.03409075  0.         -0.2315172 ]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 7342 is [True, False, False, False, True, False]
Current timestep = 7343. State = [[-0.32863808 -0.03645991]]. Action = [[-0.08699812 -0.04385517  0.          0.86275935]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 7343 is [True, False, False, False, True, False]
Current timestep = 7344. State = [[-0.33143187 -0.03671743]]. Action = [[-0.01886386  0.0444149   0.          0.5338185 ]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 7344 is [True, False, False, False, True, False]
Current timestep = 7345. State = [[-0.3312279  -0.03837671]]. Action = [[ 0.01596944 -0.04095444  0.          0.19940042]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 7345 is [True, False, False, False, True, False]
State prediction error at timestep 7345 is 0.012
Human Feedback received at timestep 7345 of None
Current timestep = 7346. State = [[-0.33306956 -0.03800358]]. Action = [[-0.04576841  0.04520329  0.         -0.8523314 ]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 7346 is [True, False, False, False, True, False]
Current timestep = 7347. State = [[-0.33720684 -0.03215754]]. Action = [[-0.04992957  0.09990988  0.          0.5725825 ]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 7347 is [True, False, False, False, True, False]
Current timestep = 7348. State = [[-0.33745512 -0.03377534]]. Action = [[ 0.04248445 -0.09971937  0.          0.7174454 ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 7348 is [True, False, False, False, True, False]
Current timestep = 7349. State = [[-0.33859375 -0.03356643]]. Action = [[-0.0346719   0.0611195   0.          0.16053641]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 7349 is [True, False, False, False, True, False]
Current timestep = 7350. State = [[-0.33957893 -0.03019757]]. Action = [[0.01426701 0.0306633  0.         0.39785135]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 7350 is [True, False, False, False, True, False]
State prediction error at timestep 7350 is 0.012
Human Feedback received at timestep 7350 of None
Current timestep = 7351. State = [[-0.33862734 -0.02572061]]. Action = [[0.03224782 0.05875511 0.         0.3702277 ]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 7351 is [True, False, False, False, True, False]
Current timestep = 7352. State = [[-0.33880648 -0.02168903]]. Action = [[-1.08629465e-05  2.88487151e-02  0.00000000e+00 -3.96325469e-01]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 7352 is [True, False, False, False, True, False]
State prediction error at timestep 7352 is 0.012
Human Feedback received at timestep 7352 of None
Current timestep = 7353. State = [[-0.3434729  -0.02226964]]. Action = [[-0.07948384 -0.04600643  0.          0.15506673]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 7353 is [True, False, False, False, True, False]
Current timestep = 7354. State = [[-0.34363675 -0.02494242]]. Action = [[ 0.05499517 -0.03838537  0.          0.01127791]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 7354 is [True, False, False, False, True, False]
Current timestep = 7355. State = [[-0.3453435  -0.02354523]]. Action = [[-0.06074122  0.04501756  0.          0.5706097 ]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 7355 is [True, False, False, False, True, False]
State prediction error at timestep 7355 is 0.012
Human Feedback received at timestep 7355 of None
Current timestep = 7356. State = [[-0.3439869  -0.02373655]]. Action = [[ 0.07254829 -0.03754119  0.          0.61623883]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 7356 is [True, False, False, False, True, False]
Current timestep = 7357. State = [[-0.34151778 -0.02479241]]. Action = [[ 0.01124159 -0.00558891  0.          0.25631046]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 7357 is [True, False, False, False, True, False]
Current timestep = 7358. State = [[-0.34300727 -0.02324284]]. Action = [[-0.04260451  0.03358095  0.          0.9360558 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 7358 is [True, False, False, False, True, False]
Current timestep = 7359. State = [[-0.34690985 -0.02358471]]. Action = [[-0.06048118 -0.02759754  0.          0.88406134]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 7359 is [True, False, False, False, True, False]
Current timestep = 7360. State = [[-0.3507648  -0.02801407]]. Action = [[-0.04958041 -0.0707951   0.         -0.9508452 ]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 7360 is [True, False, False, False, True, False]
Current timestep = 7361. State = [[-0.34796667 -0.03406426]]. Action = [[ 0.08658383 -0.07038493  0.         -0.59430957]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 7361 is [True, False, False, False, True, False]
Current timestep = 7362. State = [[-0.34841427 -0.03897028]]. Action = [[-0.07520769 -0.03784413  0.         -0.2694913 ]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 7362 is [True, False, False, False, True, False]
Current timestep = 7363. State = [[-0.34580916 -0.04022737]]. Action = [[ 0.09580355  0.01641383  0.         -0.99739456]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 7363 is [True, False, False, False, True, False]
Current timestep = 7364. State = [[-0.34597558 -0.037652  ]]. Action = [[-0.06521887  0.05962791  0.          0.08423173]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 7364 is [True, False, False, False, True, False]
Current timestep = 7365. State = [[-0.347155   -0.04046905]]. Action = [[ 0.01550223 -0.07951599  0.          0.99269176]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 7365 is [True, False, False, False, True, False]
State prediction error at timestep 7365 is 0.012
Human Feedback received at timestep 7365 of None
Current timestep = 7366. State = [[-0.34368077 -0.04055468]]. Action = [[ 0.07185378  0.05654072  0.         -0.81250393]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 7366 is [True, False, False, False, True, False]
State prediction error at timestep 7366 is 0.012
Human Feedback received at timestep 7366 of None
Current timestep = 7367. State = [[-0.34369984 -0.03589483]]. Action = [[-0.03117532  0.0662644   0.          0.2896359 ]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 7367 is [True, False, False, False, True, False]
Current timestep = 7368. State = [[-0.34720516 -0.03322694]]. Action = [[-0.04166473  0.01225146  0.         -0.6104573 ]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 7368 is [True, False, False, False, True, False]
State prediction error at timestep 7368 is 0.012
Human Feedback received at timestep 7368 of None
Current timestep = 7369. State = [[-0.3514874 -0.0359491]]. Action = [[-0.05077348 -0.06461812  0.          0.701905  ]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 7369 is [True, False, False, False, True, False]
Current timestep = 7370. State = [[-0.35715622 -0.04186198]]. Action = [[-0.07857864 -0.07559706  0.          0.08507776]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 7370 is [True, False, False, False, True, False]
State prediction error at timestep 7370 is 0.012
Human Feedback received at timestep 7370 of None
Current timestep = 7371. State = [[-0.3599724  -0.04348258]]. Action = [[-0.00286843  0.02433427  0.         -0.5914021 ]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 7371 is [True, False, False, False, True, False]
Current timestep = 7372. State = [[-0.36524245 -0.0476586 ]]. Action = [[-0.09411115 -0.08824416  0.         -0.3090843 ]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 7372 is [True, False, False, False, True, False]
Current timestep = 7373. State = [[-0.37122422 -0.04634407]]. Action = [[-0.04971692  0.09914004  0.         -0.97754097]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 7373 is [True, False, False, False, True, False]
Current timestep = 7374. State = [[-0.371809   -0.04337618]]. Action = [[0.04833154 0.00317159 0.         0.63142085]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 7374 is [True, False, False, False, True, False]
Current timestep = 7375. State = [[-0.36713436 -0.04311363]]. Action = [[ 0.0986509  -0.00940622  0.         -0.7750983 ]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 7375 is [True, False, False, False, True, False]
Current timestep = 7376. State = [[-0.3660162  -0.04085822]]. Action = [[-0.01243618  0.04100045  0.          0.18495548]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 7376 is [True, False, False, False, True, False]
Current timestep = 7377. State = [[-0.3670594 -0.0416263]]. Action = [[ 0.00539979 -0.04596229  0.          0.51862025]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 7377 is [True, False, False, False, True, False]
State prediction error at timestep 7377 is 0.012
Human Feedback received at timestep 7377 of None
Current timestep = 7378. State = [[-0.36542845 -0.04061615]]. Action = [[0.04899754 0.04224201 0.         0.5578711 ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 7378 is [True, False, False, False, True, False]
Current timestep = 7379. State = [[-0.36423802 -0.03620697]]. Action = [[ 0.01530936  0.05582067  0.         -0.6983309 ]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 7379 is [True, False, False, False, True, False]
State prediction error at timestep 7379 is 0.012
Human Feedback received at timestep 7379 of None
Current timestep = 7380. State = [[-0.36160743 -0.03288918]]. Action = [[0.0619153  0.01914462 0.         0.88370395]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 7380 is [True, False, False, False, True, False]
Current timestep = 7381. State = [[-0.35743925 -0.02945237]]. Action = [[0.06381585 0.03936743 0.         0.4799503 ]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 7381 is [True, False, False, False, True, False]
Current timestep = 7382. State = [[-0.35736418 -0.02576108]]. Action = [[-0.02654138  0.03388583  0.          0.16727853]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 7382 is [True, False, False, False, True, False]
Current timestep = 7383. State = [[-0.35357553 -0.02651209]]. Action = [[ 0.09852725 -0.05232539  0.          0.1274494 ]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 7383 is [True, False, False, False, True, False]
Current timestep = 7384. State = [[-0.34803417 -0.02624335]]. Action = [[ 0.04774589  0.02172818  0.         -0.4407283 ]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 7384 is [True, False, False, False, True, False]
Current timestep = 7385. State = [[-0.3483737  -0.02356665]]. Action = [[-0.05512422  0.03218784  0.         -0.9111806 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 7385 is [True, False, False, False, True, False]
Current timestep = 7386. State = [[-0.35152605 -0.0237931 ]]. Action = [[-0.05444301 -0.03239781  0.          0.5237014 ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 7386 is [True, False, False, False, True, False]
Current timestep = 7387. State = [[-0.34858036 -0.02710626]]. Action = [[ 0.07374471 -0.05448015  0.         -0.46702743]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 7387 is [True, False, False, False, True, False]
State prediction error at timestep 7387 is 0.012
Human Feedback received at timestep 7387 of None
Current timestep = 7388. State = [[-0.34848955 -0.02991592]]. Action = [[-0.0728973  -0.02310248  0.         -0.7328114 ]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 7388 is [True, False, False, False, True, False]
Current timestep = 7389. State = [[-0.34767053 -0.02974485]]. Action = [[0.03166451 0.02190731 0.         0.30907285]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 7389 is [True, False, False, False, True, False]
Current timestep = 7390. State = [[-0.34201145 -0.0256518 ]]. Action = [[0.08582201 0.067676   0.         0.0660429 ]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 7390 is [True, False, False, False, True, False]
Current timestep = 7391. State = [[-0.3378423  -0.02452111]]. Action = [[ 0.02674765 -0.02456633  0.         -0.91447926]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 7391 is [True, False, False, False, True, False]
State prediction error at timestep 7391 is 0.012
Human Feedback received at timestep 7391 of None
Current timestep = 7392. State = [[-0.33968264 -0.024175  ]]. Action = [[-0.07162464  0.01768508  0.          0.24669194]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 7392 is [True, False, False, False, True, False]
Current timestep = 7393. State = [[-0.3446585  -0.01981699]]. Action = [[-0.0725697   0.07625689  0.          0.7504082 ]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 7393 is [True, False, False, False, True, False]
Current timestep = 7394. State = [[-0.35083607 -0.02147232]]. Action = [[-0.08911101 -0.08966278  0.          0.89886856]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 7394 is [True, False, False, False, True, False]
State prediction error at timestep 7394 is 0.012
Human Feedback received at timestep 7394 of None
Current timestep = 7395. State = [[-0.3573027 -0.0239603]]. Action = [[-0.08414929 -0.00063983  0.         -0.42231262]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 7395 is [True, False, False, False, True, False]
Current timestep = 7396. State = [[-0.3560859  -0.02403726]]. Action = [[ 0.09203867 -0.00166897  0.          0.6349598 ]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 7396 is [True, False, False, False, True, False]
Current timestep = 7397. State = [[-0.3517424  -0.01879025]]. Action = [[0.04604181 0.09881125 0.         0.1078186 ]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 7397 is [True, False, False, False, True, False]
Current timestep = 7398. State = [[-0.34948972 -0.01762685]]. Action = [[ 0.02414787 -0.04843796  0.         -0.73986   ]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 7398 is [True, False, False, False, True, False]
Current timestep = 7399. State = [[-0.35284835 -0.02164199]]. Action = [[-0.08799454 -0.05873268  0.          0.45486712]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 7399 is [True, False, False, False, True, False]
State prediction error at timestep 7399 is 0.012
Human Feedback received at timestep 7399 of None
Current timestep = 7400. State = [[-0.3518074  -0.01932394]]. Action = [[ 0.08333031  0.08888183  0.         -0.8969942 ]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 7400 is [True, False, False, False, True, False]
State prediction error at timestep 7400 is 0.012
Human Feedback received at timestep 7400 of None
Current timestep = 7401. State = [[-0.3500822  -0.01837075]]. Action = [[-0.00629584 -0.03922821  0.          0.14493299]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 7401 is [True, False, False, False, True, False]
Current timestep = 7402. State = [[-0.35038814 -0.02329234]]. Action = [[-0.01131111 -0.08001715  0.          0.85931444]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 7402 is [True, False, False, False, True, False]
Current timestep = 7403. State = [[-0.35313222 -0.03090044]]. Action = [[-0.06355003 -0.09640241  0.          0.7701616 ]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 7403 is [True, False, False, False, True, False]
Current timestep = 7404. State = [[-0.35867962 -0.03827663]]. Action = [[-0.09512177 -0.07026736  0.          0.67663276]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 7404 is [True, False, False, False, True, False]
Current timestep = 7405. State = [[-0.36238602 -0.04244534]]. Action = [[-0.03167356 -0.01317679  0.          0.70111775]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 7405 is [True, False, False, False, True, False]
Current timestep = 7406. State = [[-0.36074278 -0.04044044]]. Action = [[0.05704362 0.07283854 0.         0.9104667 ]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 7406 is [True, False, False, False, True, False]
Current timestep = 7407. State = [[-0.35676262 -0.04288784]]. Action = [[ 0.06115081 -0.08168314  0.         -0.37677157]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 7407 is [True, False, False, False, True, False]
Current timestep = 7408. State = [[-0.35240275 -0.04185869]]. Action = [[ 0.06624898  0.08095614  0.         -0.07610881]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 7408 is [True, False, False, False, True, False]
Current timestep = 7409. State = [[-0.35057953 -0.03970279]]. Action = [[ 0.01150556  0.00284676  0.         -0.85423815]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 7409 is [True, False, False, False, True, False]
Current timestep = 7410. State = [[-0.3499284  -0.04270082]]. Action = [[ 0.01476612 -0.05794967  0.         -0.6557079 ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 7410 is [True, False, False, False, True, False]
Current timestep = 7411. State = [[-0.3514755  -0.04798188]]. Action = [[-0.03838861 -0.05948594  0.          0.1534189 ]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 7411 is [True, False, False, False, True, False]
Current timestep = 7412. State = [[-0.3480629  -0.05208085]]. Action = [[ 0.09119738 -0.02935737  0.          0.07750034]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 7412 is [True, False, False, False, True, False]
Current timestep = 7413. State = [[-0.34387922 -0.05487483]]. Action = [[ 0.02573428 -0.02117606  0.         -0.7878036 ]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 7413 is [True, False, False, False, True, False]
State prediction error at timestep 7413 is 0.012
Human Feedback received at timestep 7413 of None
Current timestep = 7414. State = [[-0.34065223 -0.06145974]]. Action = [[ 0.03384619 -0.09867813  0.         -0.7923744 ]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 7414 is [True, False, False, False, True, False]
Current timestep = 7415. State = [[-0.3373389  -0.06247315]]. Action = [[ 0.02967327  0.06430479  0.         -0.40763593]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 7415 is [True, False, False, False, True, False]
Current timestep = 7416. State = [[-0.3391643  -0.06414112]]. Action = [[-0.07347845 -0.04565806  0.          0.14067972]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 7416 is [True, False, False, False, True, False]
State prediction error at timestep 7416 is 0.012
Human Feedback received at timestep 7416 of None
Current timestep = 7417. State = [[-0.34272155 -0.06763261]]. Action = [[-0.04919865 -0.01644496  0.         -0.21960169]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 7417 is [True, False, False, False, True, False]
State prediction error at timestep 7417 is 0.012
Human Feedback received at timestep 7417 of None
Current timestep = 7418. State = [[-0.34033233 -0.07409214]]. Action = [[ 0.07124335 -0.0932961   0.         -0.22487438]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 7418 is [True, False, False, False, True, False]
State prediction error at timestep 7418 is 0.012
Human Feedback received at timestep 7418 of None
Current timestep = 7419. State = [[-0.3381196  -0.08144806]]. Action = [[-0.01408312 -0.06290852  0.         -0.82756364]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 7419 is [True, False, False, False, True, False]
State prediction error at timestep 7419 is 0.012
Human Feedback received at timestep 7419 of None
Current timestep = 7420. State = [[-0.33518896 -0.08248822]]. Action = [[0.04554608 0.05012911 0.         0.62766933]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 7420 is [True, False, False, False, True, False]
State prediction error at timestep 7420 is 0.012
Human Feedback received at timestep 7420 of None
Current timestep = 7421. State = [[-0.32907572 -0.08614621]]. Action = [[ 0.08314198 -0.07932352  0.         -0.9321372 ]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 7421 is [True, False, False, False, True, False]
Current timestep = 7422. State = [[-0.32757634 -0.08673108]]. Action = [[-0.0432133   0.05991361  0.          0.341856  ]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 7422 is [True, False, False, False, True, False]
State prediction error at timestep 7422 is 0.012
Human Feedback received at timestep 7422 of None
Current timestep = 7423. State = [[-0.32530975 -0.08742955]]. Action = [[ 0.06663658 -0.03007219  0.         -0.63691145]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 7423 is [True, False, False, False, True, False]
Current timestep = 7424. State = [[-0.32230845 -0.08860053]]. Action = [[ 0.01806241  0.0060424   0.         -0.5042112 ]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 7424 is [True, False, False, False, True, False]
Current timestep = 7425. State = [[-0.31733522 -0.08745643]]. Action = [[ 0.08286101  0.02914324  0.         -0.71716994]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 7425 is [True, False, False, False, True, False]
Current timestep = 7426. State = [[-0.31601185 -0.08572819]]. Action = [[-0.02696262  0.02097869  0.         -0.59441   ]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 7426 is [True, False, False, False, True, False]
Current timestep = 7427. State = [[-0.3122036  -0.08661009]]. Action = [[ 0.08735833 -0.02861283  0.          0.35126948]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 7427 is [True, False, False, False, True, False]
State prediction error at timestep 7427 is 0.012
Human Feedback received at timestep 7427 of None
Current timestep = 7428. State = [[-0.31320757 -0.09134708]]. Action = [[-0.08608669 -0.07162206  0.          0.355443  ]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 7428 is [True, False, False, False, True, False]
State prediction error at timestep 7428 is 0.012
Human Feedback received at timestep 7428 of None
Current timestep = 7429. State = [[-0.31475478 -0.09915409]]. Action = [[ 0.00334237 -0.0987531   0.          0.32180953]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 7429 is [True, False, False, False, True, False]
Current timestep = 7430. State = [[-0.3140531  -0.10588326]]. Action = [[ 4.5455992e-05 -5.4539181e-02  0.0000000e+00  2.8242111e-01]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 7430 is [True, False, False, False, True, False]
Current timestep = 7431. State = [[-0.3102634  -0.11324722]]. Action = [[ 0.05946112 -0.0887318   0.         -0.23730516]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 7431 is [True, False, False, False, True, False]
State prediction error at timestep 7431 is 0.012
Human Feedback received at timestep 7431 of None
Current timestep = 7432. State = [[-0.30413416 -0.11371066]]. Action = [[0.07057523 0.06979709 0.         0.9744179 ]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 7432 is [True, False, False, False, True, False]
State prediction error at timestep 7432 is 0.012
Human Feedback received at timestep 7432 of None
Current timestep = 7433. State = [[-0.3030083  -0.11202348]]. Action = [[-0.0360479   0.01764689  0.          0.02202547]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 7433 is [True, False, False, False, True, False]
State prediction error at timestep 7433 is 0.012
Human Feedback received at timestep 7433 of None
Current timestep = 7434. State = [[-0.3071232  -0.10949995]]. Action = [[-0.07721017  0.06324389  0.          0.83908105]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 7434 is [True, False, False, False, True, False]
Current timestep = 7435. State = [[-0.30919868 -0.11178608]]. Action = [[ 0.000995   -0.06519385  0.         -0.85943115]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 7435 is [True, False, False, False, True, False]
State prediction error at timestep 7435 is 0.012
Human Feedback received at timestep 7435 of None
Current timestep = 7436. State = [[-0.30762044 -0.10992441]]. Action = [[0.02953445 0.08692964 0.         0.01103592]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 7436 is [True, False, False, False, True, False]
Current timestep = 7437. State = [[-0.30994755 -0.10551745]]. Action = [[-0.06625612  0.04166081  0.         -0.3394767 ]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 7437 is [True, False, False, False, True, False]
Current timestep = 7438. State = [[-0.31513378 -0.10136744]]. Action = [[-0.06485052  0.05599969  0.         -0.17020255]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 7438 is [True, False, False, False, True, False]
State prediction error at timestep 7438 is 0.012
Human Feedback received at timestep 7438 of None
Current timestep = 7439. State = [[-0.31442454 -0.10159121]]. Action = [[ 0.0701993  -0.05227017  0.          0.51186156]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 7439 is [True, False, False, False, True, False]
State prediction error at timestep 7439 is 0.012
Human Feedback received at timestep 7439 of None
Current timestep = 7440. State = [[-0.30922568 -0.10419876]]. Action = [[ 0.06965163 -0.03728707  0.         -0.4042306 ]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 7440 is [True, False, False, False, True, False]
State prediction error at timestep 7440 is 0.012
Human Feedback received at timestep 7440 of None
Current timestep = 7441. State = [[-0.31076306 -0.10231731]]. Action = [[-0.08626892  0.05822512  0.          0.10323966]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 7441 is [True, False, False, False, True, False]
State prediction error at timestep 7441 is 0.012
Human Feedback received at timestep 7441 of None
Current timestep = 7442. State = [[-0.31415135 -0.09707014]]. Action = [[-0.00980738  0.06290368  0.          0.91814566]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 7442 is [True, False, False, False, True, False]
Current timestep = 7443. State = [[-0.31296918 -0.09626695]]. Action = [[ 0.05089267 -0.04180555  0.         -0.06950718]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 7443 is [True, False, False, False, True, False]
Current timestep = 7444. State = [[-0.31317368 -0.10082239]]. Action = [[-0.0208675  -0.08448297  0.          0.6252626 ]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 7444 is [True, False, False, False, True, False]
Current timestep = 7445. State = [[-0.31855994 -0.10518752]]. Action = [[-0.09537617 -0.0366363   0.         -0.23085678]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 7445 is [True, False, False, False, True, False]
Current timestep = 7446. State = [[-0.31725094 -0.10725679]]. Action = [[ 0.09269737 -0.01457059  0.         -0.0981859 ]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 7446 is [True, False, False, False, True, False]
State prediction error at timestep 7446 is 0.012
Human Feedback received at timestep 7446 of None
Current timestep = 7447. State = [[-0.31789947 -0.10843251]]. Action = [[-0.07112969 -0.0057864   0.          0.9057468 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 7447 is [True, False, False, False, True, False]
State prediction error at timestep 7447 is 0.012
Human Feedback received at timestep 7447 of None
Current timestep = 7448. State = [[-0.3169031  -0.10547711]]. Action = [[ 0.05908782  0.07122586  0.         -0.94454837]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 7448 is [True, False, False, False, True, False]
Current timestep = 7449. State = [[-0.31288892 -0.10749684]]. Action = [[ 0.05387815 -0.08508073  0.          0.71815324]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 7449 is [True, False, False, False, True, False]
Current timestep = 7450. State = [[-0.30647555 -0.10990673]]. Action = [[ 0.09755734 -0.00141706  0.          0.18784499]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 7450 is [True, False, False, False, True, False]
State prediction error at timestep 7450 is 0.012
Human Feedback received at timestep 7450 of None
Current timestep = 7451. State = [[-0.30451015 -0.11321765]]. Action = [[-0.02315209 -0.05985328  0.          0.1513164 ]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 7451 is [True, False, False, False, True, False]
Current timestep = 7452. State = [[-0.3073645  -0.11472113]]. Action = [[-0.056256    0.02159568  0.         -0.76730126]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 7452 is [True, False, False, False, True, False]
Current timestep = 7453. State = [[-0.31084743 -0.11171892]]. Action = [[-0.04391604  0.0692006   0.         -0.07809305]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 7453 is [True, False, False, False, True, False]
Current timestep = 7454. State = [[-0.30978546 -0.11024777]]. Action = [[ 0.05033328 -0.00454438  0.          0.46575463]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 7454 is [True, False, False, False, True, False]
State prediction error at timestep 7454 is 0.012
Human Feedback received at timestep 7454 of None
Current timestep = 7455. State = [[-0.3052541  -0.10615135]]. Action = [[0.06264221 0.07916128 0.         0.04180956]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 7455 is [True, False, False, False, True, False]
Current timestep = 7456. State = [[-0.30118152 -0.10579055]]. Action = [[ 0.04449692 -0.05112411  0.         -0.4199605 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 7456 is [True, False, False, False, True, False]
Current timestep = 7457. State = [[-0.29872796 -0.10282415]]. Action = [[0.01972549 0.07729927 0.         0.70348907]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 7457 is [True, False, False, False, True, False]
State prediction error at timestep 7457 is 0.012
Human Feedback received at timestep 7457 of None
Current timestep = 7458. State = [[-0.29380864 -0.10032216]]. Action = [[ 0.08789087 -0.0089116   0.          0.90368533]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 7458 is [True, False, False, False, True, False]
Current timestep = 7459. State = [[-0.2905562 -0.1026989]]. Action = [[ 0.00888362 -0.05978806  0.          0.3679918 ]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 7459 is [True, False, False, False, True, False]
Current timestep = 7460. State = [[-0.28785744 -0.10133357]]. Action = [[ 0.03535598  0.05545992  0.         -0.9143329 ]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 7460 is [True, False, False, False, True, False]
Current timestep = 7461. State = [[-0.28423953 -0.10368939]]. Action = [[ 0.03852274 -0.08543557  0.         -0.20676327]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 7461 is [True, False, False, False, True, False]
Current timestep = 7462. State = [[-0.28150463 -0.11054689]]. Action = [[ 0.00901647 -0.0887841   0.         -0.85017943]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 7462 is [True, False, False, False, True, False]
Current timestep = 7463. State = [[-0.27972817 -0.1105818 ]]. Action = [[0.00157402 0.0640268  0.         0.5211723 ]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 7463 is [True, False, False, False, True, False]
Current timestep = 7464. State = [[-0.27980366 -0.11415101]]. Action = [[-0.03079161 -0.09560673  0.          0.00149786]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 7464 is [True, False, False, False, True, False]
Current timestep = 7465. State = [[-0.27788043 -0.11647284]]. Action = [[0.02873909 0.02509116 0.         0.01841688]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 7465 is [True, False, False, False, True, False]
State prediction error at timestep 7465 is 0.012
Human Feedback received at timestep 7465 of None
Current timestep = 7466. State = [[-0.27855292 -0.11541536]]. Action = [[-0.05473632  0.02596832  0.         -0.64029443]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 7466 is [True, False, False, False, True, False]
State prediction error at timestep 7466 is 0.012
Human Feedback received at timestep 7466 of None
Current timestep = 7467. State = [[-0.27749872 -0.11541758]]. Action = [[ 0.03139045 -0.00184479  0.          0.01498449]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 7467 is [True, False, False, False, True, False]
Current timestep = 7468. State = [[-0.27622086 -0.11659922]]. Action = [[-0.00835396 -0.01445081  0.          0.86168766]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 7468 is [True, False, False, False, True, False]
Current timestep = 7469. State = [[-0.27313724 -0.11413692]]. Action = [[0.05303385 0.06337645 0.         0.7738302 ]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 7469 is [True, False, False, False, True, False]
State prediction error at timestep 7469 is 0.012
Human Feedback received at timestep 7469 of None
Current timestep = 7470. State = [[-0.27397713 -0.11215464]]. Action = [[-0.05655914  0.00239757  0.          0.86745214]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 7470 is [True, False, False, False, True, False]
Current timestep = 7471. State = [[-0.27606755 -0.11659927]]. Action = [[-0.0195765  -0.08900746  0.         -0.28107214]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 7471 is [True, False, False, False, True, False]
Current timestep = 7472. State = [[-0.27303404 -0.12003057]]. Action = [[ 0.06722329 -0.01096213  0.          0.46435142]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 7472 is [True, False, False, False, True, False]
Current timestep = 7473. State = [[-0.2673936  -0.12425054]]. Action = [[ 0.06856927 -0.07257138  0.          0.17244065]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 7473 is [True, False, False, False, True, False]
Current timestep = 7474. State = [[-0.26271555 -0.12880109]]. Action = [[ 0.04072129 -0.04027679  0.         -0.8241094 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 7474 is [True, False, False, False, True, False]
State prediction error at timestep 7474 is 0.012
Human Feedback received at timestep 7474 of None
Current timestep = 7475. State = [[-0.26457834 -0.12926668]]. Action = [[-0.08351693  0.03646282  0.         -0.71009016]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 7475 is [True, False, False, True, False, False]
State prediction error at timestep 7475 is 0.012
Human Feedback received at timestep 7475 of None
Current timestep = 7476. State = [[-0.26665336 -0.13351664]]. Action = [[-0.00130354 -0.08590942  0.         -0.6996451 ]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 7476 is [True, False, False, True, False, False]
Current timestep = 7477. State = [[-0.26245406 -0.133444  ]]. Action = [[ 0.08365508  0.07048102  0.         -0.08605099]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 7477 is [True, False, False, True, False, False]
State prediction error at timestep 7477 is 0.012
Human Feedback received at timestep 7477 of None
Current timestep = 7478. State = [[-0.26338974 -0.12932307]]. Action = [[-0.07336644  0.05601489  0.          0.9895129 ]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 7478 is [True, False, False, True, False, False]
Current timestep = 7479. State = [[-0.2680922 -0.1270396]]. Action = [[-0.05497072  0.02032195  0.         -0.34359586]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 7479 is [True, False, False, True, False, False]
Current timestep = 7480. State = [[-0.26703253 -0.12386048]]. Action = [[ 0.06273764  0.05011327  0.         -0.1047526 ]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 7480 is [True, False, False, True, False, False]
Current timestep = 7481. State = [[-0.2657747  -0.12244621]]. Action = [[-1.7955899e-06 -1.3005763e-02  0.0000000e+00 -4.0013087e-01]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 7481 is [True, False, False, False, True, False]
State prediction error at timestep 7481 is 0.012
Human Feedback received at timestep 7481 of None
Current timestep = 7482. State = [[-0.2686308  -0.11796053]]. Action = [[-0.05232674  0.08647837  0.          0.69980323]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 7482 is [True, False, False, False, True, False]
Current timestep = 7483. State = [[-0.26903966 -0.11588178]]. Action = [[ 0.03648572 -0.02466519  0.          0.03481245]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 7483 is [True, False, False, False, True, False]
Current timestep = 7484. State = [[-0.2726308  -0.11934988]]. Action = [[-0.08544642 -0.07141144  0.          0.16183698]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 7484 is [True, False, False, False, True, False]
Current timestep = 7485. State = [[-0.2793413  -0.11995962]]. Action = [[-0.08533691  0.02826438  0.          0.12119126]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 7485 is [True, False, False, False, True, False]
Current timestep = 7486. State = [[-0.28312215 -0.11866079]]. Action = [[-0.01856279  0.0095742   0.          0.9955969 ]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 7486 is [True, False, False, False, True, False]
Current timestep = 7487. State = [[-0.28765523 -0.11878623]]. Action = [[-0.06892904 -0.0138867   0.          0.80899346]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 7487 is [True, False, False, False, True, False]
State prediction error at timestep 7487 is 0.012
Human Feedback received at timestep 7487 of None
Current timestep = 7488. State = [[-0.29237777 -0.11463933]]. Action = [[-0.04164553  0.08748298  0.         -0.42312467]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 7488 is [True, False, False, False, True, False]
State prediction error at timestep 7488 is 0.012
Human Feedback received at timestep 7488 of None
Current timestep = 7489. State = [[-0.29262042 -0.11380666]]. Action = [[ 0.04496176 -0.04797534  0.         -0.8242605 ]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 7489 is [True, False, False, False, True, False]
Current timestep = 7490. State = [[-0.2890393  -0.11883047]]. Action = [[ 0.0654104  -0.088346    0.         -0.02981824]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 7490 is [True, False, False, False, True, False]
Current timestep = 7491. State = [[-0.28711873 -0.12169871]]. Action = [[ 0.00920822 -0.00935692  0.         -0.7141464 ]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 7491 is [True, False, False, False, True, False]
State prediction error at timestep 7491 is 0.012
Human Feedback received at timestep 7491 of None
Current timestep = 7492. State = [[-0.28991687 -0.12601897]]. Action = [[-0.05957473 -0.0727459   0.          0.75148916]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 7492 is [True, False, False, False, True, False]
Current timestep = 7493. State = [[-0.29377195 -0.12930477]]. Action = [[-0.04110752 -0.0065215   0.          0.54548395]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 7493 is [True, False, False, True, False, False]
Current timestep = 7494. State = [[-0.29987216 -0.13060191]]. Action = [[-0.09389464  0.00165732  0.          0.17470813]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 7494 is [True, False, False, True, False, False]
Current timestep = 7495. State = [[-0.30024737 -0.13493381]]. Action = [[ 0.06357264 -0.07167942  0.         -0.51021785]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 7495 is [True, False, False, True, False, False]
Current timestep = 7496. State = [[-0.3027443  -0.14056985]]. Action = [[-0.08847087 -0.04481449  0.         -0.23358572]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 7496 is [True, False, False, True, False, False]
Current timestep = 7497. State = [[-0.30759013 -0.1401053 ]]. Action = [[-0.04689569  0.06845834  0.         -0.5202867 ]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 7497 is [True, False, False, True, False, False]
Current timestep = 7498. State = [[-0.30826607 -0.13891898]]. Action = [[ 0.02642407  0.00525364  0.         -0.58302206]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 7498 is [True, False, False, True, False, False]
Current timestep = 7499. State = [[-0.30349177 -0.13911107]]. Action = [[ 0.09480896 -0.00412504  0.          0.9424424 ]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 7499 is [True, False, False, True, False, False]
Current timestep = 7500. State = [[-0.30201146 -0.13815545]]. Action = [[-0.01520909  0.0194452   0.         -0.62839264]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 7500 is [True, False, False, True, False, False]
Current timestep = 7501. State = [[-0.29866564 -0.13491368]]. Action = [[ 0.08721846  0.04971806  0.         -0.8198382 ]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 7501 is [True, False, False, True, False, False]
Current timestep = 7502. State = [[-0.29813245 -0.1278987 ]]. Action = [[-0.02552628  0.09945252  0.         -0.48121905]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 7502 is [True, False, False, True, False, False]
Current timestep = 7503. State = [[-0.3039842  -0.12134438]]. Action = [[-0.08518346  0.05948598  0.         -0.58645165]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 7503 is [True, False, False, True, False, False]
Current timestep = 7504. State = [[-0.31047648 -0.11771615]]. Action = [[-0.0564422   0.0207711   0.          0.40028477]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 7504 is [True, False, False, False, True, False]
Current timestep = 7505. State = [[-0.31686068 -0.12047833]]. Action = [[-0.06773598 -0.08605377  0.         -0.9159779 ]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 7505 is [True, False, False, False, True, False]
Current timestep = 7506. State = [[-0.32294607 -0.11873485]]. Action = [[-0.05839368  0.07372033  0.          0.29644394]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 7506 is [True, False, False, False, True, False]
Current timestep = 7507. State = [[-0.32281774 -0.11714607]]. Action = [[ 0.06908634 -0.03096527  0.          0.81335974]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 7507 is [True, False, False, False, True, False]
State prediction error at timestep 7507 is 0.012
Human Feedback received at timestep 7507 of None
Current timestep = 7508. State = [[-0.32111424 -0.12171496]]. Action = [[ 0.00990035 -0.09493986  0.          0.0458473 ]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 7508 is [True, False, False, False, True, False]
State prediction error at timestep 7508 is 0.012
Human Feedback received at timestep 7508 of None
Current timestep = 7509. State = [[-0.3172145  -0.12552185]]. Action = [[ 0.07633933 -0.02907568  0.          0.03720331]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 7509 is [True, False, False, False, True, False]
State prediction error at timestep 7509 is 0.012
Human Feedback received at timestep 7509 of None
Current timestep = 7510. State = [[-0.3147076  -0.12919599]]. Action = [[ 0.00410859 -0.05751944  0.         -0.4495983 ]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 7510 is [True, False, False, True, False, False]
Current timestep = 7511. State = [[-0.3136763  -0.13255769]]. Action = [[ 0.01013882 -0.02489642  0.          0.95368767]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 7511 is [True, False, False, True, False, False]
Current timestep = 7512. State = [[-0.3087769  -0.13751653]]. Action = [[ 0.08480745 -0.0709741   0.          0.85934806]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 7512 is [True, False, False, True, False, False]
Current timestep = 7513. State = [[-0.30751052 -0.14047928]]. Action = [[-0.04174027  0.00416861  0.         -0.35508513]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 7513 is [True, False, False, True, False, False]
Current timestep = 7514. State = [[-0.311754   -0.13834888]]. Action = [[-0.07205126  0.07040537  0.          0.47095966]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 7514 is [True, False, False, True, False, False]
Current timestep = 7515. State = [[-0.31019604 -0.14015919]]. Action = [[ 0.08588413 -0.06522059  0.          0.14963996]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 7515 is [True, False, False, True, False, False]
Current timestep = 7516. State = [[-0.303829   -0.14566346]]. Action = [[ 0.06427138 -0.05498325  0.         -0.98524797]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 7516 is [True, False, False, True, False, False]
Current timestep = 7517. State = [[-0.30402222 -0.1460342 ]]. Action = [[-0.07410283  0.0582866   0.         -0.83753335]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 7517 is [True, False, False, True, False, False]
Current timestep = 7518. State = [[-0.30416203 -0.14947343]]. Action = [[ 0.03375331 -0.08288935  0.         -0.1595071 ]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 7518 is [True, False, False, True, False, False]
State prediction error at timestep 7518 is 0.012
Human Feedback received at timestep 7518 of None
Current timestep = 7519. State = [[-0.29992926 -0.1498319 ]]. Action = [[ 0.05444198  0.05852509  0.         -0.44755578]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 7519 is [True, False, False, True, False, False]
State prediction error at timestep 7519 is 0.012
Human Feedback received at timestep 7519 of None
Current timestep = 7520. State = [[-0.29568124 -0.15170634]]. Action = [[ 0.03827875 -0.05884069  0.         -0.32388902]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 7520 is [True, False, False, True, False, False]
Current timestep = 7521. State = [[-0.29152742 -0.14897873]]. Action = [[ 0.04514825  0.09655403  0.         -0.9782997 ]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 7521 is [True, False, False, True, False, False]
Current timestep = 7522. State = [[-0.2944824  -0.14571151]]. Action = [[-0.09886951  0.01643573  0.         -0.9339499 ]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 7522 is [True, False, False, True, False, False]
Current timestep = 7523. State = [[-0.29982919 -0.14957958]]. Action = [[-0.05821138 -0.07723597  0.          0.3912456 ]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 7523 is [True, False, False, True, False, False]
Current timestep = 7524. State = [[-0.29943764 -0.15472607]]. Action = [[ 0.04100325 -0.04683228  0.          0.41101336]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 7524 is [True, False, False, True, False, False]
Current timestep = 7525. State = [[-0.30130768 -0.15816517]]. Action = [[-0.06778032 -0.02788914  0.         -0.7880907 ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 7525 is [True, False, False, True, False, False]
Current timestep = 7526. State = [[-0.30059797 -0.16451558]]. Action = [[ 0.04895376 -0.09623068  0.         -0.79596287]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 7526 is [True, False, False, True, False, False]
Current timestep = 7527. State = [[-0.29766026 -0.16700219]]. Action = [[0.02140604 0.02403706 0.         0.741637  ]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 7527 is [True, False, False, True, False, False]
Current timestep = 7528. State = [[-0.29269332 -0.16313548]]. Action = [[ 0.07551155  0.07869559  0.         -0.9033696 ]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 7528 is [True, False, False, True, False, False]
Current timestep = 7529. State = [[-0.293072   -0.16092648]]. Action = [[-0.0592593  0.0026917  0.        -0.219957 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 7529 is [True, False, False, True, False, False]
Current timestep = 7530. State = [[-0.29208633 -0.16259652]]. Action = [[ 0.05126717 -0.02984452  0.         -0.613211  ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 7530 is [True, False, False, True, False, False]
Current timestep = 7531. State = [[-0.291571   -0.16560368]]. Action = [[-0.02081553 -0.03688493  0.          0.6699655 ]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 7531 is [True, False, False, True, False, False]
State prediction error at timestep 7531 is 0.012
Human Feedback received at timestep 7531 of None
Current timestep = 7532. State = [[-0.2960438  -0.16742061]]. Action = [[-0.08318749  0.00044332  0.         -0.1674788 ]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 7532 is [True, False, False, True, False, False]
State prediction error at timestep 7532 is 0.012
Human Feedback received at timestep 7532 of None
Current timestep = 7533. State = [[-0.29640308 -0.16356   ]]. Action = [[0.04180936 0.09268933 0.         0.40800977]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 7533 is [True, False, False, True, False, False]
Current timestep = 7534. State = [[-0.2911164  -0.15602112]]. Action = [[0.08742481 0.08883335 0.         0.28691924]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 7534 is [True, False, False, True, False, False]
Current timestep = 7535. State = [[-0.28944403 -0.15039615]]. Action = [[-0.01393878  0.0357888   0.         -0.46136582]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 7535 is [True, False, False, True, False, False]
State prediction error at timestep 7535 is 0.012
Human Feedback received at timestep 7535 of None
Current timestep = 7536. State = [[-0.2900501  -0.14425251]]. Action = [[ 0.00134009  0.07805385  0.         -0.8838889 ]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 7536 is [True, False, False, True, False, False]
Current timestep = 7537. State = [[-0.2894268 -0.1441414]]. Action = [[ 0.02363347 -0.0722431   0.          0.19785929]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 7537 is [True, False, False, True, False, False]
Current timestep = 7538. State = [[-0.28590655 -0.14681086]]. Action = [[ 0.06317782 -0.03960943  0.         -0.3784089 ]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 7538 is [True, False, False, True, False, False]
Current timestep = 7539. State = [[-0.28259748 -0.14785889]]. Action = [[ 0.02752803 -0.01640042  0.         -0.77415884]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 7539 is [True, False, False, True, False, False]
Current timestep = 7540. State = [[-0.2848883  -0.15002924]]. Action = [[-0.07128752 -0.0419175   0.         -0.41283357]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 7540 is [True, False, False, True, False, False]
Current timestep = 7541. State = [[-0.28310052 -0.15268165]]. Action = [[ 0.06781628 -0.02798251  0.         -0.16965312]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 7541 is [True, False, False, True, False, False]
State prediction error at timestep 7541 is 0.012
Human Feedback received at timestep 7541 of None
Current timestep = 7542. State = [[-0.27758902 -0.15486588]]. Action = [[ 0.05964679 -0.02769573  0.          0.82391596]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 7542 is [True, False, False, True, False, False]
State prediction error at timestep 7542 is 0.012
Human Feedback received at timestep 7542 of None
Current timestep = 7543. State = [[-0.27739537 -0.15860243]]. Action = [[-0.05197264 -0.05193377  0.          0.53709936]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 7543 is [True, False, False, True, False, False]
State prediction error at timestep 7543 is 0.012
Human Feedback received at timestep 7543 of None
Current timestep = 7544. State = [[-0.2794523  -0.16334546]]. Action = [[-0.03236089 -0.04417929  0.         -0.57857865]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 7544 is [True, False, False, True, False, False]
State prediction error at timestep 7544 is 0.012
Human Feedback received at timestep 7544 of None
Current timestep = 7545. State = [[-0.27888966 -0.16293567]]. Action = [[ 0.01479061  0.05950863  0.         -0.31790233]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 7545 is [True, False, False, True, False, False]
State prediction error at timestep 7545 is 0.012
Human Feedback received at timestep 7545 of None
Current timestep = 7546. State = [[-0.27774408 -0.15961121]]. Action = [[ 0.00184882  0.04965071  0.         -0.23412442]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 7546 is [True, False, False, True, False, False]
Current timestep = 7547. State = [[-0.27997443 -0.15482216]]. Action = [[-0.05631175  0.0758451   0.          0.8511765 ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 7547 is [True, False, False, True, False, False]
Current timestep = 7548. State = [[-0.28446397 -0.1576191 ]]. Action = [[-0.0625339  -0.09549735  0.         -0.18809968]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 7548 is [True, False, False, True, False, False]
Current timestep = 7549. State = [[-0.28761807 -0.16448528]]. Action = [[-0.02713885 -0.07205985  0.          0.85099804]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 7549 is [True, False, False, True, False, False]
Current timestep = 7550. State = [[-0.2875546  -0.16835387]]. Action = [[ 0.01652056 -0.01836167  0.         -0.10258079]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 7550 is [True, False, False, True, False, False]
Current timestep = 7551. State = [[-0.28342244 -0.17204082]]. Action = [[ 0.07194393 -0.05127729  0.         -0.60419184]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 7551 is [True, False, False, True, False, False]
Current timestep = 7552. State = [[-0.28290635 -0.1731123 ]]. Action = [[-0.03827054  0.02169719  0.          0.4732443 ]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 7552 is [True, False, False, True, False, False]
Current timestep = 7553. State = [[-0.28806862 -0.17386518]]. Action = [[-0.08148374 -0.00929645  0.         -0.11767417]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 7553 is [True, False, False, True, False, False]
Current timestep = 7554. State = [[-0.28691584 -0.17194216]]. Action = [[0.08037984 0.05777677 0.         0.90891504]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 7554 is [True, False, False, True, False, False]
Current timestep = 7555. State = [[-0.28951705 -0.1705164 ]]. Action = [[-0.08861949 -0.00267046  0.          0.96293664]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 7555 is [True, False, False, True, False, False]
Current timestep = 7556. State = [[-0.28916436 -0.16842026]]. Action = [[0.06843113 0.04504821 0.         0.56174505]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 7556 is [True, False, False, True, False, False]
Current timestep = 7557. State = [[-0.29103398 -0.16435653]]. Action = [[-0.062879    0.04876766  0.         -0.1683684 ]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 7557 is [True, False, False, True, False, False]
State prediction error at timestep 7557 is 0.012
Human Feedback received at timestep 7557 of None
Current timestep = 7558. State = [[-0.29794878 -0.16003646]]. Action = [[-0.08768141  0.05275107  0.         -0.33830476]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 7558 is [True, False, False, True, False, False]
Current timestep = 7559. State = [[-0.30624974 -0.1536972 ]]. Action = [[-0.09146643  0.08934119  0.          0.41679323]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 7559 is [True, False, False, True, False, False]
Current timestep = 7560. State = [[-0.30930936 -0.14681543]]. Action = [[0.02421025 0.06547823 0.         0.85052145]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 7560 is [True, False, False, True, False, False]
Current timestep = 7561. State = [[-0.31428435 -0.14590009]]. Action = [[-0.08322088 -0.05525726  0.          0.4688915 ]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 7561 is [True, False, False, True, False, False]
Current timestep = 7562. State = [[-0.31696594 -0.1491707 ]]. Action = [[ 0.02654555 -0.05971266  0.         -0.18391502]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 7562 is [True, False, False, True, False, False]
Current timestep = 7563. State = [[-0.3209541  -0.14566946]]. Action = [[-0.06951595  0.09088247  0.          0.14724672]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 7563 is [True, False, False, True, False, False]
Current timestep = 7564. State = [[-0.3278899  -0.13797787]]. Action = [[-0.05978179  0.08042776  0.          0.96594036]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 7564 is [True, False, False, True, False, False]
Current timestep = 7565. State = [[-0.33241126 -0.13389264]]. Action = [[-0.00892355  0.00327353  0.         -0.9512298 ]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 7565 is [True, False, False, True, False, False]
Current timestep = 7566. State = [[-0.3381328 -0.1279292]]. Action = [[-0.06371631  0.08490982  0.         -0.81803733]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 7566 is [True, False, False, True, False, False]
Current timestep = 7567. State = [[-0.3463416  -0.12592763]]. Action = [[-0.07938106 -0.03807321  0.          0.04935122]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 7567 is [True, False, False, True, False, False]
Current timestep = 7568. State = [[-0.35216427 -0.1216385 ]]. Action = [[-0.01921953  0.08053722  0.          0.1229099 ]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 7568 is [True, False, False, True, False, False]
State prediction error at timestep 7568 is 0.012
Human Feedback received at timestep 7568 of None
Current timestep = 7569. State = [[-0.35215154 -0.11974721]]. Action = [[ 0.06502029 -0.04542739  0.          0.292606  ]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 7569 is [True, False, False, False, True, False]
Current timestep = 7570. State = [[-0.3544587  -0.11664954]]. Action = [[-0.05279608  0.05858812  0.          0.7121744 ]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 7570 is [True, False, False, False, True, False]
State prediction error at timestep 7570 is 0.012
Human Feedback received at timestep 7570 of None
Current timestep = 7571. State = [[-0.36229    -0.11265694]]. Action = [[-0.0859374  0.0220978  0.        -0.5206064]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 7571 is [True, False, False, False, True, False]
Current timestep = 7572. State = [[-0.3639053  -0.11036754]]. Action = [[0.0680507  0.00323878 0.         0.29396868]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 7572 is [True, False, False, False, True, False]
Current timestep = 7573. State = [[-0.360111   -0.10574193]]. Action = [[0.07201584 0.05518994 0.         0.46841455]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 7573 is [True, False, False, False, True, False]
Current timestep = 7574. State = [[-0.35861042 -0.09902795]]. Action = [[0.01209994 0.06491878 0.         0.8016906 ]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 7574 is [True, False, False, False, True, False]
Current timestep = 7575. State = [[-0.35849494 -0.09336726]]. Action = [[ 0.01878625  0.03982841  0.         -0.6256942 ]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 7575 is [True, False, False, False, True, False]
Current timestep = 7576. State = [[-0.3627021  -0.08585542]]. Action = [[-0.07266011  0.09737135  0.          0.92512   ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 7576 is [True, False, False, False, True, False]
Current timestep = 7577. State = [[-0.3638836  -0.08235794]]. Action = [[ 0.05315591 -0.02129517  0.          0.32353377]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 7577 is [True, False, False, False, True, False]
Current timestep = 7578. State = [[-0.36161533 -0.07895713]]. Action = [[0.03494645 0.04454359 0.         0.10160398]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 7578 is [True, False, False, False, True, False]
Current timestep = 7579. State = [[-0.35959587 -0.07911982]]. Action = [[ 0.02912313 -0.06041969  0.          0.9235008 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 7579 is [True, False, False, False, True, False]
Current timestep = 7580. State = [[-0.35718286 -0.0771989 ]]. Action = [[ 0.0329157   0.04817673  0.         -0.38478148]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 7580 is [True, False, False, False, True, False]
State prediction error at timestep 7580 is 0.012
Human Feedback received at timestep 7580 of None
Current timestep = 7581. State = [[-0.35852382 -0.07769413]]. Action = [[-0.05028747 -0.05657003  0.          0.01076269]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 7581 is [True, False, False, False, True, False]
Current timestep = 7582. State = [[-0.36127362 -0.07593236]]. Action = [[-0.03506128  0.06013706  0.          0.65373254]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 7582 is [True, False, False, False, True, False]
Current timestep = 7583. State = [[-0.36399952 -0.06938605]]. Action = [[-0.0392573   0.0890828   0.          0.41972494]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 7583 is [True, False, False, False, True, False]
State prediction error at timestep 7583 is 0.012
Human Feedback received at timestep 7583 of None
Current timestep = 7584. State = [[-0.36613128 -0.0649569 ]]. Action = [[-0.02036922  0.01897057  0.         -0.6990556 ]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 7584 is [True, False, False, False, True, False]
Current timestep = 7585. State = [[-0.3650942  -0.06474216]]. Action = [[ 0.03555451 -0.02898401  0.         -0.9115447 ]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 7585 is [True, False, False, False, True, False]
Current timestep = 7586. State = [[-0.3636723  -0.06135469]]. Action = [[ 0.01089154  0.06379255  0.         -0.59893686]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 7586 is [True, False, False, False, True, False]
Current timestep = 7587. State = [[-0.36655182 -0.06071508]]. Action = [[-0.06454991 -0.04259624  0.          0.52142406]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 7587 is [True, False, False, False, True, False]
Current timestep = 7588. State = [[-0.37179244 -0.06076555]]. Action = [[-0.07028182  0.0153261   0.          0.29719555]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 7588 is [True, False, False, False, True, False]
State prediction error at timestep 7588 is 0.012
Human Feedback received at timestep 7588 of None
Current timestep = 7589. State = [[-0.3765496  -0.05648178]]. Action = [[-0.05015638  0.0721428   0.          0.5869107 ]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 7589 is [True, False, False, False, True, False]
Current timestep = 7590. State = [[-0.3786588  -0.05365738]]. Action = [[ 0.         0.         0.        -0.7053936]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 7590 is [True, False, False, False, True, False]
State prediction error at timestep 7590 is 0.012
Human Feedback received at timestep 7590 of None
Current timestep = 7591. State = [[-0.37718642 -0.05446023]]. Action = [[ 0.04693953 -0.03525017  0.          0.93371797]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 7591 is [True, False, False, False, True, False]
Current timestep = 7592. State = [[-0.376521   -0.05480994]]. Action = [[0.         0.         0.         0.05776286]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 7592 is [True, False, False, False, True, False]
Current timestep = 7593. State = [[-0.37695307 -0.05444208]]. Action = [[ 0.          0.          0.         -0.62511706]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 7593 is [True, False, False, False, True, False]
Current timestep = 7594. State = [[-0.3773714  -0.05415081]]. Action = [[ 0.          0.          0.         -0.04054886]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 7594 is [True, False, False, False, True, False]
Current timestep = 7595. State = [[-0.37830296 -0.05208693]]. Action = [[-0.01158293  0.03633706  0.         -0.48837173]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 7595 is [True, False, False, False, True, False]
Current timestep = 7596. State = [[-0.37790424 -0.05561878]]. Action = [[ 0.02153206 -0.09641371  0.         -0.41708803]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 7596 is [True, False, False, False, True, False]
Current timestep = 7597. State = [[-0.37739658 -0.05859371]]. Action = [[ 0.         0.         0.        -0.6985805]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 7597 is [True, False, False, False, True, False]
Current timestep = 7598. State = [[-0.37731317 -0.05906622]]. Action = [[ 0.         0.         0.        -0.5187677]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 7598 is [True, False, False, False, True, False]
Current timestep = 7599. State = [[-0.37778458 -0.0564785 ]]. Action = [[-0.0095902   0.05707445  0.          0.9107559 ]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 7599 is [True, False, False, False, True, False]
Current timestep = 7600. State = [[-0.37632924 -0.05481627]]. Action = [[ 0.03904914 -0.00167914  0.         -0.31877303]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 7600 is [True, False, False, False, True, False]
State prediction error at timestep 7600 is 0.012
Human Feedback received at timestep 7600 of None
Current timestep = 7601. State = [[-0.37656295 -0.05376747]]. Action = [[-0.02335339  0.01745839  0.          0.1327306 ]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 7601 is [True, False, False, False, True, False]
Current timestep = 7602. State = [[-0.37655303 -0.05237985]]. Action = [[0.01654198 0.01506238 0.         0.5771425 ]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 7602 is [True, False, False, False, True, False]
Current timestep = 7603. State = [[-0.37634826 -0.05165843]]. Action = [[0.        0.        0.        0.4530728]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 7603 is [True, False, False, False, True, False]
State prediction error at timestep 7603 is 0.012
Human Feedback received at timestep 7603 of None
Current timestep = 7604. State = [[-0.37490854 -0.05551805]]. Action = [[ 0.03081965 -0.08007301  0.          0.49297142]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 7604 is [True, False, False, False, True, False]
Current timestep = 7605. State = [[-0.37386054 -0.05806654]]. Action = [[ 0.          0.          0.         -0.60233706]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 7605 is [True, False, False, False, True, False]
Current timestep = 7606. State = [[-0.3716842  -0.06235082]]. Action = [[ 0.036756 -0.0764    0.       -0.947656]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 7606 is [True, False, False, False, True, False]
Current timestep = 7607. State = [[-0.3700926  -0.06520043]]. Action = [[ 0.          0.          0.         -0.06575817]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 7607 is [True, False, False, False, True, False]
Current timestep = 7608. State = [[-0.3723961  -0.06939296]]. Action = [[-0.06121376 -0.0635324   0.         -0.59485656]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 7608 is [True, False, False, False, True, False]
Current timestep = 7609. State = [[-0.3735224  -0.07250519]]. Action = [[ 0.         0.         0.        -0.9012154]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 7609 is [True, False, False, False, True, False]
Current timestep = 7610. State = [[-0.3734358  -0.07771282]]. Action = [[-0.00550055 -0.0785325   0.         -0.3208387 ]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 7610 is [True, False, False, False, True, False]
Current timestep = 7611. State = [[-0.37080255 -0.07767595]]. Action = [[ 0.05330496  0.07524414  0.         -0.5667845 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 7611 is [True, False, False, False, True, False]
State prediction error at timestep 7611 is 0.012
Human Feedback received at timestep 7611 of None
Current timestep = 7612. State = [[-0.36890522 -0.07181399]]. Action = [[ 0.00349934  0.08273777  0.         -0.95044553]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 7612 is [True, False, False, False, True, False]
Current timestep = 7613. State = [[-0.3665934  -0.06923295]]. Action = [[ 0.04499786 -0.00254606  0.         -0.3031289 ]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 7613 is [True, False, False, False, True, False]
Current timestep = 7614. State = [[-0.36529106 -0.07344813]]. Action = [[ 0.00294425 -0.08788616  0.         -0.05358291]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 7614 is [True, False, False, False, True, False]
State prediction error at timestep 7614 is 0.012
Human Feedback received at timestep 7614 of None
Current timestep = 7615. State = [[-0.3626486  -0.07408851]]. Action = [[0.05106214 0.0442717  0.         0.9643595 ]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 7615 is [True, False, False, False, True, False]
State prediction error at timestep 7615 is 0.012
Human Feedback received at timestep 7615 of None
Current timestep = 7616. State = [[-0.35716018 -0.06875917]]. Action = [[ 0.08123114  0.0762765   0.         -0.47385883]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 7616 is [True, False, False, False, True, False]
Current timestep = 7617. State = [[-0.35221928 -0.06826781]]. Action = [[ 0.05150282 -0.05185697  0.          0.7908238 ]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 7617 is [True, False, False, False, True, False]
Current timestep = 7618. State = [[-0.35467127 -0.07438581]]. Action = [[-0.09255204 -0.09613582  0.         -0.4776644 ]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 7618 is [True, False, False, False, True, False]
Current timestep = 7619. State = [[-0.3543687  -0.07515369]]. Action = [[ 0.05997153  0.06543563  0.         -0.83567685]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 7619 is [True, False, False, False, True, False]
State prediction error at timestep 7619 is 0.012
Human Feedback received at timestep 7619 of None
Current timestep = 7620. State = [[-0.3551101  -0.06926587]]. Action = [[-0.0516293   0.08221609  0.         -0.27739716]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 7620 is [True, False, False, False, True, False]
State prediction error at timestep 7620 is 0.012
Human Feedback received at timestep 7620 of None
Current timestep = 7621. State = [[-0.35381013 -0.06592122]]. Action = [[ 0.05659989  0.00623056  0.         -0.8170964 ]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 7621 is [True, False, False, False, True, False]
Current timestep = 7622. State = [[-0.34937882 -0.06683708]]. Action = [[ 0.05423339 -0.03882186  0.         -0.03786552]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 7622 is [True, False, False, False, True, False]
State prediction error at timestep 7622 is 0.012
Human Feedback received at timestep 7622 of None
Current timestep = 7623. State = [[-0.35061526 -0.06868351]]. Action = [[-0.07232641 -0.01966999  0.          0.4889902 ]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 7623 is [True, False, False, False, True, False]
Current timestep = 7624. State = [[-0.3536963  -0.06581351]]. Action = [[-0.0301948  0.0706852  0.        -0.8300732]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 7624 is [True, False, False, False, True, False]
Current timestep = 7625. State = [[-0.35072038 -0.06719154]]. Action = [[ 0.08393525 -0.07763319  0.          0.5884142 ]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 7625 is [True, False, False, False, True, False]
State prediction error at timestep 7625 is 0.012
Human Feedback received at timestep 7625 of None
Current timestep = 7626. State = [[-0.3445193  -0.06597617]]. Action = [[0.06567546 0.06109657 0.         0.7841842 ]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 7626 is [True, False, False, False, True, False]
State prediction error at timestep 7626 is 0.012
Human Feedback received at timestep 7626 of None
Current timestep = 7627. State = [[-0.3453626  -0.06681754]]. Action = [[-0.07736579 -0.06148222  0.         -0.39955288]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 7627 is [True, False, False, False, True, False]
Current timestep = 7628. State = [[-0.34471354 -0.07264739]]. Action = [[ 0.0371687  -0.07537154  0.          0.17758751]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 7628 is [True, False, False, False, True, False]
Current timestep = 7629. State = [[-0.34281674 -0.07758737]]. Action = [[-0.00269382 -0.03937882  0.          0.25145817]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 7629 is [True, False, False, False, True, False]
State prediction error at timestep 7629 is 0.012
Human Feedback received at timestep 7629 of None
Current timestep = 7630. State = [[-0.34226164 -0.08024371]]. Action = [[-0.01072977 -0.00959028  0.          0.11088479]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 7630 is [True, False, False, False, True, False]
Current timestep = 7631. State = [[-0.3394052  -0.08524966]]. Action = [[ 0.04400421 -0.07347868  0.         -0.66034883]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 7631 is [True, False, False, False, True, False]
State prediction error at timestep 7631 is 0.012
Human Feedback received at timestep 7631 of None
Current timestep = 7632. State = [[-0.33777997 -0.08468073]]. Action = [[-0.01307798  0.07696035  0.         -0.16345537]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 7632 is [True, False, False, False, True, False]
State prediction error at timestep 7632 is 0.012
Human Feedback received at timestep 7632 of None
Current timestep = 7633. State = [[-0.33350936 -0.08290334]]. Action = [[ 0.0832197   0.00463744  0.         -0.1657865 ]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 7633 is [True, False, False, False, True, False]
Current timestep = 7634. State = [[-0.33466074 -0.07922884]]. Action = [[-0.08970384  0.08069544  0.         -0.82546306]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 7634 is [True, False, False, False, True, False]
State prediction error at timestep 7634 is 0.012
Human Feedback received at timestep 7634 of None
Current timestep = 7635. State = [[-0.33755603 -0.0787897 ]]. Action = [[-0.00321133 -0.03473601  0.         -0.67490953]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 7635 is [True, False, False, False, True, False]
Current timestep = 7636. State = [[-0.33986914 -0.0830577 ]]. Action = [[-0.03551131 -0.06320963  0.          0.45270908]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 7636 is [True, False, False, False, True, False]
Current timestep = 7637. State = [[-0.3367639  -0.08649568]]. Action = [[ 0.09047248 -0.02538314  0.         -0.5324253 ]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 7637 is [True, False, False, False, True, False]
State prediction error at timestep 7637 is 0.012
Human Feedback received at timestep 7637 of None
Current timestep = 7638. State = [[-0.33852005 -0.09256791]]. Action = [[-0.09144614 -0.09954575  0.          0.23624706]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 7638 is [True, False, False, False, True, False]
State prediction error at timestep 7638 is 0.012
Human Feedback received at timestep 7638 of None
Current timestep = 7639. State = [[-0.34547523 -0.09909308]]. Action = [[-0.09098624 -0.05222387  0.          0.09405458]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 7639 is [True, False, False, False, True, False]
Current timestep = 7640. State = [[-0.3468501  -0.10122116]]. Action = [[0.0324633  0.01541002 0.         0.72426474]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 7640 is [True, False, False, False, True, False]
Current timestep = 7641. State = [[-0.3459537  -0.10430794]]. Action = [[ 0.00768503 -0.05172253  0.          0.874743  ]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 7641 is [True, False, False, False, True, False]
State prediction error at timestep 7641 is 0.012
Human Feedback received at timestep 7641 of None
Current timestep = 7642. State = [[-0.34837937 -0.10834755]]. Action = [[-0.04952925 -0.03045078  0.          0.3866706 ]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 7642 is [True, False, False, False, True, False]
Current timestep = 7643. State = [[-0.34989876 -0.1087311 ]]. Action = [[ 0.00526259  0.03499909  0.         -0.08111906]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 7643 is [True, False, False, False, True, False]
Current timestep = 7644. State = [[-0.35231966 -0.10448959]]. Action = [[-0.03952065  0.08125602  0.          0.00057054]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 7644 is [True, False, False, False, True, False]
State prediction error at timestep 7644 is 0.012
Human Feedback received at timestep 7644 of None
Current timestep = 7645. State = [[-0.3522958  -0.10003736]]. Action = [[0.04070776 0.0434039  0.         0.9351226 ]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 7645 is [True, False, False, False, True, False]
State prediction error at timestep 7645 is 0.012
Human Feedback received at timestep 7645 of None
Current timestep = 7646. State = [[-0.3555027  -0.10223076]]. Action = [[-0.0727521  -0.08623925  0.         -0.85519624]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 7646 is [True, False, False, False, True, False]
Current timestep = 7647. State = [[-0.36233604 -0.10011649]]. Action = [[-0.07609294  0.09945499  0.          0.8164098 ]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 7647 is [True, False, False, False, True, False]
Current timestep = 7648. State = [[-0.3618897  -0.09563521]]. Action = [[ 0.09522974  0.02000531  0.         -0.1271956 ]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 7648 is [True, False, False, False, True, False]
Current timestep = 7649. State = [[-0.35717598 -0.09164792]]. Action = [[ 0.05769918  0.0431804   0.         -0.1113674 ]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 7649 is [True, False, False, False, True, False]
Current timestep = 7650. State = [[-0.35290104 -0.09282012]]. Action = [[ 0.06073431 -0.07339601  0.          0.5975337 ]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 7650 is [True, False, False, False, True, False]
Current timestep = 7651. State = [[-0.3509275 -0.0935988]]. Action = [[ 0.00823207  0.01140621  0.         -0.75239   ]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 7651 is [True, False, False, False, True, False]
Current timestep = 7652. State = [[-0.34916028 -0.08969489]]. Action = [[0.03324165 0.06190013 0.         0.6394646 ]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 7652 is [True, False, False, False, True, False]
Current timestep = 7653. State = [[-0.34386244 -0.08342701]]. Action = [[0.09294998 0.06811183 0.         0.8614402 ]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 7653 is [True, False, False, False, True, False]
Current timestep = 7654. State = [[-0.34309918 -0.07891261]]. Action = [[-0.03446577  0.02345953  0.          0.5472925 ]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 7654 is [True, False, False, False, True, False]
Current timestep = 7655. State = [[-0.34799483 -0.07720515]]. Action = [[-0.07871239  0.0026053   0.         -0.48702598]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 7655 is [True, False, False, False, True, False]
State prediction error at timestep 7655 is 0.012
Human Feedback received at timestep 7655 of None
Current timestep = 7656. State = [[-0.34946847 -0.07807653]]. Action = [[ 0.01897985 -0.03162529  0.         -0.27974498]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 7656 is [True, False, False, False, True, False]
State prediction error at timestep 7656 is 0.012
Human Feedback received at timestep 7656 of None
Current timestep = 7657. State = [[-0.34516782 -0.08166467]]. Action = [[ 0.07536563 -0.06745432  0.          0.75975096]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 7657 is [True, False, False, False, True, False]
State prediction error at timestep 7657 is 0.012
Human Feedback received at timestep 7657 of None
Current timestep = 7658. State = [[-0.34548154 -0.07979931]]. Action = [[-0.07029933  0.07313644  0.          0.3172499 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 7658 is [True, False, False, False, True, False]
Current timestep = 7659. State = [[-0.34978485 -0.07847887]]. Action = [[-0.04674888 -0.02201883  0.         -0.54784364]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 7659 is [True, False, False, False, True, False]
Current timestep = 7660. State = [[-0.34998316 -0.08123159]]. Action = [[ 0.03002378 -0.0502749   0.          0.03533125]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 7660 is [True, False, False, False, True, False]
Current timestep = 7661. State = [[-0.34975982 -0.08597766]]. Action = [[-0.01088776 -0.06659341  0.         -0.1532374 ]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 7661 is [True, False, False, False, True, False]
Current timestep = 7662. State = [[-0.35213822 -0.08945299]]. Action = [[-0.04714121 -0.02043355  0.          0.5804285 ]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 7662 is [True, False, False, False, True, False]
Current timestep = 7663. State = [[-0.35634184 -0.09108645]]. Action = [[-0.0619669  -0.00244047  0.         -0.9207098 ]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 7663 is [True, False, False, False, True, False]
Current timestep = 7664. State = [[-0.35764644 -0.09606388]]. Action = [[ 0.01105599 -0.07943842  0.         -0.7121952 ]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 7664 is [True, False, False, False, True, False]
Current timestep = 7665. State = [[-0.35717902 -0.09932511]]. Action = [[0.00300839 0.00136037 0.         0.12594831]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 7665 is [True, False, False, False, True, False]
Current timestep = 7666. State = [[-0.3560036  -0.10025884]]. Action = [[0.0198316  0.0015199  0.         0.00704718]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 7666 is [True, False, False, False, True, False]
Current timestep = 7667. State = [[-0.3554574  -0.09604026]]. Action = [[ 1.5074015e-04  9.6992441e-02  0.0000000e+00 -9.7156554e-01]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 7667 is [True, False, False, False, True, False]
Current timestep = 7668. State = [[-0.35484388 -0.09551709]]. Action = [[ 0.01874687 -0.04230836  0.         -0.5249744 ]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 7668 is [True, False, False, False, True, False]
Current timestep = 7669. State = [[-0.35696325 -0.09853757]]. Action = [[-0.04611946 -0.03135485  0.         -0.6796467 ]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 7669 is [True, False, False, False, True, False]
Current timestep = 7670. State = [[-0.3616692 -0.1009626]]. Action = [[-0.06034319 -0.0144261   0.         -0.4088651 ]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 7670 is [True, False, False, False, True, False]
Current timestep = 7671. State = [[-0.35982978 -0.09877843]]. Action = [[0.08669854 0.06482732 0.         0.26038682]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 7671 is [True, False, False, False, True, False]
Current timestep = 7672. State = [[-0.35460347 -0.09750198]]. Action = [[ 0.06719249 -0.02329232  0.         -0.50205225]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 7672 is [True, False, False, False, True, False]
Current timestep = 7673. State = [[-0.35518005 -0.1003704 ]]. Action = [[-0.04675454 -0.0523832   0.         -0.3892359 ]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 7673 is [True, False, False, False, True, False]
Current timestep = 7674. State = [[-0.35409394 -0.10563869]]. Action = [[ 0.05285909 -0.06924678  0.         -0.10941601]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 7674 is [True, False, False, False, True, False]
State prediction error at timestep 7674 is 0.012
Human Feedback received at timestep 7674 of None
Current timestep = 7675. State = [[-0.3537438  -0.10612021]]. Action = [[-0.02445345  0.04212608  0.          0.46185005]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 7675 is [True, False, False, False, True, False]
State prediction error at timestep 7675 is 0.012
Human Feedback received at timestep 7675 of None
Current timestep = 7676. State = [[-0.3548935  -0.10356348]]. Action = [[-0.00825099  0.03612094  0.         -0.7785335 ]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 7676 is [True, False, False, False, True, False]
Current timestep = 7677. State = [[-0.35101578 -0.09861866]]. Action = [[0.08905857 0.07327913 0.         0.36988747]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 7677 is [True, False, False, False, True, False]
Current timestep = 7678. State = [[-0.34912968 -0.09675249]]. Action = [[-0.00737002 -0.02154779  0.          0.8369278 ]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 7678 is [True, False, False, False, True, False]
Current timestep = 7679. State = [[-0.3523421  -0.09724849]]. Action = [[-0.05735131 -0.00418891  0.         -0.2898357 ]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 7679 is [True, False, False, False, True, False]
Current timestep = 7680. State = [[-0.35399938 -0.10062075]]. Action = [[ 0.00622723 -0.0624064   0.         -0.57426023]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 7680 is [True, False, False, False, True, False]
State prediction error at timestep 7680 is 0.012
Human Feedback received at timestep 7680 of None
Current timestep = 7681. State = [[-0.35250646 -0.09857325]]. Action = [[0.03150684 0.07930128 0.         0.49312282]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 7681 is [True, False, False, False, True, False]
Current timestep = 7682. State = [[-0.35342458 -0.09323867]]. Action = [[-0.03451008  0.05487274  0.         -0.45842266]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 7682 is [True, False, False, False, True, False]
Current timestep = 7683. State = [[-0.35948768 -0.08925185]]. Action = [[-0.098205    0.03901825  0.          0.7091787 ]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 7683 is [True, False, False, False, True, False]
Current timestep = 7684. State = [[-0.36467838 -0.09154276]]. Action = [[-0.0358668  -0.07446638  0.          0.24265647]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 7684 is [True, False, False, False, True, False]
State prediction error at timestep 7684 is 0.012
Human Feedback received at timestep 7684 of None
Current timestep = 7685. State = [[-0.3629861  -0.09113047]]. Action = [[0.07376919 0.04988065 0.         0.6966083 ]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 7685 is [True, False, False, False, True, False]
Current timestep = 7686. State = [[-0.3597038  -0.09336378]]. Action = [[ 0.03257469 -0.09024633  0.          0.249434  ]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 7686 is [True, False, False, False, True, False]
Current timestep = 7687. State = [[-0.35908842 -0.09125571]]. Action = [[-0.00842964  0.08574086  0.          0.3966179 ]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 7687 is [True, False, False, False, True, False]
Current timestep = 7688. State = [[-0.36285874 -0.08542778]]. Action = [[-0.06412336  0.05984148  0.          0.17040968]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 7688 is [True, False, False, False, True, False]
Current timestep = 7689. State = [[-0.36841562 -0.08627452]]. Action = [[-0.06240937 -0.06198274  0.          0.33095264]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 7689 is [True, False, False, False, True, False]
Current timestep = 7690. State = [[-0.36829934 -0.0913353 ]]. Action = [[ 0.05603253 -0.07048752  0.         -0.5363097 ]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 7690 is [True, False, False, False, True, False]
Current timestep = 7691. State = [[-0.36306122 -0.09624289]]. Action = [[ 0.08282705 -0.05949586  0.         -0.9983854 ]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 7691 is [True, False, False, False, True, False]
Current timestep = 7692. State = [[-0.35861498 -0.09600256]]. Action = [[ 0.03695973  0.03937199  0.         -0.2792974 ]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 7692 is [True, False, False, False, True, False]
State prediction error at timestep 7692 is 0.012
Human Feedback received at timestep 7692 of None
Current timestep = 7693. State = [[-0.3607965  -0.09271449]]. Action = [[-0.07319274  0.04795899  0.          0.2085067 ]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 7693 is [True, False, False, False, True, False]
Current timestep = 7694. State = [[-0.36113638 -0.09319181]]. Action = [[ 0.04019754 -0.03536449  0.          0.6577933 ]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 7694 is [True, False, False, False, True, False]
Current timestep = 7695. State = [[-0.36399868 -0.09013163]]. Action = [[-0.08502661  0.0900685   0.         -0.4521007 ]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 7695 is [True, False, False, False, True, False]
Current timestep = 7696. State = [[-0.36357385 -0.08847514]]. Action = [[ 0.07761594 -0.02682903  0.         -0.25352675]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 7696 is [True, False, False, False, True, False]
Current timestep = 7697. State = [[-0.35859704 -0.0935338 ]]. Action = [[ 0.05694631 -0.09312339  0.          0.5815642 ]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 7697 is [True, False, False, False, True, False]
State prediction error at timestep 7697 is 0.012
Human Feedback received at timestep 7697 of None
Current timestep = 7698. State = [[-0.35515025 -0.09542953]]. Action = [[0.02295569 0.02074132 0.         0.6264576 ]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 7698 is [True, False, False, False, True, False]
State prediction error at timestep 7698 is 0.012
Human Feedback received at timestep 7698 of None
Current timestep = 7699. State = [[-0.3541751  -0.09936003]]. Action = [[-0.0091333  -0.08061439  0.          0.61930346]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 7699 is [True, False, False, False, True, False]
Current timestep = 7700. State = [[-0.35588604 -0.1035432 ]]. Action = [[-0.0450488  -0.01955771  0.          0.7779186 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 7700 is [True, False, False, False, True, False]
Current timestep = 7701. State = [[-0.3539087  -0.10659169]]. Action = [[ 0.05181914 -0.02639611  0.         -0.55365497]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 7701 is [True, False, False, False, True, False]
Current timestep = 7702. State = [[-0.35225898 -0.11303644]]. Action = [[-0.01277304 -0.0930578   0.          0.7376405 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 7702 is [True, False, False, False, True, False]
Current timestep = 7703. State = [[-0.35170478 -0.11803876]]. Action = [[-0.00091492 -0.01719085  0.         -0.47996688]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 7703 is [True, False, False, False, True, False]
Current timestep = 7704. State = [[-0.34785798 -0.11945335]]. Action = [[0.06088001 0.01142247 0.         0.12780416]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 7704 is [True, False, False, False, True, False]
Current timestep = 7705. State = [[-0.34856144 -0.11776531]]. Action = [[-0.06795156  0.05195085  0.          0.33752823]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 7705 is [True, False, False, False, True, False]
State prediction error at timestep 7705 is 0.012
Human Feedback received at timestep 7705 of None
Current timestep = 7706. State = [[-0.34714308 -0.11861224]]. Action = [[ 0.06463567 -0.03212275  0.          0.10933888]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 7706 is [True, False, False, False, True, False]
Current timestep = 7707. State = [[-0.34818396 -0.12007458]]. Action = [[-0.06878272  0.00718568  0.          0.6007707 ]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 7707 is [True, False, False, False, True, False]
Current timestep = 7708. State = [[-0.34676203 -0.11719435]]. Action = [[ 0.06199776  0.06918     0.         -0.8941027 ]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 7708 is [True, False, False, False, True, False]
Current timestep = 7709. State = [[-0.3459639  -0.11815056]]. Action = [[-0.02101689 -0.06260372  0.         -0.9027925 ]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 7709 is [True, False, False, False, True, False]
Current timestep = 7710. State = [[-0.349619   -0.11857635]]. Action = [[-0.06299257  0.03454223  0.          0.5385325 ]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 7710 is [True, False, False, False, True, False]
Current timestep = 7711. State = [[-0.35362193 -0.11953925]]. Action = [[-0.03749391 -0.02851629  0.          0.33564126]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 7711 is [True, False, False, False, True, False]
Current timestep = 7712. State = [[-0.3515345  -0.11623807]]. Action = [[0.07698726 0.08809089 0.         0.08689809]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 7712 is [True, False, False, False, True, False]
State prediction error at timestep 7712 is 0.012
Human Feedback received at timestep 7712 of None
Current timestep = 7713. State = [[-0.3468385  -0.11570062]]. Action = [[ 0.05832421 -0.05781075  0.         -0.3953606 ]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 7713 is [True, False, False, False, True, False]
State prediction error at timestep 7713 is 0.012
Human Feedback received at timestep 7713 of None
Current timestep = 7714. State = [[-0.34790036 -0.11916624]]. Action = [[-0.05437603 -0.04847474  0.         -0.3212564 ]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 7714 is [True, False, False, False, True, False]
Current timestep = 7715. State = [[-0.34510118 -0.12143316]]. Action = [[ 0.09078559 -0.01727108  0.         -0.10029328]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 7715 is [True, False, False, False, True, False]
Current timestep = 7716. State = [[-0.346776   -0.12623577]]. Action = [[-0.09098844 -0.09194895  0.          0.04717696]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 7716 is [True, False, False, False, True, False]
Current timestep = 7717. State = [[-0.3454342  -0.12751953]]. Action = [[ 0.08416294  0.05310435  0.         -0.43084562]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 7717 is [True, False, False, True, False, False]
Current timestep = 7718. State = [[-0.3421003  -0.12521563]]. Action = [[0.01515052 0.0204679  0.         0.798537  ]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 7718 is [True, False, False, True, False, False]
State prediction error at timestep 7718 is 0.012
Human Feedback received at timestep 7718 of None
Current timestep = 7719. State = [[-0.3394421  -0.12373089]]. Action = [[ 0.03651122  0.01505519  0.         -0.8391565 ]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 7719 is [True, False, False, True, False, False]
Current timestep = 7720. State = [[-0.33726323 -0.12184083]]. Action = [[ 0.017405    0.02563887  0.         -0.81993514]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 7720 is [True, False, False, False, True, False]
State prediction error at timestep 7720 is 0.012
Human Feedback received at timestep 7720 of None
Current timestep = 7721. State = [[-0.3342808 -0.1224544]]. Action = [[ 0.04491145 -0.03145685  0.          0.33002067]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 7721 is [True, False, False, False, True, False]
Current timestep = 7722. State = [[-0.3335759  -0.12594254]]. Action = [[-0.01911422 -0.0519716   0.         -0.5696483 ]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 7722 is [True, False, False, False, True, False]
State prediction error at timestep 7722 is 0.012
Human Feedback received at timestep 7722 of None
Current timestep = 7723. State = [[-0.33766353 -0.13241425]]. Action = [[-0.08027204 -0.08621382  0.         -0.95016897]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 7723 is [True, False, False, True, False, False]
Current timestep = 7724. State = [[-0.3394539  -0.13338476]]. Action = [[0.0044204  0.05556168 0.         0.8584094 ]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 7724 is [True, False, False, True, False, False]
Current timestep = 7725. State = [[-0.33539745 -0.13667046]]. Action = [[ 0.075789   -0.08639294  0.          0.015939  ]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 7725 is [True, False, False, True, False, False]
State prediction error at timestep 7725 is 0.012
Human Feedback received at timestep 7725 of None
Current timestep = 7726. State = [[-0.32758212 -0.13754559]]. Action = [[ 0.09206881  0.04106387  0.         -0.28140283]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 7726 is [True, False, False, True, False, False]
State prediction error at timestep 7726 is 0.012
Human Feedback received at timestep 7726 of None
Current timestep = 7727. State = [[-0.31943655 -0.1341504 ]]. Action = [[ 0.08565747  0.04831364  0.         -0.47417015]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 7727 is [True, False, False, True, False, False]
State prediction error at timestep 7727 is 0.012
Human Feedback received at timestep 7727 of None
Current timestep = 7728. State = [[-0.3145987  -0.12906657]]. Action = [[ 0.0276169   0.06979056  0.         -0.4459889 ]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 7728 is [True, False, False, True, False, False]
Current timestep = 7729. State = [[-0.3086997  -0.13148855]]. Action = [[ 0.0917161  -0.09905872  0.         -0.37534738]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 7729 is [True, False, False, True, False, False]
Current timestep = 7730. State = [[-0.30258062 -0.13116807]]. Action = [[0.04695987 0.06309365 0.         0.9570224 ]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 7730 is [True, False, False, True, False, False]
Current timestep = 7731. State = [[-0.30476907 -0.12686741]]. Action = [[-0.09340806  0.05579171  0.          0.12087572]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 7731 is [True, False, False, True, False, False]
State prediction error at timestep 7731 is 0.012
Human Feedback received at timestep 7731 of None
Current timestep = 7732. State = [[-0.3041646  -0.12925713]]. Action = [[ 0.05967162 -0.0855675   0.          0.41863728]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 7732 is [True, False, False, True, False, False]
Current timestep = 7733. State = [[-0.3014216  -0.13570203]]. Action = [[-0.00515185 -0.07341869  0.         -0.9183848 ]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 7733 is [True, False, False, True, False, False]
Current timestep = 7734. State = [[-0.29491556 -0.14273097]]. Action = [[ 0.09644931 -0.08247057  0.         -0.821939  ]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 7734 is [True, False, False, True, False, False]
State prediction error at timestep 7734 is 0.012
Human Feedback received at timestep 7734 of None
Current timestep = 7735. State = [[-0.29288304 -0.14760414]]. Action = [[-0.06133386 -0.02583762  0.         -0.00977623]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 7735 is [True, False, False, True, False, False]
Current timestep = 7736. State = [[-0.29545698 -0.15372473]]. Action = [[-0.05462009 -0.07721584  0.          0.03351212]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 7736 is [True, False, False, True, False, False]
State prediction error at timestep 7736 is 0.012
Human Feedback received at timestep 7736 of None
Current timestep = 7737. State = [[-0.2925063  -0.15753137]]. Action = [[ 0.06290453  0.00115572  0.         -0.6850271 ]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 7737 is [True, False, False, True, False, False]
State prediction error at timestep 7737 is 0.012
Human Feedback received at timestep 7737 of None
Current timestep = 7738. State = [[-0.29268828 -0.16134784]]. Action = [[-0.06711209 -0.04525585  0.         -0.550325  ]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 7738 is [True, False, False, True, False, False]
Current timestep = 7739. State = [[-0.29592007 -0.15959324]]. Action = [[-0.05226091  0.09890466  0.         -0.10460019]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 7739 is [True, False, False, True, False, False]
State prediction error at timestep 7739 is 0.012
Human Feedback received at timestep 7739 of None
Current timestep = 7740. State = [[-0.29271534 -0.1544216 ]]. Action = [[ 0.08666941  0.06680994  0.         -0.572896  ]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 7740 is [True, False, False, True, False, False]
Current timestep = 7741. State = [[-0.29301274 -0.155322  ]]. Action = [[-0.07203248 -0.06267528  0.         -0.3187064 ]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 7741 is [True, False, False, True, False, False]
Current timestep = 7742. State = [[-0.29583168 -0.15639283]]. Action = [[-0.02551524  0.02742913  0.          0.10949171]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 7742 is [True, False, False, True, False, False]
Current timestep = 7743. State = [[-0.29211223 -0.15089591]]. Action = [[ 0.0909391   0.09918974  0.         -0.2638471 ]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 7743 is [True, False, False, True, False, False]
Current timestep = 7744. State = [[-0.28576815 -0.1442968 ]]. Action = [[ 0.08142648  0.05281363  0.         -0.624796  ]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 7744 is [True, False, False, True, False, False]
Current timestep = 7745. State = [[-0.28116828 -0.14461717]]. Action = [[ 0.05060806 -0.06927034  0.          0.33242583]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 7745 is [True, False, False, True, False, False]
Current timestep = 7746. State = [[-0.27864927 -0.1448354 ]]. Action = [[ 0.02401664  0.01296891  0.         -0.831593  ]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 7746 is [True, False, False, True, False, False]
Current timestep = 7747. State = [[-0.2821853  -0.14054134]]. Action = [[-0.08632669  0.0698567   0.          0.3937825 ]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 7747 is [True, False, False, True, False, False]
Current timestep = 7748. State = [[-0.2846081  -0.14073986]]. Action = [[ 0.01052868 -0.05914908  0.          0.48254144]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 7748 is [True, False, False, True, False, False]
State prediction error at timestep 7748 is 0.012
Human Feedback received at timestep 7748 of None
Current timestep = 7749. State = [[-0.28696287 -0.13950248]]. Action = [[-0.05128139  0.04817731  0.         -0.8804876 ]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 7749 is [True, False, False, True, False, False]
State prediction error at timestep 7749 is 0.012
Human Feedback received at timestep 7749 of None
Current timestep = 7750. State = [[-0.2841182  -0.14111553]]. Action = [[ 0.094472   -0.07585118  0.         -0.08380359]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 7750 is [True, False, False, True, False, False]
Current timestep = 7751. State = [[-0.27778038 -0.14223023]]. Action = [[0.06121754 0.01105802 0.         0.77571607]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 7751 is [True, False, False, True, False, False]
Current timestep = 7752. State = [[-0.27777278 -0.140276  ]]. Action = [[-0.05781012  0.0332798   0.         -0.44416845]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 7752 is [True, False, False, True, False, False]
Current timestep = 7753. State = [[-0.27582002 -0.14265339]]. Action = [[ 0.05901245 -0.06851602  0.         -0.7565087 ]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 7753 is [True, False, False, True, False, False]
Current timestep = 7754. State = [[-0.27600622 -0.14358392]]. Action = [[-0.06137896  0.02895098  0.         -0.9478002 ]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 7754 is [True, False, False, True, False, False]
State prediction error at timestep 7754 is 0.012
Human Feedback received at timestep 7754 of None
Current timestep = 7755. State = [[-0.27902785 -0.14091788]]. Action = [[-0.04360608  0.04774275  0.         -0.00274563]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 7755 is [True, False, False, True, False, False]
State prediction error at timestep 7755 is 0.012
Human Feedback received at timestep 7755 of None
Current timestep = 7756. State = [[-0.28319505 -0.14481075]]. Action = [[-0.06906451 -0.09984973  0.          0.5246395 ]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 7756 is [True, False, False, True, False, False]
Current timestep = 7757. State = [[-0.28060097 -0.14473313]]. Action = [[0.09504636 0.0792773  0.         0.16268945]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 7757 is [True, False, False, True, False, False]
Current timestep = 7758. State = [[-0.28191188 -0.14001146]]. Action = [[-0.08801056  0.04947146  0.         -0.5186803 ]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 7758 is [True, False, False, True, False, False]
Current timestep = 7759. State = [[-0.2849437  -0.13385199]]. Action = [[-0.01256232  0.08675178  0.         -0.7218136 ]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 7759 is [True, False, False, True, False, False]
State prediction error at timestep 7759 is 0.012
Human Feedback received at timestep 7759 of None
Current timestep = 7760. State = [[-0.2897376  -0.12987664]]. Action = [[-0.07930209  0.01402041  0.         -0.01358891]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 7760 is [True, False, False, True, False, False]
Current timestep = 7761. State = [[-0.29408237 -0.12888864]]. Action = [[-0.02964825 -0.00509933  0.          0.24020481]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 7761 is [True, False, False, True, False, False]
State prediction error at timestep 7761 is 0.012
Human Feedback received at timestep 7761 of None
Current timestep = 7762. State = [[-0.2942664  -0.12618934]]. Action = [[0.03168749 0.03787983 0.         0.8333881 ]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 7762 is [True, False, False, True, False, False]
Current timestep = 7763. State = [[-0.29352257 -0.12199488]]. Action = [[ 0.01616746  0.03606027  0.         -0.2626993 ]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 7763 is [True, False, False, True, False, False]
Current timestep = 7764. State = [[-0.29747286 -0.11976893]]. Action = [[-0.07141634 -0.0019461   0.          0.7616066 ]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 7764 is [True, False, False, False, True, False]
Current timestep = 7765. State = [[-0.300394   -0.12255286]]. Action = [[ 6.2786043e-04 -7.2653532e-02  0.0000000e+00 -6.9907254e-01]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 7765 is [True, False, False, False, True, False]
State prediction error at timestep 7765 is 0.012
Human Feedback received at timestep 7765 of None
Current timestep = 7766. State = [[-0.2970577  -0.12484204]]. Action = [[ 0.0859298  -0.01843027  0.          0.5022757 ]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 7766 is [True, False, False, False, True, False]
State prediction error at timestep 7766 is 0.012
Human Feedback received at timestep 7766 of None
Current timestep = 7767. State = [[-0.29659545 -0.129265  ]]. Action = [[-0.03073576 -0.08755059  0.         -0.515118  ]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 7767 is [True, False, False, False, True, False]
Current timestep = 7768. State = [[-0.30053723 -0.12960471]]. Action = [[-0.06231796  0.0502189   0.         -0.3741001 ]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 7768 is [True, False, False, True, False, False]
State prediction error at timestep 7768 is 0.012
Human Feedback received at timestep 7768 of None
Current timestep = 7769. State = [[-0.30340424 -0.12717964]]. Action = [[-0.01211368  0.02955761  0.          0.558313  ]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 7769 is [True, False, False, True, False, False]
Current timestep = 7770. State = [[-0.30238774 -0.1307617 ]]. Action = [[ 0.04193171 -0.08945527  0.          0.92150784]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 7770 is [True, False, False, True, False, False]
Current timestep = 7771. State = [[-0.29824832 -0.13739736]]. Action = [[ 0.0641643  -0.07742999  0.         -0.6751853 ]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 7771 is [True, False, False, True, False, False]
State prediction error at timestep 7771 is 0.012
Human Feedback received at timestep 7771 of None
Current timestep = 7772. State = [[-0.29533613 -0.1395859 ]]. Action = [[ 0.01749782  0.01500076  0.         -0.33232945]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 7772 is [True, False, False, True, False, False]
State prediction error at timestep 7772 is 0.012
Human Feedback received at timestep 7772 of None
Current timestep = 7773. State = [[-0.295381   -0.14278668]]. Action = [[-0.01585378 -0.05383937  0.         -0.48505914]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 7773 is [True, False, False, True, False, False]
Current timestep = 7774. State = [[-0.29534647 -0.14825837]]. Action = [[ 0.00595456 -0.05543827  0.         -0.4998436 ]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 7774 is [True, False, False, True, False, False]
Current timestep = 7775. State = [[-0.29343677 -0.14649785]]. Action = [[ 0.03180195  0.09408518  0.         -0.68436134]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 7775 is [True, False, False, True, False, False]
State prediction error at timestep 7775 is 0.012
Human Feedback received at timestep 7775 of None
Current timestep = 7776. State = [[-0.28868294 -0.14365347]]. Action = [[0.07740297 0.01593097 0.         0.41231203]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 7776 is [True, False, False, True, False, False]
State prediction error at timestep 7776 is 0.012
Human Feedback received at timestep 7776 of None
Current timestep = 7777. State = [[-0.29095745 -0.14434206]]. Action = [[-0.09417257 -0.01590215  0.         -0.2891348 ]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 7777 is [True, False, False, True, False, False]
Current timestep = 7778. State = [[-0.2966123  -0.14930491]]. Action = [[-0.05957086 -0.07234199  0.         -0.20314145]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 7778 is [True, False, False, True, False, False]
State prediction error at timestep 7778 is 0.012
Human Feedback received at timestep 7778 of None
Current timestep = 7779. State = [[-0.2982581 -0.1522896]]. Action = [[ 0.00707616  0.00243495  0.         -0.4385649 ]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 7779 is [True, False, False, True, False, False]
Current timestep = 7780. State = [[-0.29731032 -0.15035482]]. Action = [[ 0.0183681   0.05171975  0.         -0.45144963]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 7780 is [True, False, False, True, False, False]
Current timestep = 7781. State = [[-0.293177   -0.14400388]]. Action = [[0.0768132  0.09535971 0.         0.59631014]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 7781 is [True, False, False, True, False, False]
Current timestep = 7782. State = [[-0.29600722 -0.13933682]]. Action = [[-0.09626897  0.02446425  0.          0.87131953]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 7782 is [True, False, False, True, False, False]
Current timestep = 7783. State = [[-0.30048257 -0.13956387]]. Action = [[-0.02492598 -0.0271192   0.          0.4404037 ]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 7783 is [True, False, False, True, False, False]
State prediction error at timestep 7783 is 0.012
Human Feedback received at timestep 7783 of None
Current timestep = 7784. State = [[-0.2971643  -0.14007892]]. Action = [[ 0.0981015  -0.00751092  0.         -0.4521188 ]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 7784 is [True, False, False, True, False, False]
Current timestep = 7785. State = [[-0.29933628 -0.13960283]]. Action = [[-0.09702508  0.00413946  0.          0.20040977]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 7785 is [True, False, False, True, False, False]
Current timestep = 7786. State = [[-0.29970196 -0.13804948]]. Action = [[0.06260998 0.01646386 0.         0.91394854]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 7786 is [True, False, False, True, False, False]
Current timestep = 7787. State = [[-0.29900202 -0.13879699]]. Action = [[-0.00546235 -0.04181544  0.          0.26614714]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 7787 is [True, False, False, True, False, False]
State prediction error at timestep 7787 is 0.012
Human Feedback received at timestep 7787 of None
Current timestep = 7788. State = [[-0.3028548  -0.13873294]]. Action = [[-0.06715561  0.01806206  0.         -0.412185  ]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 7788 is [True, False, False, True, False, False]
State prediction error at timestep 7788 is 0.012
Human Feedback received at timestep 7788 of None
Current timestep = 7789. State = [[-0.30297175 -0.13410768]]. Action = [[ 0.04894479  0.07758086  0.         -0.911705  ]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 7789 is [True, False, False, True, False, False]
Current timestep = 7790. State = [[-0.30466828 -0.1265237 ]]. Action = [[-0.04639747  0.09147315  0.         -0.2674865 ]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 7790 is [True, False, False, True, False, False]
Current timestep = 7791. State = [[-0.30415708 -0.12477262]]. Action = [[ 0.05704883 -0.04367076  0.         -0.63149345]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 7791 is [True, False, False, True, False, False]
Current timestep = 7792. State = [[-0.30143306 -0.12186623]]. Action = [[0.03237887 0.0592583  0.         0.04068387]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 7792 is [True, False, False, False, True, False]
State prediction error at timestep 7792 is 0.012
Human Feedback received at timestep 7792 of None
Current timestep = 7793. State = [[-0.2981919  -0.11950458]]. Action = [[ 0.05221442 -0.00971859  0.          0.08289909]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 7793 is [True, False, False, False, True, False]
Current timestep = 7794. State = [[-0.29386595 -0.12259357]]. Action = [[ 0.05872815 -0.08064151  0.         -0.17621368]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 7794 is [True, False, False, False, True, False]
Current timestep = 7795. State = [[-0.293898   -0.12617561]]. Action = [[-0.04440445 -0.0342397   0.          0.12124622]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 7795 is [True, False, False, False, True, False]
Current timestep = 7796. State = [[-0.29626876 -0.12797885]]. Action = [[-0.03257797 -0.01214369  0.         -0.22017926]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 7796 is [True, False, False, True, False, False]
State prediction error at timestep 7796 is 0.012
Human Feedback received at timestep 7796 of None
Current timestep = 7797. State = [[-0.29944327 -0.12843987]]. Action = [[-0.05457834  0.00662909  0.         -0.8678467 ]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 7797 is [True, False, False, True, False, False]
Current timestep = 7798. State = [[-0.30119866 -0.12980695]]. Action = [[-0.01296175 -0.02102503  0.         -0.66427815]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 7798 is [True, False, False, True, False, False]
Current timestep = 7799. State = [[-0.3036387  -0.13202736]]. Action = [[-0.04960037 -0.02133327  0.          0.39565516]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 7799 is [True, False, False, True, False, False]
Current timestep = 7800. State = [[-0.30410728 -0.1345007 ]]. Action = [[ 0.0118442  -0.02311124  0.          0.8882545 ]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 7800 is [True, False, False, True, False, False]
Current timestep = 7801. State = [[-0.30601138 -0.1382146 ]]. Action = [[-0.05091275 -0.04592823  0.          0.40888286]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 7801 is [True, False, False, True, False, False]
Current timestep = 7802. State = [[-0.30917394 -0.13889748]]. Action = [[-0.039428    0.03326703  0.          0.73598886]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 7802 is [True, False, False, True, False, False]
Current timestep = 7803. State = [[-0.31384414 -0.13498749]]. Action = [[-0.06880609  0.07788553  0.          0.8517195 ]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 7803 is [True, False, False, True, False, False]
Current timestep = 7804. State = [[-0.32118    -0.13591209]]. Action = [[-0.09819146 -0.05298913  0.         -0.5640774 ]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 7804 is [True, False, False, True, False, False]
Current timestep = 7805. State = [[-0.32220832 -0.1400936 ]]. Action = [[ 0.05626269 -0.04742716  0.          0.73435664]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 7805 is [True, False, False, True, False, False]
Current timestep = 7806. State = [[-0.3189587  -0.13891396]]. Action = [[0.04850178 0.05314177 0.         0.00169575]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 7806 is [True, False, False, True, False, False]
Current timestep = 7807. State = [[-0.32275406 -0.13502392]]. Action = [[-0.09551343  0.04706082  0.          0.01028168]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 7807 is [True, False, False, True, False, False]
Current timestep = 7808. State = [[-0.33019564 -0.13604243]]. Action = [[-0.07443222 -0.04781387  0.          0.55816185]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 7808 is [True, False, False, True, False, False]
Current timestep = 7809. State = [[-0.3296187  -0.14129223]]. Action = [[ 0.08849668 -0.08309782  0.          0.04468453]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 7809 is [True, False, False, True, False, False]
Current timestep = 7810. State = [[-0.32382515 -0.14400992]]. Action = [[ 0.08157142 -0.00998316  0.          0.9959421 ]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 7810 is [True, False, False, True, False, False]
Current timestep = 7811. State = [[-0.32327726 -0.13958111]]. Action = [[-0.03849738  0.09937312  0.         -0.11178726]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 7811 is [True, False, False, True, False, False]
Current timestep = 7812. State = [[-0.32807863 -0.13262242]]. Action = [[-0.05660631  0.07886957  0.          0.24078143]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 7812 is [True, False, False, True, False, False]
Current timestep = 7813. State = [[-0.3350246  -0.13117184]]. Action = [[-0.07686982 -0.02624393  0.         -0.5178243 ]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 7813 is [True, False, False, True, False, False]
Current timestep = 7814. State = [[-0.34212282 -0.13164155]]. Action = [[-0.0646205  -0.00042381  0.          0.34649754]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 7814 is [True, False, False, True, False, False]
Current timestep = 7815. State = [[-0.3409388 -0.1281496]]. Action = [[ 0.0964848   0.06206781  0.         -0.8242172 ]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 7815 is [True, False, False, True, False, False]
State prediction error at timestep 7815 is 0.012
Human Feedback received at timestep 7815 of None
Current timestep = 7816. State = [[-0.33795413 -0.1262033 ]]. Action = [[ 0.03010777 -0.02542143  0.          0.32539952]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 7816 is [True, False, False, True, False, False]
Current timestep = 7817. State = [[-0.33437353 -0.12646419]]. Action = [[ 0.07205307 -0.01876023  0.         -0.910083  ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 7817 is [True, False, False, True, False, False]
Current timestep = 7818. State = [[-0.33072552 -0.1255982 ]]. Action = [[ 0.04554728  0.00477085  0.         -0.87627256]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 7818 is [True, False, False, True, False, False]
State prediction error at timestep 7818 is 0.012
Human Feedback received at timestep 7818 of None
Current timestep = 7819. State = [[-0.33217958 -0.12024721]]. Action = [[-0.04810071  0.09064475  0.         -0.6888112 ]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 7819 is [True, False, False, True, False, False]
Current timestep = 7820. State = [[-0.33263618 -0.11934741]]. Action = [[ 0.03953048 -0.05374923  0.          0.39046788]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 7820 is [True, False, False, False, True, False]
Current timestep = 7821. State = [[-0.33328018 -0.12382986]]. Action = [[-0.02614748 -0.07166687  0.         -0.7182832 ]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 7821 is [True, False, False, False, True, False]
Current timestep = 7822. State = [[-0.33445483 -0.1295322 ]]. Action = [[-0.00886164 -0.06887438  0.         -0.7971922 ]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 7822 is [True, False, False, False, True, False]
Current timestep = 7823. State = [[-0.33427596 -0.13127951]]. Action = [[ 0.0040336   0.0167314   0.         -0.26620066]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 7823 is [True, False, False, True, False, False]
Current timestep = 7824. State = [[-0.3384647  -0.12791419]]. Action = [[-0.09610856  0.07491111  0.          0.88268673]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 7824 is [True, False, False, True, False, False]
Current timestep = 7825. State = [[-0.33844015 -0.12535919]]. Action = [[ 0.06122836  0.01097973  0.         -0.71662253]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 7825 is [True, False, False, True, False, False]
State prediction error at timestep 7825 is 0.012
Human Feedback received at timestep 7825 of None
Current timestep = 7826. State = [[-0.3390946  -0.12617674]]. Action = [[-0.05304971 -0.02192067  0.          0.2867552 ]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 7826 is [True, False, False, True, False, False]
Current timestep = 7827. State = [[-0.33895954 -0.12241112]]. Action = [[0.02589417 0.09445383 0.         0.44698226]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 7827 is [True, False, False, True, False, False]
Current timestep = 7828. State = [[-0.33628014 -0.11792694]]. Action = [[0.03839549 0.02619352 0.         0.86291313]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 7828 is [True, False, False, False, True, False]
State prediction error at timestep 7828 is 0.012
Human Feedback received at timestep 7828 of None
Current timestep = 7829. State = [[-0.33904928 -0.11963423]]. Action = [[-0.08048322 -0.06716583  0.          0.05986893]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 7829 is [True, False, False, False, True, False]
State prediction error at timestep 7829 is 0.012
Human Feedback received at timestep 7829 of None
Current timestep = 7830. State = [[-0.33707556 -0.12389935]]. Action = [[ 0.0900879  -0.05079817  0.          0.36028934]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 7830 is [True, False, False, False, True, False]
State prediction error at timestep 7830 is 0.012
Human Feedback received at timestep 7830 of None
Current timestep = 7831. State = [[-0.33249345 -0.12071302]]. Action = [[0.03717866 0.08896088 0.         0.9805238 ]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 7831 is [True, False, False, False, True, False]
Current timestep = 7832. State = [[-0.33277392 -0.12160837]]. Action = [[-0.03762062 -0.08914599  0.         -0.76405466]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 7832 is [True, False, False, False, True, False]
Current timestep = 7833. State = [[-0.3311725 -0.1223892]]. Action = [[ 0.05127508  0.03251543  0.         -0.03563797]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 7833 is [True, False, False, False, True, False]
Current timestep = 7834. State = [[-0.33426693 -0.12090962]]. Action = [[-0.0950786   0.01439341  0.         -0.650465  ]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 7834 is [True, False, False, False, True, False]
Current timestep = 7835. State = [[-0.333175 -0.120763]]. Action = [[ 0.08127459 -0.00734662  0.         -0.47766215]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 7835 is [True, False, False, False, True, False]
Current timestep = 7836. State = [[-0.32921126 -0.12338404]]. Action = [[ 0.02881778 -0.05161365  0.          0.33143055]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 7836 is [True, False, False, False, True, False]
Current timestep = 7837. State = [[-0.33192056 -0.12158535]]. Action = [[-0.09085341  0.07725766  0.          0.03123045]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 7837 is [True, False, False, False, True, False]
Current timestep = 7838. State = [[-0.3374766  -0.11820936]]. Action = [[-0.05595172  0.02831698  0.          0.2766763 ]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 7838 is [True, False, False, False, True, False]
Current timestep = 7839. State = [[-0.3434049  -0.11391438]]. Action = [[-0.07187964  0.06626759  0.         -0.84396935]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 7839 is [True, False, False, False, True, False]
Current timestep = 7840. State = [[-0.3423991  -0.11419751]]. Action = [[ 0.09250494 -0.06453668  0.         -0.59527016]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 7840 is [True, False, False, False, True, False]
Current timestep = 7841. State = [[-0.3353971  -0.11189653]]. Action = [[0.09176815 0.06517019 0.         0.68705475]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 7841 is [True, False, False, False, True, False]
Current timestep = 7842. State = [[-0.33268473 -0.11231488]]. Action = [[-0.00768626 -0.06684856  0.          0.13557851]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 7842 is [True, False, False, False, True, False]
Current timestep = 7843. State = [[-0.32908976 -0.11056217]]. Action = [[0.06970324 0.06356698 0.         0.13382602]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 7843 is [True, False, False, False, True, False]
State prediction error at timestep 7843 is 0.012
Human Feedback received at timestep 7843 of None
Current timestep = 7844. State = [[-0.32634118 -0.11227345]]. Action = [[ 0.00856289 -0.08398907  0.         -0.21377295]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 7844 is [True, False, False, False, True, False]
Current timestep = 7845. State = [[-0.3220886  -0.11035494]]. Action = [[ 0.07167242  0.0840176   0.         -0.22776395]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 7845 is [True, False, False, False, True, False]
Current timestep = 7846. State = [[-0.3155543  -0.10358056]]. Action = [[0.0844821  0.0745137  0.         0.20583105]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 7846 is [True, False, False, False, True, False]
State prediction error at timestep 7846 is 0.012
Human Feedback received at timestep 7846 of None
Current timestep = 7847. State = [[-0.30973566 -0.10118453]]. Action = [[ 0.06198692 -0.01961301  0.          0.07124937]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 7847 is [True, False, False, False, True, False]
Current timestep = 7848. State = [[-0.31120864 -0.09811512]]. Action = [[-0.08252032  0.05995481  0.         -0.7334177 ]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 7848 is [True, False, False, False, True, False]
Current timestep = 7849. State = [[-0.31712154 -0.10003516]]. Action = [[-0.07584566 -0.08330683  0.         -0.12743908]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 7849 is [True, False, False, False, True, False]
Current timestep = 7850. State = [[-0.319833   -0.10052292]]. Action = [[-0.01178323  0.03183002  0.          0.07553995]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 7850 is [True, False, False, False, True, False]
State prediction error at timestep 7850 is 0.012
Human Feedback received at timestep 7850 of None
Current timestep = 7851. State = [[-0.31762797 -0.09585679]]. Action = [[ 0.05234598  0.06553093  0.         -0.7025221 ]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 7851 is [True, False, False, False, True, False]
Current timestep = 7852. State = [[-0.32011372 -0.09553103]]. Action = [[-0.0838489  -0.05330526  0.          0.40549946]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 7852 is [True, False, False, False, True, False]
Current timestep = 7853. State = [[-0.31792223 -0.09625987]]. Action = [[ 0.09020974  0.00450166  0.         -0.58034414]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 7853 is [True, False, False, False, True, False]
Current timestep = 7854. State = [[-0.3138242  -0.09298453]]. Action = [[0.02942825 0.05054796 0.         0.20674491]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 7854 is [True, False, False, False, True, False]
Current timestep = 7855. State = [[-0.3170293  -0.09070098]]. Action = [[-0.09058671  0.00590678  0.         -0.66711646]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 7855 is [True, False, False, False, True, False]
Current timestep = 7856. State = [[-0.3208473  -0.08668566]]. Action = [[-0.02905163  0.07034754  0.          0.25955272]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 7856 is [True, False, False, False, True, False]
Current timestep = 7857. State = [[-0.31935006 -0.08708537]]. Action = [[ 0.0560722  -0.06364092  0.         -0.922752  ]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 7857 is [True, False, False, False, True, False]
State prediction error at timestep 7857 is 0.012
Human Feedback received at timestep 7857 of None
Current timestep = 7858. State = [[-0.31435505 -0.0857886 ]]. Action = [[0.06814017 0.0469924  0.         0.7476125 ]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 7858 is [True, False, False, False, True, False]
Current timestep = 7859. State = [[-0.31513238 -0.08243676]]. Action = [[-0.06087892  0.02833176  0.          0.03127789]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 7859 is [True, False, False, False, True, False]
State prediction error at timestep 7859 is 0.012
Human Feedback received at timestep 7859 of None
Current timestep = 7860. State = [[-0.31409213 -0.08352803]]. Action = [[ 0.05454937 -0.05126372  0.         -0.7979916 ]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 7860 is [True, False, False, False, True, False]
State prediction error at timestep 7860 is 0.012
Human Feedback received at timestep 7860 of None
Current timestep = 7861. State = [[-0.31563044 -0.08061698]]. Action = [[-0.07221188  0.08259515  0.         -0.7426635 ]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 7861 is [True, False, False, False, True, False]
Current timestep = 7862. State = [[-0.3214529 -0.0811869]]. Action = [[-0.07640731 -0.06593112  0.         -0.2905289 ]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 7862 is [True, False, False, False, True, False]
State prediction error at timestep 7862 is 0.012
Human Feedback received at timestep 7862 of None
Current timestep = 7863. State = [[-0.31988406 -0.0836919 ]]. Action = [[ 0.08493607 -0.0202392   0.         -0.87576437]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 7863 is [True, False, False, False, True, False]
State prediction error at timestep 7863 is 0.012
Human Feedback received at timestep 7863 of None
Current timestep = 7864. State = [[-0.31951654 -0.08347181]]. Action = [[-0.04102109  0.0135422   0.         -0.7629075 ]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 7864 is [True, False, False, False, True, False]
State prediction error at timestep 7864 is 0.012
Human Feedback received at timestep 7864 of None
Current timestep = 7865. State = [[-0.3218328  -0.08111483]]. Action = [[-0.0245373   0.03779656  0.         -0.55273104]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 7865 is [True, False, False, False, True, False]
Current timestep = 7866. State = [[-0.3243513  -0.07771774]]. Action = [[-0.02975711  0.04126068  0.         -0.6265307 ]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 7866 is [True, False, False, False, True, False]
Current timestep = 7867. State = [[-0.32367212 -0.07268255]]. Action = [[ 0.04342099  0.06494265  0.         -0.06008422]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 7867 is [True, False, False, False, True, False]
Current timestep = 7868. State = [[-0.32693464 -0.07179353]]. Action = [[-0.07701854 -0.03781189  0.          0.05499172]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 7868 is [True, False, False, False, True, False]
State prediction error at timestep 7868 is 0.012
Human Feedback received at timestep 7868 of None
Current timestep = 7869. State = [[-0.32552904 -0.07041339]]. Action = [[ 0.08727279  0.0351254   0.         -0.10682422]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 7869 is [True, False, False, False, True, False]
State prediction error at timestep 7869 is 0.012
Human Feedback received at timestep 7869 of None
Current timestep = 7870. State = [[-0.31917527 -0.06982253]]. Action = [[ 0.09591734 -0.02739754  0.          0.7476711 ]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 7870 is [True, False, False, False, True, False]
Current timestep = 7871. State = [[-0.31874496 -0.07177043]]. Action = [[-0.04728895 -0.0365316   0.         -0.08721542]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 7871 is [True, False, False, False, True, False]
Current timestep = 7872. State = [[-0.32012168 -0.0745535 ]]. Action = [[-0.00177424 -0.0372906   0.         -0.3252262 ]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 7872 is [True, False, False, False, True, False]
Current timestep = 7873. State = [[-0.32357937 -0.07866278]]. Action = [[-0.07125787 -0.05586602  0.         -0.07197285]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 7873 is [True, False, False, False, True, False]
State prediction error at timestep 7873 is 0.012
Human Feedback received at timestep 7873 of None
Current timestep = 7874. State = [[-0.32066348 -0.07875974]]. Action = [[0.09936356 0.04010891 0.         0.45568383]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 7874 is [True, False, False, False, True, False]
State prediction error at timestep 7874 is 0.012
Human Feedback received at timestep 7874 of None
Current timestep = 7875. State = [[-0.31595817 -0.07626895]]. Action = [[0.03693957 0.02836639 0.         0.72452307]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 7875 is [True, False, False, False, True, False]
State prediction error at timestep 7875 is 0.012
Human Feedback received at timestep 7875 of None
Current timestep = 7876. State = [[-0.31193554 -0.07910787]]. Action = [[ 0.05126006 -0.07379557  0.         -0.06314027]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 7876 is [True, False, False, False, True, False]
Current timestep = 7877. State = [[-0.31190243 -0.08043788]]. Action = [[-0.04430557  0.0249102   0.          0.58956003]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 7877 is [True, False, False, False, True, False]
Current timestep = 7878. State = [[-0.3148585  -0.08458196]]. Action = [[-0.04707412 -0.08249972  0.         -0.87809086]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 7878 is [True, False, False, False, True, False]
Current timestep = 7879. State = [[-0.31711385 -0.08725443]]. Action = [[-0.02957411  0.01170047  0.          0.49216366]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 7879 is [True, False, False, False, True, False]
Current timestep = 7880. State = [[-0.31677786 -0.08800526]]. Action = [[ 0.01650484 -0.00334959  0.         -0.09851038]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 7880 is [True, False, False, False, True, False]
Current timestep = 7881. State = [[-0.3179195 -0.0866214]]. Action = [[-0.03742832  0.04183125  0.         -0.29868388]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 7881 is [True, False, False, False, True, False]
State prediction error at timestep 7881 is 0.012
Human Feedback received at timestep 7881 of None
Current timestep = 7882. State = [[-0.31564042 -0.08730567]]. Action = [[ 0.06893375 -0.03191859  0.          0.6905322 ]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 7882 is [True, False, False, False, True, False]
Current timestep = 7883. State = [[-0.31709677 -0.0920831 ]]. Action = [[-0.07498239 -0.06956192  0.         -0.8990841 ]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 7883 is [True, False, False, False, True, False]
Current timestep = 7884. State = [[-0.31493375 -0.09755477]]. Action = [[ 0.08104252 -0.05441587  0.         -0.5892143 ]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 7884 is [True, False, False, False, True, False]
State prediction error at timestep 7884 is 0.012
Human Feedback received at timestep 7884 of None
Current timestep = 7885. State = [[-0.3116613  -0.09506553]]. Action = [[0.01263207 0.09760156 0.         0.45620298]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 7885 is [True, False, False, False, True, False]
Current timestep = 7886. State = [[-0.3105022 -0.0934291]]. Action = [[ 0.01269405 -0.01603666  0.          0.80226946]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 7886 is [True, False, False, False, True, False]
Current timestep = 7887. State = [[-0.3093477  -0.09558522]]. Action = [[ 0.01486327 -0.03096616  0.          0.26078534]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 7887 is [True, False, False, False, True, False]
Current timestep = 7888. State = [[-0.31252792 -0.09865063]]. Action = [[-0.07791424 -0.03236081  0.         -0.13372648]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 7888 is [True, False, False, False, True, False]
Current timestep = 7889. State = [[-0.310438   -0.10378256]]. Action = [[ 0.08746444 -0.07176234  0.          0.8055997 ]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 7889 is [True, False, False, False, True, False]
Current timestep = 7890. State = [[-0.3098426  -0.11036329]]. Action = [[-0.05216277 -0.07029472  0.         -0.38259172]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 7890 is [True, False, False, False, True, False]
Current timestep = 7891. State = [[-0.31179735 -0.1152442 ]]. Action = [[-0.02970161 -0.02715463  0.          0.00100815]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 7891 is [True, False, False, False, True, False]
State prediction error at timestep 7891 is 0.012
Human Feedback received at timestep 7891 of None
Current timestep = 7892. State = [[-0.31028646 -0.11363409]]. Action = [[0.03526121 0.07755636 0.         0.26963735]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 7892 is [True, False, False, False, True, False]
Current timestep = 7893. State = [[-0.30467293 -0.11046468]]. Action = [[0.08844221 0.03026495 0.         0.5389762 ]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 7893 is [True, False, False, False, True, False]
Current timestep = 7894. State = [[-0.3056538  -0.11349457]]. Action = [[-0.08030073 -0.08422188  0.         -0.83256847]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 7894 is [True, False, False, False, True, False]
Current timestep = 7895. State = [[-0.30713645 -0.11233845]]. Action = [[0.01269583 0.09030022 0.         0.06822813]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 7895 is [True, False, False, False, True, False]
Current timestep = 7896. State = [[-0.30729216 -0.10962209]]. Action = [[-0.00513259  0.01002394  0.          0.7373607 ]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 7896 is [True, False, False, False, True, False]
Current timestep = 7897. State = [[-0.3030133  -0.11206511]]. Action = [[ 0.09548812 -0.06065278  0.         -0.49611902]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 7897 is [True, False, False, False, True, False]
State prediction error at timestep 7897 is 0.012
Human Feedback received at timestep 7897 of None
Current timestep = 7898. State = [[-0.30144826 -0.11753549]]. Action = [[-0.02674419 -0.07383839  0.         -0.46119875]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 7898 is [True, False, False, False, True, False]
Current timestep = 7899. State = [[-0.30199143 -0.12508532]]. Action = [[-0.00778864 -0.09376863  0.         -0.630576  ]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 7899 is [True, False, False, False, True, False]
Current timestep = 7900. State = [[-0.30111915 -0.1250296 ]]. Action = [[0.01222118 0.07805737 0.         0.40446997]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 7900 is [True, False, False, True, False, False]
Current timestep = 7901. State = [[-0.30305895 -0.12428543]]. Action = [[-0.05459477 -0.01139138  0.         -0.5355111 ]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 7901 is [True, False, False, True, False, False]
Current timestep = 7902. State = [[-0.30583322 -0.12616351]]. Action = [[-0.03147467 -0.0156672   0.          0.8408594 ]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 7902 is [True, False, False, False, True, False]
Current timestep = 7903. State = [[-0.3115268 -0.1242656]]. Action = [[-0.09973081  0.0657252   0.          0.40668106]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 7903 is [True, False, False, True, False, False]
Current timestep = 7904. State = [[-0.31113732 -0.12727536]]. Action = [[ 0.08556902 -0.09836735  0.          0.73687077]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 7904 is [True, False, False, False, True, False]
State prediction error at timestep 7904 is 0.012
Human Feedback received at timestep 7904 of None
Current timestep = 7905. State = [[-0.3033613  -0.12909162]]. Action = [[ 0.09727708  0.02864509  0.         -0.4448291 ]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 7905 is [True, False, False, True, False, False]
State prediction error at timestep 7905 is 0.012
Human Feedback received at timestep 7905 of None
Current timestep = 7906. State = [[-0.30382317 -0.13000268]]. Action = [[-0.09225903 -0.02078401  0.          0.63773584]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 7906 is [True, False, False, True, False, False]
Current timestep = 7907. State = [[-0.30496022 -0.13570508]]. Action = [[ 0.0141726  -0.08549159  0.         -0.20251513]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 7907 is [True, False, False, True, False, False]
State prediction error at timestep 7907 is 0.012
Human Feedback received at timestep 7907 of None
Current timestep = 7908. State = [[-0.30156207 -0.13446967]]. Action = [[0.05192309 0.09470364 0.         0.8306308 ]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 7908 is [True, False, False, True, False, False]
State prediction error at timestep 7908 is 0.012
Human Feedback received at timestep 7908 of None
Current timestep = 7909. State = [[-0.29969376 -0.13591003]]. Action = [[-0.00470021 -0.0785746   0.          0.22137225]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 7909 is [True, False, False, True, False, False]
State prediction error at timestep 7909 is 0.012
Human Feedback received at timestep 7909 of None
Current timestep = 7910. State = [[-0.3039599  -0.14271827]]. Action = [[-0.09604185 -0.07832263  0.          0.27072918]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 7910 is [True, False, False, True, False, False]
Current timestep = 7911. State = [[-0.30369565 -0.14588404]]. Action = [[ 0.05354322  0.00765346  0.         -0.31421983]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 7911 is [True, False, False, True, False, False]
Current timestep = 7912. State = [[-0.30256715 -0.14528961]]. Action = [[-0.01311817  0.02571047  0.         -0.41776448]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 7912 is [True, False, False, True, False, False]
Current timestep = 7913. State = [[-0.2989413  -0.14982435]]. Action = [[ 0.07736304 -0.09705242  0.         -0.12084371]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 7913 is [True, False, False, True, False, False]
Current timestep = 7914. State = [[-0.29202208 -0.15226221]]. Action = [[ 0.08355539  0.01853962  0.         -0.19592488]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 7914 is [True, False, False, True, False, False]
Current timestep = 7915. State = [[-0.2928212  -0.15407851]]. Action = [[-0.08190719 -0.02877291  0.          0.1026845 ]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 7915 is [True, False, False, True, False, False]
Current timestep = 7916. State = [[-0.2950634  -0.15692602]]. Action = [[-0.00934023 -0.01599372  0.         -0.86933273]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 7916 is [True, False, False, True, False, False]
Current timestep = 7917. State = [[-0.29739037 -0.15971212]]. Action = [[-0.04567112 -0.02131494  0.         -0.2495181 ]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 7917 is [True, False, False, True, False, False]
Current timestep = 7918. State = [[-0.29608274 -0.16428964]]. Action = [[ 0.0482812  -0.05676513  0.          0.9997511 ]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 7918 is [True, False, False, True, False, False]
Current timestep = 7919. State = [[-0.29910353 -0.17134026]]. Action = [[-0.09620897 -0.08379136  0.         -0.59592754]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 7919 is [True, False, False, True, False, False]
Current timestep = 7920. State = [[-0.30594906 -0.17893848]]. Action = [[-0.08958031 -0.0665521   0.         -0.92428416]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 7920 is [True, False, False, True, False, False]
Current timestep = 7921. State = [[-0.31005335 -0.17849924]]. Action = [[-0.02883495  0.09039252  0.         -0.72251695]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 7921 is [True, False, False, True, False, False]
State prediction error at timestep 7921 is 0.012
Human Feedback received at timestep 7921 of None
Current timestep = 7922. State = [[-0.3112116  -0.17735377]]. Action = [[-1.8557906e-04  3.8834661e-04  0.0000000e+00  6.8625438e-01]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 7922 is [True, False, False, True, False, False]
Current timestep = 7923. State = [[-0.31606138 -0.17903708]]. Action = [[-0.08911384 -0.01619149  0.          0.29695225]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 7923 is [True, False, False, True, False, False]
Current timestep = 7924. State = [[-0.31684867 -0.17932683]]. Action = [[0.04929831 0.02116935 0.         0.6370723 ]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 7924 is [True, False, False, True, False, False]
Current timestep = 7925. State = [[-0.31861773 -0.1799284 ]]. Action = [[-0.0482618  -0.01779103  0.         -0.91262233]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 7925 is [True, False, False, True, False, False]
State prediction error at timestep 7925 is 0.012
Human Feedback received at timestep 7925 of None
Current timestep = 7926. State = [[-0.3186845  -0.18014431]]. Action = [[ 0.04153662  0.01025672  0.         -0.6335946 ]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 7926 is [True, False, False, True, False, False]
Current timestep = 7927. State = [[-0.32021567 -0.18395635]]. Action = [[-0.03807921 -0.08254461  0.          0.476938  ]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 7927 is [True, False, False, True, False, False]
Current timestep = 7928. State = [[-0.32408676 -0.18440606]]. Action = [[-0.0402876   0.04677249  0.         -0.80231166]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 7928 is [True, False, False, True, False, False]
Current timestep = 7929. State = [[-0.32506385 -0.18433718]]. Action = [[ 0.0247101  -0.02000026  0.          0.9988644 ]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 7929 is [True, False, False, True, False, False]
Current timestep = 7930. State = [[-0.3272552  -0.18657331]]. Action = [[-0.04058993 -0.03347248  0.          0.15150619]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 7930 is [True, False, False, True, False, False]
Current timestep = 7931. State = [[-0.3268898  -0.18893176]]. Action = [[ 0.04595656 -0.02364213  0.         -0.73911387]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 7931 is [True, False, False, True, False, False]
Current timestep = 7932. State = [[-0.3284251  -0.18662609]]. Action = [[-0.04638097  0.06614172  0.          0.716815  ]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 7932 is [True, False, False, True, False, False]
Current timestep = 7933. State = [[-0.33518496 -0.1896608 ]]. Action = [[-0.09214117 -0.09950572  0.          0.01529467]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 7933 is [True, False, False, True, False, False]
Current timestep = 7934. State = [[-0.34161812 -0.19757964]]. Action = [[-0.04821469 -0.09412913  0.         -0.21913224]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 7934 is [True, False, False, True, False, False]
Current timestep = 7935. State = [[-0.34015745 -0.20003338]]. Action = [[0.08325725 0.02545688 0.         0.19571376]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 7935 is [True, False, False, True, False, False]
Current timestep = 7936. State = [[-0.33456823 -0.19876845]]. Action = [[0.06865831 0.01535398 0.         0.88429344]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 7936 is [True, False, False, True, False, False]
Current timestep = 7937. State = [[-0.3354003  -0.19468102]]. Action = [[-0.05823777  0.07668992  0.         -0.94868433]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 7937 is [True, False, False, True, False, False]
State prediction error at timestep 7937 is 0.012
Human Feedback received at timestep 7937 of None
Current timestep = 7938. State = [[-0.33394614 -0.18961881]]. Action = [[0.07552036 0.05495813 0.         0.10592294]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 7938 is [True, False, False, True, False, False]
State prediction error at timestep 7938 is 0.012
Human Feedback received at timestep 7938 of None
Current timestep = 7939. State = [[-0.32740724 -0.18938085]]. Action = [[ 0.0989928  -0.05144655  0.          0.46211243]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 7939 is [True, False, False, True, False, False]
Current timestep = 7940. State = [[-0.32062522 -0.18968138]]. Action = [[ 0.07787917 -0.00237238  0.          0.9826324 ]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 7940 is [True, False, False, True, False, False]
Current timestep = 7941. State = [[-0.16021682  0.09628181]]. Action = [[ 0.03760877 -0.01498739  0.         -0.04813564]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 7941 is [True, False, False, True, False, False]
Current timestep = 7942. State = [[-0.15780284  0.09239402]]. Action = [[0.00655278 0.01288042 0.         0.48008084]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 7942 is [True, False, False, False, True, False]
Current timestep = 7943. State = [[-0.15540102  0.09105966]]. Action = [[ 0.01359816  0.00292401  0.         -0.52712804]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 7943 is [True, False, False, False, True, False]
Current timestep = 7944. State = [[-0.15429501  0.09295963]]. Action = [[-0.00500809  0.06885763  0.          0.8751565 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 7944 is [True, False, False, False, True, False]
Current timestep = 7945. State = [[-0.15147588  0.089564  ]]. Action = [[ 0.05010397 -0.08091757  0.         -0.29832602]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 7945 is [True, False, False, False, True, False]
Current timestep = 7946. State = [[-0.14924887  0.0896323 ]]. Action = [[0.00949596 0.07645719 0.         0.18461609]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 7946 is [True, False, False, False, True, False]
Current timestep = 7947. State = [[-0.15085146  0.0912384 ]]. Action = [[-0.03939696  0.00985281  0.         -0.3360117 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 7947 is [True, False, False, False, True, False]
Current timestep = 7948. State = [[-0.15207964  0.09458201]]. Action = [[ 0.00206294  0.06914818  0.         -0.66686374]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 7948 is [True, False, False, False, True, False]
Current timestep = 7949. State = [[-0.1517407   0.09196834]]. Action = [[ 0.01510377 -0.08923656  0.          0.3275274 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7949 is [True, False, False, False, True, False]
Current timestep = 7950. State = [[-0.15498297  0.08540449]]. Action = [[-0.07807896 -0.07952098  0.          0.2863319 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 7950 is [True, False, False, False, True, False]
Current timestep = 7951. State = [[-0.16067426  0.0805928 ]]. Action = [[-0.07966395 -0.04719553  0.          0.554966  ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 7951 is [True, False, False, False, True, False]
State prediction error at timestep 7951 is 0.012
Human Feedback received at timestep 7951 of None
Current timestep = 7952. State = [[-0.16083919  0.08213063]]. Action = [[ 0.05403041  0.06690206  0.         -0.69031215]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 7952 is [True, False, False, False, True, False]
Current timestep = 7953. State = [[-0.1576084   0.08359249]]. Action = [[ 4.6269618e-02 -3.8536638e-04  0.0000000e+00  6.2680602e-01]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 7953 is [True, False, False, False, True, False]
Current timestep = 7954. State = [[-0.154753    0.08152936]]. Action = [[ 0.03580499 -0.03401863  0.         -0.23145795]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 7954 is [True, False, False, False, True, False]
Current timestep = 7955. State = [[-0.15375483  0.0799542 ]]. Action = [[-7.9170614e-04 -7.0237368e-04  0.0000000e+00 -8.9981824e-01]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 7955 is [True, False, False, False, True, False]
Current timestep = 7956. State = [[-0.15090205  0.07630307]]. Action = [[ 0.05571271 -0.05996151  0.         -0.9644026 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 7956 is [True, False, False, False, True, False]
Current timestep = 7957. State = [[-0.14690238  0.07064409]]. Action = [[ 0.0424213  -0.05965466  0.          0.3750553 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 7957 is [True, False, False, False, True, False]
Current timestep = 7958. State = [[-0.14303122  0.06824161]]. Action = [[ 0.04174911  0.01275997  0.         -0.25103402]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 7958 is [True, False, False, False, True, False]
Current timestep = 7959. State = [[-0.13884461  0.06423559]]. Action = [[ 0.04710367 -0.05941582  0.          0.41590595]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 7959 is [True, False, False, False, True, False]
State prediction error at timestep 7959 is 0.012
Human Feedback received at timestep 7959 of None
Current timestep = 7960. State = [[-0.13309108  0.06296559]]. Action = [[0.07336923 0.03922426 0.         0.9808214 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 7960 is [True, False, False, False, True, False]
Current timestep = 7961. State = [[-0.12620892  0.06608231]]. Action = [[0.08627815 0.07246677 0.         0.34042573]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 7961 is [True, False, False, False, True, False]
Current timestep = 7962. State = [[-0.12276495  0.06437908]]. Action = [[ 0.00394641 -0.05386355  0.         -0.58903974]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 7962 is [True, False, False, False, True, False]
Current timestep = 7963. State = [[-0.12318022  0.06602135]]. Action = [[-0.03441602  0.07784113  0.         -0.47294724]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 7963 is [True, False, False, False, True, False]
Current timestep = 7964. State = [[-0.12138467  0.06540748]]. Action = [[ 0.03767293 -0.050542    0.          0.70460093]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 7964 is [True, False, False, False, True, False]
Current timestep = 7965. State = [[-0.12000376  0.06480454]]. Action = [[-0.01328826  0.0190958   0.          0.16484475]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 7965 is [True, False, False, False, True, False]
Current timestep = 7966. State = [[-0.11592685  0.0681567 ]]. Action = [[ 0.07359763  0.05880304  0.         -0.18512487]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 7966 is [True, False, False, False, True, False]
Current timestep = 7967. State = [[-0.10939959  0.06989553]]. Action = [[0.0791707  0.00072466 0.         0.2937249 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 7967 is [True, False, False, False, True, False]
Current timestep = 7968. State = [[-0.10574758  0.07185768]]. Action = [[0.01022498 0.03654063 0.         0.40336895]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 7968 is [True, False, False, False, True, False]
Current timestep = 7969. State = [[-0.10208303  0.07332514]]. Action = [[ 0.04684397  0.00282191  0.         -0.5448719 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 7969 is [True, False, False, False, True, False]
Current timestep = 7970. State = [[-0.10226389  0.07003392]]. Action = [[-0.06116237 -0.07789466  0.          0.37431145]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 7970 is [True, False, False, False, True, False]
Current timestep = 7971. State = [[-0.09825098  0.07159509]]. Action = [[ 0.09779387  0.07119476  0.         -0.13745022]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 7971 is [True, False, False, False, True, False]
State prediction error at timestep 7971 is 0.012
Human Feedback received at timestep 7971 of None
Current timestep = 7972. State = [[-0.09643896  0.07671338]]. Action = [[-0.04934045  0.05401117  0.         -0.33193403]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 7972 is [True, False, False, False, True, False]
Current timestep = 7973. State = [[-0.09403325  0.0817477 ]]. Action = [[0.05010358 0.04957639 0.         0.9323616 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 7973 is [True, False, False, False, True, False]
Current timestep = 7974. State = [[-0.09029044  0.07934057]]. Action = [[ 0.02464904 -0.09684316  0.         -0.6038829 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 7974 is [True, False, False, False, True, False]
Current timestep = 7975. State = [[-0.08993957  0.07673236]]. Action = [[-0.04213031 -0.01191403  0.          0.26206565]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 7975 is [True, False, False, False, True, False]
State prediction error at timestep 7975 is 0.012
Human Feedback received at timestep 7975 of None
Current timestep = 7976. State = [[-0.09131677  0.07468773]]. Action = [[-0.04046946 -0.0459743   0.         -0.66714555]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 7976 is [True, False, False, False, True, False]
Current timestep = 7977. State = [[-0.08796437  0.07181078]]. Action = [[ 0.06211703 -0.03899757  0.          0.5532439 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 7977 is [True, False, False, False, True, False]
Current timestep = 7978. State = [[-0.08608698  0.06837269]]. Action = [[-0.02738061 -0.04383707  0.         -0.06856358]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 7978 is [True, False, False, False, True, False]
Current timestep = 7979. State = [[-0.08308816  0.07016353]]. Action = [[0.04904618 0.06752821 0.         0.1440432 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 7979 is [True, False, False, False, True, False]
Current timestep = 7980. State = [[-0.08285106  0.07100512]]. Action = [[-0.04236258 -0.01793569  0.         -0.33545756]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 7980 is [True, False, False, False, True, False]
Current timestep = 7981. State = [[-0.08176906  0.07115123]]. Action = [[0.02815837 0.01209748 0.         0.6595936 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 7981 is [True, False, False, False, True, False]
Current timestep = 7982. State = [[-0.07773174  0.07020271]]. Action = [[ 0.0577602  -0.02196701  0.         -0.68540937]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 7982 is [True, False, False, False, True, False]
State prediction error at timestep 7982 is 0.012
Human Feedback received at timestep 7982 of None
Current timestep = 7983. State = [[-0.07353793  0.0675275 ]]. Action = [[ 0.04249381 -0.03200252  0.         -0.66514117]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 7983 is [True, False, False, False, True, False]
State prediction error at timestep 7983 is 0.012
Human Feedback received at timestep 7983 of None
Current timestep = 7984. State = [[-0.06746511  0.06578553]]. Action = [[ 8.8122286e-02 -2.9694289e-04  0.0000000e+00  5.8826280e-01]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 7984 is [True, False, False, False, True, False]
Current timestep = 7985. State = [[-0.06306272  0.06250465]]. Action = [[ 0.02645925 -0.04489351  0.         -0.68564194]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 7985 is [True, False, False, False, True, False]
Current timestep = 7986. State = [[-0.05658755  0.05594163]]. Action = [[ 0.09570821 -0.08167442  0.          0.43067026]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 7986 is [True, False, False, False, True, False]
Current timestep = 7987. State = [[-0.05573862  0.0542585 ]]. Action = [[-0.06872008  0.04334649  0.          0.21776605]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 7987 is [True, False, False, False, True, False]
Current timestep = 7988. State = [[-0.05690319  0.0565974 ]]. Action = [[-0.00706293  0.04255157  0.          0.46243036]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 7988 is [True, False, False, False, True, False]
State prediction error at timestep 7988 is 0.012
Human Feedback received at timestep 7988 of None
Current timestep = 7989. State = [[-0.05731789  0.05515376]]. Action = [[-0.01538615 -0.0440298   0.         -0.04198456]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 7989 is [True, False, False, False, True, False]
Current timestep = 7990. State = [[-0.05375441  0.0518394 ]]. Action = [[ 0.06920951 -0.0303953   0.          0.2860391 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 7990 is [True, False, False, False, True, False]
Current timestep = 7991. State = [[-0.05371494  0.04588017]]. Action = [[-0.05940348 -0.08611482  0.         -0.48080075]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 7991 is [True, False, False, False, True, False]
State prediction error at timestep 7991 is 0.012
Human Feedback received at timestep 7991 of None
Current timestep = 7992. State = [[-0.05072039  0.04146229]]. Action = [[ 0.08219501 -0.0184606   0.         -0.65138763]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 7992 is [True, False, False, False, True, False]
State prediction error at timestep 7992 is 0.012
Human Feedback received at timestep 7992 of None
Current timestep = 7993. State = [[-0.20293558 -0.11218125]]. Action = [[0.06127197 0.08224186 0.         0.84529614]]. Reward = [100.]
Curr episode timestep = 51
Scene graph at timestep 7993 is [True, False, False, False, True, False]
Current timestep = 7994. State = [[-0.20054461 -0.11727197]]. Action = [[-0.02080591 -0.07956432  0.         -0.14219922]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 7994 is [True, False, False, False, True, False]
Current timestep = 7995. State = [[-0.19710594 -0.11780085]]. Action = [[ 0.06453197  0.0457618   0.         -0.8034031 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 7995 is [True, False, False, False, True, False]
Current timestep = 7996. State = [[-0.19516303 -0.11649083]]. Action = [[-0.01031714  0.0088279   0.          0.47204828]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 7996 is [True, False, False, False, True, False]
State prediction error at timestep 7996 is 0.012
Human Feedback received at timestep 7996 of None
Current timestep = 7997. State = [[-0.1908952  -0.11512388]]. Action = [[0.0774448  0.02636943 0.         0.6114166 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 7997 is [True, False, False, False, True, False]
State prediction error at timestep 7997 is 0.012
Human Feedback received at timestep 7997 of None
Current timestep = 7998. State = [[-0.18697186 -0.11075296]]. Action = [[ 0.02395721  0.07198938  0.         -0.8914311 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 7998 is [True, False, False, False, True, False]
State prediction error at timestep 7998 is 0.012
Human Feedback received at timestep 7998 of None
Current timestep = 7999. State = [[-0.18868528 -0.10492822]]. Action = [[-0.06346676  0.06954863  0.          0.21735966]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 7999 is [True, False, False, False, True, False]
Current timestep = 8000. State = [[-0.18627858 -0.10594775]]. Action = [[ 0.08024191 -0.07654023  0.          0.55993307]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 8000 is [True, False, False, False, True, False]
Current timestep = 8001. State = [[-0.18710116 -0.10311476]]. Action = [[-0.09754144  0.09690561  0.         -0.68319803]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 8001 is [True, False, False, False, True, False]
Current timestep = 8002. State = [[-0.18667975 -0.1024977 ]]. Action = [[ 0.06008502 -0.05959635  0.         -0.22704363]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8002 is [True, False, False, False, True, False]
Current timestep = 8003. State = [[-0.18293388 -0.1030898 ]]. Action = [[0.02863387 0.00753613 0.         0.3909968 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 8003 is [True, False, False, False, True, False]
Current timestep = 8004. State = [[-0.17935468 -0.10531243]]. Action = [[ 0.03570835 -0.05636612  0.          0.71743107]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 8004 is [True, False, False, False, True, False]
Current timestep = 8005. State = [[-0.17930864 -0.10695908]]. Action = [[-0.04296862 -0.00233559  0.         -0.82490623]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 8005 is [True, False, False, False, True, False]
Current timestep = 8006. State = [[-0.18259662 -0.11181314]]. Action = [[-0.06767971 -0.08966459  0.         -0.01442033]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 8006 is [True, False, False, False, True, False]
State prediction error at timestep 8006 is 0.012
Human Feedback received at timestep 8006 of None
Current timestep = 8007. State = [[-0.17921415 -0.11170179]]. Action = [[ 0.09260698  0.06613945  0.         -0.78486073]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 8007 is [True, False, False, False, True, False]
Current timestep = 8008. State = [[-0.1714198  -0.11235236]]. Action = [[ 0.09568854 -0.04736351  0.          0.61454034]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 8008 is [True, False, False, False, True, False]
Current timestep = 8009. State = [[-0.16919707 -0.11425697]]. Action = [[-0.0315216  -0.00518112  0.          0.84503007]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 8009 is [True, False, False, False, True, False]
Current timestep = 8010. State = [[-0.16497993 -0.11690834]]. Action = [[ 0.0892257  -0.04019966  0.          0.32908428]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 8010 is [True, False, False, False, True, False]
Current timestep = 8011. State = [[-0.15744151 -0.12159741]]. Action = [[ 0.08872867 -0.0581063   0.          0.0974561 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 8011 is [True, False, False, False, True, False]
Current timestep = 8012. State = [[-0.15229237 -0.12118398]]. Action = [[ 0.03269777  0.06050665  0.         -0.08864075]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 8012 is [True, False, False, False, True, False]
Current timestep = 8013. State = [[-0.14632931 -0.12358177]]. Action = [[ 0.08106271 -0.06599158  0.          0.08783734]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 8013 is [True, False, False, False, True, False]
Current timestep = 8014. State = [[-0.14639221 -0.12424787]]. Action = [[-0.08389781  0.04606966  0.         -0.37829763]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 8014 is [True, False, False, False, True, False]
State prediction error at timestep 8014 is 0.012
Human Feedback received at timestep 8014 of None
Current timestep = 8015. State = [[-0.14549263 -0.12329669]]. Action = [[0.05177852 0.00552378 0.         0.7750734 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 8015 is [True, False, False, False, True, False]
State prediction error at timestep 8015 is 0.012
Human Feedback received at timestep 8015 of None
Current timestep = 8016. State = [[-0.14492016 -0.11877441]]. Action = [[-0.02698136  0.0914445   0.         -0.00992024]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 8016 is [True, False, False, False, True, False]
Current timestep = 8017. State = [[-0.14076936 -0.11095151]]. Action = [[0.09481501 0.09570044 0.         0.5230323 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 8017 is [True, False, False, False, True, False]
State prediction error at timestep 8017 is 0.012
Human Feedback received at timestep 8017 of None
Current timestep = 8018. State = [[-0.14091924 -0.10470934]]. Action = [[-0.06401233  0.04896473  0.         -0.7296166 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 8018 is [True, False, False, False, True, False]
Current timestep = 8019. State = [[-0.13833728 -0.10191181]]. Action = [[ 0.08783885 -0.00183078  0.         -0.4631942 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 8019 is [True, False, False, False, True, False]
Current timestep = 8020. State = [[-0.13085908 -0.09896872]]. Action = [[0.09899142 0.03079518 0.         0.3998356 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 8020 is [True, False, False, False, True, False]
State prediction error at timestep 8020 is 0.012
Human Feedback received at timestep 8020 of None
Current timestep = 8021. State = [[-0.12622695 -0.09606405]]. Action = [[ 0.02571895  0.01320259  0.         -0.14392394]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 8021 is [True, False, False, False, True, False]
Current timestep = 8022. State = [[-0.12656261 -0.09223221]]. Action = [[-0.04179459  0.04337316  0.          0.68427765]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 8022 is [True, False, False, False, True, False]
State prediction error at timestep 8022 is 0.012
Human Feedback received at timestep 8022 of None
Current timestep = 8023. State = [[-0.1265644  -0.08715144]]. Action = [[ 0.00376444  0.04900607  0.         -0.45417058]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 8023 is [True, False, False, False, True, False]
Current timestep = 8024. State = [[-0.13032573 -0.08392486]]. Action = [[-0.09918095  0.00481496  0.         -0.66192347]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 8024 is [True, False, False, False, True, False]
Current timestep = 8025. State = [[-0.13595766 -0.0803563 ]]. Action = [[-0.08366869  0.03755973  0.          0.2558005 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 8025 is [True, False, False, False, True, False]
Current timestep = 8026. State = [[-0.1366709  -0.08137941]]. Action = [[ 0.02179237 -0.07376401  0.          0.11440837]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 8026 is [True, False, False, False, True, False]
Current timestep = 8027. State = [[-0.13313325 -0.08221404]]. Action = [[ 0.04785781  0.00346359  0.         -0.8297091 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 8027 is [True, False, False, False, True, False]
Current timestep = 8028. State = [[-0.12978014 -0.07880675]]. Action = [[ 0.03126194  0.05184165  0.         -0.32866406]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 8028 is [True, False, False, False, True, False]
Current timestep = 8029. State = [[-0.12669998 -0.08059587]]. Action = [[ 0.03597672 -0.07998721  0.         -0.6105552 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 8029 is [True, False, False, False, True, False]
Current timestep = 8030. State = [[-0.1239599  -0.08016466]]. Action = [[0.0250675  0.04921696 0.         0.6884217 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 8030 is [True, False, False, False, True, False]
Current timestep = 8031. State = [[-0.12019865 -0.08124366]]. Action = [[ 0.05357676 -0.05073649  0.         -0.1515426 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 8031 is [True, False, False, False, True, False]
Current timestep = 8032. State = [[-0.12109713 -0.08562756]]. Action = [[-0.06503604 -0.05526792  0.         -0.9368556 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 8032 is [True, False, False, False, True, False]
Current timestep = 8033. State = [[-0.12677339 -0.08669087]]. Action = [[-0.09977776  0.02212085  0.         -0.37972987]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 8033 is [True, False, False, False, True, False]
Current timestep = 8034. State = [[-0.13351095 -0.08775676]]. Action = [[-0.09578744 -0.02418688  0.         -0.7599047 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 8034 is [True, False, False, False, True, False]
Current timestep = 8035. State = [[-0.13824077 -0.08689306]]. Action = [[-0.04634937  0.03732685  0.         -0.00544447]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 8035 is [True, False, False, False, True, False]
Current timestep = 8036. State = [[-0.1416913  -0.08632484]]. Action = [[-0.03778727 -0.00816734  0.          0.6805732 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 8036 is [True, False, False, False, True, False]
Current timestep = 8037. State = [[-0.14759228 -0.08365546]]. Action = [[-0.08745936  0.05595731  0.          0.15363955]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 8037 is [True, False, False, False, True, False]
State prediction error at timestep 8037 is 0.012
Human Feedback received at timestep 8037 of None
Current timestep = 8038. State = [[-0.15273675 -0.07834227]]. Action = [[-0.03502493  0.06628519  0.         -0.4449587 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 8038 is [True, False, False, False, True, False]
Current timestep = 8039. State = [[-0.15687534 -0.07427897]]. Action = [[-0.03359773  0.02511268  0.          0.6775167 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 8039 is [True, False, False, False, True, False]
Current timestep = 8040. State = [[-0.16305977 -0.07642866]]. Action = [[-0.07464862 -0.07692287  0.         -0.04713249]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 8040 is [True, False, False, False, True, False]
State prediction error at timestep 8040 is 0.012
Human Feedback received at timestep 8040 of None
Current timestep = 8041. State = [[-0.16308007 -0.07362504]]. Action = [[ 0.08527153  0.08939635  0.         -0.43325198]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 8041 is [True, False, False, False, True, False]
Current timestep = 8042. State = [[-0.16036019 -0.06828277]]. Action = [[0.05494132 0.03694572 0.         0.21426296]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 8042 is [True, False, False, False, True, False]
Current timestep = 8043. State = [[-0.1650415  -0.06406656]]. Action = [[-0.09817602  0.04171886  0.         -0.31252134]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 8043 is [True, False, False, False, True, False]
Current timestep = 8044. State = [[-0.17428303 -0.06639024]]. Action = [[-0.09633657 -0.09173544  0.          0.4823953 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 8044 is [True, False, False, False, True, False]
Current timestep = 8045. State = [[-0.18179326 -0.07037621]]. Action = [[-0.06069927 -0.04044672  0.          0.41050363]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 8045 is [True, False, False, False, True, False]
State prediction error at timestep 8045 is 0.012
Human Feedback received at timestep 8045 of None
Current timestep = 8046. State = [[-0.18415703 -0.07353596]]. Action = [[ 0.02452634 -0.04235312  0.          0.4723376 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 8046 is [True, False, False, False, True, False]
Current timestep = 8047. State = [[-0.18143174 -0.07044721]]. Action = [[0.08278614 0.08700257 0.         0.03321338]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 8047 is [True, False, False, False, True, False]
Current timestep = 8048. State = [[-0.18263067 -0.06483519]]. Action = [[-0.03302667  0.05905106  0.          0.23168361]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 8048 is [True, False, False, False, True, False]
Current timestep = 8049. State = [[-0.18183613 -0.0621929 ]]. Action = [[0.0730711  0.00836507 0.         0.98764324]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 8049 is [True, False, False, False, True, False]
Current timestep = 8050. State = [[-0.18386163 -0.05885844]]. Action = [[-0.05161225  0.05290856  0.          0.67265046]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 8050 is [True, False, False, False, True, False]
Current timestep = 8051. State = [[-0.1894853  -0.05742272]]. Action = [[-0.05699021 -0.01247368  0.         -0.4221223 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 8051 is [True, False, False, False, True, False]
Current timestep = 8052. State = [[-0.18986635 -0.06085534]]. Action = [[ 0.05363334 -0.07288377  0.         -0.44453   ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 8052 is [True, False, False, False, True, False]
Current timestep = 8053. State = [[-0.19270796 -0.0664505 ]]. Action = [[-0.07498673 -0.0709413   0.          0.29890728]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 8053 is [True, False, False, False, True, False]
Current timestep = 8054. State = [[-0.19168536 -0.07113394]]. Action = [[ 0.07596219 -0.04531039  0.          0.3790815 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 8054 is [True, False, False, False, True, False]
Current timestep = 8055. State = [[-0.19301587 -0.07240701]]. Action = [[-0.06873033  0.01651192  0.          0.7918929 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 8055 is [True, False, False, False, True, False]
Current timestep = 8056. State = [[-0.19856067 -0.07560246]]. Action = [[-0.07106489 -0.05841141  0.          0.31708407]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 8056 is [True, False, False, False, True, False]
State prediction error at timestep 8056 is 0.012
Human Feedback received at timestep 8056 of None
Current timestep = 8057. State = [[-0.19921266 -0.08075816]]. Action = [[ 0.03648663 -0.05223697  0.         -0.61395884]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 8057 is [True, False, False, False, True, False]
Current timestep = 8058. State = [[-0.19792381 -0.08404063]]. Action = [[ 0.01340278 -0.01227614  0.         -0.6460787 ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 8058 is [True, False, False, False, True, False]
Current timestep = 8059. State = [[-0.1978589  -0.08243947]]. Action = [[-3.8138032e-04  6.2281944e-02  0.0000000e+00  7.3766768e-01]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 8059 is [True, False, False, False, True, False]
Current timestep = 8060. State = [[-0.19366273 -0.07884369]]. Action = [[ 0.09980648  0.0492521   0.         -0.41767323]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 8060 is [True, False, False, False, True, False]
State prediction error at timestep 8060 is 0.012
Human Feedback received at timestep 8060 of None
Current timestep = 8061. State = [[-0.18789586 -0.07681787]]. Action = [[0.07688854 0.01526725 0.         0.7800634 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 8061 is [True, False, False, False, True, False]
Current timestep = 8062. State = [[-0.18521544 -0.08093793]]. Action = [[ 0.01582507 -0.08790997  0.         -0.29120147]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 8062 is [True, False, False, False, True, False]
State prediction error at timestep 8062 is 0.012
Human Feedback received at timestep 8062 of None
Current timestep = 8063. State = [[-0.18423477 -0.08405552]]. Action = [[ 0.0060586  -0.00074903  0.          0.45760965]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 8063 is [True, False, False, False, True, False]
Current timestep = 8064. State = [[-0.18034269 -0.08959734]]. Action = [[ 0.06804062 -0.09527456  0.         -0.8625582 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 8064 is [True, False, False, False, True, False]
Current timestep = 8065. State = [[-0.1729171 -0.0954909]]. Action = [[ 0.09863555 -0.0444972   0.          0.44916177]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 8065 is [True, False, False, False, True, False]
Current timestep = 8066. State = [[-0.16724305 -0.10123149]]. Action = [[ 0.03677892 -0.06228611  0.         -0.84105355]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 8066 is [True, False, False, False, True, False]
Current timestep = 8067. State = [[-0.16491005 -0.10250753]]. Action = [[-0.003498    0.04242066  0.         -0.9189935 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 8067 is [True, False, False, False, True, False]
Current timestep = 8068. State = [[-0.16583364 -0.10040621]]. Action = [[-0.04702888  0.04756632  0.          0.98376274]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 8068 is [True, False, False, False, True, False]
Current timestep = 8069. State = [[-0.16792537 -0.1033785 ]]. Action = [[-0.04401845 -0.06721173  0.          0.05161846]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 8069 is [True, False, False, False, True, False]
State prediction error at timestep 8069 is 0.012
Human Feedback received at timestep 8069 of None
Current timestep = 8070. State = [[-0.17124285 -0.1069155 ]]. Action = [[-0.06973299 -0.01258817  0.         -0.6163743 ]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 8070 is [True, False, False, False, True, False]
Current timestep = 8071. State = [[-0.1705804  -0.10593786]]. Action = [[ 0.03218525  0.04507806  0.         -0.8110447 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 8071 is [True, False, False, False, True, False]
Current timestep = 8072. State = [[-0.1678129  -0.10405351]]. Action = [[0.02727535 0.01762356 0.         0.24755895]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 8072 is [True, False, False, False, True, False]
Current timestep = 8073. State = [[-0.16333193 -0.10391088]]. Action = [[ 0.0673482  -0.00832994  0.         -0.73061585]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 8073 is [True, False, False, False, True, False]
Current timestep = 8074. State = [[-0.1576155  -0.10412341]]. Action = [[ 0.07285341 -0.00075757  0.         -0.65252733]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 8074 is [True, False, False, False, True, False]
Current timestep = 8075. State = [[-0.15688936 -0.09954826]]. Action = [[-0.03766892  0.09203311  0.         -0.29896665]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 8075 is [True, False, False, False, True, False]
Current timestep = 8076. State = [[-0.1572782  -0.09949973]]. Action = [[ 0.00923512 -0.06017219  0.         -0.40552688]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 8076 is [True, False, False, False, True, False]
Current timestep = 8077. State = [[-0.15663528 -0.0995938 ]]. Action = [[0.00477307 0.02406023 0.         0.07424939]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 8077 is [True, False, False, False, True, False]
Current timestep = 8078. State = [[-0.1533681  -0.10121533]]. Action = [[ 0.05983622 -0.05152959  0.          0.5252564 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 8078 is [True, False, False, False, True, False]
State prediction error at timestep 8078 is 0.012
Human Feedback received at timestep 8078 of None
Current timestep = 8079. State = [[-0.14956282 -0.10125042]]. Action = [[ 0.03767423  0.02575178  0.         -0.76088023]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 8079 is [True, False, False, False, True, False]
State prediction error at timestep 8079 is 0.012
Human Feedback received at timestep 8079 of None
Current timestep = 8080. State = [[-0.15061754 -0.10200612]]. Action = [[-0.05422413 -0.02956864  0.          0.19725621]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 8080 is [True, False, False, False, True, False]
Current timestep = 8081. State = [[-0.15368068 -0.10017952]]. Action = [[-0.04662639  0.05532952  0.          0.2042737 ]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 8081 is [True, False, False, False, True, False]
Current timestep = 8082. State = [[-0.15893051 -0.10066829]]. Action = [[-0.09237289 -0.04189538  0.          0.8369894 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 8082 is [True, False, False, False, True, False]
Current timestep = 8083. State = [[-0.1645926  -0.09870202]]. Action = [[-0.0731508   0.06164857  0.         -0.37113893]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 8083 is [True, False, False, False, True, False]
Current timestep = 8084. State = [[-0.16302505 -0.09961788]]. Action = [[ 0.08646075 -0.06316951  0.          0.91386056]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 8084 is [True, False, False, False, True, False]
State prediction error at timestep 8084 is 0.012
Human Feedback received at timestep 8084 of None
Current timestep = 8085. State = [[-0.16155232 -0.10088487]]. Action = [[-0.02679718  0.0084518   0.          0.5988312 ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 8085 is [True, False, False, False, True, False]
Current timestep = 8086. State = [[-0.16056012 -0.1051422 ]]. Action = [[ 0.02245792 -0.08617026  0.         -0.5449862 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 8086 is [True, False, False, False, True, False]
Current timestep = 8087. State = [[-0.15579398 -0.10825507]]. Action = [[ 0.07821663 -0.00407799  0.         -0.9844735 ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 8087 is [True, False, False, False, True, False]
Current timestep = 8088. State = [[-0.15362512 -0.11204256]]. Action = [[-0.00716818 -0.05920271  0.          0.6125735 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 8088 is [True, False, False, False, True, False]
Current timestep = 8089. State = [[-0.15399684 -0.11518226]]. Action = [[-0.01549333 -0.0098273   0.         -0.51788014]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 8089 is [True, False, False, False, True, False]
Current timestep = 8090. State = [[-0.15064563 -0.12111835]]. Action = [[ 0.07036477 -0.09045199  0.         -0.19848144]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 8090 is [True, False, False, False, True, False]
State prediction error at timestep 8090 is 0.012
Human Feedback received at timestep 8090 of None
Current timestep = 8091. State = [[-0.15008937 -0.12218273]]. Action = [[-0.04363772  0.06013972  0.         -0.9035534 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 8091 is [True, False, False, False, True, False]
Current timestep = 8092. State = [[-0.15223919 -0.12596537]]. Action = [[-0.02614906 -0.08431041  0.          0.8474356 ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 8092 is [True, False, False, False, True, False]
State prediction error at timestep 8092 is 0.012
Human Feedback received at timestep 8092 of None
Current timestep = 8093. State = [[-0.149791 -0.129229]]. Action = [[0.06384259 0.00672807 0.         0.09393322]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 8093 is [True, False, False, True, False, False]
Current timestep = 8094. State = [[-0.147029   -0.13386174]]. Action = [[ 0.02047714 -0.07152883  0.         -0.82827026]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 8094 is [True, False, False, True, False, False]
State prediction error at timestep 8094 is 0.012
Human Feedback received at timestep 8094 of None
Current timestep = 8095. State = [[-0.14842224 -0.13419658]]. Action = [[-0.04723946  0.0616344   0.         -0.60917884]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 8095 is [True, False, False, True, False, False]
State prediction error at timestep 8095 is 0.012
Human Feedback received at timestep 8095 of None
Current timestep = 8096. State = [[-0.14833392 -0.13108537]]. Action = [[0.02909409 0.04761963 0.         0.52287936]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 8096 is [True, False, False, True, False, False]
Current timestep = 8097. State = [[-0.15050365 -0.12834515]]. Action = [[-0.05538675  0.03411602  0.          0.12052178]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 8097 is [True, False, False, True, False, False]
Current timestep = 8098. State = [[-0.14907913 -0.12318756]]. Action = [[ 0.06750979  0.08157667  0.         -0.5571322 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 8098 is [True, False, False, True, False, False]
State prediction error at timestep 8098 is 0.012
Human Feedback received at timestep 8098 of None
Current timestep = 8099. State = [[-0.14825429 -0.12238868]]. Action = [[-0.01047514 -0.04400965  0.          0.38813663]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 8099 is [True, False, False, False, True, False]
Current timestep = 8100. State = [[-0.15286808 -0.12327886]]. Action = [[-0.08800047 -0.00222679  0.          0.34672797]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 8100 is [True, False, False, False, True, False]
Current timestep = 8101. State = [[-0.15570106 -0.12795743]]. Action = [[-0.00587884 -0.09631669  0.          0.2678759 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 8101 is [True, False, False, False, True, False]
State prediction error at timestep 8101 is 0.012
Human Feedback received at timestep 8101 of None
Current timestep = 8102. State = [[-0.15432055 -0.13059081]]. Action = [[0.03517786 0.00362619 0.         0.76155925]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 8102 is [True, False, False, True, False, False]
Current timestep = 8103. State = [[-0.15779887 -0.12612288]]. Action = [[-0.09397952  0.09356835  0.          0.76407456]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 8103 is [True, False, False, True, False, False]
Current timestep = 8104. State = [[-0.16255155 -0.12066421]]. Action = [[-0.0326673   0.04863637  0.          0.94843006]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 8104 is [True, False, False, True, False, False]
Current timestep = 8105. State = [[-0.1634313  -0.12041455]]. Action = [[ 0.02134778 -0.04017488  0.         -0.12312847]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 8105 is [True, False, False, False, True, False]
State prediction error at timestep 8105 is 0.012
Human Feedback received at timestep 8105 of None
Current timestep = 8106. State = [[-0.16358174 -0.11885331]]. Action = [[ 0.00430212  0.04048001  0.         -0.45636606]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 8106 is [True, False, False, False, True, False]
Current timestep = 8107. State = [[-0.1609162  -0.12036489]]. Action = [[ 0.07161628 -0.06639507  0.         -0.7912132 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 8107 is [True, False, False, False, True, False]
Current timestep = 8108. State = [[-0.16141206 -0.12107629]]. Action = [[-0.03910948  0.01732959  0.          0.42159927]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 8108 is [True, False, False, False, True, False]
Current timestep = 8109. State = [[-0.16357714 -0.12329689]]. Action = [[-0.0096252  -0.05592361  0.         -0.8804043 ]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 8109 is [True, False, False, False, True, False]
State prediction error at timestep 8109 is 0.012
Human Feedback received at timestep 8109 of None
Current timestep = 8110. State = [[-0.16623272 -0.1206257 ]]. Action = [[-0.03565563  0.08690154  0.         -0.24275094]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 8110 is [True, False, False, False, True, False]
State prediction error at timestep 8110 is 0.012
Human Feedback received at timestep 8110 of None
Current timestep = 8111. State = [[-0.17169769 -0.11796151]]. Action = [[-0.07879315  0.00252955  0.         -0.05054975]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 8111 is [True, False, False, False, True, False]
Current timestep = 8112. State = [[-0.17428811 -0.11897702]]. Action = [[ 0.00563721 -0.02794418  0.         -0.7277129 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 8112 is [True, False, False, False, True, False]
Current timestep = 8113. State = [[-0.17122598 -0.12211992]]. Action = [[ 0.07670223 -0.05076433  0.         -0.5705837 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 8113 is [True, False, False, False, True, False]
State prediction error at timestep 8113 is 0.012
Human Feedback received at timestep 8113 of None
Current timestep = 8114. State = [[-0.16893417 -0.12716258]]. Action = [[ 0.01529716 -0.06994129  0.         -0.6805801 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 8114 is [True, False, False, False, True, False]
Current timestep = 8115. State = [[-0.16645876 -0.13452435]]. Action = [[ 0.04463124 -0.09458216  0.         -0.12223887]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 8115 is [True, False, False, True, False, False]
Current timestep = 8116. State = [[-0.16498272 -0.13784094]]. Action = [[ 0.0045565   0.0112643   0.         -0.16042143]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 8116 is [True, False, False, True, False, False]
Current timestep = 8117. State = [[-0.16094139 -0.14200458]]. Action = [[ 0.07897892 -0.0631483   0.         -0.742929  ]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 8117 is [True, False, False, True, False, False]
Current timestep = 8118. State = [[-0.15717044 -0.14992386]]. Action = [[ 0.02681012 -0.09310818  0.          0.34747064]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 8118 is [True, False, False, True, False, False]
Current timestep = 8119. State = [[-0.15800793 -0.15750721]]. Action = [[-0.04650034 -0.05707901  0.          0.8084943 ]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 8119 is [True, False, False, True, False, False]
Current timestep = 8120. State = [[-0.15536144 -0.15726103]]. Action = [[ 0.06891828  0.08445709  0.         -0.5402521 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 8120 is [True, False, False, True, False, False]
Current timestep = 8121. State = [[-0.15476678 -0.15901183]]. Action = [[-0.03366257 -0.04872068  0.          0.4003725 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 8121 is [True, False, False, True, False, False]
Current timestep = 8122. State = [[-0.15922281 -0.16478002]]. Action = [[-0.08620419 -0.05434107  0.          0.7866242 ]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 8122 is [True, False, False, True, False, False]
Current timestep = 8123. State = [[-0.15791418 -0.17254339]]. Action = [[ 0.07126226 -0.08935262  0.         -0.6288385 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 8123 is [True, False, False, True, False, False]
Current timestep = 8124. State = [[-0.15878186 -0.17707734]]. Action = [[-0.07839286  0.00535073  0.          0.41846538]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 8124 is [True, False, False, True, False, False]
Current timestep = 8125. State = [[-0.16253036 -0.18006347]]. Action = [[-0.04495208 -0.02294479  0.         -0.87440383]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 8125 is [True, False, False, True, False, False]
Current timestep = 8126. State = [[-0.16247077 -0.183603  ]]. Action = [[ 0.02426957 -0.0255762   0.         -0.33477283]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 8126 is [True, False, False, True, False, False]
Current timestep = 8127. State = [[-0.16100916 -0.18138327]]. Action = [[0.01678686 0.08461394 0.         0.40247822]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 8127 is [True, False, False, True, False, False]
Current timestep = 8128. State = [[-0.16158597 -0.18055618]]. Action = [[-0.01929673 -0.01798256  0.          0.18491101]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 8128 is [True, False, False, True, False, False]
State prediction error at timestep 8128 is 0.012
Human Feedback received at timestep 8128 of None
Current timestep = 8129. State = [[-0.15844463 -0.18485743]]. Action = [[ 0.08128268 -0.07028209  0.          0.96329   ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 8129 is [True, False, False, True, False, False]
State prediction error at timestep 8129 is 0.012
Human Feedback received at timestep 8129 of None
Current timestep = 8130. State = [[-0.15719041 -0.19240072]]. Action = [[-0.01815732 -0.09891655  0.         -0.3486902 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 8130 is [True, False, False, True, False, False]
State prediction error at timestep 8130 is 0.012
Human Feedback received at timestep 8130 of None
Current timestep = 8131. State = [[-0.1542125  -0.19336075]]. Action = [[ 0.06828745  0.05924421  0.         -0.48078823]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 8131 is [True, False, False, True, False, False]
State prediction error at timestep 8131 is 0.012
Human Feedback received at timestep 8131 of None
Current timestep = 8132. State = [[-0.1519282  -0.19128452]]. Action = [[0.00777276 0.02273677 0.         0.8955641 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 8132 is [True, False, False, True, False, False]
Current timestep = 8133. State = [[-0.14725672 -0.1914233 ]]. Action = [[ 0.0891578  -0.01038984  0.         -0.08598715]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 8133 is [True, False, False, True, False, False]
Current timestep = 8134. State = [[-0.14644086 -0.19541442]]. Action = [[-0.03825235 -0.06776085  0.         -0.01234418]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 8134 is [True, False, False, True, False, False]
Current timestep = 8135. State = [[-0.14749815 -0.20197974]]. Action = [[-0.01105372 -0.07585789  0.          0.4467306 ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 8135 is [True, False, False, True, False, False]
State prediction error at timestep 8135 is 0.012
Human Feedback received at timestep 8135 of None
Current timestep = 8136. State = [[-0.14614217 -0.20268157]]. Action = [[ 0.02499372  0.05251809  0.         -0.34307343]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 8136 is [True, False, False, True, False, False]
Current timestep = 8137. State = [[-0.14321958 -0.1985653 ]]. Action = [[0.0372447  0.06760921 0.         0.1896801 ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 8137 is [True, False, False, True, False, False]
Current timestep = 8138. State = [[-0.13945024 -0.19885272]]. Action = [[ 0.04753193 -0.04291467  0.          0.44516575]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 8138 is [True, False, False, True, False, False]
Current timestep = 8139. State = [[-0.1396643  -0.19721419]]. Action = [[-0.0451007   0.0618036   0.         -0.46088278]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 8139 is [True, False, False, True, False, False]
Current timestep = 8140. State = [[-0.14198698 -0.19878922]]. Action = [[-0.03047989 -0.0641205   0.         -0.78620076]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 8140 is [True, False, False, True, False, False]
State prediction error at timestep 8140 is 0.012
Human Feedback received at timestep 8140 of None
Current timestep = 8141. State = [[-0.13929331 -0.20206898]]. Action = [[ 0.06707146 -0.02802207  0.         -0.50637084]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 8141 is [True, False, False, True, False, False]
State prediction error at timestep 8141 is 0.012
Human Feedback received at timestep 8141 of None
Current timestep = 8142. State = [[-0.14092954 -0.20602763]]. Action = [[-0.0806695  -0.05564512  0.         -0.53012574]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 8142 is [True, False, False, True, False, False]
Current timestep = 8143. State = [[-0.13842446 -0.21194251]]. Action = [[ 0.09211872 -0.07708839  0.         -0.61497897]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 8143 is [True, False, False, True, False, False]
Current timestep = 8144. State = [[-0.13302833 -0.21946476]]. Action = [[ 0.04790203 -0.08715764  0.          0.58643603]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 8144 is [True, False, False, True, False, False]
Current timestep = 8145. State = [[-0.12976336 -0.22055878]]. Action = [[0.0207245  0.05813494 0.         0.4139979 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 8145 is [True, False, False, True, False, False]
Current timestep = 8146. State = [[-0.12689276 -0.22090481]]. Action = [[ 0.03260558 -0.01289869  0.         -0.04742008]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 8146 is [True, False, False, True, False, False]
Current timestep = 8147. State = [[-0.1277996  -0.22684938]]. Action = [[-0.0513152  -0.08809382  0.         -0.05488193]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 8147 is [True, False, False, True, False, False]
Current timestep = 8148. State = [[-0.12466601 -0.2288867 ]]. Action = [[0.0788961  0.04021027 0.         0.98263216]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 8148 is [True, False, False, True, False, False]
Current timestep = 8149. State = [[-0.12358263 -0.2241497 ]]. Action = [[-0.03619268  0.09644892  0.         -0.63385445]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 8149 is [True, False, False, True, False, False]
Current timestep = 8150. State = [[-0.12550327 -0.22088681]]. Action = [[-0.03211661  0.01963736  0.         -0.00318933]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 8150 is [True, False, False, True, False, False]
Current timestep = 8151. State = [[-0.12524934 -0.21983759]]. Action = [[ 0.01566428  0.00910725  0.         -0.39724493]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 8151 is [True, False, False, True, False, False]
State prediction error at timestep 8151 is 0.012
Human Feedback received at timestep 8151 of None
Current timestep = 8152. State = [[-0.12563884 -0.22250094]]. Action = [[-0.02344499 -0.06188715  0.          0.9429712 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 8152 is [True, False, False, True, False, False]
Current timestep = 8153. State = [[-0.13046774 -0.22804773]]. Action = [[-0.09474938 -0.07069062  0.         -0.7660643 ]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 8153 is [True, False, False, True, False, False]
Current timestep = 8154. State = [[-0.13525812 -0.22675104]]. Action = [[-0.05194294  0.08192153  0.          0.21584558]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 8154 is [True, False, False, True, False, False]
Current timestep = 8155. State = [[-0.136956   -0.22803248]]. Action = [[-0.00361085 -0.06648836  0.          0.18097138]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 8155 is [True, False, False, True, False, False]
State prediction error at timestep 8155 is 0.012
Human Feedback received at timestep 8155 of None
Current timestep = 8156. State = [[-0.13468981 -0.23248945]]. Action = [[ 0.04930442 -0.04726073  0.         -0.2551983 ]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 8156 is [True, False, False, True, False, False]
Current timestep = 8157. State = [[-0.13569789 -0.23044911]]. Action = [[-0.05236787  0.08209416  0.         -0.80780137]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 8157 is [True, False, False, True, False, False]
Current timestep = 8158. State = [[-0.13393223 -0.23276287]]. Action = [[ 0.08640546 -0.09999021  0.         -0.2910812 ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 8158 is [True, False, False, True, False, False]
Current timestep = 8159. State = [[-0.1288071  -0.23427963]]. Action = [[0.0588607  0.03162637 0.         0.8728366 ]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 8159 is [True, False, False, True, False, False]
Current timestep = 8160. State = [[-0.13063952 -0.23318219]]. Action = [[-0.0788881   0.01775706  0.          0.633855  ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 8160 is [True, False, False, True, False, False]
Current timestep = 8161. State = [[-0.13069053 -0.23631054]]. Action = [[ 0.04349004 -0.06592527  0.         -0.373415  ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 8161 is [True, False, False, True, False, False]
State prediction error at timestep 8161 is 0.012
Human Feedback received at timestep 8161 of None
Current timestep = 8162. State = [[-0.13272372 -0.23933019]]. Action = [[-0.07254632 -0.00649564  0.          0.8422165 ]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 8162 is [True, False, False, True, False, False]
Current timestep = 8163. State = [[-0.13121924 -0.24312209]]. Action = [[ 0.07034244 -0.05729957  0.         -0.23616487]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 8163 is [True, False, False, True, False, False]
Current timestep = 8164. State = [[-0.12803541 -0.24787697]]. Action = [[ 0.02006569 -0.04510879  0.         -0.22246516]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 8164 is [True, False, False, True, False, False]
Current timestep = 8165. State = [[-0.13166922 -0.25340962]]. Action = [[-0.09806294 -0.05749895  0.          0.10757208]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 8165 is [True, False, False, True, False, False]
Current timestep = 8166. State = [[-0.13299441 -0.25661483]]. Action = [[0.02005552 0.00280321 0.         0.43499327]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 8166 is [True, False, False, True, False, False]
Current timestep = 8167. State = [[-0.12931411 -0.25458702]]. Action = [[0.06256799 0.06489595 0.         0.84628105]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 8167 is [True, False, False, True, False, False]
Current timestep = 8168. State = [[-0.12337844 -0.2492701 ]]. Action = [[0.08422732 0.07754918 0.         0.781536  ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 8168 is [True, False, False, True, False, False]
State prediction error at timestep 8168 is 0.012
Human Feedback received at timestep 8168 of None
Current timestep = 8169. State = [[-0.11768733 -0.24582876]]. Action = [[0.06689283 0.01661978 0.         0.47546506]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 8169 is [True, False, False, True, False, False]
Current timestep = 8170. State = [[-0.11945128 -0.24027632]]. Action = [[-0.08677489  0.0978504   0.          0.7451904 ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 8170 is [True, False, False, True, False, False]
Current timestep = 8171. State = [[-0.12432983 -0.23304857]]. Action = [[-0.04894967  0.07274213  0.          0.52407765]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 8171 is [True, False, False, True, False, False]
Current timestep = 8172. State = [[-0.12296749 -0.22983168]]. Action = [[ 0.07031643 -0.01333704  0.          0.6349392 ]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 8172 is [True, False, False, True, False, False]
Current timestep = 8173. State = [[-0.12167652 -0.22517437]]. Action = [[-0.01140835  0.06634241  0.          0.99180937]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 8173 is [True, False, False, True, False, False]
Current timestep = 8174. State = [[-0.1209346  -0.21679832]]. Action = [[0.0205584  0.09436961 0.         0.6997423 ]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 8174 is [True, False, False, True, False, False]
Current timestep = 8175. State = [[-0.12058886 -0.21091962]]. Action = [[-0.00243752  0.01903148  0.         -0.9898154 ]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 8175 is [True, False, False, True, False, False]
Current timestep = 8176. State = [[-0.11631218 -0.20547616]]. Action = [[0.09083577 0.0496804  0.         0.7831532 ]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 8176 is [True, False, False, True, False, False]
Current timestep = 8177. State = [[-0.10975035 -0.20312056]]. Action = [[ 0.08747547 -0.03219131  0.         -0.9330747 ]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 8177 is [True, False, False, True, False, False]
Current timestep = 8178. State = [[-0.10650935 -0.20015752]]. Action = [[0.01295991 0.03561898 0.         0.43489385]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 8178 is [True, False, False, True, False, False]
Current timestep = 8179. State = [[-0.10633836 -0.19604668]]. Action = [[-0.01006977  0.02837016  0.         -0.8347149 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 8179 is [True, False, False, True, False, False]
State prediction error at timestep 8179 is 0.012
Human Feedback received at timestep 8179 of None
Current timestep = 8180. State = [[-0.10867715 -0.19761392]]. Action = [[-0.05165023 -0.07656169  0.         -0.11733508]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 8180 is [True, False, False, True, False, False]
Current timestep = 8181. State = [[-0.11395454 -0.19817092]]. Action = [[-0.09585153  0.0183847   0.          0.57921207]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 8181 is [True, False, False, True, False, False]
Current timestep = 8182. State = [[-0.11240893 -0.194092  ]]. Action = [[0.07684591 0.05953125 0.         0.7052064 ]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 8182 is [True, False, False, True, False, False]
Current timestep = 8183. State = [[-0.11260625 -0.1935749 ]]. Action = [[-0.0585265  -0.03943634  0.          0.4291321 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 8183 is [True, False, False, True, False, False]
State prediction error at timestep 8183 is 0.012
Human Feedback received at timestep 8183 of None
Current timestep = 8184. State = [[-0.10932149 -0.19858834]]. Action = [[ 0.08962279 -0.0887932   0.          0.19659424]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 8184 is [True, False, False, True, False, False]
Current timestep = 8185. State = [[-0.10172986 -0.19700496]]. Action = [[ 0.09153508  0.08471403  0.         -0.38203198]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 8185 is [True, False, False, True, False, False]
State prediction error at timestep 8185 is 0.012
Human Feedback received at timestep 8185 of None
Current timestep = 8186. State = [[-0.09701926 -0.19183256]]. Action = [[0.02739754 0.05448975 0.         0.71511364]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 8186 is [True, False, False, True, False, False]
Current timestep = 8187. State = [[-0.09808584 -0.1920309 ]]. Action = [[-0.05675057 -0.04118426  0.         -0.08148277]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 8187 is [True, False, False, True, False, False]
Current timestep = 8188. State = [[-0.09562078 -0.1890671 ]]. Action = [[ 0.06470113  0.0811158   0.         -0.71736944]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 8188 is [True, False, False, True, False, False]
Current timestep = 8189. State = [[-0.08934303 -0.18924202]]. Action = [[ 0.08077779 -0.06011455  0.         -0.67837274]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 8189 is [True, False, False, True, False, False]
Current timestep = 8190. State = [[-0.08429243 -0.1929503 ]]. Action = [[ 0.04047275 -0.04828399  0.         -0.9061366 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 8190 is [True, False, False, True, False, False]
Current timestep = 8191. State = [[-0.07796734 -0.19807972]]. Action = [[ 0.08553918 -0.07091401  0.         -0.49914247]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 8191 is [True, False, False, True, False, False]
Current timestep = 8192. State = [[-0.0761127  -0.20327659]]. Action = [[-0.03701153 -0.04824143  0.          0.07394946]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 8192 is [True, False, False, True, False, False]
Current timestep = 8193. State = [[-0.07841935 -0.20872766]]. Action = [[-0.05594222 -0.05680972  0.         -0.35391295]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 8193 is [True, False, False, True, False, False]
Current timestep = 8194. State = [[-0.07452237 -0.21380009]]. Action = [[ 0.09076383 -0.04081032  0.         -0.31995952]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 8194 is [True, False, False, True, False, False]
Current timestep = 8195. State = [[-0.06937283 -0.2130978 ]]. Action = [[0.03104626 0.06871787 0.         0.9526168 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 8195 is [True, False, False, True, False, False]
Current timestep = 8196. State = [[-0.06378201 -0.21273075]]. Action = [[ 0.07116974 -0.00933913  0.         -0.524165  ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 8196 is [True, False, False, True, False, False]
Current timestep = 8197. State = [[-0.06387985 -0.21418044]]. Action = [[-0.0709521  -0.00493762  0.         -0.631401  ]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 8197 is [True, False, False, True, False, False]
Current timestep = 8198. State = [[-0.06599432 -0.21862927]]. Action = [[-0.03040852 -0.06615166  0.         -0.7865437 ]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 8198 is [True, False, False, True, False, False]
Current timestep = 8199. State = [[-0.06755699 -0.21730064]]. Action = [[-0.03589488  0.08536372  0.          0.6437117 ]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 8199 is [True, False, False, True, False, False]
Current timestep = 8200. State = [[-0.06616316 -0.21875134]]. Action = [[ 0.03387181 -0.06832545  0.          0.11445773]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 8200 is [True, False, False, True, False, False]
Current timestep = 8201. State = [[-0.05992413 -0.2184651 ]]. Action = [[0.09312548 0.05137765 0.         0.73765993]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 8201 is [True, False, False, True, False, False]
State prediction error at timestep 8201 is 0.012
Human Feedback received at timestep 8201 of None
Current timestep = 8202. State = [[-0.0607419  -0.21496788]]. Action = [[-0.09506612  0.0494739   0.          0.5648855 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 8202 is [True, False, False, True, False, False]
Current timestep = 8203. State = [[-0.06702457 -0.2136442 ]]. Action = [[-0.09169785 -0.00509416  0.         -0.61684   ]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 8203 is [True, False, False, True, False, False]
Current timestep = 8204. State = [[-0.06844969 -0.20963703]]. Action = [[0.01847525 0.0755031  0.         0.3091371 ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 8204 is [True, False, False, True, False, False]
State prediction error at timestep 8204 is 0.012
Human Feedback received at timestep 8204 of None
Current timestep = 8205. State = [[-0.06698451 -0.20331258]]. Action = [[0.02299436 0.06350144 0.         0.37057972]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 8205 is [True, False, False, True, False, False]
Current timestep = 8206. State = [[-0.0632304  -0.19613114]]. Action = [[0.07068839 0.07458626 0.         0.3294723 ]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 8206 is [True, False, False, True, False, False]
Current timestep = 8207. State = [[-0.05795269 -0.19460674]]. Action = [[ 0.08183559 -0.05231175  0.          0.13384032]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 8207 is [True, False, False, True, False, False]
Current timestep = 8208. State = [[-0.0523691 -0.193242 ]]. Action = [[ 0.08002423  0.02352495  0.         -0.6207187 ]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 8208 is [True, False, False, True, False, False]
Current timestep = 8209. State = [[-0.05024881 -0.19429938]]. Action = [[ 0.00360515 -0.05825815  0.         -0.016761  ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 8209 is [True, False, False, True, False, False]
Current timestep = 8210. State = [[-0.04593641 -0.1901744 ]]. Action = [[0.08718126 0.09943541 0.         0.08753633]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 8210 is [True, False, False, True, False, False]
Current timestep = 8211. State = [[-0.04182911 -0.1877316 ]]. Action = [[ 0.03598904 -0.02742099  0.         -0.33941412]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 8211 is [False, True, False, True, False, False]
State prediction error at timestep 8211 is 0.012
Human Feedback received at timestep 8211 of None
Current timestep = 8212. State = [[-0.03663895 -0.18470731]]. Action = [[ 0.07971974  0.05632473  0.         -0.37683856]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 8212 is [False, True, False, True, False, False]
State prediction error at timestep 8212 is 0.012
Human Feedback received at timestep 8212 of None
Current timestep = 8213. State = [[-0.03374932 -0.18498644]]. Action = [[ 0.00506623 -0.05404848  0.         -0.5069367 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 8213 is [False, True, False, True, False, False]
Current timestep = 8214. State = [[-0.03456906 -0.18970051]]. Action = [[-0.04111117 -0.07174163  0.          0.82258034]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 8214 is [False, True, False, True, False, False]
Current timestep = 8215. State = [[-0.03498668 -0.1910511 ]]. Action = [[-0.01228832  0.01905359  0.          0.8110455 ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 8215 is [False, True, False, True, False, False]
State prediction error at timestep 8215 is 0.012
Human Feedback received at timestep 8215 of None
Current timestep = 8216. State = [[-0.03013431 -0.19066226]]. Action = [[0.08457714 0.00116006 0.         0.32027173]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 8216 is [False, True, False, True, False, False]
State prediction error at timestep 8216 is 0.012
Human Feedback received at timestep 8216 of None
Current timestep = 8217. State = [[-0.02572557 -0.19149977]]. Action = [[ 0.01967408 -0.01479577  0.          0.16523719]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 8217 is [False, True, False, True, False, False]
Current timestep = 8218. State = [[-0.02799313 -0.1959776 ]]. Action = [[-0.09024529 -0.07189686  0.         -0.46944857]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 8218 is [False, True, False, True, False, False]
Current timestep = 8219. State = [[-0.02944942 -0.20363653]]. Action = [[-0.01284582 -0.0926199   0.         -0.25748193]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 8219 is [False, True, False, True, False, False]
State prediction error at timestep 8219 is 0.012
Human Feedback received at timestep 8219 of None
Current timestep = 8220. State = [[-0.03179709 -0.20750925]]. Action = [[-0.06882378  0.00558893  0.          0.515625  ]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 8220 is [False, True, False, True, False, False]
Current timestep = 8221. State = [[-0.03088719 -0.20499343]]. Action = [[0.03153678 0.07516658 0.         0.21581233]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 8221 is [False, True, False, True, False, False]
Current timestep = 8222. State = [[-0.02947366 -0.20429744]]. Action = [[-0.00389957 -0.01647919  0.         -0.5160444 ]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 8222 is [False, True, False, True, False, False]
Current timestep = 8223. State = [[-0.02949772 -0.20340891]]. Action = [[-0.01331943  0.03512924  0.         -0.7739462 ]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 8223 is [False, True, False, True, False, False]
Current timestep = 8224. State = [[-0.03089335 -0.20333472]]. Action = [[-0.03290535 -0.01337492  0.          0.94266677]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 8224 is [False, True, False, True, False, False]
State prediction error at timestep 8224 is 0.012
Human Feedback received at timestep 8224 of None
Current timestep = 8225. State = [[-0.03511396 -0.20438012]]. Action = [[-0.07808334 -0.00955313  0.          0.4703908 ]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 8225 is [False, True, False, True, False, False]
Current timestep = 8226. State = [[-0.0381812  -0.20770872]]. Action = [[-0.02556144 -0.05537285  0.         -0.5136238 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 8226 is [False, True, False, True, False, False]
Current timestep = 8227. State = [[-0.03717714 -0.2070648 ]]. Action = [[ 0.03702783  0.05143046  0.         -0.71949667]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 8227 is [False, True, False, True, False, False]
Current timestep = 8228. State = [[-0.03863335 -0.21013229]]. Action = [[-0.04539288 -0.08783527  0.          0.7732065 ]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 8228 is [False, True, False, True, False, False]
Current timestep = 8229. State = [[-0.04072106 -0.21777125]]. Action = [[-0.01272212 -0.09218807  0.          0.5570816 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 8229 is [False, True, False, True, False, False]
State prediction error at timestep 8229 is 0.012
Human Feedback received at timestep 8229 of None
Current timestep = 8230. State = [[-0.04327937 -0.22554299]]. Action = [[-0.03665914 -0.07727478  0.         -0.6719948 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 8230 is [False, True, False, True, False, False]
Current timestep = 8231. State = [[-0.04675271 -0.22663677]]. Action = [[-0.04233123  0.05537584  0.         -0.6630698 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 8231 is [False, True, False, True, False, False]
State prediction error at timestep 8231 is 0.012
Human Feedback received at timestep 8231 of None
Current timestep = 8232. State = [[-0.04981744 -0.22286826]]. Action = [[-0.02731885  0.06944279  0.          0.13705623]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 8232 is [False, True, False, True, False, False]
State prediction error at timestep 8232 is 0.012
Human Feedback received at timestep 8232 of None
Current timestep = 8233. State = [[-0.05459968 -0.22530405]]. Action = [[-0.06730667 -0.07692087  0.         -0.65738386]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 8233 is [False, True, False, True, False, False]
Current timestep = 8234. State = [[-0.05485979 -0.2241889 ]]. Action = [[ 0.05230808  0.07842965  0.         -0.84717476]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 8234 is [True, False, False, True, False, False]
Current timestep = 8235. State = [[-0.05163211 -0.2236364 ]]. Action = [[ 0.06276464 -0.03256588  0.         -0.07777756]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 8235 is [True, False, False, True, False, False]
Current timestep = 8236. State = [[-0.05313373 -0.22404422]]. Action = [[-0.04699988  0.00860487  0.         -0.22095239]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 8236 is [True, False, False, True, False, False]
Current timestep = 8237. State = [[-0.05912303 -0.22257826]]. Action = [[-0.07820934  0.02493443  0.         -0.43652976]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 8237 is [True, False, False, True, False, False]
Current timestep = 8238. State = [[-0.05873071 -0.22001036]]. Action = [[0.07944316 0.02958902 0.         0.96565866]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 8238 is [True, False, False, True, False, False]
Current timestep = 8239. State = [[-0.05999166 -0.22082369]]. Action = [[-0.04998537 -0.04215864  0.          0.34918034]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 8239 is [True, False, False, True, False, False]
State prediction error at timestep 8239 is 0.012
Human Feedback received at timestep 8239 of None
Current timestep = 8240. State = [[-0.05907148 -0.21715195]]. Action = [[0.0608091  0.09251552 0.         0.17755151]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 8240 is [True, False, False, True, False, False]
State prediction error at timestep 8240 is 0.012
Human Feedback received at timestep 8240 of None
Current timestep = 8241. State = [[-0.05475081 -0.20947711]]. Action = [[ 0.07391318  0.08370262  0.         -0.2690401 ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 8241 is [True, False, False, True, False, False]
Current timestep = 8242. State = [[-0.05450287 -0.21032253]]. Action = [[-0.02347691 -0.09566958  0.         -0.8608856 ]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 8242 is [True, False, False, True, False, False]
Current timestep = 8243. State = [[-0.05108628 -0.2118375 ]]. Action = [[0.09349164 0.00791301 0.         0.22149229]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 8243 is [True, False, False, True, False, False]
Current timestep = 8244. State = [[-0.05006021 -0.2062621 ]]. Action = [[-0.02824572  0.09937986  0.          0.24374545]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 8244 is [True, False, False, True, False, False]
Current timestep = 8245. State = [[-0.05499124 -0.20706384]]. Action = [[-0.08307006 -0.09352848  0.          0.8965838 ]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 8245 is [True, False, False, True, False, False]
Current timestep = 8246. State = [[-0.05854807 -0.20834385]]. Action = [[-0.02411189  0.0169815   0.          0.52482533]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 8246 is [True, False, False, True, False, False]
Current timestep = 8247. State = [[-0.06159047 -0.2118031 ]]. Action = [[-0.0460367  -0.08166623  0.          0.27164984]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 8247 is [True, False, False, True, False, False]
Current timestep = 8248. State = [[-0.06135537 -0.21813503]]. Action = [[ 0.03265233 -0.07615356  0.          0.9585202 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 8248 is [True, False, False, True, False, False]
Current timestep = 8249. State = [[-0.06090973 -0.21766189]]. Action = [[-0.00660802  0.06800546  0.         -0.27989292]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 8249 is [True, False, False, True, False, False]
Current timestep = 8250. State = [[-0.0618651  -0.21880266]]. Action = [[-0.01346715 -0.05005146  0.          0.01376379]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 8250 is [True, False, False, True, False, False]
Current timestep = 8251. State = [[-0.0622731  -0.21899779]]. Action = [[ 0.00272713  0.03564016  0.         -0.63609684]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 8251 is [True, False, False, True, False, False]
Current timestep = 8252. State = [[-0.06436013 -0.2164785 ]]. Action = [[-0.04037293  0.04047156  0.          0.09289145]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 8252 is [True, False, False, True, False, False]
Current timestep = 8253. State = [[-0.06300226 -0.2160602 ]]. Action = [[ 0.05795734 -0.0140113   0.          0.03635228]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 8253 is [True, False, False, True, False, False]
Current timestep = 8254. State = [[-0.06287268 -0.21469109]]. Action = [[-0.02469148  0.03541557  0.          0.4041636 ]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 8254 is [True, False, False, True, False, False]
Current timestep = 8255. State = [[-0.06678396 -0.21691313]]. Action = [[-0.06614512 -0.06372778  0.          0.22650361]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 8255 is [True, False, False, True, False, False]
State prediction error at timestep 8255 is 0.012
Human Feedback received at timestep 8255 of None
Current timestep = 8256. State = [[-0.06722412 -0.21546817]]. Action = [[ 0.03149926  0.06863823  0.         -0.03288913]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 8256 is [True, False, False, True, False, False]
State prediction error at timestep 8256 is 0.012
Human Feedback received at timestep 8256 of None
Current timestep = 8257. State = [[-0.07070155 -0.21354963]]. Action = [[-0.08478484 -0.00304601  0.         -0.4853443 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 8257 is [True, False, False, True, False, False]
Current timestep = 8258. State = [[-0.07028344 -0.21483867]]. Action = [[ 0.06437572 -0.03233675  0.         -0.38474154]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 8258 is [True, False, False, True, False, False]
Current timestep = 8259. State = [[-0.06551349 -0.21500571]]. Action = [[ 0.06898119  0.01200008  0.         -0.95542836]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 8259 is [True, False, False, True, False, False]
Current timestep = 8260. State = [[-0.0662969  -0.21193461]]. Action = [[-0.05852162  0.05465399  0.          0.0884074 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 8260 is [True, False, False, True, False, False]
State prediction error at timestep 8260 is 0.012
Human Feedback received at timestep 8260 of None
Current timestep = 8261. State = [[-0.07179646 -0.2054131 ]]. Action = [[-0.07963123  0.0922546   0.          0.14723921]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 8261 is [True, False, False, True, False, False]
Current timestep = 8262. State = [[-0.07587428 -0.19852574]]. Action = [[-0.03233621  0.06679889  0.         -0.18089259]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 8262 is [True, False, False, True, False, False]
Current timestep = 8263. State = [[-0.08044332 -0.20023143]]. Action = [[-0.06512408 -0.09946191  0.          0.910462  ]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 8263 is [True, False, False, True, False, False]
Current timestep = 8264. State = [[-0.07901122 -0.19887565]]. Action = [[0.0811407  0.06572511 0.         0.14318347]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 8264 is [True, False, False, True, False, False]
Current timestep = 8265. State = [[-0.08062112 -0.1980216 ]]. Action = [[-0.06363992 -0.04114928  0.         -0.6888135 ]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 8265 is [True, False, False, True, False, False]
Current timestep = 8266. State = [[-0.07987282 -0.201885  ]]. Action = [[ 0.06385159 -0.07128048  0.         -0.8544646 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 8266 is [True, False, False, True, False, False]
State prediction error at timestep 8266 is 0.012
Human Feedback received at timestep 8266 of None
Current timestep = 8267. State = [[-0.08275537 -0.20293169]]. Action = [[-0.09372959  0.02220108  0.          0.9704715 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 8267 is [True, False, False, True, False, False]
Current timestep = 8268. State = [[-0.08972238 -0.20199797]]. Action = [[-0.07606842  0.00453369  0.          0.61552405]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 8268 is [True, False, False, True, False, False]
Current timestep = 8269. State = [[-0.09211056 -0.20600791]]. Action = [[ 0.0202622  -0.08729693  0.         -0.9926205 ]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 8269 is [True, False, False, True, False, False]
Current timestep = 8270. State = [[-0.09498859 -0.20885162]]. Action = [[-0.05058361  0.00034596  0.          0.1902206 ]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 8270 is [True, False, False, True, False, False]
Current timestep = 8271. State = [[-0.10072766 -0.20775576]]. Action = [[-0.07195829  0.03451351  0.          0.88877547]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 8271 is [True, False, False, True, False, False]
State prediction error at timestep 8271 is 0.012
Human Feedback received at timestep 8271 of None
Current timestep = 8272. State = [[-0.10431709 -0.20761882]]. Action = [[-0.01095704 -0.00967862  0.         -0.5326322 ]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 8272 is [True, False, False, True, False, False]
State prediction error at timestep 8272 is 0.012
Human Feedback received at timestep 8272 of None
Current timestep = 8273. State = [[-0.1040737  -0.20829256]]. Action = [[ 0.03763007 -0.00445852  0.         -0.5156265 ]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 8273 is [True, False, False, True, False, False]
Current timestep = 8274. State = [[-0.10424759 -0.21359992]]. Action = [[ 0.00094156 -0.09945172  0.          0.5548308 ]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 8274 is [True, False, False, True, False, False]
Current timestep = 8275. State = [[-0.10832053 -0.21560004]]. Action = [[-0.06586437  0.03210194  0.         -0.09613258]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 8275 is [True, False, False, True, False, False]
State prediction error at timestep 8275 is 0.012
Human Feedback received at timestep 8275 of None
Current timestep = 8276. State = [[-0.10782596 -0.21882023]]. Action = [[ 0.08082139 -0.07374824  0.          0.3502574 ]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 8276 is [True, False, False, True, False, False]
Current timestep = 8277. State = [[-0.10279562 -0.21722625]]. Action = [[ 0.07914322  0.08691242  0.         -0.65766424]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 8277 is [True, False, False, True, False, False]
State prediction error at timestep 8277 is 0.012
Human Feedback received at timestep 8277 of None
Current timestep = 8278. State = [[-0.09930768 -0.2109925 ]]. Action = [[0.04174262 0.08236993 0.         0.8617649 ]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 8278 is [True, False, False, True, False, False]
Current timestep = 8279. State = [[-0.09799118 -0.20610146]]. Action = [[0.01628272 0.04370122 0.         0.13288283]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 8279 is [True, False, False, True, False, False]
Current timestep = 8280. State = [[-0.09378526 -0.20037201]]. Action = [[0.08908605 0.07323243 0.         0.8250935 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 8280 is [True, False, False, True, False, False]
Current timestep = 8281. State = [[-0.09365693 -0.2009437 ]]. Action = [[-0.04044778 -0.07838559  0.         -0.73837847]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 8281 is [True, False, False, True, False, False]
Current timestep = 8282. State = [[-0.09796822 -0.20535558]]. Action = [[-0.06914012 -0.05531308  0.         -0.42946178]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 8282 is [True, False, False, True, False, False]
Current timestep = 8283. State = [[-0.09573188 -0.21060225]]. Action = [[ 0.08458873 -0.07582874  0.          0.22753775]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 8283 is [True, False, False, True, False, False]
Current timestep = 8284. State = [[-0.09074553 -0.20827383]]. Action = [[ 0.04449158  0.09520292  0.         -0.6844751 ]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 8284 is [True, False, False, True, False, False]
Current timestep = 8285. State = [[-0.08886671 -0.20529318]]. Action = [[-3.651306e-04  5.234435e-03  0.000000e+00  6.305562e-01]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 8285 is [True, False, False, True, False, False]
Current timestep = 8286. State = [[-0.08487792 -0.20412926]]. Action = [[ 0.06767934  0.01444616  0.         -0.53664935]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 8286 is [True, False, False, True, False, False]
State prediction error at timestep 8286 is 0.012
Human Feedback received at timestep 8286 of None
Current timestep = 8287. State = [[-0.08290771 -0.2032597 ]]. Action = [[-0.01176797  0.00416966  0.          0.9799924 ]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 8287 is [True, False, False, True, False, False]
Current timestep = 8288. State = [[-0.08427405 -0.20164849]]. Action = [[-0.04085163  0.02644246  0.         -0.8483693 ]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 8288 is [True, False, False, True, False, False]
Current timestep = 8289. State = [[-0.08889345 -0.19699948]]. Action = [[-0.09329412  0.07467627  0.          0.65928984]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 8289 is [True, False, False, True, False, False]
Current timestep = 8290. State = [[-0.09050184 -0.19668452]]. Action = [[ 0.00609102 -0.04948514  0.         -0.7822777 ]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 8290 is [True, False, False, True, False, False]
State prediction error at timestep 8290 is 0.012
Human Feedback received at timestep 8290 of None
Current timestep = 8291. State = [[-0.09167007 -0.19403853]]. Action = [[-0.04497727  0.07131194  0.          0.43718147]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 8291 is [True, False, False, True, False, False]
Current timestep = 8292. State = [[-0.09585075 -0.18854704]]. Action = [[-0.07779845  0.05756371  0.          0.7476771 ]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 8292 is [True, False, False, True, False, False]
State prediction error at timestep 8292 is 0.012
Human Feedback received at timestep 8292 of None
Current timestep = 8293. State = [[-0.09358849 -0.18643038]]. Action = [[ 0.09386418 -0.01911878  0.         -0.6767697 ]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 8293 is [True, False, False, True, False, False]
Current timestep = 8294. State = [[-0.08810712 -0.18962164]]. Action = [[ 0.05034476 -0.07254943  0.         -0.3790102 ]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 8294 is [True, False, False, True, False, False]
Current timestep = 8295. State = [[-0.08687718 -0.18935624]]. Action = [[-0.02319144  0.0424312   0.          0.5847683 ]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 8295 is [True, False, False, True, False, False]
State prediction error at timestep 8295 is 0.012
Human Feedback received at timestep 8295 of None
Current timestep = 8296. State = [[-0.08883974 -0.19190276]]. Action = [[-0.04238424 -0.07659615  0.          0.30897903]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 8296 is [True, False, False, True, False, False]
State prediction error at timestep 8296 is 0.012
Human Feedback received at timestep 8296 of None
Current timestep = 8297. State = [[-0.0880843  -0.19646099]]. Action = [[ 0.02890808 -0.04356315  0.         -0.08168137]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 8297 is [True, False, False, True, False, False]
State prediction error at timestep 8297 is 0.012
Human Feedback received at timestep 8297 of None
Current timestep = 8298. State = [[-0.0887036 -0.1980975]]. Action = [[-0.03708937  0.00439225  0.          0.8437016 ]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 8298 is [True, False, False, True, False, False]
State prediction error at timestep 8298 is 0.012
Human Feedback received at timestep 8298 of None
Current timestep = 8299. State = [[-0.08595012 -0.19356427]]. Action = [[ 0.07137594  0.09787478  0.         -0.7724587 ]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 8299 is [True, False, False, True, False, False]
Current timestep = 8300. State = [[-0.0874     -0.18709137]]. Action = [[-0.07220352  0.07151253  0.          0.8680222 ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 8300 is [True, False, False, True, False, False]
Current timestep = 8301. State = [[-0.09183273 -0.18545657]]. Action = [[-0.05207484 -0.01977631  0.          0.38852572]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 8301 is [True, False, False, True, False, False]
State prediction error at timestep 8301 is 0.012
Human Feedback received at timestep 8301 of None
Current timestep = 8302. State = [[-0.09308212 -0.18373832]]. Action = [[ 0.00906195  0.03352534  0.         -0.816579  ]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 8302 is [True, False, False, True, False, False]
Current timestep = 8303. State = [[-0.0898632  -0.18568638]]. Action = [[ 0.07249691 -0.07371577  0.         -0.12263328]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 8303 is [True, False, False, True, False, False]
Current timestep = 8304. State = [[-0.0898568  -0.18858899]]. Action = [[-0.03591204 -0.02316429  0.         -0.8128388 ]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 8304 is [True, False, False, True, False, False]
Current timestep = 8305. State = [[-0.0875602  -0.18882954]]. Action = [[ 0.07332135  0.00859635  0.         -0.8939062 ]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 8305 is [True, False, False, True, False, False]
Current timestep = 8306. State = [[-0.08724128 -0.18986483]]. Action = [[-0.02578865 -0.02683535  0.         -0.01727647]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 8306 is [True, False, False, True, False, False]
Current timestep = 8307. State = [[-0.09145151 -0.19537799]]. Action = [[-0.07149079 -0.08873601  0.          0.92981887]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 8307 is [True, False, False, True, False, False]
Current timestep = 8308. State = [[-0.09307549 -0.19867237]]. Action = [[ 0.00792275  0.00212076  0.         -0.18652642]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 8308 is [True, False, False, True, False, False]
State prediction error at timestep 8308 is 0.012
Human Feedback received at timestep 8308 of None
Current timestep = 8309. State = [[-0.0891138  -0.19676274]]. Action = [[ 0.08314031  0.05276278  0.         -0.00824732]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 8309 is [True, False, False, True, False, False]
Current timestep = 8310. State = [[-0.08320393 -0.19898912]]. Action = [[ 0.08245312 -0.06930929  0.         -0.15699345]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 8310 is [True, False, False, True, False, False]
Current timestep = 8311. State = [[-0.07732469 -0.20315976]]. Action = [[ 0.0776884  -0.03457683  0.         -0.48175   ]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 8311 is [True, False, False, True, False, False]
Current timestep = 8312. State = [[-0.07493288 -0.20669378]]. Action = [[ 0.00297973 -0.03249872  0.         -0.15111494]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 8312 is [True, False, False, True, False, False]
Current timestep = 8313. State = [[-0.07288983 -0.21235031]]. Action = [[ 0.03267216 -0.0713553   0.         -0.2943834 ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 8313 is [True, False, False, True, False, False]
Current timestep = 8314. State = [[-0.07594446 -0.21652229]]. Action = [[-0.09849726 -0.00929676  0.         -0.6062917 ]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 8314 is [True, False, False, True, False, False]
Current timestep = 8315. State = [[-0.07559209 -0.21374914]]. Action = [[ 0.05206459  0.09021076  0.         -0.85161304]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 8315 is [True, False, False, True, False, False]
Current timestep = 8316. State = [[-0.07611277 -0.21205434]]. Action = [[-0.04329559 -0.00527737  0.          0.09164095]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 8316 is [True, False, False, True, False, False]
Current timestep = 8317. State = [[-0.07879871 -0.2134821 ]]. Action = [[-0.04104596 -0.01732145  0.          0.05529201]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 8317 is [True, False, False, True, False, False]
Current timestep = 8318. State = [[-0.07742874 -0.21189657]]. Action = [[0.04538596 0.04932346 0.         0.6059048 ]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 8318 is [True, False, False, True, False, False]
Current timestep = 8319. State = [[-0.07997634 -0.21392374]]. Action = [[-0.08314022 -0.0673257   0.          0.20926166]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 8319 is [True, False, False, True, False, False]
Current timestep = 8320. State = [[-0.08368403 -0.21481991]]. Action = [[-0.03826636  0.02682158  0.          0.15916038]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 8320 is [True, False, False, True, False, False]
Current timestep = 8321. State = [[-0.08730171 -0.21807022]]. Action = [[-0.05536954 -0.07300558  0.          0.09098673]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 8321 is [True, False, False, True, False, False]
State prediction error at timestep 8321 is 0.012
Human Feedback received at timestep 8321 of None
Current timestep = 8322. State = [[-0.08784448 -0.21943644]]. Action = [[ 0.01962712  0.02299486  0.         -0.17851675]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 8322 is [True, False, False, True, False, False]
State prediction error at timestep 8322 is 0.012
Human Feedback received at timestep 8322 of None
Current timestep = 8323. State = [[-0.09096291 -0.21586536]]. Action = [[-0.07281462  0.06628647  0.         -0.9989978 ]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 8323 is [True, False, False, True, False, False]
Current timestep = 8324. State = [[-0.09133137 -0.21738885]]. Action = [[ 0.04761448 -0.07517576  0.         -0.47860837]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 8324 is [True, False, False, True, False, False]
State prediction error at timestep 8324 is 0.012
Human Feedback received at timestep 8324 of None
Current timestep = 8325. State = [[-0.09387081 -0.21525508]]. Action = [[-0.08407808  0.0939498   0.          0.12973714]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 8325 is [True, False, False, True, False, False]
State prediction error at timestep 8325 is 0.012
Human Feedback received at timestep 8325 of None
Current timestep = 8326. State = [[-0.09651434 -0.21114859]]. Action = [[ 0.0057611   0.0238141   0.         -0.30946845]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 8326 is [True, False, False, True, False, False]
Current timestep = 8327. State = [[-0.10021109 -0.2131116 ]]. Action = [[-0.05941324 -0.06693269  0.          0.36784708]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 8327 is [True, False, False, True, False, False]
Current timestep = 8328. State = [[-0.10383414 -0.21713734]]. Action = [[-0.02284932 -0.04646374  0.         -0.37104106]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 8328 is [True, False, False, True, False, False]
Current timestep = 8329. State = [[-0.10632847 -0.2220777 ]]. Action = [[-0.01744916 -0.06749038  0.          0.69428754]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 8329 is [True, False, False, True, False, False]
Current timestep = 8330. State = [[-0.10907863 -0.22799067]]. Action = [[-0.02648834 -0.06746543  0.          0.8221221 ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 8330 is [True, False, False, True, False, False]
State prediction error at timestep 8330 is 0.012
Human Feedback received at timestep 8330 of None
Current timestep = 8331. State = [[-0.11249838 -0.23479123]]. Action = [[-0.03537846 -0.075849    0.          0.7168344 ]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 8331 is [True, False, False, True, False, False]
Current timestep = 8332. State = [[-0.11110404 -0.23575233]]. Action = [[0.0703442  0.05158735 0.         0.80889106]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 8332 is [True, False, False, True, False, False]
State prediction error at timestep 8332 is 0.012
Human Feedback received at timestep 8332 of None
Current timestep = 8333. State = [[-0.10743687 -0.23418213]]. Action = [[ 0.05912095  0.02074955  0.         -0.31932932]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 8333 is [True, False, False, True, False, False]
Current timestep = 8334. State = [[-0.10608362 -0.23262389]]. Action = [[ 0.01431593  0.02940432  0.         -0.27592397]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 8334 is [True, False, False, True, False, False]
State prediction error at timestep 8334 is 0.012
Human Feedback received at timestep 8334 of None
Current timestep = 8335. State = [[-0.10527305 -0.23345803]]. Action = [[ 0.02650826 -0.02597571  0.          0.25107002]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 8335 is [True, False, False, True, False, False]
Current timestep = 8336. State = [[-0.10678855 -0.23407617]]. Action = [[-0.03167453  0.01005241  0.          0.00035691]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 8336 is [True, False, False, True, False, False]
Current timestep = 8337. State = [[-0.10500117 -0.23526673]]. Action = [[ 0.06634779 -0.02279796  0.         -0.2626127 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 8337 is [True, False, False, True, False, False]
Current timestep = 8338. State = [[-0.10656006 -0.23777506]]. Action = [[-0.0626516  -0.03010877  0.          0.6630572 ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 8338 is [True, False, False, True, False, False]
Current timestep = 8339. State = [[-0.10802191 -0.239755  ]]. Action = [[ 0.00758785 -0.0108454   0.         -0.66058123]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 8339 is [True, False, False, True, False, False]
State prediction error at timestep 8339 is 0.012
Human Feedback received at timestep 8339 of None
Current timestep = 8340. State = [[-0.10620436 -0.23932275]]. Action = [[ 0.03811803  0.0233105   0.         -0.648056  ]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 8340 is [True, False, False, True, False, False]
Current timestep = 8341. State = [[-0.10508287 -0.24217884]]. Action = [[ 0.00301009 -0.06655343  0.         -0.1216374 ]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 8341 is [True, False, False, True, False, False]
Current timestep = 8342. State = [[-0.10244711 -0.24679412]]. Action = [[ 0.05074584 -0.04595903  0.          0.36747062]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 8342 is [True, False, False, True, False, False]
Current timestep = 8343. State = [[-0.10257445 -0.25224248]]. Action = [[-0.03467343 -0.06612085  0.          0.996711  ]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 8343 is [True, False, False, True, False, False]
Current timestep = 8344. State = [[-0.1068306  -0.25605485]]. Action = [[-0.07628183 -0.01142652  0.         -0.6068806 ]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 8344 is [True, False, False, True, False, False]
State prediction error at timestep 8344 is 0.012
Human Feedback received at timestep 8344 of None
Current timestep = 8345. State = [[-0.10804162 -0.25851583]]. Action = [[ 0.01210213 -0.01246171  0.          0.4818654 ]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 8345 is [True, False, False, True, False, False]
Current timestep = 8346. State = [[-0.10340528 -0.2615174 ]]. Action = [[ 0.08726012 -0.03053212  0.         -0.5308452 ]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 8346 is [True, False, False, True, False, False]
Current timestep = 8347. State = [[-0.10247088 -0.26029405]]. Action = [[-0.03913238  0.06623247  0.         -0.49374157]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 8347 is [True, False, False, True, False, False]
Current timestep = 8348. State = [[-0.10269332 -0.2579435 ]]. Action = [[ 0.01667078  0.02182393  0.         -0.5548734 ]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 8348 is [True, False, False, True, False, False]
State prediction error at timestep 8348 is 0.012
Human Feedback received at timestep 8348 of None
Current timestep = 8349. State = [[-0.09958674 -0.26204613]]. Action = [[ 0.06044655 -0.0945897   0.          0.9850137 ]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 8349 is [True, False, False, True, False, False]
Current timestep = 8350. State = [[-0.10127808 -0.26627898]]. Action = [[-0.07437077 -0.01681877  0.          0.72249556]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 8350 is [True, False, False, True, False, False]
Current timestep = 8351. State = [[-0.09902292 -0.27163243]]. Action = [[ 0.09822997 -0.08827626  0.          0.5224148 ]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 8351 is [True, False, False, True, False, False]
Current timestep = 8352. State = [[-0.09497726 -0.27034035]]. Action = [[ 0.02268966  0.09790231  0.         -0.992233  ]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 8352 is [True, False, False, True, False, False]
Current timestep = 8353. State = [[-0.09665458 -0.27255753]]. Action = [[-0.05095989 -0.0898492   0.          0.18580449]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 8353 is [True, False, False, True, False, False]
Current timestep = 8354. State = [[-0.0936487 -0.2719387]]. Action = [[ 0.09168117  0.07488211  0.         -0.4999482 ]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 8354 is [True, False, False, True, False, False]
State prediction error at timestep 8354 is 0.012
Human Feedback received at timestep 8354 of None
Current timestep = 8355. State = [[-0.09197554 -0.26888096]]. Action = [[-0.0168448   0.02296354  0.          0.23674607]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 8355 is [True, False, False, True, False, False]
Current timestep = 8356. State = [[-0.09550878 -0.27097496]]. Action = [[-0.0698236  -0.05335962  0.         -0.21563613]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 8356 is [True, False, False, True, False, False]
Current timestep = 8357. State = [[-0.09674522 -0.2688275 ]]. Action = [[0.00823556 0.08097606 0.         0.8218403 ]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 8357 is [True, False, False, True, False, False]
State prediction error at timestep 8357 is 0.012
Human Feedback received at timestep 8357 of None
Current timestep = 8358. State = [[-0.0971811  -0.27033272]]. Action = [[-0.0171775  -0.07630832  0.         -0.9860662 ]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 8358 is [True, False, False, True, False, False]
Current timestep = 8359. State = [[-0.09702173 -0.27284238]]. Action = [[ 0.00798021 -0.00637171  0.          0.3594427 ]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 8359 is [True, False, False, True, False, False]
State prediction error at timestep 8359 is 0.012
Human Feedback received at timestep 8359 of None
Current timestep = 8360. State = [[-0.09509905 -0.2729529 ]]. Action = [[0.03154384 0.00577984 0.         0.5700474 ]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 8360 is [True, False, False, True, False, False]
State prediction error at timestep 8360 is 0.012
Human Feedback received at timestep 8360 of None
Current timestep = 8361. State = [[-0.09640871 -0.27663812]]. Action = [[-0.04855082 -0.07405785  0.         -0.8471745 ]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 8361 is [True, False, False, True, False, False]
State prediction error at timestep 8361 is 0.012
Human Feedback received at timestep 8361 of None
Current timestep = 8362. State = [[-0.09887146 -0.27700368]]. Action = [[-0.02802525  0.04704901  0.         -0.77316344]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 8362 is [True, False, False, True, False, False]
Current timestep = 8363. State = [[-0.10172412 -0.27336687]]. Action = [[-0.04471267  0.05769121  0.          0.38976586]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 8363 is [True, False, False, True, False, False]
State prediction error at timestep 8363 is 0.012
Human Feedback received at timestep 8363 of None
Current timestep = 8364. State = [[-0.10210457 -0.27527252]]. Action = [[ 0.0201246  -0.07292283  0.          0.36864102]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 8364 is [True, False, False, True, False, False]
Current timestep = 8365. State = [[-0.10518651 -0.28159747]]. Action = [[-0.07571042 -0.07826228  0.         -0.7846562 ]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 8365 is [True, False, False, True, False, False]
Current timestep = 8366. State = [[-0.10629315 -0.28866127]]. Action = [[ 0.01905565 -0.07566097  0.          0.41120172]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 8366 is [True, False, False, True, False, False]
Current timestep = 8367. State = [[-0.10701674 -0.29358694]]. Action = [[-0.02146526 -0.02896213  0.         -0.1671983 ]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 8367 is [True, False, False, True, False, False]
Current timestep = 8368. State = [[-0.10855094 -0.29536873]]. Action = [[-0.01627348  0.01142843  0.         -0.92065066]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 8368 is [True, False, False, True, False, False]
Current timestep = 8369. State = [[-0.1081146  -0.29931515]]. Action = [[ 0.02575522 -0.05898068  0.          0.67519283]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 8369 is [True, False, False, True, False, False]
State prediction error at timestep 8369 is 0.012
Human Feedback received at timestep 8369 of None
Current timestep = 8370. State = [[-0.10991916 -0.3034369 ]]. Action = [[-0.04265527 -0.02150646  0.          0.24514103]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 8370 is [True, False, False, True, False, False]
State prediction error at timestep 8370 is 0.012
Human Feedback received at timestep 8370 of None
Current timestep = 8371. State = [[-0.11368935 -0.30088007]]. Action = [[-0.04574987  0.09634864  0.          0.7073469 ]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 8371 is [True, False, False, True, False, False]
Current timestep = 8372. State = [[-0.11249454 -0.29750884]]. Action = [[0.06414676 0.0271742  0.         0.7107127 ]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 8372 is [True, False, False, True, False, False]
Current timestep = 8373. State = [[-0.10840123 -0.29319906]]. Action = [[0.05639572 0.06855739 0.         0.89950204]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 8373 is [True, False, False, True, False, False]
Current timestep = 8374. State = [[-0.10614162 -0.29091176]]. Action = [[ 0.01896705 -0.005037    0.          0.0582577 ]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 8374 is [True, False, False, True, False, False]
State prediction error at timestep 8374 is 0.012
Human Feedback received at timestep 8374 of None
Current timestep = 8375. State = [[-0.10138644 -0.28627408]]. Action = [[ 0.09106476  0.07717168  0.         -0.2272498 ]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 8375 is [True, False, False, True, False, False]
Current timestep = 8376. State = [[-0.09655534 -0.28620547]]. Action = [[ 0.05224783 -0.07034361  0.          0.31400228]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 8376 is [True, False, False, True, False, False]
State prediction error at timestep 8376 is 0.012
Human Feedback received at timestep 8376 of None
Current timestep = 8377. State = [[-0.09670238 -0.2853623 ]]. Action = [[-0.03813282  0.03859415  0.          0.3355006 ]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 8377 is [True, False, False, True, False, False]
Current timestep = 8378. State = [[-0.09889126 -0.2844754 ]]. Action = [[-0.02306036 -0.0197247   0.          0.34867084]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 8378 is [True, False, False, True, False, False]
Current timestep = 8379. State = [[-0.10224807 -0.28568166]]. Action = [[-0.05538905 -0.0258569   0.          0.7579917 ]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 8379 is [True, False, False, True, False, False]
Current timestep = 8380. State = [[-0.1007367  -0.28885648]]. Action = [[ 0.06246925 -0.05678749  0.          0.6177056 ]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 8380 is [True, False, False, True, False, False]
Current timestep = 8381. State = [[-0.09695128 -0.29526165]]. Action = [[ 0.04055765 -0.09827419  0.         -0.14787239]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 8381 is [True, False, False, True, False, False]
Current timestep = 8382. State = [[-0.09720422 -0.30003142]]. Action = [[-0.03671167 -0.02587799  0.          0.12364256]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 8382 is [True, False, False, True, False, False]
Current timestep = 8383. State = [[-0.09849541 -0.29811826]]. Action = [[-0.01239244  0.0764072   0.         -0.8567849 ]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 8383 is [True, False, False, True, False, False]
Current timestep = 8384. State = [[-0.10016505 -0.29986414]]. Action = [[-0.03134181 -0.06128429  0.          0.27787805]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 8384 is [True, False, False, True, False, False]
Current timestep = 8385. State = [[-0.09998231 -0.30073035]]. Action = [[ 0.01808107  0.03336561  0.         -0.12563348]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 8385 is [True, False, False, True, False, False]
Current timestep = 8386. State = [[-0.10364982 -0.30130944]]. Action = [[-0.08917554 -0.0136793   0.          0.82781446]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 8386 is [True, False, False, True, False, False]
Current timestep = 8387. State = [[-0.1091579 -0.3009582]]. Action = [[-0.06765947  0.03294658  0.          0.05822289]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 8387 is [True, False, False, True, False, False]
State prediction error at timestep 8387 is 0.012
Human Feedback received at timestep 8387 of None
Current timestep = 8388. State = [[-0.10988134 -0.29708323]]. Action = [[0.02453746 0.07044172 0.         0.05990028]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 8388 is [True, False, False, True, False, False]
Current timestep = 8389. State = [[-0.10879759 -0.29288417]]. Action = [[ 0.01147799  0.03847831  0.         -0.71624446]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 8389 is [True, False, False, True, False, False]
Current timestep = 8390. State = [[-0.10710232 -0.29490554]]. Action = [[ 0.03229084 -0.07790367  0.          0.73966   ]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 8390 is [True, False, False, True, False, False]
Current timestep = 8391. State = [[-0.10988456 -0.29916304]]. Action = [[-0.06998707 -0.0471369   0.          0.8600904 ]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 8391 is [True, False, False, True, False, False]
Current timestep = 8392. State = [[-0.11399037 -0.299865  ]]. Action = [[-0.03824171  0.02013062  0.         -0.1464392 ]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 8392 is [True, False, False, True, False, False]
Current timestep = 8393. State = [[-0.11316698 -0.30130756]]. Action = [[ 0.05089512 -0.03768948  0.          0.5658082 ]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 8393 is [True, False, False, True, False, False]
Current timestep = 8394. State = [[-0.11159358 -0.3016876 ]]. Action = [[0.0135896  0.01478823 0.         0.43253648]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 8394 is [True, False, False, True, False, False]
Current timestep = 8395. State = [[-0.10754667 -0.297779  ]]. Action = [[ 0.08289187  0.06863622  0.         -0.88616264]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 8395 is [True, False, False, True, False, False]
Current timestep = 8396. State = [[-0.10926567 -0.2970239 ]]. Action = [[-0.07541582 -0.03278764  0.         -0.54323334]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 8396 is [True, False, False, True, False, False]
Current timestep = 8397. State = [[-0.11601353 -0.30133587]]. Action = [[-0.09198339 -0.06513281  0.          0.4832704 ]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 8397 is [True, False, False, True, False, False]
State prediction error at timestep 8397 is 0.012
Human Feedback received at timestep 8397 of None
Current timestep = 8398. State = [[-0.1236741  -0.30455932]]. Action = [[-0.09739026 -0.01204238  0.          0.20579243]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 8398 is [True, False, False, True, False, False]
State prediction error at timestep 8398 is 0.012
Human Feedback received at timestep 8398 of None
Current timestep = 8399. State = [[-0.12734447 -0.30238873]]. Action = [[-0.00983015  0.06771106  0.         -0.25663197]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 8399 is [True, False, False, True, False, False]
Current timestep = 8400. State = [[-0.12379809 -0.29802775]]. Action = [[ 0.09236314  0.0484939   0.         -0.8697725 ]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 8400 is [True, False, False, True, False, False]
State prediction error at timestep 8400 is 0.012
Human Feedback received at timestep 8400 of None
Current timestep = 8401. State = [[-0.11859503 -0.2933391 ]]. Action = [[ 0.06619417  0.04821355  0.         -0.10763597]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 8401 is [True, False, False, True, False, False]
State prediction error at timestep 8401 is 0.012
Human Feedback received at timestep 8401 of None
Current timestep = 8402. State = [[-0.12068905 -0.29102692]]. Action = [[-7.2936498e-02 -7.5402856e-04  0.0000000e+00  9.0575767e-01]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 8402 is [True, False, False, True, False, False]
Current timestep = 8403. State = [[-0.12304784 -0.29140413]]. Action = [[ 0.00132133 -0.02058836  0.          0.8464676 ]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 8403 is [True, False, False, True, False, False]
Current timestep = 8404. State = [[-0.12235982 -0.29513258]]. Action = [[ 0.02551685 -0.07529075  0.         -0.50199914]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 8404 is [True, False, False, True, False, False]
State prediction error at timestep 8404 is 0.012
Human Feedback received at timestep 8404 of None
Current timestep = 8405. State = [[-0.12194859 -0.2950177 ]]. Action = [[ 0.002418    0.04007956  0.         -0.11235368]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 8405 is [True, False, False, True, False, False]
Current timestep = 8406. State = [[-0.11841176 -0.29068255]]. Action = [[0.07916922 0.05677428 0.         0.15351486]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 8406 is [True, False, False, True, False, False]
Current timestep = 8407. State = [[-0.11426554 -0.288871  ]]. Action = [[ 0.04785419 -0.01467969  0.          0.09058559]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 8407 is [True, False, False, True, False, False]
Current timestep = 8408. State = [[-0.11017225 -0.28656793]]. Action = [[ 0.05973854  0.03652253  0.         -0.29556942]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 8408 is [True, False, False, True, False, False]
State prediction error at timestep 8408 is 0.012
Human Feedback received at timestep 8408 of None
Current timestep = 8409. State = [[-0.10390303 -0.28306964]]. Action = [[0.09619295 0.02950601 0.         0.5701834 ]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 8409 is [True, False, False, True, False, False]
Current timestep = 8410. State = [[-0.10081823 -0.27658042]]. Action = [[0.00562961 0.09103008 0.         0.53153694]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 8410 is [True, False, False, True, False, False]
Current timestep = 8411. State = [[-0.09725343 -0.2755497 ]]. Action = [[ 0.06734126 -0.06091924  0.          0.77987885]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 8411 is [True, False, False, True, False, False]
State prediction error at timestep 8411 is 0.012
Human Feedback received at timestep 8411 of None
Current timestep = 8412. State = [[-0.09915304 -0.27574554]]. Action = [[-0.09798428  0.01773067  0.         -0.95010823]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 8412 is [True, False, False, True, False, False]
Current timestep = 8413. State = [[-0.10242257 -0.27883977]]. Action = [[-0.02308438 -0.08415726  0.          0.48552048]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 8413 is [True, False, False, True, False, False]
Current timestep = 8414. State = [[-0.10741029 -0.2817265 ]]. Action = [[-0.09869572 -0.01272354  0.         -0.831111  ]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 8414 is [True, False, False, True, False, False]
Current timestep = 8415. State = [[-0.11368862 -0.28634003]]. Action = [[-0.08443657 -0.07545114  0.          0.43528807]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 8415 is [True, False, False, True, False, False]
Current timestep = 8416. State = [[-0.11930789 -0.28851345]]. Action = [[-0.07316795  0.01714151  0.         -0.03373814]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 8416 is [True, False, False, True, False, False]
Current timestep = 8417. State = [[-0.12327586 -0.285485  ]]. Action = [[-0.04136355  0.0711185   0.          0.6879796 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 8417 is [True, False, False, True, False, False]
Current timestep = 8418. State = [[-0.12059519 -0.2875281 ]]. Action = [[ 0.09679719 -0.08647186  0.          0.40668607]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 8418 is [True, False, False, True, False, False]
Current timestep = 8419. State = [[-0.11875421 -0.2924957 ]]. Action = [[-0.01999513 -0.03705933  0.         -0.48946178]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 8419 is [True, False, False, True, False, False]
Current timestep = 8420. State = [[-0.11725006 -0.29945   ]]. Action = [[ 0.03474196 -0.09249043  0.          0.19287539]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 8420 is [True, False, False, True, False, False]
Current timestep = 8421. State = [[-0.11867385 -0.3072723 ]]. Action = [[-0.05000329 -0.07254378  0.          0.24399424]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 8421 is [True, False, False, True, False, False]
Current timestep = 8422. State = [[-0.12186168 -0.311133  ]]. Action = [[-0.03796012  0.00698356  0.         -0.8616274 ]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 8422 is [True, False, False, True, False, False]
Current timestep = 8423. State = [[-0.12316439 -0.31342918]]. Action = [[-0.00161868 -0.00869771  0.          0.51771736]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 8423 is [True, False, False, True, False, False]
Current timestep = 8424. State = [[-0.12205846 -0.31965363]]. Action = [[ 0.03044809 -0.08718373  0.          0.28794873]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 8424 is [True, False, False, True, False, False]
Current timestep = 8425. State = [[-0.12568766 -0.32861477]]. Action = [[-0.0841101  -0.09293445  0.         -0.496033  ]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 8425 is [True, False, False, True, False, False]
State prediction error at timestep 8425 is 0.012
Human Feedback received at timestep 8425 of None
Current timestep = 8426. State = [[-0.13001594 -0.32920235]]. Action = [[-0.03452479  0.09163516  0.         -0.20192587]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 8426 is [True, False, False, True, False, False]
State prediction error at timestep 8426 is 0.012
Human Feedback received at timestep 8426 of None
Current timestep = 8427. State = [[-0.12999378 -0.32501578]]. Action = [[0.03188834 0.06884464 0.         0.72249293]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 8427 is [True, False, False, True, False, False]
Current timestep = 8428. State = [[-0.12688808 -0.3221305 ]]. Action = [[ 0.05648332  0.02764607  0.         -0.45088696]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 8428 is [True, False, False, True, False, False]
Current timestep = 8429. State = [[-0.12576653 -0.3186689 ]]. Action = [[-0.00115255  0.05054937  0.         -0.06781375]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 8429 is [True, False, False, True, False, False]
State prediction error at timestep 8429 is 0.012
Human Feedback received at timestep 8429 of None
Current timestep = 8430. State = [[-0.1249036 -0.3145218]]. Action = [[0.02448833 0.04486438 0.         0.4575801 ]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 8430 is [True, False, False, True, False, False]
State prediction error at timestep 8430 is 0.012
Human Feedback received at timestep 8430 of None
Current timestep = 8431. State = [[-0.12179137 -0.31245917]]. Action = [[ 0.05653407 -0.00502297  0.          0.79799414]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 8431 is [True, False, False, True, False, False]
Current timestep = 8432. State = [[-0.12416623 -0.31051913]]. Action = [[-0.07841372  0.02211765  0.         -0.70117694]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 8432 is [True, False, False, True, False, False]
Current timestep = 8433. State = [[-0.13057697 -0.30737865]]. Action = [[-0.08269341  0.03561204  0.         -0.5756235 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 8433 is [True, False, False, True, False, False]
Current timestep = 8434. State = [[-0.13468872 -0.30057755]]. Action = [[-0.02818588  0.09911665  0.         -0.7712743 ]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 8434 is [True, False, False, True, False, False]
Current timestep = 8435. State = [[-0.13401982 -0.2994242 ]]. Action = [[ 0.04652237 -0.06985456  0.         -0.13857591]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 8435 is [True, False, False, True, False, False]
Current timestep = 8436. State = [[-0.13290401 -0.29980737]]. Action = [[-0.00151869  0.00635406  0.          0.90335464]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 8436 is [True, False, False, True, False, False]
Current timestep = 8437. State = [[-0.13177887 -0.29914442]]. Action = [[ 0.02255392 -0.00516672  0.          0.01061714]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 8437 is [True, False, False, True, False, False]
Current timestep = 8438. State = [[-0.13490508 -0.29702264]]. Action = [[-0.07700177  0.03399944  0.          0.6896795 ]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 8438 is [True, False, False, True, False, False]
Current timestep = 8439. State = [[-0.13545431 -0.29089937]]. Action = [[0.03566047 0.09240719 0.         0.6473446 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 8439 is [True, False, False, True, False, False]
Current timestep = 8440. State = [[-0.13429643 -0.28588986]]. Action = [[ 0.01026627  0.02373041  0.         -0.7575868 ]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 8440 is [True, False, False, True, False, False]
Current timestep = 8441. State = [[-0.13514708 -0.28153256]]. Action = [[-0.01940203  0.04588912  0.          0.07578599]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 8441 is [True, False, False, True, False, False]
Current timestep = 8442. State = [[-0.13134986 -0.28055245]]. Action = [[ 0.09792956 -0.04019517  0.         -0.6017651 ]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 8442 is [True, False, False, True, False, False]
Current timestep = 8443. State = [[-0.13167845 -0.2767789 ]]. Action = [[-0.07196786  0.08291706  0.         -0.7016403 ]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 8443 is [True, False, False, True, False, False]
Current timestep = 8444. State = [[-0.13113175 -0.27091718]]. Action = [[0.06210635 0.03896912 0.         0.43520808]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 8444 is [True, False, False, True, False, False]
Current timestep = 8445. State = [[-0.12767461 -0.27220762]]. Action = [[ 0.05097479 -0.09008605  0.          0.7398567 ]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 8445 is [True, False, False, True, False, False]
Current timestep = 8446. State = [[-0.12632921 -0.2720575 ]]. Action = [[ 0.00568354  0.02636427  0.         -0.86479753]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 8446 is [True, False, False, True, False, False]
Current timestep = 8447. State = [[-0.13125767 -0.26859283]]. Action = [[-0.09905665  0.04032367  0.          0.681764  ]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 8447 is [True, False, False, True, False, False]
Current timestep = 8448. State = [[-0.13565026 -0.26327524]]. Action = [[-0.02601256  0.07049908  0.          0.5790119 ]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 8448 is [True, False, False, True, False, False]
Current timestep = 8449. State = [[-0.13976589 -0.26302308]]. Action = [[-0.05729191 -0.05317765  0.          0.8582803 ]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 8449 is [True, False, False, True, False, False]
Current timestep = 8450. State = [[-0.14057004 -0.26662073]]. Action = [[ 0.02543037 -0.05564968  0.          0.43713927]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 8450 is [True, False, False, True, False, False]
Current timestep = 8451. State = [[-0.13873209 -0.27216125]]. Action = [[ 0.03315093 -0.08571117  0.         -0.0364911 ]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 8451 is [True, False, False, True, False, False]
State prediction error at timestep 8451 is 0.012
Human Feedback received at timestep 8451 of None
Current timestep = 8452. State = [[-0.1379076 -0.2756441]]. Action = [[ 0.00429013 -0.01694433  0.          0.8565788 ]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 8452 is [True, False, False, True, False, False]
Current timestep = 8453. State = [[-0.13847499 -0.27310762]]. Action = [[-0.00837963  0.07380263  0.          0.46519303]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 8453 is [True, False, False, True, False, False]
Current timestep = 8454. State = [[-0.13440897 -0.2722641 ]]. Action = [[ 0.0995404  -0.02368628  0.         -0.87792265]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 8454 is [True, False, False, True, False, False]
Current timestep = 8455. State = [[-0.12768228 -0.2686172 ]]. Action = [[ 0.08395278  0.08445083  0.         -0.0833025 ]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 8455 is [True, False, False, True, False, False]
Current timestep = 8456. State = [[-0.1292978  -0.26566124]]. Action = [[-0.08543108  0.00935348  0.         -0.46451843]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 8456 is [True, False, False, True, False, False]
Current timestep = 8457. State = [[-0.13335775 -0.26741803]]. Action = [[-0.0405895  -0.03881751  0.          0.7210636 ]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 8457 is [True, False, False, True, False, False]
Current timestep = 8458. State = [[-0.13386628 -0.2722954 ]]. Action = [[ 0.01163985 -0.07145046  0.          0.7194884 ]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 8458 is [True, False, False, True, False, False]
Current timestep = 8459. State = [[-0.13349082 -0.2737817 ]]. Action = [[-0.00283799  0.01944418  0.          0.60062027]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 8459 is [True, False, False, True, False, False]
Current timestep = 8460. State = [[-0.1356247 -0.2700417]]. Action = [[-0.04805241  0.07392757  0.         -0.7832319 ]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 8460 is [True, False, False, True, False, False]
Current timestep = 8461. State = [[-0.13770068 -0.2675906 ]]. Action = [[-0.02005292  0.0093716   0.         -0.14125818]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 8461 is [True, False, False, True, False, False]
Current timestep = 8462. State = [[-0.14058214 -0.2631549 ]]. Action = [[-0.04908415  0.08020734  0.          0.8009589 ]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 8462 is [True, False, False, True, False, False]
Current timestep = 8463. State = [[-0.14388105 -0.26443624]]. Action = [[-0.03817582 -0.07930613  0.          0.19285631]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 8463 is [True, False, False, True, False, False]
State prediction error at timestep 8463 is 0.012
Human Feedback received at timestep 8463 of None
Current timestep = 8464. State = [[-0.14753671 -0.2672885 ]]. Action = [[-0.05051196 -0.01532385  0.         -0.14143133]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 8464 is [True, False, False, True, False, False]
State prediction error at timestep 8464 is 0.012
Human Feedback received at timestep 8464 of None
Current timestep = 8465. State = [[-0.15094039 -0.26837188]]. Action = [[-0.03620755 -0.00835083  0.          0.86400056]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 8465 is [True, False, False, True, False, False]
Current timestep = 8466. State = [[-0.15003173 -0.271902  ]]. Action = [[ 0.04838704 -0.06535248  0.          0.27482665]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 8466 is [True, False, False, True, False, False]
Current timestep = 8467. State = [[-0.14706297 -0.27868032]]. Action = [[ 0.04317785 -0.09656568  0.         -0.5369911 ]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 8467 is [True, False, False, True, False, False]
Current timestep = 8468. State = [[-0.14161786 -0.28617406]]. Action = [[ 0.09461503 -0.08414643  0.          0.5107479 ]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 8468 is [True, False, False, True, False, False]
Current timestep = 8469. State = [[-0.13688008 -0.2910338 ]]. Action = [[ 0.04940378 -0.02914171  0.         -0.56654716]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 8469 is [True, False, False, True, False, False]
Current timestep = 8470. State = [[-0.13358767 -0.29813185]]. Action = [[ 0.0424317  -0.09779374  0.          0.76571274]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 8470 is [True, False, False, True, False, False]
Current timestep = 8471. State = [[-0.13061357 -0.29893947]]. Action = [[0.0378535  0.07709806 0.         0.13032556]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 8471 is [True, False, False, True, False, False]
State prediction error at timestep 8471 is 0.012
Human Feedback received at timestep 8471 of None
Current timestep = 8472. State = [[-0.12665154 -0.30055183]]. Action = [[ 0.06409352 -0.04567934  0.         -0.68858165]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 8472 is [True, False, False, True, False, False]
Current timestep = 8473. State = [[-0.12449697 -0.30023128]]. Action = [[ 0.00662281  0.05745874  0.         -0.6312347 ]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 8473 is [True, False, False, True, False, False]
State prediction error at timestep 8473 is 0.012
Human Feedback received at timestep 8473 of None
Current timestep = 8474. State = [[-0.12678382 -0.2957889 ]]. Action = [[-0.05579611  0.08100007  0.         -0.31006813]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 8474 is [True, False, False, True, False, False]
Current timestep = 8475. State = [[-0.12365421 -0.29383808]]. Action = [[ 0.09585034 -0.00491367  0.         -0.85306346]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 8475 is [True, False, False, True, False, False]
Current timestep = 8476. State = [[-0.11908933 -0.29419065]]. Action = [[ 0.02392348 -0.00344639  0.          0.39914715]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 8476 is [True, False, False, True, False, False]
State prediction error at timestep 8476 is 0.012
Human Feedback received at timestep 8476 of None
Current timestep = 8477. State = [[-0.12121409 -0.29666588]]. Action = [[-0.0812665  -0.04110275  0.          0.2627052 ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 8477 is [True, False, False, True, False, False]
Current timestep = 8478. State = [[-0.11849856 -0.29974943]]. Action = [[ 0.0801843  -0.02990213  0.          0.976212  ]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 8478 is [True, False, False, True, False, False]
Current timestep = 8479. State = [[-0.11375903 -0.2977891 ]]. Action = [[ 0.02953451  0.0621077   0.         -0.17403203]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 8479 is [True, False, False, True, False, False]
State prediction error at timestep 8479 is 0.012
Human Feedback received at timestep 8479 of None
Current timestep = 8480. State = [[-0.10975131 -0.29526138]]. Action = [[ 0.03912897  0.01407339  0.         -0.7762365 ]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 8480 is [True, False, False, True, False, False]
Current timestep = 8481. State = [[-0.10664659 -0.29303345]]. Action = [[ 0.01716954  0.02912279  0.         -0.6162355 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 8481 is [True, False, False, True, False, False]
Current timestep = 8482. State = [[-0.10837887 -0.2902437 ]]. Action = [[-0.07022415  0.0329264   0.          0.8254242 ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 8482 is [True, False, False, True, False, False]
State prediction error at timestep 8482 is 0.012
Human Feedback received at timestep 8482 of None
Current timestep = 8483. State = [[-0.1088066  -0.29164132]]. Action = [[ 0.00860077 -0.05415675  0.         -0.0645678 ]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 8483 is [True, False, False, True, False, False]
Current timestep = 8484. State = [[-0.11052604 -0.29617482]]. Action = [[-0.060632  -0.0611311  0.         0.8414357]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 8484 is [True, False, False, True, False, False]
Current timestep = 8485. State = [[-0.10806382 -0.29428828]]. Action = [[ 0.0657896   0.07978342  0.         -0.6984836 ]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 8485 is [True, False, False, True, False, False]
Current timestep = 8486. State = [[-0.10803314 -0.28699377]]. Action = [[-0.05404934  0.0987341   0.          0.48723197]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 8486 is [True, False, False, True, False, False]
Current timestep = 8487. State = [[-0.11123084 -0.2824898 ]]. Action = [[-0.05163359  0.02163303  0.          0.37194073]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 8487 is [True, False, False, True, False, False]
State prediction error at timestep 8487 is 0.012
Human Feedback received at timestep 8487 of None
Current timestep = 8488. State = [[-0.10783846 -0.2795178 ]]. Action = [[0.09317055 0.02422614 0.         0.05256546]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 8488 is [True, False, False, True, False, False]
Current timestep = 8489. State = [[-0.10957547 -0.2770744 ]]. Action = [[-0.09897023  0.01533362  0.          0.20572305]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 8489 is [True, False, False, True, False, False]
Current timestep = 8490. State = [[-0.11636364 -0.28016344]]. Action = [[-0.08796392 -0.08669853  0.         -0.10045582]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 8490 is [True, False, False, True, False, False]
Current timestep = 8491. State = [[-0.11642535 -0.28349835]]. Action = [[ 0.0559017  -0.02547945  0.         -0.13358408]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 8491 is [True, False, False, True, False, False]
Current timestep = 8492. State = [[-0.11363871 -0.27916002]]. Action = [[0.03383745 0.09406798 0.         0.2743317 ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 8492 is [True, False, False, True, False, False]
Current timestep = 8493. State = [[-0.112979   -0.27620712]]. Action = [[ 0.00053002 -0.00889187  0.          0.4526136 ]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 8493 is [True, False, False, True, False, False]
Current timestep = 8494. State = [[-0.11549576 -0.2774129 ]]. Action = [[-0.0442388  -0.03240409  0.          0.76179147]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 8494 is [True, False, False, True, False, False]
Current timestep = 8495. State = [[-0.11953837 -0.27866367]]. Action = [[-0.04900816 -0.00852542  0.         -0.2737754 ]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 8495 is [True, False, False, True, False, False]
State prediction error at timestep 8495 is 0.012
Human Feedback received at timestep 8495 of None
Current timestep = 8496. State = [[-0.12607585 -0.28403115]]. Action = [[-0.09517038 -0.09763079  0.         -0.90114623]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 8496 is [True, False, False, True, False, False]
Current timestep = 8497. State = [[-0.13087597 -0.2868141 ]]. Action = [[-0.03188271  0.0151356   0.          0.498852  ]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 8497 is [True, False, False, True, False, False]
State prediction error at timestep 8497 is 0.012
Human Feedback received at timestep 8497 of None
Current timestep = 8498. State = [[-0.13457395 -0.28940928]]. Action = [[-0.04113588 -0.0429377   0.          0.5806589 ]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 8498 is [True, False, False, True, False, False]
Current timestep = 8499. State = [[-0.13539769 -0.2915824 ]]. Action = [[ 0.02389482 -0.00291754  0.         -0.60994744]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 8499 is [True, False, False, True, False, False]
State prediction error at timestep 8499 is 0.012
Human Feedback received at timestep 8499 of None
Current timestep = 8500. State = [[-0.13229899 -0.29462695]]. Action = [[ 0.07038017 -0.04656035  0.          0.35219204]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 8500 is [True, False, False, True, False, False]
Current timestep = 8501. State = [[-0.12866223 -0.29152977]]. Action = [[0.05230265 0.09845515 0.         0.43908632]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 8501 is [True, False, False, True, False, False]
State prediction error at timestep 8501 is 0.012
Human Feedback received at timestep 8501 of None
Current timestep = 8502. State = [[-0.12594615 -0.2920853 ]]. Action = [[ 0.04442655 -0.06701107  0.          0.28165913]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 8502 is [True, False, False, True, False, False]
Current timestep = 8503. State = [[-0.12197684 -0.2898087 ]]. Action = [[0.07188829 0.08052634 0.         0.14244366]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 8503 is [True, False, False, True, False, False]
State prediction error at timestep 8503 is 0.012
Human Feedback received at timestep 8503 of None
Current timestep = 8504. State = [[-0.11688861 -0.28936183]]. Action = [[ 0.0763232 -0.0440012  0.         0.3749497]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 8504 is [True, False, False, True, False, False]
State prediction error at timestep 8504 is 0.012
Human Feedback received at timestep 8504 of None
Current timestep = 8505. State = [[-0.11755253 -0.28682017]]. Action = [[-0.05848699  0.07694543  0.         -0.2817605 ]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 8505 is [True, False, False, True, False, False]
Current timestep = 8506. State = [[-0.12079741 -0.28511664]]. Action = [[-0.0226338  -0.01867025  0.          0.14609301]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 8506 is [True, False, False, True, False, False]
State prediction error at timestep 8506 is 0.012
Human Feedback received at timestep 8506 of None
Current timestep = 8507. State = [[-0.11848217 -0.28871444]]. Action = [[ 0.07482653 -0.07906161  0.         -0.0337171 ]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 8507 is [True, False, False, True, False, False]
Current timestep = 8508. State = [[-0.11476211 -0.2931861 ]]. Action = [[ 0.03904554 -0.0532435   0.          0.2992741 ]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 8508 is [True, False, False, True, False, False]
State prediction error at timestep 8508 is 0.012
Human Feedback received at timestep 8508 of None
Current timestep = 8509. State = [[-0.11462145 -0.29798025]]. Action = [[-0.02217674 -0.06059227  0.          0.743196  ]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 8509 is [True, False, False, True, False, False]
Current timestep = 8510. State = [[-0.11347144 -0.3008641 ]]. Action = [[ 0.03141924 -0.00774847  0.          0.7579465 ]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 8510 is [True, False, False, True, False, False]
Current timestep = 8511. State = [[-0.10877785 -0.3035419 ]]. Action = [[ 0.07304304 -0.03249701  0.          0.32746756]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 8511 is [True, False, False, True, False, False]
Current timestep = 8512. State = [[-0.10498816 -0.30857098]]. Action = [[ 0.02665363 -0.06542839  0.          0.99768794]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 8512 is [True, False, False, True, False, False]
State prediction error at timestep 8512 is 0.012
Human Feedback received at timestep 8512 of None
Current timestep = 8513. State = [[-0.10119424 -0.31653625]]. Action = [[ 0.04944807 -0.09781108  0.          0.32593846]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 8513 is [True, False, False, True, False, False]
Current timestep = 8514. State = [[-0.09904197 -0.3206996 ]]. Action = [[ 0.00120683  0.00760166  0.         -0.9943191 ]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 8514 is [True, False, False, True, False, False]
State prediction error at timestep 8514 is 0.012
Human Feedback received at timestep 8514 of None
Current timestep = 8515. State = [[-0.10097209 -0.32665256]]. Action = [[-0.05647353 -0.08318046  0.          0.8556938 ]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 8515 is [True, False, False, True, False, False]
Current timestep = 8516. State = [[-0.10050214 -0.33372608]]. Action = [[ 0.02661911 -0.05040387  0.         -0.5143557 ]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 8516 is [True, False, False, True, False, False]
Current timestep = 8517. State = [[-0.09478495 -0.33586836]]. Action = [[ 0.0888968   0.02970319  0.         -0.5725866 ]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 8517 is [True, False, False, True, False, False]
State prediction error at timestep 8517 is 0.012
Human Feedback received at timestep 8517 of None
Current timestep = 8518. State = [[-0.09252311 -0.33216745]]. Action = [[-0.02327791  0.09455421  0.         -0.37621576]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 8518 is [True, False, False, True, False, False]
Current timestep = 8519. State = [[-0.09663054 -0.32779822]]. Action = [[-0.09358782  0.05937668  0.          0.11234677]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 8519 is [True, False, False, True, False, False]
Current timestep = 8520. State = [[-0.09868123 -0.33129746]]. Action = [[ 0.00094285 -0.09781601  0.         -0.17789608]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 8520 is [True, False, False, True, False, False]
Current timestep = 8521. State = [[-0.09545159 -0.33681187]]. Action = [[ 0.04680432 -0.03758842  0.         -0.5002104 ]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 8521 is [True, False, False, True, False, False]
Current timestep = 8522. State = [[-0.08985598 -0.33700526]]. Action = [[ 0.06645047  0.03608107  0.         -0.61704993]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 8522 is [True, False, False, True, False, False]
State prediction error at timestep 8522 is 0.012
Human Feedback received at timestep 8522 of None
Current timestep = 8523. State = [[-0.0876848 -0.3403702]]. Action = [[-0.01505051 -0.07668585  0.         -0.51162446]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 8523 is [True, False, False, True, False, False]
State prediction error at timestep 8523 is 0.012
Human Feedback received at timestep 8523 of None
Current timestep = 8524. State = [[-0.08402464 -0.33870968]]. Action = [[0.06329655 0.09036591 0.         0.30652416]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 8524 is [True, False, False, True, False, False]
State prediction error at timestep 8524 is 0.012
Human Feedback received at timestep 8524 of None
Current timestep = 8525. State = [[-0.08486732 -0.333937  ]]. Action = [[-0.07295332  0.05218875  0.         -0.5363009 ]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 8525 is [True, False, False, True, False, False]
Current timestep = 8526. State = [[-0.08168069 -0.32990873]]. Action = [[0.0875942  0.04388598 0.         0.2917471 ]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 8526 is [True, False, False, True, False, False]
Current timestep = 8527. State = [[-0.08024871 -0.325571  ]]. Action = [[-0.03968811  0.04841428  0.         -0.21233767]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 8527 is [True, False, False, True, False, False]
Current timestep = 8528. State = [[-0.07621614 -0.31959894]]. Action = [[ 0.08213776  0.07207002  0.         -0.29502428]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 8528 is [True, False, False, True, False, False]
State prediction error at timestep 8528 is 0.012
Human Feedback received at timestep 8528 of None
Current timestep = 8529. State = [[-0.07265551 -0.3173837 ]]. Action = [[ 0.00975291 -0.02939446  0.         -0.03332955]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 8529 is [True, False, False, True, False, False]
State prediction error at timestep 8529 is 0.012
Human Feedback received at timestep 8529 of None
Current timestep = 8530. State = [[-0.07484515 -0.31273445]]. Action = [[-0.07582019  0.0873067   0.         -0.2651385 ]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 8530 is [True, False, False, True, False, False]
Current timestep = 8531. State = [[-0.07466573 -0.31080216]]. Action = [[ 0.03945283 -0.04573941  0.         -0.06896347]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 8531 is [True, False, False, True, False, False]
Current timestep = 8532. State = [[-0.07234354 -0.3100418 ]]. Action = [[0.01265761 0.01367308 0.         0.07311285]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 8532 is [True, False, False, True, False, False]
Current timestep = 8533. State = [[-0.07604038 -0.31226808]]. Action = [[-0.0999396  -0.06739153  0.          0.14952111]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 8533 is [True, False, False, True, False, False]
Current timestep = 8534. State = [[-0.08040068 -0.3091971 ]]. Action = [[-0.0484936   0.09734394  0.         -0.4672343 ]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 8534 is [True, False, False, True, False, False]
Current timestep = 8535. State = [[-0.07980324 -0.30849048]]. Action = [[ 0.0385088  -0.05495988  0.          0.15630794]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 8535 is [True, False, False, True, False, False]
Current timestep = 8536. State = [[-0.08251671 -0.3064434 ]]. Action = [[-0.09759475  0.07388548  0.         -0.09269476]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 8536 is [True, False, False, True, False, False]
Current timestep = 8537. State = [[-0.08685639 -0.29992253]]. Action = [[-0.04006722  0.08294731  0.          0.23250008]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 8537 is [True, False, False, True, False, False]
Current timestep = 8538. State = [[-0.09067848 -0.2996022 ]]. Action = [[-0.0503379  -0.05917637  0.         -0.8315619 ]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 8538 is [True, False, False, True, False, False]
Current timestep = 8539. State = [[-0.09408201 -0.30463022]]. Action = [[-0.0308992  -0.08017208  0.         -0.90594393]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 8539 is [True, False, False, True, False, False]
Current timestep = 8540. State = [[-0.09854908 -0.31100637]]. Action = [[-0.05800043 -0.08014855  0.          0.02765906]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 8540 is [True, False, False, True, False, False]
Current timestep = 8541. State = [[-0.10579802 -0.3163361 ]]. Action = [[-0.09671216 -0.04543094  0.          0.859614  ]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 8541 is [True, False, False, True, False, False]
Current timestep = 8542. State = [[-0.11219814 -0.31944832]]. Action = [[-0.05273918 -0.01246243  0.          0.8439709 ]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 8542 is [True, False, False, True, False, False]
Current timestep = 8543. State = [[-0.11526343 -0.31655425]]. Action = [[-0.00412163  0.08790568  0.         -0.70837605]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 8543 is [True, False, False, True, False, False]
Current timestep = 8544. State = [[-0.12021726 -0.3145901 ]]. Action = [[-6.816480e-02  7.258877e-04  0.000000e+00 -7.580846e-01]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 8544 is [True, False, False, True, False, False]
State prediction error at timestep 8544 is 0.012
Human Feedback received at timestep 8544 of None
Current timestep = 8545. State = [[-0.12047209 -0.31793037]]. Action = [[ 0.07205614 -0.06990633  0.          0.8326353 ]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 8545 is [True, False, False, True, False, False]
State prediction error at timestep 8545 is 0.012
Human Feedback received at timestep 8545 of None
Current timestep = 8546. State = [[-0.11864214 -0.32431906]]. Action = [[ 0.02940955 -0.08293737  0.         -0.8231174 ]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 8546 is [True, False, False, True, False, False]
State prediction error at timestep 8546 is 0.012
Human Feedback received at timestep 8546 of None
Current timestep = 8547. State = [[-0.1177639 -0.3316169]]. Action = [[ 0.02738323 -0.08424526  0.          0.5883838 ]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 8547 is [True, False, False, True, False, False]
State prediction error at timestep 8547 is 0.012
Human Feedback received at timestep 8547 of None
Current timestep = 8548. State = [[-0.12018131 -0.33539718]]. Action = [[-0.04135899 -0.0011422   0.          0.38155603]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 8548 is [True, False, False, True, False, False]
Current timestep = 8549. State = [[-0.12467574 -0.3354274 ]]. Action = [[-0.04303762  0.02943256  0.          0.8790095 ]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 8549 is [True, False, False, True, False, False]
Current timestep = 8550. State = [[-0.12771174 -0.3386578 ]]. Action = [[-0.01067383 -0.05801097  0.         -0.4605847 ]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 8550 is [True, False, False, True, False, False]
State prediction error at timestep 8550 is 0.012
Human Feedback received at timestep 8550 of None
Current timestep = 8551. State = [[-0.13294606 -0.3405855 ]]. Action = [[-0.07745703  0.0198027   0.         -0.7816936 ]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 8551 is [True, False, False, True, False, False]
Current timestep = 8552. State = [[-0.14070058 -0.34316468]]. Action = [[-0.09178775 -0.03501381  0.          0.40344334]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 8552 is [True, False, False, True, False, False]
Current timestep = 8553. State = [[-0.14173727 -0.34511313]]. Action = [[ 0.05654513  0.0032592   0.         -0.8704694 ]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 8553 is [True, False, False, True, False, False]
Current timestep = 8554. State = [[-0.14129691 -0.34567186]]. Action = [[0.         0.         0.         0.88634634]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 8554 is [True, False, False, True, False, False]
Current timestep = 8555. State = [[-0.14203335 -0.34200326]]. Action = [[ 0.00233532  0.08257755  0.         -0.3256278 ]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 8555 is [True, False, False, True, False, False]
Current timestep = 8556. State = [[-0.1404096  -0.33643955]]. Action = [[0.04908162 0.06165641 0.         0.05125439]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 8556 is [True, False, False, True, False, False]
Current timestep = 8557. State = [[-0.14216913 -0.32897255]]. Action = [[-0.0500751   0.09944328  0.         -0.27482843]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 8557 is [True, False, False, True, False, False]
Current timestep = 8558. State = [[-0.14897181 -0.32630977]]. Action = [[-0.09735023 -0.02207541  0.         -0.16545266]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 8558 is [True, False, False, True, False, False]
Current timestep = 8559. State = [[-0.15306194 -0.32622212]]. Action = [[-0.01124892 -0.00546774  0.         -0.7148064 ]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 8559 is [True, False, False, True, False, False]
State prediction error at timestep 8559 is 0.012
Human Feedback received at timestep 8559 of None
Current timestep = 8560. State = [[-0.15897147 -0.32894802]]. Action = [[-0.09590366 -0.06794488  0.          0.23925948]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 8560 is [True, False, False, True, False, False]
State prediction error at timestep 8560 is 0.012
Human Feedback received at timestep 8560 of None
Current timestep = 8561. State = [[-0.16122076 -0.33019248]]. Action = [[ 0.02645341  0.00468514  0.         -0.6268725 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 8561 is [True, False, False, True, False, False]
Current timestep = 8562. State = [[-0.15678863 -0.33179453]]. Action = [[ 0.09531964 -0.04919003  0.          0.5064802 ]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 8562 is [True, False, False, True, False, False]
State prediction error at timestep 8562 is 0.012
Human Feedback received at timestep 8562 of None
Current timestep = 8563. State = [[-0.15556958 -0.32820964]]. Action = [[-0.02227525  0.09469082  0.          0.6490369 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 8563 is [True, False, False, True, False, False]
Current timestep = 8564. State = [[-0.1590841  -0.32354468]]. Action = [[-0.03658611  0.02181413  0.          0.94126153]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 8564 is [True, False, False, True, False, False]
Current timestep = 8565. State = [[-0.15888551 -0.32498798]]. Action = [[ 0.05387398 -0.06871979  0.          0.43855786]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 8565 is [True, False, False, True, False, False]
Current timestep = 8566. State = [[-0.15417343 -0.32602862]]. Action = [[ 0.08640074 -0.00303259  0.          0.22430086]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 8566 is [True, False, False, True, False, False]
State prediction error at timestep 8566 is 0.012
Human Feedback received at timestep 8566 of None
Current timestep = 8567. State = [[-0.15530291 -0.32507718]]. Action = [[-0.06001419  0.01015086  0.          0.60499084]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 8567 is [True, False, False, True, False, False]
Current timestep = 8568. State = [[-0.15822414 -0.3198705 ]]. Action = [[-0.01147757  0.09364914  0.          0.34447992]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 8568 is [True, False, False, True, False, False]
State prediction error at timestep 8568 is 0.012
Human Feedback received at timestep 8568 of None
Current timestep = 8569. State = [[-0.1623028  -0.31334057]]. Action = [[-0.06025406  0.06891745  0.          0.5075824 ]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 8569 is [True, False, False, True, False, False]
Current timestep = 8570. State = [[-0.16610272 -0.30975822]]. Action = [[-0.02954637  0.01602252  0.          0.18926275]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 8570 is [True, False, False, True, False, False]
Current timestep = 8571. State = [[-0.16570957 -0.31162885]]. Action = [[ 0.03900523 -0.07057021  0.          0.04317427]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 8571 is [True, False, False, True, False, False]
Current timestep = 8572. State = [[-0.16898164 -0.3091768 ]]. Action = [[-0.08900194  0.08478781  0.          0.61065304]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 8572 is [True, False, False, True, False, False]
Current timestep = 8573. State = [[-0.17226869 -0.3045232 ]]. Action = [[0.00267871 0.02603234 0.         0.72693586]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 8573 is [True, False, False, True, False, False]
State prediction error at timestep 8573 is 0.012
Human Feedback received at timestep 8573 of None
Current timestep = 8574. State = [[-0.17816731 -0.29924518]]. Action = [[-0.09715506  0.06500392  0.          0.14844775]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 8574 is [True, False, False, True, False, False]
Current timestep = 8575. State = [[-0.18130022 -0.2931342 ]]. Action = [[ 0.01737596  0.05940131  0.         -0.692467  ]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 8575 is [True, False, False, True, False, False]
Current timestep = 8576. State = [[-0.18610425 -0.29047447]]. Action = [[-0.0795448  -0.01407084  0.          0.7910336 ]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 8576 is [True, False, False, True, False, False]
Current timestep = 8577. State = [[-0.19309552 -0.29107133]]. Action = [[-0.07033819 -0.03009901  0.         -0.02913803]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 8577 is [True, False, False, True, False, False]
State prediction error at timestep 8577 is 0.012
Human Feedback received at timestep 8577 of None
Current timestep = 8578. State = [[-0.20074917 -0.29356116]]. Action = [[-0.08529888 -0.04917327  0.          0.27116704]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 8578 is [True, False, False, True, False, False]
State prediction error at timestep 8578 is 0.012
Human Feedback received at timestep 8578 of None
Current timestep = 8579. State = [[-0.20618106 -0.29852384]]. Action = [[-0.03080644 -0.07962768  0.          0.07941735]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 8579 is [True, False, False, True, False, False]
State prediction error at timestep 8579 is 0.012
Human Feedback received at timestep 8579 of None
Current timestep = 8580. State = [[-0.211191   -0.29623434]]. Action = [[-0.05642555  0.09647261  0.          0.37072587]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 8580 is [True, False, False, True, False, False]
Current timestep = 8581. State = [[-0.21351373 -0.29495436]]. Action = [[ 0.02597993 -0.03966922  0.          0.05228114]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 8581 is [True, False, False, True, False, False]
Current timestep = 8582. State = [[-0.21525414 -0.2958136 ]]. Action = [[-0.01705005 -0.00517795  0.         -0.45405853]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 8582 is [True, False, False, True, False, False]
Current timestep = 8583. State = [[-0.22076897 -0.2984569 ]]. Action = [[-0.07161439 -0.05074026  0.          0.5699892 ]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 8583 is [True, False, False, True, False, False]
Current timestep = 8584. State = [[-0.22453934 -0.29925978]]. Action = [[-0.00269058  0.01822247  0.         -0.65339535]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 8584 is [True, False, False, True, False, False]
State prediction error at timestep 8584 is 0.012
Human Feedback received at timestep 8584 of None
Current timestep = 8585. State = [[-0.23006144 -0.30387604]]. Action = [[-0.07727637 -0.09594491  0.          0.7670398 ]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 8585 is [True, False, False, True, False, False]
State prediction error at timestep 8585 is 0.012
Human Feedback received at timestep 8585 of None
Current timestep = 8586. State = [[-0.23291118 -0.30260766]]. Action = [[0.01665027 0.09378368 0.         0.02252316]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 8586 is [True, False, False, True, False, False]
Current timestep = 8587. State = [[-0.23842227 -0.3018189 ]]. Action = [[-0.08779436 -0.02791021  0.          0.93018734]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 8587 is [True, False, False, True, False, False]
Current timestep = 8588. State = [[-0.23899248 -0.30720216]]. Action = [[ 0.07250548 -0.09467676  0.          0.91691554]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 8588 is [True, False, False, True, False, False]
Current timestep = 8589. State = [[-0.23754093 -0.30953467]]. Action = [[ 0.00832264  0.0161873   0.         -0.63434243]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 8589 is [True, False, False, True, False, False]
State prediction error at timestep 8589 is 0.012
Human Feedback received at timestep 8589 of None
Current timestep = 8590. State = [[-0.24110247 -0.30736023]]. Action = [[-0.0582311   0.04837372  0.         -0.16878486]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 8590 is [True, False, False, True, False, False]
Current timestep = 8591. State = [[-0.24071257 -0.3044918 ]]. Action = [[0.06479868 0.0372547  0.         0.98475146]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 8591 is [True, False, False, True, False, False]
Current timestep = 8592. State = [[-0.23908867 -0.30423325]]. Action = [[ 0.01430664 -0.02281507  0.          0.06842387]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 8592 is [True, False, False, True, False, False]
Current timestep = 8593. State = [[-0.24328105 -0.30304664]]. Action = [[-0.07896934  0.0350601   0.         -0.5413265 ]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 8593 is [True, False, False, True, False, False]
Current timestep = 8594. State = [[-0.2441334 -0.3052004]]. Action = [[ 0.04988975 -0.07038859  0.          0.6935468 ]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 8594 is [True, False, False, True, False, False]
Current timestep = 8595. State = [[-0.2458528  -0.30773005]]. Action = [[-0.05298491 -0.0103727   0.          0.7973201 ]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 8595 is [True, False, False, True, False, False]
Current timestep = 8596. State = [[-0.25261894 -0.3094373 ]]. Action = [[-0.09710368 -0.01510355  0.         -0.03372526]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 8596 is [True, False, False, True, False, False]
Current timestep = 8597. State = [[-0.25256512 -0.3120292 ]]. Action = [[ 0.0709477  -0.03219401  0.         -0.51707757]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 8597 is [True, False, False, True, False, False]
Current timestep = 8598. State = [[-0.25382292 -0.31749195]]. Action = [[-0.05951226 -0.08367667  0.          0.16867757]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 8598 is [True, False, False, True, False, False]
Current timestep = 8599. State = [[-0.25316462 -0.32529205]]. Action = [[ 0.04953272 -0.09334175  0.         -0.43824863]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 8599 is [True, False, False, True, False, False]
Current timestep = 8600. State = [[-0.25381714 -0.33399817]]. Action = [[-0.04030595 -0.09952004  0.          0.47332716]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 8600 is [True, False, False, True, False, False]
State prediction error at timestep 8600 is 0.012
Human Feedback received at timestep 8600 of None
Current timestep = 8601. State = [[-0.25633547 -0.33444893]]. Action = [[-0.02785159  0.09370437  0.          0.5975063 ]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 8601 is [True, False, False, True, False, False]
State prediction error at timestep 8601 is 0.012
Human Feedback received at timestep 8601 of None
Current timestep = 8602. State = [[-0.25873643 -0.33011606]]. Action = [[-0.01503272  0.06804021  0.         -0.20272452]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 8602 is [True, False, False, True, False, False]
State prediction error at timestep 8602 is 0.012
Human Feedback received at timestep 8602 of None
Current timestep = 8603. State = [[-0.25986096 -0.33010787]]. Action = [[ 0.00509693 -0.02605846  0.          0.182989  ]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 8603 is [True, False, False, True, False, False]
Current timestep = 8604. State = [[-0.26438534 -0.32957137]]. Action = [[-0.07832933  0.03712957  0.         -0.0560804 ]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 8604 is [True, False, False, True, False, False]
State prediction error at timestep 8604 is 0.012
Human Feedback received at timestep 8604 of None
Current timestep = 8605. State = [[-0.2714237  -0.32897446]]. Action = [[-0.07559048  0.0058917   0.         -0.408342  ]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 8605 is [True, False, False, True, False, False]
Current timestep = 8606. State = [[-0.2702631  -0.32600787]]. Action = [[ 0.08950221  0.06100877  0.         -0.3435129 ]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 8606 is [True, False, False, True, False, False]
Current timestep = 8607. State = [[-0.26364604 -0.32206634]]. Action = [[0.09178787 0.02857592 0.         0.00821435]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 8607 is [True, False, False, True, False, False]
State prediction error at timestep 8607 is 0.012
Human Feedback received at timestep 8607 of None
Current timestep = 8608. State = [[-0.25687024 -0.32042688]]. Action = [[ 0.08274259 -0.01460253  0.         -0.10930085]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 8608 is [True, False, False, True, False, False]
State prediction error at timestep 8608 is 0.012
Human Feedback received at timestep 8608 of None
Current timestep = 8609. State = [[-0.25768667 -0.32359588]]. Action = [[-0.06671277 -0.08678111  0.          0.00910163]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 8609 is [True, False, False, True, False, False]
Current timestep = 8610. State = [[-0.26391116 -0.32536706]]. Action = [[-0.07946755  0.00680256  0.          0.13744318]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 8610 is [True, False, False, True, False, False]
Current timestep = 8611. State = [[-0.2680775  -0.32277036]]. Action = [[-0.02070091  0.05113163  0.          0.14810526]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 8611 is [True, False, False, True, False, False]
Current timestep = 8612. State = [[-0.26705855 -0.3208485 ]]. Action = [[ 0.04615847  0.00327359  0.         -0.6732453 ]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 8612 is [True, False, False, True, False, False]
State prediction error at timestep 8612 is 0.012
Human Feedback received at timestep 8612 of None
Current timestep = 8613. State = [[-0.26383117 -0.31532234]]. Action = [[ 0.04276232  0.09476729  0.         -0.553569  ]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 8613 is [True, False, False, True, False, False]
State prediction error at timestep 8613 is 0.012
Human Feedback received at timestep 8613 of None
Current timestep = 8614. State = [[-0.259854   -0.31495082]]. Action = [[ 0.05749767 -0.07431759  0.         -0.49732608]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 8614 is [True, False, False, True, False, False]
Current timestep = 8615. State = [[-0.25873035 -0.31324503]]. Action = [[-0.01933946  0.06457966  0.         -0.82454973]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 8615 is [True, False, False, True, False, False]
Current timestep = 8616. State = [[-0.25551233 -0.30755898]]. Action = [[ 0.07632091  0.06089348  0.         -0.23793024]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 8616 is [True, False, False, True, False, False]
Current timestep = 8617. State = [[-0.25616154 -0.30350026]]. Action = [[-0.05602523  0.02000722  0.          0.90504026]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 8617 is [True, False, False, True, False, False]
Current timestep = 8618. State = [[-0.2590204  -0.29841715]]. Action = [[-0.02252791  0.07021744  0.          0.6776557 ]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 8618 is [True, False, False, True, False, False]
Current timestep = 8619. State = [[-0.26425374 -0.29784834]]. Action = [[-0.08453355 -0.04845055  0.          0.4734552 ]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 8619 is [True, False, False, True, False, False]
Current timestep = 8620. State = [[-0.2711917 -0.2960806]]. Action = [[-0.08252937  0.05077829  0.          0.90821004]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 8620 is [True, False, False, True, False, False]
Current timestep = 8621. State = [[-0.2730948  -0.28931865]]. Action = [[0.02174052 0.09700032 0.         0.319991  ]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 8621 is [True, False, False, True, False, False]
Current timestep = 8622. State = [[-0.27442086 -0.2827137 ]]. Action = [[-0.02903777  0.05314288  0.          0.0310359 ]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 8622 is [True, False, False, True, False, False]
Current timestep = 8623. State = [[-0.27286422 -0.27798215]]. Action = [[0.05522356 0.03151443 0.         0.7988111 ]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 8623 is [True, False, False, True, False, False]
State prediction error at timestep 8623 is 0.012
Human Feedback received at timestep 8623 of None
Current timestep = 8624. State = [[-0.27379563 -0.27861717]]. Action = [[-0.04441104 -0.06958494  0.          0.10353374]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 8624 is [True, False, False, True, False, False]
Current timestep = 8625. State = [[-0.2762818 -0.2785876]]. Action = [[-0.01698078  0.01331352  0.         -0.69485736]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 8625 is [True, False, False, True, False, False]
Current timestep = 8626. State = [[-0.27408728 -0.27355725]]. Action = [[0.06428567 0.0717506  0.         0.63304067]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 8626 is [True, False, False, True, False, False]
State prediction error at timestep 8626 is 0.012
Human Feedback received at timestep 8626 of None
Current timestep = 8627. State = [[-0.2759779  -0.26867324]]. Action = [[-0.06686571  0.03065885  0.         -0.8879846 ]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 8627 is [True, False, False, True, False, False]
Current timestep = 8628. State = [[-0.27655053 -0.2666164 ]]. Action = [[ 3.7519149e-02 -6.6272914e-04  0.0000000e+00  7.0102322e-01]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 8628 is [True, False, False, True, False, False]
State prediction error at timestep 8628 is 0.012
Human Feedback received at timestep 8628 of None
Current timestep = 8629. State = [[-0.2789836  -0.26913813]]. Action = [[-0.05999793 -0.07429566  0.          0.9914533 ]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 8629 is [True, False, False, True, False, False]
Current timestep = 8630. State = [[-0.27783415 -0.26954842]]. Action = [[ 0.06526982  0.01974533  0.         -0.9263175 ]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 8630 is [True, False, False, True, False, False]
Current timestep = 8631. State = [[-0.27661785 -0.27305743]]. Action = [[-0.00942551 -0.09596016  0.         -0.6037078 ]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 8631 is [True, False, False, True, False, False]
Current timestep = 8632. State = [[-0.27710328 -0.27281374]]. Action = [[-0.00619201  0.05889124  0.         -0.84125054]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 8632 is [True, False, False, True, False, False]
State prediction error at timestep 8632 is 0.012
Human Feedback received at timestep 8632 of None
Current timestep = 8633. State = [[-0.27526003 -0.26763365]]. Action = [[0.04741438 0.06868831 0.         0.2561283 ]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 8633 is [True, False, False, True, False, False]
Current timestep = 8634. State = [[-0.27757952 -0.26520553]]. Action = [[-6.6820957e-02 -8.4748864e-04  0.0000000e+00  9.5394981e-01]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 8634 is [True, False, False, True, False, False]
Current timestep = 8635. State = [[-0.28109282 -0.26178616]]. Action = [[-0.02096513  0.06428327  0.         -0.73461175]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 8635 is [True, False, False, True, False, False]
State prediction error at timestep 8635 is 0.012
Human Feedback received at timestep 8635 of None
Current timestep = 8636. State = [[-0.27820197 -0.25813243]]. Action = [[0.08307514 0.02400428 0.         0.84069324]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 8636 is [True, False, False, True, False, False]
Current timestep = 8637. State = [[-0.2765659 -0.2547567]]. Action = [[-0.01126102  0.03033637  0.         -0.00675088]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 8637 is [True, False, False, True, False, False]
Current timestep = 8638. State = [[-0.28036624 -0.25789446]]. Action = [[-0.06569844 -0.09792659  0.         -0.681508  ]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 8638 is [True, False, False, True, False, False]
Current timestep = 8639. State = [[-0.28590664 -0.25631666]]. Action = [[-0.06628448  0.08967119  0.         -0.7349708 ]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 8639 is [True, False, False, True, False, False]
Current timestep = 8640. State = [[-0.29124168 -0.25664765]]. Action = [[-0.04792315 -0.06502029  0.          0.15682292]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 8640 is [True, False, False, True, False, False]
State prediction error at timestep 8640 is 0.012
Human Feedback received at timestep 8640 of None
Current timestep = 8641. State = [[-0.29016128 -0.25796515]]. Action = [[0.06322708 0.0003721  0.         0.12565339]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 8641 is [True, False, False, True, False, False]
Current timestep = 8642. State = [[-0.28503677 -0.2543245 ]]. Action = [[ 0.07058775  0.05852973  0.         -0.65676326]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 8642 is [True, False, False, True, False, False]
State prediction error at timestep 8642 is 0.012
Human Feedback received at timestep 8642 of None
Current timestep = 8643. State = [[-0.2850113  -0.25351918]]. Action = [[-0.04041059 -0.03495954  0.          0.4699999 ]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 8643 is [True, False, False, True, False, False]
State prediction error at timestep 8643 is 0.012
Human Feedback received at timestep 8643 of None
Current timestep = 8644. State = [[-0.28492087 -0.25669965]]. Action = [[ 0.02936355 -0.05435814  0.         -0.15881467]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 8644 is [True, False, False, True, False, False]
Current timestep = 8645. State = [[-0.2882158  -0.25634897]]. Action = [[-0.07975033  0.04200827  0.          0.8634064 ]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 8645 is [True, False, False, True, False, False]
Current timestep = 8646. State = [[-0.2922771  -0.25461677]]. Action = [[-0.0221189   0.01361476  0.          0.7344084 ]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 8646 is [True, False, False, True, False, False]
Current timestep = 8647. State = [[-0.29592517 -0.25665644]]. Action = [[-0.04379116 -0.05091577  0.         -0.06604052]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 8647 is [True, False, False, True, False, False]
Current timestep = 8648. State = [[-0.29479742 -0.25404105]]. Action = [[0.06024634 0.08182608 0.         0.49632776]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 8648 is [True, False, False, True, False, False]
Current timestep = 8649. State = [[-0.29574588 -0.2548241 ]]. Action = [[-0.04786414 -0.07114971  0.          0.74360657]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 8649 is [True, False, False, True, False, False]
Current timestep = 8650. State = [[-0.29668555 -0.2523511 ]]. Action = [[ 0.01659396  0.08802044  0.         -0.00017709]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 8650 is [True, False, False, True, False, False]
Current timestep = 8651. State = [[-0.29650617 -0.2482972 ]]. Action = [[0.00645877 0.02500539 0.         0.58615625]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 8651 is [True, False, False, True, False, False]
Current timestep = 8652. State = [[-0.2958475  -0.24613696]]. Action = [[0.01886351 0.01329882 0.         0.9215498 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 8652 is [True, False, False, True, False, False]
Current timestep = 8653. State = [[-0.2953986 -0.2477958]]. Action = [[ 0.00581598 -0.05757642  0.          0.7872424 ]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 8653 is [True, False, False, True, False, False]
Current timestep = 8654. State = [[-0.2964143  -0.25057885]]. Action = [[-0.01749981 -0.03379623  0.         -0.5152672 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 8654 is [True, False, False, True, False, False]
State prediction error at timestep 8654 is 0.012
Human Feedback received at timestep 8654 of None
Current timestep = 8655. State = [[-0.3016852 -0.250456 ]]. Action = [[-0.08758875  0.02480552  0.          0.05649281]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 8655 is [True, False, False, True, False, False]
Current timestep = 8656. State = [[-0.30070055 -0.25147283]]. Action = [[ 0.08449373 -0.03666238  0.         -0.74124414]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 8656 is [True, False, False, True, False, False]
Current timestep = 8657. State = [[-0.2940202 -0.2557986]]. Action = [[ 0.08199783 -0.07316969  0.         -0.87034965]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 8657 is [True, False, False, True, False, False]
Current timestep = 8658. State = [[-0.29283115 -0.25878426]]. Action = [[-0.03829563 -0.01451264  0.          0.15134263]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 8658 is [True, False, False, True, False, False]
State prediction error at timestep 8658 is 0.012
Human Feedback received at timestep 8658 of None
Current timestep = 8659. State = [[-0.2939444  -0.26141366]]. Action = [[-0.00440992 -0.03108647  0.          0.4157282 ]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 8659 is [True, False, False, True, False, False]
Current timestep = 8660. State = [[-0.29703373 -0.26772034]]. Action = [[-0.05831429 -0.09154428  0.          0.07658446]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 8660 is [True, False, False, True, False, False]
Current timestep = 8661. State = [[-0.3024795  -0.27535307]]. Action = [[-0.07310873 -0.07326225  0.          0.00862801]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 8661 is [True, False, False, True, False, False]
State prediction error at timestep 8661 is 0.012
Human Feedback received at timestep 8661 of None
Current timestep = 8662. State = [[-0.30237043 -0.28276175]]. Action = [[ 0.04749709 -0.07173104  0.          0.473773  ]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 8662 is [True, False, False, True, False, False]
State prediction error at timestep 8662 is 0.012
Human Feedback received at timestep 8662 of None
Current timestep = 8663. State = [[-0.29590803 -0.28919384]]. Action = [[ 0.09458335 -0.05605623  0.         -0.04882938]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 8663 is [True, False, False, True, False, False]
Current timestep = 8664. State = [[-0.29225802 -0.29458714]]. Action = [[ 0.00246449 -0.04267756  0.         -0.16822106]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 8664 is [True, False, False, True, False, False]
Current timestep = 8665. State = [[-0.2940793  -0.29496312]]. Action = [[-0.04637666  0.06387635  0.         -0.1222989 ]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 8665 is [True, False, False, True, False, False]
Current timestep = 8666. State = [[-0.29403436 -0.29515606]]. Action = [[3.4911551e-02 4.5194477e-04 0.0000000e+00 9.1785812e-01]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 8666 is [True, False, False, True, False, False]
Current timestep = 8667. State = [[-0.29490298 -0.2925319 ]]. Action = [[-0.03048205  0.08170041  0.         -0.38826585]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 8667 is [True, False, False, True, False, False]
Current timestep = 8668. State = [[-0.29383093 -0.289384  ]]. Action = [[ 0.0464808   0.03682237  0.         -0.63049746]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 8668 is [True, False, False, True, False, False]
Current timestep = 8669. State = [[-0.29477185 -0.2868014 ]]. Action = [[-0.039926    0.03521291  0.          0.56475127]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 8669 is [True, False, False, True, False, False]
Current timestep = 8670. State = [[-0.29243562 -0.2854486 ]]. Action = [[ 0.07490595  0.00434258  0.         -0.5987365 ]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 8670 is [True, False, False, True, False, False]
Current timestep = 8671. State = [[-0.28600526 -0.2836318 ]]. Action = [[ 0.08420297  0.01471175  0.         -0.4985373 ]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 8671 is [True, False, False, True, False, False]
State prediction error at timestep 8671 is 0.012
Human Feedback received at timestep 8671 of None
Current timestep = 8672. State = [[-0.2874378  -0.27979293]]. Action = [[-0.08285937  0.05102841  0.         -0.2912724 ]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 8672 is [True, False, False, True, False, False]
Current timestep = 8673. State = [[-0.29342002 -0.2770114 ]]. Action = [[-0.06286423  0.01391552  0.         -0.00882787]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 8673 is [True, False, False, True, False, False]
Current timestep = 8674. State = [[-0.30065787 -0.27897736]]. Action = [[-0.09077229 -0.06051987  0.          0.3367679 ]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 8674 is [True, False, False, True, False, False]
Current timestep = 8675. State = [[-0.30883974 -0.27598107]]. Action = [[-0.09448163  0.09500497  0.          0.7904773 ]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 8675 is [True, False, False, True, False, False]
Current timestep = 8676. State = [[-0.3113572  -0.27538547]]. Action = [[ 0.03146879 -0.06540806  0.         -0.08772349]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 8676 is [True, False, False, True, False, False]
Current timestep = 8677. State = [[-0.31434956 -0.27643538]]. Action = [[-0.07143284  0.0076768   0.         -0.58174884]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 8677 is [True, False, False, True, False, False]
State prediction error at timestep 8677 is 0.012
Human Feedback received at timestep 8677 of None
Current timestep = 8678. State = [[-0.3124161  -0.27461156]]. Action = [[0.0837627  0.03105891 0.         0.29350626]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 8678 is [True, False, False, True, False, False]
State prediction error at timestep 8678 is 0.012
Human Feedback received at timestep 8678 of None
Current timestep = 8679. State = [[-0.3053883 -0.2738633]]. Action = [[ 0.08889135 -0.02100318  0.         -0.4279316 ]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 8679 is [True, False, False, True, False, False]
State prediction error at timestep 8679 is 0.012
Human Feedback received at timestep 8679 of None
Current timestep = 8680. State = [[-0.30296364 -0.27408937]]. Action = [[-0.01324748 -0.01230989  0.          0.5123956 ]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 8680 is [True, False, False, True, False, False]
Current timestep = 8681. State = [[-0.3040408  -0.27002245]]. Action = [[-0.01469282  0.08254818  0.          0.3998716 ]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 8681 is [True, False, False, True, False, False]
Current timestep = 8682. State = [[-0.30232137 -0.26489446]]. Action = [[ 0.05068018  0.04542384  0.         -0.5660899 ]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 8682 is [True, False, False, True, False, False]
Current timestep = 8683. State = [[-0.3009199 -0.2586259]]. Action = [[ 0.00338571  0.07857766  0.         -0.34240723]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 8683 is [True, False, False, True, False, False]
Current timestep = 8684. State = [[-0.29955688 -0.25863034]]. Action = [[ 0.03124662 -0.07599609  0.          0.34952533]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 8684 is [True, False, False, True, False, False]
Current timestep = 8685. State = [[-0.2940602  -0.26048183]]. Action = [[ 0.08808262 -0.02103963  0.         -0.61167985]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 8685 is [True, False, False, True, False, False]
Current timestep = 8686. State = [[-0.29315016 -0.25850254]]. Action = [[-0.04352831  0.03674147  0.          0.87876844]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 8686 is [True, False, False, True, False, False]
Current timestep = 8687. State = [[-0.292405   -0.25542676]]. Action = [[ 0.03796303  0.0271531   0.         -0.82690364]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 8687 is [True, False, False, True, False, False]
State prediction error at timestep 8687 is 0.012
Human Feedback received at timestep 8687 of None
Current timestep = 8688. State = [[-0.2960305  -0.25760877]]. Action = [[-0.09695326 -0.0780578   0.          0.5156257 ]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 8688 is [True, False, False, True, False, False]
Current timestep = 8689. State = [[-0.2975911  -0.25870648]]. Action = [[ 0.02631453  0.01931183  0.         -0.26101947]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 8689 is [True, False, False, True, False, False]
Current timestep = 8690. State = [[-0.30125728 -0.26079857]]. Action = [[-0.08759202 -0.05095078  0.         -0.97576195]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 8690 is [True, False, False, True, False, False]
State prediction error at timestep 8690 is 0.012
Human Feedback received at timestep 8690 of None
Current timestep = 8691. State = [[-0.3035187 -0.2625964]]. Action = [[ 0.00541177  0.00074878  0.         -0.5618223 ]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 8691 is [True, False, False, True, False, False]
State prediction error at timestep 8691 is 0.012
Human Feedback received at timestep 8691 of None
Current timestep = 8692. State = [[-0.30295134 -0.26172227]]. Action = [[ 0.00800459  0.02530264  0.         -0.3772329 ]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 8692 is [True, False, False, True, False, False]
State prediction error at timestep 8692 is 0.012
Human Feedback received at timestep 8692 of None
Current timestep = 8693. State = [[-0.29878843 -0.26260412]]. Action = [[ 0.07247674 -0.03198653  0.         -0.96855325]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 8693 is [True, False, False, True, False, False]
State prediction error at timestep 8693 is 0.012
Human Feedback received at timestep 8693 of None
Current timestep = 8694. State = [[-0.29268304 -0.25928694]]. Action = [[0.06858984 0.07922442 0.         0.04381275]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 8694 is [True, False, False, True, False, False]
State prediction error at timestep 8694 is 0.012
Human Feedback received at timestep 8694 of None
Current timestep = 8695. State = [[-0.28518522 -0.2568145 ]]. Action = [[ 0.0988177  -0.00992339  0.         -0.97449696]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 8695 is [True, False, False, True, False, False]
Current timestep = 8696. State = [[-0.28277197 -0.2547889 ]]. Action = [[-0.02048672  0.02911182  0.         -0.07873327]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 8696 is [True, False, False, True, False, False]
Current timestep = 8697. State = [[-0.28160906 -0.25287235]]. Action = [[ 0.03074203  0.01216765  0.         -0.86274546]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 8697 is [True, False, False, True, False, False]
Current timestep = 8698. State = [[-0.27885324 -0.24875966]]. Action = [[ 0.03593726  0.06110365  0.         -0.17259037]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 8698 is [True, False, False, True, False, False]
Current timestep = 8699. State = [[-0.27370426 -0.25043473]]. Action = [[ 0.07922349 -0.09518735  0.         -0.7902313 ]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 8699 is [True, False, False, True, False, False]
Current timestep = 8700. State = [[-0.2750601 -0.2502021]]. Action = [[-0.09648122  0.06326442  0.          0.4110906 ]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 8700 is [True, False, False, True, False, False]
State prediction error at timestep 8700 is 0.012
Human Feedback received at timestep 8700 of None
Current timestep = 8701. State = [[-0.2794385  -0.24311191]]. Action = [[-0.02745517  0.0991083   0.         -0.46941364]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 8701 is [True, False, False, True, False, False]
Current timestep = 8702. State = [[-0.28524548 -0.24155818]]. Action = [[-0.08504815 -0.04530049  0.          0.42414248]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 8702 is [True, False, False, True, False, False]
Current timestep = 8703. State = [[-0.28814372 -0.23973908]]. Action = [[0.00342844 0.04474046 0.         0.93765116]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 8703 is [True, False, False, True, False, False]
State prediction error at timestep 8703 is 0.012
Human Feedback received at timestep 8703 of None
Current timestep = 8704. State = [[-0.29029903 -0.23811376]]. Action = [[-0.03528426 -0.01008976  0.          0.29829717]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 8704 is [True, False, False, True, False, False]
Current timestep = 8705. State = [[-0.29332164 -0.24010022]]. Action = [[-0.03341857 -0.04975308  0.          0.7667545 ]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 8705 is [True, False, False, True, False, False]
Current timestep = 8706. State = [[-0.29916883 -0.24321747]]. Action = [[-0.09010836 -0.0391898   0.         -0.8979638 ]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 8706 is [True, False, False, True, False, False]
Current timestep = 8707. State = [[-0.29998648 -0.24909934]]. Action = [[ 0.04568934 -0.09541966  0.         -0.29466593]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 8707 is [True, False, False, True, False, False]
State prediction error at timestep 8707 is 0.012
Human Feedback received at timestep 8707 of None
Current timestep = 8708. State = [[-0.30015028 -0.25461024]]. Action = [[-0.02883754 -0.04940159  0.          0.38728487]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 8708 is [True, False, False, True, False, False]
Current timestep = 8709. State = [[-0.30414897 -0.25663945]]. Action = [[-0.06459273  0.00977651  0.          0.6568861 ]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 8709 is [True, False, False, True, False, False]
Current timestep = 8710. State = [[-0.30370393 -0.25613844]]. Action = [[ 0.05317143  0.02943809  0.         -0.4134599 ]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 8710 is [True, False, False, True, False, False]
Current timestep = 8711. State = [[-0.30387664 -0.2580197 ]]. Action = [[-0.02862781 -0.03925901  0.          0.8779628 ]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 8711 is [True, False, False, True, False, False]
Current timestep = 8712. State = [[-0.30062592 -0.25808007]]. Action = [[0.08576491 0.03456213 0.         0.28036392]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 8712 is [True, False, False, True, False, False]
Current timestep = 8713. State = [[-0.2966452 -0.2591805]]. Action = [[ 0.03210568 -0.03703989  0.          0.01003611]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 8713 is [True, False, False, True, False, False]
Current timestep = 8714. State = [[-0.29847148 -0.2607232 ]]. Action = [[-0.0538388  -0.00248352  0.          0.34986997]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 8714 is [True, False, False, True, False, False]
State prediction error at timestep 8714 is 0.012
Human Feedback received at timestep 8714 of None
Current timestep = 8715. State = [[-0.29568487 -0.2627303 ]]. Action = [[ 0.09469458 -0.02901784  0.         -0.6503925 ]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 8715 is [True, False, False, True, False, False]
Current timestep = 8716. State = [[-0.28916106 -0.26009578]]. Action = [[0.07606585 0.06899198 0.         0.9104068 ]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 8716 is [True, False, False, True, False, False]
Current timestep = 8717. State = [[-0.28557342 -0.25450298]]. Action = [[0.02513935 0.06719144 0.         0.6955954 ]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 8717 is [True, False, False, True, False, False]
State prediction error at timestep 8717 is 0.012
Human Feedback received at timestep 8717 of None
Current timestep = 8718. State = [[-0.28094858 -0.24952175]]. Action = [[0.07987902 0.04515459 0.         0.787534  ]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 8718 is [True, False, False, True, False, False]
Current timestep = 8719. State = [[-0.2794395  -0.25110623]]. Action = [[-0.01512457 -0.08326639  0.         -0.29699016]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 8719 is [True, False, False, True, False, False]
State prediction error at timestep 8719 is 0.012
Human Feedback received at timestep 8719 of None
Current timestep = 8720. State = [[-0.28186437 -0.250563  ]]. Action = [[-0.0394928   0.04847576  0.         -0.77385235]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 8720 is [True, False, False, True, False, False]
Current timestep = 8721. State = [[-0.28174108 -0.24441111]]. Action = [[0.03389951 0.08690419 0.         0.9827806 ]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 8721 is [True, False, False, True, False, False]
Current timestep = 8722. State = [[-0.2820358  -0.23608033]]. Action = [[-0.01823158  0.09691232  0.         -0.06332296]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 8722 is [True, False, False, True, False, False]
Current timestep = 8723. State = [[-0.2859233  -0.23507077]]. Action = [[-0.06114962 -0.06236254  0.          0.63920164]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 8723 is [True, False, False, True, False, False]
Current timestep = 8724. State = [[-0.29194275 -0.2386497 ]]. Action = [[-0.0782875  -0.05504106  0.         -0.7012448 ]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 8724 is [True, False, False, True, False, False]
Current timestep = 8725. State = [[-0.29510236 -0.23776285]]. Action = [[-0.01242305  0.04462107  0.          0.25389647]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 8725 is [True, False, False, True, False, False]
State prediction error at timestep 8725 is 0.012
Human Feedback received at timestep 8725 of None
Current timestep = 8726. State = [[-0.29215923 -0.2348712 ]]. Action = [[0.06820222 0.02075632 0.         0.8131697 ]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 8726 is [True, False, False, True, False, False]
Current timestep = 8727. State = [[-0.29330432 -0.23755805]]. Action = [[-0.07034711 -0.08866777  0.         -0.27322614]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 8727 is [True, False, False, True, False, False]
Current timestep = 8728. State = [[-0.29690567 -0.23990798]]. Action = [[-0.03456921  0.00127038  0.          0.93992555]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 8728 is [True, False, False, True, False, False]
Current timestep = 8729. State = [[-0.29847896 -0.24324115]]. Action = [[-0.00895963 -0.0614192   0.          0.11743176]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 8729 is [True, False, False, True, False, False]
Current timestep = 8730. State = [[-0.29759103 -0.24122308]]. Action = [[ 0.02176018  0.08360227  0.         -0.32556063]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 8730 is [True, False, False, True, False, False]
Current timestep = 8731. State = [[-0.2985972  -0.24026087]]. Action = [[-0.03210453 -0.02427015  0.          0.38760746]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 8731 is [True, False, False, True, False, False]
Current timestep = 8732. State = [[-0.29747844 -0.24113539]]. Action = [[ 0.04332554 -0.00397678  0.         -0.16811407]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 8732 is [True, False, False, True, False, False]
Current timestep = 8733. State = [[-0.2932635  -0.23774989]]. Action = [[ 0.06048576  0.06609749  0.         -0.22792113]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 8733 is [True, False, False, True, False, False]
State prediction error at timestep 8733 is 0.012
Human Feedback received at timestep 8733 of None
Current timestep = 8734. State = [[-0.28668472 -0.23692492]]. Action = [[ 0.0950102  -0.03762485  0.          0.10132933]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 8734 is [True, False, False, True, False, False]
Current timestep = 8735. State = [[-0.2874619  -0.23804983]]. Action = [[-0.07689439 -0.01177558  0.          0.44739234]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 8735 is [True, False, False, True, False, False]
Current timestep = 8736. State = [[-0.28830618 -0.23993067]]. Action = [[ 0.0303744  -0.03046372  0.          0.83975947]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 8736 is [True, False, False, True, False, False]
Current timestep = 8737. State = [[-0.28903255 -0.23700158]]. Action = [[-0.02781284  0.07905676  0.          0.29547393]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 8737 is [True, False, False, True, False, False]
Current timestep = 8738. State = [[-0.28738502 -0.23054229]]. Action = [[ 0.05498641  0.08048924  0.         -0.48040748]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 8738 is [True, False, False, True, False, False]
State prediction error at timestep 8738 is 0.012
Human Feedback received at timestep 8738 of None
Current timestep = 8739. State = [[-0.29075328 -0.22709924]]. Action = [[-0.09338975  0.00577625  0.          0.3383844 ]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 8739 is [True, False, False, True, False, False]
State prediction error at timestep 8739 is 0.012
Human Feedback received at timestep 8739 of None
Current timestep = 8740. State = [[-0.290886   -0.22652887]]. Action = [[ 0.06065468 -0.00669289  0.          0.3175485 ]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 8740 is [True, False, False, True, False, False]
Current timestep = 8741. State = [[-0.2882207  -0.22351126]]. Action = [[0.02512289 0.04330391 0.         0.5349897 ]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 8741 is [True, False, False, True, False, False]
Current timestep = 8742. State = [[-0.29173952 -0.2225495 ]]. Action = [[-0.08296815 -0.02334466  0.         -0.00052565]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 8742 is [True, False, False, True, False, False]
Current timestep = 8743. State = [[-0.29084796 -0.22069834]]. Action = [[0.07256442 0.03645038 0.         0.75270295]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 8743 is [True, False, False, True, False, False]
State prediction error at timestep 8743 is 0.012
Human Feedback received at timestep 8743 of None
Current timestep = 8744. State = [[-0.2855098  -0.21863644]]. Action = [[ 0.06880217 -0.00377241  0.         -0.19981122]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 8744 is [True, False, False, True, False, False]
State prediction error at timestep 8744 is 0.012
Human Feedback received at timestep 8744 of None
Current timestep = 8745. State = [[-0.28169182 -0.21956769]]. Action = [[ 0.03152513 -0.04317626  0.          0.1415211 ]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 8745 is [True, False, False, True, False, False]
State prediction error at timestep 8745 is 0.012
Human Feedback received at timestep 8745 of None
Current timestep = 8746. State = [[-0.27814603 -0.21955998]]. Action = [[0.04640283 0.00702939 0.         0.61649   ]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 8746 is [True, False, False, True, False, False]
Current timestep = 8747. State = [[-0.280758  -0.2198031]]. Action = [[-0.08501128 -0.01704778  0.          0.78167295]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 8747 is [True, False, False, True, False, False]
State prediction error at timestep 8747 is 0.012
Human Feedback received at timestep 8747 of None
Current timestep = 8748. State = [[-0.27861768 -0.22435068]]. Action = [[ 0.09044089 -0.08663476  0.         -0.71970814]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 8748 is [True, False, False, True, False, False]
Current timestep = 8749. State = [[-0.27623764 -0.22940093]]. Action = [[-0.0199675  -0.04503563  0.         -0.4193989 ]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 8749 is [True, False, False, True, False, False]
Current timestep = 8750. State = [[-0.2730637  -0.22803554]]. Action = [[ 0.05418714  0.07160369  0.         -0.32542944]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 8750 is [True, False, False, True, False, False]
Current timestep = 8751. State = [[-0.26647097 -0.22204846]]. Action = [[0.08526625 0.08755564 0.         0.63617706]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 8751 is [True, False, False, True, False, False]
State prediction error at timestep 8751 is 0.012
Human Feedback received at timestep 8751 of None
Current timestep = 8752. State = [[-0.26305938 -0.22109826]]. Action = [[ 0.00241727 -0.03705868  0.         -0.4683764 ]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 8752 is [True, False, False, True, False, False]
State prediction error at timestep 8752 is 0.012
Human Feedback received at timestep 8752 of None
Current timestep = 8753. State = [[-0.26387715 -0.22041848]]. Action = [[-0.03348527  0.0341633   0.          0.49589896]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 8753 is [True, False, False, True, False, False]
State prediction error at timestep 8753 is 0.012
Human Feedback received at timestep 8753 of None
Current timestep = 8754. State = [[-0.26081347 -0.21556692]]. Action = [[ 0.07137445  0.0775696   0.         -0.0073328 ]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 8754 is [True, False, False, True, False, False]
Current timestep = 8755. State = [[-0.2596798  -0.21563822]]. Action = [[-0.02904538 -0.0609917   0.          0.2281754 ]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 8755 is [True, False, False, True, False, False]
Current timestep = 8756. State = [[-0.26444724 -0.21842684]]. Action = [[-0.09261232 -0.02465358  0.          0.4987502 ]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 8756 is [True, False, False, True, False, False]
State prediction error at timestep 8756 is 0.012
Human Feedback received at timestep 8756 of None
Current timestep = 8757. State = [[-0.26896673 -0.22334722]]. Action = [[-0.04656292 -0.07425812  0.          0.9088595 ]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 8757 is [True, False, False, True, False, False]
State prediction error at timestep 8757 is 0.012
Human Feedback received at timestep 8757 of None
Current timestep = 8758. State = [[-0.27247748 -0.22285186]]. Action = [[-0.05219135  0.06725862  0.         -0.59748906]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 8758 is [True, False, False, True, False, False]
State prediction error at timestep 8758 is 0.012
Human Feedback received at timestep 8758 of None
Current timestep = 8759. State = [[-0.27114648 -0.21779217]]. Action = [[0.05188777 0.07071321 0.         0.7183064 ]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 8759 is [True, False, False, True, False, False]
Current timestep = 8760. State = [[-0.26852754 -0.21811956]]. Action = [[ 0.01940918 -0.05931013  0.          0.8227248 ]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 8760 is [True, False, False, True, False, False]
Current timestep = 8761. State = [[-0.26777422 -0.215206  ]]. Action = [[-0.00288636  0.08464607  0.         -0.7998368 ]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 8761 is [True, False, False, True, False, False]
State prediction error at timestep 8761 is 0.012
Human Feedback received at timestep 8761 of None
Current timestep = 8762. State = [[-0.265604   -0.21378326]]. Action = [[ 0.04805399 -0.0331993   0.         -0.2892369 ]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 8762 is [True, False, False, True, False, False]
Current timestep = 8763. State = [[-0.26785576 -0.21616636]]. Action = [[-0.07288225 -0.04124893  0.         -0.53599954]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 8763 is [True, False, False, True, False, False]
Current timestep = 8764. State = [[-0.26681095 -0.21846582]]. Action = [[ 0.06341664 -0.02323619  0.         -0.5312131 ]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 8764 is [True, False, False, True, False, False]
Current timestep = 8765. State = [[-0.26386964 -0.22276297]]. Action = [[ 0.0220513  -0.07649793  0.          0.2971692 ]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 8765 is [True, False, False, True, False, False]
Current timestep = 8766. State = [[-0.26015744 -0.22124259]]. Action = [[0.05476489 0.07664173 0.         0.141155  ]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 8766 is [True, False, False, True, False, False]
Current timestep = 8767. State = [[-0.25373656 -0.21446122]]. Action = [[ 0.09586781  0.08815997  0.         -0.8805256 ]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 8767 is [True, False, False, True, False, False]
State prediction error at timestep 8767 is 0.012
Human Feedback received at timestep 8767 of None
Current timestep = 8768. State = [[-0.25198406 -0.20991996]]. Action = [[-0.01981835  0.02389976  0.         -0.2039839 ]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 8768 is [True, False, False, True, False, False]
Current timestep = 8769. State = [[-0.2569267  -0.20441273]]. Action = [[-0.08742015  0.08724486  0.          0.4578563 ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 8769 is [True, False, False, True, False, False]
Current timestep = 8770. State = [[-0.26465046 -0.20422709]]. Action = [[-0.09676371 -0.05314596  0.          0.1096518 ]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 8770 is [True, False, False, True, False, False]
Current timestep = 8771. State = [[-0.2655352  -0.20503128]]. Action = [[0.04872627 0.00361743 0.         0.87340474]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 8771 is [True, False, False, True, False, False]
State prediction error at timestep 8771 is 0.012
Human Feedback received at timestep 8771 of None
Current timestep = 8772. State = [[-0.2666214  -0.20691171]]. Action = [[-0.04480177 -0.05231939  0.          0.28746653]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 8772 is [True, False, False, True, False, False]
State prediction error at timestep 8772 is 0.012
Human Feedback received at timestep 8772 of None
Current timestep = 8773. State = [[-0.2694234  -0.20853184]]. Action = [[-0.03147418 -0.00704472  0.          0.62666166]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 8773 is [True, False, False, True, False, False]
State prediction error at timestep 8773 is 0.012
Human Feedback received at timestep 8773 of None
Current timestep = 8774. State = [[-0.26934803 -0.20583539]]. Action = [[0.0224479 0.0567904 0.        0.8194063]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 8774 is [True, False, False, True, False, False]
State prediction error at timestep 8774 is 0.012
Human Feedback received at timestep 8774 of None
Current timestep = 8775. State = [[-0.27297258 -0.20044039]]. Action = [[-0.08148418  0.07004022  0.         -0.55524254]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 8775 is [True, False, False, True, False, False]
Current timestep = 8776. State = [[-0.2802417  -0.20080017]]. Action = [[-0.09046217 -0.05245727  0.         -0.50228816]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 8776 is [True, False, False, True, False, False]
State prediction error at timestep 8776 is 0.012
Human Feedback received at timestep 8776 of None
Current timestep = 8777. State = [[-0.2869465  -0.20243466]]. Action = [[-0.06729051 -0.00381798  0.         -0.22211748]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 8777 is [True, False, False, True, False, False]
Current timestep = 8778. State = [[-0.29110014 -0.19791664]]. Action = [[-0.0266792   0.09453195  0.          0.5093906 ]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 8778 is [True, False, False, True, False, False]
Current timestep = 8779. State = [[-0.29526457 -0.19178776]]. Action = [[-0.04683697  0.05920579  0.          0.71880364]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 8779 is [True, False, False, True, False, False]
State prediction error at timestep 8779 is 0.012
Human Feedback received at timestep 8779 of None
Current timestep = 8780. State = [[-0.30221495 -0.19353646]]. Action = [[-0.08853595 -0.08684679  0.          0.9449942 ]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 8780 is [True, False, False, True, False, False]
Current timestep = 8781. State = [[-0.3030583 -0.192399 ]]. Action = [[0.06927779 0.06605073 0.         0.13736844]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 8781 is [True, False, False, True, False, False]
Current timestep = 8782. State = [[-0.29754704 -0.1914739 ]]. Action = [[ 0.09648105 -0.04697291  0.         -0.5096603 ]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 8782 is [True, False, False, True, False, False]
Current timestep = 8783. State = [[-0.29832265 -0.19611801]]. Action = [[-0.05967078 -0.09537715  0.         -0.70892584]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 8783 is [True, False, False, True, False, False]
State prediction error at timestep 8783 is 0.012
Human Feedback received at timestep 8783 of None
Current timestep = 8784. State = [[-0.2985203  -0.19390376]]. Action = [[ 0.04566585  0.09917041  0.         -0.11628926]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 8784 is [True, False, False, True, False, False]
Current timestep = 8785. State = [[-0.29681438 -0.19416818]]. Action = [[ 0.02493129 -0.07233534  0.         -0.33745116]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 8785 is [True, False, False, True, False, False]
Current timestep = 8786. State = [[-0.29296455 -0.19447015]]. Action = [[ 0.06999063  0.02354159  0.         -0.5054039 ]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 8786 is [True, False, False, True, False, False]
Current timestep = 8787. State = [[-0.2868593  -0.19162172]]. Action = [[ 0.08635097  0.03265571  0.         -0.8073458 ]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 8787 is [True, False, False, True, False, False]
State prediction error at timestep 8787 is 0.012
Human Feedback received at timestep 8787 of None
Current timestep = 8788. State = [[-0.2807756  -0.19215924]]. Action = [[ 0.07291292 -0.04580192  0.          0.28951645]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 8788 is [True, False, False, True, False, False]
Current timestep = 8789. State = [[-0.28279328 -0.19054964]]. Action = [[-0.09148556  0.06181539  0.          0.03043795]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 8789 is [True, False, False, True, False, False]
State prediction error at timestep 8789 is 0.012
Human Feedback received at timestep 8789 of None
Current timestep = 8790. State = [[-0.29034075 -0.19356246]]. Action = [[-0.08494207 -0.09630232  0.         -0.494231  ]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 8790 is [True, False, False, True, False, False]
State prediction error at timestep 8790 is 0.012
Human Feedback received at timestep 8790 of None
Current timestep = 8791. State = [[-0.2899411  -0.20055668]]. Action = [[ 0.07486316 -0.08630092  0.         -0.998309  ]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 8791 is [True, False, False, True, False, False]
Current timestep = 8792. State = [[-0.2864444  -0.19892342]]. Action = [[ 0.02765702  0.09122091  0.         -0.84423655]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 8792 is [True, False, False, True, False, False]
Current timestep = 8793. State = [[-0.28707817 -0.19535343]]. Action = [[-0.02470146  0.0200402   0.         -0.25812674]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 8793 is [True, False, False, True, False, False]
State prediction error at timestep 8793 is 0.012
Human Feedback received at timestep 8793 of None
Current timestep = 8794. State = [[-0.29183152 -0.1918828 ]]. Action = [[-0.07201093  0.05703313  0.         -0.8062365 ]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 8794 is [True, False, False, True, False, False]
Current timestep = 8795. State = [[-0.29505822 -0.19230986]]. Action = [[-0.00824035 -0.04201707  0.          0.01013446]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 8795 is [True, False, False, True, False, False]
State prediction error at timestep 8795 is 0.012
Human Feedback received at timestep 8795 of None
Current timestep = 8796. State = [[-0.294161   -0.19177394]]. Action = [[ 0.03343914  0.03137941  0.         -0.3034528 ]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 8796 is [True, False, False, True, False, False]
Current timestep = 8797. State = [[-0.29004297 -0.19287172]]. Action = [[ 0.06829617 -0.04918334  0.         -0.02063268]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 8797 is [True, False, False, True, False, False]
Current timestep = 8798. State = [[-0.29081988 -0.19659479]]. Action = [[-0.0565248 -0.0531369  0.        -0.0267365]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 8798 is [True, False, False, True, False, False]
Current timestep = 8799. State = [[-0.29001912 -0.19780104]]. Action = [[0.04711246 0.01288176 0.         0.6701205 ]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 8799 is [True, False, False, True, False, False]
State prediction error at timestep 8799 is 0.012
Human Feedback received at timestep 8799 of None
Current timestep = 8800. State = [[-0.29123357 -0.19671877]]. Action = [[-0.0514866   0.02020191  0.         -0.9024452 ]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 8800 is [True, False, False, True, False, False]
Current timestep = 8801. State = [[-0.29478472 -0.19235075]]. Action = [[-0.04113209  0.08479356  0.          0.58421755]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 8801 is [True, False, False, True, False, False]
State prediction error at timestep 8801 is 0.012
Human Feedback received at timestep 8801 of None
Current timestep = 8802. State = [[-0.2984089  -0.19031833]]. Action = [[-0.04152576 -0.00501269  0.         -0.6113506 ]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 8802 is [True, False, False, True, False, False]
Current timestep = 8803. State = [[-0.30292693 -0.18902346]]. Action = [[-0.05761904  0.02787106  0.         -0.87363505]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 8803 is [True, False, False, True, False, False]
State prediction error at timestep 8803 is 0.012
Human Feedback received at timestep 8803 of None
Current timestep = 8804. State = [[-0.3055021  -0.18640876]]. Action = [[-0.00691629  0.03410839  0.          0.13106799]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 8804 is [True, False, False, True, False, False]
Current timestep = 8805. State = [[-0.31012776 -0.18932496]]. Action = [[-0.0768801  -0.08639813  0.          0.9445753 ]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 8805 is [True, False, False, True, False, False]
State prediction error at timestep 8805 is 0.012
Human Feedback received at timestep 8805 of None
Current timestep = 8806. State = [[-0.31152925 -0.19446254]]. Action = [[ 0.02826839 -0.05563751  0.         -0.22894526]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 8806 is [True, False, False, True, False, False]
Current timestep = 8807. State = [[-0.30836606 -0.19597524]]. Action = [[ 0.05479508  0.00113771  0.         -0.14232183]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 8807 is [True, False, False, True, False, False]
Current timestep = 8808. State = [[-0.3078832  -0.19817531]]. Action = [[-0.02168    -0.04536535  0.         -0.5493541 ]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 8808 is [True, False, False, True, False, False]
Current timestep = 8809. State = [[-0.31311765 -0.19889365]]. Action = [[-0.09027324  0.02253618  0.          0.980783  ]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 8809 is [True, False, False, True, False, False]
Current timestep = 8810. State = [[-0.31379065 -0.20095092]]. Action = [[ 0.05256607 -0.04416239  0.         -0.73317194]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 8810 is [True, False, False, True, False, False]
State prediction error at timestep 8810 is 0.012
Human Feedback received at timestep 8810 of None
Current timestep = 8811. State = [[-0.3162838  -0.19991526]]. Action = [[-0.07690357  0.06282745  0.          0.697731  ]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 8811 is [True, False, False, True, False, False]
State prediction error at timestep 8811 is 0.012
Human Feedback received at timestep 8811 of None
Current timestep = 8812. State = [[-0.32248735 -0.20182146]]. Action = [[-0.06633234 -0.06179305  0.          0.2403084 ]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 8812 is [True, False, False, True, False, False]
State prediction error at timestep 8812 is 0.012
Human Feedback received at timestep 8812 of None
Current timestep = 8813. State = [[-0.32933828 -0.20310694]]. Action = [[-0.07776342  0.02265404  0.         -0.70963126]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 8813 is [True, False, False, True, False, False]
State prediction error at timestep 8813 is 0.012
Human Feedback received at timestep 8813 of None
Current timestep = 8814. State = [[-0.32990927 -0.207118  ]]. Action = [[ 0.0596297 -0.0885922  0.        -0.4760331]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 8814 is [True, False, False, True, False, False]
Current timestep = 8815. State = [[-0.33033648 -0.21504883]]. Action = [[-0.03585712 -0.09622937  0.         -0.17763484]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 8815 is [True, False, False, True, False, False]
Current timestep = 8816. State = [[-0.32831216 -0.21636474]]. Action = [[ 0.06194376  0.05476999  0.         -0.5870751 ]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 8816 is [True, False, False, True, False, False]
Current timestep = 8817. State = [[-0.33013043 -0.22004761]]. Action = [[-0.08068965 -0.09670042  0.         -0.5355215 ]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 8817 is [True, False, False, True, False, False]
State prediction error at timestep 8817 is 0.012
Human Feedback received at timestep 8817 of None
Current timestep = 8818. State = [[-0.33335027 -0.2196602 ]]. Action = [[-0.01174729  0.08944004  0.         -0.73333085]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 8818 is [True, False, False, True, False, False]
Current timestep = 8819. State = [[-0.33495277 -0.21497314]]. Action = [[-0.00775906  0.06423327  0.         -0.4396286 ]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 8819 is [True, False, False, True, False, False]
Current timestep = 8820. State = [[-0.3309235  -0.21026511]]. Action = [[ 0.09995391  0.05535831  0.         -0.22528261]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 8820 is [True, False, False, True, False, False]
Current timestep = 8821. State = [[-0.32860586 -0.21173008]]. Action = [[-0.00462145 -0.08340751  0.          0.88659453]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 8821 is [True, False, False, True, False, False]
Current timestep = 8822. State = [[-0.32469463 -0.21813755]]. Action = [[ 0.09074714 -0.09839547  0.          0.5263648 ]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 8822 is [True, False, False, True, False, False]
State prediction error at timestep 8822 is 0.012
Human Feedback received at timestep 8822 of None
Current timestep = 8823. State = [[-0.3203211  -0.21945013]]. Action = [[0.03661906 0.02425165 0.         0.79371953]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 8823 is [True, False, False, True, False, False]
Current timestep = 8824. State = [[-0.32205063 -0.21800251]]. Action = [[-5.0310470e-02  1.2319639e-02  0.0000000e+00  8.4996223e-05]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 8824 is [True, False, False, True, False, False]
Current timestep = 8825. State = [[-0.32803845 -0.21336468]]. Action = [[-0.07433177  0.08952583  0.          0.36249542]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 8825 is [True, False, False, True, False, False]
Current timestep = 8826. State = [[-0.32758635 -0.20912462]]. Action = [[ 0.07624549  0.0270723   0.         -0.24745047]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 8826 is [True, False, False, True, False, False]
State prediction error at timestep 8826 is 0.012
Human Feedback received at timestep 8826 of None
Current timestep = 8827. State = [[-0.32531506 -0.20591924]]. Action = [[0.01169096 0.03070135 0.         0.46944213]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 8827 is [True, False, False, True, False, False]
Current timestep = 8828. State = [[-0.3221716  -0.20275389]]. Action = [[ 0.06063359  0.02516886  0.         -0.6637527 ]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 8828 is [True, False, False, True, False, False]
Current timestep = 8829. State = [[-0.3222939  -0.19707443]]. Action = [[-0.03146497  0.07638306  0.          0.28795934]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 8829 is [True, False, False, True, False, False]
Current timestep = 8830. State = [[-0.31904924 -0.18909745]]. Action = [[ 0.09448344  0.08845385  0.         -0.5198575 ]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 8830 is [True, False, False, True, False, False]
Current timestep = 8831. State = [[-0.31191835 -0.18167304]]. Action = [[0.09876954 0.05172754 0.         0.13225627]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 8831 is [True, False, False, True, False, False]
State prediction error at timestep 8831 is 0.012
Human Feedback received at timestep 8831 of None
Current timestep = 8832. State = [[-0.3086801  -0.18138114]]. Action = [[ 0.01322258 -0.07992417  0.         -0.90901273]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 8832 is [True, False, False, True, False, False]
Current timestep = 8833. State = [[-0.3060871  -0.18410246]]. Action = [[ 0.05062561 -0.05129504  0.          0.37870812]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 8833 is [True, False, False, True, False, False]
Current timestep = 8834. State = [[-0.3009439  -0.18410903]]. Action = [[0.07423189 0.00089099 0.         0.03572118]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 8834 is [True, False, False, True, False, False]
Current timestep = 8835. State = [[-0.29989907 -0.18402152]]. Action = [[-0.02881502 -0.01972429  0.         -0.8671972 ]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 8835 is [True, False, False, True, False, False]
Current timestep = 8836. State = [[-0.30353454 -0.18342547]]. Action = [[-0.06468998  0.01627046  0.         -0.6138215 ]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 8836 is [True, False, False, True, False, False]
Current timestep = 8837. State = [[-0.30353886 -0.17973876]]. Action = [[0.03218686 0.06365993 0.         0.7878957 ]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 8837 is [True, False, False, True, False, False]
State prediction error at timestep 8837 is 0.012
Human Feedback received at timestep 8837 of None
Current timestep = 8838. State = [[-0.30439568 -0.17637962]]. Action = [[-0.04283908  0.02292894  0.         -0.05469483]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 8838 is [True, False, False, True, False, False]
State prediction error at timestep 8838 is 0.012
Human Feedback received at timestep 8838 of None
Current timestep = 8839. State = [[-0.3064895  -0.17115995]]. Action = [[-0.02695716  0.08407711  0.          0.7883928 ]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 8839 is [True, False, False, True, False, False]
Current timestep = 8840. State = [[-0.30473012 -0.1677059 ]]. Action = [[0.0463725  0.00530861 0.         0.66873896]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 8840 is [True, False, False, True, False, False]
State prediction error at timestep 8840 is 0.012
Human Feedback received at timestep 8840 of None
Current timestep = 8841. State = [[-0.30774045 -0.16450477]]. Action = [[-0.09737193  0.04418548  0.         -0.27038193]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 8841 is [True, False, False, True, False, False]
Current timestep = 8842. State = [[-0.3120996  -0.16063164]]. Action = [[-0.03490461  0.03958539  0.         -0.8989382 ]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 8842 is [True, False, False, True, False, False]
Current timestep = 8843. State = [[-0.31578207 -0.15993424]]. Action = [[-0.05011134 -0.02616464  0.         -0.6611014 ]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 8843 is [True, False, False, True, False, False]
Current timestep = 8844. State = [[-0.31646326 -0.1599897 ]]. Action = [[ 0.01707701 -0.00242767  0.          0.00544584]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 8844 is [True, False, False, True, False, False]
Current timestep = 8845. State = [[-0.31914642 -0.15569203]]. Action = [[-0.06285408  0.07399676  0.         -0.6230659 ]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 8845 is [True, False, False, True, False, False]
Current timestep = 8846. State = [[-0.32187077 -0.14952174]]. Action = [[-0.01065809  0.06416234  0.          0.67329454]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 8846 is [True, False, False, True, False, False]
Current timestep = 8847. State = [[-0.32693747 -0.14451484]]. Action = [[-0.08081232  0.03975435  0.          0.98295605]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 8847 is [True, False, False, True, False, False]
State prediction error at timestep 8847 is 0.012
Human Feedback received at timestep 8847 of None
Current timestep = 8848. State = [[-0.32798687 -0.14021887]]. Action = [[0.0446457 0.0368873 0.        0.4024024]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 8848 is [True, False, False, True, False, False]
Current timestep = 8849. State = [[-0.3239554  -0.14079985]]. Action = [[ 0.07794028 -0.07113442  0.         -0.3336054 ]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 8849 is [True, False, False, True, False, False]
Current timestep = 8850. State = [[-0.31747067 -0.13912855]]. Action = [[0.09850024 0.03724941 0.         0.8115375 ]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 8850 is [True, False, False, True, False, False]
Current timestep = 8851. State = [[-0.31173843 -0.13880706]]. Action = [[ 0.06533694 -0.0468461   0.         -0.2551673 ]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 8851 is [True, False, False, True, False, False]
State prediction error at timestep 8851 is 0.012
Human Feedback received at timestep 8851 of None
Current timestep = 8852. State = [[-0.31148523 -0.14135003]]. Action = [[-0.03167187 -0.04515568  0.         -0.07207882]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 8852 is [True, False, False, True, False, False]
Current timestep = 8853. State = [[-0.30790257 -0.13893537]]. Action = [[0.09234162 0.06935699 0.         0.68417776]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 8853 is [True, False, False, True, False, False]
State prediction error at timestep 8853 is 0.012
Human Feedback received at timestep 8853 of None
Current timestep = 8854. State = [[-0.30211395 -0.133633  ]]. Action = [[ 0.06702401  0.05260532  0.         -0.28024876]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 8854 is [True, False, False, True, False, False]
Current timestep = 8855. State = [[-0.29569232 -0.13044411]]. Action = [[0.09132686 0.01206747 0.         0.9188547 ]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 8855 is [True, False, False, True, False, False]
Current timestep = 8856. State = [[-0.29410172 -0.13335925]]. Action = [[-0.02474158 -0.08443226  0.          0.5875771 ]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 8856 is [True, False, False, True, False, False]
Current timestep = 8857. State = [[-0.29258278 -0.13157482]]. Action = [[ 0.0368466   0.0826835   0.         -0.04523134]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 8857 is [True, False, False, True, False, False]
Current timestep = 8858. State = [[-0.29018268 -0.12551765]]. Action = [[ 0.02425776  0.06966465  0.         -0.9213162 ]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 8858 is [True, False, False, True, False, False]
Current timestep = 8859. State = [[-0.28545713 -0.1220789 ]]. Action = [[0.07730148 0.01151441 0.         0.8312409 ]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 8859 is [True, False, False, True, False, False]
Current timestep = 8860. State = [[-0.2819463  -0.12427875]]. Action = [[ 0.01640226 -0.06998203  0.         -0.43932474]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 8860 is [True, False, False, False, True, False]
Current timestep = 8861. State = [[-0.27656662 -0.1217136 ]]. Action = [[0.08253648 0.08123275 0.         0.63800097]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 8861 is [True, False, False, False, True, False]
Current timestep = 8862. State = [[-0.26920286 -0.1174777 ]]. Action = [[0.0890098  0.02271329 0.         0.7093779 ]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 8862 is [True, False, False, False, True, False]
Current timestep = 8863. State = [[-0.2688558  -0.11799765]]. Action = [[-0.06473356 -0.04135386  0.          0.10128093]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 8863 is [True, False, False, False, True, False]
State prediction error at timestep 8863 is 0.012
Human Feedback received at timestep 8863 of None
Current timestep = 8864. State = [[-0.26927185 -0.12094731]]. Action = [[ 0.00034739 -0.04172746  0.          0.05083787]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 8864 is [True, False, False, False, True, False]
Current timestep = 8865. State = [[-0.27023327 -0.12236788]]. Action = [[-0.04863256 -0.00404777  0.         -0.5078776 ]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 8865 is [True, False, False, False, True, False]
Current timestep = 8866. State = [[-0.26965305 -0.12316454]]. Action = [[ 0.00743599 -0.01050775  0.         -0.9412954 ]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 8866 is [True, False, False, False, True, False]
Current timestep = 8867. State = [[-0.2673671  -0.12002696]]. Action = [[0.01462951 0.06938776 0.         0.17073083]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 8867 is [True, False, False, False, True, False]
Current timestep = 8868. State = [[-0.26374558 -0.1185648 ]]. Action = [[ 0.04195809 -0.01588314  0.         -0.60658365]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 8868 is [True, False, False, False, True, False]
Current timestep = 8869. State = [[-0.2585028 -0.1179029]]. Action = [[ 0.06098992  0.01359401  0.         -0.94170654]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 8869 is [True, False, False, False, True, False]
Current timestep = 8870. State = [[-0.25447205 -0.11861502]]. Action = [[ 0.02516406 -0.02802901  0.          0.8785951 ]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 8870 is [True, False, False, False, True, False]
Current timestep = 8871. State = [[-0.25337818 -0.11564653]]. Action = [[-0.01419578  0.07318699  0.          0.3887695 ]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 8871 is [True, False, False, False, True, False]
Current timestep = 8872. State = [[-0.25254762 -0.11763544]]. Action = [[ 0.00713088 -0.08491179  0.         -0.6032107 ]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 8872 is [True, False, False, False, True, False]
Current timestep = 8873. State = [[-0.24729902 -0.11726667]]. Action = [[0.0847797  0.05311849 0.         0.14052749]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 8873 is [True, False, False, False, True, False]
Current timestep = 8874. State = [[-0.24145074 -0.1198943 ]]. Action = [[ 0.0532328  -0.08584497  0.         -0.12619776]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 8874 is [True, False, False, False, True, False]
Current timestep = 8875. State = [[-0.23627691 -0.12014478]]. Action = [[ 0.05035978  0.04513728  0.         -0.93341243]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 8875 is [True, False, False, False, True, False]
Current timestep = 8876. State = [[-0.23339558 -0.11460214]]. Action = [[ 0.01072552  0.08946668  0.         -0.91652554]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 8876 is [True, False, False, False, True, False]
State prediction error at timestep 8876 is 0.012
Human Feedback received at timestep 8876 of None
Current timestep = 8877. State = [[-0.23327783 -0.10751015]]. Action = [[-0.01703032  0.08585671  0.         -0.5668709 ]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 8877 is [True, False, False, False, True, False]
State prediction error at timestep 8877 is 0.012
Human Feedback received at timestep 8877 of None
Current timestep = 8878. State = [[-0.23279339 -0.10185891]]. Action = [[0.01206325 0.04860704 0.         0.60874987]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 8878 is [True, False, False, False, True, False]
Current timestep = 8879. State = [[-0.23190655 -0.10285468]]. Action = [[ 0.0036047  -0.07024212  0.         -0.2904027 ]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 8879 is [True, False, False, False, True, False]
State prediction error at timestep 8879 is 0.012
Human Feedback received at timestep 8879 of None
Current timestep = 8880. State = [[-0.22949341 -0.10351814]]. Action = [[0.03289979 0.00910218 0.         0.9332402 ]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 8880 is [True, False, False, False, True, False]
Current timestep = 8881. State = [[-0.23161346 -0.09822555]]. Action = [[-0.07747234  0.08839936  0.          0.93149984]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 8881 is [True, False, False, False, True, False]
Current timestep = 8882. State = [[-0.23264962 -0.09113373]]. Action = [[ 0.01821367  0.07014482  0.         -0.7941885 ]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 8882 is [True, False, False, False, True, False]
Current timestep = 8883. State = [[-0.22780633 -0.08772968]]. Action = [[ 0.0956917  -0.00562207  0.         -0.9428989 ]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 8883 is [True, False, False, False, True, False]
State prediction error at timestep 8883 is 0.012
Human Feedback received at timestep 8883 of None
Current timestep = 8884. State = [[-0.22237146 -0.09034284]]. Action = [[ 0.05599117 -0.08103608  0.          0.87433386]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 8884 is [True, False, False, False, True, False]
Current timestep = 8885. State = [[-0.22329405 -0.08775961]]. Action = [[-0.07070114  0.08251136  0.          0.7041073 ]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 8885 is [True, False, False, False, True, False]
Current timestep = 8886. State = [[-0.22655642 -0.08598304]]. Action = [[-0.03026898 -0.02850842  0.         -0.35636675]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 8886 is [True, False, False, False, True, False]
Current timestep = 8887. State = [[-0.22553292 -0.08596101]]. Action = [[ 0.03842642 -0.00289835  0.          0.20988965]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 8887 is [True, False, False, False, True, False]
Current timestep = 8888. State = [[-0.22615525 -0.08259543]]. Action = [[-0.03542524  0.05528649  0.         -0.82494926]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 8888 is [True, False, False, False, True, False]
Current timestep = 8889. State = [[-0.22557762 -0.07633604]]. Action = [[ 0.03413158  0.07809994  0.         -0.42359692]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 8889 is [True, False, False, False, True, False]
State prediction error at timestep 8889 is 0.012
Human Feedback received at timestep 8889 of None
Current timestep = 8890. State = [[-0.22268924 -0.06870218]]. Action = [[ 0.05160447  0.08482634  0.         -0.89311594]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 8890 is [True, False, False, False, True, False]
Current timestep = 8891. State = [[-0.21766335 -0.06042764]]. Action = [[ 0.09011222  0.08757236  0.         -0.9572244 ]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 8891 is [True, False, False, False, True, False]
Current timestep = 8892. State = [[-0.22023426 -0.05225108]]. Action = [[-0.09391903  0.08315393  0.          0.47635996]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 8892 is [True, False, False, False, True, False]
Current timestep = 8893. State = [[-0.34668916  0.06422478]]. Action = [[-0.07629554  0.03728215  0.         -0.8416297 ]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 8893 is [True, False, False, False, True, False]
State prediction error at timestep 8893 is 0.012
Human Feedback received at timestep 8893 of None
Current timestep = 8894. State = [[-0.35098466  0.06549112]]. Action = [[-0.023316   0.0817553  0.        -0.5299538]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 8894 is [True, False, False, False, True, False]
Current timestep = 8895. State = [[-0.35656384  0.06403723]]. Action = [[-0.08222631 -0.08220239  0.         -0.75977653]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 8895 is [True, False, False, False, True, False]
State prediction error at timestep 8895 is 0.012
Human Feedback received at timestep 8895 of None
Current timestep = 8896. State = [[-0.36274865  0.06421421]]. Action = [[-0.06606683  0.04182465  0.         -0.4354049 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 8896 is [True, False, False, False, True, False]
State prediction error at timestep 8896 is 0.012
Human Feedback received at timestep 8896 of None
Current timestep = 8897. State = [[-0.37005508  0.06139642]]. Action = [[-0.09314322 -0.08913197  0.         -0.10966879]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 8897 is [True, False, False, False, True, False]
Current timestep = 8898. State = [[-0.3711551   0.06149678]]. Action = [[0.06330914 0.0534282  0.         0.19828641]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 8898 is [True, False, False, False, True, False]
Current timestep = 8899. State = [[-0.37234858  0.06496457]]. Action = [[-0.04362417  0.03710452  0.         -0.9327449 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 8899 is [True, False, False, False, True, False]
Current timestep = 8900. State = [[-0.37557212  0.06493711]]. Action = [[-0.03189046 -0.03275798  0.         -0.26769602]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 8900 is [True, False, False, False, True, False]
State prediction error at timestep 8900 is 0.012
Human Feedback received at timestep 8900 of None
Current timestep = 8901. State = [[-0.37695187  0.06434357]]. Action = [[ 0.         0.         0.        -0.9086639]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 8901 is [True, False, False, False, True, False]
Current timestep = 8902. State = [[-0.3749628   0.06186933]]. Action = [[ 0.05187938 -0.04812685  0.          0.19239056]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8902 is [True, False, False, False, True, False]
Current timestep = 8903. State = [[-0.36996818  0.05991784]]. Action = [[ 0.08084948 -0.00031888  0.         -0.08158708]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 8903 is [True, False, False, False, True, False]
Current timestep = 8904. State = [[-0.3702857   0.05484787]]. Action = [[-0.06348145 -0.08977754  0.          0.84564257]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 8904 is [True, False, False, False, True, False]
Current timestep = 8905. State = [[-0.37194023  0.05368522]]. Action = [[0.00616558 0.04496976 0.         0.56619227]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 8905 is [True, False, False, False, True, False]
State prediction error at timestep 8905 is 0.012
Human Feedback received at timestep 8905 of None
Current timestep = 8906. State = [[-0.36918277  0.05733212]]. Action = [[ 0.07377396  0.06540235  0.         -0.9455516 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 8906 is [True, False, False, False, True, False]
Current timestep = 8907. State = [[-0.3671713   0.05675221]]. Action = [[ 0.0192374  -0.03740668  0.         -0.13686562]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 8907 is [True, False, False, False, True, False]
Current timestep = 8908. State = [[-0.3623194  0.0559295]]. Action = [[ 0.09666585  0.01759794  0.         -0.22580868]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 8908 is [True, False, False, False, True, False]
State prediction error at timestep 8908 is 0.012
Human Feedback received at timestep 8908 of None
Current timestep = 8909. State = [[-0.3607191   0.05195203]]. Action = [[-0.02747552 -0.07613534  0.         -0.7505134 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 8909 is [True, False, False, False, True, False]
Current timestep = 8910. State = [[-0.3594097   0.05034209]]. Action = [[0.03753635 0.02568088 0.         0.28954113]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 8910 is [True, False, False, False, True, False]
State prediction error at timestep 8910 is 0.012
Human Feedback received at timestep 8910 of None
Current timestep = 8911. State = [[-0.3618433   0.05414256]]. Action = [[-0.06941954  0.07462468  0.         -0.65828055]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 8911 is [True, False, False, False, True, False]
State prediction error at timestep 8911 is 0.012
Human Feedback received at timestep 8911 of None
Current timestep = 8912. State = [[-0.36252478  0.05857614]]. Action = [[0.03509044 0.04616208 0.         0.54444325]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 8912 is [True, False, False, False, True, False]
Current timestep = 8913. State = [[-0.35783017  0.05577268]]. Action = [[ 0.08614751 -0.08593852  0.         -0.8754291 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 8913 is [True, False, False, False, True, False]
Current timestep = 8914. State = [[-0.35138318  0.05398727]]. Action = [[0.07755094 0.02099494 0.         0.2964673 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 8914 is [True, False, False, False, True, False]
State prediction error at timestep 8914 is 0.012
Human Feedback received at timestep 8914 of None
Current timestep = 8915. State = [[-0.3500412   0.04989278]]. Action = [[-0.03876547 -0.08713198  0.          0.1772641 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 8915 is [True, False, False, False, True, False]
State prediction error at timestep 8915 is 0.012
Human Feedback received at timestep 8915 of None
Current timestep = 8916. State = [[-0.34708676  0.04809045]]. Action = [[ 0.06479799  0.02211853  0.         -0.5747822 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 8916 is [True, False, False, False, True, False]
Current timestep = 8917. State = [[-0.34017274  0.05283192]]. Action = [[ 0.09332617  0.09568354  0.         -0.30190444]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 8917 is [True, False, False, False, True, False]
Current timestep = 8918. State = [[-0.3402977   0.05871373]]. Action = [[-0.07168063  0.06501567  0.         -0.63649917]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 8918 is [True, False, False, False, True, False]
Current timestep = 8919. State = [[-0.33940452  0.06559793]]. Action = [[ 0.06729903  0.09312425  0.         -0.08789581]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 8919 is [True, False, False, False, True, False]
Current timestep = 8920. State = [[-0.33712912  0.06645779]]. Action = [[ 0.01600705 -0.04998175  0.         -0.05834746]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 8920 is [True, False, False, False, True, False]
Current timestep = 8921. State = [[-0.33591077  0.06994529]]. Action = [[0.01061194 0.08315771 0.         0.8503618 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 8921 is [True, False, False, False, True, False]
Current timestep = 8922. State = [[-0.33054918  0.06841584]]. Action = [[ 0.09641872 -0.09952345  0.          0.4400668 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 8922 is [True, False, False, False, True, False]
Current timestep = 8923. State = [[-0.32668823  0.0639742 ]]. Action = [[-0.0009404  -0.04458055  0.         -0.10016352]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 8923 is [True, False, False, False, True, False]
Current timestep = 8924. State = [[-0.3225144   0.06350862]]. Action = [[0.05131593 0.01224288 0.         0.00362432]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 8924 is [True, False, False, False, True, False]
Current timestep = 8925. State = [[-0.32021058  0.06299186]]. Action = [[-0.01514589 -0.02061791  0.          0.7836139 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 8925 is [True, False, False, False, True, False]
State prediction error at timestep 8925 is 0.012
Human Feedback received at timestep 8925 of None
Current timestep = 8926. State = [[-0.32322147  0.06708154]]. Action = [[-0.08795132  0.08593383  0.         -0.5540214 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 8926 is [True, False, False, False, True, False]
Current timestep = 8927. State = [[-0.32592776  0.06941263]]. Action = [[-0.02657497 -0.01817839  0.         -0.71848065]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 8927 is [True, False, False, False, True, False]
State prediction error at timestep 8927 is 0.012
Human Feedback received at timestep 8927 of None
Current timestep = 8928. State = [[-0.32869503  0.06888679]]. Action = [[-0.05650505 -0.01867439  0.          0.55151486]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 8928 is [True, False, False, False, True, False]
Current timestep = 8929. State = [[-0.32509923  0.06671099]]. Action = [[ 0.09774428 -0.041521    0.          0.79959   ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 8929 is [True, False, False, False, True, False]
Current timestep = 8930. State = [[-0.32551852  0.06853589]]. Action = [[-0.0806414   0.05795696  0.          0.45898032]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 8930 is [True, False, False, False, True, False]
State prediction error at timestep 8930 is 0.012
Human Feedback received at timestep 8930 of None
Current timestep = 8931. State = [[-0.33145767  0.067164  ]]. Action = [[-0.08894225 -0.07262252  0.         -0.48939294]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 8931 is [True, False, False, False, True, False]
Current timestep = 8932. State = [[-0.33418044  0.0692435 ]]. Action = [[-0.00405196  0.07357537  0.         -0.07130539]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 8932 is [True, False, False, False, True, False]
Current timestep = 8933. State = [[-0.33039528  0.06832651]]. Action = [[ 0.09020185 -0.06567179  0.          0.6119956 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 8933 is [True, False, False, False, True, False]
Current timestep = 8934. State = [[-0.32697377  0.06452356]]. Action = [[ 0.02066757 -0.03439965  0.          0.08565938]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 8934 is [True, False, False, False, True, False]
Current timestep = 8935. State = [[-0.3265155   0.06203235]]. Action = [[-0.01090845 -0.01992899  0.          0.8136451 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 8935 is [True, False, False, False, True, False]
Current timestep = 8936. State = [[-0.3244552   0.06253608]]. Action = [[0.0436039  0.03297587 0.         0.1574601 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 8936 is [True, False, False, False, True, False]
Current timestep = 8937. State = [[-0.31969255  0.05955748]]. Action = [[ 0.07100945 -0.06454301  0.          0.45719314]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 8937 is [True, False, False, False, True, False]
Current timestep = 8938. State = [[-0.31509688  0.0534559 ]]. Action = [[ 0.04045673 -0.06664889  0.         -0.27641523]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 8938 is [True, False, False, False, True, False]
Current timestep = 8939. State = [[-0.31373477  0.05132388]]. Action = [[-0.01529904  0.01974281  0.         -0.41582978]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 8939 is [True, False, False, False, True, False]
Current timestep = 8940. State = [[-0.31201395  0.04625131]]. Action = [[ 0.02431538 -0.09016986  0.          0.7466786 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 8940 is [True, False, False, False, True, False]
State prediction error at timestep 8940 is 0.012
Human Feedback received at timestep 8940 of None
Current timestep = 8941. State = [[-0.3069474   0.03800221]]. Action = [[ 0.06634717 -0.0864475   0.         -0.5129361 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 8941 is [True, False, False, False, True, False]
Current timestep = 8942. State = [[-0.30066276  0.029571  ]]. Action = [[ 0.06132372 -0.08097967  0.         -0.42209077]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 8942 is [True, False, False, False, True, False]
Current timestep = 8943. State = [[-0.30104673  0.02772651]]. Action = [[-0.07854942  0.05093583  0.          0.6302521 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 8943 is [True, False, False, False, True, False]
Current timestep = 8944. State = [[-0.30682454  0.03013916]]. Action = [[-0.09736415  0.04988187  0.         -0.6227996 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 8944 is [True, False, False, False, True, False]
State prediction error at timestep 8944 is 0.012
Human Feedback received at timestep 8944 of None
Current timestep = 8945. State = [[-0.31406552  0.03236079]]. Action = [[-0.09587321  0.03045291  0.          0.13115585]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 8945 is [True, False, False, False, True, False]
State prediction error at timestep 8945 is 0.012
Human Feedback received at timestep 8945 of None
Current timestep = 8946. State = [[-0.32046536  0.03658508]]. Action = [[-0.06056439  0.07075318  0.          0.51307917]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 8946 is [True, False, False, False, True, False]
Current timestep = 8947. State = [[-0.32287753  0.04338493]]. Action = [[ 0.02173477  0.08879862  0.         -0.09730119]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 8947 is [True, False, False, False, True, False]
State prediction error at timestep 8947 is 0.012
Human Feedback received at timestep 8947 of None
Current timestep = 8948. State = [[-0.32476097  0.05134181]]. Action = [[-4.2533875e-04  9.2029057e-02  0.0000000e+00  6.5212297e-01]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 8948 is [True, False, False, False, True, False]
State prediction error at timestep 8948 is 0.012
Human Feedback received at timestep 8948 of None
Current timestep = 8949. State = [[-0.32751852  0.05328719]]. Action = [[-0.00871153 -0.03719478  0.          0.18713474]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 8949 is [True, False, False, False, True, False]
Current timestep = 8950. State = [[-0.32510954  0.04913973]]. Action = [[ 0.09201013 -0.08030175  0.          0.34894788]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 8950 is [True, False, False, False, True, False]
Current timestep = 8951. State = [[-0.32549235  0.04454726]]. Action = [[-0.0408993  -0.05205264  0.         -0.40289253]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 8951 is [True, False, False, False, True, False]
Current timestep = 8952. State = [[-0.33093512  0.04100368]]. Action = [[-0.08035161 -0.04419702  0.          0.6548114 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 8952 is [True, False, False, False, True, False]
Current timestep = 8953. State = [[-0.335191    0.04128023]]. Action = [[-0.03050458  0.03031459  0.          0.00420499]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 8953 is [True, False, False, False, True, False]
Current timestep = 8954. State = [[-0.33533755  0.04061762]]. Action = [[ 0.03290033 -0.02851417  0.         -0.441872  ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 8954 is [True, False, False, False, True, False]
Current timestep = 8955. State = [[-0.33799767  0.04215566]]. Action = [[-0.05649516  0.05093961  0.         -0.04418695]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 8955 is [True, False, False, False, True, False]
Current timestep = 8956. State = [[-0.3395929  0.0393515]]. Action = [[ 0.01425968 -0.08364078  0.         -0.25902325]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 8956 is [True, False, False, False, True, False]
Current timestep = 8957. State = [[-0.340149   0.0357261]]. Action = [[-0.00936107 -0.01734833  0.         -0.847785  ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 8957 is [True, False, False, False, True, False]
State prediction error at timestep 8957 is 0.012
Human Feedback received at timestep 8957 of None
Current timestep = 8958. State = [[-0.34008208  0.03221333]]. Action = [[ 0.01261865 -0.04593184  0.         -0.44056284]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 8958 is [True, False, False, False, True, False]
Current timestep = 8959. State = [[-0.3439119  0.0273833]]. Action = [[-0.08587036 -0.05530001  0.          0.7323433 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 8959 is [True, False, False, False, True, False]
Current timestep = 8960. State = [[-0.3507008   0.02986283]]. Action = [[-0.0844866   0.09896555  0.          0.37379146]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 8960 is [True, False, False, False, True, False]
State prediction error at timestep 8960 is 0.012
Human Feedback received at timestep 8960 of None
Current timestep = 8961. State = [[-0.35836235  0.03009041]]. Action = [[-0.0872598  -0.04758609  0.         -0.89536804]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 8961 is [True, False, False, False, True, False]
State prediction error at timestep 8961 is 0.012
Human Feedback received at timestep 8961 of None
Current timestep = 8962. State = [[-0.36207405  0.02949261]]. Action = [[0.00208981 0.01765101 0.         0.6717392 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 8962 is [True, False, False, False, True, False]
State prediction error at timestep 8962 is 0.012
Human Feedback received at timestep 8962 of None
Current timestep = 8963. State = [[-0.36078358  0.03304207]]. Action = [[0.06822812 0.06677867 0.         0.97509074]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 8963 is [True, False, False, False, True, False]
Current timestep = 8964. State = [[-0.36504978  0.03671075]]. Action = [[-0.08774452  0.03318702  0.         -0.27873957]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 8964 is [True, False, False, False, True, False]
Current timestep = 8965. State = [[-0.37049934  0.03519226]]. Action = [[-0.01506741 -0.05568075  0.         -0.69527054]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 8965 is [True, False, False, False, True, False]
State prediction error at timestep 8965 is 0.012
Human Feedback received at timestep 8965 of None
Current timestep = 8966. State = [[-0.370027    0.02958334]]. Action = [[ 0.06185516 -0.07893108  0.         -0.15378451]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 8966 is [True, False, False, False, True, False]
Current timestep = 8967. State = [[-0.3698563   0.02667998]]. Action = [[0.         0.         0.         0.94960546]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 8967 is [True, False, False, False, True, False]
Current timestep = 8968. State = [[-0.36738485  0.03070785]]. Action = [[0.08021667 0.09422674 0.         0.61850667]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 8968 is [True, False, False, False, True, False]
State prediction error at timestep 8968 is 0.012
Human Feedback received at timestep 8968 of None
Current timestep = 8969. State = [[-0.36403015  0.03155585]]. Action = [[ 0.05432408 -0.0305657   0.         -0.51457316]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 8969 is [True, False, False, False, True, False]
Current timestep = 8970. State = [[-0.35922095  0.02953626]]. Action = [[ 0.08137908 -0.01610662  0.         -0.8427635 ]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 8970 is [True, False, False, False, True, False]
Current timestep = 8971. State = [[-0.3596374   0.02978834]]. Action = [[-0.05586073  0.02478955  0.          0.5657213 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 8971 is [True, False, False, False, True, False]
Current timestep = 8972. State = [[-0.3586083   0.03199758]]. Action = [[0.05927951 0.0363555  0.         0.8962382 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 8972 is [True, False, False, False, True, False]
Current timestep = 8973. State = [[-0.36028013  0.028638  ]]. Action = [[-0.07023492 -0.08727136  0.         -0.42914212]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 8973 is [True, False, False, False, True, False]
Current timestep = 8974. State = [[-0.36175513  0.02102307]]. Action = [[-0.0004608  -0.09841718  0.         -0.19139022]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 8974 is [True, False, False, False, True, False]
State prediction error at timestep 8974 is 0.012
Human Feedback received at timestep 8974 of None
Current timestep = 8975. State = [[-0.3643073   0.01775596]]. Action = [[-0.06241341  0.00673486  0.         -0.03665751]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 8975 is [True, False, False, False, True, False]
Current timestep = 8976. State = [[-0.36246765  0.01220889]]. Action = [[ 0.06424656 -0.09691966  0.          0.9066398 ]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 8976 is [True, False, False, False, True, False]
Current timestep = 8977. State = [[-0.35658753  0.00536922]]. Action = [[ 0.07000601 -0.05644428  0.         -0.67374635]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 8977 is [True, False, False, False, True, False]
Current timestep = 8978. State = [[-0.3514401   0.00107537]]. Action = [[ 0.04471873 -0.02052597  0.          0.5579586 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 8978 is [True, False, False, False, True, False]
Current timestep = 8979. State = [[-0.3482555 -0.0036666]]. Action = [[ 0.01658671 -0.04931433  0.         -0.04218185]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 8979 is [True, False, False, False, True, False]
Current timestep = 8980. State = [[-0.34613585 -0.0044458 ]]. Action = [[0.01250772 0.0473214  0.         0.20334637]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 8980 is [True, False, False, False, True, False]
State prediction error at timestep 8980 is 0.012
Human Feedback received at timestep 8980 of None
Current timestep = 8981. State = [[-0.344135   -0.00591058]]. Action = [[ 0.01988832 -0.0263885   0.         -0.78780556]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 8981 is [True, False, False, False, True, False]
Current timestep = 8982. State = [[-0.34446368 -0.0075449 ]]. Action = [[-0.03171695  0.00747278  0.         -0.9029245 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 8982 is [True, False, False, False, True, False]
Current timestep = 8983. State = [[-0.34752122 -0.01332812]]. Action = [[-0.05967041 -0.0962721   0.          0.19982338]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 8983 is [True, False, False, False, True, False]
State prediction error at timestep 8983 is 0.012
Human Feedback received at timestep 8983 of None
Current timestep = 8984. State = [[-0.3512763  -0.02037721]]. Action = [[-0.05899645 -0.05910438  0.         -0.1791451 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 8984 is [True, False, False, False, True, False]
Current timestep = 8985. State = [[-0.35192204 -0.02822221]]. Action = [[ 0.00909398 -0.09007972  0.          0.24461544]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 8985 is [True, False, False, False, True, False]
Current timestep = 8986. State = [[-0.34754738 -0.03449084]]. Action = [[ 0.07878689 -0.0385494   0.         -0.5109907 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 8986 is [True, False, False, False, True, False]
Current timestep = 8987. State = [[-0.345914   -0.04043037]]. Action = [[-0.01896094 -0.06081781  0.          0.77891517]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 8987 is [True, False, False, False, True, False]
State prediction error at timestep 8987 is 0.012
Human Feedback received at timestep 8987 of None
Current timestep = 8988. State = [[-0.34868366 -0.03996564]]. Action = [[-0.05442796  0.08069714  0.         -0.98524123]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 8988 is [True, False, False, False, True, False]
Current timestep = 8989. State = [[-0.3488906  -0.04049144]]. Action = [[ 0.03261583 -0.03062057  0.         -0.3575759 ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 8989 is [True, False, False, False, True, False]
Current timestep = 8990. State = [[-0.35192975 -0.04147007]]. Action = [[-0.07542942  0.01761107  0.          0.5151135 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 8990 is [True, False, False, False, True, False]
Current timestep = 8991. State = [[-0.35804176 -0.04035598]]. Action = [[-0.07096694  0.02982681  0.         -0.25952643]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 8991 is [True, False, False, False, True, False]
Current timestep = 8992. State = [[-0.35755715 -0.03583766]]. Action = [[ 0.08204719  0.0749392   0.         -0.84550023]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 8992 is [True, False, False, False, True, False]
State prediction error at timestep 8992 is 0.012
Human Feedback received at timestep 8992 of None
Current timestep = 8993. State = [[-0.35689119 -0.03736632]]. Action = [[-0.01419161 -0.09310994  0.         -0.7700557 ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 8993 is [True, False, False, False, True, False]
Current timestep = 8994. State = [[-0.36231628 -0.03691195]]. Action = [[-0.0952291   0.06537151  0.          0.76394486]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 8994 is [True, False, False, False, True, False]
Current timestep = 8995. State = [[-0.36622107 -0.03184849]]. Action = [[-0.00132323  0.06342033  0.         -0.16413057]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 8995 is [True, False, False, False, True, False]
State prediction error at timestep 8995 is 0.012
Human Feedback received at timestep 8995 of None
Current timestep = 8996. State = [[-0.3682635 -0.0306708]]. Action = [[-0.00941822 -0.02826154  0.          0.15736032]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 8996 is [True, False, False, False, True, False]
Current timestep = 8997. State = [[-0.37338576 -0.02788912]]. Action = [[-0.07287817  0.05908539  0.          0.7095711 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 8997 is [True, False, False, False, True, False]
State prediction error at timestep 8997 is 0.012
Human Feedback received at timestep 8997 of None
Current timestep = 8998. State = [[-0.37691948 -0.0254848 ]]. Action = [[0.         0.         0.         0.09306288]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 8998 is [True, False, False, False, True, False]
Current timestep = 8999. State = [[-0.37680244 -0.02227679]]. Action = [[ 0.03700841  0.04372724  0.         -0.9501489 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 8999 is [True, False, False, False, True, False]
Current timestep = 9000. State = [[-0.37304735 -0.02051925]]. Action = [[ 0.09084975 -0.01369447  0.         -0.2910366 ]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 9000 is [True, False, False, False, True, False]
Current timestep = 9001. State = [[-0.3727687  -0.01769209]]. Action = [[-0.0223377   0.04357561  0.          0.5045786 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 9001 is [True, False, False, False, True, False]
Current timestep = 9002. State = [[-0.37226388 -0.01829871]]. Action = [[ 0.04408077 -0.0541045   0.          0.9571276 ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 9002 is [True, False, False, False, True, False]
Current timestep = 9003. State = [[-0.36859602 -0.01450757]]. Action = [[ 0.06976651  0.09662085  0.         -0.1276676 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 9003 is [True, False, False, False, True, False]
State prediction error at timestep 9003 is 0.012
Human Feedback received at timestep 9003 of None
Current timestep = 9004. State = [[-0.36922854 -0.00608392]]. Action = [[-0.03449351  0.09593835  0.          0.6841731 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 9004 is [True, False, False, False, True, False]
Current timestep = 9005. State = [[-0.37059462 -0.00133762]]. Action = [[0.01117368 0.01407961 0.         0.15478504]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 9005 is [True, False, False, False, True, False]
Current timestep = 9006. State = [[-0.36949497 -0.00044062]]. Action = [[ 0.03063074 -0.01721442  0.          0.80972624]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 9006 is [True, False, False, False, True, False]
State prediction error at timestep 9006 is 0.012
Human Feedback received at timestep 9006 of None
Current timestep = 9007. State = [[-0.36938086  0.00320179]]. Action = [[-0.00868462  0.06008307  0.          0.1445179 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 9007 is [True, False, False, False, True, False]
Current timestep = 9008. State = [[-0.36984015  0.0060983 ]]. Action = [[0.        0.        0.        0.0472734]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 9008 is [True, False, False, False, True, False]
Current timestep = 9009. State = [[-0.36721337  0.00835972]]. Action = [[ 0.05400489  0.02061178  0.         -0.3727163 ]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 9009 is [True, False, False, False, True, False]
Current timestep = 9010. State = [[-0.36431798  0.00697047]]. Action = [[ 0.02136876 -0.06035696  0.         -0.58812636]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 9010 is [True, False, False, False, True, False]
Current timestep = 9011. State = [[-0.36412802  0.00962366]]. Action = [[-0.02402913  0.07396664  0.         -0.34895182]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 9011 is [True, False, False, False, True, False]
Current timestep = 9012. State = [[-0.36187297  0.01618099]]. Action = [[ 0.05268707  0.07278094  0.         -0.8112537 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 9012 is [True, False, False, False, True, False]
State prediction error at timestep 9012 is 0.012
Human Feedback received at timestep 9012 of None
Current timestep = 9013. State = [[-0.3590663   0.02128088]]. Action = [[0.02601396 0.03646059 0.         0.841624  ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 9013 is [True, False, False, False, True, False]
Current timestep = 9014. State = [[-0.3574285   0.01858445]]. Action = [[ 0.00674318 -0.09920263  0.          0.7810509 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 9014 is [True, False, False, False, True, False]
Current timestep = 9015. State = [[-0.35887522  0.01909516]]. Action = [[-0.05399449  0.05460914  0.          0.21327746]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 9015 is [True, False, False, False, True, False]
Current timestep = 9016. State = [[-0.36220306  0.02090642]]. Action = [[-0.05611157 -0.00863629  0.          0.08859754]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 9016 is [True, False, False, False, True, False]
Current timestep = 9017. State = [[-0.36195192  0.01957798]]. Action = [[ 0.02166238 -0.03749108  0.          0.10978413]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 9017 is [True, False, False, False, True, False]
Current timestep = 9018. State = [[-0.3600962   0.01865136]]. Action = [[ 0.01213209 -0.00435304  0.          0.68625903]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 9018 is [True, False, False, False, True, False]
Current timestep = 9019. State = [[-0.3552731   0.01912815]]. Action = [[ 0.0804617   0.00975708  0.         -0.15224582]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 9019 is [True, False, False, False, True, False]
Current timestep = 9020. State = [[-0.34777144  0.01805419]]. Action = [[ 0.09886628 -0.02627765  0.          0.5978277 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 9020 is [True, False, False, False, True, False]
Current timestep = 9021. State = [[-0.3475969   0.01829531]]. Action = [[-0.07896201  0.02356502  0.         -0.61504865]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 9021 is [True, False, False, False, True, False]
Current timestep = 9022. State = [[-0.34636897  0.01585311]]. Action = [[ 0.06232233 -0.05805321  0.          0.30849826]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 9022 is [True, False, False, False, True, False]
Current timestep = 9023. State = [[-0.34804055  0.01803141]]. Action = [[-0.07656744  0.084158    0.         -0.14655274]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 9023 is [True, False, False, False, True, False]
Current timestep = 9024. State = [[-0.3525157  0.02192  ]]. Action = [[-0.04660119  0.03086404  0.         -0.7408792 ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 9024 is [True, False, False, False, True, False]
Current timestep = 9025. State = [[-0.35621366  0.02396504]]. Action = [[-0.03752198  0.01475744  0.          0.46975708]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 9025 is [True, False, False, False, True, False]
Current timestep = 9026. State = [[-0.3567097   0.02718274]]. Action = [[0.02781086 0.04595151 0.         0.07223034]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 9026 is [True, False, False, False, True, False]
Current timestep = 9027. State = [[-0.35342717  0.02590754]]. Action = [[ 0.0718246  -0.06216253  0.          0.05020154]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 9027 is [True, False, False, False, True, False]
State prediction error at timestep 9027 is 0.012
Human Feedback received at timestep 9027 of None
Current timestep = 9028. State = [[-0.35598135  0.02602136]]. Action = [[-0.08969437  0.0317289   0.         -0.7274958 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 9028 is [True, False, False, False, True, False]
Current timestep = 9029. State = [[-0.36267263  0.0268683 ]]. Action = [[-0.07357794 -0.00733321  0.         -0.26943982]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 9029 is [True, False, False, False, True, False]
State prediction error at timestep 9029 is 0.012
Human Feedback received at timestep 9029 of None
Current timestep = 9030. State = [[-0.36893794  0.02318847]]. Action = [[-0.07007165 -0.07840806  0.          0.9205121 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 9030 is [True, False, False, False, True, False]
State prediction error at timestep 9030 is 0.012
Human Feedback received at timestep 9030 of None
Current timestep = 9031. State = [[-0.37059018  0.02544083]]. Action = [[0.03156333 0.09461745 0.         0.35367048]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 9031 is [True, False, False, False, True, False]
Current timestep = 9032. State = [[-0.3708361   0.02382254]]. Action = [[-0.00096585 -0.09969071  0.          0.77756894]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 9032 is [True, False, False, False, True, False]
Current timestep = 9033. State = [[-0.37401292  0.01759805]]. Action = [[-0.05856813 -0.06835491  0.          0.15850568]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 9033 is [True, False, False, False, True, False]
Current timestep = 9034. State = [[-0.37174487  0.01477007]]. Action = [[ 0.09116852 -0.0032474   0.         -0.4900509 ]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 9034 is [True, False, False, False, True, False]
State prediction error at timestep 9034 is 0.012
Human Feedback received at timestep 9034 of None
Current timestep = 9035. State = [[-0.36920798  0.01821232]]. Action = [[ 0.00644193  0.08649515  0.         -0.52488256]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 9035 is [True, False, False, False, True, False]
Current timestep = 9036. State = [[-0.37253895  0.01911343]]. Action = [[-0.06856596 -0.02565879  0.          0.0549432 ]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 9036 is [True, False, False, False, True, False]
Current timestep = 9037. State = [[-0.37466946  0.0182352 ]]. Action = [[ 0.         0.         0.        -0.1576035]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 9037 is [True, False, False, False, True, False]
Current timestep = 9038. State = [[-0.37183312  0.01852209]]. Action = [[ 0.07089586  0.01167097  0.         -0.4503864 ]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 9038 is [True, False, False, False, True, False]
Current timestep = 9039. State = [[-0.37265012  0.02119539]]. Action = [[-0.04532885  0.0499522   0.          0.93774533]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 9039 is [True, False, False, False, True, False]
State prediction error at timestep 9039 is 0.012
Human Feedback received at timestep 9039 of None
Current timestep = 9040. State = [[-0.3756662   0.02634992]]. Action = [[-0.01880556  0.07083105  0.         -0.81414354]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 9040 is [True, False, False, False, True, False]
State prediction error at timestep 9040 is 0.012
Human Feedback received at timestep 9040 of None
Current timestep = 9041. State = [[-0.37739924  0.02896966]]. Action = [[ 0.         0.         0.        -0.1037032]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 9041 is [True, False, False, False, True, False]
Current timestep = 9042. State = [[-0.37412527  0.03182128]]. Action = [[ 0.09132097  0.04364856  0.         -0.19792253]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 9042 is [True, False, False, False, True, False]
Current timestep = 9043. State = [[-0.37379774  0.03625837]]. Action = [[-0.0241936   0.05050423  0.         -0.2298106 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 9043 is [True, False, False, False, True, False]
State prediction error at timestep 9043 is 0.012
Human Feedback received at timestep 9043 of None
Current timestep = 9044. State = [[-0.37246338  0.03684162]]. Action = [[ 0.05615415 -0.03479563  0.         -0.87048924]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 9044 is [True, False, False, False, True, False]
Current timestep = 9045. State = [[-0.37235513  0.03783226]]. Action = [[-0.02209159  0.02426173  0.         -0.85212487]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 9045 is [True, False, False, False, True, False]
Current timestep = 9046. State = [[-0.37178993  0.03688674]]. Action = [[ 0.02299814 -0.04702234  0.          0.3795265 ]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 9046 is [True, False, False, False, True, False]
State prediction error at timestep 9046 is 0.012
Human Feedback received at timestep 9046 of None
Current timestep = 9047. State = [[-0.3696943   0.03734832]]. Action = [[ 0.02296581  0.02523916  0.         -0.9382792 ]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 9047 is [True, False, False, False, True, False]
State prediction error at timestep 9047 is 0.012
Human Feedback received at timestep 9047 of None
Current timestep = 9048. State = [[-0.37028402  0.04109031]]. Action = [[-0.03136604  0.05175791  0.          0.98290634]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 9048 is [True, False, False, False, True, False]
Current timestep = 9049. State = [[-0.36975354  0.04185922]]. Action = [[ 0.02311363 -0.02781335  0.          0.8834268 ]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 9049 is [True, False, False, False, True, False]
Current timestep = 9050. State = [[-0.36865845  0.04161206]]. Action = [[0.         0.         0.         0.07941222]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 9050 is [True, False, False, False, True, False]
Current timestep = 9051. State = [[-0.36943564  0.04120463]]. Action = [[-0.0283212  -0.01572487  0.          0.66258526]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 9051 is [True, False, False, False, True, False]
Current timestep = 9052. State = [[-0.36507758  0.04332216]]. Action = [[0.09935231 0.04676972 0.         0.835214  ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 9052 is [True, False, False, False, True, False]
Current timestep = 9053. State = [[-0.36379638  0.04928602]]. Action = [[-0.03782725  0.08724426  0.         -0.4524902 ]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 9053 is [True, False, False, False, True, False]
Current timestep = 9054. State = [[-0.36292595  0.04833422]]. Action = [[ 0.02965803 -0.08863211  0.          0.35901046]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 9054 is [True, False, False, False, True, False]
State prediction error at timestep 9054 is 0.012
Human Feedback received at timestep 9054 of None
Current timestep = 9055. State = [[-0.35689706  0.04565841]]. Action = [[ 0.09180572 -0.00848769  0.          0.01880431]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 9055 is [True, False, False, False, True, False]
State prediction error at timestep 9055 is 0.012
Human Feedback received at timestep 9055 of None
Current timestep = 9056. State = [[-0.35482082  0.04591873]]. Action = [[-0.0300415   0.01328965  0.         -0.3193184 ]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 9056 is [True, False, False, False, True, False]
Current timestep = 9057. State = [[-0.35884935  0.04559456]]. Action = [[-0.08906832 -0.01824655  0.          0.9956814 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 9057 is [True, False, False, False, True, False]
State prediction error at timestep 9057 is 0.012
Human Feedback received at timestep 9057 of None
Current timestep = 9058. State = [[-0.3599982   0.04347983]]. Action = [[ 0.0082676  -0.03826075  0.         -0.29604352]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 9058 is [True, False, False, False, True, False]
Current timestep = 9059. State = [[-0.36327636  0.03806404]]. Action = [[-0.08964247 -0.08762466  0.         -0.02782482]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 9059 is [True, False, False, False, True, False]
Current timestep = 9060. State = [[-0.36111763  0.03803635]]. Action = [[ 0.09531952  0.05994507  0.         -0.41867244]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 9060 is [True, False, False, False, True, False]
Current timestep = 9061. State = [[-0.36080727  0.04389937]]. Action = [[-0.06131816  0.08690722  0.          0.3989637 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 9061 is [True, False, False, False, True, False]
Current timestep = 9062. State = [[-0.36126468  0.04577966]]. Action = [[ 0.01652317 -0.02125578  0.         -0.49330533]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 9062 is [True, False, False, False, True, False]
State prediction error at timestep 9062 is 0.012
Human Feedback received at timestep 9062 of None
Current timestep = 9063. State = [[-0.36244273  0.04631868]]. Action = [[-0.03747847  0.01451002  0.         -0.08639765]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 9063 is [True, False, False, False, True, False]
Current timestep = 9064. State = [[-0.36693949  0.04847119]]. Action = [[-0.07161729  0.02620145  0.          0.57778084]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 9064 is [True, False, False, False, True, False]
Current timestep = 9065. State = [[-0.36603183  0.04640992]]. Action = [[ 0.06690174 -0.06634746  0.          0.9787805 ]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 9065 is [True, False, False, False, True, False]
Current timestep = 9066. State = [[-0.36092663  0.04004936]]. Action = [[ 0.06770053 -0.08779348  0.         -0.650296  ]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 9066 is [True, False, False, False, True, False]
Current timestep = 9067. State = [[-0.35909143  0.03647209]]. Action = [[-0.01381856 -0.00875104  0.          0.9838872 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 9067 is [True, False, False, False, True, False]
Current timestep = 9068. State = [[-0.3585711   0.03563607]]. Action = [[0.00489243 0.00176334 0.         0.8365202 ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 9068 is [True, False, False, False, True, False]
Current timestep = 9069. State = [[-0.35982686  0.03186154]]. Action = [[-0.04000518 -0.06463055  0.          0.84473896]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 9069 is [True, False, False, False, True, False]
Current timestep = 9070. State = [[-0.36033827  0.03113822]]. Action = [[0.00115067 0.03749167 0.         0.8594295 ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 9070 is [True, False, False, False, True, False]
Current timestep = 9071. State = [[-0.36297995  0.03531972]]. Action = [[-0.05227147  0.07509174  0.         -0.5940905 ]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 9071 is [True, False, False, False, True, False]
Current timestep = 9072. State = [[-0.363065    0.03967602]]. Action = [[ 0.04336233  0.04542813  0.         -0.8447159 ]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 9072 is [True, False, False, False, True, False]
Current timestep = 9073. State = [[-0.36510897  0.0446208 ]]. Action = [[-0.04242276  0.06766225  0.         -0.9555052 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 9073 is [True, False, False, False, True, False]
Current timestep = 9074. State = [[-0.3656867  0.0516866]]. Action = [[ 0.04212726  0.09075799  0.         -0.47991407]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 9074 is [True, False, False, False, True, False]
Current timestep = 9075. State = [[-0.3623378   0.05581205]]. Action = [[0.08355895 0.01446439 0.         0.24909687]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 9075 is [True, False, False, False, True, False]
State prediction error at timestep 9075 is 0.012
Human Feedback received at timestep 9075 of None
Current timestep = 9076. State = [[-0.36001334  0.05688492]]. Action = [[ 0.02522891 -0.00353903  0.          0.8063657 ]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 9076 is [True, False, False, False, True, False]
Current timestep = 9077. State = [[-0.35626495  0.05964152]]. Action = [[ 0.07474943  0.04190909  0.         -0.28743207]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 9077 is [True, False, False, False, True, False]
State prediction error at timestep 9077 is 0.012
Human Feedback received at timestep 9077 of None
Current timestep = 9078. State = [[-0.35503653  0.06500167]]. Action = [[-0.00763105  0.06713869  0.          0.04984021]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 9078 is [True, False, False, False, True, False]
Current timestep = 9079. State = [[-0.3539911   0.06951509]]. Action = [[0.03063821 0.0288124  0.         0.34817684]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 9079 is [True, False, False, False, True, False]
Current timestep = 9080. State = [[-0.35462546  0.07614473]]. Action = [[-0.02640387  0.08915608  0.          0.2912209 ]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 9080 is [True, False, False, False, True, False]
State prediction error at timestep 9080 is 0.012
Human Feedback received at timestep 9080 of None
Current timestep = 9081. State = [[-0.35163608  0.08036613]]. Action = [[0.07880843 0.00295289 0.         0.13307929]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 9081 is [True, False, False, False, True, False]
Current timestep = 9082. State = [[-0.35074344  0.07717898]]. Action = [[-0.0403087  -0.09999733  0.         -0.387357  ]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 9082 is [True, False, False, False, True, False]
State prediction error at timestep 9082 is 0.012
Human Feedback received at timestep 9082 of None
Current timestep = 9083. State = [[-0.35166848  0.07491759]]. Action = [[-0.01796774 -0.0170122   0.         -0.82775766]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 9083 is [True, False, False, False, True, False]
Current timestep = 9084. State = [[-0.35328418  0.07292447]]. Action = [[-0.04360613 -0.05160508  0.         -0.01939899]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 9084 is [True, False, False, False, True, False]
Current timestep = 9085. State = [[-0.35149702  0.07351129]]. Action = [[ 0.04153647  0.02658773  0.         -0.3882178 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 9085 is [True, False, False, False, True, False]
State prediction error at timestep 9085 is 0.012
Human Feedback received at timestep 9085 of None
Current timestep = 9086. State = [[-0.34878078  0.07896227]]. Action = [[ 0.01983323  0.08734942  0.         -0.8231229 ]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 9086 is [True, False, False, False, True, False]
Current timestep = 9087. State = [[-0.35136807  0.07779019]]. Action = [[-0.0815166  -0.08941349  0.         -0.5709438 ]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 9087 is [True, False, False, False, True, False]
Current timestep = 9088. State = [[-0.35126364  0.07429853]]. Action = [[ 0.03867384 -0.0280168   0.          0.45089567]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 9088 is [True, False, False, False, True, False]
Current timestep = 9089. State = [[-0.35152727  0.07673859]]. Action = [[-0.03207042  0.06870284  0.         -0.9488869 ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 9089 is [True, False, False, False, True, False]
Current timestep = 9090. State = [[-0.35729828  0.07998136]]. Action = [[-0.09895147  0.02067582  0.         -0.96929747]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 9090 is [True, False, False, False, True, False]
State prediction error at timestep 9090 is 0.012
Human Feedback received at timestep 9090 of None
Current timestep = 9091. State = [[-0.35884303  0.08150768]]. Action = [[ 0.03604404  0.00802471  0.         -0.91792727]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 9091 is [True, False, False, False, True, False]
Current timestep = 9092. State = [[-0.35763445  0.08253033]]. Action = [[ 0.01812694  0.01100284  0.         -0.97803295]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 9092 is [True, False, False, False, True, False]
Current timestep = 9093. State = [[-0.36010143  0.08488829]]. Action = [[-0.04957924  0.03596776  0.          0.47618413]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 9093 is [True, False, False, False, True, False]
Current timestep = 9094. State = [[-0.3641689  0.0876578]]. Action = [[-0.03929077  0.02416877  0.          0.25645614]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 9094 is [True, False, False, False, True, False]
Current timestep = 9095. State = [[-0.36772707  0.09153423]]. Action = [[-0.02708536  0.05011087  0.          0.35552692]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 9095 is [True, False, False, False, True, False]
State prediction error at timestep 9095 is 0.012
Human Feedback received at timestep 9095 of None
Current timestep = 9096. State = [[-0.37096134  0.09178707]]. Action = [[-0.02618332 -0.03945236  0.          0.15332139]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 9096 is [True, False, False, False, True, False]
Current timestep = 9097. State = [[-0.37168667  0.09511075]]. Action = [[0.02405717 0.07635555 0.         0.30213785]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 9097 is [True, False, False, False, True, False]
Current timestep = 9098. State = [[-0.37399548  0.10117244]]. Action = [[-0.02904305  0.06788247  0.          0.36292028]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 9098 is [True, False, False, False, True, False]
Current timestep = 9099. State = [[-0.37728262  0.10321438]]. Action = [[-0.02162694 -0.01648753  0.         -0.9479425 ]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 9099 is [True, False, False, False, True, False]
Current timestep = 9100. State = [[-0.37903583  0.10370433]]. Action = [[ 0.          0.          0.         -0.14269495]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 9100 is [True, False, False, False, True, False]
Current timestep = 9101. State = [[-0.37822616  0.10298784]]. Action = [[ 0.03534747 -0.02754016  0.          0.20756972]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 9101 is [True, False, False, False, True, False]
Current timestep = 9102. State = [[-0.3770592   0.10304152]]. Action = [[0.01415817 0.00869264 0.         0.5234554 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 9102 is [True, False, False, False, True, False]
Current timestep = 9103. State = [[-0.37412515  0.10150184]]. Action = [[ 0.05466225 -0.03999848  0.          0.47512412]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 9103 is [True, False, False, False, True, False]
State prediction error at timestep 9103 is 0.012
Human Feedback received at timestep 9103 of None
Current timestep = 9104. State = [[-0.37382165  0.10481086]]. Action = [[-0.0253604   0.09065417  0.          0.30971038]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 9104 is [True, False, False, False, True, False]
State prediction error at timestep 9104 is 0.012
Human Feedback received at timestep 9104 of None
Current timestep = 9105. State = [[-0.37631363  0.11027408]]. Action = [[-0.02989965  0.05165713  0.         -0.7178812 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 9105 is [True, False, False, False, True, False]
Current timestep = 9106. State = [[-0.37787145  0.11651441]]. Action = [[5.6050718e-05 8.2027934e-02 0.0000000e+00 6.8359160e-01]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 9106 is [True, False, False, False, True, False]
Current timestep = 9107. State = [[-0.37870985  0.11962958]]. Action = [[0.         0.         0.         0.23323119]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 9107 is [True, False, False, False, True, False]
Current timestep = 9108. State = [[-0.37803337  0.11603148]]. Action = [[ 0.01952223 -0.09160139  0.         -0.39936197]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 9108 is [True, False, False, False, True, False]
State prediction error at timestep 9108 is 0.012
Human Feedback received at timestep 9108 of None
Current timestep = 9109. State = [[-0.37441272  0.11382723]]. Action = [[ 0.05674397 -0.00277466  0.         -0.59794694]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 9109 is [True, False, False, False, True, False]
Current timestep = 9110. State = [[-0.3709618   0.11160304]]. Action = [[ 0.02563544 -0.04521889  0.          0.77083254]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 9110 is [True, False, False, False, True, False]
Current timestep = 9111. State = [[-0.36929658  0.1104295 ]]. Action = [[0.        0.        0.        0.6102078]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 9111 is [True, False, False, False, True, False]
Current timestep = 9112. State = [[-0.36677814  0.10554317]]. Action = [[ 0.0290348  -0.09754858  0.         -0.9320003 ]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 9112 is [True, False, False, False, True, False]
Current timestep = 9113. State = [[-0.36159387  0.0974429 ]]. Action = [[ 0.05756777 -0.09919216  0.          0.8368554 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 9113 is [True, False, False, False, True, False]
Current timestep = 9114. State = [[-0.36130065  0.09480541]]. Action = [[-0.06195984  0.02515451  0.         -0.43499964]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 9114 is [True, False, False, False, True, False]
Current timestep = 9115. State = [[-0.36225405  0.0978274 ]]. Action = [[-0.00806659  0.06119903  0.          0.4342805 ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 9115 is [True, False, False, False, True, False]
State prediction error at timestep 9115 is 0.012
Human Feedback received at timestep 9115 of None
Current timestep = 9116. State = [[-0.35947534  0.09436174]]. Action = [[ 0.04902517 -0.09565718  0.         -0.25544512]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 9116 is [True, False, False, False, True, False]
Current timestep = 9117. State = [[-0.35546657  0.08862255]]. Action = [[ 0.03367373 -0.04054552  0.         -0.310817  ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 9117 is [True, False, False, False, True, False]
Current timestep = 9118. State = [[-0.35153514  0.08324344]]. Action = [[ 0.03774231 -0.05612902  0.         -0.5897749 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 9118 is [True, False, False, False, True, False]
Current timestep = 9119. State = [[-0.3448826   0.07516551]]. Action = [[ 0.08820673 -0.09787043  0.         -0.69107234]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 9119 is [True, False, False, False, True, False]
Current timestep = 9120. State = [[-0.33958262  0.07328919]]. Action = [[ 0.03171086  0.06094862  0.         -0.45498657]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 9120 is [True, False, False, False, True, False]
Current timestep = 9121. State = [[-0.34070212  0.07314225]]. Action = [[-0.06581758 -0.00521749  0.          0.65837574]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 9121 is [True, False, False, False, True, False]
State prediction error at timestep 9121 is 0.012
Human Feedback received at timestep 9121 of None
Current timestep = 9122. State = [[-0.34170774  0.07225971]]. Action = [[0.00177877 0.00565781 0.         0.23802292]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 9122 is [True, False, False, False, True, False]
State prediction error at timestep 9122 is 0.012
Human Feedback received at timestep 9122 of None
Current timestep = 9123. State = [[-0.3436589   0.06719685]]. Action = [[-0.04962261 -0.08610258  0.         -0.9113578 ]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 9123 is [True, False, False, False, True, False]
Current timestep = 9124. State = [[-0.34030232  0.06538692]]. Action = [[0.09476411 0.03592844 0.         0.12168336]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 9124 is [True, False, False, False, True, False]
Current timestep = 9125. State = [[-0.34043726  0.06646822]]. Action = [[-0.06988534  0.02168713  0.          0.58451056]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 9125 is [True, False, False, False, True, False]
Current timestep = 9126. State = [[-0.3397229   0.06919092]]. Action = [[ 0.05393822  0.05303701  0.         -0.44488418]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 9126 is [True, False, False, False, True, False]
Current timestep = 9127. State = [[-0.3387692   0.07396612]]. Action = [[3.0537695e-04 7.2576307e-02 0.0000000e+00 9.6455836e-01]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 9127 is [True, False, False, False, True, False]
Current timestep = 9128. State = [[-0.34408027  0.07783441]]. Action = [[-0.09861957  0.0305951   0.          0.54479694]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 9128 is [True, False, False, False, True, False]
Current timestep = 9129. State = [[-0.3501116   0.07661708]]. Action = [[-0.05429078 -0.05929602  0.         -0.9632357 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 9129 is [True, False, False, False, True, False]
Current timestep = 9130. State = [[-0.351589    0.07934499]]. Action = [[ 0.02170547  0.07502338  0.         -0.8064599 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 9130 is [True, False, False, False, True, False]
Current timestep = 9131. State = [[-0.35224742  0.08124668]]. Action = [[-0.00264435 -0.01752799  0.         -0.40654004]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 9131 is [True, False, False, False, True, False]
State prediction error at timestep 9131 is 0.012
Human Feedback received at timestep 9131 of None
Current timestep = 9132. State = [[-0.34871557  0.0824526 ]]. Action = [[0.0913269  0.02134664 0.         0.94805133]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 9132 is [True, False, False, False, True, False]
Current timestep = 9133. State = [[-0.3468914   0.08761808]]. Action = [[ 0.00211607  0.08565887  0.         -0.0258624 ]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 9133 is [True, False, False, False, True, False]
Current timestep = 9134. State = [[-0.3483095   0.08754069]]. Action = [[-0.02102162 -0.06529707  0.         -0.9028578 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 9134 is [True, False, False, False, True, False]
Current timestep = 9135. State = [[-0.3477303   0.08280361]]. Action = [[ 0.02149478 -0.07431473  0.         -0.12972951]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 9135 is [True, False, False, False, True, False]
State prediction error at timestep 9135 is 0.012
Human Feedback received at timestep 9135 of None
Current timestep = 9136. State = [[-0.34963706  0.08454777]]. Action = [[-0.05611008  0.07344974  0.          0.7695699 ]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 9136 is [True, False, False, False, True, False]
Current timestep = 9137. State = [[-0.3553575  0.0830238]]. Action = [[-0.08999473 -0.0878846   0.         -0.03687346]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 9137 is [True, False, False, False, True, False]
Current timestep = 9138. State = [[-0.35994446  0.08153012]]. Action = [[-0.0463737   0.00348021  0.          0.32577586]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 9138 is [True, False, False, False, True, False]
Current timestep = 9139. State = [[-0.36014616  0.08318584]]. Action = [[ 0.03139817  0.02722203  0.         -0.6004943 ]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 9139 is [True, False, False, False, True, False]
Current timestep = 9140. State = [[-0.36233473  0.07932673]]. Action = [[-0.05561878 -0.0968297   0.          0.52689254]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 9140 is [True, False, False, False, True, False]
State prediction error at timestep 9140 is 0.012
Human Feedback received at timestep 9140 of None
Current timestep = 9141. State = [[-0.36622727  0.08019025]]. Action = [[-0.03746646  0.07631757  0.          0.04461694]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 9141 is [True, False, False, False, True, False]
Current timestep = 9142. State = [[-0.37244955  0.08505392]]. Action = [[-0.07767823  0.05433448  0.         -0.87259704]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 9142 is [True, False, False, False, True, False]
Current timestep = 9143. State = [[-0.37227142  0.08411101]]. Action = [[ 0.08116043 -0.05658553  0.         -0.70328087]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 9143 is [True, False, False, False, True, False]
Current timestep = 9144. State = [[-0.37128666  0.08221336]]. Action = [[0.         0.         0.         0.13040519]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 9144 is [True, False, False, False, True, False]
Current timestep = 9145. State = [[-0.37470657  0.078452  ]]. Action = [[-0.05684166 -0.06999981  0.          0.47682357]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 9145 is [True, False, False, False, True, False]
State prediction error at timestep 9145 is 0.012
Human Feedback received at timestep 9145 of None
Current timestep = 9146. State = [[-0.37534645  0.07199472]]. Action = [[ 0.02694068 -0.08403885  0.         -0.813019  ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 9146 is [True, False, False, False, True, False]
Current timestep = 9147. State = [[-0.37208226  0.07089627]]. Action = [[0.05959689 0.04728798 0.         0.8433368 ]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 9147 is [True, False, False, False, True, False]
Current timestep = 9148. State = [[-0.37116587  0.07388175]]. Action = [[-0.00369888  0.05521143  0.          0.43094444]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 9148 is [True, False, False, False, True, False]
State prediction error at timestep 9148 is 0.012
Human Feedback received at timestep 9148 of None
Current timestep = 9149. State = [[-0.37455097  0.07413903]]. Action = [[-0.05617449 -0.01595066  0.          0.97948945]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 9149 is [True, False, False, False, True, False]
Current timestep = 9150. State = [[-0.37633085  0.06865389]]. Action = [[ 0.00191899 -0.09591556  0.          0.8479855 ]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 9150 is [True, False, False, False, True, False]
Current timestep = 9151. State = [[-0.37353668  0.06794084]]. Action = [[0.06381927 0.05774132 0.         0.880592  ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 9151 is [True, False, False, False, True, False]
Current timestep = 9152. State = [[-0.37212384  0.06874233]]. Action = [[ 0.          0.          0.         -0.00836331]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 9152 is [True, False, False, False, True, False]
Current timestep = 9153. State = [[-0.3716579   0.06670287]]. Action = [[ 0.0096068  -0.03270858  0.          0.29526067]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 9153 is [True, False, False, False, True, False]
Current timestep = 9154. State = [[-0.3687946   0.06807327]]. Action = [[0.05399179 0.05782037 0.         0.06568885]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 9154 is [True, False, False, False, True, False]
Current timestep = 9155. State = [[-0.36636698  0.07118448]]. Action = [[0.02442489 0.04054331 0.         0.41735876]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 9155 is [True, False, False, False, True, False]
Current timestep = 9156. State = [[-0.36677733  0.06939059]]. Action = [[-0.02321353 -0.05713813  0.         -0.41122317]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 9156 is [True, False, False, False, True, False]
Current timestep = 9157. State = [[-0.36382663  0.07139707]]. Action = [[0.07149769 0.0762101  0.         0.01249385]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 9157 is [True, False, False, False, True, False]
State prediction error at timestep 9157 is 0.012
Human Feedback received at timestep 9157 of None
Current timestep = 9158. State = [[-0.36132097  0.07332885]]. Action = [[ 0.00645159 -0.00275391  0.          0.48481274]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 9158 is [True, False, False, False, True, False]
Current timestep = 9159. State = [[-0.36217612  0.07349775]]. Action = [[-0.03425089 -0.00233581  0.          0.02050757]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 9159 is [True, False, False, False, True, False]
State prediction error at timestep 9159 is 0.012
Human Feedback received at timestep 9159 of None
Current timestep = 9160. State = [[-0.36356336  0.0744065 ]]. Action = [[-0.02088773  0.00982313  0.          0.3755747 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 9160 is [True, False, False, False, True, False]
Current timestep = 9161. State = [[-0.36726552  0.0713992 ]]. Action = [[-0.07736508 -0.07959919  0.          0.3101139 ]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 9161 is [True, False, False, False, True, False]
State prediction error at timestep 9161 is 0.012
Human Feedback received at timestep 9161 of None
Current timestep = 9162. State = [[-0.36866388  0.0731875 ]]. Action = [[ 0.00651498  0.07199573  0.         -0.05966437]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 9162 is [True, False, False, False, True, False]
Current timestep = 9163. State = [[-0.36468336  0.07149041]]. Action = [[ 0.07343184 -0.08414117  0.          0.53030574]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 9163 is [True, False, False, False, True, False]
Current timestep = 9164. State = [[-0.3651276  0.0716095]]. Action = [[-0.06180794  0.05072673  0.          0.7421595 ]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 9164 is [True, False, False, False, True, False]
Current timestep = 9165. State = [[-0.36432853  0.07697161]]. Action = [[ 0.05009443  0.07521533  0.         -0.19861072]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 9165 is [True, False, False, False, True, False]
State prediction error at timestep 9165 is 0.012
Human Feedback received at timestep 9165 of None
Current timestep = 9166. State = [[-0.36819875  0.08444149]]. Action = [[-0.09818459  0.09534606  0.         -0.6517714 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 9166 is [True, False, False, False, True, False]
Current timestep = 9167. State = [[-0.36861628  0.08428103]]. Action = [[ 0.06191587 -0.08840752  0.         -0.5261861 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 9167 is [True, False, False, False, True, False]
Current timestep = 9168. State = [[-0.3658509   0.08450776]]. Action = [[0.03331467 0.04825025 0.         0.3439517 ]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 9168 is [True, False, False, False, True, False]
State prediction error at timestep 9168 is 0.012
Human Feedback received at timestep 9168 of None
Current timestep = 9169. State = [[-0.3646771   0.08178919]]. Action = [[ 0.00782458 -0.08552741  0.         -0.467916  ]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 9169 is [True, False, False, False, True, False]
Current timestep = 9170. State = [[-0.3671069   0.07623179]]. Action = [[-0.06477521 -0.07025108  0.         -0.86887395]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 9170 is [True, False, False, False, True, False]
Current timestep = 9171. State = [[-0.36907443  0.07206165]]. Action = [[-0.01775651 -0.04503209  0.          0.21991038]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 9171 is [True, False, False, False, True, False]
State prediction error at timestep 9171 is 0.012
Human Feedback received at timestep 9171 of None
Current timestep = 9172. State = [[-0.3691596   0.07045748]]. Action = [[0.         0.         0.         0.79552615]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 9172 is [True, False, False, False, True, False]
State prediction error at timestep 9172 is 0.012
Human Feedback received at timestep 9172 of None
Current timestep = 9173. State = [[-0.36511078  0.07398178]]. Action = [[ 0.08514043  0.0842075   0.         -0.31790715]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 9173 is [True, False, False, False, True, False]
Current timestep = 9174. State = [[-0.35871652  0.07440741]]. Action = [[ 0.08836836 -0.02445843  0.         -0.0872227 ]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 9174 is [True, False, False, False, True, False]
Current timestep = 9175. State = [[-0.35627964  0.06827329]]. Action = [[-0.01401936 -0.0976752   0.         -0.7347034 ]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 9175 is [True, False, False, False, True, False]
Current timestep = 9176. State = [[-0.35665366  0.06903969]]. Action = [[-0.01241433  0.09156155  0.         -0.586486  ]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 9176 is [True, False, False, False, True, False]
State prediction error at timestep 9176 is 0.012
Human Feedback received at timestep 9176 of None
Current timestep = 9177. State = [[-0.35640278  0.07550964]]. Action = [[0.01755305 0.08900685 0.         0.09193897]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 9177 is [True, False, False, False, True, False]
Current timestep = 9178. State = [[-0.35945985  0.07811915]]. Action = [[-0.0633305  -0.00152855  0.          0.3178742 ]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 9178 is [True, False, False, False, True, False]
Current timestep = 9179. State = [[-0.36095044  0.07593029]]. Action = [[ 0.01053789 -0.05237092  0.         -0.6029809 ]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 9179 is [True, False, False, False, True, False]
Current timestep = 9180. State = [[-0.3611415   0.07003671]]. Action = [[-0.01085099 -0.09227309  0.          0.4405731 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 9180 is [True, False, False, False, True, False]
Current timestep = 9181. State = [[-0.36291265  0.06981314]]. Action = [[-0.03503405  0.05218821  0.         -0.02822948]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 9181 is [True, False, False, False, True, False]
Current timestep = 9182. State = [[-0.36130705  0.06852749]]. Action = [[ 0.054438   -0.05366745  0.         -0.2636853 ]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 9182 is [True, False, False, False, True, False]
State prediction error at timestep 9182 is 0.012
Human Feedback received at timestep 9182 of None
Current timestep = 9183. State = [[-0.36126384  0.06197536]]. Action = [[-0.03701326 -0.09777727  0.         -0.38417625]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 9183 is [True, False, False, False, True, False]
Current timestep = 9184. State = [[-0.3638613   0.05860124]]. Action = [[-0.0454994  -0.00251713  0.         -0.6136118 ]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 9184 is [True, False, False, False, True, False]
State prediction error at timestep 9184 is 0.012
Human Feedback received at timestep 9184 of None
Current timestep = 9185. State = [[-0.36196932  0.05926109]]. Action = [[ 0.06442007  0.0303239   0.         -0.12487757]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 9185 is [True, False, False, False, True, False]
Current timestep = 9186. State = [[-0.36388305  0.06213586]]. Action = [[-0.07218579  0.05324136  0.         -0.05011129]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 9186 is [True, False, False, False, True, False]
Current timestep = 9187. State = [[-0.36259222  0.0619093 ]]. Action = [[ 0.078784   -0.02757028  0.         -0.04151464]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 9187 is [True, False, False, False, True, False]
Current timestep = 9188. State = [[-0.35955897  0.06292493]]. Action = [[0.02982033 0.04743203 0.         0.9806746 ]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 9188 is [True, False, False, False, True, False]
Current timestep = 9189. State = [[-0.3613064   0.06644835]]. Action = [[-0.04273159  0.05127259  0.         -0.7787837 ]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 9189 is [True, False, False, False, True, False]
Current timestep = 9190. State = [[-0.36323258  0.06586485]]. Action = [[-0.00488538 -0.0441041   0.         -0.63865376]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 9190 is [True, False, False, False, True, False]
Current timestep = 9191. State = [[-0.36513743  0.06500886]]. Action = [[-0.02980335  0.00393263  0.         -0.07705384]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 9191 is [True, False, False, False, True, False]
Current timestep = 9192. State = [[-0.36576048  0.06989713]]. Action = [[0.01585992 0.09352837 0.         0.42648208]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 9192 is [True, False, False, False, True, False]
Current timestep = 9193. State = [[-0.36821014  0.07775117]]. Action = [[-0.03393327  0.09639084  0.         -0.66466147]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 9193 is [True, False, False, False, True, False]
Current timestep = 9194. State = [[-0.36660218  0.08442028]]. Action = [[ 0.08430489  0.06325021  0.         -0.37833565]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 9194 is [True, False, False, False, True, False]
Current timestep = 9195. State = [[-0.36480185  0.09125832]]. Action = [[ 0.02099364  0.08502013  0.         -0.43758118]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 9195 is [True, False, False, False, True, False]
Current timestep = 9196. State = [[-0.36528614  0.09415032]]. Action = [[-0.00025544 -0.01332401  0.         -0.07538432]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 9196 is [True, False, False, False, True, False]
State prediction error at timestep 9196 is 0.012
Human Feedback received at timestep 9196 of None
Current timestep = 9197. State = [[-0.36587414  0.09524991]]. Action = [[0.         0.         0.         0.97486115]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 9197 is [True, False, False, False, True, False]
State prediction error at timestep 9197 is 0.012
Human Feedback received at timestep 9197 of None
Current timestep = 9198. State = [[-0.36263072  0.09455333]]. Action = [[ 0.06904607 -0.04095751  0.          0.5378449 ]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 9198 is [True, False, False, False, True, False]
Current timestep = 9199. State = [[-0.36061153  0.09904443]]. Action = [[-0.00137958  0.09393386  0.          0.8116549 ]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 9199 is [True, False, False, False, True, False]
State prediction error at timestep 9199 is 0.012
Human Feedback received at timestep 9199 of None
Current timestep = 9200. State = [[-0.36448228  0.10651045]]. Action = [[-0.07838967  0.07003351  0.          0.4295709 ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 9200 is [True, False, False, False, True, False]
Current timestep = 9201. State = [[-0.36676797  0.11052059]]. Action = [[0.00270786 0.00341012 0.         0.9225619 ]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 9201 is [True, False, False, False, True, False]
Current timestep = 9202. State = [[-0.36766458  0.11075138]]. Action = [[-0.01721085 -0.03305318  0.         -0.24128616]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 9202 is [True, False, False, False, True, False]
Current timestep = 9203. State = [[-0.3638468   0.11370048]]. Action = [[0.08733077 0.05230881 0.         0.09105289]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 9203 is [True, False, False, False, True, False]
Current timestep = 9204. State = [[-0.36023104  0.11518412]]. Action = [[ 0.01463578 -0.02037673  0.          0.11243427]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 9204 is [True, False, False, False, True, False]
Current timestep = 9205. State = [[-0.35758552  0.11125161]]. Action = [[ 0.02195625 -0.09013848  0.          0.96493936]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 9205 is [True, False, False, False, True, False]
Current timestep = 9206. State = [[-0.35839257  0.10889927]]. Action = [[-0.05934552 -0.01261938  0.         -0.05265629]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 9206 is [True, False, False, False, True, False]
Current timestep = 9207. State = [[-0.3550399   0.11283457]]. Action = [[0.08484139 0.07954488 0.         0.78656614]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 9207 is [True, False, False, False, True, False]
Current timestep = 9208. State = [[-0.34788153  0.11962741]]. Action = [[0.07949548 0.08749592 0.         0.5185925 ]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 9208 is [True, False, False, False, True, False]
Current timestep = 9209. State = [[-0.3423086  0.1257852]]. Action = [[0.0471758  0.06814524 0.         0.7814789 ]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 9209 is [True, False, False, False, True, False]
Current timestep = 9210. State = [[-0.34148443  0.13122065]]. Action = [[-0.03087285  0.05671053  0.          0.97045135]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 9210 is [True, False, False, False, False, True]
Current timestep = 9211. State = [[-0.3424781   0.13276665]]. Action = [[-0.02157252 -0.02611672  0.         -0.44868648]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 9211 is [True, False, False, False, False, True]
Current timestep = 9212. State = [[-0.34307942  0.13347204]]. Action = [[-1.8370882e-02 -1.9083917e-04  0.0000000e+00 -6.4398974e-01]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 9212 is [True, False, False, False, False, True]
State prediction error at timestep 9212 is 0.012
Human Feedback received at timestep 9212 of None
Current timestep = 9213. State = [[-0.33994296  0.13317275]]. Action = [[ 0.05640411 -0.03053192  0.          0.3302462 ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 9213 is [True, False, False, False, False, True]
Current timestep = 9214. State = [[-0.3416566   0.13106625]]. Action = [[-0.09193167 -0.04897749  0.         -0.65778035]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 9214 is [True, False, False, False, False, True]
Current timestep = 9215. State = [[-0.34632623  0.13163805]]. Action = [[-0.06147686  0.01472987  0.         -0.05140162]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 9215 is [True, False, False, False, False, True]
Current timestep = 9216. State = [[-0.3514088   0.13599229]]. Action = [[-0.0673579   0.05820956  0.          0.9091327 ]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 9216 is [True, False, False, False, False, True]
Current timestep = 9217. State = [[-0.35110545  0.14212362]]. Action = [[ 0.06421784  0.07457452  0.         -0.83102083]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 9217 is [True, False, False, False, False, True]
Current timestep = 9218. State = [[-0.3547856  0.1446218]]. Action = [[-0.09843819 -0.01219878  0.          0.04110193]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 9218 is [True, False, False, False, False, True]
Current timestep = 9219. State = [[-0.3588025   0.14157233]]. Action = [[-0.00532816 -0.07382122  0.         -0.6347572 ]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 9219 is [True, False, False, False, False, True]
State prediction error at timestep 9219 is 0.012
Human Feedback received at timestep 9219 of None
Current timestep = 9220. State = [[-0.35838422  0.14066273]]. Action = [[ 0.03489026  0.01742759  0.         -0.01384443]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 9220 is [True, False, False, False, False, True]
Current timestep = 9221. State = [[-0.3584539   0.13701344]]. Action = [[-0.00457893 -0.08133756  0.         -0.46212763]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 9221 is [True, False, False, False, False, True]
Current timestep = 9222. State = [[-0.3598093   0.13672347]]. Action = [[-0.01456881  0.04405769  0.         -0.604249  ]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 9222 is [True, False, False, False, False, True]
State prediction error at timestep 9222 is 0.012
Human Feedback received at timestep 9222 of None
Current timestep = 9223. State = [[-0.36536777  0.1410443 ]]. Action = [[-0.08531107  0.06620669  0.          0.45124102]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 9223 is [True, False, False, False, False, True]
Current timestep = 9224. State = [[-0.3736246   0.14160474]]. Action = [[-0.09401173 -0.03494878  0.         -0.7006004 ]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 9224 is [True, False, False, False, False, True]
Current timestep = 9225. State = [[-0.37543422  0.1444143 ]]. Action = [[0.05576795 0.07411715 0.         0.37418294]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 9225 is [True, False, False, False, False, True]
State prediction error at timestep 9225 is 0.012
Human Feedback received at timestep 9225 of None
Current timestep = 9226. State = [[-0.37098226  0.14414024]]. Action = [[ 0.08341455 -0.0449122   0.          0.39515495]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 9226 is [True, False, False, False, False, True]
Current timestep = 9227. State = [[-0.3688902   0.14270999]]. Action = [[0.        0.        0.        0.5770967]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 9227 is [True, False, False, False, False, True]
Current timestep = 9228. State = [[-0.36710048  0.14341097]]. Action = [[ 0.03657655  0.01777689  0.         -0.7152574 ]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 9228 is [True, False, False, False, False, True]
State prediction error at timestep 9228 is 0.012
Human Feedback received at timestep 9228 of None
Current timestep = 9229. State = [[-0.36919588  0.14115807]]. Action = [[-0.067834   -0.05875256  0.         -0.10287821]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 9229 is [True, False, False, False, False, True]
Current timestep = 9230. State = [[-0.37300465  0.14404033]]. Action = [[-0.03609362  0.08677269  0.          0.05406773]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 9230 is [True, False, False, False, False, True]
State prediction error at timestep 9230 is 0.012
Human Feedback received at timestep 9230 of None
Current timestep = 9231. State = [[-0.3738514   0.14859495]]. Action = [[0.02080908 0.04071676 0.         0.97645116]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 9231 is [True, False, False, False, False, True]
Current timestep = 9232. State = [[-0.3740291   0.14997481]]. Action = [[0.         0.         0.         0.39447272]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 9232 is [True, False, False, False, False, True]
Current timestep = 9233. State = [[-0.37038788  0.14553533]]. Action = [[ 0.07962608 -0.09242011  0.         -0.74978024]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 9233 is [True, False, False, False, False, True]
Current timestep = 9234. State = [[-0.37044477  0.14368826]]. Action = [[-0.05059615  0.02111844  0.         -0.7449122 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 9234 is [True, False, False, False, False, True]
Current timestep = 9235. State = [[-0.374643    0.14693184]]. Action = [[-0.05672007  0.04864479  0.          0.5894146 ]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 9235 is [True, False, False, False, False, True]
Current timestep = 9236. State = [[-0.3752111   0.14635478]]. Action = [[ 0.02868365 -0.04963402  0.         -0.5596119 ]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 9236 is [True, False, False, False, False, True]
Current timestep = 9237. State = [[-0.37397322  0.14718747]]. Action = [[0.01326416 0.04282961 0.         0.7030904 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 9237 is [True, False, False, False, False, True]
State prediction error at timestep 9237 is 0.012
Human Feedback received at timestep 9237 of None
Current timestep = 9238. State = [[-0.37453544  0.1472641 ]]. Action = [[-0.01642354 -0.0225127   0.          0.3379048 ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 9238 is [True, False, False, False, False, True]
Current timestep = 9239. State = [[-0.37465736  0.14569144]]. Action = [[ 0.00615551 -0.0233518   0.         -0.60362387]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 9239 is [True, False, False, False, False, True]
State prediction error at timestep 9239 is 0.012
Human Feedback received at timestep 9239 of None
Current timestep = 9240. State = [[-0.37448856  0.14878929]]. Action = [[0.00229152 0.07743772 0.         0.8912052 ]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 9240 is [True, False, False, False, False, True]
Current timestep = 9241. State = [[-0.37479925  0.15091437]]. Action = [[0.         0.         0.         0.65225327]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 9241 is [True, False, False, False, False, True]
Current timestep = 9242. State = [[-0.375032    0.15110447]]. Action = [[0.        0.        0.        0.2828498]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 9242 is [True, False, False, False, False, True]
Current timestep = 9243. State = [[-0.3752815   0.15407643]]. Action = [[ 0.00130419  0.05855908  0.         -0.49115074]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 9243 is [True, False, False, False, False, True]
Current timestep = 9244. State = [[-0.37500694  0.16063257]]. Action = [[0.01819523 0.0981225  0.         0.59634507]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 9244 is [True, False, False, False, False, True]
Current timestep = 9245. State = [[-0.3723062   0.16304865]]. Action = [[ 0.05770331 -0.01114178  0.          0.23930812]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 9245 is [True, False, False, False, False, True]
Current timestep = 9246. State = [[-0.37172085  0.1630128 ]]. Action = [[-0.01882183 -0.00387838  0.          0.16859984]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 9246 is [True, False, False, False, False, True]
State prediction error at timestep 9246 is 0.012
Human Feedback received at timestep 9246 of None
Current timestep = 9247. State = [[-0.37275407  0.1616165 ]]. Action = [[-0.01369154 -0.04152062  0.          0.35698783]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 9247 is [True, False, False, False, False, True]
Current timestep = 9248. State = [[-0.37507468  0.16413946]]. Action = [[-0.04123217  0.05731279  0.         -0.6340814 ]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 9248 is [True, False, False, False, False, True]
Current timestep = 9249. State = [[-0.37645036  0.16660313]]. Action = [[0.         0.         0.         0.60976505]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 9249 is [True, False, False, False, False, True]
State prediction error at timestep 9249 is 0.012
Human Feedback received at timestep 9249 of None
Current timestep = 9250. State = [[-0.37753105  0.16679093]]. Action = [[-0.0186355  -0.01465497  0.          0.03124845]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 9250 is [True, False, False, False, False, True]
State prediction error at timestep 9250 is 0.012
Human Feedback received at timestep 9250 of None
Current timestep = 9251. State = [[-0.37562236  0.16979307]]. Action = [[0.05253222 0.05701036 0.         0.7331233 ]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 9251 is [True, False, False, False, False, True]
Current timestep = 9252. State = [[-0.36994565  0.1669475 ]]. Action = [[ 0.08237454 -0.09502279  0.         -0.8361583 ]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 9252 is [True, False, False, False, False, True]
Current timestep = 9253. State = [[-0.36435303  0.16094545]]. Action = [[ 0.04494276 -0.06939888  0.          0.15044725]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 9253 is [True, False, False, False, False, True]
Current timestep = 9254. State = [[-0.36421248  0.16089958]]. Action = [[-0.0495232   0.0438168   0.         -0.76284087]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 9254 is [True, False, False, False, False, True]
Current timestep = 9255. State = [[-0.36141926  0.16074707]]. Action = [[ 0.06596985 -0.02712155  0.         -0.02544796]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 9255 is [True, False, False, False, False, True]
Current timestep = 9256. State = [[-0.3607362   0.16400199]]. Action = [[-0.03886406  0.08757635  0.          0.73819125]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 9256 is [True, False, False, False, False, True]
Current timestep = 9257. State = [[-0.3590154  0.1694131]]. Action = [[ 0.05019148  0.06329792  0.         -0.27400267]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 9257 is [True, False, False, False, False, True]
Current timestep = 9258. State = [[-0.35590345  0.1743396 ]]. Action = [[ 0.03262091  0.06627917  0.         -0.67985535]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 9258 is [True, False, False, False, False, True]
State prediction error at timestep 9258 is 0.012
Human Feedback received at timestep 9258 of None
Current timestep = 9259. State = [[-0.3539072   0.17212039]]. Action = [[ 0.01154713 -0.08733208  0.         -0.6257466 ]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 9259 is [True, False, False, False, False, True]
Current timestep = 9260. State = [[-0.35731977  0.17355649]]. Action = [[-0.08736617  0.07142805  0.         -0.8479697 ]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 9260 is [True, False, False, False, False, True]
State prediction error at timestep 9260 is 0.012
Human Feedback received at timestep 9260 of None
Current timestep = 9261. State = [[-0.3549036   0.17309152]]. Action = [[ 0.0974512  -0.06663392  0.          0.24073768]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 9261 is [True, False, False, False, False, True]
Current timestep = 9262. State = [[-0.3490159   0.17416944]]. Action = [[0.05638792 0.05800285 0.         0.7051511 ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 9262 is [True, False, False, False, False, True]
Current timestep = 9263. State = [[-0.34332415  0.1795713 ]]. Action = [[0.07098471 0.08204671 0.         0.44713855]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 9263 is [True, False, False, False, False, True]
Current timestep = 9264. State = [[-0.3426769  0.1776956]]. Action = [[-0.05356913 -0.09826694  0.          0.9597831 ]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 9264 is [True, False, False, False, False, True]
Current timestep = 9265. State = [[-0.33902583  0.17412408]]. Action = [[ 0.09639207 -0.01883433  0.         -0.7087329 ]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 9265 is [True, False, False, False, False, True]
State prediction error at timestep 9265 is 0.012
Human Feedback received at timestep 9265 of None
Current timestep = 9266. State = [[-0.33283055  0.17710298]]. Action = [[ 0.05746993  0.08340304  0.         -0.4765365 ]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 9266 is [True, False, False, False, False, True]
Current timestep = 9267. State = [[-0.3271784   0.17642938]]. Action = [[ 0.06015315 -0.0523098   0.          0.5008966 ]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 9267 is [True, False, False, False, False, True]
Current timestep = 9268. State = [[-0.31958416  0.17674433]]. Action = [[ 0.08995336  0.04258882  0.         -0.99887705]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 9268 is [True, False, False, False, False, True]
State prediction error at timestep 9268 is 0.012
Human Feedback received at timestep 9268 of None
Current timestep = 9269. State = [[-0.3109704   0.17886205]]. Action = [[0.08951762 0.0323879  0.         0.5379424 ]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 9269 is [True, False, False, False, False, True]
Current timestep = 9270. State = [[-0.3094647   0.18241325]]. Action = [[-0.05976269  0.05714386  0.         -0.26548165]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 9270 is [True, False, False, False, False, True]
Current timestep = 9271. State = [[-0.3131767   0.18941315]]. Action = [[-0.07040876  0.09733655  0.          0.06554675]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 9271 is [True, False, False, False, False, True]
Current timestep = 9272. State = [[-0.31361705  0.19489846]]. Action = [[ 0.02112339  0.03538675  0.         -0.6042893 ]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 9272 is [True, False, False, False, False, True]
State prediction error at timestep 9272 is 0.012
Human Feedback received at timestep 9272 of None
Current timestep = 9273. State = [[-0.31170735  0.19658782]]. Action = [[ 0.0177706  -0.0096854   0.         -0.14363706]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 9273 is [True, False, False, False, False, True]
Current timestep = 9274. State = [[-0.30844003  0.19310917]]. Action = [[ 0.03814621 -0.0907244   0.         -0.08353692]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 9274 is [True, False, False, False, False, True]
Current timestep = 9275. State = [[-0.30187476  0.19274904]]. Action = [[0.08780953 0.02691532 0.         0.02783024]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 9275 is [True, False, False, False, False, True]
Current timestep = 9276. State = [[-0.3027297  0.1982584]]. Action = [[-0.09239613  0.08315592  0.          0.7884648 ]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 9276 is [True, False, False, False, False, True]
Current timestep = 9277. State = [[-0.30537543  0.1997639 ]]. Action = [[-0.01776799 -0.04627597  0.         -0.56688243]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 9277 is [True, False, False, False, False, True]
Current timestep = 9278. State = [[-0.30242828  0.19701934]]. Action = [[ 0.0552895  -0.05695181  0.          0.0333817 ]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 9278 is [True, False, False, False, False, True]
Current timestep = 9279. State = [[-0.29581302  0.19574264]]. Action = [[ 0.08185806 -0.00275665  0.         -0.19847   ]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 9279 is [True, False, False, False, False, True]
Current timestep = 9280. State = [[-0.29278073  0.19232234]]. Action = [[-0.01428148 -0.07123981  0.         -0.26451695]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 9280 is [True, False, False, False, False, True]
Current timestep = 9281. State = [[-0.29195273  0.18983328]]. Action = [[-0.00586174 -0.0150954   0.          0.9976908 ]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 9281 is [True, False, False, False, False, True]
Current timestep = 9282. State = [[-0.2864016   0.19268341]]. Action = [[ 0.09774005  0.07634605  0.         -0.82727265]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 9282 is [True, False, False, False, False, True]
State prediction error at timestep 9282 is 0.012
Human Feedback received at timestep 9282 of None
Current timestep = 9283. State = [[-0.28521353  0.19323565]]. Action = [[-0.06080132 -0.02842755  0.         -0.18201709]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 9283 is [True, False, False, False, False, True]
State prediction error at timestep 9283 is 0.012
Human Feedback received at timestep 9283 of None
Current timestep = 9284. State = [[-0.28385797  0.18839951]]. Action = [[ 0.04252803 -0.07973908  0.         -0.01522124]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 9284 is [True, False, False, False, False, True]
Current timestep = 9285. State = [[-0.27860802  0.18757366]]. Action = [[ 0.06816211  0.04520982  0.         -0.12220252]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 9285 is [True, False, False, False, False, True]
Current timestep = 9286. State = [[-0.27504626  0.18510202]]. Action = [[ 0.01541352 -0.05404316  0.          0.30915856]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 9286 is [True, False, False, False, False, True]
Current timestep = 9287. State = [[-0.27428052  0.17895421]]. Action = [[-0.01813956 -0.08092217  0.          0.57869804]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 9287 is [True, False, False, False, False, True]
State prediction error at timestep 9287 is 0.012
Human Feedback received at timestep 9287 of None
Current timestep = 9288. State = [[-0.26874524  0.1709679 ]]. Action = [[ 0.09554034 -0.09698281  0.         -0.33657008]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 9288 is [True, False, False, False, False, True]
Current timestep = 9289. State = [[-0.26001072  0.16640243]]. Action = [[ 0.09301988 -0.0013098   0.         -0.4040271 ]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 9289 is [True, False, False, False, False, True]
Current timestep = 9290. State = [[-0.25977924  0.1613733 ]]. Action = [[-0.09352469 -0.07102729  0.         -0.8609009 ]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 9290 is [True, False, False, False, False, True]
State prediction error at timestep 9290 is 0.012
Human Feedback received at timestep 9290 of None
Current timestep = 9291. State = [[-0.2586675   0.15825053]]. Action = [[0.057707   0.01098659 0.         0.5280061 ]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 9291 is [True, False, False, False, False, True]
Current timestep = 9292. State = [[-0.2561378   0.15993921]]. Action = [[ 0.00782969  0.06781288  0.         -0.16359377]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 9292 is [True, False, False, False, False, True]
Current timestep = 9293. State = [[-0.25505167  0.16030857]]. Action = [[9.6129179e-03 7.7126175e-04 0.0000000e+00 9.5737147e-01]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 9293 is [True, False, False, False, False, True]
State prediction error at timestep 9293 is 0.012
Human Feedback received at timestep 9293 of None
Current timestep = 9294. State = [[-0.25447774  0.15920392]]. Action = [[-2.7047098e-04  8.5815787e-05  0.0000000e+00  3.5961294e-01]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 9294 is [True, False, False, False, False, True]
Current timestep = 9295. State = [[-0.25460905  0.15743983]]. Action = [[-0.00840956 -0.01815859  0.          0.15508044]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 9295 is [True, False, False, False, False, True]
Current timestep = 9296. State = [[-0.25853026  0.15767856]]. Action = [[-0.07857162  0.02520204  0.         -0.5362334 ]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 9296 is [True, False, False, False, False, True]
Current timestep = 9297. State = [[-0.26278892  0.1628269 ]]. Action = [[-0.03349053  0.0914033   0.          0.7855092 ]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 9297 is [True, False, False, False, False, True]
State prediction error at timestep 9297 is 0.012
Human Feedback received at timestep 9297 of None
Current timestep = 9298. State = [[-0.26066914  0.16572605]]. Action = [[0.08486251 0.00604989 0.         0.24036598]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 9298 is [True, False, False, False, False, True]
Current timestep = 9299. State = [[-0.25464317  0.16760862]]. Action = [[ 0.0937211  0.0393906  0.        -0.5029073]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 9299 is [True, False, False, False, False, True]
Current timestep = 9300. State = [[-0.25552326  0.16828093]]. Action = [[-0.07114753 -0.0105404   0.         -0.25847304]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 9300 is [True, False, False, False, False, True]
Current timestep = 9301. State = [[-0.25703767  0.16927688]]. Action = [[ 0.02054     0.01969348  0.         -0.662875  ]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 9301 is [True, False, False, False, False, True]
State prediction error at timestep 9301 is 0.012
Human Feedback received at timestep 9301 of None
Current timestep = 9302. State = [[-0.25684687  0.17016414]]. Action = [[0.00761992 0.00245787 0.         0.4008689 ]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 9302 is [True, False, False, False, False, True]
Current timestep = 9303. State = [[-0.2594766   0.16961569]]. Action = [[-0.05019949 -0.02202336  0.          0.43864465]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 9303 is [True, False, False, False, False, True]
Current timestep = 9304. State = [[-0.26086035  0.16917193]]. Action = [[ 0.00501043 -0.00918438  0.          0.00732458]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 9304 is [True, False, False, False, False, True]
Current timestep = 9305. State = [[-0.26198658  0.17418645]]. Action = [[-0.0159914   0.09949609  0.         -0.85598874]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 9305 is [True, False, False, False, False, True]
Current timestep = 9306. State = [[-0.26682043  0.177394  ]]. Action = [[-0.07661147 -0.00499154  0.          0.38048935]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 9306 is [True, False, False, False, False, True]
Current timestep = 9307. State = [[-0.2672318   0.17994599]]. Action = [[0.05286046 0.03684615 0.         0.04604614]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 9307 is [True, False, False, False, False, True]
Current timestep = 9308. State = [[-0.264702    0.18240115]]. Action = [[ 0.03610604  0.01893476  0.         -0.95883507]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 9308 is [True, False, False, False, False, True]
Current timestep = 9309. State = [[-0.2683736   0.18416825]]. Action = [[-0.0907168   0.00867663  0.         -0.58705366]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 9309 is [True, False, False, False, False, True]
Current timestep = 9310. State = [[-0.27490056  0.18377063]]. Action = [[-0.07409526 -0.03903842  0.         -0.77796   ]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 9310 is [True, False, False, False, False, True]
Current timestep = 9311. State = [[-0.2822217   0.18347628]]. Action = [[-0.09388343 -0.01237265  0.          0.43183708]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 9311 is [True, False, False, False, False, True]
State prediction error at timestep 9311 is 0.012
Human Feedback received at timestep 9311 of None
Current timestep = 9312. State = [[-0.285971    0.18241706]]. Action = [[-0.00453421 -0.03831051  0.         -0.26517248]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 9312 is [True, False, False, False, False, True]
Current timestep = 9313. State = [[-0.29116735  0.17791641]]. Action = [[-0.08641652 -0.08764917  0.          0.66956043]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 9313 is [True, False, False, False, False, True]
Current timestep = 9314. State = [[-0.2966054   0.17577377]]. Action = [[-0.04487003 -0.00611638  0.         -0.6443266 ]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 9314 is [True, False, False, False, False, True]
State prediction error at timestep 9314 is 0.012
Human Feedback received at timestep 9314 of None
Current timestep = 9315. State = [[-0.29591906  0.17060687]]. Action = [[ 0.06254791 -0.0993782   0.         -0.3463502 ]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 9315 is [True, False, False, False, False, True]
Current timestep = 9316. State = [[-0.29633576  0.1696434 ]]. Action = [[-0.02516662  0.05549837  0.         -0.43556035]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 9316 is [True, False, False, False, False, True]
Current timestep = 9317. State = [[-0.30019686  0.1705102 ]]. Action = [[-0.04078202  0.00324653  0.         -0.6226119 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 9317 is [True, False, False, False, False, True]
State prediction error at timestep 9317 is 0.012
Human Feedback received at timestep 9317 of None
Current timestep = 9318. State = [[-0.3044353   0.17396402]]. Action = [[-0.03160552  0.0800151   0.          0.33009744]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 9318 is [True, False, False, False, False, True]
Current timestep = 9319. State = [[-0.31005964  0.17732622]]. Action = [[-0.05669868  0.03398594  0.         -0.5038502 ]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 9319 is [True, False, False, False, False, True]
Current timestep = 9320. State = [[-0.3100886   0.18002567]]. Action = [[0.07483927 0.04464903 0.         0.54652023]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 9320 is [True, False, False, False, False, True]
Current timestep = 9321. State = [[-0.30856606  0.17707962]]. Action = [[ 0.02176259 -0.07200314  0.          0.44934535]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 9321 is [True, False, False, False, False, True]
Current timestep = 9322. State = [[-0.30537134  0.17450409]]. Action = [[ 0.07063853  0.00195088  0.         -0.06208241]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 9322 is [True, False, False, False, False, True]
Current timestep = 9323. State = [[-0.30878648  0.17781436]]. Action = [[-0.09492841  0.0818437   0.         -0.37117767]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 9323 is [True, False, False, False, False, True]
State prediction error at timestep 9323 is 0.012
Human Feedback received at timestep 9323 of None
Current timestep = 9324. State = [[-0.30827117  0.18255761]]. Action = [[0.08591805 0.05578739 0.         0.8367337 ]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 9324 is [True, False, False, False, False, True]
State prediction error at timestep 9324 is 0.012
Human Feedback received at timestep 9324 of None
Current timestep = 9325. State = [[-0.31048694  0.18463728]]. Action = [[-0.08060381  0.00776096  0.         -0.9635221 ]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 9325 is [True, False, False, False, False, True]
Current timestep = 9326. State = [[-0.31008232  0.18258621]]. Action = [[ 0.06813148 -0.05135434  0.         -0.9275935 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 9326 is [True, False, False, False, False, True]
State prediction error at timestep 9326 is 0.012
Human Feedback received at timestep 9326 of None
Current timestep = 9327. State = [[-0.30720288  0.1815512 ]]. Action = [[ 0.02967099  0.0102744   0.         -0.2358756 ]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 9327 is [True, False, False, False, False, True]
Current timestep = 9328. State = [[-0.30427873  0.18223226]]. Action = [[ 0.04293173  0.01211707  0.         -0.63914084]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 9328 is [True, False, False, False, False, True]
Current timestep = 9329. State = [[-0.29892385  0.18707913]]. Action = [[ 0.08267158  0.09848487  0.         -0.20677155]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 9329 is [True, False, False, False, False, True]
Current timestep = 9330. State = [[-0.2989477   0.19356243]]. Action = [[-0.05208587  0.07902806  0.          0.49191117]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 9330 is [True, False, False, False, False, True]
Current timestep = 9331. State = [[-0.29568845  0.19740003]]. Action = [[0.09355991 0.02526049 0.         0.88734066]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 9331 is [True, False, False, False, False, True]
Current timestep = 9332. State = [[-0.29231223  0.19576223]]. Action = [[ 0.00508869 -0.05829325  0.          0.8202419 ]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 9332 is [True, False, False, False, False, True]
State prediction error at timestep 9332 is 0.012
Human Feedback received at timestep 9332 of None
Current timestep = 9333. State = [[-0.28857303  0.19363469]]. Action = [[ 0.05165631 -0.02395248  0.         -0.2852264 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 9333 is [True, False, False, False, False, True]
State prediction error at timestep 9333 is 0.012
Human Feedback received at timestep 9333 of None
Current timestep = 9334. State = [[-0.29039252  0.19157763]]. Action = [[-0.09407706 -0.04438731  0.         -0.02056372]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 9334 is [True, False, False, False, False, True]
State prediction error at timestep 9334 is 0.012
Human Feedback received at timestep 9334 of None
Current timestep = 9335. State = [[-0.2906982  0.1888288]]. Action = [[ 0.02214199 -0.05135302  0.          0.3889073 ]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 9335 is [True, False, False, False, False, True]
Current timestep = 9336. State = [[-0.2897172  0.1925523]]. Action = [[-0.00749497  0.09680303  0.          0.2541057 ]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 9336 is [True, False, False, False, False, True]
Current timestep = 9337. State = [[-0.29337403  0.1986962 ]]. Action = [[-0.07567696  0.0603384   0.          0.43471873]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 9337 is [True, False, False, False, False, True]
State prediction error at timestep 9337 is 0.012
Human Feedback received at timestep 9337 of None
Current timestep = 9338. State = [[-0.29409963  0.19958039]]. Action = [[ 0.02941812 -0.0357364   0.          0.63129926]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 9338 is [True, False, False, False, False, True]
Current timestep = 9339. State = [[-0.29264578  0.20200185]]. Action = [[0.01521151 0.05712048 0.         0.4608624 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 9339 is [True, False, False, False, False, True]
Current timestep = 9340. State = [[-0.28890133  0.19977655]]. Action = [[ 0.06628174 -0.08409867  0.          0.7263651 ]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 9340 is [True, False, False, False, False, True]
Current timestep = 9341. State = [[-0.28676695  0.1939002 ]]. Action = [[-0.00778223 -0.07864355  0.         -0.17982864]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 9341 is [True, False, False, False, False, True]
Current timestep = 9342. State = [[-0.28796273  0.19255428]]. Action = [[-0.03791823  0.01374509  0.          0.05016518]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 9342 is [True, False, False, False, False, True]
Current timestep = 9343. State = [[-0.29009202  0.19183044]]. Action = [[-0.03190368 -0.02559511  0.         -0.14207691]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 9343 is [True, False, False, False, False, True]
State prediction error at timestep 9343 is 0.012
Human Feedback received at timestep 9343 of None
Current timestep = 9344. State = [[-0.28686595  0.19537114]]. Action = [[ 0.0862845   0.09279761  0.         -0.06862867]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 9344 is [True, False, False, False, False, True]
Current timestep = 9345. State = [[-0.28864366  0.19778818]]. Action = [[-0.09727944 -0.00612435  0.          0.43015623]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 9345 is [True, False, False, False, False, True]
Current timestep = 9346. State = [[-0.2926844   0.20211011]]. Action = [[-0.01779742  0.08721112  0.         -0.94470143]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 9346 is [True, False, False, False, False, True]
State prediction error at timestep 9346 is 0.012
Human Feedback received at timestep 9346 of None
Current timestep = 9347. State = [[-0.29218146  0.20067994]]. Action = [[ 0.03999584 -0.07981541  0.         -0.00922471]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 9347 is [True, False, False, False, False, True]
State prediction error at timestep 9347 is 0.012
Human Feedback received at timestep 9347 of None
Current timestep = 9348. State = [[-0.29504943  0.20080474]]. Action = [[-0.07082397  0.04627147  0.         -0.7509268 ]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 9348 is [True, False, False, False, False, True]
State prediction error at timestep 9348 is 0.012
Human Feedback received at timestep 9348 of None
Current timestep = 9349. State = [[-0.3015528  0.2012347]]. Action = [[-0.07664989 -0.02579806  0.         -0.5127776 ]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 9349 is [True, False, False, False, False, True]
Current timestep = 9350. State = [[-0.30668178  0.20235707]]. Action = [[-0.03794888  0.0225753   0.         -0.4493839 ]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 9350 is [True, False, False, False, False, True]
State prediction error at timestep 9350 is 0.012
Human Feedback received at timestep 9350 of None
Current timestep = 9351. State = [[-0.31211108  0.2074723 ]]. Action = [[-0.05718248  0.08131658  0.          0.24507022]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 9351 is [True, False, False, False, False, True]
Current timestep = 9352. State = [[-0.31540132  0.20821108]]. Action = [[ 0.00137503 -0.04287278  0.         -0.10001701]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 9352 is [True, False, False, False, False, True]
State prediction error at timestep 9352 is 0.012
Human Feedback received at timestep 9352 of None
Current timestep = 9353. State = [[-0.31915814  0.21007045]]. Action = [[-0.04467101  0.04999488  0.         -0.21774238]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 9353 is [True, False, False, False, False, True]
State prediction error at timestep 9353 is 0.012
Human Feedback received at timestep 9353 of None
Current timestep = 9354. State = [[-0.32672226  0.21196093]]. Action = [[-0.09334947 -0.00279928  0.          0.53080773]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 9354 is [True, False, False, False, False, True]
Current timestep = 9355. State = [[-0.3330755   0.21164525]]. Action = [[-0.0380981  -0.02437344  0.         -0.13330084]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 9355 is [True, False, False, False, False, True]
State prediction error at timestep 9355 is 0.012
Human Feedback received at timestep 9355 of None
Current timestep = 9356. State = [[-0.33632     0.21391337]]. Action = [[-0.00391973  0.04771719  0.          0.79734194]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 9356 is [True, False, False, False, False, True]
Current timestep = 9357. State = [[-0.3335013   0.21084611]]. Action = [[ 0.0950697  -0.09156873  0.          0.3078699 ]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 9357 is [True, False, False, False, False, True]
Current timestep = 9358. State = [[-0.32818913  0.21029037]]. Action = [[ 0.07333034  0.05164485  0.         -0.04200208]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 9358 is [True, False, False, False, False, True]
Current timestep = 9359. State = [[-0.32890695  0.21491428]]. Action = [[-0.04382563  0.08048151  0.          0.6170337 ]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 9359 is [True, False, False, False, False, True]
Current timestep = 9360. State = [[-0.32577598  0.21295886]]. Action = [[ 0.09844103 -0.08562765  0.         -0.2302233 ]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 9360 is [True, False, False, False, False, True]
Current timestep = 9361. State = [[-0.31830105  0.2068173 ]]. Action = [[ 0.08835464 -0.0665888   0.          0.14001179]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 9361 is [True, False, False, False, False, True]
Current timestep = 9362. State = [[-0.31504998  0.20225805]]. Action = [[-0.00832229 -0.03905398  0.          0.722229  ]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 9362 is [True, False, False, False, False, True]
Current timestep = 9363. State = [[-0.31829748  0.20549026]]. Action = [[-0.08558346  0.09849127  0.         -0.9473597 ]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 9363 is [True, False, False, False, False, True]
Current timestep = 9364. State = [[-0.32142487  0.20864995]]. Action = [[-0.02280672  0.01095021  0.         -0.20706958]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 9364 is [True, False, False, False, False, True]
Current timestep = 9365. State = [[-0.3213393   0.20864858]]. Action = [[ 0.01322678 -0.00764792  0.         -0.78401756]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 9365 is [True, False, False, False, False, True]
Current timestep = 9366. State = [[-0.31855735  0.20637624]]. Action = [[ 0.04389914 -0.0377535   0.          0.5319929 ]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 9366 is [True, False, False, False, False, True]
Current timestep = 9367. State = [[-0.3129913   0.20295137]]. Action = [[ 0.07634587 -0.03813649  0.         -0.25536036]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 9367 is [True, False, False, False, False, True]
Current timestep = 9368. State = [[-0.30971834  0.20065837]]. Action = [[ 0.00427562 -0.0113777   0.          0.8909086 ]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 9368 is [True, False, False, False, False, True]
State prediction error at timestep 9368 is 0.012
Human Feedback received at timestep 9368 of None
Current timestep = 9369. State = [[-0.30842006  0.2030871 ]]. Action = [[ 0.00682922  0.0674844   0.         -0.25528765]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 9369 is [True, False, False, False, False, True]
State prediction error at timestep 9369 is 0.012
Human Feedback received at timestep 9369 of None
Current timestep = 9370. State = [[-0.31208962  0.20874527]]. Action = [[-0.08558162  0.08243766  0.          0.593462  ]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 9370 is [True, False, False, False, False, True]
Current timestep = 9371. State = [[-0.3174934   0.21103323]]. Action = [[-0.05873809 -0.00986747  0.          0.8075539 ]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 9371 is [True, False, False, False, False, True]
Current timestep = 9372. State = [[-0.3229463   0.21462922]]. Action = [[-0.06487106  0.06175692  0.         -0.7042821 ]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 9372 is [True, False, False, False, False, True]
Current timestep = 9373. State = [[-0.33068815  0.22207092]]. Action = [[-0.09349553  0.09872433  0.         -0.67674327]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 9373 is [True, False, False, False, False, True]
Current timestep = 9374. State = [[-0.33262673  0.23013648]]. Action = [[ 0.05664658  0.09060394  0.         -0.201581  ]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 9374 is [True, False, False, False, False, True]
Current timestep = 9375. State = [[-0.33001065  0.23286042]]. Action = [[ 0.06017637 -0.009767    0.          0.67442167]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 9375 is [True, False, False, False, False, True]
Current timestep = 9376. State = [[-0.32725957  0.23538442]]. Action = [[0.04341321 0.04075264 0.         0.68466866]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 9376 is [True, False, False, False, False, True]
Current timestep = 9377. State = [[-0.32455394  0.23484686]]. Action = [[ 0.04168943 -0.05161439  0.         -0.7494343 ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 9377 is [True, False, False, False, False, True]
Current timestep = 9378. State = [[-0.3267231   0.23122111]]. Action = [[-0.0694048  -0.07422924  0.          0.28099358]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 9378 is [True, False, False, False, False, True]
Current timestep = 9379. State = [[-0.32970876  0.23391749]]. Action = [[-0.01996505  0.06921809  0.          0.02786016]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 9379 is [True, False, False, False, False, True]
Current timestep = 9380. State = [[-0.32643646  0.23963866]]. Action = [[0.08364    0.06038717 0.         0.8997239 ]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 9380 is [True, False, False, False, False, True]
Current timestep = 9381. State = [[-0.31943026  0.24328193]]. Action = [[0.09143692 0.03189286 0.         0.17455316]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 9381 is [True, False, False, False, False, True]
Current timestep = 9382. State = [[-0.31558225  0.24732675]]. Action = [[ 0.01039447  0.05663701  0.         -0.8548138 ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 9382 is [True, False, False, False, False, True]
Current timestep = 9383. State = [[-0.31637135  0.2514931 ]]. Action = [[-0.03804741  0.03688478  0.          0.44196653]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 9383 is [True, False, False, False, False, True]
Current timestep = 9384. State = [[-0.31901303  0.2575033 ]]. Action = [[-0.040485    0.07629596  0.         -0.13485068]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 9384 is [True, False, False, False, False, True]
Current timestep = 9385. State = [[-0.3246938  0.2570559]]. Action = [[-0.09931092 -0.09258623  0.         -0.8258197 ]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 9385 is [True, False, False, False, False, True]
Current timestep = 9386. State = [[-0.33019555  0.26106578]]. Action = [[-0.04391006  0.09938554  0.         -0.20375377]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 9386 is [True, False, False, False, False, True]
Current timestep = 9387. State = [[-0.32877466  0.26565647]]. Action = [[ 0.06852707  0.00812993  0.         -0.5214643 ]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 9387 is [True, False, False, False, False, True]
Current timestep = 9388. State = [[-0.32662573  0.2702302 ]]. Action = [[ 0.01162802  0.06262576  0.         -0.1006794 ]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 9388 is [True, False, False, False, False, True]
Current timestep = 9389. State = [[-0.3226593   0.27298233]]. Action = [[ 0.07485779 -0.00109827  0.         -0.9619091 ]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 9389 is [True, False, False, False, False, True]
Current timestep = 9390. State = [[-0.32053977  0.275559  ]]. Action = [[-0.00466898  0.03173556  0.          0.5982537 ]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 9390 is [True, False, False, False, False, True]
State prediction error at timestep 9390 is 0.012
Human Feedback received at timestep 9390 of None
Current timestep = 9391. State = [[-0.32076204  0.2757418 ]]. Action = [[-0.01037746 -0.0394888   0.         -0.33595157]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 9391 is [True, False, False, False, False, True]
State prediction error at timestep 9391 is 0.012
Human Feedback received at timestep 9391 of None
Current timestep = 9392. State = [[-0.32210848  0.28018752]]. Action = [[-0.02753339  0.08584637  0.          0.7177086 ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 9392 is [True, False, False, False, False, True]
State prediction error at timestep 9392 is 0.012
Human Feedback received at timestep 9392 of None
Current timestep = 9393. State = [[-0.31855989  0.2858997 ]]. Action = [[ 0.08706941  0.05075037  0.         -0.6138266 ]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 9393 is [True, False, False, False, False, True]
Current timestep = 9394. State = [[-0.32000375  0.2885066 ]]. Action = [[-0.08683817  0.00109023  0.         -0.21573329]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 9394 is [True, False, False, False, False, True]
Current timestep = 9395. State = [[-0.32298884  0.29022378]]. Action = [[-0.01107877  0.00775417  0.         -0.6906426 ]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 9395 is [True, False, False, False, False, True]
Current timestep = 9396. State = [[-0.32076037  0.290241  ]]. Action = [[ 0.05614629 -0.02503545  0.          0.9814999 ]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 9396 is [True, False, False, False, False, True]
Current timestep = 9397. State = [[-0.32275847  0.29442975]]. Action = [[-0.07275747  0.08519556  0.         -0.00022471]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 9397 is [True, False, False, False, False, True]
Current timestep = 9398. State = [[-0.3279024  0.3002392]]. Action = [[-0.05114896  0.05020424  0.          0.6291002 ]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 9398 is [True, False, False, False, False, True]
Current timestep = 9399. State = [[-0.33126226  0.299949  ]]. Action = [[-0.02102357 -0.06303009  0.         -0.7783796 ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 9399 is [True, False, False, False, False, True]
Current timestep = 9400. State = [[-0.33534664  0.29621804]]. Action = [[-0.05892698 -0.07506993  0.          0.11683536]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 9400 is [True, False, False, False, False, True]
State prediction error at timestep 9400 is 0.012
Human Feedback received at timestep 9400 of None
Current timestep = 9401. State = [[-0.33413976  0.29580224]]. Action = [[0.07218701 0.01494597 0.         0.45598102]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 9401 is [True, False, False, False, False, True]
State prediction error at timestep 9401 is 0.012
Human Feedback received at timestep 9401 of None
Current timestep = 9402. State = [[-0.32845527  0.293548  ]]. Action = [[ 0.07465994 -0.06305437  0.         -0.8301891 ]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 9402 is [True, False, False, False, False, True]
Current timestep = 9403. State = [[-0.32211474  0.29620585]]. Action = [[0.07392698 0.09387691 0.         0.7544184 ]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 9403 is [True, False, False, False, False, True]
Current timestep = 9404. State = [[-0.32173508  0.29760805]]. Action = [[-0.05509486 -0.02467084  0.          0.0224452 ]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 9404 is [True, False, False, False, False, True]
Current timestep = 9405. State = [[-0.32466298  0.2946384 ]]. Action = [[-0.0383151  -0.05401091  0.         -0.294299  ]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 9405 is [True, False, False, False, False, True]
State prediction error at timestep 9405 is 0.012
Human Feedback received at timestep 9405 of None
Current timestep = 9406. State = [[-0.32699028  0.2904973 ]]. Action = [[-0.02976883 -0.06066746  0.          0.80728006]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 9406 is [True, False, False, False, False, True]
Current timestep = 9407. State = [[-0.33066928  0.28719163]]. Action = [[-0.05967099 -0.03695514  0.         -0.6366532 ]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 9407 is [True, False, False, False, False, True]
Current timestep = 9408. State = [[-0.33022016  0.2827618 ]]. Action = [[ 0.04458145 -0.06742237  0.          0.5649389 ]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 9408 is [True, False, False, False, False, True]
Current timestep = 9409. State = [[-0.33018637  0.28308073]]. Action = [[-0.0234644   0.05942466  0.          0.43611288]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 9409 is [True, False, False, False, False, True]
State prediction error at timestep 9409 is 0.012
Human Feedback received at timestep 9409 of None
Current timestep = 9410. State = [[-0.33568555  0.28369716]]. Action = [[-0.08942795 -0.0060091   0.         -0.02035183]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 9410 is [True, False, False, False, False, True]
Current timestep = 9411. State = [[-0.33661032  0.28202996]]. Action = [[ 0.04924285 -0.02172608  0.         -0.5722634 ]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 9411 is [True, False, False, False, False, True]
State prediction error at timestep 9411 is 0.012
Human Feedback received at timestep 9411 of None
Current timestep = 9412. State = [[-0.3321254   0.28483868]]. Action = [[0.08194875 0.0981745  0.         0.7717625 ]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 9412 is [True, False, False, False, False, True]
Current timestep = 9413. State = [[-0.3334427   0.29071844]]. Action = [[-0.05934972  0.09707653  0.          0.47082376]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 9413 is [True, False, False, False, False, True]
Current timestep = 9414. State = [[-0.33386138  0.29361352]]. Action = [[ 0.04147785  0.01920757  0.         -0.09833771]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 9414 is [True, False, False, False, False, True]
Current timestep = 9415. State = [[-0.3355527   0.29411677]]. Action = [[-0.04302865  0.00535409  0.          0.60736656]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 9415 is [True, False, False, False, False, True]
Current timestep = 9416. State = [[-0.33384904  0.29450172]]. Action = [[ 0.06969555  0.00472802  0.         -0.9628541 ]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 9416 is [True, False, False, False, False, True]
Current timestep = 9417. State = [[-0.32818067  0.29601315]]. Action = [[0.07944926 0.03396099 0.         0.56776583]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 9417 is [True, False, False, False, False, True]
Current timestep = 9418. State = [[-0.322195   0.2986379]]. Action = [[0.06782842 0.04144155 0.         0.07344925]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 9418 is [True, False, False, False, False, True]
Current timestep = 9419. State = [[-0.32211694  0.30126905]]. Action = [[-0.05129996  0.02884435  0.         -0.42197216]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 9419 is [True, False, False, False, False, True]
Current timestep = 9420. State = [[-0.32408264  0.30120364]]. Action = [[-0.02293    -0.03520364  0.         -0.44657683]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 9420 is [True, False, False, False, False, True]
State prediction error at timestep 9420 is 0.012
Human Feedback received at timestep 9420 of None
Current timestep = 9421. State = [[-0.32226253  0.29794112]]. Action = [[ 0.03762855 -0.07036375  0.          0.5480672 ]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 9421 is [True, False, False, False, False, True]
Current timestep = 9422. State = [[-0.32095048  0.29414365]]. Action = [[-0.01486734 -0.05718842  0.          0.47998595]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 9422 is [True, False, False, False, False, True]
Current timestep = 9423. State = [[-0.3235458   0.29201293]]. Action = [[-0.0657251  -0.03068881  0.          0.9383445 ]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 9423 is [True, False, False, False, False, True]
Current timestep = 9424. State = [[-0.3288114   0.29008588]]. Action = [[-0.08170842 -0.0433094   0.         -0.38405156]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 9424 is [True, False, False, False, False, True]
Current timestep = 9425. State = [[-0.32786778  0.291806  ]]. Action = [[0.06977033 0.05405209 0.         0.07757294]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 9425 is [True, False, False, False, False, True]
State prediction error at timestep 9425 is 0.012
Human Feedback received at timestep 9425 of None
Current timestep = 9426. State = [[-0.32451776  0.29772434]]. Action = [[ 0.02748629  0.09322783  0.         -0.9784463 ]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 9426 is [True, False, False, False, False, True]
Current timestep = 9427. State = [[-0.3263711   0.30125105]]. Action = [[-0.0567106   0.01601066  0.         -0.08543968]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 9427 is [True, False, False, False, False, True]
Current timestep = 9428. State = [[-0.32565895  0.30633423]]. Action = [[ 0.0536397   0.08943286  0.         -0.9289469 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 9428 is [True, False, False, False, False, True]
Current timestep = 9429. State = [[-0.3240148   0.31301206]]. Action = [[ 0.01210108  0.08695463  0.         -0.8178296 ]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 9429 is [True, False, False, False, False, True]
Current timestep = 9430. State = [[-0.32623893  0.31874555]]. Action = [[-0.04360237  0.0592747   0.         -0.30614918]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 9430 is [True, False, False, False, False, True]
Current timestep = 9431. State = [[-0.32493693  0.32574973]]. Action = [[ 0.06495192  0.09566433  0.         -0.389266  ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 9431 is [True, False, False, False, False, True]
State prediction error at timestep 9431 is 0.012
Human Feedback received at timestep 9431 of None
Current timestep = 9432. State = [[-0.32589948  0.33364776]]. Action = [[-0.04289968  0.0930715   0.          0.2124281 ]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 9432 is [True, False, False, False, False, True]
Current timestep = 9433. State = [[-0.32767916  0.3332122 ]]. Action = [[-0.00382925 -0.09892303  0.          0.12873936]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 9433 is [True, False, False, False, False, True]
Current timestep = 9434. State = [[-0.3326632  0.3293827]]. Action = [[-0.09290315 -0.07446472  0.          0.8613384 ]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 9434 is [True, False, False, False, False, True]
Current timestep = 9435. State = [[-0.33791614  0.33373386]]. Action = [[-0.03511072  0.09618954  0.          0.154616  ]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 9435 is [True, False, False, False, False, True]
Current timestep = 9436. State = [[-0.33837333  0.33551407]]. Action = [[ 0.02710023 -0.05591301  0.         -0.94003135]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 9436 is [True, False, False, False, False, True]
State prediction error at timestep 9436 is 0.012
Human Feedback received at timestep 9436 of None
Current timestep = 9437. State = [[-0.3350123   0.33363906]]. Action = [[ 0.05489068 -0.04542973  0.         -0.39335012]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 9437 is [True, False, False, False, False, True]
State prediction error at timestep 9437 is 0.012
Human Feedback received at timestep 9437 of None
Current timestep = 9438. State = [[-0.3336349   0.33137006]]. Action = [[-0.01202603 -0.04830227  0.          0.5414468 ]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 9438 is [True, False, False, False, False, True]
Current timestep = 9439. State = [[-0.3353699  0.332244 ]]. Action = [[-0.03773788  0.0204363   0.          0.99080706]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 9439 is [True, False, False, False, False, True]
Current timestep = 9440. State = [[-0.33423603  0.337312  ]]. Action = [[ 0.04452258  0.08086681  0.         -0.23351038]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 9440 is [True, False, False, False, False, True]
Current timestep = 9441. State = [[-0.33470532  0.33655426]]. Action = [[-0.04071251 -0.0772236   0.          0.92104673]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 9441 is [True, False, False, False, False, True]
Current timestep = 9442. State = [[-0.3410182   0.33920708]]. Action = [[-0.0997152   0.08862621  0.         -0.4755975 ]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 9442 is [True, False, False, False, False, True]
Current timestep = 9443. State = [[-0.3491695   0.33900565]]. Action = [[-0.08699764 -0.06488632  0.          0.05082095]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 9443 is [True, False, False, False, False, True]
Current timestep = 9444. State = [[-0.34884018  0.33946115]]. Action = [[0.08962628 0.04562021 0.         0.6750941 ]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 9444 is [True, False, False, False, False, True]
Current timestep = 9445. State = [[-0.3451745  0.3431071]]. Action = [[0.04032455 0.05550834 0.         0.03527427]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 9445 is [True, False, False, False, False, True]
Current timestep = 9446. State = [[-0.3442803   0.34452584]]. Action = [[ 0.          0.          0.         -0.10195583]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 9446 is [True, False, False, False, False, True]
Current timestep = 9447. State = [[-0.34615356  0.34312388]]. Action = [[-0.03512654 -0.03602696  0.          0.0073632 ]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 9447 is [True, False, False, False, False, True]
Current timestep = 9448. State = [[-0.3481535   0.34115142]]. Action = [[-0.01721665 -0.0321207   0.         -0.59396595]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 9448 is [True, False, False, False, False, True]
Current timestep = 9449. State = [[-0.34599665  0.33702594]]. Action = [[ 0.05416722 -0.07532213  0.         -0.5990446 ]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 9449 is [True, False, False, False, False, True]
Current timestep = 9450. State = [[-0.3419325   0.33524618]]. Action = [[ 0.04313404  0.00714173  0.         -0.6722539 ]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 9450 is [True, False, False, False, False, True]
Current timestep = 9451. State = [[-0.336429    0.33277693]]. Action = [[ 0.07119634 -0.04243029  0.          0.15524721]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 9451 is [True, False, False, False, False, True]
State prediction error at timestep 9451 is 0.012
Human Feedback received at timestep 9451 of None
Current timestep = 9452. State = [[-0.33332157  0.32959569]]. Action = [[-0.00089389 -0.02886637  0.         -0.8183788 ]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 9452 is [True, False, False, False, False, True]
Current timestep = 9453. State = [[-0.33621344  0.32908034]]. Action = [[-0.07976608  0.01468156  0.         -0.22909087]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 9453 is [True, False, False, False, False, True]
State prediction error at timestep 9453 is 0.012
Human Feedback received at timestep 9453 of None
Current timestep = 9454. State = [[-0.3411417   0.32554495]]. Action = [[-0.06396073 -0.07922617  0.          0.9347091 ]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 9454 is [True, False, False, False, False, True]
State prediction error at timestep 9454 is 0.012
Human Feedback received at timestep 9454 of None
Current timestep = 9455. State = [[-0.34225392  0.32406238]]. Action = [[ 0.01500509  0.01852467  0.         -0.29528344]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 9455 is [True, False, False, False, False, True]
Current timestep = 9456. State = [[-0.34061983  0.32661885]]. Action = [[ 0.02760989  0.05852718  0.         -0.4457891 ]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 9456 is [True, False, False, False, False, True]
Current timestep = 9457. State = [[-0.3423092   0.33082786]]. Action = [[-0.04351782  0.07204161  0.          0.23652983]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 9457 is [True, False, False, False, False, True]
Current timestep = 9458. State = [[-0.34455222  0.3339661 ]]. Action = [[-0.00682651  0.03474007  0.         -0.18710774]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 9458 is [True, False, False, False, False, True]
Current timestep = 9459. State = [[-0.34459314  0.33422765]]. Action = [[ 0.01929518 -0.00814081  0.         -0.17948234]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 9459 is [True, False, False, False, False, True]
Current timestep = 9460. State = [[-0.34796393  0.33099502]]. Action = [[-0.06835951 -0.06503124  0.          0.8808019 ]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 9460 is [True, False, False, False, False, True]
Current timestep = 9461. State = [[-0.3534645   0.32545674]]. Action = [[-0.0608537  -0.09176396  0.         -0.2973317 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 9461 is [True, False, False, False, False, True]
Current timestep = 9462. State = [[-0.3511389  0.3192952]]. Action = [[ 0.094675   -0.08210205  0.         -0.5057664 ]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 9462 is [True, False, False, False, False, True]
Current timestep = 9463. State = [[-0.3499228   0.31326622]]. Action = [[-0.02814914 -0.0696301   0.         -0.5577448 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 9463 is [True, False, False, False, False, True]
Current timestep = 9464. State = [[-0.35154104  0.31409422]]. Action = [[-0.01638345  0.06922182  0.          0.91419494]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 9464 is [True, False, False, False, False, True]
Current timestep = 9465. State = [[-0.3565329  0.3111955]]. Action = [[-0.08782027 -0.09324841  0.          0.00409162]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 9465 is [True, False, False, False, False, True]
Current timestep = 9466. State = [[-0.3616577  0.3088095]]. Action = [[-0.03504553  0.0139019   0.          0.69872034]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 9466 is [True, False, False, False, False, True]
Current timestep = 9467. State = [[-0.36141524  0.3106652 ]]. Action = [[ 0.05189892  0.05877083  0.         -0.62800485]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 9467 is [True, False, False, False, False, True]
Current timestep = 9468. State = [[-0.3616965  0.3110116]]. Action = [[-0.01256555  0.00723038  0.         -0.14798468]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 9468 is [True, False, False, False, False, True]
State prediction error at timestep 9468 is 0.012
Human Feedback received at timestep 9468 of None
Current timestep = 9469. State = [[-0.3594642   0.30902505]]. Action = [[ 0.06747397 -0.0174785   0.          0.6643305 ]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 9469 is [True, False, False, False, False, True]
Current timestep = 9470. State = [[-0.3564551  0.3092949]]. Action = [[ 0.03179776  0.04690795  0.         -0.43981946]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 9470 is [True, False, False, False, False, True]
Current timestep = 9471. State = [[-0.3554627  0.3077237]]. Action = [[ 0.00488526 -0.03116117  0.         -0.32912338]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 9471 is [True, False, False, False, False, True]
State prediction error at timestep 9471 is 0.012
Human Feedback received at timestep 9471 of None
Current timestep = 9472. State = [[-0.35946837  0.30678388]]. Action = [[-0.08146529  0.012206    0.          0.8162894 ]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 9472 is [True, False, False, False, False, True]
State prediction error at timestep 9472 is 0.012
Human Feedback received at timestep 9472 of None
Current timestep = 9473. State = [[-0.3578895   0.30730486]]. Action = [[ 0.08651575  0.01644586  0.         -0.26169002]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 9473 is [True, False, False, False, False, True]
State prediction error at timestep 9473 is 0.012
Human Feedback received at timestep 9473 of None
Current timestep = 9474. State = [[-0.35997945  0.30770445]]. Action = [[-0.08767625  0.01191636  0.         -0.27174103]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 9474 is [True, False, False, False, False, True]
State prediction error at timestep 9474 is 0.012
Human Feedback received at timestep 9474 of None
Current timestep = 9475. State = [[-0.36515495  0.31164172]]. Action = [[-0.04496503  0.07580032  0.         -0.742719  ]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 9475 is [True, False, False, False, False, True]
Current timestep = 9476. State = [[-0.36641845  0.31790128]]. Action = [[0.0234491  0.09024916 0.         0.72548544]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 9476 is [True, False, False, False, False, True]
Current timestep = 9477. State = [[-0.36298743  0.319723  ]]. Action = [[ 0.07379784 -0.00938933  0.          0.5072042 ]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 9477 is [True, False, False, False, False, True]
Current timestep = 9478. State = [[-0.36309022  0.3195958 ]]. Action = [[-0.03801204 -0.00235962  0.          0.882823  ]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 9478 is [True, False, False, False, False, True]
State prediction error at timestep 9478 is 0.012
Human Feedback received at timestep 9478 of None
Current timestep = 9479. State = [[-0.35963193  0.3164062 ]]. Action = [[ 0.09247839 -0.07664077  0.          0.8428011 ]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 9479 is [True, False, False, False, False, True]
State prediction error at timestep 9479 is 0.012
Human Feedback received at timestep 9479 of None
Current timestep = 9480. State = [[-0.3557682  0.3110054]]. Action = [[ 0.01485761 -0.08021303  0.          0.3210609 ]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 9480 is [True, False, False, False, False, True]
Current timestep = 9481. State = [[-0.3543673   0.30489433]]. Action = [[-0.00285663 -0.0946005   0.         -0.04680175]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 9481 is [True, False, False, False, False, True]
Current timestep = 9482. State = [[-0.35282242  0.30124483]]. Action = [[ 0.00900207 -0.03077608  0.         -0.9623809 ]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 9482 is [True, False, False, False, False, True]
Current timestep = 9483. State = [[-0.352556    0.29752004]]. Action = [[-0.02306613 -0.05959307  0.         -0.4808762 ]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 9483 is [True, False, False, False, False, True]
Current timestep = 9484. State = [[-0.35466787  0.29116303]]. Action = [[-0.05124519 -0.09907908  0.          0.5802101 ]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 9484 is [True, False, False, False, False, True]
Current timestep = 9485. State = [[-0.35214937  0.29003704]]. Action = [[0.07067462 0.05083062 0.         0.94828725]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 9485 is [True, False, False, False, False, True]
Current timestep = 9486. State = [[-0.34516224  0.2868387 ]]. Action = [[ 0.0781705  -0.07333973  0.          0.8886056 ]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 9486 is [True, False, False, False, False, True]
Current timestep = 9487. State = [[-0.34491444  0.28659976]]. Action = [[-0.07189777  0.05667029  0.          0.9423795 ]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 9487 is [True, False, False, False, False, True]
Current timestep = 9488. State = [[-0.34560508  0.29149157]]. Action = [[ 0.01580049  0.08640083  0.         -0.6023524 ]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 9488 is [True, False, False, False, False, True]
State prediction error at timestep 9488 is 0.012
Human Feedback received at timestep 9488 of None
Current timestep = 9489. State = [[-0.34328818  0.2949047 ]]. Action = [[ 0.03867089  0.04134768  0.         -0.1438359 ]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 9489 is [True, False, False, False, False, True]
Current timestep = 9490. State = [[-0.34604263  0.29683614]]. Action = [[-0.0790073   0.02775972  0.          0.1942383 ]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 9490 is [True, False, False, False, False, True]
State prediction error at timestep 9490 is 0.012
Human Feedback received at timestep 9490 of None
Current timestep = 9491. State = [[-0.3462962  0.3003083]]. Action = [[ 0.04749221  0.06035329  0.         -0.81770647]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 9491 is [True, False, False, False, False, True]
Current timestep = 9492. State = [[-0.3470365   0.29792336]]. Action = [[-0.03796215 -0.0876085   0.          0.11082387]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 9492 is [True, False, False, False, False, True]
Current timestep = 9493. State = [[-0.35139596  0.2945835 ]]. Action = [[-0.058222   -0.0262209   0.          0.09680033]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 9493 is [True, False, False, False, False, True]
Current timestep = 9494. State = [[-0.34919158  0.2915704 ]]. Action = [[ 0.09140202 -0.04506174  0.         -0.7375416 ]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 9494 is [True, False, False, False, False, True]
Current timestep = 9495. State = [[-0.34950534  0.28700322]]. Action = [[-0.05412038 -0.06175851  0.          0.60439944]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 9495 is [True, False, False, False, False, True]
State prediction error at timestep 9495 is 0.012
Human Feedback received at timestep 9495 of None
Current timestep = 9496. State = [[-0.34877065  0.28033787]]. Action = [[ 0.04396125 -0.0995397   0.          0.02690423]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 9496 is [True, False, False, False, False, True]
State prediction error at timestep 9496 is 0.012
Human Feedback received at timestep 9496 of None
Current timestep = 9497. State = [[-0.34434554  0.2789621 ]]. Action = [[0.06179697 0.04660895 0.         0.1873101 ]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 9497 is [True, False, False, False, False, True]
Current timestep = 9498. State = [[-0.33705676  0.2765681 ]]. Action = [[ 0.09867338 -0.04593968  0.          0.2426014 ]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 9498 is [True, False, False, False, False, True]
State prediction error at timestep 9498 is 0.012
Human Feedback received at timestep 9498 of None
Current timestep = 9499. State = [[-0.33177474  0.27276513]]. Action = [[ 0.02566499 -0.02462469  0.         -0.6755092 ]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 9499 is [True, False, False, False, False, True]
Current timestep = 9500. State = [[-0.33223566  0.26794678]]. Action = [[-0.05328701 -0.06379949  0.          0.44762254]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 9500 is [True, False, False, False, False, True]
Current timestep = 9501. State = [[-0.33601356  0.26493382]]. Action = [[-0.0683635  -0.01356941  0.         -0.02640074]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 9501 is [True, False, False, False, False, True]
Current timestep = 9502. State = [[-0.33411002  0.26520237]]. Action = [[ 0.07023212  0.03532045  0.         -0.11034328]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 9502 is [True, False, False, False, False, True]
Current timestep = 9503. State = [[-0.3313255   0.26469377]]. Action = [[ 0.00690113 -0.00352766  0.         -0.39911258]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 9503 is [True, False, False, False, False, True]
Current timestep = 9504. State = [[-0.3341913   0.26115143]]. Action = [[-0.07483923 -0.05607588  0.          0.45858967]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 9504 is [True, False, False, False, False, True]
Current timestep = 9505. State = [[-0.33623326  0.2602677 ]]. Action = [[-4.0901452e-04  2.4051860e-02  0.0000000e+00  6.8750560e-01]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 9505 is [True, False, False, False, False, True]
State prediction error at timestep 9505 is 0.012
Human Feedback received at timestep 9505 of None
Current timestep = 9506. State = [[-0.33681458  0.2623942 ]]. Action = [[-0.00470888  0.04598375  0.         -0.29507303]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 9506 is [True, False, False, False, False, True]
Current timestep = 9507. State = [[-0.33594668  0.26002768]]. Action = [[ 0.02686179 -0.06107206  0.          0.88735104]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 9507 is [True, False, False, False, False, True]
Current timestep = 9508. State = [[-0.33105448  0.2595199 ]]. Action = [[0.08660153 0.04127466 0.         0.25140238]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 9508 is [True, False, False, False, False, True]
Current timestep = 9509. State = [[-0.32531586  0.25608918]]. Action = [[ 0.05983124 -0.07047274  0.         -0.70416504]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 9509 is [True, False, False, False, False, True]
Current timestep = 9510. State = [[-0.32682195  0.2532771 ]]. Action = [[-0.08094545 -0.00435565  0.         -0.27340448]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 9510 is [True, False, False, False, False, True]
Current timestep = 9511. State = [[-0.33079562  0.25697136]]. Action = [[-0.03891856  0.08319172  0.          0.23525226]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 9511 is [True, False, False, False, False, True]
Current timestep = 9512. State = [[-0.33112866  0.25590557]]. Action = [[ 0.02134101 -0.06617983  0.          0.7421465 ]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 9512 is [True, False, False, False, False, True]
State prediction error at timestep 9512 is 0.012
Human Feedback received at timestep 9512 of None
Current timestep = 9513. State = [[-0.32709482  0.24952987]]. Action = [[ 0.06481882 -0.09057607  0.          0.341272  ]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 9513 is [True, False, False, False, False, True]
Current timestep = 9514. State = [[-0.32248172  0.2470446 ]]. Action = [[0.04278383 0.01514997 0.         0.9036299 ]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 9514 is [True, False, False, False, False, True]
Current timestep = 9515. State = [[-0.3226079   0.24577603]]. Action = [[-0.04245383 -0.01868883  0.         -0.58123434]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 9515 is [True, False, False, False, False, True]
State prediction error at timestep 9515 is 0.012
Human Feedback received at timestep 9515 of None
Current timestep = 9516. State = [[-0.32581407  0.24938618]]. Action = [[-0.04826726  0.09154841  0.         -0.95321983]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 9516 is [True, False, False, False, False, True]
Current timestep = 9517. State = [[-0.32300764  0.25223815]]. Action = [[0.0895521  0.01779963 0.         0.6922593 ]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 9517 is [True, False, False, False, False, True]
Current timestep = 9518. State = [[-0.32176387  0.2520129 ]]. Action = [[-0.02684732 -0.0039047   0.          0.01749039]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 9518 is [True, False, False, False, False, True]
Current timestep = 9519. State = [[-0.321494    0.25196514]]. Action = [[ 0.01636755  0.00608359  0.         -0.49144852]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 9519 is [True, False, False, False, False, True]
Current timestep = 9520. State = [[-0.3223309  0.2510648]]. Action = [[-0.02819125 -0.01962756  0.          0.5270629 ]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 9520 is [True, False, False, False, False, True]
State prediction error at timestep 9520 is 0.012
Human Feedback received at timestep 9520 of None
Current timestep = 9521. State = [[-0.3208804   0.25092182]]. Action = [[ 0.04277038  0.00796811  0.         -0.31125033]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 9521 is [True, False, False, False, False, True]
State prediction error at timestep 9521 is 0.012
Human Feedback received at timestep 9521 of None
Current timestep = 9522. State = [[-0.31627086  0.24818446]]. Action = [[ 0.06287389 -0.05453461  0.         -0.9237558 ]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 9522 is [True, False, False, False, False, True]
Current timestep = 9523. State = [[-0.30956924  0.24358362]]. Action = [[ 0.08209086 -0.05322137  0.         -0.4154021 ]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 9523 is [True, False, False, False, False, True]
State prediction error at timestep 9523 is 0.012
Human Feedback received at timestep 9523 of None
Current timestep = 9524. State = [[-0.30373386  0.23829003]]. Action = [[ 0.04301976 -0.06247808  0.          0.7091236 ]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 9524 is [True, False, False, False, False, True]
State prediction error at timestep 9524 is 0.012
Human Feedback received at timestep 9524 of None
Current timestep = 9525. State = [[-0.2959515  0.2315282]]. Action = [[ 0.0960978  -0.08357939  0.          0.86345613]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 9525 is [True, False, False, False, False, True]
State prediction error at timestep 9525 is 0.012
Human Feedback received at timestep 9525 of None
Current timestep = 9526. State = [[-0.28959122  0.22917734]]. Action = [[0.03210684 0.02779488 0.         0.53282547]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 9526 is [True, False, False, False, False, True]
Current timestep = 9527. State = [[-0.2849504   0.23024239]]. Action = [[0.03580458 0.03723297 0.         0.3244803 ]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 9527 is [True, False, False, False, False, True]
State prediction error at timestep 9527 is 0.012
Human Feedback received at timestep 9527 of None
Current timestep = 9528. State = [[-0.28635296  0.23134728]]. Action = [[-0.08484118  0.02213337  0.          0.38060236]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 9528 is [True, False, False, False, False, True]
State prediction error at timestep 9528 is 0.012
Human Feedback received at timestep 9528 of None
Current timestep = 9529. State = [[-0.2836674   0.23233919]]. Action = [[0.07899883 0.02204356 0.         0.9258987 ]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 9529 is [True, False, False, False, False, True]
State prediction error at timestep 9529 is 0.012
Human Feedback received at timestep 9529 of None
Current timestep = 9530. State = [[-0.28026766  0.23024349]]. Action = [[ 0.00175004 -0.03974885  0.          0.635406  ]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 9530 is [True, False, False, False, False, True]
Current timestep = 9531. State = [[-0.27561072  0.22533657]]. Action = [[ 0.06427228 -0.06589873  0.          0.27272892]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 9531 is [True, False, False, False, False, True]
Current timestep = 9532. State = [[-0.27132115  0.22186238]]. Action = [[ 0.01987194 -0.01696522  0.          0.66523457]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 9532 is [True, False, False, False, False, True]
Current timestep = 9533. State = [[-0.26848987  0.22267157]]. Action = [[ 0.01796629  0.04376339  0.         -0.12586522]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 9533 is [True, False, False, False, False, True]
Current timestep = 9534. State = [[-0.26981962  0.22298849]]. Action = [[-0.05914161 -0.00770465  0.         -0.65213704]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 9534 is [True, False, False, False, False, True]
Current timestep = 9535. State = [[-0.26963097  0.224067  ]]. Action = [[ 0.02301525  0.02889883  0.         -0.44529188]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 9535 is [True, False, False, False, False, True]
Current timestep = 9536. State = [[-0.26403385  0.22091526]]. Action = [[ 0.09032371 -0.07157512  0.         -0.7684352 ]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 9536 is [True, False, False, False, False, True]
State prediction error at timestep 9536 is 0.012
Human Feedback received at timestep 9536 of None
Current timestep = 9537. State = [[-0.2634587   0.21850818]]. Action = [[-0.05937749  0.00132271  0.         -0.31691837]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 9537 is [True, False, False, False, False, True]
Current timestep = 9538. State = [[-0.2630026   0.21488835]]. Action = [[ 0.02361996 -0.07193021  0.          0.7481134 ]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 9538 is [True, False, False, False, False, True]
Current timestep = 9539. State = [[-0.25657216  0.20980364]]. Action = [[ 0.09884796 -0.05283936  0.         -0.6460627 ]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 9539 is [True, False, False, False, False, True]
State prediction error at timestep 9539 is 0.012
Human Feedback received at timestep 9539 of None
Current timestep = 9540. State = [[-0.2537059   0.20440786]]. Action = [[-0.02550072 -0.06058837  0.         -0.8924246 ]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 9540 is [True, False, False, False, False, True]
Current timestep = 9541. State = [[-0.25569597  0.20373367]]. Action = [[-0.05314235  0.03465974  0.          0.48215508]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 9541 is [True, False, False, False, False, True]
Current timestep = 9542. State = [[-0.25678766  0.20853366]]. Action = [[-2.7716160e-05  9.2266478e-02  0.0000000e+00 -3.4952766e-01]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 9542 is [True, False, False, False, False, True]
Current timestep = 9543. State = [[-0.2591881   0.20961441]]. Action = [[-0.04653444 -0.02171311  0.          0.14616907]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 9543 is [True, False, False, False, False, True]
Current timestep = 9544. State = [[-0.2600942   0.20929687]]. Action = [[0.01195879 0.00773188 0.         0.6864338 ]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 9544 is [True, False, False, False, False, True]
Current timestep = 9545. State = [[-0.25699654  0.21061078]]. Action = [[ 0.06529193  0.03226501  0.         -0.09461135]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 9545 is [True, False, False, False, False, True]
State prediction error at timestep 9545 is 0.012
Human Feedback received at timestep 9545 of None
Current timestep = 9546. State = [[-0.25922593  0.21027057]]. Action = [[-0.08013701 -0.01999707  0.         -0.47701174]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 9546 is [True, False, False, False, False, True]
Current timestep = 9547. State = [[-0.2580353   0.21101293]]. Action = [[ 0.0846241   0.03386553  0.         -0.12588102]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 9547 is [True, False, False, False, False, True]
State prediction error at timestep 9547 is 0.012
Human Feedback received at timestep 9547 of None
Current timestep = 9548. State = [[-0.25888672  0.21137178]]. Action = [[-0.05905766 -0.00748654  0.         -0.6791547 ]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 9548 is [True, False, False, False, False, True]
Current timestep = 9549. State = [[-0.26315686  0.20938426]]. Action = [[-0.0489981  -0.04169707  0.         -0.53284776]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 9549 is [True, False, False, False, False, True]
Current timestep = 9550. State = [[-0.2628142   0.21112445]]. Action = [[ 0.04836664  0.0584714   0.         -0.40563798]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 9550 is [True, False, False, False, False, True]
Current timestep = 9551. State = [[-0.26497447  0.21733192]]. Action = [[-0.05793224  0.094004    0.          0.16743994]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 9551 is [True, False, False, False, False, True]
State prediction error at timestep 9551 is 0.012
Human Feedback received at timestep 9551 of None
Current timestep = 9552. State = [[-0.2681224   0.21833785]]. Action = [[-0.01734491 -0.04521779  0.          0.30611634]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 9552 is [True, False, False, False, False, True]
Current timestep = 9553. State = [[-0.26706427  0.2180242 ]]. Action = [[0.04339703 0.00512765 0.         0.44363475]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 9553 is [True, False, False, False, False, True]
Current timestep = 9554. State = [[-0.2657612  0.2149712]]. Action = [[ 0.00704392 -0.07100604  0.         -0.8387734 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 9554 is [True, False, False, False, False, True]
State prediction error at timestep 9554 is 0.012
Human Feedback received at timestep 9554 of None
Current timestep = 9555. State = [[-0.26990503  0.21122879]]. Action = [[-0.09336091 -0.04814303  0.         -0.12812829]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 9555 is [True, False, False, False, False, True]
Current timestep = 9556. State = [[-0.2691388   0.20579115]]. Action = [[ 0.06435329 -0.09280537  0.          0.2482934 ]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 9556 is [True, False, False, False, False, True]
State prediction error at timestep 9556 is 0.012
Human Feedback received at timestep 9556 of None
Current timestep = 9557. State = [[-0.27121508  0.19964212]]. Action = [[-0.08802897 -0.07301482  0.         -0.8329053 ]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 9557 is [True, False, False, False, False, True]
State prediction error at timestep 9557 is 0.012
Human Feedback received at timestep 9557 of None
Current timestep = 9558. State = [[-0.2777447   0.20192975]]. Action = [[-0.08638992  0.08946859  0.          0.10168266]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 9558 is [True, False, False, False, False, True]
Current timestep = 9559. State = [[-0.27837223  0.20375778]]. Action = [[ 0.05464449 -0.00796121  0.         -0.262478  ]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 9559 is [True, False, False, False, False, True]
Current timestep = 9560. State = [[-0.27308837  0.2055152 ]]. Action = [[0.09806847 0.05832175 0.         0.21435273]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 9560 is [True, False, False, False, False, True]
Current timestep = 9561. State = [[-0.27049607  0.20968802]]. Action = [[0.01376747 0.07963362 0.         0.6487758 ]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 9561 is [True, False, False, False, False, True]
Current timestep = 9562. State = [[-0.27425617  0.2149196 ]]. Action = [[-0.06922624  0.07488025  0.         -0.09307271]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 9562 is [True, False, False, False, False, True]
State prediction error at timestep 9562 is 0.012
Human Feedback received at timestep 9562 of None
Current timestep = 9563. State = [[-0.27996105  0.21664855]]. Action = [[-0.05632279 -0.01127814  0.          0.46904182]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 9563 is [True, False, False, False, False, True]
Current timestep = 9564. State = [[-0.27850398  0.21453145]]. Action = [[ 0.08191868 -0.04464833  0.         -0.9486565 ]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 9564 is [True, False, False, False, False, True]
State prediction error at timestep 9564 is 0.012
Human Feedback received at timestep 9564 of None
Current timestep = 9565. State = [[-0.27824494  0.21541601]]. Action = [[-0.02838503  0.04406055  0.         -0.09134406]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 9565 is [True, False, False, False, False, True]
Current timestep = 9566. State = [[-0.28072324  0.2194313 ]]. Action = [[-0.02181591  0.05148675  0.          0.8987689 ]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 9566 is [True, False, False, False, False, True]
Current timestep = 9567. State = [[-0.28570476  0.2218398 ]]. Action = [[-0.0716534   0.00504401  0.         -0.07678944]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 9567 is [True, False, False, False, False, True]
State prediction error at timestep 9567 is 0.012
Human Feedback received at timestep 9567 of None
Current timestep = 9568. State = [[-0.28636795  0.22015595]]. Action = [[ 0.04224845 -0.05686672  0.         -0.20160156]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 9568 is [True, False, False, False, False, True]
Current timestep = 9569. State = [[-0.28201106  0.22152165]]. Action = [[0.07580746 0.05381653 0.         0.74310446]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 9569 is [True, False, False, False, False, True]
State prediction error at timestep 9569 is 0.012
Human Feedback received at timestep 9569 of None
Current timestep = 9570. State = [[-0.28457     0.22554316]]. Action = [[-0.0920991  0.0463753  0.        -0.5711109]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 9570 is [True, False, False, False, False, True]
Current timestep = 9571. State = [[-0.29075846  0.22652751]]. Action = [[-0.06361344 -0.02472784  0.          0.15319443]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 9571 is [True, False, False, False, False, True]
Current timestep = 9572. State = [[-0.29593197  0.23067372]]. Action = [[-0.04889267  0.0772688   0.         -0.9279337 ]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 9572 is [True, False, False, False, False, True]
Current timestep = 9573. State = [[-0.3034499  0.2358616]]. Action = [[-0.09541637  0.04124556  0.          0.4269377 ]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 9573 is [True, False, False, False, False, True]
Current timestep = 9574. State = [[-0.31068352  0.23937686]]. Action = [[-0.05695015  0.01930374  0.         -0.04597569]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 9574 is [True, False, False, False, False, True]
Current timestep = 9575. State = [[-0.3189716   0.23712912]]. Action = [[-0.0997018  -0.09026122  0.          0.0537585 ]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 9575 is [True, False, False, False, False, True]
Current timestep = 9576. State = [[-0.31962678  0.23962328]]. Action = [[0.09891113 0.09450812 0.         0.40470624]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 9576 is [True, False, False, False, False, True]
Current timestep = 9577. State = [[-0.3143699   0.23902924]]. Action = [[ 0.06630332 -0.08315144  0.          0.67493176]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 9577 is [True, False, False, False, False, True]
Current timestep = 9578. State = [[-0.31017944  0.24086285]]. Action = [[ 0.04012843  0.06714647  0.         -0.6131373 ]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 9578 is [True, False, False, False, False, True]
Current timestep = 9579. State = [[-0.30518955  0.24511106]]. Action = [[0.07176169 0.04186808 0.         0.52391815]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 9579 is [True, False, False, False, False, True]
Current timestep = 9580. State = [[-0.30244836  0.24417189]]. Action = [[-0.00037573 -0.05531776  0.          0.34576178]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 9580 is [True, False, False, False, False, True]
Current timestep = 9581. State = [[-0.30047533  0.24643789]]. Action = [[0.02379749 0.06693051 0.         0.9734845 ]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 9581 is [True, False, False, False, False, True]
Current timestep = 9582. State = [[-0.29522154  0.2454105 ]]. Action = [[ 0.07595808 -0.06261271  0.         -0.22780931]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 9582 is [True, False, False, False, False, True]
State prediction error at timestep 9582 is 0.012
Human Feedback received at timestep 9582 of None
Current timestep = 9583. State = [[-0.29253122  0.2434149 ]]. Action = [[-0.01627379 -0.01075886  0.          0.6309302 ]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 9583 is [True, False, False, False, False, True]
State prediction error at timestep 9583 is 0.012
Human Feedback received at timestep 9583 of None
Current timestep = 9584. State = [[-0.2871273   0.24569377]]. Action = [[ 0.0925061   0.0550633   0.         -0.83191955]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 9584 is [True, False, False, False, False, True]
State prediction error at timestep 9584 is 0.012
Human Feedback received at timestep 9584 of None
Current timestep = 9585. State = [[-0.27915177  0.24857472]]. Action = [[0.08027317 0.03574213 0.         0.09969401]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 9585 is [True, False, False, False, False, True]
Current timestep = 9586. State = [[-0.27858722  0.25292668]]. Action = [[-0.06817994  0.06900897  0.          0.581496  ]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 9586 is [True, False, False, False, False, True]
State prediction error at timestep 9586 is 0.012
Human Feedback received at timestep 9586 of None
Current timestep = 9587. State = [[-0.27558464  0.25794572]]. Action = [[ 0.07528283  0.05467685  0.         -0.8947247 ]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 9587 is [True, False, False, False, False, True]
State prediction error at timestep 9587 is 0.012
Human Feedback received at timestep 9587 of None
Current timestep = 9588. State = [[-0.2769834   0.26486877]]. Action = [[-0.08790825  0.09890693  0.         -0.13206917]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 9588 is [True, False, False, False, False, True]
State prediction error at timestep 9588 is 0.012
Human Feedback received at timestep 9588 of None
Current timestep = 9589. State = [[-0.2819575   0.26807085]]. Action = [[-0.06086205 -0.02011891  0.         -0.23574013]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 9589 is [True, False, False, False, False, True]
Current timestep = 9590. State = [[-0.283828    0.26848528]]. Action = [[-0.00569066 -0.02055008  0.          0.3483957 ]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 9590 is [True, False, False, False, False, True]
Current timestep = 9591. State = [[-0.28195068  0.26855332]]. Action = [[ 0.0387555  -0.02000944  0.         -0.12859046]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 9591 is [True, False, False, False, False, True]
Current timestep = 9592. State = [[-0.2824547   0.26855886]]. Action = [[-0.03851181 -0.01682916  0.          0.5221168 ]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 9592 is [True, False, False, False, False, True]
State prediction error at timestep 9592 is 0.012
Human Feedback received at timestep 9592 of None
Current timestep = 9593. State = [[-0.2859997   0.26580063]]. Action = [[-0.058063   -0.08031891  0.          0.7530544 ]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 9593 is [True, False, False, False, False, True]
Current timestep = 9594. State = [[-0.28882527  0.26611474]]. Action = [[-0.0276328   0.02154406  0.          0.9648304 ]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 9594 is [True, False, False, False, False, True]
Current timestep = 9595. State = [[-0.28510126  0.26408815]]. Action = [[ 0.09203159 -0.06848209  0.         -0.10799795]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 9595 is [True, False, False, False, False, True]
Current timestep = 9596. State = [[-0.27895072  0.26481515]]. Action = [[ 0.06600482  0.05666696  0.         -0.8466421 ]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 9596 is [True, False, False, False, False, True]
State prediction error at timestep 9596 is 0.012
Human Feedback received at timestep 9596 of None
Current timestep = 9597. State = [[-0.27573377  0.268069  ]]. Action = [[ 0.0184138   0.04861281  0.         -0.06064439]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 9597 is [True, False, False, False, False, True]
Current timestep = 9598. State = [[-0.27046365  0.27108905]]. Action = [[ 0.08795399  0.04584258  0.         -0.8134595 ]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 9598 is [True, False, False, False, False, True]
Current timestep = 9599. State = [[-0.26482257  0.26852316]]. Action = [[ 0.04842194 -0.06607862  0.         -0.46805787]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 9599 is [True, False, False, False, False, True]
Current timestep = 9600. State = [[-0.26601663  0.26921323]]. Action = [[-0.07456686  0.0595003   0.          0.07380176]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 9600 is [True, False, False, False, False, True]
Current timestep = 9601. State = [[-0.27032882  0.27440533]]. Action = [[-0.05347893  0.06981746  0.         -0.2181164 ]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 9601 is [True, False, False, False, False, True]
Current timestep = 9602. State = [[-0.27156216  0.28065306]]. Action = [[0.01364511 0.08014312 0.         0.0860033 ]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 9602 is [True, False, False, False, False, True]
State prediction error at timestep 9602 is 0.012
Human Feedback received at timestep 9602 of None
Current timestep = 9603. State = [[-0.26848602  0.28351516]]. Action = [[0.06399927 0.00682823 0.         0.7159461 ]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 9603 is [True, False, False, False, False, True]
Current timestep = 9604. State = [[-0.26332086  0.28321636]]. Action = [[ 0.06671437 -0.01600224  0.          0.31723404]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 9604 is [True, False, False, False, False, True]
Current timestep = 9605. State = [[-0.25970072  0.2858388 ]]. Action = [[0.02499209 0.05796104 0.         0.88538265]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 9605 is [True, False, False, False, False, True]
Current timestep = 9606. State = [[-0.2568197  0.284286 ]]. Action = [[ 0.02916432 -0.07352971  0.         -0.08222067]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 9606 is [True, False, False, False, False, True]
Current timestep = 9607. State = [[-0.25114903  0.28573504]]. Action = [[0.07931954 0.06328126 0.         0.9950404 ]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 9607 is [True, False, False, False, False, True]
Current timestep = 9608. State = [[-0.2478493   0.28452638]]. Action = [[-0.01022185 -0.0705758   0.          0.16472816]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 9608 is [True, False, False, False, False, True]
State prediction error at timestep 9608 is 0.012
Human Feedback received at timestep 9608 of None
Current timestep = 9609. State = [[-0.24409892  0.28619105]]. Action = [[ 0.05526152  0.06744697  0.         -0.61041343]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 9609 is [True, False, False, False, False, True]
Current timestep = 9610. State = [[-0.2439838  0.2898619]]. Action = [[-0.05476369  0.03034868  0.          0.8332751 ]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 9610 is [True, False, False, False, False, True]
State prediction error at timestep 9610 is 0.012
Human Feedback received at timestep 9610 of None
Current timestep = 9611. State = [[-0.24787243  0.2957847 ]]. Action = [[-0.06552151  0.08274847  0.         -0.93775547]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 9611 is [True, False, False, False, False, True]
State prediction error at timestep 9611 is 0.012
Human Feedback received at timestep 9611 of None
Current timestep = 9612. State = [[-0.25290516  0.29573786]]. Action = [[-0.07224906 -0.08089689  0.         -0.39428937]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 9612 is [True, False, False, False, False, True]
Current timestep = 9613. State = [[-0.25561696  0.29250163]]. Action = [[-0.01988395 -0.06029969  0.          0.03863132]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 9613 is [True, False, False, False, False, True]
State prediction error at timestep 9613 is 0.012
Human Feedback received at timestep 9613 of None
Current timestep = 9614. State = [[-0.25331572  0.2901565 ]]. Action = [[ 0.05427399 -0.0368096   0.          0.5481447 ]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 9614 is [True, False, False, False, False, True]
State prediction error at timestep 9614 is 0.012
Human Feedback received at timestep 9614 of None
Current timestep = 9615. State = [[-0.25347602  0.29431084]]. Action = [[-0.03647084  0.09793787  0.         -0.47362578]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 9615 is [True, False, False, False, False, True]
Current timestep = 9616. State = [[-0.25140545  0.2939827 ]]. Action = [[ 0.06666752 -0.06993376  0.          0.5068767 ]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 9616 is [True, False, False, False, False, True]
Current timestep = 9617. State = [[-0.25127494  0.2951818 ]]. Action = [[-0.03704047  0.05958366  0.          0.58369637]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 9617 is [True, False, False, False, False, True]
State prediction error at timestep 9617 is 0.012
Human Feedback received at timestep 9617 of None
Current timestep = 9618. State = [[-0.25034213  0.2943801 ]]. Action = [[ 0.0403633  -0.05354612  0.         -0.46449596]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 9618 is [True, False, False, False, False, True]
Current timestep = 9619. State = [[-0.25311098  0.29559457]]. Action = [[-0.0802564   0.05016803  0.          0.5766144 ]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 9619 is [True, False, False, False, False, True]
State prediction error at timestep 9619 is 0.012
Human Feedback received at timestep 9619 of None
Current timestep = 9620. State = [[-0.25269106  0.29564965]]. Action = [[ 0.05912372 -0.03309449  0.         -0.4794011 ]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 9620 is [True, False, False, False, False, True]
Current timestep = 9621. State = [[-0.24951352  0.2954353 ]]. Action = [[0.03390532 0.01545896 0.         0.95450354]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 9621 is [True, False, False, False, False, True]
Current timestep = 9622. State = [[-0.24704993  0.291162  ]]. Action = [[ 0.02337971 -0.09117058  0.          0.2741996 ]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 9622 is [True, False, False, False, False, True]
Current timestep = 9623. State = [[-0.24627283  0.28529844]]. Action = [[-0.01400828 -0.06624481  0.          0.22403288]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 9623 is [True, False, False, False, False, True]
Current timestep = 9624. State = [[-0.2501373   0.28561386]]. Action = [[-0.0845905   0.04861044  0.         -0.15896213]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 9624 is [True, False, False, False, False, True]
Current timestep = 9625. State = [[-0.25365517  0.28924444]]. Action = [[-0.02048469  0.04953258  0.         -0.6510025 ]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 9625 is [True, False, False, False, False, True]
Current timestep = 9626. State = [[-0.25776252  0.2941054 ]]. Action = [[-0.05554789  0.07250079  0.          0.9663594 ]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 9626 is [True, False, False, False, False, True]
State prediction error at timestep 9626 is 0.012
Human Feedback received at timestep 9626 of None
Current timestep = 9627. State = [[-0.2641391   0.29923928]]. Action = [[-0.07166458  0.05903434  0.         -0.70014304]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 9627 is [True, False, False, False, False, True]
State prediction error at timestep 9627 is 0.012
Human Feedback received at timestep 9627 of None
Current timestep = 9628. State = [[-0.26769543  0.29886115]]. Action = [[-1.4839321e-04 -5.3816516e-02  0.0000000e+00  4.9143624e-01]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 9628 is [True, False, False, False, False, True]
Current timestep = 9629. State = [[-0.2726739   0.30096954]]. Action = [[-0.07086034  0.06035531  0.         -0.649994  ]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 9629 is [True, False, False, False, False, True]
Current timestep = 9630. State = [[-0.27758783  0.30406106]]. Action = [[-0.02241262  0.0163242   0.         -0.06644452]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 9630 is [True, False, False, False, False, True]
Current timestep = 9631. State = [[-0.27960014  0.30191916]]. Action = [[ 0.00668851 -0.06936062  0.         -0.8048672 ]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 9631 is [True, False, False, False, False, True]
Current timestep = 9632. State = [[-0.27848536  0.30324185]]. Action = [[ 0.04687852  0.05968902  0.         -0.04300398]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 9632 is [True, False, False, False, False, True]
Current timestep = 9633. State = [[-0.27908674  0.3050696 ]]. Action = [[-0.01776633  0.00355674  0.          0.96113825]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 9633 is [True, False, False, False, False, True]
State prediction error at timestep 9633 is 0.012
Human Feedback received at timestep 9633 of None
Current timestep = 9634. State = [[-0.27554372  0.3035512 ]]. Action = [[ 0.09452026 -0.03630101  0.          0.34331822]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 9634 is [True, False, False, False, False, True]
State prediction error at timestep 9634 is 0.012
Human Feedback received at timestep 9634 of None
Current timestep = 9635. State = [[-0.26999328  0.29896188]]. Action = [[ 0.05744117 -0.06716204  0.          0.56174207]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 9635 is [True, False, False, False, False, True]
State prediction error at timestep 9635 is 0.012
Human Feedback received at timestep 9635 of None
Current timestep = 9636. State = [[-0.27014807  0.2988925 ]]. Action = [[-0.0503722   0.04483256  0.          0.8228978 ]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 9636 is [True, False, False, False, False, True]
Current timestep = 9637. State = [[-0.26687488  0.3028884 ]]. Action = [[ 0.08976532  0.06737181  0.         -0.3011402 ]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 9637 is [True, False, False, False, False, True]
Current timestep = 9638. State = [[-0.26655245  0.30043694]]. Action = [[-0.06517676 -0.09426304  0.         -0.748856  ]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 9638 is [True, False, False, False, False, True]
Current timestep = 9639. State = [[-0.26959687  0.29618824]]. Action = [[-0.03026222 -0.03089253  0.         -0.58067816]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 9639 is [True, False, False, False, False, True]
Current timestep = 9640. State = [[-0.27564284  0.2976364 ]]. Action = [[-0.09720413  0.05647983  0.         -0.4977454 ]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 9640 is [True, False, False, False, False, True]
Current timestep = 9641. State = [[-0.28343797  0.30376783]]. Action = [[-0.07886727  0.09823348  0.         -0.3639636 ]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 9641 is [True, False, False, False, False, True]
Current timestep = 9642. State = [[-0.28769577  0.3019388 ]]. Action = [[-0.00824788 -0.09725983  0.          0.73349285]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 9642 is [True, False, False, False, False, True]
Current timestep = 9643. State = [[-0.293894    0.30313936]]. Action = [[-0.09094837  0.07479332  0.          0.6908653 ]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 9643 is [True, False, False, False, False, True]
Current timestep = 9644. State = [[-0.3032506  0.3024742]]. Action = [[-0.09878146 -0.06472977  0.          0.8432137 ]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 9644 is [True, False, False, False, False, True]
State prediction error at timestep 9644 is 0.012
Human Feedback received at timestep 9644 of None
Current timestep = 9645. State = [[-0.31029147  0.3057906 ]]. Action = [[-0.03311666  0.09678128  0.          0.8892182 ]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 9645 is [True, False, False, False, False, True]
Current timestep = 9646. State = [[-0.31189847  0.30583736]]. Action = [[ 0.03504581 -0.05917583  0.          0.38060582]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 9646 is [True, False, False, False, False, True]
Current timestep = 9647. State = [[-0.31212786  0.30113128]]. Action = [[ 0.00676336 -0.07153714  0.          0.20520926]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 9647 is [True, False, False, False, False, True]
Current timestep = 9648. State = [[-0.31088635  0.29991713]]. Action = [[0.04180577 0.01647677 0.         0.45048904]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 9648 is [True, False, False, False, False, True]
Current timestep = 9649. State = [[-0.3066208   0.29626808]]. Action = [[ 0.07429936 -0.07254109  0.         -0.7655086 ]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 9649 is [True, False, False, False, False, True]
Current timestep = 9650. State = [[-0.30334035  0.29638234]]. Action = [[0.02312233 0.06043943 0.         0.1435548 ]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 9650 is [True, False, False, False, False, True]
Current timestep = 9651. State = [[-0.30423245  0.29499906]]. Action = [[-0.03604325 -0.04677448  0.         -0.18450576]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 9651 is [True, False, False, False, False, True]
Current timestep = 9652. State = [[-0.30289388  0.2966769 ]]. Action = [[ 0.04938968  0.07788246  0.         -0.48049235]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 9652 is [True, False, False, False, False, True]
State prediction error at timestep 9652 is 0.012
Human Feedback received at timestep 9652 of None
Current timestep = 9653. State = [[-0.30393782  0.2955648 ]]. Action = [[-0.05679356 -0.05781475  0.         -0.43280333]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 9653 is [True, False, False, False, False, True]
Current timestep = 9654. State = [[-0.30615237  0.29374605]]. Action = [[-0.01253182  0.00168099  0.         -0.9438841 ]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 9654 is [True, False, False, False, False, True]
Current timestep = 9655. State = [[-0.30782196  0.29556912]]. Action = [[-0.01866227  0.04894338  0.          0.38649845]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 9655 is [True, False, False, False, False, True]
State prediction error at timestep 9655 is 0.012
Human Feedback received at timestep 9655 of None
Current timestep = 9656. State = [[-0.3115452  0.2979649]]. Action = [[-0.05247618  0.02972775  0.         -0.34597588]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 9656 is [True, False, False, False, False, True]
Current timestep = 9657. State = [[-0.3171881   0.29602975]]. Action = [[-0.06893132 -0.06028889  0.         -0.7220103 ]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 9657 is [True, False, False, False, False, True]
Current timestep = 9658. State = [[-0.31685296  0.2906638 ]]. Action = [[ 0.06055201 -0.08314202  0.         -0.56220096]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 9658 is [True, False, False, False, False, True]
Current timestep = 9659. State = [[-0.3163775   0.28511167]]. Action = [[-0.01848526 -0.06311266  0.          0.6088538 ]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 9659 is [True, False, False, False, False, True]
State prediction error at timestep 9659 is 0.012
Human Feedback received at timestep 9659 of None
Current timestep = 9660. State = [[-0.32040185  0.27891332]]. Action = [[-0.07013388 -0.08970183  0.          0.94453025]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 9660 is [True, False, False, False, False, True]
Current timestep = 9661. State = [[-0.31997606  0.2769563 ]]. Action = [[0.05911443 0.02325382 0.         0.8073292 ]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 9661 is [True, False, False, False, False, True]
State prediction error at timestep 9661 is 0.012
Human Feedback received at timestep 9661 of None
Current timestep = 9662. State = [[-0.3229364   0.27896538]]. Action = [[-0.08885361  0.04239754  0.         -0.7648726 ]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 9662 is [True, False, False, False, False, True]
Current timestep = 9663. State = [[-0.3260949   0.27646786]]. Action = [[-0.00513626 -0.07104436  0.         -0.46100044]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 9663 is [True, False, False, False, False, True]
Current timestep = 9664. State = [[-0.32252055  0.27586046]]. Action = [[ 0.08853813  0.04318424  0.         -0.46845806]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 9664 is [True, False, False, False, False, True]
Current timestep = 9665. State = [[-0.32005638  0.2791189 ]]. Action = [[0.00356766 0.0675176  0.         0.65312743]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 9665 is [True, False, False, False, False, True]
Current timestep = 9666. State = [[-0.32346037  0.28064778]]. Action = [[-0.06848437  0.00490829  0.          0.4364164 ]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 9666 is [True, False, False, False, False, True]
State prediction error at timestep 9666 is 0.012
Human Feedback received at timestep 9666 of None
Current timestep = 9667. State = [[-0.32194912  0.28428596]]. Action = [[0.08374148 0.08311828 0.         0.614557  ]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 9667 is [True, False, False, False, False, True]
Current timestep = 9668. State = [[-0.31510234  0.28493568]]. Action = [[ 0.09481206 -0.01916402  0.         -0.00608557]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 9668 is [True, False, False, False, False, True]
Current timestep = 9669. State = [[-0.31191155  0.28046823]]. Action = [[-0.0058061  -0.07808181  0.         -0.8778869 ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 9669 is [True, False, False, False, False, True]
Current timestep = 9670. State = [[-0.31346688  0.28045556]]. Action = [[-0.04515458  0.04119127  0.          0.01171756]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 9670 is [True, False, False, False, False, True]
Current timestep = 9671. State = [[-0.31573796  0.28134894]]. Action = [[-0.0269043  -0.00926284  0.         -0.12866908]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 9671 is [True, False, False, False, False, True]
Current timestep = 9672. State = [[-0.31351182  0.28575933]]. Action = [[0.06107982 0.09466288 0.         0.29594588]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 9672 is [True, False, False, False, False, True]
Current timestep = 9673. State = [[-0.30817693  0.29127672]]. Action = [[ 0.06899375  0.0647926   0.         -0.08795506]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 9673 is [True, False, False, False, False, True]
Current timestep = 9674. State = [[-0.30955893  0.28943002]]. Action = [[-0.0915414  -0.09688374  0.          0.76895845]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 9674 is [True, False, False, False, False, True]
Current timestep = 9675. State = [[-0.31204596  0.2866081 ]]. Action = [[ 0.00091847 -0.01405919  0.         -0.1503734 ]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 9675 is [True, False, False, False, False, True]
Current timestep = 9676. State = [[-0.31163502  0.28171116]]. Action = [[ 0.01250415 -0.09227259  0.         -0.00300884]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 9676 is [True, False, False, False, False, True]
Current timestep = 9677. State = [[-0.31134674  0.27833033]]. Action = [[-0.00473254 -0.01626475  0.          0.41948438]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 9677 is [True, False, False, False, False, True]
Current timestep = 9678. State = [[-0.31140208  0.27827263]]. Action = [[-0.00066148  0.01621242  0.         -0.5567301 ]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 9678 is [True, False, False, False, False, True]
Current timestep = 9679. State = [[-0.31192777  0.27578872]]. Action = [[-0.0114052  -0.05228079  0.          0.05335414]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 9679 is [True, False, False, False, False, True]
Current timestep = 9680. State = [[-0.31547228  0.27633196]]. Action = [[-0.06454549  0.04560117  0.          0.5450835 ]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 9680 is [True, False, False, False, False, True]
Current timestep = 9681. State = [[-0.32237825  0.28045908]]. Action = [[-0.08910475  0.06238731  0.         -0.29561794]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 9681 is [True, False, False, False, False, True]
Current timestep = 9682. State = [[-0.32994756  0.28198957]]. Action = [[-0.07543699 -0.00876834  0.         -0.25241625]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 9682 is [True, False, False, False, False, True]
Current timestep = 9683. State = [[-0.33659694  0.2842943 ]]. Action = [[-0.05619607  0.0434394   0.          0.9833386 ]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 9683 is [True, False, False, False, False, True]
State prediction error at timestep 9683 is 0.012
Human Feedback received at timestep 9683 of None
Current timestep = 9684. State = [[-0.3389434  0.287435 ]]. Action = [[ 0.02669402  0.03772149  0.         -0.43664455]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 9684 is [True, False, False, False, False, True]
Current timestep = 9685. State = [[-0.34155694  0.2851267 ]]. Action = [[-0.03251424 -0.0725056   0.          0.40852404]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 9685 is [True, False, False, False, False, True]
Current timestep = 9686. State = [[-0.34910038  0.28492588]]. Action = [[-0.0999045   0.03066366  0.          0.33852434]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 9686 is [True, False, False, False, False, True]
Current timestep = 9687. State = [[-0.35269845  0.28548437]]. Action = [[ 0.02682649 -0.0089437   0.         -0.5241641 ]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 9687 is [True, False, False, False, False, True]
Current timestep = 9688. State = [[-0.35868558  0.28561452]]. Action = [[-0.09608906  0.00556344  0.         -0.6006668 ]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 9688 is [True, False, False, False, False, True]
Current timestep = 9689. State = [[-0.36304656  0.28871483]]. Action = [[ 0.00797166  0.0580722   0.         -0.6132043 ]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 9689 is [True, False, False, False, False, True]
Current timestep = 9690. State = [[-0.3692226   0.29274586]]. Action = [[-0.08467452  0.05065123  0.         -0.94291824]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 9690 is [True, False, False, False, False, True]
Current timestep = 9691. State = [[-0.36960202  0.29219368]]. Action = [[ 0.08194866 -0.0439285   0.          0.75233567]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 9691 is [True, False, False, False, False, True]
Current timestep = 9692. State = [[-0.36619964  0.28674066]]. Action = [[ 0.04713582 -0.08566488  0.         -0.6962108 ]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 9692 is [True, False, False, False, False, True]
Current timestep = 9693. State = [[-0.36822358  0.2830738 ]]. Action = [[-0.06007751 -0.026021    0.          0.62701154]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 9693 is [True, False, False, False, False, True]
Current timestep = 9694. State = [[-0.37031808  0.28408974]]. Action = [[0.0038265  0.03627782 0.         0.5230801 ]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 9694 is [True, False, False, False, False, True]
Current timestep = 9695. State = [[-0.3688167   0.28337783]]. Action = [[ 0.03967194 -0.02892258  0.          0.03216243]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 9695 is [True, False, False, False, False, True]
Current timestep = 9696. State = [[-0.36548054  0.2797389 ]]. Action = [[ 0.04423919 -0.05049019  0.         -0.6488366 ]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 9696 is [True, False, False, False, False, True]
State prediction error at timestep 9696 is 0.012
Human Feedback received at timestep 9696 of None
Current timestep = 9697. State = [[-0.36180946  0.2775674 ]]. Action = [[ 0.03896809 -0.00279315  0.         -0.44599342]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 9697 is [True, False, False, False, False, True]
Current timestep = 9698. State = [[-0.36397323  0.27376676]]. Action = [[-0.08094941 -0.06797732  0.          0.53402734]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 9698 is [True, False, False, False, False, True]
Current timestep = 9699. State = [[-0.36984196  0.27612105]]. Action = [[-0.07491559  0.0923663   0.         -0.05414695]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 9699 is [True, False, False, False, False, True]
Current timestep = 9700. State = [[-0.37253365  0.2782356 ]]. Action = [[ 0.          0.          0.         -0.50613415]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 9700 is [True, False, False, False, False, True]
Current timestep = 9701. State = [[-0.37306544  0.277964  ]]. Action = [[ 0.         0.         0.        -0.5988701]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 9701 is [True, False, False, False, False, True]
Current timestep = 9702. State = [[-0.37347278  0.27759114]]. Action = [[ 0.          0.          0.         -0.99238396]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 9702 is [True, False, False, False, False, True]
Current timestep = 9703. State = [[-0.37573972  0.27729842]]. Action = [[-3.7235893e-02 -4.4181198e-04  0.0000000e+00 -7.1148902e-01]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 9703 is [True, False, False, False, False, True]
State prediction error at timestep 9703 is 0.012
Human Feedback received at timestep 9703 of None
Current timestep = 9704. State = [[-0.37735456  0.27715302]]. Action = [[ 0.         0.         0.        -0.0926497]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 9704 is [True, False, False, False, False, True]
State prediction error at timestep 9704 is 0.012
Human Feedback received at timestep 9704 of None
Current timestep = 9705. State = [[-0.377933    0.27699563]]. Action = [[0.        0.        0.        0.6588453]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 9705 is [True, False, False, False, False, True]
Current timestep = 9706. State = [[-0.37838542  0.2768506 ]]. Action = [[0.         0.         0.         0.16881156]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 9706 is [True, False, False, False, False, True]
Current timestep = 9707. State = [[-0.37379843  0.27543768]]. Action = [[ 0.09766958 -0.02189714  0.         -0.76708174]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 9707 is [True, False, False, False, False, True]
State prediction error at timestep 9707 is 0.012
Human Feedback received at timestep 9707 of None
Current timestep = 9708. State = [[-0.37079886  0.2742504 ]]. Action = [[0.         0.         0.         0.16366136]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 9708 is [True, False, False, False, False, True]
Current timestep = 9709. State = [[-0.37037718  0.27391264]]. Action = [[0.        0.        0.        0.8038207]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 9709 is [True, False, False, False, False, True]
Current timestep = 9710. State = [[-0.37010357  0.27369916]]. Action = [[0.         0.         0.         0.84941816]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 9710 is [True, False, False, False, False, True]
Current timestep = 9711. State = [[-0.3689877  0.2726263]]. Action = [[ 0.0164188  -0.01779941  0.          0.9508071 ]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 9711 is [True, False, False, False, False, True]
State prediction error at timestep 9711 is 0.012
Human Feedback received at timestep 9711 of None
Current timestep = 9712. State = [[-0.36729294  0.27293384]]. Action = [[0.0174582  0.02237131 0.         0.6837195 ]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 9712 is [True, False, False, False, False, True]
Current timestep = 9713. State = [[-0.36447766  0.2774227 ]]. Action = [[0.04049861 0.09094318 0.         0.45494115]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 9713 is [True, False, False, False, False, True]
Current timestep = 9714. State = [[-0.3625132  0.2783985]]. Action = [[ 0.00894451 -0.02296326  0.          0.95052385]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 9714 is [True, False, False, False, False, True]
Current timestep = 9715. State = [[-0.35865203  0.27817717]]. Action = [[0.06236251 0.01037626 0.         0.97071934]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 9715 is [True, False, False, False, False, True]
Current timestep = 9716. State = [[-0.353645    0.27634323]]. Action = [[ 0.04950615 -0.03746691  0.          0.9729142 ]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 9716 is [True, False, False, False, False, True]
Current timestep = 9717. State = [[-0.3503349  0.2786831]]. Action = [[0.01692352 0.07316478 0.         0.5208173 ]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 9717 is [True, False, False, False, False, True]
Current timestep = 9718. State = [[-0.34396684  0.28095013]]. Action = [[0.09757828 0.01188539 0.         0.22319925]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 9718 is [True, False, False, False, False, True]
State prediction error at timestep 9718 is 0.012
Human Feedback received at timestep 9718 of None
Current timestep = 9719. State = [[-0.3393172   0.28091246]]. Action = [[ 0.0101677  -0.0047273   0.         -0.98106545]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 9719 is [True, False, False, False, False, True]
State prediction error at timestep 9719 is 0.012
Human Feedback received at timestep 9719 of None
Current timestep = 9720. State = [[-0.3405199   0.28180954]]. Action = [[-0.06038094  0.01351674  0.         -0.01518303]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 9720 is [True, False, False, False, False, True]
Current timestep = 9721. State = [[-0.34524205  0.2824282 ]]. Action = [[-0.08137433 -0.01486761  0.         -0.7031185 ]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 9721 is [True, False, False, False, False, True]
Current timestep = 9722. State = [[-0.3512692  0.2824498]]. Action = [[-0.08366297 -0.01951427  0.         -0.83811253]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 9722 is [True, False, False, False, False, True]
State prediction error at timestep 9722 is 0.012
Human Feedback received at timestep 9722 of None
Current timestep = 9723. State = [[-0.3522798   0.27979815]]. Action = [[ 0.0275657  -0.0697482   0.          0.98156786]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 9723 is [True, False, False, False, False, True]
Current timestep = 9724. State = [[-0.35106093  0.280234  ]]. Action = [[0.00893591 0.03431874 0.         0.9484236 ]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 9724 is [True, False, False, False, False, True]
State prediction error at timestep 9724 is 0.012
Human Feedback received at timestep 9724 of None
Current timestep = 9725. State = [[-0.35544083  0.2822646 ]]. Action = [[-0.09041155  0.01413764  0.         -0.1693114 ]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 9725 is [True, False, False, False, False, True]
State prediction error at timestep 9725 is 0.012
Human Feedback received at timestep 9725 of None
Current timestep = 9726. State = [[-0.36015546  0.28138945]]. Action = [[-0.03152931 -0.04202135  0.          0.81086326]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 9726 is [True, False, False, False, False, True]
Current timestep = 9727. State = [[-0.3588049   0.28232235]]. Action = [[0.06398264 0.03758258 0.         0.60078955]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 9727 is [True, False, False, False, False, True]
Current timestep = 9728. State = [[-0.35834697  0.28478515]]. Action = [[-0.01469862  0.03399082  0.         -0.7003953 ]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 9728 is [True, False, False, False, False, True]
Current timestep = 9729. State = [[-0.36064833  0.28685737]]. Action = [[-0.02737869  0.02199093  0.          0.6650839 ]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 9729 is [True, False, False, False, False, True]
Current timestep = 9730. State = [[-0.35879475  0.2897216 ]]. Action = [[0.06749021 0.04687949 0.         0.74015594]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 9730 is [True, False, False, False, False, True]
Current timestep = 9731. State = [[-0.3546168   0.28811795]]. Action = [[ 0.05222815 -0.05324481  0.         -0.85156965]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 9731 is [True, False, False, False, False, True]
Current timestep = 9732. State = [[-0.35003722  0.28869694]]. Action = [[0.05718888 0.04714281 0.         0.5391426 ]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 9732 is [True, False, False, False, False, True]
State prediction error at timestep 9732 is 0.012
Human Feedback received at timestep 9732 of None
Current timestep = 9733. State = [[-0.34321898  0.29360026]]. Action = [[0.09562948 0.08881032 0.         0.7876992 ]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 9733 is [True, False, False, False, False, True]
Current timestep = 9734. State = [[-0.3426928   0.30028456]]. Action = [[-0.05792189  0.09766512  0.         -0.55951375]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 9734 is [True, False, False, False, False, True]
Current timestep = 9735. State = [[-0.34361368  0.30705577]]. Action = [[0.00600654 0.07799225 0.         0.37774336]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 9735 is [True, False, False, False, False, True]
Current timestep = 9736. State = [[-0.3453157   0.31134197]]. Action = [[-0.03972101  0.02834772  0.         -0.11641365]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 9736 is [True, False, False, False, False, True]
Current timestep = 9737. State = [[-0.34378785  0.3132067 ]]. Action = [[ 0.0502372  -0.00378297  0.          0.43159413]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 9737 is [True, False, False, False, False, True]
Current timestep = 9738. State = [[-0.34546766  0.3147644 ]]. Action = [[-0.06862526  0.0034088   0.          0.86750436]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 9738 is [True, False, False, False, False, True]
Current timestep = 9739. State = [[-0.35064915  0.31458986]]. Action = [[-0.06967197 -0.04928086  0.         -0.5802315 ]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 9739 is [True, False, False, False, False, True]
Current timestep = 9740. State = [[-0.35066652  0.31603286]]. Action = [[0.04355367 0.01632749 0.         0.15310538]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 9740 is [True, False, False, False, False, True]
Current timestep = 9741. State = [[-0.34854233  0.31970358]]. Action = [[ 0.01823697  0.03681924  0.         -0.3073467 ]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 9741 is [True, False, False, False, False, True]
State prediction error at timestep 9741 is 0.012
Human Feedback received at timestep 9741 of None
Current timestep = 9742. State = [[-0.351985    0.32434735]]. Action = [[-0.08073428  0.04552747  0.         -0.56814665]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 9742 is [True, False, False, False, False, True]
State prediction error at timestep 9742 is 0.012
Human Feedback received at timestep 9742 of None
Current timestep = 9743. State = [[-0.35575268  0.32807243]]. Action = [[-0.02041674  0.01758264  0.         -0.44152272]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 9743 is [True, False, False, False, False, True]
Current timestep = 9744. State = [[-0.36190414  0.3267992 ]]. Action = [[-0.09955081 -0.0753617   0.          0.02335417]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 9744 is [True, False, False, False, False, True]
Current timestep = 9745. State = [[-0.3628939   0.33012095]]. Action = [[0.06359725 0.09292639 0.         0.5870782 ]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 9745 is [True, False, False, False, False, True]
State prediction error at timestep 9745 is 0.012
Human Feedback received at timestep 9745 of None
Current timestep = 9746. State = [[-0.36204442  0.33233216]]. Action = [[-0.01136282 -0.03718558  0.          0.10146964]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 9746 is [True, False, False, False, False, True]
Current timestep = 9747. State = [[-0.3660202   0.33228576]]. Action = [[-0.0725491  -0.0189077   0.         -0.74344563]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 9747 is [True, False, False, False, False, True]
Current timestep = 9748. State = [[-0.3684813   0.32942143]]. Action = [[-0.00146385 -0.08529393  0.          0.90022373]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 9748 is [True, False, False, False, False, True]
Current timestep = 9749. State = [[-0.3641072   0.33149943]]. Action = [[ 0.09991354  0.08012833  0.         -0.19629347]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 9749 is [True, False, False, False, False, True]
Current timestep = 9750. State = [[-0.3560795  0.3364333]]. Action = [[0.09550386 0.05250064 0.         0.1078018 ]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 9750 is [True, False, False, False, False, True]
Current timestep = 9751. State = [[-0.35510114  0.34079733]]. Action = [[-0.05616268  0.05120648  0.          0.24473548]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 9751 is [True, False, False, False, False, True]
Current timestep = 9752. State = [[-0.35928258  0.33904853]]. Action = [[-0.06960437 -0.09433616  0.          0.3864975 ]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 9752 is [True, False, False, False, False, True]
State prediction error at timestep 9752 is 0.012
Human Feedback received at timestep 9752 of None
Current timestep = 9753. State = [[-0.3632194   0.33856103]]. Action = [[-0.04293475  0.01385213  0.          0.8921733 ]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 9753 is [True, False, False, False, False, True]
Current timestep = 9754. State = [[-0.36223593  0.3414422 ]]. Action = [[0.04909883 0.0385853  0.         0.98692274]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 9754 is [True, False, False, False, False, True]
Current timestep = 9755. State = [[-0.3569246   0.34228563]]. Action = [[ 0.07896606 -0.00599667  0.          0.957991  ]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 9755 is [True, False, False, False, False, True]
Current timestep = 9756. State = [[-0.35414216  0.34210995]]. Action = [[0.         0.         0.         0.27924883]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 9756 is [True, False, False, False, False, True]
Current timestep = 9757. State = [[-0.35106313  0.33938465]]. Action = [[ 0.04794026 -0.05768126  0.         -0.1122058 ]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 9757 is [True, False, False, False, False, True]
Current timestep = 9758. State = [[-0.34747812  0.33976203]]. Action = [[ 0.02779085  0.04269933  0.         -0.04235077]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 9758 is [True, False, False, False, False, True]
Current timestep = 9759. State = [[-0.34714568  0.34157825]]. Action = [[-0.02601537  0.02041718  0.         -0.26170456]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 9759 is [True, False, False, False, False, True]
Current timestep = 9760. State = [[-0.34903583  0.3440795 ]]. Action = [[-0.03328031  0.03943371  0.          0.3490572 ]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 9760 is [True, False, False, False, False, True]
Current timestep = 9761. State = [[-0.34987205  0.34525672]]. Action = [[0.        0.        0.        0.7530546]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 9761 is [True, False, False, False, False, True]
State prediction error at timestep 9761 is 0.012
Human Feedback received at timestep 9761 of None
Current timestep = 9762. State = [[-0.3498125   0.34542018]]. Action = [[0.        0.        0.        0.2868322]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 9762 is [True, False, False, False, False, True]
Current timestep = 9763. State = [[-0.34975347  0.34557486]]. Action = [[0.        0.        0.        0.5760865]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 9763 is [True, False, False, False, False, True]
Current timestep = 9764. State = [[-0.3464477   0.34194458]]. Action = [[ 0.06279882 -0.07732738  0.          0.8143251 ]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 9764 is [True, False, False, False, False, True]
Current timestep = 9765. State = [[-0.34523374  0.34100908]]. Action = [[-0.02238624  0.02431376  0.          0.9471674 ]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 9765 is [True, False, False, False, False, True]
Current timestep = 9766. State = [[-0.3442551  0.3435928]]. Action = [[ 0.02545061  0.04377551  0.         -0.6571621 ]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 9766 is [True, False, False, False, False, True]
Current timestep = 9767. State = [[-0.3409638   0.34580293]]. Action = [[ 0.04766984  0.02754111  0.         -0.9195884 ]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 9767 is [True, False, False, False, False, True]
Current timestep = 9768. State = [[-0.33917177  0.3463179 ]]. Action = [[ 0.         0.         0.        -0.8603207]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 9768 is [True, False, False, False, False, True]
State prediction error at timestep 9768 is 0.012
Human Feedback received at timestep 9768 of None
Current timestep = 9769. State = [[-0.3413799  0.3442146]]. Action = [[-0.05482262 -0.04780213  0.          0.7919071 ]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 9769 is [True, False, False, False, False, True]
Current timestep = 9770. State = [[-0.34472838  0.3427618 ]]. Action = [[-0.04125012 -0.01578325  0.         -0.6132037 ]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 9770 is [True, False, False, False, False, True]
State prediction error at timestep 9770 is 0.012
Human Feedback received at timestep 9770 of None
Current timestep = 9771. State = [[-0.347022   0.3438199]]. Action = [[-0.01951406  0.02172513  0.         -0.22744757]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 9771 is [True, False, False, False, False, True]
Current timestep = 9772. State = [[-0.3456955  0.3456007]]. Action = [[0.04459926 0.02160309 0.         0.8661747 ]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 9772 is [True, False, False, False, False, True]
Current timestep = 9773. State = [[-0.34690452  0.34328002]]. Action = [[-0.04871104 -0.06495377  0.          0.97596383]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 9773 is [True, False, False, False, False, True]
Current timestep = 9774. State = [[-0.34844068  0.34176573]]. Action = [[ 0.         0.         0.        -0.5732653]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 9774 is [True, False, False, False, False, True]
Current timestep = 9775. State = [[-0.34457216  0.33798793]]. Action = [[ 0.08152571 -0.07300238  0.         -0.7665682 ]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 9775 is [True, False, False, False, False, True]
Current timestep = 9776. State = [[-0.3418615   0.33553705]]. Action = [[0.         0.         0.         0.17023087]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 9776 is [True, False, False, False, False, True]
Current timestep = 9777. State = [[-0.33946356  0.3333515 ]]. Action = [[ 0.03661    -0.03225186  0.          0.95339656]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 9777 is [True, False, False, False, False, True]
State prediction error at timestep 9777 is 0.012
Human Feedback received at timestep 9777 of None
Current timestep = 9778. State = [[-0.34265757  0.333139  ]]. Action = [[-0.09596276  0.02472146  0.         -0.51261204]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 9778 is [True, False, False, False, False, True]
Current timestep = 9779. State = [[-0.34946325  0.33635324]]. Action = [[-0.07886823  0.05588695  0.          0.38772547]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 9779 is [True, False, False, False, False, True]
Current timestep = 9780. State = [[-0.35238793  0.33481368]]. Action = [[ 0.00342091 -0.06249031  0.          0.8158703 ]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 9780 is [True, False, False, False, False, True]
Current timestep = 9781. State = [[-0.34960178  0.331294  ]]. Action = [[ 0.06604817 -0.03385588  0.          0.80772686]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 9781 is [True, False, False, False, False, True]
State prediction error at timestep 9781 is 0.012
Human Feedback received at timestep 9781 of None
Current timestep = 9782. State = [[-0.3470117   0.33080098]]. Action = [[ 0.01716091  0.0240677   0.         -0.7201383 ]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 9782 is [True, False, False, False, False, True]
State prediction error at timestep 9782 is 0.012
Human Feedback received at timestep 9782 of None
Current timestep = 9783. State = [[-0.35052463  0.3345306 ]]. Action = [[-0.07668792  0.07798658  0.          0.5940647 ]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 9783 is [True, False, False, False, False, True]
Current timestep = 9784. State = [[-0.35630202  0.33496898]]. Action = [[-0.05767145 -0.0310357   0.         -0.0108763 ]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 9784 is [True, False, False, False, False, True]
Current timestep = 9785. State = [[-0.36311176  0.33056965]]. Action = [[-0.08437501 -0.08263086  0.         -0.20945144]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 9785 is [True, False, False, False, False, True]
Current timestep = 9786. State = [[-0.36917487  0.32894474]]. Action = [[-0.04877666  0.00357606  0.         -0.9450018 ]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 9786 is [True, False, False, False, False, True]
State prediction error at timestep 9786 is 0.012
Human Feedback received at timestep 9786 of None
Current timestep = 9787. State = [[-0.37248296  0.32490343]]. Action = [[-0.00914919 -0.08742638  0.          0.04048324]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 9787 is [True, False, False, False, False, True]
Current timestep = 9788. State = [[-0.37419224  0.3194251 ]]. Action = [[-0.00579423 -0.06461123  0.          0.1499753 ]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 9788 is [True, False, False, False, False, True]
Current timestep = 9789. State = [[-0.37532946  0.31716752]]. Action = [[0.        0.        0.        0.7382083]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 9789 is [True, False, False, False, False, True]
Current timestep = 9790. State = [[-0.37433463  0.31901404]]. Action = [[ 0.04035487  0.06236085  0.         -0.7033254 ]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 9790 is [True, False, False, False, False, True]
State prediction error at timestep 9790 is 0.012
Human Feedback received at timestep 9790 of None
Current timestep = 9791. State = [[-0.37290674  0.31863418]]. Action = [[ 0.02214558 -0.01275468  0.          0.8037317 ]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 9791 is [True, False, False, False, False, True]
Current timestep = 9792. State = [[-0.37273854  0.31715405]]. Action = [[ 0.          0.          0.         -0.85836816]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 9792 is [True, False, False, False, False, True]
Current timestep = 9793. State = [[-0.11462877 -0.12158145]]. Action = [[ 0.          0.          0.         -0.56864417]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 9793 is [True, False, False, False, False, True]
Current timestep = 9794. State = [[-0.11552102 -0.11591484]]. Action = [[-0.03576551  0.04672528  0.         -0.9237661 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 9794 is [True, False, False, False, True, False]
State prediction error at timestep 9794 is 0.012
Human Feedback received at timestep 9794 of None
Current timestep = 9795. State = [[-0.1158448  -0.11486185]]. Action = [[ 0.0433447  -0.02110171  0.          0.57633424]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 9795 is [True, False, False, False, True, False]
State prediction error at timestep 9795 is 0.012
Human Feedback received at timestep 9795 of None
Current timestep = 9796. State = [[-0.12004199 -0.11133322]]. Action = [[-0.0888873   0.07109775  0.         -0.66198236]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 9796 is [True, False, False, False, True, False]
State prediction error at timestep 9796 is 0.012
Human Feedback received at timestep 9796 of None
Current timestep = 9797. State = [[-0.12829442 -0.10491196]]. Action = [[-0.08883249  0.06908115  0.          0.10905313]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 9797 is [True, False, False, False, True, False]
Current timestep = 9798. State = [[-0.13593908 -0.10292891]]. Action = [[-0.07103381 -0.02823227  0.         -0.53105396]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 9798 is [True, False, False, False, True, False]
Current timestep = 9799. State = [[-0.13958943 -0.10135806]]. Action = [[ 0.00122584  0.02010379  0.         -0.02994275]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 9799 is [True, False, False, False, True, False]
State prediction error at timestep 9799 is 0.012
Human Feedback received at timestep 9799 of None
Current timestep = 9800. State = [[-0.14568429 -0.10245603]]. Action = [[-0.09088024 -0.05645712  0.          0.7307849 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 9800 is [True, False, False, False, True, False]
Current timestep = 9801. State = [[-0.14853887 -0.1010958 ]]. Action = [[ 0.02502998  0.04334902  0.         -0.04273063]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 9801 is [True, False, False, False, True, False]
Current timestep = 9802. State = [[-0.14606425 -0.10258489]]. Action = [[ 0.07440986 -0.07068624  0.          0.98079896]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 9802 is [True, False, False, False, True, False]
Current timestep = 9803. State = [[-0.14373623 -0.10334285]]. Action = [[0.03529539 0.0159436  0.         0.00937116]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9803 is [True, False, False, False, True, False]
Current timestep = 9804. State = [[-0.14050823 -0.10124063]]. Action = [[0.06950278 0.02996328 0.         0.39610827]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 9804 is [True, False, False, False, True, False]
Current timestep = 9805. State = [[-0.1434619  -0.10260032]]. Action = [[-0.08717161 -0.04588946  0.         -0.81006694]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 9805 is [True, False, False, False, True, False]
State prediction error at timestep 9805 is 0.012
Human Feedback received at timestep 9805 of None
Current timestep = 9806. State = [[-0.14628465 -0.10284699]]. Action = [[0.00667761 0.02351394 0.         0.05470848]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 9806 is [True, False, False, False, True, False]
Current timestep = 9807. State = [[-0.14841428 -0.09895224]]. Action = [[-0.0264185   0.06596031  0.         -0.9640804 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 9807 is [True, False, False, False, True, False]
Current timestep = 9808. State = [[-0.15325907 -0.09796052]]. Action = [[-0.0685408  -0.02341086  0.          0.7081094 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 9808 is [True, False, False, False, True, False]
State prediction error at timestep 9808 is 0.012
Human Feedback received at timestep 9808 of None
Current timestep = 9809. State = [[-0.15292986 -0.09967133]]. Action = [[ 0.06338894 -0.02705389  0.          0.24968398]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 9809 is [True, False, False, False, True, False]
State prediction error at timestep 9809 is 0.012
Human Feedback received at timestep 9809 of None
Current timestep = 9810. State = [[-0.1511144  -0.09556396]]. Action = [[ 0.01431926  0.09494477  0.         -0.4787171 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 9810 is [True, False, False, False, True, False]
Current timestep = 9811. State = [[-0.1524595  -0.08823961]]. Action = [[-0.02587316  0.08154007  0.          0.8117049 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 9811 is [True, False, False, False, True, False]
State prediction error at timestep 9811 is 0.012
Human Feedback received at timestep 9811 of None
Current timestep = 9812. State = [[-0.1563179  -0.08265544]]. Action = [[-0.05347517  0.04314227  0.         -0.48518157]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 9812 is [True, False, False, False, True, False]
State prediction error at timestep 9812 is 0.012
Human Feedback received at timestep 9812 of None
Current timestep = 9813. State = [[-0.15809014 -0.07894051]]. Action = [[ 0.00621004  0.02296748  0.         -0.42880952]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 9813 is [True, False, False, False, True, False]
State prediction error at timestep 9813 is 0.012
Human Feedback received at timestep 9813 of None
Current timestep = 9814. State = [[-0.16289309 -0.07285775]]. Action = [[-0.09007695  0.07996365  0.         -0.25923765]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 9814 is [True, False, False, False, True, False]
Current timestep = 9815. State = [[-0.16864164 -0.07007927]]. Action = [[-0.05269822 -0.02321334  0.          0.5437343 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 9815 is [True, False, False, False, True, False]
Current timestep = 9816. State = [[-0.17141941 -0.0720652 ]]. Action = [[-0.00998762 -0.05747597  0.         -0.371001  ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 9816 is [True, False, False, False, True, False]
Current timestep = 9817. State = [[-0.16851558 -0.07483801]]. Action = [[ 0.08390077 -0.04192158  0.         -0.56021625]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 9817 is [True, False, False, False, True, False]
State prediction error at timestep 9817 is 0.012
Human Feedback received at timestep 9817 of None
Current timestep = 9818. State = [[-0.16964589 -0.07098823]]. Action = [[-0.06324442  0.09224286  0.         -0.8716636 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 9818 is [True, False, False, False, True, False]
State prediction error at timestep 9818 is 0.012
Human Feedback received at timestep 9818 of None
Current timestep = 9819. State = [[-0.17482877 -0.07016442]]. Action = [[-0.04933942 -0.05026614  0.          0.7250103 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 9819 is [True, False, False, False, True, False]
Current timestep = 9820. State = [[-0.18073064 -0.06922427]]. Action = [[-0.06823334  0.03588449  0.         -0.51506495]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 9820 is [True, False, False, False, True, False]
Current timestep = 9821. State = [[-0.18107183 -0.06836447]]. Action = [[ 0.06355805 -0.01258463  0.          0.5471126 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 9821 is [True, False, False, False, True, False]
Current timestep = 9822. State = [[-0.177276   -0.06550451]]. Action = [[0.06798457 0.05425965 0.         0.30995798]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 9822 is [True, False, False, False, True, False]
Current timestep = 9823. State = [[-0.17958543 -0.06276959]]. Action = [[-0.0715777   0.01469668  0.          0.9443121 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 9823 is [True, False, False, False, True, False]
Current timestep = 9824. State = [[-0.18537365 -0.0582395 ]]. Action = [[-0.05825195  0.07075881  0.          0.3095069 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 9824 is [True, False, False, False, True, False]
Current timestep = 9825. State = [[-0.19006222 -0.05540986]]. Action = [[-3.618712e-02  3.223121e-05  0.000000e+00  9.064014e-01]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 9825 is [True, False, False, False, True, False]
Current timestep = 9826. State = [[-0.19385776 -0.05133338]]. Action = [[-0.02979043  0.06205941  0.         -0.41913998]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 9826 is [True, False, False, False, True, False]
Current timestep = 9827. State = [[-0.19966756 -0.05107729]]. Action = [[-0.07601072 -0.0509055   0.          0.17394817]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 9827 is [True, False, False, False, True, False]
Current timestep = 9828. State = [[-0.20634538 -0.05586094]]. Action = [[-0.07244691 -0.08124799  0.          0.11226618]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 9828 is [True, False, False, False, True, False]
Current timestep = 9829. State = [[-0.20804457 -0.05768287]]. Action = [[ 0.0302664   0.00759305  0.         -0.8514126 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 9829 is [True, False, False, False, True, False]
Current timestep = 9830. State = [[-0.20657729 -0.05379128]]. Action = [[0.04133236 0.07077699 0.         0.4560398 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 9830 is [True, False, False, False, True, False]
State prediction error at timestep 9830 is 0.012
Human Feedback received at timestep 9830 of None
Current timestep = 9831. State = [[-0.21002264 -0.04806278]]. Action = [[-0.06772022  0.06441132  0.         -0.09271353]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 9831 is [True, False, False, False, True, False]
Current timestep = 9832. State = [[-0.21348152 -0.04069623]]. Action = [[ 5.9503317e-04  9.3412511e-02  0.0000000e+00 -7.1919930e-01]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 9832 is [True, False, False, False, True, False]
Current timestep = 9833. State = [[-0.21348819 -0.03598189]]. Action = [[ 0.03906908  0.01509057  0.         -0.9778994 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 9833 is [True, False, False, False, True, False]
State prediction error at timestep 9833 is 0.012
Human Feedback received at timestep 9833 of None
Current timestep = 9834. State = [[-0.21788722 -0.02942189]]. Action = [[-0.08100615  0.09553399  0.         -0.70451117]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 9834 is [True, False, False, False, True, False]
Current timestep = 9835. State = [[-0.22195053 -0.0291238 ]]. Action = [[-0.00111643 -0.07828877  0.          0.53637505]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 9835 is [True, False, False, False, True, False]
Current timestep = 9836. State = [[-0.2275288 -0.0299001]]. Action = [[-0.08294642  0.00509982  0.          0.6180563 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 9836 is [True, False, False, False, True, False]
Current timestep = 9837. State = [[-0.2311431  -0.02889688]]. Action = [[8.0738217e-04 9.7348541e-04 0.0000000e+00 9.8588920e-01]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 9837 is [True, False, False, False, True, False]
Current timestep = 9838. State = [[-0.23081984 -0.03173875]]. Action = [[ 0.03428657 -0.07156721  0.         -0.3160622 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 9838 is [True, False, False, False, True, False]
Current timestep = 9839. State = [[-0.23388799 -0.03117758]]. Action = [[-0.06419237  0.04773805  0.         -0.86817324]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 9839 is [True, False, False, False, True, False]
Current timestep = 9840. State = [[-0.23618063 -0.02456765]]. Action = [[ 0.01456621  0.09965044  0.         -0.5032633 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 9840 is [True, False, False, False, True, False]
Current timestep = 9841. State = [[-0.23811999 -0.02012479]]. Action = [[-0.01583182  0.01551534  0.         -0.0045048 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 9841 is [True, False, False, False, True, False]
Current timestep = 9842. State = [[-0.23605384 -0.01740518]]. Action = [[0.07998986 0.02672944 0.         0.47545707]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 9842 is [True, False, False, False, True, False]
Current timestep = 9843. State = [[-0.23840265 -0.01560969]]. Action = [[-0.07668114  0.00546467  0.          0.61774135]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 9843 is [True, False, False, False, True, False]
Current timestep = 9844. State = [[-0.23945485 -0.01561403]]. Action = [[ 0.04620587 -0.01815381  0.          0.4940412 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 9844 is [True, False, False, False, True, False]
State prediction error at timestep 9844 is 0.012
Human Feedback received at timestep 9844 of None
Current timestep = 9845. State = [[-0.24285057 -0.01060825]]. Action = [[-0.07354058  0.09893008  0.          0.10015535]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 9845 is [True, False, False, False, True, False]
Current timestep = 9846. State = [[-0.24274321 -0.01110651]]. Action = [[ 0.07258288 -0.08309338  0.         -0.92072487]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 9846 is [True, False, False, False, True, False]
Current timestep = 9847. State = [[-0.24348506 -0.0167886 ]]. Action = [[-0.04772148 -0.07566218  0.         -0.04291332]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 9847 is [True, False, False, False, True, False]
State prediction error at timestep 9847 is 0.012
Human Feedback received at timestep 9847 of None
Current timestep = 9848. State = [[-0.24572885 -0.02123591]]. Action = [[-0.02043729 -0.04071933  0.         -0.5125647 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 9848 is [True, False, False, False, True, False]
Current timestep = 9849. State = [[-0.24632058 -0.02535572]]. Action = [[-0.00119936 -0.0473517   0.          0.99014664]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 9849 is [True, False, False, False, True, False]
Current timestep = 9850. State = [[-0.2416525  -0.03007742]]. Action = [[ 0.09585569 -0.04986398  0.          0.63608766]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 9850 is [True, False, False, False, True, False]
State prediction error at timestep 9850 is 0.012
Human Feedback received at timestep 9850 of None
Current timestep = 9851. State = [[-0.2358237  -0.03356957]]. Action = [[ 0.0595889  -0.01730878  0.         -0.3160318 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 9851 is [True, False, False, False, True, False]
Current timestep = 9852. State = [[-0.23471333 -0.03103736]]. Action = [[-0.0228075   0.08660334  0.          0.46119893]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 9852 is [True, False, False, False, True, False]
Current timestep = 9853. State = [[-0.23568285 -0.02601843]]. Action = [[-0.01159564  0.06683267  0.         -0.553442  ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 9853 is [True, False, False, False, True, False]
Current timestep = 9854. State = [[-0.23425172 -0.0195086 ]]. Action = [[ 0.04180705  0.09257772  0.         -0.6128431 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 9854 is [True, False, False, False, True, False]
Current timestep = 9855. State = [[-0.23701772 -0.01567883]]. Action = [[-0.07416545  0.01332612  0.          0.59887815]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 9855 is [True, False, False, False, True, False]
State prediction error at timestep 9855 is 0.012
Human Feedback received at timestep 9855 of None
Current timestep = 9856. State = [[-0.23901743 -0.01434313]]. Action = [[ 0.006081    0.00349078  0.         -0.6563799 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 9856 is [True, False, False, False, True, False]
Current timestep = 9857. State = [[-0.24259534 -0.00860412]]. Action = [[-0.06586355  0.0946862   0.         -0.31364846]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 9857 is [True, False, False, False, True, False]
Current timestep = 9858. State = [[-0.24656689 -0.00119333]]. Action = [[-0.02892796  0.06626632  0.         -0.9899197 ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 9858 is [True, False, False, False, True, False]
Current timestep = 9859. State = [[-0.24770106  0.00551414]]. Action = [[ 0.01636698  0.05849753  0.         -0.34389937]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 9859 is [True, False, False, False, True, False]
Current timestep = 9860. State = [[-0.25181428  0.00426125]]. Action = [[-0.07565032 -0.09838876  0.          0.74483347]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 9860 is [True, False, False, False, True, False]
Current timestep = 9861. State = [[-0.25755072  0.0011067 ]]. Action = [[-0.06645134 -0.03432073  0.          0.7379916 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 9861 is [True, False, False, False, True, False]
Current timestep = 9862. State = [[-0.25872874 -0.00105096]]. Action = [[ 0.02529741 -0.03785193  0.          0.296893  ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 9862 is [True, False, False, False, True, False]
Current timestep = 9863. State = [[-0.25589845 -0.00271918]]. Action = [[ 0.05636815 -0.01839218  0.          0.32812607]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 9863 is [True, False, False, False, True, False]
Current timestep = 9864. State = [[-0.2510766  0.0010262]]. Action = [[ 0.08034738  0.08472272  0.         -0.62934154]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 9864 is [True, False, False, False, True, False]
Current timestep = 9865. State = [[-0.24701728  0.00645045]]. Action = [[0.0533052  0.0558667  0.         0.29847288]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 9865 is [True, False, False, False, True, False]
Current timestep = 9866. State = [[-0.24395934  0.00681079]]. Action = [[ 0.04149001 -0.03257564  0.         -0.23839235]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 9866 is [True, False, False, False, True, False]
Current timestep = 9867. State = [[-0.24418305  0.00134136]]. Action = [[-0.03221897 -0.09271606  0.         -0.45629567]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 9867 is [True, False, False, False, True, False]
Current timestep = 9868. State = [[-0.24181998 -0.00293634]]. Action = [[ 0.05346043 -0.02354108  0.         -0.92985606]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 9868 is [True, False, False, False, True, False]
State prediction error at timestep 9868 is 0.012
Human Feedback received at timestep 9868 of None
Current timestep = 9869. State = [[-0.23698229 -0.00936555]]. Action = [[ 0.0528766  -0.09796929  0.         -0.38820213]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 9869 is [True, False, False, False, True, False]
Current timestep = 9870. State = [[-0.23289378 -0.0175404 ]]. Action = [[ 0.02650908 -0.08234683  0.         -0.30182076]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 9870 is [True, False, False, False, True, False]
Current timestep = 9871. State = [[-0.2341875  -0.01682181]]. Action = [[-0.07383164  0.0957764   0.         -0.6900764 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 9871 is [True, False, False, False, True, False]
Current timestep = 9872. State = [[-0.2342382  -0.01936645]]. Action = [[ 0.01902135 -0.08126966  0.          0.11067724]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 9872 is [True, False, False, False, True, False]
Current timestep = 9873. State = [[-0.23425724 -0.02036134]]. Action = [[-0.02716301  0.04885264  0.          0.4479531 ]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 9873 is [True, False, False, False, True, False]
Current timestep = 9874. State = [[-0.23043534 -0.0232882 ]]. Action = [[ 0.08356828 -0.06549554  0.         -0.72778624]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 9874 is [True, False, False, False, True, False]
Current timestep = 9875. State = [[-0.22275272 -0.02925015]]. Action = [[ 0.09665079 -0.05947015  0.          0.36089373]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 9875 is [True, False, False, False, True, False]
Current timestep = 9876. State = [[-0.21621688 -0.03384518]]. Action = [[ 0.05714638 -0.02818077  0.         -0.3902961 ]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 9876 is [True, False, False, False, True, False]
Current timestep = 9877. State = [[-0.21134639 -0.03441672]]. Action = [[0.04192632 0.03512486 0.         0.70805836]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 9877 is [True, False, False, False, True, False]
Current timestep = 9878. State = [[-0.20543982 -0.03296289]]. Action = [[ 0.07530538  0.03304174  0.         -0.3128916 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 9878 is [True, False, False, False, True, False]
Current timestep = 9879. State = [[-0.20660928 -0.03430257]]. Action = [[-0.0988051  -0.0282665   0.         -0.95401967]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 9879 is [True, False, False, False, True, False]
Current timestep = 9880. State = [[-0.20976597 -0.04018648]]. Action = [[-0.03034199 -0.08726118  0.         -0.61038464]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 9880 is [True, False, False, False, True, False]
Current timestep = 9881. State = [[-0.21039927 -0.04041753]]. Action = [[-0.00643899  0.06353667  0.         -0.63306475]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 9881 is [True, False, False, False, True, False]
Current timestep = 9882. State = [[-0.21391518 -0.03549709]]. Action = [[-0.07438003  0.07071983  0.         -0.9151184 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 9882 is [True, False, False, False, True, False]
Current timestep = 9883. State = [[-0.22051203 -0.03042971]]. Action = [[-0.09404051  0.05389153  0.          0.00540352]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 9883 is [True, False, False, False, True, False]
Current timestep = 9884. State = [[-0.21966809 -0.03263345]]. Action = [[ 0.09272655 -0.09097678  0.          0.0042603 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 9884 is [True, False, False, False, True, False]
Current timestep = 9885. State = [[-0.22065604 -0.03035919]]. Action = [[-0.08263314  0.09210747  0.          0.35356593]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 9885 is [True, False, False, False, True, False]
Current timestep = 9886. State = [[-0.22287378 -0.03038112]]. Action = [[ 0.00231506 -0.0637498   0.          0.55800974]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 9886 is [True, False, False, False, True, False]
Current timestep = 9887. State = [[-0.22609115 -0.0358859 ]]. Action = [[-0.06268494 -0.08264742  0.         -0.7953624 ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 9887 is [True, False, False, False, True, False]
Current timestep = 9888. State = [[-0.22724469 -0.04204712]]. Action = [[ 0.01262941 -0.07026244  0.         -0.4877733 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 9888 is [True, False, False, False, True, False]
State prediction error at timestep 9888 is 0.012
Human Feedback received at timestep 9888 of None
Current timestep = 9889. State = [[-0.2301353  -0.04104223]]. Action = [[-0.06062819  0.073672    0.         -0.24458063]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 9889 is [True, False, False, False, True, False]
Current timestep = 9890. State = [[-0.2315352  -0.03910912]]. Action = [[0.01838791 0.00284698 0.         0.7129233 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 9890 is [True, False, False, False, True, False]
Current timestep = 9891. State = [[-0.22918114 -0.03452009]]. Action = [[0.05961931 0.08833983 0.         0.6150925 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 9891 is [True, False, False, False, True, False]
Current timestep = 9892. State = [[-0.23144363 -0.03306333]]. Action = [[-0.05934677 -0.02777039  0.          0.74343896]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 9892 is [True, False, False, False, True, False]
Current timestep = 9893. State = [[-0.23724642 -0.0351263 ]]. Action = [[-0.06834734 -0.03025744  0.         -0.14618611]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 9893 is [True, False, False, False, True, False]
Current timestep = 9894. State = [[-0.24160315 -0.03689355]]. Action = [[-0.03064679 -0.01701931  0.          0.49987578]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 9894 is [True, False, False, False, True, False]
State prediction error at timestep 9894 is 0.012
Human Feedback received at timestep 9894 of None
Current timestep = 9895. State = [[-0.24506778 -0.03844802]]. Action = [[-0.03208802 -0.01916055  0.         -0.56281024]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 9895 is [True, False, False, False, True, False]
Current timestep = 9896. State = [[-0.24673045 -0.03950404]]. Action = [[ 0.00539182 -0.00698705  0.         -0.8299173 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 9896 is [True, False, False, False, True, False]
State prediction error at timestep 9896 is 0.012
Human Feedback received at timestep 9896 of None
Current timestep = 9897. State = [[-0.248601   -0.03795294]]. Action = [[-0.01818016  0.0379822   0.         -0.1011706 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 9897 is [True, False, False, False, True, False]
State prediction error at timestep 9897 is 0.012
Human Feedback received at timestep 9897 of None
Current timestep = 9898. State = [[-0.24971777 -0.03749057]]. Action = [[ 0.01120251 -0.01313246  0.          0.5317508 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 9898 is [True, False, False, False, True, False]
State prediction error at timestep 9898 is 0.012
Human Feedback received at timestep 9898 of None
Current timestep = 9899. State = [[-0.24836849 -0.03386575]]. Action = [[ 0.04633249  0.0767284   0.         -0.0080806 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 9899 is [True, False, False, False, True, False]
Current timestep = 9900. State = [[-0.24820326 -0.03396838]]. Action = [[ 0.00074594 -0.05297492  0.         -0.6471257 ]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 9900 is [True, False, False, False, True, False]
Current timestep = 9901. State = [[-0.24571262 -0.03406369]]. Action = [[ 0.06720503  0.02439442  0.         -0.56419235]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 9901 is [True, False, False, False, True, False]
Current timestep = 9902. State = [[-0.2404141 -0.0360959]]. Action = [[ 0.08470214 -0.05511694  0.         -0.519674  ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 9902 is [True, False, False, False, True, False]
Current timestep = 9903. State = [[-0.2379364  -0.03850531]]. Action = [[ 0.00376849 -0.01272751  0.         -0.85953826]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 9903 is [True, False, False, False, True, False]
Current timestep = 9904. State = [[-0.23897488 -0.0346146 ]]. Action = [[-0.02743617  0.09322084  0.          0.5452888 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 9904 is [True, False, False, False, True, False]
Current timestep = 9905. State = [[-0.24447083 -0.02695473]]. Action = [[-0.09801222  0.09868688  0.         -0.5507629 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 9905 is [True, False, False, False, True, False]
State prediction error at timestep 9905 is 0.012
Human Feedback received at timestep 9905 of None
Current timestep = 9906. State = [[-0.24826883 -0.02461382]]. Action = [[-0.01818597 -0.02537409  0.         -0.8618024 ]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 9906 is [True, False, False, False, True, False]
Current timestep = 9907. State = [[-0.247313  -0.0212718]]. Action = [[ 0.03969564  0.06169192  0.         -0.5150914 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 9907 is [True, False, False, False, True, False]
State prediction error at timestep 9907 is 0.012
Human Feedback received at timestep 9907 of None
Current timestep = 9908. State = [[-0.2506219  -0.01581207]]. Action = [[-0.08142705  0.05188056  0.          0.48433793]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 9908 is [True, False, False, False, True, False]
Current timestep = 9909. State = [[-0.25770828 -0.00877692]]. Action = [[-0.08552682  0.08202723  0.         -0.87684727]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 9909 is [True, False, False, False, True, False]
Current timestep = 9910. State = [[-0.25751495 -0.00388347]]. Action = [[ 0.08813652  0.01421429  0.         -0.7563909 ]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 9910 is [True, False, False, False, True, False]
Current timestep = 9911. State = [[-0.2529777  -0.00337969]]. Action = [[ 0.05984988 -0.03319775  0.         -0.1282314 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 9911 is [True, False, False, False, True, False]
State prediction error at timestep 9911 is 0.012
Human Feedback received at timestep 9911 of None
Current timestep = 9912. State = [[-0.25475058 -0.00226735]]. Action = [[-0.07678865  0.01604085  0.          0.24358511]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 9912 is [True, False, False, False, True, False]
Current timestep = 9913. State = [[-0.2558402   0.00110866]]. Action = [[0.0256312  0.03555793 0.         0.55556583]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 9913 is [True, False, False, False, True, False]
State prediction error at timestep 9913 is 0.012
Human Feedback received at timestep 9913 of None
Current timestep = 9914. State = [[-0.25612527  0.00341688]]. Action = [[-0.00977003  0.00232393  0.         -0.1962012 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 9914 is [True, False, False, False, True, False]
Current timestep = 9915. State = [[-0.25255835  0.00339986]]. Action = [[ 0.08467328 -0.02120304  0.         -0.32546437]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 9915 is [True, False, False, False, True, False]
State prediction error at timestep 9915 is 0.012
Human Feedback received at timestep 9915 of None
Current timestep = 9916. State = [[-0.25339696  0.00483736]]. Action = [[-0.07019904  0.02865297  0.          0.7515496 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 9916 is [True, False, False, False, True, False]
Current timestep = 9917. State = [[-0.25311214  0.00771839]]. Action = [[0.05235144 0.02950557 0.         0.23961449]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 9917 is [True, False, False, False, True, False]
Current timestep = 9918. State = [[-0.24963216  0.01215951]]. Action = [[ 0.05359285  0.05903747  0.         -0.47718382]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 9918 is [True, False, False, False, True, False]
Current timestep = 9919. State = [[-0.24718319  0.01050125]]. Action = [[ 0.02312972 -0.08003351  0.         -0.8744527 ]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 9919 is [True, False, False, False, True, False]
Current timestep = 9920. State = [[-0.24677815  0.00761479]]. Action = [[-0.01399129 -0.01783987  0.         -0.52184886]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 9920 is [True, False, False, False, True, False]
Current timestep = 9921. State = [[-0.24355449  0.01014198]]. Action = [[ 0.06498169  0.06183467  0.         -0.1281628 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 9921 is [True, False, False, False, True, False]
Current timestep = 9922. State = [[-0.24307044  0.0101972 ]]. Action = [[-0.03594781 -0.03723929  0.         -0.29499   ]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 9922 is [True, False, False, False, True, False]
Current timestep = 9923. State = [[-0.24501032  0.00470318]]. Action = [[-0.03774452 -0.09071635  0.          0.538784  ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 9923 is [True, False, False, False, True, False]
Current timestep = 9924. State = [[-0.24323429  0.00219005]]. Action = [[0.04021876 0.01056733 0.         0.6402621 ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 9924 is [True, False, False, False, True, False]
Current timestep = 9925. State = [[-0.24269615  0.00039066]]. Action = [[-0.02673411 -0.03018657  0.          0.82576203]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 9925 is [True, False, False, False, True, False]
State prediction error at timestep 9925 is 0.012
Human Feedback received at timestep 9925 of None
Current timestep = 9926. State = [[-0.24379161 -0.0041008 ]]. Action = [[-0.02677404 -0.06092683  0.          0.9099889 ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 9926 is [True, False, False, False, True, False]
Current timestep = 9927. State = [[-0.24285416 -0.01148149]]. Action = [[ 0.01618125 -0.09362238  0.          0.31197143]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 9927 is [True, False, False, False, True, False]
Current timestep = 9928. State = [[-0.2376365  -0.01414814]]. Action = [[0.08375058 0.02905642 0.         0.78157496]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 9928 is [True, False, False, False, True, False]
Current timestep = 9929. State = [[-0.23348148 -0.01610913]]. Action = [[ 0.02680545 -0.02826978  0.          0.33481574]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 9929 is [True, False, False, False, True, False]
State prediction error at timestep 9929 is 0.012
Human Feedback received at timestep 9929 of None
Current timestep = 9930. State = [[-0.23228708 -0.01386674]]. Action = [[-0.00318297  0.08448979  0.         -0.08315891]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 9930 is [True, False, False, False, True, False]
State prediction error at timestep 9930 is 0.012
Human Feedback received at timestep 9930 of None
Current timestep = 9931. State = [[-0.22793992 -0.01037565]]. Action = [[ 0.08909886  0.03662374  0.         -0.39286327]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 9931 is [True, False, False, False, True, False]
Current timestep = 9932. State = [[-0.22642182 -0.00680104]]. Action = [[-0.02022246  0.0558335   0.          0.35907733]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 9932 is [True, False, False, False, True, False]
Current timestep = 9933. State = [[-0.23128052 -0.003606  ]]. Action = [[-0.09246437  0.02954044  0.          0.8367331 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 9933 is [True, False, False, False, True, False]
State prediction error at timestep 9933 is 0.012
Human Feedback received at timestep 9933 of None
Current timestep = 9934. State = [[-0.23064938 -0.00369163]]. Action = [[ 0.07244342 -0.02901631  0.          0.20558381]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 9934 is [True, False, False, False, True, False]
Current timestep = 9935. State = [[-0.23233028 -0.00871249]]. Action = [[-0.09060679 -0.09104843  0.          0.7020582 ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 9935 is [True, False, False, False, True, False]
Current timestep = 9936. State = [[-0.23179114 -0.0101965 ]]. Action = [[0.05406069 0.02252255 0.         0.8155627 ]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 9936 is [True, False, False, False, True, False]
Current timestep = 9937. State = [[-0.22686633 -0.01388022]]. Action = [[ 0.06352282 -0.08416818  0.         -0.0032084 ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 9937 is [True, False, False, False, True, False]
State prediction error at timestep 9937 is 0.012
Human Feedback received at timestep 9937 of None
Current timestep = 9938. State = [[-0.22626019 -0.01168129]]. Action = [[-0.03815567  0.09913241  0.         -0.40758324]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 9938 is [True, False, False, False, True, False]
Current timestep = 9939. State = [[-0.22689931 -0.01053026]]. Action = [[ 1.00038946e-04 -3.31355631e-02  0.00000000e+00  9.98489380e-01]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 9939 is [True, False, False, False, True, False]
Current timestep = 9940. State = [[-0.22975752 -0.00938519]]. Action = [[-0.06474595  0.03845117  0.         -0.07063484]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 9940 is [True, False, False, False, True, False]
Current timestep = 9941. State = [[-0.22959787 -0.00747224]]. Action = [[ 0.03904255  0.01237664  0.         -0.8291417 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 9941 is [True, False, False, False, True, False]
Current timestep = 9942. State = [[-0.22625414 -0.00494221]]. Action = [[ 0.05100553  0.03644819  0.         -0.12457907]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 9942 is [True, False, False, False, True, False]
Current timestep = 9943. State = [[-0.22415766 -0.00401013]]. Action = [[ 0.01620646 -0.01003364  0.          0.65837455]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 9943 is [True, False, False, False, True, False]
State prediction error at timestep 9943 is 0.012
Human Feedback received at timestep 9943 of None
Current timestep = 9944. State = [[-0.22077245  0.00059508]]. Action = [[ 0.06159648  0.08990928  0.         -0.09792924]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 9944 is [True, False, False, False, True, False]
State prediction error at timestep 9944 is 0.012
Human Feedback received at timestep 9944 of None
Current timestep = 9945. State = [[-0.21459033  0.00428016]]. Action = [[0.09859591 0.01072468 0.         0.04880941]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 9945 is [True, False, False, False, True, False]
Current timestep = 9946. State = [[-0.20897995  0.00678699]]. Action = [[ 0.05850864  0.03112564  0.         -0.8031134 ]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 9946 is [True, False, False, False, True, False]
Current timestep = 9947. State = [[-0.21124935  0.01076846]]. Action = [[-0.0969225   0.04843857  0.          0.50340414]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 9947 is [True, False, False, False, True, False]
Current timestep = 9948. State = [[-0.21243139  0.01460765]]. Action = [[0.0298956  0.02797558 0.         0.14704919]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 9948 is [True, False, False, False, True, False]
Current timestep = 9949. State = [[-0.21412542  0.0196501 ]]. Action = [[-0.0464608   0.05969041  0.         -0.34115785]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 9949 is [True, False, False, False, True, False]
Current timestep = 9950. State = [[-0.21999066  0.02577754]]. Action = [[-0.09318911  0.05707636  0.          0.3803438 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 9950 is [True, False, False, False, True, False]
Current timestep = 9951. State = [[-0.22186923  0.03369872]]. Action = [[ 0.0267395   0.08718061  0.         -0.9803482 ]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 9951 is [True, False, False, False, True, False]
Current timestep = 9952. State = [[-0.22585694  0.04160795]]. Action = [[-0.08137675  0.06447185  0.         -0.5800579 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 9952 is [True, False, False, False, True, False]
Current timestep = 9953. State = [[-0.22752291  0.04552067]]. Action = [[ 0.02745951 -0.00643852  0.         -0.9642984 ]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 9953 is [True, False, False, False, True, False]
Current timestep = 9954. State = [[-0.2320816  0.0497664]]. Action = [[-0.0945684   0.04436677  0.          0.29728532]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 9954 is [True, False, False, False, True, False]
Current timestep = 9955. State = [[-0.23720364  0.05169236]]. Action = [[-0.03706381 -0.02994216  0.         -0.9286727 ]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 9955 is [True, False, False, False, True, False]
State prediction error at timestep 9955 is 0.012
Human Feedback received at timestep 9955 of None
Current timestep = 9956. State = [[-0.23570623  0.05591648]]. Action = [[ 0.07716835  0.06585699  0.         -0.8219613 ]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 9956 is [True, False, False, False, True, False]
State prediction error at timestep 9956 is 0.012
Human Feedback received at timestep 9956 of None
Current timestep = 9957. State = [[-0.2342372   0.06177991]]. Action = [[ 0.00909021  0.05067817  0.         -0.7530776 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 9957 is [True, False, False, False, True, False]
Current timestep = 9958. State = [[-0.2333646   0.06512004]]. Action = [[0.0271224  0.00815837 0.         0.64472413]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 9958 is [True, False, False, False, True, False]
Current timestep = 9959. State = [[-0.23326072  0.06353749]]. Action = [[-0.00589208 -0.06137547  0.          0.85750246]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 9959 is [True, False, False, False, True, False]
State prediction error at timestep 9959 is 0.012
Human Feedback received at timestep 9959 of None
Current timestep = 9960. State = [[-0.23293908  0.06674293]]. Action = [[0.01222793 0.0834777  0.         0.3006357 ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 9960 is [True, False, False, False, True, False]
State prediction error at timestep 9960 is 0.012
Human Feedback received at timestep 9960 of None
Current timestep = 9961. State = [[-0.22945617  0.07396512]]. Action = [[0.07517827 0.08267327 0.         0.3639511 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 9961 is [True, False, False, False, True, False]
Current timestep = 9962. State = [[-0.22420448  0.0791021 ]]. Action = [[0.07589091 0.03901032 0.         0.70364213]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 9962 is [True, False, False, False, True, False]
Current timestep = 9963. State = [[-0.22524065  0.0765475 ]]. Action = [[-0.07988251 -0.09513887  0.         -0.43326098]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 9963 is [True, False, False, False, True, False]
State prediction error at timestep 9963 is 0.012
Human Feedback received at timestep 9963 of None
Current timestep = 9964. State = [[-0.22912955  0.07944205]]. Action = [[-0.03421804  0.09780907  0.         -0.9268206 ]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 9964 is [True, False, False, False, True, False]
State prediction error at timestep 9964 is 0.012
Human Feedback received at timestep 9964 of None
Current timestep = 9965. State = [[-0.2327788  0.0880556]]. Action = [[-0.0358147   0.09900143  0.          0.9654664 ]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 9965 is [True, False, False, False, True, False]
Current timestep = 9966. State = [[-0.23282063  0.09554434]]. Action = [[0.04554231 0.0653002  0.         0.8823588 ]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 9966 is [True, False, False, False, True, False]
Current timestep = 9967. State = [[-0.23637575  0.09551977]]. Action = [[-0.08610907 -0.07158618  0.         -0.72468746]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 9967 is [True, False, False, False, True, False]
State prediction error at timestep 9967 is 0.012
Human Feedback received at timestep 9967 of None
Current timestep = 9968. State = [[-0.23995271  0.0923365 ]]. Action = [[-0.01114206 -0.05243126  0.         -0.00692582]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 9968 is [True, False, False, False, True, False]
Current timestep = 9969. State = [[-0.23773137  0.09292253]]. Action = [[ 0.07001474  0.02886622  0.         -0.9684034 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 9969 is [True, False, False, False, True, False]
Current timestep = 9970. State = [[-0.23559478  0.09704654]]. Action = [[0.01939867 0.06123719 0.         0.6929035 ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 9970 is [True, False, False, False, True, False]
Current timestep = 9971. State = [[-0.2310111   0.10048141]]. Action = [[ 0.09441232  0.02834944  0.         -0.24101943]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 9971 is [True, False, False, False, True, False]
Current timestep = 9972. State = [[-0.22501864  0.10010547]]. Action = [[ 0.07322334 -0.02497901  0.         -0.24134654]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 9972 is [True, False, False, False, True, False]
State prediction error at timestep 9972 is 0.012
Human Feedback received at timestep 9972 of None
Current timestep = 9973. State = [[-0.22003916  0.10075302]]. Action = [[ 0.04999118  0.03010016  0.         -0.39704955]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 9973 is [True, False, False, False, True, False]
Current timestep = 9974. State = [[-0.21910353  0.10411484]]. Action = [[-0.02337173  0.05129804  0.          0.96131456]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 9974 is [True, False, False, False, True, False]
Current timestep = 9975. State = [[-0.21715663  0.10914996]]. Action = [[ 0.04012381  0.06411304  0.         -0.40386015]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 9975 is [True, False, False, False, True, False]
State prediction error at timestep 9975 is 0.012
Human Feedback received at timestep 9975 of None
Current timestep = 9976. State = [[-0.21804804  0.11629292]]. Action = [[-0.04833619  0.09301438  0.         -0.8403499 ]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 9976 is [True, False, False, False, True, False]
Current timestep = 9977. State = [[-0.22242463  0.11867025]]. Action = [[-0.07165542 -0.0340781   0.         -0.64297146]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 9977 is [True, False, False, False, True, False]
Current timestep = 9978. State = [[-0.22466886  0.12421652]]. Action = [[-0.00949942  0.09568184  0.         -0.4380479 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 9978 is [True, False, False, False, True, False]
Current timestep = 9979. State = [[-0.22390364  0.1332556 ]]. Action = [[ 0.03033445  0.09391182  0.         -0.7252284 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 9979 is [True, False, False, False, True, False]
Current timestep = 9980. State = [[-0.22152098  0.14266957]]. Action = [[ 0.04698619  0.09956808  0.         -0.85871845]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 9980 is [True, False, False, False, False, True]
Current timestep = 9981. State = [[-0.22091946  0.14664966]]. Action = [[-0.00358676 -0.01618485  0.         -0.82360595]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 9981 is [True, False, False, False, False, True]
State prediction error at timestep 9981 is 0.012
Human Feedback received at timestep 9981 of None
Current timestep = 9982. State = [[-0.2185904   0.14477876]]. Action = [[ 0.04732055 -0.07013799  0.         -0.13306081]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 9982 is [True, False, False, False, False, True]
Current timestep = 9983. State = [[-0.2125251  0.1443286]]. Action = [[0.0850954  0.00302975 0.         0.71059084]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 9983 is [True, False, False, False, False, True]
State prediction error at timestep 9983 is 0.012
Human Feedback received at timestep 9983 of None
Current timestep = 9984. State = [[-0.20642173  0.1488496 ]]. Action = [[ 0.05991019  0.07433154  0.         -0.73437625]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 9984 is [True, False, False, False, False, True]
Current timestep = 9985. State = [[-0.20646518  0.14802091]]. Action = [[-0.06772687 -0.08343049  0.         -0.32942814]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 9985 is [True, False, False, False, False, True]
Current timestep = 9986. State = [[-0.20768476  0.14439026]]. Action = [[-0.00962213 -0.04777954  0.          0.02055025]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 9986 is [True, False, False, False, False, True]
Current timestep = 9987. State = [[-0.20372184  0.14029568]]. Action = [[ 0.06727167 -0.06062207  0.         -0.6282373 ]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 9987 is [True, False, False, False, False, True]
State prediction error at timestep 9987 is 0.012
Human Feedback received at timestep 9987 of None
Current timestep = 9988. State = [[-0.19770637  0.13818176]]. Action = [[ 0.06063776  0.00142588  0.         -0.7321148 ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 9988 is [True, False, False, False, False, True]
Current timestep = 9989. State = [[-0.19737421  0.13336697]]. Action = [[-0.06366882 -0.08805529  0.          0.5435363 ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 9989 is [True, False, False, False, False, True]
Current timestep = 9990. State = [[-0.19330396  0.12571304]]. Action = [[ 0.09226202 -0.08716077  0.         -0.9985281 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 9990 is [True, False, False, False, False, True]
Current timestep = 9991. State = [[-0.1931823   0.12044476]]. Action = [[-0.08661591 -0.03051445  0.         -0.7307165 ]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 9991 is [True, False, False, False, False, True]
Current timestep = 9992. State = [[-0.1937614   0.12083174]]. Action = [[0.0119825  0.05072958 0.         0.5931208 ]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 9992 is [True, False, False, False, True, False]
State prediction error at timestep 9992 is 0.012
Human Feedback received at timestep 9992 of None
Current timestep = 9993. State = [[-0.19209154  0.11748044]]. Action = [[ 0.01427569 -0.07174385  0.          0.4991064 ]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 9993 is [True, False, False, False, True, False]
Current timestep = 9994. State = [[-0.19222051  0.1151114 ]]. Action = [[-0.02644372  0.01670657  0.         -0.9281849 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 9994 is [True, False, False, False, True, False]
Current timestep = 9995. State = [[-0.19675629  0.11915765]]. Action = [[-0.08296515  0.09099209  0.         -0.29426175]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 9995 is [True, False, False, False, True, False]
Current timestep = 9996. State = [[-0.19641303  0.12071132]]. Action = [[ 0.06543297 -0.01315702  0.          0.7076769 ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 9996 is [True, False, False, False, True, False]
Current timestep = 9997. State = [[-0.19502668  0.12302727]]. Action = [[ 0.00594612  0.06216041  0.         -0.2560947 ]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 9997 is [True, False, False, False, True, False]
Current timestep = 9998. State = [[-0.19875954  0.12258675]]. Action = [[-0.07119519 -0.04334169  0.         -0.8190436 ]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 9998 is [True, False, False, False, True, False]
State prediction error at timestep 9998 is 0.012
Human Feedback received at timestep 9998 of None
Current timestep = 9999. State = [[-0.20513676  0.12078576]]. Action = [[-0.07987441 -0.01979128  0.         -0.9559162 ]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 9999 is [True, False, False, False, True, False]
State prediction error at timestep 9999 is 0.012
Human Feedback received at timestep 9999 of None
Current timestep = 10000. State = [[-0.20604753  0.119716  ]]. Action = [[ 0.04560929 -0.01393452  0.         -0.5039451 ]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 10000 is [True, False, False, False, True, False]
Current timestep = 10001. State = [[-0.20948626  0.11874603]]. Action = [[-0.0826887  -0.01309659  0.         -0.9943979 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 10001 is [True, False, False, False, True, False]
Current timestep = 10002. State = [[-0.21066082  0.11386718]]. Action = [[ 0.03438915 -0.09202052  0.         -0.99233204]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 10002 is [True, False, False, False, True, False]
Current timestep = 10003. State = [[-0.2075881   0.11356881]]. Action = [[0.05862799 0.05974717 0.         0.09556162]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 10003 is [True, False, False, False, True, False]
Current timestep = 10004. State = [[-0.20377813  0.11895262]]. Action = [[0.06594587 0.09393508 0.         0.4981568 ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 10004 is [True, False, False, False, True, False]
State prediction error at timestep 10004 is 0.012
Human Feedback received at timestep 10004 of None
Current timestep = 10005. State = [[-0.19940457  0.11926871]]. Action = [[ 0.07058103 -0.03338592  0.          0.30494082]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 10005 is [True, False, False, False, True, False]
Current timestep = 10006. State = [[-0.20018685  0.12041443]]. Action = [[-0.05006024  0.05194128  0.         -0.45636916]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 10006 is [True, False, False, False, True, False]
Current timestep = 10007. State = [[-0.20553952  0.12488088]]. Action = [[-0.0749505   0.06026132  0.          0.777272  ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 10007 is [True, False, False, False, True, False]
Current timestep = 10008. State = [[-0.21218053  0.1231676 ]]. Action = [[-0.08499136 -0.0852524   0.          0.32443333]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 10008 is [True, False, False, False, True, False]
Current timestep = 10009. State = [[-0.21530798  0.11721748]]. Action = [[-0.01339409 -0.08935563  0.         -0.52114004]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 10009 is [True, False, False, False, True, False]
State prediction error at timestep 10009 is 0.012
Human Feedback received at timestep 10009 of None
Current timestep = 10010. State = [[-0.21415606  0.11750966]]. Action = [[0.0378358  0.05648328 0.         0.68742657]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 10010 is [True, False, False, False, True, False]
Current timestep = 10011. State = [[-0.21157351  0.11677621]]. Action = [[ 0.03959251 -0.04297314  0.          0.5621413 ]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 10011 is [True, False, False, False, True, False]
Current timestep = 10012. State = [[-0.20814635  0.11887599]]. Action = [[ 0.05187414  0.07352882  0.         -0.83044577]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 10012 is [True, False, False, False, True, False]
Current timestep = 10013. State = [[-0.20317991  0.11824781]]. Action = [[ 0.07696033 -0.04341531  0.         -0.7452338 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 10013 is [True, False, False, False, True, False]
State prediction error at timestep 10013 is 0.012
Human Feedback received at timestep 10013 of None
Current timestep = 10014. State = [[-0.19691753  0.11870981]]. Action = [[ 0.08070727  0.04795261  0.         -0.19466895]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 10014 is [True, False, False, False, True, False]
State prediction error at timestep 10014 is 0.012
Human Feedback received at timestep 10014 of None
Current timestep = 10015. State = [[-0.19821267  0.12368421]]. Action = [[-0.08300857  0.08314516  0.         -0.42304885]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 10015 is [True, False, False, False, True, False]
Current timestep = 10016. State = [[-0.19846572  0.12295924]]. Action = [[ 0.04059476 -0.06523211  0.         -0.715852  ]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 10016 is [True, False, False, False, True, False]
Current timestep = 10017. State = [[-0.19811271  0.1258933 ]]. Action = [[-0.01426433  0.09602237  0.         -0.4296754 ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 10017 is [True, False, False, False, True, False]
Current timestep = 10018. State = [[-0.1978395   0.13229501]]. Action = [[0.01994143 0.06965908 0.         0.1621176 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 10018 is [True, False, False, False, False, True]
Current timestep = 10019. State = [[-0.19562015  0.13182965]]. Action = [[ 0.0386088  -0.0625632   0.          0.30951726]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 10019 is [True, False, False, False, False, True]
Current timestep = 10020. State = [[-0.1903062   0.13149884]]. Action = [[0.08050936 0.02059931 0.         0.34943593]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 10020 is [True, False, False, False, False, True]
Current timestep = 10021. State = [[-0.19153659  0.1281017 ]]. Action = [[-0.09886481 -0.09160861  0.         -0.12292159]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 10021 is [True, False, False, False, False, True]
State prediction error at timestep 10021 is 0.012
Human Feedback received at timestep 10021 of None
Current timestep = 10022. State = [[-0.19414619  0.12487379]]. Action = [[-0.00803219 -0.0224793   0.          0.58196294]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 10022 is [True, False, False, False, False, True]
State prediction error at timestep 10022 is 0.012
Human Feedback received at timestep 10022 of None
Current timestep = 10023. State = [[-0.19685808  0.1202971 ]]. Action = [[-0.0537819  -0.08077689  0.          0.8916497 ]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 10023 is [True, False, False, False, True, False]
Current timestep = 10024. State = [[-0.1982476   0.12074802]]. Action = [[-0.00193248  0.05670062  0.         -0.62992203]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 10024 is [True, False, False, False, True, False]
Current timestep = 10025. State = [[-0.20220324  0.12130214]]. Action = [[-0.07663009 -0.01907433  0.          0.5350728 ]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 10025 is [True, False, False, False, True, False]
Current timestep = 10026. State = [[-0.20319028  0.12240996]]. Action = [[0.03165827 0.03154067 0.         0.5587646 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 10026 is [True, False, False, False, True, False]
Current timestep = 10027. State = [[-0.20252573  0.12372863]]. Action = [[ 0.00804095  0.01244788  0.         -0.50564253]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 10027 is [True, False, False, False, True, False]
Current timestep = 10028. State = [[-0.2057141   0.12444176]]. Action = [[-0.06039596  0.00745779  0.         -0.69504654]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 10028 is [True, False, False, False, True, False]
Current timestep = 10029. State = [[-0.20951676  0.12458441]]. Action = [[-0.0319106  -0.00599963  0.          0.8366238 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 10029 is [True, False, False, False, True, False]
Current timestep = 10030. State = [[-0.21042612  0.12675142]]. Action = [[0.01698832 0.04401877 0.         0.9560571 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 10030 is [True, False, False, False, True, False]
State prediction error at timestep 10030 is 0.012
Human Feedback received at timestep 10030 of None
Current timestep = 10031. State = [[-0.21177037  0.13279432]]. Action = [[-0.01274149  0.09456521  0.          0.6485348 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 10031 is [True, False, False, False, False, True]
Current timestep = 10032. State = [[-0.21661773  0.13768889]]. Action = [[-0.06325255  0.03313959  0.         -0.40966153]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 10032 is [True, False, False, False, False, True]
Current timestep = 10033. State = [[-0.2244963   0.14358884]]. Action = [[-0.09334612  0.0768451   0.         -0.7647439 ]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 10033 is [True, False, False, False, False, True]
Current timestep = 10034. State = [[-0.22655293  0.14422034]]. Action = [[ 0.04795379 -0.05775688  0.          0.36548662]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 10034 is [True, False, False, False, False, True]
Current timestep = 10035. State = [[-0.2263983   0.14077798]]. Action = [[ 0.00341137 -0.05513488  0.         -0.24302411]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 10035 is [True, False, False, False, False, True]
State prediction error at timestep 10035 is 0.012
Human Feedback received at timestep 10035 of None
Current timestep = 10036. State = [[-0.22885443  0.13547437]]. Action = [[-0.04094852 -0.08746815  0.          0.56596553]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 10036 is [True, False, False, False, False, True]
Current timestep = 10037. State = [[-0.22718357  0.137418  ]]. Action = [[ 0.07568223  0.0902232   0.         -0.5036633 ]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 10037 is [True, False, False, False, False, True]
Current timestep = 10038. State = [[-0.22804102  0.13570282]]. Action = [[-0.06673725 -0.0923792   0.         -0.645856  ]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 10038 is [True, False, False, False, False, True]
Current timestep = 10039. State = [[-0.23069862  0.13513649]]. Action = [[-0.01146959  0.03737197  0.          0.6830405 ]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 10039 is [True, False, False, False, False, True]
Current timestep = 10040. State = [[-0.22859439  0.13636562]]. Action = [[ 0.0660397   0.01175679  0.         -0.6922076 ]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 10040 is [True, False, False, False, False, True]
State prediction error at timestep 10040 is 0.012
Human Feedback received at timestep 10040 of None
Current timestep = 10041. State = [[-0.22315621  0.13189548]]. Action = [[ 0.08407295 -0.08299537  0.          0.32715034]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 10041 is [True, False, False, False, False, True]
Current timestep = 10042. State = [[-0.219093    0.13187969]]. Action = [[ 0.03376562  0.07061584  0.         -0.70067084]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 10042 is [True, False, False, False, False, True]
State prediction error at timestep 10042 is 0.012
Human Feedback received at timestep 10042 of None
Current timestep = 10043. State = [[-0.21567468  0.13067652]]. Action = [[ 0.04679319 -0.04270541  0.          0.7712085 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 10043 is [True, False, False, False, False, True]
State prediction error at timestep 10043 is 0.012
Human Feedback received at timestep 10043 of None
Current timestep = 10044. State = [[-0.21759832  0.12592678]]. Action = [[-0.08374971 -0.06023211  0.         -0.1826495 ]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 10044 is [True, False, False, False, False, True]
Current timestep = 10045. State = [[-0.21843646  0.12177493]]. Action = [[ 0.01472912 -0.03765575  0.         -0.75821555]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 10045 is [True, False, False, False, False, True]
State prediction error at timestep 10045 is 0.012
Human Feedback received at timestep 10045 of None
Current timestep = 10046. State = [[-0.21936347  0.12427831]]. Action = [[-0.03244233  0.08908088  0.          0.4434445 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 10046 is [True, False, False, False, True, False]
Current timestep = 10047. State = [[-0.22131325  0.12698291]]. Action = [[-0.01946281  0.01260705  0.          0.35078287]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 10047 is [True, False, False, False, True, False]
Current timestep = 10048. State = [[-0.22482274  0.13090697]]. Action = [[-0.05300672  0.07078554  0.          0.6370386 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 10048 is [True, False, False, False, False, True]
Current timestep = 10049. State = [[-0.22630897  0.1329969 ]]. Action = [[ 0.01433704 -0.00438894  0.         -0.8667355 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 10049 is [True, False, False, False, False, True]
Current timestep = 10050. State = [[-0.22728497  0.13709116]]. Action = [[-0.01017343  0.07662887  0.          0.4978869 ]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 10050 is [True, False, False, False, False, True]
Current timestep = 10051. State = [[-0.22670838  0.13826506]]. Action = [[ 0.03690099 -0.02960998  0.          0.5119462 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 10051 is [True, False, False, False, False, True]
State prediction error at timestep 10051 is 0.012
Human Feedback received at timestep 10051 of None
Current timestep = 10052. State = [[-0.22988914  0.13937762]]. Action = [[-0.07294621  0.02593107  0.          0.04124725]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 10052 is [True, False, False, False, False, True]
Current timestep = 10053. State = [[-0.22851022  0.14255533]]. Action = [[0.08855922 0.03807489 0.         0.73289263]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 10053 is [True, False, False, False, False, True]
Current timestep = 10054. State = [[-0.23044403  0.14279564]]. Action = [[-0.08980932 -0.03577936  0.         -0.27028966]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 10054 is [True, False, False, False, False, True]
State prediction error at timestep 10054 is 0.012
Human Feedback received at timestep 10054 of None
Current timestep = 10055. State = [[-0.23706596  0.14132528]]. Action = [[-0.07711983 -0.03052055  0.          0.1295507 ]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 10055 is [True, False, False, False, False, True]
State prediction error at timestep 10055 is 0.012
Human Feedback received at timestep 10055 of None
Current timestep = 10056. State = [[-0.23745292  0.14460205]]. Action = [[0.06271755 0.07336927 0.         0.51839614]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 10056 is [True, False, False, False, False, True]
State prediction error at timestep 10056 is 0.012
Human Feedback received at timestep 10056 of None
Current timestep = 10057. State = [[-0.23271766  0.15064895]]. Action = [[ 0.08086631  0.07477967  0.         -0.08990771]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 10057 is [True, False, False, False, False, True]
State prediction error at timestep 10057 is 0.012
Human Feedback received at timestep 10057 of None
Current timestep = 10058. State = [[-0.22783394  0.15628974]]. Action = [[0.06642712 0.06700099 0.         0.0912627 ]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 10058 is [True, False, False, False, False, True]
Current timestep = 10059. State = [[-0.22454904  0.15723823]]. Action = [[ 0.03136603 -0.02684815  0.         -0.68385756]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 10059 is [True, False, False, False, False, True]
Current timestep = 10060. State = [[-0.21928707  0.15206786]]. Action = [[ 0.07642604 -0.09876639  0.         -0.2474947 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 10060 is [True, False, False, False, False, True]
State prediction error at timestep 10060 is 0.012
Human Feedback received at timestep 10060 of None
Current timestep = 10061. State = [[-0.21383609  0.14574166]]. Action = [[ 0.03963368 -0.0722494   0.          0.50771666]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 10061 is [True, False, False, False, False, True]
Current timestep = 10062. State = [[-0.21155463  0.14676285]]. Action = [[-0.01090318  0.06872214  0.          0.51325047]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 10062 is [True, False, False, False, False, True]
Current timestep = 10063. State = [[-0.20850098  0.14478795]]. Action = [[ 0.03680635 -0.0763236   0.         -0.5241885 ]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 10063 is [True, False, False, False, False, True]
Current timestep = 10064. State = [[-0.20259514  0.14415811]]. Action = [[0.06514127 0.03734944 0.         0.17473555]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 10064 is [True, False, False, False, False, True]
State prediction error at timestep 10064 is 0.012
Human Feedback received at timestep 10064 of None
Current timestep = 10065. State = [[-0.2032879  0.1474913]]. Action = [[-0.08559959  0.05387301  0.          0.45299375]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 10065 is [True, False, False, False, False, True]
State prediction error at timestep 10065 is 0.012
Human Feedback received at timestep 10065 of None
Current timestep = 10066. State = [[-0.20686893  0.14527112]]. Action = [[-0.05284715 -0.0843278   0.          0.5184865 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 10066 is [True, False, False, False, False, True]
Current timestep = 10067. State = [[-0.21092114  0.14041604]]. Action = [[-0.07748268 -0.06245775  0.         -0.81291825]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 10067 is [True, False, False, False, False, True]
Current timestep = 10068. State = [[-0.20922808  0.14284927]]. Action = [[ 0.07841045  0.08832384  0.         -0.98608834]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 10068 is [True, False, False, False, False, True]
Current timestep = 10069. State = [[-0.20608644  0.14916232]]. Action = [[ 0.00989912  0.07555187  0.         -0.8866087 ]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 10069 is [True, False, False, False, False, True]
Current timestep = 10070. State = [[-0.20246065  0.147588  ]]. Action = [[ 0.05197848 -0.08554673  0.          0.2803614 ]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 10070 is [True, False, False, False, False, True]
Current timestep = 10071. State = [[-0.20207568  0.1485599 ]]. Action = [[-0.04077034  0.06311635  0.         -0.7842425 ]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 10071 is [True, False, False, False, False, True]
Current timestep = 10072. State = [[-0.20302568  0.15334047]]. Action = [[-0.00480327  0.05032594  0.          0.42599964]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 10072 is [True, False, False, False, False, True]
State prediction error at timestep 10072 is 0.012
Human Feedback received at timestep 10072 of None
Current timestep = 10073. State = [[-0.19851278  0.15073106]]. Action = [[ 0.09123827 -0.09403423  0.          0.96778977]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 10073 is [True, False, False, False, False, True]
Current timestep = 10074. State = [[-0.19928782  0.14797293]]. Action = [[-0.0849679  -0.00767845  0.         -0.33731788]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 10074 is [True, False, False, False, False, True]
Current timestep = 10075. State = [[-0.20523599  0.1472066 ]]. Action = [[-0.08859872 -0.02195288  0.          0.8993325 ]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 10075 is [True, False, False, False, False, True]
Current timestep = 10076. State = [[-0.2085119   0.14908847]]. Action = [[-0.01653022  0.03656203  0.          0.57040226]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 10076 is [True, False, False, False, False, True]
Current timestep = 10077. State = [[-0.21191838  0.15209647]]. Action = [[-0.04945841  0.02827572  0.          0.50078976]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 10077 is [True, False, False, False, False, True]
Current timestep = 10078. State = [[-0.21565905  0.15774144]]. Action = [[-0.02969253  0.08298791  0.         -0.2051329 ]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 10078 is [True, False, False, False, False, True]
Current timestep = 10079. State = [[-0.21970998  0.16114418]]. Action = [[-0.03753256  0.00371315  0.          0.0881865 ]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 10079 is [True, False, False, False, False, True]
Current timestep = 10080. State = [[-0.22106448  0.16095686]]. Action = [[ 0.02015175 -0.02464769  0.         -0.6929313 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 10080 is [True, False, False, False, False, True]
Current timestep = 10081. State = [[-0.22214794  0.15686058]]. Action = [[-0.01365796 -0.0795465   0.         -0.46155602]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 10081 is [True, False, False, False, False, True]
Current timestep = 10082. State = [[-0.22364594  0.15535752]]. Action = [[-0.0106142  0.0100584  0.         0.9014232]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 10082 is [True, False, False, False, False, True]
State prediction error at timestep 10082 is 0.012
Human Feedback received at timestep 10082 of None
Current timestep = 10083. State = [[-0.22815888  0.15932071]]. Action = [[-0.06725495  0.07271294  0.          0.2166233 ]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 10083 is [True, False, False, False, False, True]
Current timestep = 10084. State = [[-0.23115756  0.15789339]]. Action = [[-7.3115528e-04 -7.8647815e-02  0.0000000e+00 -8.9337051e-01]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 10084 is [True, False, False, False, False, True]
Current timestep = 10085. State = [[-0.23175699  0.16011685]]. Action = [[ 0.00870224  0.08855725  0.         -0.6714635 ]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 10085 is [True, False, False, False, False, True]
Current timestep = 10086. State = [[-0.23249432  0.1626397 ]]. Action = [[ 0.00444759  0.00341976  0.         -0.9449718 ]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 10086 is [True, False, False, False, False, True]
Current timestep = 10087. State = [[-0.2338271   0.16162217]]. Action = [[-0.01124594 -0.02567693  0.          0.99230003]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 10087 is [True, False, False, False, False, True]
State prediction error at timestep 10087 is 0.012
Human Feedback received at timestep 10087 of None
Current timestep = 10088. State = [[-0.23939389  0.15847099]]. Action = [[-0.09660251 -0.05451757  0.          0.24892628]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 10088 is [True, False, False, False, False, True]
State prediction error at timestep 10088 is 0.012
Human Feedback received at timestep 10088 of None
Current timestep = 10089. State = [[-0.24119467  0.16018887]]. Action = [[0.0400179  0.0659169  0.         0.11111915]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 10089 is [True, False, False, False, False, True]
Current timestep = 10090. State = [[-0.24162379  0.1577355 ]]. Action = [[-0.02253786 -0.08955564  0.          0.4009081 ]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 10090 is [True, False, False, False, False, True]
State prediction error at timestep 10090 is 0.012
Human Feedback received at timestep 10090 of None
Current timestep = 10091. State = [[-0.24537265  0.15572274]]. Action = [[-0.06308019  0.00536499  0.         -0.6361826 ]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 10091 is [True, False, False, False, False, True]
Current timestep = 10092. State = [[-0.2493984   0.15812361]]. Action = [[-0.0354053   0.04368589  0.          0.03223443]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 10092 is [True, False, False, False, False, True]
State prediction error at timestep 10092 is 0.012
Human Feedback received at timestep 10092 of None
Current timestep = 10093. State = [[-0.25482625  0.15521435]]. Action = [[-0.0754158  -0.0911857   0.          0.63144875]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 10093 is [True, False, False, False, False, True]
Current timestep = 10094. State = [[-0.2595691   0.15407777]]. Action = [[-0.03821313  0.02279053  0.         -0.88110334]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 10094 is [True, False, False, False, False, True]
Current timestep = 10095. State = [[-0.2654533   0.15488309]]. Action = [[-0.07221989  0.00363138  0.         -0.28668416]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 10095 is [True, False, False, False, False, True]
State prediction error at timestep 10095 is 0.012
Human Feedback received at timestep 10095 of None
Current timestep = 10096. State = [[-0.26488417  0.15312809]]. Action = [[ 0.08428084 -0.03468325  0.          0.03162944]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 10096 is [True, False, False, False, False, True]
Current timestep = 10097. State = [[-0.26388934  0.15547691]]. Action = [[0.00132129 0.08333171 0.         0.804034  ]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 10097 is [True, False, False, False, False, True]
Current timestep = 10098. State = [[-0.26454476  0.1543203 ]]. Action = [[ 0.00945184 -0.05922049  0.         -0.46959198]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 10098 is [True, False, False, False, False, True]
Current timestep = 10099. State = [[-0.26758933  0.15344414]]. Action = [[-0.04940862  0.02240093  0.         -0.8759825 ]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 10099 is [True, False, False, False, False, True]
Current timestep = 10100. State = [[-0.26872623  0.15268043]]. Action = [[ 0.02364559 -0.02098963  0.         -0.233773  ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 10100 is [True, False, False, False, False, True]
State prediction error at timestep 10100 is 0.012
Human Feedback received at timestep 10100 of None
Current timestep = 10101. State = [[-0.26607043  0.15582283]]. Action = [[ 0.06159835  0.08793163  0.         -0.35769343]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 10101 is [True, False, False, False, False, True]
Current timestep = 10102. State = [[-0.26062807  0.15322207]]. Action = [[ 0.09141845 -0.08563813  0.          0.27312088]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 10102 is [True, False, False, False, False, True]
State prediction error at timestep 10102 is 0.012
Human Feedback received at timestep 10102 of None
Current timestep = 10103. State = [[-0.26243815  0.15169078]]. Action = [[-0.09215156  0.03132875  0.         -0.7246672 ]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 10103 is [True, False, False, False, False, True]
Current timestep = 10104. State = [[-0.26651296  0.14865254]]. Action = [[-0.03272788 -0.07812681  0.         -0.68981636]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 10104 is [True, False, False, False, False, True]
Current timestep = 10105. State = [[-0.26965344  0.14597201]]. Action = [[-0.04420579 -0.01215086  0.         -0.36909753]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 10105 is [True, False, False, False, False, True]
Current timestep = 10106. State = [[-0.26891088  0.14162911]]. Action = [[ 0.04072494 -0.07580639  0.          0.82280886]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 10106 is [True, False, False, False, False, True]
State prediction error at timestep 10106 is 0.012
Human Feedback received at timestep 10106 of None
Current timestep = 10107. State = [[-0.26327398  0.13825123]]. Action = [[ 0.08884888 -0.00727355  0.          0.4546094 ]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 10107 is [True, False, False, False, False, True]
Current timestep = 10108. State = [[-0.2627129  0.1397824]]. Action = [[-0.04460979  0.05981985  0.         -0.3504504 ]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 10108 is [True, False, False, False, False, True]
Current timestep = 10109. State = [[-0.26296628  0.13993628]]. Action = [[ 0.01744933 -0.01721933  0.         -0.8255689 ]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 10109 is [True, False, False, False, False, True]
Current timestep = 10110. State = [[-0.25987813  0.13458446]]. Action = [[ 0.04930196 -0.08466167  0.         -0.3177269 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 10110 is [True, False, False, False, False, True]
Current timestep = 10111. State = [[-0.25480288  0.13506219]]. Action = [[ 0.06672988  0.08268812  0.         -0.07158947]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 10111 is [True, False, False, False, False, True]
Current timestep = 10112. State = [[-0.2509752   0.14042458]]. Action = [[ 0.03716371  0.08603168  0.         -0.9218992 ]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 10112 is [True, False, False, False, False, True]
State prediction error at timestep 10112 is 0.012
Human Feedback received at timestep 10112 of None
Current timestep = 10113. State = [[-0.24522217  0.14136507]]. Action = [[ 0.091513   -0.01581148  0.         -0.74408066]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 10113 is [True, False, False, False, False, True]
State prediction error at timestep 10113 is 0.012
Human Feedback received at timestep 10113 of None
Current timestep = 10114. State = [[-0.24630348  0.13966887]]. Action = [[-0.09768619 -0.02254726  0.          0.90095294]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 10114 is [True, False, False, False, False, True]
State prediction error at timestep 10114 is 0.012
Human Feedback received at timestep 10114 of None
Current timestep = 10115. State = [[-0.24622108  0.13838215]]. Action = [[ 0.04952846 -0.01065072  0.          0.5218929 ]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 10115 is [True, False, False, False, False, True]
Current timestep = 10116. State = [[-0.24875227  0.13378365]]. Action = [[-0.09326522 -0.08859992  0.         -0.55546784]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 10116 is [True, False, False, False, False, True]
State prediction error at timestep 10116 is 0.012
Human Feedback received at timestep 10116 of None
Current timestep = 10117. State = [[-0.24906488  0.13071512]]. Action = [[ 0.04083262 -0.00947206  0.          0.3868233 ]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 10117 is [True, False, False, False, False, True]
Current timestep = 10118. State = [[-0.2519274   0.13178901]]. Action = [[-0.0873277   0.03206489  0.         -0.82919294]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 10118 is [True, False, False, False, False, True]
Current timestep = 10119. State = [[-0.25583473  0.1329039 ]]. Action = [[-3.230997e-02 -5.435124e-04  0.000000e+00 -6.117623e-01]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 10119 is [True, False, False, False, False, True]
Current timestep = 10120. State = [[-0.25751302  0.13513239]]. Action = [[-0.00689919  0.04042111  0.         -0.40786904]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 10120 is [True, False, False, False, False, True]
State prediction error at timestep 10120 is 0.012
Human Feedback received at timestep 10120 of None
Current timestep = 10121. State = [[-0.260098    0.13208018]]. Action = [[-0.03957149 -0.09006563  0.          0.95626116]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 10121 is [True, False, False, False, False, True]
Current timestep = 10122. State = [[-0.25970906  0.1333738 ]]. Action = [[0.04295129 0.07833064 0.         0.14905846]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 10122 is [True, False, False, False, False, True]
Current timestep = 10123. State = [[-0.25844282  0.13743153]]. Action = [[0.01675296 0.04141507 0.         0.53949094]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 10123 is [True, False, False, False, False, True]
Current timestep = 10124. State = [[-0.26038015  0.13746367]]. Action = [[-0.03941568 -0.02840365  0.         -0.40402877]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 10124 is [True, False, False, False, False, True]
Current timestep = 10125. State = [[-0.26546496  0.13368529]]. Action = [[-0.07753611 -0.0710489   0.          0.4067843 ]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 10125 is [True, False, False, False, False, True]
Current timestep = 10126. State = [[-0.2646892   0.12948036]]. Action = [[ 0.0663337  -0.04749877  0.          0.35453773]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 10126 is [True, False, False, False, False, True]
Current timestep = 10127. State = [[-0.26219636  0.13046074]]. Action = [[0.01476123 0.05627295 0.         0.75941706]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 10127 is [True, False, False, False, False, True]
Current timestep = 10128. State = [[-0.2590488   0.12893984]]. Action = [[ 0.05501113 -0.05308066  0.          0.07379282]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 10128 is [True, False, False, False, False, True]
Current timestep = 10129. State = [[-0.25768632  0.1236911 ]]. Action = [[-0.01271975 -0.06552271  0.          0.8532891 ]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 10129 is [True, False, False, False, False, True]
Current timestep = 10130. State = [[-0.25569838  0.11832514]]. Action = [[ 0.03140076 -0.05545731  0.         -0.7019484 ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 10130 is [True, False, False, False, True, False]
Current timestep = 10131. State = [[-0.25288293  0.11472189]]. Action = [[ 0.02366531 -0.01795715  0.          0.11929405]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 10131 is [True, False, False, False, True, False]
Current timestep = 10132. State = [[-0.25193715  0.11402652]]. Action = [[-0.00974195  0.02102854  0.         -0.01407021]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 10132 is [True, False, False, False, True, False]
Current timestep = 10133. State = [[-0.24796708  0.10951909]]. Action = [[ 0.07256622 -0.07880069  0.         -0.08935416]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 10133 is [True, False, False, False, True, False]
Current timestep = 10134. State = [[-0.2459599   0.10706959]]. Action = [[-0.01732318  0.02366953  0.          0.49036968]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 10134 is [True, False, False, False, True, False]
State prediction error at timestep 10134 is 0.012
Human Feedback received at timestep 10134 of None
Current timestep = 10135. State = [[-0.25017026  0.10533371]]. Action = [[-0.09476071 -0.02797213  0.         -0.7523645 ]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 10135 is [True, False, False, False, True, False]
State prediction error at timestep 10135 is 0.012
Human Feedback received at timestep 10135 of None
Current timestep = 10136. State = [[-0.25466797  0.10429046]]. Action = [[-0.04744477  0.00465117  0.          0.88193345]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 10136 is [True, False, False, False, True, False]
Current timestep = 10137. State = [[-0.25285348  0.10484742]]. Action = [[0.07295267 0.02258199 0.         0.8160362 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 10137 is [True, False, False, False, True, False]
Current timestep = 10138. State = [[-0.24776816  0.1010154 ]]. Action = [[ 0.06832302 -0.07240076  0.         -0.6866592 ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 10138 is [True, False, False, False, True, False]
Current timestep = 10139. State = [[-0.24192649  0.0942876 ]]. Action = [[ 0.07181721 -0.07099929  0.         -0.9503181 ]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 10139 is [True, False, False, False, True, False]
Current timestep = 10140. State = [[-0.24147287  0.08620403]]. Action = [[-0.05476579 -0.09631313  0.          0.30671716]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 10140 is [True, False, False, False, True, False]
Current timestep = 10141. State = [[-0.2436104   0.08575843]]. Action = [[-0.02965001  0.07255206  0.          0.17126739]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 10141 is [True, False, False, False, True, False]
Current timestep = 10142. State = [[-0.24672619  0.08662747]]. Action = [[-0.04746809 -0.00372599  0.         -0.13198167]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 10142 is [True, False, False, False, True, False]
Current timestep = 10143. State = [[-0.24582392  0.08157076]]. Action = [[ 0.04549342 -0.0861343   0.          0.98194265]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 10143 is [True, False, False, False, True, False]
Current timestep = 10144. State = [[-0.2457647   0.07927163]]. Action = [[-0.02573882  0.02485809  0.          0.21077847]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 10144 is [True, False, False, False, True, False]
Current timestep = 10145. State = [[-0.24729365  0.07655088]]. Action = [[-0.0169255  -0.04952239  0.         -0.00687832]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 10145 is [True, False, False, False, True, False]
State prediction error at timestep 10145 is 0.012
Human Feedback received at timestep 10145 of None
Current timestep = 10146. State = [[-0.24527538  0.07799125]]. Action = [[ 0.05666537  0.07534914  0.         -0.64020693]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 10146 is [True, False, False, False, True, False]
Current timestep = 10147. State = [[-0.24111767  0.08351146]]. Action = [[ 0.06863999  0.08651067  0.         -0.46796978]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 10147 is [True, False, False, False, True, False]
Current timestep = 10148. State = [[-0.2364935   0.08383773]]. Action = [[ 0.06879885 -0.03202055  0.         -0.69750756]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 10148 is [True, False, False, False, True, False]
Current timestep = 10149. State = [[-0.23207347  0.08570085]]. Action = [[0.05447284 0.06561304 0.         0.19126248]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 10149 is [True, False, False, False, True, False]
State prediction error at timestep 10149 is 0.012
Human Feedback received at timestep 10149 of None
Current timestep = 10150. State = [[-0.22919023  0.08870418]]. Action = [[ 0.02842908  0.03025416  0.         -0.9847207 ]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 10150 is [True, False, False, False, True, False]
State prediction error at timestep 10150 is 0.012
Human Feedback received at timestep 10150 of None
Current timestep = 10151. State = [[-0.22594644  0.09408553]]. Action = [[ 0.04839859  0.08945943  0.         -0.7571774 ]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 10151 is [True, False, False, False, True, False]
Current timestep = 10152. State = [[-0.22552103  0.09980322]]. Action = [[-0.01930311  0.05481049  0.          0.22536874]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 10152 is [True, False, False, False, True, False]
Current timestep = 10153. State = [[-0.22907302  0.10532273]]. Action = [[-0.06565052  0.05543531  0.         -0.30977696]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 10153 is [True, False, False, False, True, False]
State prediction error at timestep 10153 is 0.012
Human Feedback received at timestep 10153 of None
Current timestep = 10154. State = [[-0.23397233  0.1111634 ]]. Action = [[-0.06262166  0.04947383  0.          0.01758504]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 10154 is [True, False, False, False, True, False]
State prediction error at timestep 10154 is 0.012
Human Feedback received at timestep 10154 of None
Current timestep = 10155. State = [[-0.23245189  0.11234065]]. Action = [[ 0.07106506 -0.04538143  0.          0.41370094]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 10155 is [True, False, False, False, True, False]
Current timestep = 10156. State = [[-0.22866185  0.11356069]]. Action = [[ 0.03394445  0.01811372  0.         -0.27949274]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 10156 is [True, False, False, False, True, False]
Current timestep = 10157. State = [[-0.22962096  0.11261746]]. Action = [[-0.05310792 -0.05921135  0.         -0.00420332]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 10157 is [True, False, False, False, True, False]
Current timestep = 10158. State = [[-0.22591108  0.1118243 ]]. Action = [[ 0.09491301 -0.00619726  0.         -0.9460766 ]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 10158 is [True, False, False, False, True, False]
Current timestep = 10159. State = [[-0.22147097  0.11444173]]. Action = [[ 0.01658847  0.04304375  0.         -0.47996688]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 10159 is [True, False, False, False, True, False]
Current timestep = 10160. State = [[-0.22242852  0.12038719]]. Action = [[-0.05067173  0.07798717  0.         -0.54797274]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 10160 is [True, False, False, False, True, False]
Current timestep = 10161. State = [[-0.22307718  0.12401852]]. Action = [[ 0.00204674  0.00376359  0.         -0.72605187]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 10161 is [True, False, False, False, True, False]
Current timestep = 10162. State = [[-0.22251028  0.12223459]]. Action = [[-0.00354376 -0.0624403   0.         -0.7867322 ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 10162 is [True, False, False, False, True, False]
Current timestep = 10163. State = [[-0.21863171  0.11875562]]. Action = [[ 0.06051851 -0.04860151  0.         -0.62714225]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 10163 is [True, False, False, False, True, False]
Current timestep = 10164. State = [[-0.21783161  0.12230997]]. Action = [[-0.03593673  0.09699922  0.          0.9461076 ]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 10164 is [True, False, False, False, True, False]
State prediction error at timestep 10164 is 0.012
Human Feedback received at timestep 10164 of None
Current timestep = 10165. State = [[-0.21514234  0.12271694]]. Action = [[ 0.06316317 -0.0561715   0.         -0.5874938 ]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 10165 is [True, False, False, False, True, False]
Current timestep = 10166. State = [[-0.212198    0.11684044]]. Action = [[ 0.00544341 -0.0912066   0.         -0.21264791]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 10166 is [True, False, False, False, True, False]
Current timestep = 10167. State = [[-0.20982626  0.10952632]]. Action = [[ 0.01542034 -0.08941164  0.         -0.35203195]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 10167 is [True, False, False, False, True, False]
Current timestep = 10168. State = [[-0.21189106  0.10618013]]. Action = [[-0.08254682 -0.00413518  0.          0.6582283 ]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 10168 is [True, False, False, False, True, False]
State prediction error at timestep 10168 is 0.012
Human Feedback received at timestep 10168 of None
Current timestep = 10169. State = [[-0.21637104  0.10937952]]. Action = [[-0.06590003  0.07477511  0.          0.01369905]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 10169 is [True, False, False, False, True, False]
Current timestep = 10170. State = [[-0.22053106  0.10979712]]. Action = [[-0.04935513 -0.03380887  0.          0.46111608]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 10170 is [True, False, False, False, True, False]
Current timestep = 10171. State = [[-0.22553284  0.10512093]]. Action = [[-0.07382394 -0.07839602  0.         -0.7037137 ]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 10171 is [True, False, False, False, True, False]
Current timestep = 10172. State = [[-0.22344555  0.09781132]]. Action = [[ 0.09252485 -0.09213783  0.          0.9163703 ]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 10172 is [True, False, False, False, True, False]
Current timestep = 10173. State = [[-0.21983057  0.09149954]]. Action = [[ 0.01770498 -0.04868888  0.          0.45237494]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 10173 is [True, False, False, False, True, False]
Current timestep = 10174. State = [[-0.2172304   0.08583135]]. Action = [[ 0.03036619 -0.05538451  0.          0.82490635]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 10174 is [True, False, False, False, True, False]
Current timestep = 10175. State = [[-0.2189319   0.08729476]]. Action = [[-0.05741594  0.09412249  0.         -0.6582866 ]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 10175 is [True, False, False, False, True, False]
State prediction error at timestep 10175 is 0.012
Human Feedback received at timestep 10175 of None
Current timestep = 10176. State = [[-0.22479704  0.0887295 ]]. Action = [[-0.08184592 -0.00585999  0.         -0.23220456]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 10176 is [True, False, False, False, True, False]
State prediction error at timestep 10176 is 0.012
Human Feedback received at timestep 10176 of None
Current timestep = 10177. State = [[-0.23163904  0.09287234]]. Action = [[-0.0759303   0.09240363  0.          0.17219043]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 10177 is [True, False, False, False, True, False]
Current timestep = 10178. State = [[-0.23494776  0.09416956]]. Action = [[ 0.00694226 -0.02637919  0.         -0.88485616]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 10178 is [True, False, False, False, True, False]
Current timestep = 10179. State = [[-0.23266284  0.0891429 ]]. Action = [[ 0.07391096 -0.08247489  0.          0.36034107]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 10179 is [True, False, False, False, True, False]
Current timestep = 10180. State = [[-0.23186602  0.08723422]]. Action = [[-0.00369276  0.02481456  0.         -0.8726204 ]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 10180 is [True, False, False, False, True, False]
Current timestep = 10181. State = [[-0.22970727  0.08721145]]. Action = [[ 0.06503247  0.00098212  0.         -0.0823586 ]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 10181 is [True, False, False, False, True, False]
State prediction error at timestep 10181 is 0.012
Human Feedback received at timestep 10181 of None
Current timestep = 10182. State = [[-0.22816874  0.08303072]]. Action = [[ 0.0090028  -0.07027851  0.         -0.09588921]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 10182 is [True, False, False, False, True, False]
State prediction error at timestep 10182 is 0.012
Human Feedback received at timestep 10182 of None
Current timestep = 10183. State = [[-0.2310062   0.08191904]]. Action = [[-0.06009717  0.03172605  0.          0.84712195]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 10183 is [True, False, False, False, True, False]
Current timestep = 10184. State = [[-0.23155549  0.08376542]]. Action = [[ 0.03169144  0.03058922  0.         -0.76430476]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 10184 is [True, False, False, False, True, False]
Current timestep = 10185. State = [[-0.23360573  0.08252674]]. Action = [[-0.04986007 -0.03644438  0.          0.8136226 ]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 10185 is [True, False, False, False, True, False]
Current timestep = 10186. State = [[-0.23475257  0.08287029]]. Action = [[ 0.01114452  0.03173497  0.         -0.11597466]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 10186 is [True, False, False, False, True, False]
State prediction error at timestep 10186 is 0.012
Human Feedback received at timestep 10186 of None
Current timestep = 10187. State = [[-0.23888128  0.08189228]]. Action = [[-0.08280045 -0.03576175  0.          0.00445533]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 10187 is [True, False, False, False, True, False]
Current timestep = 10188. State = [[-0.23741199  0.0787097 ]]. Action = [[ 0.09022921 -0.04056726  0.          0.9628295 ]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 10188 is [True, False, False, False, True, False]
State prediction error at timestep 10188 is 0.012
Human Feedback received at timestep 10188 of None
Current timestep = 10189. State = [[-0.23275709  0.07907394]]. Action = [[ 0.04738314  0.04302926  0.         -0.77970976]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 10189 is [True, False, False, False, True, False]
Current timestep = 10190. State = [[-0.23329647  0.07743789]]. Action = [[-0.04565942 -0.0492254   0.         -0.6556419 ]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 10190 is [True, False, False, False, True, False]
State prediction error at timestep 10190 is 0.012
Human Feedback received at timestep 10190 of None
Current timestep = 10191. State = [[-0.23046485  0.07498901]]. Action = [[ 0.07926952 -0.01334731  0.          0.74796605]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 10191 is [True, False, False, False, True, False]
State prediction error at timestep 10191 is 0.012
Human Feedback received at timestep 10191 of None
Current timestep = 10192. State = [[-0.22902916  0.07270233]]. Action = [[-0.02477761 -0.02475576  0.          0.24215984]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 10192 is [True, False, False, False, True, False]
State prediction error at timestep 10192 is 0.012
Human Feedback received at timestep 10192 of None
Current timestep = 10193. State = [[-0.23342486  0.07086087]]. Action = [[-0.0930443  -0.0156849   0.          0.38531923]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 10193 is [True, False, False, False, True, False]
Current timestep = 10194. State = [[-0.23392957  0.06986834]]. Action = [[ 0.03507452 -0.00581105  0.         -0.17077994]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 10194 is [True, False, False, False, True, False]
Current timestep = 10195. State = [[-0.23377721  0.06463392]]. Action = [[-0.025663   -0.09387675  0.         -0.3895921 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 10195 is [True, False, False, False, True, False]
Current timestep = 10196. State = [[-0.23718235  0.0647732 ]]. Action = [[-0.06766094  0.06753359  0.          0.9825249 ]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 10196 is [True, False, False, False, True, False]
State prediction error at timestep 10196 is 0.012
Human Feedback received at timestep 10196 of None
Current timestep = 10197. State = [[-0.23660299  0.07131068]]. Action = [[ 0.06026059  0.09915135  0.         -0.94696784]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 10197 is [True, False, False, False, True, False]
Current timestep = 10198. State = [[-0.23657534  0.06983459]]. Action = [[-0.02633752 -0.09217279  0.          0.24066556]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 10198 is [True, False, False, False, True, False]
State prediction error at timestep 10198 is 0.012
Human Feedback received at timestep 10198 of None
Current timestep = 10199. State = [[-0.23800498  0.0705072 ]]. Action = [[-0.01195971  0.06589062  0.          0.93808246]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 10199 is [True, False, False, False, True, False]
Current timestep = 10200. State = [[-0.23757163  0.06868213]]. Action = [[ 0.02437721 -0.0735217   0.          0.37109756]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 10200 is [True, False, False, False, True, False]
Current timestep = 10201. State = [[-0.23654903  0.06213991]]. Action = [[ 0.00660338 -0.08675515  0.          0.22930086]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 10201 is [True, False, False, False, True, False]
Current timestep = 10202. State = [[-0.235892    0.06125941]]. Action = [[ 0.00475433  0.04541593  0.         -0.52139074]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 10202 is [True, False, False, False, True, False]
Current timestep = 10203. State = [[-0.2402813  0.0656323]]. Action = [[-0.09071419  0.07001475  0.         -0.48434758]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 10203 is [True, False, False, False, True, False]
Current timestep = 10204. State = [[-0.23981933  0.06561136]]. Action = [[ 0.07322443 -0.04220191  0.         -0.32128215]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 10204 is [True, False, False, False, True, False]
Current timestep = 10205. State = [[-0.2365281  0.0624425]]. Action = [[ 0.03151371 -0.03508164  0.          0.7975348 ]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 10205 is [True, False, False, False, True, False]
Current timestep = 10206. State = [[-0.23980314  0.06323037]]. Action = [[-0.09046634  0.04287974  0.         -0.03054148]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 10206 is [True, False, False, False, True, False]
Current timestep = 10207. State = [[-0.2380447   0.06060229]]. Action = [[ 0.093628   -0.07356356  0.          0.8775451 ]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 10207 is [True, False, False, False, True, False]
Current timestep = 10208. State = [[-0.23281041  0.05943618]]. Action = [[0.05185238 0.02943113 0.         0.4270606 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 10208 is [True, False, False, False, True, False]
State prediction error at timestep 10208 is 0.012
Human Feedback received at timestep 10208 of None
Current timestep = 10209. State = [[-0.22812314  0.06117778]]. Action = [[ 0.05861408  0.03206264  0.         -0.27849436]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 10209 is [True, False, False, False, True, False]
Current timestep = 10210. State = [[-0.22993788  0.06458753]]. Action = [[-0.08200129  0.05479915  0.          0.3677218 ]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 10210 is [True, False, False, False, True, False]
Current timestep = 10211. State = [[-0.23236269  0.0686891 ]]. Action = [[-0.00286952  0.04550237  0.         -0.88551044]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 10211 is [True, False, False, False, True, False]
State prediction error at timestep 10211 is 0.012
Human Feedback received at timestep 10211 of None
Current timestep = 10212. State = [[-0.23659196  0.07537228]]. Action = [[-0.07222927  0.095005    0.         -0.71443367]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 10212 is [True, False, False, False, True, False]
Current timestep = 10213. State = [[-0.23850799  0.08338475]]. Action = [[ 0.02321559  0.08363722  0.         -0.33809447]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 10213 is [True, False, False, False, True, False]
Current timestep = 10214. State = [[-0.23822498  0.08499338]]. Action = [[ 0.01694095 -0.04387496  0.          0.5750222 ]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 10214 is [True, False, False, False, True, False]
Current timestep = 10215. State = [[-0.23626593  0.08401756]]. Action = [[ 0.04158633 -0.01936281  0.          0.71420014]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 10215 is [True, False, False, False, True, False]
Current timestep = 10216. State = [[-0.23231693  0.08259135]]. Action = [[ 0.06104989 -0.03237836  0.         -0.57322514]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 10216 is [True, False, False, False, True, False]
Current timestep = 10217. State = [[-0.23233357  0.08326949]]. Action = [[-0.0402394   0.02113213  0.          0.3286997 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 10217 is [True, False, False, False, True, False]
Current timestep = 10218. State = [[-0.2300182   0.08354853]]. Action = [[ 0.06225773 -0.01759148  0.          0.07352793]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 10218 is [True, False, False, False, True, False]
State prediction error at timestep 10218 is 0.012
Human Feedback received at timestep 10218 of None
Current timestep = 10219. State = [[-0.22566319  0.08700597]]. Action = [[0.04709709 0.07445716 0.         0.24261451]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 10219 is [True, False, False, False, True, False]
Current timestep = 10220. State = [[-0.22734341  0.08848565]]. Action = [[-0.07678799 -0.02206708  0.          0.05034697]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 10220 is [True, False, False, False, True, False]
Current timestep = 10221. State = [[-0.2265582   0.08520266]]. Action = [[ 0.04842568 -0.06548931  0.          0.9449835 ]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 10221 is [True, False, False, False, True, False]
Current timestep = 10222. State = [[-0.22712988  0.08133605]]. Action = [[-0.0529827  -0.04229079  0.         -0.586936  ]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 10222 is [True, False, False, False, True, False]
Current timestep = 10223. State = [[-0.22532448  0.08344592]]. Action = [[0.05580973 0.06954483 0.         0.7957263 ]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 10223 is [True, False, False, False, True, False]
Current timestep = 10224. State = [[-0.22588085  0.08587658]]. Action = [[-0.05273582  0.00890784  0.         -0.8007947 ]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 10224 is [True, False, False, False, True, False]
Current timestep = 10225. State = [[-0.23088065  0.08697936]]. Action = [[-0.08300868  0.00708336  0.          0.77096   ]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 10225 is [True, False, False, False, True, False]
Current timestep = 10226. State = [[-0.23644042  0.08325526]]. Action = [[-0.07309532 -0.09259106  0.         -0.5789727 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 10226 is [True, False, False, False, True, False]
Current timestep = 10227. State = [[-0.23917627  0.08568738]]. Action = [[-0.01085378  0.09575971  0.         -0.03852832]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 10227 is [True, False, False, False, True, False]
State prediction error at timestep 10227 is 0.012
Human Feedback received at timestep 10227 of None
Current timestep = 10228. State = [[-0.23989849  0.09289388]]. Action = [[ 0.01029901  0.08153162  0.         -0.3650428 ]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 10228 is [True, False, False, False, True, False]
State prediction error at timestep 10228 is 0.012
Human Feedback received at timestep 10228 of None
Current timestep = 10229. State = [[-0.24162465  0.09561455]]. Action = [[-0.01820327 -0.00915585  0.         -0.77926934]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 10229 is [True, False, False, False, True, False]
Current timestep = 10230. State = [[-0.24298091  0.09901807]]. Action = [[0.00368872 0.05663974 0.         0.83670723]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 10230 is [True, False, False, False, True, False]
Current timestep = 10231. State = [[-0.24199757  0.10525008]]. Action = [[ 0.04761221  0.07914995  0.         -0.73584676]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 10231 is [True, False, False, False, True, False]
State prediction error at timestep 10231 is 0.012
Human Feedback received at timestep 10231 of None
Current timestep = 10232. State = [[-0.24360275  0.11139984]]. Action = [[-0.02780924  0.06133551  0.          0.02689385]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 10232 is [True, False, False, False, True, False]
Current timestep = 10233. State = [[-0.242386    0.11152425]]. Action = [[ 0.06576157 -0.05420671  0.         -0.62106895]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 10233 is [True, False, False, False, True, False]
Current timestep = 10234. State = [[-0.23758133  0.10943321]]. Action = [[ 0.07464094 -0.02392839  0.         -0.521186  ]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 10234 is [True, False, False, False, True, False]
Current timestep = 10235. State = [[-0.23734595  0.10482373]]. Action = [[-0.04508272 -0.08726125  0.          0.78796446]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 10235 is [True, False, False, False, True, False]
Current timestep = 10236. State = [[-0.23649994  0.09764142]]. Action = [[ 0.02955169 -0.09937204  0.         -0.81145436]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 10236 is [True, False, False, False, True, False]
Current timestep = 10237. State = [[-0.23129146  0.09039793]]. Action = [[ 0.07198227 -0.07612898  0.         -0.29287988]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 10237 is [True, False, False, False, True, False]
Current timestep = 10238. State = [[-0.22944684  0.08995093]]. Action = [[-0.02609386  0.05996489  0.          0.6108737 ]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 10238 is [True, False, False, False, True, False]
Current timestep = 10239. State = [[-0.22900231  0.09071711]]. Action = [[ 5.1205382e-03  7.6502562e-04  0.0000000e+00 -9.4494677e-01]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 10239 is [True, False, False, False, True, False]
State prediction error at timestep 10239 is 0.012
Human Feedback received at timestep 10239 of None
Current timestep = 10240. State = [[-0.22642362  0.08680376]]. Action = [[ 0.03430516 -0.06212312  0.         -0.3769955 ]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 10240 is [True, False, False, False, True, False]
Current timestep = 10241. State = [[-0.22102487  0.08621705]]. Action = [[ 0.07447956  0.04898299  0.         -0.15699345]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 10241 is [True, False, False, False, True, False]
State prediction error at timestep 10241 is 0.012
Human Feedback received at timestep 10241 of None
Current timestep = 10242. State = [[-0.21844178  0.08724479]]. Action = [[-0.00253822  0.0184207   0.          0.63178194]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 10242 is [True, False, False, False, True, False]
Current timestep = 10243. State = [[-0.21484867  0.09118968]]. Action = [[0.06430639 0.08531665 0.         0.6862825 ]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 10243 is [True, False, False, False, True, False]
Current timestep = 10244. State = [[-0.21598282  0.09310132]]. Action = [[-0.07091701 -0.00327092  0.          0.27429748]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 10244 is [True, False, False, False, True, False]
Current timestep = 10245. State = [[-0.21643642  0.09660031]]. Action = [[0.03125239 0.07020823 0.         0.4659475 ]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 10245 is [True, False, False, False, True, False]
State prediction error at timestep 10245 is 0.012
Human Feedback received at timestep 10245 of None
Current timestep = 10246. State = [[-0.21907918  0.10087764]]. Action = [[-0.06349137  0.03859553  0.         -0.98393583]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 10246 is [True, False, False, False, True, False]
State prediction error at timestep 10246 is 0.012
Human Feedback received at timestep 10246 of None
Current timestep = 10247. State = [[-0.21777144  0.10050262]]. Action = [[ 0.06873668 -0.0457764   0.         -0.3176111 ]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 10247 is [True, False, False, False, True, False]
Current timestep = 10248. State = [[-0.2118687   0.09556642]]. Action = [[ 0.08131336 -0.08038255  0.          0.5295888 ]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 10248 is [True, False, False, False, True, False]
State prediction error at timestep 10248 is 0.012
Human Feedback received at timestep 10248 of None
Current timestep = 10249. State = [[-0.2111077   0.09679434]]. Action = [[-0.04265941  0.07277598  0.         -0.7269006 ]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 10249 is [True, False, False, False, True, False]
Current timestep = 10250. State = [[-0.20896336  0.09925915]]. Action = [[ 0.05834968  0.00195074  0.         -0.7773963 ]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 10250 is [True, False, False, False, True, False]
Current timestep = 10251. State = [[-0.20720293  0.09757073]]. Action = [[-0.00807632 -0.04320211  0.         -0.41596913]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 10251 is [True, False, False, False, True, False]
Current timestep = 10252. State = [[-0.20338635  0.10062719]]. Action = [[ 0.06825168  0.08346941  0.         -0.12151742]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 10252 is [True, False, False, False, True, False]
Current timestep = 10253. State = [[-0.19904368  0.1011175 ]]. Action = [[ 0.03635169 -0.03927698  0.          0.32792544]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 10253 is [True, False, False, False, True, False]
Current timestep = 10254. State = [[-0.1976479   0.09939871]]. Action = [[-0.01653527 -0.0176035   0.          0.70238125]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 10254 is [True, False, False, False, True, False]
Current timestep = 10255. State = [[-0.1981371   0.10132956]]. Action = [[-0.02473462  0.04403818  0.         -0.86479187]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 10255 is [True, False, False, False, True, False]
Current timestep = 10256. State = [[-0.19994494  0.10149183]]. Action = [[-0.04170562 -0.03269368  0.          0.18469548]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 10256 is [True, False, False, False, True, False]
State prediction error at timestep 10256 is 0.012
Human Feedback received at timestep 10256 of None
Current timestep = 10257. State = [[-0.19856495  0.10174301]]. Action = [[ 0.03458998  0.01267146  0.         -0.2312088 ]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 10257 is [True, False, False, False, True, False]
Current timestep = 10258. State = [[-0.19439648  0.10471748]]. Action = [[0.05509669 0.04966437 0.         0.8144275 ]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 10258 is [True, False, False, False, True, False]
Current timestep = 10259. State = [[-0.19250388  0.10861115]]. Action = [[-0.00062534  0.045464    0.          0.5330334 ]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 10259 is [True, False, False, False, True, False]
Current timestep = 10260. State = [[-0.18903084  0.10617973]]. Action = [[ 0.05996612 -0.08343042  0.         -0.8669214 ]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 10260 is [True, False, False, False, True, False]
Current timestep = 10261. State = [[-0.18686828  0.10248031]]. Action = [[-0.00864766 -0.02906828  0.         -0.2857424 ]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 10261 is [True, False, False, False, True, False]
Current timestep = 10262. State = [[-0.19004433  0.09706957]]. Action = [[-0.08869215 -0.09381343  0.          0.5687647 ]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 10262 is [True, False, False, False, True, False]
Current timestep = 10263. State = [[-0.18872249  0.09007159]]. Action = [[ 0.05292518 -0.08427377  0.         -0.8377974 ]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 10263 is [True, False, False, False, True, False]
State prediction error at timestep 10263 is 0.012
Human Feedback received at timestep 10263 of None
Current timestep = 10264. State = [[-0.18723954  0.09089616]]. Action = [[-0.02255386  0.08229009  0.          0.3663504 ]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 10264 is [True, False, False, False, True, False]
State prediction error at timestep 10264 is 0.012
Human Feedback received at timestep 10264 of None
Current timestep = 10265. State = [[-0.18503752  0.09701248]]. Action = [[ 0.04647055  0.08646267  0.         -0.8818151 ]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 10265 is [True, False, False, False, True, False]
Current timestep = 10266. State = [[-0.18481912  0.0977571 ]]. Action = [[-0.02565311 -0.03372421  0.          0.47672725]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 10266 is [True, False, False, False, True, False]
Current timestep = 10267. State = [[-0.184887    0.09526603]]. Action = [[ 0.00409721 -0.03216107  0.         -0.699996  ]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 10267 is [True, False, False, False, True, False]
Current timestep = 10268. State = [[-0.18320851  0.09471833]]. Action = [[ 0.02671211  0.01278974  0.         -0.42895198]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 10268 is [True, False, False, False, True, False]
Current timestep = 10269. State = [[-0.18577956  0.09966503]]. Action = [[-0.06782188  0.09492356  0.          0.84086144]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 10269 is [True, False, False, False, True, False]
State prediction error at timestep 10269 is 0.012
Human Feedback received at timestep 10269 of None
Current timestep = 10270. State = [[-0.18877324  0.10083461]]. Action = [[-0.01757704 -0.04066945  0.          0.43333578]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 10270 is [True, False, False, False, True, False]
State prediction error at timestep 10270 is 0.012
Human Feedback received at timestep 10270 of None
Current timestep = 10271. State = [[-0.18725072  0.10128579]]. Action = [[ 0.04930069  0.02290922  0.         -0.8743027 ]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 10271 is [True, False, False, False, True, False]
Current timestep = 10272. State = [[-0.18186888  0.09804953]]. Action = [[ 0.08977681 -0.07636893  0.         -0.20671439]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 10272 is [True, False, False, False, True, False]
Current timestep = 10273. State = [[-0.17839828  0.09205144]]. Action = [[ 0.01310322 -0.06825534  0.         -0.71032894]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 10273 is [True, False, False, False, True, False]
Current timestep = 10274. State = [[-0.175041   0.0889168]]. Action = [[ 0.04530137 -0.00776912  0.          0.55770683]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 10274 is [True, False, False, False, True, False]
Current timestep = 10275. State = [[-0.17295784  0.09080091]]. Action = [[0.00436914 0.06137853 0.         0.73205054]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 10275 is [True, False, False, False, True, False]
Current timestep = 10276. State = [[-0.16778421  0.09041483]]. Action = [[ 0.09295573 -0.02745825  0.          0.16833687]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 10276 is [True, False, False, False, True, False]
Current timestep = 10277. State = [[-0.16117111  0.09068524]]. Action = [[ 0.07016142  0.04006476  0.         -0.97306937]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 10277 is [True, False, False, False, True, False]
Current timestep = 10278. State = [[-0.15529294  0.09286221]]. Action = [[ 0.06417482  0.04030121  0.         -0.2973405 ]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 10278 is [True, False, False, False, True, False]
Current timestep = 10279. State = [[-0.15052125  0.09673664]]. Action = [[ 0.04461426  0.0672899   0.         -0.7584917 ]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 10279 is [True, False, False, False, True, False]
Current timestep = 10280. State = [[-0.15173036  0.09913079]]. Action = [[-0.07333399  0.00934932  0.          0.0540936 ]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 10280 is [True, False, False, False, True, False]
Current timestep = 10281. State = [[-0.15629473  0.10044974]]. Action = [[-0.07350415  0.00632825  0.         -0.4909469 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 10281 is [True, False, False, False, True, False]
Current timestep = 10282. State = [[-0.15383236  0.104041  ]]. Action = [[ 0.09158664  0.05339999  0.         -0.05164135]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 10282 is [True, False, False, False, True, False]
Current timestep = 10283. State = [[-0.1500781   0.10983875]]. Action = [[ 0.01333195  0.06802931  0.         -0.5040012 ]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 10283 is [True, False, False, False, True, False]
State prediction error at timestep 10283 is 0.012
Human Feedback received at timestep 10283 of None
Current timestep = 10284. State = [[-0.14539735  0.11072055]]. Action = [[ 0.06891757 -0.04477692  0.          0.36567736]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 10284 is [True, False, False, False, True, False]
Current timestep = 10285. State = [[-0.13905458  0.10877206]]. Action = [[ 0.06529041 -0.03154056  0.         -0.30543387]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 10285 is [True, False, False, False, True, False]
Current timestep = 10286. State = [[-0.13525109  0.11214165]]. Action = [[0.01114456 0.07568503 0.         0.5882933 ]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 10286 is [True, False, False, False, True, False]
Current timestep = 10287. State = [[-0.13395841  0.11505787]]. Action = [[-0.00733437 -0.00085126  0.         -0.17877412]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 10287 is [True, False, False, False, True, False]
Current timestep = 10288. State = [[-0.12827711  0.11591227]]. Action = [[ 9.2912279e-02 -3.6781281e-04  0.0000000e+00 -6.5440744e-01]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 10288 is [True, False, False, False, True, False]
State prediction error at timestep 10288 is 0.012
Human Feedback received at timestep 10288 of None
Current timestep = 10289. State = [[-0.12565354  0.11428992]]. Action = [[-0.03508259 -0.04555735  0.         -0.07096297]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 10289 is [True, False, False, False, True, False]
Current timestep = 10290. State = [[-0.12062572  0.11212809]]. Action = [[ 0.087818   -0.02604911  0.          0.95399463]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 10290 is [True, False, False, False, True, False]
Current timestep = 10291. State = [[-0.12011825  0.10759312]]. Action = [[-0.08900543 -0.08190162  0.          0.7842295 ]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 10291 is [True, False, False, False, True, False]
Current timestep = 10292. State = [[-0.12090521  0.10124853]]. Action = [[-0.00747953 -0.08275715  0.          0.8725015 ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 10292 is [True, False, False, False, True, False]
State prediction error at timestep 10292 is 0.012
Human Feedback received at timestep 10292 of None
Current timestep = 10293. State = [[-0.12066791  0.09456275]]. Action = [[-0.02410865 -0.07735841  0.         -0.5627176 ]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 10293 is [True, False, False, False, True, False]
Current timestep = 10294. State = [[-0.11781476  0.08973266]]. Action = [[ 0.04046013 -0.03303601  0.         -0.2932452 ]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 10294 is [True, False, False, False, True, False]
Current timestep = 10295. State = [[-0.11963899  0.08936033]]. Action = [[-0.08559295  0.03542157  0.         -0.3926611 ]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 10295 is [True, False, False, False, True, False]
Current timestep = 10296. State = [[-0.11964234  0.091403  ]]. Action = [[0.0379417  0.03802431 0.         0.5482794 ]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 10296 is [True, False, False, False, True, False]
Current timestep = 10297. State = [[-0.11416625  0.08875933]]. Action = [[ 0.09130194 -0.05694462  0.          0.29630637]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 10297 is [True, False, False, False, True, False]
Current timestep = 10298. State = [[-0.11137267  0.08263287]]. Action = [[-0.00262708 -0.06552829  0.         -0.37043703]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 10298 is [True, False, False, False, True, False]
Current timestep = 10299. State = [[-0.10641967  0.08341139]]. Action = [[ 0.09719381  0.08503183  0.         -0.76783234]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 10299 is [True, False, False, False, True, False]
Current timestep = 10300. State = [[-0.10255558  0.08264194]]. Action = [[ 0.0207118  -0.03582159  0.          0.7543119 ]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 10300 is [True, False, False, False, True, False]
State prediction error at timestep 10300 is 0.012
Human Feedback received at timestep 10300 of None
Current timestep = 10301. State = [[-0.09774922  0.0760237 ]]. Action = [[ 0.07240953 -0.08947484  0.          0.27566075]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 10301 is [True, False, False, False, True, False]
State prediction error at timestep 10301 is 0.012
Human Feedback received at timestep 10301 of None
Current timestep = 10302. State = [[-0.09459764  0.07103393]]. Action = [[ 0.00401691 -0.01737583  0.          0.00754774]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 10302 is [True, False, False, False, True, False]
Current timestep = 10303. State = [[-0.09534209  0.06859366]]. Action = [[-0.04210258 -0.01020251  0.         -0.171462  ]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 10303 is [True, False, False, False, True, False]
Current timestep = 10304. State = [[-0.09207935  0.06630834]]. Action = [[ 0.07169082 -0.01606804  0.          0.6356996 ]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 10304 is [True, False, False, False, True, False]
Current timestep = 10305. State = [[-0.09108796  0.06479708]]. Action = [[-0.04030582  0.00201523  0.          0.1834073 ]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 10305 is [True, False, False, False, True, False]
Current timestep = 10306. State = [[-0.0916236   0.06788314]]. Action = [[-0.00623196  0.07560963  0.          0.73964536]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 10306 is [True, False, False, False, True, False]
State prediction error at timestep 10306 is 0.012
Human Feedback received at timestep 10306 of None
Current timestep = 10307. State = [[-0.09460092  0.06771195]]. Action = [[-0.06756543 -0.04375136  0.          0.82696617]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 10307 is [True, False, False, False, True, False]
State prediction error at timestep 10307 is 0.012
Human Feedback received at timestep 10307 of None
Current timestep = 10308. State = [[-0.09964157  0.0652695 ]]. Action = [[-0.08040801 -0.02960213  0.          0.5138111 ]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 10308 is [True, False, False, False, True, False]
Current timestep = 10309. State = [[-0.10593378  0.06659153]]. Action = [[-0.09206121  0.03690547  0.          0.2337482 ]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 10309 is [True, False, False, False, True, False]
Current timestep = 10310. State = [[-0.11204017  0.06891263]]. Action = [[-0.06916054  0.01102545  0.          0.5548749 ]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 10310 is [True, False, False, False, True, False]
Current timestep = 10311. State = [[-0.11349135  0.06600728]]. Action = [[ 0.02171264 -0.0803347   0.         -0.3108605 ]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 10311 is [True, False, False, False, True, False]
State prediction error at timestep 10311 is 0.012
Human Feedback received at timestep 10311 of None
Current timestep = 10312. State = [[-0.11562393  0.06323233]]. Action = [[-0.04234884 -0.01393797  0.         -0.78180724]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 10312 is [True, False, False, False, True, False]
Current timestep = 10313. State = [[-0.12126811  0.06357722]]. Action = [[-0.07702561  0.01373942  0.         -0.18246722]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 10313 is [True, False, False, False, True, False]
Current timestep = 10314. State = [[-0.12667769  0.0602762 ]]. Action = [[-0.04707937 -0.07896885  0.          0.8354926 ]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 10314 is [True, False, False, False, True, False]
Current timestep = 10315. State = [[-0.1325473  0.0595667]]. Action = [[-0.06998728  0.03093194  0.          0.39307618]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 10315 is [True, False, False, False, True, False]
Current timestep = 10316. State = [[-0.1386642   0.06454588]]. Action = [[-0.05079393  0.08298288  0.          0.3870057 ]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 10316 is [True, False, False, False, True, False]
Current timestep = 10317. State = [[-0.1441001   0.07140014]]. Action = [[-0.03297947  0.08216213  0.          0.99141765]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 10317 is [True, False, False, False, True, False]
Current timestep = 10318. State = [[-0.14977327  0.07677032]]. Action = [[-0.03984848  0.04508952  0.          0.5921589 ]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 10318 is [True, False, False, False, True, False]
Current timestep = 10319. State = [[-0.15598781  0.08216213]]. Action = [[-0.04416621  0.06288002  0.          0.14417374]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 10319 is [True, False, False, False, True, False]
State prediction error at timestep 10319 is 0.012
Human Feedback received at timestep 10319 of None
Current timestep = 10320. State = [[-0.16390496  0.08085417]]. Action = [[-0.07874222 -0.08506655  0.         -0.06983805]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 10320 is [True, False, False, False, True, False]
Current timestep = 10321. State = [[-0.16952914  0.07558634]]. Action = [[-0.02256165 -0.07532071  0.          0.7522845 ]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 10321 is [True, False, False, False, True, False]
Current timestep = 10322. State = [[-0.17668086  0.07490469]]. Action = [[-0.08740001  0.02516193  0.          0.86283183]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 10322 is [True, False, False, False, True, False]
Current timestep = 10323. State = [[-0.17815693  0.0753632 ]]. Action = [[ 0.0730926  -0.00535367  0.          0.36495638]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 10323 is [True, False, False, False, True, False]
Current timestep = 10324. State = [[-0.18221281  0.07149225]]. Action = [[-0.09190477 -0.07466613  0.          0.31671417]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 10324 is [True, False, False, False, True, False]
Current timestep = 10325. State = [[-0.18760595  0.06527104]]. Action = [[-0.02308239 -0.07570115  0.          0.9468746 ]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 10325 is [True, False, False, False, True, False]
State prediction error at timestep 10325 is 0.012
Human Feedback received at timestep 10325 of None
Current timestep = 10326. State = [[-0.19410497  0.06590121]]. Action = [[-0.07860108  0.07259258  0.         -0.32130945]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 10326 is [True, False, False, False, True, False]
Current timestep = 10327. State = [[-0.19586769  0.07032669]]. Action = [[ 0.06138105  0.06158572  0.         -0.6903675 ]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 10327 is [True, False, False, False, True, False]
Current timestep = 10328. State = [[-0.19986898  0.06797583]]. Action = [[-0.07724588 -0.07667317  0.          0.8584857 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 10328 is [True, False, False, False, True, False]
Current timestep = 10329. State = [[-0.20102336  0.06318988]]. Action = [[ 0.06288251 -0.04093599  0.         -0.459872  ]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 10329 is [True, False, False, False, True, False]
Current timestep = 10330. State = [[-0.19888985  0.05638426]]. Action = [[ 0.04264114 -0.08863825  0.         -0.7153906 ]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 10330 is [True, False, False, False, True, False]
Current timestep = 10331. State = [[-0.20204031  0.04984241]]. Action = [[-0.07400304 -0.05352372  0.         -0.6435292 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 10331 is [True, False, False, False, True, False]
Current timestep = 10332. State = [[-0.20091438  0.0482638 ]]. Action = [[0.08927526 0.0315193  0.         0.44739437]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 10332 is [True, False, False, False, True, False]
Current timestep = 10333. State = [[-0.2007751   0.04920014]]. Action = [[-0.03376696  0.03284479  0.          0.11101937]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 10333 is [True, False, False, False, True, False]
Current timestep = 10334. State = [[-0.20217496  0.05073189]]. Action = [[ 0.00176273  0.03386462  0.         -0.3458076 ]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 10334 is [True, False, False, False, True, False]
State prediction error at timestep 10334 is 0.012
Human Feedback received at timestep 10334 of None
Current timestep = 10335. State = [[-0.20401856  0.04621225]]. Action = [[-0.02740846 -0.09454242  0.         -0.74785376]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 10335 is [True, False, False, False, True, False]
State prediction error at timestep 10335 is 0.012
Human Feedback received at timestep 10335 of None
Current timestep = 10336. State = [[-0.20263635  0.03799095]]. Action = [[ 0.04450095 -0.09273009  0.          0.10658765]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 10336 is [True, False, False, False, True, False]
Current timestep = 10337. State = [[-0.20054711  0.03675579]]. Action = [[ 0.01761837  0.05826546  0.         -0.32749224]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 10337 is [True, False, False, False, True, False]
Current timestep = 10338. State = [[-0.1982172   0.03686069]]. Action = [[ 0.03954268 -0.00645339  0.         -0.62751174]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 10338 is [True, False, False, False, True, False]
Current timestep = 10339. State = [[-0.20111163  0.03218716]]. Action = [[-0.09023874 -0.07387444  0.          0.8323523 ]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 10339 is [True, False, False, False, True, False]
State prediction error at timestep 10339 is 0.012
Human Feedback received at timestep 10339 of None
Current timestep = 10340. State = [[-0.2034236   0.02943321]]. Action = [[-2.5516748e-04  3.9717183e-03  0.0000000e+00  9.5677364e-01]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 10340 is [True, False, False, False, True, False]
Current timestep = 10341. State = [[-0.19984642  0.03235469]]. Action = [[ 0.08490819  0.07570947  0.         -0.60266995]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 10341 is [True, False, False, False, True, False]
Current timestep = 10342. State = [[-0.19731614  0.03271251]]. Action = [[ 0.01529493 -0.02306913  0.         -0.7165346 ]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 10342 is [True, False, False, False, True, False]
Current timestep = 10343. State = [[-0.20137736  0.02739621]]. Action = [[-0.09848017 -0.08637183  0.         -0.1361947 ]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 10343 is [True, False, False, False, True, False]
Current timestep = 10344. State = [[-0.20759135  0.02621314]]. Action = [[-0.07546563  0.03392584  0.          0.2669146 ]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 10344 is [True, False, False, False, True, False]
Current timestep = 10345. State = [[-0.20636438  0.027309  ]]. Action = [[ 0.08760681  0.0105245   0.         -0.71114004]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 10345 is [True, False, False, False, True, False]
Current timestep = 10346. State = [[-0.20137726  0.02742362]]. Action = [[0.06201477 0.00240992 0.         0.68401647]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 10346 is [True, False, False, False, True, False]
Current timestep = 10347. State = [[-0.20204785  0.02933794]]. Action = [[-0.05121759  0.04221518  0.         -0.12964404]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 10347 is [True, False, False, False, True, False]
Current timestep = 10348. State = [[-0.20784539  0.02615444]]. Action = [[-0.09378909 -0.09044554  0.         -0.02616417]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 10348 is [True, False, False, False, True, False]
Current timestep = 10349. State = [[-0.20663542  0.02478468]]. Action = [[ 0.08783077  0.02517756  0.         -0.21827525]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 10349 is [True, False, False, False, True, False]
State prediction error at timestep 10349 is 0.012
Human Feedback received at timestep 10349 of None
Current timestep = 10350. State = [[-0.20502815  0.0301357 ]]. Action = [[-0.01936201  0.09642396  0.         -0.6659292 ]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 10350 is [True, False, False, False, True, False]
Current timestep = 10351. State = [[-0.20518504  0.03561227]]. Action = [[ 0.00516085  0.04503455  0.         -0.43441504]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 10351 is [True, False, False, False, True, False]
Current timestep = 10352. State = [[-0.20609152  0.04165996]]. Action = [[-0.01643734  0.07738612  0.         -0.60464454]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 10352 is [True, False, False, False, True, False]
Current timestep = 10353. State = [[-0.20544828  0.04260014]]. Action = [[ 0.02956044 -0.04758769  0.         -0.12717938]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 10353 is [True, False, False, False, True, False]
Current timestep = 10354. State = [[-0.20084509  0.04000121]]. Action = [[ 0.07931044 -0.04166353  0.          0.70632386]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 10354 is [True, False, False, False, True, False]
Current timestep = 10355. State = [[-0.19692674  0.040595  ]]. Action = [[ 0.03044622  0.03016194  0.         -0.20918447]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 10355 is [True, False, False, False, True, False]
Current timestep = 10356. State = [[-0.19652416  0.04527962]]. Action = [[-0.01614452  0.06957997  0.          0.7008779 ]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 10356 is [True, False, False, False, True, False]
Current timestep = 10357. State = [[-0.19287169  0.04638733]]. Action = [[ 0.07875151 -0.03041108  0.         -0.50143236]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 10357 is [True, False, False, False, True, False]
Current timestep = 10358. State = [[-0.18839464  0.04904826]]. Action = [[0.03837792 0.06199706 0.         0.5710031 ]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 10358 is [True, False, False, False, True, False]
Current timestep = 10359. State = [[-0.19066288  0.04758683]]. Action = [[-0.09086253 -0.0762096   0.         -0.23390299]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 10359 is [True, False, False, False, True, False]
State prediction error at timestep 10359 is 0.012
Human Feedback received at timestep 10359 of None
Current timestep = 10360. State = [[-0.18902993  0.04369656]]. Action = [[ 0.07245158 -0.04434894  0.          0.35994935]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 10360 is [True, False, False, False, True, False]
State prediction error at timestep 10360 is 0.012
Human Feedback received at timestep 10360 of None
Current timestep = 10361. State = [[-0.18640968  0.04093806]]. Action = [[-0.00830265 -0.02780104  0.          0.7396529 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 10361 is [True, False, False, False, True, False]
Current timestep = 10362. State = [[-0.18947189  0.04044215]]. Action = [[-0.0882799   0.00724433  0.         -0.04882413]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 10362 is [True, False, False, False, True, False]
Current timestep = 10363. State = [[-0.1875103   0.04177826]]. Action = [[0.07643988 0.02274505 0.         0.700384  ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 10363 is [True, False, False, False, True, False]
Current timestep = 10364. State = [[-0.18271403  0.04396317]]. Action = [[ 0.03739967  0.03137036  0.         -0.55798894]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 10364 is [True, False, False, False, True, False]
State prediction error at timestep 10364 is 0.012
Human Feedback received at timestep 10364 of None
Current timestep = 10365. State = [[-0.18101265  0.04720332]]. Action = [[-0.00679542  0.04448121  0.         -0.62931335]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 10365 is [True, False, False, False, True, False]
Current timestep = 10366. State = [[-0.18258025  0.0472128 ]]. Action = [[-0.04641765 -0.03409922  0.         -0.12834579]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 10366 is [True, False, False, False, True, False]
Current timestep = 10367. State = [[-0.18030241  0.04574886]]. Action = [[ 0.05638952 -0.01777792  0.         -0.5815784 ]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 10367 is [True, False, False, False, True, False]
Current timestep = 10368. State = [[-0.18162769  0.04277341]]. Action = [[-0.08094424 -0.05243585  0.         -0.37272263]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 10368 is [True, False, False, False, True, False]
State prediction error at timestep 10368 is 0.012
Human Feedback received at timestep 10368 of None
Current timestep = 10369. State = [[-0.1787364   0.03832397]]. Action = [[ 0.09472936 -0.05695261  0.         -0.27802485]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 10369 is [True, False, False, False, True, False]
Current timestep = 10370. State = [[-0.17651124  0.03457109]]. Action = [[-0.03042053 -0.0306157   0.         -0.30652213]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 10370 is [True, False, False, False, True, False]
State prediction error at timestep 10370 is 0.012
Human Feedback received at timestep 10370 of None
Current timestep = 10371. State = [[-0.17734145  0.03768562]]. Action = [[-0.02351227  0.09141047  0.         -0.7540686 ]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 10371 is [True, False, False, False, True, False]
Current timestep = 10372. State = [[-0.17322944  0.04013526]]. Action = [[ 0.0924371   0.00178964  0.         -0.9195413 ]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 10372 is [True, False, False, False, True, False]
Current timestep = 10373. State = [[-0.16926582  0.03804524]]. Action = [[ 0.02113178 -0.0386337   0.         -0.98839325]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 10373 is [True, False, False, False, True, False]
Current timestep = 10374. State = [[-0.16337645  0.03638413]]. Action = [[ 9.347790e-02 -6.350875e-04  0.000000e+00 -8.419769e-01]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 10374 is [True, False, False, False, True, False]
Current timestep = 10375. State = [[-0.1631022   0.03403914]]. Action = [[-0.07142226 -0.0349972   0.         -0.42316604]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 10375 is [True, False, False, False, True, False]
Current timestep = 10376. State = [[-0.16479966  0.03589641]]. Action = [[-0.0062753   0.06461412  0.         -0.19396257]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 10376 is [True, False, False, False, True, False]
Current timestep = 10377. State = [[-0.16224705  0.03801022]]. Action = [[0.05905484 0.00933991 0.         0.48953128]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 10377 is [True, False, False, False, True, False]
Current timestep = 10378. State = [[-0.15650716  0.03560884]]. Action = [[ 0.08548027 -0.04955112  0.         -0.5889958 ]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 10378 is [True, False, False, False, True, False]
Current timestep = 10379. State = [[-0.15254493  0.03258004]]. Action = [[ 0.02378181 -0.02134264  0.          0.18597078]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 10379 is [True, False, False, False, True, False]
Current timestep = 10380. State = [[-0.15233539  0.03192448]]. Action = [[-0.02490127  0.01111977  0.         -0.4988017 ]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 10380 is [True, False, False, False, True, False]
State prediction error at timestep 10380 is 0.012
Human Feedback received at timestep 10380 of None
Current timestep = 10381. State = [[-0.153432    0.03616944]]. Action = [[-0.02088369  0.08415989  0.          0.31371832]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 10381 is [True, False, False, False, True, False]
State prediction error at timestep 10381 is 0.012
Human Feedback received at timestep 10381 of None
Current timestep = 10382. State = [[-0.15017664  0.03932641]]. Action = [[ 0.07553097  0.01216511  0.         -0.14457095]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 10382 is [True, False, False, False, True, False]
Current timestep = 10383. State = [[-0.14958084  0.04371872]]. Action = [[-0.0347729   0.07382125  0.         -0.51656425]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 10383 is [True, False, False, False, True, False]
Current timestep = 10384. State = [[-0.1509066   0.04437844]]. Action = [[-0.01374757 -0.04334892  0.         -0.8530594 ]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 10384 is [True, False, False, False, True, False]
State prediction error at timestep 10384 is 0.012
Human Feedback received at timestep 10384 of None
Current timestep = 10385. State = [[-0.15309347  0.04478607]]. Action = [[-0.04481874  0.01620839  0.          0.7229935 ]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 10385 is [True, False, False, False, True, False]
Current timestep = 10386. State = [[-0.15349366  0.04674659]]. Action = [[ 0.01126511  0.01433109  0.         -0.11197609]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 10386 is [True, False, False, False, True, False]
Current timestep = 10387. State = [[-0.15119989  0.04697303]]. Action = [[ 0.03844827 -0.01901425  0.          0.24735904]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 10387 is [True, False, False, False, True, False]
Current timestep = 10388. State = [[-0.14886035  0.04231552]]. Action = [[ 0.01762524 -0.09142334  0.          0.62765217]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 10388 is [True, False, False, False, True, False]
Current timestep = 10389. State = [[-0.15011083  0.03747795]]. Action = [[-0.05369156 -0.04473388  0.         -0.47279674]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 10389 is [True, False, False, False, True, False]
State prediction error at timestep 10389 is 0.012
Human Feedback received at timestep 10389 of None
Current timestep = 10390. State = [[-0.1543475   0.03885926]]. Action = [[-0.07440345  0.05648457  0.         -0.74648994]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 10390 is [True, False, False, False, True, False]
Current timestep = 10391. State = [[-0.1558615   0.04061881]]. Action = [[0.00600161 0.00071971 0.         0.5707749 ]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 10391 is [True, False, False, False, True, False]
State prediction error at timestep 10391 is 0.012
Human Feedback received at timestep 10391 of None
Current timestep = 10392. State = [[-0.15511511  0.03752545]]. Action = [[ 0.01126719 -0.06466539  0.         -0.00115049]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 10392 is [True, False, False, False, True, False]
State prediction error at timestep 10392 is 0.012
Human Feedback received at timestep 10392 of None
Current timestep = 10393. State = [[-0.15721543  0.03694684]]. Action = [[-0.05271954  0.02993173  0.         -0.9848106 ]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 10393 is [True, False, False, False, True, False]
Current timestep = 10394. State = [[-0.15861352  0.034956  ]]. Action = [[ 0.0019298  -0.05301785  0.         -0.74693084]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 10394 is [True, False, False, False, True, False]
Current timestep = 10395. State = [[-0.15939759  0.03331092]]. Action = [[-0.01367117  0.00345018  0.          0.6229594 ]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 10395 is [True, False, False, False, True, False]
Current timestep = 10396. State = [[-0.15992855  0.03162151]]. Action = [[ 0.00184219 -0.02657379  0.          0.869434  ]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 10396 is [True, False, False, False, True, False]
Current timestep = 10397. State = [[-0.1644362   0.02864311]]. Action = [[-0.08985911 -0.03614455  0.          0.4641738 ]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 10397 is [True, False, False, False, True, False]
Current timestep = 10398. State = [[-0.17157285  0.02743474]]. Action = [[-0.09033586  0.00283641  0.          0.77394235]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 10398 is [True, False, False, False, True, False]
Current timestep = 10399. State = [[-0.17918013  0.0298488 ]]. Action = [[-0.08686933  0.0497698   0.         -0.24161816]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 10399 is [True, False, False, False, True, False]
State prediction error at timestep 10399 is 0.012
Human Feedback received at timestep 10399 of None
Current timestep = 10400. State = [[-0.18302618  0.02804985]]. Action = [[-0.00161372 -0.06678733  0.          0.3406285 ]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 10400 is [True, False, False, False, True, False]
Current timestep = 10401. State = [[-0.18404377  0.02247875]]. Action = [[ 0.0097734  -0.06883369  0.          0.7331507 ]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 10401 is [True, False, False, False, True, False]
Current timestep = 10402. State = [[-0.18630904  0.02152804]]. Action = [[-0.02433841  0.03534036  0.         -0.8277827 ]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 10402 is [True, False, False, False, True, False]
Current timestep = 10403. State = [[-0.19149299  0.02663993]]. Action = [[-0.05774294  0.093278    0.          0.43894958]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 10403 is [True, False, False, False, True, False]
Current timestep = 10404. State = [[-0.19676238  0.02521053]]. Action = [[-0.03597705 -0.08331927  0.          0.3396746 ]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 10404 is [True, False, False, False, True, False]
Current timestep = 10405. State = [[-0.20169213  0.01853572]]. Action = [[-0.0476886  -0.08365034  0.          0.9326047 ]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 10405 is [True, False, False, False, True, False]
Current timestep = 10406. State = [[-0.20199795  0.01079632]]. Action = [[ 0.0496223  -0.09076016  0.          0.79831386]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 10406 is [True, False, False, False, True, False]
Current timestep = 10407. State = [[-0.20133086  0.01153963]]. Action = [[ 0.01562353  0.0952195   0.         -0.54752207]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 10407 is [True, False, False, False, True, False]
Current timestep = 10408. State = [[-0.20149322  0.00898733]]. Action = [[ 0.0151298  -0.08604847  0.          0.26907754]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 10408 is [True, False, False, False, True, False]
State prediction error at timestep 10408 is 0.012
Human Feedback received at timestep 10408 of None
Current timestep = 10409. State = [[-0.19872242  0.00121491]]. Action = [[ 0.06698609 -0.08484077  0.         -0.39648622]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 10409 is [True, False, False, False, True, False]
Current timestep = 10410. State = [[-0.19777733 -0.00226663]]. Action = [[-0.006788    0.01256806  0.          0.5572889 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 10410 is [True, False, False, False, True, False]
State prediction error at timestep 10410 is 0.012
Human Feedback received at timestep 10410 of None
Current timestep = 10411. State = [[-0.19993338 -0.00750741]]. Action = [[-0.03532855 -0.07968186  0.          0.72054493]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 10411 is [True, False, False, False, True, False]
Current timestep = 10412. State = [[-0.1986762  -0.01002559]]. Action = [[0.05004675 0.02768185 0.         0.8994278 ]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 10412 is [True, False, False, False, True, False]
Current timestep = 10413. State = [[-0.19594905 -0.01389673]]. Action = [[ 0.03407357 -0.05952858  0.          0.20288515]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 10413 is [True, False, False, False, True, False]
Current timestep = 10414. State = [[-0.1969149  -0.02211468]]. Action = [[-0.04370296 -0.09815617  0.         -0.65211344]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 10414 is [True, False, False, False, True, False]
Current timestep = 10415. State = [[-0.19400346 -0.02873919]]. Action = [[ 0.07755441 -0.03758245  0.          0.66203034]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 10415 is [True, False, False, False, True, False]
Current timestep = 10416. State = [[-0.19118625 -0.02691656]]. Action = [[0.00890414 0.09942345 0.         0.91597843]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 10416 is [True, False, False, False, True, False]
Current timestep = 10417. State = [[-0.19184129 -0.02948774]]. Action = [[-0.02501398 -0.08150895  0.         -0.5636873 ]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 10417 is [True, False, False, False, True, False]
Current timestep = 10418. State = [[-0.1958921  -0.03135212]]. Action = [[-0.07881711  0.0336344   0.         -0.74132025]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 10418 is [True, False, False, False, True, False]
Current timestep = 10419. State = [[-0.20254363 -0.03235208]]. Action = [[-0.09904052 -0.01862757  0.          0.6808336 ]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 10419 is [True, False, False, False, True, False]
Current timestep = 10420. State = [[-0.20472558 -0.03715946]]. Action = [[ 0.01346729 -0.07270069  0.         -0.19955021]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 10420 is [True, False, False, False, True, False]
Current timestep = 10421. State = [[-0.20715843 -0.04240784]]. Action = [[-0.05637479 -0.04554336  0.         -0.9002896 ]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 10421 is [True, False, False, False, True, False]
Current timestep = 10422. State = [[-0.20495589 -0.04144019]]. Action = [[ 0.08461425  0.06439824  0.         -0.79418445]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 10422 is [True, False, False, False, True, False]
Current timestep = 10423. State = [[-0.20496196 -0.04376069]]. Action = [[-0.04028578 -0.07211091  0.         -0.8150027 ]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 10423 is [True, False, False, False, True, False]
Current timestep = 10424. State = [[-0.20552152 -0.05046342]]. Action = [[ 0.01036723 -0.07890552  0.          0.7831677 ]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 10424 is [True, False, False, False, True, False]
Current timestep = 10425. State = [[-0.20586722 -0.05004726]]. Action = [[-0.00911161  0.07616527  0.         -0.20497048]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 10425 is [True, False, False, False, True, False]
Current timestep = 10426. State = [[-0.20634434 -0.05300044]]. Action = [[ 0.00095405 -0.08705404  0.          0.03405464]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 10426 is [True, False, False, False, True, False]
Current timestep = 10427. State = [[-0.20756753 -0.05471143]]. Action = [[-0.02213092  0.03111636  0.          0.9210305 ]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 10427 is [True, False, False, False, True, False]
Current timestep = 10428. State = [[-0.21061724 -0.05125972]]. Action = [[-0.04219861  0.06632604  0.          0.17165732]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 10428 is [True, False, False, False, True, False]
Current timestep = 10429. State = [[-0.2095535  -0.04635751]]. Action = [[ 0.06346067  0.06055932  0.         -0.43807948]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 10429 is [True, False, False, False, True, False]
State prediction error at timestep 10429 is 0.012
Human Feedback received at timestep 10429 of None
Current timestep = 10430. State = [[-0.20569764 -0.04127637]]. Action = [[0.06595469 0.05635508 0.         0.15556669]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 10430 is [True, False, False, False, True, False]
Current timestep = 10431. State = [[-0.20336632 -0.03538609]]. Action = [[ 0.03054065  0.06900174  0.         -0.40845108]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 10431 is [True, False, False, False, True, False]
State prediction error at timestep 10431 is 0.012
Human Feedback received at timestep 10431 of None
Current timestep = 10432. State = [[-0.2076735  -0.03585037]]. Action = [[-0.09554505 -0.06921998  0.         -0.9728915 ]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 10432 is [True, False, False, False, True, False]
State prediction error at timestep 10432 is 0.012
Human Feedback received at timestep 10432 of None
Current timestep = 10433. State = [[-0.2091993  -0.03504198]]. Action = [[0.03329075 0.03925217 0.         0.8955686 ]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 10433 is [True, False, False, False, True, False]
Current timestep = 10434. State = [[-0.21199164 -0.02839943]]. Action = [[-0.0611567   0.09336426  0.         -0.25125486]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 10434 is [True, False, False, False, True, False]
Current timestep = 10435. State = [[-0.21698435 -0.01981445]]. Action = [[-0.0514374   0.09035563  0.          0.8446423 ]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 10435 is [True, False, False, False, True, False]
Current timestep = 10436. State = [[-0.21807174 -0.01897137]]. Action = [[ 0.02815644 -0.07124186  0.          0.35328627]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 10436 is [True, False, False, False, True, False]
Current timestep = 10437. State = [[-0.21584827 -0.02449788]]. Action = [[ 0.04262581 -0.0971387   0.         -0.09227151]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 10437 is [True, False, False, False, True, False]
State prediction error at timestep 10437 is 0.012
Human Feedback received at timestep 10437 of None
Current timestep = 10438. State = [[-0.21057974 -0.02245685]]. Action = [[ 0.09238213  0.08932406  0.         -0.31416863]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 10438 is [True, False, False, False, True, False]
Current timestep = 10439. State = [[-0.20628332 -0.01587203]]. Action = [[ 0.04454205  0.06786228  0.         -0.9278    ]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 10439 is [True, False, False, False, True, False]
Current timestep = 10440. State = [[-0.20393378 -0.00976228]]. Action = [[0.02758289 0.06318084 0.         0.01297903]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 10440 is [True, False, False, False, True, False]
Current timestep = 10441. State = [[-0.19874844 -0.00608129]]. Action = [[ 0.09390915  0.01609905  0.         -0.41879815]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 10441 is [True, False, False, False, True, False]
State prediction error at timestep 10441 is 0.012
Human Feedback received at timestep 10441 of None
Current timestep = 10442. State = [[-0.19948967 -0.00632722]]. Action = [[-0.08425425 -0.03372777  0.          0.07059371]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 10442 is [True, False, False, False, True, False]
Current timestep = 10443. State = [[-0.20028329 -0.00485328]]. Action = [[0.02596075 0.0310654  0.         0.8054167 ]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 10443 is [True, False, False, False, True, False]
Current timestep = 10444. State = [[-0.20394298 -0.00637592]]. Action = [[-0.0938273  -0.06445614  0.          0.56794393]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 10444 is [True, False, False, False, True, False]
Current timestep = 10445. State = [[-0.20259139 -0.00992338]]. Action = [[ 0.07779262 -0.04613768  0.          0.47324324]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 10445 is [True, False, False, False, True, False]
Current timestep = 10446. State = [[-0.1952711  -0.01387724]]. Action = [[ 0.09161264 -0.05053252  0.         -0.44371367]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 10446 is [True, False, False, False, True, False]
State prediction error at timestep 10446 is 0.012
Human Feedback received at timestep 10446 of None
Current timestep = 10447. State = [[-0.19106305 -0.01877262]]. Action = [[ 0.00695463 -0.05778029  0.          0.13931775]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 10447 is [True, False, False, False, True, False]
State prediction error at timestep 10447 is 0.012
Human Feedback received at timestep 10447 of None
Current timestep = 10448. State = [[-0.19104971 -0.02308432]]. Action = [[-0.03834032 -0.03515372  0.         -0.57596517]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 10448 is [True, False, False, False, True, False]
Current timestep = 10449. State = [[-0.18691015 -0.02022648]]. Action = [[0.08151089 0.09900186 0.         0.48547077]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 10449 is [True, False, False, False, True, False]
State prediction error at timestep 10449 is 0.012
Human Feedback received at timestep 10449 of None
Current timestep = 10450. State = [[-0.18651116 -0.02118068]]. Action = [[-0.0625898  -0.06302923  0.          0.95320034]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 10450 is [True, False, False, False, True, False]
State prediction error at timestep 10450 is 0.012
Human Feedback received at timestep 10450 of None
Current timestep = 10451. State = [[-0.18272577 -0.02335622]]. Action = [[0.09413301 0.00482901 0.         0.5169374 ]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 10451 is [True, False, False, False, True, False]
Current timestep = 10452. State = [[-0.17560431 -0.02385434]]. Action = [[0.07349134 0.00522075 0.         0.41563797]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 10452 is [True, False, False, False, True, False]
Current timestep = 10453. State = [[-0.1765989  -0.02461912]]. Action = [[-0.09821913 -0.00438605  0.          0.75661635]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 10453 is [True, False, False, False, True, False]
Current timestep = 10454. State = [[-0.17480238 -0.02735779]]. Action = [[ 0.08070355 -0.04380909  0.         -0.27627373]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 10454 is [True, False, False, False, True, False]
Current timestep = 10455. State = [[-0.17048481 -0.03359693]]. Action = [[ 0.02261476 -0.08529638  0.         -0.1254617 ]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 10455 is [True, False, False, False, True, False]
Current timestep = 10456. State = [[-0.16447386 -0.0333389 ]]. Action = [[ 0.08455909  0.07580364  0.         -0.01187164]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 10456 is [True, False, False, False, True, False]
Current timestep = 10457. State = [[-0.15726523 -0.03133212]]. Action = [[0.08169693 0.01222537 0.         0.8940084 ]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 10457 is [True, False, False, False, True, False]
Current timestep = 10458. State = [[-0.1548805  -0.03507128]]. Action = [[-0.02328113 -0.07232098  0.         -0.6149031 ]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 10458 is [True, False, False, False, True, False]
State prediction error at timestep 10458 is 0.012
Human Feedback received at timestep 10458 of None
Current timestep = 10459. State = [[-0.1535616  -0.03431978]]. Action = [[0.01127136 0.06980205 0.         0.9650022 ]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 10459 is [True, False, False, False, True, False]
Current timestep = 10460. State = [[-0.15320101 -0.03429637]]. Action = [[-0.02164696 -0.03179378  0.         -0.82057333]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 10460 is [True, False, False, False, True, False]
State prediction error at timestep 10460 is 0.012
Human Feedback received at timestep 10460 of None
Current timestep = 10461. State = [[-0.1513832  -0.03279126]]. Action = [[0.02642507 0.05072176 0.         0.1882168 ]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 10461 is [True, False, False, False, True, False]
Current timestep = 10462. State = [[-0.15242119 -0.02694679]]. Action = [[-0.05195012  0.08524535  0.         -0.7091472 ]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 10462 is [True, False, False, False, True, False]
Current timestep = 10463. State = [[-0.15086228 -0.02299864]]. Action = [[ 0.05180783  0.0142864   0.         -0.9055541 ]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 10463 is [True, False, False, False, True, False]
Current timestep = 10464. State = [[-0.14812921 -0.02588014]]. Action = [[ 0.01675044 -0.08336862  0.         -0.19251841]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 10464 is [True, False, False, False, True, False]
Current timestep = 10465. State = [[-0.14684542 -0.02499992]]. Action = [[-1.6927719e-05  5.6721635e-02  0.0000000e+00  3.5072196e-01]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 10465 is [True, False, False, False, True, False]
Current timestep = 10466. State = [[-0.14779702 -0.02404273]]. Action = [[-0.03266287 -0.02321352  0.         -0.8774148 ]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 10466 is [True, False, False, False, True, False]
Current timestep = 10467. State = [[-0.15040828 -0.02777015]]. Action = [[-0.05169603 -0.07260466  0.          0.9497638 ]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 10467 is [True, False, False, False, True, False]
State prediction error at timestep 10467 is 0.012
Human Feedback received at timestep 10467 of None
Current timestep = 10468. State = [[-0.14843018 -0.02773654]]. Action = [[0.05766856 0.04005858 0.         0.6555798 ]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 10468 is [True, False, False, False, True, False]
State prediction error at timestep 10468 is 0.012
Human Feedback received at timestep 10468 of None
Current timestep = 10469. State = [[-0.14473881 -0.02430948]]. Action = [[0.03780732 0.04354358 0.         0.21427119]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 10469 is [True, False, False, False, True, False]
Current timestep = 10470. State = [[-0.14073713 -0.02449612]]. Action = [[ 0.05409149 -0.03460993  0.         -0.8683176 ]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 10470 is [True, False, False, False, True, False]
Current timestep = 10471. State = [[-0.1423987  -0.02336589]]. Action = [[-0.07920216  0.04087137  0.          0.45631063]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 10471 is [True, False, False, False, True, False]
Current timestep = 10472. State = [[-0.14520678 -0.01833983]]. Action = [[-0.01642215  0.07160277  0.          0.3172145 ]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 10472 is [True, False, False, False, True, False]
Current timestep = 10473. State = [[-0.14647269 -0.01614201]]. Action = [[-0.00978299 -0.01178129  0.          0.18523872]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 10473 is [True, False, False, False, True, False]
Current timestep = 10474. State = [[-0.14280993 -0.01484727]]. Action = [[ 0.08908046  0.0181094   0.         -0.3059284 ]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 10474 is [True, False, False, False, True, False]
Current timestep = 10475. State = [[-0.14072448 -0.01267128]]. Action = [[-0.0002569   0.02296392  0.         -0.059654  ]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 10475 is [True, False, False, False, True, False]
State prediction error at timestep 10475 is 0.012
Human Feedback received at timestep 10475 of None
Current timestep = 10476. State = [[-0.1419284  -0.00806128]]. Action = [[-0.02249084  0.06591756  0.          0.31586206]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 10476 is [True, False, False, False, True, False]
Current timestep = 10477. State = [[-0.13975714 -0.00856345]]. Action = [[ 0.06168074 -0.06454104  0.         -0.14436352]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 10477 is [True, False, False, False, True, False]
Current timestep = 10478. State = [[-0.13349842 -0.01418731]]. Action = [[ 0.09211939 -0.08366192  0.          0.07588828]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 10478 is [True, False, False, False, True, False]
State prediction error at timestep 10478 is 0.012
Human Feedback received at timestep 10478 of None
Current timestep = 10479. State = [[-0.12581201 -0.02115496]]. Action = [[ 0.09260768 -0.08236264  0.          0.2610879 ]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 10479 is [True, False, False, False, True, False]
Current timestep = 10480. State = [[-0.12406613 -0.02501533]]. Action = [[-0.0469919  -0.00988398  0.         -0.2927388 ]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 10480 is [True, False, False, False, True, False]
Current timestep = 10481. State = [[-0.12795778 -0.02921307]]. Action = [[-0.08361046 -0.058       0.          0.04361475]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 10481 is [True, False, False, False, True, False]
Current timestep = 10482. State = [[-0.13081098 -0.02726497]]. Action = [[-0.03403895  0.09175403  0.         -0.72445774]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 10482 is [True, False, False, False, True, False]
Current timestep = 10483. State = [[-0.12880698 -0.02133378]]. Action = [[ 0.0570787   0.07636078  0.         -0.55203307]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 10483 is [True, False, False, False, True, False]
Current timestep = 10484. State = [[-0.12306689 -0.01595349]]. Action = [[0.09104722 0.06099079 0.         0.3202536 ]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 10484 is [True, False, False, False, True, False]
Current timestep = 10485. State = [[-0.1176029  -0.00915938]]. Action = [[0.0684102  0.0926565  0.         0.79660606]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 10485 is [True, False, False, False, True, False]
Current timestep = 10486. State = [[-0.1138089  -0.00148425]]. Action = [[0.04643429 0.0848835  0.         0.54265785]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 10486 is [True, False, False, False, True, False]
State prediction error at timestep 10486 is 0.012
Human Feedback received at timestep 10486 of None
Current timestep = 10487. State = [[-0.10991814  0.0064423 ]]. Action = [[0.06102783 0.0853203  0.         0.05437529]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 10487 is [True, False, False, False, True, False]
Current timestep = 10488. State = [[-0.10589764  0.0109311 ]]. Action = [[ 0.05310587  0.01001962  0.         -0.26038504]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 10488 is [True, False, False, False, True, False]
Current timestep = 10489. State = [[-0.10327533  0.00975682]]. Action = [[ 0.01673035 -0.06199365  0.          0.26758194]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 10489 is [True, False, False, False, True, False]
Current timestep = 10490. State = [[-0.10258365  0.00449297]]. Action = [[-0.01879134 -0.09674376  0.          0.15436614]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 10490 is [True, False, False, False, True, False]
Current timestep = 10491. State = [[-0.10288091  0.00018507]]. Action = [[-0.03140844 -0.0469281   0.         -0.1742869 ]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 10491 is [True, False, False, False, True, False]
State prediction error at timestep 10491 is 0.012
Human Feedback received at timestep 10491 of None
Current timestep = 10492. State = [[-0.10573082  0.00282591]]. Action = [[-0.07881282  0.06986422  0.          0.8633106 ]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 10492 is [True, False, False, False, True, False]
Current timestep = 10493. State = [[-0.10471206  0.00317195]]. Action = [[ 0.03745247 -0.0478778   0.          0.18679357]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 10493 is [True, False, False, False, True, False]
Current timestep = 10494. State = [[-0.10055436  0.00666948]]. Action = [[ 0.04145562  0.08689845  0.         -0.16490269]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 10494 is [True, False, False, False, True, False]
Current timestep = 10495. State = [[-0.10217838  0.00878257]]. Action = [[-0.08096321 -0.01941429  0.          0.40957582]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 10495 is [True, False, False, False, True, False]
Current timestep = 10496. State = [[-0.09969205  0.00918222]]. Action = [[ 0.08694804  0.0048617   0.         -0.9902094 ]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 10496 is [True, False, False, False, True, False]
Current timestep = 10497. State = [[-0.09606808  0.0142699 ]]. Action = [[ 0.01215328  0.0916832   0.         -0.36701518]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 10497 is [True, False, False, False, True, False]
Current timestep = 10498. State = [[-0.09129589  0.01728502]]. Action = [[ 0.07753748 -0.00491954  0.         -0.7174201 ]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 10498 is [True, False, False, False, True, False]
Current timestep = 10499. State = [[-0.08636668  0.01886031]]. Action = [[0.0455581  0.02287781 0.         0.19954443]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 10499 is [True, False, False, False, True, False]
Current timestep = 10500. State = [[-0.0853937   0.01764473]]. Action = [[-0.02467183 -0.04656237  0.         -0.79210794]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 10500 is [True, False, False, False, True, False]
Current timestep = 10501. State = [[-0.08357125  0.01820211]]. Action = [[0.02895253 0.03034606 0.         0.29064226]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 10501 is [True, False, False, False, True, False]
Current timestep = 10502. State = [[-0.08498405  0.02221384]]. Action = [[-0.06316903  0.0548814   0.         -0.38518375]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 10502 is [True, False, False, False, True, False]
Current timestep = 10503. State = [[-0.08686383  0.02941506]]. Action = [[-0.01631458  0.09305339  0.          0.31832147]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 10503 is [True, False, False, False, True, False]
Current timestep = 10504. State = [[-0.09026291  0.03725152]]. Action = [[-0.06223631  0.07278886  0.          0.8079256 ]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 10504 is [True, False, False, False, True, False]
Current timestep = 10505. State = [[-0.09286163  0.03786504]]. Action = [[-0.02063824 -0.0689683   0.         -0.09907711]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 10505 is [True, False, False, False, True, False]
Current timestep = 10506. State = [[-0.09106234  0.03958893]]. Action = [[ 0.0488958   0.04270376  0.         -0.5145478 ]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 10506 is [True, False, False, False, True, False]
State prediction error at timestep 10506 is 0.012
Human Feedback received at timestep 10506 of None
Current timestep = 10507. State = [[-0.09017511  0.04192001]]. Action = [[-0.00474672 -0.00132618  0.         -0.22481072]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 10507 is [True, False, False, False, True, False]
State prediction error at timestep 10507 is 0.012
Human Feedback received at timestep 10507 of None
Current timestep = 10508. State = [[-0.09315193  0.03959963]]. Action = [[-0.06263149 -0.07007635  0.         -0.3166198 ]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 10508 is [True, False, False, False, True, False]
Current timestep = 10509. State = [[-0.0918797   0.03352101]]. Action = [[ 0.0548246  -0.09512816  0.          0.5708914 ]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 10509 is [True, False, False, False, True, False]
Current timestep = 10510. State = [[-0.0925891   0.02724054]]. Action = [[-0.05976279 -0.06752029  0.          0.04690313]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 10510 is [True, False, False, False, True, False]
Current timestep = 10511. State = [[-0.09619298  0.02841192]]. Action = [[-0.05509486  0.0719379   0.         -0.3286245 ]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 10511 is [True, False, False, False, True, False]
Current timestep = 10512. State = [[-0.09680665  0.03229177]]. Action = [[ 0.02014949  0.04094303  0.         -0.700256  ]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 10512 is [True, False, False, False, True, False]
Current timestep = 10513. State = [[-0.09332282  0.03637548]]. Action = [[0.07435671 0.05854037 0.         0.5025823 ]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 10513 is [True, False, False, False, True, False]
State prediction error at timestep 10513 is 0.012
Human Feedback received at timestep 10513 of None
Current timestep = 10514. State = [[-0.09400866  0.0404857 ]]. Action = [[-0.04155569  0.04726062  0.          0.98664415]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 10514 is [True, False, False, False, True, False]
Current timestep = 10515. State = [[-0.09595376  0.04097065]]. Action = [[-0.00233079 -0.02584815  0.          0.94365156]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 10515 is [True, False, False, False, True, False]
Current timestep = 10516. State = [[-0.09291716  0.0385836 ]]. Action = [[ 0.07892289 -0.03693012  0.          0.08893144]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 10516 is [True, False, False, False, True, False]
State prediction error at timestep 10516 is 0.012
Human Feedback received at timestep 10516 of None
Current timestep = 10517. State = [[-0.08806376  0.03213479]]. Action = [[ 0.06416754 -0.09962981  0.         -0.4015537 ]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 10517 is [True, False, False, False, True, False]
Current timestep = 10518. State = [[-0.08157577  0.02658644]]. Action = [[ 0.09368195 -0.0325141   0.         -0.68288517]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 10518 is [True, False, False, False, True, False]
Current timestep = 10519. State = [[-0.07617196  0.02205187]]. Action = [[ 0.04857547 -0.04056031  0.          0.15999508]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 10519 is [True, False, False, False, True, False]
Current timestep = 10520. State = [[-0.07239056  0.02033038]]. Action = [[0.03380508 0.02215216 0.         0.5463598 ]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 10520 is [True, False, False, False, True, False]
Current timestep = 10521. State = [[-0.07340293  0.01565395]]. Action = [[-0.06404389 -0.07661355  0.         -0.24213243]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 10521 is [True, False, False, False, True, False]
Current timestep = 10522. State = [[-0.07542984  0.01330109]]. Action = [[-0.03359476  0.02188291  0.          0.934145  ]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 10522 is [True, False, False, False, True, False]
Current timestep = 10523. State = [[-0.07107906  0.00792335]]. Action = [[ 0.0940752  -0.09386709  0.         -0.7982232 ]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 10523 is [True, False, False, False, True, False]
Current timestep = 10524. State = [[-0.07118818  0.00478269]]. Action = [[-0.08838373  0.01931077  0.         -0.05979246]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 10524 is [True, False, False, False, True, False]
State prediction error at timestep 10524 is 0.012
Human Feedback received at timestep 10524 of None
Current timestep = 10525. State = [[-0.07696332  0.00459379]]. Action = [[-0.09151085  0.00573428  0.          0.49620485]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 10525 is [True, False, False, False, True, False]
State prediction error at timestep 10525 is 0.012
Human Feedback received at timestep 10525 of None
Current timestep = 10526. State = [[-0.07761295  0.00872036]]. Action = [[0.03921624 0.08831263 0.         0.62164927]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 10526 is [True, False, False, False, True, False]
Current timestep = 10527. State = [[-0.07270864  0.00621515]]. Action = [[ 0.0846479  -0.09687131  0.          0.03725696]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 10527 is [True, False, False, False, True, False]
Current timestep = 10528. State = [[-0.07059213  0.00739254]]. Action = [[-0.00344373  0.08924762  0.         -0.80907226]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 10528 is [True, False, False, False, True, False]
State prediction error at timestep 10528 is 0.012
Human Feedback received at timestep 10528 of None
Current timestep = 10529. State = [[-0.06764573  0.01339877]]. Action = [[0.06655621 0.07306053 0.         0.7368196 ]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 10529 is [True, False, False, False, True, False]
Current timestep = 10530. State = [[-0.06545116  0.01254897]]. Action = [[ 0.01423287 -0.06578892  0.         -0.52884805]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 10530 is [True, False, False, False, True, False]
Current timestep = 10531. State = [[-0.0606247   0.00637216]]. Action = [[ 0.08619346 -0.08651113  0.         -0.12253076]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 10531 is [True, False, False, False, True, False]
Current timestep = 10532. State = [[-0.06061901  0.00790709]]. Action = [[-0.06242568  0.09188765  0.         -0.9584845 ]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 10532 is [True, False, False, False, True, False]
State prediction error at timestep 10532 is 0.012
Human Feedback received at timestep 10532 of None
Current timestep = 10533. State = [[-0.06399064  0.00759015]]. Action = [[-0.04416058 -0.05939431  0.          0.49314868]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 10533 is [True, False, False, False, True, False]
Current timestep = 10534. State = [[-0.06485453  0.00637796]]. Action = [[-1.2971461e-05  5.2743927e-03  0.0000000e+00  4.3710160e-01]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 10534 is [True, False, False, False, True, False]
Current timestep = 10535. State = [[-0.06596402  0.0044358 ]]. Action = [[-0.02925585 -0.04160178  0.          0.31977153]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 10535 is [True, False, False, False, True, False]
State prediction error at timestep 10535 is 0.012
Human Feedback received at timestep 10535 of None
Current timestep = 10536. State = [[-0.06687084  0.00736161]]. Action = [[-0.00866408  0.08209813  0.          0.7498627 ]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 10536 is [True, False, False, False, True, False]
State prediction error at timestep 10536 is 0.012
Human Feedback received at timestep 10536 of None
Current timestep = 10537. State = [[-0.07039072  0.0141083 ]]. Action = [[-0.0649382   0.08001221  0.          0.38061643]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 10537 is [True, False, False, False, True, False]
Current timestep = 10538. State = [[-0.07432449  0.01584488]]. Action = [[-0.03990387 -0.03314658  0.         -0.11084443]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 10538 is [True, False, False, False, True, False]
State prediction error at timestep 10538 is 0.012
Human Feedback received at timestep 10538 of None
Current timestep = 10539. State = [[-0.07197527  0.0138333 ]]. Action = [[ 0.08216503 -0.03881481  0.          0.5335895 ]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 10539 is [True, False, False, False, True, False]
Current timestep = 10540. State = [[-0.07188316  0.0155294 ]]. Action = [[-0.03929975  0.05016992  0.          0.33604813]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 10540 is [True, False, False, False, True, False]
Current timestep = 10541. State = [[-0.07571421  0.0196092 ]]. Action = [[-0.05234907  0.0413297   0.          0.46280503]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 10541 is [True, False, False, False, True, False]
State prediction error at timestep 10541 is 0.012
Human Feedback received at timestep 10541 of None
Current timestep = 10542. State = [[-0.07771122  0.026639  ]]. Action = [[ 0.00205584  0.09707265  0.         -0.9664524 ]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 10542 is [True, False, False, False, True, False]
Current timestep = 10543. State = [[-0.07524145  0.02841381]]. Action = [[ 0.07157115 -0.04348127  0.         -0.92293787]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 10543 is [True, False, False, False, True, False]
State prediction error at timestep 10543 is 0.012
Human Feedback received at timestep 10543 of None
Current timestep = 10544. State = [[-0.07736924  0.02578425]]. Action = [[-0.07862813 -0.04622295  0.         -0.9231888 ]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 10544 is [True, False, False, False, True, False]
Current timestep = 10545. State = [[-0.08383826  0.02533264]]. Action = [[-0.08127538  0.00474085  0.         -0.8017033 ]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 10545 is [True, False, False, False, True, False]
State prediction error at timestep 10545 is 0.012
Human Feedback received at timestep 10545 of None
Current timestep = 10546. State = [[-0.08845013  0.02567804]]. Action = [[-0.03398673 -0.00832137  0.         -0.8228191 ]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 10546 is [True, False, False, False, True, False]
Current timestep = 10547. State = [[-0.08717752  0.0237379 ]]. Action = [[ 0.06560414 -0.04190779  0.         -0.8541705 ]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 10547 is [True, False, False, False, True, False]
State prediction error at timestep 10547 is 0.012
Human Feedback received at timestep 10547 of None
Current timestep = 10548. State = [[-0.08989182  0.0246713 ]]. Action = [[-0.08032353  0.04307664  0.         -0.9439222 ]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 10548 is [True, False, False, False, True, False]
Current timestep = 10549. State = [[-0.09471095  0.02398942]]. Action = [[-0.03609673 -0.04128847  0.          0.32435346]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 10549 is [True, False, False, False, True, False]
Current timestep = 10550. State = [[-0.09253693  0.02106639]]. Action = [[ 0.09207097 -0.03321631  0.         -0.07695109]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 10550 is [True, False, False, False, True, False]
State prediction error at timestep 10550 is 0.012
Human Feedback received at timestep 10550 of None
Current timestep = 10551. State = [[-0.08873306  0.01459249]]. Action = [[ 0.04371163 -0.09487021  0.          0.42721498]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 10551 is [True, False, False, False, True, False]
Current timestep = 10552. State = [[-0.08548036  0.00670321]]. Action = [[ 0.04419278 -0.07678182  0.         -0.64591545]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 10552 is [True, False, False, False, True, False]
Current timestep = 10553. State = [[-0.08161771  0.00422648]]. Action = [[ 0.05391654  0.03236724  0.         -0.39173198]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 10553 is [True, False, False, False, True, False]
State prediction error at timestep 10553 is 0.012
Human Feedback received at timestep 10553 of None
Current timestep = 10554. State = [[-0.07589766  0.00298676]]. Action = [[ 0.08868777 -0.00397639  0.         -0.6758429 ]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 10554 is [True, False, False, False, True, False]
State prediction error at timestep 10554 is 0.012
Human Feedback received at timestep 10554 of None
Current timestep = 10555. State = [[-0.07389992  0.00498432]]. Action = [[-0.01027836  0.07706847  0.         -0.48078036]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 10555 is [True, False, False, False, True, False]
Current timestep = 10556. State = [[-0.072336    0.00989248]]. Action = [[0.03872428 0.07768501 0.         0.32684517]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 10556 is [True, False, False, False, True, False]
Current timestep = 10557. State = [[-0.07049767  0.01113933]]. Action = [[ 0.01960747 -0.00956558  0.         -0.9462884 ]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 10557 is [True, False, False, False, True, False]
Current timestep = 10558. State = [[-0.06670442  0.00885433]]. Action = [[ 0.06232011 -0.03412093  0.          0.53568363]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 10558 is [True, False, False, False, True, False]
State prediction error at timestep 10558 is 0.012
Human Feedback received at timestep 10558 of None
Current timestep = 10559. State = [[-0.06743551  0.01193705]]. Action = [[-0.06189209  0.08772092  0.          0.8999213 ]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 10559 is [True, False, False, False, True, False]
Current timestep = 10560. State = [[-0.07302843  0.01776068]]. Action = [[-0.09107438  0.05709944  0.         -0.6841092 ]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 10560 is [True, False, False, False, True, False]
Current timestep = 10561. State = [[-0.07967748  0.02035953]]. Action = [[-0.09326132 -0.00791585  0.         -0.7664331 ]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 10561 is [True, False, False, False, True, False]
State prediction error at timestep 10561 is 0.012
Human Feedback received at timestep 10561 of None
Current timestep = 10562. State = [[-0.08024947  0.01934249]]. Action = [[ 0.04258872 -0.04509125  0.          0.09354162]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 10562 is [True, False, False, False, True, False]
Current timestep = 10563. State = [[-0.07848299  0.02139896]]. Action = [[0.01083757 0.04697549 0.         0.30808353]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 10563 is [True, False, False, False, True, False]
Current timestep = 10564. State = [[-0.07581247  0.02601997]]. Action = [[ 0.04924161  0.04654139  0.         -0.93190247]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 10564 is [True, False, False, False, True, False]
State prediction error at timestep 10564 is 0.012
Human Feedback received at timestep 10564 of None
Current timestep = 10565. State = [[-0.07222587  0.0233475 ]]. Action = [[ 0.04735703 -0.09839445  0.         -0.46573937]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 10565 is [True, False, False, False, True, False]
Current timestep = 10566. State = [[-0.06948978  0.02384529]]. Action = [[0.02322237 0.06039792 0.         0.7502909 ]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 10566 is [True, False, False, False, True, False]
Current timestep = 10567. State = [[-0.06929789  0.02187051]]. Action = [[-0.01757363 -0.07827333  0.         -0.70432764]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 10567 is [True, False, False, False, True, False]
Current timestep = 10568. State = [[-0.06772483  0.02137075]]. Action = [[ 0.02908542  0.03250808  0.         -0.44714653]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 10568 is [True, False, False, False, True, False]
Current timestep = 10569. State = [[-0.06520963  0.01789778]]. Action = [[ 0.02373652 -0.08412106  0.          0.25003684]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 10569 is [True, False, False, False, True, False]
State prediction error at timestep 10569 is 0.012
Human Feedback received at timestep 10569 of None
Current timestep = 10570. State = [[-0.06762777  0.01333448]]. Action = [[-0.08623882 -0.03599324  0.          0.5006553 ]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 10570 is [True, False, False, False, True, False]
Current timestep = 10571. State = [[-0.06500171  0.00789252]]. Action = [[ 0.09230744 -0.07326045  0.         -0.53476804]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 10571 is [True, False, False, False, True, False]
State prediction error at timestep 10571 is 0.012
Human Feedback received at timestep 10571 of None
Current timestep = 10572. State = [[-0.06170145  0.00846795]]. Action = [[-0.00421734  0.0772304   0.         -0.88499427]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 10572 is [True, False, False, False, True, False]
Current timestep = 10573. State = [[-0.05728916  0.01285964]]. Action = [[ 0.07535029  0.06040599  0.         -0.06050956]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 10573 is [True, False, False, False, True, False]
Current timestep = 10574. State = [[-0.05696262  0.01634267]]. Action = [[-0.04953296  0.03992725  0.         -0.5124745 ]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 10574 is [True, False, False, False, True, False]
Current timestep = 10575. State = [[-0.05889469  0.01408877]]. Action = [[-0.02568865 -0.07176732  0.         -0.8821296 ]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 10575 is [True, False, False, False, True, False]
Current timestep = 10576. State = [[-0.05750804  0.01093279]]. Action = [[ 0.03073054 -0.02158032  0.          0.4126835 ]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 10576 is [True, False, False, False, True, False]
State prediction error at timestep 10576 is 0.012
Human Feedback received at timestep 10576 of None
Current timestep = 10577. State = [[-0.05247925  0.0051567 ]]. Action = [[ 0.07577833 -0.09304471  0.          0.19086003]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 10577 is [True, False, False, False, True, False]
Current timestep = 10578. State = [[-0.05199321 -0.00033019]]. Action = [[-0.0534209  -0.03832488  0.          0.9440315 ]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 10578 is [True, False, False, False, True, False]
Current timestep = 10579. State = [[-0.05056741 -0.00501834]]. Action = [[ 0.04190388 -0.04921564  0.          0.0216254 ]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 10579 is [True, False, False, False, True, False]
Current timestep = 10580. State = [[-0.33152166  0.12044749]]. Action = [[ 0.01004563 -0.07380109  0.          0.9441283 ]]. Reward = [100.]
Curr episode timestep = 786
Scene graph at timestep 10580 is [True, False, False, False, True, False]
Current timestep = 10581. State = [[-0.32911572  0.1246658 ]]. Action = [[0.04873695 0.01917366 0.         0.16291499]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 10581 is [True, False, False, False, True, False]
Current timestep = 10582. State = [[-0.32939425  0.1225223 ]]. Action = [[-0.03169237 -0.06920458  0.          0.68552566]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 10582 is [True, False, False, False, True, False]
State prediction error at timestep 10582 is 0.012
Human Feedback received at timestep 10582 of None
Current timestep = 10583. State = [[-0.33356443  0.12438885]]. Action = [[-0.06854686  0.05998423  0.         -0.35767007]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 10583 is [True, False, False, False, True, False]
State prediction error at timestep 10583 is 0.012
Human Feedback received at timestep 10583 of None
Current timestep = 10584. State = [[-0.33948043  0.12435377]]. Action = [[-0.07760791 -0.06122911  0.         -0.79573935]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 10584 is [True, False, False, False, True, False]
Current timestep = 10585. State = [[-0.34122923  0.12268952]]. Action = [[ 0.01023626 -0.02668224  0.         -0.50745994]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 10585 is [True, False, False, False, True, False]
Current timestep = 10586. State = [[-0.3445254   0.12129946]]. Action = [[-0.07231572 -0.0297685   0.          0.60834026]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 10586 is [True, False, False, False, True, False]
Current timestep = 10587. State = [[-0.34778097  0.12592426]]. Action = [[-0.01761736  0.09562758  0.         -0.20989537]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 10587 is [True, False, False, False, True, False]
Current timestep = 10588. State = [[-0.34461895  0.1260657 ]]. Action = [[ 0.09211161 -0.06502871  0.         -0.6233083 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 10588 is [True, False, False, False, False, True]
State prediction error at timestep 10588 is 0.012
Human Feedback received at timestep 10588 of None
Current timestep = 10589. State = [[-0.34187242  0.1236502 ]]. Action = [[ 0.00739893 -0.00917192  0.         -0.3832358 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 10589 is [True, False, False, False, False, True]
State prediction error at timestep 10589 is 0.012
Human Feedback received at timestep 10589 of None
Current timestep = 10590. State = [[-0.3401978   0.12651756]]. Action = [[0.02966387 0.07075816 0.         0.9271281 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 10590 is [True, False, False, False, True, False]
Current timestep = 10591. State = [[-0.34417838  0.12938468]]. Action = [[-0.09454785  0.01567228  0.         -0.03467512]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10591 is [True, False, False, False, False, True]
Current timestep = 10592. State = [[-0.35211134  0.13088793]]. Action = [[-0.09436069  0.00811891  0.         -0.7525545 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 10592 is [True, False, False, False, False, True]
State prediction error at timestep 10592 is 0.012
Human Feedback received at timestep 10592 of None
Current timestep = 10593. State = [[-0.35886145  0.13275133]]. Action = [[-0.05852013  0.01670619  0.          0.69857264]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 10593 is [True, False, False, False, False, True]
Current timestep = 10594. State = [[-0.36565682  0.13544059]]. Action = [[-0.07111598  0.02849873  0.          0.10178506]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 10594 is [True, False, False, False, False, True]
Current timestep = 10595. State = [[-0.37130362  0.1418117 ]]. Action = [[-0.03028787  0.09584779  0.         -0.64344764]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 10595 is [True, False, False, False, False, True]
Current timestep = 10596. State = [[-0.37439632  0.14899018]]. Action = [[0.01241858 0.07666726 0.         0.7854936 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 10596 is [True, False, False, False, False, True]
Current timestep = 10597. State = [[-0.37850884  0.15594925]]. Action = [[-0.03118023  0.08277225  0.         -0.9053404 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 10597 is [True, False, False, False, False, True]
Current timestep = 10598. State = [[-0.38208535  0.15916501]]. Action = [[ 0.         0.         0.        -0.9541752]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 10598 is [True, False, False, False, False, True]
Current timestep = 10599. State = [[-0.38428214  0.16011776]]. Action = [[0.         0.         0.         0.61224484]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 10599 is [True, False, False, False, False, True]
State prediction error at timestep 10599 is 0.012
Human Feedback received at timestep 10599 of None
Current timestep = 10600. State = [[-0.38191873  0.15770331]]. Action = [[ 0.07912097 -0.0619783   0.          0.73091125]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 10600 is [True, False, False, False, False, True]
State prediction error at timestep 10600 is 0.012
Human Feedback received at timestep 10600 of None
Current timestep = 10601. State = [[-0.38035062  0.15622027]]. Action = [[ 0.         0.         0.        -0.5238626]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 10601 is [True, False, False, False, False, True]
Current timestep = 10602. State = [[-0.37967193  0.15346791]]. Action = [[ 0.01514206 -0.0628911   0.          0.40013528]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 10602 is [True, False, False, False, False, True]
Current timestep = 10603. State = [[-0.37891275  0.1519832 ]]. Action = [[0.         0.         0.         0.67537344]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 10603 is [True, False, False, False, False, True]
State prediction error at timestep 10603 is 0.012
Human Feedback received at timestep 10603 of None
Current timestep = 10604. State = [[-0.37646854  0.1563326 ]]. Action = [[ 0.04546464  0.09129096  0.         -0.20800859]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 10604 is [True, False, False, False, False, True]
State prediction error at timestep 10604 is 0.012
Human Feedback received at timestep 10604 of None
Current timestep = 10605. State = [[-0.37089473  0.15414682]]. Action = [[ 0.07925346 -0.09332114  0.         -0.47610116]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 10605 is [True, False, False, False, False, True]
Current timestep = 10606. State = [[-0.36339572  0.15381007]]. Action = [[0.08372188 0.06107325 0.         0.30126083]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 10606 is [True, False, False, False, False, True]
Current timestep = 10607. State = [[-0.3595252   0.15479845]]. Action = [[0.00351468 0.00148575 0.         0.89801574]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 10607 is [True, False, False, False, False, True]
Current timestep = 10608. State = [[-0.36140203  0.15197971]]. Action = [[-0.07350812 -0.06081745  0.         -0.64804405]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 10608 is [True, False, False, False, False, True]
Current timestep = 10609. State = [[-0.35810533  0.1506065 ]]. Action = [[ 0.08797898  0.00941853  0.         -0.96066666]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 10609 is [True, False, False, False, False, True]
State prediction error at timestep 10609 is 0.012
Human Feedback received at timestep 10609 of None
Current timestep = 10610. State = [[-0.3579906   0.15475233]]. Action = [[-0.07557484  0.08137157  0.          0.23800933]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 10610 is [True, False, False, False, False, True]
Current timestep = 10611. State = [[-0.35864744  0.162186  ]]. Action = [[ 0.0149878   0.09178839  0.         -0.24868155]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 10611 is [True, False, False, False, False, True]
Current timestep = 10612. State = [[-0.36284262  0.17000188]]. Action = [[-0.08912304  0.08679352  0.         -0.21088886]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 10612 is [True, False, False, False, False, True]
Current timestep = 10613. State = [[-0.36774543  0.17600554]]. Action = [[-0.03338301  0.04108914  0.         -0.87824416]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 10613 is [True, False, False, False, False, True]
Current timestep = 10614. State = [[-0.36801574  0.17521478]]. Action = [[ 0.03079908 -0.07257047  0.         -0.12100965]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 10614 is [True, False, False, False, False, True]
State prediction error at timestep 10614 is 0.012
Human Feedback received at timestep 10614 of None
Current timestep = 10615. State = [[-0.3645817   0.17507702]]. Action = [[0.05831986 0.01621495 0.         0.1140337 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 10615 is [True, False, False, False, False, True]
Current timestep = 10616. State = [[-0.3616845   0.17856118]]. Action = [[ 0.02796002  0.0498649   0.         -0.51841223]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 10616 is [True, False, False, False, False, True]
Current timestep = 10617. State = [[-0.36341107  0.18178119]]. Action = [[-0.04970571  0.01864769  0.          0.1178652 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 10617 is [True, False, False, False, False, True]
Current timestep = 10618. State = [[-0.36233792  0.18154223]]. Action = [[ 0.05031899 -0.0390495   0.          0.38264048]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 10618 is [True, False, False, False, False, True]
State prediction error at timestep 10618 is 0.012
Human Feedback received at timestep 10618 of None
Current timestep = 10619. State = [[-0.36220443  0.18478   ]]. Action = [[-0.02824582  0.07366053  0.          0.840253  ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 10619 is [True, False, False, False, False, True]
Current timestep = 10620. State = [[-0.36406446  0.19166607]]. Action = [[-0.01479459  0.08104063  0.         -0.84481335]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 10620 is [True, False, False, False, False, True]
Current timestep = 10621. State = [[-0.3604459   0.19126688]]. Action = [[ 0.08926324 -0.07618959  0.         -0.6144022 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 10621 is [True, False, False, False, False, True]
Current timestep = 10622. State = [[-0.3570818  0.1862099]]. Action = [[ 0.0036367  -0.07210155  0.         -0.89202744]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 10622 is [True, False, False, False, False, True]
Current timestep = 10623. State = [[-0.35435385  0.18504423]]. Action = [[ 0.03010383  0.00999751  0.         -0.07787228]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 10623 is [True, False, False, False, False, True]
Current timestep = 10624. State = [[-0.34866157  0.18871723]]. Action = [[ 0.08079762  0.07277817  0.         -0.95951   ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 10624 is [True, False, False, False, False, True]
Current timestep = 10625. State = [[-0.3498609  0.1943499]]. Action = [[-0.08723434  0.07237103  0.         -0.09713441]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 10625 is [True, False, False, False, False, True]
Current timestep = 10626. State = [[-0.34772745  0.20063436]]. Action = [[0.09331319 0.08148239 0.         0.46858907]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 10626 is [True, False, False, False, False, True]
Current timestep = 10627. State = [[-0.3406265   0.19976567]]. Action = [[ 0.08264486 -0.06655971  0.         -0.90587944]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 10627 is [True, False, False, False, False, True]
Current timestep = 10628. State = [[-0.33378896  0.19393627]]. Action = [[ 0.05998655 -0.08517621  0.         -0.34757006]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 10628 is [True, False, False, False, False, True]
Current timestep = 10629. State = [[-0.33280164  0.19266932]]. Action = [[-0.05374135  0.0207594   0.         -0.1205222 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 10629 is [True, False, False, False, False, True]
Current timestep = 10630. State = [[-0.32888037  0.19431846]]. Action = [[ 0.08005454  0.0145638   0.         -0.11409277]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 10630 is [True, False, False, False, False, True]
State prediction error at timestep 10630 is 0.012
Human Feedback received at timestep 10630 of None
Current timestep = 10631. State = [[-0.32235467  0.19206552]]. Action = [[ 0.05406559 -0.05561465  0.          0.54839075]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 10631 is [True, False, False, False, False, True]
State prediction error at timestep 10631 is 0.012
Human Feedback received at timestep 10631 of None
Current timestep = 10632. State = [[-0.31548107  0.19333503]]. Action = [[0.06806371 0.06198769 0.         0.2724843 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 10632 is [True, False, False, False, False, True]
Current timestep = 10633. State = [[-0.3091725   0.19700123]]. Action = [[0.05263247 0.04936922 0.         0.64911187]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 10633 is [True, False, False, False, False, True]
Current timestep = 10634. State = [[-0.30673012  0.19875462]]. Action = [[-0.01681846  0.00775979  0.          0.46500993]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 10634 is [True, False, False, False, False, True]
Current timestep = 10635. State = [[-0.30787033  0.19862413]]. Action = [[-0.04808975 -0.01966269  0.         -0.9788099 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 10635 is [True, False, False, False, False, True]
State prediction error at timestep 10635 is 0.012
Human Feedback received at timestep 10635 of None
Current timestep = 10636. State = [[-0.30687922  0.19592072]]. Action = [[ 0.01737426 -0.06140691  0.          0.24543679]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 10636 is [True, False, False, False, False, True]
Current timestep = 10637. State = [[-0.3028379   0.19351847]]. Action = [[ 0.04172856 -0.02319215  0.          0.3031032 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 10637 is [True, False, False, False, False, True]
State prediction error at timestep 10637 is 0.012
Human Feedback received at timestep 10637 of None
Current timestep = 10638. State = [[-0.2968586   0.19703047]]. Action = [[ 0.07154811  0.08864539  0.         -0.37545288]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 10638 is [True, False, False, False, False, True]
Current timestep = 10639. State = [[-0.29145607  0.20272174]]. Action = [[0.04944085 0.07306296 0.         0.33317542]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 10639 is [True, False, False, False, False, True]
Current timestep = 10640. State = [[-0.28518778  0.20206676]]. Action = [[ 0.0751574  -0.05408704  0.          0.24496889]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 10640 is [True, False, False, False, False, True]
State prediction error at timestep 10640 is 0.012
Human Feedback received at timestep 10640 of None
Current timestep = 10641. State = [[-0.2802112   0.19699228]]. Action = [[ 0.02236192 -0.07400224  0.          0.8278103 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 10641 is [True, False, False, False, False, True]
Current timestep = 10642. State = [[-0.27400115  0.19155726]]. Action = [[ 0.06869116 -0.06606606  0.          0.71240914]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 10642 is [True, False, False, False, False, True]
State prediction error at timestep 10642 is 0.012
Human Feedback received at timestep 10642 of None
Current timestep = 10643. State = [[-0.27102125  0.1901637 ]]. Action = [[-0.02462367  0.01820967  0.         -0.22654772]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 10643 is [True, False, False, False, False, True]
Current timestep = 10644. State = [[-0.2728381   0.19222678]]. Action = [[-0.06186012  0.03217194  0.         -0.7427703 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 10644 is [True, False, False, False, False, True]
Current timestep = 10645. State = [[-0.26926956  0.1949508 ]]. Action = [[0.08690701 0.03650749 0.         0.6500833 ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 10645 is [True, False, False, False, False, True]
Current timestep = 10646. State = [[-0.26311225  0.19893917]]. Action = [[ 0.0566586   0.06563998  0.         -0.07624608]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 10646 is [True, False, False, False, False, True]
Current timestep = 10647. State = [[-0.25768945  0.2019178 ]]. Action = [[0.05563878 0.02745178 0.         0.7560035 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 10647 is [True, False, False, False, False, True]
Current timestep = 10648. State = [[-0.2592157   0.20132309]]. Action = [[-0.09446443 -0.03954118  0.          0.8038416 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 10648 is [True, False, False, False, False, True]
Current timestep = 10649. State = [[-0.26321158  0.1978987 ]]. Action = [[-0.04692132 -0.06550871  0.          0.6411433 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 10649 is [True, False, False, False, False, True]
Current timestep = 10650. State = [[-0.26767698  0.1965054 ]]. Action = [[-0.07344984 -0.00752456  0.          0.49242723]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 10650 is [True, False, False, False, False, True]
Current timestep = 10651. State = [[-0.2732854   0.19437586]]. Action = [[-0.07474248 -0.05590317  0.          0.97822654]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 10651 is [True, False, False, False, False, True]
Current timestep = 10652. State = [[-0.27291518  0.19052884]]. Action = [[ 0.053217   -0.05691136  0.         -0.79208666]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 10652 is [True, False, False, False, False, True]
Current timestep = 10653. State = [[-0.27632853  0.19001125]]. Action = [[-0.09687052  0.02430189  0.         -0.7966049 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 10653 is [True, False, False, False, False, True]
Current timestep = 10654. State = [[-0.27475896  0.18856429]]. Action = [[ 0.09788718 -0.04096103  0.         -0.9104157 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 10654 is [True, False, False, False, False, True]
Current timestep = 10655. State = [[-0.27489075  0.18388903]]. Action = [[-0.05596957 -0.06345993  0.          0.4069252 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 10655 is [True, False, False, False, False, True]
Current timestep = 10656. State = [[-0.27748263  0.17879929]]. Action = [[-0.02019151 -0.05658751  0.          0.24190044]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 10656 is [True, False, False, False, False, True]
Current timestep = 10657. State = [[-0.2775486   0.17371625]]. Action = [[ 0.01517055 -0.05296108  0.          0.26407957]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 10657 is [True, False, False, False, False, True]
State prediction error at timestep 10657 is 0.012
Human Feedback received at timestep 10657 of None
Current timestep = 10658. State = [[-0.28044462  0.17002794]]. Action = [[-0.0627483  -0.02199649  0.          0.08852839]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 10658 is [True, False, False, False, False, True]
Current timestep = 10659. State = [[-0.27868894  0.16766882]]. Action = [[ 0.08349388 -0.00715446  0.          0.67995596]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 10659 is [True, False, False, False, False, True]
State prediction error at timestep 10659 is 0.012
Human Feedback received at timestep 10659 of None
Current timestep = 10660. State = [[-0.27929413  0.1656988 ]]. Action = [[-0.05223566 -0.00483921  0.         -0.3158152 ]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 10660 is [True, False, False, False, False, True]
Current timestep = 10661. State = [[-0.280532    0.16690683]]. Action = [[ 0.01585467  0.0536881   0.         -0.6606737 ]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 10661 is [True, False, False, False, False, True]
Current timestep = 10662. State = [[-0.27963606  0.16262563]]. Action = [[ 0.02565185 -0.0911796   0.          0.1484245 ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 10662 is [True, False, False, False, False, True]
Current timestep = 10663. State = [[-0.2752803   0.16103461]]. Action = [[ 0.08387356  0.05065332  0.         -0.57592523]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 10663 is [True, False, False, False, False, True]
Current timestep = 10664. State = [[-0.27698824  0.16084558]]. Action = [[-0.08430843 -0.0064052   0.         -0.11765945]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 10664 is [True, False, False, False, False, True]
Current timestep = 10665. State = [[-0.28071377  0.16229083]]. Action = [[-0.01095687  0.05066846  0.          0.03722882]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 10665 is [True, False, False, False, False, True]
Current timestep = 10666. State = [[-0.27944794  0.15828577]]. Action = [[ 0.05519525 -0.09191214  0.          0.5711168 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 10666 is [True, False, False, False, False, True]
Current timestep = 10667. State = [[-0.2748499   0.15251228]]. Action = [[ 0.07002745 -0.04076726  0.         -0.600145  ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 10667 is [True, False, False, False, False, True]
Current timestep = 10668. State = [[-0.2696856   0.15345107]]. Action = [[ 0.06626608  0.07650461  0.         -0.5598055 ]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 10668 is [True, False, False, False, False, True]
Current timestep = 10669. State = [[-0.2658472   0.15318587]]. Action = [[ 0.03925798 -0.01897554  0.         -0.14845544]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 10669 is [True, False, False, False, False, True]
State prediction error at timestep 10669 is 0.012
Human Feedback received at timestep 10669 of None
Current timestep = 10670. State = [[-0.26163167  0.14959903]]. Action = [[ 0.05182851 -0.04019069  0.          0.3312751 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 10670 is [True, False, False, False, False, True]
Current timestep = 10671. State = [[-0.26329046  0.14416525]]. Action = [[-0.09041371 -0.07249375  0.          0.1620692 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 10671 is [True, False, False, False, False, True]
Current timestep = 10672. State = [[-0.26184216  0.14207356]]. Action = [[0.0688178  0.01670073 0.         0.646384  ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 10672 is [True, False, False, False, False, True]
State prediction error at timestep 10672 is 0.012
Human Feedback received at timestep 10672 of None
Current timestep = 10673. State = [[-0.26232693  0.13845477]]. Action = [[-0.0760092  -0.07058813  0.          0.8339329 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 10673 is [True, False, False, False, False, True]
Current timestep = 10674. State = [[-0.26272258  0.1345066 ]]. Action = [[ 0.01150541 -0.03063256  0.          0.15978718]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 10674 is [True, False, False, False, False, True]
State prediction error at timestep 10674 is 0.012
Human Feedback received at timestep 10674 of None
Current timestep = 10675. State = [[-0.25951126  0.13440917]]. Action = [[0.04696617 0.03444258 0.         0.05760145]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 10675 is [True, False, False, False, False, True]
State prediction error at timestep 10675 is 0.012
Human Feedback received at timestep 10675 of None
Current timestep = 10676. State = [[-0.2531291   0.13530122]]. Action = [[ 0.09685553  0.0222019   0.         -0.7483088 ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 10676 is [True, False, False, False, False, True]
Current timestep = 10677. State = [[-0.24918695  0.13555798]]. Action = [[0.01622842 0.01502755 0.         0.28728747]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 10677 is [True, False, False, False, False, True]
Current timestep = 10678. State = [[-0.25118938  0.13140607]]. Action = [[-0.07065872 -0.08292453  0.         -0.84014064]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 10678 is [True, False, False, False, False, True]
State prediction error at timestep 10678 is 0.012
Human Feedback received at timestep 10678 of None
Current timestep = 10679. State = [[-0.25515726  0.12516797]]. Action = [[-0.06018325 -0.07586199  0.          0.69531274]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 10679 is [True, False, False, False, False, True]
Current timestep = 10680. State = [[-0.25924024  0.12617348]]. Action = [[-0.05710148  0.07075483  0.          0.84804416]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 10680 is [True, False, False, False, False, True]
Current timestep = 10681. State = [[-0.2652829   0.13192733]]. Action = [[-0.078968    0.07636211  0.          0.6643326 ]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 10681 is [True, False, False, False, False, True]
Current timestep = 10682. State = [[-0.26483607  0.13010068]]. Action = [[ 0.07425291 -0.09118674  0.          0.26757622]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 10682 is [True, False, False, False, False, True]
State prediction error at timestep 10682 is 0.012
Human Feedback received at timestep 10682 of None
Current timestep = 10683. State = [[-0.26779866  0.12340048]]. Action = [[-0.09743173 -0.08343466  0.         -0.62498933]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 10683 is [True, False, False, False, False, True]
Current timestep = 10684. State = [[-0.2727238   0.12279144]]. Action = [[-0.03207742  0.04241409  0.         -0.37823975]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 10684 is [True, False, False, False, True, False]
State prediction error at timestep 10684 is 0.012
Human Feedback received at timestep 10684 of None
Current timestep = 10685. State = [[-0.27380058  0.12025104]]. Action = [[ 0.02202845 -0.06573975  0.          0.7082863 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 10685 is [True, False, False, False, True, False]
Current timestep = 10686. State = [[-0.27799863  0.11939245]]. Action = [[-0.07558723  0.03148677  0.         -0.8721305 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 10686 is [True, False, False, False, True, False]
Current timestep = 10687. State = [[-0.27915043  0.12368394]]. Action = [[ 0.05388331  0.08142383  0.         -0.5527914 ]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 10687 is [True, False, False, False, True, False]
State prediction error at timestep 10687 is 0.012
Human Feedback received at timestep 10687 of None
Current timestep = 10688. State = [[-0.27672648  0.12853043]]. Action = [[ 0.0581683   0.06311632  0.         -0.32521987]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 10688 is [True, False, False, False, True, False]
Current timestep = 10689. State = [[-0.2769839   0.13165753]]. Action = [[-0.00672609  0.03428406  0.         -0.9525438 ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 10689 is [True, False, False, False, False, True]
Current timestep = 10690. State = [[-0.27856082  0.13035691]]. Action = [[-0.00615896 -0.04692559  0.          0.56855893]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 10690 is [True, False, False, False, False, True]
Current timestep = 10691. State = [[-0.27545512  0.13233124]]. Action = [[ 0.08655036  0.06878521  0.         -0.72500396]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 10691 is [True, False, False, False, False, True]
Current timestep = 10692. State = [[-0.2701665   0.13205434]]. Action = [[ 0.06723116 -0.03882236  0.         -0.42461348]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 10692 is [True, False, False, False, False, True]
Current timestep = 10693. State = [[-0.26750767  0.13148497]]. Action = [[0.00760875 0.01191284 0.         0.55594933]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 10693 is [True, False, False, False, False, True]
Current timestep = 10694. State = [[-0.26583663  0.132411  ]]. Action = [[ 0.01701345  0.01164389  0.         -0.750239  ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 10694 is [True, False, False, False, False, True]
Current timestep = 10695. State = [[-0.26203054  0.13622215]]. Action = [[ 0.05559767  0.06813457  0.         -0.0345577 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 10695 is [True, False, False, False, False, True]
Current timestep = 10696. State = [[-0.2568563  0.1404034]]. Action = [[ 0.0616091   0.04382629  0.         -0.88500357]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 10696 is [True, False, False, False, False, True]
Current timestep = 10697. State = [[-0.2495017   0.14510307]]. Action = [[0.09888307 0.06713379 0.         0.61220074]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 10697 is [True, False, False, False, False, True]
Current timestep = 10698. State = [[-0.24291436  0.15123954]]. Action = [[0.05900573 0.08235022 0.         0.1057446 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 10698 is [True, False, False, False, False, True]
Current timestep = 10699. State = [[-0.24167342  0.15667835]]. Action = [[-0.03222037  0.0475476   0.         -0.9212189 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 10699 is [True, False, False, False, False, True]
Current timestep = 10700. State = [[-0.23928186  0.15968718]]. Action = [[ 0.04281468  0.00566097  0.         -0.36864853]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 10700 is [True, False, False, False, False, True]
State prediction error at timestep 10700 is 0.012
Human Feedback received at timestep 10700 of None
Current timestep = 10701. State = [[-0.23835915  0.16044557]]. Action = [[-0.03317993 -0.0202348   0.         -0.50308406]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 10701 is [True, False, False, False, False, True]
State prediction error at timestep 10701 is 0.012
Human Feedback received at timestep 10701 of None
Current timestep = 10702. State = [[-0.24178043  0.15873481]]. Action = [[-0.08907282 -0.06562169  0.          0.4829743 ]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 10702 is [True, False, False, False, False, True]
Current timestep = 10703. State = [[-0.24431452  0.16282076]]. Action = [[-0.02862002  0.07810483  0.          0.2743163 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 10703 is [True, False, False, False, False, True]
Current timestep = 10704. State = [[-0.24529737  0.16427305]]. Action = [[-0.0211857  -0.05483799  0.          0.37397695]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 10704 is [True, False, False, False, False, True]
Current timestep = 10705. State = [[-0.24009387  0.16246776]]. Action = [[ 0.0985477  -0.03635453  0.         -0.48161602]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 10705 is [True, False, False, False, False, True]
State prediction error at timestep 10705 is 0.012
Human Feedback received at timestep 10705 of None
Current timestep = 10706. State = [[-0.23652399  0.16186261]]. Action = [[-0.0097191  -0.0058362   0.          0.87627006]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 10706 is [True, False, False, False, False, True]
Current timestep = 10707. State = [[-0.23571047  0.16039945]]. Action = [[-0.00800613 -0.04028118  0.         -0.07879853]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 10707 is [True, False, False, False, False, True]
Current timestep = 10708. State = [[-0.23092902  0.16234152]]. Action = [[0.08218909 0.05787221 0.         0.8325342 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 10708 is [True, False, False, False, False, True]
Current timestep = 10709. State = [[-0.22539929  0.16298929]]. Action = [[ 0.04480547 -0.01724194  0.         -0.95411223]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 10709 is [True, False, False, False, False, True]
Current timestep = 10710. State = [[-0.2266638   0.16719797]]. Action = [[-0.07556309  0.09240959  0.          0.26422703]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 10710 is [True, False, False, False, False, True]
Current timestep = 10711. State = [[-0.22978249  0.16759744]]. Action = [[-0.03612693 -0.05957729  0.          0.00664425]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 10711 is [True, False, False, False, False, True]
Current timestep = 10712. State = [[-0.22735466  0.16520362]]. Action = [[ 0.05783246 -0.02815007  0.          0.21271133]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 10712 is [True, False, False, False, False, True]
Current timestep = 10713. State = [[-0.22646618  0.1657257 ]]. Action = [[-0.02813332  0.02478719  0.         -0.8575085 ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 10713 is [True, False, False, False, False, True]
Current timestep = 10714. State = [[-0.22929877  0.1678707 ]]. Action = [[-0.05189946  0.02117292  0.         -0.7288704 ]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 10714 is [True, False, False, False, False, True]
Current timestep = 10715. State = [[-0.23471446  0.17194767]]. Action = [[-0.07954828  0.05438065  0.         -0.46190882]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 10715 is [True, False, False, False, False, True]
Current timestep = 10716. State = [[-0.23816313  0.17867562]]. Action = [[-0.00779822  0.08520056  0.         -0.22283244]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 10716 is [True, False, False, False, False, True]
Current timestep = 10717. State = [[-0.23835495  0.1837502 ]]. Action = [[0.02957504 0.03560155 0.         0.15902364]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 10717 is [True, False, False, False, False, True]
State prediction error at timestep 10717 is 0.012
Human Feedback received at timestep 10717 of None
Current timestep = 10718. State = [[-0.23716454  0.18204634]]. Action = [[ 0.02925134 -0.07121132  0.          0.58248353]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 10718 is [True, False, False, False, False, True]
Current timestep = 10719. State = [[-0.23999347  0.17737041]]. Action = [[-0.06904013 -0.07043501  0.          0.76252866]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 10719 is [True, False, False, False, False, True]
Current timestep = 10720. State = [[-0.24652563  0.17612836]]. Action = [[-0.09084364 -0.001615    0.          0.7842083 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 10720 is [True, False, False, False, False, True]
State prediction error at timestep 10720 is 0.012
Human Feedback received at timestep 10720 of None
Current timestep = 10721. State = [[-0.24606489  0.17514062]]. Action = [[ 0.07732286 -0.02706568  0.         -0.2898534 ]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 10721 is [True, False, False, False, False, True]
Current timestep = 10722. State = [[-0.2488198   0.17922488]]. Action = [[-0.08761144  0.09878657  0.         -0.86709726]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 10722 is [True, False, False, False, False, True]
State prediction error at timestep 10722 is 0.012
Human Feedback received at timestep 10722 of None
Current timestep = 10723. State = [[-0.24872571  0.18223803]]. Action = [[ 0.06944104 -0.00306661  0.          0.21948504]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 10723 is [True, False, False, False, False, True]
State prediction error at timestep 10723 is 0.012
Human Feedback received at timestep 10723 of None
Current timestep = 10724. State = [[-0.24910438  0.18465446]]. Action = [[-0.02815164  0.04617164  0.         -0.8534237 ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 10724 is [True, False, False, False, False, True]
Current timestep = 10725. State = [[-0.25392577  0.18301767]]. Action = [[-0.07147131 -0.07031003  0.         -0.73953336]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 10725 is [True, False, False, False, False, True]
Current timestep = 10726. State = [[-0.25210038  0.17801452]]. Action = [[ 0.08997954 -0.06777464  0.         -0.6917429 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 10726 is [True, False, False, False, False, True]
Current timestep = 10727. State = [[-0.24694122  0.17196444]]. Action = [[ 0.0513503 -0.072612   0.        -0.9501324]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 10727 is [True, False, False, False, False, True]
State prediction error at timestep 10727 is 0.012
Human Feedback received at timestep 10727 of None
Current timestep = 10728. State = [[-0.24738161  0.16758145]]. Action = [[-0.0556655  -0.03311736  0.          0.925596  ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 10728 is [True, False, False, False, False, True]
Current timestep = 10729. State = [[-0.24713127  0.16354518]]. Action = [[ 0.02034561 -0.04944778  0.         -0.15668213]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 10729 is [True, False, False, False, False, True]
Current timestep = 10730. State = [[-0.24510707  0.16455144]]. Action = [[ 0.01982562  0.07044371  0.         -0.6769177 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 10730 is [True, False, False, False, False, True]
Current timestep = 10731. State = [[-0.24385852  0.16682737]]. Action = [[ 0.01159568  0.0292772   0.         -0.09428918]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 10731 is [True, False, False, False, False, True]
Current timestep = 10732. State = [[-0.24626791  0.16322948]]. Action = [[-0.06146654 -0.07841965  0.         -0.940222  ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 10732 is [True, False, False, False, False, True]
Current timestep = 10733. State = [[-0.24734391  0.16205062]]. Action = [[ 0.0132788   0.03181949  0.         -0.47135758]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 10733 is [True, False, False, False, False, True]
State prediction error at timestep 10733 is 0.012
Human Feedback received at timestep 10733 of None
Current timestep = 10734. State = [[-0.2429876   0.16654038]]. Action = [[0.09391525 0.09336288 0.         0.885731  ]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 10734 is [True, False, False, False, False, True]
Current timestep = 10735. State = [[-0.23640947  0.16494547]]. Action = [[ 0.08842028 -0.06461173  0.          0.8912015 ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 10735 is [True, False, False, False, False, True]
Current timestep = 10736. State = [[-0.22930476  0.15819332]]. Action = [[ 0.08048012 -0.07971089  0.          0.34572375]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 10736 is [True, False, False, False, False, True]
Current timestep = 10737. State = [[-0.23004994  0.15919016]]. Action = [[-0.08320777  0.09161437  0.         -0.5505469 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 10737 is [True, False, False, False, False, True]
Current timestep = 10738. State = [[-0.23441781  0.16381617]]. Action = [[-0.05375809  0.04238286  0.          0.26215994]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 10738 is [True, False, False, False, False, True]
Current timestep = 10739. State = [[-0.23922971  0.16967428]]. Action = [[-0.06347895  0.08011534  0.         -0.7159898 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 10739 is [True, False, False, False, False, True]
Current timestep = 10740. State = [[-0.24445207  0.17628075]]. Action = [[-0.0543691   0.06562867  0.         -0.5427482 ]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 10740 is [True, False, False, False, False, True]
Current timestep = 10741. State = [[-0.2466545   0.17674303]]. Action = [[ 0.00561098 -0.05707759  0.          0.10390854]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 10741 is [True, False, False, False, False, True]
Current timestep = 10742. State = [[-0.24959877  0.17366147]]. Action = [[-0.05279412 -0.05799139  0.         -0.7067213 ]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 10742 is [True, False, False, False, False, True]
Current timestep = 10743. State = [[-0.24736476  0.17017907]]. Action = [[ 0.08246595 -0.05409373  0.          0.6319885 ]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 10743 is [True, False, False, False, False, True]
Current timestep = 10744. State = [[-0.24570403  0.16494317]]. Action = [[-0.01771866 -0.07980671  0.          0.19782078]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 10744 is [True, False, False, False, False, True]
Current timestep = 10745. State = [[-0.2456513   0.16338353]]. Action = [[-0.00139664  0.013511    0.         -0.9089568 ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 10745 is [True, False, False, False, False, True]
Current timestep = 10746. State = [[-0.24444625  0.16189705]]. Action = [[ 0.01828329 -0.03140058  0.          0.3895718 ]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 10746 is [True, False, False, False, False, True]
Current timestep = 10747. State = [[-0.24032018  0.16505253]]. Action = [[ 0.07113864  0.09602297  0.         -0.8375857 ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 10747 is [True, False, False, False, False, True]
Current timestep = 10748. State = [[-0.23766938  0.1705615 ]]. Action = [[ 0.01656221  0.07457153  0.         -0.29146612]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 10748 is [True, False, False, False, False, True]
Current timestep = 10749. State = [[-0.23355179  0.17397383]]. Action = [[0.07624245 0.03557237 0.         0.05900896]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 10749 is [True, False, False, False, False, True]
Current timestep = 10750. State = [[-0.2313945   0.17063245]]. Action = [[-0.00892568 -0.08415562  0.          0.93574286]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 10750 is [True, False, False, False, False, True]
Current timestep = 10751. State = [[-0.22800896  0.16706797]]. Action = [[ 0.0603335  -0.01859181  0.          0.02628386]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 10751 is [True, False, False, False, False, True]
Current timestep = 10752. State = [[-0.22592002  0.1654021 ]]. Action = [[-0.00669895 -0.01069011  0.         -0.62954843]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 10752 is [True, False, False, False, False, True]
Current timestep = 10753. State = [[-0.2207569   0.16113266]]. Action = [[ 0.08764937 -0.06940403  0.         -0.07226044]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 10753 is [True, False, False, False, False, True]
Current timestep = 10754. State = [[-0.2190306   0.16213846]]. Action = [[-0.03785942  0.0780711   0.         -0.38465273]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 10754 is [True, False, False, False, False, True]
Current timestep = 10755. State = [[-0.21649937  0.16067715]]. Action = [[ 0.05225398 -0.06552501  0.         -0.32609332]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 10755 is [True, False, False, False, False, True]
State prediction error at timestep 10755 is 0.012
Human Feedback received at timestep 10755 of None
Current timestep = 10756. State = [[-0.21806534  0.15758131]]. Action = [[-0.087499   -0.02232255  0.         -0.8497207 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 10756 is [True, False, False, False, False, True]
Current timestep = 10757. State = [[-0.21917813  0.15597951]]. Action = [[ 0.0038496  -0.01864094  0.         -0.927715  ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 10757 is [True, False, False, False, False, True]
Current timestep = 10758. State = [[-0.21716304  0.15846094]]. Action = [[ 0.02943692  0.06649325  0.         -0.9893283 ]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 10758 is [True, False, False, False, False, True]
Current timestep = 10759. State = [[-0.21332291  0.16057608]]. Action = [[ 0.05860717  0.01293024  0.         -0.452246  ]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 10759 is [True, False, False, False, False, True]
Current timestep = 10760. State = [[-0.20801902  0.15666103]]. Action = [[ 0.06586433 -0.07771935  0.          0.8202771 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 10760 is [True, False, False, False, False, True]
State prediction error at timestep 10760 is 0.012
Human Feedback received at timestep 10760 of None
Current timestep = 10761. State = [[-0.2072013   0.15568338]]. Action = [[-0.03855358  0.03656191  0.         -0.5044779 ]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 10761 is [True, False, False, False, False, True]
Current timestep = 10762. State = [[-0.20395365  0.15251091]]. Action = [[ 0.07148687 -0.0766616   0.         -0.6904756 ]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 10762 is [True, False, False, False, False, True]
Current timestep = 10763. State = [[-0.19916409  0.14838158]]. Action = [[ 0.03641755 -0.02590673  0.         -0.05462575]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 10763 is [True, False, False, False, False, True]
Current timestep = 10764. State = [[-0.19863744  0.14221743]]. Action = [[-0.04030025 -0.0937511   0.          0.578985  ]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 10764 is [True, False, False, False, False, True]
Current timestep = 10765. State = [[-0.19961256  0.13681555]]. Action = [[-0.0295275  -0.04271145  0.         -0.69016385]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 10765 is [True, False, False, False, False, True]
State prediction error at timestep 10765 is 0.012
Human Feedback received at timestep 10765 of None
Current timestep = 10766. State = [[-0.19845556  0.13141884]]. Action = [[ 0.01397    -0.06518114  0.         -0.87964606]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 10766 is [True, False, False, False, False, True]
Current timestep = 10767. State = [[-0.19500151  0.12822022]]. Action = [[ 3.9429493e-02 -7.4131787e-04  0.0000000e+00 -8.0891341e-01]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 10767 is [True, False, False, False, False, True]
State prediction error at timestep 10767 is 0.012
Human Feedback received at timestep 10767 of None
Current timestep = 10768. State = [[-0.19727693  0.12387148]]. Action = [[-0.09444109 -0.06278862  0.         -0.00471395]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 10768 is [True, False, False, False, False, True]
Current timestep = 10769. State = [[-0.1960918   0.12415465]]. Action = [[0.08213677 0.07052786 0.         0.8353417 ]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 10769 is [True, False, False, False, True, False]
Current timestep = 10770. State = [[-0.19248508  0.12673873]]. Action = [[ 0.02319987  0.0375318   0.         -0.91079193]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 10770 is [True, False, False, False, True, False]
State prediction error at timestep 10770 is 0.012
Human Feedback received at timestep 10770 of None
Current timestep = 10771. State = [[-0.1928198   0.12375254]]. Action = [[-0.03368481 -0.06923281  0.          0.82093596]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 10771 is [True, False, False, False, False, True]
Current timestep = 10772. State = [[-0.18957964  0.11639   ]]. Action = [[ 0.06945533 -0.09527176  0.          0.70513546]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 10772 is [True, False, False, False, True, False]
State prediction error at timestep 10772 is 0.012
Human Feedback received at timestep 10772 of None
Current timestep = 10773. State = [[-0.182675    0.11294855]]. Action = [[ 0.08690331  0.01468781  0.         -0.09481281]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 10773 is [True, False, False, False, True, False]
Current timestep = 10774. State = [[-0.18180163  0.11527745]]. Action = [[-0.0469281   0.06793573  0.          0.10014379]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 10774 is [True, False, False, False, True, False]
Current timestep = 10775. State = [[-0.18533239  0.12082311]]. Action = [[-0.05142007  0.08436502  0.         -0.8537864 ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 10775 is [True, False, False, False, True, False]
Current timestep = 10776. State = [[-0.18261303  0.12394352]]. Action = [[ 0.09566218  0.01684596  0.         -0.9949622 ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 10776 is [True, False, False, False, True, False]
Current timestep = 10777. State = [[-0.17845678  0.12751645]]. Action = [[0.03856046 0.06520157 0.         0.88319564]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 10777 is [True, False, False, False, True, False]
State prediction error at timestep 10777 is 0.012
Human Feedback received at timestep 10777 of None
Current timestep = 10778. State = [[-0.17482856  0.12836657]]. Action = [[ 0.05147541 -0.02103852  0.         -0.08934718]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 10778 is [True, False, False, False, False, True]
Current timestep = 10779. State = [[-0.17594264  0.12649107]]. Action = [[-0.06397997 -0.03429041  0.          0.25897908]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 10779 is [True, False, False, False, False, True]
Current timestep = 10780. State = [[-0.1782975   0.12214795]]. Action = [[-0.02786931 -0.08030428  0.         -0.33469892]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 10780 is [True, False, False, False, False, True]
State prediction error at timestep 10780 is 0.012
Human Feedback received at timestep 10780 of None
Current timestep = 10781. State = [[-0.1747837   0.11727741]]. Action = [[ 0.07316495 -0.0556872   0.         -0.4591322 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 10781 is [True, False, False, False, True, False]
Current timestep = 10782. State = [[-0.1749861   0.11939261]]. Action = [[-0.06278186  0.08159424  0.         -0.23217928]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 10782 is [True, False, False, False, True, False]
Current timestep = 10783. State = [[-0.17771399  0.1184456 ]]. Action = [[-0.03587639 -0.07203154  0.         -0.42113674]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 10783 is [True, False, False, False, True, False]
Current timestep = 10784. State = [[-0.1775609   0.11196577]]. Action = [[ 0.00659031 -0.09604062  0.          0.4884665 ]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 10784 is [True, False, False, False, True, False]
Current timestep = 10785. State = [[-0.17936245  0.10629816]]. Action = [[-0.0610038  -0.05289973  0.          0.60023403]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 10785 is [True, False, False, False, True, False]
Current timestep = 10786. State = [[-0.18372473  0.10208526]]. Action = [[-0.07329887 -0.0465498   0.          0.5116966 ]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 10786 is [True, False, False, False, True, False]
Current timestep = 10787. State = [[-0.1812273   0.09845249]]. Action = [[ 0.09324441 -0.02919202  0.          0.07291758]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 10787 is [True, False, False, False, True, False]
Current timestep = 10788. State = [[-0.17773962  0.09152398]]. Action = [[ 0.00539911 -0.09652509  0.         -0.25349617]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 10788 is [True, False, False, False, True, False]
Current timestep = 10789. State = [[-0.17335929  0.08853027]]. Action = [[0.06699838 0.02782954 0.         0.70347023]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 10789 is [True, False, False, False, True, False]
Current timestep = 10790. State = [[-0.17433323  0.09184226]]. Action = [[-0.06688676  0.08396945  0.         -0.31287503]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 10790 is [True, False, False, False, True, False]
Current timestep = 10791. State = [[-0.17189862  0.09325346]]. Action = [[ 0.0940134   0.00108452  0.         -0.7841524 ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 10791 is [True, False, False, False, True, False]
Current timestep = 10792. State = [[-0.16683897  0.09718037]]. Action = [[ 0.06063441  0.09863434  0.         -0.93759054]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 10792 is [True, False, False, False, True, False]
Current timestep = 10793. State = [[-0.16331716  0.10320248]]. Action = [[0.04793174 0.07981498 0.         0.74729514]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 10793 is [True, False, False, False, True, False]
Current timestep = 10794. State = [[-0.15784547  0.10293682]]. Action = [[ 0.09188873 -0.04584451  0.         -0.802305  ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 10794 is [True, False, False, False, True, False]
Current timestep = 10795. State = [[-0.150462    0.10528138]]. Action = [[ 0.09738105  0.08136933  0.         -0.20984685]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 10795 is [True, False, False, False, True, False]
State prediction error at timestep 10795 is 0.012
Human Feedback received at timestep 10795 of None
Current timestep = 10796. State = [[-0.14939363  0.10671604]]. Action = [[-0.0519338  -0.01691169  0.         -0.5732832 ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 10796 is [True, False, False, False, True, False]
State prediction error at timestep 10796 is 0.012
Human Feedback received at timestep 10796 of None
Current timestep = 10797. State = [[-0.15442958  0.10648097]]. Action = [[-0.08694544 -0.00844164  0.          0.5844064 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 10797 is [True, False, False, False, True, False]
Current timestep = 10798. State = [[-0.15332544  0.11015095]]. Action = [[ 0.07743175  0.06635571  0.         -0.27275276]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 10798 is [True, False, False, False, True, False]
State prediction error at timestep 10798 is 0.012
Human Feedback received at timestep 10798 of None
Current timestep = 10799. State = [[-0.15095763  0.11313582]]. Action = [[-0.00373852  0.00588882  0.          0.77136934]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 10799 is [True, False, False, False, True, False]
Current timestep = 10800. State = [[-0.15313697  0.11101452]]. Action = [[-0.0666797  -0.07116257  0.          0.6048993 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 10800 is [True, False, False, False, True, False]
Current timestep = 10801. State = [[-0.1505337   0.11043233]]. Action = [[0.07237446 0.01014514 0.         0.38549852]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 10801 is [True, False, False, False, True, False]
State prediction error at timestep 10801 is 0.012
Human Feedback received at timestep 10801 of None
Current timestep = 10802. State = [[-0.14658706  0.10659775]]. Action = [[ 0.00926282 -0.09386829  0.          0.90828204]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 10802 is [True, False, False, False, True, False]
Current timestep = 10803. State = [[-0.1410197   0.10685942]]. Action = [[0.07228769 0.05590346 0.         0.54260695]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 10803 is [True, False, False, False, True, False]
Current timestep = 10804. State = [[-0.13584717  0.10480844]]. Action = [[ 0.03107847 -0.07049014  0.         -0.7515515 ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 10804 is [True, False, False, False, True, False]
State prediction error at timestep 10804 is 0.012
Human Feedback received at timestep 10804 of None
Current timestep = 10805. State = [[-0.13141568  0.09959749]]. Action = [[ 0.03058574 -0.05965686  0.         -0.5387732 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 10805 is [True, False, False, False, True, False]
Current timestep = 10806. State = [[-0.12499549  0.09621563]]. Action = [[ 0.07201893 -0.01661399  0.          0.0884831 ]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 10806 is [True, False, False, False, True, False]
State prediction error at timestep 10806 is 0.012
Human Feedback received at timestep 10806 of None
Current timestep = 10807. State = [[-0.11871443  0.09932695]]. Action = [[0.05266692 0.09556896 0.         0.42072272]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 10807 is [True, False, False, False, True, False]
State prediction error at timestep 10807 is 0.012
Human Feedback received at timestep 10807 of None
Current timestep = 10808. State = [[-0.11155932  0.10198578]]. Action = [[ 0.08909196  0.01740503  0.         -0.21350354]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 10808 is [True, False, False, False, True, False]
Current timestep = 10809. State = [[-0.11176702  0.10487506]]. Action = [[-0.09259399  0.05371345  0.          0.7328479 ]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 10809 is [True, False, False, False, True, False]
Current timestep = 10810. State = [[-0.11186707  0.10686888]]. Action = [[ 0.03155892  0.00616659  0.         -0.7830186 ]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 10810 is [True, False, False, False, True, False]
State prediction error at timestep 10810 is 0.012
Human Feedback received at timestep 10810 of None
Current timestep = 10811. State = [[-0.10799898  0.10834768]]. Action = [[ 0.05299845  0.02259852  0.         -0.27998698]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 10811 is [True, False, False, False, True, False]
Current timestep = 10812. State = [[-0.10464405  0.10460223]]. Action = [[ 0.02355871 -0.09044348  0.         -0.06342071]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 10812 is [True, False, False, False, True, False]
State prediction error at timestep 10812 is 0.012
Human Feedback received at timestep 10812 of None
Current timestep = 10813. State = [[-0.10112132  0.10105889]]. Action = [[ 0.03406466 -0.01776394  0.          0.41251016]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 10813 is [True, False, False, False, True, False]
Current timestep = 10814. State = [[-0.0980607   0.10308684]]. Action = [[ 0.02133954  0.05881699  0.         -0.4380046 ]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 10814 is [True, False, False, False, True, False]
Current timestep = 10815. State = [[-0.09880438  0.10203535]]. Action = [[-0.04958544 -0.05573452  0.          0.54746497]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 10815 is [True, False, False, False, True, False]
Current timestep = 10816. State = [[-0.09543598  0.09769315]]. Action = [[ 0.0745898  -0.05640728  0.          0.6326896 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 10816 is [True, False, False, False, True, False]
Current timestep = 10817. State = [[-0.09049409  0.09744851]]. Action = [[ 0.03565717  0.03921885  0.         -0.5511713 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 10817 is [True, False, False, False, True, False]
Current timestep = 10818. State = [[-0.09206406  0.09665642]]. Action = [[-0.08423643 -0.03301789  0.         -0.71001697]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 10818 is [True, False, False, False, True, False]
Current timestep = 10819. State = [[-0.09657083  0.09648094]]. Action = [[-0.0697694   0.01118045  0.          0.53267694]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 10819 is [True, False, False, False, True, False]
Current timestep = 10820. State = [[-0.1015685   0.10028584]]. Action = [[-0.07299565  0.06094223  0.          0.88982415]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 10820 is [True, False, False, False, True, False]
Current timestep = 10821. State = [[-0.10167564  0.10197681]]. Action = [[ 0.04277477 -0.01578142  0.         -0.93359584]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 10821 is [True, False, False, False, True, False]
Current timestep = 10822. State = [[-0.09659071  0.10028099]]. Action = [[ 0.0890374  -0.03122862  0.         -0.83655   ]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 10822 is [True, False, False, False, True, False]
Current timestep = 10823. State = [[-0.09742653  0.09758014]]. Action = [[-0.07602234 -0.03563225  0.         -0.73447037]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 10823 is [True, False, False, False, True, False]
Current timestep = 10824. State = [[-0.10115118  0.09632833]]. Action = [[-0.03185044 -0.00413038  0.          0.21119046]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 10824 is [True, False, False, False, True, False]
Current timestep = 10825. State = [[-0.10110281  0.09863571]]. Action = [[ 0.03330588  0.05170453  0.         -0.5123736 ]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 10825 is [True, False, False, False, True, False]
State prediction error at timestep 10825 is 0.012
Human Feedback received at timestep 10825 of None
Current timestep = 10826. State = [[-0.10358483  0.09524578]]. Action = [[-0.05956061 -0.09714165  0.         -0.9332871 ]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 10826 is [True, False, False, False, True, False]
Current timestep = 10827. State = [[-0.11013379  0.08849243]]. Action = [[-0.09650706 -0.08006177  0.         -0.13196445]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 10827 is [True, False, False, False, True, False]
Current timestep = 10828. State = [[-0.10995415  0.08908684]]. Action = [[ 0.08895386  0.07332725  0.         -0.6208471 ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 10828 is [True, False, False, False, True, False]
Current timestep = 10829. State = [[-0.1051999   0.08866319]]. Action = [[ 0.05651215 -0.03568558  0.         -0.43346238]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 10829 is [True, False, False, False, True, False]
State prediction error at timestep 10829 is 0.012
Human Feedback received at timestep 10829 of None
Current timestep = 10830. State = [[-0.10287987  0.08558495]]. Action = [[ 0.00874083 -0.02749676  0.          0.66827035]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 10830 is [True, False, False, False, True, False]
Current timestep = 10831. State = [[-0.10234671  0.08585464]]. Action = [[-0.00143411  0.03806997  0.          0.4614663 ]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 10831 is [True, False, False, False, True, False]
Current timestep = 10832. State = [[-0.10444093  0.09072334]]. Action = [[-0.04277588  0.08553033  0.          0.72022486]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 10832 is [True, False, False, False, True, False]
State prediction error at timestep 10832 is 0.012
Human Feedback received at timestep 10832 of None
Current timestep = 10833. State = [[-0.1055209   0.08903594]]. Action = [[ 0.00368509 -0.08549793  0.         -0.91384345]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 10833 is [True, False, False, False, True, False]
Current timestep = 10834. State = [[-0.10216083  0.08511572]]. Action = [[ 0.06510852 -0.02643329  0.         -0.9386838 ]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 10834 is [True, False, False, False, True, False]
State prediction error at timestep 10834 is 0.012
Human Feedback received at timestep 10834 of None
Current timestep = 10835. State = [[-0.09903168  0.08112872]]. Action = [[ 0.02304792 -0.04918836  0.         -0.38537616]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 10835 is [True, False, False, False, True, False]
Current timestep = 10836. State = [[-0.09506961  0.08050011]]. Action = [[ 0.0596348   0.03420939  0.         -0.93187493]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 10836 is [True, False, False, False, True, False]
Current timestep = 10837. State = [[-0.09215463  0.08525631]]. Action = [[0.02433239 0.09433607 0.         0.8135773 ]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 10837 is [True, False, False, False, True, False]
State prediction error at timestep 10837 is 0.012
Human Feedback received at timestep 10837 of None
Current timestep = 10838. State = [[-0.08704635  0.09189104]]. Action = [[ 0.09556331  0.08831956  0.         -0.3146749 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 10838 is [True, False, False, False, True, False]
Current timestep = 10839. State = [[-0.08577968  0.09300044]]. Action = [[-0.03266032 -0.02979174  0.         -0.5389564 ]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 10839 is [True, False, False, False, True, False]
Current timestep = 10840. State = [[-0.08873207  0.09353615]]. Action = [[-0.04573517  0.02008595  0.         -0.2462073 ]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 10840 is [True, False, False, False, True, False]
Current timestep = 10841. State = [[-0.09430371  0.09087619]]. Action = [[-0.09568494 -0.07896841  0.         -0.36713207]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 10841 is [True, False, False, False, True, False]
Current timestep = 10842. State = [[-0.09688086  0.09046931]]. Action = [[-0.00705323  0.02090517  0.         -0.80510795]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 10842 is [True, False, False, False, True, False]
Current timestep = 10843. State = [[-0.09707653  0.09545362]]. Action = [[ 0.00206751  0.07666037  0.         -0.6107991 ]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 10843 is [True, False, False, False, True, False]
Current timestep = 10844. State = [[-0.09772739  0.10079435]]. Action = [[-0.00559007  0.04523786  0.          0.3887056 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 10844 is [True, False, False, False, True, False]
Current timestep = 10845. State = [[-0.10231804  0.10305979]]. Action = [[-0.08377844 -0.00582637  0.         -0.16014135]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 10845 is [True, False, False, False, True, False]
State prediction error at timestep 10845 is 0.012
Human Feedback received at timestep 10845 of None
Current timestep = 10846. State = [[-0.10418725  0.10813855]]. Action = [[0.02317707 0.07880316 0.         0.68636787]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 10846 is [True, False, False, False, True, False]
State prediction error at timestep 10846 is 0.012
Human Feedback received at timestep 10846 of None
Current timestep = 10847. State = [[-0.10593566  0.11658047]]. Action = [[-0.02696222  0.09692632  0.         -0.5178608 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 10847 is [True, False, False, False, True, False]
Current timestep = 10848. State = [[-0.10840157  0.11865927]]. Action = [[-0.01639885 -0.04980904  0.         -0.38934696]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 10848 is [True, False, False, False, True, False]
State prediction error at timestep 10848 is 0.012
Human Feedback received at timestep 10848 of None
Current timestep = 10849. State = [[-0.10647298  0.12154837]]. Action = [[0.06750382 0.05673202 0.         0.71689916]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 10849 is [True, False, False, False, True, False]
Current timestep = 10850. State = [[-0.10216362  0.12578891]]. Action = [[0.06990314 0.03465254 0.         0.39538455]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 10850 is [True, False, False, False, True, False]
Current timestep = 10851. State = [[-0.09723918  0.12509891]]. Action = [[ 0.07009663 -0.04852283  0.          0.48044407]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 10851 is [True, False, False, False, False, True]
Current timestep = 10852. State = [[-0.09429289  0.12812293]]. Action = [[ 0.01867094  0.08160756  0.         -0.25170624]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 10852 is [True, False, False, False, False, True]
Current timestep = 10853. State = [[-0.09652908  0.13098446]]. Action = [[-0.06306289 -0.00195603  0.         -0.19078481]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 10853 is [True, False, False, False, False, True]
State prediction error at timestep 10853 is 0.012
Human Feedback received at timestep 10853 of None
Current timestep = 10854. State = [[-0.10087884  0.12987211]]. Action = [[-0.06599565 -0.04601152  0.          0.23893762]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 10854 is [True, False, False, False, False, True]
Current timestep = 10855. State = [[-0.10403343  0.13069117]]. Action = [[-0.03890405  0.02015306  0.         -0.8869537 ]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 10855 is [True, False, False, False, False, True]
State prediction error at timestep 10855 is 0.012
Human Feedback received at timestep 10855 of None
Current timestep = 10856. State = [[-0.1053656   0.13078585]]. Action = [[-0.01164399 -0.02954847  0.          0.84106874]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 10856 is [True, False, False, False, False, True]
Current timestep = 10857. State = [[-0.10530192  0.1355106 ]]. Action = [[ 0.00622388  0.09594012  0.         -0.26662463]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 10857 is [True, False, False, False, False, True]
State prediction error at timestep 10857 is 0.012
Human Feedback received at timestep 10857 of None
Current timestep = 10858. State = [[-0.10464142  0.1426927 ]]. Action = [[ 0.02108191  0.07441298  0.         -0.39787662]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 10858 is [True, False, False, False, False, True]
Current timestep = 10859. State = [[-0.1034694  0.1461615]]. Action = [[0.02578414 0.00721207 0.         0.95715463]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 10859 is [True, False, False, False, False, True]
Current timestep = 10860. State = [[-0.10677935  0.15061902]]. Action = [[-0.07266059  0.06352607  0.          0.40803695]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 10860 is [True, False, False, False, False, True]
Current timestep = 10861. State = [[-0.10449082  0.14921644]]. Action = [[ 0.09848689 -0.08784302  0.          0.42028558]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 10861 is [True, False, False, False, False, True]
State prediction error at timestep 10861 is 0.012
Human Feedback received at timestep 10861 of None
Current timestep = 10862. State = [[-0.10193653  0.14632402]]. Action = [[-0.00309423 -0.01923686  0.         -0.40460318]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 10862 is [True, False, False, False, False, True]
Current timestep = 10863. State = [[-0.10450928  0.14260411]]. Action = [[-0.06587285 -0.0717424   0.         -0.3300882 ]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 10863 is [True, False, False, False, False, True]
State prediction error at timestep 10863 is 0.012
Human Feedback received at timestep 10863 of None
Current timestep = 10864. State = [[-0.10469457  0.14143729]]. Action = [[ 0.02053299  0.01115926  0.         -0.870732  ]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 10864 is [True, False, False, False, False, True]
State prediction error at timestep 10864 is 0.012
Human Feedback received at timestep 10864 of None
Current timestep = 10865. State = [[-0.10128741  0.14364038]]. Action = [[ 0.05233019  0.04088343  0.         -0.08171535]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 10865 is [True, False, False, False, False, True]
Current timestep = 10866. State = [[-0.10266434  0.1454248 ]]. Action = [[-0.06632011  0.01176129  0.         -0.06534147]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 10866 is [True, False, False, False, False, True]
State prediction error at timestep 10866 is 0.012
Human Feedback received at timestep 10866 of None
Current timestep = 10867. State = [[-0.10580708  0.1494431 ]]. Action = [[-0.02784321  0.06603152  0.          0.10941958]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 10867 is [True, False, False, False, False, True]
State prediction error at timestep 10867 is 0.012
Human Feedback received at timestep 10867 of None
Current timestep = 10868. State = [[-0.10564812  0.15221475]]. Action = [[0.03009195 0.00806375 0.         0.7776756 ]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 10868 is [True, False, False, False, False, True]
Current timestep = 10869. State = [[-0.10938241  0.15446685]]. Action = [[-0.0853432   0.02733786  0.         -0.08160132]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 10869 is [True, False, False, False, False, True]
State prediction error at timestep 10869 is 0.012
Human Feedback received at timestep 10869 of None
Current timestep = 10870. State = [[-0.11299109  0.15499012]]. Action = [[-0.01626192 -0.02379994  0.         -0.62742484]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 10870 is [True, False, False, False, False, True]
State prediction error at timestep 10870 is 0.012
Human Feedback received at timestep 10870 of None
Current timestep = 10871. State = [[-0.11313821  0.15854749]]. Action = [[ 0.02279731  0.0702612   0.         -0.25214237]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 10871 is [True, False, False, False, False, True]
Current timestep = 10872. State = [[-0.11622186  0.15724444]]. Action = [[-0.06501566 -0.08276387  0.          0.8890829 ]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 10872 is [True, False, False, False, False, True]
State prediction error at timestep 10872 is 0.012
Human Feedback received at timestep 10872 of None
Current timestep = 10873. State = [[-0.12274107  0.15604304]]. Action = [[-0.08546627  0.00565406  0.          0.00323248]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 10873 is [True, False, False, False, False, True]
Current timestep = 10874. State = [[-0.12972565  0.1538026 ]]. Action = [[-0.07810842 -0.06360015  0.          0.2887336 ]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 10874 is [True, False, False, False, False, True]
Current timestep = 10875. State = [[-0.12913689  0.14845802]]. Action = [[ 0.07851505 -0.07687966  0.          0.87500525]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 10875 is [True, False, False, False, False, True]
Current timestep = 10876. State = [[-0.12892285  0.14581598]]. Action = [[-0.02972484  0.00123124  0.         -0.27644348]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 10876 is [True, False, False, False, False, True]
Current timestep = 10877. State = [[-0.12991166  0.14355047]]. Action = [[ 0.00190265 -0.0344139   0.         -0.05493826]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 10877 is [True, False, False, False, False, True]
Current timestep = 10878. State = [[-0.12758629  0.14200692]]. Action = [[ 0.05589134  0.00605303  0.         -0.22063977]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 10878 is [True, False, False, False, False, True]
Current timestep = 10879. State = [[-0.12832057  0.139736  ]]. Action = [[-0.03861222 -0.02700932  0.         -0.9003359 ]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 10879 is [True, False, False, False, False, True]
Current timestep = 10880. State = [[-0.12814787  0.13936956]]. Action = [[0.03406285 0.02870936 0.         0.44938457]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 10880 is [True, False, False, False, False, True]
Current timestep = 10881. State = [[-0.12934542  0.14149679]]. Action = [[-0.02805461  0.04760236  0.          0.25275922]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 10881 is [True, False, False, False, False, True]
Current timestep = 10882. State = [[-0.13153419  0.13755505]]. Action = [[-0.01691218 -0.09544591  0.          0.5318253 ]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 10882 is [True, False, False, False, False, True]
Current timestep = 10883. State = [[-0.12793054  0.13124835]]. Action = [[ 0.09096356 -0.05518366  0.          0.15273213]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 10883 is [True, False, False, False, False, True]
State prediction error at timestep 10883 is 0.012
Human Feedback received at timestep 10883 of None
Current timestep = 10884. State = [[-0.12090489  0.12708476]]. Action = [[ 0.09349854 -0.01744064  0.          0.85906935]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 10884 is [True, False, False, False, False, True]
Current timestep = 10885. State = [[-0.12110411  0.12583888]]. Action = [[-0.07152031  0.01663005  0.          0.7667451 ]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 10885 is [True, False, False, False, False, True]
Current timestep = 10886. State = [[-0.12401297  0.12228952]]. Action = [[-0.02471272 -0.05869547  0.         -0.93972284]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 10886 is [True, False, False, False, False, True]
Current timestep = 10887. State = [[-0.12310737  0.11991368]]. Action = [[ 0.03316892  0.00827776  0.         -0.33871228]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 10887 is [True, False, False, False, True, False]
State prediction error at timestep 10887 is 0.012
Human Feedback received at timestep 10887 of None
Current timestep = 10888. State = [[-0.12665842  0.11821733]]. Action = [[-0.09467956 -0.018569    0.         -0.74082375]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 10888 is [True, False, False, False, True, False]
Current timestep = 10889. State = [[-0.12597027  0.11822655]]. Action = [[ 0.08324695  0.02907147  0.         -0.59961534]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 10889 is [True, False, False, False, True, False]
Current timestep = 10890. State = [[-0.12480094  0.1137862 ]]. Action = [[-0.02523907 -0.09092374  0.          0.3676455 ]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 10890 is [True, False, False, False, True, False]
Current timestep = 10891. State = [[-0.12649119  0.1138989 ]]. Action = [[-0.02717391  0.06801794  0.         -0.4150185 ]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 10891 is [True, False, False, False, True, False]
Current timestep = 10892. State = [[-0.12350355  0.1110998 ]]. Action = [[ 0.07970626 -0.08231737  0.          0.61185384]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 10892 is [True, False, False, False, True, False]
State prediction error at timestep 10892 is 0.012
Human Feedback received at timestep 10892 of None
Current timestep = 10893. State = [[-0.12040714  0.11198372]]. Action = [[ 0.02032213  0.08336487  0.         -0.15443575]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 10893 is [True, False, False, False, True, False]
Current timestep = 10894. State = [[-0.11569617  0.11020436]]. Action = [[ 0.0860379  -0.06651995  0.          0.7277212 ]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 10894 is [True, False, False, False, True, False]
Current timestep = 10895. State = [[-0.11193269  0.10855928]]. Action = [[0.02299818 0.02241831 0.         0.52430594]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 10895 is [True, False, False, False, True, False]
Current timestep = 10896. State = [[-0.10801759  0.11185976]]. Action = [[ 0.06075133  0.07264242  0.         -0.87737125]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 10896 is [True, False, False, False, True, False]
Current timestep = 10897. State = [[-0.10560468  0.11763976]]. Action = [[0.01399902 0.08558684 0.         0.2694502 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 10897 is [True, False, False, False, True, False]
State prediction error at timestep 10897 is 0.012
Human Feedback received at timestep 10897 of None
Current timestep = 10898. State = [[-0.1054999   0.12024581]]. Action = [[-0.00907988  0.00087094  0.         -0.6397354 ]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 10898 is [True, False, False, False, True, False]
Current timestep = 10899. State = [[-0.10688057  0.12099627]]. Action = [[-0.03225815  0.00268871  0.          0.7975153 ]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 10899 is [True, False, False, False, True, False]
Current timestep = 10900. State = [[-0.10932127  0.12089568]]. Action = [[-0.04410158 -0.02118979  0.         -0.33796263]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 10900 is [True, False, False, False, True, False]
Current timestep = 10901. State = [[-0.10910976  0.11675064]]. Action = [[ 0.01341371 -0.09011696  0.         -0.8361747 ]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 10901 is [True, False, False, False, True, False]
State prediction error at timestep 10901 is 0.012
Human Feedback received at timestep 10901 of None
Current timestep = 10902. State = [[-0.1112288   0.11812572]]. Action = [[-0.06800912  0.06853824  0.          0.03960943]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 10902 is [True, False, False, False, True, False]
State prediction error at timestep 10902 is 0.012
Human Feedback received at timestep 10902 of None
Current timestep = 10903. State = [[-0.1159912  0.1236767]]. Action = [[-0.06750631  0.05199892  0.         -0.46289575]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 10903 is [True, False, False, False, True, False]
Current timestep = 10904. State = [[-0.11433582  0.12739086]]. Action = [[0.08195212 0.01986047 0.         0.7891066 ]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 10904 is [True, False, False, False, True, False]
State prediction error at timestep 10904 is 0.012
Human Feedback received at timestep 10904 of None
Current timestep = 10905. State = [[-0.11391785  0.1309186 ]]. Action = [[-0.03360524  0.03854644  0.         -0.76089394]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 10905 is [True, False, False, False, False, True]
State prediction error at timestep 10905 is 0.012
Human Feedback received at timestep 10905 of None
Current timestep = 10906. State = [[-0.11436889  0.13663808]]. Action = [[0.01331113 0.06942911 0.         0.01008642]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 10906 is [True, False, False, False, False, True]
Current timestep = 10907. State = [[-0.11669826  0.13538527]]. Action = [[-0.05192909 -0.09251188  0.         -0.22068179]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 10907 is [True, False, False, False, False, True]
Current timestep = 10908. State = [[-0.12134717  0.1373515 ]]. Action = [[-0.06502352  0.06741825  0.          0.21859682]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 10908 is [True, False, False, False, False, True]
Current timestep = 10909. State = [[-0.12563029  0.13730295]]. Action = [[-0.04165779 -0.0651562   0.          0.9587048 ]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 10909 is [True, False, False, False, False, True]
Current timestep = 10910. State = [[-0.12937306  0.13205047]]. Action = [[-0.04956677 -0.09346815  0.         -0.3191067 ]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 10910 is [True, False, False, False, False, True]
State prediction error at timestep 10910 is 0.012
Human Feedback received at timestep 10910 of None
Current timestep = 10911. State = [[-0.12891905  0.13059855]]. Action = [[ 0.04429377  0.01730573  0.         -0.22002923]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 10911 is [True, False, False, False, False, True]
Current timestep = 10912. State = [[-0.12396558  0.13493411]]. Action = [[0.09086626 0.0845725  0.         0.03639817]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 10912 is [True, False, False, False, False, True]
Current timestep = 10913. State = [[-0.12314992  0.14032106]]. Action = [[-0.01919128  0.066223    0.         -0.21017295]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 10913 is [True, False, False, False, False, True]
Current timestep = 10914. State = [[-0.12879851  0.14546154]]. Action = [[-0.09010285  0.05784497  0.         -0.4117266 ]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 10914 is [True, False, False, False, False, True]
State prediction error at timestep 10914 is 0.012
Human Feedback received at timestep 10914 of None
Current timestep = 10915. State = [[-0.13672562  0.1519092 ]]. Action = [[-0.08887532  0.07525625  0.          0.50894   ]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 10915 is [True, False, False, False, False, True]
Current timestep = 10916. State = [[-0.14264211  0.15722452]]. Action = [[-0.03716005  0.03332109  0.         -0.28507614]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 10916 is [True, False, False, False, False, True]
Current timestep = 10917. State = [[-0.14704588  0.15812045]]. Action = [[-0.03553055 -0.03459972  0.         -0.0210771 ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 10917 is [True, False, False, False, False, True]
Current timestep = 10918. State = [[-0.14606518  0.1564666 ]]. Action = [[ 0.0688119  -0.03855181  0.         -0.4720835 ]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 10918 is [True, False, False, False, False, True]
State prediction error at timestep 10918 is 0.012
Human Feedback received at timestep 10918 of None
Current timestep = 10919. State = [[-0.14378007  0.15252464]]. Action = [[ 0.02746529 -0.06578101  0.          0.31402397]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 10919 is [True, False, False, False, False, True]
Current timestep = 10920. State = [[-0.14219229  0.15289518]]. Action = [[0.02506114 0.04622153 0.         0.4013164 ]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 10920 is [True, False, False, False, False, True]
Current timestep = 10921. State = [[-0.14097312  0.1573353 ]]. Action = [[ 0.02375925  0.0681861   0.         -0.5623072 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 10921 is [True, False, False, False, False, True]
Current timestep = 10922. State = [[-0.13833724  0.15479366]]. Action = [[ 0.04941804 -0.08819519  0.         -0.6137061 ]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 10922 is [True, False, False, False, False, True]
State prediction error at timestep 10922 is 0.012
Human Feedback received at timestep 10922 of None
Current timestep = 10923. State = [[-0.13893074  0.15503028]]. Action = [[-0.04185097  0.06148607  0.          0.7547357 ]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 10923 is [True, False, False, False, False, True]
State prediction error at timestep 10923 is 0.012
Human Feedback received at timestep 10923 of None
Current timestep = 10924. State = [[-0.135961    0.15477897]]. Action = [[ 0.08433307 -0.03517185  0.         -0.428285  ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 10924 is [True, False, False, False, False, True]
Current timestep = 10925. State = [[-0.13016431  0.15460221]]. Action = [[0.06817282 0.02729899 0.         0.52011776]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 10925 is [True, False, False, False, False, True]
Current timestep = 10926. State = [[-0.12726381  0.15095066]]. Action = [[ 0.00618479 -0.075964    0.         -0.73737025]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 10926 is [True, False, False, False, False, True]
Current timestep = 10927. State = [[-0.12185879  0.1454151 ]]. Action = [[ 0.08373547 -0.05303596  0.         -0.01462108]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 10927 is [True, False, False, False, False, True]
Current timestep = 10928. State = [[-0.11407953  0.14637901]]. Action = [[ 0.08919486  0.07967772  0.         -0.18591893]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 10928 is [True, False, False, False, False, True]
Current timestep = 10929. State = [[-0.10622218  0.14642209]]. Action = [[ 0.08758698 -0.01430954  0.         -0.67100835]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 10929 is [True, False, False, False, False, True]
Current timestep = 10930. State = [[-0.10101675  0.14907688]]. Action = [[0.02940895 0.08565431 0.         0.08014798]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 10930 is [True, False, False, False, False, True]
Current timestep = 10931. State = [[-0.10236882  0.15416822]]. Action = [[-0.07275015  0.06418278  0.         -0.6713979 ]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 10931 is [True, False, False, False, False, True]
Current timestep = 10932. State = [[-0.10301989  0.15373531]]. Action = [[ 0.00275856 -0.0555365   0.         -0.9610977 ]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 10932 is [True, False, False, False, False, True]
Current timestep = 10933. State = [[-0.10212238  0.15086702]]. Action = [[-0.00876333 -0.03808036  0.         -0.5489694 ]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 10933 is [True, False, False, False, False, True]
Current timestep = 10934. State = [[-0.09805186  0.14914668]]. Action = [[ 0.05994587 -0.01854946  0.         -0.7125491 ]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 10934 is [True, False, False, False, False, True]
Current timestep = 10935. State = [[-0.09978478  0.15184604]]. Action = [[-0.09801771  0.05837224  0.         -0.92391616]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 10935 is [True, False, False, False, False, True]
Current timestep = 10936. State = [[-0.10549337  0.15733972]]. Action = [[-0.08020438  0.0550838   0.         -0.41460288]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 10936 is [True, False, False, False, False, True]
Current timestep = 10937. State = [[-0.10609724  0.16495246]]. Action = [[0.04081195 0.09298367 0.         0.29546583]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 10937 is [True, False, False, False, False, True]
Current timestep = 10938. State = [[-0.10789749  0.16585451]]. Action = [[-0.06163377 -0.07100143  0.          0.06236541]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 10938 is [True, False, False, False, False, True]
Current timestep = 10939. State = [[-0.1141687   0.16629682]]. Action = [[-0.09525122  0.0123059   0.          0.20644939]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 10939 is [True, False, False, False, False, True]
Current timestep = 10940. State = [[-0.12142257  0.1668049 ]]. Action = [[-0.08789315 -0.03286413  0.         -0.72408485]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 10940 is [True, False, False, False, False, True]
Current timestep = 10941. State = [[-0.1242358  0.1654487]]. Action = [[ 0.00392071 -0.04170296  0.          0.958508  ]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 10941 is [True, False, False, False, False, True]
Current timestep = 10942. State = [[-0.12854308  0.16757071]]. Action = [[-0.07399489  0.04605817  0.          0.49608183]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 10942 is [True, False, False, False, False, True]
Current timestep = 10943. State = [[-0.13293703  0.1665684 ]]. Action = [[-0.02830459 -0.06705356  0.         -0.13050342]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 10943 is [True, False, False, False, False, True]
Current timestep = 10944. State = [[-0.13330437  0.16962172]]. Action = [[ 0.03742034  0.090925    0.         -0.23159742]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 10944 is [True, False, False, False, False, True]
State prediction error at timestep 10944 is 0.012
Human Feedback received at timestep 10944 of None
Current timestep = 10945. State = [[-0.13751344  0.17339648]]. Action = [[-0.07984257  0.01732445  0.         -0.77198225]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 10945 is [True, False, False, False, False, True]
Current timestep = 10946. State = [[-0.137054    0.17363195]]. Action = [[ 0.09164522 -0.01203309  0.         -0.19467604]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 10946 is [True, False, False, False, False, True]
Current timestep = 10947. State = [[-0.1361632   0.17366448]]. Action = [[-0.00411069  0.01199257  0.         -0.20928401]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 10947 is [True, False, False, False, False, True]
Current timestep = 10948. State = [[-0.13895388  0.17737943]]. Action = [[-0.03328452  0.07154653  0.          0.02888143]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 10948 is [True, False, False, False, False, True]
Current timestep = 10949. State = [[-0.13652813  0.17499   ]]. Action = [[ 0.0916735  -0.08798158  0.         -0.75935495]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 10949 is [True, False, False, False, False, True]
Current timestep = 10950. State = [[-0.1368313   0.17155556]]. Action = [[-0.04889549 -0.01089495  0.         -0.88993037]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 10950 is [True, False, False, False, False, True]
State prediction error at timestep 10950 is 0.012
Human Feedback received at timestep 10950 of None
Current timestep = 10951. State = [[-0.13980357  0.16673042]]. Action = [[-0.03312524 -0.08460835  0.          0.05551612]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 10951 is [True, False, False, False, False, True]
Current timestep = 10952. State = [[-0.14044027  0.16715297]]. Action = [[ 0.00938195  0.06554117  0.         -0.445221  ]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 10952 is [True, False, False, False, False, True]
Current timestep = 10953. State = [[-0.14332148  0.16679129]]. Action = [[-0.05890745 -0.03724082  0.          0.8159225 ]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 10953 is [True, False, False, False, False, True]
State prediction error at timestep 10953 is 0.012
Human Feedback received at timestep 10953 of None
Current timestep = 10954. State = [[-0.14508991  0.16705099]]. Action = [[0.00345407 0.02778483 0.         0.26958072]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 10954 is [True, False, False, False, False, True]
Current timestep = 10955. State = [[-0.14404957  0.1631241 ]]. Action = [[ 0.02796844 -0.08817425  0.          0.44703317]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 10955 is [True, False, False, False, False, True]
Current timestep = 10956. State = [[-0.14065583  0.15526946]]. Action = [[ 0.05012447 -0.09420633  0.         -0.4965471 ]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 10956 is [True, False, False, False, False, True]
Current timestep = 10957. State = [[-0.13727623  0.1555444 ]]. Action = [[ 0.03499401  0.08987544  0.         -0.8597472 ]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 10957 is [True, False, False, False, False, True]
Current timestep = 10958. State = [[-0.136178    0.16142951]]. Action = [[0.008671   0.09352333 0.         0.78038585]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 10958 is [True, False, False, False, False, True]
Current timestep = 10959. State = [[-0.14000472  0.16028146]]. Action = [[-0.08501521 -0.07285375  0.         -0.31120038]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 10959 is [True, False, False, False, False, True]
Current timestep = 10960. State = [[-0.13889335  0.15978506]]. Action = [[0.09194245 0.04196686 0.         0.78217065]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 10960 is [True, False, False, False, False, True]
Current timestep = 10961. State = [[-0.13558663  0.15646212]]. Action = [[ 0.01409253 -0.07901222  0.         -0.4413712 ]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 10961 is [True, False, False, False, False, True]
State prediction error at timestep 10961 is 0.012
Human Feedback received at timestep 10961 of None
Current timestep = 10962. State = [[-0.13599263  0.15553495]]. Action = [[-0.03077843  0.03398808  0.         -0.26074457]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 10962 is [True, False, False, False, False, True]
State prediction error at timestep 10962 is 0.012
Human Feedback received at timestep 10962 of None
Current timestep = 10963. State = [[-0.13939835  0.15222365]]. Action = [[-0.06574507 -0.08477079  0.          0.19567525]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 10963 is [True, False, False, False, False, True]
State prediction error at timestep 10963 is 0.012
Human Feedback received at timestep 10963 of None
Current timestep = 10964. State = [[-0.14399266  0.15351023]]. Action = [[-0.06832276  0.06923073  0.         -0.7084198 ]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 10964 is [True, False, False, False, False, True]
Current timestep = 10965. State = [[-0.14786696  0.15494125]]. Action = [[-0.03739298 -0.01897591  0.          0.6216861 ]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 10965 is [True, False, False, False, False, True]
Current timestep = 10966. State = [[-0.15009552  0.15762612]]. Action = [[-0.01483416  0.05315752  0.         -0.10537875]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 10966 is [True, False, False, False, False, True]
State prediction error at timestep 10966 is 0.012
Human Feedback received at timestep 10966 of None
Current timestep = 10967. State = [[-0.15098311  0.16186132]]. Action = [[0.00922229 0.04571138 0.         0.43603468]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 10967 is [True, False, False, False, False, True]
State prediction error at timestep 10967 is 0.012
Human Feedback received at timestep 10967 of None
Current timestep = 10968. State = [[-0.1492454   0.16262852]]. Action = [[ 0.05227823 -0.01911608  0.          0.07600176]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 10968 is [True, False, False, False, False, True]
State prediction error at timestep 10968 is 0.012
Human Feedback received at timestep 10968 of None
Current timestep = 10969. State = [[-0.14510667  0.16492607]]. Action = [[0.07470889 0.05807472 0.         0.56566286]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 10969 is [True, False, False, False, False, True]
State prediction error at timestep 10969 is 0.012
Human Feedback received at timestep 10969 of None
Current timestep = 10970. State = [[-0.14730738  0.1665055 ]]. Action = [[-0.08210552 -0.00458409  0.         -0.7141086 ]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 10970 is [True, False, False, False, False, True]
State prediction error at timestep 10970 is 0.012
Human Feedback received at timestep 10970 of None
Current timestep = 10971. State = [[-0.14633025  0.16437526]]. Action = [[ 0.08591599 -0.04222031  0.         -0.57949454]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 10971 is [True, False, False, False, False, True]
Current timestep = 10972. State = [[-0.14020255  0.15774456]]. Action = [[ 0.08747322 -0.09765902  0.         -0.31243038]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 10972 is [True, False, False, False, False, True]
Current timestep = 10973. State = [[-0.13738252  0.15488389]]. Action = [[ 4.4807047e-04  2.0178892e-02  0.0000000e+00 -9.0423268e-01]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 10973 is [True, False, False, False, False, True]
Current timestep = 10974. State = [[-0.13551365  0.1582827 ]]. Action = [[0.03174608 0.07791974 0.         0.5218928 ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 10974 is [True, False, False, False, False, True]
Current timestep = 10975. State = [[-0.1314536   0.15797059]]. Action = [[ 0.06138498 -0.03514542  0.         -0.6049867 ]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 10975 is [True, False, False, False, False, True]
Current timestep = 10976. State = [[-0.13171422  0.15859254]]. Action = [[-0.05250511  0.04413987  0.         -0.9886281 ]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 10976 is [True, False, False, False, False, True]
Current timestep = 10977. State = [[-0.13282338  0.15521646]]. Action = [[-0.00874561 -0.09059855  0.          0.1926434 ]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 10977 is [True, False, False, False, False, True]
Current timestep = 10978. State = [[-0.13240717  0.15583068]]. Action = [[-0.00111314  0.06624768  0.          0.5356504 ]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 10978 is [True, False, False, False, False, True]
Current timestep = 10979. State = [[-0.13479052  0.15812276]]. Action = [[-0.05613831  0.00802103  0.         -0.2648729 ]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 10979 is [True, False, False, False, False, True]
Current timestep = 10980. State = [[-0.13174815  0.1558788 ]]. Action = [[ 0.08771699 -0.05631629  0.          0.21401262]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 10980 is [True, False, False, False, False, True]
Current timestep = 10981. State = [[-0.12425295  0.15531074]]. Action = [[ 0.09568343  0.02885916  0.         -0.32275522]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 10981 is [True, False, False, False, False, True]
Current timestep = 10982. State = [[-0.1203376   0.15552922]]. Action = [[ 0.01117513  0.0010216   0.         -0.5473026 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 10982 is [True, False, False, False, False, True]
Current timestep = 10983. State = [[-0.11422575  0.15061727]]. Action = [[ 0.09682161 -0.08985371  0.          0.43820655]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 10983 is [True, False, False, False, False, True]
Current timestep = 10984. State = [[-0.1070956   0.14851807]]. Action = [[0.06461561 0.03062611 0.         0.79679275]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 10984 is [True, False, False, False, False, True]
State prediction error at timestep 10984 is 0.012
Human Feedback received at timestep 10984 of None
Current timestep = 10985. State = [[-0.10504002  0.14885622]]. Action = [[-0.02460372  0.01077261  0.         -0.25812173]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 10985 is [True, False, False, False, False, True]
State prediction error at timestep 10985 is 0.012
Human Feedback received at timestep 10985 of None
Current timestep = 10986. State = [[-0.10659957  0.14810312]]. Action = [[-0.04945363 -0.0146025   0.         -0.9462788 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 10986 is [True, False, False, False, False, True]
Current timestep = 10987. State = [[-0.10855629  0.14556839]]. Action = [[-0.04139387 -0.04402149  0.         -0.10369879]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 10987 is [True, False, False, False, False, True]
State prediction error at timestep 10987 is 0.012
Human Feedback received at timestep 10987 of None
Current timestep = 10988. State = [[-0.10554014  0.14411116]]. Action = [[ 0.06375469 -0.00232881  0.         -0.13428539]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 10988 is [True, False, False, False, False, True]
Current timestep = 10989. State = [[-0.10326308  0.1478002 ]]. Action = [[-0.00770009  0.08128574  0.         -0.11397457]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 10989 is [True, False, False, False, False, True]
Current timestep = 10990. State = [[-0.1043628   0.15329891]]. Action = [[-0.02958935  0.05910081  0.          0.6776141 ]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 10990 is [True, False, False, False, False, True]
Current timestep = 10991. State = [[-0.10398197  0.1585763 ]]. Action = [[ 0.02319084  0.05662642  0.         -0.31681228]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 10991 is [True, False, False, False, False, True]
Current timestep = 10992. State = [[-0.09973743  0.16512795]]. Action = [[ 0.08269753  0.08498753  0.         -0.90620935]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 10992 is [True, False, False, False, False, True]
Current timestep = 10993. State = [[-0.09739772  0.16430521]]. Action = [[ 5.1434338e-04 -8.2515739e-02  0.0000000e+00  6.4458656e-01]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 10993 is [True, False, False, False, False, True]
Current timestep = 10994. State = [[-0.0976868   0.16314074]]. Action = [[-0.01216619  0.00745396  0.          0.3823626 ]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 10994 is [True, False, False, False, False, True]
State prediction error at timestep 10994 is 0.012
Human Feedback received at timestep 10994 of None
Current timestep = 10995. State = [[-0.09709442  0.16718997]]. Action = [[0.01816156 0.06661139 0.         0.5628829 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 10995 is [True, False, False, False, False, True]
Current timestep = 10996. State = [[-0.09718193  0.17094028]]. Action = [[-0.00853081  0.02239127  0.         -0.8390219 ]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 10996 is [True, False, False, False, False, True]
Current timestep = 10997. State = [[-0.09747109  0.1685398 ]]. Action = [[-0.00454681 -0.08107284  0.          0.7482866 ]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 10997 is [True, False, False, False, False, True]
Current timestep = 10998. State = [[-0.09455132  0.16972856]]. Action = [[ 0.05599494  0.05965105  0.         -0.5830245 ]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 10998 is [True, False, False, False, False, True]
State prediction error at timestep 10998 is 0.012
Human Feedback received at timestep 10998 of None
Current timestep = 10999. State = [[-0.08879732  0.16765583]]. Action = [[ 0.07670071 -0.07738702  0.         -0.7637402 ]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 10999 is [True, False, False, False, False, True]
Current timestep = 11000. State = [[-0.0871194   0.16654006]]. Action = [[-0.03020214  0.02274393  0.         -0.72875357]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 11000 is [True, False, False, False, False, True]
Current timestep = 11001. State = [[-0.0864585   0.17165291]]. Action = [[ 0.01331173  0.08935643  0.         -0.549898  ]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 11001 is [True, False, False, False, False, True]
Current timestep = 11002. State = [[-0.08214826  0.17626232]]. Action = [[ 0.07593026  0.03786141  0.         -0.503537  ]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 11002 is [True, False, False, False, False, True]
Current timestep = 11003. State = [[-0.08229505  0.17990854]]. Action = [[-0.05595533  0.04237654  0.          0.3913567 ]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 11003 is [True, False, False, False, False, True]
Current timestep = 11004. State = [[-0.07897734  0.17770867]]. Action = [[ 0.08963802 -0.08106712  0.          0.06311083]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 11004 is [True, False, False, False, False, True]
Current timestep = 11005. State = [[-0.07538924  0.17533454]]. Action = [[ 0.00825898 -0.00436807  0.         -0.96357286]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 11005 is [True, False, False, False, False, True]
Current timestep = 11006. State = [[-0.07447971  0.17049953]]. Action = [[-0.01135396 -0.09568069  0.          0.72642684]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 11006 is [True, False, False, False, False, True]
Current timestep = 11007. State = [[-0.06985691  0.1715949 ]]. Action = [[ 0.08412958  0.08483499  0.         -0.12814307]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 11007 is [True, False, False, False, False, True]
Current timestep = 11008. State = [[-0.06880367  0.16986592]]. Action = [[-0.06906883 -0.08486742  0.         -0.20257664]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 11008 is [True, False, False, False, False, True]
State prediction error at timestep 11008 is 0.012
Human Feedback received at timestep 11008 of None
Current timestep = 11009. State = [[-0.06682485  0.16388033]]. Action = [[ 0.05052287 -0.07167206  0.          0.5941838 ]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 11009 is [True, False, False, False, False, True]
State prediction error at timestep 11009 is 0.012
Human Feedback received at timestep 11009 of None
Current timestep = 11010. State = [[-0.06661096  0.16579229]]. Action = [[-0.04390359  0.09549404  0.          0.823735  ]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 11010 is [True, False, False, False, False, True]
State prediction error at timestep 11010 is 0.012
Human Feedback received at timestep 11010 of None
Current timestep = 11011. State = [[-0.06778964  0.16958736]]. Action = [[-0.0093549   0.02422214  0.         -0.49341673]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 11011 is [True, False, False, False, False, True]
Current timestep = 11012. State = [[-0.07197801  0.16652928]]. Action = [[-0.09337255 -0.08759155  0.          0.8727827 ]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 11012 is [True, False, False, False, False, True]
Current timestep = 11013. State = [[-0.07837068  0.1646052 ]]. Action = [[-0.09101397 -0.00216687  0.          0.2511891 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 11013 is [True, False, False, False, False, True]
Current timestep = 11014. State = [[-0.07903505  0.16103202]]. Action = [[ 0.03814467 -0.07780115  0.          0.18023825]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 11014 is [True, False, False, False, False, True]
Current timestep = 11015. State = [[-0.07688643  0.16222277]]. Action = [[ 0.02845616  0.07412536  0.         -0.03594291]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 11015 is [True, False, False, False, False, True]
Current timestep = 11016. State = [[-0.07453744  0.1647319 ]]. Action = [[ 0.04614224  0.01830034  0.         -0.8519302 ]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 11016 is [True, False, False, False, False, True]
Current timestep = 11017. State = [[-0.07781843  0.16074474]]. Action = [[-0.09730516 -0.09275361  0.          0.58000267]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 11017 is [True, False, False, False, False, True]
Current timestep = 11018. State = [[-0.07878332  0.1576433 ]]. Action = [[0.05611203 0.00157058 0.         0.7082025 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 11018 is [True, False, False, False, False, True]
State prediction error at timestep 11018 is 0.012
Human Feedback received at timestep 11018 of None
Current timestep = 11019. State = [[-0.07959556  0.15868679]]. Action = [[-0.03119873  0.03696012  0.         -0.09073734]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 11019 is [True, False, False, False, False, True]
Current timestep = 11020. State = [[-0.08466846  0.15655199]]. Action = [[-0.07633354 -0.0589016   0.         -0.8413142 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 11020 is [True, False, False, False, False, True]
Current timestep = 11021. State = [[-0.09007036  0.15805228]]. Action = [[-0.05443681  0.06367568  0.          0.66649175]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 11021 is [True, False, False, False, False, True]
State prediction error at timestep 11021 is 0.012
Human Feedback received at timestep 11021 of None
Current timestep = 11022. State = [[-0.09237819  0.16307424]]. Action = [[ 0.01170181  0.06441052  0.         -0.49415374]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 11022 is [True, False, False, False, False, True]
Current timestep = 11023. State = [[-0.09383498  0.1636319 ]]. Action = [[-0.00426714 -0.03030118  0.          0.77715814]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 11023 is [True, False, False, False, False, True]
Current timestep = 11024. State = [[-0.09740344  0.16312116]]. Action = [[-0.046034    0.00203081  0.         -0.90298975]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 11024 is [True, False, False, False, False, True]
Current timestep = 11025. State = [[-0.09616906  0.16554193]]. Action = [[ 0.08387352  0.0495084   0.         -0.6800459 ]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 11025 is [True, False, False, False, False, True]
State prediction error at timestep 11025 is 0.012
Human Feedback received at timestep 11025 of None
Current timestep = 11026. State = [[-0.09154733  0.16325533]]. Action = [[ 0.07182281 -0.06709275  0.          0.5691699 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 11026 is [True, False, False, False, False, True]
Current timestep = 11027. State = [[-0.09288032  0.1618545 ]]. Action = [[-0.06403591  0.01838007  0.         -0.6340245 ]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 11027 is [True, False, False, False, False, True]
State prediction error at timestep 11027 is 0.012
Human Feedback received at timestep 11027 of None
Current timestep = 11028. State = [[-0.09330912  0.1626577 ]]. Action = [[0.03320556 0.01122537 0.         0.37779295]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 11028 is [True, False, False, False, False, True]
Current timestep = 11029. State = [[-0.09662239  0.16751346]]. Action = [[-0.07463318  0.09244711  0.         -0.7328222 ]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 11029 is [True, False, False, False, False, True]
Current timestep = 11030. State = [[-0.09680544  0.17038679]]. Action = [[ 0.05326883 -0.0028552   0.         -0.24052823]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 11030 is [True, False, False, False, False, True]
State prediction error at timestep 11030 is 0.012
Human Feedback received at timestep 11030 of None
Current timestep = 11031. State = [[-0.09654316  0.16802965]]. Action = [[-0.01355314 -0.05359368  0.          0.84475875]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 11031 is [True, False, False, False, False, True]
Current timestep = 11032. State = [[-0.09569795  0.16675754]]. Action = [[ 0.02555377  0.00157319  0.         -0.6126278 ]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 11032 is [True, False, False, False, False, True]
Current timestep = 11033. State = [[-0.09277351  0.16896762]]. Action = [[0.04945929 0.0474144  0.         0.02837801]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 11033 is [True, False, False, False, False, True]
Current timestep = 11034. State = [[-0.08745586  0.17441215]]. Action = [[0.08941648 0.09000332 0.         0.51373696]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 11034 is [True, False, False, False, False, True]
Current timestep = 11035. State = [[-0.08794406  0.18063843]]. Action = [[-0.05747692  0.07351743  0.         -0.45930207]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 11035 is [True, False, False, False, False, True]
Current timestep = 11036. State = [[-0.08644619  0.18621287]]. Action = [[ 0.07861374  0.06170297  0.         -0.85781145]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 11036 is [True, False, False, False, False, True]
Current timestep = 11037. State = [[-0.08695919  0.18604845]]. Action = [[-0.05432397 -0.05637991  0.         -0.84275234]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 11037 is [True, False, False, False, False, True]
Current timestep = 11038. State = [[-0.08816852  0.18114056]]. Action = [[ 0.00503539 -0.08476716  0.         -0.5701357 ]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 11038 is [True, False, False, False, False, True]
Current timestep = 11039. State = [[-0.08996413  0.17545424]]. Action = [[-0.04737214 -0.07655091  0.          0.23707175]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 11039 is [True, False, False, False, False, True]
Current timestep = 11040. State = [[-0.08685834  0.17607531]]. Action = [[0.09261418 0.0612557  0.         0.48241043]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 11040 is [True, False, False, False, False, True]
Current timestep = 11041. State = [[-0.08495     0.17492467]]. Action = [[-0.03571801 -0.0587217   0.          0.06061184]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 11041 is [True, False, False, False, False, True]
Current timestep = 11042. State = [[-0.08012235  0.16981965]]. Action = [[ 0.09642392 -0.06670132  0.          0.6368717 ]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 11042 is [True, False, False, False, False, True]
Current timestep = 11043. State = [[-0.07209145  0.16930082]]. Action = [[0.08873452 0.05030904 0.         0.87617934]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 11043 is [True, False, False, False, False, True]
Current timestep = 11044. State = [[-0.06810245  0.17036018]]. Action = [[0.00886619 0.01807632 0.         0.30205524]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 11044 is [True, False, False, False, False, True]
Current timestep = 11045. State = [[-0.06248865  0.16585982]]. Action = [[ 0.08280752 -0.08289794  0.          0.8821528 ]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 11045 is [True, False, False, False, False, True]
Current timestep = 11046. State = [[-0.05590557  0.1627069 ]]. Action = [[0.05702668 0.01091994 0.         0.46036994]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 11046 is [True, False, False, False, False, True]
Current timestep = 11047. State = [[-0.04983568  0.16444759]]. Action = [[0.06283421 0.06104007 0.         0.39633358]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 11047 is [True, False, False, False, False, True]
Current timestep = 11048. State = [[-0.04919538  0.16739558]]. Action = [[-0.05007261  0.04401154  0.          0.09622252]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 11048 is [False, True, False, False, False, True]
Current timestep = 11049. State = [[-0.04735034  0.1724315 ]]. Action = [[ 0.04872537  0.08176879  0.         -0.50411   ]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 11049 is [False, True, False, False, False, True]
Current timestep = 11050. State = [[-0.04826375  0.17090593]]. Action = [[-0.07389423 -0.08729958  0.          0.02730763]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 11050 is [False, True, False, False, False, True]
Current timestep = 11051. State = [[-0.05286651  0.17365822]]. Action = [[-0.07063131  0.09118209  0.         -0.34645665]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 11051 is [False, True, False, False, False, True]
Current timestep = 11052. State = [[-0.05910206  0.17493054]]. Action = [[-0.09187883 -0.05119357  0.         -0.7973365 ]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 11052 is [True, False, False, False, False, True]
Current timestep = 11053. State = [[-0.05864289  0.17130925]]. Action = [[ 0.06043483 -0.07205141  0.          0.8826573 ]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 11053 is [True, False, False, False, False, True]
Current timestep = 11054. State = [[-0.05286505  0.17324974]]. Action = [[ 0.08442382  0.07343072  0.         -0.22905648]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 11054 is [True, False, False, False, False, True]
Current timestep = 11055. State = [[-0.04739565  0.17179507]]. Action = [[ 0.06194546 -0.06978125  0.         -0.6435952 ]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 11055 is [True, False, False, False, False, True]
State prediction error at timestep 11055 is 0.012
Human Feedback received at timestep 11055 of None
Current timestep = 11056. State = [[-0.04217966  0.17341007]]. Action = [[ 0.06089441  0.07910433  0.         -0.3597656 ]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 11056 is [False, True, False, False, False, True]
Current timestep = 11057. State = [[-0.03677166  0.1747302 ]]. Action = [[ 0.07012779 -0.00680933  0.          0.38890553]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 11057 is [False, True, False, False, False, True]
Current timestep = 11058. State = [[-0.03381009  0.17702189]]. Action = [[0.01034433 0.05791176 0.         0.7557223 ]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 11058 is [False, True, False, False, False, True]
Current timestep = 11059. State = [[-0.03674633  0.1752712 ]]. Action = [[-0.09324361 -0.0735264   0.         -0.77721107]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 11059 is [False, True, False, False, False, True]
State prediction error at timestep 11059 is 0.012
Human Feedback received at timestep 11059 of None
Current timestep = 11060. State = [[-0.03854715  0.17777975]]. Action = [[ 0.00563174  0.08551466  0.         -0.8654568 ]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 11060 is [False, True, False, False, False, True]
Current timestep = 11061. State = [[-0.03820176  0.17732897]]. Action = [[-0.00316669 -0.0672665   0.          0.03159463]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 11061 is [False, True, False, False, False, True]
Current timestep = 11062. State = [[-0.03977861  0.1762783 ]]. Action = [[-0.04821678  0.00333875  0.          0.4640751 ]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 11062 is [False, True, False, False, False, True]
Current timestep = 11063. State = [[-0.04394192  0.18047613]]. Action = [[-0.0720372   0.06693051  0.         -0.59989464]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 11063 is [False, True, False, False, False, True]
State prediction error at timestep 11063 is 0.012
Human Feedback received at timestep 11063 of None
Current timestep = 11064. State = [[-0.04223653  0.1796358 ]]. Action = [[ 0.07216888 -0.07616825  0.          0.68127906]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 11064 is [False, True, False, False, False, True]
Current timestep = 11065. State = [[-0.04427436  0.17987987]]. Action = [[-0.09108072  0.03600944  0.         -0.6659534 ]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 11065 is [False, True, False, False, False, True]
State prediction error at timestep 11065 is 0.012
Human Feedback received at timestep 11065 of None
Current timestep = 11066. State = [[-0.04192386  0.1767421 ]]. Action = [[ 0.09690107 -0.09454363  0.         -0.76925063]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 11066 is [False, True, False, False, False, True]
Current timestep = 11067. State = [[-0.03824512  0.17490304]]. Action = [[0.01501098 0.01997123 0.         0.42059815]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 11067 is [False, True, False, False, False, True]
Current timestep = 11068. State = [[-0.03757443  0.1705238 ]]. Action = [[-0.00986934 -0.09280766  0.          0.10325432]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 11068 is [False, True, False, False, False, True]
Current timestep = 11069. State = [[-0.04104332  0.16318853]]. Action = [[-0.09217878 -0.0915181   0.          0.47411513]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 11069 is [False, True, False, False, False, True]
Current timestep = 11070. State = [[-0.0467393   0.15954472]]. Action = [[-0.09364752 -0.017735    0.          0.5623393 ]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 11070 is [False, True, False, False, False, True]
Current timestep = 11071. State = [[-0.05244298  0.15427376]]. Action = [[-0.08216713 -0.09465951  0.         -0.94358355]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 11071 is [False, True, False, False, False, True]
Current timestep = 11072. State = [[-0.05808708  0.151745  ]]. Action = [[-0.07933807  0.00526742  0.         -0.1334089 ]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 11072 is [True, False, False, False, False, True]
Current timestep = 11073. State = [[-0.06164359  0.15376449]]. Action = [[-0.02005117  0.04343308  0.          0.54648113]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 11073 is [True, False, False, False, False, True]
Current timestep = 11074. State = [[-0.06002601  0.15798467]]. Action = [[ 0.079992    0.07043248  0.         -0.07174385]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 11074 is [True, False, False, False, False, True]
Current timestep = 11075. State = [[-0.05822812  0.15959936]]. Action = [[ 0.03335143  0.00619175  0.         -0.20727265]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 11075 is [True, False, False, False, False, True]
State prediction error at timestep 11075 is 0.012
Human Feedback received at timestep 11075 of None
Current timestep = 11076. State = [[-0.06240109  0.1551959 ]]. Action = [[-0.08840542 -0.08621134  0.          0.47829676]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 11076 is [True, False, False, False, False, True]
Current timestep = 11077. State = [[-0.0640106   0.15575846]]. Action = [[ 0.06056079  0.07945073  0.         -0.6055254 ]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 11077 is [True, False, False, False, False, True]
State prediction error at timestep 11077 is 0.012
Human Feedback received at timestep 11077 of None
Current timestep = 11078. State = [[-0.06429559  0.1541699 ]]. Action = [[-0.01020078 -0.06084838  0.          0.6269032 ]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 11078 is [True, False, False, False, False, True]
Current timestep = 11079. State = [[-0.06307559  0.15639654]]. Action = [[ 0.05557511  0.09517319  0.         -0.6969083 ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 11079 is [True, False, False, False, False, True]
Current timestep = 11080. State = [[-0.06245214  0.16117921]]. Action = [[ 0.01290462  0.05886035  0.         -0.7417594 ]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 11080 is [True, False, False, False, False, True]
Current timestep = 11081. State = [[-0.05876205  0.15841013]]. Action = [[ 0.09240838 -0.08041483  0.          0.876878  ]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 11081 is [True, False, False, False, False, True]
Current timestep = 11082. State = [[-0.05585432  0.15173319]]. Action = [[ 0.01595781 -0.0717657   0.         -0.88021755]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 11082 is [True, False, False, False, False, True]
State prediction error at timestep 11082 is 0.012
Human Feedback received at timestep 11082 of None
Current timestep = 11083. State = [[-0.05706478  0.15042146]]. Action = [[-0.0388237   0.03510656  0.         -0.86451834]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 11083 is [True, False, False, False, False, True]
Current timestep = 11084. State = [[-0.05900712  0.14811605]]. Action = [[-0.02417142 -0.05463758  0.          0.07636642]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 11084 is [True, False, False, False, False, True]
State prediction error at timestep 11084 is 0.012
Human Feedback received at timestep 11084 of None
Current timestep = 11085. State = [[-0.05706418  0.14795433]]. Action = [[ 0.0497972   0.03885371  0.         -0.794651  ]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 11085 is [True, False, False, False, False, True]
State prediction error at timestep 11085 is 0.012
Human Feedback received at timestep 11085 of None
Current timestep = 11086. State = [[-0.05708975  0.14460136]]. Action = [[-0.03885515 -0.07917428  0.          0.7507769 ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 11086 is [True, False, False, False, False, True]
State prediction error at timestep 11086 is 0.012
Human Feedback received at timestep 11086 of None
Current timestep = 11087. State = [[-0.05372045  0.14200431]]. Action = [[0.08507135 0.00698471 0.         0.8080394 ]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 11087 is [True, False, False, False, False, True]
Current timestep = 11088. State = [[-0.05242649  0.1385118 ]]. Action = [[-0.04002157 -0.05726147  0.          0.24565065]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 11088 is [True, False, False, False, False, True]
Current timestep = 11089. State = [[-0.05353528  0.13324253]]. Action = [[-0.0228125  -0.06042478  0.          0.37340367]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 11089 is [True, False, False, False, False, True]
Current timestep = 11090. State = [[-0.05321548  0.1265389 ]]. Action = [[-0.00217719 -0.08308651  0.          0.04459536]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 11090 is [True, False, False, False, False, True]
Current timestep = 11091. State = [[-0.05235472  0.11894055]]. Action = [[-0.005686   -0.08145603  0.         -0.7577157 ]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 11091 is [True, False, False, False, False, True]
Current timestep = 11092. State = [[-0.33614534  0.02943438]]. Action = [[ 0.05572242 -0.00067271  0.          0.01838648]]. Reward = [100.]
Curr episode timestep = 511
Scene graph at timestep 11092 is [True, False, False, False, True, False]
Current timestep = 11093. State = [[-0.33014938  0.03066675]]. Action = [[ 0.081841   -0.04303649  0.         -0.60746926]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 11093 is [True, False, False, False, True, False]
State prediction error at timestep 11093 is 0.012
Human Feedback received at timestep 11093 of None
Current timestep = 11094. State = [[-0.3235147   0.02477284]]. Action = [[ 0.08691531 -0.09244271  0.          0.76299775]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 11094 is [True, False, False, False, True, False]
Current timestep = 11095. State = [[-0.31817988  0.01790472]]. Action = [[ 0.03982779 -0.06919086  0.         -0.94676226]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 11095 is [True, False, False, False, True, False]
Current timestep = 11096. State = [[-0.3117175  0.0100133]]. Action = [[ 0.07787464 -0.09355526  0.         -0.8525678 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 11096 is [True, False, False, False, True, False]
Current timestep = 11097. State = [[-0.30532163  0.00360878]]. Action = [[ 0.04849298 -0.04142705  0.         -0.6055323 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 11097 is [True, False, False, False, True, False]
Current timestep = 11098. State = [[-0.30481952 -0.00365892]]. Action = [[-0.0665549  -0.08395771  0.          0.9419055 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 11098 is [True, False, False, False, True, False]
Current timestep = 11099. State = [[-0.30267364 -0.01098388]]. Action = [[ 0.03949792 -0.05646346  0.          0.3331735 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 11099 is [True, False, False, False, True, False]
State prediction error at timestep 11099 is 0.012
Human Feedback received at timestep 11099 of None
Current timestep = 11100. State = [[-0.29981363 -0.01553551]]. Action = [[ 0.00230283 -0.01178551  0.         -0.22024798]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 11100 is [True, False, False, False, True, False]
Current timestep = 11101. State = [[-0.3007714 -0.0141679]]. Action = [[-0.05201938  0.0753546   0.         -0.6055592 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 11101 is [True, False, False, False, True, False]
State prediction error at timestep 11101 is 0.012
Human Feedback received at timestep 11101 of None
Current timestep = 11102. State = [[-0.3023675  -0.00978972]]. Action = [[-0.0200967   0.06833211  0.         -0.8511471 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 11102 is [True, False, False, False, True, False]
Current timestep = 11103. State = [[-0.30409393 -0.0119971 ]]. Action = [[-0.03114683 -0.07511772  0.          0.6571475 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 11103 is [True, False, False, False, True, False]
Current timestep = 11104. State = [[-0.3076723  -0.01363503]]. Action = [[-0.06222167  0.02239253  0.         -0.30237788]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11104 is [True, False, False, False, True, False]
Current timestep = 11105. State = [[-0.31260672 -0.01661108]]. Action = [[-0.06653672 -0.06129515  0.         -0.08134985]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 11105 is [True, False, False, False, True, False]
Current timestep = 11106. State = [[-0.3159752  -0.01611203]]. Action = [[-0.02382819  0.05437387  0.          0.9431673 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 11106 is [True, False, False, False, True, False]
Current timestep = 11107. State = [[-0.3211576  -0.01045162]]. Action = [[-0.07254989  0.08074356  0.         -0.12992257]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 11107 is [True, False, False, False, True, False]
State prediction error at timestep 11107 is 0.012
Human Feedback received at timestep 11107 of None
Current timestep = 11108. State = [[-0.32327753 -0.01163042]]. Action = [[ 0.02439889 -0.08344308  0.          0.01858711]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 11108 is [True, False, False, False, True, False]
Current timestep = 11109. State = [[-0.3204727  -0.01746301]]. Action = [[ 0.07232497 -0.07095307  0.         -0.21724737]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 11109 is [True, False, False, False, True, False]
Current timestep = 11110. State = [[-0.31807685 -0.02234057]]. Action = [[ 0.02700899 -0.04541506  0.          0.1042006 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 11110 is [True, False, False, False, True, False]
Current timestep = 11111. State = [[-0.31751034 -0.02527851]]. Action = [[ 0.00474577 -0.0163096   0.         -0.05045986]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 11111 is [True, False, False, False, True, False]
State prediction error at timestep 11111 is 0.012
Human Feedback received at timestep 11111 of None
Current timestep = 11112. State = [[-0.31954053 -0.02862361]]. Action = [[-0.03851751 -0.03881563  0.         -0.8815997 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 11112 is [True, False, False, False, True, False]
Current timestep = 11113. State = [[-0.32183275 -0.0304685 ]]. Action = [[-0.02038164  0.00659323  0.         -0.57818246]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 11113 is [True, False, False, False, True, False]
Current timestep = 11114. State = [[-0.3197807  -0.03143891]]. Action = [[ 0.06397546 -0.0050687   0.          0.6036829 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 11114 is [True, False, False, False, True, False]
Current timestep = 11115. State = [[-0.3210808  -0.02820857]]. Action = [[-0.05638803  0.08033941  0.         -0.82331836]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 11115 is [True, False, False, False, True, False]
Current timestep = 11116. State = [[-0.3225035  -0.02111508]]. Action = [[0.02104391 0.09593315 0.         0.21909642]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 11116 is [True, False, False, False, True, False]
Current timestep = 11117. State = [[-0.32655966 -0.01401118]]. Action = [[-0.06778269  0.07111008  0.         -0.311166  ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 11117 is [True, False, False, False, True, False]
Current timestep = 11118. State = [[-0.3272473  -0.01339693]]. Action = [[ 0.05311172 -0.05107779  0.         -0.4489342 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 11118 is [True, False, False, False, True, False]
State prediction error at timestep 11118 is 0.012
Human Feedback received at timestep 11118 of None
Current timestep = 11119. State = [[-0.32520553 -0.01182124]]. Action = [[ 0.03334071  0.04187872  0.         -0.08403152]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 11119 is [True, False, False, False, True, False]
State prediction error at timestep 11119 is 0.012
Human Feedback received at timestep 11119 of None
Current timestep = 11120. State = [[-0.32646662 -0.00987185]]. Action = [[-0.03139486 -0.00275396  0.          0.37245584]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 11120 is [True, False, False, False, True, False]
Current timestep = 11121. State = [[-0.328981   -0.00627555]]. Action = [[-0.02453687  0.05469467  0.          0.6195321 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 11121 is [True, False, False, False, True, False]
Current timestep = 11122. State = [[-0.33079442 -0.00779554]]. Action = [[-0.0141181  -0.08078973  0.          0.6299932 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 11122 is [True, False, False, False, True, False]
Current timestep = 11123. State = [[-0.3319555  -0.00576563]]. Action = [[-0.00872693  0.07750661  0.          0.06576955]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 11123 is [True, False, False, False, True, False]
Current timestep = 11124. State = [[-0.33278856  0.00076236]]. Action = [[-5.797595e-04  6.851440e-02  0.000000e+00 -6.454741e-01]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 11124 is [True, False, False, False, True, False]
State prediction error at timestep 11124 is 0.012
Human Feedback received at timestep 11124 of None
Current timestep = 11125. State = [[-0.33450544  0.00676514]]. Action = [[-0.0203542   0.05237488  0.          0.6255121 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 11125 is [True, False, False, False, True, False]
Current timestep = 11126. State = [[-0.3396489  0.0100562]]. Action = [[-0.08131961  0.00634801  0.          0.747895  ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 11126 is [True, False, False, False, True, False]
Current timestep = 11127. State = [[-0.34660035  0.00804598]]. Action = [[-0.08944868 -0.06840222  0.         -0.6768005 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 11127 is [True, False, False, False, True, False]
Current timestep = 11128. State = [[-0.34939384  0.00987624]]. Action = [[0.00890446 0.06293572 0.         0.93017197]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 11128 is [True, False, False, False, True, False]
Current timestep = 11129. State = [[-0.34896067  0.01742855]]. Action = [[ 0.02833036  0.09313814  0.         -0.8205622 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 11129 is [True, False, False, False, True, False]
Current timestep = 11130. State = [[-0.34965113  0.02290908]]. Action = [[-0.00213374  0.02475365  0.          0.16299963]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 11130 is [True, False, False, False, True, False]
Current timestep = 11131. State = [[-0.3539621   0.02943321]]. Action = [[-0.06124013  0.0850882   0.         -0.5277035 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 11131 is [True, False, False, False, True, False]
Current timestep = 11132. State = [[-0.35517234  0.03693612]]. Action = [[ 0.04504085  0.06720156  0.         -0.80472535]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 11132 is [True, False, False, False, True, False]
Current timestep = 11133. State = [[-0.35354882  0.03609742]]. Action = [[ 0.03768266 -0.09258804  0.         -0.86648583]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 11133 is [True, False, False, False, True, False]
Current timestep = 11134. State = [[-0.3565722   0.03231041]]. Action = [[-0.08010116 -0.04207375  0.         -0.923166  ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 11134 is [True, False, False, False, True, False]
Current timestep = 11135. State = [[-0.35753238  0.03615321]]. Action = [[0.04237311 0.09475828 0.         0.5992074 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 11135 is [True, False, False, False, True, False]
Current timestep = 11136. State = [[-0.3604267   0.04177676]]. Action = [[-0.06964058  0.03962404  0.          0.7262695 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 11136 is [True, False, False, False, True, False]
Current timestep = 11137. State = [[-0.36336637  0.04459314]]. Action = [[-0.00859955  0.00855206  0.          0.23146653]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 11137 is [True, False, False, False, True, False]
Current timestep = 11138. State = [[-0.35992366  0.04485776]]. Action = [[ 0.0932548  -0.01779816  0.         -0.76389784]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 11138 is [True, False, False, False, True, False]
Current timestep = 11139. State = [[-0.36052582  0.04439026]]. Action = [[-0.06710196 -0.01106765  0.         -0.952796  ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 11139 is [True, False, False, False, True, False]
State prediction error at timestep 11139 is 0.012
Human Feedback received at timestep 11139 of None
Current timestep = 11140. State = [[-0.3591114   0.04254339]]. Action = [[ 0.07564063 -0.03532362  0.          0.00214195]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 11140 is [True, False, False, False, True, False]
Current timestep = 11141. State = [[-0.35879272  0.03715937]]. Action = [[-0.04068945 -0.08444528  0.         -0.7644051 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 11141 is [True, False, False, False, True, False]
State prediction error at timestep 11141 is 0.012
Human Feedback received at timestep 11141 of None
Current timestep = 11142. State = [[-0.3582454   0.03041219]]. Action = [[ 0.0218999  -0.07309066  0.         -0.82804155]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 11142 is [True, False, False, False, True, False]
Current timestep = 11143. State = [[-0.35684973  0.03147523]]. Action = [[ 0.01246951  0.09108318  0.         -0.77293134]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 11143 is [True, False, False, False, True, False]
Current timestep = 11144. State = [[-0.35466605  0.03281393]]. Action = [[ 0.03993047 -0.01289359  0.         -0.0438835 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 11144 is [True, False, False, False, True, False]
Current timestep = 11145. State = [[-0.35523784  0.03551649]]. Action = [[-0.03279501  0.06733786  0.         -0.91800034]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 11145 is [True, False, False, False, True, False]
Current timestep = 11146. State = [[-0.35225952  0.03691394]]. Action = [[ 0.08681407 -0.00869409  0.         -0.2058891 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 11146 is [True, False, False, False, True, False]
State prediction error at timestep 11146 is 0.012
Human Feedback received at timestep 11146 of None
Current timestep = 11147. State = [[-0.34552974  0.03791489]]. Action = [[ 0.0931843   0.02690869  0.         -0.8519277 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 11147 is [True, False, False, False, True, False]
State prediction error at timestep 11147 is 0.012
Human Feedback received at timestep 11147 of None
Current timestep = 11148. State = [[-0.34450823  0.03502246]]. Action = [[-0.05053478 -0.07132626  0.         -0.6929125 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 11148 is [True, False, False, False, True, False]
Current timestep = 11149. State = [[-0.3490438   0.03371643]]. Action = [[-0.07488082  0.01885182  0.         -0.7894086 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 11149 is [True, False, False, False, True, False]
State prediction error at timestep 11149 is 0.012
Human Feedback received at timestep 11149 of None
Current timestep = 11150. State = [[-0.34781224  0.03312116]]. Action = [[ 0.07406483 -0.01781498  0.          0.09459007]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 11150 is [True, False, False, False, True, False]
Current timestep = 11151. State = [[-0.34224114  0.03654714]]. Action = [[ 0.0726008   0.08215194  0.         -0.81180227]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 11151 is [True, False, False, False, True, False]
Current timestep = 11152. State = [[-0.3429692  0.0431897]]. Action = [[-0.05944492  0.08047614  0.          0.07806098]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 11152 is [True, False, False, False, True, False]
Current timestep = 11153. State = [[-0.34326988  0.0447554 ]]. Action = [[ 0.03283983 -0.03089843  0.          0.9732053 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 11153 is [True, False, False, False, True, False]
Current timestep = 11154. State = [[-0.34631455  0.04893784]]. Action = [[-0.07418863  0.08643215  0.          0.43656003]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 11154 is [True, False, False, False, True, False]
Current timestep = 11155. State = [[-0.3527929   0.05723816]]. Action = [[-0.07805426  0.09259493  0.         -0.19620752]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 11155 is [True, False, False, False, True, False]
Current timestep = 11156. State = [[-0.35188705  0.06239866]]. Action = [[0.09665107 0.0170192  0.         0.948951  ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 11156 is [True, False, False, False, True, False]
Current timestep = 11157. State = [[-0.3534729   0.06754811]]. Action = [[-0.07628396  0.05770374  0.         -0.43825263]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 11157 is [True, False, False, False, True, False]
Current timestep = 11158. State = [[-0.3521065   0.07048751]]. Action = [[ 0.0901437  -0.00689908  0.          0.7396431 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 11158 is [True, False, False, False, True, False]
State prediction error at timestep 11158 is 0.012
Human Feedback received at timestep 11158 of None
Current timestep = 11159. State = [[-0.349656    0.07089988]]. Action = [[ 0.00690009 -0.01525612  0.         -0.7125075 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 11159 is [True, False, False, False, True, False]
Current timestep = 11160. State = [[-0.35292572  0.06924404]]. Action = [[-0.08396821 -0.05027647  0.         -0.7792016 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 11160 is [True, False, False, False, True, False]
Current timestep = 11161. State = [[-0.35627416  0.07117902]]. Action = [[-0.03162457  0.0447427   0.          0.16134489]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 11161 is [True, False, False, False, True, False]
Current timestep = 11162. State = [[-0.3548569   0.07636224]]. Action = [[0.05478423 0.05967725 0.         0.30881834]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 11162 is [True, False, False, False, True, False]
Current timestep = 11163. State = [[-0.35093358  0.08285764]]. Action = [[0.06354993 0.07871837 0.         0.87062967]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 11163 is [True, False, False, False, True, False]
Current timestep = 11164. State = [[-0.34872872  0.08608217]]. Action = [[0.01908386 0.00204475 0.         0.22872627]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 11164 is [True, False, False, False, True, False]
State prediction error at timestep 11164 is 0.012
Human Feedback received at timestep 11164 of None
Current timestep = 11165. State = [[-0.3471632   0.08227666]]. Action = [[ 0.01563032 -0.09498311  0.          0.7356478 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 11165 is [True, False, False, False, True, False]
Current timestep = 11166. State = [[-0.34352362  0.0770255 ]]. Action = [[ 0.04509021 -0.05750102  0.          0.48205137]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 11166 is [True, False, False, False, True, False]
Current timestep = 11167. State = [[-0.3404722   0.07612518]]. Action = [[ 0.01211803  0.02032425  0.         -0.07283872]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 11167 is [True, False, False, False, True, False]
Current timestep = 11168. State = [[-0.335743    0.07977486]]. Action = [[ 0.07058578  0.06779862  0.         -0.7020935 ]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 11168 is [True, False, False, False, True, False]
State prediction error at timestep 11168 is 0.012
Human Feedback received at timestep 11168 of None
Current timestep = 11169. State = [[-0.33504137  0.080726  ]]. Action = [[-0.04587331 -0.01973937  0.          0.32208335]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 11169 is [True, False, False, False, True, False]
Current timestep = 11170. State = [[-0.33526427  0.07882461]]. Action = [[ 0.00425707 -0.03003534  0.         -0.59242594]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 11170 is [True, False, False, False, True, False]
Current timestep = 11171. State = [[-0.32997897  0.07420703]]. Action = [[ 0.08961301 -0.06891652  0.          0.5208459 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 11171 is [True, False, False, False, True, False]
Current timestep = 11172. State = [[-0.3297656   0.06910498]]. Action = [[-0.07845041 -0.05107363  0.          0.51409125]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 11172 is [True, False, False, False, True, False]
Current timestep = 11173. State = [[-0.32915443  0.07025532]]. Action = [[0.04367476 0.06828942 0.         0.09372222]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 11173 is [True, False, False, False, True, False]
Current timestep = 11174. State = [[-0.33158436  0.07229251]]. Action = [[-0.08467862  0.00987134  0.         -0.11983019]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 11174 is [True, False, False, False, True, False]
State prediction error at timestep 11174 is 0.012
Human Feedback received at timestep 11174 of None
Current timestep = 11175. State = [[-0.33181158  0.07615818]]. Action = [[0.04920932 0.07276724 0.         0.00389493]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 11175 is [True, False, False, False, True, False]
Current timestep = 11176. State = [[-0.3259811  0.0735596]]. Action = [[ 0.09674261 -0.09465771  0.         -0.02434802]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 11176 is [True, False, False, False, True, False]
Current timestep = 11177. State = [[-0.32197478  0.0748262 ]]. Action = [[ 0.02211686  0.09617824  0.         -0.285419  ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 11177 is [True, False, False, False, True, False]
Current timestep = 11178. State = [[-0.32479605  0.07945061]]. Action = [[-0.07568111  0.03674949  0.          0.47686505]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 11178 is [True, False, False, False, True, False]
Current timestep = 11179. State = [[-0.33036345  0.07787884]]. Action = [[-0.07430683 -0.07090589  0.         -0.9824439 ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 11179 is [True, False, False, False, True, False]
Current timestep = 11180. State = [[-0.33533266  0.07857199]]. Action = [[-0.06050373  0.03824832  0.          0.24841285]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 11180 is [True, False, False, False, True, False]
State prediction error at timestep 11180 is 0.012
Human Feedback received at timestep 11180 of None
Current timestep = 11181. State = [[-0.33410326  0.07959531]]. Action = [[ 0.07271681 -0.01240668  0.         -0.7805499 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 11181 is [True, False, False, False, True, False]
Current timestep = 11182. State = [[-0.33487263  0.08069704]]. Action = [[-0.04995596  0.02023879  0.          0.09400725]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 11182 is [True, False, False, False, True, False]
State prediction error at timestep 11182 is 0.012
Human Feedback received at timestep 11182 of None
Current timestep = 11183. State = [[-0.33891755  0.0860787 ]]. Action = [[-0.04460133  0.08391256  0.         -0.70758224]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 11183 is [True, False, False, False, True, False]
Current timestep = 11184. State = [[-0.33953717  0.0908932 ]]. Action = [[ 0.03722062  0.03112162  0.         -0.83967185]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 11184 is [True, False, False, False, True, False]
Current timestep = 11185. State = [[-0.3427513   0.09607457]]. Action = [[-0.0603142   0.06663891  0.          0.4117664 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 11185 is [True, False, False, False, True, False]
Current timestep = 11186. State = [[-0.34672263  0.09667691]]. Action = [[-0.02413143 -0.05080803  0.         -0.95705676]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 11186 is [True, False, False, False, True, False]
State prediction error at timestep 11186 is 0.012
Human Feedback received at timestep 11186 of None
Current timestep = 11187. State = [[-0.34424007  0.09489247]]. Action = [[ 0.08402122 -0.02359165  0.          0.95874214]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 11187 is [True, False, False, False, True, False]
Current timestep = 11188. State = [[-0.34056056  0.08957101]]. Action = [[ 0.03186262 -0.09539356  0.         -0.00930399]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 11188 is [True, False, False, False, True, False]
Current timestep = 11189. State = [[-0.3386153   0.08824805]]. Action = [[ 0.01181509  0.03456689  0.         -0.7351936 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 11189 is [True, False, False, False, True, False]
Current timestep = 11190. State = [[-0.33866426  0.09070247]]. Action = [[-0.01255502  0.03381025  0.          0.267375  ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 11190 is [True, False, False, False, True, False]
State prediction error at timestep 11190 is 0.012
Human Feedback received at timestep 11190 of None
Current timestep = 11191. State = [[-0.33704007  0.08688226]]. Action = [[ 0.03301791 -0.09690876  0.          0.03793585]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 11191 is [True, False, False, False, True, False]
Current timestep = 11192. State = [[-0.33899593  0.08220223]]. Action = [[-0.07738478 -0.03310869  0.         -0.9917331 ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 11192 is [True, False, False, False, True, False]
State prediction error at timestep 11192 is 0.012
Human Feedback received at timestep 11192 of None
Current timestep = 11193. State = [[-0.33728924  0.07916734]]. Action = [[ 0.06490991 -0.02914254  0.          0.44635427]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 11193 is [True, False, False, False, True, False]
Current timestep = 11194. State = [[-0.33080545  0.07415614]]. Action = [[ 0.07825888 -0.06211326  0.         -0.5798    ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 11194 is [True, False, False, False, True, False]
Current timestep = 11195. State = [[-0.33202535  0.07313384]]. Action = [[-0.09854292  0.03913476  0.         -0.79291064]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 11195 is [True, False, False, False, True, False]
State prediction error at timestep 11195 is 0.012
Human Feedback received at timestep 11195 of None
Current timestep = 11196. State = [[-0.3313577   0.07433242]]. Action = [[0.06396649 0.01906221 0.         0.2828827 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 11196 is [True, False, False, False, True, False]
State prediction error at timestep 11196 is 0.012
Human Feedback received at timestep 11196 of None
Current timestep = 11197. State = [[-0.3288141   0.06957205]]. Action = [[ 0.00873568 -0.09122264  0.         -0.3576119 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 11197 is [True, False, False, False, True, False]
Current timestep = 11198. State = [[-0.3283389   0.06484002]]. Action = [[-0.01530512 -0.02411665  0.          0.35415936]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 11198 is [True, False, False, False, True, False]
Current timestep = 11199. State = [[-0.32552144  0.05993225]]. Action = [[ 0.04924869 -0.06044988  0.         -0.04266727]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 11199 is [True, False, False, False, True, False]
State prediction error at timestep 11199 is 0.012
Human Feedback received at timestep 11199 of None
Current timestep = 11200. State = [[-0.3261936   0.06137812]]. Action = [[-0.05325787  0.09062976  0.          0.9179263 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 11200 is [True, False, False, False, True, False]
State prediction error at timestep 11200 is 0.012
Human Feedback received at timestep 11200 of None
Current timestep = 11201. State = [[-0.33195058  0.05986971]]. Action = [[-0.09652662 -0.07433261  0.         -0.15180457]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 11201 is [True, False, False, False, True, False]
Current timestep = 11202. State = [[-0.33876732  0.05947749]]. Action = [[-0.087153    0.03732119  0.         -0.1816932 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 11202 is [True, False, False, False, True, False]
Current timestep = 11203. State = [[-0.3431689   0.05744231]]. Action = [[-0.02795906 -0.05911323  0.         -0.7427085 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 11203 is [True, False, False, False, True, False]
Current timestep = 11204. State = [[-0.34610897  0.05084366]]. Action = [[-0.03146005 -0.09208398  0.         -0.5183761 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 11204 is [True, False, False, False, True, False]
Current timestep = 11205. State = [[-0.3517159  0.0435902]]. Action = [[-0.08854169 -0.07680245  0.          0.30060053]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 11205 is [True, False, False, False, True, False]
Current timestep = 11206. State = [[-0.356314    0.03665733]]. Action = [[-0.03260112 -0.07260498  0.         -0.0519588 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 11206 is [True, False, False, False, True, False]
Current timestep = 11207. State = [[-0.35747945  0.03038724]]. Action = [[ 0.01470707 -0.05329387  0.         -0.7105223 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 11207 is [True, False, False, False, True, False]
Current timestep = 11208. State = [[-0.36058992  0.02262047]]. Action = [[-0.05078281 -0.08961214  0.          0.28947604]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 11208 is [True, False, False, False, True, False]
Current timestep = 11209. State = [[-0.362994    0.02239434]]. Action = [[0.00927186 0.09126114 0.         0.19912732]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 11209 is [True, False, False, False, True, False]
Current timestep = 11210. State = [[-0.3639617   0.02511094]]. Action = [[ 0.01956709  0.02609266  0.         -0.43504834]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 11210 is [True, False, False, False, True, False]
State prediction error at timestep 11210 is 0.012
Human Feedback received at timestep 11210 of None
Current timestep = 11211. State = [[-0.3634471   0.02499638]]. Action = [[ 0.04529608 -0.00469688  0.         -0.49462938]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 11211 is [True, False, False, False, True, False]
Current timestep = 11212. State = [[-0.3633893   0.02460568]]. Action = [[0.01630199 0.00792766 0.         0.20701349]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 11212 is [True, False, False, False, True, False]
Current timestep = 11213. State = [[-0.36137626  0.0290819 ]]. Action = [[0.07156923 0.09424526 0.         0.17553604]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 11213 is [True, False, False, False, True, False]
Current timestep = 11214. State = [[-0.36278686  0.02782791]]. Action = [[-0.04307675 -0.08654346  0.         -0.25526083]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 11214 is [True, False, False, False, True, False]
Current timestep = 11215. State = [[-0.36743745  0.02959042]]. Action = [[-0.03778703  0.09343076  0.          0.45408618]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 11215 is [True, False, False, False, True, False]
Current timestep = 11216. State = [[-0.37124252  0.03308551]]. Action = [[-0.01729787  0.01393919  0.         -0.7540779 ]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 11216 is [True, False, False, False, True, False]
Current timestep = 11217. State = [[-0.37019444  0.03301136]]. Action = [[ 0.06538969 -0.01993589  0.         -0.7895777 ]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 11217 is [True, False, False, False, True, False]
Current timestep = 11218. State = [[-0.36545688  0.02819959]]. Action = [[ 0.0815985  -0.08672245  0.         -0.02504706]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 11218 is [True, False, False, False, True, False]
Current timestep = 11219. State = [[-0.36751226  0.02717773]]. Action = [[-0.09442412  0.03636787  0.          0.20433044]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 11219 is [True, False, False, False, True, False]
Current timestep = 11220. State = [[-0.36842728  0.02721757]]. Action = [[ 0.04788405 -0.01628268  0.          0.609987  ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 11220 is [True, False, False, False, True, False]
Current timestep = 11221. State = [[-0.3651193   0.02316223]]. Action = [[ 0.050505  -0.0672133  0.        -0.5556495]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 11221 is [True, False, False, False, True, False]
Current timestep = 11222. State = [[-0.36378226  0.01916453]]. Action = [[-0.00738731 -0.02794969  0.          0.3185737 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 11222 is [True, False, False, False, True, False]
Current timestep = 11223. State = [[-0.36696306  0.01278333]]. Action = [[-0.07931776 -0.09391538  0.          0.37704158]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 11223 is [True, False, False, False, True, False]
State prediction error at timestep 11223 is 0.012
Human Feedback received at timestep 11223 of None
Current timestep = 11224. State = [[-0.37157795  0.01260076]]. Action = [[-0.06385645  0.07630246  0.          0.1700468 ]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 11224 is [True, False, False, False, True, False]
Current timestep = 11225. State = [[-0.3734838   0.01415168]]. Action = [[ 0.          0.          0.         -0.19353014]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 11225 is [True, False, False, False, True, False]
Current timestep = 11226. State = [[-0.37180424  0.01133469]]. Action = [[ 0.04226824 -0.04984605  0.         -0.00901395]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 11226 is [True, False, False, False, True, False]
Current timestep = 11227. State = [[-0.3693266   0.01066836]]. Action = [[0.03320556 0.0278613  0.         0.40454972]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 11227 is [True, False, False, False, True, False]
Current timestep = 11228. State = [[-0.36872092  0.01099863]]. Action = [[0.         0.         0.         0.46910894]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 11228 is [True, False, False, False, True, False]
State prediction error at timestep 11228 is 0.012
Human Feedback received at timestep 11228 of None
Current timestep = 11229. State = [[-0.366681    0.00918476]]. Action = [[ 0.04583702 -0.02971022  0.         -0.6722537 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 11229 is [True, False, False, False, True, False]
Current timestep = 11230. State = [[-0.36124125  0.00363593]]. Action = [[ 0.08517656 -0.08168485  0.          0.46605265]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 11230 is [True, False, False, False, True, False]
Current timestep = 11231. State = [[-0.36193523 -0.0008598 ]]. Action = [[-0.08637591 -0.02260189  0.          0.8681189 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 11231 is [True, False, False, False, True, False]
Current timestep = 11232. State = [[-0.36706072  0.00165928]]. Action = [[-0.05732287  0.08422219  0.         -0.6791543 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 11232 is [True, False, False, False, True, False]
Current timestep = 11233. State = [[-0.36834955  0.00351557]]. Action = [[ 0.02597202 -0.00369492  0.         -0.84753746]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 11233 is [True, False, False, False, True, False]
Current timestep = 11234. State = [[-0.36968604  0.00757301]]. Action = [[-0.01964982  0.08224923  0.          0.18326116]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 11234 is [True, False, False, False, True, False]
Current timestep = 11235. State = [[-0.367302    0.00659305]]. Action = [[ 0.08241159 -0.07432356  0.         -0.38931847]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 11235 is [True, False, False, False, True, False]
Current timestep = 11236. State = [[-0.36248395  0.00092653]]. Action = [[ 0.06398215 -0.06863599  0.         -0.36739647]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 11236 is [True, False, False, False, True, False]
State prediction error at timestep 11236 is 0.012
Human Feedback received at timestep 11236 of None
Current timestep = 11237. State = [[-0.35601878 -0.00453681]]. Action = [[ 0.09148254 -0.05526673  0.         -0.86909693]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 11237 is [True, False, False, False, True, False]
Current timestep = 11238. State = [[-0.3555277  -0.01068549]]. Action = [[-0.06898695 -0.07013531  0.         -0.8223675 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 11238 is [True, False, False, False, True, False]
Current timestep = 11239. State = [[-0.35296294 -0.00987002]]. Action = [[ 0.09368075  0.08710397  0.         -0.41608763]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 11239 is [True, False, False, False, True, False]
Current timestep = 11240. State = [[-0.34835324 -0.0104748 ]]. Action = [[ 0.03644914 -0.04763675  0.          0.08291864]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 11240 is [True, False, False, False, True, False]
Current timestep = 11241. State = [[-0.3491439  -0.00906319]]. Action = [[-0.05592424  0.06846485  0.          0.2882073 ]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 11241 is [True, False, False, False, True, False]
Current timestep = 11242. State = [[-0.35111827 -0.00511298]]. Action = [[-0.01807917  0.04762387  0.         -0.44049847]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 11242 is [True, False, False, False, True, False]
Current timestep = 11243. State = [[-0.34816542 -0.00049294]]. Action = [[ 0.07541472  0.05816286  0.         -0.1939702 ]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 11243 is [True, False, False, False, True, False]
State prediction error at timestep 11243 is 0.012
Human Feedback received at timestep 11243 of None
Current timestep = 11244. State = [[-0.34646773 -0.00089154]]. Action = [[-0.00801039 -0.05404875  0.          0.8517475 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 11244 is [True, False, False, False, True, False]
Current timestep = 11245. State = [[-0.34265214 -0.00261278]]. Action = [[ 0.07133872 -0.01021601  0.         -0.38376266]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 11245 is [True, False, False, False, True, False]
Current timestep = 11246. State = [[-0.33914354 -0.00657865]]. Action = [[ 0.01597665 -0.07403775  0.          0.96424556]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 11246 is [True, False, False, False, True, False]
State prediction error at timestep 11246 is 0.012
Human Feedback received at timestep 11246 of None
Current timestep = 11247. State = [[-0.33325085 -0.01090949]]. Action = [[ 0.08560412 -0.03770933  0.         -0.96211493]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 11247 is [True, False, False, False, True, False]
Current timestep = 11248. State = [[-0.3296819  -0.01633896]]. Action = [[-0.00667799 -0.07276775  0.         -0.87740344]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 11248 is [True, False, False, False, True, False]
Current timestep = 11249. State = [[-0.3248513  -0.02377478]]. Action = [[ 0.06343267 -0.08479922  0.         -0.20243877]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 11249 is [True, False, False, False, True, False]
Current timestep = 11250. State = [[-0.3237158  -0.03256414]]. Action = [[-0.05618138 -0.09477716  0.          0.90881443]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 11250 is [True, False, False, False, True, False]
Current timestep = 11251. State = [[-0.3264997  -0.03309421]]. Action = [[-0.06489418  0.08639478  0.          0.26212263]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 11251 is [True, False, False, False, True, False]
Current timestep = 11252. State = [[-0.33122003 -0.03332459]]. Action = [[-0.0850434  -0.02280574  0.          0.8209815 ]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 11252 is [True, False, False, False, True, False]
Current timestep = 11253. State = [[-0.3373158  -0.03532826]]. Action = [[-0.09033544 -0.00384986  0.          0.17121553]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 11253 is [True, False, False, False, True, False]
Current timestep = 11254. State = [[-0.33582178 -0.03480898]]. Action = [[ 0.09814804  0.02770238  0.         -0.6764983 ]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 11254 is [True, False, False, False, True, False]
State prediction error at timestep 11254 is 0.012
Human Feedback received at timestep 11254 of None
Current timestep = 11255. State = [[-0.3287738  -0.03059595]]. Action = [[ 0.09269386  0.07030544  0.         -0.9697133 ]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 11255 is [True, False, False, False, True, False]
Current timestep = 11256. State = [[-0.32239166 -0.02916138]]. Action = [[ 0.07737277 -0.02017252  0.          0.90135145]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 11256 is [True, False, False, False, True, False]
Current timestep = 11257. State = [[-0.3181158  -0.02584865]]. Action = [[ 0.03903586  0.07003983  0.         -0.29189265]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 11257 is [True, False, False, False, True, False]
State prediction error at timestep 11257 is 0.012
Human Feedback received at timestep 11257 of None
Current timestep = 11258. State = [[-0.31234652 -0.02540577]]. Action = [[ 0.09129561 -0.04133419  0.         -0.58355045]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 11258 is [True, False, False, False, True, False]
Current timestep = 11259. State = [[-0.3102319  -0.02993463]]. Action = [[-0.02453543 -0.07309276  0.         -0.76166147]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 11259 is [True, False, False, False, True, False]
Current timestep = 11260. State = [[-0.30922937 -0.03444899]]. Action = [[ 0.01196865 -0.04223132  0.          0.78420126]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 11260 is [True, False, False, False, True, False]
Current timestep = 11261. State = [[-0.30905715 -0.03649257]]. Action = [[-0.02545418 -0.00491457  0.         -0.7646226 ]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 11261 is [True, False, False, False, True, False]
Current timestep = 11262. State = [[-0.30515322 -0.04185597]]. Action = [[ 0.07202645 -0.09159767  0.         -0.93788636]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 11262 is [True, False, False, False, True, False]
Current timestep = 11263. State = [[-0.302492   -0.04453118]]. Action = [[-0.01489977  0.01826392  0.         -0.9851397 ]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 11263 is [True, False, False, False, True, False]
State prediction error at timestep 11263 is 0.012
Human Feedback received at timestep 11263 of None
Current timestep = 11264. State = [[-0.29733068 -0.04096078]]. Action = [[0.09000132 0.0784852  0.         0.3756528 ]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 11264 is [True, False, False, False, True, False]
Current timestep = 11265. State = [[-0.298027  -0.0371668]]. Action = [[-0.08931931  0.03762455  0.         -0.40978658]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 11265 is [True, False, False, False, True, False]
State prediction error at timestep 11265 is 0.012
Human Feedback received at timestep 11265 of None
Current timestep = 11266. State = [[-0.29639488 -0.0344058 ]]. Action = [[ 0.08355575  0.02990677  0.         -0.2930547 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 11266 is [True, False, False, False, True, False]
Current timestep = 11267. State = [[-0.29644987 -0.03044006]]. Action = [[-0.05572289  0.05502678  0.         -0.03332269]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 11267 is [True, False, False, False, True, False]
Current timestep = 11268. State = [[-0.29483935 -0.03009562]]. Action = [[ 0.06082394 -0.03710312  0.         -0.85232943]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 11268 is [True, False, False, False, True, False]
Current timestep = 11269. State = [[-0.28927997 -0.02890116]]. Action = [[ 0.07457068  0.03245253  0.         -0.89869934]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 11269 is [True, False, False, False, True, False]
Current timestep = 11270. State = [[-0.28999412 -0.02355899]]. Action = [[-0.0706272   0.07624733  0.          0.75375235]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 11270 is [True, False, False, False, True, False]
Current timestep = 11271. State = [[-0.28836682 -0.01658547]]. Action = [[ 0.08104726  0.07332809  0.         -0.14537388]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 11271 is [True, False, False, False, True, False]
State prediction error at timestep 11271 is 0.012
Human Feedback received at timestep 11271 of None
Current timestep = 11272. State = [[-0.2885394  -0.01343426]]. Action = [[-0.04615668 -0.00767048  0.         -0.9602528 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 11272 is [True, False, False, False, True, False]
Current timestep = 11273. State = [[-0.29387888 -0.01480844]]. Action = [[-0.09165714 -0.04842606  0.         -0.8581791 ]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 11273 is [True, False, False, False, True, False]
Current timestep = 11274. State = [[-0.30028623 -0.01654821]]. Action = [[-0.08993996 -0.02408172  0.         -0.28040695]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 11274 is [True, False, False, False, True, False]
Current timestep = 11275. State = [[-0.3035701  -0.02127281]]. Action = [[-0.02261971 -0.09084237  0.          0.12221313]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 11275 is [True, False, False, False, True, False]
State prediction error at timestep 11275 is 0.012
Human Feedback received at timestep 11275 of None
Current timestep = 11276. State = [[-0.3087018  -0.02427989]]. Action = [[-0.09656572 -0.00859307  0.         -0.8213126 ]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 11276 is [True, False, False, False, True, False]
Current timestep = 11277. State = [[-0.314621  -0.0217968]]. Action = [[-0.06336181  0.05850869  0.          0.86793673]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 11277 is [True, False, False, False, True, False]
Current timestep = 11278. State = [[-0.32095984 -0.02369633]]. Action = [[-0.07748966 -0.07332322  0.         -0.03369707]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 11278 is [True, False, False, False, True, False]
State prediction error at timestep 11278 is 0.012
Human Feedback received at timestep 11278 of None
Current timestep = 11279. State = [[-0.32596526 -0.02204962]]. Action = [[-0.03404146  0.07877255  0.         -0.93534005]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 11279 is [True, False, False, False, True, False]
State prediction error at timestep 11279 is 0.012
Human Feedback received at timestep 11279 of None
Current timestep = 11280. State = [[-0.32878524 -0.02432299]]. Action = [[-0.00503141 -0.09364003  0.         -0.2934379 ]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 11280 is [True, False, False, False, True, False]
Current timestep = 11281. State = [[-0.32792687 -0.02858564]]. Action = [[ 0.05599537 -0.02771714  0.          0.8972995 ]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 11281 is [True, False, False, False, True, False]
Current timestep = 11282. State = [[-0.32671085 -0.02688422]]. Action = [[ 0.02866071  0.05985733  0.         -0.97843647]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 11282 is [True, False, False, False, True, False]
Current timestep = 11283. State = [[-0.33206028 -0.02451999]]. Action = [[-0.09676998  0.01760695  0.         -0.81890625]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 11283 is [True, False, False, False, True, False]
Current timestep = 11284. State = [[-0.33568323 -0.02635027]]. Action = [[ 0.01957434 -0.04566604  0.         -0.06939793]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 11284 is [True, False, False, False, True, False]
State prediction error at timestep 11284 is 0.012
Human Feedback received at timestep 11284 of None
Current timestep = 11285. State = [[-0.3401472  -0.02803382]]. Action = [[-0.06614679 -0.00176142  0.          0.41304374]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 11285 is [True, False, False, False, True, False]
Current timestep = 11286. State = [[-0.33950555 -0.02853531]]. Action = [[ 0.09161588 -0.00393654  0.         -0.20481938]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 11286 is [True, False, False, False, True, False]
Current timestep = 11287. State = [[-0.33481973 -0.03029088]]. Action = [[ 0.07084373 -0.03030286  0.         -0.13812947]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 11287 is [True, False, False, False, True, False]
Current timestep = 11288. State = [[-0.32994142 -0.0273603 ]]. Action = [[ 0.07391308  0.07899348  0.         -0.22345877]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 11288 is [True, False, False, False, True, False]
State prediction error at timestep 11288 is 0.012
Human Feedback received at timestep 11288 of None
Current timestep = 11289. State = [[-0.32565835 -0.02825009]]. Action = [[ 0.05528634 -0.06476504  0.         -0.07359797]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 11289 is [True, False, False, False, True, False]
Current timestep = 11290. State = [[-0.321938   -0.02630556]]. Action = [[0.04532547 0.07807604 0.         0.5549592 ]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 11290 is [True, False, False, False, True, False]
Current timestep = 11291. State = [[-0.3237708  -0.02755092]]. Action = [[-0.07069087 -0.07098746  0.          0.9820365 ]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 11291 is [True, False, False, False, True, False]
Current timestep = 11292. State = [[-0.3238387  -0.02889141]]. Action = [[ 0.02796567  0.01963241  0.         -0.9746834 ]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 11292 is [True, False, False, False, True, False]
State prediction error at timestep 11292 is 0.012
Human Feedback received at timestep 11292 of None
Current timestep = 11293. State = [[-0.320728   -0.02363378]]. Action = [[0.04547311 0.09676287 0.         0.5669974 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 11293 is [True, False, False, False, True, False]
Current timestep = 11294. State = [[-0.32316205 -0.01673945]]. Action = [[-0.07800851  0.07267418  0.          0.15455782]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 11294 is [True, False, False, False, True, False]
Current timestep = 11295. State = [[-0.326217   -0.01577172]]. Action = [[-0.01712725 -0.03991786  0.         -0.5369466 ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 11295 is [True, False, False, False, True, False]
Current timestep = 11296. State = [[-0.3298675  -0.01865879]]. Action = [[-0.06499497 -0.0487235   0.         -0.30071682]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 11296 is [True, False, False, False, True, False]
Current timestep = 11297. State = [[-0.3340687  -0.01882312]]. Action = [[-0.05344641  0.01882718  0.          0.08556592]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 11297 is [True, False, False, False, True, False]
Current timestep = 11298. State = [[-0.3329827  -0.01617915]]. Action = [[0.06039605 0.03289876 0.         0.90514433]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 11298 is [True, False, False, False, True, False]
Current timestep = 11299. State = [[-0.32908335 -0.01139792]]. Action = [[0.05662281 0.06001084 0.         0.66594625]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 11299 is [True, False, False, False, True, False]
Current timestep = 11300. State = [[-0.32839647 -0.00443445]]. Action = [[-0.00652556  0.08362467  0.         -0.6527398 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 11300 is [True, False, False, False, True, False]
Current timestep = 11301. State = [[-0.33079574 -0.00462733]]. Action = [[-0.03807805 -0.07925369  0.         -0.5147574 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 11301 is [True, False, False, False, True, False]
Current timestep = 11302. State = [[-0.3274411  -0.00611363]]. Action = [[0.09618948 0.00079668 0.         0.7311405 ]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 11302 is [True, False, False, False, True, False]
Current timestep = 11303. State = [[-0.32247618 -0.00950164]]. Action = [[ 0.04199029 -0.07429694  0.         -0.663702  ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 11303 is [True, False, False, False, True, False]
Current timestep = 11304. State = [[-0.3196893  -0.01625588]]. Action = [[ 0.01002816 -0.09015478  0.         -0.35966015]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 11304 is [True, False, False, False, True, False]
State prediction error at timestep 11304 is 0.012
Human Feedback received at timestep 11304 of None
Current timestep = 11305. State = [[-0.3148496  -0.02364316]]. Action = [[ 0.06373649 -0.07975815  0.          0.35503888]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 11305 is [True, False, False, False, True, False]
State prediction error at timestep 11305 is 0.012
Human Feedback received at timestep 11305 of None
Current timestep = 11306. State = [[-0.3069343  -0.02304231]]. Action = [[ 0.09936524  0.08584715  0.         -0.75025254]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 11306 is [True, False, False, False, True, False]
Current timestep = 11307. State = [[-0.3024284  -0.02421919]]. Action = [[ 0.00765979 -0.05453179  0.         -0.65006274]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 11307 is [True, False, False, False, True, False]
Current timestep = 11308. State = [[-0.3030664  -0.03128964]]. Action = [[-0.0550456  -0.08920456  0.         -0.5866631 ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 11308 is [True, False, False, False, True, False]
Current timestep = 11309. State = [[-0.3067199  -0.03369531]]. Action = [[-0.0821967   0.03530475  0.         -0.13381362]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 11309 is [True, False, False, False, True, False]
State prediction error at timestep 11309 is 0.012
Human Feedback received at timestep 11309 of None
Current timestep = 11310. State = [[-0.3079004  -0.03533557]]. Action = [[-0.00267532 -0.02451308  0.         -0.61309886]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 11310 is [True, False, False, False, True, False]
State prediction error at timestep 11310 is 0.012
Human Feedback received at timestep 11310 of None
Current timestep = 11311. State = [[-0.30904782 -0.03612325]]. Action = [[-0.03766389  0.01925014  0.         -0.95750284]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 11311 is [True, False, False, False, True, False]
Current timestep = 11312. State = [[-0.31350085 -0.03308716]]. Action = [[-0.07882086  0.06520455  0.          0.13662994]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 11312 is [True, False, False, False, True, False]
Current timestep = 11313. State = [[-0.3173517  -0.02858881]]. Action = [[-0.02933279  0.05470932  0.          0.77154374]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 11313 is [True, False, False, False, True, False]
Current timestep = 11314. State = [[-0.31598282 -0.02994697]]. Action = [[ 0.0632075  -0.06763537  0.         -0.34797233]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 11314 is [True, False, False, False, True, False]
Current timestep = 11315. State = [[-0.31406072 -0.03587028]]. Action = [[ 0.01648005 -0.08166392  0.         -0.9128916 ]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 11315 is [True, False, False, False, True, False]
State prediction error at timestep 11315 is 0.012
Human Feedback received at timestep 11315 of None
Current timestep = 11316. State = [[-0.31553248 -0.04246399]]. Action = [[-0.03956768 -0.07323543  0.         -0.6629282 ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 11316 is [True, False, False, False, True, False]
State prediction error at timestep 11316 is 0.012
Human Feedback received at timestep 11316 of None
Current timestep = 11317. State = [[-0.31345862 -0.04651744]]. Action = [[ 0.06521676 -0.01995988  0.         -0.8447339 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 11317 is [True, False, False, False, True, False]
Current timestep = 11318. State = [[-0.31370002 -0.05149354]]. Action = [[-0.04288618 -0.06689254  0.          0.01810992]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 11318 is [True, False, False, False, True, False]
State prediction error at timestep 11318 is 0.012
Human Feedback received at timestep 11318 of None
Current timestep = 11319. State = [[-0.3182801  -0.05390896]]. Action = [[-0.07469134  0.0164445   0.         -0.90440595]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 11319 is [True, False, False, False, True, False]
Current timestep = 11320. State = [[-0.32119316 -0.05138673]]. Action = [[-0.0114376   0.06537271  0.          0.24011433]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 11320 is [True, False, False, False, True, False]
Current timestep = 11321. State = [[-0.31938234 -0.05094935]]. Action = [[ 0.06127503 -0.02010675  0.         -0.71141493]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 11321 is [True, False, False, False, True, False]
State prediction error at timestep 11321 is 0.012
Human Feedback received at timestep 11321 of None
Current timestep = 11322. State = [[-0.31701177 -0.05445806]]. Action = [[ 0.02792352 -0.05350626  0.          0.37220466]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 11322 is [True, False, False, False, True, False]
Current timestep = 11323. State = [[-0.31380096 -0.05232118]]. Action = [[ 0.05988271  0.08239355  0.         -0.4798106 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 11323 is [True, False, False, False, True, False]
Current timestep = 11324. State = [[-0.3147101  -0.04953384]]. Action = [[-0.04153135  0.00913963  0.         -0.9959454 ]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 11324 is [True, False, False, False, True, False]
Current timestep = 11325. State = [[-0.31433448 -0.04871113]]. Action = [[ 0.0403944   0.00790501  0.         -0.6524624 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 11325 is [True, False, False, False, True, False]
Current timestep = 11326. State = [[-0.31819254 -0.04373609]]. Action = [[-0.0957525   0.09237439  0.          0.5390779 ]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 11326 is [True, False, False, False, True, False]
Current timestep = 11327. State = [[-0.31938592 -0.03571643]]. Action = [[ 0.0576951   0.09115944  0.         -0.9262773 ]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 11327 is [True, False, False, False, True, False]
Current timestep = 11328. State = [[-0.3215736  -0.03455862]]. Action = [[-0.05673599 -0.06137535  0.          0.41454244]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 11328 is [True, False, False, False, True, False]
Current timestep = 11329. State = [[-0.32721832 -0.03667269]]. Action = [[-0.07495636 -0.02323413  0.         -0.21286523]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 11329 is [True, False, False, False, True, False]
Current timestep = 11330. State = [[-0.32581583 -0.03461583]]. Action = [[ 0.09183378  0.0428179   0.         -0.22540915]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 11330 is [True, False, False, False, True, False]
State prediction error at timestep 11330 is 0.012
Human Feedback received at timestep 11330 of None
Current timestep = 11331. State = [[-0.32212448 -0.03006203]]. Action = [[0.03293604 0.04667024 0.         0.87366414]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 11331 is [True, False, False, False, True, False]
Current timestep = 11332. State = [[-0.32168472 -0.02806498]]. Action = [[-0.00982212 -0.00853477  0.          0.8150723 ]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 11332 is [True, False, False, False, True, False]
State prediction error at timestep 11332 is 0.012
Human Feedback received at timestep 11332 of None
Current timestep = 11333. State = [[-0.32033414 -0.02286972]]. Action = [[ 0.03431243  0.0892344   0.         -0.2293784 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 11333 is [True, False, False, False, True, False]
Current timestep = 11334. State = [[-0.31495878 -0.01717275]]. Action = [[ 0.09908288  0.03663147  0.         -0.6757575 ]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 11334 is [True, False, False, False, True, False]
Current timestep = 11335. State = [[-0.31531623 -0.01043742]]. Action = [[-0.06606777  0.08498202  0.          0.5581142 ]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 11335 is [True, False, False, False, True, False]
Current timestep = 11336. State = [[-0.31941095 -0.00652699]]. Action = [[-3.4753956e-02 -4.1486323e-04  0.0000000e+00 -6.5871096e-01]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 11336 is [True, False, False, False, True, False]
Current timestep = 11337. State = [[-0.3250832  -0.00871465]]. Action = [[-0.08647048 -0.07297952  0.         -0.574295  ]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 11337 is [True, False, False, False, True, False]
State prediction error at timestep 11337 is 0.012
Human Feedback received at timestep 11337 of None
Current timestep = 11338. State = [[-0.33041993 -0.01137043]]. Action = [[-0.05962989 -0.02928008  0.          0.3913803 ]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 11338 is [True, False, False, False, True, False]
Current timestep = 11339. State = [[-0.3333584  -0.00794096]]. Action = [[-0.01847472  0.07426374  0.          0.17687416]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 11339 is [True, False, False, False, True, False]
Current timestep = 11340. State = [[-0.33388358 -0.00096927]]. Action = [[ 0.01902791  0.07757949  0.         -0.589914  ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 11340 is [True, False, False, False, True, False]
Current timestep = 11341. State = [[-0.33222258  0.00079903]]. Action = [[ 0.04654387 -0.03497504  0.          0.02450347]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 11341 is [True, False, False, False, True, False]
Current timestep = 11342. State = [[-0.33451205  0.00306749]]. Action = [[-0.05864795  0.04631046  0.          0.8034667 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 11342 is [True, False, False, False, True, False]
Current timestep = 11343. State = [[-0.33298838  0.00278429]]. Action = [[ 0.0847813  -0.04737113  0.         -0.9463284 ]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 11343 is [True, False, False, False, True, False]
Current timestep = 11344. State = [[-0.33483344 -0.00074966]]. Action = [[-0.08876844 -0.05275819  0.          0.27182043]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 11344 is [True, False, False, False, True, False]
State prediction error at timestep 11344 is 0.012
Human Feedback received at timestep 11344 of None
Current timestep = 11345. State = [[-0.34147477  0.00210533]]. Action = [[-0.07718553  0.08687399  0.          0.53340805]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 11345 is [True, False, False, False, True, False]
Current timestep = 11346. State = [[-0.34961268  0.0065142 ]]. Action = [[-0.09853313  0.03088763  0.         -0.7802893 ]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 11346 is [True, False, False, False, True, False]
Current timestep = 11347. State = [[-0.3516307   0.00478921]]. Action = [[ 0.04778413 -0.06581248  0.         -0.03726274]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 11347 is [True, False, False, False, True, False]
Current timestep = 11348. State = [[-0.3491111   0.00601292]]. Action = [[0.05129781 0.05788506 0.         0.95203257]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 11348 is [True, False, False, False, True, False]
State prediction error at timestep 11348 is 0.012
Human Feedback received at timestep 11348 of None
Current timestep = 11349. State = [[-0.34916934  0.00962984]]. Action = [[-0.0078647   0.03178652  0.          0.75124896]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 11349 is [True, False, False, False, True, False]
State prediction error at timestep 11349 is 0.012
Human Feedback received at timestep 11349 of None
Current timestep = 11350. State = [[-0.34608692  0.01467529]]. Action = [[0.09251735 0.06954057 0.         0.09320676]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 11350 is [True, False, False, False, True, False]
Current timestep = 11351. State = [[-0.3463578   0.01562863]]. Action = [[-0.04139732 -0.03577107  0.          0.24489582]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 11351 is [True, False, False, False, True, False]
Current timestep = 11352. State = [[-0.35182023  0.01266655]]. Action = [[-0.07903843 -0.05013821  0.         -0.8173753 ]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 11352 is [True, False, False, False, True, False]
Current timestep = 11353. State = [[-0.35118222  0.00825953]]. Action = [[ 0.0703618  -0.06091726  0.         -0.30357313]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 11353 is [True, False, False, False, True, False]
Current timestep = 11354. State = [[-0.34909508  0.00846731]]. Action = [[ 0.00352477  0.04545889  0.         -0.6302273 ]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 11354 is [True, False, False, False, True, False]
Current timestep = 11355. State = [[-0.3529993   0.01210226]]. Action = [[-0.08629595  0.04850378  0.          0.45508325]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 11355 is [True, False, False, False, True, False]
Current timestep = 11356. State = [[-0.35405296  0.0179498 ]]. Action = [[ 0.03787813  0.08122457  0.         -0.96583486]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 11356 is [True, False, False, False, True, False]
Current timestep = 11357. State = [[-0.3531058   0.02258188]]. Action = [[0.01488471 0.02991845 0.         0.7468257 ]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 11357 is [True, False, False, False, True, False]
Current timestep = 11358. State = [[-0.35264754  0.02665844]]. Action = [[ 0.01403244  0.04485155  0.         -0.53215176]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 11358 is [True, False, False, False, True, False]
State prediction error at timestep 11358 is 0.012
Human Feedback received at timestep 11358 of None
Current timestep = 11359. State = [[-0.35579953  0.02605934]]. Action = [[-0.06479782 -0.05780258  0.         -0.07851946]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 11359 is [True, False, False, False, True, False]
Current timestep = 11360. State = [[-0.35405955  0.02756454]]. Action = [[ 0.08395702  0.04829314  0.         -0.12593472]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 11360 is [True, False, False, False, True, False]
State prediction error at timestep 11360 is 0.012
Human Feedback received at timestep 11360 of None
Current timestep = 11361. State = [[-0.3544923   0.02635881]]. Action = [[-0.06512031 -0.06645913  0.          0.179739  ]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 11361 is [True, False, False, False, True, False]
Current timestep = 11362. State = [[-0.3573936  0.0262595]]. Action = [[-0.03096692  0.02496152  0.         -0.07112944]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 11362 is [True, False, False, False, True, False]
Current timestep = 11363. State = [[-0.35641322  0.02646052]]. Action = [[ 0.0395845  -0.01726141  0.         -0.9185115 ]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 11363 is [True, False, False, False, True, False]
Current timestep = 11364. State = [[-0.35446453  0.02754316]]. Action = [[0.01997982 0.02655406 0.         0.4943006 ]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 11364 is [True, False, False, False, True, False]
Current timestep = 11365. State = [[-0.35572395  0.02508164]]. Action = [[-0.04022169 -0.06779923  0.         -0.81151664]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 11365 is [True, False, False, False, True, False]
Current timestep = 11366. State = [[-0.35385343  0.02673632]]. Action = [[0.06072725 0.07445563 0.         0.11576009]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 11366 is [True, False, False, False, True, False]
State prediction error at timestep 11366 is 0.012
Human Feedback received at timestep 11366 of None
Current timestep = 11367. State = [[-0.35322258  0.0335749 ]]. Action = [[-0.01430543  0.0908555   0.         -0.4884168 ]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 11367 is [True, False, False, False, True, False]
Current timestep = 11368. State = [[-0.35026556  0.03853564]]. Action = [[0.07991613 0.03262156 0.         0.88539267]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 11368 is [True, False, False, False, True, False]
State prediction error at timestep 11368 is 0.012
Human Feedback received at timestep 11368 of None
Current timestep = 11369. State = [[-0.35002473  0.04015387]]. Action = [[-0.03405689 -0.00267328  0.         -0.39324725]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 11369 is [True, False, False, False, True, False]
Current timestep = 11370. State = [[-0.3545625  0.0389937]]. Action = [[-0.07588966 -0.03806413  0.          0.7019917 ]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 11370 is [True, False, False, False, True, False]
State prediction error at timestep 11370 is 0.012
Human Feedback received at timestep 11370 of None
Current timestep = 11371. State = [[-0.3594509   0.04076674]]. Action = [[-0.05908846  0.04199395  0.         -0.82619786]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 11371 is [True, False, False, False, True, False]
Current timestep = 11372. State = [[-0.36572635  0.04396439]]. Action = [[-0.08706406  0.02187121  0.          0.2674178 ]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 11372 is [True, False, False, False, True, False]
Current timestep = 11373. State = [[-0.36973765  0.0407744 ]]. Action = [[-0.02473682 -0.09701758  0.         -0.85954785]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 11373 is [True, False, False, False, True, False]
Current timestep = 11374. State = [[-0.37065145  0.04279606]]. Action = [[ 0.01225372  0.09811259  0.         -0.40444708]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 11374 is [True, False, False, False, True, False]
State prediction error at timestep 11374 is 0.012
Human Feedback received at timestep 11374 of None
Current timestep = 11375. State = [[-0.3710213   0.05048382]]. Action = [[ 0.01596101  0.08521941  0.         -0.83580476]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 11375 is [True, False, False, False, True, False]
Current timestep = 11376. State = [[-0.3752896   0.05818109]]. Action = [[-0.05934727  0.08133706  0.          0.33905172]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 11376 is [True, False, False, False, True, False]
Current timestep = 11377. State = [[-0.37876597  0.06192929]]. Action = [[0.        0.        0.        0.2809131]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 11377 is [True, False, False, False, True, False]
Current timestep = 11378. State = [[-0.38036934  0.06321417]]. Action = [[ 0.          0.          0.         -0.38045043]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 11378 is [True, False, False, False, True, False]
Current timestep = 11379. State = [[-0.38158196  0.06421715]]. Action = [[0.         0.         0.         0.33344328]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 11379 is [True, False, False, False, True, False]
Current timestep = 11380. State = [[-0.38251546  0.06506468]]. Action = [[0.         0.         0.         0.69357824]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 11380 is [True, False, False, False, True, False]
Current timestep = 11381. State = [[-0.3832091   0.06575663]]. Action = [[ 0.         0.         0.        -0.7244575]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 11381 is [True, False, False, False, True, False]
Current timestep = 11382. State = [[-0.3837143   0.06628715]]. Action = [[ 0.          0.          0.         -0.89308256]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 11382 is [True, False, False, False, True, False]
Current timestep = 11383. State = [[-0.3840636   0.06665824]]. Action = [[0.        0.        0.        0.4023385]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 11383 is [True, False, False, False, True, False]
Current timestep = 11384. State = [[-0.38429213  0.06689548]]. Action = [[ 0.        0.        0.       -0.884195]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 11384 is [True, False, False, False, True, False]
Current timestep = 11385. State = [[-0.3821423   0.06690037]]. Action = [[ 0.0474189  -0.00203991  0.         -0.72337353]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 11385 is [True, False, False, False, True, False]
Current timestep = 11386. State = [[-0.3808518   0.06677672]]. Action = [[ 0.         0.         0.        -0.8392242]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 11386 is [True, False, False, False, True, False]
Current timestep = 11387. State = [[-0.38067642  0.06673135]]. Action = [[ 0.          0.          0.         -0.79368484]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 11387 is [True, False, False, False, True, False]
State prediction error at timestep 11387 is 0.012
Human Feedback received at timestep 11387 of None
Current timestep = 11388. State = [[-0.38051546  0.06669953]]. Action = [[0.       0.       0.       0.394933]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 11388 is [True, False, False, False, True, False]
State prediction error at timestep 11388 is 0.012
Human Feedback received at timestep 11388 of None
Current timestep = 11389. State = [[-0.37554535  0.06438807]]. Action = [[ 0.09687171 -0.0421367   0.         -0.9205189 ]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 11389 is [True, False, False, False, True, False]
Current timestep = 11390. State = [[-0.36931005  0.06671793]]. Action = [[ 0.06652593  0.08442367  0.         -0.12454176]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 11390 is [True, False, False, False, True, False]
Current timestep = 11391. State = [[-0.3668774   0.06682147]]. Action = [[ 0.00052691 -0.0400323   0.         -0.40652514]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 11391 is [True, False, False, False, True, False]
State prediction error at timestep 11391 is 0.012
Human Feedback received at timestep 11391 of None
Current timestep = 11392. State = [[-0.3625188  0.0685665]]. Action = [[0.07523299 0.06081153 0.         0.19271398]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 11392 is [True, False, False, False, True, False]
Current timestep = 11393. State = [[-0.36066237  0.07409134]]. Action = [[-0.01322456  0.07861144  0.          0.0296911 ]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 11393 is [True, False, False, False, True, False]
State prediction error at timestep 11393 is 0.012
Human Feedback received at timestep 11393 of None
Current timestep = 11394. State = [[-0.3559521   0.07483117]]. Action = [[ 0.09213405 -0.03805493  0.         -0.24482566]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 11394 is [True, False, False, False, True, False]
Current timestep = 11395. State = [[-0.35060316  0.07062995]]. Action = [[ 0.0338838  -0.06654297  0.         -0.77277553]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 11395 is [True, False, False, False, True, False]
Current timestep = 11396. State = [[-0.34976137  0.06778257]]. Action = [[-0.04049149 -0.02036648  0.          0.08058929]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 11396 is [True, False, False, False, True, False]
Current timestep = 11397. State = [[-0.34597057  0.06960215]]. Action = [[0.06815428 0.04796755 0.         0.9197676 ]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 11397 is [True, False, False, False, True, False]
Current timestep = 11398. State = [[-0.3381592   0.06633708]]. Action = [[ 0.08646674 -0.09212493  0.         -0.30229902]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 11398 is [True, False, False, False, True, False]
Current timestep = 11399. State = [[-0.3288955   0.05944952]]. Action = [[ 0.09090651 -0.07529138  0.         -0.8108676 ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 11399 is [True, False, False, False, True, False]
State prediction error at timestep 11399 is 0.012
Human Feedback received at timestep 11399 of None
Current timestep = 11400. State = [[-0.3191571   0.05833603]]. Action = [[ 0.09496181  0.04470656  0.         -0.42290306]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 11400 is [True, False, False, False, True, False]
Current timestep = 11401. State = [[-0.30917996  0.05797965]]. Action = [[ 0.09936925 -0.00881715  0.         -0.12980223]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 11401 is [True, False, False, False, True, False]
State prediction error at timestep 11401 is 0.012
Human Feedback received at timestep 11401 of None
Current timestep = 11402. State = [[-0.3054237   0.05283973]]. Action = [[-0.04357221 -0.08041074  0.          0.5163363 ]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 11402 is [True, False, False, False, True, False]
Current timestep = 11403. State = [[-0.30688602  0.04590135]]. Action = [[-0.0664344  -0.07580361  0.         -0.652614  ]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 11403 is [True, False, False, False, True, False]
Current timestep = 11404. State = [[-0.30988666  0.04474948]]. Action = [[-0.07343477  0.0404376   0.         -0.6961789 ]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 11404 is [True, False, False, False, True, False]
Current timestep = 11405. State = [[-0.31059954  0.04666493]]. Action = [[-0.00036918  0.03001376  0.         -0.11752415]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 11405 is [True, False, False, False, True, False]
Current timestep = 11406. State = [[-0.30553263  0.05019915]]. Action = [[ 0.09866158  0.06292377  0.         -0.14837319]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 11406 is [True, False, False, False, True, False]
State prediction error at timestep 11406 is 0.012
Human Feedback received at timestep 11406 of None
Current timestep = 11407. State = [[-0.303692    0.05510956]]. Action = [[-0.01843698  0.06664724  0.         -0.5518414 ]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 11407 is [True, False, False, False, True, False]
Current timestep = 11408. State = [[-0.30327561  0.05420319]]. Action = [[ 0.01617372 -0.06187406  0.         -0.15701658]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 11408 is [True, False, False, False, True, False]
Current timestep = 11409. State = [[-0.30542013  0.05312201]]. Action = [[-0.05860953  0.00843793  0.          0.44060397]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 11409 is [True, False, False, False, True, False]
State prediction error at timestep 11409 is 0.012
Human Feedback received at timestep 11409 of None
Current timestep = 11410. State = [[-0.30524144  0.05384417]]. Action = [[ 0.03458116  0.00535093  0.         -0.4172287 ]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 11410 is [True, False, False, False, True, False]
Current timestep = 11411. State = [[-0.30119336  0.05581683]]. Action = [[ 0.06774253  0.03288267  0.         -0.81552315]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 11411 is [True, False, False, False, True, False]
Current timestep = 11412. State = [[-0.29874143  0.05988844]]. Action = [[0.01635154 0.05931979 0.         0.8927417 ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 11412 is [True, False, False, False, True, False]
State prediction error at timestep 11412 is 0.012
Human Feedback received at timestep 11412 of None
Current timestep = 11413. State = [[-0.30081743  0.05888064]]. Action = [[-0.05365061 -0.06494936  0.         -0.27036297]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 11413 is [True, False, False, False, True, False]
State prediction error at timestep 11413 is 0.012
Human Feedback received at timestep 11413 of None
Current timestep = 11414. State = [[-0.29809105  0.06058269]]. Action = [[ 0.08948288  0.06352089  0.         -0.9437294 ]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 11414 is [True, False, False, False, True, False]
Current timestep = 11415. State = [[-0.29574     0.06010402]]. Action = [[-0.01260762 -0.05272054  0.         -0.17781526]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 11415 is [True, False, False, False, True, False]
State prediction error at timestep 11415 is 0.012
Human Feedback received at timestep 11415 of None
Current timestep = 11416. State = [[-0.29156446  0.06271119]]. Action = [[0.07786108 0.07567909 0.         0.88669765]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 11416 is [True, False, False, False, True, False]
Current timestep = 11417. State = [[-0.2845283   0.06033015]]. Action = [[ 0.0838557  -0.09530427  0.          0.48350668]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 11417 is [True, False, False, False, True, False]
Current timestep = 11418. State = [[-0.2790009   0.05881442]]. Action = [[ 0.03482465  0.02557135  0.         -0.04187703]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 11418 is [True, False, False, False, True, False]
State prediction error at timestep 11418 is 0.012
Human Feedback received at timestep 11418 of None
Current timestep = 11419. State = [[-0.27653158  0.0626362 ]]. Action = [[ 0.00097375  0.06544549  0.         -0.52745545]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 11419 is [True, False, False, False, True, False]
State prediction error at timestep 11419 is 0.012
Human Feedback received at timestep 11419 of None
Current timestep = 11420. State = [[-0.27441937  0.06690394]]. Action = [[ 0.01916937  0.04226453  0.         -0.5526717 ]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 11420 is [True, False, False, False, True, False]
Current timestep = 11421. State = [[-0.26800033  0.06809928]]. Action = [[ 0.09880314 -0.00877737  0.         -0.7293856 ]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 11421 is [True, False, False, False, True, False]
Current timestep = 11422. State = [[-0.26575738  0.06377899]]. Action = [[-0.0466643  -0.08956907  0.          0.88312066]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 11422 is [True, False, False, False, True, False]
Current timestep = 11423. State = [[-0.26225784  0.06511559]]. Action = [[0.07203818 0.07747381 0.         0.86037016]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 11423 is [True, False, False, False, True, False]
Current timestep = 11424. State = [[-0.26180083  0.0635564 ]]. Action = [[-0.0643746  -0.08090599  0.          0.10327649]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 11424 is [True, False, False, False, True, False]
Current timestep = 11425. State = [[-0.26499325  0.06445989]]. Action = [[-0.05774508  0.05511875  0.         -0.6383183 ]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 11425 is [True, False, False, False, True, False]
Current timestep = 11426. State = [[-0.26816338  0.06242533]]. Action = [[-0.04874885 -0.08209459  0.         -0.7335379 ]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 11426 is [True, False, False, False, True, False]
Current timestep = 11427. State = [[-0.27195925  0.06148656]]. Action = [[-0.06506963  0.0186498   0.          0.79819906]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 11427 is [True, False, False, False, True, False]
State prediction error at timestep 11427 is 0.012
Human Feedback received at timestep 11427 of None
Current timestep = 11428. State = [[-0.27678323  0.06373825]]. Action = [[-0.06499577  0.02749444  0.          0.24010384]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 11428 is [True, False, False, False, True, False]
State prediction error at timestep 11428 is 0.012
Human Feedback received at timestep 11428 of None
Current timestep = 11429. State = [[-0.28202194  0.06227412]]. Action = [[-0.06432037 -0.05685776  0.          0.6493143 ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 11429 is [True, False, False, False, True, False]
State prediction error at timestep 11429 is 0.012
Human Feedback received at timestep 11429 of None
Current timestep = 11430. State = [[-0.28342694  0.06313577]]. Action = [[ 0.02162883  0.04404985  0.         -0.310449  ]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 11430 is [True, False, False, False, True, False]
State prediction error at timestep 11430 is 0.012
Human Feedback received at timestep 11430 of None
Current timestep = 11431. State = [[-0.28165284  0.06350336]]. Action = [[ 0.04677858 -0.01709484  0.          0.6381798 ]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 11431 is [True, False, False, False, True, False]
Current timestep = 11432. State = [[-0.2773473   0.06579214]]. Action = [[ 0.08536131  0.06101973  0.         -0.52284104]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 11432 is [True, False, False, False, True, False]
State prediction error at timestep 11432 is 0.012
Human Feedback received at timestep 11432 of None
Current timestep = 11433. State = [[-0.27432823  0.0704998 ]]. Action = [[ 0.0389818  0.0676466  0.        -0.4936806]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 11433 is [True, False, False, False, True, False]
Current timestep = 11434. State = [[-0.2758227   0.07303651]]. Action = [[-0.03402983  0.01136098  0.          0.33349764]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 11434 is [True, False, False, False, True, False]
Current timestep = 11435. State = [[-0.27854028  0.07103141]]. Action = [[-0.02415975 -0.05434474  0.         -0.94968504]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 11435 is [True, False, False, False, True, False]
Current timestep = 11436. State = [[-0.27927035  0.06905981]]. Action = [[ 0.00564604 -0.01347168  0.         -0.7745402 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 11436 is [True, False, False, False, True, False]
Current timestep = 11437. State = [[-0.28148168  0.07337017]]. Action = [[-0.0397166   0.09259479  0.          0.21553612]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 11437 is [True, False, False, False, True, False]
State prediction error at timestep 11437 is 0.012
Human Feedback received at timestep 11437 of None
Current timestep = 11438. State = [[-0.2810374   0.07919572]]. Action = [[ 0.04934711  0.05602547  0.         -0.43815452]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 11438 is [True, False, False, False, True, False]
Current timestep = 11439. State = [[-0.2792766   0.08499366]]. Action = [[ 0.02991221  0.07239277  0.         -0.2566502 ]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 11439 is [True, False, False, False, True, False]
Current timestep = 11440. State = [[-0.27668777  0.08993796]]. Action = [[ 0.05454279  0.04418422  0.         -0.15259784]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 11440 is [True, False, False, False, True, False]
State prediction error at timestep 11440 is 0.012
Human Feedback received at timestep 11440 of None
Current timestep = 11441. State = [[-0.2773301   0.09213371]]. Action = [[-3.2961071e-02  3.2480806e-04  0.0000000e+00 -7.0682609e-01]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 11441 is [True, False, False, False, True, False]
Current timestep = 11442. State = [[-0.27468613  0.08843186]]. Action = [[ 0.07329812 -0.09566792  0.          0.1821903 ]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 11442 is [True, False, False, False, True, False]
Current timestep = 11443. State = [[-0.275451    0.08561346]]. Action = [[-0.06939092 -0.01643724  0.          0.06216919]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 11443 is [True, False, False, False, True, False]
Current timestep = 11444. State = [[-0.27323958  0.08311259]]. Action = [[ 0.06922295 -0.0504838   0.          0.2865548 ]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 11444 is [True, False, False, False, True, False]
State prediction error at timestep 11444 is 0.012
Human Feedback received at timestep 11444 of None
Current timestep = 11445. State = [[-0.265569   0.0782065]]. Action = [[ 0.09752548 -0.06788914  0.         -0.86245626]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 11445 is [True, False, False, False, True, False]
Current timestep = 11446. State = [[-0.26515374  0.07804668]]. Action = [[-0.08127292  0.04537011  0.         -0.5492365 ]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 11446 is [True, False, False, False, True, False]
Current timestep = 11447. State = [[-0.26754504  0.08163881]]. Action = [[-0.0249439   0.04958244  0.          0.18686438]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 11447 is [True, False, False, False, True, False]
Current timestep = 11448. State = [[-0.27271533  0.08628019]]. Action = [[-0.09679011  0.05958468  0.          0.30530477]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 11448 is [True, False, False, False, True, False]
State prediction error at timestep 11448 is 0.012
Human Feedback received at timestep 11448 of None
Current timestep = 11449. State = [[-0.2762948   0.09013599]]. Action = [[-0.01399948  0.02987867  0.         -0.7046341 ]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 11449 is [True, False, False, False, True, False]
Current timestep = 11450. State = [[-0.2819641   0.08880704]]. Action = [[-0.09932914 -0.06165338  0.          0.20905268]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 11450 is [True, False, False, False, True, False]
Current timestep = 11451. State = [[-0.2842607   0.08335309]]. Action = [[ 0.01533544 -0.08891457  0.         -0.19526303]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 11451 is [True, False, False, False, True, False]
Current timestep = 11452. State = [[-0.28268415  0.07704127]]. Action = [[ 0.02906894 -0.07390533  0.         -0.78554237]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 11452 is [True, False, False, False, True, False]
Current timestep = 11453. State = [[-0.27822912  0.07846644]]. Action = [[0.08285391 0.08905614 0.         0.42208004]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 11453 is [True, False, False, False, True, False]
Current timestep = 11454. State = [[-0.27384743  0.08239352]]. Action = [[ 0.05780139  0.04551411  0.         -0.1904481 ]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 11454 is [True, False, False, False, True, False]
State prediction error at timestep 11454 is 0.012
Human Feedback received at timestep 11454 of None
Current timestep = 11455. State = [[-0.27639377  0.08306724]]. Action = [[-0.08301902 -0.00738023  0.          0.7433684 ]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 11455 is [True, False, False, False, True, False]
Current timestep = 11456. State = [[-0.28370264  0.08261901]]. Action = [[-0.09136415 -0.00506984  0.         -0.4503249 ]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 11456 is [True, False, False, False, True, False]
Current timestep = 11457. State = [[-0.28496468  0.08455735]]. Action = [[ 0.05334976  0.04315107  0.         -0.8654228 ]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 11457 is [True, False, False, False, True, False]
Current timestep = 11458. State = [[-0.28475705  0.08593199]]. Action = [[-0.00582474  0.00354642  0.         -0.24880713]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 11458 is [True, False, False, False, True, False]
Current timestep = 11459. State = [[-0.28194204  0.08847622]]. Action = [[0.07525345 0.04860515 0.         0.34582257]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 11459 is [True, False, False, False, True, False]
Current timestep = 11460. State = [[-0.27936235  0.08692165]]. Action = [[ 0.02144752 -0.05746623  0.          0.6459842 ]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 11460 is [True, False, False, False, True, False]
Current timestep = 11461. State = [[-0.27990636  0.08782736]]. Action = [[-0.02313889  0.05099875  0.          0.0200702 ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 11461 is [True, False, False, False, True, False]
Current timestep = 11462. State = [[-0.27624398  0.09043895]]. Action = [[ 0.09295768  0.02425535  0.         -0.88921624]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 11462 is [True, False, False, False, True, False]
Current timestep = 11463. State = [[-0.2751961  0.0902369]]. Action = [[-0.03553621 -0.0207103   0.          0.37271953]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 11463 is [True, False, False, False, True, False]
Current timestep = 11464. State = [[-0.2715059   0.09315471]]. Action = [[ 0.09488695  0.06989879  0.         -0.48236287]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 11464 is [True, False, False, False, True, False]
Current timestep = 11465. State = [[-0.2675061  0.099406 ]]. Action = [[ 0.02550223  0.08545286  0.         -0.21103191]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 11465 is [True, False, False, False, True, False]
State prediction error at timestep 11465 is 0.012
Human Feedback received at timestep 11465 of None
Current timestep = 11466. State = [[-0.26709247  0.09877754]]. Action = [[-0.01856748 -0.07400776  0.         -0.9375272 ]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 11466 is [True, False, False, False, True, False]
State prediction error at timestep 11466 is 0.012
Human Feedback received at timestep 11466 of None
Current timestep = 11467. State = [[-0.26829016  0.10172545]]. Action = [[-0.02980617  0.08572317  0.         -0.6657059 ]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 11467 is [True, False, False, False, True, False]
Current timestep = 11468. State = [[-0.26987883  0.10292518]]. Action = [[-0.02466832 -0.04439614  0.          0.9026785 ]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 11468 is [True, False, False, False, True, False]
Current timestep = 11469. State = [[-0.26760936  0.1005016 ]]. Action = [[ 0.04534263 -0.04571933  0.         -0.24375397]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 11469 is [True, False, False, False, True, False]
Current timestep = 11470. State = [[-0.2656722   0.09633394]]. Action = [[-0.00695823 -0.06853798  0.          0.05682707]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 11470 is [True, False, False, False, True, False]
Current timestep = 11471. State = [[-0.26106137  0.09918246]]. Action = [[0.08062539 0.09586173 0.         0.78193676]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 11471 is [True, False, False, False, True, False]
Current timestep = 11472. State = [[-0.25704753  0.10436501]]. Action = [[ 0.02138958  0.04846077  0.         -0.2135818 ]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 11472 is [True, False, False, False, True, False]
Current timestep = 11473. State = [[-0.25148788  0.10867154]]. Action = [[ 0.08487234  0.0516024   0.         -0.677968  ]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 11473 is [True, False, False, False, True, False]
State prediction error at timestep 11473 is 0.012
Human Feedback received at timestep 11473 of None
Current timestep = 11474. State = [[-0.2442318  0.1092294]]. Action = [[ 0.0819257  -0.02219499  0.         -0.902406  ]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 11474 is [True, False, False, False, True, False]
Current timestep = 11475. State = [[-0.24267557  0.1115384 ]]. Action = [[-0.0428308   0.053261    0.          0.45140243]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 11475 is [True, False, False, False, True, False]
Current timestep = 11476. State = [[-0.2387652  0.1095331]]. Action = [[ 0.07501683 -0.08170466  0.         -0.8350539 ]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 11476 is [True, False, False, False, True, False]
State prediction error at timestep 11476 is 0.012
Human Feedback received at timestep 11476 of None
Current timestep = 11477. State = [[-0.2364509   0.11074577]]. Action = [[-0.02550764  0.0645206   0.          0.5280273 ]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 11477 is [True, False, False, False, True, False]
Current timestep = 11478. State = [[-0.23356214  0.11597221]]. Action = [[0.04751381 0.05868535 0.         0.29462564]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 11478 is [True, False, False, False, True, False]
Current timestep = 11479. State = [[-0.23386498  0.11480942]]. Action = [[-0.06056547 -0.07586737  0.         -0.9030022 ]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 11479 is [True, False, False, False, True, False]
Current timestep = 11480. State = [[-0.23666383  0.11388046]]. Action = [[-0.04926019  0.00458179  0.          0.02687049]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 11480 is [True, False, False, False, True, False]
State prediction error at timestep 11480 is 0.012
Human Feedback received at timestep 11480 of None
Current timestep = 11481. State = [[-0.23881546  0.11917841]]. Action = [[-0.02745446  0.0879477   0.          0.16708672]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 11481 is [True, False, False, False, True, False]
Current timestep = 11482. State = [[-0.23641174  0.1254097 ]]. Action = [[ 0.0696872   0.05775187  0.         -0.4772293 ]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 11482 is [True, False, False, False, True, False]
Current timestep = 11483. State = [[-0.23912506  0.1302522 ]]. Action = [[-0.09245332  0.04169475  0.          0.21658862]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 11483 is [True, False, False, False, False, True]
Current timestep = 11484. State = [[-0.23967074  0.12817892]]. Action = [[ 0.0497627  -0.09072801  0.          0.5544634 ]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 11484 is [True, False, False, False, False, True]
State prediction error at timestep 11484 is 0.012
Human Feedback received at timestep 11484 of None
Current timestep = 11485. State = [[-0.23469314  0.12244511]]. Action = [[ 0.07807031 -0.07438529  0.         -0.9792975 ]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 11485 is [True, False, False, False, False, True]
State prediction error at timestep 11485 is 0.012
Human Feedback received at timestep 11485 of None
Current timestep = 11486. State = [[-0.23052324  0.11983653]]. Action = [[ 0.03271634 -0.004714    0.         -0.12735021]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 11486 is [True, False, False, False, True, False]
Current timestep = 11487. State = [[-0.2249629   0.12387603]]. Action = [[0.0868598  0.09561632 0.         0.8443818 ]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 11487 is [True, False, False, False, True, False]
Current timestep = 11488. State = [[-0.22049332  0.13050102]]. Action = [[0.03970119 0.09078638 0.         0.82302856]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 11488 is [True, False, False, False, True, False]
Current timestep = 11489. State = [[-0.21474679  0.13333601]]. Action = [[0.08772517 0.00915788 0.         0.61543083]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 11489 is [True, False, False, False, False, True]
Current timestep = 11490. State = [[-0.21526255  0.1313476 ]]. Action = [[-0.08774816 -0.05229997  0.         -0.32232928]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 11490 is [True, False, False, False, False, True]
State prediction error at timestep 11490 is 0.012
Human Feedback received at timestep 11490 of None
Current timestep = 11491. State = [[-0.21785097  0.13095276]]. Action = [[-0.01675496  0.01478747  0.         -0.6588805 ]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 11491 is [True, False, False, False, False, True]
Current timestep = 11492. State = [[-0.21910816  0.13491905]]. Action = [[-0.01457824  0.06662614  0.         -0.7388823 ]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 11492 is [True, False, False, False, False, True]
Current timestep = 11493. State = [[-0.2235322   0.13923325]]. Action = [[-0.07684124  0.03548891  0.         -0.0396027 ]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 11493 is [True, False, False, False, False, True]
Current timestep = 11494. State = [[-0.22646317  0.1431298 ]]. Action = [[-0.00682847  0.03569797  0.         -0.8544368 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 11494 is [True, False, False, False, False, True]
Current timestep = 11495. State = [[-0.23047675  0.1456719 ]]. Action = [[-0.06347688  0.00666875  0.         -0.29817975]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 11495 is [True, False, False, False, False, True]
Current timestep = 11496. State = [[-0.23502271  0.14440414]]. Action = [[-0.04607445 -0.05894793  0.         -0.43247932]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 11496 is [True, False, False, False, False, True]
Current timestep = 11497. State = [[-0.2349386  0.1482136]]. Action = [[0.04749065 0.09028364 0.         0.12097573]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 11497 is [True, False, False, False, False, True]
Current timestep = 11498. State = [[-0.23729002  0.15585133]]. Action = [[-0.05504873  0.08419663  0.          0.8054458 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 11498 is [True, False, False, False, False, True]
Current timestep = 11499. State = [[-0.2372113   0.15975654]]. Action = [[ 0.05281372  0.00405693  0.         -0.53941536]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 11499 is [True, False, False, False, False, True]
Current timestep = 11500. State = [[-0.23417585  0.1641716 ]]. Action = [[0.05219329 0.06725299 0.         0.08804512]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 11500 is [True, False, False, False, False, True]
Current timestep = 11501. State = [[-0.22876795  0.16497098]]. Action = [[ 0.09274868 -0.03501027  0.          0.13450515]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 11501 is [True, False, False, False, False, True]
State prediction error at timestep 11501 is 0.012
Human Feedback received at timestep 11501 of None
Current timestep = 11502. State = [[-0.22582993  0.16784225]]. Action = [[ 0.00673846  0.06727124  0.         -0.53929734]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 11502 is [True, False, False, False, False, True]
Current timestep = 11503. State = [[-0.22278091  0.17101642]]. Action = [[0.05353298 0.01398989 0.         0.4302075 ]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 11503 is [True, False, False, False, False, True]
Current timestep = 11504. State = [[-0.21698344  0.17257293]]. Action = [[0.07708471 0.01146773 0.         0.12256801]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 11504 is [True, False, False, False, False, True]
Current timestep = 11505. State = [[-0.21816595  0.17451487]]. Action = [[-0.09215508  0.01686218  0.         -0.35422146]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 11505 is [True, False, False, False, False, True]
Current timestep = 11506. State = [[-0.220799    0.17926747]]. Action = [[-0.01425231  0.06420138  0.         -0.7132178 ]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 11506 is [True, False, False, False, False, True]
Current timestep = 11507. State = [[-0.22545387  0.18516022]]. Action = [[-0.08486473  0.05622835  0.          0.4416864 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 11507 is [True, False, False, False, False, True]
Current timestep = 11508. State = [[-0.226599    0.18649898]]. Action = [[ 0.02785576 -0.03907821  0.          0.7860756 ]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 11508 is [True, False, False, False, False, True]
Current timestep = 11509. State = [[-0.22837701  0.19061275]]. Action = [[-0.04733489  0.07622755  0.          0.31481624]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 11509 is [True, False, False, False, False, True]
Current timestep = 11510. State = [[-0.23416518  0.19076492]]. Action = [[-0.08703037 -0.07577129  0.         -0.17608392]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 11510 is [True, False, False, False, False, True]
Current timestep = 11511. State = [[-0.23419155  0.18621223]]. Action = [[ 0.05260628 -0.08385126  0.          0.6400809 ]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 11511 is [True, False, False, False, False, True]
Current timestep = 11512. State = [[-0.23503372  0.18709943]]. Action = [[-0.04575061  0.05210354  0.          0.9196465 ]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 11512 is [True, False, False, False, False, True]
Current timestep = 11513. State = [[-0.23774439  0.186612  ]]. Action = [[-0.02620372 -0.05632496  0.         -0.24600303]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 11513 is [True, False, False, False, False, True]
Current timestep = 11514. State = [[-0.23656203  0.18405649]]. Action = [[ 0.04127464 -0.03270329  0.          0.5616673 ]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 11514 is [True, False, False, False, False, True]
Current timestep = 11515. State = [[-0.23292011  0.18212381]]. Action = [[ 0.05043242 -0.01568285  0.         -0.49623215]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 11515 is [True, False, False, False, False, True]
Current timestep = 11516. State = [[-0.23227797  0.18122573]]. Action = [[-0.01973567  0.00171185  0.         -0.950098  ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 11516 is [True, False, False, False, False, True]
State prediction error at timestep 11516 is 0.012
Human Feedback received at timestep 11516 of None
Current timestep = 11517. State = [[-0.22790281  0.1772305 ]]. Action = [[ 0.09413328 -0.06814889  0.          0.97100663]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 11517 is [True, False, False, False, False, True]
Current timestep = 11518. State = [[-0.22353135  0.1785728 ]]. Action = [[0.02838328 0.09331361 0.         0.06937265]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 11518 is [True, False, False, False, False, True]
State prediction error at timestep 11518 is 0.012
Human Feedback received at timestep 11518 of None
Current timestep = 11519. State = [[-0.2188639   0.18366686]]. Action = [[ 0.07657196  0.07813997  0.         -0.7234882 ]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 11519 is [True, False, False, False, False, True]
Current timestep = 11520. State = [[-0.21428616  0.18368576]]. Action = [[ 0.04570761 -0.02418577  0.          0.5123092 ]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 11520 is [True, False, False, False, False, True]
Current timestep = 11521. State = [[-0.21382827  0.17874998]]. Action = [[-0.03539226 -0.07641025  0.          0.59136724]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 11521 is [True, False, False, False, False, True]
Current timestep = 11522. State = [[-0.21261935  0.17272396]]. Action = [[ 0.02047692 -0.07122107  0.         -0.7362857 ]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 11522 is [True, False, False, False, False, True]
Current timestep = 11523. State = [[-0.21464135  0.16582496]]. Action = [[-0.08161599 -0.09059468  0.          0.3385713 ]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 11523 is [True, False, False, False, False, True]
Current timestep = 11524. State = [[-0.21436891  0.16314815]]. Action = [[ 0.02855564  0.00854693  0.         -0.697443  ]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 11524 is [True, False, False, False, False, True]
Current timestep = 11525. State = [[-0.21474597  0.16456714]]. Action = [[-0.04162288  0.0378871   0.         -0.2283333 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 11525 is [True, False, False, False, False, True]
Current timestep = 11526. State = [[-0.21970674  0.16486229]]. Action = [[-0.09098566 -0.01299146  0.          0.6940981 ]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 11526 is [True, False, False, False, False, True]
State prediction error at timestep 11526 is 0.012
Human Feedback received at timestep 11526 of None
Current timestep = 11527. State = [[-0.21932091  0.16519302]]. Action = [[ 0.06149688  0.0157433   0.         -0.01014763]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 11527 is [True, False, False, False, False, True]
State prediction error at timestep 11527 is 0.012
Human Feedback received at timestep 11527 of None
Current timestep = 11528. State = [[-0.21603307  0.16210556]]. Action = [[ 0.02998706 -0.06413323  0.         -0.96601045]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 11528 is [True, False, False, False, False, True]
Current timestep = 11529. State = [[-0.21409254  0.15993957]]. Action = [[ 0.01038827  0.00224669  0.         -0.97137713]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 11529 is [True, False, False, False, False, True]
Current timestep = 11530. State = [[-0.20912287  0.15699661]]. Action = [[ 0.08606494 -0.04533271  0.         -0.9726875 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 11530 is [True, False, False, False, False, True]
State prediction error at timestep 11530 is 0.012
Human Feedback received at timestep 11530 of None
Current timestep = 11531. State = [[-0.20500119  0.15300183]]. Action = [[ 0.02193049 -0.03361562  0.         -0.2706014 ]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 11531 is [True, False, False, False, False, True]
State prediction error at timestep 11531 is 0.012
Human Feedback received at timestep 11531 of None
Current timestep = 11532. State = [[-0.20321691  0.1462121 ]]. Action = [[ 0.00145356 -0.09686097  0.          0.2902249 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 11532 is [True, False, False, False, False, True]
Current timestep = 11533. State = [[-0.20332977  0.1404392 ]]. Action = [[-0.02976272 -0.04041907  0.         -0.22537625]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 11533 is [True, False, False, False, False, True]
Current timestep = 11534. State = [[-0.20210917  0.13937657]]. Action = [[0.02108945 0.02701988 0.         0.5868083 ]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 11534 is [True, False, False, False, False, True]
Current timestep = 11535. State = [[-0.20182832  0.13618487]]. Action = [[-0.02075054 -0.05507091  0.          0.38223052]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 11535 is [True, False, False, False, False, True]
Current timestep = 11536. State = [[-0.20301062  0.1366098 ]]. Action = [[-0.02457753  0.06039038  0.          0.3372364 ]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 11536 is [True, False, False, False, False, True]
Current timestep = 11537. State = [[-0.2007918  0.141802 ]]. Action = [[ 0.06447417  0.09122484  0.         -0.522353  ]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 11537 is [True, False, False, False, False, True]
State prediction error at timestep 11537 is 0.012
Human Feedback received at timestep 11537 of None
Current timestep = 11538. State = [[-0.19756833  0.14342922]]. Action = [[ 0.04017317 -0.00357868  0.          0.09661436]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 11538 is [True, False, False, False, False, True]
Current timestep = 11539. State = [[-0.20074315  0.1413208 ]]. Action = [[-0.09230817 -0.0370031   0.          0.36794722]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 11539 is [True, False, False, False, False, True]
Current timestep = 11540. State = [[-0.2014071  0.1433318]]. Action = [[ 0.05135088  0.06664873  0.         -0.12213206]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 11540 is [True, False, False, False, False, True]
Current timestep = 11541. State = [[-0.19833641  0.14965305]]. Action = [[ 0.04784799  0.09339953  0.         -0.91906935]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 11541 is [True, False, False, False, False, True]
Current timestep = 11542. State = [[-0.19671354  0.15140288]]. Action = [[ 0.01448905 -0.02202474  0.          0.6791897 ]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 11542 is [True, False, False, False, False, True]
Current timestep = 11543. State = [[-0.19657227  0.15393719]]. Action = [[-0.00324093  0.05326033  0.         -0.16473544]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 11543 is [True, False, False, False, False, True]
Current timestep = 11544. State = [[-0.19542839  0.15239967]]. Action = [[ 0.02546015 -0.07370593  0.         -0.91731244]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 11544 is [True, False, False, False, False, True]
Current timestep = 11545. State = [[-0.1911726   0.14737068]]. Action = [[ 0.0606593  -0.06980999  0.          0.9642012 ]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 11545 is [True, False, False, False, False, True]
State prediction error at timestep 11545 is 0.012
Human Feedback received at timestep 11545 of None
Current timestep = 11546. State = [[-0.18707417  0.14185724]]. Action = [[ 0.02682992 -0.06962218  0.         -0.584045  ]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 11546 is [True, False, False, False, False, True]
Current timestep = 11547. State = [[-0.18885566  0.13502672]]. Action = [[-0.08814246 -0.09662392  0.          0.39771783]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 11547 is [True, False, False, False, False, True]
Current timestep = 11548. State = [[-0.18812974  0.13119808]]. Action = [[ 0.03581121 -0.01498073  0.         -0.15765226]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 11548 is [True, False, False, False, False, True]
Current timestep = 11549. State = [[-0.18906435  0.12523992]]. Action = [[-0.07145824 -0.09937748  0.          0.49751532]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 11549 is [True, False, False, False, False, True]
Current timestep = 11550. State = [[-0.19310437  0.12223399]]. Action = [[-0.07299985  0.00648084  0.         -0.30173236]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 11550 is [True, False, False, False, False, True]
State prediction error at timestep 11550 is 0.012
Human Feedback received at timestep 11550 of None
Current timestep = 11551. State = [[-0.19339763  0.12531887]]. Action = [[ 0.02953718  0.0753633   0.         -0.48711574]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 11551 is [True, False, False, False, True, False]
State prediction error at timestep 11551 is 0.012
Human Feedback received at timestep 11551 of None
Current timestep = 11552. State = [[-0.18801288  0.12186366]]. Action = [[ 0.09554902 -0.09527879  0.         -0.05281174]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 11552 is [True, False, False, False, False, True]
Current timestep = 11553. State = [[-0.18124911  0.12123305]]. Action = [[0.08247984 0.07220262 0.         0.7559376 ]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 11553 is [True, False, False, False, True, False]
Current timestep = 11554. State = [[-0.17664112  0.12264474]]. Action = [[0.04654568 0.01997765 0.         0.7509265 ]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 11554 is [True, False, False, False, True, False]
Current timestep = 11555. State = [[-0.1746165   0.12075995]]. Action = [[ 0.00893308 -0.02814458  0.         -0.03742838]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 11555 is [True, False, False, False, True, False]
Current timestep = 11556. State = [[-0.17072167  0.12223626]]. Action = [[ 0.06791077  0.06576014  0.         -0.41118652]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 11556 is [True, False, False, False, True, False]
State prediction error at timestep 11556 is 0.012
Human Feedback received at timestep 11556 of None
Current timestep = 11557. State = [[-0.17247519  0.12802975]]. Action = [[-0.07872397  0.09208987  0.          0.69549835]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 11557 is [True, False, False, False, True, False]
State prediction error at timestep 11557 is 0.012
Human Feedback received at timestep 11557 of None
Current timestep = 11558. State = [[-0.17916505  0.13498113]]. Action = [[-0.08735128  0.07931215  0.          0.57736754]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 11558 is [True, False, False, False, False, True]
Current timestep = 11559. State = [[-0.1809101  0.1427788]]. Action = [[0.03806163 0.09157827 0.         0.32384777]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 11559 is [True, False, False, False, False, True]
State prediction error at timestep 11559 is 0.012
Human Feedback received at timestep 11559 of None
Current timestep = 11560. State = [[-0.18442214  0.14241913]]. Action = [[-0.08216616 -0.09203052  0.          0.15359652]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 11560 is [True, False, False, False, False, True]
State prediction error at timestep 11560 is 0.012
Human Feedback received at timestep 11560 of None
Current timestep = 11561. State = [[-0.18373571  0.14542526]]. Action = [[ 0.09328903  0.09124508  0.         -0.64665467]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 11561 is [True, False, False, False, False, True]
State prediction error at timestep 11561 is 0.012
Human Feedback received at timestep 11561 of None
Current timestep = 11562. State = [[-0.18464516  0.15153374]]. Action = [[-0.06047749  0.04550297  0.         -0.24195951]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 11562 is [True, False, False, False, False, True]
Current timestep = 11563. State = [[-0.18500243  0.15141293]]. Action = [[ 0.03231088 -0.0642067   0.         -0.03764939]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 11563 is [True, False, False, False, False, True]
Current timestep = 11564. State = [[-0.18779688  0.14896777]]. Action = [[-0.07743552 -0.04476137  0.         -0.812526  ]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 11564 is [True, False, False, False, False, True]
Current timestep = 11565. State = [[-0.19007215  0.14525588]]. Action = [[-0.01193227 -0.07725164  0.         -0.21086848]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 11565 is [True, False, False, False, False, True]
Current timestep = 11566. State = [[-0.18721555  0.14803258]]. Action = [[0.06706417 0.08952475 0.         0.5987834 ]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 11566 is [True, False, False, False, False, True]
Current timestep = 11567. State = [[-0.1883526   0.15503003]]. Action = [[-0.06121726  0.08060045  0.         -0.7987488 ]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 11567 is [True, False, False, False, False, True]
State prediction error at timestep 11567 is 0.012
Human Feedback received at timestep 11567 of None
Current timestep = 11568. State = [[-0.19312982  0.1633256 ]]. Action = [[-0.05515697  0.09827461  0.          0.5730164 ]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 11568 is [True, False, False, False, False, True]
Current timestep = 11569. State = [[-0.19441567  0.17056854]]. Action = [[0.02767067 0.06258021 0.         0.08722436]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 11569 is [True, False, False, False, False, True]
State prediction error at timestep 11569 is 0.012
Human Feedback received at timestep 11569 of None
Current timestep = 11570. State = [[-0.19720002  0.1757114 ]]. Action = [[-0.04771981  0.03895023  0.         -0.5929935 ]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 11570 is [True, False, False, False, False, True]
Current timestep = 11571. State = [[-0.19889894  0.18153839]]. Action = [[0.01684443 0.06325973 0.         0.43621767]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 11571 is [True, False, False, False, False, True]
Current timestep = 11572. State = [[-0.1981397  0.1819591]]. Action = [[ 0.02958215 -0.05758612  0.         -0.9126025 ]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 11572 is [True, False, False, False, False, True]
Current timestep = 11573. State = [[-0.19630799  0.18068634]]. Action = [[ 0.02974468 -0.01862317  0.          0.6949569 ]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 11573 is [True, False, False, False, False, True]
Current timestep = 11574. State = [[-0.19823733  0.18430132]]. Action = [[-0.05046083  0.06521478  0.         -0.30751586]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 11574 is [True, False, False, False, False, True]
Current timestep = 11575. State = [[-0.19752121  0.19075216]]. Action = [[ 0.05588948  0.07342591  0.         -0.41852587]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 11575 is [True, False, False, False, False, True]
Current timestep = 11576. State = [[-0.2002472   0.19342487]]. Action = [[-0.0818077  -0.0139909   0.         -0.35418367]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 11576 is [True, False, False, False, False, True]
Current timestep = 11577. State = [[-0.20428154  0.19830532]]. Action = [[-0.02136674  0.07988536  0.          0.83825934]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 11577 is [True, False, False, False, False, True]
State prediction error at timestep 11577 is 0.012
Human Feedback received at timestep 11577 of None
Current timestep = 11578. State = [[-0.20503576  0.19980064]]. Action = [[ 0.01920058 -0.03802114  0.          0.80814517]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 11578 is [True, False, False, False, False, True]
Current timestep = 11579. State = [[-0.2083851  0.2043159]]. Action = [[-0.06264637  0.09054362  0.          0.30674577]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 11579 is [True, False, False, False, False, True]
Current timestep = 11580. State = [[-0.20795512  0.20599909]]. Action = [[ 0.06437729 -0.03982723  0.         -0.039612  ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 11580 is [True, False, False, False, False, True]
Current timestep = 11581. State = [[-0.20267077  0.20453456]]. Action = [[ 0.08274492 -0.02103089  0.         -0.2965002 ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 11581 is [True, False, False, False, False, True]
Current timestep = 11582. State = [[-0.1972957   0.20696683]]. Action = [[ 0.06190334  0.06112667  0.         -0.26930875]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 11582 is [True, False, False, False, False, True]
Current timestep = 11583. State = [[-0.19289362  0.20631696]]. Action = [[ 0.04626293 -0.04716207  0.          0.8525317 ]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 11583 is [True, False, False, False, False, True]
Current timestep = 11584. State = [[-0.19201842  0.20837575]]. Action = [[-0.02498706  0.06568969  0.          0.91020286]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 11584 is [True, False, False, False, False, True]
Current timestep = 11585. State = [[-0.19082052  0.20848344]]. Action = [[ 0.0230248  -0.04146711  0.          0.6386061 ]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 11585 is [True, False, False, False, False, True]
State prediction error at timestep 11585 is 0.012
Human Feedback received at timestep 11585 of None
Current timestep = 11586. State = [[-0.19116078  0.20345818]]. Action = [[-0.04392114 -0.09063858  0.         -0.45912808]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 11586 is [True, False, False, False, False, True]
State prediction error at timestep 11586 is 0.012
Human Feedback received at timestep 11586 of None
Current timestep = 11587. State = [[-0.19085458  0.20315167]]. Action = [[0.00492332 0.03740255 0.         0.0491097 ]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 11587 is [True, False, False, False, False, True]
Current timestep = 11588. State = [[-0.19242114  0.20500846]]. Action = [[-0.0527835   0.01064773  0.          0.89698553]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 11588 is [True, False, False, False, False, True]
Current timestep = 11589. State = [[-0.18925524  0.20718302]]. Action = [[ 0.08501337  0.03177164  0.         -0.06115472]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 11589 is [True, False, False, False, False, True]
Current timestep = 11590. State = [[-0.1876448   0.20450296]]. Action = [[-0.03553396 -0.07903156  0.         -0.41141695]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 11590 is [True, False, False, False, False, True]
State prediction error at timestep 11590 is 0.012
Human Feedback received at timestep 11590 of None
Current timestep = 11591. State = [[-0.19218494  0.2043015 ]]. Action = [[-0.08973777  0.03283285  0.          0.3862381 ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 11591 is [True, False, False, False, False, True]
Current timestep = 11592. State = [[-0.19316688  0.20298061]]. Action = [[ 0.02701633 -0.0536786   0.          0.16398048]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 11592 is [True, False, False, False, False, True]
Current timestep = 11593. State = [[-0.1950987   0.20557581]]. Action = [[-0.05280107  0.07991315  0.          0.11836219]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 11593 is [True, False, False, False, False, True]
Current timestep = 11594. State = [[-0.19278435  0.20783344]]. Action = [[ 0.08844306 -0.00089725  0.          0.46704602]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 11594 is [True, False, False, False, False, True]
State prediction error at timestep 11594 is 0.012
Human Feedback received at timestep 11594 of None
Current timestep = 11595. State = [[-0.18651888  0.21013248]]. Action = [[0.09144223 0.0557794  0.         0.5903766 ]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 11595 is [True, False, False, False, False, True]
Current timestep = 11596. State = [[-0.18530378  0.20686516]]. Action = [[-0.03739467 -0.09466176  0.         -0.7123625 ]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 11596 is [True, False, False, False, False, True]
State prediction error at timestep 11596 is 0.012
Human Feedback received at timestep 11596 of None
Current timestep = 11597. State = [[-0.18891817  0.20493767]]. Action = [[-0.05069662  0.01974013  0.          0.10834932]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 11597 is [True, False, False, False, False, True]
Current timestep = 11598. State = [[-0.18761979  0.2068144 ]]. Action = [[ 0.07116026  0.03969636  0.         -0.3415655 ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 11598 is [True, False, False, False, False, True]
Current timestep = 11599. State = [[-0.1826704   0.21044676]]. Action = [[ 0.07600158  0.0679641   0.         -0.16986364]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 11599 is [True, False, False, False, False, True]
Current timestep = 11600. State = [[-0.18254906  0.2073088 ]]. Action = [[-0.04898765 -0.09807349  0.          0.37204027]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 11600 is [True, False, False, False, False, True]
Current timestep = 11601. State = [[-0.18429326  0.20129709]]. Action = [[-0.00584909 -0.0595715   0.          0.04948354]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 11601 is [True, False, False, False, False, True]
Current timestep = 11602. State = [[-0.18122444  0.19548959]]. Action = [[ 0.06868029 -0.06469919  0.          0.6704763 ]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 11602 is [True, False, False, False, False, True]
Current timestep = 11603. State = [[-0.1835752   0.19308974]]. Action = [[-0.09280093  0.01052238  0.          0.39183855]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 11603 is [True, False, False, False, False, True]
Current timestep = 11604. State = [[-0.18941167  0.19452973]]. Action = [[-0.06776281  0.03440685  0.         -0.05231655]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 11604 is [True, False, False, False, False, True]
Current timestep = 11605. State = [[-0.189384    0.19222887]]. Action = [[ 0.05038591 -0.05813003  0.         -0.59797597]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 11605 is [True, False, False, False, False, True]
Current timestep = 11606. State = [[-0.1844716   0.19181065]]. Action = [[0.08256171 0.04462826 0.         0.5539725 ]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 11606 is [True, False, False, False, False, True]
Current timestep = 11607. State = [[-0.17934531  0.18783394]]. Action = [[ 0.06196091 -0.07742467  0.         -0.62758374]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 11607 is [True, False, False, False, False, True]
Current timestep = 11608. State = [[-0.17380187  0.18606715]]. Action = [[0.0704831  0.0369683  0.         0.62815106]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 11608 is [True, False, False, False, False, True]
Current timestep = 11609. State = [[-0.17353147  0.18859234]]. Action = [[-0.04174252  0.05934676  0.          0.5628561 ]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 11609 is [True, False, False, False, False, True]
Current timestep = 11610. State = [[-0.17279264  0.19011317]]. Action = [[0.03415532 0.01197585 0.         0.92152166]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 11610 is [True, False, False, False, False, True]
State prediction error at timestep 11610 is 0.012
Human Feedback received at timestep 11610 of None
Current timestep = 11611. State = [[-0.16970085  0.18971613]]. Action = [[ 0.04014709 -0.00309113  0.         -0.48746395]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 11611 is [True, False, False, False, False, True]
Current timestep = 11612. State = [[-0.1683793  0.1876262]]. Action = [[-0.00643402 -0.03121439  0.         -0.28058517]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 11612 is [True, False, False, False, False, True]
Current timestep = 11613. State = [[-0.17057887  0.19011445]]. Action = [[-0.05339799  0.07043823  0.          0.27864027]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 11613 is [True, False, False, False, False, True]
Current timestep = 11614. State = [[-0.17213966  0.18882455]]. Action = [[-0.00806984 -0.07280518  0.         -0.46813583]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 11614 is [True, False, False, False, False, True]
Current timestep = 11615. State = [[-0.16850506  0.19126976]]. Action = [[0.07833592 0.08895952 0.         0.4751488 ]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 11615 is [True, False, False, False, False, True]
Current timestep = 11616. State = [[-0.16790567  0.18985583]]. Action = [[-0.0538969  -0.08768786  0.          0.5741099 ]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 11616 is [True, False, False, False, False, True]
Current timestep = 11617. State = [[-0.1666766   0.18375362]]. Action = [[ 0.0408606  -0.08076141  0.          0.21631896]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 11617 is [True, False, False, False, False, True]
Current timestep = 11618. State = [[-0.16097917  0.18168063]]. Action = [[0.08318355 0.01700325 0.         0.55335045]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 11618 is [True, False, False, False, False, True]
Current timestep = 11619. State = [[-0.15533538  0.1801521 ]]. Action = [[ 0.05495971 -0.01859411  0.          0.90283346]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 11619 is [True, False, False, False, False, True]
Current timestep = 11620. State = [[-0.15278181  0.18089727]]. Action = [[0.00299873 0.04523606 0.         0.97105026]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 11620 is [True, False, False, False, False, True]
Current timestep = 11621. State = [[-0.15034837  0.18022902]]. Action = [[ 0.03181321 -0.02336162  0.          0.66274536]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 11621 is [True, False, False, False, False, True]
Current timestep = 11622. State = [[-0.14516257  0.17467798]]. Action = [[ 0.06681291 -0.08329971  0.         -0.5756531 ]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 11622 is [True, False, False, False, False, True]
State prediction error at timestep 11622 is 0.012
Human Feedback received at timestep 11622 of None
Current timestep = 11623. State = [[-0.1391697   0.17532186]]. Action = [[0.05994227 0.08651883 0.         0.36350596]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 11623 is [True, False, False, False, False, True]
Current timestep = 11624. State = [[-0.13319394  0.17318444]]. Action = [[ 0.06505556 -0.06672628  0.         -0.31915295]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 11624 is [True, False, False, False, False, True]
Current timestep = 11625. State = [[-0.13397472  0.16611466]]. Action = [[-0.09748511 -0.09418597  0.         -0.9440349 ]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 11625 is [True, False, False, False, False, True]
Current timestep = 11626. State = [[-0.13778083  0.1616226 ]]. Action = [[-0.05995978 -0.02750806  0.          0.5275116 ]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 11626 is [True, False, False, False, False, True]
Current timestep = 11627. State = [[-0.14067602  0.16330363]]. Action = [[-0.04157639  0.06009021  0.          0.06682515]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 11627 is [True, False, False, False, False, True]
Current timestep = 11628. State = [[-0.14199117  0.16485631]]. Action = [[-0.00566863  0.00286454  0.          0.3406011 ]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 11628 is [True, False, False, False, False, True]
Current timestep = 11629. State = [[-0.1421657   0.16262779]]. Action = [[-0.00053585 -0.04403594  0.          0.46918702]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 11629 is [True, False, False, False, False, True]
State prediction error at timestep 11629 is 0.012
Human Feedback received at timestep 11629 of None
Current timestep = 11630. State = [[-0.14609917  0.15680136]]. Action = [[-0.08624635 -0.09101284  0.          0.8901403 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 11630 is [True, False, False, False, False, True]
Current timestep = 11631. State = [[-0.15020199  0.15694755]]. Action = [[-0.03477846  0.05759407  0.         -0.6325488 ]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 11631 is [True, False, False, False, False, True]
State prediction error at timestep 11631 is 0.012
Human Feedback received at timestep 11631 of None
Current timestep = 11632. State = [[-0.14740553  0.15661387]]. Action = [[ 0.09352327 -0.03087511  0.         -0.8349812 ]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 11632 is [True, False, False, False, False, True]
Current timestep = 11633. State = [[-0.14737749  0.15640046]]. Action = [[-0.03838168  0.02621756  0.          0.32569408]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 11633 is [True, False, False, False, False, True]
State prediction error at timestep 11633 is 0.012
Human Feedback received at timestep 11633 of None
Current timestep = 11634. State = [[-0.14488369  0.15311815]]. Action = [[ 0.08233168 -0.06758651  0.         -0.09229958]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 11634 is [True, False, False, False, False, True]
State prediction error at timestep 11634 is 0.012
Human Feedback received at timestep 11634 of None
Current timestep = 11635. State = [[-0.14207472  0.15170075]]. Action = [[0.01986287 0.031457   0.         0.7163937 ]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 11635 is [True, False, False, False, False, True]
Current timestep = 11636. State = [[-0.13835007  0.15530376]]. Action = [[ 0.074172    0.08002973  0.         -0.4423883 ]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 11636 is [True, False, False, False, False, True]
Current timestep = 11637. State = [[-0.13420597  0.15576555]]. Action = [[ 0.05417774 -0.01482388  0.         -0.57459015]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 11637 is [True, False, False, False, False, True]
State prediction error at timestep 11637 is 0.012
Human Feedback received at timestep 11637 of None
Current timestep = 11638. State = [[-0.1353115   0.15796696]]. Action = [[-0.05159289  0.06640171  0.         -0.34723973]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 11638 is [True, False, False, False, False, True]
Current timestep = 11639. State = [[-0.1326327   0.16363765]]. Action = [[0.09415143 0.0853649  0.         0.37847865]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 11639 is [True, False, False, False, False, True]
Current timestep = 11640. State = [[-0.1259736  0.1628749]]. Action = [[ 0.08564732 -0.05948564  0.          0.12093794]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 11640 is [True, False, False, False, False, True]
Current timestep = 11641. State = [[-0.12586895  0.15885457]]. Action = [[-0.0719455  -0.05132923  0.         -0.7758943 ]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 11641 is [True, False, False, False, False, True]
Current timestep = 11642. State = [[-0.12214033  0.15371326]]. Action = [[ 0.09685554 -0.07345078  0.         -0.10512853]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 11642 is [True, False, False, False, False, True]
Current timestep = 11643. State = [[-0.11533146  0.15448192]]. Action = [[ 0.06091138  0.06997157  0.         -0.17980105]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 11643 is [True, False, False, False, False, True]
Current timestep = 11644. State = [[-0.10746586  0.15208647]]. Action = [[ 0.09801545 -0.07346679  0.         -0.65799415]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 11644 is [True, False, False, False, False, True]
Current timestep = 11645. State = [[-0.09820978  0.14508872]]. Action = [[ 0.09455409 -0.08088382  0.          0.1063    ]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 11645 is [True, False, False, False, False, True]
Current timestep = 11646. State = [[-0.09644509  0.13850479]]. Action = [[-0.07835766 -0.06508527  0.          0.14716482]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 11646 is [True, False, False, False, False, True]
Current timestep = 11647. State = [[-0.09858959  0.13915819]]. Action = [[-0.05125817  0.06781817  0.         -0.25296813]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 11647 is [True, False, False, False, False, True]
State prediction error at timestep 11647 is 0.012
Human Feedback received at timestep 11647 of None
Current timestep = 11648. State = [[-0.09503382  0.1393646 ]]. Action = [[ 0.0754826  -0.01933913  0.         -0.70641065]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 11648 is [True, False, False, False, False, True]
Current timestep = 11649. State = [[-0.09135119  0.14212093]]. Action = [[0.01151681 0.08161085 0.         0.22819018]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 11649 is [True, False, False, False, False, True]
State prediction error at timestep 11649 is 0.012
Human Feedback received at timestep 11649 of None
Current timestep = 11650. State = [[-0.0942449  0.1413507]]. Action = [[-0.09476177 -0.0596513   0.          0.57330775]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 11650 is [True, False, False, False, False, True]
State prediction error at timestep 11650 is 0.012
Human Feedback received at timestep 11650 of None
Current timestep = 11651. State = [[-0.09968298  0.14449209]]. Action = [[-0.07441682  0.08883128  0.         -0.78053147]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 11651 is [True, False, False, False, False, True]
State prediction error at timestep 11651 is 0.012
Human Feedback received at timestep 11651 of None
Current timestep = 11652. State = [[-0.09928572  0.1463911 ]]. Action = [[ 0.05552352 -0.02292685  0.         -0.7909175 ]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 11652 is [True, False, False, False, False, True]
Current timestep = 11653. State = [[-0.0935237  0.1473062]]. Action = [[ 0.09790628  0.02696071  0.         -0.16680104]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 11653 is [True, False, False, False, False, True]
Current timestep = 11654. State = [[-0.09351235  0.15195099]]. Action = [[-0.04914593  0.07849277  0.          0.16396499]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 11654 is [True, False, False, False, False, True]
Current timestep = 11655. State = [[-0.09113847  0.15487239]]. Action = [[ 0.08768987  0.00679582  0.         -0.751046  ]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 11655 is [True, False, False, False, False, True]
Current timestep = 11656. State = [[-0.0866172   0.15521884]]. Action = [[ 0.05379405 -0.00050592  0.         -0.263116  ]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 11656 is [True, False, False, False, False, True]
Current timestep = 11657. State = [[-0.08206176  0.15683413]]. Action = [[0.06266857 0.03402104 0.         0.29235363]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 11657 is [True, False, False, False, False, True]
Current timestep = 11658. State = [[-0.08145775  0.15402809]]. Action = [[-0.0360354  -0.07933164  0.         -0.5485678 ]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 11658 is [True, False, False, False, False, True]
Current timestep = 11659. State = [[-0.08418033  0.15073954]]. Action = [[-0.05451003 -0.0285548   0.          0.09866548]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 11659 is [True, False, False, False, False, True]
State prediction error at timestep 11659 is 0.012
Human Feedback received at timestep 11659 of None
Current timestep = 11660. State = [[-0.08171117  0.15289699]]. Action = [[ 0.07670518  0.06079831  0.         -0.6479642 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 11660 is [True, False, False, False, False, True]
State prediction error at timestep 11660 is 0.012
Human Feedback received at timestep 11660 of None
Current timestep = 11661. State = [[-0.0758593   0.15609728]]. Action = [[ 0.0677202   0.03168011  0.         -0.7672398 ]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 11661 is [True, False, False, False, False, True]
Current timestep = 11662. State = [[-0.06969452  0.1612046 ]]. Action = [[ 0.07625761  0.08700467  0.         -0.3294555 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 11662 is [True, False, False, False, False, True]
Current timestep = 11663. State = [[-0.06901915  0.16334546]]. Action = [[-0.05070536 -0.01278499  0.         -0.41372424]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 11663 is [True, False, False, False, False, True]
Current timestep = 11664. State = [[-0.06745304  0.16080475]]. Action = [[ 0.04336307 -0.0554973   0.         -0.339917  ]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 11664 is [True, False, False, False, False, True]
Current timestep = 11665. State = [[-0.06823362  0.15612498]]. Action = [[-0.06377894 -0.07026435  0.         -0.843355  ]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 11665 is [True, False, False, False, False, True]
State prediction error at timestep 11665 is 0.012
Human Feedback received at timestep 11665 of None
Current timestep = 11666. State = [[-0.07017137  0.1513487 ]]. Action = [[-0.03641979 -0.0646002   0.          0.65214515]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 11666 is [True, False, False, False, False, True]
Current timestep = 11667. State = [[-0.07015989  0.14558285]]. Action = [[-0.00920682 -0.08208337  0.         -0.45833266]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 11667 is [True, False, False, False, False, True]
State prediction error at timestep 11667 is 0.012
Human Feedback received at timestep 11667 of None
Current timestep = 11668. State = [[-0.06696282  0.1409664 ]]. Action = [[ 0.04223003 -0.03755092  0.         -0.03945184]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 11668 is [True, False, False, False, False, True]
Current timestep = 11669. State = [[-0.06209343  0.1397324 ]]. Action = [[0.05447481 0.01825235 0.         0.820537  ]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 11669 is [True, False, False, False, False, True]
Current timestep = 11670. State = [[-0.05888927  0.14041731]]. Action = [[0.01974175 0.02842797 0.         0.12832463]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 11670 is [True, False, False, False, False, True]
Current timestep = 11671. State = [[-0.05790282  0.14520434]]. Action = [[0.00123061 0.09968267 0.         0.81762815]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 11671 is [True, False, False, False, False, True]
Current timestep = 11672. State = [[-0.06075218  0.14578274]]. Action = [[-0.06441525 -0.03965032  0.          0.07151759]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 11672 is [True, False, False, False, False, True]
Current timestep = 11673. State = [[-0.05824701  0.14270712]]. Action = [[ 0.0883153  -0.03626563  0.         -0.38735616]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 11673 is [True, False, False, False, False, True]
Current timestep = 11674. State = [[-0.05183066  0.1449997 ]]. Action = [[ 0.08200648  0.08282068  0.         -0.4688164 ]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 11674 is [True, False, False, False, False, True]
Current timestep = 11675. State = [[-0.0479162   0.15049167]]. Action = [[0.03629918 0.07781287 0.         0.09897864]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 11675 is [True, False, False, False, False, True]
Current timestep = 11676. State = [[-0.04646061  0.1496962 ]]. Action = [[ 0.00586648 -0.0592373   0.          0.27524853]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 11676 is [False, True, False, False, False, True]
Current timestep = 11677. State = [[-0.04141912  0.15077485]]. Action = [[ 0.09405909  0.05848657  0.         -0.8149042 ]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 11677 is [False, True, False, False, False, True]
Current timestep = 11678. State = [[-0.03578002  0.15031886]]. Action = [[ 0.05220006 -0.03455116  0.          0.58225954]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 11678 is [False, True, False, False, False, True]
State prediction error at timestep 11678 is 0.012
Human Feedback received at timestep 11678 of None
Current timestep = 11679. State = [[-0.03517236  0.1527353 ]]. Action = [[-0.03859789  0.06965757  0.          0.49493217]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 11679 is [False, True, False, False, False, True]
Current timestep = 11680. State = [[-0.03231084  0.15118752]]. Action = [[ 0.05737204 -0.07721652  0.          0.19239295]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 11680 is [False, True, False, False, False, True]
Current timestep = 11681. State = [[-0.03346416  0.14646098]]. Action = [[-0.09494488 -0.06212125  0.         -0.97818244]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 11681 is [False, True, False, False, False, True]
State prediction error at timestep 11681 is 0.012
Human Feedback received at timestep 11681 of None
Current timestep = 11682. State = [[-0.03673875  0.14413697]]. Action = [[-0.05481466 -0.02222299  0.         -0.79455733]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 11682 is [False, True, False, False, False, True]
State prediction error at timestep 11682 is 0.012
Human Feedback received at timestep 11682 of None
Current timestep = 11683. State = [[-0.03914753  0.1406633 ]]. Action = [[-0.04937372 -0.06928027  0.          0.59108627]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 11683 is [False, True, False, False, False, True]
Current timestep = 11684. State = [[-0.03618529  0.14189143]]. Action = [[0.07718606 0.0627126  0.         0.7908151 ]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 11684 is [False, True, False, False, False, True]
Current timestep = 11685. State = [[-0.03463183  0.14492056]]. Action = [[-0.02899788  0.02309326  0.         -0.10796952]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 11685 is [False, True, False, False, False, True]
State prediction error at timestep 11685 is 0.012
Human Feedback received at timestep 11685 of None
Current timestep = 11686. State = [[-0.03306323  0.14178176]]. Action = [[ 0.02590107 -0.08567661  0.          0.5457765 ]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 11686 is [False, True, False, False, False, True]
Current timestep = 11687. State = [[-0.0301513   0.14339165]]. Action = [[ 0.02808782  0.08355392  0.         -0.22872496]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 11687 is [False, True, False, False, False, True]
State prediction error at timestep 11687 is 0.012
Human Feedback received at timestep 11687 of None
Current timestep = 11688. State = [[-0.02706181  0.14076132]]. Action = [[ 0.03696006 -0.09688204  0.         -0.05284077]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 11688 is [False, True, False, False, False, True]
Current timestep = 11689. State = [[-0.0287003   0.13965848]]. Action = [[-0.07321129  0.03639593  0.         -0.9215491 ]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 11689 is [False, True, False, False, False, True]
Current timestep = 11690. State = [[-0.03122249  0.144615  ]]. Action = [[-0.02198936  0.076128    0.         -0.6277799 ]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 11690 is [False, True, False, False, False, True]
Current timestep = 11691. State = [[-0.02952581  0.14651425]]. Action = [[ 0.05070754 -0.01471843  0.          0.6083683 ]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 11691 is [False, True, False, False, False, True]
Current timestep = 11692. State = [[-0.03270457  0.14790763]]. Action = [[-0.09741541  0.02517091  0.         -0.22291708]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 11692 is [False, True, False, False, False, True]
State prediction error at timestep 11692 is 0.012
Human Feedback received at timestep 11692 of None
Current timestep = 11693. State = [[-0.0362424   0.14854762]]. Action = [[-0.01577505 -0.01696965  0.          0.72120214]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 11693 is [False, True, False, False, False, True]
Current timestep = 11694. State = [[-0.03976319  0.14453854]]. Action = [[-0.05882978 -0.08658969  0.         -0.42286468]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 11694 is [False, True, False, False, False, True]
Current timestep = 11695. State = [[-0.03767549  0.14267181]]. Action = [[0.08962908 0.01046165 0.         0.6451136 ]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 11695 is [False, True, False, False, False, True]
Current timestep = 11696. State = [[-0.031899    0.14418605]]. Action = [[0.07513072 0.03502382 0.         0.22636354]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 11696 is [False, True, False, False, False, True]
Current timestep = 11697. State = [[-0.03368472  0.14610192]]. Action = [[-0.0903977   0.02094402  0.         -0.81373245]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 11697 is [False, True, False, False, False, True]
State prediction error at timestep 11697 is 0.012
Human Feedback received at timestep 11697 of None
Current timestep = 11698. State = [[-0.04019938  0.1465047 ]]. Action = [[-0.08208165 -0.01055671  0.         -0.5228793 ]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 11698 is [False, True, False, False, False, True]
Current timestep = 11699. State = [[-0.04286065  0.15022498]]. Action = [[ 0.00783873  0.07226563  0.         -0.07214093]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 11699 is [False, True, False, False, False, True]
State prediction error at timestep 11699 is 0.012
Human Feedback received at timestep 11699 of None
Current timestep = 11700. State = [[-0.04636881  0.15106674]]. Action = [[-0.0589026  -0.03665423  0.         -0.50231034]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 11700 is [False, True, False, False, False, True]
Current timestep = 11701. State = [[-0.04814947  0.153191  ]]. Action = [[0.01309264 0.04938606 0.         0.2868042 ]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 11701 is [False, True, False, False, False, True]
Current timestep = 11702. State = [[-0.04840891  0.1556312 ]]. Action = [[0.01098046 0.01221476 0.         0.28929353]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 11702 is [False, True, False, False, False, True]
Current timestep = 11703. State = [[-0.04812355  0.15835659]]. Action = [[ 0.02210591  0.03949995  0.         -0.7410806 ]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 11703 is [False, True, False, False, False, True]
Current timestep = 11704. State = [[-0.04799901  0.15778835]]. Action = [[ 0.01058578 -0.03996756  0.         -0.17253864]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 11704 is [False, True, False, False, False, True]
Current timestep = 11705. State = [[-0.05199981  0.1526135 ]]. Action = [[-0.08474921 -0.09004154  0.          0.6769452 ]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 11705 is [False, True, False, False, False, True]
Current timestep = 11706. State = [[-0.05394692  0.1535366 ]]. Action = [[ 0.01843899  0.06924599  0.         -0.0025785 ]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 11706 is [True, False, False, False, False, True]
Current timestep = 11707. State = [[-0.05018508  0.1562499 ]]. Action = [[0.08197961 0.01889356 0.         0.01742101]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 11707 is [True, False, False, False, False, True]
Current timestep = 11708. State = [[-0.04974802  0.15249078]]. Action = [[-0.03851449 -0.08604619  0.          0.62405264]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 11708 is [True, False, False, False, False, True]
Current timestep = 11709. State = [[-0.05018915  0.1527719 ]]. Action = [[0.01542561 0.0622902  0.         0.57446337]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 11709 is [False, True, False, False, False, True]
Current timestep = 11710. State = [[-0.05010106  0.15279938]]. Action = [[ 0.0037479  -0.02512678  0.         -0.85274434]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 11710 is [True, False, False, False, False, True]
State prediction error at timestep 11710 is 0.012
Human Feedback received at timestep 11710 of None
Current timestep = 11711. State = [[-0.04644807  0.14787593]]. Action = [[ 0.07621843 -0.07536615  0.         -0.10002524]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 11711 is [True, False, False, False, False, True]
Current timestep = 11712. State = [[-0.03961572  0.14003016]]. Action = [[ 0.09346371 -0.08880251  0.         -0.36145163]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 11712 is [False, True, False, False, False, True]
Current timestep = 11713. State = [[-0.03322917  0.13813496]]. Action = [[0.06751031 0.05416193 0.         0.82287526]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 11713 is [False, True, False, False, False, True]
Current timestep = 11714. State = [[-0.03362751  0.13394077]]. Action = [[-0.07633287 -0.08370028  0.         -0.21625131]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 11714 is [False, True, False, False, False, True]
Current timestep = 11715. State = [[-0.03148366  0.12891829]]. Action = [[ 0.07940551 -0.02089387  0.          0.2523893 ]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 11715 is [False, True, False, False, False, True]
Current timestep = 11716. State = [[-0.02902481  0.12571906]]. Action = [[-0.0051     -0.01331417  0.         -0.48030508]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 11716 is [False, True, False, False, False, True]
Current timestep = 11717. State = [[-0.10935874  0.20168519]]. Action = [[ 0.06989596 -0.05333811  0.         -0.8466209 ]]. Reward = [100.]
Curr episode timestep = 624
Scene graph at timestep 11717 is [False, True, False, False, False, True]
Current timestep = 11718. State = [[-0.10976756  0.20123094]]. Action = [[-0.07163207 -0.02852539  0.          0.24601161]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 11718 is [True, False, False, False, False, True]
State prediction error at timestep 11718 is 0.012
Human Feedback received at timestep 11718 of None
Current timestep = 11719. State = [[-0.11044124  0.20495577]]. Action = [[ 0.02716462  0.05901673  0.         -0.7849703 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 11719 is [True, False, False, False, False, True]
State prediction error at timestep 11719 is 0.012
Human Feedback received at timestep 11719 of None
Current timestep = 11720. State = [[-0.10920287  0.20945431]]. Action = [[0.01551254 0.02823693 0.         0.3129406 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 11720 is [True, False, False, False, False, True]
Current timestep = 11721. State = [[-0.11085066  0.21312006]]. Action = [[-0.04105097  0.02661184  0.          0.7414329 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 11721 is [True, False, False, False, False, True]
State prediction error at timestep 11721 is 0.012
Human Feedback received at timestep 11721 of None
Current timestep = 11722. State = [[-0.10813678  0.21769705]]. Action = [[0.08555187 0.05042779 0.         0.6092471 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 11722 is [True, False, False, False, False, True]
State prediction error at timestep 11722 is 0.012
Human Feedback received at timestep 11722 of None
Current timestep = 11723. State = [[-0.10316359  0.21704488]]. Action = [[ 0.0508549  -0.06173119  0.          0.0384711 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 11723 is [True, False, False, False, False, True]
Current timestep = 11724. State = [[-0.09914425  0.21812317]]. Action = [[0.03576852 0.04303104 0.         0.35477316]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 11724 is [True, False, False, False, False, True]
Current timestep = 11725. State = [[-0.09455148  0.22210391]]. Action = [[0.05885617 0.04965232 0.         0.18119824]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 11725 is [True, False, False, False, False, True]
State prediction error at timestep 11725 is 0.012
Human Feedback received at timestep 11725 of None
Current timestep = 11726. State = [[-0.09528342  0.22597039]]. Action = [[-0.06591807  0.03648012  0.         -0.21365404]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 11726 is [True, False, False, False, False, True]
Current timestep = 11727. State = [[-0.09500486  0.22443992]]. Action = [[ 0.02574234 -0.07298844  0.         -0.25911832]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 11727 is [True, False, False, False, False, True]
Current timestep = 11728. State = [[-0.09490082  0.22132826]]. Action = [[-0.0343041  -0.03900313  0.         -0.05079085]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 11728 is [True, False, False, False, False, True]
Current timestep = 11729. State = [[-0.09103459  0.22067162]]. Action = [[ 0.07739232  0.0012119   0.         -0.34486723]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11729 is [True, False, False, False, False, True]
Current timestep = 11730. State = [[-0.0879017   0.22243048]]. Action = [[-0.00226635  0.03270841  0.          0.48540556]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 11730 is [True, False, False, False, False, True]
Current timestep = 11731. State = [[-0.08388132  0.22743563]]. Action = [[ 0.06534802  0.08036966  0.         -0.4799614 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 11731 is [True, False, False, False, False, True]
State prediction error at timestep 11731 is 0.012
Human Feedback received at timestep 11731 of None
Current timestep = 11732. State = [[-0.07861741  0.23328432]]. Action = [[ 0.06293737  0.07306658  0.         -0.93210775]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 11732 is [True, False, False, False, False, True]
State prediction error at timestep 11732 is 0.012
Human Feedback received at timestep 11732 of None
Current timestep = 11733. State = [[-0.07885669  0.2393569 ]]. Action = [[-0.05004781  0.0731524   0.         -0.37589633]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 11733 is [True, False, False, False, False, True]
Current timestep = 11734. State = [[-0.0768392  0.2411206]]. Action = [[ 0.06221739 -0.02399622  0.          0.8775171 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 11734 is [True, False, False, False, False, True]
Current timestep = 11735. State = [[-0.07775688  0.23863864]]. Action = [[-0.07417502 -0.06020784  0.         -0.9031007 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 11735 is [True, False, False, False, False, True]
Current timestep = 11736. State = [[-0.07542157  0.23396498]]. Action = [[ 0.0688828  -0.07792848  0.          0.9789947 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 11736 is [True, False, False, False, False, True]
Current timestep = 11737. State = [[-0.07006985  0.23605983]]. Action = [[0.05278296 0.0870356  0.         0.17054355]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 11737 is [True, False, False, False, False, True]
State prediction error at timestep 11737 is 0.012
Human Feedback received at timestep 11737 of None
Current timestep = 11738. State = [[-0.06567367  0.24179311]]. Action = [[0.04965282 0.07081536 0.         0.95034766]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 11738 is [True, False, False, False, False, True]
Current timestep = 11739. State = [[-0.06695827  0.24857654]]. Action = [[-0.06184198  0.08888     0.          0.40038645]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 11739 is [True, False, False, False, False, True]
State prediction error at timestep 11739 is 0.012
Human Feedback received at timestep 11739 of None
Current timestep = 11740. State = [[-0.0687762   0.25693238]]. Action = [[-5.5755675e-04  9.6864201e-02  0.0000000e+00  9.3864489e-01]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 11740 is [True, False, False, False, False, True]
State prediction error at timestep 11740 is 0.012
Human Feedback received at timestep 11740 of None
Current timestep = 11741. State = [[-0.07327642  0.2640244 ]]. Action = [[-0.08054049  0.05552531  0.         -0.43144768]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 11741 is [True, False, False, False, False, True]
Current timestep = 11742. State = [[-0.07259422  0.26805577]]. Action = [[ 0.07419867  0.01079327  0.         -0.11828601]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 11742 is [True, False, False, False, False, True]
Current timestep = 11743. State = [[-0.07358501  0.272107  ]]. Action = [[-0.05191294  0.03916907  0.          0.39792657]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 11743 is [True, False, False, False, False, True]
Current timestep = 11744. State = [[-0.07223286  0.2720829 ]]. Action = [[ 0.05875409 -0.06224768  0.          0.9485649 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 11744 is [True, False, False, False, False, True]
Current timestep = 11745. State = [[-0.06689596  0.27552179]]. Action = [[0.07789182 0.08115221 0.         0.0323565 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 11745 is [True, False, False, False, False, True]
Current timestep = 11746. State = [[-0.06503028  0.2822877 ]]. Action = [[-0.0048937   0.07569196  0.          0.06431735]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 11746 is [True, False, False, False, False, True]
Current timestep = 11747. State = [[-0.06515714  0.28494462]]. Action = [[-0.00346465 -0.01511769  0.         -0.2180655 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 11747 is [True, False, False, False, False, True]
Current timestep = 11748. State = [[-0.06474825  0.29034954]]. Action = [[0.00489066 0.09063407 0.         0.5838467 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 11748 is [True, False, False, False, False, True]
Current timestep = 11749. State = [[-0.05987852  0.29060188]]. Action = [[ 0.09242635 -0.06835604  0.          0.26693273]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 11749 is [True, False, False, False, False, True]
Current timestep = 11750. State = [[-0.06023158  0.29149383]]. Action = [[-0.0789483   0.03937867  0.          0.4753151 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 11750 is [True, False, False, False, False, True]
State prediction error at timestep 11750 is 0.012
Human Feedback received at timestep 11750 of None
Current timestep = 11751. State = [[-0.06094117  0.2980423 ]]. Action = [[0.02063354 0.0854615  0.         0.11588204]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 11751 is [True, False, False, False, False, True]
Current timestep = 11752. State = [[-0.06375187  0.30207342]]. Action = [[-0.07746205 -0.00488864  0.          0.7236171 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 11752 is [True, False, False, False, False, True]
Current timestep = 11753. State = [[-0.06897176  0.3031146 ]]. Action = [[-0.073339   -0.02296752  0.         -0.15770376]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 11753 is [True, False, False, False, False, True]
State prediction error at timestep 11753 is 0.012
Human Feedback received at timestep 11753 of None
Current timestep = 11754. State = [[-0.0673719  0.3064972]]. Action = [[ 0.08668726  0.05238349  0.         -0.50293857]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 11754 is [True, False, False, False, False, True]
Current timestep = 11755. State = [[-0.06382054  0.30585632]]. Action = [[ 0.01022694 -0.076092    0.          0.6559777 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 11755 is [True, False, False, False, False, True]
Current timestep = 11756. State = [[-0.06609993  0.30916104]]. Action = [[-0.07606062  0.08000243  0.         -0.40631843]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 11756 is [True, False, False, False, False, True]
Current timestep = 11757. State = [[-0.07133017  0.31388742]]. Action = [[-0.07250849  0.00979154  0.         -0.6641515 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 11757 is [True, False, False, False, False, True]
State prediction error at timestep 11757 is 0.012
Human Feedback received at timestep 11757 of None
Current timestep = 11758. State = [[-0.07455169  0.3211079 ]]. Action = [[-0.01921384  0.09433413  0.          0.10361683]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 11758 is [True, False, False, False, False, True]
State prediction error at timestep 11758 is 0.012
Human Feedback received at timestep 11758 of None
Current timestep = 11759. State = [[-0.07257655  0.32982576]]. Action = [[ 0.07408757  0.08710491  0.         -0.15909076]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 11759 is [True, False, False, False, False, True]
Current timestep = 11760. State = [[-0.07510516  0.336968  ]]. Action = [[-0.07527675  0.05626663  0.          0.64421797]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 11760 is [True, False, False, False, False, True]
State prediction error at timestep 11760 is 0.012
Human Feedback received at timestep 11760 of None
Current timestep = 11761. State = [[-0.07501338  0.34408563]]. Action = [[0.0780318  0.08166819 0.         0.3784411 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 11761 is [True, False, False, False, False, True]
Current timestep = 11762. State = [[-0.07484803  0.34382793]]. Action = [[-0.03683744 -0.09803824  0.         -0.5620931 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 11762 is [True, False, False, False, False, True]
State prediction error at timestep 11762 is 0.012
Human Feedback received at timestep 11762 of None
Current timestep = 11763. State = [[-0.07630057  0.34246182]]. Action = [[0.         0.         0.         0.58615065]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 11763 is [True, False, False, False, False, True]
Current timestep = 11764. State = [[-0.08164988  0.34235004]]. Action = [[-0.09874647 -0.02069288  0.          0.13721597]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 11764 is [True, False, False, False, False, True]
Current timestep = 11765. State = [[-0.08592465  0.34009904]]. Action = [[-0.02525105 -0.06047773  0.          0.25072408]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 11765 is [True, False, False, False, False, True]
Current timestep = 11766. State = [[-0.0869642   0.33929867]]. Action = [[ 0.          0.          0.         -0.29241598]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 11766 is [True, False, False, False, False, True]
Current timestep = 11767. State = [[-0.08733681  0.3397066 ]]. Action = [[0.        0.        0.        0.5983919]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 11767 is [True, False, False, False, False, True]
State prediction error at timestep 11767 is 0.012
Human Feedback received at timestep 11767 of None
Current timestep = 11768. State = [[-0.08440021  0.33974254]]. Action = [[ 6.8433054e-02  2.4738163e-04  0.0000000e+00 -6.9329047e-01]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 11768 is [True, False, False, False, False, True]
Current timestep = 11769. State = [[-0.07957242  0.33441296]]. Action = [[ 0.06136987 -0.09503894  0.          0.1850456 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 11769 is [True, False, False, False, False, True]
Current timestep = 11770. State = [[-0.08067566  0.3270559 ]]. Action = [[-0.08076878 -0.08309633  0.          0.14262092]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 11770 is [True, False, False, False, False, True]
Current timestep = 11771. State = [[-0.08061485  0.32754412]]. Action = [[0.05276043 0.09103122 0.         0.47274375]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 11771 is [True, False, False, False, False, True]
Current timestep = 11772. State = [[-0.07825365  0.3332921 ]]. Action = [[0.01766647 0.08714128 0.         0.5184294 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 11772 is [True, False, False, False, False, True]
Current timestep = 11773. State = [[-0.07585055  0.33764485]]. Action = [[0.03929553 0.04909887 0.         0.6363485 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 11773 is [True, False, False, False, False, True]
State prediction error at timestep 11773 is 0.012
Human Feedback received at timestep 11773 of None
Current timestep = 11774. State = [[-0.07475881  0.3387375 ]]. Action = [[ 0.         0.         0.        -0.7514542]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 11774 is [True, False, False, False, False, True]
Current timestep = 11775. State = [[-0.07722444  0.3349057 ]]. Action = [[-0.06544563 -0.0859796   0.          0.8130784 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 11775 is [True, False, False, False, False, True]
Current timestep = 11776. State = [[-0.07462292  0.33410102]]. Action = [[ 0.09882226  0.04482018  0.         -0.5381656 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 11776 is [True, False, False, False, False, True]
Current timestep = 11777. State = [[-0.0697844  0.3391603]]. Action = [[ 0.03481597  0.08395941  0.         -0.18869185]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 11777 is [True, False, False, False, False, True]
Current timestep = 11778. State = [[-0.06932312  0.33834913]]. Action = [[-0.04186009 -0.082311    0.          0.29524648]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 11778 is [True, False, False, False, False, True]
Current timestep = 11779. State = [[-0.07381736  0.3392478 ]]. Action = [[-0.08843832  0.04736581  0.         -0.4980359 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 11779 is [True, False, False, False, False, True]
Current timestep = 11780. State = [[-0.07476556  0.33864847]]. Action = [[ 0.02367047 -0.05840616  0.          0.34378386]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 11780 is [True, False, False, False, False, True]
Current timestep = 11781. State = [[-0.07143256  0.33739704]]. Action = [[ 0.04719026 -0.00551646  0.         -0.9192764 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 11781 is [True, False, False, False, False, True]
State prediction error at timestep 11781 is 0.012
Human Feedback received at timestep 11781 of None
Current timestep = 11782. State = [[-0.06595508  0.33855715]]. Action = [[0.07886327 0.02941773 0.         0.62329054]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 11782 is [True, False, False, False, False, True]
State prediction error at timestep 11782 is 0.012
Human Feedback received at timestep 11782 of None
Current timestep = 11783. State = [[-0.06734696  0.342575  ]]. Action = [[-0.07937692  0.06850903  0.         -0.92031604]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 11783 is [True, False, False, False, False, True]
State prediction error at timestep 11783 is 0.012
Human Feedback received at timestep 11783 of None
Current timestep = 11784. State = [[-0.06962287  0.34498   ]]. Action = [[0.         0.         0.         0.28959012]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 11784 is [True, False, False, False, False, True]
Current timestep = 11785. State = [[-0.07265144  0.3460031 ]]. Action = [[-0.05689166  0.00616354  0.         -0.7030453 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 11785 is [True, False, False, False, False, True]
State prediction error at timestep 11785 is 0.012
Human Feedback received at timestep 11785 of None
Current timestep = 11786. State = [[-0.07191874  0.3469234 ]]. Action = [[ 0.05229522  0.00111645  0.         -0.46556967]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 11786 is [True, False, False, False, False, True]
State prediction error at timestep 11786 is 0.012
Human Feedback received at timestep 11786 of None
Current timestep = 11787. State = [[-0.06754756  0.34447458]]. Action = [[ 0.06231946 -0.05450605  0.         -0.68753135]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 11787 is [True, False, False, False, False, True]
State prediction error at timestep 11787 is 0.012
Human Feedback received at timestep 11787 of None
Current timestep = 11788. State = [[-0.06120323  0.3438781 ]]. Action = [[ 0.08797426  0.02776652  0.         -0.95734215]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 11788 is [True, False, False, False, False, True]
Current timestep = 11789. State = [[-0.05811631  0.3397717 ]]. Action = [[-0.01155429 -0.091682    0.         -0.82267296]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 11789 is [True, False, False, False, False, True]
Current timestep = 11790. State = [[-0.05584823  0.3341236 ]]. Action = [[ 0.0293817  -0.04754911  0.         -0.09197938]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 11790 is [True, False, False, False, False, True]
State prediction error at timestep 11790 is 0.012
Human Feedback received at timestep 11790 of None
Current timestep = 11791. State = [[-0.04976003  0.32988212]]. Action = [[ 0.08670489 -0.02903674  0.          0.10942876]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 11791 is [True, False, False, False, False, True]
State prediction error at timestep 11791 is 0.012
Human Feedback received at timestep 11791 of None
Current timestep = 11792. State = [[-0.04325736  0.32398894]]. Action = [[ 0.05789968 -0.06296213  0.         -0.02670884]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 11792 is [False, True, False, False, False, True]
State prediction error at timestep 11792 is 0.012
Human Feedback received at timestep 11792 of None
Current timestep = 11793. State = [[-0.03615448  0.31720272]]. Action = [[ 0.07731143 -0.05586464  0.          0.5258336 ]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 11793 is [False, True, False, False, False, True]
Current timestep = 11794. State = [[-0.03566242  0.31033894]]. Action = [[-0.08864285 -0.06996155  0.         -0.11992323]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 11794 is [False, True, False, False, False, True]
Current timestep = 11795. State = [[-0.03357114  0.30770853]]. Action = [[0.07215919 0.03760316 0.         0.3980732 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 11795 is [False, True, False, False, False, True]
Current timestep = 11796. State = [[-0.02963299  0.3076115 ]]. Action = [[0.01583026 0.01761849 0.         0.8797467 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 11796 is [False, True, False, False, False, True]
Current timestep = 11797. State = [[-0.02917216  0.30673957]]. Action = [[-0.0273541  -0.00230137  0.          0.37639618]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 11797 is [False, True, False, False, False, True]
Current timestep = 11798. State = [[-0.02556533  0.3019917 ]]. Action = [[ 0.06257213 -0.07674009  0.          0.9863944 ]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 11798 is [False, True, False, False, False, True]
Current timestep = 11799. State = [[-0.01950894  0.2939611 ]]. Action = [[ 0.05726749 -0.09346808  0.          0.55341995]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 11799 is [False, True, False, False, False, True]
Current timestep = 11800. State = [[-0.01133779  0.28539485]]. Action = [[ 0.09579045 -0.08173124  0.          0.3916068 ]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 11800 is [False, True, False, False, False, True]
Current timestep = 11801. State = [[-0.01109058  0.2827292 ]]. Action = [[-0.09580757  0.03679503  0.          0.28300476]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 11801 is [False, True, False, False, False, True]
State prediction error at timestep 11801 is 0.012
Human Feedback received at timestep 11801 of None
Current timestep = 11802. State = [[-0.00999986  0.27908465]]. Action = [[ 0.04106734 -0.07140865  0.         -0.4430623 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 11802 is [False, True, False, False, False, True]
Current timestep = 11803. State = [[-0.00843987  0.27603126]]. Action = [[-0.01797754  0.0016842   0.          0.7301786 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 11803 is [False, True, False, False, False, True]
Current timestep = 11804. State = [[-0.00816621  0.27721402]]. Action = [[-0.00527509  0.0437245   0.          0.07805729]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 11804 is [False, True, False, False, False, True]
Current timestep = 11805. State = [[-0.00652147  0.2765396 ]]. Action = [[ 0.02710671 -0.02456906  0.          0.4670204 ]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 11805 is [False, True, False, False, False, True]
Current timestep = 11806. State = [[-0.00363861  0.27720186]]. Action = [[ 0.03824558  0.04255339  0.         -0.9862353 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 11806 is [False, True, False, False, False, True]
State prediction error at timestep 11806 is 0.012
Human Feedback received at timestep 11806 of None
Current timestep = 11807. State = [[-0.00184053  0.28015375]]. Action = [[0.01916528 0.05202616 0.         0.7459079 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 11807 is [False, True, False, False, False, True]
Current timestep = 11808. State = [[-0.00052325  0.2763092 ]]. Action = [[ 0.01589197 -0.09881567  0.          0.7263931 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 11808 is [False, True, False, False, False, True]
Current timestep = 11809. State = [[0.00180105 0.27037632]]. Action = [[ 0.02664245 -0.05192938  0.         -0.6517174 ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 11809 is [False, True, False, False, False, True]
State prediction error at timestep 11809 is 0.012
Human Feedback received at timestep 11809 of None
Current timestep = 11810. State = [[0.00092765 0.26991567]]. Action = [[-0.04666327  0.03880616  0.          0.56005454]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 11810 is [False, True, False, False, False, True]
State prediction error at timestep 11810 is 0.012
Human Feedback received at timestep 11810 of None
Current timestep = 11811. State = [[0.00187563 0.26612636]]. Action = [[ 0.03378012 -0.08910736  0.          0.12362373]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 11811 is [False, True, False, False, False, True]
State prediction error at timestep 11811 is 0.012
Human Feedback received at timestep 11811 of None
Current timestep = 11812. State = [[0.00416964 0.26312268]]. Action = [[0.01371729 0.00422251 0.         0.60734737]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 11812 is [False, True, False, False, False, True]
State prediction error at timestep 11812 is 0.012
Human Feedback received at timestep 11812 of None
Current timestep = 11813. State = [[0.00839385 0.25754124]]. Action = [[ 0.06347749 -0.09306408  0.          0.38666892]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 11813 is [False, True, False, False, False, True]
State prediction error at timestep 11813 is 0.012
Human Feedback received at timestep 11813 of None
Current timestep = 11814. State = [[0.00845056 0.25500146]]. Action = [[-0.05646761  0.02825341  0.          0.62667644]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 11814 is [False, True, False, False, False, True]
Current timestep = 11815. State = [[0.00525834 0.25894424]]. Action = [[-0.04760078  0.07637847  0.         -0.9627075 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 11815 is [False, True, False, False, False, True]
State prediction error at timestep 11815 is 0.012
Human Feedback received at timestep 11815 of None
Current timestep = 11816. State = [[0.00030121 0.25773785]]. Action = [[-0.08480816 -0.07594305  0.         -0.06472212]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 11816 is [False, True, False, False, False, True]
Current timestep = 11817. State = [[-0.00533021  0.26107278]]. Action = [[-0.07169896  0.09665325  0.         -0.2699715 ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 11817 is [False, True, False, False, False, True]
Current timestep = 11818. State = [[-0.00930085  0.2678501 ]]. Action = [[-0.02360485  0.06147362  0.         -0.03589004]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 11818 is [False, True, False, False, False, True]
Current timestep = 11819. State = [[-0.01547247  0.27540705]]. Action = [[-0.08341678  0.08519926  0.         -0.7724582 ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 11819 is [False, True, False, False, False, True]
Current timestep = 11820. State = [[-0.02166461  0.28185922]]. Action = [[-0.04249414  0.04039492  0.         -0.54432917]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 11820 is [False, True, False, False, False, True]
Current timestep = 11821. State = [[-0.02751844  0.2863627 ]]. Action = [[-0.05382081  0.02277537  0.          0.86808753]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 11821 is [False, True, False, False, False, True]
Current timestep = 11822. State = [[-0.02747647  0.2900745 ]]. Action = [[0.0824075  0.02692644 0.         0.24323869]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 11822 is [False, True, False, False, False, True]
Current timestep = 11823. State = [[-0.02821087  0.29519543]]. Action = [[-0.01490527  0.06325842  0.         -0.31520176]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 11823 is [False, True, False, False, False, True]
Current timestep = 11824. State = [[-0.03003143  0.30209306]]. Action = [[0.01287029 0.07944424 0.         0.2283206 ]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 11824 is [False, True, False, False, False, True]
State prediction error at timestep 11824 is 0.012
Human Feedback received at timestep 11824 of None
Current timestep = 11825. State = [[-0.02916177  0.30305386]]. Action = [[ 0.05194984 -0.04622377  0.         -0.62097836]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 11825 is [False, True, False, False, False, True]
Current timestep = 11826. State = [[-0.02472603  0.30284208]]. Action = [[0.08875562 0.01450833 0.         0.74452186]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 11826 is [False, True, False, False, False, True]
Current timestep = 11827. State = [[-0.02406954  0.30011246]]. Action = [[-0.03505148 -0.06774296  0.          0.5335095 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 11827 is [False, True, False, False, False, True]
State prediction error at timestep 11827 is 0.012
Human Feedback received at timestep 11827 of None
Current timestep = 11828. State = [[-0.02103195  0.2958205 ]]. Action = [[ 0.08689875 -0.03884353  0.         -0.35750204]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 11828 is [False, True, False, False, False, True]
Current timestep = 11829. State = [[-0.02214528  0.29219657]]. Action = [[-0.08784076 -0.04021121  0.          0.8142215 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 11829 is [False, True, False, False, False, True]
Current timestep = 11830. State = [[-0.02284063  0.2906766 ]]. Action = [[0.02918566 0.00662333 0.         0.01317203]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 11830 is [False, True, False, False, False, True]
Current timestep = 11831. State = [[-0.01771005  0.2929798 ]]. Action = [[0.0978035  0.06887966 0.         0.8270395 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 11831 is [False, True, False, False, False, True]
Current timestep = 11832. State = [[-0.01549273  0.29484853]]. Action = [[-0.0065125   0.0227882   0.          0.33685553]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 11832 is [False, True, False, False, False, True]
Current timestep = 11833. State = [[-0.01774787  0.2926463 ]]. Action = [[-0.04752537 -0.04692884  0.          0.89314353]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 11833 is [False, True, False, False, False, True]
Current timestep = 11834. State = [[-0.02118541  0.2919175 ]]. Action = [[-0.05257757  0.01398005  0.         -0.67257035]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 11834 is [False, True, False, False, False, True]
Current timestep = 11835. State = [[-0.02580987  0.29229912]]. Action = [[-0.0697937  -0.00627106  0.         -0.2435925 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 11835 is [False, True, False, False, False, True]
Current timestep = 11836. State = [[-0.02404347  0.29067057]]. Action = [[ 0.07815029 -0.03670552  0.          0.10600257]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 11836 is [False, True, False, False, False, True]
Current timestep = 11837. State = [[-0.02555108  0.28967756]]. Action = [[-0.08468401 -0.00517625  0.         -0.5804461 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 11837 is [False, True, False, False, False, True]
Current timestep = 11838. State = [[-0.02625649  0.28550276]]. Action = [[ 0.02125671 -0.09139379  0.          0.26884377]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 11838 is [False, True, False, False, False, True]
Current timestep = 11839. State = [[-0.0218223   0.28312778]]. Action = [[ 0.07406051  0.00971714  0.         -0.39874256]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 11839 is [False, True, False, False, False, True]
Current timestep = 11840. State = [[-0.01743829  0.2792554 ]]. Action = [[ 0.03867703 -0.0651159   0.          0.20879996]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 11840 is [False, True, False, False, False, True]
Current timestep = 11841. State = [[-0.01128788  0.2769504 ]]. Action = [[0.09051884 0.01760043 0.         0.0042994 ]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 11841 is [False, True, False, False, False, True]
State prediction error at timestep 11841 is 0.012
Human Feedback received at timestep 11841 of None
Current timestep = 11842. State = [[-0.0114014   0.27960274]]. Action = [[-0.06546144  0.07421514  0.         -0.28571028]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 11842 is [False, True, False, False, False, True]
Current timestep = 11843. State = [[-0.01720502  0.28340918]]. Action = [[-0.08758293  0.04271808  0.         -0.13395369]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 11843 is [False, True, False, False, False, True]
Current timestep = 11844. State = [[-0.01953892  0.28836143]]. Action = [[0.01381417 0.07019729 0.         0.25374687]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 11844 is [False, True, False, False, False, True]
Current timestep = 11845. State = [[-0.01985646  0.2872307 ]]. Action = [[-0.00207906 -0.07361553  0.          0.50362635]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 11845 is [False, True, False, False, False, True]
State prediction error at timestep 11845 is 0.012
Human Feedback received at timestep 11845 of None
Current timestep = 11846. State = [[-0.01740203  0.28739354]]. Action = [[0.06014111 0.04196539 0.         0.6508939 ]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 11846 is [False, True, False, False, False, True]
State prediction error at timestep 11846 is 0.012
Human Feedback received at timestep 11846 of None
Current timestep = 11847. State = [[-0.01726156  0.28953713]]. Action = [[-0.02291161  0.02089536  0.          0.42235136]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 11847 is [False, True, False, False, False, True]
Current timestep = 11848. State = [[-0.02095922  0.2933843 ]]. Action = [[-0.05687628  0.05563471  0.          0.7091017 ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 11848 is [False, True, False, False, False, True]
State prediction error at timestep 11848 is 0.012
Human Feedback received at timestep 11848 of None
Current timestep = 11849. State = [[-0.02160951  0.2965914 ]]. Action = [[0.0321077  0.01682448 0.         0.57849574]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 11849 is [False, True, False, False, False, True]
Current timestep = 11850. State = [[-0.02320846  0.2938462 ]]. Action = [[-0.05036473 -0.0873864   0.          0.8444419 ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 11850 is [False, True, False, False, False, True]
Current timestep = 11851. State = [[-0.0218057  0.2958226]]. Action = [[0.08531871 0.09452889 0.         0.01995313]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 11851 is [False, True, False, False, False, True]
Current timestep = 11852. State = [[-0.01538467  0.29957372]]. Action = [[0.0940466  0.02533264 0.         0.07024193]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 11852 is [False, True, False, False, False, True]
Current timestep = 11853. State = [[-0.0080358   0.30232358]]. Action = [[ 0.09839494  0.04663915  0.         -0.25876045]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 11853 is [False, True, False, False, False, True]
Current timestep = 11854. State = [[-0.00643623  0.2997541 ]]. Action = [[-0.06506816 -0.09292798  0.         -0.5827322 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 11854 is [False, True, False, False, False, True]
Current timestep = 11855. State = [[-0.00857913  0.2927865 ]]. Action = [[-0.03313476 -0.09151731  0.          0.3343624 ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 11855 is [False, True, False, False, False, True]
State prediction error at timestep 11855 is 0.012
Human Feedback received at timestep 11855 of None
Current timestep = 11856. State = [[-0.00504882  0.28622276]]. Action = [[ 0.07530678 -0.0657893   0.          0.8593168 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 11856 is [False, True, False, False, False, True]
Current timestep = 11857. State = [[-0.00468011  0.28584525]]. Action = [[-0.05568948  0.05420207  0.         -0.27739906]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 11857 is [False, True, False, False, False, True]
Current timestep = 11858. State = [[-0.00074752  0.2843188 ]]. Action = [[ 0.09784155 -0.04630682  0.         -0.18233919]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 11858 is [False, True, False, False, False, True]
Current timestep = 11859. State = [[-0.00189473  0.28643623]]. Action = [[-0.0934592  0.0883477  0.         0.5411272]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 11859 is [False, True, False, False, False, True]
Current timestep = 11860. State = [[-0.00644739  0.29292178]]. Action = [[-0.04308007  0.07733383  0.          0.68914175]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 11860 is [False, True, False, False, False, True]
Current timestep = 11861. State = [[-0.01299354  0.3002746 ]]. Action = [[-0.09429615  0.08207589  0.         -0.97096217]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 11861 is [False, True, False, False, False, True]
State prediction error at timestep 11861 is 0.012
Human Feedback received at timestep 11861 of None
Current timestep = 11862. State = [[-0.01671087  0.3063527 ]]. Action = [[ 0.00118315  0.04110112  0.         -0.93898845]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 11862 is [False, True, False, False, False, True]
Current timestep = 11863. State = [[-0.01653221  0.31013826]]. Action = [[0.03529043 0.02105691 0.         0.65995026]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 11863 is [False, True, False, False, False, True]
State prediction error at timestep 11863 is 0.012
Human Feedback received at timestep 11863 of None
Current timestep = 11864. State = [[-0.02055581  0.316521  ]]. Action = [[-0.07172523  0.08793176  0.         -0.7454778 ]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 11864 is [False, True, False, False, False, True]
State prediction error at timestep 11864 is 0.012
Human Feedback received at timestep 11864 of None
Current timestep = 11865. State = [[-0.02356281  0.3242164 ]]. Action = [[ 0.01631291  0.06913719  0.         -0.5188898 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 11865 is [False, True, False, False, False, True]
Current timestep = 11866. State = [[-0.02857767  0.3298679 ]]. Action = [[-0.07232843  0.03363345  0.          0.75130653]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 11866 is [False, True, False, False, False, True]
Current timestep = 11867. State = [[-0.02841827  0.33328727]]. Action = [[0.08635037 0.01461395 0.         0.5654794 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 11867 is [False, True, False, False, False, True]
Current timestep = 11868. State = [[-0.03155991  0.33566278]]. Action = [[-9.5120057e-02  2.3335218e-04  0.0000000e+00 -8.8514394e-01]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 11868 is [False, True, False, False, False, True]
State prediction error at timestep 11868 is 0.012
Human Feedback received at timestep 11868 of None
Current timestep = 11869. State = [[-0.03646774  0.3382767 ]]. Action = [[-0.02515937  0.01578853  0.          0.8771899 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 11869 is [False, True, False, False, False, True]
Current timestep = 11870. State = [[-0.03585903  0.34266767]]. Action = [[0.06210227 0.0553362  0.         0.6080686 ]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 11870 is [False, True, False, False, False, True]
Current timestep = 11871. State = [[-0.03552678  0.34508184]]. Action = [[0.         0.         0.         0.12913597]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 11871 is [False, True, False, False, False, True]
Current timestep = 11872. State = [[-0.03522068  0.3419586 ]]. Action = [[ 0.01719526 -0.08023284  0.         -0.85524416]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 11872 is [False, True, False, False, False, True]
Current timestep = 11873. State = [[-0.03353263  0.33944944]]. Action = [[ 0.02212943 -0.01313721  0.          0.72180843]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 11873 is [False, True, False, False, False, True]
State prediction error at timestep 11873 is 0.012
Human Feedback received at timestep 11873 of None
Current timestep = 11874. State = [[-0.03263095  0.3389935 ]]. Action = [[0.        0.        0.        0.0096823]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 11874 is [False, True, False, False, False, True]
Current timestep = 11875. State = [[-0.03227466  0.3389186 ]]. Action = [[ 0.          0.          0.         -0.24013102]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 11875 is [False, True, False, False, False, True]
Current timestep = 11876. State = [[-0.0352142  0.3366468]]. Action = [[-0.07560524 -0.05164033  0.         -0.70261246]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 11876 is [False, True, False, False, False, True]
Current timestep = 11877. State = [[-0.03210313  0.33209997]]. Action = [[ 0.09617911 -0.06080463  0.          0.00012207]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 11877 is [False, True, False, False, False, True]
State prediction error at timestep 11877 is 0.012
Human Feedback received at timestep 11877 of None
Current timestep = 11878. State = [[-0.02813811  0.32590252]]. Action = [[ 0.0020955  -0.07975195  0.         -0.83129895]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 11878 is [False, True, False, False, False, True]
State prediction error at timestep 11878 is 0.012
Human Feedback received at timestep 11878 of None
Current timestep = 11879. State = [[-0.02571356  0.3257639 ]]. Action = [[0.01998677 0.06119118 0.         0.19365168]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 11879 is [False, True, False, False, False, True]
Current timestep = 11880. State = [[-0.02545588  0.3232538 ]]. Action = [[-0.03478189 -0.07494491  0.          0.2791443 ]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 11880 is [False, True, False, False, False, True]
Current timestep = 11881. State = [[-0.02995551  0.3253908 ]]. Action = [[-0.09614327  0.08982713  0.          0.94014883]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 11881 is [False, True, False, False, False, True]
Current timestep = 11882. State = [[-0.02934979  0.32825428]]. Action = [[ 0.06957754  0.00642904  0.         -0.09032595]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 11882 is [False, True, False, False, False, True]
Current timestep = 11883. State = [[-0.02984903  0.32559326]]. Action = [[-0.05962113 -0.06853656  0.         -0.36007756]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 11883 is [False, True, False, False, False, True]
State prediction error at timestep 11883 is 0.012
Human Feedback received at timestep 11883 of None
Current timestep = 11884. State = [[-0.02754288  0.32371527]]. Action = [[0.09182066 0.01450813 0.         0.06008863]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 11884 is [False, True, False, False, False, True]
Current timestep = 11885. State = [[-0.02143539  0.3261352 ]]. Action = [[ 0.08302552  0.06259301  0.         -0.9071864 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 11885 is [False, True, False, False, False, True]
Current timestep = 11886. State = [[-0.017707    0.33068871]]. Action = [[0.04194928 0.08261911 0.         0.47116578]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 11886 is [False, True, False, False, False, True]
Current timestep = 11887. State = [[-0.01330285  0.3352348 ]]. Action = [[0.08533437 0.06926972 0.         0.02334487]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 11887 is [False, True, False, False, False, True]
Current timestep = 11888. State = [[-0.01396296  0.33351883]]. Action = [[-0.08872856 -0.08475346  0.          0.00274146]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 11888 is [False, True, False, False, False, True]
Current timestep = 11889. State = [[-0.01508505  0.3345651 ]]. Action = [[ 0.05492616  0.09318426  0.         -0.20626462]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 11889 is [False, True, False, False, False, True]
Current timestep = 11890. State = [[-0.01145727  0.33340046]]. Action = [[ 0.07155187 -0.05095744  0.         -0.7844748 ]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 11890 is [False, True, False, False, False, True]
Current timestep = 11891. State = [[-0.01353908  0.33577794]]. Action = [[-0.07260583  0.09704221  0.          0.7282505 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 11891 is [False, True, False, False, False, True]
Current timestep = 11892. State = [[-0.01636583  0.33383355]]. Action = [[-0.00773811 -0.09636568  0.         -0.13926733]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 11892 is [False, True, False, False, False, True]
Current timestep = 11893. State = [[-0.01423192  0.33133078]]. Action = [[0.05177105 0.00113697 0.         0.00807703]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 11893 is [False, True, False, False, False, True]
Current timestep = 11894. State = [[-0.01014416  0.33252403]]. Action = [[0.05564796 0.03445057 0.         0.57298934]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 11894 is [False, True, False, False, False, True]
Current timestep = 11895. State = [[-0.01166144  0.33750075]]. Action = [[-0.05856302  0.08882704  0.          0.71669817]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 11895 is [False, True, False, False, False, True]
State prediction error at timestep 11895 is 0.012
Human Feedback received at timestep 11895 of None
Current timestep = 11896. State = [[-0.01128224  0.34345314]]. Action = [[0.05481256 0.0669705  0.         0.42887092]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 11896 is [False, True, False, False, False, True]
Current timestep = 11897. State = [[-0.00893093  0.34519824]]. Action = [[ 0.03449292 -0.00620442  0.         -0.1998012 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 11897 is [False, True, False, False, False, True]
State prediction error at timestep 11897 is 0.012
Human Feedback received at timestep 11897 of None
Current timestep = 11898. State = [[-0.01075917  0.34661108]]. Action = [[-0.05314139  0.02445851  0.         -0.596822  ]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 11898 is [False, True, False, False, False, True]
Current timestep = 11899. State = [[-0.01320677  0.34841022]]. Action = [[-0.020616    0.00523325  0.          0.93718266]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 11899 is [False, True, False, False, False, True]
Current timestep = 11900. State = [[-0.01514669  0.3487224 ]]. Action = [[-0.03023268 -0.02036835  0.          0.857167  ]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 11900 is [False, True, False, False, False, True]
Current timestep = 11901. State = [[-0.01560982  0.34939373]]. Action = [[ 0.          0.          0.         -0.75589746]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 11901 is [False, True, False, False, False, True]
Current timestep = 11902. State = [[-0.01433407  0.34936157]]. Action = [[ 0.01773336 -0.02109085  0.          0.7134265 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 11902 is [False, True, False, False, False, True]
Current timestep = 11903. State = [[-0.01325609  0.34957382]]. Action = [[0.         0.         0.         0.04128814]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 11903 is [False, True, False, False, False, True]
Current timestep = 11904. State = [[-0.00817763  0.34773248]]. Action = [[ 0.09126694 -0.04603208  0.         -0.42997766]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 11904 is [False, True, False, False, False, True]
State prediction error at timestep 11904 is 0.012
Human Feedback received at timestep 11904 of None
Current timestep = 11905. State = [[-0.00483046  0.34624982]]. Action = [[0.         0.         0.         0.75862575]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 11905 is [False, True, False, False, False, True]
Current timestep = 11906. State = [[-0.00357585  0.34132627]]. Action = [[-0.00308136 -0.09734805  0.          0.6706507 ]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 11906 is [False, True, False, False, False, True]
State prediction error at timestep 11906 is 0.012
Human Feedback received at timestep 11906 of None
Current timestep = 11907. State = [[-0.00188372  0.33840188]]. Action = [[ 0.         0.         0.        -0.7038512]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 11907 is [False, True, False, False, False, True]
Current timestep = 11908. State = [[-2.1047734e-04  3.3880502e-01]]. Action = [[0.00639728 0.01761754 0.         0.20374691]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 11908 is [False, True, False, False, False, True]
Current timestep = 11909. State = [[-3.063484e-04  3.411853e-01]]. Action = [[-0.02359848  0.04281553  0.          0.80352724]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 11909 is [False, True, False, False, False, True]
Current timestep = 11910. State = [[0.00358785 0.33942905]]. Action = [[ 0.08046702 -0.05754721  0.          0.64654374]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 11910 is [False, True, False, False, False, True]
Current timestep = 11911. State = [[0.00658569 0.3372547 ]]. Action = [[ 0.         0.         0.        -0.5552517]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 11911 is [False, True, False, False, False, True]
State prediction error at timestep 11911 is 0.012
Human Feedback received at timestep 11911 of None
Current timestep = 11912. State = [[0.01113606 0.33366877]]. Action = [[ 0.07353988 -0.05667956  0.          0.09931469]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 11912 is [False, True, False, False, False, True]
Current timestep = 11913. State = [[0.01795965 0.33502632]]. Action = [[0.09500849 0.09435094 0.         0.81169116]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 11913 is [False, True, False, False, False, True]
Current timestep = 11914. State = [[0.0204608  0.33692217]]. Action = [[-0.01435434  0.01027286  0.          0.2054019 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 11914 is [False, True, False, False, False, True]
Current timestep = 11915. State = [[0.01637883 0.33515054]]. Action = [[-0.09720325 -0.03692432  0.          0.50688505]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 11915 is [False, True, False, False, False, True]
State prediction error at timestep 11915 is 0.012
Human Feedback received at timestep 11915 of None
Current timestep = 11916. State = [[0.01843716 0.33122528]]. Action = [[ 0.09886872 -0.04244706  0.          0.79377496]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 11916 is [False, True, False, False, False, True]
Current timestep = 11917. State = [[0.02061383 0.33221972]]. Action = [[-0.01847824  0.06138826  0.          0.18929207]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 11917 is [False, True, False, False, False, True]
State prediction error at timestep 11917 is 0.012
Human Feedback received at timestep 11917 of None
Current timestep = 11918. State = [[0.01790987 0.33389482]]. Action = [[-0.05488405 -0.000219    0.          0.06057143]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 11918 is [False, True, False, False, False, True]
Current timestep = 11919. State = [[0.01929557 0.33007383]]. Action = [[ 0.0455705  -0.08621325  0.          0.00344682]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 11919 is [False, True, False, False, False, True]
Current timestep = 11920. State = [[0.02542583 0.32598534]]. Action = [[ 0.08373282 -0.0265885   0.         -0.11482382]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 11920 is [False, True, False, False, False, True]
Current timestep = 11921. State = [[0.03298954 0.320851  ]]. Action = [[ 0.08970235 -0.06357874  0.         -0.5458386 ]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 11921 is [False, True, False, False, False, True]
State prediction error at timestep 11921 is 0.012
Human Feedback received at timestep 11921 of None
Current timestep = 11922. State = [[0.03305982 0.32186958]]. Action = [[-0.07498892  0.09047572  0.         -0.507548  ]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 11922 is [False, True, False, False, False, True]
Current timestep = 11923. State = [[0.03094841 0.3201527 ]]. Action = [[-0.02164902 -0.08048169  0.          0.97199774]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 11923 is [False, True, False, False, False, True]
Current timestep = 11924. State = [[0.03485002 0.31795695]]. Action = [[ 0.09003664  0.016171    0.         -0.1629532 ]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 11924 is [False, True, False, False, False, True]
State prediction error at timestep 11924 is 0.012
Human Feedback received at timestep 11924 of None
Current timestep = 11925. State = [[0.04174232 0.32062837]]. Action = [[0.08459214 0.06737021 0.         0.14361882]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 11925 is [False, True, False, False, False, True]
Current timestep = 11926. State = [[0.04761556 0.32042092]]. Action = [[ 0.07029098 -0.01894681  0.         -0.82934165]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 11926 is [False, True, False, False, False, True]
Current timestep = 11927. State = [[0.0511891  0.31752107]]. Action = [[ 0.02116056 -0.02440981  0.          0.23892808]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 11927 is [False, True, False, False, False, True]
Current timestep = 11928. State = [[0.05458651 0.31777024]]. Action = [[0.04350791 0.04466826 0.         0.28142715]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 11928 is [False, False, True, False, False, True]
State prediction error at timestep 11928 is 0.012
Human Feedback received at timestep 11928 of None
Current timestep = 11929. State = [[0.05739091 0.315131  ]]. Action = [[ 0.02116019 -0.05549359  0.          0.5502188 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 11929 is [False, False, True, False, False, True]
State prediction error at timestep 11929 is 0.012
Human Feedback received at timestep 11929 of None
Current timestep = 11930. State = [[0.06299678 0.30791202]]. Action = [[ 0.07973189 -0.08979128  0.         -0.15590143]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 11930 is [False, False, True, False, False, True]
Current timestep = 11931. State = [[0.06812284 0.3018699 ]]. Action = [[ 0.02999044 -0.03291322  0.         -0.6540847 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 11931 is [False, False, True, False, False, True]
State prediction error at timestep 11931 is 0.012
Human Feedback received at timestep 11931 of None
Current timestep = 11932. State = [[0.06851862 0.29554152]]. Action = [[-0.06198433 -0.07829206  0.         -0.8406293 ]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 11932 is [False, False, True, False, False, True]
Current timestep = 11933. State = [[0.06617174 0.28932258]]. Action = [[-0.07731521 -0.05932875  0.          0.66537607]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 11933 is [False, False, True, False, False, True]
Current timestep = 11934. State = [[0.06982901 0.2823879 ]]. Action = [[ 0.07220625 -0.08043773  0.         -0.18163145]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 11934 is [False, False, True, False, False, True]
Current timestep = 11935. State = [[0.0778687  0.27940896]]. Action = [[0.08567644 0.02054272 0.         0.65722394]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 11935 is [False, False, True, False, False, True]
Current timestep = 11936. State = [[0.08538777 0.2777522 ]]. Action = [[ 0.07762206 -0.00446777  0.         -0.28982544]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 11936 is [False, False, True, False, False, True]
State prediction error at timestep 11936 is 0.012
Human Feedback received at timestep 11936 of None
Current timestep = 11937. State = [[0.0911015  0.27158806]]. Action = [[ 0.04214288 -0.08222626  0.          0.25061154]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 11937 is [False, False, True, False, False, True]
Current timestep = 11938. State = [[0.09603365 0.26511765]]. Action = [[ 0.03948619 -0.03801677  0.          0.5659652 ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 11938 is [False, False, True, False, False, True]
Current timestep = 11939. State = [[0.09621849 0.25927547]]. Action = [[-0.07603981 -0.05796149  0.          0.2944945 ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 11939 is [False, False, True, False, False, True]
State prediction error at timestep 11939 is 0.012
Human Feedback received at timestep 11939 of None
Current timestep = 11940. State = [[0.09295753 0.2609802 ]]. Action = [[-0.07325969  0.09574408  0.         -0.23127842]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 11940 is [False, False, True, False, False, True]
Current timestep = 11941. State = [[0.09437951 0.2646959 ]]. Action = [[ 0.06280381  0.03236724  0.         -0.65196526]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 11941 is [False, False, True, False, False, True]
Current timestep = 11942. State = [[0.10021387 0.26620874]]. Action = [[0.09251096 0.0169434  0.         0.07405901]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 11942 is [False, False, True, False, False, True]
Current timestep = 11943. State = [[0.10205297 0.26801735]]. Action = [[-0.00656412  0.03475609  0.         -0.8598256 ]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 11943 is [False, False, True, False, False, True]
Current timestep = 11944. State = [[0.10577035 0.26711228]]. Action = [[ 0.08808055 -0.02992655  0.         -0.6581615 ]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 11944 is [False, False, True, False, False, True]
Current timestep = 11945. State = [[0.11040217 0.2688153 ]]. Action = [[0.0661547  0.06902447 0.         0.15571499]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 11945 is [False, False, True, False, False, True]
Current timestep = 11946. State = [[0.10850883 0.2740956 ]]. Action = [[-0.06344018  0.0724966   0.         -0.7738794 ]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 11946 is [False, False, True, False, False, True]
Current timestep = 11947. State = [[0.10614522 0.2811946 ]]. Action = [[0.02140667 0.09646327 0.         0.02344096]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 11947 is [False, False, True, False, False, True]
State prediction error at timestep 11947 is 0.012
Human Feedback received at timestep 11947 of None
Current timestep = 11948. State = [[0.10824044 0.2807737 ]]. Action = [[ 0.07294381 -0.07281756  0.         -0.4338373 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 11948 is [False, False, True, False, False, True]
Current timestep = 11949. State = [[0.11062919 0.27531078]]. Action = [[ 0.02866995 -0.06511682  0.          0.23843527]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 11949 is [False, False, True, False, False, True]
Current timestep = 11950. State = [[0.1092287  0.27137542]]. Action = [[-0.04689984 -0.0275741   0.         -0.0643205 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 11950 is [False, False, True, False, False, True]
Current timestep = 11951. State = [[0.10781826 0.26652077]]. Action = [[-0.02171648 -0.07070763  0.          0.38517082]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 11951 is [False, False, True, False, False, True]
Current timestep = 11952. State = [[0.10781393 0.26761925]]. Action = [[0.0045592  0.07837851 0.         0.7756951 ]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 11952 is [False, False, True, False, False, True]
Current timestep = 11953. State = [[0.11052281 0.27318516]]. Action = [[0.06215166 0.07480118 0.         0.93304753]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 11953 is [False, False, True, False, False, True]
Current timestep = 11954. State = [[0.11259204 0.27303916]]. Action = [[ 0.00646855 -0.05395322  0.         -0.9100245 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 11954 is [False, False, True, False, False, True]
State prediction error at timestep 11954 is 0.012
Human Feedback received at timestep 11954 of None
Current timestep = 11955. State = [[0.11165513 0.267317  ]]. Action = [[-0.03920255 -0.08527454  0.          0.8873017 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 11955 is [False, False, True, False, False, True]
State prediction error at timestep 11955 is 0.012
Human Feedback received at timestep 11955 of None
Current timestep = 11956. State = [[0.11331943 0.2603464 ]]. Action = [[ 0.02723033 -0.07930027  0.          0.96299577]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 11956 is [False, False, True, False, False, True]
Current timestep = 11957. State = [[0.11953902 0.25281668]]. Action = [[ 0.08527189 -0.07704095  0.          0.5916281 ]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 11957 is [False, False, True, False, False, True]
Current timestep = 11958. State = [[0.12566039 0.24377944]]. Action = [[ 0.04731212 -0.09327686  0.          0.11240268]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 11958 is [False, False, True, False, False, True]
Current timestep = 11959. State = [[0.12544186 0.24126129]]. Action = [[-0.07322769  0.05424807  0.         -0.7112136 ]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 11959 is [False, False, True, False, False, True]
Current timestep = 11960. State = [[0.12487909 0.2376404 ]]. Action = [[-0.01106478 -0.07567458  0.          0.04928839]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 11960 is [False, False, True, False, False, True]
Current timestep = 11961. State = [[0.12685886 0.23017287]]. Action = [[ 0.00228441 -0.08116922  0.         -0.36917585]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 11961 is [False, False, True, False, False, True]
Current timestep = 11962. State = [[0.12613176 0.23051788]]. Action = [[-0.06271686  0.08342499  0.         -0.83380395]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 11962 is [False, False, True, False, False, True]
Current timestep = 11963. State = [[0.12333726 0.2358697 ]]. Action = [[-0.05071804  0.06038123  0.          0.9664264 ]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 11963 is [False, False, True, False, False, True]
Current timestep = 11964. State = [[0.12230614 0.24263722]]. Action = [[-0.00298621  0.07968379  0.         -0.7779721 ]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 11964 is [False, False, True, False, False, True]
Current timestep = 11965. State = [[0.11977477 0.24373695]]. Action = [[-0.09657657 -0.07254795  0.         -0.54101294]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 11965 is [False, False, True, False, False, True]
Current timestep = 11966. State = [[0.1150487  0.24049169]]. Action = [[-0.07898919 -0.05901707  0.         -0.77277553]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 11966 is [False, False, True, False, False, True]
Current timestep = 11967. State = [[0.11475798 0.24070753]]. Action = [[0.05877457 0.03924931 0.         0.18241084]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 11967 is [False, False, True, False, False, True]
Current timestep = 11968. State = [[0.11768889 0.24504623]]. Action = [[ 0.03228774  0.0538635   0.         -0.14657569]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 11968 is [False, False, True, False, False, True]
Current timestep = 11969. State = [[0.11519364 0.25028077]]. Action = [[-0.08557546  0.04359335  0.          0.02777565]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 11969 is [False, False, True, False, False, True]
Current timestep = 11970. State = [[0.11660551 0.24928845]]. Action = [[ 0.07429992 -0.07154341  0.          0.4631884 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 11970 is [False, False, True, False, False, True]
Current timestep = 11971. State = [[0.11788379 0.24537134]]. Action = [[-0.02782532 -0.0474329   0.          0.47921562]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 11971 is [False, False, True, False, False, True]
Current timestep = 11972. State = [[0.11560477 0.24156779]]. Action = [[-0.05971084 -0.05025234  0.         -0.8226895 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 11972 is [False, False, True, False, False, True]
Current timestep = 11973. State = [[0.1179134  0.23861831]]. Action = [[ 0.08329787 -0.0131572   0.          0.13280559]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 11973 is [False, False, True, False, False, True]
Current timestep = 11974. State = [[0.12316766 0.2371023 ]]. Action = [[ 0.05030606 -0.00686778  0.          0.14290881]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 11974 is [False, False, True, False, False, True]
Current timestep = 11975. State = [[0.12478075 0.23194544]]. Action = [[-0.04130886 -0.09295472  0.          0.4364605 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 11975 is [False, False, True, False, False, True]
State prediction error at timestep 11975 is 0.012
Human Feedback received at timestep 11975 of None
Current timestep = 11976. State = [[0.12227008 0.23091954]]. Action = [[-0.06638867  0.0487221   0.         -0.44855714]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 11976 is [False, False, True, False, False, True]
State prediction error at timestep 11976 is 0.012
Human Feedback received at timestep 11976 of None
Current timestep = 11977. State = [[0.11920286 0.23299646]]. Action = [[-0.04830315  0.01599182  0.         -0.21268177]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 11977 is [False, False, True, False, False, True]
Current timestep = 11978. State = [[0.1203157  0.23616605]]. Action = [[0.05884192 0.05475948 0.         0.56038   ]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 11978 is [False, False, True, False, False, True]
State prediction error at timestep 11978 is 0.012
Human Feedback received at timestep 11978 of None
Current timestep = 11979. State = [[0.12296042 0.24178693]]. Action = [[ 0.03765152  0.07513357  0.         -0.33196115]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 11979 is [False, False, True, False, False, True]
Current timestep = 11980. State = [[0.12382571 0.24665423]]. Action = [[ 0.02063459  0.0414191   0.         -0.41402125]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 11980 is [False, False, True, False, False, True]
Current timestep = 11981. State = [[0.12373635 0.24803156]]. Action = [[ 0.00950964 -0.01052563  0.         -0.28015667]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 11981 is [False, False, True, False, False, True]
Current timestep = 11982. State = [[0.12050465 0.2465351 ]]. Action = [[-0.07314026 -0.03952716  0.         -0.36633718]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 11982 is [False, False, True, False, False, True]
State prediction error at timestep 11982 is 0.012
Human Feedback received at timestep 11982 of None
Current timestep = 11983. State = [[0.11707337 0.24223092]]. Action = [[-0.04345181 -0.07438342  0.          0.73485124]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 11983 is [False, False, True, False, False, True]
Current timestep = 11984. State = [[0.12019705 0.23530717]]. Action = [[ 0.08151396 -0.08939066  0.         -0.23865038]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 11984 is [False, False, True, False, False, True]
Current timestep = 11985. State = [[0.12193535 0.22963473]]. Action = [[-0.03569482 -0.04390991  0.         -0.7254058 ]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 11985 is [False, False, True, False, False, True]
Current timestep = 11986. State = [[0.12362964 0.22979069]]. Action = [[ 0.04976489  0.05729035  0.         -0.6648879 ]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 11986 is [False, False, True, False, False, True]
Current timestep = 11987. State = [[0.12482475 0.23074128]]. Action = [[-0.01073826  0.0009086   0.         -0.885009  ]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 11987 is [False, False, True, False, False, True]
Current timestep = 11988. State = [[0.12767527 0.23041442]]. Action = [[ 0.05710355  0.0011261   0.         -0.12342727]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 11988 is [False, False, True, False, False, True]
Current timestep = 11989. State = [[0.13201828 0.23444735]]. Action = [[0.07204697 0.09559429 0.         0.52364635]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 11989 is [False, False, True, False, False, True]
Current timestep = 11990. State = [[0.13670464 0.23698168]]. Action = [[0.08938543 0.00815181 0.         0.48163247]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 11990 is [False, False, True, False, False, True]
Current timestep = 11991. State = [[0.14082646 0.233715  ]]. Action = [[ 0.06383459 -0.05364975  0.         -0.6883619 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 11991 is [False, False, True, False, False, True]
Current timestep = 11992. State = [[0.13876134 0.23526473]]. Action = [[-0.06361795  0.08756118  0.         -0.76274437]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 11992 is [False, False, True, False, False, True]
Current timestep = 11993. State = [[0.13780269 0.2338179 ]]. Action = [[ 0.03012466 -0.07252989  0.          0.20158994]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 11993 is [False, False, True, False, False, True]
Current timestep = 11994. State = [[0.13519631 0.23357914]]. Action = [[-0.06494571  0.0437872   0.         -0.5517275 ]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 11994 is [False, False, True, False, False, True]
Current timestep = 11995. State = [[0.13155974 0.2358466 ]]. Action = [[-0.03815681  0.0159141   0.         -0.69070715]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 11995 is [False, False, True, False, False, True]
Current timestep = 11996. State = [[0.13037428 0.2343839 ]]. Action = [[-0.00464972 -0.05099204  0.         -0.7568418 ]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 11996 is [False, False, True, False, False, True]
State prediction error at timestep 11996 is 0.012
Human Feedback received at timestep 11996 of None
Current timestep = 11997. State = [[0.12717935 0.23773845]]. Action = [[-0.07151343  0.08653993  0.         -0.5307281 ]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 11997 is [False, False, True, False, False, True]
Current timestep = 11998. State = [[0.12920126 0.239487  ]]. Action = [[ 0.09579737 -0.0302618   0.          0.5585289 ]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 11998 is [False, False, True, False, False, True]
Current timestep = 11999. State = [[0.13318193 0.23877107]]. Action = [[ 0.03867493 -0.00519904  0.          0.26227677]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 11999 is [False, False, True, False, False, True]
Current timestep = 12000. State = [[0.13521956 0.24126615]]. Action = [[ 0.02645559  0.05279999  0.         -0.12228739]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 12000 is [False, False, True, False, False, True]
Current timestep = 12001. State = [[0.13951282 0.23848988]]. Action = [[ 0.08520325 -0.08325623  0.         -0.29645038]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 12001 is [False, False, True, False, False, True]
Current timestep = 12002. State = [[0.14416501 0.23614088]]. Action = [[ 0.05602586  0.01897874  0.         -0.12024516]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 12002 is [False, False, True, False, False, True]
Current timestep = 12003. State = [[0.14397347 0.23300758]]. Action = [[-0.09320549 -0.07476942  0.         -0.6258825 ]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 12003 is [False, False, True, False, False, True]
Current timestep = 12004. State = [[0.14380689 0.23164156]]. Action = [[ 0.0626931  0.0425039  0.        -0.9452894]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 12004 is [False, False, True, False, False, True]
Current timestep = 12005. State = [[0.14443259 0.23213458]]. Action = [[-0.00547374  0.00765294  0.          0.18991983]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 12005 is [False, False, True, False, False, True]
Current timestep = 12006. State = [[0.14573875 0.22747487]]. Action = [[ 0.02865464 -0.08289757  0.          0.87512696]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 12006 is [False, False, True, False, False, True]
Current timestep = 12007. State = [[0.15078224 0.21948615]]. Action = [[ 0.07836623 -0.08297719  0.         -0.36936986]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 12007 is [False, False, True, False, False, True]
Current timestep = 12008. State = [[0.15181299 0.21106379]]. Action = [[-0.09350372 -0.09680229  0.         -0.6579213 ]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 12008 is [False, False, True, False, False, True]
Current timestep = 12009. State = [[0.14902906 0.20878302]]. Action = [[-0.0508524   0.04445633  0.         -0.973811  ]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 12009 is [False, False, True, False, False, True]
Current timestep = 12010. State = [[0.15033308 0.20568494]]. Action = [[ 0.03968693 -0.06080057  0.          0.08935535]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 12010 is [False, False, True, False, False, True]
Current timestep = 12011. State = [[0.1520505  0.20034194]]. Action = [[-0.00295763 -0.04389521  0.         -0.84185743]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 12011 is [False, False, True, False, False, True]
Current timestep = 12012. State = [[0.15543497 0.19521376]]. Action = [[ 0.05295112 -0.0429945   0.          0.31681395]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 12012 is [False, False, True, False, False, True]
Current timestep = 12013. State = [[0.15421076 0.19556765]]. Action = [[-0.07104225  0.06553198  0.          0.5968553 ]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 12013 is [False, False, True, False, False, True]
Current timestep = 12014. State = [[0.1545205  0.20061252]]. Action = [[0.09386847 0.09259162 0.         0.38754296]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 12014 is [False, False, True, False, False, True]
State prediction error at timestep 12014 is 0.012
Human Feedback received at timestep 12014 of None
Current timestep = 12015. State = [[0.15845788 0.19950409]]. Action = [[ 0.05505372 -0.06838471  0.          0.23998618]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 12015 is [False, False, True, False, False, True]
Current timestep = 12016. State = [[0.16277306 0.19643657]]. Action = [[ 0.06362204 -0.00843078  0.          0.9177916 ]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 12016 is [False, False, True, False, False, True]
State prediction error at timestep 12016 is 0.012
Human Feedback received at timestep 12016 of None
Current timestep = 12017. State = [[0.16357067 0.19130976]]. Action = [[-0.06334282 -0.09162649  0.          0.7120867 ]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 12017 is [False, False, True, False, False, True]
Current timestep = 12018. State = [[0.16244824 0.19175479]]. Action = [[ 0.01635666  0.08685715  0.         -0.55150926]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 12018 is [False, False, True, False, False, True]
State prediction error at timestep 12018 is 0.012
Human Feedback received at timestep 12018 of None
Current timestep = 12019. State = [[0.16631849 0.18883795]]. Action = [[ 0.08618034 -0.09128125  0.         -0.07144433]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 12019 is [False, False, True, False, False, True]
Current timestep = 12020. State = [[0.16934559 0.18313035]]. Action = [[ 0.01936624 -0.0353898   0.          0.35680997]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 12020 is [False, False, True, False, False, True]
Current timestep = 12021. State = [[0.1693395  0.18493213]]. Action = [[-0.00754742  0.0874557   0.         -0.39621276]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 12021 is [False, False, True, False, False, True]
Current timestep = 12022. State = [[0.17072462 0.19140168]]. Action = [[0.06389713 0.09269363 0.         0.23630452]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 12022 is [False, False, True, False, False, True]
Current timestep = 12023. State = [[0.17195733 0.19902095]]. Action = [[0.03843076 0.09336247 0.         0.4807167 ]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 12023 is [False, False, True, False, False, True]
Current timestep = 12024. State = [[0.16974214 0.20216262]]. Action = [[-0.07108299 -0.02388712  0.          0.6425326 ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 12024 is [False, False, True, False, False, True]
Current timestep = 12025. State = [[0.16826552 0.20566058]]. Action = [[ 0.06435452  0.07288245  0.         -0.80232036]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 12025 is [False, False, True, False, False, True]
Current timestep = 12026. State = [[0.17051809 0.20368262]]. Action = [[ 0.06152459 -0.08986456  0.         -0.37728238]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 12026 is [False, False, True, False, False, True]
Current timestep = 12027. State = [[0.17041072 0.20407112]]. Action = [[-0.00632853  0.06278271  0.          0.12958086]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 12027 is [False, False, True, False, False, True]
State prediction error at timestep 12027 is 0.012
Human Feedback received at timestep 12027 of None
Current timestep = 12028. State = [[0.16992162 0.2038966 ]]. Action = [[ 0.02341722 -0.03946912  0.          0.9073403 ]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 12028 is [False, False, True, False, False, True]
Current timestep = 12029. State = [[0.16565876 0.20504214]]. Action = [[-0.09247753  0.04275735  0.         -0.65501225]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 12029 is [False, False, True, False, False, True]
State prediction error at timestep 12029 is 0.012
Human Feedback received at timestep 12029 of None
Current timestep = 12030. State = [[0.16412717 0.20863447]]. Action = [[ 0.08239522  0.05504883  0.         -0.09412521]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 12030 is [False, False, True, False, False, True]
Current timestep = 12031. State = [[0.16285975 0.21372318]]. Action = [[-0.04025806  0.05695019  0.         -0.48221153]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 12031 is [False, False, True, False, False, True]
Current timestep = 12032. State = [[0.16324957 0.21388328]]. Action = [[ 0.04008038 -0.05132218  0.         -0.4003539 ]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 12032 is [False, False, True, False, False, True]
Current timestep = 12033. State = [[0.1674183  0.20836414]]. Action = [[ 0.06624072 -0.08648395  0.         -0.00978559]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 12033 is [False, False, True, False, False, True]
Current timestep = 12034. State = [[0.16672663 0.20475796]]. Action = [[-0.09831215 -0.01839391  0.         -0.8136686 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 12034 is [False, False, True, False, False, True]
State prediction error at timestep 12034 is 0.012
Human Feedback received at timestep 12034 of None
Current timestep = 12035. State = [[0.16186376 0.20050126]]. Action = [[-0.09292027 -0.070776    0.         -0.5346381 ]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 12035 is [False, False, True, False, False, True]
Current timestep = 12036. State = [[0.16120595 0.19926938]]. Action = [[0.07696266 0.0459205  0.         0.7224157 ]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 12036 is [False, False, True, False, False, True]
Current timestep = 12037. State = [[0.16706105 0.19766226]]. Action = [[ 0.08093061 -0.04012271  0.          0.82549906]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 12037 is [False, False, True, False, False, True]
Current timestep = 12038. State = [[0.17445432 0.19753933]]. Action = [[ 0.09170816  0.03594323  0.         -0.08839893]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 12038 is [False, False, True, False, False, True]
Current timestep = 12039. State = [[0.1813937 0.1996672]]. Action = [[ 0.09667499  0.04026546  0.         -0.5517268 ]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 12039 is [False, False, True, False, False, True]
Current timestep = 12040. State = [[0.18399058 0.20160052]]. Action = [[-0.00871792  0.0220442   0.         -0.3129859 ]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 12040 is [False, False, True, False, False, True]
Current timestep = 12041. State = [[0.18263534 0.19957615]]. Action = [[-0.03356574 -0.04875225  0.          0.14974129]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 12041 is [False, False, True, False, False, True]
Current timestep = 12042. State = [[0.18233187 0.2021597 ]]. Action = [[0.0500033  0.09796388 0.         0.10038757]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 12042 is [False, False, True, False, False, True]
Current timestep = 12043. State = [[0.18712911 0.20185345]]. Action = [[ 0.09139032 -0.05775837  0.         -0.9222617 ]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 12043 is [False, False, True, False, False, True]
Current timestep = 12044. State = [[0.18718882 0.2035959 ]]. Action = [[-0.07154112  0.06890949  0.          0.45354962]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 12044 is [False, False, True, False, False, True]
Current timestep = 12045. State = [[0.1839267  0.21035348]]. Action = [[-0.02971907  0.07843592  0.         -0.37883842]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 12045 is [False, False, True, False, False, True]
Current timestep = 12046. State = [[0.17940627 0.21651535]]. Action = [[-0.07204501  0.04109628  0.          0.8724923 ]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 12046 is [False, False, True, False, False, True]
Current timestep = 12047. State = [[0.17848794 0.22177951]]. Action = [[ 0.08029883  0.0533726   0.         -0.904606  ]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 12047 is [False, False, True, False, False, True]
State prediction error at timestep 12047 is 0.012
Human Feedback received at timestep 12047 of None
Current timestep = 12048. State = [[0.18345894 0.22040483]]. Action = [[ 0.08257752 -0.08335321  0.          0.4454167 ]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 12048 is [False, False, True, False, False, True]
Current timestep = 12049. State = [[0.1891314  0.21879563]]. Action = [[ 0.06988407  0.01085164  0.         -0.45006686]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 12049 is [False, False, True, False, False, True]
State prediction error at timestep 12049 is 0.012
Human Feedback received at timestep 12049 of None
Current timestep = 12050. State = [[0.19122331 0.21813394]]. Action = [[-0.01188619 -0.01693542  0.         -0.6806629 ]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 12050 is [False, False, True, False, False, True]
Current timestep = 12051. State = [[0.19020857 0.21429086]]. Action = [[-0.0370913  -0.06328084  0.         -0.6205807 ]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 12051 is [False, False, True, False, False, True]
Current timestep = 12052. State = [[0.19227277 0.20825274]]. Action = [[ 0.0331933  -0.06987941  0.         -0.5258573 ]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 12052 is [False, False, True, False, False, True]
Current timestep = 12053. State = [[0.19313832 0.2017241 ]]. Action = [[-0.05344278 -0.06754662  0.          0.27147615]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 12053 is [False, False, True, False, False, True]
Current timestep = 12054. State = [[0.1919807  0.19937067]]. Action = [[-0.0497696   0.01224758  0.          0.16103196]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 12054 is [False, False, True, False, False, True]
State prediction error at timestep 12054 is 0.012
Human Feedback received at timestep 12054 of None
Current timestep = 12055. State = [[0.1953351  0.19624665]]. Action = [[ 0.08790848 -0.04970825  0.         -0.69309115]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 12055 is [False, False, True, False, False, True]
Current timestep = 12056. State = [[0.19772473 0.19365051]]. Action = [[-0.09216508 -0.0131529   0.         -0.9785653 ]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 12056 is [False, False, True, False, False, True]
Current timestep = 12057. State = [[0.20060794 0.18999992]]. Action = [[ 0.09828735 -0.04692142  0.         -0.6105895 ]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 12057 is [False, False, True, False, False, True]
Current timestep = 12058. State = [[0.20157948 0.19217406]]. Action = [[-0.06187006  0.08811577  0.          0.14857185]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 12058 is [False, False, True, False, False, True]
Current timestep = 12059. State = [[0.20179063 0.19621177]]. Action = [[0.01456084 0.01905583 0.         0.37091374]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 12059 is [False, False, True, False, False, True]
Current timestep = 12060. State = [[0.20074533 0.20146829]]. Action = [[-0.04345373  0.07073601  0.          0.8848382 ]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 12060 is [False, False, True, False, False, True]
Current timestep = 12061. State = [[0.20212752 0.20648278]]. Action = [[0.0771604  0.03256802 0.         0.31776488]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 12061 is [False, False, True, False, False, True]
Current timestep = 12062. State = [[0.20440099 0.2060546 ]]. Action = [[-0.07818218 -0.06330769  0.         -0.4457357 ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 12062 is [False, False, True, False, False, True]
Current timestep = 12063. State = [[0.20629293 0.20451897]]. Action = [[ 0.04026379 -0.01092861  0.         -0.9710524 ]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 12063 is [False, False, True, False, False, True]
Current timestep = 12064. State = [[0.20923902 0.20258923]]. Action = [[ 0.03449238 -0.03038116  0.         -0.4703089 ]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 12064 is [False, False, True, False, False, True]
State prediction error at timestep 12064 is 0.012
Human Feedback received at timestep 12064 of None
Current timestep = 12065. State = [[0.20936725 0.20576735]]. Action = [[-0.01838816  0.08400451  0.          0.01074922]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 12065 is [False, False, True, False, False, True]
Current timestep = 12066. State = [[0.20687412 0.20746426]]. Action = [[-0.05090242 -0.02890718  0.         -0.7669431 ]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 12066 is [False, False, True, False, False, True]
Current timestep = 12067. State = [[0.20734785 0.20596169]]. Action = [[ 0.05821628 -0.02038737  0.         -0.19396907]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 12067 is [False, False, True, False, False, True]
Current timestep = 12068. State = [[0.20633551 0.20762095]]. Action = [[-0.08979144  0.0375943   0.          0.6120267 ]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 12068 is [False, False, True, False, False, True]
Current timestep = 12069. State = [[0.20560418 0.20951426]]. Action = [[0.06501957 0.00571988 0.         0.7636467 ]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 12069 is [False, False, True, False, False, True]
Current timestep = 12070. State = [[0.20955884 0.21070032]]. Action = [[0.06104413 0.0148557  0.         0.59128   ]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 12070 is [False, False, True, False, False, True]
Current timestep = 12071. State = [[0.21495573 0.2083937 ]]. Action = [[ 0.08587805 -0.04763975  0.         -0.05670559]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 12071 is [False, False, True, False, False, True]
Current timestep = 12072. State = [[0.21895133 0.20694275]]. Action = [[0.04361779 0.02141418 0.         0.5139029 ]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 12072 is [False, False, True, False, False, True]
Current timestep = 12073. State = [[0.21711867 0.21148743]]. Action = [[-0.0667551   0.09047591  0.          0.63582146]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 12073 is [False, False, True, False, False, True]
State prediction error at timestep 12073 is 0.012
Human Feedback received at timestep 12073 of None
Current timestep = 12074. State = [[0.2185544  0.20922424]]. Action = [[ 0.09483344 -0.09720211  0.          0.24288487]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 12074 is [False, False, True, False, False, True]
State prediction error at timestep 12074 is 0.012
Human Feedback received at timestep 12074 of None
Current timestep = 12075. State = [[0.22058581 0.21022694]]. Action = [[ 0.00528824  0.09586439  0.         -0.5310095 ]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 12075 is [False, False, True, False, False, True]
Current timestep = 12076. State = [[0.21728618 0.2165937 ]]. Action = [[-0.06229981  0.06774285  0.         -0.91755444]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 12076 is [False, False, True, False, False, True]
Current timestep = 12077. State = [[0.21511656 0.22356428]]. Action = [[ 0.08135491  0.08185547  0.         -0.828545  ]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 12077 is [False, False, True, False, False, True]
Current timestep = 12078. State = [[0.21681271 0.22961797]]. Action = [[ 0.05245478  0.05274787  0.         -0.56383973]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 12078 is [False, False, True, False, False, True]
Current timestep = 12079. State = [[0.21618536 0.23323965]]. Action = [[-0.02488399  0.01871443  0.         -0.53949916]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 12079 is [False, False, True, False, False, True]
Current timestep = 12080. State = [[0.21776442 0.23132937]]. Action = [[ 0.07224777 -0.06213293  0.          0.58697295]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 12080 is [False, False, True, False, False, True]
Current timestep = 12081. State = [[0.21964099 0.22570853]]. Action = [[ 0.00574241 -0.06595415  0.          0.84142005]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 12081 is [False, False, True, False, False, True]
Current timestep = 12082. State = [[0.22012196 0.22576095]]. Action = [[ 0.01051208  0.05902553  0.         -0.8593844 ]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 12082 is [False, False, True, False, False, True]
Current timestep = 12083. State = [[0.22067124 0.22372943]]. Action = [[ 0.01431347 -0.06206647  0.         -0.83106905]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 12083 is [False, False, True, False, False, True]
State prediction error at timestep 12083 is 0.012
Human Feedback received at timestep 12083 of None
Current timestep = 12084. State = [[0.22482625 0.21697663]]. Action = [[ 0.07953758 -0.07372534  0.          0.5745535 ]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 12084 is [False, False, True, False, False, True]
Current timestep = 12085. State = [[0.22761048 0.20968251]]. Action = [[-0.01982242 -0.05907092  0.         -0.17477357]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 12085 is [False, False, True, False, False, True]
Current timestep = 12086. State = [[0.2264816  0.20680173]]. Action = [[-0.03719591  0.01434366  0.          0.32332504]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 12086 is [False, False, True, False, False, True]
Current timestep = 12087. State = [[0.22745939 0.20740536]]. Action = [[0.0972802  0.03033968 0.         0.00699115]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 12087 is [False, False, True, False, False, True]
Current timestep = 12088. State = [[0.23046152 0.2074532 ]]. Action = [[0.03216093 0.00613842 0.         0.88823843]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 12088 is [False, False, True, False, False, True]
Current timestep = 12089. State = [[0.23363507 0.2101373 ]]. Action = [[ 0.05654543  0.06766018  0.         -0.97748333]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 12089 is [False, False, True, False, False, True]
State prediction error at timestep 12089 is 0.012
Human Feedback received at timestep 12089 of None
Current timestep = 12090. State = [[0.23486923 0.21176155]]. Action = [[0.00836061 0.00287557 0.         0.87981224]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 12090 is [False, False, True, False, False, True]
Current timestep = 12091. State = [[0.23769742 0.21201861]]. Action = [[ 0.0968507   0.0135455   0.         -0.65201485]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 12091 is [False, False, True, False, False, True]
Current timestep = 12092. State = [[0.24309063 0.21410133]]. Action = [[ 0.09860375  0.05576747  0.         -0.9032737 ]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 12092 is [False, False, True, False, False, True]
State prediction error at timestep 12092 is 0.012
Human Feedback received at timestep 12092 of None
Current timestep = 12093. State = [[0.24699783 0.21934979]]. Action = [[ 0.08166     0.09528822  0.         -0.81676674]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 12093 is [False, False, True, False, False, True]
Current timestep = 12094. State = [[0.24699971 0.22473426]]. Action = [[-0.0768315   0.06039371  0.         -0.4502808 ]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 12094 is [False, False, True, False, False, True]
Current timestep = 12095. State = [[0.24371947 0.23193096]]. Action = [[-0.00133333  0.09569544  0.         -0.3201337 ]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 12095 is [False, False, True, False, False, True]
Current timestep = 12096. State = [[0.24077246 0.2312652 ]]. Action = [[-0.04184068 -0.08911132  0.          0.8696923 ]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 12096 is [False, False, True, False, False, True]
Current timestep = 12097. State = [[0.23630755 0.22536622]]. Action = [[-0.07943932 -0.07952891  0.         -0.5407239 ]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 12097 is [False, False, True, False, False, True]
Current timestep = 12098. State = [[0.23385964 0.22213401]]. Action = [[-0.01623775 -0.02175461  0.          0.60360515]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 12098 is [False, False, True, False, False, True]
Current timestep = 12099. State = [[0.23466896 0.22381108]]. Action = [[0.07393134 0.04797142 0.         0.21279573]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 12099 is [False, False, True, False, False, True]
State prediction error at timestep 12099 is 0.012
Human Feedback received at timestep 12099 of None
Current timestep = 12100. State = [[0.23674005 0.22060473]]. Action = [[ 0.01247877 -0.08304612  0.          0.87684894]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 12100 is [False, False, True, False, False, True]
State prediction error at timestep 12100 is 0.012
Human Feedback received at timestep 12100 of None
Current timestep = 12101. State = [[0.23596478 0.21594545]]. Action = [[-0.04343382 -0.02919313  0.          0.0082984 ]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 12101 is [False, False, True, False, False, True]
Current timestep = 12102. State = [[0.23548672 0.21674171]]. Action = [[-0.0015717   0.04286382  0.         -0.78264135]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 12102 is [False, False, True, False, False, True]
State prediction error at timestep 12102 is 0.012
Human Feedback received at timestep 12102 of None
Current timestep = 12103. State = [[0.23720568 0.2223728 ]]. Action = [[ 0.05805749  0.0854476   0.         -0.9175377 ]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 12103 is [False, False, True, False, False, True]
State prediction error at timestep 12103 is 0.012
Human Feedback received at timestep 12103 of None
Current timestep = 12104. State = [[0.2378648  0.22526266]]. Action = [[-0.02657883 -0.00085014  0.          0.7348013 ]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 12104 is [False, False, True, False, False, True]
State prediction error at timestep 12104 is 0.012
Human Feedback received at timestep 12104 of None
Current timestep = 12105. State = [[0.23513657 0.2294865 ]]. Action = [[-0.03873577  0.0650289   0.         -0.5947474 ]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 12105 is [False, False, True, False, False, True]
State prediction error at timestep 12105 is 0.012
Human Feedback received at timestep 12105 of None
Current timestep = 12106. State = [[0.23717034 0.22752163]]. Action = [[ 0.0852014  -0.09538247  0.          0.05582058]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 12106 is [False, False, True, False, False, True]
Current timestep = 12107. State = [[0.24003537 0.2260184 ]]. Action = [[ 0.01682808  0.03520254  0.         -0.3530982 ]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 12107 is [False, False, True, False, False, True]
Current timestep = 12108. State = [[0.24257165 0.22537893]]. Action = [[ 0.05000979 -0.02022385  0.         -0.98675686]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 12108 is [False, False, True, False, False, True]
Current timestep = 12109. State = [[0.24504663 0.22089015]]. Action = [[ 0.02823823 -0.05682873  0.         -0.38028455]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 12109 is [False, False, True, False, False, True]
Current timestep = 12110. State = [[0.25002736 0.2126723 ]]. Action = [[ 0.08370603 -0.09071716  0.          0.12957299]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 12110 is [False, False, True, False, False, True]
Current timestep = 12111. State = [[0.25598386 0.20286925]]. Action = [[ 0.07013287 -0.07669015  0.         -0.9185578 ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 12111 is [False, False, True, False, False, True]
Current timestep = 12112. State = [[0.25729463 0.19772513]]. Action = [[-0.06866342  0.01443504  0.          0.44134116]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 12112 is [False, False, True, False, False, True]
Current timestep = 12113. State = [[0.25846043 0.19307588]]. Action = [[ 0.0444217  -0.05294735  0.         -0.45090044]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 12113 is [False, False, True, False, False, True]
Current timestep = 12114. State = [[0.25850517 0.18791066]]. Action = [[-0.06168951 -0.02538862  0.         -0.40757823]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 12114 is [False, False, True, False, False, True]
Current timestep = 12115. State = [[0.25521174 0.18513231]]. Action = [[-0.06666762 -0.01401474  0.          0.34761846]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 12115 is [False, False, True, False, False, True]
Current timestep = 12116. State = [[0.25457156 0.18574767]]. Action = [[ 0.05471555  0.02564303  0.         -0.9781712 ]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 12116 is [False, False, True, False, False, True]
Current timestep = 12117. State = [[0.2542285  0.18334542]]. Action = [[-0.05373345 -0.05530655  0.         -0.6082219 ]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 12117 is [False, False, True, False, False, True]
Current timestep = 12118. State = [[0.25042087 0.1841033 ]]. Action = [[-0.08639168  0.0431703   0.          0.43720865]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 12118 is [False, False, True, False, False, True]
Current timestep = 12119. State = [[0.24608508 0.18901926]]. Action = [[-0.07419668  0.04319514  0.         -0.8068855 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 12119 is [False, False, True, False, False, True]
Current timestep = 12120. State = [[0.2454302  0.19323431]]. Action = [[0.03628366 0.01190054 0.         0.82900286]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 12120 is [False, False, True, False, False, True]
Current timestep = 12121. State = [[0.24410051 0.19961146]]. Action = [[-0.05889934  0.07766915  0.          0.5258477 ]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 12121 is [False, False, True, False, False, True]
Current timestep = 12122. State = [[0.24484399 0.2004425 ]]. Action = [[ 0.0325468  -0.07444583  0.         -0.45939636]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 12122 is [False, False, True, False, False, True]
Current timestep = 12123. State = [[0.24620944 0.2019397 ]]. Action = [[-0.00753705  0.04916603  0.          0.5178652 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 12123 is [False, False, True, False, False, True]
Current timestep = 12124. State = [[0.24804404 0.20630316]]. Action = [[ 0.03650934  0.03372966  0.         -0.9321914 ]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 12124 is [False, False, True, False, False, True]
Current timestep = 12125. State = [[0.24618194 0.2135439 ]]. Action = [[-0.08478729  0.09507216  0.         -0.09662163]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 12125 is [False, False, True, False, False, True]
Current timestep = 12126. State = [[0.24561483 0.2173291 ]]. Action = [[ 0.05290189 -0.02448276  0.         -0.44996297]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 12126 is [False, False, True, False, False, True]
Current timestep = 12127. State = [[0.24518217 0.21852894]]. Action = [[-0.05071625  0.01140301  0.          0.71946776]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 12127 is [False, False, True, False, False, True]
Current timestep = 12128. State = [[0.24220553 0.21620467]]. Action = [[-0.05395422 -0.0775211   0.         -0.7774315 ]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 12128 is [False, False, True, False, False, True]
State prediction error at timestep 12128 is 0.012
Human Feedback received at timestep 12128 of None
Current timestep = 12129. State = [[0.2403052  0.21820487]]. Action = [[-0.03506702  0.06878351  0.         -0.27900392]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 12129 is [False, False, True, False, False, True]
Current timestep = 12130. State = [[0.2408274 0.2256164]]. Action = [[ 0.06385929  0.07522211  0.         -0.9582355 ]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 12130 is [False, False, True, False, False, True]
Current timestep = 12131. State = [[0.2445345 0.2337365]]. Action = [[ 0.08746993  0.08835305  0.         -0.8017627 ]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 12131 is [False, False, True, False, False, True]
State prediction error at timestep 12131 is 0.012
Human Feedback received at timestep 12131 of None
Current timestep = 12132. State = [[0.24833412 0.23239554]]. Action = [[ 0.06270692 -0.09290247  0.          0.2167027 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 12132 is [False, False, True, False, False, True]
Current timestep = 12133. State = [[0.25336185 0.22674277]]. Action = [[ 0.08085685 -0.03815696  0.          0.43013382]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 12133 is [False, False, True, False, False, True]
State prediction error at timestep 12133 is 0.012
Human Feedback received at timestep 12133 of None
Current timestep = 12134. State = [[0.25865713 0.22612835]]. Action = [[ 0.09177063  0.0551194   0.         -0.9896686 ]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 12134 is [False, False, True, False, False, True]
Current timestep = 12135. State = [[0.2611698  0.22354442]]. Action = [[-0.03194623 -0.03895891  0.         -0.05951309]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 12135 is [False, False, True, False, False, True]
Current timestep = 12136. State = [[0.2648282  0.21674837]]. Action = [[ 0.09506961 -0.07017889  0.          0.09167647]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 12136 is [False, False, True, False, False, True]
Current timestep = 12137. State = [[0.26901847 0.21181731]]. Action = [[ 0.06750149  0.00475178  0.         -0.4423529 ]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 12137 is [False, False, True, False, False, True]
Current timestep = 12138. State = [[0.27214244 0.20883487]]. Action = [[ 0.06852228  0.00218674  0.         -0.5037556 ]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 12138 is [False, False, True, False, False, True]
Current timestep = 12139. State = [[0.2728203  0.20270295]]. Action = [[-0.00768441 -0.06023879  0.          0.29501534]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 12139 is [False, False, True, False, False, True]
Current timestep = 12140. State = [[0.27088496 0.20261256]]. Action = [[-0.00963507  0.08698992  0.         -0.5656987 ]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 12140 is [False, False, True, False, False, True]
Current timestep = 12141. State = [[0.26972717 0.19904947]]. Action = [[ 0.01618241 -0.09185109  0.          0.95383215]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 12141 is [False, False, True, False, False, True]
Current timestep = 12142. State = [[0.27093786 0.19665891]]. Action = [[ 0.05565781  0.04343323  0.         -0.77071047]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 12142 is [False, False, True, False, False, True]
Current timestep = 12143. State = [[0.27157024 0.1990507 ]]. Action = [[0.02879416 0.05117001 0.         0.6484854 ]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 12143 is [False, False, True, False, False, True]
Current timestep = 12144. State = [[0.27336743 0.20153782]]. Action = [[ 0.08333207  0.03495749  0.         -0.55061626]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 12144 is [False, False, True, False, False, True]
Current timestep = 12145. State = [[0.27419966 0.20474355]]. Action = [[ 0.04439986  0.05859961  0.         -0.35272276]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 12145 is [False, False, True, False, False, True]
Current timestep = 12146. State = [[0.27609882 0.20253812]]. Action = [[ 0.08744202 -0.06069943  0.          0.16203415]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 12146 is [False, False, True, False, False, True]
Current timestep = 12147. State = [[0.2792375  0.19451614]]. Action = [[ 0.07888072 -0.0830501   0.         -0.26374245]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 12147 is [False, False, True, False, False, True]
Current timestep = 12148. State = [[0.2797964 0.1842541]]. Action = [[-0.09074133 -0.08272273  0.         -0.56305516]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 12148 is [False, False, True, False, False, True]
State prediction error at timestep 12148 is 0.012
Human Feedback received at timestep 12148 of None
Current timestep = 12149. State = [[0.27828145 0.17706642]]. Action = [[-0.00648538 -0.03538272  0.          0.33302867]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 12149 is [False, False, True, False, False, True]
Current timestep = 12150. State = [[0.27845815 0.17825672]]. Action = [[0.09350831 0.09287191 0.         0.7637241 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 12150 is [False, False, True, False, False, True]
Current timestep = 12151. State = [[0.28055674 0.18227561]]. Action = [[ 0.07866725  0.05412448  0.         -0.8404694 ]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 12151 is [False, False, True, False, False, True]
Current timestep = 12152. State = [[0.2782001  0.18690847]]. Action = [[-0.05390578  0.07651374  0.         -0.76099014]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 12152 is [False, False, True, False, False, True]
Current timestep = 12153. State = [[0.27097443 0.19256611]]. Action = [[-0.07577737  0.05396224  0.         -0.9308276 ]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 12153 is [False, False, True, False, False, True]
State prediction error at timestep 12153 is 0.012
Human Feedback received at timestep 12153 of None
Current timestep = 12154. State = [[0.26640865 0.19456755]]. Action = [[-0.01501241 -0.01992105  0.         -0.25783962]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 12154 is [False, False, True, False, False, True]
Current timestep = 12155. State = [[0.26452008 0.19586307]]. Action = [[ 0.00313631  0.01749776  0.         -0.7217568 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 12155 is [False, False, True, False, False, True]
Current timestep = 12156. State = [[0.26005864 0.19933777]]. Action = [[-0.08655247  0.04227299  0.         -0.7045438 ]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 12156 is [False, False, True, False, False, True]
State prediction error at timestep 12156 is 0.012
Human Feedback received at timestep 12156 of None
Current timestep = 12157. State = [[0.2533165 0.2055012]]. Action = [[-0.08630187  0.06118856  0.         -0.9758625 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 12157 is [False, False, True, False, False, True]
Current timestep = 12158. State = [[0.24854831 0.20712142]]. Action = [[-0.05458298 -0.05071604  0.         -0.36446428]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 12158 is [False, False, True, False, False, True]
Current timestep = 12159. State = [[0.24948116 0.20323688]]. Action = [[ 0.06961682 -0.08029727  0.         -0.9545725 ]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 12159 is [False, False, True, False, False, True]
State prediction error at timestep 12159 is 0.012
Human Feedback received at timestep 12159 of None
Current timestep = 12160. State = [[0.25351262 0.20503469]]. Action = [[ 0.09506326  0.09552775  0.         -0.98282015]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 12160 is [False, False, True, False, False, True]
Current timestep = 12161. State = [[0.25637782 0.20762418]]. Action = [[ 0.04886139 -0.00718865  0.          0.0402081 ]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 12161 is [False, False, True, False, False, True]
State prediction error at timestep 12161 is 0.012
Human Feedback received at timestep 12161 of None
Current timestep = 12162. State = [[0.2567948  0.21197721]]. Action = [[0.01150589 0.0842716  0.         0.9078741 ]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 12162 is [False, False, True, False, False, True]
Current timestep = 12163. State = [[0.25415158 0.21916991]]. Action = [[-0.02104332  0.0763833   0.         -0.6581706 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 12163 is [False, False, True, False, False, True]
Current timestep = 12164. State = [[0.24911512 0.22776227]]. Action = [[-0.05250169  0.09063032  0.         -0.0398339 ]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 12164 is [False, False, True, False, False, True]
Current timestep = 12165. State = [[0.24766114 0.23103262]]. Action = [[ 0.03703881 -0.02942495  0.          0.95660067]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 12165 is [False, False, True, False, False, True]
Current timestep = 12166. State = [[0.24996111 0.2297847 ]]. Action = [[ 0.06082944 -0.02726995  0.         -0.2888704 ]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 12166 is [False, False, True, False, False, True]
Current timestep = 12167. State = [[0.25330293 0.2317021 ]]. Action = [[ 0.08952942  0.05935813  0.         -0.79347515]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 12167 is [False, False, True, False, False, True]
Current timestep = 12168. State = [[0.25251648 0.23530783]]. Action = [[-0.06999505  0.0422025   0.         -0.9283512 ]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 12168 is [False, False, True, False, False, True]
Current timestep = 12169. State = [[0.24814434 0.23525542]]. Action = [[-0.08561777 -0.03767176  0.          0.4281597 ]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 12169 is [False, False, True, False, False, True]
Current timestep = 12170. State = [[0.24582851 0.23614044]]. Action = [[ 0.00275581  0.02748258  0.         -0.09374738]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 12170 is [False, False, True, False, False, True]
Current timestep = 12171. State = [[0.24144493 0.24051775]]. Action = [[-0.07278446  0.0526375   0.         -0.43762302]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 12171 is [False, False, True, False, False, True]
State prediction error at timestep 12171 is 0.012
Human Feedback received at timestep 12171 of None
Current timestep = 12172. State = [[0.23957613 0.24265468]]. Action = [[ 0.0587584  -0.01722185  0.         -0.74542725]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 12172 is [False, False, True, False, False, True]
Current timestep = 12173. State = [[0.2432201  0.23861605]]. Action = [[ 0.07590697 -0.07430287  0.         -0.43708795]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 12173 is [False, False, True, False, False, True]
Current timestep = 12174. State = [[0.24451913 0.23528817]]. Action = [[-0.00516937 -0.00123446  0.          0.2433697 ]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 12174 is [False, False, True, False, False, True]
Current timestep = 12175. State = [[0.24730098 0.23000355]]. Action = [[ 0.06722531 -0.07641597  0.         -0.9458929 ]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 12175 is [False, False, True, False, False, True]
Current timestep = 12176. State = [[0.2519371  0.22578846]]. Action = [[ 0.07586762  0.00398488  0.         -0.7780518 ]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 12176 is [False, False, True, False, False, True]
Current timestep = 12177. State = [[0.25640422 0.2218893 ]]. Action = [[ 0.08579927 -0.03051182  0.          0.20610988]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 12177 is [False, False, True, False, False, True]
Current timestep = 12178. State = [[0.25658956 0.21856691]]. Action = [[-0.05881929  0.00437704  0.          0.76715875]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 12178 is [False, False, True, False, False, True]
Current timestep = 12179. State = [[0.25298163 0.21911825]]. Action = [[-0.03872203  0.03791145  0.         -0.96966666]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 12179 is [False, False, True, False, False, True]
State prediction error at timestep 12179 is 0.012
Human Feedback received at timestep 12179 of None
Current timestep = 12180. State = [[0.2485535 0.221836 ]]. Action = [[-0.05259784  0.03806252  0.          0.00746691]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 12180 is [False, False, True, False, False, True]
Current timestep = 12181. State = [[0.24907783 0.21849047]]. Action = [[ 0.06515593 -0.09094092  0.         -0.437567  ]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 12181 is [False, False, True, False, False, True]
Current timestep = 12182. State = [[0.25321382 0.2120632 ]]. Action = [[ 0.06423979 -0.05064697  0.         -0.4832427 ]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 12182 is [False, False, True, False, False, True]
Current timestep = 12183. State = [[0.25378504 0.21128538]]. Action = [[-0.00557267  0.04971723  0.         -0.22109991]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 12183 is [False, False, True, False, False, True]
State prediction error at timestep 12183 is 0.012
Human Feedback received at timestep 12183 of None
Current timestep = 12184. State = [[0.2512292  0.20948592]]. Action = [[-0.04949194 -0.04482904  0.         -0.5227576 ]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 12184 is [False, False, True, False, False, True]
Current timestep = 12185. State = [[0.25179714 0.20752788]]. Action = [[ 0.0835487   0.00107485  0.         -0.98866546]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 12185 is [False, False, True, False, False, True]
Current timestep = 12186. State = [[0.2555385  0.20284371]]. Action = [[ 0.06294819 -0.06709138  0.         -0.44915724]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 12186 is [False, False, True, False, False, True]
Current timestep = 12187. State = [[0.25417662 0.20208795]]. Action = [[-0.0842794   0.05846507  0.         -0.8633213 ]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 12187 is [False, False, True, False, False, True]
State prediction error at timestep 12187 is 0.012
Human Feedback received at timestep 12187 of None
Current timestep = 12188. State = [[0.2497565 0.1987064]]. Action = [[-0.07095867 -0.09137873  0.         -0.7501576 ]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 12188 is [False, False, True, False, False, True]
Current timestep = 12189. State = [[0.24871904 0.19795007]]. Action = [[ 0.03438181  0.05449875  0.         -0.2206896 ]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 12189 is [False, False, True, False, False, True]
Current timestep = 12190. State = [[0.24926625 0.20064169]]. Action = [[ 0.00730021  0.01979768  0.         -0.9545882 ]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 12190 is [False, False, True, False, False, True]
Current timestep = 12191. State = [[0.25018775 0.19777834]]. Action = [[ 0.01396322 -0.07380123  0.         -0.37787312]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 12191 is [False, False, True, False, False, True]
Current timestep = 12192. State = [[0.25401062 0.19218357]]. Action = [[ 0.06570771 -0.05310164  0.          0.93001163]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 12192 is [False, False, True, False, False, True]
Current timestep = 12193. State = [[0.25812683 0.18701944]]. Action = [[ 0.05002601 -0.03719829  0.          0.2229085 ]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 12193 is [False, False, True, False, False, True]
State prediction error at timestep 12193 is 0.012
Human Feedback received at timestep 12193 of None
Current timestep = 12194. State = [[0.2590691  0.18001573]]. Action = [[-0.07670428 -0.07075715  0.         -0.34702325]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 12194 is [False, False, True, False, False, True]
Current timestep = 12195. State = [[0.25679666 0.17348397]]. Action = [[-0.06856933 -0.05240339  0.         -0.68031645]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 12195 is [False, False, True, False, False, True]
Current timestep = 12196. State = [[0.2555917  0.16960908]]. Action = [[-0.03606392 -0.01926848  0.         -0.8591624 ]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 12196 is [False, False, True, False, False, True]
State prediction error at timestep 12196 is 0.012
Human Feedback received at timestep 12196 of None
Current timestep = 12197. State = [[0.25285286 0.16640633]]. Action = [[-0.09412123 -0.03423278  0.         -0.51358736]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 12197 is [False, False, True, False, False, True]
State prediction error at timestep 12197 is 0.012
Human Feedback received at timestep 12197 of None
Current timestep = 12198. State = [[0.24956767 0.16893841]]. Action = [[-0.08063293  0.07403097  0.         -0.8169179 ]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 12198 is [False, False, True, False, False, True]
Current timestep = 12199. State = [[0.2503521  0.17113727]]. Action = [[ 0.07033009 -0.02520929  0.          0.49219155]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 12199 is [False, False, True, False, False, True]
Current timestep = 12200. State = [[0.25301442 0.1659028 ]]. Action = [[-0.00697454 -0.09590504  0.         -0.8683435 ]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 12200 is [False, False, True, False, False, True]
State prediction error at timestep 12200 is 0.012
Human Feedback received at timestep 12200 of None
Current timestep = 12201. State = [[0.2557743 0.1661589]]. Action = [[ 0.02904046  0.08284765  0.         -0.4903376 ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 12201 is [False, False, True, False, False, True]
State prediction error at timestep 12201 is 0.012
Human Feedback received at timestep 12201 of None
Current timestep = 12202. State = [[0.2577204  0.17382592]]. Action = [[ 0.02403665  0.09362187  0.         -0.13944495]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 12202 is [False, False, True, False, False, True]
Current timestep = 12203. State = [[0.25790837 0.17524911]]. Action = [[-0.00779504 -0.05470798  0.         -0.13059634]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 12203 is [False, False, True, False, False, True]
Current timestep = 12204. State = [[0.25949368 0.1786353 ]]. Action = [[ 0.07165509  0.08996511  0.         -0.49989164]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 12204 is [False, False, True, False, False, True]
Current timestep = 12205. State = [[0.26305985 0.18655592]]. Action = [[ 0.09571893  0.08446825  0.         -0.8656347 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 12205 is [False, False, True, False, False, True]
Current timestep = 12206. State = [[0.2645246  0.19137776]]. Action = [[ 0.04801328  0.02371588  0.         -0.7027426 ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 12206 is [False, False, True, False, False, True]
Current timestep = 12207. State = [[0.26307333 0.19103572]]. Action = [[-0.07320154 -0.02789517  0.          0.6596055 ]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 12207 is [False, False, True, False, False, True]
Current timestep = 12208. State = [[0.26040465 0.19360784]]. Action = [[-0.01090521  0.05873693  0.          0.36386728]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 12208 is [False, False, True, False, False, True]
State prediction error at timestep 12208 is 0.012
Human Feedback received at timestep 12208 of None
Current timestep = 12209. State = [[0.2612759  0.19751452]]. Action = [[ 0.09281225  0.02394559  0.         -0.42069578]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 12209 is [False, False, True, False, False, True]
Current timestep = 12210. State = [[0.25983512 0.20177186]]. Action = [[-0.06025114  0.06216209  0.         -0.45943916]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 12210 is [False, False, True, False, False, True]
State prediction error at timestep 12210 is 0.012
Human Feedback received at timestep 12210 of None
Current timestep = 12211. State = [[0.25943395 0.20097663]]. Action = [[ 0.06917741 -0.06761076  0.         -0.91797704]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 12211 is [False, False, True, False, False, True]
Current timestep = 12212. State = [[0.25882187 0.19910422]]. Action = [[-0.01850636  0.00739276  0.          0.7543049 ]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 12212 is [False, False, True, False, False, True]
Current timestep = 12213. State = [[0.2558128  0.19555807]]. Action = [[-0.04532079 -0.06497387  0.          0.59030235]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 12213 is [False, False, True, False, False, True]
Current timestep = 12214. State = [[0.2552786  0.18937887]]. Action = [[ 5.3630769e-04 -6.9210052e-02  0.0000000e+00 -7.0925874e-01]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 12214 is [False, False, True, False, False, True]
Current timestep = 12215. State = [[0.25746647 0.18605784]]. Action = [[0.04345506 0.00377864 0.         0.30591464]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 12215 is [False, False, True, False, False, True]
State prediction error at timestep 12215 is 0.012
Human Feedback received at timestep 12215 of None
Current timestep = 12216. State = [[0.25927892 0.17957453]]. Action = [[ 0.01354058 -0.0983564   0.         -0.07117057]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 12216 is [False, False, True, False, False, True]
Current timestep = 12217. State = [[0.25970477 0.1785469 ]]. Action = [[-0.00389384  0.08087633  0.         -0.95611495]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 12217 is [False, False, True, False, False, True]
State prediction error at timestep 12217 is 0.012
Human Feedback received at timestep 12217 of None
Current timestep = 12218. State = [[0.25995073 0.180308  ]]. Action = [[ 0.02052502  0.0036305   0.         -0.76818985]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 12218 is [False, False, True, False, False, True]
Current timestep = 12219. State = [[0.25850457 0.18081324]]. Action = [[-0.03102442  0.01118667  0.         -0.63044673]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 12219 is [False, False, True, False, False, True]
Current timestep = 12220. State = [[0.2579784  0.18508384]]. Action = [[ 0.02546316  0.07537299  0.         -0.9868836 ]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 12220 is [False, False, True, False, False, True]
Current timestep = 12221. State = [[0.25519595 0.18920678]]. Action = [[-0.08788165  0.02650831  0.         -0.93133307]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 12221 is [False, False, True, False, False, True]
Current timestep = 12222. State = [[0.25509825 0.1885164 ]]. Action = [[ 0.07547317 -0.0545336   0.         -0.40479505]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 12222 is [False, False, True, False, False, True]
Current timestep = 12223. State = [[0.25556993 0.18699916]]. Action = [[-2.0261422e-02  1.5799701e-04  0.0000000e+00 -8.2751089e-01]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 12223 is [False, False, True, False, False, True]
State prediction error at timestep 12223 is 0.012
Human Feedback received at timestep 12223 of None
Current timestep = 12224. State = [[0.25659332 0.1894497 ]]. Action = [[0.09441961 0.04739744 0.         0.20407212]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 12224 is [False, False, True, False, False, True]
Current timestep = 12225. State = [[0.25551453 0.19311948]]. Action = [[-0.04605001  0.04350502  0.         -0.74380934]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 12225 is [False, False, True, False, False, True]
Current timestep = 12226. State = [[0.2530255  0.19666947]]. Action = [[-0.00778048  0.02940948  0.         -0.22312337]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 12226 is [False, False, True, False, False, True]
State prediction error at timestep 12226 is 0.012
Human Feedback received at timestep 12226 of None
Current timestep = 12227. State = [[0.25390643 0.20155415]]. Action = [[ 0.09225803  0.05904486  0.         -0.17444617]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 12227 is [False, False, True, False, False, True]
Current timestep = 12228. State = [[0.25541398 0.20774946]]. Action = [[ 0.09033538  0.05030181  0.         -0.86796916]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 12228 is [False, False, True, False, False, True]
State prediction error at timestep 12228 is 0.012
Human Feedback received at timestep 12228 of None
Current timestep = 12229. State = [[0.2554814  0.21372338]]. Action = [[ 0.01090693  0.09489907  0.         -0.3933667 ]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 12229 is [False, False, True, False, False, True]
Current timestep = 12230. State = [[0.25548595 0.21453501]]. Action = [[ 0.02155749 -0.01660428  0.         -0.8508271 ]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 12230 is [False, False, True, False, False, True]
Current timestep = 12231. State = [[0.2538086  0.21258812]]. Action = [[-0.02754803 -0.02535811  0.         -0.2931279 ]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 12231 is [False, False, True, False, False, True]
State prediction error at timestep 12231 is 0.012
Human Feedback received at timestep 12231 of None
Current timestep = 12232. State = [[0.2540106  0.20741968]]. Action = [[ 0.0403691  -0.08095797  0.         -0.8159995 ]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 12232 is [False, False, True, False, False, True]
Current timestep = 12233. State = [[0.25623566 0.20628315]]. Action = [[0.08726007 0.03792808 0.         0.7280537 ]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 12233 is [False, False, True, False, False, True]
State prediction error at timestep 12233 is 0.012
Human Feedback received at timestep 12233 of None
Current timestep = 12234. State = [[0.2570618  0.21074636]]. Action = [[0.09454458 0.07246933 0.         0.180053  ]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 12234 is [False, False, True, False, False, True]
Current timestep = 12235. State = [[0.2576286  0.21370633]]. Action = [[0.09170642 0.04588283 0.         0.6587012 ]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 12235 is [False, False, True, False, False, True]
Current timestep = 12236. State = [[0.25483048 0.21722871]]. Action = [[-0.07136372  0.07584972  0.         -0.732278  ]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 12236 is [False, False, True, False, False, True]
Current timestep = 12237. State = [[0.250189   0.21951339]]. Action = [[-0.02340577 -0.00699414  0.         -0.8117361 ]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 12237 is [False, False, True, False, False, True]
Current timestep = 12238. State = [[0.25076824 0.21663894]]. Action = [[ 0.06590881 -0.05945516  0.          0.01927173]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 12238 is [False, False, True, False, False, True]
State prediction error at timestep 12238 is 0.012
Human Feedback received at timestep 12238 of None
Current timestep = 12239. State = [[0.25121585 0.20998386]]. Action = [[-0.0640824  -0.09551354  0.         -0.9298594 ]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 12239 is [False, False, True, False, False, True]
Current timestep = 12240. State = [[0.2528457  0.20344165]]. Action = [[ 0.08030345 -0.05151615  0.         -0.327689  ]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 12240 is [False, False, True, False, False, True]
State prediction error at timestep 12240 is 0.012
Human Feedback received at timestep 12240 of None
Current timestep = 12241. State = [[0.25554287 0.2034536 ]]. Action = [[0.05341182 0.06393576 0.         0.03718567]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 12241 is [False, False, True, False, False, True]
State prediction error at timestep 12241 is 0.012
Human Feedback received at timestep 12241 of None
Current timestep = 12242. State = [[0.2556763  0.20504083]]. Action = [[ 0.0078451   0.01846095  0.         -0.75554395]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 12242 is [False, False, True, False, False, True]
Current timestep = 12243. State = [[0.2559348  0.20693244]]. Action = [[ 0.07028199  0.02569682  0.         -0.7011799 ]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 12243 is [False, False, True, False, False, True]
Current timestep = 12244. State = [[0.25611964 0.20583789]]. Action = [[ 0.03025804 -0.04989297  0.         -0.3604653 ]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 12244 is [False, False, True, False, False, True]
Current timestep = 12245. State = [[0.25507042 0.20041338]]. Action = [[-0.02465619 -0.07827185  0.         -0.54471743]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 12245 is [False, False, True, False, False, True]
Current timestep = 12246. State = [[0.25696287 0.19212027]]. Action = [[ 0.06703097 -0.08728343  0.         -0.32678932]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 12246 is [False, False, True, False, False, True]
Current timestep = 12247. State = [[0.26039037 0.18327793]]. Action = [[ 0.04547847 -0.06984816  0.          0.8276479 ]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 12247 is [False, False, True, False, False, True]
Current timestep = 12248. State = [[0.26068884 0.18183556]]. Action = [[-0.0237004   0.07392745  0.         -0.98591006]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 12248 is [False, False, True, False, False, True]
Current timestep = 12249. State = [[0.2623758 0.1798809]]. Action = [[ 0.08315214 -0.05618333  0.          0.23598027]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 12249 is [False, False, True, False, False, True]
Current timestep = 12250. State = [[0.26233226 0.17722546]]. Action = [[-0.0237117  -0.00487923  0.         -0.9953223 ]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 12250 is [False, False, True, False, False, True]
State prediction error at timestep 12250 is 0.012
Human Feedback received at timestep 12250 of None
Current timestep = 12251. State = [[0.2583068  0.17563583]]. Action = [[-0.07318793 -0.00538766  0.         -0.89543176]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 12251 is [False, False, True, False, False, True]
State prediction error at timestep 12251 is 0.012
Human Feedback received at timestep 12251 of None
Current timestep = 12252. State = [[0.2546205  0.17254113]]. Action = [[-0.05556374 -0.04827645  0.          0.6443176 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 12252 is [False, False, True, False, False, True]
Current timestep = 12253. State = [[0.25080127 0.1674501 ]]. Action = [[-0.09477109 -0.06621601  0.         -0.8595932 ]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 12253 is [False, False, True, False, False, True]
State prediction error at timestep 12253 is 0.012
Human Feedback received at timestep 12253 of None
Current timestep = 12254. State = [[0.24724343 0.16168413]]. Action = [[-0.09361456 -0.07211455  0.         -0.6890703 ]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 12254 is [False, False, True, False, False, True]
State prediction error at timestep 12254 is 0.012
Human Feedback received at timestep 12254 of None
Current timestep = 12255. State = [[0.24644776 0.16204244]]. Action = [[ 0.04745165  0.04964408  0.         -0.8535441 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 12255 is [False, False, True, False, False, True]
Current timestep = 12256. State = [[0.24867517 0.16741075]]. Action = [[ 0.04228052  0.05918213  0.         -0.68568796]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 12256 is [False, False, True, False, False, True]
Current timestep = 12257. State = [[0.24904314 0.16623402]]. Action = [[-0.0871494  -0.07103406  0.         -0.9606107 ]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 12257 is [False, False, True, False, False, True]
Current timestep = 12258. State = [[0.24976806 0.1666906 ]]. Action = [[ 0.09803338  0.04192809  0.         -0.80503327]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 12258 is [False, False, True, False, False, True]
Current timestep = 12259. State = [[0.24915898 0.17370981]]. Action = [[-0.04196572  0.09511686  0.         -0.87753016]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 12259 is [False, False, True, False, False, True]
Current timestep = 12260. State = [[0.24917987 0.18345161]]. Action = [[ 0.08320922  0.09400553  0.         -0.06930131]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 12260 is [False, False, True, False, False, True]
Current timestep = 12261. State = [[0.24997297 0.18890105]]. Action = [[ 0.02000405  0.01526233  0.         -0.24138641]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 12261 is [False, False, True, False, False, True]
Current timestep = 12262. State = [[0.24775466 0.195187  ]]. Action = [[-0.03170701  0.08298815  0.          0.6110804 ]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 12262 is [False, False, True, False, False, True]
State prediction error at timestep 12262 is 0.012
Human Feedback received at timestep 12262 of None
Current timestep = 12263. State = [[0.24563798 0.2031375 ]]. Action = [[ 0.00572072  0.06842387  0.         -0.416476  ]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 12263 is [False, False, True, False, False, True]
Current timestep = 12264. State = [[0.24562487 0.20666751]]. Action = [[ 0.03673477 -0.00873315  0.          0.02275372]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 12264 is [False, False, True, False, False, True]
Current timestep = 12265. State = [[0.24437925 0.20527121]]. Action = [[-0.05208953 -0.04152197  0.         -0.32719302]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 12265 is [False, False, True, False, False, True]
Current timestep = 12266. State = [[0.23999935 0.20817444]]. Action = [[-0.06430121  0.06399987  0.          0.07226336]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 12266 is [False, False, True, False, False, True]
Current timestep = 12267. State = [[0.2376783  0.21643698]]. Action = [[ 0.07517789  0.0894881   0.         -0.6109507 ]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 12267 is [False, False, True, False, False, True]
Current timestep = 12268. State = [[0.23897284 0.22329783]]. Action = [[0.06166781 0.05321623 0.         0.24374676]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 12268 is [False, False, True, False, False, True]
Current timestep = 12269. State = [[0.23983069 0.22186187]]. Action = [[ 0.0257602  -0.07243608  0.          0.33312595]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 12269 is [False, False, True, False, False, True]
Current timestep = 12270. State = [[0.2365406  0.22171566]]. Action = [[-0.09304058  0.04148846  0.         -0.33297282]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 12270 is [False, False, True, False, False, True]
Current timestep = 12271. State = [[0.2344991  0.21938328]]. Action = [[ 0.00616296 -0.07821737  0.          0.7236618 ]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 12271 is [False, False, True, False, False, True]
Current timestep = 12272. State = [[0.23080815 0.22197175]]. Action = [[-0.08374979  0.09358411  0.         -0.04453617]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 12272 is [False, False, True, False, False, True]
Current timestep = 12273. State = [[0.22823407 0.22868142]]. Action = [[ 0.0238416   0.04949304  0.         -0.92909425]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 12273 is [False, False, True, False, False, True]
Current timestep = 12274. State = [[0.23069674 0.22919667]]. Action = [[ 0.06567749 -0.0417469   0.          0.42978692]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 12274 is [False, False, True, False, False, True]
State prediction error at timestep 12274 is 0.012
Human Feedback received at timestep 12274 of None
Current timestep = 12275. State = [[0.23579323 0.22454487]]. Action = [[ 0.09152723 -0.05757331  0.          0.70850134]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 12275 is [False, False, True, False, False, True]
Current timestep = 12276. State = [[0.24035403 0.2223601 ]]. Action = [[ 0.07363588  0.02892794  0.         -0.13087988]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 12276 is [False, False, True, False, False, True]
Current timestep = 12277. State = [[0.24175139 0.21790345]]. Action = [[-0.06789523 -0.05925237  0.         -0.38495624]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 12277 is [False, False, True, False, False, True]
Current timestep = 12278. State = [[0.2425329  0.21796522]]. Action = [[ 0.07805248  0.07237905  0.         -0.57133853]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 12278 is [False, False, True, False, False, True]
State prediction error at timestep 12278 is 0.012
Human Feedback received at timestep 12278 of None
Current timestep = 12279. State = [[0.24252546 0.22244215]]. Action = [[ 0.02007303  0.07178707  0.         -0.2921918 ]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 12279 is [False, False, True, False, False, True]
Current timestep = 12280. State = [[0.24222164 0.22847924]]. Action = [[ 0.00826705  0.09915722  0.         -0.27075422]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 12280 is [False, False, True, False, False, True]
State prediction error at timestep 12280 is 0.012
Human Feedback received at timestep 12280 of None
Current timestep = 12281. State = [[0.24192809 0.2280247 ]]. Action = [[ 0.00799837 -0.04864236  0.          0.06183207]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 12281 is [False, False, True, False, False, True]
Current timestep = 12282. State = [[0.24187683 0.22650824]]. Action = [[ 0.0254884   0.00977776  0.         -0.3794273 ]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 12282 is [False, False, True, False, False, True]
Current timestep = 12283. State = [[0.24182509 0.22854084]]. Action = [[0.01576312 0.06316883 0.         0.29395866]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 12283 is [False, False, True, False, False, True]
Current timestep = 12284. State = [[0.24099512 0.22553349]]. Action = [[-0.04782999 -0.07655421  0.         -0.6975181 ]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 12284 is [False, False, True, False, False, True]
Current timestep = 12285. State = [[0.2393319  0.22697398]]. Action = [[0.05070891 0.08649934 0.         0.48161912]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 12285 is [False, False, True, False, False, True]
Current timestep = 12286. State = [[0.23929964 0.22937827]]. Action = [[ 0.04201949 -0.00504078  0.         -0.9828564 ]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 12286 is [False, False, True, False, False, True]
Current timestep = 12287. State = [[0.23876785 0.23251276]]. Action = [[-0.01476187  0.07799316  0.         -0.52801746]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 12287 is [False, False, True, False, False, True]
Current timestep = 12288. State = [[0.23645912 0.2301323 ]]. Action = [[-0.02878939 -0.08668772  0.          0.8722358 ]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 12288 is [False, False, True, False, False, True]
Current timestep = 12289. State = [[0.23346795 0.2322043 ]]. Action = [[-0.03292391  0.09650486  0.          0.74989414]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 12289 is [False, False, True, False, False, True]
State prediction error at timestep 12289 is 0.012
Human Feedback received at timestep 12289 of None
Current timestep = 12290. State = [[0.23040295 0.23267315]]. Action = [[-0.02415709 -0.0609394   0.         -0.09743869]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 12290 is [False, False, True, False, False, True]
Current timestep = 12291. State = [[0.23020361 0.22923118]]. Action = [[ 0.00758137 -0.0419924   0.         -0.6434931 ]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 12291 is [False, False, True, False, False, True]
Current timestep = 12292. State = [[0.22866309 0.2253973 ]]. Action = [[-0.06324631 -0.04707011  0.         -0.85940397]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 12292 is [False, False, True, False, False, True]
Current timestep = 12293. State = [[0.22594795 0.21957251]]. Action = [[-0.07017384 -0.08980489  0.         -0.6002176 ]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 12293 is [False, False, True, False, False, True]
Current timestep = 12294. State = [[0.22586767 0.21510476]]. Action = [[-0.02270091 -0.03535053  0.         -0.68927616]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 12294 is [False, False, True, False, False, True]
Current timestep = 12295. State = [[0.22826204 0.21199308]]. Action = [[ 0.01312044 -0.03385504  0.         -0.3329959 ]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 12295 is [False, False, True, False, False, True]
Current timestep = 12296. State = [[0.22855426 0.21041483]]. Action = [[-0.04725956 -0.00440916  0.         -0.9510439 ]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 12296 is [False, False, True, False, False, True]
Current timestep = 12297. State = [[0.22875224 0.21462525]]. Action = [[ 0.00425829  0.081742    0.         -0.72808933]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 12297 is [False, False, True, False, False, True]
Current timestep = 12298. State = [[0.22858772 0.21473743]]. Action = [[-0.0343978  -0.06272487  0.         -0.92944   ]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 12298 is [False, False, True, False, False, True]
State prediction error at timestep 12298 is 0.012
Human Feedback received at timestep 12298 of None
Current timestep = 12299. State = [[0.22955024 0.21400885]]. Action = [[ 0.00237526  0.00846549  0.         -0.9555943 ]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 12299 is [False, False, True, False, False, True]
Current timestep = 12300. State = [[0.22940521 0.21240824]]. Action = [[-0.04231077 -0.04590195  0.         -0.9266676 ]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 12300 is [False, False, True, False, False, True]
Current timestep = 12301. State = [[0.23112033 0.21193334]]. Action = [[ 0.03603757  0.00762063  0.         -0.4020803 ]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 12301 is [False, False, True, False, False, True]
State prediction error at timestep 12301 is 0.012
Human Feedback received at timestep 12301 of None
Current timestep = 12302. State = [[0.23493741 0.20799725]]. Action = [[ 0.03494395 -0.07948759  0.         -0.22856188]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 12302 is [False, False, True, False, False, True]
Current timestep = 12303. State = [[0.23917449 0.20905007]]. Action = [[ 0.06907351  0.09024177  0.         -0.42192733]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 12303 is [False, False, True, False, False, True]
Current timestep = 12304. State = [[0.24166085 0.21623205]]. Action = [[0.04324127 0.09732165 0.         0.64230967]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 12304 is [False, False, True, False, False, True]
Current timestep = 12305. State = [[0.24043171 0.22430392]]. Action = [[-0.00670731  0.08907913  0.          0.7675613 ]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 12305 is [False, False, True, False, False, True]
State prediction error at timestep 12305 is 0.012
Human Feedback received at timestep 12305 of None
Current timestep = 12306. State = [[0.2370104 0.2330458]]. Action = [[-0.02145221  0.08986659  0.          0.34256947]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 12306 is [False, False, True, False, False, True]
State prediction error at timestep 12306 is 0.012
Human Feedback received at timestep 12306 of None
Current timestep = 12307. State = [[0.23634219 0.23437998]]. Action = [[ 0.03905261 -0.06037098  0.         -0.48255503]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 12307 is [False, False, True, False, False, True]
State prediction error at timestep 12307 is 0.012
Human Feedback received at timestep 12307 of None
Current timestep = 12308. State = [[0.24004386 0.22946961]]. Action = [[ 0.08159801 -0.06642479  0.         -0.55940074]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 12308 is [False, False, True, False, False, True]
Current timestep = 12309. State = [[0.24231642 0.22746046]]. Action = [[ 0.02852475  0.02488116  0.         -0.9579532 ]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 12309 is [False, False, True, False, False, True]
Current timestep = 12310. State = [[0.244679   0.22958344]]. Action = [[0.08301147 0.05387295 0.         0.4508145 ]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 12310 is [False, False, True, False, False, True]
Current timestep = 12311. State = [[0.24745461 0.22712123]]. Action = [[ 0.0720251  -0.04963298  0.         -0.24911237]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 12311 is [False, False, True, False, False, True]
Current timestep = 12312. State = [[0.2493451  0.22444671]]. Action = [[0.05296522 0.0130541  0.         0.25285852]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 12312 is [False, False, True, False, False, True]
Current timestep = 12313. State = [[0.24952987 0.22162245]]. Action = [[ 0.01597551 -0.07439409  0.         -0.10550237]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 12313 is [False, False, True, False, False, True]
Current timestep = 12314. State = [[0.25074723 0.21979201]]. Action = [[0.0722725  0.01662798 0.         0.56347966]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 12314 is [False, False, True, False, False, True]
Current timestep = 12315. State = [[0.25110057 0.22300357]]. Action = [[ 0.08320523  0.05236401  0.         -0.5966491 ]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 12315 is [False, False, True, False, False, True]
Current timestep = 12316. State = [[0.25107947 0.22675447]]. Action = [[0.08668838 0.03969932 0.         0.5668011 ]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 12316 is [False, False, True, False, False, True]
State prediction error at timestep 12316 is 0.012
Human Feedback received at timestep 12316 of None
Current timestep = 12317. State = [[0.24995998 0.2258154 ]]. Action = [[-0.07331101 -0.02744894  0.          0.44663405]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 12317 is [False, False, True, False, False, True]
Current timestep = 12318. State = [[0.24814962 0.22613668]]. Action = [[ 0.02586908  0.02986329  0.         -0.30469584]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 12318 is [False, False, True, False, False, True]
Current timestep = 12319. State = [[0.24873403 0.22294043]]. Action = [[ 0.05532663 -0.09644433  0.         -0.39179564]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 12319 is [False, False, True, False, False, True]
Current timestep = 12320. State = [[0.25103018 0.21943705]]. Action = [[ 0.06859051 -0.0188413   0.         -0.6771041 ]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 12320 is [False, False, True, False, False, True]
Current timestep = 12321. State = [[0.2507894  0.21464665]]. Action = [[-0.00742076 -0.07725038  0.         -0.12424183]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 12321 is [False, False, True, False, False, True]
Current timestep = 12322. State = [[0.24908343 0.20740338]]. Action = [[-0.0303133  -0.06648383  0.          0.0609107 ]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 12322 is [False, False, True, False, False, True]
Current timestep = 12323. State = [[0.24991985 0.2021985 ]]. Action = [[ 0.0393262  -0.02657081  0.         -0.56087565]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 12323 is [False, False, True, False, False, True]
Current timestep = 12324. State = [[0.25415516 0.19665295]]. Action = [[ 0.08135851 -0.04736936  0.         -0.5792876 ]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 12324 is [False, False, True, False, False, True]
Current timestep = 12325. State = [[0.2553668  0.19519073]]. Action = [[-0.02481916  0.04932047  0.          0.06837976]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 12325 is [False, False, True, False, False, True]
State prediction error at timestep 12325 is 0.012
Human Feedback received at timestep 12325 of None
Current timestep = 12326. State = [[0.25691724 0.19231828]]. Action = [[ 0.05838501 -0.06797308  0.         -0.00155932]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 12326 is [False, False, True, False, False, True]
Current timestep = 12327. State = [[0.25763574 0.19060192]]. Action = [[-0.00264045  0.03092486  0.         -0.7505769 ]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 12327 is [False, False, True, False, False, True]
State prediction error at timestep 12327 is 0.012
Human Feedback received at timestep 12327 of None
Current timestep = 12328. State = [[0.25868973 0.19163433]]. Action = [[ 0.09243376  0.00543394  0.         -0.34239244]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 12328 is [False, False, True, False, False, True]
Current timestep = 12329. State = [[0.260616   0.19278327]]. Action = [[ 0.07051276  0.00696163  0.         -0.8003933 ]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 12329 is [False, False, True, False, False, True]
State prediction error at timestep 12329 is 0.012
Human Feedback received at timestep 12329 of None
Current timestep = 12330. State = [[0.2606087  0.18930493]]. Action = [[-0.00290423 -0.07945415  0.          0.7300569 ]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 12330 is [False, False, True, False, False, True]
Current timestep = 12331. State = [[0.26131633 0.18761475]]. Action = [[ 0.0901944   0.02994121  0.         -0.00265396]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 12331 is [False, False, True, False, False, True]
Current timestep = 12332. State = [[0.26264352 0.18792062]]. Action = [[ 0.05973209 -0.02219619  0.          0.04348266]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 12332 is [False, False, True, False, False, True]
Current timestep = 12333. State = [[0.2628845  0.18894383]]. Action = [[ 0.00635028  0.04356932  0.         -0.8408751 ]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 12333 is [False, False, True, False, False, True]
Current timestep = 12334. State = [[0.2627851  0.18692221]]. Action = [[ 0.01441535 -0.06063783  0.         -0.9615738 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 12334 is [False, False, True, False, False, True]
State prediction error at timestep 12334 is 0.012
Human Feedback received at timestep 12334 of None
Current timestep = 12335. State = [[0.2649703  0.18203911]]. Action = [[ 0.08049317 -0.05471081  0.         -0.68211883]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 12335 is [False, False, True, False, False, True]
Current timestep = 12336. State = [[0.26498085 0.18160766]]. Action = [[-0.02108718  0.03619268  0.         -0.9348425 ]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 12336 is [False, False, True, False, False, True]
Current timestep = 12337. State = [[0.2662544  0.17755464]]. Action = [[ 0.06626708 -0.09157442  0.         -0.46019065]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 12337 is [False, False, True, False, False, True]
Current timestep = 12338. State = [[0.26530463 0.17349146]]. Action = [[-0.07281612 -0.00791197  0.          0.40381837]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 12338 is [False, False, True, False, False, True]
State prediction error at timestep 12338 is 0.012
Human Feedback received at timestep 12338 of None
Current timestep = 12339. State = [[0.26136348 0.17112686]]. Action = [[-0.05602471 -0.02294542  0.         -0.83019257]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 12339 is [False, False, True, False, False, True]
Current timestep = 12340. State = [[0.2573907  0.17116275]]. Action = [[-0.06879927  0.01985738  0.         -0.9245273 ]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 12340 is [False, False, True, False, False, True]
Current timestep = 12341. State = [[0.25613666 0.17095938]]. Action = [[-0.00338236 -0.02007893  0.          0.31115305]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 12341 is [False, False, True, False, False, True]
Current timestep = 12342. State = [[0.25426587 0.16713353]]. Action = [[-0.07261711 -0.06453223  0.         -0.38410807]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 12342 is [False, False, True, False, False, True]
State prediction error at timestep 12342 is 0.012
Human Feedback received at timestep 12342 of None
Current timestep = 12343. State = [[0.2539663  0.16655427]]. Action = [[ 0.03198124  0.02749679  0.         -0.21751875]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 12343 is [False, False, True, False, False, True]
State prediction error at timestep 12343 is 0.012
Human Feedback received at timestep 12343 of None
Current timestep = 12344. State = [[0.25826553 0.16563278]]. Action = [[ 0.08035    -0.03476502  0.         -0.459149  ]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 12344 is [False, False, True, False, False, True]
State prediction error at timestep 12344 is 0.012
Human Feedback received at timestep 12344 of None
Current timestep = 12345. State = [[0.26023424 0.16064548]]. Action = [[-0.07681088 -0.0564132   0.          0.32149816]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 12345 is [False, False, True, False, False, True]
Current timestep = 12346. State = [[0.26329544 0.15540975]]. Action = [[ 0.07901505 -0.05147368  0.          0.03925312]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 12346 is [False, False, True, False, False, True]
State prediction error at timestep 12346 is 0.012
Human Feedback received at timestep 12346 of None
Current timestep = 12347. State = [[0.26750052 0.15261357]]. Action = [[ 0.0464263   0.00677451  0.         -0.9938313 ]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 12347 is [False, False, True, False, False, True]
Current timestep = 12348. State = [[0.26678613 0.15261209]]. Action = [[-0.09627095  0.02998247  0.         -0.5569516 ]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 12348 is [False, False, True, False, False, True]
State prediction error at timestep 12348 is 0.012
Human Feedback received at timestep 12348 of None
Current timestep = 12349. State = [[0.26427773 0.15748793]]. Action = [[-0.02099851  0.08038203  0.         -0.9152315 ]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 12349 is [False, False, True, False, False, True]
Current timestep = 12350. State = [[0.26458114 0.16555713]]. Action = [[0.07829254 0.08670265 0.         0.26308477]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 12350 is [False, False, True, False, False, True]
Current timestep = 12351. State = [[0.26584178 0.17031884]]. Action = [[ 0.04207987  0.01702492  0.         -0.9747558 ]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 12351 is [False, False, True, False, False, True]
State prediction error at timestep 12351 is 0.012
Human Feedback received at timestep 12351 of None
Current timestep = 12352. State = [[0.26682058 0.17151453]]. Action = [[ 0.04227889 -0.00301107  0.         -0.8015487 ]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 12352 is [False, False, True, False, False, True]
State prediction error at timestep 12352 is 0.012
Human Feedback received at timestep 12352 of None
Current timestep = 12353. State = [[0.26993203 0.16866341]]. Action = [[ 0.09964997 -0.07641822  0.          0.5040028 ]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 12353 is [False, False, True, False, False, True]
Current timestep = 12354. State = [[0.27340543 0.16429268]]. Action = [[ 0.07949925 -0.06624423  0.         -0.5494343 ]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 12354 is [False, False, True, False, False, True]
Current timestep = 12355. State = [[0.27625954 0.16309682]]. Action = [[ 0.09372834  0.00221558  0.         -0.93055123]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 12355 is [False, False, True, False, False, True]
Current timestep = 12356. State = [[0.27839684 0.15923177]]. Action = [[ 0.07070131 -0.09324002  0.         -0.9630514 ]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 12356 is [False, False, True, False, False, True]
Current timestep = 12357. State = [[0.2799302  0.15851243]]. Action = [[ 0.09745378  0.02805889  0.         -0.22290945]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 12357 is [False, False, True, False, False, True]
Current timestep = 12358. State = [[0.28085044 0.15882936]]. Action = [[ 0.07787525 -0.03391196  0.         -0.04053837]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 12358 is [False, False, True, False, False, True]
Current timestep = 12359. State = [[0.28132537 0.16187187]]. Action = [[ 0.09567254  0.0616662   0.         -0.61826813]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 12359 is [False, False, True, False, False, True]
Current timestep = 12360. State = [[0.27970034 0.16386193]]. Action = [[-0.09611408  0.02061591  0.         -0.15167046]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 12360 is [False, False, True, False, False, True]
State prediction error at timestep 12360 is 0.012
Human Feedback received at timestep 12360 of None
Current timestep = 12361. State = [[0.27706632 0.16892071]]. Action = [[0.03402396 0.08739526 0.         0.41394806]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 12361 is [False, False, True, False, False, True]
State prediction error at timestep 12361 is 0.012
Human Feedback received at timestep 12361 of None
Current timestep = 12362. State = [[0.27686584 0.17462969]]. Action = [[ 0.02213482  0.08534307  0.         -0.88481146]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 12362 is [False, False, True, False, False, True]
State prediction error at timestep 12362 is 0.012
Human Feedback received at timestep 12362 of None
Current timestep = 12363. State = [[0.27580944 0.17598687]]. Action = [[-0.01318079 -0.00672868  0.         -0.21970844]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 12363 is [False, False, True, False, False, True]
Current timestep = 12364. State = [[0.27140436 0.17694987]]. Action = [[-0.0385219   0.0125522   0.          0.10127664]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 12364 is [False, False, True, False, False, True]
Current timestep = 12365. State = [[0.26496682 0.18207046]]. Action = [[-0.07720622  0.07529745  0.          0.9184716 ]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 12365 is [False, False, True, False, False, True]
Current timestep = 12366. State = [[0.26118258 0.19045617]]. Action = [[ 0.07844902  0.08022364  0.         -0.94830394]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 12366 is [False, False, True, False, False, True]
Current timestep = 12367. State = [[0.2587357  0.19394279]]. Action = [[-0.0403122  -0.00965295  0.         -0.8566617 ]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 12367 is [False, False, True, False, False, True]
Current timestep = 12368. State = [[0.25726718 0.19367157]]. Action = [[ 0.01172803 -0.01995241  0.         -0.11110121]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 12368 is [False, False, True, False, False, True]
Current timestep = 12369. State = [[0.25867093 0.19622445]]. Action = [[ 0.08636487  0.05505075  0.         -0.25697172]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 12369 is [False, False, True, False, False, True]
State prediction error at timestep 12369 is 0.012
Human Feedback received at timestep 12369 of None
Current timestep = 12370. State = [[0.25963557 0.20129262]]. Action = [[0.06056718 0.04786337 0.         0.76563704]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 12370 is [False, False, True, False, False, True]
Current timestep = 12371. State = [[0.26201427 0.19931442]]. Action = [[ 0.08913057 -0.09027029  0.         -0.771727  ]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 12371 is [False, False, True, False, False, True]
Current timestep = 12372. State = [[0.2628273  0.19867419]]. Action = [[ 0.02079661  0.04094788  0.         -0.17498529]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 12372 is [False, False, True, False, False, True]
Current timestep = 12373. State = [[0.26297215 0.20008394]]. Action = [[ 0.04740868  0.0174851   0.         -0.9041991 ]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 12373 is [False, False, True, False, False, True]
Current timestep = 12374. State = [[0.26296163 0.20147204]]. Action = [[ 0.02439451  0.0264113   0.         -0.8733524 ]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 12374 is [False, False, True, False, False, True]
Current timestep = 12375. State = [[0.2630923  0.19954409]]. Action = [[ 0.04288884 -0.05945874  0.         -0.8157435 ]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 12375 is [False, False, True, False, False, True]
Current timestep = 12376. State = [[0.26471928 0.19654965]]. Action = [[ 0.07975794 -0.04303003  0.         -0.5827197 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 12376 is [False, False, True, False, False, True]
Current timestep = 12377. State = [[0.2652976 0.1952591]]. Action = [[ 0.03179664 -0.00841484  0.         -0.72690785]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 12377 is [False, False, True, False, False, True]
Current timestep = 12378. State = [[0.26693103 0.19231078]]. Action = [[ 0.09023912 -0.06827065  0.         -0.5886009 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 12378 is [False, False, True, False, False, True]
Current timestep = 12379. State = [[0.26750034 0.19055355]]. Action = [[0.01360075 0.00404151 0.         0.05431795]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 12379 is [False, False, True, False, False, True]
Current timestep = 12380. State = [[0.26805323 0.190181  ]]. Action = [[ 0.06941313 -0.00890295  0.          0.74005926]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 12380 is [False, False, True, False, False, True]
Current timestep = 12381. State = [[0.2684112  0.19358289]]. Action = [[ 0.05747957  0.08175946  0.         -0.29548347]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 12381 is [False, False, True, False, False, True]
Current timestep = 12382. State = [[0.26659217 0.1984222 ]]. Action = [[-0.07210808  0.07965215  0.          0.81362724]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 12382 is [False, False, True, False, False, True]
Current timestep = 12383. State = [[0.26581383 0.19755574]]. Action = [[ 0.09372021 -0.07692964  0.          0.39090538]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 12383 is [False, False, True, False, False, True]
Current timestep = 12384. State = [[0.266304   0.19960494]]. Action = [[ 0.03358004  0.09503398  0.         -0.2565831 ]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 12384 is [False, False, True, False, False, True]
Current timestep = 12385. State = [[0.26632306 0.19883648]]. Action = [[ 0.04159515 -0.06652142  0.         -0.92635083]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 12385 is [False, False, True, False, False, True]
Current timestep = 12386. State = [[0.2675815  0.19580944]]. Action = [[ 0.09549161 -0.05364574  0.         -0.01479465]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 12386 is [False, False, True, False, False, True]
State prediction error at timestep 12386 is 0.012
Human Feedback received at timestep 12386 of None
Current timestep = 12387. State = [[0.2668015  0.19199291]]. Action = [[-0.06220671 -0.04559406  0.          0.54990685]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 12387 is [False, False, True, False, False, True]
Current timestep = 12388. State = [[0.26366872 0.19235373]]. Action = [[-0.01832143  0.05180273  0.          0.4604709 ]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 12388 is [False, False, True, False, False, True]
State prediction error at timestep 12388 is 0.012
Human Feedback received at timestep 12388 of None
Current timestep = 12389. State = [[0.2594178 0.1946498]]. Action = [[-0.06246739  0.01977537  0.          0.0911032 ]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 12389 is [False, False, True, False, False, True]
Current timestep = 12390. State = [[0.25377417 0.19308333]]. Action = [[-0.09497547 -0.05023458  0.          0.18435979]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 12390 is [False, False, True, False, False, True]
Current timestep = 12391. State = [[0.24996682 0.19304089]]. Action = [[-0.05673028  0.01983206  0.         -0.5635103 ]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 12391 is [False, False, True, False, False, True]
State prediction error at timestep 12391 is 0.012
Human Feedback received at timestep 12391 of None
Current timestep = 12392. State = [[0.24840714 0.1957712 ]]. Action = [[-0.0153715   0.02657517  0.         -0.31535262]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 12392 is [False, False, True, False, False, True]
Current timestep = 12393. State = [[0.2494816  0.20040943]]. Action = [[0.05051091 0.05334381 0.         0.21914887]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 12393 is [False, False, True, False, False, True]
Current timestep = 12394. State = [[0.24928705 0.20040938]]. Action = [[-0.07491914 -0.04760845  0.         -0.7587968 ]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 12394 is [False, False, True, False, False, True]
Current timestep = 12395. State = [[0.24686521 0.19778565]]. Action = [[-0.05129053 -0.03696933  0.          0.51148343]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 12395 is [False, False, True, False, False, True]
Current timestep = 12396. State = [[0.24820317 0.19328077]]. Action = [[ 0.02621806 -0.07027841  0.          0.85415936]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 12396 is [False, False, True, False, False, True]
Current timestep = 12397. State = [[0.25008607 0.19491135]]. Action = [[ 0.01148842  0.09266696  0.         -0.43538058]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 12397 is [False, False, True, False, False, True]
Current timestep = 12398. State = [[0.2514379  0.20138524]]. Action = [[ 0.04064678  0.06434869  0.         -0.3984931 ]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 12398 is [False, False, True, False, False, True]
Current timestep = 12399. State = [[0.25412455 0.20068951]]. Action = [[ 0.06519016 -0.06684509  0.         -0.04358393]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 12399 is [False, False, True, False, False, True]
Current timestep = 12400. State = [[0.2551695  0.19804685]]. Action = [[-0.00762959 -0.00593799  0.         -0.8134459 ]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 12400 is [False, False, True, False, False, True]
Current timestep = 12401. State = [[0.25497958 0.20089142]]. Action = [[0.01813843 0.06964169 0.         0.6989527 ]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 12401 is [False, False, True, False, False, True]
State prediction error at timestep 12401 is 0.012
Human Feedback received at timestep 12401 of None
Current timestep = 12402. State = [[0.25760084 0.19868715]]. Action = [[ 0.07989889 -0.08091328  0.          0.19821095]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 12402 is [False, False, True, False, False, True]
State prediction error at timestep 12402 is 0.012
Human Feedback received at timestep 12402 of None
Current timestep = 12403. State = [[0.26160735 0.19758335]]. Action = [[0.09476063 0.05354016 0.         0.80331564]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 12403 is [False, False, True, False, False, True]
Current timestep = 12404. State = [[0.2621436 0.1992606]]. Action = [[ 0.03358931 -0.0019751   0.         -0.14346874]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 12404 is [False, False, True, False, False, True]
Current timestep = 12405. State = [[0.26201782 0.19910169]]. Action = [[ 0.00396812  0.00283601  0.         -0.96688986]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 12405 is [False, False, True, False, False, True]
Current timestep = 12406. State = [[0.259579   0.19838303]]. Action = [[-0.08389825 -0.00744447  0.         -0.88422203]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 12406 is [False, False, True, False, False, True]
Current timestep = 12407. State = [[0.25713286 0.20137787]]. Action = [[0.04059117 0.06337226 0.         0.79045427]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 12407 is [False, False, True, False, False, True]
Current timestep = 12408. State = [[0.25331095 0.20781966]]. Action = [[-0.09230309  0.08139329  0.         -0.41258442]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 12408 is [False, False, True, False, False, True]
State prediction error at timestep 12408 is 0.012
Human Feedback received at timestep 12408 of None
Current timestep = 12409. State = [[0.25086248 0.21045381]]. Action = [[ 0.02499358 -0.02349715  0.         -0.928653  ]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 12409 is [False, False, True, False, False, True]
Current timestep = 12410. State = [[0.25099578 0.21450713]]. Action = [[ 0.03193235  0.07523104  0.         -0.9579763 ]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 12410 is [False, False, True, False, False, True]
Current timestep = 12411. State = [[0.25162166 0.21570641]]. Action = [[ 0.0635483  -0.06769994  0.         -0.8077886 ]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 12411 is [False, False, True, False, False, True]
State prediction error at timestep 12411 is 0.012
Human Feedback received at timestep 12411 of None
Current timestep = 12412. State = [[0.25239775 0.21234669]]. Action = [[ 0.02130954 -0.04666197  0.         -0.27219045]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 12412 is [False, False, True, False, False, True]
State prediction error at timestep 12412 is 0.012
Human Feedback received at timestep 12412 of None
Current timestep = 12413. State = [[0.25154004 0.2081897 ]]. Action = [[-0.0198537  -0.05480352  0.         -0.08368051]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 12413 is [False, False, True, False, False, True]
Current timestep = 12414. State = [[0.24795474 0.2076744 ]]. Action = [[-0.06972096  0.0356561   0.         -0.85630137]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 12414 is [False, False, True, False, False, True]
State prediction error at timestep 12414 is 0.012
Human Feedback received at timestep 12414 of None
Current timestep = 12415. State = [[0.24727483 0.20763889]]. Action = [[ 0.04850035 -0.0206551   0.         -0.7249434 ]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 12415 is [False, False, True, False, False, True]
Current timestep = 12416. State = [[0.24915193 0.20266424]]. Action = [[ 0.0190464  -0.07429654  0.          0.63975894]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 12416 is [False, False, True, False, False, True]
Current timestep = 12417. State = [[0.24979615 0.19523197]]. Action = [[-0.0162266  -0.07528166  0.          0.49838245]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 12417 is [False, False, True, False, False, True]
State prediction error at timestep 12417 is 0.012
Human Feedback received at timestep 12417 of None
Current timestep = 12418. State = [[0.2505209  0.19202207]]. Action = [[-0.00218061  0.0158573   0.         -0.93455756]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 12418 is [False, False, True, False, False, True]
Current timestep = 12419. State = [[0.25279438 0.19527279]]. Action = [[0.09635092 0.07643985 0.         0.0373677 ]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 12419 is [False, False, True, False, False, True]
Current timestep = 12420. State = [[0.25647157 0.19357404]]. Action = [[ 0.07026611 -0.063924    0.          0.08210039]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 12420 is [False, False, True, False, False, True]
State prediction error at timestep 12420 is 0.012
Human Feedback received at timestep 12420 of None
Current timestep = 12421. State = [[0.25966737 0.19312166]]. Action = [[0.07460862 0.04738783 0.         0.6547202 ]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 12421 is [False, False, True, False, False, True]
Current timestep = 12422. State = [[0.26041612 0.18995391]]. Action = [[ 0.02446894 -0.09488197  0.         -0.68112004]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 12422 is [False, False, True, False, False, True]
State prediction error at timestep 12422 is 0.012
Human Feedback received at timestep 12422 of None
Current timestep = 12423. State = [[0.2622465  0.18661843]]. Action = [[ 0.04926647  0.00661682  0.         -0.8368219 ]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 12423 is [False, False, True, False, False, True]
Current timestep = 12424. State = [[0.2618619  0.18268728]]. Action = [[-0.0207601  -0.07928298  0.         -0.827913  ]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 12424 is [False, False, True, False, False, True]
Current timestep = 12425. State = [[0.26182106 0.18167187]]. Action = [[ 0.03712585  0.05354894  0.         -0.81753457]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 12425 is [False, False, True, False, False, True]
State prediction error at timestep 12425 is 0.012
Human Feedback received at timestep 12425 of None
Current timestep = 12426. State = [[0.26319885 0.18462464]]. Action = [[ 0.09534634  0.01261707  0.         -0.96978605]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 12426 is [False, False, True, False, False, True]
State prediction error at timestep 12426 is 0.012
Human Feedback received at timestep 12426 of None
Current timestep = 12427. State = [[0.26439402 0.18738718]]. Action = [[ 0.0879085   0.01584925  0.         -0.34295428]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 12427 is [False, False, True, False, False, True]
Current timestep = 12428. State = [[0.26281354 0.18593213]]. Action = [[-0.06521837 -0.04418586  0.         -0.97257906]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 12428 is [False, False, True, False, False, True]
Current timestep = 12429. State = [[0.26227692 0.18492393]]. Action = [[0.09229464 0.01067052 0.         0.3792528 ]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 12429 is [False, False, True, False, False, True]
Current timestep = 12430. State = [[0.26387063 0.18634562]]. Action = [[ 0.06341215  0.01275291  0.         -0.7770695 ]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 12430 is [False, False, True, False, False, True]
Current timestep = 12431. State = [[0.26599464 0.18330802]]. Action = [[ 0.07309062 -0.08581473  0.          0.3108908 ]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 12431 is [False, False, True, False, False, True]
Current timestep = 12432. State = [[0.26698786 0.18553758]]. Action = [[ 0.09414143  0.09572942  0.         -0.9732149 ]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 12432 is [False, False, True, False, False, True]
Current timestep = 12433. State = [[0.26507944 0.18983239]]. Action = [[-0.0795802   0.04924     0.         -0.01695973]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 12433 is [False, False, True, False, False, True]
Current timestep = 12434. State = [[0.2642272  0.18700032]]. Action = [[ 0.06101687 -0.09261487  0.         -0.32803416]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 12434 is [False, False, True, False, False, True]
State prediction error at timestep 12434 is 0.012
Human Feedback received at timestep 12434 of None
Current timestep = 12435. State = [[0.2640271  0.18098317]]. Action = [[-0.02428658 -0.05134177  0.         -0.4536137 ]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 12435 is [False, False, True, False, False, True]
Current timestep = 12436. State = [[0.26352873 0.17688906]]. Action = [[ 0.0109906  -0.02612194  0.         -0.52265245]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 12436 is [False, False, True, False, False, True]
Current timestep = 12437. State = [[0.26476088 0.17782553]]. Action = [[ 0.09085263  0.05469551  0.         -0.2257095 ]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 12437 is [False, False, True, False, False, True]
State prediction error at timestep 12437 is 0.012
Human Feedback received at timestep 12437 of None
Current timestep = 12438. State = [[0.26549324 0.18136993]]. Action = [[ 0.07579685  0.04282118  0.         -0.9604269 ]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 12438 is [False, False, True, False, False, True]
Current timestep = 12439. State = [[0.26615402 0.18161869]]. Action = [[ 0.0506881  -0.02200097  0.         -0.3056146 ]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 12439 is [False, False, True, False, False, True]
State prediction error at timestep 12439 is 0.012
Human Feedback received at timestep 12439 of None
Current timestep = 12440. State = [[0.2664598  0.17743412]]. Action = [[ 0.02240083 -0.07157759  0.         -0.34889925]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 12440 is [False, False, True, False, False, True]
State prediction error at timestep 12440 is 0.012
Human Feedback received at timestep 12440 of None
Current timestep = 12441. State = [[0.26716653 0.17730087]]. Action = [[0.08925653 0.05283914 0.         0.2373023 ]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 12441 is [False, False, True, False, False, True]
State prediction error at timestep 12441 is 0.012
Human Feedback received at timestep 12441 of None
Current timestep = 12442. State = [[0.26831046 0.18040836]]. Action = [[0.0857631  0.04447784 0.         0.3767091 ]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 12442 is [False, False, True, False, False, True]
Current timestep = 12443. State = [[0.27071267 0.17837694]]. Action = [[ 0.09617425 -0.06855202  0.         -0.98652667]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 12443 is [False, False, True, False, False, True]
Current timestep = 12444. State = [[0.2697278  0.17823154]]. Action = [[-0.07273948  0.05008341  0.         -0.74214745]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 12444 is [False, False, True, False, False, True]
Current timestep = 12445. State = [[0.2679166  0.18300085]]. Action = [[0.03556124 0.08476499 0.         0.07488418]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 12445 is [False, False, True, False, False, True]
State prediction error at timestep 12445 is 0.012
Human Feedback received at timestep 12445 of None
Current timestep = 12446. State = [[0.26810563 0.1823389 ]]. Action = [[ 0.05363522 -0.06678502  0.         -0.4127782 ]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 12446 is [False, False, True, False, False, True]
State prediction error at timestep 12446 is 0.012
Human Feedback received at timestep 12446 of None
Current timestep = 12447. State = [[0.2689348  0.18247795]]. Action = [[ 0.09291119  0.0216897   0.         -0.96604156]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 12447 is [False, False, True, False, False, True]
Current timestep = 12448. State = [[0.26908612 0.18391855]]. Action = [[ 0.04087598  0.01697542  0.         -0.44467986]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 12448 is [False, False, True, False, False, True]
Current timestep = 12449. State = [[0.26984456 0.1805537 ]]. Action = [[ 0.06228205 -0.09067259  0.          0.5049224 ]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 12449 is [False, False, True, False, False, True]
State prediction error at timestep 12449 is 0.012
Human Feedback received at timestep 12449 of None
Current timestep = 12450. State = [[0.2712495  0.17876995]]. Action = [[0.07331299 0.0196601  0.         0.0133692 ]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 12450 is [False, False, True, False, False, True]
Current timestep = 12451. State = [[0.2722671  0.17915069]]. Action = [[0.07082225 0.00500154 0.         0.4958557 ]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 12451 is [False, False, True, False, False, True]
State prediction error at timestep 12451 is 0.012
Human Feedback received at timestep 12451 of None
Current timestep = 12452. State = [[0.27125287 0.17527708]]. Action = [[-0.04347196 -0.05892996  0.         -0.08776122]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 12452 is [False, False, True, False, False, True]
Current timestep = 12453. State = [[0.2701616  0.17402343]]. Action = [[0.09354205 0.02879678 0.         0.48844862]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 12453 is [False, False, True, False, False, True]
Current timestep = 12454. State = [[0.27031475 0.17120986]]. Action = [[ 0.02805231 -0.06731488  0.         -0.71995866]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 12454 is [False, False, True, False, False, True]
Current timestep = 12455. State = [[0.27046722 0.17218444]]. Action = [[ 0.09557096  0.05763019  0.         -0.17256558]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 12455 is [False, False, True, False, False, True]
Current timestep = 12456. State = [[0.27040407 0.17607976]]. Action = [[ 0.03354571  0.05010632  0.         -0.22713417]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 12456 is [False, False, True, False, False, True]
State prediction error at timestep 12456 is 0.012
Human Feedback received at timestep 12456 of None
Current timestep = 12457. State = [[0.270003   0.17551526]]. Action = [[ 0.00653827 -0.04579386  0.         -0.20079643]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 12457 is [False, False, True, False, False, True]
Current timestep = 12458. State = [[0.2716862 0.1700738]]. Action = [[ 0.07979435 -0.07981106  0.         -0.62781274]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 12458 is [False, False, True, False, False, True]
Current timestep = 12459. State = [[0.273991   0.16498141]]. Action = [[ 0.06331737 -0.05823703  0.         -0.71919537]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 12459 is [False, False, True, False, False, True]
State prediction error at timestep 12459 is 0.012
Human Feedback received at timestep 12459 of None
Current timestep = 12460. State = [[0.27432883 0.16599603]]. Action = [[ 0.00759226  0.07372246  0.         -0.8561315 ]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 12460 is [False, False, True, False, False, True]
State prediction error at timestep 12460 is 0.012
Human Feedback received at timestep 12460 of None
Current timestep = 12461. State = [[0.27422455 0.17057896]]. Action = [[ 0.04275412  0.07026596  0.         -0.91210884]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 12461 is [False, False, True, False, False, True]
State prediction error at timestep 12461 is 0.012
Human Feedback received at timestep 12461 of None
Current timestep = 12462. State = [[0.2731153  0.16867845]]. Action = [[-0.06657289 -0.07439687  0.         -0.35575688]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 12462 is [False, False, True, False, False, True]
Current timestep = 12463. State = [[0.2711195  0.16858245]]. Action = [[ 0.01343757  0.05105103  0.         -0.75190383]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 12463 is [False, False, True, False, False, True]
Current timestep = 12464. State = [[0.272567   0.16668923]]. Action = [[ 0.0923403  -0.08349892  0.         -0.9692056 ]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 12464 is [False, False, True, False, False, True]
Current timestep = 12465. State = [[0.27507925 0.16337809]]. Action = [[ 0.07175992 -0.03616381  0.         -0.09210354]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 12465 is [False, False, True, False, False, True]
Current timestep = 12466. State = [[0.27546656 0.16404296]]. Action = [[0.02629835 0.03795605 0.         0.31071544]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 12466 is [False, False, True, False, False, True]
State prediction error at timestep 12466 is 0.012
Human Feedback received at timestep 12466 of None
Current timestep = 12467. State = [[0.27501765 0.16557752]]. Action = [[-0.00559666  0.03876016  0.         -0.75233734]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 12467 is [False, False, True, False, False, True]
State prediction error at timestep 12467 is 0.012
Human Feedback received at timestep 12467 of None
Current timestep = 12468. State = [[0.2752496  0.16379292]]. Action = [[ 0.05981236 -0.06207411  0.          0.868737  ]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 12468 is [False, False, True, False, False, True]
Current timestep = 12469. State = [[0.27793482 0.1587243 ]]. Action = [[ 0.0927942  -0.07647391  0.         -0.5464687 ]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 12469 is [False, False, True, False, False, True]
Current timestep = 12470. State = [[0.27748314 0.15502098]]. Action = [[-0.06684431 -0.01812427  0.         -0.43992007]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 12470 is [False, False, True, False, False, True]
State prediction error at timestep 12470 is 0.012
Human Feedback received at timestep 12470 of None
Current timestep = 12471. State = [[0.27622026 0.15521961]]. Action = [[0.02797779 0.03532834 0.         0.3615116 ]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 12471 is [False, False, True, False, False, True]
Current timestep = 12472. State = [[0.2764954  0.15263118]]. Action = [[ 0.0338695  -0.08040108  0.         -0.9510982 ]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 12472 is [False, False, True, False, False, True]
Current timestep = 12473. State = [[0.27688327 0.14486265]]. Action = [[ 0.01414704 -0.09464098  0.         -0.6175544 ]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 12473 is [False, False, True, False, False, True]
Current timestep = 12474. State = [[0.2751216  0.13955715]]. Action = [[-0.0407796  -0.01276581  0.         -0.6641036 ]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 12474 is [False, False, True, False, False, True]
Current timestep = 12475. State = [[0.27522942 0.13717468]]. Action = [[ 0.04448385 -0.00790944  0.         -0.64435816]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 12475 is [False, False, True, False, False, True]
Current timestep = 12476. State = [[0.27882773 0.13121687]]. Action = [[ 0.0731179  -0.0829076   0.          0.60666835]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 12476 is [False, False, True, False, False, True]
Current timestep = 12477. State = [[0.2789283  0.12297288]]. Action = [[-0.09261759 -0.09572586  0.         -0.7536378 ]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 12477 is [False, False, True, False, False, True]
Current timestep = 12478. State = [[0.2777364  0.11285358]]. Action = [[-0.02724108 -0.0938049   0.          0.5386945 ]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 12478 is [False, False, True, False, True, False]
Current timestep = 12479. State = [[0.28027716 0.10628741]]. Action = [[ 0.08593418 -0.02331939  0.         -0.980918  ]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 12479 is [False, False, True, False, True, False]
Current timestep = 12480. State = [[0.2823287  0.09861268]]. Action = [[-0.00505294 -0.0833628   0.         -0.62277216]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 12480 is [False, False, True, False, True, False]
Current timestep = 12481. State = [[0.28383493 0.09743799]]. Action = [[0.04988425 0.08280454 0.         0.24280596]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 12481 is [False, False, True, False, True, False]
Current timestep = 12482. State = [[0.28294817 0.10072421]]. Action = [[-0.03010034  0.03770397  0.          0.20076406]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 12482 is [False, False, True, False, True, False]
Current timestep = 12483. State = [[0.2819022  0.09888262]]. Action = [[-0.00070788 -0.05758622  0.          0.25743878]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 12483 is [False, False, True, False, True, False]
Current timestep = 12484. State = [[0.28302318 0.09313696]]. Action = [[ 0.0189602  -0.06559703  0.          0.3915664 ]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 12484 is [False, False, True, False, True, False]
Current timestep = 12485. State = [[0.2857439  0.09250458]]. Action = [[0.0547703  0.05438831 0.         0.27856135]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 12485 is [False, False, True, False, True, False]
State prediction error at timestep 12485 is 0.012
Human Feedback received at timestep 12485 of None
Current timestep = 12486. State = [[0.2871693  0.09703171]]. Action = [[0.04022294 0.06979825 0.         0.78753257]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 12486 is [False, False, True, False, True, False]
Current timestep = 12487. State = [[0.28807002 0.10230661]]. Action = [[ 0.03422385  0.08160853  0.         -0.2104863 ]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 12487 is [False, False, True, False, True, False]
Current timestep = 12488. State = [[0.28967932 0.102652  ]]. Action = [[ 0.06422978 -0.04883688  0.         -0.0793429 ]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 12488 is [False, False, True, False, True, False]
State prediction error at timestep 12488 is 0.012
Human Feedback received at timestep 12488 of None
Current timestep = 12489. State = [[0.29129276 0.09987605]]. Action = [[ 0.05185802 -0.05120241  0.          0.74550295]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 12489 is [False, False, True, False, True, False]
Current timestep = 12490. State = [[0.29234606 0.1015154 ]]. Action = [[ 0.04606248  0.05939812  0.         -0.62718785]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 12490 is [False, False, True, False, True, False]
State prediction error at timestep 12490 is 0.012
Human Feedback received at timestep 12490 of None
Current timestep = 12491. State = [[0.29303437 0.10691348]]. Action = [[ 0.08141368  0.07461531  0.         -0.94741607]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 12491 is [False, False, True, False, True, False]
Current timestep = 12492. State = [[0.2917579  0.11091302]]. Action = [[-0.02654912  0.04198243  0.         -0.6613935 ]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 12492 is [False, False, True, False, True, False]
Current timestep = 12493. State = [[0.29103965 0.11367036]]. Action = [[0.07995751 0.01565282 0.         0.8761709 ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 12493 is [False, False, True, False, True, False]
Current timestep = 12494. State = [[0.29161364 0.1188599 ]]. Action = [[ 0.09426751  0.09097797  0.         -0.08903837]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 12494 is [False, False, True, False, True, False]
Current timestep = 12495. State = [[0.29041994 0.11962   ]]. Action = [[-0.04793147 -0.02787296  0.          0.10816073]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 12495 is [False, False, True, False, True, False]
State prediction error at timestep 12495 is 0.012
Human Feedback received at timestep 12495 of None
Current timestep = 12496. State = [[0.2897404  0.12021255]]. Action = [[0.07718582 0.0230846  0.         0.96123123]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 12496 is [False, False, True, False, True, False]
Current timestep = 12497. State = [[0.28906664 0.11961396]]. Action = [[-0.09119343 -0.01683362  0.          0.5168686 ]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 12497 is [False, False, True, False, True, False]
State prediction error at timestep 12497 is 0.012
Human Feedback received at timestep 12497 of None
Current timestep = 12498. State = [[0.2880484  0.12159442]]. Action = [[ 0.05612426  0.04882417  0.         -0.81962246]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 12498 is [False, False, True, False, True, False]
Current timestep = 12499. State = [[0.28859618 0.12580445]]. Action = [[ 0.05295957  0.05995158  0.         -0.23766083]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 12499 is [False, False, True, False, True, False]
Current timestep = 12500. State = [[0.28956756 0.12712377]]. Action = [[ 0.0819677  -0.02705102  0.          0.1331842 ]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 12500 is [False, False, True, False, False, True]
Current timestep = 12501. State = [[0.28890425 0.12638341]]. Action = [[-0.01927648 -0.00272758  0.         -0.49969614]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 12501 is [False, False, True, False, False, True]
State prediction error at timestep 12501 is 0.012
Human Feedback received at timestep 12501 of None
Current timestep = 12502. State = [[0.2871168  0.12326781]]. Action = [[ 3.6138296e-04 -5.3515285e-02  0.0000000e+00 -8.8749373e-01]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 12502 is [False, False, True, False, False, True]
Current timestep = 12503. State = [[0.28341565 0.12245411]]. Action = [[-0.06073586  0.02859672  0.         -0.8442124 ]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 12503 is [False, False, True, False, True, False]
Current timestep = 12504. State = [[0.28245798 0.12273213]]. Action = [[ 0.08314589 -0.01416909  0.          0.10362709]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 12504 is [False, False, True, False, True, False]
Current timestep = 12505. State = [[0.28454593 0.12444685]]. Action = [[ 0.09838579  0.03350513  0.         -0.3933853 ]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 12505 is [False, False, True, False, True, False]
Current timestep = 12506. State = [[0.28279772 0.12251799]]. Action = [[-0.0856277  -0.06045895  0.         -0.44165242]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 12506 is [False, False, True, False, True, False]
Current timestep = 12507. State = [[0.28073683 0.12410491]]. Action = [[ 0.05531646  0.07913627  0.         -0.8926579 ]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 12507 is [False, False, True, False, True, False]
Current timestep = 12508. State = [[0.27828532 0.12944199]]. Action = [[-0.03644942  0.04799839  0.         -0.84460574]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 12508 is [False, False, True, False, True, False]
Current timestep = 12509. State = [[0.27780494 0.13567267]]. Action = [[ 0.09487043  0.07857094  0.         -0.83634394]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 12509 is [False, False, True, False, False, True]
Current timestep = 12510. State = [[0.27892932 0.14093608]]. Action = [[ 0.07758493  0.03847284  0.         -0.9525875 ]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 12510 is [False, False, True, False, False, True]
Current timestep = 12511. State = [[0.27929127 0.13946883]]. Action = [[ 0.02963849 -0.0717683   0.          0.16066182]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 12511 is [False, False, True, False, False, True]
Current timestep = 12512. State = [[0.2771303  0.14002338]]. Action = [[-0.03657772  0.04888693  0.         -0.84468377]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 12512 is [False, False, True, False, False, True]
Current timestep = 12513. State = [[0.27783418 0.13784583]]. Action = [[ 0.0905581 -0.0839635  0.        -0.89952  ]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 12513 is [False, False, True, False, False, True]
Current timestep = 12514. State = [[0.27917215 0.13998874]]. Action = [[0.0360058  0.09171071 0.         0.78732157]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 12514 is [False, False, True, False, False, True]
Current timestep = 12515. State = [[0.27908596 0.1413131 ]]. Action = [[0.0039199  0.00379071 0.         0.88331044]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 12515 is [False, False, True, False, False, True]
State prediction error at timestep 12515 is 0.012
Human Feedback received at timestep 12515 of None
Current timestep = 12516. State = [[0.2754787 0.1444383]]. Action = [[-0.06609891  0.06983206  0.         -0.8114971 ]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 12516 is [False, False, True, False, False, True]
State prediction error at timestep 12516 is 0.012
Human Feedback received at timestep 12516 of None
Current timestep = 12517. State = [[0.27357486 0.14575362]]. Action = [[ 0.03031152 -0.02906731  0.         -0.5337944 ]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 12517 is [False, False, True, False, False, True]
State prediction error at timestep 12517 is 0.012
Human Feedback received at timestep 12517 of None
Current timestep = 12518. State = [[0.2723129  0.14067714]]. Action = [[-0.03736091 -0.08359659  0.          0.9270911 ]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 12518 is [False, False, True, False, False, True]
State prediction error at timestep 12518 is 0.012
Human Feedback received at timestep 12518 of None
Current timestep = 12519. State = [[0.2709507  0.13966519]]. Action = [[-0.01006974  0.04426784  0.          0.70989954]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 12519 is [False, False, True, False, False, True]
Current timestep = 12520. State = [[0.26846418 0.14481853]]. Action = [[-0.03282122  0.07229389  0.          0.32553792]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 12520 is [False, False, True, False, False, True]
Current timestep = 12521. State = [[0.26766807 0.15007623]]. Action = [[ 0.02742169  0.0384332   0.         -0.95100397]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 12521 is [False, False, True, False, False, True]
Current timestep = 12522. State = [[0.27065998 0.14884469]]. Action = [[ 0.09585326 -0.07901887  0.          0.8561287 ]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 12522 is [False, False, True, False, False, True]
Current timestep = 12523. State = [[0.27485478 0.14306016]]. Action = [[ 0.07992888 -0.09244946  0.         -0.922071  ]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 12523 is [False, False, True, False, False, True]
Current timestep = 12524. State = [[0.27506405 0.13828674]]. Action = [[-0.08117251 -0.02621939  0.         -0.901685  ]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 12524 is [False, False, True, False, False, True]
Current timestep = 12525. State = [[0.27128094 0.13932456]]. Action = [[-0.05764836  0.05528597  0.         -0.9864273 ]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 12525 is [False, False, True, False, False, True]
Current timestep = 12526. State = [[0.26677006 0.14175019]]. Action = [[-0.06838456  0.01075043  0.          0.2703278 ]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 12526 is [False, False, True, False, False, True]
Current timestep = 12527. State = [[0.26495087 0.14793521]]. Action = [[0.08417945 0.09132493 0.         0.7337723 ]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 12527 is [False, False, True, False, False, True]
State prediction error at timestep 12527 is 0.012
Human Feedback received at timestep 12527 of None
Current timestep = 12528. State = [[0.26601148 0.15035194]]. Action = [[ 0.03420068 -0.03261261  0.         -0.33305275]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 12528 is [False, False, True, False, False, True]
State prediction error at timestep 12528 is 0.012
Human Feedback received at timestep 12528 of None
Current timestep = 12529. State = [[0.2687044  0.15236962]]. Action = [[ 0.083385    0.05015505  0.         -0.8325553 ]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 12529 is [False, False, True, False, False, True]
State prediction error at timestep 12529 is 0.012
Human Feedback received at timestep 12529 of None
Current timestep = 12530. State = [[0.2705042 0.152448 ]]. Action = [[ 0.04527355 -0.03835679  0.         -0.6826929 ]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 12530 is [False, False, True, False, False, True]
Current timestep = 12531. State = [[0.27065465 0.15563789]]. Action = [[0.00855444 0.09420574 0.         0.93298864]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 12531 is [False, False, True, False, False, True]
Current timestep = 12532. State = [[0.26992592 0.15911858]]. Action = [[-0.01125469  0.03914601  0.         -0.51080006]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 12532 is [False, False, True, False, False, True]
Current timestep = 12533. State = [[0.26762778 0.15627836]]. Action = [[-0.02017812 -0.08433296  0.         -0.45383888]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 12533 is [False, False, True, False, False, True]
Current timestep = 12534. State = [[0.26429504 0.15092076]]. Action = [[-0.07169876 -0.0503016   0.         -0.25965863]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 12534 is [False, False, True, False, False, True]
Current timestep = 12535. State = [[0.26210853 0.14675325]]. Action = [[-0.03677077 -0.04086122  0.         -0.38218403]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 12535 is [False, False, True, False, False, True]
State prediction error at timestep 12535 is 0.012
Human Feedback received at timestep 12535 of None
Current timestep = 12536. State = [[0.2632583  0.14512362]]. Action = [[ 0.07117159 -0.0010538   0.          0.8670461 ]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 12536 is [False, False, True, False, False, True]
State prediction error at timestep 12536 is 0.012
Human Feedback received at timestep 12536 of None
Current timestep = 12537. State = [[0.2653688 0.1439572]]. Action = [[ 0.01912589 -0.00768073  0.         -0.5140013 ]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 12537 is [False, False, True, False, False, True]
Current timestep = 12538. State = [[0.26730427 0.13759199]]. Action = [[ 0.02391909 -0.09841223  0.          0.18981624]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 12538 is [False, False, True, False, False, True]
State prediction error at timestep 12538 is 0.012
Human Feedback received at timestep 12538 of None
Current timestep = 12539. State = [[0.26667455 0.13516103]]. Action = [[-0.04115857  0.04359584  0.         -0.18504488]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 12539 is [False, False, True, False, False, True]
Current timestep = 12540. State = [[0.26411885 0.13199021]]. Action = [[-0.05548533 -0.06986241  0.         -0.01444459]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 12540 is [False, False, True, False, False, True]
Current timestep = 12541. State = [[0.26205185 0.12846817]]. Action = [[-0.05627304 -0.01620112  0.         -0.8890143 ]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 12541 is [False, False, True, False, False, True]
State prediction error at timestep 12541 is 0.012
Human Feedback received at timestep 12541 of None
Current timestep = 12542. State = [[0.2616128 0.1285431]]. Action = [[-0.01776506  0.01779596  0.          0.5451329 ]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 12542 is [False, False, True, False, False, True]
Current timestep = 12543. State = [[0.26455453 0.12417969]]. Action = [[ 0.04396198 -0.09261185  0.          0.7141365 ]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 12543 is [False, False, True, False, False, True]
Current timestep = 12544. State = [[0.26718783 0.1208668 ]]. Action = [[ 0.00708006  0.00879337  0.         -0.05841362]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 12544 is [False, False, True, False, True, False]
Current timestep = 12545. State = [[0.27006075 0.12508518]]. Action = [[0.08451924 0.09112697 0.         0.74191856]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 12545 is [False, False, True, False, True, False]
Current timestep = 12546. State = [[0.27261007 0.13095981]]. Action = [[ 0.05133098  0.06133447  0.         -0.48123646]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 12546 is [False, False, True, False, False, True]
Current timestep = 12547. State = [[0.2750575  0.13356952]]. Action = [[ 0.07206122  0.01019776  0.         -0.98764926]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 12547 is [False, False, True, False, False, True]
Current timestep = 12548. State = [[0.27901837 0.12843281]]. Action = [[ 0.09596782 -0.0942879   0.          0.25779116]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 12548 is [False, False, True, False, False, True]
Current timestep = 12549. State = [[0.2801493  0.12352883]]. Action = [[-0.0188381   0.00292052  0.          0.21680236]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 12549 is [False, False, True, False, False, True]
State prediction error at timestep 12549 is 0.012
Human Feedback received at timestep 12549 of None
Current timestep = 12550. State = [[0.2774545  0.12085831]]. Action = [[-0.09084719 -0.02037119  0.         -0.79058474]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 12550 is [False, False, True, False, True, False]
Current timestep = 12551. State = [[0.2769599  0.11599115]]. Action = [[ 0.04049964 -0.06482127  0.         -0.94503677]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 12551 is [False, False, True, False, True, False]
Current timestep = 12552. State = [[0.27929088 0.11542327]]. Action = [[0.05840703 0.05867831 0.         0.9982307 ]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 12552 is [False, False, True, False, True, False]
State prediction error at timestep 12552 is 0.012
Human Feedback received at timestep 12552 of None
Current timestep = 12553. State = [[0.2804758  0.11836877]]. Action = [[ 0.09628613  0.01977403  0.         -0.1924305 ]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 12553 is [False, False, True, False, True, False]
Current timestep = 12554. State = [[0.28099683 0.11814598]]. Action = [[ 0.03916971 -0.02903309  0.          0.41867256]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 12554 is [False, False, True, False, True, False]
Current timestep = 12555. State = [[0.2782742 0.1198914]]. Action = [[-0.09400546  0.06172926  0.         -0.8932779 ]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 12555 is [False, False, True, False, True, False]
Current timestep = 12556. State = [[0.273565   0.12610154]]. Action = [[-0.03176264  0.07372131  0.         -0.29295492]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 12556 is [False, False, True, False, True, False]
State prediction error at timestep 12556 is 0.012
Human Feedback received at timestep 12556 of None
Current timestep = 12557. State = [[0.27264088 0.1282493 ]]. Action = [[ 0.03807569 -0.02875465  0.         -0.1782707 ]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 12557 is [False, False, True, False, False, True]
Current timestep = 12558. State = [[0.27269635 0.12611221]]. Action = [[ 0.00999689 -0.04050289  0.         -0.8592067 ]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 12558 is [False, False, True, False, False, True]
Current timestep = 12559. State = [[0.2718999  0.12584569]]. Action = [[-0.00511454  0.01563641  0.         -0.89886206]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 12559 is [False, False, True, False, False, True]
Current timestep = 12560. State = [[0.2681959  0.12987961]]. Action = [[-0.07402366  0.07035469  0.          0.82996   ]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 12560 is [False, False, True, False, False, True]
Current timestep = 12561. State = [[0.261932   0.13679457]]. Action = [[-0.08665355  0.0663201   0.          0.57328963]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 12561 is [False, False, True, False, False, True]
Current timestep = 12562. State = [[0.25853285 0.13781704]]. Action = [[-0.02993036 -0.0618773   0.          0.42751002]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 12562 is [False, False, True, False, False, True]
Current timestep = 12563. State = [[0.2585338  0.14195646]]. Action = [[ 0.08826304  0.08760338  0.         -0.22196418]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 12563 is [False, False, True, False, False, True]
Current timestep = 12564. State = [[0.26110637 0.14815769]]. Action = [[0.06593793 0.04058794 0.         0.57133365]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 12564 is [False, False, True, False, False, True]
Current timestep = 12565. State = [[0.2619704 0.1538053]]. Action = [[0.02550068 0.06288259 0.         0.61024225]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 12565 is [False, False, True, False, False, True]
State prediction error at timestep 12565 is 0.012
Human Feedback received at timestep 12565 of None
Current timestep = 12566. State = [[0.25970238 0.15900294]]. Action = [[-0.07394077  0.04784498  0.         -0.07411629]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 12566 is [False, False, True, False, False, True]
State prediction error at timestep 12566 is 0.012
Human Feedback received at timestep 12566 of None
Current timestep = 12567. State = [[0.25978988 0.16190238]]. Action = [[ 9.6739940e-02  5.1163137e-04  0.0000000e+00 -8.1477398e-01]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 12567 is [False, False, True, False, False, True]
Current timestep = 12568. State = [[0.26213625 0.16061892]]. Action = [[ 0.05921639 -0.05827104  0.         -0.9287999 ]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 12568 is [False, False, True, False, False, True]
State prediction error at timestep 12568 is 0.012
Human Feedback received at timestep 12568 of None
Current timestep = 12569. State = [[0.26353633 0.15447071]]. Action = [[ 0.02306763 -0.09228941  0.         -0.57237303]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 12569 is [False, False, True, False, False, True]
Current timestep = 12570. State = [[0.26550415 0.15368609]]. Action = [[0.09456823 0.05995057 0.         0.73924637]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 12570 is [False, False, True, False, False, True]
Current timestep = 12571. State = [[0.2665208  0.15965016]]. Action = [[0.08757458 0.09276695 0.         0.7877295 ]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 12571 is [False, False, True, False, False, True]
Current timestep = 12572. State = [[0.26872402 0.15807089]]. Action = [[ 0.09192199 -0.08745298  0.         -0.9452146 ]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 12572 is [False, False, True, False, False, True]
State prediction error at timestep 12572 is 0.012
Human Feedback received at timestep 12572 of None
Current timestep = 12573. State = [[0.26915145 0.15105557]]. Action = [[-0.04752845 -0.07742411  0.          0.23924863]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 12573 is [False, False, True, False, False, True]
State prediction error at timestep 12573 is 0.012
Human Feedback received at timestep 12573 of None
Current timestep = 12574. State = [[0.26807612 0.15033531]]. Action = [[0.02278155 0.06198431 0.         0.15195334]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 12574 is [False, False, True, False, False, True]
State prediction error at timestep 12574 is 0.012
Human Feedback received at timestep 12574 of None
Current timestep = 12575. State = [[0.26797587 0.15045665]]. Action = [[ 0.00721909 -0.02086853  0.         -0.43262506]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 12575 is [False, False, True, False, False, True]
Current timestep = 12576. State = [[0.2680562 0.1493529]]. Action = [[ 0.02440561 -0.01594127  0.         -0.7023695 ]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 12576 is [False, False, True, False, False, True]
Current timestep = 12577. State = [[0.26600814 0.15114303]]. Action = [[-0.03762409  0.04460981  0.          0.2429223 ]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 12577 is [False, False, True, False, False, True]
Current timestep = 12578. State = [[0.26204965 0.15233825]]. Action = [[-0.04736775 -0.00665973  0.         -0.49370778]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 12578 is [False, False, True, False, False, True]
Current timestep = 12579. State = [[0.25836727 0.15102582]]. Action = [[-0.05611537 -0.03201221  0.         -0.7275593 ]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 12579 is [False, False, True, False, False, True]
Current timestep = 12580. State = [[0.25909305 0.14690152]]. Action = [[ 0.08495802 -0.07222178  0.         -0.9948187 ]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 12580 is [False, False, True, False, False, True]
Current timestep = 12581. State = [[0.25859883 0.14877696]]. Action = [[-0.04812421  0.0919509   0.          0.18703055]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 12581 is [False, False, True, False, False, True]
Current timestep = 12582. State = [[0.25856256 0.15033482]]. Action = [[ 0.02760515 -0.02867067  0.          0.0548383 ]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 12582 is [False, False, True, False, False, True]
Current timestep = 12583. State = [[0.2606716  0.14670423]]. Action = [[ 0.02893039 -0.05426588  0.         -0.584323  ]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 12583 is [False, False, True, False, False, True]
State prediction error at timestep 12583 is 0.012
Human Feedback received at timestep 12583 of None
Current timestep = 12584. State = [[0.26188132 0.14699346]]. Action = [[ 0.01049012  0.05222731  0.         -0.7979835 ]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 12584 is [False, False, True, False, False, True]
Current timestep = 12585. State = [[0.26441383 0.15117386]]. Action = [[0.09782825 0.05414385 0.         0.10033023]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 12585 is [False, False, True, False, False, True]
Current timestep = 12586. State = [[0.26756132 0.15162417]]. Action = [[ 0.07799061 -0.03209518  0.         -0.9716971 ]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 12586 is [False, False, True, False, False, True]
State prediction error at timestep 12586 is 0.012
Human Feedback received at timestep 12586 of None
Current timestep = 12587. State = [[0.2689068  0.15553138]]. Action = [[ 0.07055772  0.069479    0.         -0.7429427 ]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 12587 is [False, False, True, False, False, True]
Current timestep = 12588. State = [[0.2711629  0.15514785]]. Action = [[ 0.09182956 -0.06947608  0.          0.87826395]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 12588 is [False, False, True, False, False, True]
Current timestep = 12589. State = [[0.27159384 0.14985593]]. Action = [[-0.04438312 -0.06628086  0.          0.9399884 ]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 12589 is [False, False, True, False, False, True]
Current timestep = 12590. State = [[0.26771203 0.14913085]]. Action = [[-0.05684441  0.03815993  0.         -0.9739626 ]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 12590 is [False, False, True, False, False, True]
State prediction error at timestep 12590 is 0.012
Human Feedback received at timestep 12590 of None
Current timestep = 12591. State = [[0.26460278 0.15244855]]. Action = [[-0.01838358  0.04116983  0.          0.34855676]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 12591 is [False, False, True, False, False, True]
Current timestep = 12592. State = [[0.26161656 0.15708461]]. Action = [[-0.02919485  0.05154362  0.          0.16312933]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 12592 is [False, False, True, False, False, True]
Current timestep = 12593. State = [[0.25991514 0.1607248 ]]. Action = [[ 0.00310241  0.01853023  0.         -0.9336239 ]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 12593 is [False, False, True, False, False, True]
Current timestep = 12594. State = [[0.2623175  0.15878521]]. Action = [[ 0.08125325 -0.06324515  0.         -0.91173315]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 12594 is [False, False, True, False, False, True]
Current timestep = 12595. State = [[0.2649315  0.15851969]]. Action = [[ 0.052446    0.02589662  0.         -0.651103  ]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 12595 is [False, False, True, False, False, True]
Current timestep = 12596. State = [[0.2675352  0.15538679]]. Action = [[ 0.07015536 -0.09256082  0.         -0.75123686]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 12596 is [False, False, True, False, False, True]
Current timestep = 12597. State = [[0.2672031  0.15520512]]. Action = [[-0.03596233  0.06596679  0.         -0.9698148 ]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 12597 is [False, False, True, False, False, True]
Current timestep = 12598. State = [[0.26559585 0.15467067]]. Action = [[-0.00158624 -0.03623663  0.          0.79496074]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 12598 is [False, False, True, False, False, True]
State prediction error at timestep 12598 is 0.012
Human Feedback received at timestep 12598 of None
Current timestep = 12599. State = [[0.26790398 0.15002316]]. Action = [[ 0.08530737 -0.06253384  0.          0.20924759]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 12599 is [False, False, True, False, False, True]
Current timestep = 12600. State = [[0.26875603 0.14363043]]. Action = [[-0.04971161 -0.07473613  0.          0.348989  ]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 12600 is [False, False, True, False, False, True]
Current timestep = 12601. State = [[0.27034613 0.13686517]]. Action = [[ 0.08185443 -0.05782481  0.         -0.7168093 ]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 12601 is [False, False, True, False, False, True]
State prediction error at timestep 12601 is 0.012
Human Feedback received at timestep 12601 of None
Current timestep = 12602. State = [[0.2743589  0.12863593]]. Action = [[ 0.05858771 -0.0845831   0.         -0.9316281 ]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 12602 is [False, False, True, False, False, True]
Current timestep = 12603. State = [[0.2738839 0.1266838]]. Action = [[-0.03632735  0.05033214  0.         -0.71549726]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 12603 is [False, False, True, False, False, True]
Current timestep = 12604. State = [[0.27355862 0.1307903 ]]. Action = [[ 0.07550781  0.07252357  0.         -0.44233108]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 12604 is [False, False, True, False, False, True]
State prediction error at timestep 12604 is 0.012
Human Feedback received at timestep 12604 of None
Current timestep = 12605. State = [[0.27475384 0.13318262]]. Action = [[0.06426541 0.00175558 0.         0.5625069 ]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 12605 is [False, False, True, False, False, True]
State prediction error at timestep 12605 is 0.012
Human Feedback received at timestep 12605 of None
Current timestep = 12606. State = [[0.2770773  0.13412048]]. Action = [[0.09308288 0.00695751 0.         0.86533856]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 12606 is [False, False, True, False, False, True]
Current timestep = 12607. State = [[0.27942207 0.13545445]]. Action = [[0.08903729 0.01564686 0.         0.04642785]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 12607 is [False, False, True, False, False, True]
Current timestep = 12608. State = [[0.2794816  0.13291755]]. Action = [[-0.02520011 -0.04786151  0.          0.7403393 ]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 12608 is [False, False, True, False, False, True]
Current timestep = 12609. State = [[0.27603474 0.12926702]]. Action = [[-0.05212556 -0.03183318  0.         -0.8805876 ]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 12609 is [False, False, True, False, False, True]
Current timestep = 12610. State = [[0.2733402  0.13072145]]. Action = [[-0.01974045  0.05495057  0.          0.23599613]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 12610 is [False, False, True, False, False, True]
State prediction error at timestep 12610 is 0.012
Human Feedback received at timestep 12610 of None
Current timestep = 12611. State = [[0.26992735 0.12755074]]. Action = [[-0.08685175 -0.09529798  0.          0.9020772 ]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 12611 is [False, False, True, False, False, True]
Current timestep = 12612. State = [[0.26944986 0.11968482]]. Action = [[ 0.00759367 -0.09312092  0.         -0.87654126]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 12612 is [False, False, True, False, False, True]
Current timestep = 12613. State = [[0.27137294 0.11485065]]. Action = [[ 0.01273917 -0.01165412  0.          0.9094143 ]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 12613 is [False, False, True, False, True, False]
Current timestep = 12614. State = [[0.27442738 0.11697049]]. Action = [[0.09233671 0.07119574 0.         0.65233994]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 12614 is [False, False, True, False, True, False]
Current timestep = 12615. State = [[0.2786524  0.11708428]]. Action = [[ 0.08255567 -0.02374937  0.         -0.7954818 ]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 12615 is [False, False, True, False, True, False]
Current timestep = 12616. State = [[0.2816781 0.1114082]]. Action = [[ 0.05210156 -0.07047898  0.         -0.9911967 ]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 12616 is [False, False, True, False, True, False]
Current timestep = 12617. State = [[-0.17708126  0.06191133]]. Action = [[ 0.0406655  -0.07367346  0.          0.927546  ]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 12617 is [False, False, True, False, True, False]
Current timestep = 12618. State = [[-0.17778248  0.05953713]]. Action = [[-0.04856439  0.01643684  0.          0.4295249 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 12618 is [True, False, False, False, True, False]
State prediction error at timestep 12618 is 0.012
Human Feedback received at timestep 12618 of None
Current timestep = 12619. State = [[-0.17505495  0.05720754]]. Action = [[ 0.04946382 -0.04636036  0.         -0.93249756]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 12619 is [True, False, False, False, True, False]
State prediction error at timestep 12619 is 0.012
Human Feedback received at timestep 12619 of None
Current timestep = 12620. State = [[-0.1691673   0.05597758]]. Action = [[0.06329951 0.0179251  0.         0.19412422]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 12620 is [True, False, False, False, True, False]
Current timestep = 12621. State = [[-0.1640254   0.05791584]]. Action = [[0.04299017 0.04888154 0.         0.18868816]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 12621 is [True, False, False, False, True, False]
Current timestep = 12622. State = [[-0.16195898  0.05566125]]. Action = [[-0.00867135 -0.05954553  0.         -0.86327946]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 12622 is [True, False, False, False, True, False]
State prediction error at timestep 12622 is 0.012
Human Feedback received at timestep 12622 of None
Current timestep = 12623. State = [[-0.15675549  0.0532442 ]]. Action = [[8.351327e-02 9.985268e-05 0.000000e+00 6.863884e-01]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 12623 is [True, False, False, False, True, False]
Current timestep = 12624. State = [[-0.15625171  0.05628879]]. Action = [[-0.06445649  0.07686546  0.          0.011765  ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 12624 is [True, False, False, False, True, False]
Current timestep = 12625. State = [[-0.15269291  0.05365528]]. Action = [[ 0.09022396 -0.09129155  0.          0.13615596]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 12625 is [True, False, False, False, True, False]
Current timestep = 12626. State = [[-0.14495097  0.05174582]]. Action = [[0.08769733 0.02655137 0.         0.29863667]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 12626 is [True, False, False, False, True, False]
Current timestep = 12627. State = [[-0.14494035  0.04782106]]. Action = [[-0.09017403 -0.08116965  0.         -0.42283058]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 12627 is [True, False, False, False, True, False]
Current timestep = 12628. State = [[-0.14458396  0.04738263]]. Action = [[ 0.04085375  0.04779715  0.         -0.6534517 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 12628 is [True, False, False, False, True, False]
Current timestep = 12629. State = [[-0.14287232  0.04688363]]. Action = [[ 0.00292218 -0.02613638  0.         -0.65111905]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 12629 is [True, False, False, False, True, False]
Current timestep = 12630. State = [[-0.14298622  0.0471833 ]]. Action = [[-0.01703747  0.02716047  0.          0.03636384]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12630 is [True, False, False, False, True, False]
State prediction error at timestep 12630 is 0.012
Human Feedback received at timestep 12630 of None
Current timestep = 12631. State = [[-0.1427459   0.04769286]]. Action = [[ 0.00581439 -0.00133963  0.         -0.9673408 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 12631 is [True, False, False, False, True, False]
Current timestep = 12632. State = [[-0.1383315   0.04462887]]. Action = [[ 0.0803205  -0.05661815  0.         -0.6614803 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 12632 is [True, False, False, False, True, False]
Current timestep = 12633. State = [[-0.1329298   0.04153783]]. Action = [[ 0.05551255 -0.01641889  0.          0.84111536]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 12633 is [True, False, False, False, True, False]
State prediction error at timestep 12633 is 0.012
Human Feedback received at timestep 12633 of None
Current timestep = 12634. State = [[-0.12938313  0.04474512]]. Action = [[ 0.02880632  0.08983959  0.         -0.7661748 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 12634 is [True, False, False, False, True, False]
Current timestep = 12635. State = [[-0.124472    0.04392029]]. Action = [[ 0.07426807 -0.05842526  0.          0.19428098]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 12635 is [True, False, False, False, True, False]
Current timestep = 12636. State = [[-0.12364744  0.037242  ]]. Action = [[-0.04924753 -0.09237505  0.         -0.9872835 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 12636 is [True, False, False, False, True, False]
State prediction error at timestep 12636 is 0.012
Human Feedback received at timestep 12636 of None
Current timestep = 12637. State = [[-0.12306466  0.03644661]]. Action = [[0.01582067 0.05168337 0.         0.3854792 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 12637 is [True, False, False, False, True, False]
Current timestep = 12638. State = [[-0.12157963  0.03273425]]. Action = [[ 0.00539038 -0.09074246  0.         -0.3965615 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 12638 is [True, False, False, False, True, False]
State prediction error at timestep 12638 is 0.012
Human Feedback received at timestep 12638 of None
Current timestep = 12639. State = [[-0.11909702  0.03090654]]. Action = [[0.02708326 0.02959812 0.         0.41006637]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 12639 is [True, False, False, False, True, False]
Current timestep = 12640. State = [[-0.12071538  0.02676141]]. Action = [[-0.07036988 -0.08440854  0.         -0.9957633 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 12640 is [True, False, False, False, True, False]
Current timestep = 12641. State = [[-0.12583621  0.027583  ]]. Action = [[-0.08815019  0.07528921  0.         -0.88632494]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 12641 is [True, False, False, False, True, False]
Current timestep = 12642. State = [[-0.12551582  0.02958653]]. Action = [[ 0.05579298  0.00224771  0.         -0.9913936 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 12642 is [True, False, False, False, True, False]
Current timestep = 12643. State = [[-0.12119581  0.03125637]]. Action = [[0.05833017 0.03418141 0.         0.5521847 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 12643 is [True, False, False, False, True, False]
Current timestep = 12644. State = [[-0.12277659  0.03464909]]. Action = [[-0.06973381  0.04853829  0.         -0.25417745]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 12644 is [True, False, False, False, True, False]
State prediction error at timestep 12644 is 0.012
Human Feedback received at timestep 12644 of None
Current timestep = 12645. State = [[-0.12211917  0.03739851]]. Action = [[ 0.05995319  0.01914889  0.         -0.5067706 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 12645 is [True, False, False, False, True, False]
State prediction error at timestep 12645 is 0.012
Human Feedback received at timestep 12645 of None
Current timestep = 12646. State = [[-0.11804835  0.03518993]]. Action = [[ 0.05821971 -0.06155268  0.         -0.08275199]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 12646 is [True, False, False, False, True, False]
Current timestep = 12647. State = [[-0.12043446  0.03571232]]. Action = [[-0.08994144  0.04341585  0.         -0.7519194 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 12647 is [True, False, False, False, True, False]
Current timestep = 12648. State = [[-0.12363463  0.04133888]]. Action = [[-0.01060986  0.08029712  0.          0.4938321 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 12648 is [True, False, False, False, True, False]
Current timestep = 12649. State = [[-0.12562133  0.04308987]]. Action = [[-0.02009709 -0.02792169  0.          0.4790591 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 12649 is [True, False, False, False, True, False]
State prediction error at timestep 12649 is 0.012
Human Feedback received at timestep 12649 of None
Current timestep = 12650. State = [[-0.12376894  0.04322648]]. Action = [[0.06050663 0.00341761 0.         0.10719347]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 12650 is [True, False, False, False, True, False]
Current timestep = 12651. State = [[-0.12460798  0.04805025]]. Action = [[-0.03876564  0.08554991  0.         -0.6617789 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 12651 is [True, False, False, False, True, False]
Current timestep = 12652. State = [[-0.12536491  0.05350281]]. Action = [[0.02082206 0.04297944 0.         0.24984765]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 12652 is [True, False, False, False, True, False]
Current timestep = 12653. State = [[-0.12708953  0.05371097]]. Action = [[-0.03328915 -0.04275992  0.         -0.5115826 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 12653 is [True, False, False, False, True, False]
State prediction error at timestep 12653 is 0.012
Human Feedback received at timestep 12653 of None
Current timestep = 12654. State = [[-0.1236134   0.05107528]]. Action = [[ 0.09844837 -0.0437988   0.         -0.860074  ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 12654 is [True, False, False, False, True, False]
Current timestep = 12655. State = [[-0.12374353  0.04821097]]. Action = [[-0.06795205 -0.0379459   0.         -0.8539547 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 12655 is [True, False, False, False, True, False]
State prediction error at timestep 12655 is 0.012
Human Feedback received at timestep 12655 of None
Current timestep = 12656. State = [[-0.12693043  0.04747953]]. Action = [[-0.03388923  0.00262649  0.         -0.77467453]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 12656 is [True, False, False, False, True, False]
Current timestep = 12657. State = [[-0.13088891  0.05208435]]. Action = [[-0.05835736  0.08565591  0.         -0.9548881 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 12657 is [True, False, False, False, True, False]
Current timestep = 12658. State = [[-0.12986061  0.05833872]]. Action = [[ 0.07216287  0.06578263  0.         -0.08705288]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 12658 is [True, False, False, False, True, False]
Current timestep = 12659. State = [[-0.1322373  0.056167 ]]. Action = [[-0.08797117 -0.09813903  0.         -0.7762774 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 12659 is [True, False, False, False, True, False]
State prediction error at timestep 12659 is 0.012
Human Feedback received at timestep 12659 of None
Current timestep = 12660. State = [[-0.13123173  0.05568513]]. Action = [[ 0.09052432  0.03970835  0.         -0.6443156 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 12660 is [True, False, False, False, True, False]
Current timestep = 12661. State = [[-0.12498302  0.05890261]]. Action = [[ 0.09180988  0.04519933  0.         -0.286999  ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 12661 is [True, False, False, False, True, False]
Current timestep = 12662. State = [[-0.12449604  0.05584952]]. Action = [[-0.05009736 -0.08913384  0.         -0.6821165 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 12662 is [True, False, False, False, True, False]
Current timestep = 12663. State = [[-0.128144    0.05092652]]. Action = [[-0.05380896 -0.04837331  0.         -0.94737446]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 12663 is [True, False, False, False, True, False]
State prediction error at timestep 12663 is 0.012
Human Feedback received at timestep 12663 of None
Current timestep = 12664. State = [[-0.13003138  0.04625218]]. Action = [[-0.01335507 -0.05916902  0.          0.7405411 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 12664 is [True, False, False, False, True, False]
Current timestep = 12665. State = [[-0.12647592  0.03979044]]. Action = [[ 0.07629333 -0.07999721  0.         -0.28784394]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 12665 is [True, False, False, False, True, False]
Current timestep = 12666. State = [[-0.1240476   0.03910696]]. Action = [[ 0.00106356  0.05925756  0.         -0.97619444]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 12666 is [True, False, False, False, True, False]
Current timestep = 12667. State = [[-0.12352162  0.03666938]]. Action = [[ 0.0024728  -0.05938942  0.         -0.68400145]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 12667 is [True, False, False, False, True, False]
Current timestep = 12668. State = [[-0.11852651  0.0322516 ]]. Action = [[ 0.09422804 -0.03010537  0.         -0.85180783]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 12668 is [True, False, False, False, True, False]
Current timestep = 12669. State = [[-0.11676849  0.02492958]]. Action = [[-0.03215716 -0.09719154  0.          0.77494395]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 12669 is [True, False, False, False, True, False]
Current timestep = 12670. State = [[-0.11558063  0.02226813]]. Action = [[ 0.02703538  0.0365077   0.         -0.91691256]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 12670 is [True, False, False, False, True, False]
Current timestep = 12671. State = [[-0.11219718  0.01750084]]. Action = [[ 0.04663569 -0.08086638  0.         -0.5535587 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 12671 is [True, False, False, False, True, False]
Current timestep = 12672. State = [[-0.11067014  0.01765949]]. Action = [[-0.00516166  0.08391989  0.          0.4539156 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 12672 is [True, False, False, False, True, False]
Current timestep = 12673. State = [[-0.11334655  0.02371282]]. Action = [[-0.05645983  0.09755064  0.          0.09283817]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 12673 is [True, False, False, False, True, False]
Current timestep = 12674. State = [[-0.11130554  0.02323915]]. Action = [[ 0.07854379 -0.05951478  0.         -0.5291288 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 12674 is [True, False, False, False, True, False]
Current timestep = 12675. State = [[-0.10790228  0.01665397]]. Action = [[ 0.02135529 -0.08913716  0.          0.65487146]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 12675 is [True, False, False, False, True, False]
Current timestep = 12676. State = [[-0.10376634  0.01559792]]. Action = [[0.06016412 0.04832342 0.         0.4128908 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 12676 is [True, False, False, False, True, False]
Current timestep = 12677. State = [[-0.09835473  0.01285694]]. Action = [[ 0.06748196 -0.06553122  0.         -0.36389375]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 12677 is [True, False, False, False, True, False]
Current timestep = 12678. State = [[-0.09700716  0.00644452]]. Action = [[-0.0319545  -0.07456622  0.         -0.86489445]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 12678 is [True, False, False, False, True, False]
Current timestep = 12679. State = [[-0.10000712  0.00148697]]. Action = [[-0.07411896 -0.0363341   0.         -0.97526187]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 12679 is [True, False, False, False, True, False]
State prediction error at timestep 12679 is 0.012
Human Feedback received at timestep 12679 of None
Current timestep = 12680. State = [[-0.09663589 -0.00469529]]. Action = [[ 0.09377652 -0.07991375  0.         -0.64680815]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 12680 is [True, False, False, False, True, False]
Current timestep = 12681. State = [[-0.09196678 -0.00908314]]. Action = [[ 0.01385431 -0.0108064   0.         -0.21853119]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 12681 is [True, False, False, False, True, False]
Current timestep = 12682. State = [[-0.08850727 -0.01527726]]. Action = [[ 0.02789753 -0.08427946  0.          0.5157485 ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 12682 is [True, False, False, False, True, False]
Current timestep = 12683. State = [[-0.08361749 -0.02187705]]. Action = [[ 0.05176189 -0.04608345  0.          0.9623184 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 12683 is [True, False, False, False, True, False]
State prediction error at timestep 12683 is 0.012
Human Feedback received at timestep 12683 of None
Current timestep = 12684. State = [[-0.07607184 -0.02316037]]. Action = [[ 0.09897167  0.04467418  0.         -0.991668  ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 12684 is [True, False, False, False, True, False]
Current timestep = 12685. State = [[-0.0760812  -0.02871371]]. Action = [[-0.09558248 -0.09872344  0.          0.34982276]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 12685 is [True, False, False, False, True, False]
Current timestep = 12686. State = [[-0.07397982 -0.03137901]]. Action = [[ 0.08337503  0.03675707  0.         -0.9668924 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 12686 is [True, False, False, False, True, False]
State prediction error at timestep 12686 is 0.012
Human Feedback received at timestep 12686 of None
Current timestep = 12687. State = [[-0.07465163 -0.03338994]]. Action = [[-0.08005887 -0.02843173  0.          0.29824412]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 12687 is [True, False, False, False, True, False]
State prediction error at timestep 12687 is 0.012
Human Feedback received at timestep 12687 of None
Current timestep = 12688. State = [[-0.07243695 -0.03182787]]. Action = [[ 0.08433012  0.06901129  0.         -0.9692462 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 12688 is [True, False, False, False, True, False]
Current timestep = 12689. State = [[-0.07071269 -0.0355842 ]]. Action = [[-0.02012528 -0.0984571   0.         -0.83288723]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 12689 is [True, False, False, False, True, False]
State prediction error at timestep 12689 is 0.012
Human Feedback received at timestep 12689 of None
Current timestep = 12690. State = [[-0.06606561 -0.0421568 ]]. Action = [[ 0.090726   -0.05611453  0.         -0.19034207]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 12690 is [True, False, False, False, True, False]
Current timestep = 12691. State = [[-0.06629992 -0.04219109]]. Action = [[-0.08187284  0.05944059  0.          0.8543222 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 12691 is [True, False, False, False, True, False]
Current timestep = 12692. State = [[-0.06999982 -0.04109709]]. Action = [[-0.04109491  0.0012169   0.         -0.8951735 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 12692 is [True, False, False, False, True, False]
Current timestep = 12693. State = [[-0.06675746 -0.03835979]]. Action = [[0.09916344 0.0577059  0.         0.47963858]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 12693 is [True, False, False, False, True, False]
State prediction error at timestep 12693 is 0.012
Human Feedback received at timestep 12693 of None
Current timestep = 12694. State = [[-0.06705409 -0.03434686]]. Action = [[-0.06373253  0.04756434  0.         -0.6549926 ]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 12694 is [True, False, False, False, True, False]
State prediction error at timestep 12694 is 0.012
Human Feedback received at timestep 12694 of None
Current timestep = 12695. State = [[-0.07014533 -0.0307446 ]]. Action = [[-0.02462933  0.03340938  0.         -0.9878555 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 12695 is [True, False, False, False, True, False]
Current timestep = 12696. State = [[-0.07478875 -0.03277891]]. Action = [[-0.07506298 -0.07625987  0.         -0.8633974 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 12696 is [True, False, False, False, True, False]
Current timestep = 12697. State = [[-0.07379469 -0.03787778]]. Action = [[ 0.07076056 -0.06848811  0.          0.34773767]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 12697 is [True, False, False, False, True, False]
Current timestep = 12698. State = [[-0.07271889 -0.03611425]]. Action = [[-0.01554898  0.07762844  0.         -0.7043695 ]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 12698 is [True, False, False, False, True, False]
State prediction error at timestep 12698 is 0.012
Human Feedback received at timestep 12698 of None
Current timestep = 12699. State = [[-0.07143329 -0.03075184]]. Action = [[ 0.03783961  0.05928036  0.         -0.590236  ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 12699 is [True, False, False, False, True, False]
Current timestep = 12700. State = [[-0.07266285 -0.02966656]]. Action = [[-0.04067539 -0.02455082  0.         -0.37684405]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 12700 is [True, False, False, False, True, False]
Current timestep = 12701. State = [[-0.07824693 -0.02684486]]. Action = [[-0.09332609  0.05776041  0.          0.03995633]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 12701 is [True, False, False, False, True, False]
Current timestep = 12702. State = [[-0.08188491 -0.02418639]]. Action = [[-0.01828792  0.00314389  0.         -0.9800354 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 12702 is [True, False, False, False, True, False]
Current timestep = 12703. State = [[-0.08626825 -0.02322838]]. Action = [[-0.07103294 -0.00318307  0.         -0.44567168]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 12703 is [True, False, False, False, True, False]
Current timestep = 12704. State = [[-0.08830523 -0.02664306]]. Action = [[ 0.00541148 -0.08305355  0.          0.3792125 ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 12704 is [True, False, False, False, True, False]
State prediction error at timestep 12704 is 0.012
Human Feedback received at timestep 12704 of None
Current timestep = 12705. State = [[-0.08902272 -0.0242966 ]]. Action = [[-0.00497778  0.08845773  0.          0.20017612]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 12705 is [True, False, False, False, True, False]
State prediction error at timestep 12705 is 0.012
Human Feedback received at timestep 12705 of None
Current timestep = 12706. State = [[-0.08622132 -0.01779305]]. Action = [[ 0.08310717  0.06997395  0.         -0.9264856 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 12706 is [True, False, False, False, True, False]
Current timestep = 12707. State = [[-0.08067238 -0.01988826]]. Action = [[ 0.09526747 -0.09528571  0.          0.86843264]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 12707 is [True, False, False, False, True, False]
State prediction error at timestep 12707 is 0.012
Human Feedback received at timestep 12707 of None
Current timestep = 12708. State = [[-0.07522639 -0.01997986]]. Action = [[ 0.07431746  0.05345029  0.         -0.9009128 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 12708 is [True, False, False, False, True, False]
Current timestep = 12709. State = [[-0.07224204 -0.01441137]]. Action = [[ 0.03090527  0.08589662  0.         -0.3755257 ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 12709 is [True, False, False, False, True, False]
State prediction error at timestep 12709 is 0.012
Human Feedback received at timestep 12709 of None
Current timestep = 12710. State = [[-0.07278518 -0.01638399]]. Action = [[-0.02462586 -0.09508998  0.         -0.88045734]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 12710 is [True, False, False, False, True, False]
State prediction error at timestep 12710 is 0.012
Human Feedback received at timestep 12710 of None
Current timestep = 12711. State = [[-0.06966336 -0.01435413]]. Action = [[ 0.07562534  0.09462953  0.         -0.97157264]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 12711 is [True, False, False, False, True, False]
Current timestep = 12712. State = [[-0.07107804 -0.00999818]]. Action = [[-0.07997595  0.02952272  0.          0.97773373]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 12712 is [True, False, False, False, True, False]
State prediction error at timestep 12712 is 0.012
Human Feedback received at timestep 12712 of None
Current timestep = 12713. State = [[-0.06944583 -0.00744563]]. Action = [[0.08124024 0.01833012 0.         0.01554978]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 12713 is [True, False, False, False, True, False]
Current timestep = 12714. State = [[-0.06285141 -0.00706115]]. Action = [[ 0.08840001 -0.01348974  0.         -0.8795185 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 12714 is [True, False, False, False, True, False]
State prediction error at timestep 12714 is 0.012
Human Feedback received at timestep 12714 of None
Current timestep = 12715. State = [[-0.05803802 -0.0078945 ]]. Action = [[ 0.03552725 -0.01491771  0.         -0.21591109]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 12715 is [True, False, False, False, True, False]
State prediction error at timestep 12715 is 0.012
Human Feedback received at timestep 12715 of None
Current timestep = 12716. State = [[-0.05832075 -0.00382459]]. Action = [[-0.04779964  0.08481329  0.         -0.72915864]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 12716 is [True, False, False, False, True, False]
State prediction error at timestep 12716 is 0.012
Human Feedback received at timestep 12716 of None
Current timestep = 12717. State = [[-0.06163615 -0.00071998]]. Action = [[-0.06532563 -0.00244241  0.          0.48132825]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 12717 is [True, False, False, False, True, False]
Current timestep = 12718. State = [[-0.05833406  0.0042619 ]]. Action = [[ 0.09684855  0.07848275  0.         -0.18063396]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 12718 is [True, False, False, False, True, False]
Current timestep = 12719. State = [[-0.05451459  0.00411997]]. Action = [[ 0.00427085 -0.06847005  0.         -0.8855319 ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 12719 is [True, False, False, False, True, False]
Current timestep = 12720. State = [[-0.05092047 -0.00060477]]. Action = [[ 0.0362064  -0.07145832  0.          0.09515786]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 12720 is [True, False, False, False, True, False]
State prediction error at timestep 12720 is 0.012
Human Feedback received at timestep 12720 of None
Current timestep = 12721. State = [[-0.1628493   0.14987117]]. Action = [[ 0.08556455 -0.09547774  0.         -0.9016655 ]]. Reward = [100.]
Curr episode timestep = 103
Scene graph at timestep 12721 is [True, False, False, False, True, False]
Current timestep = 12722. State = [[-0.15807179  0.1567898 ]]. Action = [[0.05578639 0.06867454 0.         0.44929457]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 12722 is [True, False, False, False, False, True]
Current timestep = 12723. State = [[-0.15228102  0.15992928]]. Action = [[ 0.07432575  0.00346959  0.         -0.5652578 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 12723 is [True, False, False, False, False, True]
State prediction error at timestep 12723 is 0.012
Human Feedback received at timestep 12723 of None
Current timestep = 12724. State = [[-0.14769086  0.16183801]]. Action = [[0.02963642 0.01568397 0.         0.18417954]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 12724 is [True, False, False, False, False, True]
Current timestep = 12725. State = [[-0.14188139  0.16626824]]. Action = [[0.07450017 0.06027595 0.         0.14462376]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 12725 is [True, False, False, False, False, True]
Current timestep = 12726. State = [[-0.13779743  0.16888496]]. Action = [[ 0.01106925 -0.00278457  0.          0.65707004]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 12726 is [True, False, False, False, False, True]
Current timestep = 12727. State = [[-0.1391789   0.17037466]]. Action = [[-7.6723874e-02 -3.7176907e-04  0.0000000e+00 -6.9076848e-01]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 12727 is [True, False, False, False, False, True]
State prediction error at timestep 12727 is 0.012
Human Feedback received at timestep 12727 of None
Current timestep = 12728. State = [[-0.13517405  0.16924404]]. Action = [[ 0.08669361 -0.0552868   0.          0.86567473]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 12728 is [True, False, False, False, False, True]
State prediction error at timestep 12728 is 0.012
Human Feedback received at timestep 12728 of None
Current timestep = 12729. State = [[-0.13152146  0.17254175]]. Action = [[-0.01522426  0.07522548  0.         -0.74692166]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 12729 is [True, False, False, False, False, True]
State prediction error at timestep 12729 is 0.012
Human Feedback received at timestep 12729 of None
Current timestep = 12730. State = [[-0.12928514  0.17218782]]. Action = [[ 0.01235893 -0.07728007  0.         -0.41770303]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 12730 is [True, False, False, False, False, True]
State prediction error at timestep 12730 is 0.012
Human Feedback received at timestep 12730 of None
Current timestep = 12731. State = [[-0.12496674  0.17048939]]. Action = [[ 0.03647526 -0.01477308  0.          0.22450042]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 12731 is [True, False, False, False, False, True]
State prediction error at timestep 12731 is 0.012
Human Feedback received at timestep 12731 of None
Current timestep = 12732. State = [[-0.11940005  0.16818225]]. Action = [[ 0.04834337 -0.04885723  0.          0.9272554 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 12732 is [True, False, False, False, False, True]
State prediction error at timestep 12732 is 0.012
Human Feedback received at timestep 12732 of None
Current timestep = 12733. State = [[-0.11630439  0.17081976]]. Action = [[-0.00651651  0.07667146  0.         -0.27394295]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 12733 is [True, False, False, False, False, True]
Current timestep = 12734. State = [[-0.11654866  0.17515558]]. Action = [[-0.03249735  0.03359997  0.         -0.03200406]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12734 is [True, False, False, False, False, True]
Current timestep = 12735. State = [[-0.11428397  0.17286389]]. Action = [[ 0.03684623 -0.08251636  0.         -0.22119558]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 12735 is [True, False, False, False, False, True]
Current timestep = 12736. State = [[-0.10792996  0.17540991]]. Action = [[ 0.0882849   0.09729161  0.         -0.7369473 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 12736 is [True, False, False, False, False, True]
Current timestep = 12737. State = [[-0.10806061  0.181373  ]]. Action = [[-0.07804051  0.05856063  0.         -0.00475228]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 12737 is [True, False, False, False, False, True]
State prediction error at timestep 12737 is 0.012
Human Feedback received at timestep 12737 of None
Current timestep = 12738. State = [[-0.10880521  0.18560301]]. Action = [[ 0.02059551  0.03274141  0.         -0.4118899 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 12738 is [True, False, False, False, False, True]
State prediction error at timestep 12738 is 0.012
Human Feedback received at timestep 12738 of None
Current timestep = 12739. State = [[-0.10688543  0.18892725]]. Action = [[ 0.03004039  0.03194601  0.         -0.38865125]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 12739 is [True, False, False, False, False, True]
Current timestep = 12740. State = [[-0.1034289   0.18904124]]. Action = [[ 0.05204231 -0.0293455   0.         -0.70561945]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 12740 is [True, False, False, False, False, True]
Current timestep = 12741. State = [[-0.09763716  0.18690911]]. Action = [[ 0.08003182 -0.03228665  0.         -0.8100178 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 12741 is [True, False, False, False, False, True]
State prediction error at timestep 12741 is 0.012
Human Feedback received at timestep 12741 of None
Current timestep = 12742. State = [[-0.09055717  0.18809935]]. Action = [[ 0.08595865  0.04835861  0.         -0.394378  ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 12742 is [True, False, False, False, False, True]
Current timestep = 12743. State = [[-0.08288831  0.18416844]]. Action = [[ 0.08810427 -0.09614566  0.         -0.87022966]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 12743 is [True, False, False, False, False, True]
Current timestep = 12744. State = [[-0.0784284   0.18207517]]. Action = [[0.00792138 0.02657983 0.         0.01821733]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 12744 is [True, False, False, False, False, True]
Current timestep = 12745. State = [[-0.08077036  0.18080735]]. Action = [[-0.09622932 -0.03542694  0.         -0.02546167]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 12745 is [True, False, False, False, False, True]
Current timestep = 12746. State = [[-0.08448035  0.18486287]]. Action = [[-0.05454242  0.09361517  0.         -0.7237973 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 12746 is [True, False, False, False, False, True]
Current timestep = 12747. State = [[-0.08626033  0.19209154]]. Action = [[-0.01292499  0.07804313  0.          0.7626369 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 12747 is [True, False, False, False, False, True]
Current timestep = 12748. State = [[-0.08644245  0.19425113]]. Action = [[ 0.00317977 -0.02415963  0.         -0.32525927]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 12748 is [True, False, False, False, False, True]
Current timestep = 12749. State = [[-0.08504335  0.19336952]]. Action = [[ 0.02166645 -0.02508837  0.         -0.32250512]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 12749 is [True, False, False, False, False, True]
Current timestep = 12750. State = [[-0.08829731  0.1941098 ]]. Action = [[-0.08677956  0.01137906  0.         -0.31999898]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 12750 is [True, False, False, False, False, True]
Current timestep = 12751. State = [[-0.08844035  0.19716594]]. Action = [[0.04908741 0.03617626 0.         0.07521224]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 12751 is [True, False, False, False, False, True]
Current timestep = 12752. State = [[-0.08501282  0.20360062]]. Action = [[ 0.05132525  0.09457017  0.         -0.66681623]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 12752 is [True, False, False, False, False, True]
Current timestep = 12753. State = [[-0.08613611  0.20749015]]. Action = [[-0.04873271  0.00508548  0.         -0.13663995]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 12753 is [True, False, False, False, False, True]
Current timestep = 12754. State = [[-0.09060284  0.21111728]]. Action = [[-0.05681939  0.04312108  0.          0.8996048 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 12754 is [True, False, False, False, False, True]
Current timestep = 12755. State = [[-0.09074331  0.21265279]]. Action = [[ 0.04241765 -0.0202641   0.         -0.7348732 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 12755 is [True, False, False, False, False, True]
State prediction error at timestep 12755 is 0.012
Human Feedback received at timestep 12755 of None
Current timestep = 12756. State = [[-0.09242672  0.20941454]]. Action = [[-0.05583885 -0.07830646  0.          0.17291188]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 12756 is [True, False, False, False, False, True]
State prediction error at timestep 12756 is 0.012
Human Feedback received at timestep 12756 of None
Current timestep = 12757. State = [[-0.08980577  0.20583487]]. Action = [[ 0.08745668 -0.03872337  0.          0.6416571 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 12757 is [True, False, False, False, False, True]
Current timestep = 12758. State = [[-0.08917634  0.20106807]]. Action = [[-0.05242196 -0.07734382  0.         -0.90359193]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 12758 is [True, False, False, False, False, True]
Current timestep = 12759. State = [[-0.08618185  0.2028927 ]]. Action = [[ 0.09475327  0.09466428  0.         -0.58971214]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 12759 is [True, False, False, False, False, True]
Current timestep = 12760. State = [[-0.07879385  0.20823964]]. Action = [[0.09275267 0.0695894  0.         0.6713054 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 12760 is [True, False, False, False, False, True]
Current timestep = 12761. State = [[-0.07371698  0.20889509]]. Action = [[ 0.03587735 -0.01842801  0.         -0.44734657]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 12761 is [True, False, False, False, False, True]
State prediction error at timestep 12761 is 0.012
Human Feedback received at timestep 12761 of None
Current timestep = 12762. State = [[-0.07242104  0.21079876]]. Action = [[-0.01496304  0.05259866  0.         -0.12534589]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 12762 is [True, False, False, False, False, True]
Current timestep = 12763. State = [[-0.06980534  0.2165042 ]]. Action = [[ 0.04873187  0.08526815  0.         -0.77352965]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 12763 is [True, False, False, False, False, True]
Current timestep = 12764. State = [[-0.06607098  0.2183627 ]]. Action = [[ 0.03986842 -0.01523103  0.          0.7294791 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 12764 is [True, False, False, False, False, True]
State prediction error at timestep 12764 is 0.012
Human Feedback received at timestep 12764 of None
Current timestep = 12765. State = [[-0.06437247  0.21482703]]. Action = [[-0.0097429  -0.07226098  0.         -0.28643358]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 12765 is [True, False, False, False, False, True]
Current timestep = 12766. State = [[-0.06581125  0.20935142]]. Action = [[-0.06020799 -0.08262633  0.          0.6090946 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 12766 is [True, False, False, False, False, True]
State prediction error at timestep 12766 is 0.012
Human Feedback received at timestep 12766 of None
Current timestep = 12767. State = [[-0.06614915  0.20379846]]. Action = [[-0.01389085 -0.07706974  0.         -0.6169903 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 12767 is [True, False, False, False, False, True]
Current timestep = 12768. State = [[-0.06330688  0.20558937]]. Action = [[0.04023691 0.08162231 0.         0.14483654]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 12768 is [True, False, False, False, False, True]
Current timestep = 12769. State = [[-0.06253386  0.20800346]]. Action = [[-2.9487893e-02  1.7447770e-04  0.0000000e+00 -6.7337346e-01]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 12769 is [True, False, False, False, False, True]
Current timestep = 12770. State = [[-0.06249258  0.20989908]]. Action = [[-0.00287268  0.0267312   0.          0.28977144]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 12770 is [True, False, False, False, False, True]
Current timestep = 12771. State = [[-0.06177622  0.2111719 ]]. Action = [[ 0.00416225  0.00097376  0.         -0.29324377]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 12771 is [True, False, False, False, False, True]
Current timestep = 12772. State = [[-0.06478126  0.20786014]]. Action = [[-0.0835079  -0.08263545  0.          0.63336813]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 12772 is [True, False, False, False, False, True]
State prediction error at timestep 12772 is 0.012
Human Feedback received at timestep 12772 of None
Current timestep = 12773. State = [[-0.06893567  0.20850022]]. Action = [[-0.05258417  0.04456048  0.         -0.47221774]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 12773 is [True, False, False, False, False, True]
Current timestep = 12774. State = [[-0.074319    0.21455348]]. Action = [[-0.07506205  0.08028493  0.         -0.39590377]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 12774 is [True, False, False, False, False, True]
Current timestep = 12775. State = [[-0.07531247  0.22223663]]. Action = [[ 0.04928758  0.08788972  0.         -0.40251338]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 12775 is [True, False, False, False, False, True]
Current timestep = 12776. State = [[-0.07772669  0.22373274]]. Action = [[-0.0582828  -0.04856565  0.          0.9173231 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 12776 is [True, False, False, False, False, True]
Current timestep = 12777. State = [[-0.07790481  0.22267808]]. Action = [[ 0.05180068 -0.01318303  0.         -0.6525259 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 12777 is [True, False, False, False, False, True]
Current timestep = 12778. State = [[-0.07323369  0.21951684]]. Action = [[ 0.08956137 -0.05603296  0.          0.22269678]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 12778 is [True, False, False, False, False, True]
Current timestep = 12779. State = [[-0.06823073  0.21287096]]. Action = [[ 0.05916376 -0.08720725  0.          0.48842   ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 12779 is [True, False, False, False, False, True]
Current timestep = 12780. State = [[-0.06606054  0.20993032]]. Action = [[0.00497131 0.01546901 0.         0.5376626 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 12780 is [True, False, False, False, False, True]
Current timestep = 12781. State = [[-0.06093658  0.20470016]]. Action = [[ 0.09357751 -0.08445137  0.          0.7414663 ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 12781 is [True, False, False, False, False, True]
Current timestep = 12782. State = [[-0.05984365  0.19906805]]. Action = [[-0.05136668 -0.03317402  0.          0.6773473 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 12782 is [True, False, False, False, False, True]
State prediction error at timestep 12782 is 0.012
Human Feedback received at timestep 12782 of None
Current timestep = 12783. State = [[-0.05568684  0.19352148]]. Action = [[ 0.09529162 -0.05516942  0.         -0.40870583]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 12783 is [True, False, False, False, False, True]
Current timestep = 12784. State = [[-0.05462839  0.18761684]]. Action = [[-0.06212724 -0.04993758  0.         -0.9378342 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 12784 is [True, False, False, False, False, True]
State prediction error at timestep 12784 is 0.012
Human Feedback received at timestep 12784 of None
Current timestep = 12785. State = [[-0.0514736   0.18063772]]. Action = [[ 0.07464056 -0.07198866  0.         -0.29906034]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 12785 is [True, False, False, False, False, True]
Current timestep = 12786. State = [[-0.04776145  0.17311159]]. Action = [[ 0.00936534 -0.06319636  0.         -0.8774921 ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 12786 is [True, False, False, False, False, True]
Current timestep = 12787. State = [[-0.04839304  0.16502936]]. Action = [[-0.05248339 -0.08242731  0.          0.817875  ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 12787 is [False, True, False, False, False, True]
Current timestep = 12788. State = [[-0.05116736  0.16302297]]. Action = [[-0.05796088  0.04403795  0.         -0.17860341]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 12788 is [False, True, False, False, False, True]
Current timestep = 12789. State = [[-0.0504925   0.16329785]]. Action = [[0.03541177 0.01174022 0.         0.20334673]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 12789 is [True, False, False, False, False, True]
Current timestep = 12790. State = [[-0.04536435  0.16381197]]. Action = [[0.08818307 0.03409832 0.         0.2343427 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 12790 is [True, False, False, False, False, True]
Current timestep = 12791. State = [[-0.04502092  0.16590048]]. Action = [[-0.03868803  0.04979607  0.         -0.6946254 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 12791 is [False, True, False, False, False, True]
Current timestep = 12792. State = [[-0.04809852  0.16416468]]. Action = [[-0.03685351 -0.05133162  0.         -0.3828472 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 12792 is [False, True, False, False, False, True]
Current timestep = 12793. State = [[-0.04977443  0.1632089 ]]. Action = [[-0.00857672  0.01673986  0.          0.56590486]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 12793 is [False, True, False, False, False, True]
Current timestep = 12794. State = [[-0.05475973  0.16553451]]. Action = [[-0.08820857  0.0404989   0.         -0.39355195]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 12794 is [False, True, False, False, False, True]
State prediction error at timestep 12794 is 0.012
Human Feedback received at timestep 12794 of None
Current timestep = 12795. State = [[-0.0566439  0.1670351]]. Action = [[ 0.02544213 -0.00106174  0.          0.1491847 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 12795 is [True, False, False, False, False, True]
Current timestep = 12796. State = [[-0.0573445   0.16832945]]. Action = [[-0.01041347  0.0196406   0.          0.28808498]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 12796 is [True, False, False, False, False, True]
Current timestep = 12797. State = [[-0.05741717  0.1680816 ]]. Action = [[ 0.01913766 -0.02268699  0.          0.6295444 ]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 12797 is [True, False, False, False, False, True]
State prediction error at timestep 12797 is 0.012
Human Feedback received at timestep 12797 of None
Current timestep = 12798. State = [[-0.05304203  0.16765185]]. Action = [[ 0.09492636  0.00537427  0.         -0.1604054 ]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 12798 is [True, False, False, False, False, True]
State prediction error at timestep 12798 is 0.012
Human Feedback received at timestep 12798 of None
Current timestep = 12799. State = [[-0.04667389  0.17042273]]. Action = [[ 0.09488935  0.06719802  0.         -0.90353256]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 12799 is [True, False, False, False, False, True]
Current timestep = 12800. State = [[-0.04099125  0.16886897]]. Action = [[ 0.07273538 -0.05262659  0.          0.26836717]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 12800 is [False, True, False, False, False, True]
Current timestep = 12801. State = [[-0.03661301  0.16272725]]. Action = [[ 0.0404677  -0.07597142  0.          0.278062  ]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 12801 is [False, True, False, False, False, True]
Current timestep = 12802. State = [[-0.03167626  0.1557447 ]]. Action = [[ 0.05671001 -0.07094083  0.          0.13286352]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 12802 is [False, True, False, False, False, True]
Current timestep = 12803. State = [[-0.02640618  0.15103014]]. Action = [[ 0.04735821 -0.01987462  0.         -0.17419964]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 12803 is [False, True, False, False, False, True]
State prediction error at timestep 12803 is 0.012
Human Feedback received at timestep 12803 of None
Current timestep = 12804. State = [[-0.02239443  0.1507505 ]]. Action = [[ 0.02547515  0.04230096  0.         -0.79754555]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 12804 is [False, True, False, False, False, True]
Current timestep = 12805. State = [[-0.02324086  0.15087654]]. Action = [[-0.06452253  0.00289007  0.          0.62980103]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 12805 is [False, True, False, False, False, True]
Current timestep = 12806. State = [[-0.0193346   0.14524159]]. Action = [[ 0.08600824 -0.09958628  0.          0.5094774 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 12806 is [False, True, False, False, False, True]
State prediction error at timestep 12806 is 0.012
Human Feedback received at timestep 12806 of None
Current timestep = 12807. State = [[-0.01889382  0.14007202]]. Action = [[-0.08103447 -0.02814456  0.         -0.5374563 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 12807 is [False, True, False, False, False, True]
Current timestep = 12808. State = [[-0.0191156   0.13773122]]. Action = [[ 0.00367136 -0.01479156  0.         -0.37472713]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 12808 is [False, True, False, False, False, True]
State prediction error at timestep 12808 is 0.012
Human Feedback received at timestep 12808 of None
Current timestep = 12809. State = [[-0.01430717  0.13816625]]. Action = [[ 0.07827901  0.03509267  0.         -0.6732801 ]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 12809 is [False, True, False, False, False, True]
State prediction error at timestep 12809 is 0.012
Human Feedback received at timestep 12809 of None
Current timestep = 12810. State = [[-0.00812527  0.13556604]]. Action = [[ 0.06788155 -0.05191977  0.         -0.19114614]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 12810 is [False, True, False, False, False, True]
Current timestep = 12811. State = [[-0.0058024   0.13035516]]. Action = [[-0.01622804 -0.05403934  0.         -0.9244531 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 12811 is [False, True, False, False, False, True]
State prediction error at timestep 12811 is 0.012
Human Feedback received at timestep 12811 of None
Current timestep = 12812. State = [[-0.3330548   0.03190787]]. Action = [[-0.00881414 -0.09662123  0.         -0.00016987]]. Reward = [100.]
Curr episode timestep = 90
Scene graph at timestep 12812 is [False, True, False, False, False, True]
Current timestep = 12813. State = [[-0.33069214  0.02744314]]. Action = [[-0.05408141 -0.00323613  0.         -0.51986414]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 12813 is [True, False, False, False, True, False]
State prediction error at timestep 12813 is 0.012
Human Feedback received at timestep 12813 of None
Current timestep = 12814. State = [[-0.33370456  0.02717458]]. Action = [[-0.06825632  0.02100668  0.         -0.8567784 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 12814 is [True, False, False, False, True, False]
Current timestep = 12815. State = [[-0.33051428  0.02285567]]. Action = [[ 0.08931168 -0.07705277  0.         -0.8610741 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 12815 is [True, False, False, False, True, False]
Current timestep = 12816. State = [[-0.32273078  0.02137392]]. Action = [[ 0.08720144  0.04302161  0.         -0.4681909 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 12816 is [True, False, False, False, True, False]
Current timestep = 12817. State = [[-0.31837514  0.02605301]]. Action = [[ 0.01914998  0.09010526  0.         -0.8622679 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 12817 is [True, False, False, False, True, False]
Current timestep = 12818. State = [[-0.31837714  0.03029102]]. Action = [[-0.0261185   0.03724612  0.          0.20410538]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 12818 is [True, False, False, False, True, False]
State prediction error at timestep 12818 is 0.012
Human Feedback received at timestep 12818 of None
Current timestep = 12819. State = [[-0.3181893   0.02829098]]. Action = [[ 0.00309396 -0.06521112  0.         -0.9164697 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 12819 is [True, False, False, False, True, False]
Current timestep = 12820. State = [[-0.31994483  0.02343831]]. Action = [[-0.05951056 -0.05782734  0.          0.3294053 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 12820 is [True, False, False, False, True, False]
Current timestep = 12821. State = [[-0.31730974  0.0237908 ]]. Action = [[ 0.07474167  0.04796628  0.         -0.6683632 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 12821 is [True, False, False, False, True, False]
Current timestep = 12822. State = [[-0.31723794  0.02684294]]. Action = [[-0.06098814  0.03267241  0.         -0.14967191]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 12822 is [True, False, False, False, True, False]
Current timestep = 12823. State = [[-0.31551975  0.02314577]]. Action = [[ 0.05146224 -0.09880527  0.         -0.8639818 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 12823 is [True, False, False, False, True, False]
State prediction error at timestep 12823 is 0.012
Human Feedback received at timestep 12823 of None
Current timestep = 12824. State = [[-0.31451133  0.01871753]]. Action = [[-0.02784799 -0.02584669  0.         -0.99441504]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 12824 is [True, False, False, False, True, False]
Current timestep = 12825. State = [[-0.30997774  0.0142094 ]]. Action = [[ 0.08980865 -0.0607023   0.         -0.71979713]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12825 is [True, False, False, False, True, False]
State prediction error at timestep 12825 is 0.012
Human Feedback received at timestep 12825 of None
Current timestep = 12826. State = [[-0.30848917  0.00703114]]. Action = [[-0.04992848 -0.08836321  0.         -0.8990686 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 12826 is [True, False, False, False, True, False]
Current timestep = 12827. State = [[-0.3128962   0.00479576]]. Action = [[-0.08868848  0.03195248  0.         -0.5015787 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 12827 is [True, False, False, False, True, False]
State prediction error at timestep 12827 is 0.012
Human Feedback received at timestep 12827 of None
Current timestep = 12828. State = [[-0.31904215  0.00904167]]. Action = [[-0.08521345  0.08480432  0.          0.45017612]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 12828 is [True, False, False, False, True, False]
Current timestep = 12829. State = [[-0.32229814  0.00711412]]. Action = [[-0.01237252 -0.08581334  0.          0.4522252 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 12829 is [True, False, False, False, True, False]
Current timestep = 12830. State = [[-0.32561478  0.00771187]]. Action = [[-0.04554886  0.07162934  0.         -0.528953  ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 12830 is [True, False, False, False, True, False]
Current timestep = 12831. State = [[-0.3317129   0.01107717]]. Action = [[-0.07580807  0.02752381  0.         -0.85893804]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 12831 is [True, False, False, False, True, False]
State prediction error at timestep 12831 is 0.012
Human Feedback received at timestep 12831 of None
Current timestep = 12832. State = [[-0.3326765   0.01543051]]. Action = [[ 0.06434006  0.06076569  0.         -0.88231003]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 12832 is [True, False, False, False, True, False]
Current timestep = 12833. State = [[-0.32931948  0.01570963]]. Action = [[ 0.07041397 -0.04322359  0.         -0.6418066 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 12833 is [True, False, False, False, True, False]
Current timestep = 12834. State = [[-0.3242083   0.01477849]]. Action = [[ 9.0380572e-02 -4.6814978e-04  0.0000000e+00 -8.4710991e-01]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 12834 is [True, False, False, False, True, False]
Current timestep = 12835. State = [[-0.3201524   0.01348337]]. Action = [[ 0.04615993 -0.02542366  0.          0.29935837]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 12835 is [True, False, False, False, True, False]
State prediction error at timestep 12835 is 0.012
Human Feedback received at timestep 12835 of None
Current timestep = 12836. State = [[-0.32257622  0.01410481]]. Action = [[-0.07990257  0.02902059  0.         -0.84929496]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 12836 is [True, False, False, False, True, False]
Current timestep = 12837. State = [[-0.3206184   0.01054358]]. Action = [[ 0.09680233 -0.08540487  0.         -0.8012908 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 12837 is [True, False, False, False, True, False]
State prediction error at timestep 12837 is 0.012
Human Feedback received at timestep 12837 of None
Current timestep = 12838. State = [[-0.31492564  0.01174301]]. Action = [[0.06014744 0.08418184 0.         0.46041977]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 12838 is [True, False, False, False, True, False]
Current timestep = 12839. State = [[-0.31448558  0.01394586]]. Action = [[-0.03790766 -0.00259718  0.          0.03678286]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 12839 is [True, False, False, False, True, False]
Current timestep = 12840. State = [[-0.3191432   0.01919389]]. Action = [[-0.08754562  0.09953941  0.         -0.9261584 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 12840 is [True, False, False, False, True, False]
Current timestep = 12841. State = [[-0.3200683   0.02498269]]. Action = [[0.03482626 0.04212097 0.         0.42104554]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 12841 is [True, False, False, False, True, False]
State prediction error at timestep 12841 is 0.012
Human Feedback received at timestep 12841 of None
Current timestep = 12842. State = [[-0.31799412  0.02631001]]. Action = [[ 0.02611078 -0.02118038  0.         -0.5571972 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 12842 is [True, False, False, False, True, False]
State prediction error at timestep 12842 is 0.012
Human Feedback received at timestep 12842 of None
Current timestep = 12843. State = [[-0.31474346  0.03160895]]. Action = [[ 0.0515599   0.09848184  0.         -0.4198922 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 12843 is [True, False, False, False, True, False]
Current timestep = 12844. State = [[-0.31730336  0.03745537]]. Action = [[-0.08390266  0.03363582  0.         -0.8416699 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 12844 is [True, False, False, False, True, False]
Current timestep = 12845. State = [[-0.31657636  0.04232732]]. Action = [[0.07926563 0.04635372 0.         0.7101071 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 12845 is [True, False, False, False, True, False]
Current timestep = 12846. State = [[-0.31180814  0.04998379]]. Action = [[ 0.06563265  0.09483887  0.         -0.20126861]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 12846 is [True, False, False, False, True, False]
Current timestep = 12847. State = [[-0.30661783  0.05181128]]. Action = [[ 0.07176027 -0.05074389  0.         -0.5475708 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 12847 is [True, False, False, False, True, False]
Current timestep = 12848. State = [[-0.30371106  0.05086582]]. Action = [[ 0.00398432 -0.01645351  0.         -0.44924122]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 12848 is [True, False, False, False, True, False]
Current timestep = 12849. State = [[-0.30006018  0.05387563]]. Action = [[ 0.05076747  0.05013228  0.         -0.15113556]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 12849 is [True, False, False, False, True, False]
State prediction error at timestep 12849 is 0.012
Human Feedback received at timestep 12849 of None
Current timestep = 12850. State = [[-0.29956296  0.05616046]]. Action = [[-0.04118143 -0.00427818  0.          0.6638057 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 12850 is [True, False, False, False, True, False]
Current timestep = 12851. State = [[-0.29565534  0.05762491]]. Action = [[0.0798495  0.0109589  0.         0.32055056]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 12851 is [True, False, False, False, True, False]
Current timestep = 12852. State = [[-0.28802252  0.05464495]]. Action = [[ 0.08022822 -0.07788689  0.         -0.45510244]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 12852 is [True, False, False, False, True, False]
State prediction error at timestep 12852 is 0.012
Human Feedback received at timestep 12852 of None
Current timestep = 12853. State = [[-0.28110033  0.05299298]]. Action = [[ 0.05268345  0.01002618  0.         -0.05124503]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 12853 is [True, False, False, False, True, False]
Current timestep = 12854. State = [[-0.27826402  0.05809421]]. Action = [[-0.01297052  0.09689515  0.         -0.9348711 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 12854 is [True, False, False, False, True, False]
State prediction error at timestep 12854 is 0.012
Human Feedback received at timestep 12854 of None
Current timestep = 12855. State = [[-0.28087902  0.06480397]]. Action = [[-0.07900526  0.06525163  0.         -0.2691899 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 12855 is [True, False, False, False, True, False]
Current timestep = 12856. State = [[-0.27825424  0.06963968]]. Action = [[ 0.08392813  0.03628821  0.         -0.8191205 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 12856 is [True, False, False, False, True, False]
Current timestep = 12857. State = [[-0.27657187  0.06752949]]. Action = [[-0.04509213 -0.0877945   0.          0.72584593]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 12857 is [True, False, False, False, True, False]
Current timestep = 12858. State = [[-0.27479428  0.06976387]]. Action = [[ 0.03372482  0.07911148  0.         -0.16723156]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 12858 is [True, False, False, False, True, False]
Current timestep = 12859. State = [[-0.2685395   0.07755637]]. Action = [[ 0.09735856  0.09376914  0.         -0.13619721]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 12859 is [True, False, False, False, True, False]
Current timestep = 12860. State = [[-0.2612023  0.0857029]]. Action = [[0.09000934 0.08823474 0.         0.35803223]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 12860 is [True, False, False, False, True, False]
Current timestep = 12861. State = [[-0.25393096  0.0889529 ]]. Action = [[ 0.08550025 -0.0076377   0.         -0.76549876]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 12861 is [True, False, False, False, True, False]
Current timestep = 12862. State = [[-0.24675351  0.0872724 ]]. Action = [[ 0.07075193 -0.04975129  0.          0.77017236]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 12862 is [True, False, False, False, True, False]
Current timestep = 12863. State = [[-0.23796976  0.08263952]]. Action = [[ 0.0970043 -0.076421   0.        -0.3730793]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 12863 is [True, False, False, False, True, False]
State prediction error at timestep 12863 is 0.012
Human Feedback received at timestep 12863 of None
Current timestep = 12864. State = [[-0.22979306  0.08519448]]. Action = [[0.0637609  0.09546014 0.         0.49667156]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 12864 is [True, False, False, False, True, False]
State prediction error at timestep 12864 is 0.012
Human Feedback received at timestep 12864 of None
Current timestep = 12865. State = [[-0.22722375  0.08574939]]. Action = [[-0.03853536 -0.05315137  0.         -0.42762178]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 12865 is [True, False, False, False, True, False]
Current timestep = 12866. State = [[-0.22974122  0.08956889]]. Action = [[-0.08120786  0.08810938  0.          0.43834352]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 12866 is [True, False, False, False, True, False]
Current timestep = 12867. State = [[-0.22849818  0.09802676]]. Action = [[0.04686701 0.09699837 0.         0.04415977]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 12867 is [True, False, False, False, True, False]
Current timestep = 12868. State = [[-0.22145067  0.09795517]]. Action = [[ 0.09377477 -0.08552121  0.         -0.6134666 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 12868 is [True, False, False, False, True, False]
State prediction error at timestep 12868 is 0.012
Human Feedback received at timestep 12868 of None
Current timestep = 12869. State = [[-0.21523389  0.09892765]]. Action = [[ 0.03808185  0.05370993  0.         -0.30618536]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 12869 is [True, False, False, False, True, False]
Current timestep = 12870. State = [[-0.21113612  0.09746095]]. Action = [[ 0.02354611 -0.07327209  0.         -0.7229588 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 12870 is [True, False, False, False, True, False]
State prediction error at timestep 12870 is 0.012
Human Feedback received at timestep 12870 of None
Current timestep = 12871. State = [[-0.21045004  0.09645861]]. Action = [[-0.04323759  0.00689746  0.         -0.63903093]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 12871 is [True, False, False, False, True, False]
Current timestep = 12872. State = [[-0.20888251  0.10164717]]. Action = [[ 0.02181153  0.08678     0.         -0.88193995]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 12872 is [True, False, False, False, True, False]
Current timestep = 12873. State = [[-0.2025199   0.10357121]]. Action = [[ 0.09481085 -0.02525322  0.         -0.6727378 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 12873 is [True, False, False, False, True, False]
Current timestep = 12874. State = [[-0.1960219   0.10554156]]. Action = [[0.0522402  0.04580534 0.         0.38519287]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 12874 is [True, False, False, False, True, False]
State prediction error at timestep 12874 is 0.012
Human Feedback received at timestep 12874 of None
Current timestep = 12875. State = [[-0.19145922  0.11182236]]. Action = [[ 0.03767652  0.09365102  0.         -0.41827536]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 12875 is [True, False, False, False, True, False]
Current timestep = 12876. State = [[-0.18918577  0.11991587]]. Action = [[ 0.00833715  0.09364793  0.         -0.7282607 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 12876 is [True, False, False, False, True, False]
State prediction error at timestep 12876 is 0.012
Human Feedback received at timestep 12876 of None
Current timestep = 12877. State = [[-0.19059455  0.12042465]]. Action = [[-0.05350823 -0.07254946  0.          0.04200149]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 12877 is [True, False, False, False, True, False]
Current timestep = 12878. State = [[-0.18766281  0.11910509]]. Action = [[ 0.07061698 -0.01230408  0.         -0.7506149 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 12878 is [True, False, False, False, True, False]
Current timestep = 12879. State = [[-0.18123886  0.12153657]]. Action = [[ 0.06752598  0.04168934  0.         -0.00696212]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 12879 is [True, False, False, False, True, False]
State prediction error at timestep 12879 is 0.012
Human Feedback received at timestep 12879 of None
Current timestep = 12880. State = [[-0.18016472  0.12802413]]. Action = [[-0.04059235  0.09003442  0.         -0.6133003 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 12880 is [True, False, False, False, True, False]
Current timestep = 12881. State = [[-0.18175423  0.13277273]]. Action = [[-0.02819474  0.01450437  0.         -0.80186266]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 12881 is [True, False, False, False, False, True]
Current timestep = 12882. State = [[-0.17724665  0.13320181]]. Action = [[ 0.0932442  -0.02959094  0.         -0.31307608]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 12882 is [True, False, False, False, False, True]
Current timestep = 12883. State = [[-0.16965808  0.13490808]]. Action = [[ 0.08254244  0.0357041   0.         -0.5821297 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 12883 is [True, False, False, False, False, True]
Current timestep = 12884. State = [[-0.16197076  0.13298096]]. Action = [[ 0.08081297 -0.06770833  0.          0.5619011 ]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 12884 is [True, False, False, False, False, True]
Current timestep = 12885. State = [[-0.1601922   0.13393624]]. Action = [[-0.0480698   0.05148239  0.          0.3547635 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 12885 is [True, False, False, False, False, True]
Current timestep = 12886. State = [[-0.16030341  0.13847409]]. Action = [[-0.00822942  0.04702836  0.         -0.11205387]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 12886 is [True, False, False, False, False, True]
Current timestep = 12887. State = [[-0.15696591  0.14527522]]. Action = [[ 0.05386884  0.090694    0.         -0.22400838]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 12887 is [True, False, False, False, False, True]
Current timestep = 12888. State = [[-0.15524612  0.14543708]]. Action = [[-0.01706823 -0.07093488  0.         -0.05316263]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 12888 is [True, False, False, False, False, True]
Current timestep = 12889. State = [[-0.15129769  0.14070056]]. Action = [[ 0.06133724 -0.07414619  0.         -0.55325764]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 12889 is [True, False, False, False, False, True]
State prediction error at timestep 12889 is 0.012
Human Feedback received at timestep 12889 of None
Current timestep = 12890. State = [[-0.15200077  0.13760139]]. Action = [[-0.08425736 -0.02852368  0.          0.30959606]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 12890 is [True, False, False, False, False, True]
Current timestep = 12891. State = [[-0.15446274  0.13515018]]. Action = [[-0.0357884  -0.04434872  0.         -0.7204532 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 12891 is [True, False, False, False, False, True]
State prediction error at timestep 12891 is 0.012
Human Feedback received at timestep 12891 of None
Current timestep = 12892. State = [[-0.15208848  0.12947284]]. Action = [[ 0.04374153 -0.09296425  0.         -0.27784038]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 12892 is [True, False, False, False, False, True]
State prediction error at timestep 12892 is 0.012
Human Feedback received at timestep 12892 of None
Current timestep = 12893. State = [[-0.15297328  0.12326341]]. Action = [[-0.07256453 -0.06410553  0.         -0.4535799 ]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 12893 is [True, False, False, False, False, True]
Current timestep = 12894. State = [[-0.15848732  0.12535816]]. Action = [[-0.09478493  0.08742253  0.         -0.9007833 ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 12894 is [True, False, False, False, True, False]
Current timestep = 12895. State = [[-0.1569922   0.12746587]]. Action = [[ 0.09392311 -0.00121487  0.          0.48600507]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 12895 is [True, False, False, False, False, True]
Current timestep = 12896. State = [[-0.15080868  0.13018505]]. Action = [[ 0.08264229  0.06574257  0.         -0.96404517]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 12896 is [True, False, False, False, False, True]
Current timestep = 12897. State = [[-0.14771312  0.13291748]]. Action = [[ 0.02084035  0.03014243  0.         -0.10293114]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 12897 is [True, False, False, False, False, True]
State prediction error at timestep 12897 is 0.012
Human Feedback received at timestep 12897 of None
Current timestep = 12898. State = [[-0.1439422  0.1310166]]. Action = [[ 0.06406053 -0.04802826  0.          0.25297606]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 12898 is [True, False, False, False, False, True]
Current timestep = 12899. State = [[-0.13877876  0.1327537 ]]. Action = [[ 0.06620019  0.0763882   0.         -0.86580527]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 12899 is [True, False, False, False, False, True]
Current timestep = 12900. State = [[-0.14025216  0.13908982]]. Action = [[-0.07121718  0.09106614  0.          0.2783363 ]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 12900 is [True, False, False, False, False, True]
Current timestep = 12901. State = [[-0.1381445   0.14360963]]. Action = [[ 0.09417827  0.03285191  0.         -0.5263084 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 12901 is [True, False, False, False, False, True]
Current timestep = 12902. State = [[-0.1340494   0.14630494]]. Action = [[ 0.03613401  0.02866208  0.         -0.91429174]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 12902 is [True, False, False, False, False, True]
Current timestep = 12903. State = [[-0.12860104  0.15054797]]. Action = [[ 0.08777478  0.06186087  0.         -0.4631139 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 12903 is [True, False, False, False, False, True]
Current timestep = 12904. State = [[-0.12493719  0.15506174]]. Action = [[ 0.02064111  0.04632283  0.         -0.90807295]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 12904 is [True, False, False, False, False, True]
Current timestep = 12905. State = [[-0.12571584  0.16112788]]. Action = [[-0.03762026  0.07500697  0.         -0.37274396]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 12905 is [True, False, False, False, False, True]
Current timestep = 12906. State = [[-0.12321527  0.16890591]]. Action = [[0.06866682 0.08488584 0.         0.9398837 ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 12906 is [True, False, False, False, False, True]
Current timestep = 12907. State = [[-0.11848668  0.1705826 ]]. Action = [[ 0.04944403 -0.0459809   0.          0.5379319 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 12907 is [True, False, False, False, False, True]
State prediction error at timestep 12907 is 0.012
Human Feedback received at timestep 12907 of None
Current timestep = 12908. State = [[-0.11790098  0.16739489]]. Action = [[-0.04674333 -0.07391085  0.         -0.4816311 ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 12908 is [True, False, False, False, False, True]
Current timestep = 12909. State = [[-0.11497021  0.16266668]]. Action = [[ 0.04731358 -0.08281136  0.         -0.62481475]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 12909 is [True, False, False, False, False, True]
Current timestep = 12910. State = [[-0.11555374  0.16396996]]. Action = [[-0.07705651  0.05703486  0.          0.56851697]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 12910 is [True, False, False, False, False, True]
State prediction error at timestep 12910 is 0.012
Human Feedback received at timestep 12910 of None
Current timestep = 12911. State = [[-0.11151062  0.162972  ]]. Action = [[ 0.09409631 -0.0730503   0.         -0.09855735]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 12911 is [True, False, False, False, False, True]
Current timestep = 12912. State = [[-0.10323683  0.15688083]]. Action = [[ 0.07846162 -0.08663359  0.          0.87198937]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 12912 is [True, False, False, False, False, True]
Current timestep = 12913. State = [[-0.09647448  0.15530768]]. Action = [[0.04761355 0.03142718 0.         0.85423875]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 12913 is [True, False, False, False, False, True]
Current timestep = 12914. State = [[-0.09217051  0.15709339]]. Action = [[ 0.02103125  0.0339934   0.         -0.38389146]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 12914 is [True, False, False, False, False, True]
Current timestep = 12915. State = [[-0.08623987  0.15266854]]. Action = [[ 0.07050488 -0.09626089  0.         -0.6964751 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 12915 is [True, False, False, False, False, True]
Current timestep = 12916. State = [[-0.07749794  0.14829239]]. Action = [[ 0.09647424 -0.00889616  0.         -0.82661456]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 12916 is [True, False, False, False, False, True]
State prediction error at timestep 12916 is 0.012
Human Feedback received at timestep 12916 of None
Current timestep = 12917. State = [[-0.0707179   0.14862081]]. Action = [[ 0.04375283  0.04614434  0.         -0.950752  ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 12917 is [True, False, False, False, False, True]
Current timestep = 12918. State = [[-0.06854486  0.1519313 ]]. Action = [[-0.01624532  0.0637381   0.         -0.6642901 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 12918 is [True, False, False, False, False, True]
State prediction error at timestep 12918 is 0.012
Human Feedback received at timestep 12918 of None
Current timestep = 12919. State = [[-0.07057485  0.15674298]]. Action = [[-0.06205236  0.06467532  0.          0.19524825]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 12919 is [True, False, False, False, False, True]
State prediction error at timestep 12919 is 0.012
Human Feedback received at timestep 12919 of None
Current timestep = 12920. State = [[-0.06876826  0.15593779]]. Action = [[ 0.04853707 -0.06271494  0.         -0.90197986]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 12920 is [True, False, False, False, False, True]
Current timestep = 12921. State = [[-0.06640725  0.15341985]]. Action = [[-0.00391705 -0.02082212  0.          0.24949098]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 12921 is [True, False, False, False, False, True]
Current timestep = 12922. State = [[-0.06306639  0.15558486]]. Action = [[ 0.04692661  0.05400675  0.         -0.9401994 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 12922 is [True, False, False, False, False, True]
State prediction error at timestep 12922 is 0.012
Human Feedback received at timestep 12922 of None
Current timestep = 12923. State = [[-0.06420972  0.1575072 ]]. Action = [[-0.07197883 -0.00107398  0.         -0.7417352 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 12923 is [True, False, False, False, False, True]
Current timestep = 12924. State = [[-0.06157666  0.15503804]]. Action = [[ 0.08047592 -0.06035705  0.         -0.7427518 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 12924 is [True, False, False, False, False, True]
Current timestep = 12925. State = [[-0.06258696  0.15798625]]. Action = [[-0.08138707  0.09116244  0.         -0.95220757]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 12925 is [True, False, False, False, False, True]
State prediction error at timestep 12925 is 0.012
Human Feedback received at timestep 12925 of None
Current timestep = 12926. State = [[-0.06238144  0.16218612]]. Action = [[0.04268635 0.01596026 0.         0.5370972 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 12926 is [True, False, False, False, False, True]
Current timestep = 12927. State = [[-0.05947257  0.1677107 ]]. Action = [[ 0.03866784  0.08481007  0.         -0.12189823]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 12927 is [True, False, False, False, False, True]
Current timestep = 12928. State = [[-0.06154152  0.17514367]]. Action = [[-0.0586345   0.08073182  0.         -0.69743764]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 12928 is [True, False, False, False, False, True]
Current timestep = 12929. State = [[-0.0664411   0.17452247]]. Action = [[-0.06574273 -0.09501422  0.          0.14375913]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 12929 is [True, False, False, False, False, True]
Current timestep = 12930. State = [[-0.07209923  0.17430384]]. Action = [[-0.08399747  0.01127462  0.         -0.47347975]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 12930 is [True, False, False, False, False, True]
State prediction error at timestep 12930 is 0.012
Human Feedback received at timestep 12930 of None
Current timestep = 12931. State = [[-0.07305297  0.17858177]]. Action = [[ 0.0399872   0.05155801  0.         -0.8732561 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 12931 is [True, False, False, False, False, True]
Current timestep = 12932. State = [[-0.07585809  0.18135145]]. Action = [[-0.07519221 -0.00625449  0.          0.2397449 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 12932 is [True, False, False, False, False, True]
Current timestep = 12933. State = [[-0.07581078  0.1824168 ]]. Action = [[ 0.05209417 -0.00388452  0.         -0.16322452]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 12933 is [True, False, False, False, False, True]
Current timestep = 12934. State = [[-0.07051589  0.18215439]]. Action = [[ 0.08978086 -0.01609288  0.          0.76779866]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 12934 is [True, False, False, False, False, True]
Current timestep = 12935. State = [[-0.06949715  0.17960128]]. Action = [[-0.03590353 -0.04689638  0.          0.01392066]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 12935 is [True, False, False, False, False, True]
State prediction error at timestep 12935 is 0.012
Human Feedback received at timestep 12935 of None
Current timestep = 12936. State = [[-0.06769089  0.1812952 ]]. Action = [[ 0.05892951  0.06480723  0.         -0.06404245]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 12936 is [True, False, False, False, False, True]
State prediction error at timestep 12936 is 0.012
Human Feedback received at timestep 12936 of None
Current timestep = 12937. State = [[-0.06198174  0.18665779]]. Action = [[0.09319944 0.0820579  0.         0.23100209]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 12937 is [True, False, False, False, False, True]
Current timestep = 12938. State = [[-0.05544405  0.18520579]]. Action = [[ 0.08552744 -0.06458236  0.          0.09951711]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 12938 is [True, False, False, False, False, True]
State prediction error at timestep 12938 is 0.012
Human Feedback received at timestep 12938 of None
Current timestep = 12939. State = [[-0.05503568  0.17871521]]. Action = [[-0.06822507 -0.08844491  0.          0.83119655]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 12939 is [True, False, False, False, False, True]
Current timestep = 12940. State = [[-0.05205655  0.1742964 ]]. Action = [[ 0.0883844  -0.01838184  0.          0.5423945 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 12940 is [True, False, False, False, False, True]
Current timestep = 12941. State = [[-0.05230466  0.17618401]]. Action = [[-0.07545176  0.06872893  0.         -0.36078918]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 12941 is [True, False, False, False, False, True]
Current timestep = 12942. State = [[-0.05089691  0.17390017]]. Action = [[ 0.05083307 -0.07909379  0.          0.6861414 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 12942 is [True, False, False, False, False, True]
Current timestep = 12943. State = [[-0.04976523  0.16662376]]. Action = [[-0.02939291 -0.09205113  0.         -0.673229  ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 12943 is [True, False, False, False, False, True]
Current timestep = 12944. State = [[-0.04697819  0.15940571]]. Action = [[ 0.04030099 -0.0744022   0.         -0.3750986 ]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 12944 is [False, True, False, False, False, True]
Current timestep = 12945. State = [[-0.04002059  0.15647851]]. Action = [[0.09459753 0.01666838 0.         0.70986557]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 12945 is [False, True, False, False, False, True]
Current timestep = 12946. State = [[-0.03163167  0.1553541 ]]. Action = [[ 0.0986068   0.00946967  0.         -0.11336327]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 12946 is [False, True, False, False, False, True]
Current timestep = 12947. State = [[-0.02398307  0.15411179]]. Action = [[ 0.08070339  0.01189915  0.         -0.23252034]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 12947 is [False, True, False, False, False, True]
Current timestep = 12948. State = [[-0.01690666  0.15465997]]. Action = [[ 0.07947675  0.04618081  0.         -0.98371094]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 12948 is [False, True, False, False, False, True]
Current timestep = 12949. State = [[-0.01443312  0.15477654]]. Action = [[-0.01760156  0.00804196  0.         -0.8036778 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 12949 is [False, True, False, False, False, True]
Current timestep = 12950. State = [[-0.00962977  0.15094356]]. Action = [[ 0.08408635 -0.05953231  0.         -0.72481465]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 12950 is [False, True, False, False, False, True]
State prediction error at timestep 12950 is 0.012
Human Feedback received at timestep 12950 of None
Current timestep = 12951. State = [[-0.00316916  0.15270868]]. Action = [[0.06456996 0.0975147  0.         0.3799131 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 12951 is [False, True, False, False, False, True]
Current timestep = 12952. State = [[-0.00088159  0.15196495]]. Action = [[-0.01579196 -0.05418593  0.         -0.9539409 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 12952 is [False, True, False, False, False, True]
Current timestep = 12953. State = [[0.00401476 0.15225309]]. Action = [[ 0.09238467  0.04800252  0.         -0.86280924]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 12953 is [False, True, False, False, False, True]
Current timestep = 12954. State = [[0.00452693 0.1582717 ]]. Action = [[-0.06486398  0.09951606  0.         -0.3382594 ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 12954 is [False, True, False, False, False, True]
Current timestep = 12955. State = [[0.00254455 0.16402152]]. Action = [[-0.02049876  0.04252673  0.         -0.9812661 ]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 12955 is [False, True, False, False, False, True]
State prediction error at timestep 12955 is 0.012
Human Feedback received at timestep 12955 of None
Current timestep = 12956. State = [[0.00543241 0.16373566]]. Action = [[ 0.05969439 -0.05504954  0.         -0.976307  ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 12956 is [False, True, False, False, False, True]
Current timestep = 12957. State = [[0.00774995 0.15976667]]. Action = [[-0.00714102 -0.06631956  0.         -0.93290985]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 12957 is [False, True, False, False, False, True]
State prediction error at timestep 12957 is 0.012
Human Feedback received at timestep 12957 of None
Current timestep = 12958. State = [[0.00921025 0.15777491]]. Action = [[ 0.00295945 -0.01392095  0.         -0.18970501]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 12958 is [False, True, False, False, False, True]
State prediction error at timestep 12958 is 0.012
Human Feedback received at timestep 12958 of None
Current timestep = 12959. State = [[0.00730735 0.16171081]]. Action = [[-0.06798741  0.07459898  0.         -0.20680457]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 12959 is [False, True, False, False, False, True]
State prediction error at timestep 12959 is 0.012
Human Feedback received at timestep 12959 of None
Current timestep = 12960. State = [[0.00620991 0.1683793 ]]. Action = [[-0.00157025  0.06630845  0.         -0.7275108 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 12960 is [False, True, False, False, False, True]
State prediction error at timestep 12960 is 0.012
Human Feedback received at timestep 12960 of None
Current timestep = 12961. State = [[0.00265063 0.17274769]]. Action = [[-0.08243434  0.0143816   0.         -0.52105004]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 12961 is [False, True, False, False, False, True]
Current timestep = 12962. State = [[-0.00093341  0.17411746]]. Action = [[-0.03966209 -0.02282297  0.          0.07694304]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 12962 is [False, True, False, False, False, True]
Current timestep = 12963. State = [[-0.00498784  0.17664531]]. Action = [[-0.06941114  0.02332214  0.          0.23884487]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 12963 is [False, True, False, False, False, True]
State prediction error at timestep 12963 is 0.012
Human Feedback received at timestep 12963 of None
Current timestep = 12964. State = [[-0.00992048  0.18296522]]. Action = [[-0.06292269  0.07073488  0.          0.8153964 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 12964 is [False, True, False, False, False, True]
Current timestep = 12965. State = [[-0.01451755  0.18431696]]. Action = [[-0.05289324 -0.06184722  0.         -0.89854556]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 12965 is [False, True, False, False, False, True]
Current timestep = 12966. State = [[-0.01642111  0.18877599]]. Action = [[ 0.0021891   0.08416823  0.         -0.9147851 ]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 12966 is [False, True, False, False, False, True]
Current timestep = 12967. State = [[-0.01345877  0.19067861]]. Action = [[ 0.08129694 -0.03890177  0.         -0.35848755]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 12967 is [False, True, False, False, False, True]
Current timestep = 12968. State = [[-0.00772445  0.18988281]]. Action = [[ 0.09166668 -0.00566734  0.         -0.44026875]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 12968 is [False, True, False, False, False, True]
Current timestep = 12969. State = [[-0.00606019  0.18559134]]. Action = [[-0.0197476  -0.08210263  0.         -0.5726199 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 12969 is [False, True, False, False, False, True]
Current timestep = 12970. State = [[-0.00422265  0.17818326]]. Action = [[ 0.04259878 -0.08992254  0.          0.27624524]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 12970 is [False, True, False, False, False, True]
Current timestep = 12971. State = [[-0.00356865  0.17127414]]. Action = [[-0.02173315 -0.0614025   0.         -0.8203919 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 12971 is [False, True, False, False, False, True]
Current timestep = 12972. State = [[-0.00068428  0.1667633 ]]. Action = [[ 0.05728117 -0.02193679  0.         -0.28894204]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 12972 is [False, True, False, False, False, True]
Current timestep = 12973. State = [[-0.00091247  0.16404155]]. Action = [[-0.05103404 -0.00590077  0.          0.25664854]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 12973 is [False, True, False, False, False, True]
Current timestep = 12974. State = [[0.002283   0.16495867]]. Action = [[0.09968851 0.0602747  0.         0.67320454]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 12974 is [False, True, False, False, False, True]
State prediction error at timestep 12974 is 0.012
Human Feedback received at timestep 12974 of None
Current timestep = 12975. State = [[0.003423   0.16123188]]. Action = [[-0.05839702 -0.08511247  0.         -0.9192462 ]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 12975 is [False, True, False, False, False, True]
Current timestep = 12976. State = [[0.00599789 0.15490037]]. Action = [[ 0.08015566 -0.04786495  0.         -0.9524501 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 12976 is [False, True, False, False, False, True]
Current timestep = 12977. State = [[0.00534235 0.15451108]]. Action = [[-0.06373669  0.0567938   0.         -0.7469715 ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 12977 is [False, True, False, False, False, True]
Current timestep = 12978. State = [[0.00632371 0.15094021]]. Action = [[ 0.05205669 -0.08019434  0.          0.0431695 ]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 12978 is [False, True, False, False, False, True]
State prediction error at timestep 12978 is 0.012
Human Feedback received at timestep 12978 of None
Current timestep = 12979. State = [[0.0121988  0.14263004]]. Action = [[ 0.08884268 -0.08950524  0.         -0.61198056]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 12979 is [False, True, False, False, False, True]
Current timestep = 12980. State = [[0.01777146 0.14051865]]. Action = [[ 0.05896138  0.05760846  0.         -0.41867483]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 12980 is [False, True, False, False, False, True]
Current timestep = 12981. State = [[0.02323612 0.13764627]]. Action = [[ 0.07635754 -0.04426238  0.         -0.98107594]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 12981 is [False, True, False, False, False, True]
State prediction error at timestep 12981 is 0.012
Human Feedback received at timestep 12981 of None
Current timestep = 12982. State = [[0.02831932 0.1304947 ]]. Action = [[ 0.05172289 -0.07403868  0.          0.56491256]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 12982 is [False, True, False, False, False, True]
Current timestep = 12983. State = [[0.02938927 0.126206  ]]. Action = [[-0.02637251  0.00261848  0.         -0.28562403]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 12983 is [False, True, False, False, False, True]
Current timestep = 12984. State = [[-0.17855598  0.14122608]]. Action = [[ 0.03966934 -0.04088318  0.         -0.9280612 ]]. Reward = [100.]
Curr episode timestep = 171
Scene graph at timestep 12984 is [False, True, False, False, False, True]
State prediction error at timestep 12984 is 0.012
Human Feedback received at timestep 12984 of None
Current timestep = 12985. State = [[-0.17723612  0.146567  ]]. Action = [[-0.0435285   0.03739896  0.          0.9737518 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 12985 is [True, False, False, False, False, True]
Current timestep = 12986. State = [[-0.17324793  0.15022883]]. Action = [[ 0.08730444  0.01390113  0.         -0.54730767]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 12986 is [True, False, False, False, False, True]
State prediction error at timestep 12986 is 0.012
Human Feedback received at timestep 12986 of None
Current timestep = 12987. State = [[-0.16654932  0.14805947]]. Action = [[ 0.06436148 -0.07905994  0.         -0.66602314]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 12987 is [True, False, False, False, False, True]
State prediction error at timestep 12987 is 0.012
Human Feedback received at timestep 12987 of None
Current timestep = 12988. State = [[-0.16522004  0.14826068]]. Action = [[-0.04533005  0.02984839  0.         -0.5976258 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 12988 is [True, False, False, False, False, True]
State prediction error at timestep 12988 is 0.012
Human Feedback received at timestep 12988 of None
Current timestep = 12989. State = [[-0.16819169  0.14818922]]. Action = [[-0.06983043 -0.04337513  0.         -0.40205818]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 12989 is [True, False, False, False, False, True]
State prediction error at timestep 12989 is 0.012
Human Feedback received at timestep 12989 of None
Current timestep = 12990. State = [[-0.17029725  0.15166388]]. Action = [[-0.02903387  0.06637549  0.         -0.7890638 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 12990 is [True, False, False, False, False, True]
State prediction error at timestep 12990 is 0.012
Human Feedback received at timestep 12990 of None
Current timestep = 12991. State = [[-0.16687982  0.15270601]]. Action = [[ 0.07424606 -0.03743117  0.          0.04303372]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 12991 is [True, False, False, False, False, True]
Current timestep = 12992. State = [[-0.16286762  0.14874086]]. Action = [[ 0.02259833 -0.068625    0.          0.55209506]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 12992 is [True, False, False, False, False, True]
Current timestep = 12993. State = [[-0.1596718   0.14546192]]. Action = [[ 0.0266374  -0.02589615  0.          0.00535452]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 12993 is [True, False, False, False, False, True]
Current timestep = 12994. State = [[-0.15291323  0.13959125]]. Action = [[ 0.09754104 -0.09104901  0.          0.37567282]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 12994 is [True, False, False, False, False, True]
Current timestep = 12995. State = [[-0.15063328  0.1392129 ]]. Action = [[-0.03627425  0.06895336  0.         -0.9590809 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 12995 is [True, False, False, False, False, True]
Current timestep = 12996. State = [[-0.14772885  0.1442031 ]]. Action = [[ 0.0629924   0.07856893  0.         -0.1539188 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 12996 is [True, False, False, False, False, True]
State prediction error at timestep 12996 is 0.012
Human Feedback received at timestep 12996 of None
Current timestep = 12997. State = [[-0.14131996  0.14457971]]. Action = [[ 0.08661348 -0.02383555  0.          0.30542445]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12997 is [True, False, False, False, False, True]
Current timestep = 12998. State = [[-0.13782439  0.13943587]]. Action = [[-3.3802539e-04 -7.6767534e-02  0.0000000e+00 -7.8267276e-01]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 12998 is [True, False, False, False, False, True]
Current timestep = 12999. State = [[-0.13197923  0.13277724]]. Action = [[ 0.08966848 -0.07103078  0.         -0.03625679]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 12999 is [True, False, False, False, False, True]
Current timestep = 13000. State = [[-0.12728947  0.1270923 ]]. Action = [[ 0.01199383 -0.04445273  0.         -0.80168617]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 13000 is [True, False, False, False, False, True]
Current timestep = 13001. State = [[-0.12498898  0.12268776]]. Action = [[ 0.00123131 -0.03473744  0.         -0.8285806 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 13001 is [True, False, False, False, False, True]
Current timestep = 13002. State = [[-0.11895385  0.1206126 ]]. Action = [[ 0.09016479  0.00945503  0.         -0.3697611 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 13002 is [True, False, False, False, True, False]
State prediction error at timestep 13002 is 0.012
Human Feedback received at timestep 13002 of None
Current timestep = 13003. State = [[-0.11362588  0.11684836]]. Action = [[ 0.02529294 -0.04714468  0.          0.4959805 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 13003 is [True, False, False, False, True, False]
Current timestep = 13004. State = [[-0.11184172  0.11152745]]. Action = [[-0.01788792 -0.05071611  0.          0.5387564 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 13004 is [True, False, False, False, True, False]
State prediction error at timestep 13004 is 0.012
Human Feedback received at timestep 13004 of None
Current timestep = 13005. State = [[-0.10654152  0.10925855]]. Action = [[ 0.08544212  0.01501457  0.         -0.7226671 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 13005 is [True, False, False, False, True, False]
Current timestep = 13006. State = [[-0.09992025  0.10478371]]. Action = [[ 0.05398852 -0.0647305   0.         -0.13042241]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 13006 is [True, False, False, False, True, False]
State prediction error at timestep 13006 is 0.012
Human Feedback received at timestep 13006 of None
Current timestep = 13007. State = [[-0.09650642  0.09863129]]. Action = [[-0.00213742 -0.05481361  0.          0.3211373 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 13007 is [True, False, False, False, True, False]
Current timestep = 13008. State = [[-0.09418955  0.09873874]]. Action = [[ 0.01034904  0.06460632  0.         -0.8485558 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 13008 is [True, False, False, False, True, False]
Current timestep = 13009. State = [[-0.08993283  0.09876347]]. Action = [[ 0.05496354 -0.01203673  0.         -0.8382529 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 13009 is [True, False, False, False, True, False]
Current timestep = 13010. State = [[-0.08381878  0.09299485]]. Action = [[ 0.06668784 -0.08747756  0.         -0.9881267 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 13010 is [True, False, False, False, True, False]
Current timestep = 13011. State = [[-0.07587217  0.08433931]]. Action = [[ 0.09096345 -0.09255414  0.          0.48156142]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 13011 is [True, False, False, False, True, False]
State prediction error at timestep 13011 is 0.012
Human Feedback received at timestep 13011 of None
Current timestep = 13012. State = [[-0.06696402  0.08249743]]. Action = [[ 0.09704518  0.06019323  0.         -0.88195   ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 13012 is [True, False, False, False, True, False]
State prediction error at timestep 13012 is 0.012
Human Feedback received at timestep 13012 of None
Current timestep = 13013. State = [[-0.06608549  0.07903127]]. Action = [[-0.09074519 -0.07159941  0.         -0.9319616 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 13013 is [True, False, False, False, True, False]
Current timestep = 13014. State = [[-0.063224    0.07235007]]. Action = [[ 0.08898679 -0.06361736  0.         -0.79054546]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 13014 is [True, False, False, False, True, False]
Current timestep = 13015. State = [[-0.05966992  0.06436437]]. Action = [[-0.00272721 -0.08489748  0.         -0.15067798]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 13015 is [True, False, False, False, True, False]
Current timestep = 13016. State = [[-0.06031547  0.057743  ]]. Action = [[-0.04996848 -0.04657784  0.          0.5199864 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 13016 is [True, False, False, False, True, False]
Current timestep = 13017. State = [[-0.062805    0.05939445]]. Action = [[-0.05553892  0.0922266   0.          0.42600298]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 13017 is [True, False, False, False, True, False]
Current timestep = 13018. State = [[-0.06192642  0.06392634]]. Action = [[ 0.03753584  0.05593125  0.         -0.98126215]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 13018 is [True, False, False, False, True, False]
Current timestep = 13019. State = [[-0.05774743  0.06962205]]. Action = [[ 0.06734469  0.08873779  0.         -0.87216485]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 13019 is [True, False, False, False, True, False]
State prediction error at timestep 13019 is 0.012
Human Feedback received at timestep 13019 of None
Current timestep = 13020. State = [[-0.05933549  0.0751985 ]]. Action = [[-0.07008629  0.05631671  0.         -0.8438916 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 13020 is [True, False, False, False, True, False]
State prediction error at timestep 13020 is 0.012
Human Feedback received at timestep 13020 of None
Current timestep = 13021. State = [[-0.05773862  0.07795896]]. Action = [[ 0.08915549  0.00910766  0.         -0.25326514]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 13021 is [True, False, False, False, True, False]
Current timestep = 13022. State = [[-0.05822304  0.07460658]]. Action = [[-0.06190585 -0.08808827  0.         -0.53491366]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 13022 is [True, False, False, False, True, False]
Current timestep = 13023. State = [[-0.05732795  0.07246377]]. Action = [[ 0.05628056 -0.00120665  0.         -0.8038287 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 13023 is [True, False, False, False, True, False]
Current timestep = 13024. State = [[-0.05715068  0.07081217]]. Action = [[-0.02580731 -0.03341343  0.         -0.10968077]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 13024 is [True, False, False, False, True, False]
Current timestep = 13025. State = [[-0.05354955  0.0743395 ]]. Action = [[ 0.09355415  0.0908569   0.         -0.94546777]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 13025 is [True, False, False, False, True, False]
State prediction error at timestep 13025 is 0.012
Human Feedback received at timestep 13025 of None
Current timestep = 13026. State = [[-0.20300779 -0.00130119]]. Action = [[ 0.08084697 -0.09365123  0.         -0.1530208 ]]. Reward = [100.]
Curr episode timestep = 41
Scene graph at timestep 13026 is [True, False, False, False, True, False]
Current timestep = 13027. State = [[-2.0873664e-01 -4.7188540e-05]]. Action = [[-0.07114746 -0.0469057   0.         -0.89180624]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 13027 is [True, False, False, False, True, False]
State prediction error at timestep 13027 is 0.012
Human Feedback received at timestep 13027 of None
Current timestep = 13028. State = [[-0.20728467  0.00400944]]. Action = [[ 0.08126015  0.08780356  0.         -0.912734  ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 13028 is [True, False, False, False, True, False]
Current timestep = 13029. State = [[-0.20433737  0.00931036]]. Action = [[ 0.02359442  0.03424936  0.         -0.52646834]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 13029 is [True, False, False, False, True, False]
Current timestep = 13030. State = [[-0.20577204  0.01542606]]. Action = [[-0.03972832  0.07534828  0.         -0.22277433]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 13030 is [True, False, False, False, True, False]
Current timestep = 13031. State = [[-0.20303015  0.02334315]]. Action = [[0.09413049 0.08454461 0.         0.57780194]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 13031 is [True, False, False, False, True, False]
Current timestep = 13032. State = [[-0.19719002  0.02784289]]. Action = [[ 0.08208237  0.00907198  0.         -0.57345337]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 13032 is [True, False, False, False, True, False]
State prediction error at timestep 13032 is 0.012
Human Feedback received at timestep 13032 of None
Current timestep = 13033. State = [[-0.19434047  0.03209471]]. Action = [[ 0.01383294  0.04961807  0.         -0.23379058]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 13033 is [True, False, False, False, True, False]
State prediction error at timestep 13033 is 0.012
Human Feedback received at timestep 13033 of None
Current timestep = 13034. State = [[-0.19490644  0.03718944]]. Action = [[-0.02185447  0.04223052  0.         -0.7825239 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 13034 is [True, False, False, False, True, False]
Current timestep = 13035. State = [[-0.19229105  0.0391904 ]]. Action = [[ 0.06117041 -0.01877765  0.         -0.12801385]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 13035 is [True, False, False, False, True, False]
Current timestep = 13036. State = [[-0.18672512  0.03650529]]. Action = [[ 0.06657849 -0.07099537  0.         -0.8385522 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 13036 is [True, False, False, False, True, False]
Current timestep = 13037. State = [[-0.17968456  0.03408448]]. Action = [[ 0.08072334 -0.0227378   0.         -0.8576545 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 13037 is [True, False, False, False, True, False]
State prediction error at timestep 13037 is 0.012
Human Feedback received at timestep 13037 of None
Current timestep = 13038. State = [[-0.1766633   0.03465937]]. Action = [[-0.01620473  0.01835974  0.         -0.7186496 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 13038 is [True, False, False, False, True, False]
Current timestep = 13039. State = [[-0.1775718   0.03176829]]. Action = [[-0.04904633 -0.07710066  0.         -0.91002434]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 13039 is [True, False, False, False, True, False]
Current timestep = 13040. State = [[-0.17846878  0.02756057]]. Action = [[-0.03225952 -0.04467563  0.         -0.05888319]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13040 is [True, False, False, False, True, False]
Current timestep = 13041. State = [[-0.17408124  0.02427116]]. Action = [[ 0.07464939 -0.0331832   0.          0.93374765]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 13041 is [True, False, False, False, True, False]
Current timestep = 13042. State = [[-0.16717212  0.02604788]]. Action = [[ 0.06903122  0.06963421  0.         -0.8542969 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 13042 is [True, False, False, False, True, False]
Current timestep = 13043. State = [[-0.1600842   0.02941406]]. Action = [[ 0.08102868  0.04077307  0.         -0.10869539]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 13043 is [True, False, False, False, True, False]
Current timestep = 13044. State = [[-0.15196364  0.03082286]]. Action = [[ 0.09788244  0.01408608  0.         -0.97566354]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 13044 is [True, False, False, False, True, False]
Current timestep = 13045. State = [[-0.14431132  0.03003557]]. Action = [[ 0.07424206 -0.01361322  0.         -0.4329939 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 13045 is [True, False, False, False, True, False]
State prediction error at timestep 13045 is 0.012
Human Feedback received at timestep 13045 of None
Current timestep = 13046. State = [[-0.14410576  0.02538963]]. Action = [[-0.08382012 -0.07734321  0.         -0.30800092]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 13046 is [True, False, False, False, True, False]
Current timestep = 13047. State = [[-0.14020634  0.01959222]]. Action = [[ 0.09905999 -0.06080768  0.         -0.14467329]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 13047 is [True, False, False, False, True, False]
Current timestep = 13048. State = [[-0.1351101   0.01500865]]. Action = [[ 0.0099972  -0.03594698  0.         -0.6883322 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 13048 is [True, False, False, False, True, False]
Current timestep = 13049. State = [[-0.13158104  0.01235028]]. Action = [[ 0.02037156 -0.01075838  0.         -0.64187646]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 13049 is [True, False, False, False, True, False]
Current timestep = 13050. State = [[-0.12689829  0.00918786]]. Action = [[ 0.04256862 -0.03504881  0.         -0.93018275]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 13050 is [True, False, False, False, True, False]
Current timestep = 13051. State = [[-0.12807548  0.01001542]]. Action = [[-0.09277474  0.05678541  0.         -0.13111901]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 13051 is [True, False, False, False, True, False]
Current timestep = 13052. State = [[-0.12983263  0.01516658]]. Action = [[-0.0140324   0.07847672  0.         -0.15797067]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 13052 is [True, False, False, False, True, False]
State prediction error at timestep 13052 is 0.012
Human Feedback received at timestep 13052 of None
Current timestep = 13053. State = [[-0.12552169  0.01419227]]. Action = [[ 0.08581681 -0.06710999  0.         -0.76280105]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 13053 is [True, False, False, False, True, False]
State prediction error at timestep 13053 is 0.012
Human Feedback received at timestep 13053 of None
Current timestep = 13054. State = [[-0.12015641  0.00848637]]. Action = [[ 0.04564448 -0.07127243  0.         -0.8730024 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 13054 is [True, False, False, False, True, False]
Current timestep = 13055. State = [[-0.11406289  0.00104771]]. Action = [[ 0.07396675 -0.09103242  0.         -0.7260269 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 13055 is [True, False, False, False, True, False]
Current timestep = 13056. State = [[-0.10770222 -0.00166235]]. Action = [[ 0.06256659  0.02492503  0.         -0.89244974]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 13056 is [True, False, False, False, True, False]
Current timestep = 13057. State = [[-0.10558698 -0.00457576]]. Action = [[-0.02005646 -0.04608768  0.         -0.82458776]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 13057 is [True, False, False, False, True, False]
Current timestep = 13058. State = [[-0.10312489 -0.00892967]]. Action = [[ 0.0307973  -0.03683959  0.         -0.5981526 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 13058 is [True, False, False, False, True, False]
Current timestep = 13059. State = [[-0.10429349 -0.00932926]]. Action = [[-0.07068391  0.03882314  0.         -0.54440117]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 13059 is [True, False, False, False, True, False]
Current timestep = 13060. State = [[-0.10457029 -0.01362414]]. Action = [[ 0.007255   -0.09025999  0.         -0.7342144 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 13060 is [True, False, False, False, True, False]
Current timestep = 13061. State = [[-0.09868751 -0.01904944]]. Action = [[ 0.098927   -0.03427579  0.         -0.7522185 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 13061 is [True, False, False, False, True, False]
Current timestep = 13062. State = [[-0.09365806 -0.01760719]]. Action = [[0.03187127 0.07806016 0.         0.46950436]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 13062 is [True, False, False, False, True, False]
Current timestep = 13063. State = [[-0.08969858 -0.01379088]]. Action = [[ 0.04971809  0.05017979  0.         -0.30938625]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 13063 is [True, False, False, False, True, False]
Current timestep = 13064. State = [[-0.08383016 -0.00943142]]. Action = [[ 0.08561053  0.06613868  0.         -0.06497377]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 13064 is [True, False, False, False, True, False]
Current timestep = 13065. State = [[-0.08326966 -0.01088223]]. Action = [[-0.05173786 -0.06565793  0.         -0.568781  ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 13065 is [True, False, False, False, True, False]
Current timestep = 13066. State = [[-0.07986049 -0.01001734]]. Action = [[ 0.09003808  0.05496598  0.         -0.8668447 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 13066 is [True, False, False, False, True, False]
Current timestep = 13067. State = [[-0.0800283  -0.00389752]]. Action = [[-0.06844653  0.08850115  0.         -0.4668103 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 13067 is [True, False, False, False, True, False]
State prediction error at timestep 13067 is 0.012
Human Feedback received at timestep 13067 of None
Current timestep = 13068. State = [[-0.07774132 -0.00118979]]. Action = [[ 0.0842584  -0.01375798  0.         -0.6141665 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 13068 is [True, False, False, False, True, False]
State prediction error at timestep 13068 is 0.012
Human Feedback received at timestep 13068 of None
Current timestep = 13069. State = [[-0.07089002  0.00133265]]. Action = [[ 0.08925978  0.04272193  0.         -0.79680616]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 13069 is [True, False, False, False, True, False]
State prediction error at timestep 13069 is 0.012
Human Feedback received at timestep 13069 of None
Current timestep = 13070. State = [[-0.06970596  0.00089163]]. Action = [[-0.04601352 -0.04735655  0.         -0.91510737]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 13070 is [True, False, False, False, True, False]
State prediction error at timestep 13070 is 0.012
Human Feedback received at timestep 13070 of None
Current timestep = 13071. State = [[-0.06683243  0.00180953]]. Action = [[ 0.06787715  0.03122673  0.         -0.7669837 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 13071 is [True, False, False, False, True, False]
State prediction error at timestep 13071 is 0.012
Human Feedback received at timestep 13071 of None
Current timestep = 13072. State = [[-0.06372777  0.00460859]]. Action = [[ 0.01186837  0.02746923  0.         -0.85405743]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 13072 is [True, False, False, False, True, False]
State prediction error at timestep 13072 is 0.012
Human Feedback received at timestep 13072 of None
Current timestep = 13073. State = [[-0.06444538  0.00189679]]. Action = [[-0.04505185 -0.08453719  0.          0.04325151]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 13073 is [True, False, False, False, True, False]
Current timestep = 13074. State = [[-0.06181232 -0.00236602]]. Action = [[ 0.05028456 -0.04450852  0.         -0.7709728 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 13074 is [True, False, False, False, True, False]
State prediction error at timestep 13074 is 0.012
Human Feedback received at timestep 13074 of None
Current timestep = 13075. State = [[-0.05596658 -0.00689895]]. Action = [[ 0.06380097 -0.05847217  0.         -0.05390203]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 13075 is [True, False, False, False, True, False]
Current timestep = 13076. State = [[-0.05355131 -0.01221622]]. Action = [[-0.02027044 -0.05813238  0.         -0.51092684]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 13076 is [True, False, False, False, True, False]
Current timestep = 13077. State = [[-0.31160998 -0.007903  ]]. Action = [[ 0.07067288  0.02780845  0.         -0.9614178 ]]. Reward = [100.]
Curr episode timestep = 50
Scene graph at timestep 13077 is [True, False, False, False, True, False]
Current timestep = 13078. State = [[-0.31880283  0.00055796]]. Action = [[-0.06769855  0.07838795  0.         -0.03853655]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 13078 is [True, False, False, False, True, False]
State prediction error at timestep 13078 is 0.012
Human Feedback received at timestep 13078 of None
Current timestep = 13079. State = [[-0.32022756  0.00535397]]. Action = [[ 0.06529727  0.00989195  0.         -0.60590994]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 13079 is [True, False, False, False, True, False]
Current timestep = 13080. State = [[-0.32199055  0.00903221]]. Action = [[-0.0280529   0.03008438  0.          0.06849456]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 13080 is [True, False, False, False, True, False]
Current timestep = 13081. State = [[-0.3202488   0.01401175]]. Action = [[ 0.0920889   0.04877505  0.         -0.21625257]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 13081 is [True, False, False, False, True, False]
Current timestep = 13082. State = [[-0.31574312  0.0134511 ]]. Action = [[ 0.07341827 -0.06978514  0.         -0.06699729]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 13082 is [True, False, False, False, True, False]
Current timestep = 13083. State = [[-0.3162221   0.01440537]]. Action = [[-0.04319831  0.03943927  0.         -0.94609046]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 13083 is [True, False, False, False, True, False]
Current timestep = 13084. State = [[-0.3144242   0.01499968]]. Action = [[ 0.07041007 -0.02535851  0.          0.0050472 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 13084 is [True, False, False, False, True, False]
Current timestep = 13085. State = [[-0.3103221   0.01348264]]. Action = [[ 0.04482623 -0.0266094   0.         -0.01930779]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 13085 is [True, False, False, False, True, False]
Current timestep = 13086. State = [[-0.30484217  0.01467439]]. Action = [[0.07661026 0.03643864 0.         0.28773832]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 13086 is [True, False, False, False, True, False]
Current timestep = 13087. State = [[-0.30040377  0.01455663]]. Action = [[ 0.03239391 -0.02443399  0.         -0.8503223 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 13087 is [True, False, False, False, True, False]
State prediction error at timestep 13087 is 0.012
Human Feedback received at timestep 13087 of None
Current timestep = 13088. State = [[-0.2941934   0.01081755]]. Action = [[ 0.08182297 -0.05868353  0.          0.79248285]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 13088 is [True, False, False, False, True, False]
State prediction error at timestep 13088 is 0.012
Human Feedback received at timestep 13088 of None
Current timestep = 13089. State = [[-0.2915204   0.00478995]]. Action = [[-0.03112602 -0.07546927  0.         -0.12928998]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 13089 is [True, False, False, False, True, False]
State prediction error at timestep 13089 is 0.012
Human Feedback received at timestep 13089 of None
Current timestep = 13090. State = [[-0.2934542   0.00486396]]. Action = [[-0.0656196   0.06270628  0.         -0.9153041 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 13090 is [True, False, False, False, True, False]
Current timestep = 13091. State = [[-0.2941959   0.00143393]]. Action = [[-0.0112446  -0.09158039  0.          0.23296344]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13091 is [True, False, False, False, True, False]
Current timestep = 13092. State = [[-0.28880623 -0.00153322]]. Action = [[ 0.09316888  0.01012428  0.         -0.48345637]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 13092 is [True, False, False, False, True, False]
Current timestep = 13093. State = [[-0.28876925  0.00039521]]. Action = [[-0.08525296  0.05167415  0.         -0.7911469 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 13093 is [True, False, False, False, True, False]
Current timestep = 13094. State = [[-0.28611314 -0.00238003]]. Action = [[ 0.09617061 -0.07560964  0.         -0.8541508 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 13094 is [True, False, False, False, True, False]
State prediction error at timestep 13094 is 0.012
Human Feedback received at timestep 13094 of None
Current timestep = 13095. State = [[-0.28639433 -0.0100123 ]]. Action = [[-0.09085989 -0.09358471  0.         -0.55847764]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 13095 is [True, False, False, False, True, False]
Current timestep = 13096. State = [[-0.28858817 -0.01628043]]. Action = [[-0.01423339 -0.04705791  0.         -0.4982959 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 13096 is [True, False, False, False, True, False]
Current timestep = 13097. State = [[-0.28465277 -0.0215447 ]]. Action = [[ 0.08377335 -0.04870559  0.          0.62881064]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 13097 is [True, False, False, False, True, False]
Current timestep = 13098. State = [[-0.2844393  -0.02527071]]. Action = [[-0.05636357 -0.01507042  0.          0.39288354]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 13098 is [True, False, False, False, True, False]
Current timestep = 13099. State = [[-0.28116423 -0.02902659]]. Action = [[ 0.09958916 -0.03658798  0.         -0.6280687 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 13099 is [True, False, False, False, True, False]
Current timestep = 13100. State = [[-0.28087032 -0.02947119]]. Action = [[-0.06242738  0.04324733  0.         -0.7905924 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 13100 is [True, False, False, False, True, False]
State prediction error at timestep 13100 is 0.012
Human Feedback received at timestep 13100 of None
Current timestep = 13101. State = [[-0.2816922  -0.03204442]]. Action = [[ 0.01825251 -0.05155727  0.         -0.5780922 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 13101 is [True, False, False, False, True, False]
State prediction error at timestep 13101 is 0.012
Human Feedback received at timestep 13101 of None
Current timestep = 13102. State = [[-0.2852468  -0.03261191]]. Action = [[-0.07895746  0.04015291  0.         -0.6803782 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 13102 is [True, False, False, False, True, False]
Current timestep = 13103. State = [[-0.29095992 -0.03204839]]. Action = [[-0.06299835  0.00537487  0.         -0.6537273 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 13103 is [True, False, False, False, True, False]
Current timestep = 13104. State = [[-0.28942543 -0.02949664]]. Action = [[ 0.09560332  0.05241058  0.         -0.7606678 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 13104 is [True, False, False, False, True, False]
Current timestep = 13105. State = [[-0.28340623 -0.0284633 ]]. Action = [[ 0.08961798 -0.01281828  0.          0.17589629]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 13105 is [True, False, False, False, True, False]
Current timestep = 13106. State = [[-0.2777271  -0.03024646]]. Action = [[ 0.0725239  -0.03154191  0.         -0.63807404]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 13106 is [True, False, False, False, True, False]
Current timestep = 13107. State = [[-0.2758662  -0.02759823]]. Action = [[-0.00450483  0.07306822  0.         -0.95993483]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 13107 is [True, False, False, False, True, False]
State prediction error at timestep 13107 is 0.012
Human Feedback received at timestep 13107 of None
Current timestep = 13108. State = [[-0.27953878 -0.02696005]]. Action = [[-0.07641674 -0.03064126  0.         -0.8787582 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 13108 is [True, False, False, False, True, False]
Current timestep = 13109. State = [[-0.28189734 -0.03151152]]. Action = [[-0.01245523 -0.07495207  0.         -0.87984   ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 13109 is [True, False, False, False, True, False]
State prediction error at timestep 13109 is 0.012
Human Feedback received at timestep 13109 of None
Current timestep = 13110. State = [[-0.27748677 -0.03174041]]. Action = [[ 0.09570102  0.04357939  0.         -0.8168798 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 13110 is [True, False, False, False, True, False]
Current timestep = 13111. State = [[-0.26994482 -0.02656887]]. Action = [[ 0.09911007  0.07579974  0.         -0.819566  ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 13111 is [True, False, False, False, True, False]
State prediction error at timestep 13111 is 0.012
Human Feedback received at timestep 13111 of None
Current timestep = 13112. State = [[-0.2681107  -0.02180289]]. Action = [[-0.02593333  0.04114372  0.         -0.84602696]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 13112 is [True, False, False, False, True, False]
Current timestep = 13113. State = [[-0.26649207 -0.01717236]]. Action = [[ 0.04448279  0.05395054  0.         -0.5623378 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 13113 is [True, False, False, False, True, False]
Current timestep = 13114. State = [[-0.26690817 -0.01049737]]. Action = [[-0.0311234   0.08279306  0.          0.02433503]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 13114 is [True, False, False, False, True, False]
State prediction error at timestep 13114 is 0.012
Human Feedback received at timestep 13114 of None
Current timestep = 13115. State = [[-0.27016175 -0.00249951]]. Action = [[-0.04535864  0.0850467   0.         -0.63728976]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 13115 is [True, False, False, False, True, False]
Current timestep = 13116. State = [[-0.2732251  -0.00230855]]. Action = [[-0.03287904 -0.08132048  0.         -0.9504244 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 13116 is [True, False, False, False, True, False]
Current timestep = 13117. State = [[-0.2710079  -0.00777357]]. Action = [[ 0.06019614 -0.08996495  0.          0.32567   ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 13117 is [True, False, False, False, True, False]
State prediction error at timestep 13117 is 0.012
Human Feedback received at timestep 13117 of None
Current timestep = 13118. State = [[-0.267332   -0.01149607]]. Action = [[ 0.02902878 -0.03263074  0.          0.5261018 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 13118 is [True, False, False, False, True, False]
State prediction error at timestep 13118 is 0.012
Human Feedback received at timestep 13118 of None
Current timestep = 13119. State = [[-0.2696792  -0.01724758]]. Action = [[-0.09041899 -0.09735096  0.         -0.6859586 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 13119 is [True, False, False, False, True, False]
Current timestep = 13120. State = [[-0.27149227 -0.0179022 ]]. Action = [[-0.00557964  0.05097932  0.          0.15469372]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 13120 is [True, False, False, False, True, False]
Current timestep = 13121. State = [[-0.26864433 -0.02157787]]. Action = [[ 0.05414278 -0.09342498  0.          0.36312318]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 13121 is [True, False, False, False, True, False]
Current timestep = 13122. State = [[-0.26513618 -0.02828863]]. Action = [[ 0.02881349 -0.06503527  0.         -0.7574049 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 13122 is [True, False, False, False, True, False]
Current timestep = 13123. State = [[-0.26097047 -0.03433759]]. Action = [[ 0.05200244 -0.05567522  0.         -0.98760235]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 13123 is [True, False, False, False, True, False]
Current timestep = 13124. State = [[-0.25546822 -0.0372573 ]]. Action = [[0.06717325 0.00668422 0.         0.434106  ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 13124 is [True, False, False, False, True, False]
Current timestep = 13125. State = [[-0.2496783  -0.04300631]]. Action = [[ 0.0637346  -0.08443543  0.         -0.7801491 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 13125 is [True, False, False, False, True, False]
State prediction error at timestep 13125 is 0.012
Human Feedback received at timestep 13125 of None
Current timestep = 13126. State = [[-0.24901333 -0.04403131]]. Action = [[-0.04703551  0.06609187  0.         -0.46125257]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 13126 is [True, False, False, False, True, False]
Current timestep = 13127. State = [[-0.24524756 -0.04410197]]. Action = [[ 0.09776144 -0.00721789  0.         -0.3707736 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 13127 is [True, False, False, False, True, False]
Current timestep = 13128. State = [[-0.23903531 -0.04704798]]. Action = [[ 0.05913288 -0.02988694  0.         -0.575613  ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 13128 is [True, False, False, False, True, False]
Current timestep = 13129. State = [[-0.23839128 -0.05085609]]. Action = [[-0.04509423 -0.031709    0.         -0.20915568]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 13129 is [True, False, False, False, True, False]
State prediction error at timestep 13129 is 0.012
Human Feedback received at timestep 13129 of None
Current timestep = 13130. State = [[-0.23788175 -0.0509475 ]]. Action = [[ 0.01411265  0.04241206  0.         -0.82529795]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 13130 is [True, False, False, False, True, False]
Current timestep = 13131. State = [[-0.23391217 -0.05293397]]. Action = [[ 0.05883879 -0.04680313  0.         -0.20551682]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 13131 is [True, False, False, False, True, False]
Current timestep = 13132. State = [[-0.22869983 -0.05640541]]. Action = [[ 0.05501524 -0.02787115  0.         -0.6458416 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 13132 is [True, False, False, False, True, False]
Current timestep = 13133. State = [[-0.22957341 -0.0588517 ]]. Action = [[-0.07667167 -0.01396115  0.          0.03780198]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 13133 is [True, False, False, False, True, False]
State prediction error at timestep 13133 is 0.012
Human Feedback received at timestep 13133 of None
Current timestep = 13134. State = [[-0.22758849 -0.05529426]]. Action = [[ 0.0693898   0.09296685  0.         -0.07031602]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 13134 is [True, False, False, False, True, False]
Current timestep = 13135. State = [[-0.22549072 -0.05214138]]. Action = [[-0.00321782  0.01067054  0.         -0.44679213]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 13135 is [True, False, False, False, True, False]
Current timestep = 13136. State = [[-0.22627509 -0.05072615]]. Action = [[-0.02586313  0.01708041  0.         -0.97349745]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 13136 is [True, False, False, False, True, False]
Current timestep = 13137. State = [[-0.22603123 -0.04786031]]. Action = [[ 0.01194841  0.04041112  0.         -0.91011727]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 13137 is [True, False, False, False, True, False]
Current timestep = 13138. State = [[-0.22348966 -0.04904994]]. Action = [[ 0.04014952 -0.0590613   0.         -0.95985657]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 13138 is [True, False, False, False, True, False]
Current timestep = 13139. State = [[-0.21968068 -0.04831829]]. Action = [[ 0.0470335   0.03970175  0.         -0.74991053]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 13139 is [True, False, False, False, True, False]
Current timestep = 13140. State = [[-0.21666397 -0.04601712]]. Action = [[ 0.02651774  0.01520588  0.         -0.92285717]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 13140 is [True, False, False, False, True, False]
Current timestep = 13141. State = [[-0.21651953 -0.04980091]]. Action = [[-0.02532512 -0.09331992  0.         -0.78754234]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 13141 is [True, False, False, False, True, False]
Current timestep = 13142. State = [[-0.21329756 -0.04855024]]. Action = [[ 0.06619208  0.07938006  0.         -0.94662404]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 13142 is [True, False, False, False, True, False]
State prediction error at timestep 13142 is 0.012
Human Feedback received at timestep 13142 of None
Current timestep = 13143. State = [[-0.20850767 -0.04120621]]. Action = [[ 0.05396738  0.09532518  0.         -0.40465128]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 13143 is [True, False, False, False, True, False]
Current timestep = 13144. State = [[-0.20975319 -0.03322633]]. Action = [[-0.06395096  0.08673237  0.          0.08268392]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 13144 is [True, False, False, False, True, False]
Current timestep = 13145. State = [[-0.20851193 -0.02552217]]. Action = [[ 0.06418685  0.07613743  0.         -0.9456141 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 13145 is [True, False, False, False, True, False]
Current timestep = 13146. State = [[-0.20532887 -0.02532125]]. Action = [[ 0.02998859 -0.07299642  0.          0.32984698]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 13146 is [True, False, False, False, True, False]
Current timestep = 13147. State = [[-0.20825362 -0.02918274]]. Action = [[-0.09685238 -0.0604654   0.         -0.8146747 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 13147 is [True, False, False, False, True, False]
Current timestep = 13148. State = [[-0.20588969 -0.03350552]]. Action = [[ 0.09567712 -0.06588307  0.         -0.46696806]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 13148 is [True, False, False, False, True, False]
Current timestep = 13149. State = [[-0.20155078 -0.03560514]]. Action = [[ 0.00969368 -0.00645119  0.         -0.8627249 ]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 13149 is [True, False, False, False, True, False]
Current timestep = 13150. State = [[-0.19872253 -0.040595  ]]. Action = [[ 0.01704836 -0.09191837  0.         -0.4021572 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 13150 is [True, False, False, False, True, False]
Current timestep = 13151. State = [[-0.2003139  -0.04496721]]. Action = [[-0.08102648 -0.0217123   0.         -0.73725283]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 13151 is [True, False, False, False, True, False]
Current timestep = 13152. State = [[-0.19837251 -0.05125128]]. Action = [[ 0.05629972 -0.09287088  0.         -0.931888  ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 13152 is [True, False, False, False, True, False]
Current timestep = 13153. State = [[-0.19939746 -0.0559372 ]]. Action = [[-0.09056167 -0.01143647  0.         -0.76910317]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 13153 is [True, False, False, False, True, False]
Current timestep = 13154. State = [[-0.20217541 -0.05699072]]. Action = [[-0.03323982  0.01534721  0.         -0.59103906]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 13154 is [True, False, False, False, True, False]
Current timestep = 13155. State = [[-0.2016178  -0.05386801]]. Action = [[ 0.02162839  0.07536665  0.         -0.9000379 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 13155 is [True, False, False, False, True, False]
Current timestep = 13156. State = [[-0.20131369 -0.05512989]]. Action = [[-0.00647337 -0.0573243   0.         -0.8001701 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 13156 is [True, False, False, False, True, False]
Current timestep = 13157. State = [[-0.20172757 -0.05879258]]. Action = [[-0.00614142 -0.02822232  0.         -0.7551134 ]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 13157 is [True, False, False, False, True, False]
State prediction error at timestep 13157 is 0.012
Human Feedback received at timestep 13157 of None
Current timestep = 13158. State = [[-0.19770952 -0.06070129]]. Action = [[ 0.09099681 -0.00612813  0.          0.22572327]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 13158 is [True, False, False, False, True, False]
Current timestep = 13159. State = [[-0.19557142 -0.06608446]]. Action = [[-0.00321154 -0.08893057  0.         -0.18784022]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 13159 is [True, False, False, False, True, False]
Current timestep = 13160. State = [[-0.19703242 -0.07432585]]. Action = [[-0.03521925 -0.09106411  0.         -0.96105677]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 13160 is [True, False, False, False, True, False]
Current timestep = 13161. State = [[-0.19335134 -0.07909545]]. Action = [[ 0.09154094 -0.01140727  0.          0.11663866]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 13161 is [True, False, False, False, True, False]
Current timestep = 13162. State = [[-0.19066787 -0.07956097]]. Action = [[-6.7972392e-04  2.9338770e-02  0.0000000e+00 -8.0566144e-01]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 13162 is [True, False, False, False, True, False]
Current timestep = 13163. State = [[-0.18751217 -0.07978565]]. Action = [[ 0.05976317  0.00435108  0.         -0.83008397]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 13163 is [True, False, False, False, True, False]
State prediction error at timestep 13163 is 0.012
Human Feedback received at timestep 13163 of None
Current timestep = 13164. State = [[-0.18964411 -0.08179626]]. Action = [[-0.08604293 -0.01994922  0.         -0.8907512 ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 13164 is [True, False, False, False, True, False]
Current timestep = 13165. State = [[-0.19068912 -0.0854381 ]]. Action = [[ 0.02407446 -0.04046285  0.         -0.36255407]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 13165 is [True, False, False, False, True, False]
State prediction error at timestep 13165 is 0.012
Human Feedback received at timestep 13165 of None
Current timestep = 13166. State = [[-0.188787  -0.0866222]]. Action = [[ 0.0273905   0.01931821  0.         -0.7086709 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 13166 is [True, False, False, False, True, False]
Current timestep = 13167. State = [[-0.1881607  -0.08555802]]. Action = [[-0.00239831  0.0249819   0.         -0.8704611 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 13167 is [True, False, False, False, True, False]
Current timestep = 13168. State = [[-0.1836025  -0.08406641]]. Action = [[ 0.09802835  0.02177472  0.         -0.6803105 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 13168 is [True, False, False, False, True, False]
Current timestep = 13169. State = [[-0.18379086 -0.08174163]]. Action = [[-0.06354798  0.03744593  0.         -0.86090857]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 13169 is [True, False, False, False, True, False]
Current timestep = 13170. State = [[-0.18214639 -0.07712611]]. Action = [[0.07803442 0.06513741 0.         0.04263628]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 13170 is [True, False, False, False, True, False]
Current timestep = 13171. State = [[-0.17682092 -0.07079252]]. Action = [[ 0.07934309  0.07312424  0.         -0.8521997 ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 13171 is [True, False, False, False, True, False]
Current timestep = 13172. State = [[-0.17721123 -0.07027997]]. Action = [[-0.04853119 -0.05289103  0.         -0.8299321 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 13172 is [True, False, False, False, True, False]
Current timestep = 13173. State = [[-0.17949459 -0.0668238 ]]. Action = [[-0.02057669  0.0819943   0.         -0.803439  ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 13173 is [True, False, False, False, True, False]
Current timestep = 13174. State = [[-0.17777126 -0.06603011]]. Action = [[ 0.050451   -0.05153157  0.         -0.4184121 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 13174 is [True, False, False, False, True, False]
Current timestep = 13175. State = [[-0.17156786 -0.06548236]]. Action = [[ 0.09610047  0.0198779   0.         -0.6846167 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 13175 is [True, False, False, False, True, False]
State prediction error at timestep 13175 is 0.012
Human Feedback received at timestep 13175 of None
Current timestep = 13176. State = [[-0.16387235 -0.06616767]]. Action = [[ 0.09533768 -0.03913294  0.         -0.95852625]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 13176 is [True, False, False, False, True, False]
Current timestep = 13177. State = [[-0.15643156 -0.07135571]]. Action = [[ 0.07793892 -0.08870006  0.         -0.87986803]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 13177 is [True, False, False, False, True, False]
Current timestep = 13178. State = [[-0.15258713 -0.07055508]]. Action = [[0.00332715 0.07264826 0.         0.7579615 ]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 13178 is [True, False, False, False, True, False]
Current timestep = 13179. State = [[-0.14994912 -0.0723277 ]]. Action = [[ 0.02045266 -0.07115302  0.         -0.46572077]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 13179 is [True, False, False, False, True, False]
Current timestep = 13180. State = [[-0.14515026 -0.07036586]]. Action = [[0.0551331  0.08588258 0.         0.5643492 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 13180 is [True, False, False, False, True, False]
Current timestep = 13181. State = [[-0.1425443  -0.06365635]]. Action = [[-0.00598298  0.08734662  0.         -0.88368475]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 13181 is [True, False, False, False, True, False]
Current timestep = 13182. State = [[-0.13953727 -0.05820923]]. Action = [[ 0.03836095  0.0466358   0.         -0.95131886]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 13182 is [True, False, False, False, True, False]
Current timestep = 13183. State = [[-0.13325496 -0.05539235]]. Action = [[ 0.08431602  0.01101414  0.         -0.92142844]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 13183 is [True, False, False, False, True, False]
Current timestep = 13184. State = [[-0.13216588 -0.04919638]]. Action = [[-0.05439956  0.09829206  0.          0.41009903]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 13184 is [True, False, False, False, True, False]
Current timestep = 13185. State = [[-0.13229106 -0.04857653]]. Action = [[ 0.00702101 -0.07164038  0.         -0.8143909 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 13185 is [True, False, False, False, True, False]
Current timestep = 13186. State = [[-0.13082351 -0.05138969]]. Action = [[ 0.0045623  -0.04014602  0.         -0.46228147]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 13186 is [True, False, False, False, True, False]
Current timestep = 13187. State = [[-0.12864327 -0.0485934 ]]. Action = [[ 0.0191931   0.06437068  0.         -0.32481092]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 13187 is [True, False, False, False, True, False]
Current timestep = 13188. State = [[-0.1294996  -0.04542224]]. Action = [[-0.04757135  0.00833583  0.         -0.7734629 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 13188 is [True, False, False, False, True, False]
Current timestep = 13189. State = [[-0.13168657 -0.0395997 ]]. Action = [[-0.03633078  0.08925284  0.         -0.69089705]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 13189 is [True, False, False, False, True, False]
Current timestep = 13190. State = [[-0.1325613  -0.03382531]]. Action = [[-0.00567999  0.03643256  0.         -0.24406284]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 13190 is [True, False, False, False, True, False]
Current timestep = 13191. State = [[-0.13014126 -0.03148819]]. Action = [[ 0.05010288 -0.0057733   0.         -0.8055998 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 13191 is [True, False, False, False, True, False]
Current timestep = 13192. State = [[-0.12537532 -0.03062362]]. Action = [[ 0.06882013 -0.00423578  0.         -0.882676  ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 13192 is [True, False, False, False, True, False]
Current timestep = 13193. State = [[-0.12052854 -0.02900075]]. Action = [[ 0.05704982  0.01742037  0.         -0.9620264 ]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 13193 is [True, False, False, False, True, False]
Current timestep = 13194. State = [[-0.11501008 -0.02635002]]. Action = [[ 0.07492361  0.02938312  0.         -0.9203928 ]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 13194 is [True, False, False, False, True, False]
Current timestep = 13195. State = [[-0.11334234 -0.0239666 ]]. Action = [[-0.01825241  0.01853353  0.         -0.31989944]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 13195 is [True, False, False, False, True, False]
Current timestep = 13196. State = [[-0.11273111 -0.01971492]]. Action = [[ 0.00995531  0.06030259  0.         -0.35672778]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 13196 is [True, False, False, False, True, False]
Current timestep = 13197. State = [[-0.10861704 -0.02082257]]. Action = [[ 0.06776644 -0.07235666  0.         -0.60951674]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 13197 is [True, False, False, False, True, False]
Current timestep = 13198. State = [[-0.1020721  -0.02683585]]. Action = [[ 0.07682813 -0.08549311  0.          0.5035976 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 13198 is [True, False, False, False, True, False]
Current timestep = 13199. State = [[-0.09512875 -0.0343341 ]]. Action = [[ 0.06946588 -0.0907829   0.          0.33745456]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 13199 is [True, False, False, False, True, False]
Current timestep = 13200. State = [[-0.08721983 -0.04046749]]. Action = [[ 0.08707414 -0.04676906  0.         -0.24805719]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 13200 is [True, False, False, False, True, False]
Current timestep = 13201. State = [[-0.07888116 -0.04436778]]. Action = [[ 0.08405239 -0.01748772  0.         -0.54644585]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 13201 is [True, False, False, False, True, False]
Current timestep = 13202. State = [[-0.07372034 -0.05070031]]. Action = [[ 0.01588599 -0.07938739  0.          0.13974977]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 13202 is [True, False, False, False, True, False]
Current timestep = 13203. State = [[-0.0705905  -0.05698103]]. Action = [[ 0.00510589 -0.038779    0.         -0.7419033 ]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 13203 is [True, False, False, False, True, False]
Current timestep = 13204. State = [[-0.0656457  -0.06395246]]. Action = [[ 0.05020655 -0.07121933  0.          0.32885897]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 13204 is [True, False, False, False, True, False]
State prediction error at timestep 13204 is 0.012
Human Feedback received at timestep 13204 of None
Current timestep = 13205. State = [[-0.0640962 -0.0685356]]. Action = [[-0.04586142 -0.00347412  0.         -0.54994607]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 13205 is [True, False, False, False, True, False]
Current timestep = 13206. State = [[-0.05876979 -0.07333698]]. Action = [[ 0.09514771 -0.05047116  0.         -0.8480136 ]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 13206 is [True, False, False, False, True, False]
Current timestep = 13207. State = [[-0.05087498 -0.08008362]]. Action = [[ 0.06614528 -0.06084979  0.         -0.8986195 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 13207 is [True, False, False, False, True, False]
Current timestep = 13208. State = [[-0.2777315  0.1980633]]. Action = [[ 0.0076475  -0.05961667  0.         -0.80651283]]. Reward = [100.]
Curr episode timestep = 130
Scene graph at timestep 13208 is [True, False, False, False, True, False]
State prediction error at timestep 13208 is 0.012
Human Feedback received at timestep 13208 of None
Current timestep = 13209. State = [[-0.2788465   0.19417706]]. Action = [[ 0.07429003 -0.0614366   0.         -0.41411752]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 13209 is [True, False, False, False, False, True]
Current timestep = 13210. State = [[-0.27689287  0.19294886]]. Action = [[ 0.03247102  0.02616758  0.         -0.09618229]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 13210 is [True, False, False, False, False, True]
Current timestep = 13211. State = [[-0.27334133  0.19166805]]. Action = [[ 0.0818041  -0.01433177  0.         -0.24275607]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 13211 is [True, False, False, False, False, True]
Current timestep = 13212. State = [[-0.27001297  0.19102459]]. Action = [[ 0.04230019  0.02708618  0.         -0.25462937]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 13212 is [True, False, False, False, False, True]
Current timestep = 13213. State = [[-0.26898503  0.19275016]]. Action = [[0.01341035 0.05102385 0.         0.3691783 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 13213 is [True, False, False, False, False, True]
State prediction error at timestep 13213 is 0.012
Human Feedback received at timestep 13213 of None
Current timestep = 13214. State = [[-0.27059367  0.1943573 ]]. Action = [[-0.02276397  0.02615894  0.          0.47745693]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 13214 is [True, False, False, False, False, True]
State prediction error at timestep 13214 is 0.012
Human Feedback received at timestep 13214 of None
Current timestep = 13215. State = [[-0.269256    0.19165814]]. Action = [[ 0.05415464 -0.05427     0.         -0.36911452]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 13215 is [True, False, False, False, False, True]
Current timestep = 13216. State = [[-0.26499632  0.1916536 ]]. Action = [[ 0.0620961  0.0517519  0.        -0.6972427]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 13216 is [True, False, False, False, False, True]
Current timestep = 13217. State = [[-0.25952482  0.19343193]]. Action = [[0.07767551 0.03186841 0.         0.5295931 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 13217 is [True, False, False, False, False, True]
State prediction error at timestep 13217 is 0.012
Human Feedback received at timestep 13217 of None
Current timestep = 13218. State = [[-0.25248462  0.19044358]]. Action = [[ 0.08946427 -0.05741603  0.          0.94147146]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 13218 is [True, False, False, False, False, True]
State prediction error at timestep 13218 is 0.012
Human Feedback received at timestep 13218 of None
Current timestep = 13219. State = [[-0.24459977  0.18817092]]. Action = [[0.08524819 0.00919889 0.         0.6313807 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 13219 is [True, False, False, False, False, True]
State prediction error at timestep 13219 is 0.012
Human Feedback received at timestep 13219 of None
Current timestep = 13220. State = [[-0.2375552   0.18373695]]. Action = [[ 0.06023896 -0.07106102  0.          0.26372933]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 13220 is [True, False, False, False, False, True]
Current timestep = 13221. State = [[-0.22891884  0.17905442]]. Action = [[ 0.0949458  -0.03143801  0.          0.5135493 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 13221 is [True, False, False, False, False, True]
State prediction error at timestep 13221 is 0.012
Human Feedback received at timestep 13221 of None
Current timestep = 13222. State = [[-0.22635776  0.1785605 ]]. Action = [[-0.05446804  0.03139802  0.         -0.89269006]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13222 is [True, False, False, False, False, True]
Current timestep = 13223. State = [[-0.22257714  0.18017627]]. Action = [[ 0.06182986  0.02766124  0.         -0.8865314 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 13223 is [True, False, False, False, False, True]
Current timestep = 13224. State = [[-0.21620865  0.18033777]]. Action = [[ 5.5657275e-02 -4.2183697e-04  0.0000000e+00 -5.5391866e-01]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 13224 is [True, False, False, False, False, True]
Current timestep = 13225. State = [[-0.20880203  0.17571823]]. Action = [[ 0.07280082 -0.0814527   0.         -0.67567897]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 13225 is [True, False, False, False, False, True]
State prediction error at timestep 13225 is 0.012
Human Feedback received at timestep 13225 of None
Current timestep = 13226. State = [[-0.20253932  0.17310014]]. Action = [[0.03397406 0.00822334 0.         0.30709255]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 13226 is [True, False, False, False, False, True]
Current timestep = 13227. State = [[-0.19567713  0.1724613 ]]. Action = [[ 0.07032461 -0.00110922  0.          0.43031907]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 13227 is [True, False, False, False, False, True]
State prediction error at timestep 13227 is 0.012
Human Feedback received at timestep 13227 of None
Current timestep = 13228. State = [[-0.18748796  0.16830991]]. Action = [[ 0.07602795 -0.06677084  0.          0.5067427 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 13228 is [True, False, False, False, False, True]
State prediction error at timestep 13228 is 0.012
Human Feedback received at timestep 13228 of None
Current timestep = 13229. State = [[-0.18563354  0.16461083]]. Action = [[-0.06491152 -0.02311669  0.         -0.8634547 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 13229 is [True, False, False, False, False, True]
State prediction error at timestep 13229 is 0.012
Human Feedback received at timestep 13229 of None
Current timestep = 13230. State = [[-0.18187155  0.16028298]]. Action = [[ 0.05943555 -0.06338383  0.         -0.94831747]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 13230 is [True, False, False, False, False, True]
State prediction error at timestep 13230 is 0.012
Human Feedback received at timestep 13230 of None
Current timestep = 13231. State = [[-0.18029407  0.1614763 ]]. Action = [[-0.0453122   0.07544889  0.         -0.9083124 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 13231 is [True, False, False, False, False, True]
Current timestep = 13232. State = [[-0.1810773   0.16724803]]. Action = [[-0.019185    0.07615591  0.         -0.0854792 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 13232 is [True, False, False, False, False, True]
State prediction error at timestep 13232 is 0.012
Human Feedback received at timestep 13232 of None
Current timestep = 13233. State = [[-0.183013    0.16563746]]. Action = [[-0.04767957 -0.08772734  0.         -0.77336395]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 13233 is [True, False, False, False, False, True]
Current timestep = 13234. State = [[-0.1796281   0.15994188]]. Action = [[ 0.0760256  -0.07214836  0.          0.41992354]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 13234 is [True, False, False, False, False, True]
Current timestep = 13235. State = [[-0.17526369  0.15620542]]. Action = [[ 0.02208869 -0.02446665  0.         -0.40030622]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 13235 is [True, False, False, False, False, True]
Current timestep = 13236. State = [[-0.17631468  0.15743645]]. Action = [[-0.05837962  0.04707295  0.          0.25098038]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 13236 is [True, False, False, False, False, True]
Current timestep = 13237. State = [[-0.1756805  0.1611459]]. Action = [[0.03657252 0.0491556  0.         0.02102757]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 13237 is [True, False, False, False, False, True]
Current timestep = 13238. State = [[-0.17137492  0.16544496]]. Action = [[0.07024875 0.06172692 0.         0.05737233]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 13238 is [True, False, False, False, False, True]
Current timestep = 13239. State = [[-0.16734114  0.16306761]]. Action = [[ 0.04042136 -0.07892732  0.         -0.4019484 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 13239 is [True, False, False, False, False, True]
Current timestep = 13240. State = [[-0.16482127  0.1612398 ]]. Action = [[ 0.01522926  0.01342131  0.         -0.5976865 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 13240 is [True, False, False, False, False, True]
Current timestep = 13241. State = [[-0.16767587  0.1589568 ]]. Action = [[-0.08440914 -0.05199143  0.         -0.69792306]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 13241 is [True, False, False, False, False, True]
State prediction error at timestep 13241 is 0.012
Human Feedback received at timestep 13241 of None
Current timestep = 13242. State = [[-0.16540436  0.1537306 ]]. Action = [[ 0.0842768  -0.07429317  0.          0.40308404]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 13242 is [True, False, False, False, False, True]
Current timestep = 13243. State = [[-0.16008833  0.14803308]]. Action = [[ 0.04113028 -0.05688931  0.         -0.8944363 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 13243 is [True, False, False, False, False, True]
Current timestep = 13244. State = [[-0.15344909  0.14784439]]. Action = [[ 0.0875143   0.05441076  0.         -0.9908421 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 13244 is [True, False, False, False, False, True]
Current timestep = 13245. State = [[-0.14795661  0.14328563]]. Action = [[ 0.03725385 -0.09507222  0.         -0.46610785]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 13245 is [True, False, False, False, False, True]
Current timestep = 13246. State = [[-0.14143899  0.13835233]]. Action = [[ 0.0790349  -0.01577128  0.         -0.6082327 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 13246 is [True, False, False, False, False, True]
State prediction error at timestep 13246 is 0.012
Human Feedback received at timestep 13246 of None
Current timestep = 13247. State = [[-0.1337213  0.1336524]]. Action = [[ 0.07974885 -0.04551905  0.          0.6256969 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 13247 is [True, False, False, False, False, True]
Current timestep = 13248. State = [[-0.1325228  0.1263452]]. Action = [[-0.07117452 -0.08805113  0.         -0.11457902]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 13248 is [True, False, False, False, False, True]
State prediction error at timestep 13248 is 0.012
Human Feedback received at timestep 13248 of None
Current timestep = 13249. State = [[-0.12977056  0.12346205]]. Action = [[ 0.06732457  0.02959742  0.         -0.06699449]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 13249 is [True, False, False, False, False, True]
Current timestep = 13250. State = [[-0.12812541  0.12614001]]. Action = [[-0.03006005  0.07153549  0.         -0.14521623]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 13250 is [True, False, False, False, True, False]
State prediction error at timestep 13250 is 0.012
Human Feedback received at timestep 13250 of None
Current timestep = 13251. State = [[-0.12525634  0.12747912]]. Action = [[ 0.05389053  0.00499977  0.         -0.5575583 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 13251 is [True, False, False, False, False, True]
Current timestep = 13252. State = [[-0.12363422  0.12627302]]. Action = [[-0.01534577 -0.01428538  0.         -0.8552517 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 13252 is [True, False, False, False, False, True]
Current timestep = 13253. State = [[-0.1201316   0.12569162]]. Action = [[ 0.06130768  0.00647273  0.         -0.30710697]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 13253 is [True, False, False, False, False, True]
Current timestep = 13254. State = [[-0.11331532  0.12504013]]. Action = [[ 0.09069579 -0.00353699  0.         -0.9066142 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 13254 is [True, False, False, False, False, True]
Current timestep = 13255. State = [[-0.105771    0.12017566]]. Action = [[ 0.08195015 -0.07901289  0.         -0.97609395]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 13255 is [True, False, False, False, False, True]
State prediction error at timestep 13255 is 0.012
Human Feedback received at timestep 13255 of None
Current timestep = 13256. State = [[-0.09786569  0.11628803]]. Action = [[ 0.08407674 -0.00946905  0.         -0.15641332]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 13256 is [True, False, False, False, True, False]
Current timestep = 13257. State = [[-0.09441907  0.11571169]]. Action = [[-0.01118373  0.01932321  0.         -0.78242254]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 13257 is [True, False, False, False, True, False]
Current timestep = 13258. State = [[-0.08960437  0.11913612]]. Action = [[ 0.07484648  0.07488329  0.         -0.21051311]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 13258 is [True, False, False, False, True, False]
Current timestep = 13259. State = [[-0.08357958  0.12202211]]. Action = [[ 0.05713966  0.02705839  0.         -0.85602707]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 13259 is [True, False, False, False, True, False]
Current timestep = 13260. State = [[-0.08113874  0.12562083]]. Action = [[-0.00966094  0.05963638  0.         -0.87860066]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 13260 is [True, False, False, False, True, False]
Current timestep = 13261. State = [[-0.08423115  0.12475837]]. Action = [[-0.09474535 -0.06465898  0.         -0.5858901 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 13261 is [True, False, False, False, False, True]
State prediction error at timestep 13261 is 0.012
Human Feedback received at timestep 13261 of None
Current timestep = 13262. State = [[-0.0816052  0.1200925]]. Action = [[ 0.08135719 -0.07108356  0.         -0.9573401 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 13262 is [True, False, False, False, True, False]
State prediction error at timestep 13262 is 0.012
Human Feedback received at timestep 13262 of None
Current timestep = 13263. State = [[-0.07429539  0.1176568 ]]. Action = [[ 0.06707276 -0.008943    0.         -0.77588505]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 13263 is [True, False, False, False, True, False]
Current timestep = 13264. State = [[-0.06894971  0.11898375]]. Action = [[ 0.03174125  0.03628013  0.         -0.9641416 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 13264 is [True, False, False, False, True, False]
Current timestep = 13265. State = [[-0.06143887  0.11535923]]. Action = [[ 0.09768475 -0.08989798  0.         -0.6809937 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 13265 is [True, False, False, False, True, False]
Current timestep = 13266. State = [[-0.05422601  0.11226057]]. Action = [[ 0.05076887  0.00282403  0.         -0.92407954]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 13266 is [True, False, False, False, True, False]
Current timestep = 13267. State = [[-0.08300045  0.01347938]]. Action = [[ 0.02060473  0.00804187  0.         -0.37595034]]. Reward = [100.]
Curr episode timestep = 58
Scene graph at timestep 13267 is [True, False, False, False, True, False]
State prediction error at timestep 13267 is 0.012
Human Feedback received at timestep 13267 of None
Current timestep = 13268. State = [[-0.08282933  0.01292995]]. Action = [[-0.08751273  0.05978502  0.         -0.9547317 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 13268 is [True, False, False, False, True, False]
Current timestep = 13269. State = [[-0.08074175  0.01866107]]. Action = [[ 0.09103554  0.08573093  0.         -0.5873891 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 13269 is [True, False, False, False, True, False]
Current timestep = 13270. State = [[-0.07674761  0.01799159]]. Action = [[ 0.0248843  -0.06698451  0.         -0.8344501 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 13270 is [True, False, False, False, True, False]
Current timestep = 13271. State = [[-0.07180291  0.02013708]]. Action = [[ 0.06950548  0.07960873  0.         -0.87087315]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 13271 is [True, False, False, False, True, False]
Current timestep = 13272. State = [[-0.06587295  0.02255121]]. Action = [[ 0.06898586  0.00135507  0.         -0.60327244]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 13272 is [True, False, False, False, True, False]
Current timestep = 13273. State = [[-0.05956745  0.02203037]]. Action = [[ 0.070716   -0.01573126  0.         -0.7145444 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 13273 is [True, False, False, False, True, False]
State prediction error at timestep 13273 is 0.012
Human Feedback received at timestep 13273 of None
Current timestep = 13274. State = [[-0.05190232  0.02473018]]. Action = [[ 0.09468386  0.06368235  0.         -0.96575767]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 13274 is [True, False, False, False, True, False]
Current timestep = 13275. State = [[-0.255476  -0.1186156]]. Action = [[ 0.09521323 -0.05328564  0.          0.45121598]]. Reward = [100.]
Curr episode timestep = 7
Scene graph at timestep 13275 is [True, False, False, False, True, False]
State prediction error at timestep 13275 is 0.012
Human Feedback received at timestep 13275 of None
Current timestep = 13276. State = [[-0.2488729  -0.11798117]]. Action = [[ 0.06557813  0.08815589  0.         -0.467102  ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 13276 is [True, False, False, False, True, False]
Current timestep = 13277. State = [[-0.2510563  -0.11657748]]. Action = [[-0.09670632 -0.00361643  0.         -0.8935419 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 13277 is [True, False, False, False, True, False]
Current timestep = 13278. State = [[-0.25530463 -0.1209961 ]]. Action = [[-0.04203912 -0.06723741  0.         -0.63401043]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 13278 is [True, False, False, False, True, False]
Current timestep = 13279. State = [[-0.25182486 -0.12311503]]. Action = [[ 0.09272183  0.01529759  0.         -0.9290881 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 13279 is [True, False, False, False, True, False]
State prediction error at timestep 13279 is 0.012
Human Feedback received at timestep 13279 of None
Current timestep = 13280. State = [[-0.2456397  -0.11831245]]. Action = [[0.06754268 0.0951926  0.         0.20988953]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 13280 is [True, False, False, False, True, False]
Current timestep = 13281. State = [[-0.23865429 -0.11106597]]. Action = [[ 0.0979756   0.08239108  0.         -0.40784848]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 13281 is [True, False, False, False, True, False]
State prediction error at timestep 13281 is 0.012
Human Feedback received at timestep 13281 of None
Current timestep = 13282. State = [[-0.23200676 -0.10397251]]. Action = [[ 0.07732732  0.07310174  0.         -0.678902  ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 13282 is [True, False, False, False, True, False]
State prediction error at timestep 13282 is 0.012
Human Feedback received at timestep 13282 of None
Current timestep = 13283. State = [[-0.23320808 -0.09991869]]. Action = [[-0.07727041  0.01736204  0.         -0.8581525 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 13283 is [True, False, False, False, True, False]
Current timestep = 13284. State = [[-0.23450686 -0.09801832]]. Action = [[ 0.01118612  0.00588472  0.         -0.8079865 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 13284 is [True, False, False, False, True, False]
Current timestep = 13285. State = [[-0.23471244 -0.09285644]]. Action = [[-0.0122155   0.07461757  0.         -0.07418567]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 13285 is [True, False, False, False, True, False]
Current timestep = 13286. State = [[-0.23042569 -0.09141867]]. Action = [[ 0.09356665 -0.0472612   0.         -0.94342434]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 13286 is [True, False, False, False, True, False]
Current timestep = 13287. State = [[-0.22291659 -0.09533924]]. Action = [[ 0.0850857  -0.08156881  0.         -0.6108775 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 13287 is [True, False, False, False, True, False]
Current timestep = 13288. State = [[-0.21477056 -0.10048036]]. Action = [[ 0.08751769 -0.07063236  0.         -0.27371073]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 13288 is [True, False, False, False, True, False]
Current timestep = 13289. State = [[-0.2139435  -0.10293078]]. Action = [[-0.08270884 -0.00419875  0.         -0.90436643]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13289 is [True, False, False, False, True, False]
Current timestep = 13290. State = [[-0.21425198 -0.10344646]]. Action = [[ 0.01034857 -0.00204812  0.         -0.76532155]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 13290 is [True, False, False, False, True, False]
Current timestep = 13291. State = [[-0.20964848 -0.10813865]]. Action = [[ 0.06815603 -0.08753716  0.         -0.8527548 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 13291 is [True, False, False, False, True, False]
Current timestep = 13292. State = [[-0.20454603 -0.10910302]]. Action = [[ 0.0393622   0.04339641  0.         -0.9340341 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 13292 is [True, False, False, False, True, False]
Current timestep = 13293. State = [[-0.20404597 -0.11123867]]. Action = [[-0.04021912 -0.0509077   0.         -0.64087546]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 13293 is [True, False, False, False, True, False]
State prediction error at timestep 13293 is 0.012
Human Feedback received at timestep 13293 of None
Current timestep = 13294. State = [[-0.20612842 -0.1118668 ]]. Action = [[-0.04854923  0.03606419  0.         -0.3819499 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 13294 is [True, False, False, False, True, False]
Current timestep = 13295. State = [[-0.20216222 -0.10698295]]. Action = [[ 0.09212429  0.09078015  0.         -0.84593487]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 13295 is [True, False, False, False, True, False]
Current timestep = 13296. State = [[-0.19441238 -0.10737173]]. Action = [[ 0.0940016  -0.06198182  0.         -0.8408084 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 13296 is [True, False, False, False, True, False]
Current timestep = 13297. State = [[-0.19182134 -0.11294723]]. Action = [[-0.02381177 -0.07346435  0.         -0.7690651 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 13297 is [True, False, False, False, True, False]
Current timestep = 13298. State = [[-0.18685608 -0.11645892]]. Action = [[ 0.08998438 -0.01341964  0.         -0.9574627 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 13298 is [True, False, False, False, True, False]
Current timestep = 13299. State = [[-0.18110484 -0.11978131]]. Action = [[ 0.04389737 -0.0435163   0.         -0.6759822 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 13299 is [True, False, False, False, True, False]
State prediction error at timestep 13299 is 0.012
Human Feedback received at timestep 13299 of None
Current timestep = 13300. State = [[-0.17843363 -0.11812156]]. Action = [[ 0.00202163  0.07494783  0.         -0.89977086]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 13300 is [True, False, False, False, True, False]
Current timestep = 13301. State = [[-0.17524268 -0.12076376]]. Action = [[ 0.03907669 -0.08298546  0.         -0.87623316]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 13301 is [True, False, False, False, True, False]
Current timestep = 13302. State = [[-0.17575271 -0.11972556]]. Action = [[-0.063876    0.08370001  0.         -0.7070815 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 13302 is [True, False, False, False, True, False]
State prediction error at timestep 13302 is 0.012
Human Feedback received at timestep 13302 of None
Current timestep = 13303. State = [[-0.1752915  -0.11669125]]. Action = [[ 0.02774215  0.02083472  0.         -0.79736483]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 13303 is [True, False, False, False, True, False]
State prediction error at timestep 13303 is 0.012
Human Feedback received at timestep 13303 of None
Current timestep = 13304. State = [[-0.17187612 -0.12045162]]. Action = [[ 0.04127862 -0.08984806  0.         -0.7318239 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 13304 is [True, False, False, False, True, False]
Current timestep = 13305. State = [[-0.16574761 -0.12631778]]. Action = [[ 0.08481611 -0.06110891  0.         -0.52852255]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 13305 is [True, False, False, False, True, False]
State prediction error at timestep 13305 is 0.012
Human Feedback received at timestep 13305 of None
Current timestep = 13306. State = [[-0.16171427 -0.12907405]]. Action = [[ 0.01345346 -0.00574915  0.         -0.90570164]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 13306 is [True, False, False, True, False, False]
Current timestep = 13307. State = [[-0.15883255 -0.12521741]]. Action = [[ 0.02965934  0.09539535  0.         -0.6120615 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 13307 is [True, False, False, True, False, False]
State prediction error at timestep 13307 is 0.012
Human Feedback received at timestep 13307 of None
Current timestep = 13308. State = [[-0.160066   -0.12731455]]. Action = [[-0.0634564  -0.09601609  0.         -0.94641125]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 13308 is [True, False, False, True, False, False]
Current timestep = 13309. State = [[-0.15796322 -0.13087569]]. Action = [[ 0.05758338 -0.00524981  0.         -0.8809062 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 13309 is [True, False, False, True, False, False]
Current timestep = 13310. State = [[-0.15116228 -0.12939969]]. Action = [[ 0.09194931  0.04453912  0.         -0.93670964]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 13310 is [True, False, False, True, False, False]
Current timestep = 13311. State = [[-0.14963548 -0.12588857]]. Action = [[-0.03936174  0.04945629  0.         -0.87018144]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 13311 is [True, False, False, True, False, False]
Current timestep = 13312. State = [[-0.14964913 -0.1282992 ]]. Action = [[ 0.00540338 -0.07685629  0.         -0.9081521 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 13312 is [True, False, False, True, False, False]
State prediction error at timestep 13312 is 0.012
Human Feedback received at timestep 13312 of None
Current timestep = 13313. State = [[-0.14663023 -0.13096017]]. Action = [[ 0.04464986 -0.00581716  0.         -0.60600245]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 13313 is [True, False, False, True, False, False]
State prediction error at timestep 13313 is 0.012
Human Feedback received at timestep 13313 of None
Current timestep = 13314. State = [[-0.142964   -0.12859498]]. Action = [[ 0.03577044  0.05626578  0.         -0.8716298 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 13314 is [True, False, False, True, False, False]
Current timestep = 13315. State = [[-0.13749954 -0.12397883]]. Action = [[ 0.08050752  0.05637892  0.         -0.7990363 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 13315 is [True, False, False, True, False, False]
Current timestep = 13316. State = [[-0.13294823 -0.12000894]]. Action = [[ 0.03809073  0.0349756   0.         -0.82971   ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 13316 is [True, False, False, False, True, False]
Current timestep = 13317. State = [[-0.1342974  -0.11988515]]. Action = [[-0.06470958 -0.03027626  0.         -0.9251098 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 13317 is [True, False, False, False, True, False]
State prediction error at timestep 13317 is 0.012
Human Feedback received at timestep 13317 of None
Current timestep = 13318. State = [[-0.13686001 -0.11867474]]. Action = [[-0.03524186  0.03257113  0.         -0.9276396 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 13318 is [True, False, False, False, True, False]
Current timestep = 13319. State = [[-0.13336457 -0.1186052 ]]. Action = [[ 0.08190996 -0.02968256  0.         -0.5554143 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 13319 is [True, False, False, False, True, False]
Current timestep = 13320. State = [[-0.12573415 -0.11918081]]. Action = [[ 0.09482396 -0.00555143  0.         -0.5260715 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 13320 is [True, False, False, False, True, False]
Current timestep = 13321. State = [[-0.11786836 -0.11452217]]. Action = [[0.08925562 0.08848812 0.         0.3143382 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 13321 is [True, False, False, False, True, False]
State prediction error at timestep 13321 is 0.012
Human Feedback received at timestep 13321 of None
Current timestep = 13322. State = [[-0.11137539 -0.10772611]]. Action = [[ 0.06582469  0.07150293  0.         -0.33773315]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 13322 is [True, False, False, False, True, False]
State prediction error at timestep 13322 is 0.012
Human Feedback received at timestep 13322 of None
Current timestep = 13323. State = [[-0.10955945 -0.10050718]]. Action = [[-0.01772363  0.08191573  0.         -0.9337581 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 13323 is [True, False, False, False, True, False]
Current timestep = 13324. State = [[-0.11211859 -0.09616439]]. Action = [[-0.06488873  0.01287093  0.         -0.88835627]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 13324 is [True, False, False, False, True, False]
Current timestep = 13325. State = [[-0.1100556  -0.09675655]]. Action = [[ 0.05939073 -0.05066035  0.         -0.81715864]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 13325 is [True, False, False, False, True, False]
Current timestep = 13326. State = [[-0.10525645 -0.09472532]]. Action = [[ 0.03975252  0.04558214  0.         -0.9659413 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 13326 is [True, False, False, False, True, False]
Current timestep = 13327. State = [[-0.09832733 -0.09074099]]. Action = [[0.09455521 0.03015179 0.         0.6277778 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 13327 is [True, False, False, False, True, False]
Current timestep = 13328. State = [[-0.09556226 -0.08719957]]. Action = [[-0.02283841  0.0289286   0.         -0.7674742 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 13328 is [True, False, False, False, True, False]
Current timestep = 13329. State = [[-0.09388787 -0.08059037]]. Action = [[ 0.02148279  0.08989718  0.         -0.65230715]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 13329 is [True, False, False, False, True, False]
State prediction error at timestep 13329 is 0.012
Human Feedback received at timestep 13329 of None
Current timestep = 13330. State = [[-0.08866071 -0.07526352]]. Action = [[ 0.07805879  0.02343114  0.         -0.43832076]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 13330 is [True, False, False, False, True, False]
Current timestep = 13331. State = [[-0.08534741 -0.07294203]]. Action = [[ 0.00457821  0.00076883  0.         -0.3840335 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 13331 is [True, False, False, False, True, False]
Current timestep = 13332. State = [[-0.08485775 -0.07444745]]. Action = [[-0.0203302  -0.05699144  0.         -0.91311586]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 13332 is [True, False, False, False, True, False]
Current timestep = 13333. State = [[-0.08081426 -0.07277063]]. Action = [[ 0.06613494  0.04777119  0.         -0.82263386]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 13333 is [True, False, False, False, True, False]
State prediction error at timestep 13333 is 0.012
Human Feedback received at timestep 13333 of None
Current timestep = 13334. State = [[-0.07884881 -0.0699577 ]]. Action = [[-0.02134239  0.0120367   0.         -0.8693296 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 13334 is [True, False, False, False, True, False]
Current timestep = 13335. State = [[-0.07457583 -0.07023612]]. Action = [[ 0.07296985 -0.02953628  0.         -0.9728372 ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 13335 is [True, False, False, False, True, False]
Current timestep = 13336. State = [[-0.06733501 -0.07214016]]. Action = [[ 0.08304944 -0.02901445  0.         -0.92990416]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 13336 is [True, False, False, False, True, False]
Current timestep = 13337. State = [[-0.0595389  -0.07347572]]. Action = [[ 0.08512849 -0.00832663  0.         -0.6273657 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 13337 is [True, False, False, False, True, False]
Current timestep = 13338. State = [[-0.05184719 -0.07161485]]. Action = [[ 0.08107079  0.04767198  0.         -0.40833038]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 13338 is [True, False, False, False, True, False]
State prediction error at timestep 13338 is 0.012
Human Feedback received at timestep 13338 of None
Current timestep = 13339. State = [[-0.05082913 -0.0682221 ]]. Action = [[-0.06208361  0.04369017  0.         -0.9526304 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 13339 is [True, False, False, False, True, False]
Current timestep = 13340. State = [[-0.15307139 -0.05929029]]. Action = [[ 0.09596298  0.07439495  0.         -0.23406255]]. Reward = [100.]
Curr episode timestep = 64
Scene graph at timestep 13340 is [True, False, False, False, True, False]
Current timestep = 13341. State = [[-0.15231992 -0.05768059]]. Action = [[ 0.07754327 -0.04792904  0.         -0.02583468]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 13341 is [True, False, False, False, True, False]
Current timestep = 13342. State = [[-0.14752519 -0.0590759 ]]. Action = [[ 0.04009726 -0.01723896  0.         -0.8932717 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 13342 is [True, False, False, False, True, False]
Current timestep = 13343. State = [[-0.14383873 -0.0633221 ]]. Action = [[ 0.02995428 -0.08015934  0.         -0.6252195 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 13343 is [True, False, False, False, True, False]
Current timestep = 13344. State = [[-0.13946104 -0.06454229]]. Action = [[ 0.05168439  0.02545319  0.         -0.9326794 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 13344 is [True, False, False, False, True, False]
Current timestep = 13345. State = [[-0.13300106 -0.06234617]]. Action = [[ 0.08876192  0.0339122   0.         -0.8385953 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 13345 is [True, False, False, False, True, False]
Current timestep = 13346. State = [[-0.12598377 -0.06405086]]. Action = [[ 0.08073736 -0.05192287  0.         -0.37958205]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 13346 is [True, False, False, False, True, False]
State prediction error at timestep 13346 is 0.012
Human Feedback received at timestep 13346 of None
Current timestep = 13347. State = [[-0.11948165 -0.06522665]]. Action = [[ 0.06884938  0.01455879  0.         -0.93819517]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 13347 is [True, False, False, False, True, False]
State prediction error at timestep 13347 is 0.012
Human Feedback received at timestep 13347 of None
Current timestep = 13348. State = [[-0.11255892 -0.06176343]]. Action = [[0.08354767 0.07110246 0.         0.02895451]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 13348 is [True, False, False, False, True, False]
Current timestep = 13349. State = [[-0.11010088 -0.06303105]]. Action = [[-0.01899186 -0.06237608  0.         -0.79076326]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 13349 is [True, False, False, False, True, False]
Current timestep = 13350. State = [[-0.10673834 -0.0639799 ]]. Action = [[ 0.05012383  0.02227803  0.         -0.9610367 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 13350 is [True, False, False, False, True, False]
Current timestep = 13351. State = [[-0.10209708 -0.06725956]]. Action = [[ 0.03883579 -0.07004163  0.         -0.84011173]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 13351 is [True, False, False, False, True, False]
Current timestep = 13352. State = [[-0.09468413 -0.06570391]]. Action = [[ 0.09911776  0.08137081  0.         -0.84299254]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 13352 is [True, False, False, False, True, False]
Current timestep = 13353. State = [[-0.08610553 -0.06379215]]. Action = [[ 0.09256008 -0.00278948  0.          0.26792967]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 13353 is [True, False, False, False, True, False]
Current timestep = 13354. State = [[-0.07773481 -0.06799995]]. Action = [[ 0.08531173 -0.07954919  0.         -0.6375985 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13354 is [True, False, False, False, True, False]
State prediction error at timestep 13354 is 0.012
Human Feedback received at timestep 13354 of None
Current timestep = 13355. State = [[-0.06880242 -0.07298321]]. Action = [[ 0.09394123 -0.04054048  0.         -0.7937878 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 13355 is [True, False, False, False, True, False]
Current timestep = 13356. State = [[-0.06182685 -0.07116286]]. Action = [[ 0.04651498  0.07935894  0.         -0.9018862 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 13356 is [True, False, False, False, True, False]
State prediction error at timestep 13356 is 0.012
Human Feedback received at timestep 13356 of None
Current timestep = 13357. State = [[-0.05596855 -0.06540687]]. Action = [[ 0.05081067  0.0798207   0.         -0.03012633]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 13357 is [True, False, False, False, True, False]
Current timestep = 13358. State = [[-0.36743614  0.17110935]]. Action = [[0.07532451 0.00785837 0.         0.04620814]]. Reward = [100.]
Curr episode timestep = 17
Scene graph at timestep 13358 is [True, False, False, False, True, False]
Current timestep = 13359. State = [[-0.36804512  0.16879088]]. Action = [[0.07860965 0.00266524 0.         0.16137242]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 13359 is [True, False, False, False, False, True]
State prediction error at timestep 13359 is 0.012
Human Feedback received at timestep 13359 of None
Current timestep = 13360. State = [[-0.36398837  0.16873637]]. Action = [[0.06284816 0.01610561 0.         0.04725897]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 13360 is [True, False, False, False, False, True]
State prediction error at timestep 13360 is 0.012
Human Feedback received at timestep 13360 of None
Current timestep = 13361. State = [[-0.36285305  0.16402006]]. Action = [[-0.00925751 -0.09391739  0.         -0.5493671 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 13361 is [True, False, False, False, False, True]
State prediction error at timestep 13361 is 0.012
Human Feedback received at timestep 13361 of None
Current timestep = 13362. State = [[-0.36677223  0.16129853]]. Action = [[-0.07469964  0.00332732  0.         -0.47944105]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 13362 is [True, False, False, False, False, True]
Current timestep = 13363. State = [[-0.36701208  0.15803936]]. Action = [[ 0.04138988 -0.0631468   0.         -0.2698881 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 13363 is [True, False, False, False, False, True]
State prediction error at timestep 13363 is 0.012
Human Feedback received at timestep 13363 of None
Current timestep = 13364. State = [[-0.36639148  0.15453474]]. Action = [[-0.01240624 -0.02451446  0.          0.65752363]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 13364 is [True, False, False, False, False, True]
State prediction error at timestep 13364 is 0.012
Human Feedback received at timestep 13364 of None
Current timestep = 13365. State = [[-0.3693618   0.15217467]]. Action = [[-0.05875326 -0.02396867  0.         -0.8246976 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 13365 is [True, False, False, False, False, True]
Current timestep = 13366. State = [[-0.3681057   0.14931251]]. Action = [[ 0.05713607 -0.03345945  0.          0.21277213]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 13366 is [True, False, False, False, False, True]
State prediction error at timestep 13366 is 0.012
Human Feedback received at timestep 13366 of None
Current timestep = 13367. State = [[-0.363927    0.14459579]]. Action = [[ 0.04635691 -0.05413942  0.          0.6305485 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 13367 is [True, False, False, False, False, True]
Current timestep = 13368. State = [[-0.35810935  0.13846634]]. Action = [[ 0.07570209 -0.06410362  0.         -0.23191535]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 13368 is [True, False, False, False, False, True]
Current timestep = 13369. State = [[-0.3550512  0.1323822]]. Action = [[-0.00428708 -0.05430598  0.          0.2977506 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 13369 is [True, False, False, False, False, True]
State prediction error at timestep 13369 is 0.012
Human Feedback received at timestep 13369 of None
Current timestep = 13370. State = [[-0.35708177  0.12891755]]. Action = [[-0.06459072 -0.01350492  0.          0.01544404]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 13370 is [True, False, False, False, False, True]
Current timestep = 13371. State = [[-0.35962617  0.13151112]]. Action = [[-0.02546138  0.081931    0.         -0.61563075]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 13371 is [True, False, False, False, False, True]
State prediction error at timestep 13371 is 0.012
Human Feedback received at timestep 13371 of None
Current timestep = 13372. State = [[-0.35848516  0.13256922]]. Action = [[ 0.0441694  -0.00424619  0.          0.21450639]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13372 is [True, False, False, False, False, True]
Current timestep = 13373. State = [[-0.35419893  0.13315046]]. Action = [[0.06960652 0.03767166 0.         0.30451405]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 13373 is [True, False, False, False, False, True]
Current timestep = 13374. State = [[-0.34851682  0.13012967]]. Action = [[ 0.0784513  -0.05502993  0.         -0.27805   ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 13374 is [True, False, False, False, False, True]
Current timestep = 13375. State = [[-0.34715405  0.1305255 ]]. Action = [[-0.02311181  0.06353573  0.         -0.31748736]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 13375 is [True, False, False, False, False, True]
State prediction error at timestep 13375 is 0.012
Human Feedback received at timestep 13375 of None
Current timestep = 13376. State = [[-0.34695306  0.12932825]]. Action = [[ 0.01260047 -0.04869255  0.          0.04789901]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 13376 is [True, False, False, False, False, True]
Current timestep = 13377. State = [[-0.3460067   0.12475412]]. Action = [[ 0.00194118 -0.05947179  0.         -0.5804837 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 13377 is [True, False, False, False, False, True]
Current timestep = 13378. State = [[-0.3412354   0.12378265]]. Action = [[ 0.08316899  0.02766954  0.         -0.50602084]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 13378 is [True, False, False, False, True, False]
State prediction error at timestep 13378 is 0.012
Human Feedback received at timestep 13378 of None
Current timestep = 13379. State = [[-0.34207213  0.12607189]]. Action = [[-0.08201168  0.0404327   0.         -0.23183   ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 13379 is [True, False, False, False, True, False]
Current timestep = 13380. State = [[-0.34840015  0.12402832]]. Action = [[-0.09493142 -0.07135955  0.          0.38156915]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 13380 is [True, False, False, False, False, True]
Current timestep = 13381. State = [[-0.34761703  0.12379084]]. Action = [[0.07859797 0.03598738 0.         0.49943578]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 13381 is [True, False, False, False, True, False]
Current timestep = 13382. State = [[-0.34809813  0.1207891 ]]. Action = [[-0.07566004 -0.0876468   0.          0.41188335]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 13382 is [True, False, False, False, True, False]
Current timestep = 13383. State = [[-0.35310557  0.12157682]]. Action = [[-0.07098758  0.05884517  0.         -0.15730298]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 13383 is [True, False, False, False, True, False]
State prediction error at timestep 13383 is 0.012
Human Feedback received at timestep 13383 of None
Current timestep = 13384. State = [[-0.35438186  0.12399837]]. Action = [[ 0.02494512  0.01002324  0.         -0.01009828]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 13384 is [True, False, False, False, True, False]
State prediction error at timestep 13384 is 0.012
Human Feedback received at timestep 13384 of None
Current timestep = 13385. State = [[-0.3547708   0.12840308]]. Action = [[-0.00374552  0.07990529  0.          0.85206795]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 13385 is [True, False, False, False, True, False]
Current timestep = 13386. State = [[-0.3517572   0.13045269]]. Action = [[ 0.08636754 -0.00412469  0.          0.6555395 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 13386 is [True, False, False, False, False, True]
Current timestep = 13387. State = [[-0.3458413   0.13215932]]. Action = [[0.08920255 0.04393143 0.         0.39651334]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 13387 is [True, False, False, False, False, True]
State prediction error at timestep 13387 is 0.012
Human Feedback received at timestep 13387 of None
Current timestep = 13388. State = [[-0.33980054  0.135265  ]]. Action = [[ 0.08001561  0.04940107  0.         -0.27760553]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 13388 is [True, False, False, False, False, True]
Current timestep = 13389. State = [[-0.33926618  0.13275528]]. Action = [[-0.04799415 -0.08261205  0.          0.39222157]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 13389 is [True, False, False, False, False, True]
Current timestep = 13390. State = [[-0.34201917  0.12796627]]. Action = [[-0.03520522 -0.0564961   0.         -0.15586627]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 13390 is [True, False, False, False, False, True]
Current timestep = 13391. State = [[-0.3455611   0.13058649]]. Action = [[-0.05082233  0.08413085  0.          0.439744  ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 13391 is [True, False, False, False, False, True]
State prediction error at timestep 13391 is 0.012
Human Feedback received at timestep 13391 of None
Current timestep = 13392. State = [[-0.34307525  0.12875797]]. Action = [[ 0.08720263 -0.09448882  0.         -0.17598331]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 13392 is [True, False, False, False, False, True]
Current timestep = 13393. State = [[-0.33798748  0.12975183]]. Action = [[0.05255897 0.0868616  0.         0.54389906]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 13393 is [True, False, False, False, False, True]
Current timestep = 13394. State = [[-0.33928403  0.13257536]]. Action = [[-0.06218871  0.01485083  0.         -0.25514555]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 13394 is [True, False, False, False, False, True]
Current timestep = 13395. State = [[-0.34289098  0.13776267]]. Action = [[-0.0311287   0.09064453  0.         -0.01956636]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 13395 is [True, False, False, False, False, True]
State prediction error at timestep 13395 is 0.012
Human Feedback received at timestep 13395 of None
Current timestep = 13396. State = [[-0.34012052  0.13697736]]. Action = [[ 0.08925544 -0.07759474  0.         -0.13188279]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 13396 is [True, False, False, False, False, True]
Current timestep = 13397. State = [[-0.3358422   0.13708201]]. Action = [[ 0.03736215  0.05042563  0.         -0.08582425]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 13397 is [True, False, False, False, False, True]
State prediction error at timestep 13397 is 0.012
Human Feedback received at timestep 13397 of None
Current timestep = 13398. State = [[-0.32981455  0.13582976]]. Action = [[ 0.09369246 -0.04640631  0.          0.41015935]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 13398 is [True, False, False, False, False, True]
Current timestep = 13399. State = [[-0.3228626  0.1384111]]. Action = [[ 0.07308317  0.08827225  0.         -0.36549544]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 13399 is [True, False, False, False, False, True]
Current timestep = 13400. State = [[-0.31895217  0.13638371]]. Action = [[ 0.01252828 -0.08800313  0.          0.1179049 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 13400 is [True, False, False, False, False, True]
Current timestep = 13401. State = [[-0.3137372  0.13428  ]]. Action = [[ 0.07115617  0.00866797  0.         -0.48806846]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 13401 is [True, False, False, False, False, True]
State prediction error at timestep 13401 is 0.012
Human Feedback received at timestep 13401 of None
Current timestep = 13402. State = [[-0.30742517  0.13617367]]. Action = [[ 0.05931074  0.0441991   0.         -0.53746253]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 13402 is [True, False, False, False, False, True]
Current timestep = 13403. State = [[-0.30057603  0.13509491]]. Action = [[ 0.07153101 -0.03922362  0.         -0.17548013]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 13403 is [True, False, False, False, False, True]
Current timestep = 13404. State = [[-0.29227465  0.13305843]]. Action = [[ 0.08555423 -0.00993119  0.         -0.8358869 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 13404 is [True, False, False, False, False, True]
Current timestep = 13405. State = [[-0.285161    0.12896992]]. Action = [[ 0.04567166 -0.0645664   0.         -0.13662118]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 13405 is [True, False, False, False, False, True]
Current timestep = 13406. State = [[-0.27649623  0.12420537]]. Action = [[ 0.09176201 -0.0455302   0.         -0.87465775]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 13406 is [True, False, False, False, False, True]
Current timestep = 13407. State = [[-0.271874    0.11871911]]. Action = [[-0.02286275 -0.06755073  0.         -0.44980502]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 13407 is [True, False, False, False, True, False]
Current timestep = 13408. State = [[-0.26631352  0.1115326 ]]. Action = [[ 0.05885177 -0.08940412  0.         -0.45043862]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 13408 is [True, False, False, False, True, False]
State prediction error at timestep 13408 is 0.012
Human Feedback received at timestep 13408 of None
Current timestep = 13409. State = [[-0.25842774  0.10864974]]. Action = [[ 0.06701118  0.02219154  0.         -0.6452277 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 13409 is [True, False, False, False, True, False]
Current timestep = 13410. State = [[-0.25084487  0.10871823]]. Action = [[0.06259865 0.02283849 0.         0.12497377]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 13410 is [True, False, False, False, True, False]
Current timestep = 13411. State = [[-0.24276435  0.11202352]]. Action = [[ 0.08313554  0.08459557  0.         -0.44784105]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 13411 is [True, False, False, False, True, False]
Current timestep = 13412. State = [[-0.23755759  0.11642218]]. Action = [[ 0.02148248  0.06429208  0.         -0.54419965]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 13412 is [True, False, False, False, True, False]
Current timestep = 13413. State = [[-0.23544623  0.11427183]]. Action = [[-0.00771026 -0.07203145  0.         -0.6955987 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 13413 is [True, False, False, False, True, False]
Current timestep = 13414. State = [[-0.23312399  0.10919029]]. Action = [[ 0.00842037 -0.0593377   0.         -0.92399657]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 13414 is [True, False, False, False, True, False]
State prediction error at timestep 13414 is 0.012
Human Feedback received at timestep 13414 of None
Current timestep = 13415. State = [[-0.2324332   0.10445047]]. Action = [[-0.03416114 -0.05694751  0.          0.48933327]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 13415 is [True, False, False, False, True, False]
Current timestep = 13416. State = [[-0.22698686  0.10080286]]. Action = [[ 0.09309102 -0.03159094  0.         -0.8504499 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 13416 is [True, False, False, False, True, False]
Current timestep = 13417. State = [[-0.22160886  0.09561591]]. Action = [[ 0.01494388 -0.07065178  0.         -0.77381843]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 13417 is [True, False, False, False, True, False]
Current timestep = 13418. State = [[-0.22134835  0.09400347]]. Action = [[-0.0495495   0.02206707  0.         -0.49211752]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 13418 is [True, False, False, False, True, False]
Current timestep = 13419. State = [[-0.21854374  0.08931416]]. Action = [[ 0.04817695 -0.09385483  0.         -0.92171943]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 13419 is [True, False, False, False, True, False]
State prediction error at timestep 13419 is 0.012
Human Feedback received at timestep 13419 of None
Current timestep = 13420. State = [[-0.21490769  0.08260187]]. Action = [[ 0.01193336 -0.06148564  0.          0.51652575]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 13420 is [True, False, False, False, True, False]
State prediction error at timestep 13420 is 0.012
Human Feedback received at timestep 13420 of None
Current timestep = 13421. State = [[-0.20849395  0.07699119]]. Action = [[ 0.08970865 -0.04697277  0.         -0.24698275]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 13421 is [True, False, False, False, True, False]
State prediction error at timestep 13421 is 0.012
Human Feedback received at timestep 13421 of None
Current timestep = 13422. State = [[-0.20863906  0.07532664]]. Action = [[-0.09001001  0.02505643  0.         -0.67057157]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 13422 is [True, False, False, False, True, False]
Current timestep = 13423. State = [[-0.20734355  0.07551327]]. Action = [[ 0.06264999  0.01646979  0.         -0.52090883]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 13423 is [True, False, False, False, True, False]
State prediction error at timestep 13423 is 0.012
Human Feedback received at timestep 13423 of None
Current timestep = 13424. State = [[-0.20541942  0.07826354]]. Action = [[-0.00111852  0.06943206  0.         -0.2983362 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 13424 is [True, False, False, False, True, False]
Current timestep = 13425. State = [[-0.20117019  0.07834475]]. Action = [[ 0.08482479 -0.02104487  0.         -0.829486  ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 13425 is [True, False, False, False, True, False]
Current timestep = 13426. State = [[-0.19403791  0.07390669]]. Action = [[ 0.09391173 -0.05786508  0.         -0.9238746 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 13426 is [True, False, False, False, True, False]
Current timestep = 13427. State = [[-0.19190462  0.07427359]]. Action = [[-0.02314539  0.06296995  0.         -0.70993805]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 13427 is [True, False, False, False, True, False]
Current timestep = 13428. State = [[-0.18765305  0.07550352]]. Action = [[ 0.08923147  0.00363906  0.         -0.8867233 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 13428 is [True, False, False, False, True, False]
Current timestep = 13429. State = [[-0.18817909  0.0731343 ]]. Action = [[-0.08360207 -0.04401032  0.         -0.6478486 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 13429 is [True, False, False, False, True, False]
Current timestep = 13430. State = [[-0.19125497  0.07395567]]. Action = [[-0.0273172   0.04429214  0.         -0.924401  ]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 13430 is [True, False, False, False, True, False]
Current timestep = 13431. State = [[-0.19319832  0.07365815]]. Action = [[-0.02359857 -0.03223324  0.         -0.47971404]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 13431 is [True, False, False, False, True, False]
Current timestep = 13432. State = [[-0.19036967  0.07009073]]. Action = [[ 0.06932522 -0.05379052  0.         -0.54709095]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 13432 is [True, False, False, False, True, False]
Current timestep = 13433. State = [[-0.18673626  0.07081354]]. Action = [[ 0.03229966  0.05480628  0.         -0.8548866 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 13433 is [True, False, False, False, True, False]
Current timestep = 13434. State = [[-0.18381937  0.06872173]]. Action = [[ 0.03505675 -0.06537554  0.          0.39577508]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 13434 is [True, False, False, False, True, False]
Current timestep = 13435. State = [[-0.17903398  0.0707005 ]]. Action = [[ 0.06976158  0.0869916   0.         -0.79807323]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 13435 is [True, False, False, False, True, False]
Current timestep = 13436. State = [[-0.1741277   0.07340042]]. Action = [[ 0.05618482  0.01533394  0.         -0.96879303]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 13436 is [True, False, False, False, True, False]
Current timestep = 13437. State = [[-0.17455399  0.07628714]]. Action = [[-0.05224414  0.05043962  0.         -0.5966462 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 13437 is [True, False, False, False, True, False]
Current timestep = 13438. State = [[-0.17068422  0.07521456]]. Action = [[ 0.09952217 -0.05356472  0.         -0.6823923 ]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 13438 is [True, False, False, False, True, False]
Current timestep = 13439. State = [[-0.16554844  0.07568564]]. Action = [[ 0.03321493  0.04124188  0.         -0.82643414]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 13439 is [True, False, False, False, True, False]
Current timestep = 13440. State = [[-0.16247812  0.07708643]]. Action = [[ 0.02206353  0.00548412  0.         -0.32602   ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 13440 is [True, False, False, False, True, False]
Current timestep = 13441. State = [[-0.1560473   0.07393296]]. Action = [[ 0.09331363 -0.06813834  0.         -0.60956717]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 13441 is [True, False, False, False, True, False]
Current timestep = 13442. State = [[-0.15041366  0.07577375]]. Action = [[ 0.03306038  0.08211455  0.         -0.875551  ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 13442 is [True, False, False, False, True, False]
Current timestep = 13443. State = [[-0.14343299  0.07706799]]. Action = [[ 0.094416   -0.01723579  0.         -0.630913  ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 13443 is [True, False, False, False, True, False]
Current timestep = 13444. State = [[-0.13673271  0.07989194]]. Action = [[ 0.05237753  0.06839549  0.         -0.9034967 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 13444 is [True, False, False, False, True, False]
Current timestep = 13445. State = [[-0.13095935  0.08160602]]. Action = [[ 0.0546736  -0.00442365  0.         -0.92947626]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 13445 is [True, False, False, False, True, False]
State prediction error at timestep 13445 is 0.012
Human Feedback received at timestep 13445 of None
Current timestep = 13446. State = [[-0.1267715   0.07883014]]. Action = [[ 0.01351013 -0.05816091  0.         -0.761134  ]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 13446 is [True, False, False, False, True, False]
Current timestep = 13447. State = [[-0.12016778  0.0733835 ]]. Action = [[ 0.0772242  -0.07685085  0.         -0.86349666]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 13447 is [True, False, False, False, True, False]
Current timestep = 13448. State = [[-0.11095543  0.06640722]]. Action = [[ 0.0903355  -0.08429582  0.         -0.8597744 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 13448 is [True, False, False, False, True, False]
Current timestep = 13449. State = [[-0.10420624  0.06036095]]. Action = [[ 0.02534867 -0.05085272  0.         -0.56774914]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 13449 is [True, False, False, False, True, False]
Current timestep = 13450. State = [[-0.0973376   0.05264365]]. Action = [[ 0.06015565 -0.09771577  0.         -0.786304  ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 13450 is [True, False, False, False, True, False]
Current timestep = 13451. State = [[-0.09459372  0.04788496]]. Action = [[-0.04584745 -0.00633287  0.         -0.3383546 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 13451 is [True, False, False, False, True, False]
Current timestep = 13452. State = [[-0.09438701  0.04830987]]. Action = [[-0.03388868  0.04144876  0.          0.36784375]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 13452 is [True, False, False, False, True, False]
Current timestep = 13453. State = [[-0.09020512  0.04817691]]. Action = [[ 0.06041009 -0.00532438  0.         -0.8011731 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 13453 is [True, False, False, False, True, False]
Current timestep = 13454. State = [[-0.08300589  0.04411765]]. Action = [[ 0.07638579 -0.05696765  0.         -0.93362916]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 13454 is [True, False, False, False, True, False]
Current timestep = 13455. State = [[-0.07955722  0.04368683]]. Action = [[-0.01009355  0.0486533   0.         -0.28891683]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 13455 is [True, False, False, False, True, False]
Current timestep = 13456. State = [[-0.07599138  0.04405497]]. Action = [[ 0.04655533 -0.00297026  0.         -0.716724  ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 13456 is [True, False, False, False, True, False]
Current timestep = 13457. State = [[-0.07177465  0.04144414]]. Action = [[ 0.03303529 -0.03831691  0.         -0.6712373 ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 13457 is [True, False, False, False, True, False]
Current timestep = 13458. State = [[-0.06673566  0.0394018 ]]. Action = [[ 0.05718065 -0.00379822  0.         -0.9034815 ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 13458 is [True, False, False, False, True, False]
Current timestep = 13459. State = [[-0.06167638  0.04010676]]. Action = [[ 0.04793536  0.03248852  0.         -0.67804873]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 13459 is [True, False, False, False, True, False]
Current timestep = 13460. State = [[-0.05565746  0.03909886]]. Action = [[ 0.07463811 -0.02675278  0.         -0.7954045 ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 13460 is [True, False, False, False, True, False]
Current timestep = 13461. State = [[-0.05278181  0.03848551]]. Action = [[-0.0075938   0.01427982  0.         -0.9958087 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 13461 is [True, False, False, False, True, False]
Current timestep = 13462. State = [[-0.05120323  0.04213912]]. Action = [[ 0.01188874  0.07099999  0.         -0.8300473 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 13462 is [True, False, False, False, True, False]
Current timestep = 13463. State = [[-0.05173646  0.04517844]]. Action = [[-0.03712071  0.01467756  0.         -0.41926718]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 13463 is [True, False, False, False, True, False]
Current timestep = 13464. State = [[-0.30350998 -0.19470136]]. Action = [[0.09692051 0.08787907 0.         0.00340867]]. Reward = [100.]
Curr episode timestep = 105
Scene graph at timestep 13464 is [True, False, False, False, True, False]
Current timestep = 13465. State = [[-0.3033652 -0.1965784]]. Action = [[ 0.08570112  0.01241033  0.         -0.64113736]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 13465 is [True, False, False, True, False, False]
Current timestep = 13466. State = [[-0.29894817 -0.19652498]]. Action = [[ 0.05307569 -0.02091605  0.         -0.4384793 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 13466 is [True, False, False, True, False, False]
Current timestep = 13467. State = [[-0.29451647 -0.19442739]]. Action = [[ 0.06086118  0.03457393  0.         -0.93579984]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 13467 is [True, False, False, True, False, False]
Current timestep = 13468. State = [[-0.2878955 -0.1911017]]. Action = [[ 0.09923155  0.0238492   0.         -0.5426564 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 13468 is [True, False, False, True, False, False]
Current timestep = 13469. State = [[-0.28062576 -0.18827133]]. Action = [[ 0.08716851  0.01387085  0.         -0.9069253 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 13469 is [True, False, False, True, False, False]
State prediction error at timestep 13469 is 0.012
Human Feedback received at timestep 13469 of None
Current timestep = 13470. State = [[-0.27472565 -0.18315615]]. Action = [[ 0.0647561   0.06680138  0.         -0.85337776]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 13470 is [True, False, False, True, False, False]
Current timestep = 13471. State = [[-0.27027622 -0.1810386 ]]. Action = [[ 0.04977099 -0.02326412  0.         -0.82372046]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 13471 is [True, False, False, True, False, False]
Current timestep = 13472. State = [[-0.26780334 -0.18428564]]. Action = [[ 0.01358338 -0.07441994  0.         -0.9475793 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 13472 is [True, False, False, True, False, False]
Current timestep = 13473. State = [[-0.2634621  -0.18852085]]. Action = [[ 0.06386919 -0.05186534  0.         -0.9280696 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 13473 is [True, False, False, True, False, False]
Current timestep = 13474. State = [[-0.2648805  -0.18880722]]. Action = [[-0.09375234  0.03288809  0.         -0.8613251 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 13474 is [True, False, False, True, False, False]
Current timestep = 13475. State = [[-0.267232  -0.1855048]]. Action = [[-0.00786675  0.05391897  0.         -0.28996837]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 13475 is [True, False, False, True, False, False]
Current timestep = 13476. State = [[-0.26305017 -0.18144062]]. Action = [[ 0.08236907  0.04282231  0.         -0.48178196]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 13476 is [True, False, False, True, False, False]
Current timestep = 13477. State = [[-0.26003236 -0.17677428]]. Action = [[ 0.00238398  0.05094212  0.         -0.966985  ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 13477 is [True, False, False, True, False, False]
Current timestep = 13478. State = [[-0.26258314 -0.17736231]]. Action = [[-0.06623265 -0.05483743  0.         -0.8221343 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13478 is [True, False, False, True, False, False]
State prediction error at timestep 13478 is 0.012
Human Feedback received at timestep 13478 of None
Current timestep = 13479. State = [[-0.26389116 -0.1774112 ]]. Action = [[ 0.00065519  0.0250795   0.         -0.55774415]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 13479 is [True, False, False, True, False, False]
Current timestep = 13480. State = [[-0.259287   -0.18025033]]. Action = [[ 0.08473255 -0.08134792  0.         -0.7426537 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 13480 is [True, False, False, True, False, False]
Current timestep = 13481. State = [[-0.25249198 -0.1795974 ]]. Action = [[ 0.06878453  0.05135656  0.         -0.8746381 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 13481 is [True, False, False, True, False, False]
Current timestep = 13482. State = [[-0.24521083 -0.17864248]]. Action = [[ 0.08596738 -0.01784577  0.         -0.92898726]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 13482 is [True, False, False, True, False, False]
State prediction error at timestep 13482 is 0.012
Human Feedback received at timestep 13482 of None
Current timestep = 13483. State = [[-0.24148947 -0.17686312]]. Action = [[ 0.00370789  0.03874815  0.         -0.95425904]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 13483 is [True, False, False, True, False, False]
Current timestep = 13484. State = [[-0.23598331 -0.17917807]]. Action = [[ 0.09013508 -0.07383792  0.         -0.9726888 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 13484 is [True, False, False, True, False, False]
Current timestep = 13485. State = [[-0.23181944 -0.18002234]]. Action = [[ 0.00485206  0.02781325  0.         -0.748991  ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 13485 is [True, False, False, True, False, False]
State prediction error at timestep 13485 is 0.012
Human Feedback received at timestep 13485 of None
Current timestep = 13486. State = [[-0.2266722  -0.18114302]]. Action = [[ 0.07410223 -0.03249677  0.          0.1913265 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 13486 is [True, False, False, True, False, False]
Current timestep = 13487. State = [[-0.22730614 -0.18360926]]. Action = [[-0.08637405 -0.02128981  0.         -0.8200766 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 13487 is [True, False, False, True, False, False]
Current timestep = 13488. State = [[-0.23038585 -0.18904652]]. Action = [[-0.0414516  -0.07841758  0.         -0.9394918 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 13488 is [True, False, False, True, False, False]
State prediction error at timestep 13488 is 0.012
Human Feedback received at timestep 13488 of None
Current timestep = 13489. State = [[-0.22948013 -0.19685926]]. Action = [[ 0.01876433 -0.08919008  0.         -0.555563  ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 13489 is [True, False, False, True, False, False]
Current timestep = 13490. State = [[-0.2289281  -0.19946474]]. Action = [[-0.02528199  0.02834103  0.         -0.8242048 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 13490 is [True, False, False, True, False, False]
Current timestep = 13491. State = [[-0.22390957 -0.19731371]]. Action = [[ 0.09515677  0.05191483  0.         -0.7115395 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 13491 is [True, False, False, True, False, False]
Current timestep = 13492. State = [[-0.21771961 -0.19435008]]. Action = [[ 0.05638693  0.03672045  0.         -0.7835297 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 13492 is [True, False, False, True, False, False]
Current timestep = 13493. State = [[-0.21068735 -0.19542342]]. Action = [[ 0.09529243 -0.04262131  0.         -0.5635979 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 13493 is [True, False, False, True, False, False]
State prediction error at timestep 13493 is 0.012
Human Feedback received at timestep 13493 of None
Current timestep = 13494. State = [[-0.20309962 -0.19576149]]. Action = [[0.08486966 0.01702732 0.         0.22064006]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 13494 is [True, False, False, True, False, False]
Current timestep = 13495. State = [[-0.19734533 -0.19123201]]. Action = [[ 0.05300643  0.08105613  0.         -0.9189513 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 13495 is [True, False, False, True, False, False]
Current timestep = 13496. State = [[-0.19052336 -0.18873827]]. Action = [[ 0.09523074 -0.00528997  0.         -0.8232075 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 13496 is [True, False, False, True, False, False]
Current timestep = 13497. State = [[-0.18850991 -0.18665972]]. Action = [[-0.03127481  0.03485856  0.         -0.6922493 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 13497 is [True, False, False, True, False, False]
Current timestep = 13498. State = [[-0.18597063 -0.18258551]]. Action = [[ 0.05278099  0.05130864  0.         -0.9045587 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 13498 is [True, False, False, True, False, False]
Current timestep = 13499. State = [[-0.18030544 -0.18186937]]. Action = [[ 0.07099146 -0.03545267  0.         -0.45865262]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 13499 is [True, False, False, True, False, False]
State prediction error at timestep 13499 is 0.012
Human Feedback received at timestep 13499 of None
Current timestep = 13500. State = [[-0.17489399 -0.18204205]]. Action = [[ 0.04740299 -0.00289761  0.         -0.20116866]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 13500 is [True, False, False, True, False, False]
State prediction error at timestep 13500 is 0.012
Human Feedback received at timestep 13500 of None
Current timestep = 13501. State = [[-0.16817014 -0.18182121]]. Action = [[ 0.08327963 -0.00876735  0.         -0.90772367]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 13501 is [True, False, False, True, False, False]
Current timestep = 13502. State = [[-0.16153601 -0.18035147]]. Action = [[ 0.05917049  0.02029081  0.         -0.8269153 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 13502 is [True, False, False, True, False, False]
Current timestep = 13503. State = [[-0.15366961 -0.18076135]]. Action = [[ 0.0944506  -0.03216258  0.         -0.46813583]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 13503 is [True, False, False, True, False, False]
Current timestep = 13504. State = [[-0.14744464 -0.17857645]]. Action = [[ 0.03799654  0.05320541  0.         -0.8463891 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 13504 is [True, False, False, True, False, False]
Current timestep = 13505. State = [[-0.14137638 -0.17464267]]. Action = [[ 0.06567318  0.04008354  0.         -0.7749397 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 13505 is [True, False, False, True, False, False]
Current timestep = 13506. State = [[-0.133681  -0.1700737]]. Action = [[ 0.0848716   0.05343211  0.         -0.29047108]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 13506 is [True, False, False, True, False, False]
Current timestep = 13507. State = [[-0.12472815 -0.16635752]]. Action = [[ 0.09910249  0.02386878  0.         -0.46843785]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 13507 is [True, False, False, True, False, False]
Current timestep = 13508. State = [[-0.11622664 -0.16711737]]. Action = [[ 0.07789554 -0.04996734  0.         -0.73870337]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 13508 is [True, False, False, True, False, False]
State prediction error at timestep 13508 is 0.012
Human Feedback received at timestep 13508 of None
Current timestep = 13509. State = [[-0.10864317 -0.16595684]]. Action = [[ 0.06532931  0.0371953   0.         -0.9689848 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 13509 is [True, False, False, True, False, False]
State prediction error at timestep 13509 is 0.012
Human Feedback received at timestep 13509 of None
Current timestep = 13510. State = [[-0.10118448 -0.1656493 ]]. Action = [[ 0.06787183 -0.02645309  0.         -0.9525521 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 13510 is [True, False, False, True, False, False]
Current timestep = 13511. State = [[-0.09196359 -0.1696817 ]]. Action = [[ 0.09750908 -0.07526611  0.         -0.7378377 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 13511 is [True, False, False, True, False, False]
Current timestep = 13512. State = [[-0.08754368 -0.16778098]]. Action = [[-0.03106871  0.08567999  0.         -0.87104774]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 13512 is [True, False, False, True, False, False]
Current timestep = 13513. State = [[-0.08173417 -0.16151105]]. Action = [[ 0.08783894  0.07094271  0.         -0.694787  ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 13513 is [True, False, False, True, False, False]
Current timestep = 13514. State = [[-0.0725868 -0.1634584]]. Action = [[ 0.09725104 -0.09656951  0.         -0.85450566]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 13514 is [True, False, False, True, False, False]
Current timestep = 13515. State = [[-0.06980921 -0.1624228 ]]. Action = [[-0.0612596   0.07420243  0.         -0.7240516 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 13515 is [True, False, False, True, False, False]
State prediction error at timestep 13515 is 0.012
Human Feedback received at timestep 13515 of None
Current timestep = 13516. State = [[-0.06665163 -0.16253598]]. Action = [[ 0.06313191 -0.05514579  0.         -0.8627604 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 13516 is [True, False, False, True, False, False]
State prediction error at timestep 13516 is 0.012
Human Feedback received at timestep 13516 of None
Current timestep = 13517. State = [[-0.06086576 -0.16808811]]. Action = [[ 0.04580121 -0.08677604  0.         -0.84882975]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 13517 is [True, False, False, True, False, False]
Current timestep = 13518. State = [[-0.05583389 -0.16835792]]. Action = [[ 0.03551512  0.05102462  0.         -0.66005254]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 13518 is [True, False, False, True, False, False]
Current timestep = 13519. State = [[-0.05001539 -0.17027508]]. Action = [[ 0.05922724 -0.05985117  0.         -0.9344171 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 13519 is [True, False, False, True, False, False]
State prediction error at timestep 13519 is 0.012
Human Feedback received at timestep 13519 of None
Current timestep = 13520. State = [[-0.04199928 -0.17226928]]. Action = [[ 0.09300836  0.00383949  0.         -0.96183836]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 13520 is [True, False, False, True, False, False]
Current timestep = 13521. State = [[-0.03582235 -0.1765764 ]]. Action = [[ 0.03631907 -0.07352512  0.         -0.92766136]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 13521 is [False, True, False, True, False, False]
Current timestep = 13522. State = [[-0.02820971 -0.17998639]]. Action = [[ 0.09539426 -0.00560386  0.         -0.44725358]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 13522 is [False, True, False, True, False, False]
Current timestep = 13523. State = [[-0.02133615 -0.1813293 ]]. Action = [[ 5.0184883e-02 -4.6089292e-05  0.0000000e+00 -5.9218717e-01]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 13523 is [False, True, False, True, False, False]
Current timestep = 13524. State = [[-0.01929082 -0.18347527]]. Action = [[-0.03088574 -0.02137248  0.         -0.9804129 ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 13524 is [False, True, False, True, False, False]
Current timestep = 13525. State = [[-0.01814879 -0.18135324]]. Action = [[-0.00869993  0.07539322  0.         -0.8055371 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 13525 is [False, True, False, True, False, False]
Current timestep = 13526. State = [[-0.0152331  -0.18194826]]. Action = [[ 0.02086892 -0.04421233  0.         -0.8110976 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 13526 is [False, True, False, True, False, False]
Current timestep = 13527. State = [[-0.00864756 -0.18148112]]. Action = [[ 0.08415867  0.04065449  0.         -0.94598204]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 13527 is [False, True, False, True, False, False]
State prediction error at timestep 13527 is 0.012
Human Feedback received at timestep 13527 of None
Current timestep = 13528. State = [[-0.0057957  -0.17974007]]. Action = [[-0.02517001  0.01505236  0.         -0.61743677]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 13528 is [False, True, False, True, False, False]
Current timestep = 13529. State = [[-0.00725502 -0.1755551 ]]. Action = [[-0.05789567  0.07230324  0.         -0.6348463 ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 13529 is [False, True, False, True, False, False]
Current timestep = 13530. State = [[-0.0043501  -0.17350481]]. Action = [[ 0.06310038 -0.01467173  0.         -0.9144617 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 13530 is [False, True, False, True, False, False]
State prediction error at timestep 13530 is 0.012
Human Feedback received at timestep 13530 of None
Current timestep = 13531. State = [[ 0.00190108 -0.17612378]]. Action = [[ 0.0627755  -0.05667059  0.         -0.81768197]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 13531 is [False, True, False, True, False, False]
Current timestep = 13532. State = [[ 0.00542245 -0.17457716]]. Action = [[ 0.00371693  0.05922622  0.         -0.82815576]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 13532 is [False, True, False, True, False, False]
Current timestep = 13533. State = [[ 0.01125215 -0.17648545]]. Action = [[ 0.09214307 -0.07903765  0.         -0.96897304]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 13533 is [False, True, False, True, False, False]
Current timestep = 13534. State = [[ 0.01565247 -0.18032826]]. Action = [[ 0.01000053 -0.03030945  0.         -0.94425875]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 13534 is [False, True, False, True, False, False]
Current timestep = 13535. State = [[ 0.01942166 -0.18467976]]. Action = [[ 0.03807335 -0.05723004  0.         -0.8056951 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 13535 is [False, True, False, True, False, False]
State prediction error at timestep 13535 is 0.012
Human Feedback received at timestep 13535 of None
Current timestep = 13536. State = [[ 0.02471965 -0.18538906]]. Action = [[ 0.05851347  0.03542284  0.         -0.53595865]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 13536 is [False, True, False, True, False, False]
Current timestep = 13537. State = [[ 0.03191978 -0.18960105]]. Action = [[ 0.09094239 -0.08897281  0.         -0.89648676]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 13537 is [False, True, False, True, False, False]
Current timestep = 13538. State = [[ 0.03317692 -0.19128172]]. Action = [[-0.06870224  0.04366932  0.         -0.874792  ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 13538 is [False, True, False, True, False, False]
Current timestep = 13539. State = [[ 0.03669675 -0.18582623]]. Action = [[0.09368298 0.09635172 0.         0.33646595]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 13539 is [False, True, False, True, False, False]
Current timestep = 13540. State = [[ 0.04188688 -0.18079583]]. Action = [[ 0.04589298  0.04076654  0.         -0.16354942]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 13540 is [False, True, False, True, False, False]
Current timestep = 13541. State = [[ 0.04828804 -0.17583843]]. Action = [[ 0.09522129  0.06162808  0.         -0.9946752 ]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 13541 is [False, True, False, True, False, False]
State prediction error at timestep 13541 is 0.012
Human Feedback received at timestep 13541 of None
Current timestep = 13542. State = [[ 0.05577378 -0.17276354]]. Action = [[ 0.0958494   0.00731323  0.         -0.7000742 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 13542 is [False, True, False, True, False, False]
Current timestep = 13543. State = [[ 0.05692493 -0.17610788]]. Action = [[-0.04821223 -0.08667304  0.         -0.5093399 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 13543 is [False, False, True, True, False, False]
Current timestep = 13544. State = [[ 0.06099227 -0.17584074]]. Action = [[ 0.0916662   0.04820821  0.         -0.9780107 ]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 13544 is [False, False, True, True, False, False]
State prediction error at timestep 13544 is 0.012
Human Feedback received at timestep 13544 of None
Current timestep = 13545. State = [[ 0.06765269 -0.171103  ]]. Action = [[ 0.07387509  0.05816781  0.         -0.9761119 ]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 13545 is [False, False, True, True, False, False]
Current timestep = 13546. State = [[ 0.07455444 -0.16526303]]. Action = [[ 0.08663633  0.06566926  0.         -0.5602007 ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 13546 is [False, False, True, True, False, False]
Current timestep = 13547. State = [[ 0.08180343 -0.16498421]]. Action = [[ 0.08766799 -0.05248589  0.         -0.90910053]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 13547 is [False, False, True, True, False, False]
State prediction error at timestep 13547 is 0.012
Human Feedback received at timestep 13547 of None
Current timestep = 13548. State = [[ 0.0820553  -0.17062242]]. Action = [[-0.08210754 -0.09104501  0.         -0.9502394 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 13548 is [False, False, True, True, False, False]
Current timestep = 13549. State = [[ 0.08560119 -0.17189781]]. Action = [[ 0.09669519  0.02669699  0.         -0.8881581 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 13549 is [False, False, True, True, False, False]
Current timestep = 13550. State = [[ 0.08875547 -0.17516561]]. Action = [[-0.01107063 -0.07607849  0.         -0.9406513 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 13550 is [False, False, True, True, False, False]
State prediction error at timestep 13550 is 0.012
Human Feedback received at timestep 13550 of None
Current timestep = 13551. State = [[ 0.09257179 -0.18164685]]. Action = [[ 0.0509767  -0.07408221  0.         -0.8870823 ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 13551 is [False, False, True, True, False, False]
Current timestep = 13552. State = [[ 0.09467393 -0.1827296 ]]. Action = [[-0.01866092  0.04562593  0.         -0.07310569]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 13552 is [False, False, True, True, False, False]
Current timestep = 13553. State = [[ 0.09417783 -0.18036552]]. Action = [[-0.04149109  0.03944708  0.         -0.9584968 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 13553 is [False, False, True, True, False, False]
Current timestep = 13554. State = [[ 0.09471666 -0.17523852]]. Action = [[-0.00794425  0.08381151  0.         -0.87786186]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 13554 is [False, False, True, True, False, False]
Current timestep = 13555. State = [[ 0.09928869 -0.17207848]]. Action = [[ 0.06875733  0.00463875  0.         -0.9035897 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 13555 is [False, False, True, True, False, False]
State prediction error at timestep 13555 is 0.012
Human Feedback received at timestep 13555 of None
Current timestep = 13556. State = [[ 0.10114225 -0.17083435]]. Action = [[-0.03171311  0.01013117  0.         -0.11029935]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 13556 is [False, False, True, True, False, False]
Current timestep = 13557. State = [[ 0.10566431 -0.16842374]]. Action = [[ 0.08523411  0.02874374  0.         -0.6112602 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 13557 is [False, False, True, True, False, False]
State prediction error at timestep 13557 is 0.012
Human Feedback received at timestep 13557 of None
Current timestep = 13558. State = [[ 0.11339196 -0.16452982]]. Action = [[0.09874936 0.04547214 0.         0.41380906]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 13558 is [False, False, True, True, False, False]
Current timestep = 13559. State = [[ 0.11413236 -0.16446452]]. Action = [[-0.07264817 -0.03853937  0.         -0.7559227 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 13559 is [False, False, True, True, False, False]
State prediction error at timestep 13559 is 0.012
Human Feedback received at timestep 13559 of None
Current timestep = 13560. State = [[ 0.11645664 -0.16518041]]. Action = [[ 0.07360484 -0.00693186  0.         -0.96716857]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 13560 is [False, False, True, True, False, False]
State prediction error at timestep 13560 is 0.012
Human Feedback received at timestep 13560 of None
Current timestep = 13561. State = [[ 0.11724057 -0.16301355]]. Action = [[-0.0453141   0.04077936  0.         -0.98210037]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 13561 is [False, False, True, True, False, False]
State prediction error at timestep 13561 is 0.012
Human Feedback received at timestep 13561 of None
Current timestep = 13562. State = [[ 0.12070017 -0.15766288]]. Action = [[ 0.08629072  0.06766628  0.         -0.97229403]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 13562 is [False, False, True, True, False, False]
State prediction error at timestep 13562 is 0.012
Human Feedback received at timestep 13562 of None
Current timestep = 13563. State = [[ 0.12630416 -0.15253493]]. Action = [[ 0.06387473  0.04233748  0.         -0.69479036]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 13563 is [False, False, True, True, False, False]
State prediction error at timestep 13563 is 0.012
Human Feedback received at timestep 13563 of None
Current timestep = 13564. State = [[ 0.13190694 -0.15402335]]. Action = [[ 0.07633325 -0.07506348  0.         -0.6500586 ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 13564 is [False, False, True, True, False, False]
Current timestep = 13565. State = [[ 0.13834898 -0.15313834]]. Action = [[0.09164516 0.05224616 0.         0.05203283]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 13565 is [False, False, True, True, False, False]
Current timestep = 13566. State = [[ 0.14216878 -0.15140064]]. Action = [[ 0.0284648  -0.0004281   0.         -0.41912848]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 13566 is [False, False, True, True, False, False]
Current timestep = 13567. State = [[ 0.14662229 -0.1481725 ]]. Action = [[ 0.07193174  0.05703411  0.         -0.7894008 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 13567 is [False, False, True, True, False, False]
Current timestep = 13568. State = [[ 0.15299508 -0.14363001]]. Action = [[ 0.09434431  0.04750373  0.         -0.9672492 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 13568 is [False, False, True, True, False, False]
State prediction error at timestep 13568 is 0.012
Human Feedback received at timestep 13568 of None
Current timestep = 13569. State = [[ 0.15479125 -0.13826923]]. Action = [[-0.026071    0.06471933  0.         -0.46666998]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 13569 is [False, False, True, True, False, False]
State prediction error at timestep 13569 is 0.012
Human Feedback received at timestep 13569 of None
Current timestep = 13570. State = [[ 0.1582669  -0.13385786]]. Action = [[ 0.08538041  0.02587428  0.         -0.8787258 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 13570 is [False, False, True, True, False, False]
State prediction error at timestep 13570 is 0.012
Human Feedback received at timestep 13570 of None
Current timestep = 13571. State = [[ 0.16070598 -0.13163722]]. Action = [[-0.00092444  0.00513856  0.         -0.6856278 ]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 13571 is [False, False, True, True, False, False]
Current timestep = 13572. State = [[ 0.16147354 -0.12773304]]. Action = [[-3.6428124e-04  5.2017041e-02  0.0000000e+00 -9.6756506e-01]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 13572 is [False, False, True, True, False, False]
Current timestep = 13573. State = [[ 0.16450949 -0.12348733]]. Action = [[ 0.04654112  0.02853657  0.         -0.85303706]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 13573 is [False, False, True, True, False, False]
Current timestep = 13574. State = [[ 0.16947484 -0.11792127]]. Action = [[ 0.06732971  0.06586998  0.         -0.95031214]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 13574 is [False, False, True, False, True, False]
Current timestep = 13575. State = [[ 0.17362578 -0.11126816]]. Action = [[0.04411191 0.06313268 0.         0.5663289 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 13575 is [False, False, True, False, True, False]
Current timestep = 13576. State = [[ 0.17817543 -0.10462976]]. Action = [[0.06776919 0.06008249 0.         0.6847658 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 13576 is [False, False, True, False, True, False]
Current timestep = 13577. State = [[ 0.18383963 -0.09687479]]. Action = [[ 0.08746027  0.08207408  0.         -0.9311417 ]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 13577 is [False, False, True, False, True, False]
Current timestep = 13578. State = [[ 0.18897335 -0.09249957]]. Action = [[ 0.07278302  0.00102621  0.         -0.15551865]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 13578 is [False, False, True, False, True, False]
Current timestep = 13579. State = [[ 0.18997896 -0.08719392]]. Action = [[-0.01738697  0.0711196   0.         -0.67401767]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 13579 is [False, False, True, False, True, False]
Current timestep = 13580. State = [[ 0.1928749  -0.08239205]]. Action = [[ 0.07907393  0.0202805   0.         -0.65638435]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 13580 is [False, False, True, False, True, False]
Current timestep = 13581. State = [[ 0.19414678 -0.08345506]]. Action = [[-0.01902835 -0.06259367  0.         -0.20279819]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 13581 is [False, False, True, False, True, False]
Current timestep = 13582. State = [[ 0.1954262  -0.08096797]]. Action = [[ 0.02912033  0.06953425  0.         -0.89972144]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 13582 is [False, False, True, False, True, False]
Current timestep = 13583. State = [[ 0.1978926  -0.07850264]]. Action = [[ 0.03470211 -0.00632444  0.         -0.97753686]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 13583 is [False, False, True, False, True, False]
Current timestep = 13584. State = [[ 0.20284086 -0.07371213]]. Action = [[0.09191964 0.08402465 0.         0.77937806]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 13584 is [False, False, True, False, True, False]
Current timestep = 13585. State = [[ 0.20616686 -0.07258146]]. Action = [[ 0.03557896 -0.03995575  0.         -0.9828528 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 13585 is [False, False, True, False, True, False]
Current timestep = 13586. State = [[ 0.20932494 -0.07597301]]. Action = [[ 0.05661311 -0.05027077  0.          0.63585615]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 13586 is [False, False, True, False, True, False]
Current timestep = 13587. State = [[ 0.21285285 -0.07958229]]. Action = [[ 0.05691462 -0.03103899  0.         -0.11030197]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 13587 is [False, False, True, False, True, False]
Current timestep = 13588. State = [[ 0.21328531 -0.08476099]]. Action = [[-0.016023   -0.06287739  0.         -0.95413154]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 13588 is [False, False, True, False, True, False]
Current timestep = 13589. State = [[ 0.21198948 -0.08381589]]. Action = [[-0.02141488  0.08512438  0.          0.04163241]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 13589 is [False, False, True, False, True, False]
Current timestep = 13590. State = [[ 0.21466094 -0.08488984]]. Action = [[ 0.08560283 -0.05283273  0.         -0.9726142 ]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 13590 is [False, False, True, False, True, False]
Current timestep = 13591. State = [[ 0.21901622 -0.08309516]]. Action = [[ 0.06298966  0.08219362  0.         -0.9320243 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 13591 is [False, False, True, False, True, False]
Current timestep = 13592. State = [[ 0.22219591 -0.07726559]]. Action = [[ 0.05788844  0.07394818  0.         -0.27323306]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 13592 is [False, False, True, False, True, False]
Current timestep = 13593. State = [[ 0.22074558 -0.06946795]]. Action = [[-0.07020335  0.09759632  0.         -0.7150122 ]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 13593 is [False, False, True, False, True, False]
Current timestep = 13594. State = [[ 0.21855217 -0.06537351]]. Action = [[-0.00668728 -0.00478438  0.         -0.9201849 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 13594 is [False, False, True, False, True, False]
State prediction error at timestep 13594 is 0.012
Human Feedback received at timestep 13594 of None
Current timestep = 13595. State = [[ 0.21573685 -0.05925385]]. Action = [[-0.05543974  0.0908481   0.         -0.99038786]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 13595 is [False, False, True, False, True, False]
Current timestep = 13596. State = [[ 0.2163366  -0.05063749]]. Action = [[ 0.0721641   0.07552225  0.         -0.9252708 ]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 13596 is [False, False, True, False, True, False]
Current timestep = 13597. State = [[ 0.22117016 -0.04205802]]. Action = [[ 0.08446754  0.06755317  0.         -0.7593682 ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 13597 is [False, False, True, False, True, False]
State prediction error at timestep 13597 is 0.012
Human Feedback received at timestep 13597 of None
Current timestep = 13598. State = [[ 0.2226343  -0.03985753]]. Action = [[-0.04140506 -0.06082311  0.         -0.6028409 ]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 13598 is [False, False, True, False, True, False]
Current timestep = 13599. State = [[ 0.22352351 -0.03948105]]. Action = [[ 0.03438275 -0.0064881   0.         -0.21599764]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 13599 is [False, False, True, False, True, False]
State prediction error at timestep 13599 is 0.012
Human Feedback received at timestep 13599 of None
Current timestep = 13600. State = [[ 0.22637846 -0.03612374]]. Action = [[ 0.05376943  0.03451968  0.         -0.9515069 ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 13600 is [False, False, True, False, True, False]
Current timestep = 13601. State = [[ 0.22884856 -0.03231106]]. Action = [[ 0.04116399  0.01924032  0.         -0.86787117]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 13601 is [False, False, True, False, True, False]
Current timestep = 13602. State = [[ 0.23254581 -0.02899694]]. Action = [[ 0.07908127  0.02081142  0.         -0.94219077]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 13602 is [False, False, True, False, True, False]
State prediction error at timestep 13602 is 0.012
Human Feedback received at timestep 13602 of None
Current timestep = 13603. State = [[ 0.23492238 -0.02367477]]. Action = [[ 0.03909773  0.06273285  0.         -0.72286016]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 13603 is [False, False, True, False, True, False]
Current timestep = 13604. State = [[ 0.2341246  -0.02485911]]. Action = [[-0.04496403 -0.08874138  0.         -0.48316073]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 13604 is [False, False, True, False, True, False]
State prediction error at timestep 13604 is 0.012
Human Feedback received at timestep 13604 of None
Current timestep = 13605. State = [[ 0.23249345 -0.02374722]]. Action = [[-0.0109561   0.06379076  0.         -0.98266643]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 13605 is [False, False, True, False, True, False]
Current timestep = 13606. State = [[ 0.23414584 -0.01983977]]. Action = [[ 0.05574655  0.02528534  0.         -0.86137986]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 13606 is [False, False, True, False, True, False]
Current timestep = 13607. State = [[ 0.23560876 -0.01771431]]. Action = [[ 0.01693106  0.00573149  0.         -0.735379  ]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 13607 is [False, False, True, False, True, False]
Current timestep = 13608. State = [[ 0.23792417 -0.01295258]]. Action = [[ 0.05719946  0.07179422  0.         -0.919243  ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 13608 is [False, False, True, False, True, False]
Current timestep = 13609. State = [[ 0.23893955 -0.01322155]]. Action = [[ 0.00238562 -0.06859457  0.          0.02713823]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 13609 is [False, False, True, False, True, False]
Current timestep = 13610. State = [[ 0.24171227 -0.01911923]]. Action = [[ 0.06801487 -0.08232518  0.         -0.7692401 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 13610 is [False, False, True, False, True, False]
Current timestep = 13611. State = [[ 0.24553709 -0.02466693]]. Action = [[ 0.05674434 -0.04508908  0.         -0.9432236 ]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 13611 is [False, False, True, False, True, False]
Current timestep = 13612. State = [[ 0.24678226 -0.02779988]]. Action = [[ 0.00666726 -0.00898148  0.         -0.7411618 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 13612 is [False, False, True, False, True, False]
Current timestep = 13613. State = [[ 0.24958946 -0.02951477]]. Action = [[ 0.07232908 -0.00184636  0.         -0.37929988]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 13613 is [False, False, True, False, True, False]
Current timestep = 13614. State = [[ 0.25126594 -0.03436474]]. Action = [[ 0.00235188 -0.06909303  0.         -0.7359432 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 13614 is [False, False, True, False, True, False]
State prediction error at timestep 13614 is 0.012
Human Feedback received at timestep 13614 of None
Current timestep = 13615. State = [[ 0.24911426 -0.04129904]]. Action = [[-0.06159868 -0.06093124  0.         -0.9721366 ]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 13615 is [False, False, True, False, True, False]
Current timestep = 13616. State = [[ 0.24985841 -0.04849636]]. Action = [[ 0.09272171 -0.06388082  0.         -0.9693132 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 13616 is [False, False, True, False, True, False]
State prediction error at timestep 13616 is 0.012
Human Feedback received at timestep 13616 of None
Current timestep = 13617. State = [[ 0.25471005 -0.05731421]]. Action = [[ 0.06444662 -0.0865927   0.         -0.9093077 ]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 13617 is [False, False, True, False, True, False]
Current timestep = 13618. State = [[ 0.25812012 -0.05966328]]. Action = [[0.0333767  0.05732901 0.         0.231956  ]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 13618 is [False, False, True, False, True, False]
Current timestep = 13619. State = [[ 0.2596028  -0.06279378]]. Action = [[ 0.0107808  -0.05744174  0.         -0.9630766 ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 13619 is [False, False, True, False, True, False]
Current timestep = 13620. State = [[ 0.26331213 -0.06444176]]. Action = [[ 0.09583414  0.02935239  0.         -0.9755542 ]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 13620 is [False, False, True, False, True, False]
State prediction error at timestep 13620 is 0.012
Human Feedback received at timestep 13620 of None
Current timestep = 13621. State = [[ 0.2675134  -0.06002789]]. Action = [[ 0.05575527  0.08667152  0.         -0.8603542 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 13621 is [False, False, True, False, True, False]
Current timestep = 13622. State = [[ 0.2679353  -0.05318038]]. Action = [[-0.01168568  0.07695303  0.         -0.977421  ]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 13622 is [False, False, True, False, True, False]
Current timestep = 13623. State = [[ 0.2698638  -0.04633012]]. Action = [[ 0.09931771  0.06032664  0.         -0.78274083]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 13623 is [False, False, True, False, True, False]
Current timestep = 13624. State = [[ 0.27425057 -0.04439811]]. Action = [[ 0.07497431 -0.02929821  0.         -0.34707344]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 13624 is [False, False, True, False, True, False]
Current timestep = 13625. State = [[ 0.2790039  -0.04359188]]. Action = [[ 0.09315831  0.01172914  0.         -0.8281267 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 13625 is [False, False, True, False, True, False]
Current timestep = 13626. State = [[ 0.28067797 -0.04241238]]. Action = [[-0.01037643  0.00706468  0.         -0.8970487 ]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 13626 is [False, False, True, False, True, False]
Current timestep = 13627. State = [[ 0.28220782 -0.04192967]]. Action = [[ 0.06788676 -0.00589018  0.         -0.97219133]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 13627 is [False, False, True, False, True, False]
Current timestep = 13628. State = [[ 0.28231084 -0.04166245]]. Action = [[-0.03795009  0.00774442  0.         -0.470181  ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 13628 is [False, False, True, False, True, False]
Current timestep = 13629. State = [[ 0.28269947 -0.03842279]]. Action = [[ 0.08027818  0.04705036  0.         -0.298029  ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 13629 is [False, False, True, False, True, False]
State prediction error at timestep 13629 is 0.012
Human Feedback received at timestep 13629 of None
Current timestep = 13630. State = [[ 0.285774   -0.03176739]]. Action = [[ 0.06305791  0.08785815  0.         -0.22103357]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 13630 is [False, False, True, False, True, False]
Current timestep = 13631. State = [[ 0.288188   -0.02911707]]. Action = [[ 0.05485275 -0.02153955  0.         -0.95271075]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 13631 is [False, False, True, False, True, False]
State prediction error at timestep 13631 is 0.012
Human Feedback received at timestep 13631 of None
Current timestep = 13632. State = [[ 0.29121634 -0.03236851]]. Action = [[ 0.06958271 -0.06070533  0.         -0.9459394 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 13632 is [False, False, True, False, True, False]
Current timestep = 13633. State = [[ 0.29360047 -0.03466723]]. Action = [[ 0.04824165  0.00180479  0.         -0.20083833]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 13633 is [False, False, True, False, True, False]
State prediction error at timestep 13633 is 0.012
Human Feedback received at timestep 13633 of None
Current timestep = 13634. State = [[ 0.29610157 -0.03259287]]. Action = [[ 0.06533388  0.05362143  0.         -0.4337114 ]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 13634 is [False, False, True, False, True, False]
State prediction error at timestep 13634 is 0.012
Human Feedback received at timestep 13634 of None
Current timestep = 13635. State = [[ 0.2967619  -0.03578489]]. Action = [[ 0.01313045 -0.08381386  0.         -0.96621513]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 13635 is [False, False, True, False, True, False]
Current timestep = 13636. State = [[ 0.2986373  -0.03613542]]. Action = [[ 0.07138995  0.06066126  0.         -0.39157933]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 13636 is [False, False, True, False, True, False]
Current timestep = 13637. State = [[ 0.300973   -0.03690773]]. Action = [[ 0.05183595 -0.0339795   0.         -0.796924  ]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 13637 is [False, False, True, False, True, False]
Current timestep = 13638. State = [[ 0.30435747 -0.03747423]]. Action = [[ 0.08683694  0.02661746  0.         -0.9387631 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 13638 is [False, False, True, False, True, False]
Current timestep = 13639. State = [[ 0.30655095 -0.03936921]]. Action = [[ 0.05017806 -0.0319139   0.         -0.7547443 ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 13639 is [False, False, True, False, True, False]
Current timestep = 13640. State = [[ 0.30953005 -0.03806208]]. Action = [[0.09083653 0.06596818 0.         0.6242801 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 13640 is [False, False, True, False, True, False]
Current timestep = 13641. State = [[ 0.30993018 -0.03285418]]. Action = [[ 0.007005    0.07829421  0.         -0.8859081 ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 13641 is [False, False, True, False, True, False]
State prediction error at timestep 13641 is 0.012
Human Feedback received at timestep 13641 of None
Current timestep = 13642. State = [[ 0.30754814 -0.03090686]]. Action = [[-0.00722577 -0.01481859  0.         -0.7662871 ]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 13642 is [False, False, True, False, True, False]
Current timestep = 13643. State = [[ 0.30835217 -0.03598227]]. Action = [[ 0.07918694 -0.09675261  0.         -0.36805326]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 13643 is [False, False, True, False, True, False]
Current timestep = 13644. State = [[ 0.31273314 -0.04360786]]. Action = [[ 0.09755022 -0.0631292   0.         -0.18327427]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 13644 is [False, False, True, False, True, False]
State prediction error at timestep 13644 is 0.012
Human Feedback received at timestep 13644 of None
Current timestep = 13645. State = [[ 0.31658497 -0.04587186]]. Action = [[ 0.08821083  0.03922632  0.         -0.71428645]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 13645 is [False, False, True, False, True, False]
State prediction error at timestep 13645 is 0.012
Human Feedback received at timestep 13645 of None
Current timestep = 13646. State = [[ 0.31797498 -0.04407002]]. Action = [[ 0.05232105  0.04552061  0.         -0.85360855]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 13646 is [False, False, True, False, True, False]
State prediction error at timestep 13646 is 0.012
Human Feedback received at timestep 13646 of None
Current timestep = 13647. State = [[ 0.31991446 -0.03910521]]. Action = [[ 0.09310529  0.08484871  0.         -0.03446585]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 13647 is [False, False, True, False, True, False]
Current timestep = 13648. State = [[ 0.32187918 -0.03168388]]. Action = [[ 0.09405816  0.09414349  0.         -0.89779705]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 13648 is [False, False, True, False, True, False]
Current timestep = 13649. State = [[ 0.3221134  -0.02798964]]. Action = [[ 0.0579512   0.02511954  0.         -0.9310391 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 13649 is [False, False, True, False, True, False]
Current timestep = 13650. State = [[ 0.3222445  -0.02910101]]. Action = [[ 0.05402083 -0.05654863  0.         -0.68923044]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 13650 is [False, False, True, False, True, False]
Current timestep = 13651. State = [[ 0.3228148 -0.030437 ]]. Action = [[ 0.06848843 -0.02778714  0.         -0.9874393 ]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 13651 is [False, False, True, False, True, False]
State prediction error at timestep 13651 is 0.012
Human Feedback received at timestep 13651 of None
Current timestep = 13652. State = [[ 0.3233305  -0.03173454]]. Action = [[ 0.0574893  -0.0321577   0.         -0.87596506]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 13652 is [False, False, True, False, True, False]
Current timestep = 13653. State = [[ 0.3234748  -0.03539615]]. Action = [[ 0.03558709 -0.07749648  0.         -0.2994902 ]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 13653 is [False, False, True, False, True, False]
Current timestep = 13654. State = [[ 0.32411063 -0.04007779]]. Action = [[ 0.05169485 -0.07610175  0.         -0.99164724]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 13654 is [False, False, True, False, True, False]
Current timestep = 13655. State = [[ 0.32510984 -0.03725299]]. Action = [[0.09374454 0.09298632 0.         0.56202817]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 13655 is [False, False, True, False, True, False]
State prediction error at timestep 13655 is 0.012
Human Feedback received at timestep 13655 of None
Current timestep = 13656. State = [[ 0.32588813 -0.03788128]]. Action = [[ 0.0979562  -0.07960398  0.         -0.9331764 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 13656 is [False, False, True, False, True, False]
Current timestep = 13657. State = [[ 0.32705685 -0.04102597]]. Action = [[ 0.08653241 -0.05300444  0.         -0.82731956]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 13657 is [False, False, True, False, True, False]
State prediction error at timestep 13657 is 0.012
Human Feedback received at timestep 13657 of None
Current timestep = 13658. State = [[ 0.3252567 -0.0451382]]. Action = [[-0.04720068 -0.04926589  0.         -0.82155836]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 13658 is [False, False, True, False, True, False]
Current timestep = 13659. State = [[ 0.32175168 -0.04434836]]. Action = [[-0.0181652   0.06677187  0.         -0.52175313]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 13659 is [False, False, True, False, True, False]
State prediction error at timestep 13659 is 0.012
Human Feedback received at timestep 13659 of None
Current timestep = 13660. State = [[ 0.3207457  -0.03940058]]. Action = [[ 0.01340939  0.07691409  0.         -0.556948  ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 13660 is [False, False, True, False, True, False]
State prediction error at timestep 13660 is 0.012
Human Feedback received at timestep 13660 of None
Current timestep = 13661. State = [[ 0.3200793 -0.0335722]]. Action = [[-0.0009956   0.08479605  0.         -0.9874669 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 13661 is [False, False, True, False, True, False]
Current timestep = 13662. State = [[ 0.31972215 -0.03186829]]. Action = [[ 0.02113064 -0.02509902  0.         -0.95914644]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 13662 is [False, False, True, False, True, False]
State prediction error at timestep 13662 is 0.012
Human Feedback received at timestep 13662 of None
Current timestep = 13663. State = [[ 0.32068998 -0.03119859]]. Action = [[ 6.2064581e-02 -2.9057264e-06  0.0000000e+00 -9.8396325e-01]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 13663 is [False, False, True, False, True, False]
State prediction error at timestep 13663 is 0.012
Human Feedback received at timestep 13663 of None
Current timestep = 13664. State = [[ 0.3223288  -0.03301883]]. Action = [[ 0.0677026  -0.08083473  0.         -0.9855909 ]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 13664 is [False, False, True, False, True, False]
Current timestep = 13665. State = [[ 0.32363072 -0.03810417]]. Action = [[ 0.05193491 -0.09468525  0.         -0.39699292]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 13665 is [False, False, True, False, True, False]
Current timestep = 13666. State = [[ 0.32664788 -0.0420917 ]]. Action = [[ 0.09749449 -0.06589445  0.         -0.9497363 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 13666 is [False, False, True, False, True, False]
Current timestep = 13667. State = [[ 0.32809594 -0.04476295]]. Action = [[ 0.0509459  -0.03163804  0.         -0.9727727 ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 13667 is [False, False, True, False, True, False]
State prediction error at timestep 13667 is 0.012
Human Feedback received at timestep 13667 of None
Current timestep = 13668. State = [[ 0.32874334 -0.04661386]]. Action = [[ 0.07750116 -0.02260972  0.         -0.955919  ]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 13668 is [False, False, True, False, True, False]
Current timestep = 13669. State = [[ 0.32840726 -0.04797341]]. Action = [[ 0.00081316 -0.01769809  0.         -0.28084803]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 13669 is [False, False, True, False, True, False]
State prediction error at timestep 13669 is 0.012
Human Feedback received at timestep 13669 of None
Current timestep = 13670. State = [[ 0.3283658 -0.0450543]]. Action = [[ 0.08055849  0.07846744  0.         -0.79770076]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 13670 is [False, False, True, False, True, False]
State prediction error at timestep 13670 is 0.012
Human Feedback received at timestep 13670 of None
Current timestep = 13671. State = [[ 0.32863805 -0.04122778]]. Action = [[ 0.05628981  0.03797937  0.         -0.97944564]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 13671 is [False, False, True, False, True, False]
Current timestep = 13672. State = [[ 0.32873702 -0.04148568]]. Action = [[ 0.04838558 -0.04313992  0.         -0.69003963]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 13672 is [False, False, True, False, True, False]
Current timestep = 13673. State = [[ 0.32960314 -0.04194909]]. Action = [[ 0.08594208 -0.01639603  0.         -0.65896016]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 13673 is [False, False, True, False, True, False]
Current timestep = 13674. State = [[ 0.33087447 -0.03859982]]. Action = [[ 0.09701016  0.05370904  0.         -0.9592627 ]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 13674 is [False, False, True, False, True, False]
State prediction error at timestep 13674 is 0.012
Human Feedback received at timestep 13674 of None
Current timestep = 13675. State = [[ 0.33156508 -0.03553778]]. Action = [[0.08349576 0.01071932 0.         0.04567003]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 13675 is [False, False, True, False, True, False]
Current timestep = 13676. State = [[ 0.3294491  -0.03135671]]. Action = [[-0.06917988  0.07115147  0.         -0.9856915 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 13676 is [False, False, True, False, True, False]
State prediction error at timestep 13676 is 0.012
Human Feedback received at timestep 13676 of None
Current timestep = 13677. State = [[ 0.32808754 -0.02418189]]. Action = [[ 0.04696717  0.09905904  0.         -0.5557538 ]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 13677 is [False, False, True, False, True, False]
State prediction error at timestep 13677 is 0.012
Human Feedback received at timestep 13677 of None
Current timestep = 13678. State = [[ 0.3281692  -0.02154914]]. Action = [[ 0.05173058 -0.01585861  0.         -0.77022314]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 13678 is [False, False, True, False, True, False]
State prediction error at timestep 13678 is 0.012
Human Feedback received at timestep 13678 of None
Current timestep = 13679. State = [[ 0.32824084 -0.02006627]]. Action = [[ 0.05468767  0.02849925  0.         -0.7896899 ]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 13679 is [False, False, True, False, True, False]
State prediction error at timestep 13679 is 0.012
Human Feedback received at timestep 13679 of None
Current timestep = 13680. State = [[ 0.32682505 -0.02346655]]. Action = [[-0.03915259 -0.07376887  0.         -0.49544114]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 13680 is [False, False, True, False, True, False]
State prediction error at timestep 13680 is 0.012
Human Feedback received at timestep 13680 of None
Current timestep = 13681. State = [[ 0.32545125 -0.02319355]]. Action = [[ 0.09316585  0.05482914  0.         -0.9436437 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 13681 is [False, False, True, False, True, False]
Current timestep = 13682. State = [[ 0.32502934 -0.01880692]]. Action = [[-0.00053031  0.07638238  0.         -0.29529077]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 13682 is [False, False, True, False, True, False]
Current timestep = 13683. State = [[ 0.32484728 -0.01570428]]. Action = [[ 0.08681289  0.0227136   0.         -0.8600987 ]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 13683 is [False, False, True, False, True, False]
Current timestep = 13684. State = [[ 0.325592   -0.01587002]]. Action = [[ 0.07361294 -0.02794416  0.         -0.5009756 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 13684 is [False, False, True, False, True, False]
Current timestep = 13685. State = [[ 0.32576653 -0.01865743]]. Action = [[ 0.04685911 -0.05411652  0.         -0.96974343]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 13685 is [False, False, True, False, True, False]
State prediction error at timestep 13685 is 0.012
Human Feedback received at timestep 13685 of None
Current timestep = 13686. State = [[ 0.32635543 -0.02135097]]. Action = [[ 0.07802863 -0.04445758  0.         -0.9087468 ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 13686 is [False, False, True, False, True, False]
State prediction error at timestep 13686 is 0.012
Human Feedback received at timestep 13686 of None
Current timestep = 13687. State = [[ 0.32439515 -0.02311573]]. Action = [[-0.04187791  0.00094257  0.         -0.6684246 ]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 13687 is [False, False, True, False, True, False]
State prediction error at timestep 13687 is 0.012
Human Feedback received at timestep 13687 of None
Current timestep = 13688. State = [[ 0.32295415 -0.02016183]]. Action = [[ 0.02466432  0.09071428  0.         -0.47625184]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 13688 is [False, False, True, False, True, False]
State prediction error at timestep 13688 is 0.012
Human Feedback received at timestep 13688 of None
Current timestep = 13689. State = [[ 0.32332468 -0.014658  ]]. Action = [[ 0.05618931  0.08785205  0.         -0.93836755]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 13689 is [False, False, True, False, True, False]
Current timestep = 13690. State = [[ 0.3236006  -0.01455874]]. Action = [[ 0.04879821 -0.05004861  0.         -0.74194705]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 13690 is [False, False, True, False, True, False]
Current timestep = 13691. State = [[ 0.32375783 -0.01458278]]. Action = [[ 0.0515083   0.00405679  0.         -0.79608774]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 13691 is [False, False, True, False, True, False]
State prediction error at timestep 13691 is 0.012
Human Feedback received at timestep 13691 of None
Current timestep = 13692. State = [[ 0.32431114 -0.01364402]]. Action = [[ 0.07386629 -0.00484308  0.         -0.82417977]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 13692 is [False, False, True, False, True, False]
Current timestep = 13693. State = [[ 0.32488474 -0.013238  ]]. Action = [[ 0.08165164 -0.0218005   0.         -0.47192234]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 13693 is [False, False, True, False, True, False]
State prediction error at timestep 13693 is 0.012
Human Feedback received at timestep 13693 of None
Current timestep = 13694. State = [[ 0.32528207 -0.01089518]]. Action = [[ 0.06864079  0.05830152  0.         -0.903428  ]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 13694 is [False, False, True, False, True, False]
Current timestep = 13695. State = [[ 0.32546958 -0.01182436]]. Action = [[ 0.06099566 -0.06897873  0.         -0.43838048]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 13695 is [False, False, True, False, True, False]
Current timestep = 13696. State = [[ 0.32550487 -0.01429086]]. Action = [[ 0.03844345 -0.05098922  0.          0.13900423]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 13696 is [False, False, True, False, True, False]
Current timestep = 13697. State = [[ 0.32551625 -0.01540568]]. Action = [[ 0.04774866 -0.02526725  0.         -0.97781247]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 13697 is [False, False, True, False, True, False]
Current timestep = 13698. State = [[ 0.32571602 -0.01537578]]. Action = [[ 0.08061282 -0.01509131  0.         -0.6718621 ]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 13698 is [False, False, True, False, True, False]
Current timestep = 13699. State = [[ 0.32463598 -0.01320864]]. Action = [[-0.01031306  0.05591951  0.         -0.85710126]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 13699 is [False, False, True, False, True, False]
Current timestep = 13700. State = [[ 0.32175782 -0.01620962]]. Action = [[-0.01497899 -0.0867008   0.         -0.96992433]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 13700 is [False, False, True, False, True, False]
Current timestep = 13701. State = [[ 0.31917483 -0.0232181 ]]. Action = [[-0.01620349 -0.0732756   0.         -0.07824075]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 13701 is [False, False, True, False, True, False]
Current timestep = 13702. State = [[ 0.31869283 -0.02626277]]. Action = [[ 0.03707523  0.01458268  0.         -0.6477497 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 13702 is [False, False, True, False, True, False]
Current timestep = 13703. State = [[ 0.31948912 -0.02258077]]. Action = [[ 0.09315384  0.07218226  0.         -0.15305698]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 13703 is [False, False, True, False, True, False]
Current timestep = 13704. State = [[ 0.3205617  -0.02082879]]. Action = [[ 0.09473763 -0.01644036  0.         -0.79431164]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 13704 is [False, False, True, False, True, False]
Current timestep = 13705. State = [[ 0.32158855 -0.01837813]]. Action = [[ 0.05905242  0.06040671  0.         -0.5504786 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 13705 is [False, False, True, False, True, False]
Current timestep = 13706. State = [[ 0.32309058 -0.01300892]]. Action = [[ 0.0920651   0.09254008  0.         -0.9388694 ]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 13706 is [False, False, True, False, True, False]
Current timestep = 13707. State = [[ 0.32332155 -0.01218552]]. Action = [[ 0.00104598 -0.01644194  0.         -0.9803036 ]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 13707 is [False, False, True, False, True, False]
Current timestep = 13708. State = [[ 0.3201274  -0.01067552]]. Action = [[-0.05623189  0.03579468  0.         -0.9486512 ]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 13708 is [False, False, True, False, True, False]
Current timestep = 13709. State = [[ 0.31641963 -0.01361591]]. Action = [[-0.01354375 -0.09013306  0.         -0.96699697]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 13709 is [False, False, True, False, True, False]
Current timestep = 13710. State = [[ 0.3158568  -0.01425391]]. Action = [[ 0.0462809   0.04622354  0.         -0.17276782]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 13710 is [False, False, True, False, True, False]
Current timestep = 13711. State = [[ 0.3152648  -0.01259731]]. Action = [[-0.00513529  0.01180997  0.         -0.96074754]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 13711 is [False, False, True, False, True, False]
Current timestep = 13712. State = [[ 0.31537652 -0.00810387]]. Action = [[ 0.05496927  0.08858836  0.         -0.9750272 ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 13712 is [False, False, True, False, True, False]
Current timestep = 13713. State = [[ 0.31675175 -0.00775376]]. Action = [[ 0.07372452 -0.06325388  0.         -0.89114165]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 13713 is [False, False, True, False, True, False]
State prediction error at timestep 13713 is 0.012
Human Feedback received at timestep 13713 of None
Current timestep = 13714. State = [[ 0.31727272 -0.0095906 ]]. Action = [[ 0.03597952 -0.01873778  0.         -0.98043376]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 13714 is [False, False, True, False, True, False]
Current timestep = 13715. State = [[ 0.3157472 -0.0104532]]. Action = [[-0.02754965  0.00299958  0.         -0.9085427 ]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 13715 is [False, False, True, False, True, False]
Current timestep = 13716. State = [[ 0.3154003  -0.01205825]]. Action = [[ 0.0840288  -0.04341843  0.         -0.98351765]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 13716 is [False, False, True, False, True, False]
Current timestep = 13717. State = [[ 0.31693602 -0.01136582]]. Action = [[ 0.08588348  0.02651308  0.         -0.9093213 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 13717 is [False, False, True, False, True, False]
Current timestep = 13718. State = [[ 0.31736317 -0.01052655]]. Action = [[0.04181271 0.00876607 0.         0.05091631]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 13718 is [False, False, True, False, True, False]
Current timestep = 13719. State = [[ 0.31679812 -0.00899385]]. Action = [[-0.00322942  0.04666298  0.         -0.97371143]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 13719 is [False, False, True, False, True, False]
Current timestep = 13720. State = [[ 0.31685492 -0.00514616]]. Action = [[ 0.08158202  0.05601332  0.         -0.57492185]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 13720 is [False, False, True, False, True, False]
Current timestep = 13721. State = [[ 0.3181545  -0.00488985]]. Action = [[ 0.07117995 -0.0382321   0.         -0.9755696 ]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 13721 is [False, False, True, False, True, False]
Current timestep = 13722. State = [[ 0.3196991  -0.00815413]]. Action = [[ 0.07594504 -0.08629774  0.         -0.6607859 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 13722 is [False, False, True, False, True, False]
State prediction error at timestep 13722 is 0.012
Human Feedback received at timestep 13722 of None
Current timestep = 13723. State = [[ 0.32087398 -0.00586652]]. Action = [[ 0.0693048   0.07954372  0.         -0.9631399 ]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 13723 is [False, False, True, False, True, False]
State prediction error at timestep 13723 is 0.012
Human Feedback received at timestep 13723 of None
Current timestep = 13724. State = [[ 0.32149008 -0.00320635]]. Action = [[0.0890351  0.00801501 0.         0.23136759]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 13724 is [False, False, True, False, True, False]
Current timestep = 13725. State = [[ 0.32000548 -0.00599182]]. Action = [[-0.02353815 -0.05731387  0.         -0.67529523]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 13725 is [False, False, True, False, True, False]
Current timestep = 13726. State = [[ 0.3189537  -0.00960587]]. Action = [[ 0.03542932 -0.03343568  0.         -0.9814    ]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 13726 is [False, False, True, False, True, False]
State prediction error at timestep 13726 is 0.012
Human Feedback received at timestep 13726 of None
Current timestep = 13727. State = [[ 0.31944484 -0.00993806]]. Action = [[ 6.5649249e-02  8.8083744e-04  0.0000000e+00 -9.7990888e-01]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 13727 is [False, False, True, False, True, False]
Current timestep = 13728. State = [[ 0.31961918 -0.01124013]]. Action = [[ 0.04216688 -0.04712012  0.         -0.9818983 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 13728 is [False, False, True, False, True, False]
Current timestep = 13729. State = [[ 0.31997558 -0.00815673]]. Action = [[ 0.09116802  0.09026719  0.         -0.9888371 ]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 13729 is [False, False, True, False, True, False]
Current timestep = 13730. State = [[ 0.31950015 -0.00312238]]. Action = [[-4.1775405e-05  7.4369572e-02  0.0000000e+00 -8.9691198e-01]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 13730 is [False, False, True, False, True, False]
Current timestep = 13731. State = [[ 0.31713456 -0.00430126]]. Action = [[-0.01101753 -0.06470127  0.         -0.6178739 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 13731 is [False, False, True, False, True, False]
Current timestep = 13732. State = [[ 0.31660408 -0.00517801]]. Action = [[ 0.06688482  0.01800354  0.         -0.6953075 ]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 13732 is [False, False, True, False, True, False]
State prediction error at timestep 13732 is 0.012
Human Feedback received at timestep 13732 of None
Current timestep = 13733. State = [[ 0.31764597 -0.00269945]]. Action = [[0.069153   0.03580648 0.         0.0907166 ]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 13733 is [False, False, True, False, True, False]
State prediction error at timestep 13733 is 0.012
Human Feedback received at timestep 13733 of None
Current timestep = 13734. State = [[0.31879863 0.00068473]]. Action = [[ 0.07407897  0.05626727  0.         -0.5801127 ]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 13734 is [False, False, True, False, True, False]
State prediction error at timestep 13734 is 0.012
Human Feedback received at timestep 13734 of None
Current timestep = 13735. State = [[0.31764    0.00325926]]. Action = [[-0.01781841  0.02515426  0.         -0.79386014]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 13735 is [False, False, True, False, True, False]
Current timestep = 13736. State = [[0.31729642 0.00254794]]. Action = [[ 0.07871766 -0.06525664  0.         -0.06560308]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 13736 is [False, False, True, False, True, False]
Current timestep = 13737. State = [[ 0.31576836 -0.00214967]]. Action = [[-0.04138166 -0.068647    0.         -0.4997481 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 13737 is [False, False, True, False, True, False]
Current timestep = 13738. State = [[ 0.3149171  -0.00431226]]. Action = [[0.07416817 0.00876254 0.         0.446666  ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 13738 is [False, False, True, False, True, False]
Current timestep = 13739. State = [[ 0.315187   -0.00304312]]. Action = [[0.03685143 0.01118859 0.         0.2668072 ]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 13739 is [False, False, True, False, True, False]
Current timestep = 13740. State = [[ 0.31595778 -0.00334705]]. Action = [[ 0.07086452 -0.02322206  0.         -0.06233764]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 13740 is [False, False, True, False, True, False]
Current timestep = 13741. State = [[ 0.31431603 -0.00731859]]. Action = [[-0.0345075  -0.0631057   0.         -0.12153733]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 13741 is [False, False, True, False, True, False]
Current timestep = 13742. State = [[ 0.31245834 -0.01251015]]. Action = [[ 0.00137641 -0.04067348  0.         -0.9881597 ]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 13742 is [False, False, True, False, True, False]
State prediction error at timestep 13742 is 0.012
Human Feedback received at timestep 13742 of None
Current timestep = 13743. State = [[ 0.3128699 -0.0147743]]. Action = [[ 0.04340433 -0.00168289  0.         -0.99303365]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 13743 is [False, False, True, False, True, False]
Current timestep = 13744. State = [[ 0.314407  -0.0126584]]. Action = [[ 0.09012767  0.03995051  0.         -0.85686874]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 13744 is [False, False, True, False, True, False]
Current timestep = 13745. State = [[ 0.3163865  -0.01336289]]. Action = [[ 0.09718264 -0.05756927  0.         -0.29797542]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 13745 is [False, False, True, False, True, False]
Current timestep = 13746. State = [[ 0.31751904 -0.01525968]]. Action = [[ 0.04857356 -0.02633686  0.         -0.99518913]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 13746 is [False, False, True, False, True, False]
Current timestep = 13747. State = [[ 0.31748292 -0.01281728]]. Action = [[ 0.00530636  0.07418998  0.         -0.9904164 ]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 13747 is [False, False, True, False, True, False]
State prediction error at timestep 13747 is 0.012
Human Feedback received at timestep 13747 of None
Current timestep = 13748. State = [[ 0.31830603 -0.0119957 ]]. Action = [[ 0.08482937 -0.03317793  0.         -0.9980817 ]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 13748 is [False, False, True, False, True, False]
Current timestep = 13749. State = [[ 0.32015213 -0.01104472]]. Action = [[ 0.09063024  0.01572522  0.         -0.85168815]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 13749 is [False, False, True, False, True, False]
Current timestep = 13750. State = [[ 0.32132182 -0.00847516]]. Action = [[ 0.06966289  0.02978048  0.         -0.98439246]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 13750 is [False, False, True, False, True, False]
Current timestep = 13751. State = [[ 0.32156196 -0.00526403]]. Action = [[ 0.04085796  0.06922232  0.         -0.5563159 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 13751 is [False, False, True, False, True, False]
Current timestep = 13752. State = [[ 0.32209545 -0.00138603]]. Action = [[ 0.06599107  0.06046204  0.         -0.714569  ]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 13752 is [False, False, True, False, True, False]
Current timestep = 13753. State = [[0.32275814 0.0032078 ]]. Action = [[0.06289489 0.08359935 0.         0.15992689]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 13753 is [False, False, True, False, True, False]
Current timestep = 13754. State = [[0.3230783  0.00499128]]. Action = [[ 0.06232271 -0.01553563  0.          0.0109967 ]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 13754 is [False, False, True, False, True, False]
Current timestep = 13755. State = [[0.32210526 0.00115113]]. Action = [[-0.00100572 -0.09366801  0.         -0.74295616]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 13755 is [False, False, True, False, True, False]
Current timestep = 13756. State = [[ 0.32174778 -0.00083972]]. Action = [[ 0.08446611  0.01145832  0.         -0.95464087]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 13756 is [False, False, True, False, True, False]
Current timestep = 13757. State = [[ 0.32187444 -0.00088681]]. Action = [[ 0.01992403  0.00782906  0.         -0.3108189 ]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 13757 is [False, False, True, False, True, False]
Current timestep = 13758. State = [[ 0.3221656  -0.00297694]]. Action = [[ 0.06128103 -0.05671516  0.         -0.81906796]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 13758 is [False, False, True, False, True, False]
Current timestep = 13759. State = [[ 0.32262215 -0.00407019]]. Action = [[ 0.07544865 -0.01080342  0.         -0.80808705]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 13759 is [False, False, True, False, True, False]
Current timestep = 13760. State = [[ 0.32272285 -0.003143  ]]. Action = [[ 0.05108007  0.02544045  0.         -0.64318764]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 13760 is [False, False, True, False, True, False]
State prediction error at timestep 13760 is 0.012
Human Feedback received at timestep 13760 of None
Current timestep = 13761. State = [[ 0.3230481  -0.00394008]]. Action = [[ 0.07341113 -0.05289805  0.         -0.9954429 ]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 13761 is [False, False, True, False, True, False]
Current timestep = 13762. State = [[ 0.32315406 -0.00234218]]. Action = [[0.02578223 0.06211371 0.         0.03859019]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 13762 is [False, False, True, False, True, False]
State prediction error at timestep 13762 is 0.012
Human Feedback received at timestep 13762 of None
Current timestep = 13763. State = [[ 0.3220792  -0.00144936]]. Action = [[-0.00357912 -0.00015613  0.         -0.08780438]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 13763 is [False, False, True, False, True, False]
Current timestep = 13764. State = [[ 0.3219323  -0.00150505]]. Action = [[ 0.09838071 -0.02413622  0.         -0.32667017]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 13764 is [False, False, True, False, True, False]
State prediction error at timestep 13764 is 0.012
Human Feedback received at timestep 13764 of None
Current timestep = 13765. State = [[ 0.32227045 -0.00286865]]. Action = [[ 0.05809321 -0.0533813   0.         -0.89588463]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 13765 is [False, False, True, False, True, False]
Current timestep = 13766. State = [[ 0.32234403 -0.00390627]]. Action = [[ 0.04982772 -0.02514805  0.         -0.9665517 ]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 13766 is [False, False, True, False, True, False]
Current timestep = 13767. State = [[ 0.32268643 -0.00201362]]. Action = [[0.09724122 0.03854702 0.         0.03347456]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 13767 is [False, False, True, False, True, False]
State prediction error at timestep 13767 is 0.012
Human Feedback received at timestep 13767 of None
Current timestep = 13768. State = [[ 0.3231812  -0.00074757]]. Action = [[ 0.07790125 -0.00266053  0.         -0.9843346 ]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 13768 is [False, False, True, False, True, False]
State prediction error at timestep 13768 is 0.012
Human Feedback received at timestep 13768 of None
Current timestep = 13769. State = [[ 0.3232181  -0.00318885]]. Action = [[ 0.02338562 -0.0698844   0.         -0.4698593 ]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 13769 is [False, False, True, False, True, False]
Current timestep = 13770. State = [[ 0.3231774  -0.00172245]]. Action = [[ 0.0382745   0.07917773  0.         -0.80584204]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 13770 is [False, False, True, False, True, False]
State prediction error at timestep 13770 is 0.012
Human Feedback received at timestep 13770 of None
Current timestep = 13771. State = [[0.3235459  0.00088933]]. Action = [[ 0.07752488  0.02371253  0.         -0.9006168 ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 13771 is [False, False, True, False, True, False]
Current timestep = 13772. State = [[0.32365057 0.00122612]]. Action = [[ 0.0439382  -0.01672455  0.         -0.8549536 ]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 13772 is [False, False, True, False, True, False]
Current timestep = 13773. State = [[0.32407117 0.00397091]]. Action = [[ 0.07693712  0.08006813  0.         -0.99174   ]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 13773 is [False, False, True, False, True, False]
Current timestep = 13774. State = [[0.32419908 0.0033814 ]]. Action = [[ 0.03758992 -0.05891422  0.         -0.6773075 ]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 13774 is [False, False, True, False, True, False]
Current timestep = 13775. State = [[ 0.3233312  -0.00079299]]. Action = [[ 0.00491688 -0.06512697  0.         -0.6976989 ]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 13775 is [False, False, True, False, True, False]
Current timestep = 13776. State = [[ 0.3232659  -0.00352712]]. Action = [[ 0.0590755  -0.02930596  0.         -0.40331137]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 13776 is [False, False, True, False, True, False]
State prediction error at timestep 13776 is 0.012
Human Feedback received at timestep 13776 of None
Current timestep = 13777. State = [[ 0.32366124 -0.00164221]]. Action = [[ 0.0920717   0.04185245  0.         -0.8320272 ]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 13777 is [False, False, True, False, True, False]
Current timestep = 13778. State = [[0.3238365  0.00098884]]. Action = [[ 0.0620062   0.04312798  0.         -0.9055469 ]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 13778 is [False, False, True, False, True, False]
State prediction error at timestep 13778 is 0.012
Human Feedback received at timestep 13778 of None
Current timestep = 13779. State = [[0.3240324  0.00118093]]. Action = [[ 0.083436   -0.03771731  0.         -0.9549147 ]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 13779 is [False, False, True, False, True, False]
Current timestep = 13780. State = [[ 0.3236616 -0.0028234]]. Action = [[ 0.01559076 -0.08193703  0.         -0.924017  ]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 13780 is [False, False, True, False, True, False]
Current timestep = 13781. State = [[ 0.3235178  -0.00944327]]. Action = [[ 0.03198486 -0.09768895  0.         -0.26242948]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 13781 is [False, False, True, False, True, False]
Current timestep = 13782. State = [[ 0.3237389 -0.0139739]]. Action = [[ 0.03833241 -0.04945667  0.         -0.7439287 ]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 13782 is [False, False, True, False, True, False]
State prediction error at timestep 13782 is 0.012
Human Feedback received at timestep 13782 of None
Current timestep = 13783. State = [[ 0.3240345 -0.0122546]]. Action = [[ 0.08317529  0.05105907  0.         -0.43838853]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 13783 is [False, False, True, False, True, False]
Current timestep = 13784. State = [[ 0.32187346 -0.01486981]]. Action = [[-0.08212725 -0.0610824   0.         -0.9106697 ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 13784 is [False, False, True, False, True, False]
Current timestep = 13785. State = [[ 0.31953546 -0.01409398]]. Action = [[ 0.07600576  0.06555387  0.         -0.7667117 ]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 13785 is [False, False, True, False, True, False]
Current timestep = 13786. State = [[ 0.3194702  -0.01493163]]. Action = [[ 0.01273596 -0.07826175  0.         -0.62909734]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 13786 is [False, False, True, False, True, False]
State prediction error at timestep 13786 is 0.012
Human Feedback received at timestep 13786 of None
Current timestep = 13787. State = [[ 0.32016185 -0.01476075]]. Action = [[ 0.06620369  0.0331992   0.         -0.9832352 ]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 13787 is [False, False, True, False, True, False]
Current timestep = 13788. State = [[ 0.31955346 -0.01468683]]. Action = [[-0.00586271 -0.01948229  0.         -0.7521092 ]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 13788 is [False, False, True, False, True, False]
Current timestep = 13789. State = [[ 0.31953707 -0.01303037]]. Action = [[ 0.09676553  0.0364553   0.         -0.83637154]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 13789 is [False, False, True, False, True, False]
Current timestep = 13790. State = [[ 0.31823182 -0.01388359]]. Action = [[-0.03044996 -0.04169338  0.         -0.85205156]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 13790 is [False, False, True, False, True, False]
Current timestep = 13791. State = [[ 0.31780583 -0.01586863]]. Action = [[ 0.06644101 -0.0262657   0.         -0.61031383]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 13791 is [False, False, True, False, True, False]
Current timestep = 13792. State = [[ 0.31908026 -0.0124916 ]]. Action = [[ 0.08154637  0.07151986  0.         -0.85900563]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 13792 is [False, False, True, False, True, False]
Current timestep = 13793. State = [[ 0.3202805  -0.00862328]]. Action = [[0.06612321 0.04206099 0.         0.50122714]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 13793 is [False, False, True, False, True, False]
Current timestep = 13794. State = [[ 0.321737   -0.00306477]]. Action = [[ 0.09037941  0.09692878  0.         -0.9454746 ]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 13794 is [False, False, True, False, True, False]
State prediction error at timestep 13794 is 0.012
Human Feedback received at timestep 13794 of None
Current timestep = 13795. State = [[ 0.32115597 -0.00313765]]. Action = [[-0.00836224 -0.06060417  0.         -0.66013706]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 13795 is [False, False, True, False, True, False]
Current timestep = 13796. State = [[ 0.3202942  -0.00208258]]. Action = [[ 0.02140965  0.04303183  0.         -0.91792256]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 13796 is [False, False, True, False, True, False]
State prediction error at timestep 13796 is 0.012
Human Feedback received at timestep 13796 of None
Current timestep = 13797. State = [[ 0.32109436 -0.00356395]]. Action = [[ 0.08573372 -0.09293325  0.         -0.92852277]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 13797 is [False, False, True, False, True, False]
Current timestep = 13798. State = [[ 0.32232797 -0.00414978]]. Action = [[ 0.08521057  0.00162943  0.         -0.6454286 ]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 13798 is [False, False, True, False, True, False]
Current timestep = 13799. State = [[ 0.32305276 -0.00674697]]. Action = [[ 0.08363246 -0.09462612  0.         -0.9733475 ]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 13799 is [False, False, True, False, True, False]
State prediction error at timestep 13799 is 0.012
Human Feedback received at timestep 13799 of None
Current timestep = 13800. State = [[ 0.32346126 -0.01232165]]. Action = [[ 0.0388855  -0.09042179  0.         -0.58404577]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 13800 is [False, False, True, False, True, False]
Current timestep = 13801. State = [[ 0.3237231  -0.01311138]]. Action = [[0.0516201  0.03513116 0.         0.41149938]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 13801 is [False, False, True, False, True, False]
Current timestep = 13802. State = [[ 0.32435212 -0.01497586]]. Action = [[ 0.08193571 -0.0595776   0.         -0.8030392 ]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 13802 is [False, False, True, False, True, False]
State prediction error at timestep 13802 is 0.012
Human Feedback received at timestep 13802 of None
Current timestep = 13803. State = [[ 0.3233728  -0.02033018]]. Action = [[-0.00344334 -0.07804912  0.         -0.21689731]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 13803 is [False, False, True, False, True, False]
Current timestep = 13804. State = [[ 0.323422   -0.02492884]]. Action = [[ 0.07830762 -0.05960203  0.         -0.56757873]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 13804 is [False, False, True, False, True, False]
Current timestep = 13805. State = [[ 0.3245217  -0.02807276]]. Action = [[ 0.07746812 -0.05759263  0.         -0.9494442 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 13805 is [False, False, True, False, True, False]
Current timestep = 13806. State = [[ 0.32474166 -0.02793363]]. Action = [[ 0.03387653  0.03432138  0.         -0.9170834 ]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 13806 is [False, False, True, False, True, False]
State prediction error at timestep 13806 is 0.012
Human Feedback received at timestep 13806 of None
Current timestep = 13807. State = [[ 0.32520536 -0.02858887]]. Action = [[ 0.09139759 -0.05891829  0.         -0.932432  ]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 13807 is [False, False, True, False, True, False]
Current timestep = 13808. State = [[ 0.32595184 -0.02620561]]. Action = [[ 0.07046158  0.05918612  0.         -0.9515811 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 13808 is [False, False, True, False, True, False]
Current timestep = 13809. State = [[ 0.32405955 -0.02839161]]. Action = [[-0.04443208 -0.08120872  0.         -0.28406364]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 13809 is [False, False, True, False, True, False]
Current timestep = 13810. State = [[ 0.32139748 -0.0333934 ]]. Action = [[ 0.00309787 -0.0391808   0.         -0.04872787]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 13810 is [False, False, True, False, True, False]
State prediction error at timestep 13810 is 0.012
Human Feedback received at timestep 13810 of None
Current timestep = 13811. State = [[ 0.32106155 -0.03584855]]. Action = [[ 0.02789641 -0.02275284  0.         -0.7336252 ]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 13811 is [False, False, True, False, True, False]
State prediction error at timestep 13811 is 0.012
Human Feedback received at timestep 13811 of None
Current timestep = 13812. State = [[ 0.32179168 -0.03753064]]. Action = [[ 0.06926071 -0.0500952   0.         -0.75206125]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 13812 is [False, False, True, False, True, False]
Current timestep = 13813. State = [[ 0.3229714  -0.04185677]]. Action = [[ 0.05631689 -0.09181791  0.         -0.9860147 ]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 13813 is [False, False, True, False, True, False]
Current timestep = 13814. State = [[ 0.3247539  -0.04706889]]. Action = [[ 0.09132152 -0.08405705  0.         -0.9759234 ]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 13814 is [False, False, True, False, True, False]
Current timestep = 13815. State = [[ 0.32541683 -0.05045429]]. Action = [[ 0.03677835 -0.04348619  0.         -0.6526823 ]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 13815 is [False, False, True, False, True, False]
State prediction error at timestep 13815 is 0.012
Human Feedback received at timestep 13815 of None
Current timestep = 13816. State = [[ 0.32499775 -0.05689721]]. Action = [[ 0.01181535 -0.09829605  0.         -0.09698379]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 13816 is [False, False, True, False, True, False]
Current timestep = 13817. State = [[ 0.32569617 -0.05954051]]. Action = [[0.07271443 0.01024079 0.         0.70048106]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 13817 is [False, False, True, False, True, False]
Current timestep = 13818. State = [[ 0.32668695 -0.05777361]]. Action = [[ 0.06642332  0.03960981  0.         -0.69250834]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 13818 is [False, False, True, False, True, False]
Current timestep = 13819. State = [[ 0.3268313  -0.05479312]]. Action = [[ 0.02939249  0.04294815  0.         -0.79364437]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 13819 is [False, False, True, False, True, False]
Current timestep = 13820. State = [[ 0.32717004 -0.05195808]]. Action = [[ 0.06044327  0.03261376  0.         -0.6631127 ]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 13820 is [False, False, True, False, True, False]
State prediction error at timestep 13820 is 0.012
Human Feedback received at timestep 13820 of None
Current timestep = 13821. State = [[ 0.3272386  -0.05237216]]. Action = [[ 0.02135656 -0.04730163  0.         -0.7689249 ]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 13821 is [False, False, True, False, True, False]
Current timestep = 13822. State = [[ 0.32726368 -0.05344092]]. Action = [[ 0.05160177 -0.03815046  0.         -0.9229802 ]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 13822 is [False, False, True, False, True, False]
Current timestep = 13823. State = [[ 0.3278103  -0.05010779]]. Action = [[0.08322906 0.06605989 0.         0.8161756 ]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 13823 is [False, False, True, False, True, False]
Current timestep = 13824. State = [[ 0.32609126 -0.04878923]]. Action = [[-0.03424434 -0.00943504  0.         -0.92029953]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 13824 is [False, False, True, False, True, False]
Current timestep = 13825. State = [[ 0.32469764 -0.05357193]]. Action = [[ 0.02539022 -0.09858479  0.         -0.8655249 ]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 13825 is [False, False, True, False, True, False]
Current timestep = 13826. State = [[ 0.32471743 -0.05491985]]. Action = [[ 0.03748102  0.02445724  0.         -0.8975384 ]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 13826 is [False, False, True, False, True, False]
Current timestep = 13827. State = [[ 0.32512614 -0.05606464]]. Action = [[ 0.05605652 -0.05985463  0.         -0.97036946]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 13827 is [False, False, True, False, True, False]
Current timestep = 13828. State = [[ 0.32625166 -0.06007884]]. Action = [[ 0.06594964 -0.08379827  0.         -0.97546047]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 13828 is [False, False, True, False, True, False]
Current timestep = 13829. State = [[ 0.32770535 -0.06417462]]. Action = [[ 0.06780142 -0.06545725  0.         -0.7817385 ]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 13829 is [False, False, True, False, True, False]
Current timestep = 13830. State = [[ 0.3259228  -0.06550609]]. Action = [[-0.07278755  0.02722367  0.         -0.46335506]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 13830 is [False, False, True, False, True, False]
Current timestep = 13831. State = [[ 0.32479283 -0.06388973]]. Action = [[ 0.08932843  0.02532163  0.         -0.4492538 ]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 13831 is [False, False, True, False, True, False]
Current timestep = 13832. State = [[ 0.3249339  -0.06023977]]. Action = [[ 0.01948389  0.08074165  0.         -0.9000325 ]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 13832 is [False, False, True, False, True, False]
Current timestep = 13833. State = [[ 0.3225489  -0.05672114]]. Action = [[-0.06054796  0.04763371  0.         -0.9388116 ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 13833 is [False, False, True, False, True, False]
Current timestep = 13834. State = [[ 0.32045546 -0.04971961]]. Action = [[ 0.06613979  0.07277127  0.         -0.9223469 ]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 13834 is [False, False, True, False, True, False]
Current timestep = 13835. State = [[ 0.32100737 -0.04797452]]. Action = [[ 0.04746749 -0.03285473  0.         -0.9952501 ]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 13835 is [False, False, True, False, True, False]
Current timestep = 13836. State = [[ 0.32254493 -0.04862652]]. Action = [[ 0.08397748 -0.04120046  0.         -0.98294044]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 13836 is [False, False, True, False, True, False]
Current timestep = 13837. State = [[ 0.3215484  -0.05208771]]. Action = [[-0.06073885 -0.05802834  0.         -0.990114  ]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 13837 is [False, False, True, False, True, False]
Current timestep = 13838. State = [[ 0.32088488 -0.05404037]]. Action = [[ 6.3693844e-02  7.5441599e-04  0.0000000e+00 -8.2936615e-01]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 13838 is [False, False, True, False, True, False]
Current timestep = 13839. State = [[ 0.31956962 -0.05088406]]. Action = [[-0.03447804  0.06584022  0.         -0.62742937]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 13839 is [False, False, True, False, True, False]
Current timestep = 13840. State = [[ 0.3187744  -0.04536036]]. Action = [[ 0.05231721  0.0666348   0.         -0.78359663]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 13840 is [False, False, True, False, True, False]
State prediction error at timestep 13840 is 0.012
Human Feedback received at timestep 13840 of None
Current timestep = 13841. State = [[ 0.3187858  -0.04548324]]. Action = [[ 0.01173206 -0.04975141  0.         -0.7922253 ]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 13841 is [False, False, True, False, True, False]
Current timestep = 13842. State = [[ 0.32024205 -0.04849547]]. Action = [[ 0.09157255 -0.07031225  0.         -0.7210965 ]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 13842 is [False, False, True, False, True, False]
Current timestep = 13843. State = [[ 0.31974056 -0.05320189]]. Action = [[-0.0180333  -0.06317683  0.          0.21689153]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 13843 is [False, False, True, False, True, False]
Current timestep = 13844. State = [[ 0.31998992 -0.05404162]]. Action = [[ 0.07594388  0.03214452  0.         -0.7907524 ]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 13844 is [False, False, True, False, True, False]
Current timestep = 13845. State = [[ 0.32029548 -0.05331896]]. Action = [[0.00545887 0.00201353 0.         0.17285001]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 13845 is [False, False, True, False, True, False]
Current timestep = 13846. State = [[ 0.32123172 -0.05168553]]. Action = [[ 0.07740765  0.03392465  0.         -0.8858849 ]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 13846 is [False, False, True, False, True, False]
Current timestep = 13847. State = [[ 0.32289788 -0.05301982]]. Action = [[ 0.06473497 -0.06210914  0.         -0.85610574]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 13847 is [False, False, True, False, True, False]
Current timestep = 13848. State = [[ 0.32165042 -0.05364566]]. Action = [[-0.03198014  0.01463101  0.         -0.7308027 ]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 13848 is [False, False, True, False, True, False]
State prediction error at timestep 13848 is 0.012
Human Feedback received at timestep 13848 of None
Current timestep = 13849. State = [[ 0.32055873 -0.05043688]]. Action = [[ 0.02240531  0.06754047  0.         -0.38108242]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 13849 is [False, False, True, False, True, False]
Current timestep = 13850. State = [[ 0.32165903 -0.04449108]]. Action = [[ 0.08966985  0.08308331  0.         -0.9263735 ]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 13850 is [False, False, True, False, True, False]
Current timestep = 13851. State = [[ 0.32304716 -0.0410115 ]]. Action = [[ 0.06126835  0.00905168  0.         -0.81002617]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 13851 is [False, False, True, False, True, False]
Current timestep = 13852. State = [[ 0.32446268 -0.038023  ]]. Action = [[ 0.08424134  0.0245175   0.         -0.92290413]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 13852 is [False, False, True, False, True, False]
Current timestep = 13853. State = [[ 0.32571238 -0.03858058]]. Action = [[ 0.07072797 -0.07471851  0.         -0.8565529 ]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 13853 is [False, False, True, False, True, False]
Current timestep = 13854. State = [[ 0.3259906 -0.0362311]]. Action = [[ 0.02457837  0.08843627  0.         -0.692575  ]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 13854 is [False, False, True, False, True, False]
Current timestep = 13855. State = [[ 0.3268303  -0.03115305]]. Action = [[ 0.09714425  0.06779679  0.         -0.71536404]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 13855 is [False, False, True, False, True, False]
State prediction error at timestep 13855 is 0.012
Human Feedback received at timestep 13855 of None
Current timestep = 13856. State = [[ 0.3250239  -0.02527151]]. Action = [[-0.0585556   0.09113357  0.         -0.94161093]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 13856 is [False, False, True, False, True, False]
Current timestep = 13857. State = [[ 0.3199144  -0.01979929]]. Action = [[-0.04305647  0.02931922  0.         -0.95914805]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 13857 is [False, False, True, False, True, False]
Current timestep = 13858. State = [[ 0.314519   -0.02198008]]. Action = [[-0.06793576 -0.08918911  0.         -0.9281484 ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 13858 is [False, False, True, False, True, False]
State prediction error at timestep 13858 is 0.012
Human Feedback received at timestep 13858 of None
Current timestep = 13859. State = [[ 0.31258103 -0.02082955]]. Action = [[ 0.04540036  0.06926475  0.         -0.00256264]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 13859 is [False, False, True, False, True, False]
State prediction error at timestep 13859 is 0.012
Human Feedback received at timestep 13859 of None
Current timestep = 13860. State = [[ 0.3143127  -0.01367223]]. Action = [[ 0.07821786  0.06774575  0.         -0.9875328 ]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 13860 is [False, False, True, False, True, False]
Current timestep = 13861. State = [[ 0.3146344  -0.00989411]]. Action = [[ 0.0183867  -0.00136288  0.         -0.9336858 ]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 13861 is [False, False, True, False, True, False]
Current timestep = 13862. State = [[ 0.31568122 -0.01211957]]. Action = [[ 0.06585611 -0.09287214  0.         -0.9678937 ]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 13862 is [False, False, True, False, True, False]
Current timestep = 13863. State = [[ 0.31826335 -0.0113702 ]]. Action = [[ 0.08616448  0.05134644  0.         -0.02487159]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 13863 is [False, False, True, False, True, False]
Current timestep = 13864. State = [[ 0.31981596 -0.00502263]]. Action = [[ 0.06982703  0.08755613  0.         -0.8685048 ]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 13864 is [False, False, True, False, True, False]
Current timestep = 13865. State = [[ 0.3210164  -0.00254461]]. Action = [[ 0.08757637 -0.0158676   0.         -0.9690522 ]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 13865 is [False, False, True, False, True, False]
State prediction error at timestep 13865 is 0.012
Human Feedback received at timestep 13865 of None
Current timestep = 13866. State = [[ 0.32240453 -0.00507237]]. Action = [[ 0.07612646 -0.08590914  0.         -0.9613745 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 13866 is [False, False, True, False, True, False]
State prediction error at timestep 13866 is 0.012
Human Feedback received at timestep 13866 of None
Current timestep = 13867. State = [[ 0.32396767 -0.00839689]]. Action = [[ 0.08874712 -0.06527925  0.         -0.5948815 ]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 13867 is [False, False, True, False, True, False]
Current timestep = 13868. State = [[ 0.32367656 -0.01225484]]. Action = [[ 0.00505469 -0.05533192  0.         -0.96536285]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 13868 is [False, False, True, False, True, False]
Current timestep = 13869. State = [[ 0.32359818 -0.01087331]]. Action = [[ 0.07548831  0.07329828  0.         -0.98970777]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 13869 is [False, False, True, False, True, False]
State prediction error at timestep 13869 is 0.012
Human Feedback received at timestep 13869 of None
Current timestep = 13870. State = [[ 0.32392895 -0.01083316]]. Action = [[ 0.05883295 -0.04085226  0.         -0.97859764]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 13870 is [False, False, True, False, True, False]
Current timestep = 13871. State = [[ 0.32444897 -0.01209258]]. Action = [[ 0.09430344 -0.04162487  0.          0.6712314 ]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 13871 is [False, False, True, False, True, False]
Current timestep = 13872. State = [[ 0.3250066  -0.01253706]]. Action = [[ 0.06242467  0.00263872  0.         -0.9338703 ]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 13872 is [False, False, True, False, True, False]
Current timestep = 13873. State = [[ 0.32492098 -0.01063421]]. Action = [[ 0.01024469  0.05184307  0.         -0.9418916 ]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 13873 is [False, False, True, False, True, False]
Current timestep = 13874. State = [[ 0.32511562 -0.00645603]]. Action = [[ 0.07288717  0.06672265  0.         -0.5676255 ]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 13874 is [False, False, True, False, True, False]
State prediction error at timestep 13874 is 0.012
Human Feedback received at timestep 13874 of None
Current timestep = 13875. State = [[ 0.32546073 -0.00513877]]. Action = [[ 0.06406338 -0.02268145  0.         -0.27629793]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 13875 is [False, False, True, False, True, False]
Current timestep = 13876. State = [[ 0.3246152  -0.00496206]]. Action = [[ 0.00096206  0.00339779  0.         -0.39938593]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 13876 is [False, False, True, False, True, False]
State prediction error at timestep 13876 is 0.012
Human Feedback received at timestep 13876 of None
Current timestep = 13877. State = [[ 0.3209624  -0.00454059]]. Action = [[-0.0429609   0.00537045  0.         -0.9882025 ]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 13877 is [False, False, True, False, True, False]
Current timestep = 13878. State = [[ 3.1911108e-01 -2.6227871e-04]]. Action = [[ 0.05392975  0.08296462  0.         -0.18814564]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 13878 is [False, False, True, False, True, False]
State prediction error at timestep 13878 is 0.012
Human Feedback received at timestep 13878 of None
Current timestep = 13879. State = [[0.3198454  0.00079098]]. Action = [[ 0.07812399 -0.04411623  0.         -0.3584224 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 13879 is [False, False, True, False, True, False]
State prediction error at timestep 13879 is 0.012
Human Feedback received at timestep 13879 of None
Current timestep = 13880. State = [[ 0.32021073 -0.00191353]]. Action = [[ 0.04819828 -0.07557239  0.         -0.8935517 ]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 13880 is [False, False, True, False, True, False]
Current timestep = 13881. State = [[ 0.31775603 -0.00054423]]. Action = [[-0.0459814   0.06626188  0.         -0.9763725 ]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 13881 is [False, False, True, False, True, False]
Current timestep = 13882. State = [[0.31679255 0.00395713]]. Action = [[ 0.09856286  0.04869919  0.         -0.9628196 ]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 13882 is [False, False, True, False, True, False]
Current timestep = 13883. State = [[0.31832084 0.00251717]]. Action = [[ 0.08368648 -0.0789275   0.         -0.70124656]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 13883 is [False, False, True, False, True, False]
Current timestep = 13884. State = [[0.31971756 0.00155036]]. Action = [[ 0.06785808 -0.00748879  0.         -0.9964043 ]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 13884 is [False, False, True, False, True, False]
Current timestep = 13885. State = [[0.31987083 0.00250035]]. Action = [[ 0.01503366  0.03382271  0.         -0.9039297 ]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 13885 is [False, False, True, False, True, False]
Current timestep = 13886. State = [[0.31983465 0.00484165]]. Action = [[0.03144927 0.05802617 0.         0.12627387]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 13886 is [False, False, True, False, True, False]
Current timestep = 13887. State = [[0.3202911  0.00269464]]. Action = [[ 0.06053271 -0.09685741  0.         -0.50048035]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 13887 is [False, False, True, False, True, False]
Current timestep = 13888. State = [[0.31786972 0.00170016]]. Action = [[-0.0754347  0.0334995  0.        -0.6967947]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 13888 is [False, False, True, False, True, False]
State prediction error at timestep 13888 is 0.012
Human Feedback received at timestep 13888 of None
Current timestep = 13889. State = [[0.31255156 0.00156757]]. Action = [[-0.05820968 -0.01469101  0.         -0.4102903 ]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 13889 is [False, False, True, False, True, False]
State prediction error at timestep 13889 is 0.012
Human Feedback received at timestep 13889 of None
Current timestep = 13890. State = [[0.31112948 0.00080369]]. Action = [[ 0.05218595 -0.01482045  0.         -0.9210875 ]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 13890 is [False, False, True, False, True, False]
Current timestep = 13891. State = [[ 0.31379494 -0.00279237]]. Action = [[ 0.08396263 -0.05876074  0.         -0.9802367 ]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 13891 is [False, False, True, False, True, False]
Current timestep = 13892. State = [[ 0.31533307 -0.00335984]]. Action = [[ 0.0533848   0.01130338  0.         -0.03035635]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 13892 is [False, False, True, False, True, False]
State prediction error at timestep 13892 is 0.012
Human Feedback received at timestep 13892 of None
Current timestep = 13893. State = [[3.1676653e-01 1.6920148e-04]]. Action = [[ 0.09798504  0.06047585  0.         -0.7972541 ]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 13893 is [False, False, True, False, True, False]
State prediction error at timestep 13893 is 0.012
Human Feedback received at timestep 13893 of None
Current timestep = 13894. State = [[0.317177   0.00139264]]. Action = [[ 0.0364526  -0.01008618  0.         -0.85444856]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 13894 is [False, False, True, False, True, False]
Current timestep = 13895. State = [[0.31637868 0.00152438]]. Action = [[-0.00488666  0.01173917  0.         -0.9891326 ]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 13895 is [False, False, True, False, True, False]
State prediction error at timestep 13895 is 0.012
Human Feedback received at timestep 13895 of None
Current timestep = 13896. State = [[0.31638658 0.00454833]]. Action = [[ 0.0919965   0.05588935  0.         -0.7700202 ]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 13896 is [False, False, True, False, True, False]
Current timestep = 13897. State = [[0.31804192 0.00342007]]. Action = [[ 0.0944036  -0.07790122  0.         -0.8633406 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 13897 is [False, False, True, False, True, False]
Current timestep = 13898. State = [[0.31949684 0.00345283]]. Action = [[ 0.08475389  0.0025696   0.         -0.8274951 ]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 13898 is [False, False, True, False, True, False]
State prediction error at timestep 13898 is 0.012
Human Feedback received at timestep 13898 of None
Current timestep = 13899. State = [[0.32020319 0.00310413]]. Action = [[ 0.0614345  -0.02668256  0.         -0.9559726 ]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 13899 is [False, False, True, False, True, False]
Current timestep = 13900. State = [[0.32135966 0.00063243]]. Action = [[ 0.09074729 -0.06934521  0.         -0.52307   ]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 13900 is [False, False, True, False, True, False]
Current timestep = 13901. State = [[ 0.3228521  -0.00061673]]. Action = [[ 0.09859169 -0.0245024   0.         -0.59017956]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 13901 is [False, False, True, False, True, False]
Current timestep = 13902. State = [[ 0.32308984 -0.0041324 ]]. Action = [[ 0.02906222 -0.07668581  0.         -0.7877568 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 13902 is [False, False, True, False, True, False]
Current timestep = 13903. State = [[ 0.323851   -0.00943042]]. Action = [[ 0.08178463 -0.09673147  0.         -0.9814034 ]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 13903 is [False, False, True, False, True, False]
State prediction error at timestep 13903 is 0.012
Human Feedback received at timestep 13903 of None
Current timestep = 13904. State = [[ 0.3249216  -0.01214805]]. Action = [[ 0.09586874 -0.03317967  0.         -0.9775081 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 13904 is [False, False, True, False, True, False]
State prediction error at timestep 13904 is 0.012
Human Feedback received at timestep 13904 of None
Current timestep = 13905. State = [[ 0.32518393 -0.00976002]]. Action = [[0.09344799 0.05977125 0.         0.24887252]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 13905 is [False, False, True, False, True, False]
State prediction error at timestep 13905 is 0.012
Human Feedback received at timestep 13905 of None
Current timestep = 13906. State = [[ 0.32523775 -0.00961026]]. Action = [[ 0.05001237 -0.03183313  0.         -0.92884654]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 13906 is [False, False, True, False, True, False]
Current timestep = 13907. State = [[ 0.3248246  -0.01410007]]. Action = [[ 0.01403464 -0.09154391  0.         -0.965306  ]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 13907 is [False, False, True, False, True, False]
Current timestep = 13908. State = [[ 0.32461837 -0.01637123]]. Action = [[ 0.06033669  0.00714706  0.         -0.7971622 ]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 13908 is [False, False, True, False, True, False]
Current timestep = 13909. State = [[ 0.3249078  -0.01639068]]. Action = [[ 0.07663991 -0.0380057   0.         -0.975127  ]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 13909 is [False, False, True, False, True, False]
Current timestep = 13910. State = [[ 0.32498583 -0.01639206]]. Action = [[ 0.0450547  -0.00687627  0.         -0.28618777]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 13910 is [False, False, True, False, True, False]
Current timestep = 13911. State = [[ 0.32476985 -0.01942754]]. Action = [[ 0.02415006 -0.08523738  0.         -0.9956879 ]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 13911 is [False, False, True, False, True, False]
Current timestep = 13912. State = [[ 0.32170644 -0.01783892]]. Action = [[-0.06503338  0.08897568  0.         -0.5025564 ]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 13912 is [False, False, True, False, True, False]
State prediction error at timestep 13912 is 0.012
Human Feedback received at timestep 13912 of None
Current timestep = 13913. State = [[ 0.31687307 -0.01741485]]. Action = [[-0.03725141 -0.04118845  0.         -0.9594969 ]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 13913 is [False, False, True, False, True, False]
Current timestep = 13914. State = [[ 0.31488883 -0.02283557]]. Action = [[ 0.00616612 -0.0782192   0.         -0.73539364]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 13914 is [False, False, True, False, True, False]
Current timestep = 13915. State = [[ 0.31649005 -0.03000759]]. Action = [[ 0.07280643 -0.07361048  0.         -0.9656889 ]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 13915 is [False, False, True, False, True, False]
State prediction error at timestep 13915 is 0.012
Human Feedback received at timestep 13915 of None
Current timestep = 13916. State = [[ 0.31697065 -0.02997022]]. Action = [[-0.00643516  0.07495975  0.         -0.951432  ]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 13916 is [False, False, True, False, True, False]
Current timestep = 13917. State = [[ 0.31743935 -0.02768024]]. Action = [[0.08862593 0.01184005 0.         0.09279203]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 13917 is [False, False, True, False, True, False]
Current timestep = 13918. State = [[ 0.31892657 -0.02852876]]. Action = [[ 0.0876941  -0.04151118  0.         -0.68120444]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 13918 is [False, False, True, False, True, False]
Current timestep = 13919. State = [[ 0.31958377 -0.02776903]]. Action = [[ 0.04408585  0.03071821  0.         -0.99896777]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 13919 is [False, False, True, False, True, False]
Current timestep = 13920. State = [[ 0.32019556 -0.03019627]]. Action = [[ 0.05441982 -0.08742378  0.         -0.92911655]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 13920 is [False, False, True, False, True, False]
State prediction error at timestep 13920 is 0.012
Human Feedback received at timestep 13920 of None
Current timestep = 13921. State = [[ 0.31933552 -0.03508791]]. Action = [[-0.00935908 -0.05912974  0.         -0.9514709 ]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 13921 is [False, False, True, False, True, False]
State prediction error at timestep 13921 is 0.012
Human Feedback received at timestep 13921 of None
Current timestep = 13922. State = [[ 0.3200066  -0.04064301]]. Action = [[ 0.07452609 -0.07631575  0.         -0.90674114]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 13922 is [False, False, True, False, True, False]
Current timestep = 13923. State = [[ 0.32221526 -0.0450208 ]]. Action = [[ 0.07524469 -0.05897938  0.         -0.9816925 ]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 13923 is [False, False, True, False, True, False]
Current timestep = 13924. State = [[ 0.32382694 -0.04648129]]. Action = [[ 0.0692646  -0.01117103  0.         -0.6160658 ]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 13924 is [False, False, True, False, True, False]
State prediction error at timestep 13924 is 0.012
Human Feedback received at timestep 13924 of None
Current timestep = 13925. State = [[ 0.32403436 -0.04708381]]. Action = [[ 0.03518448 -0.00865485  0.         -0.04984641]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 13925 is [False, False, True, False, True, False]
Current timestep = 13926. State = [[ 0.3218207 -0.0470551]]. Action = [[-0.07273879  0.02582505  0.         -0.94352067]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 13926 is [False, False, True, False, True, False]
Current timestep = 13927. State = [[ 0.32005805 -0.04944049]]. Action = [[ 0.05119187 -0.05931889  0.         -0.55073917]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 13927 is [False, False, True, False, True, False]
Current timestep = 13928. State = [[ 0.32034272 -0.05222219]]. Action = [[ 0.03272904 -0.03676464  0.         -0.8454887 ]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 13928 is [False, False, True, False, True, False]
Current timestep = 13929. State = [[ 0.32086056 -0.04995799]]. Action = [[ 0.05011851  0.06422272  0.         -0.37883478]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 13929 is [False, False, True, False, True, False]
Current timestep = 13930. State = [[ 0.3218202  -0.04510547]]. Action = [[ 0.08230896  0.06331516  0.         -0.9584252 ]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 13930 is [False, False, True, False, True, False]
State prediction error at timestep 13930 is 0.012
Human Feedback received at timestep 13930 of None
Current timestep = 13931. State = [[ 0.32205433 -0.04471829]]. Action = [[ 0.01823577 -0.03596689  0.         -0.7425697 ]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 13931 is [False, False, True, False, True, False]
Current timestep = 13932. State = [[ 0.31968665 -0.04730656]]. Action = [[-0.04424734 -0.0398111   0.         -0.6550372 ]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 13932 is [False, False, True, False, True, False]
Current timestep = 13933. State = [[ 0.31497037 -0.04570393]]. Action = [[-0.05618786  0.05725536  0.         -0.64284647]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 13933 is [False, False, True, False, True, False]
Current timestep = 13934. State = [[ 0.31278682 -0.0428933 ]]. Action = [[ 0.00378515  0.01116756  0.         -0.8798867 ]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 13934 is [False, False, True, False, True, False]
Current timestep = 13935. State = [[ 0.3132311  -0.04020455]]. Action = [[ 0.03719794  0.03000989  0.         -0.88216186]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 13935 is [False, False, True, False, True, False]
State prediction error at timestep 13935 is 0.012
Human Feedback received at timestep 13935 of None
Current timestep = 13936. State = [[ 0.31311926 -0.03702032]]. Action = [[ 0.01124462  0.03201931  0.         -0.669654  ]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 13936 is [False, False, True, False, True, False]
Current timestep = 13937. State = [[ 0.3136371  -0.03423718]]. Action = [[0.03514314 0.04768694 0.         0.4311533 ]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 13937 is [False, False, True, False, True, False]
Current timestep = 13938. State = [[ 0.31463048 -0.0289636 ]]. Action = [[ 0.04816622  0.08139993  0.         -0.24650562]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 13938 is [False, False, True, False, True, False]
State prediction error at timestep 13938 is 0.012
Human Feedback received at timestep 13938 of None
Current timestep = 13939. State = [[ 0.31652912 -0.02813871]]. Action = [[ 0.09009678 -0.06145054  0.         -0.27259755]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 13939 is [False, False, True, False, True, False]
Current timestep = 13940. State = [[ 0.317268   -0.02815824]]. Action = [[ 0.03344112  0.00617085  0.         -0.7912888 ]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 13940 is [False, False, True, False, True, False]
Current timestep = 13941. State = [[ 0.31666553 -0.03098005]]. Action = [[-0.00153998 -0.06667283  0.         -0.6715193 ]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 13941 is [False, False, True, False, True, False]
Current timestep = 13942. State = [[ 0.31671715 -0.03608356]]. Action = [[ 0.03344817 -0.06487435  0.          0.22760797]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 13942 is [False, False, True, False, True, False]
Current timestep = 13943. State = [[ 0.31659216 -0.04134529]]. Action = [[ 0.00814857 -0.06234909  0.         -0.46834767]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 13943 is [False, False, True, False, True, False]
Current timestep = 13944. State = [[ 0.31677762 -0.04310012]]. Action = [[ 0.03326955  0.01489906  0.         -0.7477979 ]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 13944 is [False, False, True, False, True, False]
Current timestep = 13945. State = [[ 0.31718445 -0.04572915]]. Action = [[ 0.03279085 -0.07282542  0.          0.5945275 ]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 13945 is [False, False, True, False, True, False]
Current timestep = 13946. State = [[ 0.31853747 -0.04728762]]. Action = [[ 0.05790005  0.00220984  0.         -0.85210043]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 13946 is [False, False, True, False, True, False]
Current timestep = 13947. State = [[ 0.31953847 -0.05108732]]. Action = [[ 0.04246385 -0.08533655  0.         -0.96434665]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 13947 is [False, False, True, False, True, False]
Current timestep = 13948. State = [[ 0.32016477 -0.05510737]]. Action = [[ 0.03346208 -0.04788752  0.          0.08930933]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 13948 is [False, False, True, False, True, False]
Current timestep = 13949. State = [[ 0.32123303 -0.05702231]]. Action = [[ 0.05597202 -0.02782804  0.         -0.51806986]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 13949 is [False, False, True, False, True, False]
State prediction error at timestep 13949 is 0.012
Human Feedback received at timestep 13949 of None
Current timestep = 13950. State = [[ 0.3198036 -0.0570474]]. Action = [[-0.04172685  0.02572861  0.         -0.98744774]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 13950 is [False, False, True, False, True, False]
Current timestep = 13951. State = [[ 0.31746495 -0.05878482]]. Action = [[-0.00428797 -0.03757563  0.         -0.8266246 ]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 13951 is [False, False, True, False, True, False]
Current timestep = 13952. State = [[ 0.31554475 -0.06386235]]. Action = [[-0.01561973 -0.06125354  0.         -0.95522845]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 13952 is [False, False, True, False, True, False]
Current timestep = 13953. State = [[ 0.31612384 -0.07090757]]. Action = [[ 0.04322881 -0.08176671  0.         -0.89557284]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 13953 is [False, False, True, False, True, False]
State prediction error at timestep 13953 is 0.012
Human Feedback received at timestep 13953 of None
Current timestep = 13954. State = [[ 0.31861296 -0.07355255]]. Action = [[ 0.06973126  0.00515617  0.         -0.7481334 ]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 13954 is [False, False, True, False, True, False]
State prediction error at timestep 13954 is 0.012
Human Feedback received at timestep 13954 of None
Current timestep = 13955. State = [[ 0.31896526 -0.0778489 ]]. Action = [[ 0.00277293 -0.0873621   0.          0.7665752 ]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 13955 is [False, False, True, False, True, False]
State prediction error at timestep 13955 is 0.012
Human Feedback received at timestep 13955 of None
Current timestep = 13956. State = [[ 0.32028538 -0.0831762 ]]. Action = [[ 0.06315661 -0.04661706  0.         -0.29068232]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 13956 is [False, False, True, False, True, False]
State prediction error at timestep 13956 is 0.012
Human Feedback received at timestep 13956 of None
Current timestep = 13957. State = [[ 0.32023984 -0.08616149]]. Action = [[-0.00508893 -0.02278639  0.         -0.08446252]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 13957 is [False, False, True, False, True, False]
Current timestep = 13958. State = [[ 0.319065  -0.0889392]]. Action = [[-0.00670401 -0.01906886  0.          0.39211035]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 13958 is [False, False, True, False, True, False]
State prediction error at timestep 13958 is 0.012
Human Feedback received at timestep 13958 of None
Current timestep = 13959. State = [[ 0.31932214 -0.09445111]]. Action = [[ 0.03130545 -0.08293895  0.         -0.99418664]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 13959 is [False, False, True, False, True, False]
State prediction error at timestep 13959 is 0.012
Human Feedback received at timestep 13959 of None
Current timestep = 13960. State = [[ 0.31809658 -0.09938572]]. Action = [[-0.02398147 -0.02806041  0.         -0.9180193 ]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 13960 is [False, False, True, False, True, False]
Current timestep = 13961. State = [[ 0.3187851  -0.10243043]]. Action = [[ 0.0917014  -0.03342214  0.         -0.79515404]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 13961 is [False, False, True, False, True, False]
State prediction error at timestep 13961 is 0.012
Human Feedback received at timestep 13961 of None
Current timestep = 13962. State = [[ 0.31908575 -0.10697681]]. Action = [[ 0.00134578 -0.06354563  0.         -0.81455743]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 13962 is [False, False, True, False, True, False]
State prediction error at timestep 13962 is 0.012
Human Feedback received at timestep 13962 of None
Current timestep = 13963. State = [[ 0.3204581  -0.11224502]]. Action = [[ 0.06362519 -0.057163    0.         -0.617355  ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 13963 is [False, False, True, False, True, False]
Current timestep = 13964. State = [[ 0.32012406 -0.11214118]]. Action = [[-0.04556305  0.06172339  0.         -0.68672734]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 13964 is [False, False, True, False, True, False]
Current timestep = 13965. State = [[ 0.31989735 -0.10874366]]. Action = [[ 0.04527127  0.04302765  0.         -0.9711924 ]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 13965 is [False, False, True, False, True, False]
Current timestep = 13966. State = [[ 0.32004115 -0.10472613]]. Action = [[ 0.00396279  0.06217558  0.         -0.99534535]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 13966 is [False, False, True, False, True, False]
Current timestep = 13967. State = [[ 0.32154098 -0.10677668]]. Action = [[ 0.06681902 -0.09243438  0.         -0.62251693]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 13967 is [False, False, True, False, True, False]
Current timestep = 13968. State = [[ 0.32371822 -0.10666408]]. Action = [[0.06643073 0.0276086  0.         0.01534259]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 13968 is [False, False, True, False, True, False]
State prediction error at timestep 13968 is 0.012
Human Feedback received at timestep 13968 of None
Current timestep = 13969. State = [[ 0.32555968 -0.10770409]]. Action = [[ 0.06752343 -0.07284421  0.          0.09649408]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 13969 is [False, False, True, False, True, False]
Current timestep = 13970. State = [[ 0.32772288 -0.10850815]]. Action = [[ 0.09641156 -0.01720454  0.         -0.47787225]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 13970 is [False, False, True, False, True, False]
Current timestep = 13971. State = [[ 0.32641524 -0.11394758]]. Action = [[-0.074715   -0.0990041   0.         -0.85816747]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 13971 is [False, False, True, False, True, False]
Current timestep = 13972. State = [[ 0.3250747  -0.12269547]]. Action = [[ 0.02770128 -0.0797043   0.         -0.9965744 ]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 13972 is [False, False, True, False, True, False]
Current timestep = 13973. State = [[ 0.32269624 -0.13169941]]. Action = [[-0.07771003 -0.07085709  0.         -0.36870646]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 13973 is [False, False, True, False, True, False]
Current timestep = 13974. State = [[ 0.32200044 -0.13748844]]. Action = [[ 0.06779838 -0.03038085  0.          0.63995075]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 13974 is [False, False, True, True, False, False]
State prediction error at timestep 13974 is 0.012
Human Feedback received at timestep 13974 of None
Current timestep = 13975. State = [[ 0.32099658 -0.13842034]]. Action = [[-0.03584532  0.0413636   0.         -0.9657029 ]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 13975 is [False, False, True, True, False, False]
Current timestep = 13976. State = [[ 0.32082334 -0.14197716]]. Action = [[ 0.08050621 -0.09277572  0.         -0.93214923]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 13976 is [False, False, True, True, False, False]
State prediction error at timestep 13976 is 0.012
Human Feedback received at timestep 13976 of None
Current timestep = 13977. State = [[ 0.31963333 -0.1477429 ]]. Action = [[-0.02749153 -0.04859889  0.         -0.9757414 ]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 13977 is [False, False, True, True, False, False]
State prediction error at timestep 13977 is 0.012
Human Feedback received at timestep 13977 of None
Current timestep = 13978. State = [[ 0.3201145  -0.15285295]]. Action = [[ 0.08677783 -0.05352737  0.         -0.17281473]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 13978 is [False, False, True, True, False, False]
State prediction error at timestep 13978 is 0.012
Human Feedback received at timestep 13978 of None
Current timestep = 13979. State = [[ 0.3229566 -0.157265 ]]. Action = [[ 0.08898806 -0.05641328  0.         -0.14750022]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 13979 is [False, False, True, True, False, False]
State prediction error at timestep 13979 is 0.012
Human Feedback received at timestep 13979 of None
Current timestep = 13980. State = [[ 0.32597378 -0.15599579]]. Action = [[ 0.08803154  0.07137703  0.         -0.9119626 ]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 13980 is [False, False, True, True, False, False]
State prediction error at timestep 13980 is 0.012
Human Feedback received at timestep 13980 of None
Current timestep = 13981. State = [[ 0.3255551  -0.15236378]]. Action = [[-0.03939786  0.054571    0.         -0.9625085 ]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 13981 is [False, False, True, True, False, False]
Current timestep = 13982. State = [[ 0.3236057  -0.14575526]]. Action = [[-0.00312035  0.09024572  0.         -0.9910186 ]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 13982 is [False, False, True, True, False, False]
Current timestep = 13983. State = [[ 0.32443914 -0.14334077]]. Action = [[ 0.08929525 -0.04773874  0.         -0.08259833]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 13983 is [False, False, True, True, False, False]
State prediction error at timestep 13983 is 0.012
Human Feedback received at timestep 13983 of None
Current timestep = 13984. State = [[ 0.32432124 -0.14002106]]. Action = [[-0.02622467  0.08833382  0.         -0.7968165 ]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 13984 is [False, False, True, True, False, False]
Current timestep = 13985. State = [[ 0.32145134 -0.13754569]]. Action = [[-0.02864512 -0.0209948   0.         -0.91016173]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 13985 is [False, False, True, True, False, False]
Current timestep = 13986. State = [[ 0.3215792  -0.13200055]]. Action = [[ 0.08932433  0.08428461  0.         -0.9446955 ]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 13986 is [False, False, True, True, False, False]
Current timestep = 13987. State = [[ 0.3210862  -0.12507114]]. Action = [[-0.01369652  0.06013856  0.         -0.4813043 ]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 13987 is [False, False, True, True, False, False]
Current timestep = 13988. State = [[ 0.32133338 -0.120179  ]]. Action = [[ 0.04578207  0.03192265  0.         -0.9486488 ]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 13988 is [False, False, True, True, False, False]
Current timestep = 13989. State = [[ 0.32331094 -0.1199021 ]]. Action = [[ 0.08219401 -0.05935868  0.         -0.79913175]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 13989 is [False, False, True, False, True, False]
State prediction error at timestep 13989 is 0.012
Human Feedback received at timestep 13989 of None
Current timestep = 13990. State = [[ 0.32595807 -0.12353019]]. Action = [[ 0.08261866 -0.08137137  0.         -0.9666376 ]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 13990 is [False, False, True, False, True, False]
Current timestep = 13991. State = [[ 0.32652026 -0.12705883]]. Action = [[ 0.01764899 -0.04751733  0.         -0.8628254 ]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 13991 is [False, False, True, False, True, False]
Current timestep = 13992. State = [[ 0.32763806 -0.12711617]]. Action = [[ 0.08817815  0.00689907  0.         -0.94175154]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 13992 is [False, False, True, True, False, False]
Current timestep = 13993. State = [[ 0.3289168  -0.12590131]]. Action = [[ 0.06430329  0.00645465  0.         -0.92108005]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 13993 is [False, False, True, True, False, False]
Current timestep = 13994. State = [[ 0.3301698  -0.12230559]]. Action = [[0.07849278 0.07250784 0.         0.22174668]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 13994 is [False, False, True, True, False, False]
Current timestep = 13995. State = [[ 0.3312678  -0.12337774]]. Action = [[ 0.06489775 -0.06994673  0.         -0.60575897]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 13995 is [False, False, True, False, True, False]
Current timestep = 13996. State = [[ 0.3314267  -0.12575926]]. Action = [[ 0.03904495 -0.04557868  0.         -0.96574426]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 13996 is [False, False, True, False, True, False]
Current timestep = 13997. State = [[ 0.3306296  -0.12392121]]. Action = [[ 0.00099061  0.05934057  0.         -0.79781675]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 13997 is [False, False, True, True, False, False]
State prediction error at timestep 13997 is 0.012
Human Feedback received at timestep 13997 of None
Current timestep = 13998. State = [[ 0.33056724 -0.12355606]]. Action = [[ 0.08176822 -0.05673254  0.         -0.5246858 ]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 13998 is [False, False, True, False, True, False]
Current timestep = 13999. State = [[ 0.33065358 -0.12567374]]. Action = [[ 0.02067547 -0.04384933  0.         -0.8490306 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 13999 is [False, False, True, False, True, False]
Current timestep = 14000. State = [[ 0.33101055 -0.1248229 ]]. Action = [[0.06360824 0.02091771 0.         0.58804286]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 14000 is [False, False, True, True, False, False]
Current timestep = 14001. State = [[ 0.33019522 -0.12539543]]. Action = [[-0.00278012 -0.03495771  0.         -0.5964699 ]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 14001 is [False, False, True, False, True, False]
Current timestep = 14002. State = [[ 0.32995218 -0.12516813]]. Action = [[ 0.05155381  0.02021015  0.         -0.8520527 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 14002 is [False, False, True, True, False, False]
Current timestep = 14003. State = [[ 0.32765317 -0.12511076]]. Action = [[-0.05466381  0.00118498  0.         -0.9786948 ]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 14003 is [False, False, True, True, False, False]
State prediction error at timestep 14003 is 0.012
Human Feedback received at timestep 14003 of None
Current timestep = 14004. State = [[ 0.32427102 -0.12739056]]. Action = [[-0.01723608 -0.04084769  0.         -0.36093086]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 14004 is [False, False, True, True, False, False]
Current timestep = 14005. State = [[ 0.32460845 -0.13083176]]. Action = [[ 0.08391149 -0.05169037  0.         -0.5019627 ]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 14005 is [False, False, True, True, False, False]
State prediction error at timestep 14005 is 0.012
Human Feedback received at timestep 14005 of None
Current timestep = 14006. State = [[ 0.326654   -0.12922476]]. Action = [[0.07422421 0.04735488 0.         0.08288383]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 14006 is [False, False, True, True, False, False]
Current timestep = 14007. State = [[ 0.32777235 -0.12377924]]. Action = [[ 0.05139003  0.0960976   0.         -0.62776566]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 14007 is [False, False, True, True, False, False]
Current timestep = 14008. State = [[ 0.3292695  -0.11838876]]. Action = [[ 0.08555413  0.05707812  0.         -0.9360703 ]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 14008 is [False, False, True, False, True, False]
Current timestep = 14009. State = [[ 0.33000267 -0.11879572]]. Action = [[ 0.04862171 -0.07307398  0.         -0.9632289 ]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 14009 is [False, False, True, False, True, False]
Current timestep = 14010. State = [[ 0.33000097 -0.12250628]]. Action = [[ 0.02612994 -0.08319266  0.         -0.95759887]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 14010 is [False, False, True, False, True, False]
Current timestep = 14011. State = [[ 0.33092132 -0.12247205]]. Action = [[ 0.07658029  0.01412036  0.         -0.90033007]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 14011 is [False, False, True, False, True, False]
Current timestep = 14012. State = [[ 0.33025646 -0.12383795]]. Action = [[-0.00705715 -0.05176263  0.         -0.93368596]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 14012 is [False, False, True, False, True, False]
Current timestep = 14013. State = [[ 0.32603097 -0.12440357]]. Action = [[-0.06893508  0.03181828  0.          0.02033317]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 14013 is [False, False, True, False, True, False]
Current timestep = 14014. State = [[ 0.3235502 -0.1243393]]. Action = [[ 0.02899755 -0.01834415  0.          0.07382405]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 14014 is [False, False, True, False, True, False]
Current timestep = 14015. State = [[ 0.32530504 -0.12121388]]. Action = [[ 0.08304123  0.06898589  0.         -0.72635645]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 14015 is [False, False, True, False, True, False]
Current timestep = 14016. State = [[ 0.32703722 -0.1223233 ]]. Action = [[ 0.08669486 -0.09466758  0.         -0.99006855]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 14016 is [False, False, True, False, True, False]
State prediction error at timestep 14016 is 0.012
Human Feedback received at timestep 14016 of None
Current timestep = 14017. State = [[ 0.325444   -0.12730539]]. Action = [[-0.05152685 -0.04794086  0.         -0.8718008 ]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 14017 is [False, False, True, False, True, False]
Current timestep = 14018. State = [[ 0.32376686 -0.12868726]]. Action = [[ 0.01814167  0.02326415  0.         -0.78753734]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 14018 is [False, False, True, True, False, False]
Current timestep = 14019. State = [[ 0.3217146  -0.12478694]]. Action = [[-0.04724397  0.08145607  0.         -0.7527765 ]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 14019 is [False, False, True, True, False, False]
Current timestep = 14020. State = [[ 0.32092917 -0.11882336]]. Action = [[ 0.06713154  0.04309007  0.         -0.937551  ]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 14020 is [False, False, True, False, True, False]
State prediction error at timestep 14020 is 0.012
Human Feedback received at timestep 14020 of None
Current timestep = 14021. State = [[ 0.3221771  -0.11266145]]. Action = [[ 0.04469564  0.0840457   0.         -0.38581824]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 14021 is [False, False, True, False, True, False]
Current timestep = 14022. State = [[ 0.32332423 -0.11210822]]. Action = [[ 0.04690876 -0.06439081  0.         -0.954523  ]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 14022 is [False, False, True, False, True, False]
Current timestep = 14023. State = [[ 0.32346863 -0.11444627]]. Action = [[ 0.0152787  -0.05262741  0.         -0.60418737]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 14023 is [False, False, True, False, True, False]
Current timestep = 14024. State = [[ 0.3217116  -0.11991467]]. Action = [[-0.02748728 -0.08868355  0.         -0.7536206 ]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 14024 is [False, False, True, False, True, False]
Current timestep = 14025. State = [[ 0.32117867 -0.1246782 ]]. Action = [[ 0.02564698 -0.01772641  0.         -0.9568387 ]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 14025 is [False, False, True, False, True, False]
Current timestep = 14026. State = [[ 0.31907776 -0.13137296]]. Action = [[-0.05331472 -0.09276655  0.          0.6926266 ]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 14026 is [False, False, True, False, True, False]
Current timestep = 14027. State = [[ 0.3177114  -0.13576138]]. Action = [[ 0.0044621   0.00772431  0.         -0.96830636]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 14027 is [False, False, True, True, False, False]
Current timestep = 14028. State = [[ 0.3182307  -0.13695413]]. Action = [[ 0.02520303  0.00116052  0.         -0.98395985]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 14028 is [False, False, True, True, False, False]
Current timestep = 14029. State = [[ 0.3161509  -0.13755384]]. Action = [[-0.05379708  0.0099612   0.          0.4272052 ]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 14029 is [False, False, True, True, False, False]
Current timestep = 14030. State = [[ 0.3160032  -0.14168245]]. Action = [[ 0.0761858  -0.09278386  0.         -0.98776436]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 14030 is [False, False, True, True, False, False]
Current timestep = 14031. State = [[ 0.3190978  -0.14675638]]. Action = [[ 0.06453853 -0.02606351  0.         -0.9538549 ]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 14031 is [False, False, True, True, False, False]
Current timestep = 14032. State = [[ 0.31941375 -0.14804812]]. Action = [[-0.00550197 -0.00402492  0.         -0.9906376 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 14032 is [False, False, True, True, False, False]
Current timestep = 14033. State = [[ 0.32025   -0.1522285]]. Action = [[ 0.04558671 -0.07483581  0.         -0.9524833 ]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 14033 is [False, False, True, True, False, False]
Current timestep = 14034. State = [[ 0.32128575 -0.15732703]]. Action = [[ 0.03150659 -0.06132733  0.         -0.6895783 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 14034 is [False, False, True, True, False, False]
Current timestep = 14035. State = [[ 0.3219594  -0.16227254]]. Action = [[ 0.02795263 -0.06606145  0.         -0.9656566 ]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 14035 is [False, False, True, True, False, False]
Current timestep = 14036. State = [[ 0.323806   -0.16550894]]. Action = [[ 0.08479557 -0.03747646  0.         -0.28195947]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 14036 is [False, False, True, True, False, False]
Current timestep = 14037. State = [[ 0.32479796 -0.16660205]]. Action = [[ 0.03799929 -0.01258137  0.         -0.9966969 ]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 14037 is [False, False, True, True, False, False]
Current timestep = 14038. State = [[ 0.32602924 -0.16387968]]. Action = [[ 0.06101521  0.07654116  0.         -0.93809813]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 14038 is [False, False, True, True, False, False]
State prediction error at timestep 14038 is 0.012
Human Feedback received at timestep 14038 of None
Current timestep = 14039. State = [[ 0.32795146 -0.16226368]]. Action = [[ 0.08455152 -0.01569488  0.          0.478395  ]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 14039 is [False, False, True, True, False, False]
Current timestep = 14040. State = [[ 0.32695937 -0.1658721 ]]. Action = [[-0.05144876 -0.0747395   0.         -0.89238167]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 14040 is [False, False, True, True, False, False]
Current timestep = 14041. State = [[ 0.3263605  -0.17074355]]. Action = [[ 0.08498663 -0.06619844  0.         -0.9990945 ]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 14041 is [False, False, True, True, False, False]
Current timestep = 14042. State = [[ 0.3281177  -0.17447408]]. Action = [[ 0.081473   -0.07078524  0.         -0.7519473 ]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 14042 is [False, False, True, True, False, False]
Current timestep = 14043. State = [[ 0.32957384 -0.17830011]]. Action = [[ 0.07208224 -0.07221286  0.          0.44692647]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 14043 is [False, False, True, True, False, False]
Current timestep = 14044. State = [[ 0.32982993 -0.17750004]]. Action = [[ 0.01561043  0.0474636   0.         -0.8620853 ]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 14044 is [False, False, True, True, False, False]
Current timestep = 14045. State = [[ 0.32999006 -0.17656033]]. Action = [[ 0.0604834  -0.01376239  0.         -0.4231522 ]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 14045 is [False, False, True, True, False, False]
Current timestep = 14046. State = [[ 0.3309887  -0.17620765]]. Action = [[ 0.08562917 -0.00725808  0.         -0.67895484]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 14046 is [False, False, True, True, False, False]
Current timestep = 14047. State = [[ 0.33251256 -0.17375861]]. Action = [[0.08895665 0.03231371 0.         0.5908387 ]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 14047 is [False, False, True, True, False, False]
Current timestep = 14048. State = [[ 0.33419904 -0.16878638]]. Action = [[ 0.07946122  0.08567946  0.         -0.41927004]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 14048 is [False, False, True, True, False, False]
State prediction error at timestep 14048 is 0.012
Human Feedback received at timestep 14048 of None
Current timestep = 14049. State = [[ 0.33529347 -0.16550072]]. Action = [[ 0.07522879 -0.00529863  0.         -0.6677573 ]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 14049 is [False, False, True, True, False, False]
Current timestep = 14050. State = [[ 0.33544344 -0.16116591]]. Action = [[0.02358773 0.08404452 0.         0.0423739 ]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 14050 is [False, False, True, True, False, False]
Current timestep = 14051. State = [[ 0.3354756 -0.16094  ]]. Action = [[ 0.0730213  -0.06851701  0.         -0.40807003]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 14051 is [False, False, True, True, False, False]
Current timestep = 14052. State = [[ 0.33550778 -0.16225505]]. Action = [[ 0.03522969 -0.00479696  0.         -0.7079699 ]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 14052 is [False, False, True, True, False, False]
Current timestep = 14053. State = [[ 0.33586964 -0.15946832]]. Action = [[ 0.06400908  0.0751416   0.         -0.9415897 ]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 14053 is [False, False, True, True, False, False]
Current timestep = 14054. State = [[ 0.33596587 -0.16188504]]. Action = [[ 0.03367429 -0.0929428   0.         -0.99576247]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 14054 is [False, False, True, True, False, False]
State prediction error at timestep 14054 is 0.012
Human Feedback received at timestep 14054 of None
Current timestep = 14055. State = [[ 0.33491984 -0.16212794]]. Action = [[-0.00631706  0.05524764  0.         -0.9873674 ]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 14055 is [False, False, True, True, False, False]
State prediction error at timestep 14055 is 0.012
Human Feedback received at timestep 14055 of None
Current timestep = 14056. State = [[ 0.33426023 -0.16313092]]. Action = [[ 0.0934087  -0.08110949  0.         -0.66670823]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 14056 is [False, False, True, True, False, False]
Current timestep = 14057. State = [[ 0.3345151  -0.16260226]]. Action = [[ 0.05987585  0.04306138  0.         -0.9780308 ]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 14057 is [False, False, True, True, False, False]
Current timestep = 14058. State = [[ 0.332907   -0.16010784]]. Action = [[-0.03508443  0.0528832   0.         -0.6313671 ]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 14058 is [False, False, True, True, False, False]
Current timestep = 14059. State = [[ 0.33145267 -0.16077222]]. Action = [[ 0.07802393 -0.08262118  0.          0.02286553]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 14059 is [False, False, True, True, False, False]
Current timestep = 14060. State = [[ 0.33125848 -0.16174178]]. Action = [[ 0.01142738 -0.00070854  0.         -0.08685255]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 14060 is [False, False, True, True, False, False]
State prediction error at timestep 14060 is 0.012
Human Feedback received at timestep 14060 of None
Current timestep = 14061. State = [[ 0.33101863 -0.1638994 ]]. Action = [[ 0.01754165 -0.05302507  0.         -0.7810393 ]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 14061 is [False, False, True, True, False, False]
Current timestep = 14062. State = [[ 0.33163086 -0.16610697]]. Action = [[ 0.09851087 -0.06094399  0.         -0.3264547 ]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 14062 is [False, False, True, True, False, False]
Current timestep = 14063. State = [[ 0.33277327 -0.16360483]]. Action = [[ 0.07461948  0.06474195  0.         -0.91387   ]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 14063 is [False, False, True, True, False, False]
Current timestep = 14064. State = [[ 0.3325842  -0.16146494]]. Action = [[ 0.00446822  0.01714192  0.         -0.97285974]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 14064 is [False, False, True, True, False, False]
Current timestep = 14065. State = [[ 0.3321925  -0.15937406]]. Action = [[ 0.0184628   0.03914111  0.         -0.8265182 ]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 14065 is [False, False, True, True, False, False]
Current timestep = 14066. State = [[ 0.33247876 -0.1607054 ]]. Action = [[ 0.08076029 -0.09452716  0.          0.35737514]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 14066 is [False, False, True, True, False, False]
Current timestep = 14067. State = [[ 0.33352736 -0.16077152]]. Action = [[ 0.08945855 -0.01028909  0.          0.05978715]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 14067 is [False, False, True, True, False, False]
Current timestep = 14068. State = [[ 0.33250496 -0.15713945]]. Action = [[-0.01466174  0.06054304  0.         -0.7994584 ]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 14068 is [False, False, True, True, False, False]
Current timestep = 14069. State = [[ 0.33217296 -0.1535694 ]]. Action = [[ 0.06078423  0.03422516  0.         -0.8617142 ]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 14069 is [False, False, True, True, False, False]
Current timestep = 14070. State = [[ 0.3326963  -0.15486945]]. Action = [[ 0.06364072 -0.08203951  0.         -0.42612934]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 14070 is [False, False, True, True, False, False]
Current timestep = 14071. State = [[ 0.33157346 -0.15902343]]. Action = [[-0.00655426 -0.06326836  0.         -0.9118719 ]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 14071 is [False, False, True, True, False, False]
Current timestep = 14072. State = [[ 0.33166322 -0.15845971]]. Action = [[ 0.06734588  0.04753727  0.         -0.299621  ]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 14072 is [False, False, True, True, False, False]
Current timestep = 14073. State = [[ 0.33249325 -0.15695702]]. Action = [[ 0.07323188 -0.01626291  0.          0.10582459]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 14073 is [False, False, True, True, False, False]
Current timestep = 14074. State = [[ 0.33049715 -0.1599042 ]]. Action = [[-0.03152028 -0.06262521  0.         -0.9824194 ]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 14074 is [False, False, True, True, False, False]
Current timestep = 14075. State = [[ 0.32896307 -0.16490301]]. Action = [[ 0.01940266 -0.05393826  0.         -0.9467898 ]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 14075 is [False, False, True, True, False, False]
Current timestep = 14076. State = [[ 0.3296789 -0.1672633]]. Action = [[ 0.06353319 -0.02956794  0.         -0.88998413]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 14076 is [False, False, True, True, False, False]
Current timestep = 14077. State = [[ 0.3281013  -0.17124759]]. Action = [[-0.02819276 -0.06301723  0.         -0.48099953]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 14077 is [False, False, True, True, False, False]
State prediction error at timestep 14077 is 0.012
Human Feedback received at timestep 14077 of None
Current timestep = 14078. State = [[ 0.3275635  -0.17567164]]. Action = [[ 0.07833429 -0.06001497  0.         -0.96863204]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 14078 is [False, False, True, True, False, False]
Current timestep = 14079. State = [[ 0.3286488 -0.1792711]]. Action = [[ 0.06217957 -0.06746699  0.         -0.94185805]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 14079 is [False, False, True, True, False, False]
State prediction error at timestep 14079 is 0.012
Human Feedback received at timestep 14079 of None
Current timestep = 14080. State = [[ 0.3268526  -0.18143621]]. Action = [[-0.03980844  0.00141436  0.          0.4446876 ]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 14080 is [False, False, True, True, False, False]
Current timestep = 14081. State = [[ 0.3264134  -0.17905094]]. Action = [[ 0.08110104  0.06737103  0.         -0.9307041 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 14081 is [False, False, True, True, False, False]
Current timestep = 14082. State = [[ 0.32577536 -0.17376386]]. Action = [[-0.0178557   0.07922404  0.         -0.9890647 ]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 14082 is [False, False, True, True, False, False]
State prediction error at timestep 14082 is 0.012
Human Feedback received at timestep 14082 of None
Current timestep = 14083. State = [[ 0.3236682 -0.1705709]]. Action = [[-0.01105167 -0.00045629  0.         -0.32438022]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 14083 is [False, False, True, True, False, False]
State prediction error at timestep 14083 is 0.012
Human Feedback received at timestep 14083 of None
Current timestep = 14084. State = [[ 0.32369563 -0.17368637]]. Action = [[ 0.04996138 -0.0965897   0.         -0.9355068 ]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 14084 is [False, False, True, True, False, False]
Current timestep = 14085. State = [[ 0.32615045 -0.17168814]]. Action = [[ 0.08297066  0.07191982  0.         -0.98736936]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 14085 is [False, False, True, True, False, False]
Current timestep = 14086. State = [[ 0.32742965 -0.1709257 ]]. Action = [[ 0.04625783 -0.05539429  0.         -0.99912095]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 14086 is [False, False, True, True, False, False]
Current timestep = 14087. State = [[ 0.32763317 -0.16806856]]. Action = [[ 0.03092549  0.08276076  0.         -0.05969286]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 14087 is [False, False, True, True, False, False]
Current timestep = 14088. State = [[ 0.32864583 -0.16519727]]. Action = [[ 0.07718635  0.0034907   0.         -0.95995826]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 14088 is [False, False, True, True, False, False]
State prediction error at timestep 14088 is 0.012
Human Feedback received at timestep 14088 of None
Current timestep = 14089. State = [[ 0.33021027 -0.16442789]]. Action = [[ 0.06621499 -0.00460638  0.         -0.99495614]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 14089 is [False, False, True, True, False, False]
Current timestep = 14090. State = [[ 0.33150813 -0.16682741]]. Action = [[ 0.08345153 -0.07890519  0.         -0.8966765 ]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 14090 is [False, False, True, True, False, False]
State prediction error at timestep 14090 is 0.012
Human Feedback received at timestep 14090 of None
Current timestep = 14091. State = [[ 0.33060977 -0.1655651 ]]. Action = [[-0.03195331  0.07714958  0.          0.28018892]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 14091 is [False, False, True, True, False, False]
Current timestep = 14092. State = [[ 0.33007047 -0.16098437]]. Action = [[ 0.05395287  0.05578095  0.         -0.95746166]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 14092 is [False, False, True, True, False, False]
Current timestep = 14093. State = [[ 0.33044454 -0.15907183]]. Action = [[ 0.04197558  0.00626807  0.         -0.9933593 ]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 14093 is [False, False, True, True, False, False]
State prediction error at timestep 14093 is 0.012
Human Feedback received at timestep 14093 of None
Current timestep = 14094. State = [[ 0.33161694 -0.15650618]]. Action = [[ 0.09209866  0.02804659  0.         -0.99800473]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 14094 is [False, False, True, True, False, False]
State prediction error at timestep 14094 is 0.012
Human Feedback received at timestep 14094 of None
Current timestep = 14095. State = [[ 0.33288646 -0.15602604]]. Action = [[ 0.07496179 -0.03385483  0.         -0.95974344]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 14095 is [False, False, True, True, False, False]
Current timestep = 14096. State = [[ 0.33409137 -0.15628642]]. Action = [[ 0.09707666 -0.01659326  0.         -0.8759625 ]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 14096 is [False, False, True, True, False, False]
Current timestep = 14097. State = [[ 0.33432153 -0.15687555]]. Action = [[ 0.03334979 -0.01030457  0.         -0.9397681 ]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 14097 is [False, False, True, True, False, False]
Current timestep = 14098. State = [[ 0.3343305 -0.1551743]]. Action = [[0.04160912 0.06403353 0.         0.447649  ]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 14098 is [False, False, True, True, False, False]
Current timestep = 14099. State = [[ 0.33431265 -0.15785886]]. Action = [[ 0.02687363 -0.09315508  0.         -0.78677297]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 14099 is [False, False, True, True, False, False]
Current timestep = 14100. State = [[ 0.33431414 -0.15902327]]. Action = [[0.05100412 0.01283668 0.         0.13487637]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 14100 is [False, False, True, True, False, False]
Current timestep = 14101. State = [[ 0.33490214 -0.1565634 ]]. Action = [[ 0.09126253  0.03115172  0.         -0.49680626]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 14101 is [False, False, True, True, False, False]
State prediction error at timestep 14101 is 0.012
Human Feedback received at timestep 14101 of None
Current timestep = 14102. State = [[ 0.33506104 -0.15661623]]. Action = [[ 0.03593645 -0.02671232  0.         -0.6405235 ]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 14102 is [False, False, True, True, False, False]
State prediction error at timestep 14102 is 0.012
Human Feedback received at timestep 14102 of None
Current timestep = 14103. State = [[ 0.33267736 -0.15684149]]. Action = [[-0.07279464  0.0290019   0.          0.17671764]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 14103 is [False, False, True, True, False, False]
State prediction error at timestep 14103 is 0.012
Human Feedback received at timestep 14103 of None
Current timestep = 14104. State = [[ 0.33094963 -0.15406728]]. Action = [[0.07162947 0.02345932 0.         0.04765892]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 14104 is [False, False, True, True, False, False]
Current timestep = 14105. State = [[ 0.3320754  -0.15229082]]. Action = [[ 0.08519179 -0.01407942  0.          0.19634199]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 14105 is [False, False, True, True, False, False]
Current timestep = 14106. State = [[ 0.33227277 -0.15032338]]. Action = [[ 0.01755212  0.02347279  0.         -0.9527143 ]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 14106 is [False, False, True, True, False, False]
Current timestep = 14107. State = [[ 0.33076784 -0.15394609]]. Action = [[-0.01379365 -0.09178811  0.         -0.873366  ]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 14107 is [False, False, True, True, False, False]
Current timestep = 14108. State = [[ 0.3306322  -0.15749238]]. Action = [[ 0.07229174 -0.02621315  0.         -0.9985114 ]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 14108 is [False, False, True, True, False, False]
State prediction error at timestep 14108 is 0.012
Human Feedback received at timestep 14108 of None
Current timestep = 14109. State = [[ 0.33086032 -0.15889974]]. Action = [[ 0.02638041 -0.01108647  0.         -0.9196229 ]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 14109 is [False, False, True, True, False, False]
Current timestep = 14110. State = [[ 0.33141068 -0.16156131]]. Action = [[ 0.09312535 -0.07472434  0.         -0.9841813 ]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 14110 is [False, False, True, True, False, False]
Current timestep = 14111. State = [[ 0.32899055 -0.16816641]]. Action = [[-0.04674126 -0.0863798   0.          0.2508042 ]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 14111 is [False, False, True, True, False, False]
Current timestep = 14112. State = [[ 0.3277654  -0.17297131]]. Action = [[ 0.08863956 -0.02430647  0.         -0.9244495 ]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 14112 is [False, False, True, True, False, False]
State prediction error at timestep 14112 is 0.012
Human Feedback received at timestep 14112 of None
Current timestep = 14113. State = [[ 0.32807854 -0.1717694 ]]. Action = [[ 0.0346125   0.05891041  0.         -0.8914198 ]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 14113 is [False, False, True, True, False, False]
State prediction error at timestep 14113 is 0.012
Human Feedback received at timestep 14113 of None
Current timestep = 14114. State = [[ 0.32864055 -0.17324927]]. Action = [[ 0.06456318 -0.06810199  0.         -0.711591  ]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 14114 is [False, False, True, True, False, False]
Current timestep = 14115. State = [[ 0.32979506 -0.17104624]]. Action = [[ 0.05970176  0.08595388  0.         -0.8591963 ]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 14115 is [False, False, True, True, False, False]
Current timestep = 14116. State = [[ 0.33136016 -0.16945438]]. Action = [[ 0.09368075 -0.03424767  0.         -0.6728251 ]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 14116 is [False, False, True, True, False, False]
Current timestep = 14117. State = [[ 0.33259755 -0.1724038 ]]. Action = [[ 0.06736035 -0.09163106  0.         -0.897406  ]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 14117 is [False, False, True, True, False, False]
Current timestep = 14118. State = [[ 0.33410582 -0.17119426]]. Action = [[ 0.09436519  0.04618425  0.         -0.530312  ]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 14118 is [False, False, True, True, False, False]
State prediction error at timestep 14118 is 0.012
Human Feedback received at timestep 14118 of None
Current timestep = 14119. State = [[ 0.33244845 -0.17010473]]. Action = [[-0.07772894  0.01452085  0.         -0.6933627 ]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 14119 is [False, False, True, True, False, False]
Current timestep = 14120. State = [[ 0.3309633  -0.16997112]]. Action = [[ 0.06227405 -0.01667207  0.          0.5137119 ]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 14120 is [False, False, True, True, False, False]
State prediction error at timestep 14120 is 0.012
Human Feedback received at timestep 14120 of None
Current timestep = 14121. State = [[ 0.33154064 -0.17228462]]. Action = [[ 0.06292612 -0.08358985  0.         -0.9781972 ]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 14121 is [False, False, True, True, False, False]
Current timestep = 14122. State = [[ 0.33193907 -0.17441885]]. Action = [[ 0.04982708 -0.03107973  0.         -0.8190622 ]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 14122 is [False, False, True, True, False, False]
Current timestep = 14123. State = [[ 0.3314004  -0.17715864]]. Action = [[ 0.00414826 -0.05679566  0.         -0.9362532 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 14123 is [False, False, True, True, False, False]
Current timestep = 14124. State = [[ 0.33152187 -0.17750593]]. Action = [[ 0.06686831  0.00907244  0.         -0.02111834]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 14124 is [False, False, True, True, False, False]
State prediction error at timestep 14124 is 0.012
Human Feedback received at timestep 14124 of None
Current timestep = 14125. State = [[ 0.33239353 -0.17327833]]. Action = [[ 0.06183351  0.07765832  0.         -0.42291903]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 14125 is [False, False, True, True, False, False]
Current timestep = 14126. State = [[ 0.3336513  -0.17092302]]. Action = [[ 0.09618426 -0.00849057  0.         -0.7905663 ]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 14126 is [False, False, True, True, False, False]
Current timestep = 14127. State = [[ 0.33493423 -0.16903262]]. Action = [[0.08577128 0.00279354 0.         0.6808057 ]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 14127 is [False, False, True, True, False, False]
State prediction error at timestep 14127 is 0.012
Human Feedback received at timestep 14127 of None
Current timestep = 14128. State = [[ 0.33486485 -0.1706733 ]]. Action = [[ 0.01242039 -0.07823338  0.          0.4630115 ]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 14128 is [False, False, True, True, False, False]
Current timestep = 14129. State = [[ 0.33465582 -0.17202814]]. Action = [[ 0.03557979 -0.01735085  0.         -0.98645145]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 14129 is [False, False, True, True, False, False]
Current timestep = 14130. State = [[ 0.33506373 -0.17108968]]. Action = [[ 0.08184344 -0.00351648  0.         -0.18952167]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 14130 is [False, False, True, True, False, False]
Current timestep = 14131. State = [[ 0.335186   -0.17406353]]. Action = [[ 0.04605255 -0.09506347  0.         -0.5221275 ]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 14131 is [False, False, True, True, False, False]
State prediction error at timestep 14131 is 0.012
Human Feedback received at timestep 14131 of None
Current timestep = 14132. State = [[ 0.3335093  -0.17378135]]. Action = [[-0.03745335  0.05716116  0.          0.26220703]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 14132 is [False, False, True, True, False, False]
Current timestep = 14133. State = [[ 0.3317776  -0.17481133]]. Action = [[ 0.06160433 -0.07987711  0.          0.1576767 ]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 14133 is [False, False, True, True, False, False]
Current timestep = 14134. State = [[ 0.3325466  -0.17231251]]. Action = [[ 0.06805146  0.05863864  0.         -0.16747546]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 14134 is [False, False, True, True, False, False]
Current timestep = 14135. State = [[ 0.33263877 -0.17168756]]. Action = [[ 0.01200076 -0.03852372  0.         -0.9176964 ]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 14135 is [False, False, True, True, False, False]
Current timestep = 14136. State = [[ 0.33257344 -0.17425856]]. Action = [[ 0.04236009 -0.05898152  0.         -0.9947634 ]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 14136 is [False, False, True, True, False, False]
Current timestep = 14137. State = [[ 0.33303684 -0.1762866 ]]. Action = [[ 0.07360489 -0.04814015  0.         -0.61197376]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 14137 is [False, False, True, True, False, False]
Current timestep = 14138. State = [[ 0.33373335 -0.17668177]]. Action = [[ 0.06819559 -0.01388298  0.         -0.992684  ]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 14138 is [False, False, True, True, False, False]
Current timestep = 14139. State = [[ 0.33405593 -0.17896006]]. Action = [[ 0.07958173 -0.08886027  0.         -0.59920055]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 14139 is [False, False, True, True, False, False]
State prediction error at timestep 14139 is 0.012
Human Feedback received at timestep 14139 of None
Current timestep = 14140. State = [[ 0.3343593  -0.18234266]]. Action = [[ 0.086124   -0.08740434  0.         -0.9796655 ]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 14140 is [False, False, True, True, False, False]
Current timestep = 14141. State = [[ 0.3347957 -0.1819142]]. Action = [[ 0.08088944  0.02120544  0.         -0.74923396]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 14141 is [False, False, True, True, False, False]
Current timestep = 14142. State = [[ 0.33509594 -0.1833637 ]]. Action = [[ 0.09499759 -0.0932204   0.         -0.9667227 ]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 14142 is [False, False, True, True, False, False]
Current timestep = 14143. State = [[ 0.33333516 -0.18215185]]. Action = [[-0.04261827  0.06420221  0.         -0.9916683 ]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 14143 is [False, False, True, True, False, False]
State prediction error at timestep 14143 is 0.012
Human Feedback received at timestep 14143 of None
Current timestep = 14144. State = [[ 0.33216134 -0.18025129]]. Action = [[ 0.08364702 -0.02054084  0.         -0.35548127]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 14144 is [False, False, True, True, False, False]
Current timestep = 14145. State = [[ 0.3327574  -0.17868516]]. Action = [[ 0.0584806  0.0291918  0.        -0.1977793]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 14145 is [False, False, True, True, False, False]
Current timestep = 14146. State = [[ 0.33306244 -0.17953849]]. Action = [[ 0.05479614 -0.07568034  0.         -0.78536355]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 14146 is [False, False, True, True, False, False]
Current timestep = 14147. State = [[ 0.33366442 -0.17923531]]. Action = [[ 0.0791245  -0.00295465  0.         -0.95124215]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 14147 is [False, False, True, True, False, False]
Current timestep = 14148. State = [[ 0.3343481  -0.17776062]]. Action = [[ 0.09635299 -0.01418493  0.         -0.9364777 ]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 14148 is [False, False, True, True, False, False]
Current timestep = 14149. State = [[ 0.33435902 -0.18038456]]. Action = [[ 0.01851167 -0.08727681  0.          0.7130127 ]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 14149 is [False, False, True, True, False, False]
Current timestep = 14150. State = [[ 0.3310082 -0.1872526]]. Action = [[-0.0512916  -0.08556733  0.         -0.9301615 ]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 14150 is [False, False, True, True, False, False]
State prediction error at timestep 14150 is 0.012
Human Feedback received at timestep 14150 of None
Current timestep = 14151. State = [[ 0.3288729  -0.19615884]]. Action = [[ 0.03817999 -0.09658737  0.         -0.8815762 ]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 14151 is [False, False, True, True, False, False]
Current timestep = 14152. State = [[ 0.32994032 -0.19725266]]. Action = [[0.07714646 0.03816136 0.         0.31740427]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 14152 is [False, False, True, True, False, False]
Current timestep = 14153. State = [[ 0.33052507 -0.19855432]]. Action = [[ 0.06865647 -0.08396292  0.         -0.60286045]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 14153 is [False, False, True, True, False, False]
State prediction error at timestep 14153 is 0.012
Human Feedback received at timestep 14153 of None
Current timestep = 14154. State = [[ 0.33078286 -0.20287523]]. Action = [[ 0.06624617 -0.09708196  0.         -0.9247723 ]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 14154 is [False, False, True, True, False, False]
State prediction error at timestep 14154 is 0.012
Human Feedback received at timestep 14154 of None
Current timestep = 14155. State = [[ 0.33087173 -0.20396152]]. Action = [[ 0.03509945  0.0030422   0.         -0.87294126]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 14155 is [False, False, True, True, False, False]
Current timestep = 14156. State = [[ 0.32806212 -0.20788723]]. Action = [[-0.04632132 -0.08199102  0.         -0.9499223 ]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 14156 is [False, False, True, True, False, False]
Current timestep = 14157. State = [[ 0.3262536 -0.2152854]]. Action = [[ 0.04050363 -0.07723938  0.         -0.42192298]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 14157 is [False, False, True, True, False, False]
Current timestep = 14158. State = [[ 0.3269858  -0.21720496]]. Action = [[ 0.05956174 -0.00539909  0.         -0.5707819 ]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 14158 is [False, False, True, True, False, False]
State prediction error at timestep 14158 is 0.012
Human Feedback received at timestep 14158 of None
Current timestep = 14159. State = [[ 0.32713452 -0.21390852]]. Action = [[0.01304744 0.09187526 0.         0.64213884]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 14159 is [False, False, True, True, False, False]
Current timestep = 14160. State = [[ 0.3236487 -0.2156293]]. Action = [[-0.07916383 -0.05918751  0.          0.29744124]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 14160 is [False, False, True, True, False, False]
State prediction error at timestep 14160 is 0.012
Human Feedback received at timestep 14160 of None
Current timestep = 14161. State = [[ 0.31987014 -0.22252272]]. Action = [[-0.02247898 -0.08168825  0.         -0.534577  ]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 14161 is [False, False, True, True, False, False]
Current timestep = 14162. State = [[ 0.31963524 -0.22206952]]. Action = [[ 0.03983987  0.08580392  0.         -0.7409204 ]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 14162 is [False, False, True, True, False, False]
Current timestep = 14163. State = [[ 0.32156587 -0.2230178 ]]. Action = [[ 0.06991065 -0.08449509  0.         -0.9976245 ]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 14163 is [False, False, True, True, False, False]
Current timestep = 14164. State = [[ 0.32318527 -0.2276615 ]]. Action = [[ 0.07106336 -0.08829005  0.         -0.6379293 ]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 14164 is [False, False, True, True, False, False]
Current timestep = 14165. State = [[ 0.32188627 -0.2330247 ]]. Action = [[-0.04940776 -0.05479028  0.         -0.9985877 ]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 14165 is [False, False, True, True, False, False]
Current timestep = 14166. State = [[ 0.3213897 -0.235349 ]]. Action = [[ 0.09455309 -0.0113049   0.         -0.8311648 ]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 14166 is [False, False, True, True, False, False]
Current timestep = 14167. State = [[ 0.32222027 -0.23819512]]. Action = [[ 0.040239   -0.07612021  0.         -0.9181015 ]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 14167 is [False, False, True, True, False, False]
State prediction error at timestep 14167 is 0.012
Human Feedback received at timestep 14167 of None
Current timestep = 14168. State = [[ 0.32303947 -0.24346447]]. Action = [[ 0.04801538 -0.09785392  0.          0.94543624]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 14168 is [False, False, True, True, False, False]
State prediction error at timestep 14168 is 0.012
Human Feedback received at timestep 14168 of None
Current timestep = 14169. State = [[ 0.32026595 -0.25178263]]. Action = [[-0.06300195 -0.09829506  0.         -0.801327  ]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 14169 is [False, False, True, True, False, False]
Current timestep = 14170. State = [[ 0.3184463  -0.26061618]]. Action = [[ 0.05269171 -0.07511602  0.         -0.54638743]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 14170 is [False, False, True, True, False, False]
State prediction error at timestep 14170 is 0.012
Human Feedback received at timestep 14170 of None
Current timestep = 14171. State = [[ 0.318915   -0.26399976]]. Action = [[ 0.04163537 -0.00536866  0.         -0.85139   ]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 14171 is [False, False, True, True, False, False]
Current timestep = 14172. State = [[ 0.31978756 -0.26509652]]. Action = [[ 0.08605409 -0.04266015  0.         -0.41169226]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 14172 is [False, False, True, True, False, False]
Current timestep = 14173. State = [[ 0.31864664 -0.27082518]]. Action = [[-0.01625463 -0.0992369   0.         -0.740342  ]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 14173 is [False, False, True, True, False, False]
Current timestep = 14174. State = [[ 0.31850386 -0.27788416]]. Action = [[ 0.07446636 -0.09302419  0.         -0.921339  ]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 14174 is [False, False, True, True, False, False]
Current timestep = 14175. State = [[ 0.31980106 -0.2822861 ]]. Action = [[ 0.07677381 -0.0696788   0.          0.6746396 ]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 14175 is [False, False, True, True, False, False]
Current timestep = 14176. State = [[ 0.32173145 -0.2798324 ]]. Action = [[ 0.08332974  0.09080071  0.         -0.6742033 ]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 14176 is [False, False, True, True, False, False]
Current timestep = 14177. State = [[ 0.32247904 -0.2806771 ]]. Action = [[ 0.04179136 -0.07427271  0.         -0.29826307]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 14177 is [False, False, True, True, False, False]
Current timestep = 14178. State = [[ 0.32077003 -0.2844264 ]]. Action = [[-0.02002843 -0.06437854  0.         -0.8557066 ]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 14178 is [False, False, True, True, False, False]
Current timestep = 14179. State = [[ 0.31999016 -0.28873298]]. Action = [[ 0.04257066 -0.06755278  0.         -0.9879844 ]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 14179 is [False, False, True, True, False, False]
State prediction error at timestep 14179 is 0.012
Human Feedback received at timestep 14179 of None
Current timestep = 14180. State = [[ 0.32002714 -0.29131052]]. Action = [[ 0.03084321 -0.05552761  0.         -0.21881956]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 14180 is [False, False, True, True, False, False]
Current timestep = 14181. State = [[ 0.32061946 -0.29371777]]. Action = [[ 0.05585734 -0.08362748  0.          0.45994663]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 14181 is [False, False, True, True, False, False]
Current timestep = 14182. State = [[ 0.32089463 -0.29470322]]. Action = [[ 0.04339527 -0.02376141  0.         -0.44565988]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 14182 is [False, False, True, True, False, False]
Current timestep = 14183. State = [[ 0.32129794 -0.2951344 ]]. Action = [[ 0.0822156  -0.08148414  0.          0.84675145]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 14183 is [False, False, True, True, False, False]
State prediction error at timestep 14183 is 0.012
Human Feedback received at timestep 14183 of None
Current timestep = 14184. State = [[ 0.32191136 -0.2971369 ]]. Action = [[ 0.07449498 -0.09645436  0.         -0.5564985 ]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 14184 is [False, False, True, True, False, False]
State prediction error at timestep 14184 is 0.012
Human Feedback received at timestep 14184 of None
Current timestep = 14185. State = [[ 0.32001656 -0.29768693]]. Action = [[-0.03902537  0.01989494  0.         -0.9324463 ]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 14185 is [False, False, True, True, False, False]
Current timestep = 14186. State = [[ 0.3185063 -0.2968607]]. Action = [[ 0.02847631  0.0053661   0.         -0.99380136]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 14186 is [False, False, True, True, False, False]
Current timestep = 14187. State = [[ 0.31807828 -0.29714662]]. Action = [[ 0.00451406 -0.03352553  0.          0.7302567 ]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 14187 is [False, False, True, True, False, False]
Current timestep = 14188. State = [[ 0.31838205 -0.2995205 ]]. Action = [[ 0.07696991 -0.09635882  0.         -0.13375151]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 14188 is [False, False, True, True, False, False]
Current timestep = 14189. State = [[ 0.3159335  -0.30288285]]. Action = [[-0.05045549 -0.03190803  0.         -0.8840555 ]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 14189 is [False, False, True, True, False, False]
Current timestep = 14190. State = [[ 0.313183   -0.30588317]]. Action = [[ 0.00451802 -0.02106974  0.          0.8690698 ]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 14190 is [False, False, True, True, False, False]
State prediction error at timestep 14190 is 0.012
Human Feedback received at timestep 14190 of None
Current timestep = 14191. State = [[ 0.31282046 -0.30413386]]. Action = [[ 0.01656906  0.05717147  0.         -0.91446114]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 14191 is [False, False, True, True, False, False]
Current timestep = 14192. State = [[ 0.31431478 -0.29919535]]. Action = [[ 0.06419048  0.0735933   0.         -0.9059533 ]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 14192 is [False, False, True, True, False, False]
Current timestep = 14193. State = [[ 0.3157743  -0.29933214]]. Action = [[ 0.07376539 -0.08203901  0.         -0.2725892 ]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 14193 is [False, False, True, True, False, False]
Current timestep = 14194. State = [[ 0.31465173 -0.30498993]]. Action = [[-0.01650193 -0.09445634  0.         -0.89421624]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 14194 is [False, False, True, True, False, False]
Current timestep = 14195. State = [[ 0.31394482 -0.30385244]]. Action = [[ 0.02759039  0.09702494  0.         -0.90931857]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 14195 is [False, False, True, True, False, False]
Current timestep = 14196. State = [[ 0.3118848  -0.30374125]]. Action = [[-0.0336799  -0.04722051  0.         -0.3311866 ]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 14196 is [False, False, True, True, False, False]
Current timestep = 14197. State = [[ 0.3113089  -0.30805668]]. Action = [[ 0.07263526 -0.08624468  0.         -0.2769435 ]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 14197 is [False, False, True, True, False, False]
State prediction error at timestep 14197 is 0.012
Human Feedback received at timestep 14197 of None
Current timestep = 14198. State = [[ 0.31270918 -0.307434  ]]. Action = [[0.05633282 0.05545076 0.         0.6919012 ]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 14198 is [False, False, True, True, False, False]
Current timestep = 14199. State = [[ 0.31362063 -0.30855194]]. Action = [[ 0.08136299 -0.09525453  0.         -0.24945712]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 14199 is [False, False, True, True, False, False]
Current timestep = 14200. State = [[ 0.31469256 -0.3116002 ]]. Action = [[ 0.0734129  -0.04961375  0.         -0.9266736 ]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 14200 is [False, False, True, True, False, False]
State prediction error at timestep 14200 is 0.012
Human Feedback received at timestep 14200 of None
Current timestep = 14201. State = [[ 0.31537017 -0.31589884]]. Action = [[ 0.05798764 -0.09897733  0.         -0.99601454]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 14201 is [False, False, True, True, False, False]
Current timestep = 14202. State = [[ 0.31591454 -0.32023755]]. Action = [[ 0.04074781 -0.07997831  0.         -0.96788055]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 14202 is [False, False, True, True, False, False]
Current timestep = 14203. State = [[ 0.31697997 -0.32394788]]. Action = [[ 0.07400956 -0.09863455  0.         -0.42674327]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 14203 is [False, False, True, True, False, False]
State prediction error at timestep 14203 is 0.012
Human Feedback received at timestep 14203 of None
Current timestep = 14204. State = [[ 0.3145582  -0.32768062]]. Action = [[-0.06174254 -0.02904073  0.         -0.9634449 ]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 14204 is [False, False, True, True, False, False]
Current timestep = 14205. State = [[ 0.31242618 -0.33198285]]. Action = [[ 0.06064444 -0.06961417  0.         -0.98914504]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 14205 is [False, False, True, True, False, False]
Current timestep = 14206. State = [[ 0.3126684  -0.33579516]]. Action = [[ 0.06048859 -0.0838729   0.         -0.9903536 ]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 14206 is [False, False, True, True, False, False]
State prediction error at timestep 14206 is 0.012
Human Feedback received at timestep 14206 of None
Current timestep = 14207. State = [[ 0.31285274 -0.3359645 ]]. Action = [[0.03341684 0.00123511 0.         0.10471427]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 14207 is [False, False, True, True, False, False]
Current timestep = 14208. State = [[ 0.31289598 -0.33366024]]. Action = [[0.03038142 0.0123658  0.         0.40832758]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 14208 is [False, False, True, True, False, False]
State prediction error at timestep 14208 is 0.012
Human Feedback received at timestep 14208 of None
Current timestep = 14209. State = [[ 0.31293142 -0.33117008]]. Action = [[ 3.1531967e-02  2.5612116e-04  0.0000000e+00 -8.1542289e-01]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 14209 is [False, False, True, True, False, False]
Current timestep = 14210. State = [[ 0.31150907 -0.3336738 ]]. Action = [[-0.02229147 -0.08784305  0.         -0.9879325 ]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 14210 is [False, False, True, True, False, False]
Current timestep = 14211. State = [[ 0.31125426 -0.3359534 ]]. Action = [[ 0.06425954 -0.00428475  0.         -0.8045359 ]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 14211 is [False, False, True, True, False, False]
State prediction error at timestep 14211 is 0.012
Human Feedback received at timestep 14211 of None
Current timestep = 14212. State = [[ 0.31255677 -0.33256593]]. Action = [[0.05917651 0.06531926 0.         0.9544661 ]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 14212 is [False, False, True, True, False, False]
Current timestep = 14213. State = [[ 0.3130368 -0.3317484]]. Action = [[ 0.04210822 -0.04055796  0.         -0.8216984 ]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 14213 is [False, False, True, True, False, False]
Current timestep = 14214. State = [[ 0.31247047 -0.33131328]]. Action = [[-0.00099359  0.01488143  0.          0.49612904]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 14214 is [False, False, True, True, False, False]
Current timestep = 14215. State = [[ 0.31307042 -0.32845563]]. Action = [[ 0.07836891  0.03246816  0.         -0.6288452 ]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 14215 is [False, False, True, True, False, False]
Current timestep = 14216. State = [[ 0.31483278 -0.3240856 ]]. Action = [[ 0.06389872  0.06725407  0.         -0.83347607]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 14216 is [False, False, True, True, False, False]
Current timestep = 14217. State = [[ 0.3149463  -0.32059428]]. Action = [[ 0.00589855  0.03615508  0.         -0.4129591 ]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 14217 is [False, False, True, True, False, False]
Current timestep = 14218. State = [[ 0.31198058 -0.31753698]]. Action = [[-0.05028421  0.03161646  0.         -0.90073454]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 14218 is [False, False, True, True, False, False]
Current timestep = 14219. State = [[ 0.31161758 -0.3109492 ]]. Action = [[0.04998346 0.07877249 0.         0.3065989 ]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 14219 is [False, False, True, True, False, False]
Current timestep = 14220. State = [[ 0.31092    -0.30424914]]. Action = [[-0.07076974  0.0798979   0.         -0.9167937 ]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 14220 is [False, False, True, True, False, False]
State prediction error at timestep 14220 is 0.012
Human Feedback received at timestep 14220 of None
Current timestep = 14221. State = [[ 0.30819473 -0.29846156]]. Action = [[-0.03612156  0.03538818  0.         -0.86333597]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 14221 is [False, False, True, True, False, False]
Current timestep = 14222. State = [[ 0.30571017 -0.29817963]]. Action = [[-0.04049195 -0.04952722  0.         -0.30425644]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 14222 is [False, False, True, True, False, False]
Current timestep = 14223. State = [[ 0.3067126  -0.29750055]]. Action = [[ 0.05128051  0.02212407  0.         -0.43748623]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 14223 is [False, False, True, True, False, False]
Current timestep = 14224. State = [[ 0.30620208 -0.2929696 ]]. Action = [[-0.08149391  0.08438811  0.         -0.98836726]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 14224 is [False, False, True, True, False, False]
State prediction error at timestep 14224 is 0.012
Human Feedback received at timestep 14224 of None
Current timestep = 14225. State = [[ 0.30586454 -0.29270425]]. Action = [[ 0.05437984 -0.08913475  0.         -0.75941545]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 14225 is [False, False, True, True, False, False]
State prediction error at timestep 14225 is 0.012
Human Feedback received at timestep 14225 of None
Current timestep = 14226. State = [[ 0.30752292 -0.2900118 ]]. Action = [[ 0.02476831  0.08248601  0.         -0.71294755]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 14226 is [False, False, True, True, False, False]
Current timestep = 14227. State = [[ 0.30671987 -0.28189057]]. Action = [[-0.0390644   0.09357021  0.         -0.7566478 ]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 14227 is [False, False, True, True, False, False]
State prediction error at timestep 14227 is 0.012
Human Feedback received at timestep 14227 of None
Current timestep = 14228. State = [[ 0.30541733 -0.2778447 ]]. Action = [[-0.0256422  -0.00597725  0.          0.91369987]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 14228 is [False, False, True, True, False, False]
Current timestep = 14229. State = [[ 0.30316493 -0.2756416 ]]. Action = [[-0.06024609  0.02742922  0.          0.5908992 ]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 14229 is [False, False, True, True, False, False]
Current timestep = 14230. State = [[ 0.3047569  -0.26890215]]. Action = [[ 0.07043832  0.08348501  0.         -0.72260463]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 14230 is [False, False, True, True, False, False]
Current timestep = 14231. State = [[ 0.30931628 -0.2673064 ]]. Action = [[ 0.07378825 -0.07202023  0.         -0.98563296]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 14231 is [False, False, True, True, False, False]
Current timestep = 14232. State = [[ 0.31174466 -0.2666048 ]]. Action = [[0.02468927 0.02591871 0.         0.16470492]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 14232 is [False, False, True, True, False, False]
Current timestep = 14233. State = [[ 0.31066653 -0.26289564]]. Action = [[-0.04288105  0.04622982  0.         -0.9418245 ]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 14233 is [False, False, True, True, False, False]
Current timestep = 14234. State = [[ 0.31029898 -0.2652131 ]]. Action = [[ 0.01593497 -0.09080075  0.          0.86135113]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 14234 is [False, False, True, True, False, False]
Current timestep = 14235. State = [[ 0.31274974 -0.2638111 ]]. Action = [[ 0.0595646   0.08098324  0.         -0.94776434]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 14235 is [False, False, True, True, False, False]
Current timestep = 14236. State = [[ 0.31338787 -0.25906083]]. Action = [[-0.00275168  0.02469267  0.          0.9534745 ]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 14236 is [False, False, True, True, False, False]
Current timestep = 14237. State = [[ 0.31267712 -0.2537765 ]]. Action = [[-0.00830057  0.06235338  0.         -0.9661745 ]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 14237 is [False, False, True, True, False, False]
Current timestep = 14238. State = [[ 0.31138662 -0.24750885]]. Action = [[-0.02593019  0.05679002  0.          0.819994  ]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 14238 is [False, False, True, True, False, False]
Current timestep = 14239. State = [[ 0.31311995 -0.24209416]]. Action = [[ 0.07029956  0.02159326  0.         -0.32513416]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 14239 is [False, False, True, True, False, False]
Current timestep = 14240. State = [[ 0.31453115 -0.23712692]]. Action = [[ 0.00636729  0.04135022  0.         -0.5659155 ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 14240 is [False, False, True, True, False, False]
Current timestep = 14241. State = [[ 0.31235698 -0.23767969]]. Action = [[-0.04965742 -0.0644611   0.         -0.8442146 ]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 14241 is [False, False, True, True, False, False]
Current timestep = 14242. State = [[ 0.31189513 -0.24082454]]. Action = [[ 0.01045451 -0.02763863  0.         -0.74811274]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 14242 is [False, False, True, True, False, False]
State prediction error at timestep 14242 is 0.012
Human Feedback received at timestep 14242 of None
Current timestep = 14243. State = [[ 0.31029028 -0.24176368]]. Action = [[-0.05030868  0.00867305  0.         -0.97119   ]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 14243 is [False, False, True, True, False, False]
Current timestep = 14244. State = [[ 0.30960545 -0.24618618]]. Action = [[ 0.00326176 -0.08203202  0.         -0.8940589 ]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 14244 is [False, False, True, True, False, False]
Current timestep = 14245. State = [[ 0.31146014 -0.24824499]]. Action = [[ 0.03916986  0.02825987  0.         -0.7952492 ]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 14245 is [False, False, True, True, False, False]
Current timestep = 14246. State = [[ 0.31068134 -0.24688858]]. Action = [[-0.04712102  0.0266378   0.         -0.46474957]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 14246 is [False, False, True, True, False, False]
Current timestep = 14247. State = [[ 0.31142297 -0.24462153]]. Action = [[ 0.04201739  0.02400824  0.         -0.95198107]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 14247 is [False, False, True, True, False, False]
State prediction error at timestep 14247 is 0.012
Human Feedback received at timestep 14247 of None
Current timestep = 14248. State = [[ 0.3154009  -0.24452911]]. Action = [[ 0.08405729 -0.02939913  0.         -0.9837324 ]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 14248 is [False, False, True, True, False, False]
State prediction error at timestep 14248 is 0.012
Human Feedback received at timestep 14248 of None
Current timestep = 14249. State = [[ 0.31764886 -0.24483973]]. Action = [[ 0.03655735 -0.00271627  0.          0.9900844 ]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 14249 is [False, False, True, True, False, False]
Current timestep = 14250. State = [[ 0.31995064 -0.24726887]]. Action = [[ 0.08555687 -0.07374917  0.         -0.16140121]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 14250 is [False, False, True, True, False, False]
Current timestep = 14251. State = [[ 0.31925914 -0.24805006]]. Action = [[-0.01503529  0.01805508  0.         -0.7509589 ]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 14251 is [False, False, True, True, False, False]
State prediction error at timestep 14251 is 0.012
Human Feedback received at timestep 14251 of None
Current timestep = 14252. State = [[ 0.31889284 -0.24893121]]. Action = [[ 0.02767351 -0.0269665   0.         -0.39014173]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 14252 is [False, False, True, True, False, False]
Current timestep = 14253. State = [[ 0.31613663 -0.2535669 ]]. Action = [[-0.07066256 -0.06924267  0.         -0.79223734]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 14253 is [False, False, True, True, False, False]
Current timestep = 14254. State = [[ 0.31467715 -0.25649944]]. Action = [[ 0.01965985  0.01185493  0.         -0.8406049 ]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 14254 is [False, False, True, True, False, False]
Current timestep = 14255. State = [[ 0.31286836 -0.2529273 ]]. Action = [[-0.0476816   0.0824948   0.         -0.94207174]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 14255 is [False, False, True, True, False, False]
Current timestep = 14256. State = [[ 0.3135882  -0.24497733]]. Action = [[ 0.09201819  0.06704976  0.         -0.67180526]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 14256 is [False, False, True, True, False, False]
Current timestep = 14257. State = [[ 0.31697935 -0.24163163]]. Action = [[ 0.06590872 -0.02584016  0.         -0.19983935]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 14257 is [False, False, True, True, False, False]
Current timestep = 14258. State = [[ 0.31724232 -0.24247068]]. Action = [[-0.05847707 -0.01853645  0.         -0.98352563]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 14258 is [False, False, True, True, False, False]
Current timestep = 14259. State = [[ 0.31455025 -0.24723469]]. Action = [[-0.03988736 -0.08383808  0.         -0.98586166]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 14259 is [False, False, True, True, False, False]
Current timestep = 14260. State = [[ 0.31462058 -0.25308254]]. Action = [[ 0.03587549 -0.04965698  0.         -0.875455  ]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 14260 is [False, False, True, True, False, False]
State prediction error at timestep 14260 is 0.012
Human Feedback received at timestep 14260 of None
Current timestep = 14261. State = [[ 0.31335288 -0.25728327]]. Action = [[-0.03394262 -0.0280669   0.         -0.7892239 ]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 14261 is [False, False, True, True, False, False]
State prediction error at timestep 14261 is 0.012
Human Feedback received at timestep 14261 of None
Current timestep = 14262. State = [[ 0.3141995  -0.25599867]]. Action = [[ 0.09093886  0.04538082  0.         -0.7784801 ]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 14262 is [False, False, True, True, False, False]
Current timestep = 14263. State = [[ 0.31554052 -0.25709713]]. Action = [[ 0.02369539 -0.06791     0.         -0.88573873]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 14263 is [False, False, True, True, False, False]
Current timestep = 14264. State = [[ 0.31767902 -0.2542271 ]]. Action = [[0.07751705 0.08463276 0.         0.97505   ]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 14264 is [False, False, True, True, False, False]
Current timestep = 14265. State = [[ 0.31987745 -0.25301343]]. Action = [[ 0.05704711 -0.05030968  0.         -0.6853719 ]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 14265 is [False, False, True, True, False, False]
Current timestep = 14266. State = [[ 0.32181233 -0.2527632 ]]. Action = [[ 0.0641324   0.01330633  0.         -0.7500089 ]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 14266 is [False, False, True, True, False, False]
State prediction error at timestep 14266 is 0.012
Human Feedback received at timestep 14266 of None
Current timestep = 14267. State = [[ 0.32028383 -0.25593227]]. Action = [[-0.04089801 -0.07479132  0.         -0.39688766]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 14267 is [False, False, True, True, False, False]
State prediction error at timestep 14267 is 0.012
Human Feedback received at timestep 14267 of None
Current timestep = 14268. State = [[ 0.31718317 -0.2563402 ]]. Action = [[-0.02119318  0.05065984  0.         -0.99924135]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 14268 is [False, False, True, True, False, False]
Current timestep = 14269. State = [[ 0.31764784 -0.2514219 ]]. Action = [[0.05522961 0.05927552 0.         0.14890039]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 14269 is [False, False, True, True, False, False]
State prediction error at timestep 14269 is 0.012
Human Feedback received at timestep 14269 of None
Current timestep = 14270. State = [[ 0.31822497 -0.24806094]]. Action = [[ 0.01397054  0.02854294  0.         -0.9726658 ]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 14270 is [False, False, True, True, False, False]
Current timestep = 14271. State = [[ 0.31976092 -0.24653026]]. Action = [[0.06433985 0.00404572 0.         0.08118403]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 14271 is [False, False, True, True, False, False]
Current timestep = 14272. State = [[ 0.3225657  -0.24488609]]. Action = [[ 0.091534   -0.00147988  0.         -0.94549507]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 14272 is [False, False, True, True, False, False]
Current timestep = 14273. State = [[ 0.3256169  -0.24250339]]. Action = [[ 0.08880772  0.02817685  0.         -0.8574735 ]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 14273 is [False, False, True, True, False, False]
Current timestep = 14274. State = [[ 0.32823563 -0.23780352]]. Action = [[ 0.08214412  0.07022589  0.         -0.36907208]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 14274 is [False, False, True, True, False, False]
State prediction error at timestep 14274 is 0.012
Human Feedback received at timestep 14274 of None
Current timestep = 14275. State = [[ 0.3268496  -0.23913033]]. Action = [[-0.05523822 -0.06617049  0.         -0.9943243 ]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 14275 is [False, False, True, True, False, False]
Current timestep = 14276. State = [[ 0.32367325 -0.24205992]]. Action = [[-0.00593039 -0.01392384  0.          0.5722941 ]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 14276 is [False, False, True, True, False, False]
Current timestep = 14277. State = [[ 0.3211238  -0.24359909]]. Action = [[-0.01934503 -0.01562355  0.         -0.9986997 ]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 14277 is [False, False, True, True, False, False]
Current timestep = 14278. State = [[ 0.32141113 -0.24204549]]. Action = [[ 0.09077606  0.03205534  0.         -0.99799263]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 14278 is [False, False, True, True, False, False]
Current timestep = 14279. State = [[ 0.3228167  -0.24199446]]. Action = [[ 0.05439372 -0.03331977  0.         -0.9782201 ]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 14279 is [False, False, True, True, False, False]
State prediction error at timestep 14279 is 0.012
Human Feedback received at timestep 14279 of None
Current timestep = 14280. State = [[ 0.32323548 -0.24607258]]. Action = [[ 0.03407382 -0.090898    0.          0.22346437]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 14280 is [False, False, True, True, False, False]
Current timestep = 14281. State = [[ 0.3236711 -0.2503702]]. Action = [[ 0.0370765  -0.07391948  0.          0.5339618 ]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 14281 is [False, False, True, True, False, False]
State prediction error at timestep 14281 is 0.012
Human Feedback received at timestep 14281 of None
Current timestep = 14282. State = [[ 0.32381815 -0.24999732]]. Action = [[ 0.03377987  0.02606475  0.         -0.48636663]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 14282 is [False, False, True, True, False, False]
State prediction error at timestep 14282 is 0.012
Human Feedback received at timestep 14282 of None
Current timestep = 14283. State = [[ 0.32430133 -0.24511364]]. Action = [[ 0.04752275  0.09207089  0.         -0.9815025 ]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 14283 is [False, False, True, True, False, False]
Current timestep = 14284. State = [[ 0.3217345 -0.2454189]]. Action = [[-0.04951176 -0.05887158  0.         -0.9081106 ]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 14284 is [False, False, True, True, False, False]
State prediction error at timestep 14284 is 0.012
Human Feedback received at timestep 14284 of None
Current timestep = 14285. State = [[ 0.32089967 -0.2441203 ]]. Action = [[ 0.06846445  0.05596995  0.         -0.6801039 ]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 14285 is [False, False, True, True, False, False]
Current timestep = 14286. State = [[ 0.32279623 -0.24167207]]. Action = [[ 0.07565188 -0.00293736  0.         -0.9904097 ]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 14286 is [False, False, True, True, False, False]
Current timestep = 14287. State = [[ 0.32422864 -0.24405372]]. Action = [[ 0.07625093 -0.08925693  0.          0.15840352]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 14287 is [False, False, True, True, False, False]
Current timestep = 14288. State = [[ 0.32548684 -0.2481954 ]]. Action = [[ 0.08041853 -0.08311273  0.         -0.7160834 ]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 14288 is [False, False, True, True, False, False]
Current timestep = 14289. State = [[ 0.32765922 -0.2454218 ]]. Action = [[0.09245498 0.09546395 0.         0.87522423]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 14289 is [False, False, True, True, False, False]
Current timestep = 14290. State = [[ 0.3284202  -0.24325448]]. Action = [[ 0.04890733 -0.02651874  0.          0.46268892]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 14290 is [False, False, True, True, False, False]
Current timestep = 14291. State = [[ 0.328684   -0.24430421]]. Action = [[ 0.07811861 -0.06206053  0.         -0.738243  ]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 14291 is [False, False, True, True, False, False]
State prediction error at timestep 14291 is 0.012
Human Feedback received at timestep 14291 of None
Current timestep = 14292. State = [[ 0.32906133 -0.24292699]]. Action = [[ 0.0567494   0.04598895  0.         -0.6740845 ]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 14292 is [False, False, True, True, False, False]
Current timestep = 14293. State = [[ 0.3278908 -0.2421329]]. Action = [[-0.01096392 -0.00377798  0.         -0.73224574]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 14293 is [False, False, True, True, False, False]
State prediction error at timestep 14293 is 0.012
Human Feedback received at timestep 14293 of None
Current timestep = 14294. State = [[ 0.32469586 -0.2395274 ]]. Action = [[-0.02611327  0.04891866  0.          0.9681208 ]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 14294 is [False, False, True, True, False, False]
Current timestep = 14295. State = [[ 0.32244965 -0.23644236]]. Action = [[-0.00301312  0.01965501  0.         -0.994759  ]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 14295 is [False, False, True, True, False, False]
Current timestep = 14296. State = [[ 0.32329345 -0.23271137]]. Action = [[ 0.0647623   0.04543864  0.         -0.728036  ]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 14296 is [False, False, True, True, False, False]
Current timestep = 14297. State = [[ 0.3247549 -0.2275842]]. Action = [[ 0.05090139  0.06603882  0.         -0.5650376 ]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 14297 is [False, False, True, True, False, False]
Current timestep = 14298. State = [[ 0.32508078 -0.22480202]]. Action = [[ 0.02211263  0.02175291  0.         -0.80473983]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 14298 is [False, False, True, True, False, False]
Current timestep = 14299. State = [[ 0.32315385 -0.22751415]]. Action = [[-0.02818104 -0.0697837   0.         -0.956905  ]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 14299 is [False, False, True, True, False, False]
State prediction error at timestep 14299 is 0.012
Human Feedback received at timestep 14299 of None
Current timestep = 14300. State = [[ 0.3194876  -0.22726814]]. Action = [[-0.04043299  0.04760984  0.          0.9911804 ]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 14300 is [False, False, True, True, False, False]
Current timestep = 14301. State = [[ 0.31863123 -0.22865157]]. Action = [[ 0.05033565 -0.07255422  0.          0.840333  ]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 14301 is [False, False, True, True, False, False]
State prediction error at timestep 14301 is 0.012
Human Feedback received at timestep 14301 of None
Current timestep = 14302. State = [[ 0.31794912 -0.23573454]]. Action = [[-0.0049357  -0.09039121  0.         -0.9711405 ]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 14302 is [False, False, True, True, False, False]
State prediction error at timestep 14302 is 0.012
Human Feedback received at timestep 14302 of None
Current timestep = 14303. State = [[ 0.31627846 -0.23614715]]. Action = [[-0.01729222  0.07398634  0.         -0.97108763]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 14303 is [False, False, True, True, False, False]
Current timestep = 14304. State = [[ 0.3134637  -0.23897906]]. Action = [[-0.040995   -0.08201548  0.         -0.8718619 ]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 14304 is [False, False, True, True, False, False]
State prediction error at timestep 14304 is 0.012
Human Feedback received at timestep 14304 of None
Current timestep = 14305. State = [[ 0.31366166 -0.24598682]]. Action = [[ 0.0599296  -0.07773437  0.         -0.8808657 ]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 14305 is [False, False, True, True, False, False]
Current timestep = 14306. State = [[ 0.3165106  -0.25142106]]. Action = [[ 0.07160584 -0.03679065  0.         -0.29866546]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 14306 is [False, False, True, True, False, False]
State prediction error at timestep 14306 is 0.012
Human Feedback received at timestep 14306 of None
Current timestep = 14307. State = [[ 0.31776258 -0.25727978]]. Action = [[ 0.03818888 -0.09366914  0.         -0.8823085 ]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 14307 is [False, False, True, True, False, False]
State prediction error at timestep 14307 is 0.012
Human Feedback received at timestep 14307 of None
Current timestep = 14308. State = [[ 0.317279   -0.26390934]]. Action = [[-0.00085296 -0.07032692  0.         -0.23133147]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 14308 is [False, False, True, True, False, False]
Current timestep = 14309. State = [[ 0.31791174 -0.2698876 ]]. Action = [[ 0.07080931 -0.07719181  0.         -0.9721367 ]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 14309 is [False, False, True, True, False, False]
Current timestep = 14310. State = [[ 0.3189033  -0.27556723]]. Action = [[ 0.04072376 -0.0874541   0.          0.76394117]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 14310 is [False, False, True, True, False, False]
Current timestep = 14311. State = [[ 0.3199523  -0.27993393]]. Action = [[ 0.05101379 -0.0628968   0.         -0.5818292 ]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 14311 is [False, False, True, True, False, False]
Current timestep = 14312. State = [[ 0.32074535 -0.27842897]]. Action = [[ 0.05296872  0.06255136  0.         -0.80453247]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 14312 is [False, False, True, True, False, False]
State prediction error at timestep 14312 is 0.012
Human Feedback received at timestep 14312 of None
Current timestep = 14313. State = [[ 0.32189137 -0.27673793]]. Action = [[0.0639889  0.01832245 0.         0.809852  ]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 14313 is [False, False, True, True, False, False]
State prediction error at timestep 14313 is 0.012
Human Feedback received at timestep 14313 of None
Current timestep = 14314. State = [[ 0.3204054 -0.2747948]]. Action = [[-0.08754703  0.06801415  0.         -0.63727486]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 14314 is [False, False, True, True, False, False]
Current timestep = 14315. State = [[ 0.31739447 -0.2676203 ]]. Action = [[-0.01888593  0.09189568  0.         -0.91049075]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 14315 is [False, False, True, True, False, False]
Current timestep = 14316. State = [[ 0.3172797  -0.26415613]]. Action = [[ 0.04328275 -0.03823888  0.         -0.8106491 ]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 14316 is [False, False, True, True, False, False]
Current timestep = 14317. State = [[ 0.31800014 -0.26530096]]. Action = [[ 0.03425407 -0.05124348  0.         -0.845226  ]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 14317 is [False, False, True, True, False, False]
Current timestep = 14318. State = [[ 0.3181479 -0.2691771]]. Action = [[ 0.01545455 -0.09125849  0.         -0.9992478 ]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 14318 is [False, False, True, True, False, False]
Current timestep = 14319. State = [[ 0.31605414 -0.2706012 ]]. Action = [[-0.03442036  0.01869901  0.         -0.9857906 ]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 14319 is [False, False, True, True, False, False]
State prediction error at timestep 14319 is 0.012
Human Feedback received at timestep 14319 of None
Current timestep = 14320. State = [[ 0.3119522 -0.2674365]]. Action = [[-0.06159761  0.06175911  0.         -0.9759892 ]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 14320 is [False, False, True, True, False, False]
State prediction error at timestep 14320 is 0.012
Human Feedback received at timestep 14320 of None
Current timestep = 14321. State = [[ 0.309979   -0.26460382]]. Action = [[-0.01485566  0.01703809  0.         -0.45129967]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 14321 is [False, False, True, True, False, False]
State prediction error at timestep 14321 is 0.012
Human Feedback received at timestep 14321 of None
Current timestep = 14322. State = [[ 0.3101388  -0.25906715]]. Action = [[ 0.0088461   0.08392685  0.         -0.6306765 ]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 14322 is [False, False, True, True, False, False]
State prediction error at timestep 14322 is 0.012
Human Feedback received at timestep 14322 of None
Current timestep = 14323. State = [[ 0.31194484 -0.25362518]]. Action = [[0.03601398 0.02488081 0.         0.8760307 ]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 14323 is [False, False, True, True, False, False]
Current timestep = 14324. State = [[ 0.3135278 -0.2549687]]. Action = [[ 0.02663458 -0.07617094  0.         -0.5868343 ]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 14324 is [False, False, True, True, False, False]
Current timestep = 14325. State = [[ 0.31135133 -0.26140952]]. Action = [[-0.07800418 -0.067754    0.          0.96433306]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 14325 is [False, False, True, True, False, False]
Current timestep = 14326. State = [[ 0.3120144 -0.2603215]]. Action = [[ 0.08174718  0.08320413  0.         -0.92545515]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 14326 is [False, False, True, True, False, False]
Current timestep = 14327. State = [[ 0.31266943 -0.25962073]]. Action = [[-0.00929537 -0.05308292  0.         -0.8044441 ]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 14327 is [False, False, True, True, False, False]
Current timestep = 14328. State = [[ 0.31419158 -0.26093215]]. Action = [[ 0.06990398 -0.02293631  0.          0.54949665]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 14328 is [False, False, True, True, False, False]
Current timestep = 14329. State = [[ 0.31365907 -0.2604142 ]]. Action = [[-0.03410727  0.0207296   0.          0.05314171]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 14329 is [False, False, True, True, False, False]
Current timestep = 14330. State = [[ 0.31344205 -0.26316777]]. Action = [[ 0.04043002 -0.07265724  0.          0.16620088]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 14330 is [False, False, True, True, False, False]
Current timestep = 14331. State = [[ 0.31407312 -0.2644055 ]]. Action = [[ 0.02106418  0.02070583  0.         -0.8425462 ]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 14331 is [False, False, True, True, False, False]
State prediction error at timestep 14331 is 0.012
Human Feedback received at timestep 14331 of None
Current timestep = 14332. State = [[ 0.31567347 -0.25977492]]. Action = [[ 0.05042725  0.08850215  0.         -0.7495275 ]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 14332 is [False, False, True, True, False, False]
Current timestep = 14333. State = [[ 0.31643626 -0.2601792 ]]. Action = [[ 0.01960746 -0.07105687  0.         -0.99689615]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 14333 is [False, False, True, True, False, False]
State prediction error at timestep 14333 is 0.012
Human Feedback received at timestep 14333 of None
Current timestep = 14334. State = [[ 0.31748503 -0.26370198]]. Action = [[ 0.04745943 -0.04126785  0.         -0.9782321 ]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 14334 is [False, False, True, True, False, False]
Current timestep = 14335. State = [[ 0.3202752  -0.26186207]]. Action = [[ 0.08656923  0.0640944   0.         -0.9866468 ]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 14335 is [False, False, True, True, False, False]
Current timestep = 14336. State = [[ 0.32268408 -0.2609663 ]]. Action = [[ 0.06734405 -0.02969514  0.          0.28335714]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 14336 is [False, False, True, True, False, False]
Current timestep = 14337. State = [[ 0.3219981  -0.25907254]]. Action = [[-0.04786091  0.06848835  0.         -0.76673424]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 14337 is [False, False, True, True, False, False]
Current timestep = 14338. State = [[ 0.3196392  -0.25348988]]. Action = [[-0.00887194  0.06054168  0.         -0.5357551 ]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 14338 is [False, False, True, True, False, False]
Current timestep = 14339. State = [[ 0.31908128 -0.2509666 ]]. Action = [[ 0.01510842 -0.00976603  0.          0.27204704]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 14339 is [False, False, True, True, False, False]
Current timestep = 14340. State = [[ 0.31787428 -0.25146782]]. Action = [[-0.02026308 -0.02459137  0.         -0.974298  ]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 14340 is [False, False, True, True, False, False]
Current timestep = 14341. State = [[ 0.3158189  -0.25471765]]. Action = [[-0.01760206 -0.05280684  0.         -0.96958745]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 14341 is [False, False, True, True, False, False]
Current timestep = 14342. State = [[ 0.31567  -0.252858]]. Action = [[0.02419291 0.07329198 0.         0.9573449 ]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 14342 is [False, False, True, True, False, False]
Current timestep = 14343. State = [[ 0.3181432  -0.24763663]]. Action = [[0.07753182 0.03440297 0.         0.89530754]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 14343 is [False, False, True, True, False, False]
State prediction error at timestep 14343 is 0.012
Human Feedback received at timestep 14343 of None
Current timestep = 14344. State = [[ 0.31877783 -0.24795036]]. Action = [[-0.00277352 -0.06766829  0.         -0.94016945]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 14344 is [False, False, True, True, False, False]
Current timestep = 14345. State = [[ 0.31897417 -0.2533851 ]]. Action = [[ 0.02441441 -0.09420083  0.         -0.2406044 ]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 14345 is [False, False, True, True, False, False]
Current timestep = 14346. State = [[ 0.32067683 -0.25622013]]. Action = [[ 0.06559924 -0.01752578  0.          0.9132261 ]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 14346 is [False, False, True, True, False, False]
Current timestep = 14347. State = [[ 0.32197645 -0.25907612]]. Action = [[ 0.04687498 -0.06997625  0.         -0.9921306 ]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 14347 is [False, False, True, True, False, False]
Current timestep = 14348. State = [[ 0.32361332 -0.26052007]]. Action = [[ 0.0759     -0.0086015   0.         -0.95046777]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 14348 is [False, False, True, True, False, False]
State prediction error at timestep 14348 is 0.012
Human Feedback received at timestep 14348 of None
Current timestep = 14349. State = [[ 0.32420433 -0.25884926]]. Action = [[0.03800323 0.03498604 0.         0.4165461 ]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 14349 is [False, False, True, True, False, False]
State prediction error at timestep 14349 is 0.012
Human Feedback received at timestep 14349 of None
Current timestep = 14350. State = [[ 0.3231923 -0.2543173]]. Action = [[-0.01312231  0.07350754  0.         -0.91085666]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 14350 is [False, False, True, True, False, False]
Current timestep = 14351. State = [[ 0.32335925 -0.25421813]]. Action = [[ 0.08058947 -0.08104108  0.         -0.7925417 ]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 14351 is [False, False, True, True, False, False]
Current timestep = 14352. State = [[ 0.3251759 -0.2546886]]. Action = [[ 0.09003296 -0.00747681  0.         -0.4044305 ]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 14352 is [False, False, True, True, False, False]
State prediction error at timestep 14352 is 0.012
Human Feedback received at timestep 14352 of None
Current timestep = 14353. State = [[ 0.3249901  -0.25613347]]. Action = [[-0.00258822 -0.0444913   0.          0.77473974]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 14353 is [False, False, True, True, False, False]
Current timestep = 14354. State = [[ 0.32212576 -0.25294432]]. Action = [[-0.04033097  0.09148484  0.         -0.91769505]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 14354 is [False, False, True, True, False, False]
Current timestep = 14355. State = [[ 0.31779864 -0.24492705]]. Action = [[-0.06002478  0.09407701  0.         -0.9073164 ]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 14355 is [False, False, True, True, False, False]
Current timestep = 14356. State = [[ 0.31657478 -0.24352102]]. Action = [[ 0.07498992 -0.0956042   0.         -0.74420756]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 14356 is [False, False, True, True, False, False]
State prediction error at timestep 14356 is 0.012
Human Feedback received at timestep 14356 of None
Current timestep = 14357. State = [[ 0.3139562  -0.24746576]]. Action = [[-0.06451909 -0.04018313  0.         -0.98522556]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 14357 is [False, False, True, True, False, False]
Current timestep = 14358. State = [[ 0.31230524 -0.24558417]]. Action = [[-0.00227369  0.08089238  0.         -0.9830961 ]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 14358 is [False, False, True, True, False, False]
Current timestep = 14359. State = [[ 0.31163153 -0.24416503]]. Action = [[-0.01718618 -0.02560299  0.         -0.3571992 ]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 14359 is [False, False, True, True, False, False]
State prediction error at timestep 14359 is 0.012
Human Feedback received at timestep 14359 of None
Current timestep = 14360. State = [[ 0.31130442 -0.24875869]]. Action = [[-0.00229688 -0.07684259  0.         -0.62073135]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 14360 is [False, False, True, True, False, False]
State prediction error at timestep 14360 is 0.012
Human Feedback received at timestep 14360 of None
Current timestep = 14361. State = [[ 0.31159908 -0.25342533]]. Action = [[ 0.00865467 -0.03094202  0.          0.6602564 ]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 14361 is [False, False, True, True, False, False]
Current timestep = 14362. State = [[ 0.31500384 -0.24997303]]. Action = [[ 0.09484202  0.09634428  0.         -0.2453965 ]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 14362 is [False, False, True, True, False, False]
Current timestep = 14363. State = [[ 0.3180723  -0.24333131]]. Action = [[ 0.04934532  0.04343603  0.         -0.9589039 ]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 14363 is [False, False, True, True, False, False]
Current timestep = 14364. State = [[-0.24314864  0.11546608]]. Action = [[ 0.02406783 -0.04652822  0.          0.979102  ]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 14364 is [False, False, True, True, False, False]
Current timestep = 14365. State = [[-0.23710033  0.10772973]]. Action = [[ 0.07262295 -0.08019653  0.          0.04990005]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 14365 is [True, False, False, False, True, False]
Current timestep = 14366. State = [[-0.23047455  0.09915505]]. Action = [[ 0.07839511 -0.094488    0.         -0.6426042 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 14366 is [True, False, False, False, True, False]
Current timestep = 14367. State = [[-0.22301002  0.09699207]]. Action = [[ 0.0862956  0.0541557  0.        -0.6436079]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 14367 is [True, False, False, False, True, False]
State prediction error at timestep 14367 is 0.012
Human Feedback received at timestep 14367 of None
Current timestep = 14368. State = [[-0.21491273  0.09490079]]. Action = [[ 0.09470222 -0.02681196  0.         -0.19378817]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 14368 is [True, False, False, False, True, False]
Current timestep = 14369. State = [[-0.20633645  0.09678958]]. Action = [[ 0.09607198  0.09791274  0.         -0.6284127 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 14369 is [True, False, False, False, True, False]
Current timestep = 14370. State = [[-0.20082077  0.09338436]]. Action = [[ 0.0268398  -0.08635537  0.         -0.70012367]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 14370 is [True, False, False, False, True, False]
Current timestep = 14371. State = [[-0.19691728  0.08565535]]. Action = [[ 0.02387656 -0.07519424  0.         -0.76681244]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 14371 is [True, False, False, False, True, False]
Current timestep = 14372. State = [[-0.19038059  0.08087897]]. Action = [[ 0.0771519  -0.01511605  0.         -0.14952683]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 14372 is [True, False, False, False, True, False]
Current timestep = 14373. State = [[-0.18235664  0.07664277]]. Action = [[ 0.07700551 -0.03632836  0.         -0.16980827]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 14373 is [True, False, False, False, True, False]
Current timestep = 14374. State = [[-0.17337322  0.06987648]]. Action = [[ 0.09088974 -0.0749585   0.         -0.11281955]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 14374 is [True, False, False, False, True, False]
State prediction error at timestep 14374 is 0.012
Human Feedback received at timestep 14374 of None
Current timestep = 14375. State = [[-0.16398679  0.06157733]]. Action = [[ 0.08515447 -0.07903125  0.         -0.52543914]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 14375 is [True, False, False, False, True, False]
Current timestep = 14376. State = [[-0.15563338  0.05598228]]. Action = [[ 0.06328303 -0.01790157  0.         -0.69825554]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 14376 is [True, False, False, False, True, False]
Current timestep = 14377. State = [[-0.14688767  0.04813508]]. Action = [[ 0.08236199 -0.09738413  0.         -0.78784746]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 14377 is [True, False, False, False, True, False]
Current timestep = 14378. State = [[-0.13738585  0.04363905]]. Action = [[ 0.08611377  0.01803118  0.         -0.21694303]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 14378 is [True, False, False, False, True, False]
State prediction error at timestep 14378 is 0.012
Human Feedback received at timestep 14378 of None
Current timestep = 14379. State = [[-0.12762645  0.03738635]]. Action = [[ 0.09103451 -0.08214088  0.         -0.8179015 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14379 is [True, False, False, False, True, False]
Current timestep = 14380. State = [[-0.11905388  0.03433429]]. Action = [[ 0.06281742  0.03684974  0.         -0.48577702]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 14380 is [True, False, False, False, True, False]
Current timestep = 14381. State = [[-0.11074866  0.02892742]]. Action = [[ 0.07521749 -0.08181936  0.         -0.6479826 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 14381 is [True, False, False, False, True, False]
Current timestep = 14382. State = [[-0.10144736  0.0221189 ]]. Action = [[ 0.08624608 -0.04448765  0.         -0.862852  ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 14382 is [True, False, False, False, True, False]
Current timestep = 14383. State = [[-0.09183013  0.02202079]]. Action = [[ 0.08939234  0.07114189  0.         -0.23098564]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 14383 is [True, False, False, False, True, False]
State prediction error at timestep 14383 is 0.012
Human Feedback received at timestep 14383 of None
Current timestep = 14384. State = [[-0.08342376  0.02129853]]. Action = [[ 0.06776691 -0.01879941  0.         -0.50404644]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 14384 is [True, False, False, False, True, False]
Current timestep = 14385. State = [[-0.07779302  0.01693205]]. Action = [[ 0.01834878 -0.05067732  0.         -0.8317531 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 14385 is [True, False, False, False, True, False]
State prediction error at timestep 14385 is 0.012
Human Feedback received at timestep 14385 of None
Current timestep = 14386. State = [[-0.07021166  0.01048303]]. Action = [[ 0.08254331 -0.07364644  0.         -0.85664064]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 14386 is [True, False, False, False, True, False]
Current timestep = 14387. State = [[-0.06150045  0.00208272]]. Action = [[ 0.06957061 -0.09378776  0.         -0.7815464 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 14387 is [True, False, False, False, True, False]
Current timestep = 14388. State = [[-0.05307484 -0.00678309]]. Action = [[ 0.06690342 -0.08391408  0.         -0.8600654 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 14388 is [True, False, False, False, True, False]
State prediction error at timestep 14388 is 0.012
Human Feedback received at timestep 14388 of None
