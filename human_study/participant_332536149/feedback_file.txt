Current timestep = 0. State = [[-0.25830325  0.00801939]]. Action = [[-0.02517132 -0.00313229  0.08415417 -0.03610903]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is None
Current timestep = 1. State = [[-0.25805557  0.00783758]]. Action = [[ 0.01121883  0.03684529 -0.07181501 -0.24135602]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False]
State prediction error at timestep 1 is 0.012
Human Feedback received at timestep 1 of -1
Current timestep = 2. State = [[-0.25793397  0.00891028]]. Action = [[-0.06113325  0.04126974  0.03300034  0.97395396]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, True, False]
Current timestep = 3. State = [[-0.25826472  0.00989667]]. Action = [[-0.06263261  0.07551753 -0.02271957 -0.21903908]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, True, False]
State prediction error at timestep 3 is 0.012
Human Feedback received at timestep 3 of 1
Current timestep = 4. State = [[-0.2610454   0.01754107]]. Action = [[-0.02606332 -0.08540395 -0.09080984  0.91687274]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, True, False]
Current timestep = 5. State = [[-0.2610809   0.01616036]]. Action = [[-0.07761858  0.08164795 -0.07904283 -0.8448607 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, True, False]
Current timestep = 6. State = [[-0.2620539   0.01700983]]. Action = [[ 0.09810986 -0.04243719 -0.07681088 -0.2252906 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, True, False]
Current timestep = 7. State = [[-0.2622343  0.0164135]]. Action = [[-0.05269296  0.07933923 -0.05097861  0.7123525 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, True, False]
State prediction error at timestep 7 is 0.012
Human Feedback received at timestep 7 of 1
Current timestep = 8. State = [[-0.2637731   0.02014828]]. Action = [[ 0.0754961   0.04299169 -0.08663189 -0.08161724]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, True, False]
Current timestep = 9. State = [[-0.26389557  0.02046767]]. Action = [[-0.07022719 -0.05783322  0.0835178   0.24431825]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, True, False]
State prediction error at timestep 9 is 0.012
Human Feedback received at timestep 9 of 1
Current timestep = 10. State = [[-0.264519    0.01856368]]. Action = [[ 0.06681105 -0.08201386 -0.0795724  -0.67114556]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, True, False]
State prediction error at timestep 10 is 0.012
Human Feedback received at timestep 10 of -1
Current timestep = 11. State = [[-0.264821    0.01340589]]. Action = [[-0.00926805 -0.06453748  0.05081462 -0.9684069 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, True, False]
Current timestep = 12. State = [[-0.26491043  0.01183305]]. Action = [[-0.00988554 -0.09839112  0.08039667 -0.614913  ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, True, False]
State prediction error at timestep 12 is 0.012
Human Feedback received at timestep 12 of -1
Current timestep = 13. State = [[-0.2656061  0.0016988]]. Action = [[ 0.09057599 -0.05426887  0.07797232  0.24568582]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, True, False]
State prediction error at timestep 13 is 0.012
Human Feedback received at timestep 13 of 1
Current timestep = 14. State = [[-0.26466635 -0.00092474]]. Action = [[ 0.07226252  0.01412418 -0.09395985 -0.4160719 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, True, False]
Current timestep = 15. State = [[-0.2635765 -0.0009482]]. Action = [[-0.05909092 -0.05171558 -0.0525969   0.7692232 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, True, False]
Current timestep = 16. State = [[-0.2634742  -0.00177734]]. Action = [[-0.08847439  0.07359082 -0.01290637  0.7894316 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, True, False]
State prediction error at timestep 16 is 0.012
Human Feedback received at timestep 16 of 1
Current timestep = 17. State = [[-0.26418197 -0.00094143]]. Action = [[ 0.00787131  0.08607116 -0.07212043 -0.33679414]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, True, False]
Current timestep = 18. State = [[-0.26466876  0.00057252]]. Action = [[-0.03301679  0.08093991 -0.04848113 -0.731575  ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, True, False]
Current timestep = 19. State = [[-0.2656691   0.00342497]]. Action = [[ 0.00312903 -0.03759826  0.05114145 -0.25821555]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, True, False]
State prediction error at timestep 19 is 0.012
Human Feedback received at timestep 19 of -1
Current timestep = 20. State = [[-0.26699167  0.00699574]]. Action = [[ 0.0632496   0.05764089 -0.0382315   0.49787724]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, True, False]
Current timestep = 21. State = [[-0.26720577  0.00774622]]. Action = [[ 0.05672931  0.00467298 -0.07356826  0.501621  ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, True, False]
Current timestep = 22. State = [[-0.26692125  0.00812702]]. Action = [[ 0.06753404  0.09819474  0.039411   -0.9514527 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [True, False, False, False, True, False]
Current timestep = 23. State = [[-0.26561058  0.01064848]]. Action = [[-0.02280841  0.06887992  0.05683497  0.03624845]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [True, False, False, False, True, False]
State prediction error at timestep 23 is 0.012
Human Feedback received at timestep 23 of 1
Current timestep = 24. State = [[-0.26479766  0.02083513]]. Action = [[ 0.03349089  0.09955809  0.05350745 -0.682824  ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [True, False, False, False, True, False]
Current timestep = 25. State = [[-0.26425844  0.02307309]]. Action = [[-0.0462237  -0.08078437  0.09888066  0.63734305]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [True, False, False, False, True, False]
Current timestep = 26. State = [[-0.26420626  0.023249  ]]. Action = [[ 0.04534339  0.01859118 -0.00705447 -0.01341397]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [True, False, False, False, True, False]
State prediction error at timestep 26 is 0.012
Human Feedback received at timestep 26 of 1
Current timestep = 27. State = [[-0.26264176  0.02435151]]. Action = [[-0.05272523 -0.06325215  0.00538734 -0.01878482]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [True, False, False, False, True, False]
State prediction error at timestep 27 is 0.012
Human Feedback received at timestep 27 of -1
Current timestep = 28. State = [[-0.26267305  0.02416739]]. Action = [[-7.3070809e-02  1.4945790e-02 -7.2551519e-04 -9.1120285e-01]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [True, False, False, False, True, False]
Current timestep = 29. State = [[-0.26271102  0.02425375]]. Action = [[ 0.05071848  0.05536649 -0.01994523 -0.4208697 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [True, False, False, False, True, False]
Current timestep = 30. State = [[-0.26287845  0.02480883]]. Action = [[-0.01370352  0.06336819 -0.09457915 -0.95380545]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [True, False, False, False, True, False]
Current timestep = 31. State = [[-0.26351914  0.02650819]]. Action = [[-0.02395083  0.01285665 -0.02076205  0.84736323]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [True, False, False, False, True, False]
Current timestep = 32. State = [[-0.26401305  0.02786313]]. Action = [[ 4.3716282e-04 -7.0835866e-02 -7.5898826e-02 -4.9097490e-01]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [True, False, False, False, True, False]
Current timestep = 33. State = [[-0.26398823  0.0277578 ]]. Action = [[-0.07968862 -0.07912775  0.08637451 -0.9374181 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [True, False, False, False, True, False]
Current timestep = 34. State = [[-0.26401678  0.02668804]]. Action = [[ 0.0229729   0.01553579 -0.09458311  0.09854746]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [True, False, False, False, True, False]
Current timestep = 35. State = [[-0.2641044   0.02653368]]. Action = [[-0.02379552 -0.03595639  0.03375626  0.6699455 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [True, False, False, False, True, False]
Current timestep = 36. State = [[-0.264128    0.02558672]]. Action = [[ 0.09312334 -0.00839349  0.06660537  0.02484822]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [True, False, False, False, True, False]
Current timestep = 37. State = [[-0.26405895  0.02473534]]. Action = [[ 0.0663007  -0.04746206  0.0988551   0.314659  ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [True, False, False, False, True, False]
Current timestep = 38. State = [[-0.26349607  0.02306598]]. Action = [[-0.03301517 -0.06903735 -0.06527947 -0.56067777]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [True, False, False, False, True, False]
Current timestep = 39. State = [[-0.26310173  0.02043165]]. Action = [[-0.02143808 -0.03881108 -0.03790156  0.5556381 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [True, False, False, False, True, False]
Current timestep = 40. State = [[-0.2630961   0.01839647]]. Action = [[-0.09060122  0.09276371 -0.07957199  0.32077074]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [True, False, False, False, True, False]
Current timestep = 41. State = [[-0.26348022  0.01823133]]. Action = [[ 0.04349054 -0.03881253  0.08305307 -0.17703742]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [True, False, False, False, True, False]
State prediction error at timestep 41 is 0.012
