Current timestep = 0. State = [[-0.32604954 -0.08628346]]. Action = [[0.00435984 0.09830839 0.         0.7271644 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [True, False, False, False, True, False]
State prediction error at timestep 0 is tensor(0.0668, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 0 of -1
Current timestep = 1. State = [[-0.33171427 -0.08338373]]. Action = [[-0.08950701 -0.00990611  0.          0.9261981 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False]
State prediction error at timestep 1 is tensor(0.0582, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1 of -1
Current timestep = 2. State = [[-0.33283383 -0.08530019]]. Action = [[ 0.05919518 -0.05022885  0.          0.01753342]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, True, False]
State prediction error at timestep 2 is tensor(0.0498, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2 of -1
Current timestep = 3. State = [[-0.32827216 -0.08361269]]. Action = [[ 0.07941671  0.04839007  0.         -0.508215  ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, True, False]
State prediction error at timestep 3 is tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 3 of -1
Current timestep = 4. State = [[-0.32541144 -0.08398328]]. Action = [[ 0.02240024 -0.05187739  0.          0.0605756 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, True, False]
State prediction error at timestep 4 is tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 4 of 1
Current timestep = 5. State = [[-0.32796615 -0.0831293 ]]. Action = [[-0.0650194   0.04303177  0.         -0.71769756]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, True, False]
State prediction error at timestep 5 is tensor(0.0098, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 5 of 1
Current timestep = 6. State = [[-0.33477747 -0.08681682]]. Action = [[-0.09400084 -0.09525075  0.         -0.5530515 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, True, False]
State prediction error at timestep 6 is tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 6 of 1
Current timestep = 7. State = [[-0.34229743 -0.08951695]]. Action = [[-0.0857139   0.01565989  0.          0.7501273 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, True, False]
State prediction error at timestep 7 is tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 7 of 0
Current timestep = 8. State = [[-0.3429924  -0.09307348]]. Action = [[ 0.06538809 -0.06983318  0.          0.3590908 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, True, False]
State prediction error at timestep 8 is tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 8 of 1
Current timestep = 9. State = [[-0.33896303 -0.09812035]]. Action = [[ 0.05116356 -0.04876601  0.          0.966053  ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, True, False]
State prediction error at timestep 9 is tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 9 of 1
Current timestep = 10. State = [[-0.3412551  -0.09594422]]. Action = [[-0.09368288  0.09747208  0.          0.95621693]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, True, False]
State prediction error at timestep 10 is tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 10 of -1
Current timestep = 11. State = [[-0.34793594 -0.08933613]]. Action = [[-0.06636739  0.08788531  0.         -0.7747761 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, True, False]
State prediction error at timestep 11 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 11 of -1
Current timestep = 12. State = [[-0.35245717 -0.09058045]]. Action = [[-0.02059557 -0.08004597  0.         -0.9538186 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, True, False]
State prediction error at timestep 12 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 12 of -1
Current timestep = 13. State = [[-0.35142303 -0.09697355]]. Action = [[ 0.06858451 -0.08364228  0.          0.7987578 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, True, False]
State prediction error at timestep 13 is tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 13 of -1
Current timestep = 14. State = [[-0.34905127 -0.10322254]]. Action = [[ 0.03612078 -0.07337215  0.          0.99142814]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, True, False]
State prediction error at timestep 14 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 14 of -1
Current timestep = 15. State = [[-0.34914297 -0.10760628]]. Action = [[-0.0091228  -0.0333114   0.         -0.21504265]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, True, False]
State prediction error at timestep 15 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 15 of -1
Current timestep = 16. State = [[-0.35157442 -0.11439168]]. Action = [[-0.03355686 -0.09515958  0.         -0.46814477]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, True, False]
State prediction error at timestep 16 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 16 of -1
Current timestep = 17. State = [[-0.35037917 -0.11503301]]. Action = [[ 0.06324864  0.07869077  0.         -0.04857576]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, True, False]
State prediction error at timestep 17 is tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 17 of -1
Current timestep = 18. State = [[-0.3524331  -0.11050749]]. Action = [[-0.07426463  0.06323761  0.         -0.8001202 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, True, False]
State prediction error at timestep 18 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 18 of 0
Current timestep = 19. State = [[-0.35570943 -0.10838579]]. Action = [[-0.01453441  0.01495703  0.         -0.615005  ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, True, False]
State prediction error at timestep 19 is tensor(8.4397e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 19 of 0
Current timestep = 20. State = [[-0.3527177  -0.10655253]]. Action = [[0.08605505 0.02347057 0.         0.3043015 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, True, False]
State prediction error at timestep 20 is tensor(0.0074, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 20 of -1
Current timestep = 21. State = [[-0.35501432 -0.10529277]]. Action = [[-0.09338094  0.00789271  0.          0.027578  ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, True, False]
State prediction error at timestep 21 is tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward>)
