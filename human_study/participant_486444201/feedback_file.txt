Current timestep = 0. State = [[-0.32604954 -0.08628346]]. Action = [[0.00435984 0.09830839 0.         0.7271644 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [True, False, False, False, True, False]
State prediction error at timestep 0 is tensor(0.0668, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 0 of None
Current timestep = 1. State = [[-0.33171427 -0.08338373]]. Action = [[-0.08950701 -0.00990611  0.          0.9261981 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False]
State prediction error at timestep 1 is tensor(0.0582, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1 of None
Current timestep = 2. State = [[-0.33283383 -0.08530018]]. Action = [[ 0.05919524 -0.05022868  0.          0.01754153]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, True, False]
State prediction error at timestep 2 is tensor(0.0498, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2 of None
Current timestep = 3. State = [[-0.32827222 -0.08361281]]. Action = [[ 0.07941509  0.0483874   0.         -0.50816584]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, True, False]
State prediction error at timestep 3 is tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 3 of None
Current timestep = 4. State = [[-0.3254116  -0.08398479]]. Action = [[ 0.02239919 -0.05190226  0.          0.06075954]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, True, False]
State prediction error at timestep 4 is tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 4 of None
Current timestep = 5. State = [[-0.3279671  -0.08313566]]. Action = [[-0.06503823  0.04295453  0.         -0.71753365]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, True, False]
State prediction error at timestep 5 is tensor(0.0098, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 5 of None
Current timestep = 6. State = [[-0.33477935 -0.08682702]]. Action = [[-0.09400872 -0.0952624   0.         -0.55266756]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, True, False]
State prediction error at timestep 6 is tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 6 of None
Current timestep = 7. State = [[-0.3423005  -0.08953982]]. Action = [[-0.08573388  0.01543184  0.          0.75047183]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, True, False]
State prediction error at timestep 7 is tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 7 of None
Current timestep = 8. State = [[-0.34299555 -0.0931111 ]]. Action = [[ 0.06539624 -0.06995545  0.          0.36012435]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, True, False]
State prediction error at timestep 8 is tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 8 of None
Current timestep = 9. State = [[-0.33896556 -0.09817613]]. Action = [[ 0.05116934 -0.04899728  0.          0.96619225]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, True, False]
State prediction error at timestep 9 is tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 9 of None
Current timestep = 10. State = [[-0.34125704 -0.09601232]]. Action = [[-0.09370168  0.09744289  0.          0.9564408 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, True, False]
State prediction error at timestep 10 is tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 10 of None
Current timestep = 11. State = [[-0.34794155 -0.08941568]]. Action = [[-0.06642361  0.08775141  0.         -0.7740712 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, True, False]
State prediction error at timestep 11 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 11 of None
Current timestep = 12. State = [[-0.3524674  -0.09067384]]. Action = [[-0.02062605 -0.08017505  0.         -0.9536822 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, True, False]
State prediction error at timestep 12 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 12 of None
Current timestep = 13. State = [[-0.35143182 -0.09707875]]. Action = [[ 0.06866229 -0.083746    0.          0.8004637 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, True, False]
State prediction error at timestep 13 is tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 13 of None
Current timestep = 14. State = [[-0.3490534  -0.10334155]]. Action = [[ 0.03622013 -0.07354388  0.          0.9915631 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, True, False]
State prediction error at timestep 14 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 14 of None
Current timestep = 15. State = [[-0.34913963 -0.10775554]]. Action = [[-0.00907946 -0.03376415  0.         -0.21082371]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, True, False]
State prediction error at timestep 15 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 15 of None
Current timestep = 16. State = [[-0.3515684  -0.11455903]]. Action = [[-0.03354903 -0.0951744   0.         -0.46467394]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, True, False]
State prediction error at timestep 16 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 16 of None
Current timestep = 17. State = [[-0.35036102 -0.11521903]]. Action = [[ 0.06343738  0.07837261  0.         -0.04249555]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, True, False]
State prediction error at timestep 17 is tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 17 of None
Current timestep = 18. State = [[-0.3524108  -0.11073043]]. Action = [[-0.07434311  0.06280682  0.         -0.7986902 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, True, False]
State prediction error at timestep 18 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 18 of None
Current timestep = 19. State = [[-0.35568303 -0.10865618]]. Action = [[-0.01442628  0.01446489  0.         -0.61173034]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, True, False]
State prediction error at timestep 19 is tensor(8.1447e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 19 of None
Current timestep = 20. State = [[-0.3526776  -0.10687124]]. Action = [[0.08623167 0.02300803 0.         0.31270623]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, True, False]
State prediction error at timestep 20 is tensor(0.0074, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 20 of None
Current timestep = 21. State = [[-0.35496762 -0.10565591]]. Action = [[-0.09344417  0.00754379  0.          0.03627145]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, True, False]
State prediction error at timestep 21 is tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 21 of None
Current timestep = 22. State = [[-0.35567173 -0.1096269 ]]. Action = [[ 0.06830675 -0.09284499  0.         -0.53725266]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [True, False, False, False, True, False]
State prediction error at timestep 22 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 22 of None
Current timestep = 23. State = [[-0.34997484 -0.11670735]]. Action = [[ 0.08822257 -0.09029897  0.          0.20686066]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [True, False, False, False, True, False]
State prediction error at timestep 23 is tensor(0.0072, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 23 of None
Current timestep = 24. State = [[-0.34345004 -0.12370998]]. Action = [[ 0.07326324 -0.08367714  0.         -0.62574905]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [True, False, False, False, True, False]
State prediction error at timestep 24 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 24 of None
Current timestep = 25. State = [[-0.33743477 -0.13015684]]. Action = [[ 0.05893933 -0.06729642  0.         -0.7062875 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [True, False, False, True, False, False]
State prediction error at timestep 25 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 25 of None
Current timestep = 26. State = [[-0.3335562 -0.1360468]]. Action = [[ 0.01803955 -0.05434812  0.         -0.49133933]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [True, False, False, True, False, False]
State prediction error at timestep 26 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 26 of None
Current timestep = 27. State = [[-0.3279426  -0.14183766]]. Action = [[ 0.07475772 -0.05114451  0.         -0.83698577]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [True, False, False, True, False, False]
State prediction error at timestep 27 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 27 of None
Current timestep = 28. State = [[-0.32778814 -0.14228137]]. Action = [[-0.07985155  0.07023907  0.          0.716177  ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [True, False, False, True, False, False]
State prediction error at timestep 28 is tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 28 of None
Current timestep = 29. State = [[-0.3257879  -0.13905415]]. Action = [[ 0.07731897  0.0548152   0.         -0.19668382]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [True, False, False, True, False, False]
State prediction error at timestep 29 is tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 29 of None
Current timestep = 30. State = [[-0.32135898 -0.13593896]]. Action = [[0.03792714 0.03898365 0.         0.9145137 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [True, False, False, True, False, False]
State prediction error at timestep 30 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 30 of None
Current timestep = 31. State = [[-0.32012093 -0.13237548]]. Action = [[-0.00734532  0.05215795  0.         -0.68890154]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [True, False, False, True, False, False]
State prediction error at timestep 31 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 31 of None
Current timestep = 32. State = [[-0.3156949  -0.13425143]]. Action = [[ 0.09171552 -0.07368196  0.         -0.01193464]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [True, False, False, True, False, False]
State prediction error at timestep 32 is tensor(0.0062, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 32 of None
Current timestep = 33. State = [[-0.31349254 -0.1335877 ]]. Action = [[-0.03082895  0.06172993  0.         -0.43724132]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [True, False, False, True, False, False]
State prediction error at timestep 33 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 33 of None
Current timestep = 34. State = [[-0.31570745 -0.1293414 ]]. Action = [[-0.03572042  0.05166627  0.         -0.984189  ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [True, False, False, True, False, False]
State prediction error at timestep 34 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 34 of None
Current timestep = 35. State = [[-0.3144213  -0.12887667]]. Action = [[ 0.04760996 -0.03087246  0.          0.73354495]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [True, False, False, True, False, False]
State prediction error at timestep 35 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 35 of None
Current timestep = 36. State = [[-0.3164821 -0.131975 ]]. Action = [[-0.07450292 -0.05111818  0.         -0.9411027 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [True, False, False, True, False, False]
State prediction error at timestep 36 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 36 of None
Current timestep = 37. State = [[-0.31953534 -0.13823329]]. Action = [[-0.02443783 -0.08774377  0.         -0.680884  ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [True, False, False, True, False, False]
State prediction error at timestep 37 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 37 of None
Current timestep = 38. State = [[-0.31880757 -0.14025575]]. Action = [[ 0.02529877  0.02194778  0.         -0.69732094]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [True, False, False, True, False, False]
State prediction error at timestep 38 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 38 of None
Current timestep = 39. State = [[-0.32189897 -0.13661738]]. Action = [[-0.08657759  0.07219615  0.         -0.52458906]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [True, False, False, True, False, False]
State prediction error at timestep 39 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 39 of None
Current timestep = 40. State = [[-0.3218579  -0.13827516]]. Action = [[ 0.0623932 -0.0812559  0.        -0.505362 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [True, False, False, True, False, False]
State prediction error at timestep 40 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 40 of None
Current timestep = 41. State = [[-0.31472388 -0.14271297]]. Action = [[ 0.0969845  -0.04060469  0.         -0.45733178]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [True, False, False, True, False, False]
State prediction error at timestep 41 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 41 of None
Current timestep = 42. State = [[-0.30885214 -0.1393448 ]]. Action = [[ 0.03615708  0.09605473  0.         -0.7085937 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [True, False, False, True, False, False]
State prediction error at timestep 42 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 42 of None
Current timestep = 43. State = [[-0.3075256 -0.1385312]]. Action = [[-0.01379284 -0.03964251  0.          0.885164  ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [True, False, False, True, False, False]
State prediction error at timestep 43 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 43 of None
Current timestep = 44. State = [[-0.30511642 -0.13938357]]. Action = [[ 0.04331518  0.00724858  0.         -0.32532144]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [True, False, False, True, False, False]
State prediction error at timestep 44 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 44 of None
Current timestep = 45. State = [[-0.3004675  -0.14153159]]. Action = [[ 0.05608428 -0.04577896  0.          0.5140588 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [True, False, False, True, False, False]
State prediction error at timestep 45 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 45 of None
Current timestep = 46. State = [[-0.2973581  -0.14006814]]. Action = [[0.01304604 0.0577567  0.         0.5734048 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [True, False, False, True, False, False]
State prediction error at timestep 46 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 46 of None
Current timestep = 47. State = [[-0.29775846 -0.13404134]]. Action = [[-0.03035113  0.08973774  0.         -0.25634837]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [True, False, False, True, False, False]
State prediction error at timestep 47 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 47 of None
Current timestep = 48. State = [[-0.2946827  -0.13356327]]. Action = [[ 0.07656788 -0.05497192  0.         -0.7528407 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [True, False, False, True, False, False]
State prediction error at timestep 48 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 48 of None
Current timestep = 49. State = [[-0.28808215 -0.13106784]]. Action = [[ 0.07046223  0.06966154  0.         -0.49434084]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [True, False, False, True, False, False]
State prediction error at timestep 49 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 49 of None
Current timestep = 50. State = [[-0.28263673 -0.12450146]]. Action = [[ 0.04658066  0.07537553  0.         -0.86270106]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [True, False, False, False, True, False]
State prediction error at timestep 50 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 50 of None
Current timestep = 51. State = [[-0.2849465  -0.12122615]]. Action = [[-0.09492144  0.00337236  0.          0.3534478 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 51 is [True, False, False, False, True, False]
State prediction error at timestep 51 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 51 of None
Current timestep = 52. State = [[-0.2884364  -0.12493194]]. Action = [[-0.03289726 -0.0846393   0.         -0.5317908 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 52 is [True, False, False, False, True, False]
State prediction error at timestep 52 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 52 of None
Current timestep = 53. State = [[-0.2924004  -0.12905939]]. Action = [[-0.07372832 -0.03210803  0.         -0.3655308 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 53 is [True, False, False, True, False, False]
State prediction error at timestep 53 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 53 of None
Current timestep = 54. State = [[-0.29175925 -0.1345024 ]]. Action = [[ 0.04515976 -0.08424617  0.         -0.08591765]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 54 is [True, False, False, True, False, False]
State prediction error at timestep 54 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 54 of None
Current timestep = 55. State = [[-0.29224348 -0.14118977]]. Action = [[-0.05234873 -0.07303961  0.          0.24395955]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 55 is [True, False, False, True, False, False]
State prediction error at timestep 55 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 55 of None
Current timestep = 56. State = [[-0.2935808  -0.14767027]]. Action = [[-0.01509072 -0.06223612  0.         -0.30916786]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 56 is [True, False, False, True, False, False]
State prediction error at timestep 56 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 56 of None
Current timestep = 57. State = [[-0.296698   -0.14820628]]. Action = [[-0.06777793  0.05757075  0.          0.8447294 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 57 is [True, False, False, True, False, False]
State prediction error at timestep 57 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 57 of None
Current timestep = 58. State = [[-0.29488915 -0.1444477 ]]. Action = [[0.0731707  0.06383226 0.         0.16354978]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 58 is [True, False, False, True, False, False]
State prediction error at timestep 58 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 58 of None
Current timestep = 59. State = [[-0.29312417 -0.13960184]]. Action = [[-0.00756636  0.06271797  0.         -0.6371225 ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 59 is [True, False, False, True, False, False]
State prediction error at timestep 59 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 59 of None
Current timestep = 60. State = [[-0.29052037 -0.13890968]]. Action = [[ 0.05789507 -0.02778776  0.          0.34296846]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 60 is [True, False, False, True, False, False]
State prediction error at timestep 60 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 60 of None
Current timestep = 61. State = [[-0.29315203 -0.14057347]]. Action = [[-0.08712094 -0.01703764  0.         -0.6709282 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 61 is [True, False, False, True, False, False]
State prediction error at timestep 61 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 61 of None
Current timestep = 62. State = [[-0.2946062  -0.14345214]]. Action = [[ 0.02928352 -0.04201383  0.          0.7420423 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 62 is [True, False, False, True, False, False]
State prediction error at timestep 62 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 62 of None
Current timestep = 63. State = [[-0.2921044  -0.14441872]]. Action = [[ 0.04457492  0.00559046  0.         -0.58027   ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 63 is [True, False, False, True, False, False]
State prediction error at timestep 63 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 63 of None
Current timestep = 64. State = [[-0.2934974  -0.14515385]]. Action = [[-0.04956371 -0.01710913  0.          0.08260489]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 64 is [True, False, False, True, False, False]
State prediction error at timestep 64 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 64 of None
Current timestep = 65. State = [[-0.2969364  -0.14632499]]. Action = [[-0.03606131 -0.00573687  0.          0.5306635 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 65 is [True, False, False, True, False, False]
State prediction error at timestep 65 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 65 of None
Current timestep = 66. State = [[-0.30299938 -0.14961572]]. Action = [[-0.09214138 -0.04942728  0.          0.7834394 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 66 is [True, False, False, True, False, False]
State prediction error at timestep 66 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 66 of None
Current timestep = 67. State = [[-0.3087747  -0.15668295]]. Action = [[-0.05005399 -0.09348495  0.         -0.9126737 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 67 is [True, False, False, True, False, False]
State prediction error at timestep 67 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 67 of None
Current timestep = 68. State = [[-0.30875462 -0.1625674 ]]. Action = [[ 0.04520542 -0.04233116  0.         -0.11649919]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 68 is [True, False, False, True, False, False]
State prediction error at timestep 68 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 68 of None
Current timestep = 69. State = [[-0.3051849  -0.16444488]]. Action = [[ 0.0544023   0.00353122  0.         -0.17321903]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 69 is [True, False, False, True, False, False]
State prediction error at timestep 69 is tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 69 of None
Current timestep = 70. State = [[-0.29955998 -0.16759995]]. Action = [[ 0.08436743 -0.05597566  0.         -0.7629528 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 70 is [True, False, False, True, False, False]
State prediction error at timestep 70 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 70 of None
Current timestep = 71. State = [[-0.30078626 -0.17202455]]. Action = [[-0.07863273 -0.0375288   0.          0.44133997]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 71 is [True, False, False, True, False, False]
State prediction error at timestep 71 is tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 71 of None
Current timestep = 72. State = [[-0.30629405 -0.17581381]]. Action = [[-0.05588006 -0.02587659  0.         -0.6986717 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 72 is [True, False, False, True, False, False]
State prediction error at timestep 72 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 72 of None
Current timestep = 73. State = [[-0.30621335 -0.17921014]]. Action = [[ 0.05203088 -0.02631958  0.          0.7714429 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 73 is [True, False, False, True, False, False]
State prediction error at timestep 73 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 73 of None
Current timestep = 74. State = [[-0.30612662 -0.18541655]]. Action = [[-0.01667716 -0.08764011  0.          0.54999256]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 74 is [True, False, False, True, False, False]
State prediction error at timestep 74 is tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 74 of None
Current timestep = 75. State = [[-0.30335984 -0.19070832]]. Action = [[ 0.07094366 -0.03047304  0.         -0.06648868]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 75 is [True, False, False, True, False, False]
State prediction error at timestep 75 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 75 of None
Current timestep = 76. State = [[-0.29732487 -0.19472417]]. Action = [[ 0.08019779 -0.04101266  0.         -0.00120997]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 76 is [True, False, False, True, False, False]
State prediction error at timestep 76 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 76 of None
Current timestep = 77. State = [[-0.29738328 -0.1988749 ]]. Action = [[-0.05424083 -0.03388353  0.          0.60991466]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 77 is [True, False, False, True, False, False]
State prediction error at timestep 77 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 77 of None
Current timestep = 78. State = [[-0.29488298 -0.19722204]]. Action = [[ 0.08216538  0.08587495  0.         -0.92393196]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 78 is [True, False, False, True, False, False]
State prediction error at timestep 78 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 78 of None
Current timestep = 79. State = [[-0.29323092 -0.19543213]]. Action = [[-0.01305099  0.00414294  0.          0.280133  ]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 79 is [True, False, False, True, False, False]
State prediction error at timestep 79 is tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 79 of None
Current timestep = 80. State = [[-0.28953698 -0.19895992]]. Action = [[ 0.08208812 -0.06493977  0.         -0.8023042 ]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 80 is [True, False, False, True, False, False]
State prediction error at timestep 80 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 80 of None
Current timestep = 81. State = [[-0.29066485 -0.19782409]]. Action = [[-0.0863136   0.08920132  0.         -0.5418714 ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 81 is [True, False, False, True, False, False]
State prediction error at timestep 81 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 81 of None
Current timestep = 82. State = [[-0.29197884 -0.19356984]]. Action = [[ 0.03636044  0.03875247  0.         -0.53592783]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 82 is [True, False, False, True, False, False]
State prediction error at timestep 82 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 82 of None
Current timestep = 83. State = [[-0.28895164 -0.19397621]]. Action = [[ 0.05714736 -0.04794896  0.          0.54164505]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 83 is [True, False, False, True, False, False]
State prediction error at timestep 83 is tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 83 of None
Current timestep = 84. State = [[-0.28954238 -0.19054149]]. Action = [[-0.04169829  0.08812124  0.          0.16435027]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 84 is [True, False, False, True, False, False]
State prediction error at timestep 84 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 84 of None
Current timestep = 85. State = [[-0.29637164 -0.18881868]]. Action = [[-0.09386183 -0.02766778  0.         -0.4471004 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 85 is [True, False, False, True, False, False]
State prediction error at timestep 85 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 85 of None
Current timestep = 86. State = [[-0.30292216 -0.18676987]]. Action = [[-0.05021065  0.04696802  0.         -0.31456292]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 86 is [True, False, False, True, False, False]
State prediction error at timestep 86 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 86 of None
Current timestep = 87. State = [[-0.30942342 -0.18381153]]. Action = [[-0.07318203  0.02330372  0.         -0.94092625]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 87 is [True, False, False, True, False, False]
State prediction error at timestep 87 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 87 of None
Current timestep = 88. State = [[-0.31107888 -0.17933653]]. Action = [[ 0.03608038  0.0597463   0.         -0.1485101 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 88 is [True, False, False, True, False, False]
State prediction error at timestep 88 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 88 of None
Current timestep = 89. State = [[-0.3093929  -0.17189798]]. Action = [[0.03588101 0.08424745 0.         0.72728515]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 89 is [True, False, False, True, False, False]
State prediction error at timestep 89 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 89 of None
Current timestep = 90. State = [[-0.3074474  -0.16868968]]. Action = [[ 0.03582566 -0.02468487  0.         -0.57426333]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 90 is [True, False, False, True, False, False]
State prediction error at timestep 90 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 90 of None
Current timestep = 91. State = [[-0.30842522 -0.17246784]]. Action = [[-0.02372159 -0.09848043  0.          0.65254605]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 91 is [True, False, False, True, False, False]
State prediction error at timestep 91 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 91 of None
Current timestep = 92. State = [[-0.31231016 -0.17773314]]. Action = [[-0.04921351 -0.06410162  0.         -0.21959925]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 92 is [True, False, False, True, False, False]
State prediction error at timestep 92 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 92 of None
Current timestep = 93. State = [[-0.3121777  -0.17555882]]. Action = [[ 0.04527733  0.08112764  0.         -0.9027257 ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 93 is [True, False, False, True, False, False]
State prediction error at timestep 93 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 93 of None
Current timestep = 94. State = [[-0.31248632 -0.1751134 ]]. Action = [[-0.0250743  -0.04552994  0.         -0.7957489 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 94 is [True, False, False, True, False, False]
State prediction error at timestep 94 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 94 of None
Current timestep = 95. State = [[-0.31284434 -0.17221117]]. Action = [[ 0.01128552  0.07857841  0.         -0.953551  ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 95 is [True, False, False, True, False, False]
State prediction error at timestep 95 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 95 of None
Current timestep = 96. State = [[-0.31393522 -0.17263283]]. Action = [[-0.02295548 -0.05828817  0.         -0.79793316]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 96 is [True, False, False, True, False, False]
State prediction error at timestep 96 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 96 of None
Current timestep = 97. State = [[-0.31114185 -0.17453703]]. Action = [[ 0.07296499 -0.01049364  0.         -0.41482598]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 97 is [True, False, False, True, False, False]
State prediction error at timestep 97 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 97 of None
Current timestep = 98. State = [[-0.30863374 -0.1736454 ]]. Action = [[ 0.00643849  0.0184052   0.         -0.8022589 ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 98 is [True, False, False, True, False, False]
State prediction error at timestep 98 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 98 of None
Current timestep = 99. State = [[-0.3073743  -0.16883315]]. Action = [[ 0.01777432  0.08199792  0.         -0.24452662]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 99 is [True, False, False, True, False, False]
State prediction error at timestep 99 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 99 of None
Current timestep = 100. State = [[-0.30361223 -0.16379371]]. Action = [[ 0.06508752  0.04058089  0.         -0.7943448 ]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 100 is [True, False, False, True, False, False]
State prediction error at timestep 100 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 100 of None
Current timestep = 101. State = [[-0.29713145 -0.15706937]]. Action = [[ 0.09153306  0.08392868  0.         -0.9493565 ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 101 is [True, False, False, True, False, False]
State prediction error at timestep 101 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 101 of None
Current timestep = 102. State = [[-0.2947682  -0.15097114]]. Action = [[-0.00710889  0.04199185  0.         -0.75457567]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 102 is [True, False, False, True, False, False]
State prediction error at timestep 102 is tensor(3.8019e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 102 of None
Current timestep = 103. State = [[-0.29191485 -0.15177433]]. Action = [[ 0.06249606 -0.07246204  0.          0.06477809]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 103 is [True, False, False, True, False, False]
State prediction error at timestep 103 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 103 of None
Current timestep = 104. State = [[-0.2865393 -0.1515061]]. Action = [[ 0.06639535  0.0207387   0.         -0.62643766]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 104 is [True, False, False, True, False, False]
State prediction error at timestep 104 is tensor(2.2039e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 104 of None
Current timestep = 105. State = [[-0.28035995 -0.15345265]]. Action = [[ 0.0712591  -0.07239728  0.         -0.5898253 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 105 is [True, False, False, True, False, False]
State prediction error at timestep 105 is tensor(5.3580e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 105 of None
Current timestep = 106. State = [[-0.27602306 -0.14997862]]. Action = [[ 0.02201173  0.09787326  0.         -0.5130818 ]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 106 is [True, False, False, True, False, False]
State prediction error at timestep 106 is tensor(3.0439e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 106 of None
Current timestep = 107. State = [[-0.27173048 -0.14759202]]. Action = [[ 0.05863035 -0.02467187  0.          0.15600681]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 107 is [True, False, False, True, False, False]
State prediction error at timestep 107 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 107 of None
Current timestep = 108. State = [[-0.26544854 -0.14680995]]. Action = [[0.07366601 0.00974835 0.         0.19119322]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 108 is [True, False, False, True, False, False]
State prediction error at timestep 108 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 108 of None
Current timestep = 109. State = [[-0.26308972 -0.14471605]]. Action = [[-0.01889743  0.02365838  0.          0.1033498 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 109 is [True, False, False, True, False, False]
State prediction error at timestep 109 is tensor(6.3254e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 109 of None
Current timestep = 110. State = [[-0.2635116  -0.13935491]]. Action = [[-0.02226926  0.08669998  0.          0.06672692]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 110 is [True, False, False, True, False, False]
State prediction error at timestep 110 is tensor(4.8894e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 110 of None
Current timestep = 111. State = [[-0.2646824  -0.13255192]]. Action = [[-0.02919118  0.07460263  0.         -0.31455213]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 111 is [True, False, False, True, False, False]
State prediction error at timestep 111 is tensor(4.1393e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 111 of None
Current timestep = 112. State = [[-0.26440695 -0.13380767]]. Action = [[ 0.00673946 -0.08929274  0.         -0.9165057 ]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 112 is [True, False, False, True, False, False]
State prediction error at timestep 112 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 112 of None
Current timestep = 113. State = [[-0.25923845 -0.13953757]]. Action = [[ 0.07839321 -0.07971199  0.          0.44455087]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 113 is [True, False, False, True, False, False]
State prediction error at timestep 113 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 113 of None
Current timestep = 114. State = [[-0.2587347 -0.1418054]]. Action = [[-0.07074497  0.00189976  0.         -0.5383673 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 114 is [True, False, False, True, False, False]
State prediction error at timestep 114 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 114 of None
Current timestep = 115. State = [[-0.25698492 -0.13720593]]. Action = [[0.05568183 0.0908032  0.         0.07338595]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 115 is [True, False, False, True, False, False]
State prediction error at timestep 115 is tensor(1.6380e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 115 of None
Current timestep = 116. State = [[-0.250266   -0.13818064]]. Action = [[ 0.09744205 -0.0879102   0.         -0.02250725]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 116 is [True, False, False, True, False, False]
State prediction error at timestep 116 is tensor(2.8357e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 116 of None
Current timestep = 117. State = [[-0.24637754 -0.1421957 ]]. Action = [[-1.8393248e-04 -3.7044920e-02  0.0000000e+00  6.4866734e-01]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 117 is [True, False, False, True, False, False]
State prediction error at timestep 117 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 117 of None
Current timestep = 118. State = [[-0.24472731 -0.13906732]]. Action = [[ 0.00969952  0.09172004  0.         -0.8351518 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 118 is [True, False, False, True, False, False]
State prediction error at timestep 118 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 118 of None
Current timestep = 119. State = [[-0.2462078  -0.13319235]]. Action = [[-0.05208472  0.06840052  0.         -0.57194847]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 119 is [True, False, False, True, False, False]
State prediction error at timestep 119 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 119 of None
Current timestep = 120. State = [[-0.24492815 -0.13272007]]. Action = [[ 0.04597933 -0.03798363  0.         -0.26840603]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 120 is [True, False, False, True, False, False]
State prediction error at timestep 120 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 120 of None
Current timestep = 121. State = [[-0.23838215 -0.1375143 ]]. Action = [[ 0.09177988 -0.08230245  0.         -0.22404808]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 121 is [True, False, False, True, False, False]
State prediction error at timestep 121 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 121 of None
Current timestep = 122. State = [[-0.2333303  -0.13902129]]. Action = [[0.02691147 0.01803006 0.         0.29837286]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 122 is [True, False, False, True, False, False]
State prediction error at timestep 122 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 122 of None
Current timestep = 123. State = [[-0.23509097 -0.14202282]]. Action = [[-0.07719038 -0.06139922  0.         -0.6976466 ]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 123 is [True, False, False, True, False, False]
State prediction error at timestep 123 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 123 of None
Current timestep = 124. State = [[-0.23358153 -0.14048833]]. Action = [[ 0.05345894  0.07995074  0.         -0.36949706]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 124 is [True, False, False, True, False, False]
State prediction error at timestep 124 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 124 of None
Current timestep = 125. State = [[-0.22799757 -0.13519369]]. Action = [[ 0.07012018  0.06067916  0.         -0.89316255]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 125 is [True, False, False, True, False, False]
State prediction error at timestep 125 is tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 125 of None
Current timestep = 126. State = [[-0.2221043  -0.13472365]]. Action = [[ 0.06557637 -0.03788507  0.         -0.49634492]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 126 is [True, False, False, True, False, False]
State prediction error at timestep 126 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 126 of None
Current timestep = 127. State = [[-0.21795946 -0.13163573]]. Action = [[0.03025316 0.07409523 0.         0.3022282 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 127 is [True, False, False, True, False, False]
State prediction error at timestep 127 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 127 of None
Current timestep = 128. State = [[-0.21806177 -0.12954257]]. Action = [[-0.03462861 -0.00886088  0.         -0.88619226]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 128 is [True, False, False, True, False, False]
State prediction error at timestep 128 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 128 of None
Current timestep = 129. State = [[-0.21671921 -0.131645  ]]. Action = [[ 0.03025208 -0.04577982  0.         -0.9661095 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 129 is [True, False, False, True, False, False]
State prediction error at timestep 129 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 129 of None
Current timestep = 130. State = [[-0.21520136 -0.1342449 ]]. Action = [[-0.00448696 -0.02939345  0.          0.74524343]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 130 is [True, False, False, True, False, False]
State prediction error at timestep 130 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 130 of None
Current timestep = 131. State = [[-0.21216169 -0.13469827]]. Action = [[ 0.0437078   0.00884126  0.         -0.94852537]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 131 is [True, False, False, True, False, False]
State prediction error at timestep 131 is tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 131 of None
Current timestep = 132. State = [[-0.21421279 -0.1359184 ]]. Action = [[-0.08823476 -0.0264411   0.          0.6057162 ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 132 is [True, False, False, True, False, False]
State prediction error at timestep 132 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 132 of None
Current timestep = 133. State = [[-0.21313398 -0.13657638]]. Action = [[ 0.05329754  0.00743739  0.         -0.73417974]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 133 is [True, False, False, True, False, False]
State prediction error at timestep 133 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 133 of None
Current timestep = 134. State = [[-0.21127485 -0.13194796]]. Action = [[-0.00472779  0.08996452  0.         -0.313873  ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 134 is [True, False, False, True, False, False]
State prediction error at timestep 134 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 134 of None
Current timestep = 135. State = [[-0.20802891 -0.125654  ]]. Action = [[ 0.05927698  0.06546011  0.         -0.48902696]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 135 is [True, False, False, True, False, False]
State prediction error at timestep 135 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 135 of None
Current timestep = 136. State = [[-0.20724745 -0.12659886]]. Action = [[-0.02438033 -0.07531552  0.         -0.94854784]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 136 is [True, False, False, True, False, False]
State prediction error at timestep 136 is tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 136 of None
Current timestep = 137. State = [[-0.20845602 -0.12790743]]. Action = [[-0.02210756  0.00905782  0.         -0.4377808 ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 137 is [True, False, False, True, False, False]
State prediction error at timestep 137 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 137 of None
Current timestep = 138. State = [[-0.20615013 -0.13078499]]. Action = [[ 0.05144646 -0.065789    0.          0.5631981 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 138 is [True, False, False, True, False, False]
State prediction error at timestep 138 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 138 of None
Current timestep = 139. State = [[-0.19990681 -0.13703004]]. Action = [[ 0.08778626 -0.0885314   0.         -0.46138155]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 139 is [True, False, False, True, False, False]
State prediction error at timestep 139 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 139 of None
Current timestep = 140. State = [[-0.19408539 -0.13939078]]. Action = [[ 0.05194949  0.01271038  0.         -0.7271328 ]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 140 is [True, False, False, True, False, False]
State prediction error at timestep 140 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 140 of None
Current timestep = 141. State = [[-0.19520785 -0.13586338]]. Action = [[-0.07671288  0.08099077  0.         -0.8429633 ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 141 is [True, False, False, True, False, False]
State prediction error at timestep 141 is tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 141 of None
Current timestep = 142. State = [[-0.19679634 -0.1321382 ]]. Action = [[ 0.0012453   0.03556318  0.         -0.39457023]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 142 is [True, False, False, True, False, False]
State prediction error at timestep 142 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 142 of None
Current timestep = 143. State = [[-0.19842954 -0.13578635]]. Action = [[-0.03633756 -0.09418394  0.          0.25695074]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 143 is [True, False, False, True, False, False]
State prediction error at timestep 143 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 143 of None
Current timestep = 144. State = [[-0.19494997 -0.13544767]]. Action = [[ 0.08882966  0.06598433  0.         -0.22281373]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 144 is [True, False, False, True, False, False]
State prediction error at timestep 144 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 144 of None
Current timestep = 145. State = [[-0.1964832  -0.13661253]]. Action = [[-0.08816331 -0.06302179  0.         -0.05668837]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 145 is [True, False, False, True, False, False]
State prediction error at timestep 145 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 145 of None
Current timestep = 146. State = [[-0.20193388 -0.1348661 ]]. Action = [[-0.07111715  0.07659329  0.          0.29248834]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 146 is [True, False, False, True, False, False]
State prediction error at timestep 146 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 146 of None
Current timestep = 147. State = [[-0.20099334 -0.13671984]]. Action = [[ 0.07136879 -0.08393641  0.         -0.36177433]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 147 is [True, False, False, True, False, False]
State prediction error at timestep 147 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 147 of None
Current timestep = 148. State = [[-0.1961222 -0.1387938]]. Action = [[ 0.04925121  0.00942131  0.         -0.8954313 ]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 148 is [True, False, False, True, False, False]
State prediction error at timestep 148 is tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 148 of None
Current timestep = 149. State = [[-0.19141138 -0.14296982]]. Action = [[ 0.05104961 -0.08083465  0.         -0.9734423 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 149 is [True, False, False, True, False, False]
State prediction error at timestep 149 is tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 149 of None
Current timestep = 150. State = [[-0.18455817 -0.1419974 ]]. Action = [[ 0.09441175  0.0751619   0.         -0.06481206]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 150 is [True, False, False, True, False, False]
State prediction error at timestep 150 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 150 of None
Current timestep = 151. State = [[-0.17843871 -0.14099292]]. Action = [[ 0.05671098 -0.01705305  0.         -0.80955017]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 151 is [True, False, False, True, False, False]
State prediction error at timestep 151 is tensor(0.0062, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 151 of None
Current timestep = 152. State = [[-0.17789203 -0.14571768]]. Action = [[-0.04195581 -0.07819287  0.         -0.2532825 ]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 152 is [True, False, False, True, False, False]
State prediction error at timestep 152 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 152 of None
Current timestep = 153. State = [[-0.17704599 -0.1439068 ]]. Action = [[0.01923206 0.0977012  0.         0.40493035]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 153 is [True, False, False, True, False, False]
State prediction error at timestep 153 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 153 of None
Current timestep = 154. State = [[-0.17763177 -0.13924597]]. Action = [[-0.0385046   0.04565517  0.         -0.93924767]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 154 is [True, False, False, True, False, False]
State prediction error at timestep 154 is tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 154 of None
Current timestep = 155. State = [[-0.17956078 -0.14191306]]. Action = [[-0.03469849 -0.08091599  0.         -0.66715074]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 155 is [True, False, False, True, False, False]
State prediction error at timestep 155 is tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 155 of None
Current timestep = 156. State = [[-0.18004823 -0.14227691]]. Action = [[-0.00570323  0.04251546  0.         -0.6177148 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 156 is [True, False, False, True, False, False]
State prediction error at timestep 156 is tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 156 of None
Current timestep = 157. State = [[-0.17819144 -0.13927889]]. Action = [[0.03045905 0.03587116 0.         0.1512059 ]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 157 is [True, False, False, True, False, False]
State prediction error at timestep 157 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 157 of None
Current timestep = 158. State = [[-0.17748776 -0.1373541 ]]. Action = [[-0.01113888  0.00889014  0.         -0.81470823]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 158 is [True, False, False, True, False, False]
State prediction error at timestep 158 is tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 158 of None
Current timestep = 159. State = [[-0.17730966 -0.1318122 ]]. Action = [[ 0.00324055  0.09510059  0.         -0.7571435 ]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 159 is [True, False, False, True, False, False]
State prediction error at timestep 159 is tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 159 of None
Current timestep = 160. State = [[-0.17721584 -0.12892571]]. Action = [[-0.00079836 -0.01528897  0.         -0.19361317]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 160 is [True, False, False, True, False, False]
State prediction error at timestep 160 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 160 of None
Current timestep = 161. State = [[-0.17631982 -0.1264225 ]]. Action = [[ 0.01856641  0.03714008  0.         -0.8919489 ]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 161 is [True, False, False, True, False, False]
State prediction error at timestep 161 is tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 161 of None
Current timestep = 162. State = [[-0.17360185 -0.12400767]]. Action = [[ 0.04707891  0.00530438  0.         -0.34793043]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 162 is [True, False, False, False, True, False]
State prediction error at timestep 162 is tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 162 of None
Current timestep = 163. State = [[-0.17217927 -0.12381842]]. Action = [[ 0.00273812 -0.02125858  0.          0.22714484]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 163 is [True, False, False, False, True, False]
State prediction error at timestep 163 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 163 of None
Current timestep = 164. State = [[-0.17589608 -0.12160581]]. Action = [[-0.0837265   0.04268847  0.         -0.5530472 ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 164 is [True, False, False, False, True, False]
State prediction error at timestep 164 is tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 164 of None
Current timestep = 165. State = [[-0.18008384 -0.1221605 ]]. Action = [[-0.04095819 -0.04755416  0.          0.710667  ]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 165 is [True, False, False, False, True, False]
State prediction error at timestep 165 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 165 of None
Current timestep = 166. State = [[-0.18015839 -0.12681702]]. Action = [[ 0.02244838 -0.07530906  0.          0.04876173]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 166 is [True, False, False, True, False, False]
State prediction error at timestep 166 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 166 of None
Current timestep = 167. State = [[-0.18141024 -0.1258222 ]]. Action = [[-0.03968007  0.0636952   0.         -0.07502997]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 167 is [True, False, False, True, False, False]
State prediction error at timestep 167 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 167 of None
Current timestep = 168. State = [[-0.17828114 -0.12835516]]. Action = [[ 0.09731426 -0.09170576  0.          0.10280859]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 168 is [True, False, False, True, False, False]
State prediction error at timestep 168 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 168 of None
Current timestep = 169. State = [[-0.17069711 -0.13226652]]. Action = [[ 0.09577601 -0.0221171   0.         -0.96921426]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 169 is [True, False, False, True, False, False]
State prediction error at timestep 169 is tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 169 of None
Current timestep = 170. State = [[-0.16354159 -0.1377996 ]]. Action = [[ 0.07780256 -0.08372957  0.         -0.8996382 ]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 170 is [True, False, False, True, False, False]
State prediction error at timestep 170 is tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 170 of None
Current timestep = 171. State = [[-0.16403943 -0.13912414]]. Action = [[-0.08767621  0.05081899  0.         -0.95316285]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 171 is [True, False, False, True, False, False]
State prediction error at timestep 171 is tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 171 of None
Current timestep = 172. State = [[-0.16255262 -0.1416017 ]]. Action = [[ 0.08241279 -0.06146271  0.          0.7341882 ]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 172 is [True, False, False, True, False, False]
State prediction error at timestep 172 is tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 172 of None
Current timestep = 173. State = [[-0.16130605 -0.14768581]]. Action = [[-0.02979808 -0.06459431  0.          0.68503535]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 173 is [True, False, False, True, False, False]
State prediction error at timestep 173 is tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 173 of None
Current timestep = 174. State = [[-0.16143858 -0.1544118 ]]. Action = [[-0.00428994 -0.06474148  0.         -0.9585862 ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 174 is [True, False, False, True, False, False]
State prediction error at timestep 174 is tensor(0.0070, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 174 of None
Current timestep = 175. State = [[-0.16124834 -0.15331414]]. Action = [[-0.00858837  0.09524328  0.         -0.9053191 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 175 is [True, False, False, True, False, False]
State prediction error at timestep 175 is tensor(0.0071, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 175 of None
Current timestep = 176. State = [[-0.15921879 -0.15184827]]. Action = [[ 3.5827689e-02 -4.1664392e-04  0.0000000e+00 -6.7738444e-01]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 176 is [True, False, False, True, False, False]
State prediction error at timestep 176 is tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 176 of None
Current timestep = 177. State = [[-0.15620872 -0.15235552]]. Action = [[ 0.03305223  0.00249888  0.         -0.2402196 ]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 177 is [True, False, False, True, False, False]
State prediction error at timestep 177 is tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 177 of None
Current timestep = 178. State = [[-0.15910229 -0.15572979]]. Action = [[-0.09001112 -0.05458039  0.         -0.16368663]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 178 is [True, False, False, True, False, False]
State prediction error at timestep 178 is tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 178 of None
Current timestep = 179. State = [[-0.15992647 -0.16006799]]. Action = [[ 0.02207436 -0.03756168  0.          0.8393779 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 179 is [True, False, False, True, False, False]
State prediction error at timestep 179 is tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 179 of None
Current timestep = 180. State = [[-0.15688512 -0.15790798]]. Action = [[ 0.0446971   0.08004446  0.         -0.91132325]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 180 is [True, False, False, True, False, False]
State prediction error at timestep 180 is tensor(0.0070, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 180 of None
Current timestep = 181. State = [[-0.15148467 -0.15727104]]. Action = [[ 0.08200116 -0.0299238   0.         -0.91764426]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 181 is [True, False, False, True, False, False]
State prediction error at timestep 181 is tensor(0.0072, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 181 of None
Current timestep = 182. State = [[-0.14807618 -0.15501536]]. Action = [[ 0.01850939  0.06111563  0.         -0.17120665]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 182 is [True, False, False, True, False, False]
State prediction error at timestep 182 is tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 182 of None
Current timestep = 183. State = [[-0.1503008  -0.14841369]]. Action = [[-0.06275274  0.09559447  0.         -0.17459524]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 183 is [True, False, False, True, False, False]
State prediction error at timestep 183 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 183 of None
Current timestep = 184. State = [[-0.15614532 -0.14595054]]. Action = [[-0.0894238  -0.01610518  0.          0.38157284]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 184 is [True, False, False, True, False, False]
State prediction error at timestep 184 is tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 184 of None
Current timestep = 185. State = [[-0.16309932 -0.15019141]]. Action = [[-0.09550122 -0.08684864  0.         -0.28130263]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 185 is [True, False, False, True, False, False]
State prediction error at timestep 185 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 185 of None
Current timestep = 186. State = [[-0.1617991  -0.15343854]]. Action = [[ 0.08684722 -0.02104642  0.         -0.5656564 ]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 186 is [True, False, False, True, False, False]
State prediction error at timestep 186 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 186 of None
Current timestep = 187. State = [[-0.1626489  -0.15148222]]. Action = [[-0.0736371   0.05216948  0.         -0.32180786]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 187 is [True, False, False, True, False, False]
State prediction error at timestep 187 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 187 of None
Current timestep = 188. State = [[-0.16439761 -0.14531045]]. Action = [[0.00998636 0.08479091 0.         0.74505746]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 188 is [True, False, False, True, False, False]
State prediction error at timestep 188 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 188 of None
Current timestep = 189. State = [[-0.16687442 -0.13958317]]. Action = [[-0.04081595  0.04607918  0.          0.41192472]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 189 is [True, False, False, True, False, False]
State prediction error at timestep 189 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 189 of None
Current timestep = 190. State = [[-0.17196244 -0.14175296]]. Action = [[-0.06706262 -0.09120143  0.          0.31058538]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 190 is [True, False, False, True, False, False]
State prediction error at timestep 190 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 190 of None
Current timestep = 191. State = [[-0.1720679  -0.13992967]]. Action = [[ 0.05394008  0.0766312   0.         -0.84216917]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 191 is [True, False, False, True, False, False]
State prediction error at timestep 191 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 191 of None
Current timestep = 192. State = [[-0.17007163 -0.13529651]]. Action = [[0.03140029 0.03012384 0.         0.36797857]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 192 is [True, False, False, True, False, False]
State prediction error at timestep 192 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 192 of None
Current timestep = 193. State = [[-0.16978692 -0.12848854]]. Action = [[ 0.00656237  0.09354534  0.         -0.36648762]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 193 is [True, False, False, True, False, False]
State prediction error at timestep 193 is tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 193 of None
Current timestep = 194. State = [[-0.16781454 -0.12655236]]. Action = [[ 0.05708151 -0.04371686  0.          0.47513294]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 194 is [True, False, False, True, False, False]
State prediction error at timestep 194 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 194 of None
Current timestep = 195. State = [[-0.16782583 -0.12442905]]. Action = [[-0.01779375  0.04235553  0.         -0.8609843 ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 195 is [True, False, False, False, True, False]
State prediction error at timestep 195 is tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 195 of None
Current timestep = 196. State = [[-0.16602357 -0.12658134]]. Action = [[ 0.05932758 -0.08730996  0.          0.4440391 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 196 is [True, False, False, True, False, False]
State prediction error at timestep 196 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 196 of None
Current timestep = 197. State = [[-0.16438141 -0.12946422]]. Action = [[ 0.00450791 -0.01971347  0.         -0.46942592]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 197 is [True, False, False, True, False, False]
State prediction error at timestep 197 is tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 197 of None
Current timestep = 198. State = [[-0.16320781 -0.13237536]]. Action = [[ 0.01796357 -0.04709416  0.         -0.09800684]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 198 is [True, False, False, True, False, False]
State prediction error at timestep 198 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 198 of None
Current timestep = 199. State = [[-0.16528031 -0.13224012]]. Action = [[-0.06066329  0.03592093  0.         -0.92163295]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 199 is [True, False, False, True, False, False]
State prediction error at timestep 199 is tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 199 of None
Current timestep = 200. State = [[-0.16308592 -0.1298561 ]]. Action = [[0.0766081  0.03129532 0.         0.49557257]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 200 is [True, False, False, True, False, False]
State prediction error at timestep 200 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 200 of None
Current timestep = 201. State = [[-0.15881953 -0.12540364]]. Action = [[ 0.04170042  0.06818094  0.         -0.9016541 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 201 is [True, False, False, True, False, False]
State prediction error at timestep 201 is tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 201 of None
Current timestep = 202. State = [[-0.15348615 -0.12461194]]. Action = [[ 0.07982295 -0.03120009  0.         -0.01796281]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 202 is [True, False, False, False, True, False]
State prediction error at timestep 202 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 202 of None
Current timestep = 203. State = [[-0.14709911 -0.12181418]]. Action = [[ 0.07860499  0.06573229  0.         -0.69627917]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 203 is [True, False, False, False, True, False]
State prediction error at timestep 203 is tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 203 of None
Current timestep = 204. State = [[-0.14658117 -0.11799689]]. Action = [[-0.04576306  0.03109819  0.         -0.34049845]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 204 is [True, False, False, False, True, False]
State prediction error at timestep 204 is tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 204 of None
Current timestep = 205. State = [[-0.147107   -0.11763189]]. Action = [[ 0.00085052 -0.0227257   0.          0.06691444]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 205 is [True, False, False, False, True, False]
State prediction error at timestep 205 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 205 of None
Current timestep = 206. State = [[-0.1506425  -0.11525325]]. Action = [[-0.08906895  0.05045999  0.         -0.15999377]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 206 is [True, False, False, False, True, False]
State prediction error at timestep 206 is tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 206 of None
Current timestep = 207. State = [[-0.15512384 -0.11562476]]. Action = [[-0.0588933  -0.04783098  0.         -0.07499313]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 207 is [True, False, False, False, True, False]
State prediction error at timestep 207 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 207 of None
Current timestep = 208. State = [[-0.16035646 -0.11201043]]. Action = [[-0.08636668  0.08767145  0.         -0.7197887 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 208 is [True, False, False, False, True, False]
State prediction error at timestep 208 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 208 of None
Current timestep = 209. State = [[-0.16042021 -0.11334401]]. Action = [[ 0.05153228 -0.09572721  0.         -0.23051631]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 209 is [True, False, False, False, True, False]
State prediction error at timestep 209 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 209 of None
Current timestep = 210. State = [[-0.1573447  -0.11462112]]. Action = [[ 0.021734    0.01939516  0.         -0.9660799 ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 210 is [True, False, False, False, True, False]
State prediction error at timestep 210 is tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 210 of None
Current timestep = 211. State = [[-0.1517947 -0.1186257]]. Action = [[ 0.08753536 -0.09383938  0.         -0.7511918 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 211 is [True, False, False, False, True, False]
State prediction error at timestep 211 is tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 211 of None
Current timestep = 212. State = [[-0.14810584 -0.1200159 ]]. Action = [[ 0.01020353  0.03045822  0.         -0.15673643]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 212 is [True, False, False, False, True, False]
State prediction error at timestep 212 is tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 212 of None
Current timestep = 213. State = [[-0.14492624 -0.11856889]]. Action = [[ 0.04492814  0.01952668  0.         -0.0274756 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 213 is [True, False, False, False, True, False]
State prediction error at timestep 213 is tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 213 of None
Current timestep = 214. State = [[-0.14543083 -0.12059633]]. Action = [[-0.04797783 -0.04706627  0.         -0.8874194 ]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 214 is [True, False, False, False, True, False]
State prediction error at timestep 214 is tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 214 of None
Current timestep = 215. State = [[-0.14275788 -0.12383542]]. Action = [[ 0.06835457 -0.02792741  0.         -0.8747029 ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 215 is [True, False, False, False, True, False]
State prediction error at timestep 215 is tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 215 of None
Current timestep = 216. State = [[-0.13692202 -0.12760039]]. Action = [[ 0.06969178 -0.04537316  0.         -0.48320687]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 216 is [True, False, False, True, False, False]
State prediction error at timestep 216 is tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 216 of None
Current timestep = 217. State = [[-0.13793874 -0.12693758]]. Action = [[-0.08729779  0.06075687  0.          0.62777877]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 217 is [True, False, False, True, False, False]
State prediction error at timestep 217 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 217 of None
Current timestep = 218. State = [[-0.14167175 -0.12284006]]. Action = [[-0.03395958  0.05820105  0.         -0.56183386]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 218 is [True, False, False, False, True, False]
State prediction error at timestep 218 is tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 218 of None
Current timestep = 219. State = [[-0.13883501 -0.11938652]]. Action = [[ 0.08842202  0.03041712  0.         -0.7791199 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 219 is [True, False, False, False, True, False]
State prediction error at timestep 219 is tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 219 of None
Current timestep = 220. State = [[-0.13241167 -0.12248179]]. Action = [[ 0.08825677 -0.08891974  0.         -0.8828833 ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 220 is [True, False, False, False, True, False]
State prediction error at timestep 220 is tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 220 of None
Current timestep = 221. State = [[-0.12967391 -0.12960869]]. Action = [[-3.9216131e-04 -9.0303965e-02  0.0000000e+00 -9.0667701e-01]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 221 is [True, False, False, True, False, False]
State prediction error at timestep 221 is tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 221 of None
Current timestep = 222. State = [[-0.12520452 -0.13366793]]. Action = [[ 0.0783845  -0.01325782  0.         -0.47893226]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 222 is [True, False, False, True, False, False]
State prediction error at timestep 222 is tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 222 of None
Current timestep = 223. State = [[-0.12180389 -0.13056546]]. Action = [[ 0.01376997  0.08796317  0.         -0.98658085]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 223 is [True, False, False, True, False, False]
State prediction error at timestep 223 is tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 223 of None
Current timestep = 224. State = [[-0.11772322 -0.12359157]]. Action = [[ 0.06568214  0.09662368  0.         -0.9814874 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 224 is [True, False, False, False, True, False]
State prediction error at timestep 224 is tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 224 of None
Current timestep = 225. State = [[-0.11175412 -0.12329891]]. Action = [[ 0.07810546 -0.05605414  0.         -0.9116442 ]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 225 is [True, False, False, False, True, False]
State prediction error at timestep 225 is tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 225 of None
Current timestep = 226. State = [[-0.10770214 -0.12100485]]. Action = [[ 0.02440158  0.07289266  0.         -0.70836556]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 226 is [True, False, False, False, True, False]
State prediction error at timestep 226 is tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 226 of None
Current timestep = 227. State = [[-0.10280323 -0.11375333]]. Action = [[ 0.07269251  0.09512161  0.         -0.8798352 ]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 227 is [True, False, False, False, True, False]
State prediction error at timestep 227 is tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 227 of None
Current timestep = 228. State = [[-0.10175988 -0.11367599]]. Action = [[-0.03612902 -0.07547991  0.         -0.92198867]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 228 is [True, False, False, False, True, False]
State prediction error at timestep 228 is tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 228 of None
Current timestep = 229. State = [[-0.09711868 -0.11605868]]. Action = [[ 0.09056532 -0.019853    0.         -0.66732836]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 229 is [True, False, False, False, True, False]
State prediction error at timestep 229 is tensor(0.0085, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 229 of None
Current timestep = 230. State = [[-0.09495109 -0.11965802]]. Action = [[-0.03603417 -0.06595498  0.          0.6482564 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 230 is [True, False, False, False, True, False]
State prediction error at timestep 230 is tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 230 of None
Current timestep = 231. State = [[-0.09536769 -0.1189028 ]]. Action = [[-0.02589919  0.0526622   0.         -0.31883043]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 231 is [True, False, False, False, True, False]
State prediction error at timestep 231 is tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 231 of None
Current timestep = 232. State = [[-0.09344714 -0.12116462]]. Action = [[ 0.02196995 -0.07633873  0.         -0.7025927 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 232 is [True, False, False, False, True, False]
State prediction error at timestep 232 is tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 232 of None
Current timestep = 233. State = [[-0.09388387 -0.1276313 ]]. Action = [[-0.05558281 -0.08173689  0.         -0.6128802 ]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 233 is [True, False, False, True, False, False]
State prediction error at timestep 233 is tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 233 of None
Current timestep = 234. State = [[-0.09749436 -0.1301453 ]]. Action = [[-0.08147253  0.01356877  0.         -0.25118566]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 234 is [True, False, False, True, False, False]
State prediction error at timestep 234 is tensor(0.0076, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 234 of None
Current timestep = 235. State = [[-0.0959801  -0.12813494]]. Action = [[ 0.05166782  0.04652192  0.         -0.9584807 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 235 is [True, False, False, True, False, False]
State prediction error at timestep 235 is tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 235 of None
Current timestep = 236. State = [[-0.09177445 -0.13159607]]. Action = [[ 0.03860941 -0.08854376  0.          0.77237105]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 236 is [True, False, False, True, False, False]
State prediction error at timestep 236 is tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 236 of None
Current timestep = 237. State = [[-0.08785226 -0.1299776 ]]. Action = [[ 0.04075079  0.09514409  0.         -0.44616377]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 237 is [True, False, False, True, False, False]
State prediction error at timestep 237 is tensor(0.0087, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 237 of None
Current timestep = 238. State = [[-0.08617593 -0.12726302]]. Action = [[-0.00191407  0.006726    0.          0.05251479]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 238 is [True, False, False, True, False, False]
State prediction error at timestep 238 is tensor(0.0074, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 238 of None
Current timestep = 239. State = [[-0.08271077 -0.12484033]]. Action = [[ 0.06249734  0.04261472  0.         -0.39751267]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 239 is [True, False, False, False, True, False]
State prediction error at timestep 239 is tensor(0.0090, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 239 of None
Current timestep = 240. State = [[-0.07819421 -0.12309613]]. Action = [[ 0.0534177   0.00535719  0.         -0.18938398]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 240 is [True, False, False, False, True, False]
State prediction error at timestep 240 is tensor(0.0094, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 240 of None
Current timestep = 241. State = [[-0.07260642 -0.12459502]]. Action = [[ 0.07849348 -0.03903358  0.          0.11425495]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 241 is [True, False, False, False, True, False]
State prediction error at timestep 241 is tensor(0.0080, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 241 of None
Current timestep = 242. State = [[-0.07327331 -0.12281477]]. Action = [[-0.07928754  0.0601706   0.         -0.75666744]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 242 is [True, False, False, False, True, False]
State prediction error at timestep 242 is tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 242 of None
Current timestep = 243. State = [[-0.07621196 -0.12510502]]. Action = [[-0.02245636 -0.08554407  0.         -0.56010056]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 243 is [True, False, False, True, False, False]
State prediction error at timestep 243 is tensor(0.0089, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 243 of None
Current timestep = 244. State = [[-0.07933091 -0.12692016]]. Action = [[-0.05432862  0.00989646  0.         -0.91395444]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 244 is [True, False, False, True, False, False]
State prediction error at timestep 244 is tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 244 of None
Current timestep = 245. State = [[-0.07856935 -0.12784502]]. Action = [[ 0.04419396 -0.02299352  0.         -0.88941836]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 245 is [True, False, False, True, False, False]
State prediction error at timestep 245 is tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 245 of None
Current timestep = 246. State = [[-0.07889704 -0.12513839]]. Action = [[-0.03340079  0.06752204  0.         -0.5340969 ]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 246 is [True, False, False, True, False, False]
State prediction error at timestep 246 is tensor(0.0087, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 246 of None
Current timestep = 247. State = [[-0.08156182 -0.11845809]]. Action = [[-0.0372306   0.08939011  0.         -0.5996798 ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 247 is [True, False, False, False, True, False]
State prediction error at timestep 247 is tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 247 of None
Current timestep = 248. State = [[-0.08103497 -0.11518127]]. Action = [[ 0.03807179 -0.00397983  0.         -0.16885108]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 248 is [True, False, False, False, True, False]
State prediction error at timestep 248 is tensor(0.0083, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 248 of None
Current timestep = 249. State = [[-0.07971642 -0.11718803]]. Action = [[ 0.01185431 -0.05619736  0.         -0.9152822 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 249 is [True, False, False, False, True, False]
State prediction error at timestep 249 is tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 249 of None
Current timestep = 250. State = [[-0.08151709 -0.12093799]]. Action = [[-0.04437668 -0.04995789  0.         -0.4438148 ]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 250 is [True, False, False, False, True, False]
State prediction error at timestep 250 is tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 250 of None
Current timestep = 251. State = [[-0.07847848 -0.12282401]]. Action = [[ 0.08941735 -0.00826125  0.          0.79118454]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 251 is [True, False, False, False, True, False]
State prediction error at timestep 251 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 251 of None
Current timestep = 252. State = [[-0.07199185 -0.11867189]]. Action = [[ 0.08880136  0.09011982  0.         -0.8408416 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 252 is [True, False, False, False, True, False]
State prediction error at timestep 252 is tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 252 of None
Current timestep = 253. State = [[-0.07149649 -0.11118452]]. Action = [[-0.04087759  0.09437845  0.         -0.9426048 ]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 253 is [True, False, False, False, True, False]
State prediction error at timestep 253 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 253 of None
Current timestep = 254. State = [[-0.0736263  -0.10740632]]. Action = [[-0.01887534  0.00470914  0.         -0.88149875]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 254 is [True, False, False, False, True, False]
State prediction error at timestep 254 is tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 254 of None
Current timestep = 255. State = [[-0.06971951 -0.10859825]]. Action = [[ 0.09957046 -0.04670478  0.         -0.9585923 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 255 is [True, False, False, False, True, False]
State prediction error at timestep 255 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 255 of None
Current timestep = 256. State = [[-0.06995042 -0.10597369]]. Action = [[-0.07462709  0.07112799  0.         -0.12121713]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 256 is [True, False, False, False, True, False]
State prediction error at timestep 256 is tensor(0.0082, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 256 of None
Current timestep = 257. State = [[-0.07457298 -0.10232142]]. Action = [[-0.05257046  0.01552172  0.         -0.6954086 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 257 is [True, False, False, False, True, False]
State prediction error at timestep 257 is tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 257 of None
Current timestep = 258. State = [[-0.07982037 -0.10004878]]. Action = [[-0.07234057  0.01344629  0.         -0.10722435]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 258 is [True, False, False, False, True, False]
State prediction error at timestep 258 is tensor(0.0074, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 258 of None
Current timestep = 259. State = [[-0.08097588 -0.10088588]]. Action = [[ 0.02452465 -0.04589802  0.         -0.43979377]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 259 is [True, False, False, False, True, False]
State prediction error at timestep 259 is tensor(0.0075, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 259 of None
Current timestep = 260. State = [[-0.0823664  -0.10477456]]. Action = [[-0.03729273 -0.06448126  0.          0.3881147 ]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 260 is [True, False, False, False, True, False]
State prediction error at timestep 260 is tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 260 of None
Current timestep = 261. State = [[-0.08415487 -0.10973743]]. Action = [[-0.01674557 -0.06308734  0.          0.35896087]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 261 is [True, False, False, False, True, False]
State prediction error at timestep 261 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 261 of None
Current timestep = 262. State = [[-0.08299139 -0.11441307]]. Action = [[ 0.0338257  -0.04755974  0.          0.27368164]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 262 is [True, False, False, False, True, False]
State prediction error at timestep 262 is tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 262 of None
Current timestep = 263. State = [[-0.07760362 -0.11291598]]. Action = [[ 0.09825271  0.07306144  0.         -0.8265477 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 263 is [True, False, False, False, True, False]
State prediction error at timestep 263 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 263 of None
Current timestep = 264. State = [[-0.07584672 -0.10769747]]. Action = [[-0.01077856  0.07376336  0.         -0.07547539]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 264 is [True, False, False, False, True, False]
State prediction error at timestep 264 is tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 264 of None
Current timestep = 265. State = [[-0.07700337 -0.1016254 ]]. Action = [[-0.00984494  0.07857186  0.          0.02294111]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 265 is [True, False, False, False, True, False]
State prediction error at timestep 265 is tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 265 of None
Current timestep = 266. State = [[-0.07658838 -0.09775688]]. Action = [[0.02622204 0.02156143 0.         0.24346161]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 266 is [True, False, False, False, True, False]
State prediction error at timestep 266 is tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 266 of None
Current timestep = 267. State = [[-0.07773773 -0.09491994]]. Action = [[-0.02837231  0.02925659  0.         -0.60072744]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 267 is [True, False, False, False, True, False]
State prediction error at timestep 267 is tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 267 of None
Current timestep = 268. State = [[-0.07759653 -0.09816907]]. Action = [[ 0.02398013 -0.09731371  0.         -0.15434766]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 268 is [True, False, False, False, True, False]
State prediction error at timestep 268 is tensor(0.0071, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 268 of None
Current timestep = 269. State = [[-0.08063384 -0.10396546]]. Action = [[-0.0789359  -0.06632335  0.          0.03132367]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 269 is [True, False, False, False, True, False]
State prediction error at timestep 269 is tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 269 of None
Current timestep = 270. State = [[-0.07901564 -0.10323166]]. Action = [[ 0.07775206  0.05648781  0.         -0.80053717]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 270 is [True, False, False, False, True, False]
State prediction error at timestep 270 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 270 of None
Current timestep = 271. State = [[-0.0789854  -0.09759409]]. Action = [[-0.0418909   0.07929084  0.         -0.29894078]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 271 is [True, False, False, False, True, False]
State prediction error at timestep 271 is tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 271 of None
Current timestep = 272. State = [[-0.08075091 -0.09698773]]. Action = [[-0.01402382 -0.04455657  0.          0.20696151]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 272 is [True, False, False, False, True, False]
State prediction error at timestep 272 is tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 272 of None
Current timestep = 273. State = [[-0.07902152 -0.10130339]]. Action = [[ 0.04417313 -0.06809179  0.          0.85092926]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 273 is [True, False, False, False, True, False]
State prediction error at timestep 273 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 273 of None
Current timestep = 274. State = [[-0.07481825 -0.10403358]]. Action = [[ 0.06232005 -0.01075452  0.         -0.6231805 ]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 274 is [True, False, False, False, True, False]
State prediction error at timestep 274 is tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 274 of None
Current timestep = 275. State = [[-0.07250135 -0.10970042]]. Action = [[ 0.00882664 -0.0961043   0.         -0.64135456]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 275 is [True, False, False, False, True, False]
State prediction error at timestep 275 is tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 275 of None
Current timestep = 276. State = [[-0.06880277 -0.11284747]]. Action = [[0.06254917 0.01142285 0.         0.3280499 ]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 276 is [True, False, False, False, True, False]
State prediction error at timestep 276 is tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 276 of None
Current timestep = 277. State = [[-0.06730445 -0.10909937]]. Action = [[-0.01073998  0.09050272  0.         -0.04665679]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 277 is [True, False, False, False, True, False]
State prediction error at timestep 277 is tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 277 of None
Current timestep = 278. State = [[-0.0712785  -0.10215452]]. Action = [[-0.08570568  0.09609223  0.         -0.8342241 ]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 278 is [True, False, False, False, True, False]
State prediction error at timestep 278 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 278 of None
Current timestep = 279. State = [[-0.06953257 -0.10291668]]. Action = [[ 0.09345431 -0.08052297  0.         -0.92570287]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 279 is [True, False, False, False, True, False]
State prediction error at timestep 279 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 279 of None
Current timestep = 280. State = [[-0.06614398 -0.10801713]]. Action = [[-0.0013587  -0.05469605  0.         -0.37102276]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 280 is [True, False, False, False, True, False]
State prediction error at timestep 280 is tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 280 of None
Current timestep = 281. State = [[-0.06785389 -0.10703381]]. Action = [[-0.06680836  0.0620558   0.         -0.8225328 ]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 281 is [True, False, False, False, True, False]
State prediction error at timestep 281 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 281 of None
Current timestep = 282. State = [[-0.06783619 -0.10410515]]. Action = [[0.01259848 0.02437731 0.         0.13708079]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 282 is [True, False, False, False, True, False]
State prediction error at timestep 282 is tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 282 of None
Current timestep = 283. State = [[-0.06789996 -0.09914204]]. Action = [[-0.0250494   0.07598232  0.         -0.96977854]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 283 is [True, False, False, False, True, False]
State prediction error at timestep 283 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 283 of None
Current timestep = 284. State = [[-0.07146994 -0.09756666]]. Action = [[-0.07575284 -0.02814543  0.         -0.8902079 ]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 284 is [True, False, False, False, True, False]
State prediction error at timestep 284 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 284 of None
Current timestep = 285. State = [[-0.06879434 -0.10139219]]. Action = [[ 0.09565008 -0.07804678  0.          0.70493805]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 285 is [True, False, False, False, True, False]
State prediction error at timestep 285 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 285 of None
Current timestep = 286. State = [[-0.06891967 -0.09938551]]. Action = [[-0.08442501  0.0850196   0.          0.706267  ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 286 is [True, False, False, False, True, False]
State prediction error at timestep 286 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 286 of None
Current timestep = 287. State = [[-0.07444139 -0.09398496]]. Action = [[-0.07648765  0.04874492  0.         -0.36686844]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 287 is [True, False, False, False, True, False]
State prediction error at timestep 287 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 287 of None
Current timestep = 288. State = [[-0.07375656 -0.08829901]]. Action = [[ 0.06920148  0.06112327  0.         -0.7576747 ]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 288 is [True, False, False, False, True, False]
State prediction error at timestep 288 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 288 of None
Current timestep = 289. State = [[-0.06927942 -0.08963893]]. Action = [[ 0.06573725 -0.08649232  0.          0.0662601 ]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 289 is [True, False, False, False, True, False]
State prediction error at timestep 289 is tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 289 of None
Current timestep = 290. State = [[-0.07090641 -0.09261093]]. Action = [[-0.07681118 -0.02102212  0.         -0.6566087 ]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 290 is [True, False, False, False, True, False]
State prediction error at timestep 290 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 290 of None
Current timestep = 291. State = [[-0.07585315 -0.09605452]]. Action = [[-0.0580017  -0.06023573  0.         -0.6094841 ]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 291 is [True, False, False, False, True, False]
State prediction error at timestep 291 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 291 of None
Current timestep = 292. State = [[-0.07821991 -0.09768245]]. Action = [[-0.00926689  0.00316113  0.         -0.1858362 ]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 292 is [True, False, False, False, True, False]
State prediction error at timestep 292 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 292 of None
Current timestep = 293. State = [[-0.07967516 -0.10134121]]. Action = [[-0.01577621 -0.06921993  0.         -0.9212457 ]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 293 is [True, False, False, False, True, False]
State prediction error at timestep 293 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 293 of None
Current timestep = 294. State = [[-0.07613061 -0.10757962]]. Action = [[ 0.09351457 -0.07241698  0.          0.12498856]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 294 is [True, False, False, False, True, False]
State prediction error at timestep 294 is tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 294 of None
Current timestep = 295. State = [[-0.07458556 -0.10827214]]. Action = [[-0.0138489   0.05249805  0.         -0.96284735]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 295 is [True, False, False, False, True, False]
State prediction error at timestep 295 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 295 of None
Current timestep = 296. State = [[-0.07139631 -0.11238738]]. Action = [[ 0.08568268 -0.09083103  0.          0.5596614 ]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 296 is [True, False, False, False, True, False]
State prediction error at timestep 296 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 296 of None
Current timestep = 297. State = [[-0.06979098 -0.11201414]]. Action = [[-0.0094654   0.08573849  0.          0.20355439]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 297 is [True, False, False, False, True, False]
State prediction error at timestep 297 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 297 of None
Current timestep = 298. State = [[-0.06790879 -0.10676375]]. Action = [[ 0.05543529  0.07574027  0.         -0.08405113]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 298 is [True, False, False, False, True, False]
State prediction error at timestep 298 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 298 of None
Current timestep = 299. State = [[-0.06644528 -0.10853694]]. Action = [[ 0.01275221 -0.07359684  0.         -0.95834327]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 299 is [True, False, False, False, True, False]
State prediction error at timestep 299 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 299 of None
Current timestep = 300. State = [[-0.07044248 -0.10771839]]. Action = [[-0.09188253  0.06810571  0.         -0.86397994]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 300 is [True, False, False, False, True, False]
State prediction error at timestep 300 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 300 of None
Current timestep = 301. State = [[-0.06982242 -0.10844053]]. Action = [[ 0.0816297  -0.0525126   0.          0.04302537]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 301 is [True, False, False, False, True, False]
State prediction error at timestep 301 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 301 of None
Current timestep = 302. State = [[-0.07127889 -0.10816055]]. Action = [[-0.08639731  0.04129194  0.         -0.64740026]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 302 is [True, False, False, False, True, False]
State prediction error at timestep 302 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 302 of None
Current timestep = 303. State = [[-0.07191429 -0.1048737 ]]. Action = [[0.03486221 0.04113758 0.         0.13628578]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 303 is [True, False, False, False, True, False]
State prediction error at timestep 303 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 303 of None
Current timestep = 304. State = [[-0.07236037 -0.10480254]]. Action = [[-0.02334759 -0.03109773  0.         -0.8594745 ]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 304 is [True, False, False, False, True, False]
State prediction error at timestep 304 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 304 of None
Current timestep = 305. State = [[-0.07408246 -0.10046863]]. Action = [[-0.02179058  0.09622443  0.         -0.09737033]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 305 is [True, False, False, False, True, False]
State prediction error at timestep 305 is tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 305 of None
Current timestep = 306. State = [[-0.07254257 -0.09809271]]. Action = [[ 0.05113504 -0.02282911  0.          0.322621  ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 306 is [True, False, False, False, True, False]
State prediction error at timestep 306 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 306 of None
Current timestep = 307. State = [[-0.06679458 -0.09527321]]. Action = [[ 0.09913371  0.05133148  0.         -0.6141987 ]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 307 is [True, False, False, False, True, False]
State prediction error at timestep 307 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 307 of None
Current timestep = 308. State = [[-0.06574693 -0.09701783]]. Action = [[-0.03049731 -0.07833579  0.         -0.85786146]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 308 is [True, False, False, False, True, False]
State prediction error at timestep 308 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 308 of None
Current timestep = 309. State = [[-0.06982157 -0.099775  ]]. Action = [[-0.07578351 -0.01784189  0.          0.96148634]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 309 is [True, False, False, False, True, False]
State prediction error at timestep 309 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 309 of None
Current timestep = 310. State = [[-0.06845433 -0.09628151]]. Action = [[ 0.06788141  0.0775881   0.         -0.24912238]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 310 is [True, False, False, False, True, False]
State prediction error at timestep 310 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 310 of None
Current timestep = 311. State = [[-0.06700291 -0.09331838]]. Action = [[-0.00876398  0.00552112  0.          0.5992118 ]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 311 is [True, False, False, False, True, False]
State prediction error at timestep 311 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 311 of None
Current timestep = 312. State = [[-0.06390388 -0.09397099]]. Action = [[ 0.06263942 -0.02738083  0.         -0.995379  ]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 312 is [True, False, False, False, True, False]
State prediction error at timestep 312 is tensor(6.5755e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 312 of None
Current timestep = 313. State = [[-0.06196669 -0.09211253]]. Action = [[-1.5832484e-05  4.7849543e-02  0.0000000e+00 -9.8492742e-01]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 313 is [True, False, False, False, True, False]
State prediction error at timestep 313 is tensor(4.6140e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 313 of None
Current timestep = 314. State = [[-0.0572894  -0.08704426]]. Action = [[0.09259333 0.06622834 0.         0.5162505 ]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 314 is [True, False, False, False, True, False]
State prediction error at timestep 314 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 314 of None
Current timestep = 315. State = [[-0.05044387 -0.08240774]]. Action = [[ 0.09090281  0.04024484  0.         -0.9352383 ]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 315 is [True, False, False, False, True, False]
State prediction error at timestep 315 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 315 of None
Current timestep = 316. State = [[-0.18604495 -0.03221656]]. Action = [[0.01185153 0.09014822 0.         0.49807823]]. Reward = [100.]
Curr episode timestep = 316
Scene graph at timestep 316 is [True, False, False, False, True, False]
State prediction error at timestep 316 is tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 316 of None
Current timestep = 317. State = [[-0.1934449  -0.03317354]]. Action = [[-0.07373514  0.035932    0.          0.6331867 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 317 is [True, False, False, False, True, False]
State prediction error at timestep 317 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 317 of None
Current timestep = 318. State = [[-0.19408157 -0.02741897]]. Action = [[ 0.06983908  0.09250028  0.         -0.78581196]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 318 is [True, False, False, False, True, False]
State prediction error at timestep 318 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 318 of None
Current timestep = 319. State = [[-0.19229497 -0.02905893]]. Action = [[ 0.03759862 -0.0954158   0.         -0.8149729 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 319 is [True, False, False, False, True, False]
State prediction error at timestep 319 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 319 of None
Current timestep = 320. State = [[-0.1925582  -0.03534839]]. Action = [[-0.00234128 -0.06812812  0.         -0.82736313]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 320 is [True, False, False, False, True, False]
State prediction error at timestep 320 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 320 of None
Current timestep = 321. State = [[-0.19059803 -0.03669779]]. Action = [[ 0.06181519  0.02952261  0.         -0.7082916 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 321 is [True, False, False, False, True, False]
State prediction error at timestep 321 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 321 of None
Current timestep = 322. State = [[-0.19285886 -0.03229027]]. Action = [[-0.06012329  0.08797897  0.         -0.0436061 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 322 is [True, False, False, False, True, False]
State prediction error at timestep 322 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 322 of None
Current timestep = 323. State = [[-0.19759028 -0.02529373]]. Action = [[-0.03237077  0.09400576  0.         -0.65993226]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 323 is [True, False, False, False, True, False]
State prediction error at timestep 323 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 323 of None
Current timestep = 324. State = [[-0.19594637 -0.02428262]]. Action = [[ 0.09405703 -0.0414823   0.         -0.3707137 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 324 is [True, False, False, False, True, False]
State prediction error at timestep 324 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 324 of None
Current timestep = 325. State = [[-0.19508158 -0.02045687]]. Action = [[-0.00761622  0.09413958  0.         -0.4225403 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 325 is [True, False, False, False, True, False]
State prediction error at timestep 325 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 325 of None
Current timestep = 326. State = [[-0.19825706 -0.02073514]]. Action = [[-0.04113787 -0.06863061  0.         -0.89098907]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 326 is [True, False, False, False, True, False]
State prediction error at timestep 326 is tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 326 of None
Current timestep = 327. State = [[-0.20224468 -0.0188073 ]]. Action = [[-0.04413927  0.06716467  0.          0.3922112 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 327 is [True, False, False, False, True, False]
State prediction error at timestep 327 is tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 327 of None
Current timestep = 328. State = [[-0.20311321 -0.01704209]]. Action = [[ 0.02435204 -0.01461549  0.         -0.9379036 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 328 is [True, False, False, False, True, False]
State prediction error at timestep 328 is tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 328 of None
Current timestep = 329. State = [[-0.19946484 -0.01660273]]. Action = [[ 0.07696142  0.00361027  0.         -0.24558246]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 329 is [True, False, False, False, True, False]
State prediction error at timestep 329 is tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 329 of None
Current timestep = 330. State = [[-0.20178531 -0.01470437]]. Action = [[-0.08968778  0.02715828  0.         -0.97710234]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 330 is [True, False, False, False, True, False]
State prediction error at timestep 330 is tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 330 of None
Current timestep = 331. State = [[-0.20682015 -0.01248803]]. Action = [[-0.03966068  0.01607104  0.          0.2875929 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 331 is [True, False, False, False, True, False]
State prediction error at timestep 331 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 331 of None
Current timestep = 332. State = [[-0.20734   -0.0064551]]. Action = [[ 0.03598507  0.09611126  0.         -0.49144018]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 332 is [True, False, False, False, True, False]
State prediction error at timestep 332 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 332 of None
Current timestep = 333. State = [[-2.0690946e-01 -1.1433615e-04]]. Action = [[ 0.01770635  0.05103337  0.         -0.9859259 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 333 is [True, False, False, False, True, False]
State prediction error at timestep 333 is tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 333 of None
Current timestep = 334. State = [[-0.2091163   0.00491456]]. Action = [[-0.03104451  0.04515808  0.         -0.8364887 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 334 is [True, False, False, False, True, False]
State prediction error at timestep 334 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 334 of None
Current timestep = 335. State = [[-0.21372278  0.00933472]]. Action = [[-0.05569751  0.0340815   0.         -0.8766092 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 335 is [True, False, False, False, True, False]
State prediction error at timestep 335 is tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 335 of None
Current timestep = 336. State = [[-0.21418758  0.01155927]]. Action = [[ 0.04369695 -0.00549036  0.         -0.4613874 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 336 is [True, False, False, False, True, False]
State prediction error at timestep 336 is tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 336 of None
Current timestep = 337. State = [[-0.21828209  0.01733153]]. Action = [[-0.09220613  0.08986337  0.         -0.72134674]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 337 is [True, False, False, False, True, False]
State prediction error at timestep 337 is tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 337 of None
Current timestep = 338. State = [[-0.22176231  0.02574595]]. Action = [[ 0.00639872  0.08406541  0.         -0.8329116 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 338 is [True, False, False, False, True, False]
State prediction error at timestep 338 is tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 338 of None
Current timestep = 339. State = [[-0.22698136  0.02950851]]. Action = [[-0.0807749  -0.01257744  0.         -0.95212734]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 339 is [True, False, False, False, True, False]
State prediction error at timestep 339 is tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 339 of None
Current timestep = 340. State = [[-0.23427822  0.03310697]]. Action = [[-0.08109045  0.03940845  0.         -0.8274143 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 340 is [True, False, False, False, True, False]
State prediction error at timestep 340 is tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 340 of None
Current timestep = 341. State = [[-0.23360257  0.03118879]]. Action = [[ 0.09262551 -0.09472864  0.         -0.88172936]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 341 is [True, False, False, False, True, False]
State prediction error at timestep 341 is tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 341 of None
Current timestep = 342. State = [[-0.2362441   0.03310738]]. Action = [[-0.09712332  0.07019674  0.         -0.6871707 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 342 is [True, False, False, False, True, False]
State prediction error at timestep 342 is tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 342 of None
Current timestep = 343. State = [[-0.2355367   0.03642889]]. Action = [[ 0.09542974  0.00679877  0.         -0.7911701 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 343 is [True, False, False, False, True, False]
State prediction error at timestep 343 is tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 343 of None
Current timestep = 344. State = [[-0.23396546  0.04065847]]. Action = [[-0.00492574  0.0619627   0.         -0.91450304]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 344 is [True, False, False, False, True, False]
State prediction error at timestep 344 is tensor(0.0074, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 344 of None
Current timestep = 345. State = [[-0.23055637  0.04747154]]. Action = [[ 0.08516229  0.08394561  0.         -0.86286813]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 345 is [True, False, False, False, True, False]
State prediction error at timestep 345 is tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 345 of None
Current timestep = 346. State = [[-0.22666588  0.05047208]]. Action = [[ 0.04471678 -0.0057978   0.         -0.99193394]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 346 is [True, False, False, False, True, False]
State prediction error at timestep 346 is tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 346 of None
Current timestep = 347. State = [[-0.22107932  0.05018592]]. Action = [[ 0.0879839  -0.01781151  0.         -0.94075984]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 347 is [True, False, False, False, True, False]
State prediction error at timestep 347 is tensor(0.0075, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 347 of None
Current timestep = 348. State = [[-0.21762526  0.05446697]]. Action = [[ 0.01353999  0.08718143  0.         -0.4362285 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 348 is [True, False, False, False, True, False]
State prediction error at timestep 348 is tensor(0.0082, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 348 of None
Current timestep = 349. State = [[-0.2136817   0.05273863]]. Action = [[ 0.05863182 -0.09838398  0.         -0.5915705 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 349 is [True, False, False, False, True, False]
State prediction error at timestep 349 is tensor(0.0072, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 349 of None
Current timestep = 350. State = [[-0.21158908  0.04845076]]. Action = [[-0.01903856 -0.03954691  0.          0.14760208]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 350 is [True, False, False, False, True, False]
State prediction error at timestep 350 is tensor(0.0089, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 350 of None
Current timestep = 351. State = [[-0.20626143  0.05196981]]. Action = [[ 0.09104259  0.09367571  0.         -0.7939128 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 351 is [True, False, False, False, True, False]
State prediction error at timestep 351 is tensor(0.0071, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 351 of None
Current timestep = 352. State = [[-0.1993609   0.05708737]]. Action = [[ 0.06346586  0.04724199  0.         -0.49365246]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 352 is [True, False, False, False, True, False]
State prediction error at timestep 352 is tensor(0.0077, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 352 of None
Current timestep = 353. State = [[-0.20023598  0.06349615]]. Action = [[-0.08867712  0.08914562  0.         -0.3189423 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 353 is [True, False, False, False, True, False]
State prediction error at timestep 353 is tensor(0.0095, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 353 of None
Current timestep = 354. State = [[-0.20257032  0.06575321]]. Action = [[-0.02080842 -0.02907237  0.         -0.6844312 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 354 is [True, False, False, False, True, False]
State prediction error at timestep 354 is tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 354 of None
Current timestep = 355. State = [[-0.19809462  0.07033327]]. Action = [[0.0948169  0.08517284 0.         0.12938285]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 355 is [True, False, False, False, True, False]
State prediction error at timestep 355 is tensor(0.0111, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 355 of None
Current timestep = 356. State = [[-0.19693826  0.0753085 ]]. Action = [[-0.04757467  0.02716831  0.         -0.13715506]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 356 is [True, False, False, False, True, False]
State prediction error at timestep 356 is tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 356 of None
Current timestep = 357. State = [[-0.19549543  0.07985259]]. Action = [[ 0.04282906  0.04446075  0.         -0.965465  ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 357 is [True, False, False, False, True, False]
State prediction error at timestep 357 is tensor(0.0090, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 357 of None
Current timestep = 358. State = [[-0.19011408  0.08550338]]. Action = [[ 0.08161964  0.06033658  0.         -0.9477744 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 358 is [True, False, False, False, True, False]
State prediction error at timestep 358 is tensor(0.0095, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 358 of None
Current timestep = 359. State = [[-0.18415466  0.08800472]]. Action = [[ 0.06708188 -0.00977646  0.          0.54889464]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 359 is [True, False, False, False, True, False]
State prediction error at timestep 359 is tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 359 of None
Current timestep = 360. State = [[-0.17974466  0.09250002]]. Action = [[ 0.03508932  0.07189072  0.         -0.00216669]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 360 is [True, False, False, False, True, False]
State prediction error at timestep 360 is tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 360 of None
Current timestep = 361. State = [[-0.1736311   0.09751624]]. Action = [[0.08829207 0.03698904 0.         0.72948015]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 361 is [True, False, False, False, True, False]
State prediction error at timestep 361 is tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 361 of None
Current timestep = 362. State = [[-0.1681501   0.10172497]]. Action = [[ 0.04163463  0.04022165  0.         -0.7161324 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 362 is [True, False, False, False, True, False]
State prediction error at timestep 362 is tensor(0.0098, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 362 of None
Current timestep = 363. State = [[-0.17012273  0.10921957]]. Action = [[-0.0919165   0.09788194  0.          0.7330234 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 363 is [True, False, False, False, True, False]
State prediction error at timestep 363 is tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 363 of None
Current timestep = 364. State = [[-0.1669867   0.11077838]]. Action = [[ 0.09670176 -0.06280027  0.         -0.85736406]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 364 is [True, False, False, False, True, False]
State prediction error at timestep 364 is tensor(0.0090, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 364 of None
Current timestep = 365. State = [[-0.15994753  0.10971774]]. Action = [[ 0.0603688  -0.01575383  0.          0.08580399]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 365 is [True, False, False, False, True, False]
State prediction error at timestep 365 is tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 365 of None
Current timestep = 366. State = [[-0.15775424  0.11086081]]. Action = [[-0.0298913   0.00985235  0.         -0.87130105]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 366 is [True, False, False, False, True, False]
State prediction error at timestep 366 is tensor(0.0090, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 366 of None
Current timestep = 367. State = [[-0.15306193  0.11561587]]. Action = [[ 0.07743875  0.06772221  0.         -0.49214935]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 367 is [True, False, False, False, True, False]
State prediction error at timestep 367 is tensor(0.0102, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 367 of None
Current timestep = 368. State = [[-0.15226974  0.12170437]]. Action = [[-0.0621279  0.0587666  0.        -0.7718304]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 368 is [True, False, False, False, True, False]
State prediction error at timestep 368 is tensor(0.0099, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 368 of None
Current timestep = 369. State = [[-0.15261117  0.12834458]]. Action = [[ 0.00153668  0.06563554  0.         -0.77121174]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 369 is [True, False, False, False, False, True]
State prediction error at timestep 369 is tensor(0.0104, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 369 of None
Current timestep = 370. State = [[-0.14731982  0.1359743 ]]. Action = [[ 0.09753089  0.08375744  0.         -0.7193367 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 370 is [True, False, False, False, False, True]
State prediction error at timestep 370 is tensor(0.0109, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 370 of None
Current timestep = 371. State = [[-0.14355735  0.14326061]]. Action = [[ 0.01206796  0.06808909  0.         -0.1484226 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 371 is [True, False, False, False, False, True]
State prediction error at timestep 371 is tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 371 of None
Current timestep = 372. State = [[-0.13832293  0.14331119]]. Action = [[ 0.08147437 -0.07267924  0.          0.28157055]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 372 is [True, False, False, False, False, True]
State prediction error at timestep 372 is tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 372 of None
Current timestep = 373. State = [[-0.13668989  0.14056516]]. Action = [[-0.04483504 -0.04516206  0.         -0.93585247]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 373 is [True, False, False, False, False, True]
State prediction error at timestep 373 is tensor(0.0089, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 373 of None
Current timestep = 374. State = [[-0.13215403  0.14036626]]. Action = [[8.6417936e-02 1.9238144e-04 0.0000000e+00 2.1290123e-01]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 374 is [True, False, False, False, False, True]
State prediction error at timestep 374 is tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 374 of None
Current timestep = 375. State = [[-0.12947431  0.13833345]]. Action = [[-0.03515954 -0.05876913  0.         -0.9239963 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 375 is [True, False, False, False, False, True]
State prediction error at timestep 375 is tensor(0.0082, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 375 of None
Current timestep = 376. State = [[-0.1312296   0.14043869]]. Action = [[-0.05864388  0.05733129  0.          0.11837578]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 376 is [True, False, False, False, False, True]
State prediction error at timestep 376 is tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 376 of None
Current timestep = 377. State = [[-0.12925804  0.14710358]]. Action = [[ 0.05294404  0.08426946  0.         -0.46221733]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 377 is [True, False, False, False, False, True]
State prediction error at timestep 377 is tensor(0.0097, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 377 of None
Current timestep = 378. State = [[-0.1255887   0.15365629]]. Action = [[ 0.03236107  0.06480313  0.         -0.24293602]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 378 is [True, False, False, False, False, True]
State prediction error at timestep 378 is tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 378 of None
Current timestep = 379. State = [[-0.126926    0.15997979]]. Action = [[-0.05798434  0.06494939  0.          0.30246925]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 379 is [True, False, False, False, False, True]
State prediction error at timestep 379 is tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 379 of None
Current timestep = 380. State = [[-0.13248536  0.16321263]]. Action = [[-0.09123563 -0.0098684   0.         -0.4061725 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 380 is [True, False, False, False, False, True]
State prediction error at timestep 380 is tensor(0.0101, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 380 of None
Current timestep = 381. State = [[-0.13644637  0.1634927 ]]. Action = [[-0.03771004 -0.03331573  0.         -0.8857828 ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 381 is [True, False, False, False, False, True]
State prediction error at timestep 381 is tensor(0.0084, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 381 of None
Current timestep = 382. State = [[-0.13661854  0.15953927]]. Action = [[ 0.0098634  -0.09694251  0.          0.15162456]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 382 is [True, False, False, False, False, True]
State prediction error at timestep 382 is tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 382 of None
Current timestep = 383. State = [[-0.13662837  0.16246669]]. Action = [[-0.01236192  0.09550025  0.         -0.9462384 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 383 is [True, False, False, False, False, True]
State prediction error at timestep 383 is tensor(0.0080, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 383 of None
Current timestep = 384. State = [[-0.14049107  0.16659607]]. Action = [[-0.06694706  0.00591914  0.          0.3810197 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 384 is [True, False, False, False, False, True]
State prediction error at timestep 384 is tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 384 of None
Current timestep = 385. State = [[-0.1426555  0.1649577]]. Action = [[-0.0008333  -0.0654867   0.         -0.63849175]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 385 is [True, False, False, False, False, True]
State prediction error at timestep 385 is tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 385 of None
Current timestep = 386. State = [[-0.14522536  0.16021651]]. Action = [[-0.05066428 -0.07608692  0.         -0.7467245 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 386 is [True, False, False, False, False, True]
State prediction error at timestep 386 is tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 386 of None
Current timestep = 387. State = [[-0.1501006   0.15916334]]. Action = [[-0.07035406  0.01191242  0.         -0.89853334]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 387 is [True, False, False, False, False, True]
State prediction error at timestep 387 is tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 387 of None
Current timestep = 388. State = [[-0.15350868  0.16218723]]. Action = [[-0.01628955  0.04753966  0.         -0.31506962]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 388 is [True, False, False, False, False, True]
State prediction error at timestep 388 is tensor(0.0083, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 388 of None
Current timestep = 389. State = [[-0.15160847  0.16075715]]. Action = [[ 0.07088231 -0.05704239  0.          0.32690752]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 389 is [True, False, False, False, False, True]
State prediction error at timestep 389 is tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 389 of None
Current timestep = 390. State = [[-0.15150467  0.16015173]]. Action = [[-0.02031896  0.03026891  0.         -0.40286708]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 390 is [True, False, False, False, False, True]
State prediction error at timestep 390 is tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 390 of None
Current timestep = 391. State = [[-0.14959906  0.15951146]]. Action = [[ 0.06639422 -0.01657367  0.          0.38169467]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 391 is [True, False, False, False, False, True]
State prediction error at timestep 391 is tensor(0.0111, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 391 of None
Current timestep = 392. State = [[-0.15187715  0.16213161]]. Action = [[-0.06622058  0.0770124   0.         -0.8483203 ]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 392 is [True, False, False, False, False, True]
State prediction error at timestep 392 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 392 of None
Current timestep = 393. State = [[-0.15100949  0.16623692]]. Action = [[ 0.08005103  0.0492112   0.         -0.68046904]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 393 is [True, False, False, False, False, True]
State prediction error at timestep 393 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 393 of None
Current timestep = 394. State = [[-0.1490956   0.16993068]]. Action = [[ 0.018935    0.05533818  0.         -0.05422103]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 394 is [True, False, False, False, False, True]
State prediction error at timestep 394 is tensor(0.0091, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 394 of None
Current timestep = 395. State = [[-0.14805278  0.17152819]]. Action = [[ 0.02647097  0.00491761  0.         -0.25470078]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 395 is [True, False, False, False, False, True]
State prediction error at timestep 395 is tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 395 of None
Current timestep = 396. State = [[-0.1431563  0.1690817]]. Action = [[ 0.09368201 -0.04795967  0.         -0.81853527]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 396 is [True, False, False, False, False, True]
State prediction error at timestep 396 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 396 of None
Current timestep = 397. State = [[-0.1409995   0.16991928]]. Action = [[-0.01036333  0.05367155  0.         -0.57695645]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 397 is [True, False, False, False, False, True]
State prediction error at timestep 397 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 397 of None
Current timestep = 398. State = [[-0.14552015  0.17060286]]. Action = [[-0.09796377 -0.02093121  0.         -0.40949917]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 398 is [True, False, False, False, False, True]
State prediction error at timestep 398 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 398 of None
Current timestep = 399. State = [[-0.148407    0.17064409]]. Action = [[-0.01016746 -0.00275965  0.         -0.51793283]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 399 is [True, False, False, False, False, True]
State prediction error at timestep 399 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 399 of None
Current timestep = 400. State = [[-0.1493581   0.16673926]]. Action = [[-0.01724321 -0.08908166  0.         -0.53926814]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 400 is [True, False, False, False, False, True]
State prediction error at timestep 400 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 400 of None
Current timestep = 401. State = [[-0.14680952  0.16245371]]. Action = [[ 0.05001435 -0.04025743  0.         -0.9934623 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 401 is [True, False, False, False, False, True]
State prediction error at timestep 401 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 401 of None
Current timestep = 402. State = [[-0.1486541  0.1621818]]. Action = [[-0.07908053  0.02167807  0.          0.60197806]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 402 is [True, False, False, False, False, True]
State prediction error at timestep 402 is tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 402 of None
Current timestep = 403. State = [[-0.14797013  0.15871637]]. Action = [[ 0.04718464 -0.08235101  0.         -0.8415303 ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 403 is [True, False, False, False, False, True]
State prediction error at timestep 403 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 403 of None
Current timestep = 404. State = [[-0.14277282  0.1564247 ]]. Action = [[ 0.07153029  0.0137526   0.         -0.7283066 ]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 404 is [True, False, False, False, False, True]
State prediction error at timestep 404 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 404 of None
Current timestep = 405. State = [[-0.14038037  0.15875746]]. Action = [[ 0.00195732  0.06149139  0.         -0.77827895]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 405 is [True, False, False, False, False, True]
State prediction error at timestep 405 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 405 of None
Current timestep = 406. State = [[-0.13841256  0.15806556]]. Action = [[ 0.03399021 -0.03458209  0.         -0.8287349 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 406 is [True, False, False, False, False, True]
State prediction error at timestep 406 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 406 of None
Current timestep = 407. State = [[-0.13981682  0.15972385]]. Action = [[-0.05421577  0.06355592  0.         -0.71773875]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 407 is [True, False, False, False, False, True]
State prediction error at timestep 407 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 407 of None
Current timestep = 408. State = [[-0.13744837  0.16601872]]. Action = [[0.08777755 0.09964433 0.         0.35871136]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 408 is [True, False, False, False, False, True]
State prediction error at timestep 408 is tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 408 of None
Current timestep = 409. State = [[-0.13727705  0.17258841]]. Action = [[-0.03960049  0.07394571  0.         -0.7673674 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 409 is [True, False, False, False, False, True]
State prediction error at timestep 409 is tensor(6.1613e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 409 of None
Current timestep = 410. State = [[-0.13760334  0.17387408]]. Action = [[ 0.02032544 -0.03052529  0.         -0.7641954 ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 410 is [True, False, False, False, False, True]
State prediction error at timestep 410 is tensor(1.8293e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 410 of None
Current timestep = 411. State = [[-0.13722053  0.17363189]]. Action = [[-0.00245807 -0.0033558   0.          0.5297909 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 411 is [True, False, False, False, False, True]
State prediction error at timestep 411 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 411 of None
Current timestep = 412. State = [[-0.13451488  0.16973117]]. Action = [[ 0.05014073 -0.08918399  0.          0.05031383]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 412 is [True, False, False, False, False, True]
State prediction error at timestep 412 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 412 of None
Current timestep = 413. State = [[-0.12910841  0.16467957]]. Action = [[ 0.06561085 -0.05378416  0.         -0.82324415]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 413 is [True, False, False, False, False, True]
State prediction error at timestep 413 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 413 of None
Current timestep = 414. State = [[-0.12416272  0.15916122]]. Action = [[ 0.0383283  -0.07025295  0.          0.73958945]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 414 is [True, False, False, False, False, True]
State prediction error at timestep 414 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 414 of None
Current timestep = 415. State = [[-0.11986996  0.16028081]]. Action = [[ 0.03833384  0.08048587  0.         -0.9651355 ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 415 is [True, False, False, False, False, True]
State prediction error at timestep 415 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 415 of None
Current timestep = 416. State = [[-0.11951022  0.16367221]]. Action = [[-0.03444133  0.03630342  0.         -0.70805544]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 416 is [True, False, False, False, False, True]
State prediction error at timestep 416 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 416 of None
Current timestep = 417. State = [[-0.11606888  0.16359347]]. Action = [[ 0.07100191 -0.01936097  0.          0.2970091 ]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 417 is [True, False, False, False, False, True]
State prediction error at timestep 417 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 417 of None
Current timestep = 418. State = [[-0.11320465  0.15839015]]. Action = [[-0.00459515 -0.08675406  0.         -0.230219  ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 418 is [True, False, False, False, False, True]
State prediction error at timestep 418 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 418 of None
Current timestep = 419. State = [[-0.11272145  0.15878265]]. Action = [[-0.01558597  0.06668124  0.         -0.10705018]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 419 is [True, False, False, False, False, True]
State prediction error at timestep 419 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 419 of None
Current timestep = 420. State = [[-0.10792295  0.15735108]]. Action = [[ 0.08892933 -0.05786657  0.         -0.4370476 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 420 is [True, False, False, False, False, True]
State prediction error at timestep 420 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 420 of None
Current timestep = 421. State = [[-0.10013652  0.1586926 ]]. Action = [[0.09242637 0.07652202 0.         0.09023726]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 421 is [True, False, False, False, False, True]
State prediction error at timestep 421 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 421 of None
Current timestep = 422. State = [[-0.09540709  0.15540074]]. Action = [[ 0.01971923 -0.09312426  0.         -0.60313267]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 422 is [True, False, False, False, False, True]
State prediction error at timestep 422 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 422 of None
Current timestep = 423. State = [[-0.08870494  0.14987797]]. Action = [[ 0.09730012 -0.04001926  0.          0.2828709 ]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 423 is [True, False, False, False, False, True]
State prediction error at timestep 423 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 423 of None
Current timestep = 424. State = [[-0.08844958  0.14672594]]. Action = [[-0.09181233 -0.01921806  0.         -0.83109766]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 424 is [True, False, False, False, False, True]
State prediction error at timestep 424 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 424 of None
Current timestep = 425. State = [[-0.08628498  0.14776598]]. Action = [[ 0.0812682   0.05395044  0.         -0.868702  ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 425 is [True, False, False, False, False, True]
State prediction error at timestep 425 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 425 of None
Current timestep = 426. State = [[-0.07899759  0.15285262]]. Action = [[0.09091359 0.09235809 0.         0.598106  ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 426 is [True, False, False, False, False, True]
State prediction error at timestep 426 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 426 of None
Current timestep = 427. State = [[-0.07809311  0.15877682]]. Action = [[-0.05220569  0.07412284  0.          0.10936797]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 427 is [True, False, False, False, False, True]
State prediction error at timestep 427 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 427 of None
Current timestep = 428. State = [[-0.07949328  0.16447626]]. Action = [[-0.00645233  0.06305242  0.         -0.0701645 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 428 is [True, False, False, False, False, True]
State prediction error at timestep 428 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 428 of None
Current timestep = 429. State = [[-0.0751892   0.16891903]]. Action = [[0.09607125 0.0394846  0.         0.7274227 ]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 429 is [True, False, False, False, False, True]
State prediction error at timestep 429 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 429 of None
Current timestep = 430. State = [[-0.07203169  0.17007725]]. Action = [[ 0.00756101 -0.01379795  0.          0.5263125 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 430 is [True, False, False, False, False, True]
State prediction error at timestep 430 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 430 of None
Current timestep = 431. State = [[-0.07302023  0.170069  ]]. Action = [[-0.03942317 -0.01377114  0.         -0.94864035]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 431 is [True, False, False, False, False, True]
State prediction error at timestep 431 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 431 of None
Current timestep = 432. State = [[-0.06917971  0.17504217]]. Action = [[ 0.09904965  0.09146481  0.         -0.12769777]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 432 is [True, False, False, False, False, True]
State prediction error at timestep 432 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 432 of None
Current timestep = 433. State = [[-0.06868783  0.17457855]]. Action = [[-0.08692148 -0.09438004  0.         -0.63977927]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 433 is [True, False, False, False, False, True]
State prediction error at timestep 433 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 433 of None
Current timestep = 434. State = [[-0.06745455  0.17600009]]. Action = [[ 0.06846143  0.0629921   0.         -0.6451024 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 434 is [True, False, False, False, False, True]
State prediction error at timestep 434 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 434 of None
Current timestep = 435. State = [[-0.06068081  0.17619409]]. Action = [[ 0.08961923 -0.04145808  0.          0.19869888]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 435 is [True, False, False, False, False, True]
State prediction error at timestep 435 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 435 of None
Current timestep = 436. State = [[-0.06100394  0.17854577]]. Action = [[-0.08498625  0.05956627  0.         -0.03712451]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 436 is [True, False, False, False, False, True]
State prediction error at timestep 436 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 436 of None
Current timestep = 437. State = [[-0.06247284  0.18278204]]. Action = [[-3.5867095e-04  3.1027384e-02  0.0000000e+00  7.8097582e-01]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 437 is [True, False, False, False, False, True]
State prediction error at timestep 437 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 437 of None
Current timestep = 438. State = [[-0.06070391  0.18812302]]. Action = [[ 0.03165197  0.06762481  0.         -0.96456945]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 438 is [True, False, False, False, False, True]
State prediction error at timestep 438 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 438 of None
Current timestep = 439. State = [[-0.06233489  0.19437684]]. Action = [[-0.05228326  0.06337228  0.         -0.89675266]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 439 is [True, False, False, False, False, True]
State prediction error at timestep 439 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 439 of None
Current timestep = 440. State = [[-0.060377    0.19279067]]. Action = [[ 0.06497986 -0.09891482  0.          0.8566419 ]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 440 is [True, False, False, False, False, True]
State prediction error at timestep 440 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 440 of None
Current timestep = 441. State = [[-0.05511896  0.19482413]]. Action = [[ 0.06448378  0.08357132  0.         -0.92626995]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 441 is [True, False, False, False, False, True]
State prediction error at timestep 441 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 441 of None
Current timestep = 442. State = [[-0.05516386  0.19508749]]. Action = [[-0.05756077 -0.05872153  0.         -0.81888294]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 442 is [True, False, False, False, False, True]
State prediction error at timestep 442 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 442 of None
Current timestep = 443. State = [[-0.05625702  0.19573896]]. Action = [[0.00074176 0.02995834 0.         0.1802324 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 443 is [True, False, False, False, False, True]
State prediction error at timestep 443 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 443 of None
Current timestep = 444. State = [[-0.05290508  0.19503386]]. Action = [[ 0.0673781  -0.03761851  0.         -0.871663  ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 444 is [True, False, False, False, False, True]
State prediction error at timestep 444 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 444 of None
Current timestep = 445. State = [[-0.05288314  0.19256915]]. Action = [[-0.04886719 -0.03133871  0.         -0.8509049 ]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 445 is [True, False, False, False, False, True]
State prediction error at timestep 445 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 445 of None
Current timestep = 446. State = [[-0.05782246  0.19497307]]. Action = [[-0.08785035  0.05911205  0.         -0.5092126 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 446 is [True, False, False, False, False, True]
State prediction error at timestep 446 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 446 of None
Current timestep = 447. State = [[-0.05819075  0.19422166]]. Action = [[ 0.03819413 -0.06173578  0.         -0.757402  ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 447 is [True, False, False, False, False, True]
State prediction error at timestep 447 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 447 of None
Current timestep = 448. State = [[-0.05333278  0.1894615 ]]. Action = [[ 0.07419535 -0.06157604  0.         -0.26733863]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 448 is [True, False, False, False, False, True]
State prediction error at timestep 448 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 448 of None
Current timestep = 449. State = [[-0.05509795  0.18809038]]. Action = [[-0.09427935  0.01628031  0.         -0.791532  ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 449 is [True, False, False, False, False, True]
State prediction error at timestep 449 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 449 of None
Current timestep = 450. State = [[-0.05564714  0.18933961]]. Action = [[0.039079   0.02061701 0.         0.6999843 ]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 450 is [True, False, False, False, False, True]
State prediction error at timestep 450 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 450 of None
Current timestep = 451. State = [[-0.05209192  0.18740498]]. Action = [[ 0.0535842  -0.04322369  0.         -0.65210915]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 451 is [True, False, False, False, False, True]
State prediction error at timestep 451 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 451 of None
Current timestep = 452. State = [[-0.05203281  0.18218006]]. Action = [[-0.03975767 -0.06947058  0.         -0.6796356 ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 452 is [True, False, False, False, False, True]
State prediction error at timestep 452 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 452 of None
Current timestep = 453. State = [[-0.05187664  0.17533918]]. Action = [[ 0.00886096 -0.08408941  0.          0.223688  ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 453 is [True, False, False, False, False, True]
State prediction error at timestep 453 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 453 of None
Current timestep = 454. State = [[-0.0481794  0.170285 ]]. Action = [[ 0.05593581 -0.02821187  0.          0.66351104]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 454 is [False, True, False, False, False, True]
State prediction error at timestep 454 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 454 of None
Current timestep = 455. State = [[-0.04835662  0.1715141 ]]. Action = [[-0.04521712  0.07275031  0.          0.38863897]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 455 is [False, True, False, False, False, True]
State prediction error at timestep 455 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 455 of None
Current timestep = 456. State = [[-0.04668597  0.1714712 ]]. Action = [[ 0.05644295 -0.02031497  0.         -0.31971574]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 456 is [False, True, False, False, False, True]
State prediction error at timestep 456 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 456 of None
Current timestep = 457. State = [[-0.04347973  0.17143522]]. Action = [[ 0.03616876  0.03398333  0.         -0.99689347]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 457 is [False, True, False, False, False, True]
State prediction error at timestep 457 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 457 of None
Current timestep = 458. State = [[-0.04211959  0.17489058]]. Action = [[0.0125974  0.07278246 0.         0.6528033 ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 458 is [False, True, False, False, False, True]
State prediction error at timestep 458 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 458 of None
Current timestep = 459. State = [[-0.0458126   0.17900833]]. Action = [[-0.07572332  0.04887991  0.         -0.6079391 ]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 459 is [False, True, False, False, False, True]
State prediction error at timestep 459 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 459 of None
Current timestep = 460. State = [[-0.04716538  0.17721568]]. Action = [[ 0.02187307 -0.07089917  0.          0.76403284]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 460 is [False, True, False, False, False, True]
State prediction error at timestep 460 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 460 of None
Current timestep = 461. State = [[-0.04496385  0.17485182]]. Action = [[ 0.0378954  -0.00775312  0.         -0.9849755 ]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 461 is [False, True, False, False, False, True]
State prediction error at timestep 461 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 461 of None
Current timestep = 462. State = [[-0.04470884  0.1736782 ]]. Action = [[-0.01505198 -0.01385823  0.          0.28755498]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 462 is [False, True, False, False, False, True]
State prediction error at timestep 462 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 462 of None
Current timestep = 463. State = [[-0.04786699  0.17073081]]. Action = [[-0.06277445 -0.05328531  0.          0.5096462 ]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 463 is [False, True, False, False, False, True]
State prediction error at timestep 463 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 463 of None
Current timestep = 464. State = [[-0.04522403  0.16950732]]. Action = [[0.09507061 0.01049405 0.         0.29248524]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 464 is [False, True, False, False, False, True]
State prediction error at timestep 464 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 464 of None
Current timestep = 465. State = [[-0.0437723   0.17218788]]. Action = [[-0.0306132   0.05435573  0.          0.77313066]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 465 is [False, True, False, False, False, True]
State prediction error at timestep 465 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 465 of None
Current timestep = 466. State = [[-0.03985877  0.17729934]]. Action = [[0.09692433 0.07409088 0.         0.20028007]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 466 is [False, True, False, False, False, True]
State prediction error at timestep 466 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 466 of None
Current timestep = 467. State = [[-0.03975108  0.18345442]]. Action = [[-0.0560289   0.07659016  0.          0.03656256]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 467 is [False, True, False, False, False, True]
State prediction error at timestep 467 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 467 of None
Current timestep = 468. State = [[-0.04415587  0.18418495]]. Action = [[-0.06241982 -0.04926784  0.         -0.7642311 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 468 is [False, True, False, False, False, True]
State prediction error at timestep 468 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 468 of None
Current timestep = 469. State = [[-0.04550421  0.1835544 ]]. Action = [[ 0.00236021 -0.00979757  0.          0.81110954]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 469 is [False, True, False, False, False, True]
State prediction error at timestep 469 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 469 of None
Current timestep = 470. State = [[-0.04708346  0.18038768]]. Action = [[-0.04060962 -0.07709982  0.         -0.95276743]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 470 is [False, True, False, False, False, True]
State prediction error at timestep 470 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 470 of None
Current timestep = 471. State = [[-0.05067399  0.18051524]]. Action = [[-0.06385813  0.02793127  0.         -0.7864066 ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 471 is [True, False, False, False, False, True]
State prediction error at timestep 471 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 471 of None
Current timestep = 472. State = [[-0.05631123  0.17977048]]. Action = [[-0.08771055 -0.05275123  0.         -0.68305767]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 472 is [True, False, False, False, False, True]
State prediction error at timestep 472 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 472 of None
Current timestep = 473. State = [[-0.05796317  0.17539835]]. Action = [[ 0.00722432 -0.07977861  0.          0.68337405]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 473 is [True, False, False, False, False, True]
State prediction error at timestep 473 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 473 of None
Current timestep = 474. State = [[-0.05556286  0.17150684]]. Action = [[ 0.04011638 -0.03509398  0.         -0.8046633 ]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 474 is [True, False, False, False, False, True]
State prediction error at timestep 474 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 474 of None
Current timestep = 475. State = [[-0.05418949  0.17095986]]. Action = [[ 0.00333098  0.0203289   0.         -0.9433328 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 475 is [True, False, False, False, False, True]
State prediction error at timestep 475 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 475 of None
Current timestep = 476. State = [[-0.05021369  0.1663721 ]]. Action = [[ 0.07958306 -0.08735388  0.         -0.77915967]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 476 is [True, False, False, False, False, True]
State prediction error at timestep 476 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 476 of None
Current timestep = 477. State = [[-0.05069807  0.15911466]]. Action = [[-0.06769274 -0.0740193   0.         -0.7942422 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 477 is [True, False, False, False, False, True]
State prediction error at timestep 477 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 477 of None
Current timestep = 478. State = [[-0.05174647  0.15566257]]. Action = [[ 0.00988408  0.00114918  0.         -0.05230415]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 478 is [True, False, False, False, False, True]
State prediction error at timestep 478 is tensor(9.0406e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 478 of None
Current timestep = 479. State = [[-0.05009476  0.15350291]]. Action = [[ 0.03242589 -0.01064234  0.         -0.74662197]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 479 is [True, False, False, False, False, True]
State prediction error at timestep 479 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 479 of None
Current timestep = 480. State = [[-0.05368069  0.14831145]]. Action = [[-0.09840836 -0.07138821  0.         -0.08760995]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 480 is [True, False, False, False, False, True]
State prediction error at timestep 480 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 480 of None
Current timestep = 481. State = [[-0.05294428  0.14244534]]. Action = [[ 0.08613933 -0.04291958  0.         -0.9798343 ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 481 is [True, False, False, False, False, True]
State prediction error at timestep 481 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 481 of None
Current timestep = 482. State = [[-0.05170412  0.13614526]]. Action = [[-0.02255277 -0.06267504  0.         -0.9690105 ]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 482 is [True, False, False, False, False, True]
State prediction error at timestep 482 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 482 of None
Current timestep = 483. State = [[-0.05641312  0.13511252]]. Action = [[-0.09073891  0.04814532  0.          0.48626256]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 483 is [True, False, False, False, False, True]
State prediction error at timestep 483 is tensor(6.0128e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 483 of None
Current timestep = 484. State = [[-0.05687074  0.13276272]]. Action = [[ 0.04794984 -0.04979857  0.          0.73534036]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 484 is [True, False, False, False, False, True]
State prediction error at timestep 484 is tensor(4.1278e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 484 of None
Current timestep = 485. State = [[-0.05964873  0.13392046]]. Action = [[-0.07268779  0.07521311  0.         -0.42847276]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 485 is [True, False, False, False, False, True]
State prediction error at timestep 485 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 485 of None
Current timestep = 486. State = [[-0.05943348  0.13310604]]. Action = [[ 0.0611145  -0.04367035  0.          0.02552819]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 486 is [True, False, False, False, False, True]
State prediction error at timestep 486 is tensor(1.9417e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 486 of None
Current timestep = 487. State = [[-0.05638402  0.12936972]]. Action = [[ 0.04525454 -0.03095014  0.          0.31174433]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 487 is [True, False, False, False, False, True]
State prediction error at timestep 487 is tensor(7.0397e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 487 of None
Current timestep = 488. State = [[-0.05622638  0.12620072]]. Action = [[-0.01371291 -0.02148351  0.         -0.651771  ]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 488 is [True, False, False, False, False, True]
State prediction error at timestep 488 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 488 of None
Current timestep = 489. State = [[-0.05393421  0.12809914]]. Action = [[ 0.06666458  0.07413066  0.         -0.8805777 ]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 489 is [True, False, False, False, False, True]
State prediction error at timestep 489 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 489 of None
Current timestep = 490. State = [[-0.0492068   0.13093989]]. Action = [[0.07857919 0.03761297 0.         0.8724617 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 490 is [False, True, False, False, False, True]
State prediction error at timestep 490 is tensor(2.2053e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 490 of None
Current timestep = 491. State = [[-0.05175731  0.13594007]]. Action = [[-0.09123781  0.08912777  0.         -0.8861072 ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 491 is [True, False, False, False, False, True]
State prediction error at timestep 491 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 491 of None
Current timestep = 492. State = [[-0.05961718  0.13583915]]. Action = [[-0.09934918 -0.06087896  0.         -0.8164157 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 492 is [True, False, False, False, False, True]
State prediction error at timestep 492 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 492 of None
Current timestep = 493. State = [[-0.06691379  0.13699998]]. Action = [[-0.08191719  0.03873125  0.          0.41963613]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 493 is [True, False, False, False, False, True]
State prediction error at timestep 493 is tensor(9.1801e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 493 of None
Current timestep = 494. State = [[-0.07085647  0.14168273]]. Action = [[-0.01028489  0.05232174  0.          0.1006887 ]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 494 is [True, False, False, False, False, True]
State prediction error at timestep 494 is tensor(8.2519e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 494 of None
Current timestep = 495. State = [[-0.0752199   0.14028607]]. Action = [[-0.05939303 -0.08350846  0.         -0.8734267 ]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 495 is [True, False, False, False, False, True]
State prediction error at timestep 495 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 495 of None
Current timestep = 496. State = [[-0.0759005  0.1374623]]. Action = [[ 0.03725865 -0.02798805  0.          0.41580582]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 496 is [True, False, False, False, False, True]
State prediction error at timestep 496 is tensor(3.6495e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 496 of None
Current timestep = 497. State = [[-0.07284296  0.14022022]]. Action = [[ 0.06396467  0.07074595  0.         -0.16293776]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 497 is [True, False, False, False, False, True]
State prediction error at timestep 497 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 497 of None
Current timestep = 498. State = [[-0.0720001   0.13793473]]. Action = [[-0.0029472  -0.08542409  0.         -0.9153493 ]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 498 is [True, False, False, False, False, True]
State prediction error at timestep 498 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 498 of None
Current timestep = 499. State = [[-0.06889968  0.13292156]]. Action = [[ 0.07228012 -0.04513639  0.         -0.47093332]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 499 is [True, False, False, False, False, True]
State prediction error at timestep 499 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 499 of None
Current timestep = 500. State = [[-0.06303347  0.13030735]]. Action = [[ 0.08552033 -0.00121915  0.          0.00141442]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 500 is [True, False, False, False, False, True]
State prediction error at timestep 500 is tensor(4.5360e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 500 of None
Current timestep = 501. State = [[-0.06333228  0.1329061 ]]. Action = [[-0.05575528  0.07898221  0.         -0.2139731 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 501 is [True, False, False, False, False, True]
State prediction error at timestep 501 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 501 of None
Current timestep = 502. State = [[-0.06313476  0.1313838 ]]. Action = [[ 0.03668465 -0.06094838  0.         -0.9359514 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 502 is [True, False, False, False, False, True]
State prediction error at timestep 502 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 502 of None
Current timestep = 503. State = [[-0.06213683  0.12510523]]. Action = [[-0.00345428 -0.07593755  0.         -0.00957137]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 503 is [True, False, False, False, False, True]
State prediction error at timestep 503 is tensor(9.0548e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 503 of None
Current timestep = 504. State = [[-0.06027256  0.11691274]]. Action = [[ 0.02509788 -0.09790611  0.         -0.8804873 ]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 504 is [True, False, False, False, True, False]
State prediction error at timestep 504 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 504 of None
Current timestep = 505. State = [[-0.05569888  0.11398189]]. Action = [[0.06378982 0.03102066 0.         0.5671929 ]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 505 is [True, False, False, False, True, False]
State prediction error at timestep 505 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 505 of None
Current timestep = 506. State = [[-0.05394944  0.11427677]]. Action = [[-0.01186339  0.02355348  0.         -0.585575  ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 506 is [True, False, False, False, True, False]
State prediction error at timestep 506 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 506 of None
Current timestep = 507. State = [[-0.05046522  0.11774746]]. Action = [[ 0.07139004  0.0821235   0.         -0.6152159 ]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 507 is [True, False, False, False, True, False]
State prediction error at timestep 507 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 507 of None
Current timestep = 508. State = [[-0.05170989  0.11994974]]. Action = [[-0.07755039  0.01138115  0.          0.7337606 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 508 is [True, False, False, False, True, False]
State prediction error at timestep 508 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 508 of None
Current timestep = 509. State = [[-0.05009175  0.12317397]]. Action = [[ 0.08828562  0.06556135  0.         -0.99313545]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 509 is [True, False, False, False, True, False]
State prediction error at timestep 509 is tensor(7.6700e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 509 of None
Current timestep = 510. State = [[-0.15367858  0.07896432]]. Action = [[ 0.07787991 -0.01192182  0.         -0.64921033]]. Reward = [100.]
Curr episode timestep = 193
Scene graph at timestep 510 is [True, False, False, False, True, False]
State prediction error at timestep 510 is tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 510 of None
Current timestep = 511. State = [[-0.15575679  0.08645852]]. Action = [[-0.05455391  0.07491086  0.         -0.7948948 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 511 is [True, False, False, False, True, False]
State prediction error at timestep 511 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 511 of None
Current timestep = 512. State = [[-0.15483223  0.09367724]]. Action = [[ 0.04478926  0.07287122  0.         -0.98999643]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 512 is [True, False, False, False, True, False]
State prediction error at timestep 512 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 512 of None
Current timestep = 513. State = [[-0.15031043  0.09457821]]. Action = [[ 0.06359791 -0.05338441  0.          0.11007965]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 513 is [True, False, False, False, True, False]
State prediction error at timestep 513 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 513 of None
Current timestep = 514. State = [[-0.14812973  0.09142245]]. Action = [[-0.00976153 -0.0582801   0.          0.77830815]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 514 is [True, False, False, False, True, False]
State prediction error at timestep 514 is tensor(1.1635e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 514 of None
Current timestep = 515. State = [[-0.14520621  0.09262457]]. Action = [[ 0.04104842  0.04001445  0.         -0.97895885]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 515 is [True, False, False, False, True, False]
State prediction error at timestep 515 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 515 of None
Current timestep = 516. State = [[-0.1438323   0.09916034]]. Action = [[-0.01113202  0.09273403  0.         -0.8861686 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 516 is [True, False, False, False, True, False]
State prediction error at timestep 516 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 516 of None
Current timestep = 517. State = [[-0.14630696  0.09853563]]. Action = [[-0.0631564  -0.09263217  0.         -0.24746609]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 517 is [True, False, False, False, True, False]
State prediction error at timestep 517 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 517 of None
Current timestep = 518. State = [[-0.14591478  0.09824727]]. Action = [[ 0.02369791  0.02289695  0.         -0.37573653]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 518 is [True, False, False, False, True, False]
State prediction error at timestep 518 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 518 of None
Current timestep = 519. State = [[-0.13985404  0.09693633]]. Action = [[ 0.09472007 -0.04936346  0.         -0.93243814]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 519 is [True, False, False, False, True, False]
State prediction error at timestep 519 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 519 of None
Current timestep = 520. State = [[-0.1378175   0.09536415]]. Action = [[-0.03603081 -0.00729632  0.         -0.8566656 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 520 is [True, False, False, False, True, False]
State prediction error at timestep 520 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 520 of None
Current timestep = 521. State = [[-0.13784993  0.09135944]]. Action = [[-0.00692641 -0.07865517  0.         -0.35375464]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 521 is [True, False, False, False, True, False]
State prediction error at timestep 521 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 521 of None
Current timestep = 522. State = [[-0.14073284  0.09381987]]. Action = [[-0.076865   0.0958504  0.         0.8152894]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 522 is [True, False, False, False, True, False]
State prediction error at timestep 522 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 522 of None
Current timestep = 523. State = [[-0.13827874  0.09558031]]. Action = [[ 0.0885627  -0.02278001  0.          0.5103345 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 523 is [True, False, False, False, True, False]
State prediction error at timestep 523 is tensor(3.4841e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 523 of None
Current timestep = 524. State = [[-0.13288027  0.09320977]]. Action = [[ 0.05100156 -0.03443407  0.         -0.15612322]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 524 is [True, False, False, False, True, False]
State prediction error at timestep 524 is tensor(5.1063e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 524 of None
Current timestep = 525. State = [[-0.1265113   0.09182698]]. Action = [[ 0.08397891  0.00304289  0.         -0.6039998 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 525 is [True, False, False, False, True, False]
State prediction error at timestep 525 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 525 of None
Current timestep = 526. State = [[-0.1246101   0.09242839]]. Action = [[-0.02713408  0.02328877  0.         -0.9920753 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 526 is [True, False, False, False, True, False]
State prediction error at timestep 526 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 526 of None
Current timestep = 527. State = [[-0.12073065  0.09739599]]. Action = [[ 0.08482382  0.0947305   0.         -0.42623782]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 527 is [True, False, False, False, True, False]
State prediction error at timestep 527 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 527 of None
Current timestep = 528. State = [[-0.11567675  0.09883364]]. Action = [[ 0.04709201 -0.02080694  0.         -0.91535544]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 528 is [True, False, False, False, True, False]
State prediction error at timestep 528 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 528 of None
Current timestep = 529. State = [[-0.11683427  0.10083918]]. Action = [[-0.07104699  0.04915578  0.          0.07545269]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 529 is [True, False, False, False, True, False]
State prediction error at timestep 529 is tensor(6.9087e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 529 of None
Current timestep = 530. State = [[-0.11521939  0.09930509]]. Action = [[ 0.0554798  -0.06751062  0.          0.36440635]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 530 is [True, False, False, False, True, False]
State prediction error at timestep 530 is tensor(2.0425e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 530 of None
Current timestep = 531. State = [[-0.10962488  0.09681965]]. Action = [[ 0.06520689 -0.01368806  0.          0.67698765]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 531 is [True, False, False, False, True, False]
State prediction error at timestep 531 is tensor(6.8211e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 531 of None
Current timestep = 532. State = [[-0.10395669  0.09885646]]. Action = [[ 0.05896478  0.05519748  0.         -0.47881126]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 532 is [True, False, False, False, True, False]
State prediction error at timestep 532 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 532 of None
Current timestep = 533. State = [[-0.1057274   0.10438335]]. Action = [[-0.09397481  0.0759637   0.         -0.70420414]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 533 is [True, False, False, False, True, False]
State prediction error at timestep 533 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 533 of None
Current timestep = 534. State = [[-0.1056574   0.10744854]]. Action = [[ 0.04542672  0.00220773  0.         -0.6691308 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 534 is [True, False, False, False, True, False]
State prediction error at timestep 534 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 534 of None
Current timestep = 535. State = [[-0.09960841  0.10830426]]. Action = [[0.09481149 0.00389504 0.         0.56124353]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 535 is [True, False, False, False, True, False]
State prediction error at timestep 535 is tensor(1.4519e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 535 of None
Current timestep = 536. State = [[-0.09743216  0.10876859]]. Action = [[-2.2724733e-02  2.5876611e-04  0.0000000e+00  5.5326223e-01]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 536 is [True, False, False, False, True, False]
State prediction error at timestep 536 is tensor(2.7597e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 536 of None
Current timestep = 537. State = [[-0.09425437  0.1046903 ]]. Action = [[ 0.05843461 -0.08986419  0.         -0.91948223]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 537 is [True, False, False, False, True, False]
State prediction error at timestep 537 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 537 of None
Current timestep = 538. State = [[-0.09475305  0.10487343]]. Action = [[-0.06567232  0.05423158  0.         -0.20949358]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 538 is [True, False, False, False, True, False]
State prediction error at timestep 538 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 538 of None
Current timestep = 539. State = [[-0.0933897   0.11095747]]. Action = [[ 0.05177612  0.08510358  0.         -0.99338025]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 539 is [True, False, False, False, True, False]
State prediction error at timestep 539 is tensor(6.3213e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 539 of None
Current timestep = 540. State = [[-0.09588574  0.11413474]]. Action = [[-0.09874459 -0.00430997  0.         -0.885375  ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 540 is [True, False, False, False, True, False]
State prediction error at timestep 540 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 540 of None
Current timestep = 541. State = [[-0.1020548   0.11513714]]. Action = [[-0.08248148 -0.00478257  0.         -0.8303036 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 541 is [True, False, False, False, True, False]
State prediction error at timestep 541 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 541 of None
Current timestep = 542. State = [[-0.10298777  0.11335424]]. Action = [[ 0.02570329 -0.05734837  0.         -0.98716235]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 542 is [True, False, False, False, True, False]
State prediction error at timestep 542 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 542 of None
Current timestep = 543. State = [[-0.10310677  0.10805684]]. Action = [[-0.0224773  -0.08723488  0.          0.3303119 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 543 is [True, False, False, False, True, False]
State prediction error at timestep 543 is tensor(2.2714e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 543 of None
Current timestep = 544. State = [[-0.10618936  0.11050035]]. Action = [[-0.05681566  0.09543245  0.         -0.9356353 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 544 is [True, False, False, False, True, False]
State prediction error at timestep 544 is tensor(7.3022e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 544 of None
Current timestep = 545. State = [[-0.10499322  0.10938659]]. Action = [[ 0.06179453 -0.08549089  0.          0.44329095]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 545 is [True, False, False, False, True, False]
State prediction error at timestep 545 is tensor(1.0139e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 545 of None
Current timestep = 546. State = [[-0.09942818  0.11110695]]. Action = [[ 0.08997076  0.08859264  0.         -0.7499742 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 546 is [True, False, False, False, True, False]
State prediction error at timestep 546 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 546 of None
Current timestep = 547. State = [[-0.09410947  0.1163419 ]]. Action = [[ 0.07378072  0.06791382  0.         -0.4312389 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 547 is [True, False, False, False, True, False]
State prediction error at timestep 547 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 547 of None
Current timestep = 548. State = [[-0.0881773   0.12056421]]. Action = [[ 0.09273645  0.0542526   0.         -0.04003352]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 548 is [True, False, False, False, True, False]
State prediction error at timestep 548 is tensor(3.4637e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 548 of None
Current timestep = 549. State = [[-0.08327189  0.11730503]]. Action = [[ 0.05037384 -0.08866217  0.         -0.5403863 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 549 is [True, False, False, False, True, False]
State prediction error at timestep 549 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 549 of None
Current timestep = 550. State = [[-0.08024796  0.11220176]]. Action = [[ 0.01845197 -0.04167136  0.         -0.61198634]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 550 is [True, False, False, False, True, False]
State prediction error at timestep 550 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 550 of None
Current timestep = 551. State = [[-0.07769644  0.10767371]]. Action = [[ 0.01812482 -0.0509989   0.         -0.57754076]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 551 is [True, False, False, False, True, False]
State prediction error at timestep 551 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 551 of None
Current timestep = 552. State = [[-0.07147727  0.10377191]]. Action = [[ 0.08927567 -0.02868698  0.         -0.97523606]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 552 is [True, False, False, False, True, False]
State prediction error at timestep 552 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 552 of None
Current timestep = 553. State = [[-0.06801116  0.10000532]]. Action = [[-0.0125605  -0.033888    0.         -0.63755894]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 553 is [True, False, False, False, True, False]
State prediction error at timestep 553 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 553 of None
Current timestep = 554. State = [[-0.06795342  0.09486064]]. Action = [[-0.03334014 -0.06313461  0.         -0.6811187 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 554 is [True, False, False, False, True, False]
State prediction error at timestep 554 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 554 of None
Current timestep = 555. State = [[-0.06673533  0.09253994]]. Action = [[ 0.00523585  0.00989383  0.         -0.97257245]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 555 is [True, False, False, False, True, False]
State prediction error at timestep 555 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 555 of None
Current timestep = 556. State = [[-0.06112857  0.0918948 ]]. Action = [[ 0.08488526  0.00471036  0.         -0.828215  ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 556 is [True, False, False, False, True, False]
State prediction error at timestep 556 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 556 of None
Current timestep = 557. State = [[-0.05804756  0.09567707]]. Action = [[-0.00598137  0.09413853  0.         -0.45436877]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 557 is [True, False, False, False, True, False]
State prediction error at timestep 557 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 557 of None
Current timestep = 558. State = [[-0.05302097  0.09429113]]. Action = [[ 0.08738204 -0.07050566  0.         -0.7150705 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 558 is [True, False, False, False, True, False]
State prediction error at timestep 558 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 558 of None
Current timestep = 559. State = [[-0.33844447  0.17249212]]. Action = [[0.08087962 0.09648389 0.         0.4302752 ]]. Reward = [100.]
Curr episode timestep = 48
Scene graph at timestep 559 is [True, False, False, False, False, True]
State prediction error at timestep 559 is tensor(0.0423, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 559 of None
Current timestep = 560. State = [[-0.3458586  0.1760356]]. Action = [[-0.07481678  0.01634103  0.          0.15289104]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 560 is [True, False, False, False, False, True]
State prediction error at timestep 560 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 560 of None
Current timestep = 561. State = [[-0.34932995  0.17450996]]. Action = [[-0.00317583 -0.06989611  0.         -0.9837991 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 561 is [True, False, False, False, False, True]
State prediction error at timestep 561 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 561 of None
Current timestep = 562. State = [[-0.3542831   0.17361999]]. Action = [[-0.07868577  0.00056628  0.          0.25656855]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 562 is [True, False, False, False, False, True]
State prediction error at timestep 562 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 562 of None
Current timestep = 563. State = [[-0.35539147  0.17799692]]. Action = [[ 0.05477179  0.07963195  0.         -0.7304185 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 563 is [True, False, False, False, False, True]
State prediction error at timestep 563 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 563 of None
Current timestep = 564. State = [[-0.35185143  0.1841879 ]]. Action = [[ 0.07264747  0.07957477  0.         -0.57663023]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 564 is [True, False, False, False, False, True]
State prediction error at timestep 564 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 564 of None
Current timestep = 565. State = [[-0.3463381  0.1865168]]. Action = [[ 0.08989149  0.00567225  0.         -0.05512255]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 565 is [True, False, False, False, False, True]
State prediction error at timestep 565 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 565 of None
Current timestep = 566. State = [[-0.34765074  0.18344769]]. Action = [[-0.08559708 -0.07820754  0.         -0.12908006]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 566 is [True, False, False, False, False, True]
State prediction error at timestep 566 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 566 of None
Current timestep = 567. State = [[-0.3481586   0.18181512]]. Action = [[ 0.04937271  0.00928976  0.         -0.81188226]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 567 is [True, False, False, False, False, True]
State prediction error at timestep 567 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 567 of None
Current timestep = 568. State = [[-0.34762514  0.18086207]]. Action = [[-0.00981151 -0.02027389  0.         -0.35185385]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 568 is [True, False, False, False, False, True]
State prediction error at timestep 568 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 568 of None
Current timestep = 569. State = [[-0.34525135  0.18339173]]. Action = [[0.05576172 0.06785766 0.         0.03660917]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 569 is [True, False, False, False, False, True]
State prediction error at timestep 569 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 569 of None
Current timestep = 570. State = [[-0.34812418  0.18700655]]. Action = [[-0.08955034  0.03592894  0.          0.09634864]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 570 is [True, False, False, False, False, True]
State prediction error at timestep 570 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 570 of None
Current timestep = 571. State = [[-0.35495675  0.19240527]]. Action = [[-0.07515022  0.07774586  0.         -0.6502125 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 571 is [True, False, False, False, False, True]
State prediction error at timestep 571 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 571 of None
Current timestep = 572. State = [[-0.36084253  0.19432862]]. Action = [[-0.05063985 -0.02247103  0.         -0.7186309 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 572 is [True, False, False, False, False, True]
State prediction error at timestep 572 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 572 of None
Current timestep = 573. State = [[-0.36751956  0.19812313]]. Action = [[-0.07811721  0.067366    0.         -0.9639782 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 573 is [True, False, False, False, False, True]
State prediction error at timestep 573 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 573 of None
Current timestep = 574. State = [[-0.37476385  0.20563504]]. Action = [[-0.0603688   0.09365318  0.         -0.2743988 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 574 is [True, False, False, False, False, True]
State prediction error at timestep 574 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 574 of None
Current timestep = 575. State = [[-0.3788643   0.20936196]]. Action = [[ 0.          0.          0.         -0.87405586]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 575 is [True, False, False, False, False, True]
State prediction error at timestep 575 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 575 of None
Current timestep = 576. State = [[-0.37703496  0.21087621]]. Action = [[ 0.07806211  0.01362626  0.         -0.16845089]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 576 is [True, False, False, False, False, True]
State prediction error at timestep 576 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 576 of None
Current timestep = 577. State = [[-0.37617663  0.21170555]]. Action = [[ 0.          0.          0.         -0.85999095]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 577 is [True, False, False, False, False, True]
State prediction error at timestep 577 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 577 of None
Current timestep = 578. State = [[-0.37278074  0.2156576 ]]. Action = [[0.08709898 0.0723651  0.         0.0897727 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 578 is [True, False, False, False, False, True]
State prediction error at timestep 578 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 578 of None
Current timestep = 579. State = [[-0.36747506  0.21575299]]. Action = [[ 0.06355289 -0.0436518   0.         -0.49836302]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 579 is [True, False, False, False, False, True]
State prediction error at timestep 579 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 579 of None
Current timestep = 580. State = [[-0.36303723  0.2111607 ]]. Action = [[ 0.03971662 -0.07985608  0.         -0.7669274 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 580 is [True, False, False, False, False, True]
State prediction error at timestep 580 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 580 of None
Current timestep = 581. State = [[-0.36442727  0.20743191]]. Action = [[-0.07682313 -0.04622988  0.          0.36436534]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 581 is [True, False, False, False, False, True]
State prediction error at timestep 581 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 581 of None
Current timestep = 582. State = [[-0.36106488  0.20649098]]. Action = [[ 0.09146688 -0.00230528  0.         -0.927411  ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 582 is [True, False, False, False, False, True]
State prediction error at timestep 582 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 582 of None
Current timestep = 583. State = [[-0.3530516   0.20584914]]. Action = [[ 0.07888923 -0.00925609  0.         -0.80217665]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 583 is [True, False, False, False, False, True]
State prediction error at timestep 583 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 583 of None
Current timestep = 584. State = [[-0.344487    0.20308888]]. Action = [[ 0.08377207 -0.04175016  0.         -0.37514126]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 584 is [True, False, False, False, False, True]
State prediction error at timestep 584 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 584 of None
Current timestep = 585. State = [[-0.3439175   0.20038676]]. Action = [[-0.08788439 -0.02625225  0.         -0.5847831 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 585 is [True, False, False, False, False, True]
State prediction error at timestep 585 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 585 of None
Current timestep = 586. State = [[-0.34329563  0.1997745 ]]. Action = [[ 0.02353217  0.00202602  0.         -0.30630726]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 586 is [True, False, False, False, False, True]
State prediction error at timestep 586 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 586 of None
Current timestep = 587. State = [[-0.34538332  0.19631079]]. Action = [[-0.08647256 -0.07209126  0.         -0.2562604 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 587 is [True, False, False, False, False, True]
State prediction error at timestep 587 is tensor(6.0967e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 587 of None
Current timestep = 588. State = [[-0.34827614  0.19776052]]. Action = [[-0.02586249  0.07099742  0.          0.3371222 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 588 is [True, False, False, False, False, True]
State prediction error at timestep 588 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 588 of None
Current timestep = 589. State = [[-0.34401923  0.19872531]]. Action = [[ 0.09739711 -0.01241609  0.          0.6788218 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 589 is [True, False, False, False, False, True]
State prediction error at timestep 589 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 589 of None
Current timestep = 590. State = [[-0.336202    0.19464464]]. Action = [[ 0.09153926 -0.05628297  0.         -0.8765905 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 590 is [True, False, False, False, False, True]
State prediction error at timestep 590 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 590 of None
Current timestep = 591. State = [[-0.3322671  0.1955339]]. Action = [[ 0.00659671  0.07650862  0.         -0.6527873 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 591 is [True, False, False, False, False, True]
State prediction error at timestep 591 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 591 of None
Current timestep = 592. State = [[-0.32978603  0.19998127]]. Action = [[ 0.03550252  0.06602284  0.         -0.40060747]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 592 is [True, False, False, False, False, True]
State prediction error at timestep 592 is tensor(8.6803e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 592 of None
Current timestep = 593. State = [[-0.33204243  0.20024012]]. Action = [[-0.07770424 -0.03056848  0.         -0.9990724 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 593 is [True, False, False, False, False, True]
State prediction error at timestep 593 is tensor(4.1995e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 593 of None
Current timestep = 594. State = [[-0.33484262  0.19839446]]. Action = [[-0.01453017 -0.02524221  0.         -0.7067156 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 594 is [True, False, False, False, False, True]
State prediction error at timestep 594 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 594 of None
Current timestep = 595. State = [[-0.33134812  0.20205903]]. Action = [[ 0.09095774  0.09863707  0.         -0.9078261 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 595 is [True, False, False, False, False, True]
State prediction error at timestep 595 is tensor(7.0647e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 595 of None
Current timestep = 596. State = [[-0.33228338  0.2083962 ]]. Action = [[-0.0695235   0.07551303  0.         -0.81383604]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 596 is [True, False, False, False, False, True]
State prediction error at timestep 596 is tensor(5.2380e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 596 of None
Current timestep = 597. State = [[-0.3307293   0.21238564]]. Action = [[ 0.07826222  0.0297216   0.         -0.8877925 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 597 is [True, False, False, False, False, True]
State prediction error at timestep 597 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 597 of None
Current timestep = 598. State = [[-0.3270834  0.210499 ]]. Action = [[ 0.03120924 -0.06269739  0.         -0.7965759 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 598 is [True, False, False, False, False, True]
State prediction error at timestep 598 is tensor(5.6415e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 598 of None
Current timestep = 599. State = [[-0.3284245   0.20662265]]. Action = [[-0.05861041 -0.0594977   0.         -0.98397595]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 599 is [True, False, False, False, False, True]
State prediction error at timestep 599 is tensor(5.8665e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 599 of None
Current timestep = 600. State = [[-0.32567942  0.20988268]]. Action = [[ 0.08838887  0.09594963  0.         -0.9379067 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 600 is [True, False, False, False, False, True]
State prediction error at timestep 600 is tensor(3.0896e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 600 of None
Current timestep = 601. State = [[-0.3252917   0.20959538]]. Action = [[-0.07537161 -0.08886627  0.         -0.94796556]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 601 is [True, False, False, False, False, True]
State prediction error at timestep 601 is tensor(6.5184e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 601 of None
Current timestep = 602. State = [[-0.3306284   0.20742747]]. Action = [[-0.08210637 -0.02011269  0.         -0.8482857 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 602 is [True, False, False, False, False, True]
State prediction error at timestep 602 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 602 of None
Current timestep = 603. State = [[-0.32980156  0.20787887]]. Action = [[ 0.06664736  0.01035118  0.         -0.9645829 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 603 is [True, False, False, False, False, True]
State prediction error at timestep 603 is tensor(5.8743e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 603 of None
Current timestep = 604. State = [[-0.3238282  0.2111914]]. Action = [[ 0.08297012  0.06404174  0.         -0.0879786 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 604 is [True, False, False, False, False, True]
State prediction error at timestep 604 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 604 of None
Current timestep = 605. State = [[-0.31799603  0.20781752]]. Action = [[ 0.0574734  -0.0988246   0.         -0.49383008]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 605 is [True, False, False, False, False, True]
State prediction error at timestep 605 is tensor(7.5170e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 605 of None
Current timestep = 606. State = [[-0.31135646  0.20808455]]. Action = [[0.08355542 0.07536071 0.         0.41712475]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 606 is [True, False, False, False, False, True]
State prediction error at timestep 606 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 606 of None
Current timestep = 607. State = [[-0.30623037  0.2054954 ]]. Action = [[ 0.02873773 -0.08177964  0.         -0.8690293 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 607 is [True, False, False, False, False, True]
State prediction error at timestep 607 is tensor(4.6446e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 607 of None
Current timestep = 608. State = [[-0.3006578   0.20699179]]. Action = [[ 0.07176108  0.09299018  0.         -0.924362  ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 608 is [True, False, False, False, False, True]
State prediction error at timestep 608 is tensor(1.4691e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 608 of None
Current timestep = 609. State = [[-0.2942203   0.20742954]]. Action = [[ 0.06093001 -0.02519904  0.         -0.42758965]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 609 is [True, False, False, False, False, True]
State prediction error at timestep 609 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 609 of None
Current timestep = 610. State = [[-0.28627712  0.21053626]]. Action = [[ 0.09187192  0.09225894  0.         -0.00030965]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 610 is [True, False, False, False, False, True]
State prediction error at timestep 610 is tensor(4.2138e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 610 of None
Current timestep = 611. State = [[-0.280709    0.20956472]]. Action = [[ 0.01869567 -0.06181797  0.         -0.4008453 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 611 is [True, False, False, False, False, True]
State prediction error at timestep 611 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 611 of None
Current timestep = 612. State = [[-0.2771763   0.21229905]]. Action = [[ 0.0244455   0.09626503  0.         -0.79703677]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 612 is [True, False, False, False, False, True]
State prediction error at timestep 612 is tensor(2.8848e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 612 of None
Current timestep = 613. State = [[-0.270359   0.2106447]]. Action = [[ 0.09206829 -0.08294318  0.         -0.7330631 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 613 is [True, False, False, False, False, True]
State prediction error at timestep 613 is tensor(5.4591e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 613 of None
Current timestep = 614. State = [[-0.2608962   0.20572136]]. Action = [[ 0.09375852 -0.04730086  0.         -0.9370782 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 614 is [True, False, False, False, False, True]
State prediction error at timestep 614 is tensor(3.9763e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 614 of None
Current timestep = 615. State = [[-0.25827858  0.20487481]]. Action = [[-0.05406648  0.0191981   0.          0.70596504]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 615 is [True, False, False, False, False, True]
State prediction error at timestep 615 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 615 of None
Current timestep = 616. State = [[-0.25601152  0.2046565 ]]. Action = [[ 0.02852095 -0.01786149  0.         -0.86152446]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 616 is [True, False, False, False, False, True]
State prediction error at timestep 616 is tensor(4.0906e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 616 of None
Current timestep = 617. State = [[-0.25404423  0.19966401]]. Action = [[-0.02037843 -0.0960578   0.         -0.9229336 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 617 is [True, False, False, False, False, True]
State prediction error at timestep 617 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 617 of None
Current timestep = 618. State = [[-0.25629044  0.19951037]]. Action = [[-0.07899954  0.0446322   0.          0.44405615]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 618 is [True, False, False, False, False, True]
State prediction error at timestep 618 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 618 of None
Current timestep = 619. State = [[-0.2617758   0.19927931]]. Action = [[-0.09445044 -0.04428436  0.         -0.9880715 ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 619 is [True, False, False, False, False, True]
State prediction error at timestep 619 is tensor(3.8390e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 619 of None
Current timestep = 620. State = [[-0.26123792  0.20100665]]. Action = [[ 0.06096568  0.05138946  0.         -0.12642717]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 620 is [True, False, False, False, False, True]
State prediction error at timestep 620 is tensor(1.8525e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 620 of None
Current timestep = 621. State = [[-0.25405297  0.19970492]]. Action = [[ 0.09848437 -0.05780016  0.         -0.84140456]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 621 is [True, False, False, False, False, True]
State prediction error at timestep 621 is tensor(4.1408e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 621 of None
Current timestep = 622. State = [[-0.2477542  0.1988828]]. Action = [[ 0.04674495  0.02137645  0.         -0.84299153]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 622 is [True, False, False, False, False, True]
State prediction error at timestep 622 is tensor(7.0107e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 622 of None
Current timestep = 623. State = [[-0.24308144  0.20271993]]. Action = [[ 0.04561526  0.07599802  0.         -0.23985577]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 623 is [True, False, False, False, False, True]
State prediction error at timestep 623 is tensor(6.3059e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 623 of None
Current timestep = 624. State = [[-0.24334936  0.20543383]]. Action = [[-0.04872105  0.01334139  0.          0.37829137]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 624 is [True, False, False, False, False, True]
State prediction error at timestep 624 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 624 of None
Current timestep = 625. State = [[-0.2485784  0.2044489]]. Action = [[-0.0926365  -0.04114735  0.         -0.6823578 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 625 is [True, False, False, False, False, True]
State prediction error at timestep 625 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 625 of None
Current timestep = 626. State = [[-0.25044072  0.20326263]]. Action = [[ 0.00790635 -0.01815805  0.          0.22903311]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 626 is [True, False, False, False, False, True]
State prediction error at timestep 626 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 626 of None
Current timestep = 627. State = [[-0.25430372  0.20194854]]. Action = [[-0.08576979 -0.02905196  0.         -0.9786542 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 627 is [True, False, False, False, False, True]
State prediction error at timestep 627 is tensor(4.9680e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 627 of None
Current timestep = 628. State = [[-0.25527307  0.20070933]]. Action = [[ 0.02931156 -0.02134444  0.         -0.7460973 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 628 is [True, False, False, False, False, True]
State prediction error at timestep 628 is tensor(5.9621e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 628 of None
Current timestep = 629. State = [[-0.25080964  0.19854061]]. Action = [[ 0.07759208 -0.03019757  0.         -0.44757903]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 629 is [True, False, False, False, False, True]
State prediction error at timestep 629 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 629 of None
Current timestep = 630. State = [[-0.24378805  0.19850208]]. Action = [[0.09749503 0.033984   0.         0.06271482]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 630 is [True, False, False, False, False, True]
State prediction error at timestep 630 is tensor(1.7690e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 630 of None
Current timestep = 631. State = [[-0.2362498  0.194881 ]]. Action = [[ 0.08864775 -0.06692711  0.          0.6907854 ]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 631 is [True, False, False, False, False, True]
State prediction error at timestep 631 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 631 of None
Current timestep = 632. State = [[-0.22894543  0.19586058]]. Action = [[ 0.07890714  0.08785111  0.         -0.99468154]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 632 is [True, False, False, False, False, True]
State prediction error at timestep 632 is tensor(3.8429e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 632 of None
Current timestep = 633. State = [[-0.22108641  0.19453633]]. Action = [[ 0.09399367 -0.04399243  0.         -0.8239386 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 633 is [True, False, False, False, False, True]
State prediction error at timestep 633 is tensor(8.8242e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 633 of None
Current timestep = 634. State = [[-0.2129394   0.19574732]]. Action = [[ 0.0828483  0.0791489  0.        -0.7261174]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 634 is [True, False, False, False, False, True]
State prediction error at timestep 634 is tensor(6.9344e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 634 of None
Current timestep = 635. State = [[-0.20812994  0.20107488]]. Action = [[ 0.02235992  0.09180338  0.         -0.97722065]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 635 is [True, False, False, False, False, True]
State prediction error at timestep 635 is tensor(6.6083e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 635 of None
Current timestep = 636. State = [[-0.20793952  0.19889694]]. Action = [[-0.04709195 -0.09352652  0.         -0.02950972]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 636 is [True, False, False, False, False, True]
State prediction error at timestep 636 is tensor(1.6742e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 636 of None
Current timestep = 637. State = [[-0.20816725  0.19712277]]. Action = [[-0.00825642  0.01305436  0.          0.08223927]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 637 is [True, False, False, False, False, True]
State prediction error at timestep 637 is tensor(6.2521e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 637 of None
Current timestep = 638. State = [[-0.20549515  0.20118617]]. Action = [[ 0.04187209  0.07768012  0.         -0.880095  ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 638 is [True, False, False, False, False, True]
State prediction error at timestep 638 is tensor(6.2109e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 638 of None
Current timestep = 639. State = [[-0.19896314  0.20674562]]. Action = [[ 0.09859139  0.07118354  0.         -0.4972914 ]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 639 is [True, False, False, False, False, True]
State prediction error at timestep 639 is tensor(8.3432e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 639 of None
Current timestep = 640. State = [[-0.19364324  0.20427632]]. Action = [[ 0.02874706 -0.09478816  0.          0.770751  ]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 640 is [True, False, False, False, False, True]
State prediction error at timestep 640 is tensor(8.6524e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 640 of None
Current timestep = 641. State = [[-0.19544445  0.19756849]]. Action = [[-0.08874512 -0.09548942  0.         -0.9475864 ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 641 is [True, False, False, False, False, True]
State prediction error at timestep 641 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 641 of None
Current timestep = 642. State = [[-0.19555365  0.19437739]]. Action = [[ 0.01915906 -0.01939958  0.         -0.8775045 ]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 642 is [True, False, False, False, False, True]
State prediction error at timestep 642 is tensor(6.6183e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 642 of None
Current timestep = 643. State = [[-0.19754036  0.19342935]]. Action = [[-0.07604833 -0.01415092  0.         -0.44371533]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 643 is [True, False, False, False, False, True]
State prediction error at timestep 643 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 643 of None
Current timestep = 644. State = [[-0.20239103  0.19569404]]. Action = [[-0.07567173  0.03949643  0.         -0.5922185 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 644 is [True, False, False, False, False, True]
State prediction error at timestep 644 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 644 of None
Current timestep = 645. State = [[-0.20704725  0.20124236]]. Action = [[-0.05119219  0.07225261  0.         -0.9836193 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 645 is [True, False, False, False, False, True]
State prediction error at timestep 645 is tensor(2.4185e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 645 of None
Current timestep = 646. State = [[-0.21397711  0.20747992]]. Action = [[-0.09477343  0.06180889  0.          0.53159714]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 646 is [True, False, False, False, False, True]
State prediction error at timestep 646 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 646 of None
Current timestep = 647. State = [[-0.21623029  0.21106291]]. Action = [[ 0.03586108  0.0099887   0.         -0.74267554]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 647 is [True, False, False, False, False, True]
State prediction error at timestep 647 is tensor(4.3794e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 647 of None
Current timestep = 648. State = [[-0.22020105  0.21345362]]. Action = [[-0.07099564  0.02001761  0.         -0.9844585 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 648 is [True, False, False, False, False, True]
State prediction error at timestep 648 is tensor(2.2287e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 648 of None
Current timestep = 649. State = [[-0.22659343  0.21577294]]. Action = [[-0.06025081  0.00900584  0.         -0.9542409 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 649 is [True, False, False, False, False, True]
State prediction error at timestep 649 is tensor(2.2477e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 649 of None
Current timestep = 650. State = [[-0.22596888  0.22075202]]. Action = [[0.09271664 0.07988923 0.         0.3213768 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 650 is [True, False, False, False, False, True]
State prediction error at timestep 650 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 650 of None
Current timestep = 651. State = [[-0.22743413  0.22507882]]. Action = [[-0.05365675  0.02400132  0.          0.39675796]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 651 is [True, False, False, False, False, True]
State prediction error at timestep 651 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 651 of None
Current timestep = 652. State = [[-0.23367293  0.22359927]]. Action = [[-0.07413442 -0.07145747  0.         -0.9704362 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 652 is [True, False, False, False, False, True]
State prediction error at timestep 652 is tensor(3.0375e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 652 of None
Current timestep = 653. State = [[-0.24033731  0.22104669]]. Action = [[-0.07228331 -0.04150636  0.         -0.9649498 ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 653 is [True, False, False, False, False, True]
State prediction error at timestep 653 is tensor(3.3351e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 653 of None
Current timestep = 654. State = [[-0.24386132  0.21762724]]. Action = [[-0.00897346 -0.0668564   0.          0.09964621]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 654 is [True, False, False, False, False, True]
State prediction error at timestep 654 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 654 of None
Current timestep = 655. State = [[-0.24581861  0.22056587]]. Action = [[-0.01096582  0.09117777  0.         -0.33086097]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 655 is [True, False, False, False, False, True]
State prediction error at timestep 655 is tensor(5.4003e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 655 of None
Current timestep = 656. State = [[-0.24543907  0.22115862]]. Action = [[ 0.04098373 -0.03921248  0.         -0.66430426]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 656 is [True, False, False, False, False, True]
State prediction error at timestep 656 is tensor(7.4150e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 656 of None
Current timestep = 657. State = [[-0.24513121  0.21727437]]. Action = [[-0.00133132 -0.0548162   0.         -0.8661055 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 657 is [True, False, False, False, False, True]
State prediction error at timestep 657 is tensor(6.0004e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 657 of None
Current timestep = 658. State = [[-0.24783719  0.21987088]]. Action = [[-0.04181717  0.09233918  0.         -0.72249055]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 658 is [True, False, False, False, False, True]
State prediction error at timestep 658 is tensor(2.1778e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 658 of None
Current timestep = 659. State = [[-0.24596918  0.22274065]]. Action = [[ 0.08431611  0.01609199  0.         -0.63080114]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 659 is [True, False, False, False, False, True]
State prediction error at timestep 659 is tensor(3.3415e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 659 of None
Current timestep = 660. State = [[-0.24122916  0.22021829]]. Action = [[ 0.06275976 -0.04571314  0.         -0.10829455]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 660 is [True, False, False, False, False, True]
State prediction error at timestep 660 is tensor(2.4730e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 660 of None
Current timestep = 661. State = [[-0.23675181  0.2182385 ]]. Action = [[ 0.0531683   0.0049869   0.         -0.35500515]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 661 is [True, False, False, False, False, True]
State prediction error at timestep 661 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 661 of None
Current timestep = 662. State = [[-0.23268823  0.21688741]]. Action = [[ 0.04372063 -0.00857604  0.          0.735559  ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 662 is [True, False, False, False, False, True]
State prediction error at timestep 662 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 662 of None
Current timestep = 663. State = [[-0.23488975  0.2182345 ]]. Action = [[-0.08275677  0.04598222  0.         -0.80637765]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 663 is [True, False, False, False, False, True]
State prediction error at timestep 663 is tensor(7.4028e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 663 of None
Current timestep = 664. State = [[-0.23348771  0.21932101]]. Action = [[0.0682798  0.00106657 0.         0.8464353 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 664 is [True, False, False, False, False, True]
State prediction error at timestep 664 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 664 of None
Current timestep = 665. State = [[-0.2319701   0.22119457]]. Action = [[-0.01305398  0.04409815  0.         -0.5842229 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 665 is [True, False, False, False, False, True]
State prediction error at timestep 665 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 665 of None
Current timestep = 666. State = [[-0.23272476  0.22088721]]. Action = [[-0.01639304 -0.03170468  0.         -0.98920864]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 666 is [True, False, False, False, False, True]
State prediction error at timestep 666 is tensor(2.7800e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 666 of None
Current timestep = 667. State = [[-0.23687616  0.218717  ]]. Action = [[-0.08640352 -0.03727583  0.         -0.9855602 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 667 is [True, False, False, False, False, True]
State prediction error at timestep 667 is tensor(4.8712e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 667 of None
Current timestep = 668. State = [[-0.2372967   0.21882173]]. Action = [[ 0.03600959  0.01339464  0.         -0.39592373]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 668 is [True, False, False, False, False, True]
State prediction error at timestep 668 is tensor(9.1486e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 668 of None
Current timestep = 669. State = [[-0.23653045  0.22088313]]. Action = [[-0.00793909  0.02860726  0.         -0.33672547]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 669 is [True, False, False, False, False, True]
State prediction error at timestep 669 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 669 of None
Current timestep = 670. State = [[-0.23631418  0.22267702]]. Action = [[ 0.00597535  0.01255739  0.         -0.92794293]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 670 is [True, False, False, False, False, True]
State prediction error at timestep 670 is tensor(7.3727e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 670 of None
Current timestep = 671. State = [[-0.23157983  0.21946958]]. Action = [[ 0.08839173 -0.07600591  0.         -0.88182104]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 671 is [True, False, False, False, False, True]
State prediction error at timestep 671 is tensor(3.7220e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 671 of None
Current timestep = 672. State = [[-0.22725192  0.21624812]]. Action = [[ 0.02246039 -0.01670019  0.         -0.5258692 ]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 672 is [True, False, False, False, False, True]
State prediction error at timestep 672 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 672 of None
Current timestep = 673. State = [[-0.22102132  0.21579637]]. Action = [[ 0.09420461  0.01364545  0.         -0.01952273]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 673 is [True, False, False, False, False, True]
State prediction error at timestep 673 is tensor(1.3700e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 673 of None
Current timestep = 674. State = [[-0.21821406  0.21434234]]. Action = [[-0.01926376 -0.02296376  0.          0.26151466]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 674 is [True, False, False, False, False, True]
State prediction error at timestep 674 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 674 of None
Current timestep = 675. State = [[-0.22174418  0.21157195]]. Action = [[-0.08713161 -0.04018925  0.         -0.79504156]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 675 is [True, False, False, False, False, True]
State prediction error at timestep 675 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 675 of None
Current timestep = 676. State = [[-0.22413974  0.21365859]]. Action = [[-0.01256095  0.06444701  0.          0.3670429 ]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 676 is [True, False, False, False, False, True]
State prediction error at timestep 676 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 676 of None
Current timestep = 677. State = [[-0.22349495  0.21255602]]. Action = [[ 0.01439345 -0.05946186  0.         -0.8416075 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 677 is [True, False, False, False, False, True]
State prediction error at timestep 677 is tensor(7.7336e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 677 of None
Current timestep = 678. State = [[-0.2268349   0.21035635]]. Action = [[-0.08731909 -0.01552775  0.         -0.04377836]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 678 is [True, False, False, False, False, True]
State prediction error at timestep 678 is tensor(1.7997e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 678 of None
Current timestep = 679. State = [[-0.2315199   0.20713422]]. Action = [[-0.05243193 -0.06518163  0.         -0.9369584 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 679 is [True, False, False, False, False, True]
State prediction error at timestep 679 is tensor(5.1295e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 679 of None
Current timestep = 680. State = [[-0.23124807  0.20133068]]. Action = [[ 0.03355675 -0.08498718  0.         -0.8815718 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 680 is [True, False, False, False, False, True]
State prediction error at timestep 680 is tensor(4.2613e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 680 of None
Current timestep = 681. State = [[-0.22786607  0.19482899]]. Action = [[ 0.0440359  -0.07082949  0.         -0.44301546]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 681 is [True, False, False, False, False, True]
State prediction error at timestep 681 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 681 of None
Current timestep = 682. State = [[-0.22191216  0.18945542]]. Action = [[ 0.08519159 -0.0403239   0.         -0.15979469]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 682 is [True, False, False, False, False, True]
State prediction error at timestep 682 is tensor(8.9868e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 682 of None
Current timestep = 683. State = [[-0.21743594  0.18174064]]. Action = [[ 0.02591098 -0.09581873  0.         -0.8748261 ]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 683 is [True, False, False, False, False, True]
State prediction error at timestep 683 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 683 of None
Current timestep = 684. State = [[-0.21333481  0.17792825]]. Action = [[ 0.04686034  0.01823232  0.         -0.5184479 ]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 684 is [True, False, False, False, False, True]
State prediction error at timestep 684 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 684 of None
Current timestep = 685. State = [[-0.20845804  0.1756235 ]]. Action = [[ 0.05714538 -0.00822493  0.         -0.28413397]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 685 is [True, False, False, False, False, True]
State prediction error at timestep 685 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 685 of None
Current timestep = 686. State = [[-0.20911844  0.1689854 ]]. Action = [[-0.07160991 -0.09235428  0.         -0.1055249 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 686 is [True, False, False, False, False, True]
State prediction error at timestep 686 is tensor(4.2307e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 686 of None
Current timestep = 687. State = [[-0.2094627   0.16681692]]. Action = [[ 0.02530081  0.04818561  0.         -0.36090094]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 687 is [True, False, False, False, False, True]
State prediction error at timestep 687 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 687 of None
Current timestep = 688. State = [[-0.20827118  0.16166879]]. Action = [[ 0.00448124 -0.09167729  0.         -0.54868484]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 688 is [True, False, False, False, False, True]
State prediction error at timestep 688 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 688 of None
Current timestep = 689. State = [[-0.20437616  0.16136105]]. Action = [[ 0.07229792  0.0858844   0.         -0.8707937 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 689 is [True, False, False, False, False, True]
State prediction error at timestep 689 is tensor(3.9873e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 689 of None
Current timestep = 690. State = [[-0.19930463  0.16044246]]. Action = [[ 0.05800996 -0.02692471  0.         -0.13413543]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 690 is [True, False, False, False, False, True]
State prediction error at timestep 690 is tensor(6.6281e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 690 of None
Current timestep = 691. State = [[-0.19410199  0.16203056]]. Action = [[ 0.06374992  0.0805077   0.         -0.37404597]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 691 is [True, False, False, False, False, True]
State prediction error at timestep 691 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 691 of None
Current timestep = 692. State = [[-0.19543074  0.16577092]]. Action = [[-0.07240522  0.05286013  0.         -0.7750932 ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 692 is [True, False, False, False, False, True]
State prediction error at timestep 692 is tensor(7.8195e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 692 of None
Current timestep = 693. State = [[-0.1942847   0.16265224]]. Action = [[ 0.06205503 -0.08588717  0.         -0.6878755 ]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 693 is [True, False, False, False, False, True]
State prediction error at timestep 693 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 693 of None
Current timestep = 694. State = [[-0.19275907  0.15518062]]. Action = [[-0.01352839 -0.09315361  0.         -0.41945982]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 694 is [True, False, False, False, False, True]
State prediction error at timestep 694 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 694 of None
Current timestep = 695. State = [[-0.19382747  0.15250129]]. Action = [[-0.03344549  0.00944833  0.          0.08609581]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 695 is [True, False, False, False, False, True]
State prediction error at timestep 695 is tensor(7.7194e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 695 of None
Current timestep = 696. State = [[-0.19156834  0.14759408]]. Action = [[ 0.04995548 -0.0933864   0.         -0.9164132 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 696 is [True, False, False, False, False, True]
State prediction error at timestep 696 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 696 of None
Current timestep = 697. State = [[-0.18710549  0.14569545]]. Action = [[ 0.04605327  0.03356037  0.         -0.89172107]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 697 is [True, False, False, False, False, True]
State prediction error at timestep 697 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 697 of None
Current timestep = 698. State = [[-0.1833998   0.14602661]]. Action = [[0.03498278 0.01111311 0.         0.21686244]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 698 is [True, False, False, False, False, True]
State prediction error at timestep 698 is tensor(1.0201e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 698 of None
Current timestep = 699. State = [[-0.17708772  0.14903232]]. Action = [[ 0.09845764  0.07619444  0.         -0.6925963 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 699 is [True, False, False, False, False, True]
State prediction error at timestep 699 is tensor(6.2244e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 699 of None
Current timestep = 700. State = [[-0.17027943  0.15030925]]. Action = [[ 0.07389463  0.00485037  0.         -0.7112819 ]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 700 is [True, False, False, False, False, True]
State prediction error at timestep 700 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 700 of None
Current timestep = 701. State = [[-0.16498777  0.154265  ]]. Action = [[0.05006295 0.09374186 0.         0.4150772 ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 701 is [True, False, False, False, False, True]
State prediction error at timestep 701 is tensor(7.8123e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 701 of None
Current timestep = 702. State = [[-0.16528334  0.15710425]]. Action = [[-0.05336875  0.00870063  0.         -0.54655534]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 702 is [True, False, False, False, False, True]
State prediction error at timestep 702 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 702 of None
Current timestep = 703. State = [[-0.16228144  0.16069123]]. Action = [[0.08303607 0.06308196 0.         0.28545046]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 703 is [True, False, False, False, False, True]
State prediction error at timestep 703 is tensor(3.0838e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 703 of None
Current timestep = 704. State = [[-0.16253714  0.16673383]]. Action = [[-0.06455845  0.07499553  0.         -0.09456444]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 704 is [True, False, False, False, False, True]
State prediction error at timestep 704 is tensor(1.6618e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 704 of None
Current timestep = 705. State = [[-0.15969037  0.1657738 ]]. Action = [[ 0.08099215 -0.0860699   0.         -0.8776778 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 705 is [True, False, False, False, False, True]
State prediction error at timestep 705 is tensor(3.4134e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 705 of None
Current timestep = 706. State = [[-0.15767622  0.16764551]]. Action = [[-0.02161039  0.06947843  0.         -0.45366234]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 706 is [True, False, False, False, False, True]
State prediction error at timestep 706 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 706 of None
Current timestep = 707. State = [[-0.15686238  0.17432913]]. Action = [[0.01543687 0.073479   0.         0.00144446]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 707 is [True, False, False, False, False, True]
State prediction error at timestep 707 is tensor(2.5519e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 707 of None
Current timestep = 708. State = [[-0.1591824   0.18165414]]. Action = [[-0.06125847  0.07362426  0.         -0.95208585]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 708 is [True, False, False, False, False, True]
State prediction error at timestep 708 is tensor(1.7218e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 708 of None
Current timestep = 709. State = [[-0.159296    0.18560125]]. Action = [[ 0.02910168 -0.00277322  0.         -0.6312248 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 709 is [True, False, False, False, False, True]
State prediction error at timestep 709 is tensor(5.3474e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 709 of None
Current timestep = 710. State = [[-0.16219701  0.18404758]]. Action = [[-0.08801895 -0.07487424  0.         -0.7066295 ]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 710 is [True, False, False, False, False, True]
State prediction error at timestep 710 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 710 of None
Current timestep = 711. State = [[-0.16722609  0.18351777]]. Action = [[-0.06638209 -0.01224699  0.         -0.79488623]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 711 is [True, False, False, False, False, True]
State prediction error at timestep 711 is tensor(5.7990e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 711 of None
Current timestep = 712. State = [[-0.1719394   0.18600741]]. Action = [[-0.06004999  0.01945768  0.          0.03730249]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 712 is [True, False, False, False, False, True]
State prediction error at timestep 712 is tensor(3.1941e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 712 of None
Current timestep = 713. State = [[-0.17528525  0.18663351]]. Action = [[-0.02921057 -0.03419071  0.         -0.82578933]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 713 is [True, False, False, False, False, True]
State prediction error at timestep 713 is tensor(4.6658e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 713 of None
Current timestep = 714. State = [[-0.18024524  0.19012125]]. Action = [[-0.07490948  0.05958103  0.         -0.9929851 ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 714 is [True, False, False, False, False, True]
State prediction error at timestep 714 is tensor(3.8945e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 714 of None
Current timestep = 715. State = [[-0.18629068  0.19312108]]. Action = [[-0.06125618 -0.00299867  0.          0.11581945]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 715 is [True, False, False, False, False, True]
State prediction error at timestep 715 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 715 of None
Current timestep = 716. State = [[-0.18765023  0.19246374]]. Action = [[ 0.03033621 -0.03789983  0.         -0.33604884]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 716 is [True, False, False, False, False, True]
State prediction error at timestep 716 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 716 of None
Current timestep = 717. State = [[-0.19209035  0.19276838]]. Action = [[-0.08551618  0.01362847  0.         -0.54537874]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 717 is [True, False, False, False, False, True]
State prediction error at timestep 717 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 717 of None
Current timestep = 718. State = [[-0.19360991  0.19325513]]. Action = [[ 0.042078   -0.00858474  0.         -0.8512873 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 718 is [True, False, False, False, False, True]
State prediction error at timestep 718 is tensor(1.8070e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 718 of None
Current timestep = 719. State = [[-0.19686791  0.1956259 ]]. Action = [[-0.06211795  0.04945264  0.          0.28851616]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 719 is [True, False, False, False, False, True]
State prediction error at timestep 719 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 719 of None
Current timestep = 720. State = [[-0.2005901   0.20089844]]. Action = [[-0.0086655   0.07402278  0.         -0.71818745]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 720 is [True, False, False, False, False, True]
State prediction error at timestep 720 is tensor(1.2731e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 720 of None
Current timestep = 721. State = [[-0.19780618  0.2000557 ]]. Action = [[ 0.09895653 -0.06011579  0.         -0.8354593 ]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 721 is [True, False, False, False, False, True]
State prediction error at timestep 721 is tensor(2.8276e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 721 of None
Current timestep = 722. State = [[-0.20009048  0.20056912]]. Action = [[-0.07921505  0.05199658  0.         -0.02548915]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 722 is [True, False, False, False, False, True]
State prediction error at timestep 722 is tensor(1.6862e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 722 of None
Current timestep = 723. State = [[-0.20355757  0.20633519]]. Action = [[ 0.00144859  0.08666148  0.         -0.7722773 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 723 is [True, False, False, False, False, True]
State prediction error at timestep 723 is tensor(1.9469e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 723 of None
Current timestep = 724. State = [[-0.20255353  0.2114253 ]]. Action = [[ 0.05666017  0.05177224  0.         -0.57580626]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 724 is [True, False, False, False, False, True]
State prediction error at timestep 724 is tensor(2.2671e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 724 of None
Current timestep = 725. State = [[-0.19952844  0.21255091]]. Action = [[ 0.05685186 -0.00686871  0.          0.35779536]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 725 is [True, False, False, False, False, True]
State prediction error at timestep 725 is tensor(6.5647e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 725 of None
Current timestep = 726. State = [[-0.19419904  0.20770468]]. Action = [[ 0.08492806 -0.09248821  0.         -0.36755216]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 726 is [True, False, False, False, False, True]
State prediction error at timestep 726 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 726 of None
Current timestep = 727. State = [[-0.1868536   0.20086703]]. Action = [[ 0.09021271 -0.07614396  0.         -0.4142195 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 727 is [True, False, False, False, False, True]
State prediction error at timestep 727 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 727 of None
Current timestep = 728. State = [[-0.18472053  0.19750474]]. Action = [[-0.03364623 -0.00803602  0.          0.83901906]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 728 is [True, False, False, False, False, True]
State prediction error at timestep 728 is tensor(1.0281e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 728 of None
Current timestep = 729. State = [[-0.18090275  0.19411837]]. Action = [[ 0.06637654 -0.04978693  0.         -0.38389885]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 729 is [True, False, False, False, False, True]
State prediction error at timestep 729 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 729 of None
Current timestep = 730. State = [[-0.18137434  0.1913752 ]]. Action = [[-0.08145909 -0.0131226   0.          0.19101381]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 730 is [True, False, False, False, False, True]
State prediction error at timestep 730 is tensor(6.1725e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 730 of None
Current timestep = 731. State = [[-0.1854289   0.19373879]]. Action = [[-0.06649695  0.061144    0.         -0.7846142 ]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 731 is [True, False, False, False, False, True]
State prediction error at timestep 731 is tensor(2.9802e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 731 of None
Current timestep = 732. State = [[-0.184528    0.19096729]]. Action = [[ 0.04259891 -0.0893927   0.          0.54204977]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 732 is [True, False, False, False, False, True]
State prediction error at timestep 732 is tensor(6.0834e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 732 of None
Current timestep = 733. State = [[-0.18725148  0.19147645]]. Action = [[-0.09312073  0.0679263   0.         -0.9412025 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 733 is [True, False, False, False, False, True]
State prediction error at timestep 733 is tensor(7.8132e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 733 of None
Current timestep = 734. State = [[-0.18650334  0.19381897]]. Action = [[ 0.06845092  0.01049823  0.         -0.74334   ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 734 is [True, False, False, False, False, True]
State prediction error at timestep 734 is tensor(3.9975e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 734 of None
Current timestep = 735. State = [[-0.1879877   0.19111441]]. Action = [[-0.07435589 -0.06626314  0.         -0.6629184 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 735 is [True, False, False, False, False, True]
State prediction error at timestep 735 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 735 of None
Current timestep = 736. State = [[-0.18686388  0.18450111]]. Action = [[ 0.06213946 -0.09496504  0.         -0.0999583 ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 736 is [True, False, False, False, False, True]
State prediction error at timestep 736 is tensor(3.0541e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 736 of None
Current timestep = 737. State = [[-0.18671843  0.17912717]]. Action = [[-0.03638103 -0.04028258  0.         -0.93581367]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 737 is [True, False, False, False, False, True]
State prediction error at timestep 737 is tensor(6.1743e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 737 of None
Current timestep = 738. State = [[-0.18642357  0.17824845]]. Action = [[ 0.02146723  0.02236868  0.         -0.81616735]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 738 is [True, False, False, False, False, True]
State prediction error at timestep 738 is tensor(3.9414e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 738 of None
Current timestep = 739. State = [[-0.18938038  0.18159968]]. Action = [[-0.06649239  0.07195691  0.         -0.7614515 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 739 is [True, False, False, False, False, True]
State prediction error at timestep 739 is tensor(2.8924e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 739 of None
Current timestep = 740. State = [[-0.19602308  0.18546943]]. Action = [[-0.08288784  0.04066379  0.         -0.60546315]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 740 is [True, False, False, False, False, True]
State prediction error at timestep 740 is tensor(2.4765e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 740 of None
Current timestep = 741. State = [[-0.19552056  0.18568431]]. Action = [[ 0.08350687 -0.01938571  0.          0.49074173]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 741 is [True, False, False, False, False, True]
State prediction error at timestep 741 is tensor(2.2341e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 741 of None
Current timestep = 742. State = [[-0.19389246  0.1879456 ]]. Action = [[0.00914097 0.0648182  0.         0.45006108]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 742 is [True, False, False, False, False, True]
State prediction error at timestep 742 is tensor(5.8743e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 742 of None
Current timestep = 743. State = [[-0.19159642  0.19212002]]. Action = [[ 0.06239968  0.05615527  0.         -0.89179873]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 743 is [True, False, False, False, False, True]
State prediction error at timestep 743 is tensor(5.8746e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 743 of None
Current timestep = 744. State = [[-0.190715    0.19598654]]. Action = [[0.00363304 0.05123831 0.         0.9591639 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 744 is [True, False, False, False, False, True]
State prediction error at timestep 744 is tensor(4.3267e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 744 of None
Current timestep = 745. State = [[-0.19484313  0.19433399]]. Action = [[-0.07911585 -0.07326297  0.         -0.7796792 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 745 is [True, False, False, False, False, True]
State prediction error at timestep 745 is tensor(6.3736e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 745 of None
Current timestep = 746. State = [[-0.19324672  0.19098064]]. Action = [[ 0.09206713 -0.03250124  0.         -0.89114326]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 746 is [True, False, False, False, False, True]
State prediction error at timestep 746 is tensor(1.8391e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 746 of None
Current timestep = 747. State = [[-0.19386102  0.19281854]]. Action = [[-0.06245117  0.05651661  0.          0.32625747]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 747 is [True, False, False, False, False, True]
State prediction error at timestep 747 is tensor(3.9956e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 747 of None
Current timestep = 748. State = [[-0.19103707  0.1949288 ]]. Action = [[0.09414282 0.0051381  0.         0.17089558]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 748 is [True, False, False, False, False, True]
State prediction error at timestep 748 is tensor(1.1111e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 748 of None
Current timestep = 749. State = [[-0.18999241  0.19206989]]. Action = [[-0.04240106 -0.06889234  0.          0.5379673 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 749 is [True, False, False, False, False, True]
State prediction error at timestep 749 is tensor(2.7201e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 749 of None
Current timestep = 750. State = [[-0.19053848  0.186194  ]]. Action = [[-0.00203671 -0.08575591  0.         -0.16753787]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 750 is [True, False, False, False, False, True]
State prediction error at timestep 750 is tensor(4.6952e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 750 of None
Current timestep = 751. State = [[-0.19310011  0.18264452]]. Action = [[-0.06616767 -0.0233991   0.         -0.01850593]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 751 is [True, False, False, False, False, True]
State prediction error at timestep 751 is tensor(4.4908e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 751 of None
Current timestep = 752. State = [[-0.19566026  0.18603365]]. Action = [[-0.02124311  0.0830744   0.         -0.9954066 ]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 752 is [True, False, False, False, False, True]
State prediction error at timestep 752 is tensor(1.5876e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 752 of None
Current timestep = 753. State = [[-0.1917676   0.18338764]]. Action = [[ 0.09484438 -0.09882001  0.         -0.00982201]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 753 is [True, False, False, False, False, True]
State prediction error at timestep 753 is tensor(1.3498e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 753 of None
Current timestep = 754. State = [[-0.18385343  0.17566226]]. Action = [[ 0.09822422 -0.08116858  0.         -0.00965673]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 754 is [True, False, False, False, False, True]
State prediction error at timestep 754 is tensor(3.8672e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 754 of None
Current timestep = 755. State = [[-0.17701465  0.17502117]]. Action = [[ 0.06485412  0.07072622  0.         -0.4990071 ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 755 is [True, False, False, False, False, True]
State prediction error at timestep 755 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 755 of None
Current timestep = 756. State = [[-0.17790227  0.17222404]]. Action = [[-0.08729248 -0.07455187  0.         -0.951071  ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 756 is [True, False, False, False, False, True]
State prediction error at timestep 756 is tensor(4.8058e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 756 of None
Current timestep = 757. State = [[-0.17537342  0.16708261]]. Action = [[ 0.09766882 -0.03400389  0.         -0.53300124]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 757 is [True, False, False, False, False, True]
State prediction error at timestep 757 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 757 of None
Current timestep = 758. State = [[-0.1755212   0.16589896]]. Action = [[-0.06972717  0.02744371  0.         -0.26083332]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 758 is [True, False, False, False, False, True]
State prediction error at timestep 758 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 758 of None
Current timestep = 759. State = [[-0.17434442  0.16861539]]. Action = [[ 0.05975468  0.0647266   0.         -0.52785385]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 759 is [True, False, False, False, False, True]
State prediction error at timestep 759 is tensor(4.5526e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 759 of None
Current timestep = 760. State = [[-0.17414704  0.16870168]]. Action = [[-0.03111105 -0.01751219  0.          0.36060333]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 760 is [True, False, False, False, False, True]
State prediction error at timestep 760 is tensor(1.1353e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 760 of None
Current timestep = 761. State = [[-0.17867404  0.1717898 ]]. Action = [[-0.07638167  0.0779795   0.          0.5446844 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 761 is [True, False, False, False, False, True]
State prediction error at timestep 761 is tensor(1.5320e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 761 of None
Current timestep = 762. State = [[-0.17946213  0.17363118]]. Action = [[ 0.03780248 -0.0087795   0.         -0.5450827 ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 762 is [True, False, False, False, False, True]
State prediction error at timestep 762 is tensor(4.3937e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 762 of None
Current timestep = 763. State = [[-0.18201646  0.17742221]]. Action = [[-0.05967756  0.07582349  0.         -0.98712957]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 763 is [True, False, False, False, False, True]
State prediction error at timestep 763 is tensor(9.2117e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 763 of None
Current timestep = 764. State = [[-0.18393613  0.17723499]]. Action = [[ 0.00795119 -0.05990616  0.         -0.01541817]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 764 is [True, False, False, False, False, True]
State prediction error at timestep 764 is tensor(8.5345e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 764 of None
Current timestep = 765. State = [[-0.18164843  0.17211229]]. Action = [[ 0.04944909 -0.08039597  0.         -0.51731336]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 765 is [True, False, False, False, False, True]
State prediction error at timestep 765 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 765 of None
Current timestep = 766. State = [[-0.18169984  0.16927576]]. Action = [[-0.0314877  -0.01182826  0.         -0.3450958 ]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 766 is [True, False, False, False, False, True]
State prediction error at timestep 766 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 766 of None
Current timestep = 767. State = [[-0.18482043  0.17089827]]. Action = [[-0.04778857  0.03722338  0.         -0.761178  ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 767 is [True, False, False, False, False, True]
State prediction error at timestep 767 is tensor(5.3105e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 767 of None
Current timestep = 768. State = [[-0.19001585  0.17550106]]. Action = [[-0.07015808  0.06272685  0.         -0.2930509 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 768 is [True, False, False, False, False, True]
State prediction error at timestep 768 is tensor(4.0836e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 768 of None
Current timestep = 769. State = [[-0.19278331  0.18214957]]. Action = [[ 0.00498321  0.08471084  0.         -0.97801226]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 769 is [True, False, False, False, False, True]
State prediction error at timestep 769 is tensor(2.9799e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 769 of None
Current timestep = 770. State = [[-0.19303966  0.18982819]]. Action = [[ 0.02555949  0.09421455  0.         -0.7884393 ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 770 is [True, False, False, False, False, True]
State prediction error at timestep 770 is tensor(2.1809e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 770 of None
Current timestep = 771. State = [[-0.19706428  0.1902237 ]]. Action = [[-0.07542247 -0.0694467   0.         -0.82025856]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 771 is [True, False, False, False, False, True]
State prediction error at timestep 771 is tensor(3.9852e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 771 of None
Current timestep = 772. State = [[-0.20487505  0.18543203]]. Action = [[-0.09350871 -0.08489807  0.          0.1664561 ]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 772 is [True, False, False, False, False, True]
State prediction error at timestep 772 is tensor(8.4050e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 772 of None
Current timestep = 773. State = [[-0.20668301  0.17992477]]. Action = [[ 0.04065578 -0.07902218  0.         -0.6890601 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 773 is [True, False, False, False, False, True]
State prediction error at timestep 773 is tensor(5.4331e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 773 of None
Current timestep = 774. State = [[-0.20382467  0.17896521]]. Action = [[ 0.05450998  0.02899978  0.         -0.11727142]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 774 is [True, False, False, False, False, True]
State prediction error at timestep 774 is tensor(4.1107e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 774 of None
Current timestep = 775. State = [[-0.20208383  0.18302657]]. Action = [[ 0.02272024  0.07983773  0.         -0.9178512 ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 775 is [True, False, False, False, False, True]
State prediction error at timestep 775 is tensor(2.5486e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 775 of None
Current timestep = 776. State = [[-0.20379758  0.18163835]]. Action = [[-0.03530105 -0.0683025   0.         -0.7157455 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 776 is [True, False, False, False, False, True]
State prediction error at timestep 776 is tensor(7.8881e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 776 of None
Current timestep = 777. State = [[-0.20194182  0.17606503]]. Action = [[ 0.06669145 -0.06740217  0.         -0.8612726 ]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 777 is [True, False, False, False, False, True]
State prediction error at timestep 777 is tensor(4.8588e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 777 of None
Current timestep = 778. State = [[-0.1977369   0.17376553]]. Action = [[ 0.05178187  0.0151819   0.         -0.02401131]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 778 is [True, False, False, False, False, True]
State prediction error at timestep 778 is tensor(2.0023e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 778 of None
Current timestep = 779. State = [[-0.19924554  0.17152181]]. Action = [[-0.06659424 -0.03325915  0.         -0.79453534]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 779 is [True, False, False, False, False, True]
State prediction error at timestep 779 is tensor(8.3636e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 779 of None
Current timestep = 780. State = [[-0.20477085  0.1656378 ]]. Action = [[-0.08136597 -0.09014343  0.          0.33865452]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 780 is [True, False, False, False, False, True]
State prediction error at timestep 780 is tensor(1.8309e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 780 of None
Current timestep = 781. State = [[-0.20291376  0.16290477]]. Action = [[ 0.09623004  0.0187216   0.         -0.9742958 ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 781 is [True, False, False, False, False, True]
State prediction error at timestep 781 is tensor(2.4899e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 781 of None
Current timestep = 782. State = [[-0.1950584   0.15948184]]. Action = [[ 0.09563532 -0.05115573  0.          0.19943571]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 782 is [True, False, False, False, False, True]
State prediction error at timestep 782 is tensor(2.6911e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 782 of None
Current timestep = 783. State = [[-0.18808073  0.15660761]]. Action = [[ 0.06319001  0.0029721   0.         -0.9405144 ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 783 is [True, False, False, False, False, True]
State prediction error at timestep 783 is tensor(9.6946e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 783 of None
Current timestep = 784. State = [[-0.18112078  0.15607288]]. Action = [[0.07991765 0.02307348 0.         0.7791686 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 784 is [True, False, False, False, False, True]
State prediction error at timestep 784 is tensor(6.8498e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 784 of None
Current timestep = 785. State = [[-0.18014075  0.15609987]]. Action = [[-0.05479734  0.01517282  0.          0.29862905]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 785 is [True, False, False, False, False, True]
State prediction error at timestep 785 is tensor(2.1225e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 785 of None
Current timestep = 786. State = [[-0.17841743  0.15977378]]. Action = [[ 0.04913033  0.08503402  0.         -0.37618297]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 786 is [True, False, False, False, False, True]
State prediction error at timestep 786 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 786 of None
Current timestep = 787. State = [[-0.1788852   0.15793566]]. Action = [[-0.05649011 -0.07784439  0.         -0.4015621 ]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 787 is [True, False, False, False, False, True]
State prediction error at timestep 787 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 787 of None
Current timestep = 788. State = [[-0.17960013  0.15990649]]. Action = [[ 0.00803082  0.08802976  0.         -0.7093947 ]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 788 is [True, False, False, False, False, True]
State prediction error at timestep 788 is tensor(3.7687e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 788 of None
Current timestep = 789. State = [[-0.1771965   0.16354458]]. Action = [[ 0.04630091  0.02762879  0.         -0.06905138]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 789 is [True, False, False, False, False, True]
State prediction error at timestep 789 is tensor(9.3241e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 789 of None
Current timestep = 790. State = [[-0.17971955  0.16294879]]. Action = [[-0.08638468 -0.03741048  0.          0.83164144]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 790 is [True, False, False, False, False, True]
State prediction error at timestep 790 is tensor(7.9247e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 790 of None
Current timestep = 791. State = [[-0.18581548  0.1598439 ]]. Action = [[-0.08123295 -0.05831217  0.         -0.97657406]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 791 is [True, False, False, False, False, True]
State prediction error at timestep 791 is tensor(1.9225e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 791 of None
Current timestep = 792. State = [[-0.19252323  0.16197816]]. Action = [[-0.08639898  0.05900807  0.         -0.8389355 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 792 is [True, False, False, False, False, True]
State prediction error at timestep 792 is tensor(7.1960e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 792 of None
Current timestep = 793. State = [[-0.19154832  0.16470109]]. Action = [[0.09414358 0.00993919 0.         0.24174225]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 793 is [True, False, False, False, False, True]
State prediction error at timestep 793 is tensor(8.7087e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 793 of None
Current timestep = 794. State = [[-0.19231847  0.16503559]]. Action = [[-0.05716166 -0.01107396  0.         -0.8720465 ]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 794 is [True, False, False, False, False, True]
State prediction error at timestep 794 is tensor(4.3350e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 794 of None
Current timestep = 795. State = [[-0.19177277  0.16444689]]. Action = [[ 0.05318899 -0.01439317  0.         -0.9853858 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 795 is [True, False, False, False, False, True]
State prediction error at timestep 795 is tensor(5.7856e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 795 of None
Current timestep = 796. State = [[-0.19145918  0.1613872 ]]. Action = [[-0.01473095 -0.05496125  0.         -0.04101241]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 796 is [True, False, False, False, False, True]
State prediction error at timestep 796 is tensor(1.6144e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 796 of None
Current timestep = 797. State = [[-0.19285472  0.15883732]]. Action = [[-0.0198672  -0.02039111  0.         -0.7592256 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 797 is [True, False, False, False, False, True]
State prediction error at timestep 797 is tensor(7.7905e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 797 of None
Current timestep = 798. State = [[-0.19454546  0.15604301]]. Action = [[-0.0218766  -0.04218298  0.         -0.7852765 ]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 798 is [True, False, False, False, False, True]
State prediction error at timestep 798 is tensor(7.9742e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 798 of None
Current timestep = 799. State = [[-0.1952285   0.15547429]]. Action = [[ 0.00078012  0.01820868  0.         -0.6721428 ]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 799 is [True, False, False, False, False, True]
State prediction error at timestep 799 is tensor(7.4490e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 799 of None
Current timestep = 800. State = [[-0.19296008  0.15643573]]. Action = [[ 0.05318733  0.02104495  0.         -0.9283992 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 800 is [True, False, False, False, False, True]
State prediction error at timestep 800 is tensor(3.2419e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 800 of None
Current timestep = 801. State = [[-0.18724671  0.15404256]]. Action = [[ 0.09341408 -0.04232084  0.         -0.43570817]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 801 is [True, False, False, False, False, True]
State prediction error at timestep 801 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 801 of None
Current timestep = 802. State = [[-0.18346453  0.14725874]]. Action = [[ 0.01723769 -0.09009178  0.          0.80735683]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 802 is [True, False, False, False, False, True]
State prediction error at timestep 802 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 802 of None
Current timestep = 803. State = [[-0.18448077  0.14466867]]. Action = [[-0.04701221  0.02222691  0.         -0.8684809 ]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 803 is [True, False, False, False, False, True]
State prediction error at timestep 803 is tensor(5.5534e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 803 of None
Current timestep = 804. State = [[-0.18229365  0.14644657]]. Action = [[ 0.06520989  0.04654033  0.         -0.21148145]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 804 is [True, False, False, False, False, True]
State prediction error at timestep 804 is tensor(6.4421e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 804 of None
Current timestep = 805. State = [[-0.17599805  0.14574836]]. Action = [[ 0.08770282 -0.01661402  0.         -0.17325044]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 805 is [True, False, False, False, False, True]
State prediction error at timestep 805 is tensor(8.0568e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 805 of None
Current timestep = 806. State = [[-0.169079    0.13979802]]. Action = [[ 0.07502035 -0.0842034   0.         -0.4269899 ]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 806 is [True, False, False, False, False, True]
State prediction error at timestep 806 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 806 of None
Current timestep = 807. State = [[-0.16223837  0.13937537]]. Action = [[ 0.07280185  0.07264955  0.         -0.07721984]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 807 is [True, False, False, False, False, True]
State prediction error at timestep 807 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 807 of None
Current timestep = 808. State = [[-0.15734512  0.14474335]]. Action = [[0.03995537 0.09839117 0.         0.15999722]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 808 is [True, False, False, False, False, True]
State prediction error at timestep 808 is tensor(5.4691e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 808 of None
Current timestep = 809. State = [[-0.15686202  0.14468586]]. Action = [[-0.03611841 -0.04542102  0.          0.5728071 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 809 is [True, False, False, False, False, True]
State prediction error at timestep 809 is tensor(3.3411e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 809 of None
Current timestep = 810. State = [[-0.15348883  0.14078014]]. Action = [[ 0.06449436 -0.04853399  0.         -0.5285346 ]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 810 is [True, False, False, False, False, True]
State prediction error at timestep 810 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 810 of None
Current timestep = 811. State = [[-0.15199581  0.14349656]]. Action = [[-0.02817736  0.09283025  0.         -0.301669  ]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 811 is [True, False, False, False, False, True]
State prediction error at timestep 811 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 811 of None
Current timestep = 812. State = [[-0.14937373  0.14421788]]. Action = [[ 0.04984509 -0.03862877  0.         -0.6406912 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 812 is [True, False, False, False, False, True]
State prediction error at timestep 812 is tensor(9.8742e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 812 of None
Current timestep = 813. State = [[-0.14621268  0.14184316]]. Action = [[ 0.01328947 -0.02961161  0.         -0.84497255]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 813 is [True, False, False, False, False, True]
State prediction error at timestep 813 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 813 of None
Current timestep = 814. State = [[-0.14795142  0.14021719]]. Action = [[-0.07316679 -0.02063358  0.         -0.8969563 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 814 is [True, False, False, False, False, True]
State prediction error at timestep 814 is tensor(6.1882e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 814 of None
Current timestep = 815. State = [[-0.14641204  0.13713911]]. Action = [[ 0.0444978  -0.05875156  0.         -0.9042825 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 815 is [True, False, False, False, False, True]
State prediction error at timestep 815 is tensor(5.3147e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 815 of None
Current timestep = 816. State = [[-0.13986456  0.14006256]]. Action = [[ 0.09090043  0.09690524  0.         -0.9060341 ]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 816 is [True, False, False, False, False, True]
State prediction error at timestep 816 is tensor(4.9169e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 816 of None
Current timestep = 817. State = [[-0.13367622  0.1418546 ]]. Action = [[ 0.05868029 -0.01219621  0.         -0.5054985 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 817 is [True, False, False, False, False, True]
State prediction error at timestep 817 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 817 of None
Current timestep = 818. State = [[-0.12687269  0.13722406]]. Action = [[ 0.07802653 -0.08281392  0.         -0.90674835]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 818 is [True, False, False, False, False, True]
State prediction error at timestep 818 is tensor(9.9182e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 818 of None
Current timestep = 819. State = [[-0.12199892  0.13697645]]. Action = [[ 0.02250241  0.05541243  0.         -0.74435097]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 819 is [True, False, False, False, False, True]
State prediction error at timestep 819 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 819 of None
Current timestep = 820. State = [[-0.12111092  0.14031115]]. Action = [[-0.02385489  0.04344568  0.         -0.6893322 ]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 820 is [True, False, False, False, False, True]
State prediction error at timestep 820 is tensor(8.9144e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 820 of None
Current timestep = 821. State = [[-0.12058946  0.14465453]]. Action = [[ 0.00105224  0.05748702  0.         -0.7532946 ]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 821 is [True, False, False, False, False, True]
State prediction error at timestep 821 is tensor(4.8506e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 821 of None
Current timestep = 822. State = [[-0.12370177  0.14701755]]. Action = [[-8.3768308e-02 -2.7845055e-04  0.0000000e+00 -3.2602310e-01]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 822 is [True, False, False, False, False, True]
State prediction error at timestep 822 is tensor(8.6634e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 822 of None
Current timestep = 823. State = [[-0.1238711   0.14867082]]. Action = [[0.02856057 0.01160879 0.         0.6682048 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 823 is [True, False, False, False, False, True]
State prediction error at timestep 823 is tensor(1.7407e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 823 of None
Current timestep = 824. State = [[-0.12460189  0.14798395]]. Action = [[-0.04379533 -0.04085473  0.         -0.8989877 ]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 824 is [True, False, False, False, False, True]
State prediction error at timestep 824 is tensor(4.1602e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 824 of None
Current timestep = 825. State = [[-0.12253784  0.15134344]]. Action = [[ 0.05869288  0.07370894  0.         -0.82746816]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 825 is [True, False, False, False, False, True]
State prediction error at timestep 825 is tensor(3.0416e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 825 of None
Current timestep = 826. State = [[-0.11672271  0.1521524 ]]. Action = [[ 0.07892118 -0.03736067  0.         -0.8511992 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 826 is [True, False, False, False, False, True]
State prediction error at timestep 826 is tensor(5.5267e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 826 of None
Current timestep = 827. State = [[-0.11538351  0.14982833]]. Action = [[-0.03853248 -0.03683665  0.          0.58830893]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 827 is [True, False, False, False, False, True]
State prediction error at timestep 827 is tensor(6.8600e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 827 of None
Current timestep = 828. State = [[-0.11316169  0.15137492]]. Action = [[ 0.04888571  0.04592545  0.         -0.9445583 ]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 828 is [True, False, False, False, False, True]
State prediction error at timestep 828 is tensor(1.8103e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 828 of None
Current timestep = 829. State = [[-0.11409966  0.15411086]]. Action = [[-0.06114295  0.02110831  0.         -0.267821  ]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 829 is [True, False, False, False, False, True]
State prediction error at timestep 829 is tensor(9.2322e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 829 of None
Current timestep = 830. State = [[-0.11499421  0.15608087]]. Action = [[ 0.00409018  0.01170845  0.         -0.40159595]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 830 is [True, False, False, False, False, True]
State prediction error at timestep 830 is tensor(7.7186e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 830 of None
Current timestep = 831. State = [[-0.11851908  0.15505446]]. Action = [[-0.08485473 -0.04531053  0.         -0.42926586]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 831 is [True, False, False, False, False, True]
State prediction error at timestep 831 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 831 of None
Current timestep = 832. State = [[-0.11876421  0.15885918]]. Action = [[ 0.04640882  0.08958895  0.         -0.952247  ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 832 is [True, False, False, False, False, True]
State prediction error at timestep 832 is tensor(4.4158e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 832 of None
Current timestep = 833. State = [[-0.11421316  0.15808877]]. Action = [[ 0.06463823 -0.0776719   0.         -0.7500523 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 833 is [True, False, False, False, False, True]
State prediction error at timestep 833 is tensor(6.4979e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 833 of None
Current timestep = 834. State = [[-0.11059     0.16032977]]. Action = [[ 0.0254031   0.08487298  0.         -0.9707994 ]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 834 is [True, False, False, False, False, True]
State prediction error at timestep 834 is tensor(9.5935e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 834 of None
Current timestep = 835. State = [[-0.10706402  0.16705056]]. Action = [[ 0.05439211  0.08461481  0.         -0.10137272]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 835 is [True, False, False, False, False, True]
State prediction error at timestep 835 is tensor(6.7327e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 835 of None
Current timestep = 836. State = [[-0.10161368  0.17386071]]. Action = [[ 0.08472612  0.08274011  0.         -0.68601465]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 836 is [True, False, False, False, False, True]
State prediction error at timestep 836 is tensor(5.5577e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 836 of None
Current timestep = 837. State = [[-0.09607015  0.17918642]]. Action = [[ 0.06780443  0.05397529  0.         -0.5958774 ]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 837 is [True, False, False, False, False, True]
State prediction error at timestep 837 is tensor(7.6568e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 837 of None
Current timestep = 838. State = [[-0.08974023  0.17738132]]. Action = [[ 0.08159382 -0.07596143  0.         -0.9453525 ]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 838 is [True, False, False, False, False, True]
State prediction error at timestep 838 is tensor(5.5817e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 838 of None
Current timestep = 839. State = [[-0.08323535  0.17367321]]. Action = [[ 0.06138403 -0.03627026  0.         -0.82736075]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 839 is [True, False, False, False, False, True]
State prediction error at timestep 839 is tensor(8.6612e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 839 of None
Current timestep = 840. State = [[-0.07649596  0.17382854]]. Action = [[ 0.06973734  0.02835866  0.         -0.8155819 ]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 840 is [True, False, False, False, False, True]
State prediction error at timestep 840 is tensor(8.6993e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 840 of None
Current timestep = 841. State = [[-0.07703693  0.17882343]]. Action = [[-0.09003887  0.08160429  0.          0.37636757]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 841 is [True, False, False, False, False, True]
State prediction error at timestep 841 is tensor(1.6048e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 841 of None
Current timestep = 842. State = [[-0.07499424  0.18376917]]. Action = [[ 0.06702308  0.03801759  0.         -0.50322247]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 842 is [True, False, False, False, False, True]
State prediction error at timestep 842 is tensor(4.7452e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 842 of None
Current timestep = 843. State = [[-0.07432514  0.18718126]]. Action = [[-0.04830685  0.02592341  0.         -0.66850996]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 843 is [True, False, False, False, False, True]
State prediction error at timestep 843 is tensor(7.9231e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 843 of None
Current timestep = 844. State = [[-0.07072003  0.18722238]]. Action = [[ 0.0727281  -0.03921443  0.          0.1903255 ]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 844 is [True, False, False, False, False, True]
State prediction error at timestep 844 is tensor(7.2959e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 844 of None
Current timestep = 845. State = [[-0.0676621   0.18731199]]. Action = [[-0.00767609  0.00541653  0.         -0.75277686]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 845 is [True, False, False, False, False, True]
State prediction error at timestep 845 is tensor(7.9021e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 845 of None
Current timestep = 846. State = [[-0.06159602  0.18794732]]. Action = [[ 0.09753457 -0.00417178  0.         -0.73881674]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 846 is [True, False, False, False, False, True]
State prediction error at timestep 846 is tensor(6.8350e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 846 of None
Current timestep = 847. State = [[-0.05720254  0.18523808]]. Action = [[-0.00128826 -0.06201497  0.          0.15117264]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 847 is [True, False, False, False, False, True]
State prediction error at timestep 847 is tensor(4.8895e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 847 of None
Current timestep = 848. State = [[-0.05552093  0.17928529]]. Action = [[-0.01206763 -0.09314666  0.         -0.9650483 ]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 848 is [True, False, False, False, False, True]
State prediction error at timestep 848 is tensor(7.9964e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 848 of None
Current timestep = 849. State = [[-0.05674069  0.1762072 ]]. Action = [[-0.06923755 -0.01380563  0.         -0.45466882]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 849 is [True, False, False, False, False, True]
State prediction error at timestep 849 is tensor(5.3302e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 849 of None
Current timestep = 850. State = [[-0.05369406  0.1712636 ]]. Action = [[ 0.05615849 -0.09306554  0.         -0.9394925 ]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 850 is [True, False, False, False, False, True]
State prediction error at timestep 850 is tensor(3.2114e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 850 of None
Current timestep = 851. State = [[-0.0489368   0.16936362]]. Action = [[0.02638597 0.02666112 0.         0.03922749]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 851 is [False, True, False, False, False, True]
State prediction error at timestep 851 is tensor(8.0480e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 851 of None
Current timestep = 852. State = [[-0.04816472  0.17113498]]. Action = [[-0.03131233  0.03443254  0.         -0.45389378]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 852 is [False, True, False, False, False, True]
State prediction error at timestep 852 is tensor(4.6035e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 852 of None
Current timestep = 853. State = [[-0.0443237   0.17474337]]. Action = [[ 0.080655    0.06163654  0.         -0.9429861 ]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 853 is [False, True, False, False, False, True]
State prediction error at timestep 853 is tensor(4.2214e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 853 of None
Current timestep = 854. State = [[-0.04440028  0.17918709]]. Action = [[-0.06034715  0.05686305  0.         -0.9860719 ]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 854 is [False, True, False, False, False, True]
State prediction error at timestep 854 is tensor(3.7286e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 854 of None
Current timestep = 855. State = [[-0.04547225  0.17804046]]. Action = [[ 0.00214121 -0.06443019  0.         -0.98794264]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 855 is [False, True, False, False, False, True]
State prediction error at timestep 855 is tensor(1.7638e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 855 of None
Current timestep = 856. State = [[-0.04527114  0.17348659]]. Action = [[-0.00923176 -0.0615316   0.          0.06395268]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 856 is [False, True, False, False, False, True]
State prediction error at timestep 856 is tensor(1.2072e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 856 of None
Current timestep = 857. State = [[-0.04154351  0.16723348]]. Action = [[ 0.0654515  -0.08580338  0.         -0.7366477 ]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 857 is [False, True, False, False, False, True]
State prediction error at timestep 857 is tensor(8.7004e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 857 of None
Current timestep = 858. State = [[-0.04169757  0.16592833]]. Action = [[-0.05692024  0.0384692   0.         -0.5745712 ]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 858 is [False, True, False, False, False, True]
State prediction error at timestep 858 is tensor(5.1386e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 858 of None
Current timestep = 859. State = [[-0.04682346  0.16331224]]. Action = [[-0.0921061  -0.07225795  0.         -0.14371043]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 859 is [False, True, False, False, False, True]
State prediction error at timestep 859 is tensor(2.4226e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 859 of None
Current timestep = 860. State = [[-0.05298929  0.16166012]]. Action = [[-9.073537e-02  7.869601e-04  0.000000e+00 -9.509663e-01]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 860 is [True, False, False, False, False, True]
State prediction error at timestep 860 is tensor(1.5778e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 860 of None
Current timestep = 861. State = [[-0.05919439  0.16246848]]. Action = [[-0.07854428  0.00769665  0.         -0.31575406]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 861 is [True, False, False, False, False, True]
State prediction error at timestep 861 is tensor(4.5799e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 861 of None
Current timestep = 862. State = [[-0.06246668  0.16404177]]. Action = [[-0.01238865  0.01660591  0.          0.5029113 ]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 862 is [True, False, False, False, False, True]
State prediction error at timestep 862 is tensor(1.5590e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 862 of None
Current timestep = 863. State = [[-0.06421455  0.16562745]]. Action = [[-0.00688659  0.01587838  0.         -0.5727068 ]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 863 is [True, False, False, False, False, True]
State prediction error at timestep 863 is tensor(1.8553e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 863 of None
Current timestep = 864. State = [[-0.06977747  0.17062795]]. Action = [[-0.08118087  0.08493636  0.         -0.75866765]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 864 is [True, False, False, False, False, True]
State prediction error at timestep 864 is tensor(1.0283e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 864 of None
Current timestep = 865. State = [[-0.07198377  0.17686872]]. Action = [[ 0.0454281   0.06619022  0.         -0.6172999 ]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 865 is [True, False, False, False, False, True]
State prediction error at timestep 865 is tensor(1.0670e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 865 of None
Current timestep = 866. State = [[-0.07593336  0.17715935]]. Action = [[-0.06789801 -0.04891085  0.         -0.70940125]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 866 is [True, False, False, False, False, True]
State prediction error at timestep 866 is tensor(1.8486e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 866 of None
Current timestep = 867. State = [[-0.07699606  0.18029834]]. Action = [[0.06982625 0.08606017 0.         0.44941294]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 867 is [True, False, False, False, False, True]
State prediction error at timestep 867 is tensor(2.7226e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 867 of None
Current timestep = 868. State = [[-0.07966451  0.18449065]]. Action = [[-0.0518306   0.0294896   0.         -0.55441666]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 868 is [True, False, False, False, False, True]
State prediction error at timestep 868 is tensor(2.4390e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 868 of None
Current timestep = 869. State = [[-0.08646439  0.18877497]]. Action = [[-0.07073341  0.0530088   0.         -0.7865992 ]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 869 is [True, False, False, False, False, True]
State prediction error at timestep 869 is tensor(1.6792e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 869 of None
Current timestep = 870. State = [[-0.08620988  0.19235493]]. Action = [[ 0.09657706  0.02842025  0.         -0.3785575 ]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 870 is [True, False, False, False, False, True]
State prediction error at timestep 870 is tensor(6.7634e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 870 of None
Current timestep = 871. State = [[-0.08323582  0.18976273]]. Action = [[ 0.04121806 -0.07608715  0.         -0.6798469 ]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 871 is [True, False, False, False, False, True]
State prediction error at timestep 871 is tensor(5.6377e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 871 of None
Current timestep = 872. State = [[-0.07828485  0.18863113]]. Action = [[ 0.09301568  0.02311287  0.         -0.8230147 ]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 872 is [True, False, False, False, False, True]
State prediction error at timestep 872 is tensor(4.6730e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 872 of None
Current timestep = 873. State = [[-0.07499794  0.18516277]]. Action = [[ 0.01930475 -0.07161572  0.         -0.78354394]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 873 is [True, False, False, False, False, True]
State prediction error at timestep 873 is tensor(6.2158e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 873 of None
Current timestep = 874. State = [[-0.07693833  0.18475679]]. Action = [[-0.05795069  0.04157702  0.         -0.72488606]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 874 is [True, False, False, False, False, True]
State prediction error at timestep 874 is tensor(3.4829e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 874 of None
Current timestep = 875. State = [[-0.07376758  0.18084338]]. Action = [[ 0.0899455  -0.09503918  0.         -0.6805855 ]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 875 is [True, False, False, False, False, True]
State prediction error at timestep 875 is tensor(4.3390e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 875 of None
Current timestep = 876. State = [[-0.07398156  0.17333408]]. Action = [[-0.08141106 -0.08817455  0.         -0.5531831 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 876 is [True, False, False, False, False, True]
State prediction error at timestep 876 is tensor(7.6496e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 876 of None
Current timestep = 877. State = [[-0.07857022  0.17423879]]. Action = [[-0.06996746  0.08161021  0.         -0.85892665]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 877 is [True, False, False, False, False, True]
State prediction error at timestep 877 is tensor(2.6687e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 877 of None
Current timestep = 878. State = [[-0.07636388  0.17182982]]. Action = [[ 0.08338077 -0.08491488  0.         -0.5486183 ]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 878 is [True, False, False, False, False, True]
State prediction error at timestep 878 is tensor(2.7141e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 878 of None
Current timestep = 879. State = [[-0.06963731  0.16667683]]. Action = [[ 0.08689015 -0.03187789  0.         -0.5567169 ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 879 is [True, False, False, False, False, True]
State prediction error at timestep 879 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 879 of None
Current timestep = 880. State = [[-0.0622835   0.16172567]]. Action = [[ 0.09005759 -0.04199257  0.          0.21169436]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 880 is [True, False, False, False, False, True]
State prediction error at timestep 880 is tensor(6.1150e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 880 of None
Current timestep = 881. State = [[-0.05513646  0.16048656]]. Action = [[ 0.08128626  0.04509116  0.         -0.48183787]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 881 is [True, False, False, False, False, True]
State prediction error at timestep 881 is tensor(9.2127e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 881 of None
Current timestep = 882. State = [[-0.05129732  0.15928876]]. Action = [[ 0.01784156 -0.00626888  0.         -0.6464832 ]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 882 is [True, False, False, False, False, True]
State prediction error at timestep 882 is tensor(7.7135e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 882 of None
Current timestep = 883. State = [[-0.04544553  0.15722056]]. Action = [[ 0.09152757 -0.0014891   0.         -0.1368342 ]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 883 is [False, True, False, False, False, True]
State prediction error at timestep 883 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 883 of None
Current timestep = 884. State = [[-0.03731196  0.15254843]]. Action = [[ 0.09536042 -0.05225141  0.          0.52518487]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 884 is [False, True, False, False, False, True]
State prediction error at timestep 884 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 884 of None
Current timestep = 885. State = [[-0.03131837  0.14989221]]. Action = [[ 0.04113264  0.01882945  0.         -0.90335095]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 885 is [False, True, False, False, False, True]
State prediction error at timestep 885 is tensor(5.1127e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 885 of None
Current timestep = 886. State = [[-0.03110533  0.1467367 ]]. Action = [[-0.05803394 -0.0425142   0.         -0.84024   ]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 886 is [False, True, False, False, False, True]
State prediction error at timestep 886 is tensor(1.8044e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 886 of None
Current timestep = 887. State = [[-0.03420101  0.14342175]]. Action = [[-0.07415251 -0.02701037  0.         -0.6873187 ]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 887 is [False, True, False, False, False, True]
State prediction error at timestep 887 is tensor(3.1221e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 887 of None
Current timestep = 888. State = [[-0.0325626   0.14389652]]. Action = [[ 0.05142046  0.03761484  0.         -0.9643406 ]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 888 is [False, True, False, False, False, True]
State prediction error at timestep 888 is tensor(9.4241e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 888 of None
Current timestep = 889. State = [[-0.02988888  0.1427215 ]]. Action = [[ 1.7291307e-04 -3.8742136e-02  0.0000000e+00  3.0637443e-01]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 889 is [False, True, False, False, False, True]
State prediction error at timestep 889 is tensor(5.8241e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 889 of None
Current timestep = 890. State = [[-0.0243742   0.13650207]]. Action = [[ 0.07970456 -0.09739367  0.         -0.6277181 ]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 890 is [False, True, False, False, False, True]
State prediction error at timestep 890 is tensor(6.6380e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 890 of None
Current timestep = 891. State = [[-0.01798324  0.13223289]]. Action = [[ 0.05343916 -0.00995098  0.         -0.6912418 ]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 891 is [False, True, False, False, False, True]
State prediction error at timestep 891 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 891 of None
Current timestep = 892. State = [[-0.01021268  0.12732269]]. Action = [[ 0.09637154 -0.06407495  0.         -0.3368503 ]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 892 is [False, True, False, False, False, True]
State prediction error at timestep 892 is tensor(9.0483e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 892 of None
Current timestep = 893. State = [[-0.35961157  0.12521824]]. Action = [[ 0.08677707 -0.03397493  0.         -0.12736076]]. Reward = [100.]
Curr episode timestep = 333
Scene graph at timestep 893 is [True, False, False, False, False, True]
State prediction error at timestep 893 is tensor(0.0594, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 893 of None
Current timestep = 894. State = [[-0.36283404  0.1256434 ]]. Action = [[-0.04919813 -0.09688291  0.         -0.52008146]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 894 is [True, False, False, False, False, True]
State prediction error at timestep 894 is tensor(6.4863e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 894 of None
Current timestep = 895. State = [[-0.35971552  0.12227283]]. Action = [[ 0.09033526 -0.05415378  0.         -0.7808078 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 895 is [True, False, False, False, True, False]
State prediction error at timestep 895 is tensor(7.2032e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 895 of None
Current timestep = 896. State = [[-0.35915488  0.11989598]]. Action = [[-0.05932964 -0.04600285  0.         -0.36017656]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 896 is [True, False, False, False, True, False]
State prediction error at timestep 896 is tensor(8.7542e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 896 of None
Current timestep = 897. State = [[-0.3586687   0.12112716]]. Action = [[ 0.02152965  0.02462681  0.         -0.5125264 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 897 is [True, False, False, False, True, False]
State prediction error at timestep 897 is tensor(7.2879e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 897 of None
Current timestep = 898. State = [[-0.35609424  0.12398491]]. Action = [[ 0.02585504  0.02613055  0.         -0.76187396]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 898 is [True, False, False, False, True, False]
State prediction error at timestep 898 is tensor(5.7966e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 898 of None
Current timestep = 899. State = [[-0.3567977  0.1226314]]. Action = [[-0.04824836 -0.06020584  0.         -0.6265589 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 899 is [True, False, False, False, True, False]
State prediction error at timestep 899 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 899 of None
Current timestep = 900. State = [[-0.3540578   0.11940029]]. Action = [[ 0.0624548  -0.04280114  0.         -0.74621236]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 900 is [True, False, False, False, True, False]
State prediction error at timestep 900 is tensor(8.3134e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 900 of None
Current timestep = 901. State = [[-0.35010117  0.11946147]]. Action = [[ 0.02476573  0.02926048  0.         -0.8491765 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 901 is [True, False, False, False, True, False]
State prediction error at timestep 901 is tensor(5.9028e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 901 of None
Current timestep = 902. State = [[-0.34973726  0.11553809]]. Action = [[-0.03163539 -0.09302761  0.         -0.8194918 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 902 is [True, False, False, False, True, False]
State prediction error at timestep 902 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 902 of None
Current timestep = 903. State = [[-0.3502516   0.11155491]]. Action = [[-0.01778588 -0.02475397  0.         -0.9657731 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 903 is [True, False, False, False, True, False]
State prediction error at timestep 903 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 903 of None
Current timestep = 904. State = [[-0.3531768   0.10654079]]. Action = [[-0.07002357 -0.07886755  0.         -0.7620338 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 904 is [True, False, False, False, True, False]
State prediction error at timestep 904 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 904 of None
Current timestep = 905. State = [[-0.35546565  0.09956013]]. Action = [[-0.02604827 -0.08702117  0.         -0.77012545]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 905 is [True, False, False, False, True, False]
State prediction error at timestep 905 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 905 of None
Current timestep = 906. State = [[-0.352882    0.09718821]]. Action = [[ 0.06025509  0.02610045  0.         -0.17381936]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 906 is [True, False, False, False, True, False]
State prediction error at timestep 906 is tensor(6.0593e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 906 of None
Current timestep = 907. State = [[-0.35467643  0.09715735]]. Action = [[-0.07701131  0.01009114  0.         -0.2869388 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 907 is [True, False, False, False, True, False]
State prediction error at timestep 907 is tensor(3.1722e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 907 of None
Current timestep = 908. State = [[-0.35573542  0.0990532 ]]. Action = [[ 0.03032909  0.05133266  0.         -0.51079804]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 908 is [True, False, False, False, True, False]
State prediction error at timestep 908 is tensor(6.6206e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 908 of None
Current timestep = 909. State = [[-0.35853332  0.09560291]]. Action = [[-0.06138743 -0.08390728  0.         -0.2626996 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 909 is [True, False, False, False, True, False]
State prediction error at timestep 909 is tensor(2.4154e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 909 of None
Current timestep = 910. State = [[-0.36547765  0.09434699]]. Action = [[-0.08966028  0.03520954  0.         -0.66944104]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 910 is [True, False, False, False, True, False]
State prediction error at timestep 910 is tensor(9.2532e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 910 of None
Current timestep = 911. State = [[-0.3680703   0.09329772]]. Action = [[ 0.02900072 -0.0282966   0.         -0.3267277 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 911 is [True, False, False, False, True, False]
State prediction error at timestep 911 is tensor(6.1229e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 911 of None
Current timestep = 912. State = [[-0.36888567  0.09173691]]. Action = [[ 0.         0.         0.        -0.5536486]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 912 is [True, False, False, False, True, False]
State prediction error at timestep 912 is tensor(8.5827e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 912 of None
Current timestep = 913. State = [[-0.36659288  0.09374312]]. Action = [[ 0.08107107  0.06072114  0.         -0.49720228]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 913 is [True, False, False, False, True, False]
State prediction error at timestep 913 is tensor(4.4757e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 913 of None
Current timestep = 914. State = [[-0.36556855  0.09358051]]. Action = [[ 0.00680955 -0.01893435  0.         -0.2363851 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 914 is [True, False, False, False, True, False]
State prediction error at timestep 914 is tensor(1.9513e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 914 of None
Current timestep = 915. State = [[-0.36767602  0.09455284]]. Action = [[-0.02450981  0.04219268  0.         -0.5744612 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 915 is [True, False, False, False, True, False]
State prediction error at timestep 915 is tensor(5.0683e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 915 of None
Current timestep = 916. State = [[-0.36949328  0.09539302]]. Action = [[ 0.         0.         0.        -0.8078065]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 916 is [True, False, False, False, True, False]
State prediction error at timestep 916 is tensor(4.6638e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 916 of None
Current timestep = 917. State = [[-0.36764884  0.09087808]]. Action = [[ 0.05333465 -0.08590373  0.         -0.02233732]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 917 is [True, False, False, False, True, False]
State prediction error at timestep 917 is tensor(4.8957e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 917 of None
Current timestep = 918. State = [[-0.36629945  0.08790771]]. Action = [[ 0.        0.        0.       -0.298015]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 918 is [True, False, False, False, True, False]
State prediction error at timestep 918 is tensor(7.1222e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 918 of None
Current timestep = 919. State = [[-0.36626294  0.08310779]]. Action = [[-0.00469278 -0.08621593  0.         -0.17469662]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 919 is [True, False, False, False, True, False]
State prediction error at timestep 919 is tensor(2.0290e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 919 of None
Current timestep = 920. State = [[-0.36828873  0.08361607]]. Action = [[-0.04586527  0.0714627   0.         -0.06367815]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 920 is [True, False, False, False, True, False]
State prediction error at timestep 920 is tensor(3.3680e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 920 of None
Current timestep = 921. State = [[-0.3696816   0.08532247]]. Action = [[ 0.          0.          0.         -0.49073517]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 921 is [True, False, False, False, True, False]
State prediction error at timestep 921 is tensor(3.0725e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 921 of None
Current timestep = 922. State = [[-0.36882055  0.08887056]]. Action = [[0.0263226  0.07409384 0.         0.21565175]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 922 is [True, False, False, False, True, False]
State prediction error at timestep 922 is tensor(1.8403e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 922 of None
Current timestep = 923. State = [[-0.3694353   0.08939755]]. Action = [[-0.01694781 -0.03038712  0.         -0.76261544]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 923 is [True, False, False, False, True, False]
State prediction error at timestep 923 is tensor(4.9117e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 923 of None
Current timestep = 924. State = [[-0.36518013  0.08554421]]. Action = [[ 0.09858776 -0.05904131  0.         -0.83453476]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 924 is [True, False, False, False, True, False]
State prediction error at timestep 924 is tensor(6.0341e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 924 of None
Current timestep = 925. State = [[-0.35819262  0.08665413]]. Action = [[ 0.08512191  0.07163806  0.         -0.8595563 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 925 is [True, False, False, False, True, False]
State prediction error at timestep 925 is tensor(3.8189e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 925 of None
Current timestep = 926. State = [[-0.35246897  0.08997028]]. Action = [[ 0.06272467  0.03891466  0.         -0.38448584]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 926 is [True, False, False, False, True, False]
State prediction error at timestep 926 is tensor(4.9553e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 926 of None
Current timestep = 927. State = [[-0.3491711   0.08797121]]. Action = [[ 0.01595386 -0.05931797  0.         -0.28679752]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 927 is [True, False, False, False, True, False]
State prediction error at timestep 927 is tensor(2.9476e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 927 of None
Current timestep = 928. State = [[-0.34900397  0.08416918]]. Action = [[-0.03380392 -0.04401457  0.         -0.75886995]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 928 is [True, False, False, False, True, False]
State prediction error at timestep 928 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 928 of None
Current timestep = 929. State = [[-0.3513001   0.08323396]]. Action = [[-0.05813587  0.00411346  0.         -0.73279023]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 929 is [True, False, False, False, True, False]
State prediction error at timestep 929 is tensor(7.1154e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 929 of None
Current timestep = 930. State = [[-0.3479327   0.07887994]]. Action = [[ 0.07684267 -0.09013894  0.         -0.10711133]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 930 is [True, False, False, False, True, False]
State prediction error at timestep 930 is tensor(1.5907e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 930 of None
Current timestep = 931. State = [[-0.34167188  0.07206362]]. Action = [[ 0.05382612 -0.07364506  0.         -0.47023672]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 931 is [True, False, False, False, True, False]
State prediction error at timestep 931 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 931 of None
Current timestep = 932. State = [[-0.33417022  0.06929249]]. Action = [[ 0.08581305  0.01004495  0.         -0.02587157]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 932 is [True, False, False, False, True, False]
State prediction error at timestep 932 is tensor(5.9906e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 932 of None
Current timestep = 933. State = [[-0.32728702  0.070273  ]]. Action = [[ 0.05949051  0.04194463  0.         -0.6131398 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 933 is [True, False, False, False, True, False]
State prediction error at timestep 933 is tensor(5.0688e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 933 of None
Current timestep = 934. State = [[-0.326589    0.06608623]]. Action = [[-0.0598185  -0.08938282  0.         -0.19645005]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 934 is [True, False, False, False, True, False]
State prediction error at timestep 934 is tensor(5.7665e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 934 of None
Current timestep = 935. State = [[-0.32417262  0.0650204 ]]. Action = [[ 0.05781082  0.0499563   0.         -0.6392015 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 935 is [True, False, False, False, True, False]
State prediction error at timestep 935 is tensor(5.4538e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 935 of None
Current timestep = 936. State = [[-0.32536572  0.06084512]]. Action = [[-0.08847131 -0.09460086  0.         -0.8773129 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 936 is [True, False, False, False, True, False]
State prediction error at timestep 936 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 936 of None
Current timestep = 937. State = [[-0.3265839   0.06171883]]. Action = [[0.01075169 0.08857764 0.         0.15695691]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 937 is [True, False, False, False, True, False]
State prediction error at timestep 937 is tensor(3.3958e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 937 of None
Current timestep = 938. State = [[-0.32784057  0.06105625]]. Action = [[-0.03544956 -0.05246164  0.         -0.79464877]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 938 is [True, False, False, False, True, False]
State prediction error at timestep 938 is tensor(6.1004e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 938 of None
Current timestep = 939. State = [[-0.3258997   0.06036731]]. Action = [[ 0.05580052  0.02337976  0.         -0.72872806]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 939 is [True, False, False, False, True, False]
State prediction error at timestep 939 is tensor(4.5591e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 939 of None
Current timestep = 940. State = [[-0.32817322  0.05886792]]. Action = [[-0.08345276 -0.03558801  0.         -0.9294859 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 940 is [True, False, False, False, True, False]
State prediction error at timestep 940 is tensor(7.4640e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 940 of None
Current timestep = 941. State = [[-0.32851982  0.06215958]]. Action = [[ 0.05122767  0.09186623  0.         -0.538494  ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 941 is [True, False, False, False, True, False]
State prediction error at timestep 941 is tensor(1.2985e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 941 of None
Current timestep = 942. State = [[-0.32352963  0.06504996]]. Action = [[0.09083671 0.0099628  0.         0.18633938]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 942 is [True, False, False, False, True, False]
State prediction error at timestep 942 is tensor(1.2472e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 942 of None
Current timestep = 943. State = [[-0.32182825  0.06118124]]. Action = [[-0.01544491 -0.08311255  0.          0.3401059 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 943 is [True, False, False, False, True, False]
State prediction error at timestep 943 is tensor(4.2487e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 943 of None
Current timestep = 944. State = [[-0.3247923   0.06205273]]. Action = [[-0.054345    0.06789234  0.         -0.8166828 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 944 is [True, False, False, False, True, False]
State prediction error at timestep 944 is tensor(3.5023e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 944 of None
Current timestep = 945. State = [[-0.32561916  0.063382  ]]. Action = [[ 0.02049645 -0.01407737  0.         -0.05296975]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 945 is [True, False, False, False, True, False]
State prediction error at timestep 945 is tensor(4.5829e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 945 of None
Current timestep = 946. State = [[-0.323424    0.06777868]]. Action = [[ 0.04402389  0.09241939  0.         -0.01153988]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 946 is [True, False, False, False, True, False]
State prediction error at timestep 946 is tensor(2.0949e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 946 of None
Current timestep = 947. State = [[-0.3251349   0.06964878]]. Action = [[-0.05064201 -0.02212848  0.         -0.6695864 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 947 is [True, False, False, False, True, False]
State prediction error at timestep 947 is tensor(3.3877e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 947 of None
Current timestep = 948. State = [[-0.32387912  0.06547905]]. Action = [[ 0.05850222 -0.08209962  0.         -0.7453917 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 948 is [True, False, False, False, True, False]
State prediction error at timestep 948 is tensor(7.1633e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 948 of None
Current timestep = 949. State = [[-0.3223685   0.06486346]]. Action = [[-0.00190441  0.03517855  0.         -0.23658568]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 949 is [True, False, False, False, True, False]
State prediction error at timestep 949 is tensor(1.0623e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 949 of None
Current timestep = 950. State = [[-0.3207122   0.07054038]]. Action = [[ 0.03776301  0.09445126  0.         -0.44532645]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 950 is [True, False, False, False, True, False]
State prediction error at timestep 950 is tensor(9.1234e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 950 of None
Current timestep = 951. State = [[-0.32456562  0.07738793]]. Action = [[-0.09173711  0.07473362  0.         -0.3611759 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 951 is [True, False, False, False, True, False]
State prediction error at timestep 951 is tensor(8.5682e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 951 of None
Current timestep = 952. State = [[-0.33160332  0.07892676]]. Action = [[-0.07947914 -0.03359598  0.         -0.4745165 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 952 is [True, False, False, False, True, False]
State prediction error at timestep 952 is tensor(2.8913e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 952 of None
Current timestep = 953. State = [[-0.33193114  0.0748459 ]]. Action = [[ 0.05168486 -0.08431823  0.         -0.19598544]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 953 is [True, False, False, False, True, False]
State prediction error at timestep 953 is tensor(2.9662e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 953 of None
Current timestep = 954. State = [[-0.3290975   0.07281256]]. Action = [[ 0.03451569  0.0010526   0.         -0.6625253 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 954 is [True, False, False, False, True, False]
State prediction error at timestep 954 is tensor(7.7181e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 954 of None
Current timestep = 955. State = [[-0.32504177  0.06922511]]. Action = [[ 0.06065059 -0.07154544  0.         -0.95054233]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 955 is [True, False, False, False, True, False]
State prediction error at timestep 955 is tensor(7.1653e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 955 of None
Current timestep = 956. State = [[-0.32186416  0.06567207]]. Action = [[ 0.01877508 -0.02417828  0.         -0.8378547 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 956 is [True, False, False, False, True, False]
State prediction error at timestep 956 is tensor(7.4166e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 956 of None
Current timestep = 957. State = [[-0.3158396   0.06437175]]. Action = [[ 0.09728409  0.00220992  0.         -0.8242504 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 957 is [True, False, False, False, True, False]
State prediction error at timestep 957 is tensor(4.6024e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 957 of None
Current timestep = 958. State = [[-0.3098583   0.06130191]]. Action = [[ 0.04843392 -0.04340488  0.         -0.9253552 ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 958 is [True, False, False, False, True, False]
State prediction error at timestep 958 is tensor(9.3766e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 958 of None
Current timestep = 959. State = [[-0.3110568   0.05516063]]. Action = [[-0.08858993 -0.0826514   0.         -0.6210025 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 959 is [True, False, False, False, True, False]
State prediction error at timestep 959 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 959 of None
Current timestep = 960. State = [[-0.3148511   0.04757686]]. Action = [[-0.06004429 -0.08895238  0.         -0.09042156]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 960 is [True, False, False, False, True, False]
State prediction error at timestep 960 is tensor(3.2158e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 960 of None
Current timestep = 961. State = [[-0.3135103  0.0436042]]. Action = [[ 0.04346072 -0.00261139  0.         -0.16087282]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 961 is [True, False, False, False, True, False]
State prediction error at timestep 961 is tensor(1.2277e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 961 of None
Current timestep = 962. State = [[-0.3147487   0.04035278]]. Action = [[-0.067632   -0.03411222  0.         -0.4463507 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 962 is [True, False, False, False, True, False]
State prediction error at timestep 962 is tensor(4.5594e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 962 of None
Current timestep = 963. State = [[-0.3119393   0.04205007]]. Action = [[ 0.09420038  0.08185036  0.         -0.5666932 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 963 is [True, False, False, False, True, False]
State prediction error at timestep 963 is tensor(1.8367e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 963 of None
Current timestep = 964. State = [[-0.3051824  0.043216 ]]. Action = [[ 0.0840153   0.00231262  0.         -0.6610932 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 964 is [True, False, False, False, True, False]
State prediction error at timestep 964 is tensor(4.2100e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 964 of None
Current timestep = 965. State = [[-0.30143115  0.04107637]]. Action = [[ 0.01765398 -0.02459572  0.         -0.84188056]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 965 is [True, False, False, False, True, False]
State prediction error at timestep 965 is tensor(6.4594e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 965 of None
Current timestep = 966. State = [[-0.30150837  0.03917836]]. Action = [[-0.02786828 -0.0066977   0.         -0.7460561 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 966 is [True, False, False, False, True, False]
State prediction error at timestep 966 is tensor(5.8810e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 966 of None
Current timestep = 967. State = [[-0.29838917  0.03919429]]. Action = [[ 0.06811034  0.01877443  0.         -0.8916676 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 967 is [True, False, False, False, True, False]
State prediction error at timestep 967 is tensor(2.1210e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 967 of None
Current timestep = 968. State = [[-0.298737    0.03887623]]. Action = [[-0.05786559 -0.00722288  0.         -0.903812  ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 968 is [True, False, False, False, True, False]
State prediction error at timestep 968 is tensor(4.6002e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 968 of None
Current timestep = 969. State = [[-0.3022196   0.03851185]]. Action = [[-5.0626434e-02 -3.3007562e-04  0.0000000e+00 -6.6870672e-01]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 969 is [True, False, False, False, True, False]
State prediction error at timestep 969 is tensor(5.8389e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 969 of None
Current timestep = 970. State = [[-0.3022101   0.03460757]]. Action = [[ 0.02267344 -0.07608817  0.         -0.7126119 ]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 970 is [True, False, False, False, True, False]
State prediction error at timestep 970 is tensor(8.0554e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 970 of None
Current timestep = 971. State = [[-0.2999627   0.02849372]]. Action = [[ 0.02360158 -0.07066945  0.         -0.58792365]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 971 is [True, False, False, False, True, False]
State prediction error at timestep 971 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 971 of None
Current timestep = 972. State = [[-0.2959274   0.02896406]]. Action = [[0.05966351 0.06753368 0.         0.52105355]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 972 is [True, False, False, False, True, False]
State prediction error at timestep 972 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 972 of None
Current timestep = 973. State = [[-0.29094094  0.03026996]]. Action = [[0.06548465 0.00246264 0.         0.92833054]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 973 is [True, False, False, False, True, False]
State prediction error at timestep 973 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 973 of None
Current timestep = 974. State = [[-0.28556392  0.02621928]]. Action = [[ 0.06349712 -0.07104673  0.         -0.47926134]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 974 is [True, False, False, False, True, False]
State prediction error at timestep 974 is tensor(3.4915e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 974 of None
Current timestep = 975. State = [[-0.278209    0.02587178]]. Action = [[ 0.09869725  0.05227039  0.         -0.74473417]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 975 is [True, False, False, False, True, False]
State prediction error at timestep 975 is tensor(5.7249e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 975 of None
Current timestep = 976. State = [[-0.27313077  0.02623873]]. Action = [[ 0.03099003 -0.00355509  0.         -0.14069086]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 976 is [True, False, False, False, True, False]
State prediction error at timestep 976 is tensor(1.7082e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 976 of None
Current timestep = 977. State = [[-0.27083933  0.0210332 ]]. Action = [[ 0.00191579 -0.09017835  0.         -0.8620521 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 977 is [True, False, False, False, True, False]
State prediction error at timestep 977 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 977 of None
Current timestep = 978. State = [[-0.26570264  0.02023442]]. Action = [[ 0.07327182  0.05276642  0.         -0.44950163]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 978 is [True, False, False, False, True, False]
State prediction error at timestep 978 is tensor(3.3239e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 978 of None
Current timestep = 979. State = [[-0.25758865  0.01685997]]. Action = [[ 0.09516277 -0.07916147  0.          0.2352091 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 979 is [True, False, False, False, True, False]
State prediction error at timestep 979 is tensor(4.2097e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 979 of None
Current timestep = 980. State = [[-0.24886034  0.01351797]]. Action = [[ 0.08597065 -0.0021296   0.         -0.9421956 ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 980 is [True, False, False, False, True, False]
State prediction error at timestep 980 is tensor(5.9321e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 980 of None
Current timestep = 981. State = [[-0.24052899  0.01439563]]. Action = [[0.08136258 0.04341517 0.         0.4082805 ]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 981 is [True, False, False, False, True, False]
State prediction error at timestep 981 is tensor(5.0556e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 981 of None
Current timestep = 982. State = [[-0.23750627  0.01117039]]. Action = [[-0.02995658 -0.0714291   0.         -0.8951079 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 982 is [True, False, False, False, True, False]
State prediction error at timestep 982 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 982 of None
Current timestep = 983. State = [[-0.23411047  0.01151738]]. Action = [[ 0.03980427  0.06334282  0.         -0.4538617 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 983 is [True, False, False, False, True, False]
State prediction error at timestep 983 is tensor(1.1502e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 983 of None
Current timestep = 984. State = [[-0.2318648   0.01208998]]. Action = [[-0.01337643 -0.0126372   0.         -0.3713647 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 984 is [True, False, False, False, True, False]
State prediction error at timestep 984 is tensor(1.2899e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 984 of None
Current timestep = 985. State = [[-0.22853842  0.01096418]]. Action = [[ 0.03634394 -0.01093714  0.         -0.56186473]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 985 is [True, False, False, False, True, False]
State prediction error at timestep 985 is tensor(3.3611e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 985 of None
Current timestep = 986. State = [[-0.22203569  0.00845311]]. Action = [[ 0.07593217 -0.03745212  0.         -0.42047036]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 986 is [True, False, False, False, True, False]
State prediction error at timestep 986 is tensor(2.9927e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 986 of None
Current timestep = 987. State = [[-0.2168707   0.00365289]]. Action = [[ 0.02229434 -0.06530415  0.         -0.51828283]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 987 is [True, False, False, False, True, False]
State prediction error at timestep 987 is tensor(7.0651e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 987 of None
Current timestep = 988. State = [[-0.21379681 -0.00105831]]. Action = [[ 0.00478777 -0.04322062  0.         -0.63522685]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 988 is [True, False, False, False, True, False]
State prediction error at timestep 988 is tensor(8.0432e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 988 of None
Current timestep = 989. State = [[-0.2070789  -0.00526717]]. Action = [[ 0.09212748 -0.04056973  0.         -0.16515547]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 989 is [True, False, False, False, True, False]
State prediction error at timestep 989 is tensor(9.5817e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 989 of None
Current timestep = 990. State = [[-0.20633867 -0.01187284]]. Action = [[-0.08941468 -0.08667971  0.         -0.71282506]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 990 is [True, False, False, False, True, False]
State prediction error at timestep 990 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 990 of None
Current timestep = 991. State = [[-0.21049835 -0.01995032]]. Action = [[-0.08091475 -0.08874202  0.         -0.59137726]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 991 is [True, False, False, False, True, False]
State prediction error at timestep 991 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 991 of None
Current timestep = 992. State = [[-0.20846415 -0.0233368 ]]. Action = [[ 0.06254298  0.01377867  0.         -0.976003  ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 992 is [True, False, False, False, True, False]
State prediction error at timestep 992 is tensor(5.9700e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 992 of None
Current timestep = 993. State = [[-0.20612215 -0.02473558]]. Action = [[-0.00960185 -0.0038752   0.         -0.55328536]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 993 is [True, False, False, False, True, False]
State prediction error at timestep 993 is tensor(3.3181e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 993 of None
Current timestep = 994. State = [[-0.20097984 -0.02237396]]. Action = [[ 0.09438056  0.07535589  0.         -0.58893013]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 994 is [True, False, False, False, True, False]
State prediction error at timestep 994 is tensor(2.1050e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 994 of None
Current timestep = 995. State = [[-0.2014168  -0.02176667]]. Action = [[-0.07522903 -0.01210747  0.         -0.8252497 ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 995 is [True, False, False, False, True, False]
State prediction error at timestep 995 is tensor(3.3881e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 995 of None
Current timestep = 996. State = [[-0.19895263 -0.01903944]]. Action = [[ 0.09713981  0.07121318  0.         -0.69031334]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 996 is [True, False, False, False, True, False]
State prediction error at timestep 996 is tensor(9.7065e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 996 of None
Current timestep = 997. State = [[-0.19204745 -0.0143559 ]]. Action = [[ 0.09743363  0.05854721  0.         -0.6256925 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 997 is [True, False, False, False, True, False]
State prediction error at timestep 997 is tensor(5.8945e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 997 of None
Current timestep = 998. State = [[-0.18943028 -0.01066415]]. Action = [[ 0.00179039  0.03775436  0.         -0.50881445]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 998 is [True, False, False, False, True, False]
State prediction error at timestep 998 is tensor(3.6474e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 998 of None
Current timestep = 999. State = [[-0.19333552 -0.00617383]]. Action = [[-0.08362988  0.05857689  0.         -0.01606435]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 999 is [True, False, False, False, True, False]
State prediction error at timestep 999 is tensor(9.7654e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 999 of None
Current timestep = 1000. State = [[-0.19555739 -0.00076464]]. Action = [[ 0.00516427  0.05509593  0.         -0.8156694 ]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 1000 is [True, False, False, False, True, False]
State prediction error at timestep 1000 is tensor(1.8987e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1000 of None
Current timestep = 1001. State = [[-0.19195518 -0.00041246]]. Action = [[ 0.0810466  -0.0510585   0.         -0.56045115]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 1001 is [True, False, False, False, True, False]
State prediction error at timestep 1001 is tensor(9.4147e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1001 of None
Current timestep = 1002. State = [[-0.19297941 -0.00538863]]. Action = [[-0.07560058 -0.0927683   0.         -0.289212  ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 1002 is [True, False, False, False, True, False]
State prediction error at timestep 1002 is tensor(5.1486e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1002 of None
Current timestep = 1003. State = [[-0.1902647  -0.00511821]]. Action = [[ 0.09862261  0.04709717  0.         -0.60156745]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 1003 is [True, False, False, False, True, False]
State prediction error at timestep 1003 is tensor(2.0378e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1003 of None
Current timestep = 1004. State = [[-0.19068651 -0.00413563]]. Action = [[-0.07702913 -0.01656137  0.         -0.57056224]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 1004 is [True, False, False, False, True, False]
State prediction error at timestep 1004 is tensor(2.3435e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1004 of None
Current timestep = 1005. State = [[-0.19558777 -0.00414293]]. Action = [[-0.06893966 -0.00421127  0.         -0.6946759 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 1005 is [True, False, False, False, True, False]
State prediction error at timestep 1005 is tensor(4.7764e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1005 of None
Current timestep = 1006. State = [[-0.19338708 -0.00790994]]. Action = [[ 0.0860477  -0.08105911  0.         -0.8089298 ]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 1006 is [True, False, False, False, True, False]
State prediction error at timestep 1006 is tensor(8.9279e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1006 of None
Current timestep = 1007. State = [[-0.19389096 -0.01145898]]. Action = [[-0.07639588 -0.02210961  0.         -0.8353169 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 1007 is [True, False, False, False, True, False]
State prediction error at timestep 1007 is tensor(9.4494e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1007 of None
Current timestep = 1008. State = [[-0.1909651 -0.0134277]]. Action = [[ 0.09717078 -0.01864698  0.         -0.3998106 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 1008 is [True, False, False, False, True, False]
State prediction error at timestep 1008 is tensor(1.5113e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1008 of None
Current timestep = 1009. State = [[-0.19056424 -0.00968882]]. Action = [[-0.05970719  0.09725357  0.         -0.27993327]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 1009 is [True, False, False, False, True, False]
State prediction error at timestep 1009 is tensor(1.0139e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1009 of None
Current timestep = 1010. State = [[-0.19196364 -0.00326806]]. Action = [[0.00356168 0.07560771 0.         0.71630883]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 1010 is [True, False, False, False, True, False]
State prediction error at timestep 1010 is tensor(7.6974e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1010 of None
Current timestep = 1011. State = [[-0.1916647   0.00318679]]. Action = [[ 0.01680292  0.07669821  0.         -0.54659516]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 1011 is [True, False, False, False, True, False]
State prediction error at timestep 1011 is tensor(1.3310e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1011 of None
Current timestep = 1012. State = [[-0.19625129  0.00762375]]. Action = [[-0.09127998  0.02809047  0.         -0.42678773]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 1012 is [True, False, False, False, True, False]
State prediction error at timestep 1012 is tensor(1.9973e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1012 of None
Current timestep = 1013. State = [[-0.19789347  0.00816956]]. Action = [[ 0.03251541 -0.02780396  0.         -0.00589901]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 1013 is [True, False, False, False, True, False]
State prediction error at timestep 1013 is tensor(7.7037e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1013 of None
Current timestep = 1014. State = [[-0.19564463  0.00677242]]. Action = [[ 0.04217657 -0.02994648  0.         -0.81645   ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 1014 is [True, False, False, False, True, False]
State prediction error at timestep 1014 is tensor(6.0981e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1014 of None
Current timestep = 1015. State = [[-0.19830595  0.0085141 ]]. Action = [[-0.07384782  0.03949556  0.         -0.895141  ]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 1015 is [True, False, False, False, True, False]
State prediction error at timestep 1015 is tensor(4.1815e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1015 of None
Current timestep = 1016. State = [[-0.1997427   0.01308737]]. Action = [[ 0.02313934  0.05366199  0.         -0.89668256]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 1016 is [True, False, False, False, True, False]
State prediction error at timestep 1016 is tensor(2.4680e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1016 of None
Current timestep = 1017. State = [[-0.19924264  0.01547808]]. Action = [[ 0.01479097 -0.00109213  0.         -0.94572884]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 1017 is [True, False, False, False, True, False]
State prediction error at timestep 1017 is tensor(2.1994e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1017 of None
Current timestep = 1018. State = [[-0.19681318  0.015647  ]]. Action = [[ 0.0529002  -0.01182407  0.         -0.25687844]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 1018 is [True, False, False, False, True, False]
State prediction error at timestep 1018 is tensor(3.9914e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1018 of None
Current timestep = 1019. State = [[-0.19452938  0.01199147]]. Action = [[ 0.02106931 -0.07540844  0.         -0.9649116 ]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 1019 is [True, False, False, False, True, False]
State prediction error at timestep 1019 is tensor(6.6738e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1019 of None
Current timestep = 1020. State = [[-0.19439541  0.0118206 ]]. Action = [[-0.01392654  0.03790446  0.         -0.9926325 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 1020 is [True, False, False, False, True, False]
State prediction error at timestep 1020 is tensor(4.2998e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1020 of None
Current timestep = 1021. State = [[-0.1982155   0.01555518]]. Action = [[-0.07412776  0.05104519  0.         -0.49808168]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 1021 is [True, False, False, False, True, False]
State prediction error at timestep 1021 is tensor(2.6484e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1021 of None
Current timestep = 1022. State = [[-0.20087251  0.0220309 ]]. Action = [[-0.00911707  0.08954269  0.         -0.72468233]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 1022 is [True, False, False, False, True, False]
State prediction error at timestep 1022 is tensor(9.8766e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1022 of None
Current timestep = 1023. State = [[-0.20028648  0.02118861]]. Action = [[ 0.02773065 -0.08513428  0.         -0.9630215 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 1023 is [True, False, False, False, True, False]
State prediction error at timestep 1023 is tensor(4.4814e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1023 of None
Current timestep = 1024. State = [[-0.1978452   0.01491499]]. Action = [[ 0.03382332 -0.0865806   0.         -0.08991486]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 1024 is [True, False, False, False, True, False]
State prediction error at timestep 1024 is tensor(3.1390e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1024 of None
Current timestep = 1025. State = [[-0.19516112  0.01399874]]. Action = [[ 0.02964921  0.03640356  0.         -0.8530944 ]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 1025 is [True, False, False, False, True, False]
State prediction error at timestep 1025 is tensor(5.2373e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1025 of None
Current timestep = 1026. State = [[-0.1945336   0.01458651]]. Action = [[-0.00901552 -0.00336424  0.          0.09358346]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 1026 is [True, False, False, False, True, False]
State prediction error at timestep 1026 is tensor(5.4072e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1026 of None
Current timestep = 1027. State = [[-0.1924426   0.01430652]]. Action = [[ 4.2252295e-02 -5.4916739e-04  0.0000000e+00 -8.2345980e-01]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 1027 is [True, False, False, False, True, False]
State prediction error at timestep 1027 is tensor(4.2368e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1027 of None
Current timestep = 1028. State = [[-0.1885681   0.01545402]]. Action = [[ 0.05143029  0.02969361  0.         -0.69356036]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 1028 is [True, False, False, False, True, False]
State prediction error at timestep 1028 is tensor(2.0790e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1028 of None
Current timestep = 1029. State = [[-0.18739714  0.02043283]]. Action = [[-0.00843237  0.08701158  0.         -0.9265682 ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 1029 is [True, False, False, False, True, False]
State prediction error at timestep 1029 is tensor(1.1067e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1029 of None
Current timestep = 1030. State = [[-0.18379621  0.02006052]]. Action = [[ 0.07575256 -0.05994251  0.          0.11328161]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 1030 is [True, False, False, False, True, False]
State prediction error at timestep 1030 is tensor(2.2444e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1030 of None
Current timestep = 1031. State = [[-0.1850857   0.01710921]]. Action = [[-0.08645914 -0.02742322  0.         -0.29778838]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 1031 is [True, False, False, False, True, False]
State prediction error at timestep 1031 is tensor(4.5451e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1031 of None
Current timestep = 1032. State = [[-0.1852282   0.01800221]]. Action = [[ 0.03779645  0.03419516  0.         -0.4041527 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 1032 is [True, False, False, False, True, False]
State prediction error at timestep 1032 is tensor(1.7245e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1032 of None
Current timestep = 1033. State = [[-0.18665342  0.01554491]]. Action = [[-0.05522608 -0.07043382  0.         -0.94870263]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 1033 is [True, False, False, False, True, False]
State prediction error at timestep 1033 is tensor(6.1023e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1033 of None
Current timestep = 1034. State = [[-0.18593574  0.01611723]]. Action = [[ 0.03670163  0.05111816  0.         -0.2928797 ]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 1034 is [True, False, False, False, True, False]
State prediction error at timestep 1034 is tensor(1.7825e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1034 of None
Current timestep = 1035. State = [[-0.1807844  0.0152062]]. Action = [[ 0.08328272 -0.04463672  0.         -0.93346006]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 1035 is [True, False, False, False, True, False]
State prediction error at timestep 1035 is tensor(3.5899e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1035 of None
Current timestep = 1036. State = [[-0.18117194  0.01493574]]. Action = [[-0.0682743   0.02342193  0.         -0.884668  ]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 1036 is [True, False, False, False, True, False]
State prediction error at timestep 1036 is tensor(5.3570e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1036 of None
Current timestep = 1037. State = [[-0.1794587   0.01059111]]. Action = [[ 0.06777104 -0.09643725  0.         -0.8817609 ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 1037 is [True, False, False, False, True, False]
State prediction error at timestep 1037 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1037 of None
Current timestep = 1038. State = [[-0.17595232  0.00690168]]. Action = [[ 0.02469663 -0.00751128  0.         -0.5735419 ]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 1038 is [True, False, False, False, True, False]
State prediction error at timestep 1038 is tensor(4.4152e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1038 of None
Current timestep = 1039. State = [[-0.16974212  0.00278725]]. Action = [[ 0.09917619 -0.05870665  0.          0.6591208 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 1039 is [True, False, False, False, True, False]
State prediction error at timestep 1039 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1039 of None
Current timestep = 1040. State = [[-0.16261353 -0.0012248 ]]. Action = [[ 0.07326489 -0.02184634  0.         -0.22384173]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 1040 is [True, False, False, False, True, False]
State prediction error at timestep 1040 is tensor(1.2787e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1040 of None
Current timestep = 1041. State = [[-0.15681656 -0.00546242]]. Action = [[ 0.05259431 -0.04204687  0.         -0.48277974]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 1041 is [True, False, False, False, True, False]
State prediction error at timestep 1041 is tensor(4.5941e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1041 of None
Current timestep = 1042. State = [[-0.15628584 -0.00395307]]. Action = [[-0.04774056  0.08475084  0.         -0.29333448]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 1042 is [True, False, False, False, True, False]
State prediction error at timestep 1042 is tensor(1.7598e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1042 of None
Current timestep = 1043. State = [[-0.15234858 -0.00623995]]. Action = [[ 0.08668857 -0.07143208  0.         -0.6690387 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 1043 is [True, False, False, False, True, False]
State prediction error at timestep 1043 is tensor(3.1288e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1043 of None
Current timestep = 1044. State = [[-0.14929466 -0.01133112]]. Action = [[-0.01422024 -0.03916249  0.         -0.7138833 ]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 1044 is [True, False, False, False, True, False]
State prediction error at timestep 1044 is tensor(6.5053e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1044 of None
Current timestep = 1045. State = [[-0.14642152 -0.01290873]]. Action = [[ 0.03380486  0.01624821  0.         -0.8388336 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 1045 is [True, False, False, False, True, False]
State prediction error at timestep 1045 is tensor(4.2968e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1045 of None
Current timestep = 1046. State = [[-0.14414051 -0.00975011]]. Action = [[ 0.00309698  0.07353423  0.         -0.70234466]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 1046 is [True, False, False, False, True, False]
State prediction error at timestep 1046 is tensor(1.2980e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1046 of None
Current timestep = 1047. State = [[-0.14717436 -0.00961494]]. Action = [[-0.08915418 -0.03256403  0.         -0.8494806 ]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 1047 is [True, False, False, False, True, False]
State prediction error at timestep 1047 is tensor(3.2377e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1047 of None
Current timestep = 1048. State = [[-0.14784361 -0.00839667]]. Action = [[ 0.01436006  0.04286883  0.         -0.59109616]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 1048 is [True, False, False, False, True, False]
State prediction error at timestep 1048 is tensor(1.9120e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1048 of None
Current timestep = 1049. State = [[-0.15149277 -0.00246542]]. Action = [[-0.09388113  0.08921526  0.         -0.37391526]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 1049 is [True, False, False, False, True, False]
State prediction error at timestep 1049 is tensor(2.0664e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1049 of None
Current timestep = 1050. State = [[-0.15109172 -0.00353889]]. Action = [[ 0.06068943 -0.08990476  0.         -0.58361506]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 1050 is [True, False, False, False, True, False]
State prediction error at timestep 1050 is tensor(1.6569e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1050 of None
Current timestep = 1051. State = [[-0.14475794 -0.01044912]]. Action = [[ 0.08910201 -0.09567379  0.         -0.4222917 ]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 1051 is [True, False, False, False, True, False]
State prediction error at timestep 1051 is tensor(5.5327e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1051 of None
Current timestep = 1052. State = [[-0.13835849 -0.01485543]]. Action = [[ 0.06493055 -0.02413792  0.         -0.9089367 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 1052 is [True, False, False, False, True, False]
State prediction error at timestep 1052 is tensor(8.6305e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1052 of None
Current timestep = 1053. State = [[-0.13194714 -0.01868043]]. Action = [[ 0.07359    -0.04634055  0.         -0.95491016]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 1053 is [True, False, False, False, True, False]
State prediction error at timestep 1053 is tensor(6.9981e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1053 of None
Current timestep = 1054. State = [[-0.12638378 -0.01706013]]. Action = [[ 0.05064925  0.07913602  0.         -0.8215699 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 1054 is [True, False, False, False, True, False]
State prediction error at timestep 1054 is tensor(1.8035e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1054 of None
Current timestep = 1055. State = [[-0.12278274 -0.01412497]]. Action = [[ 0.02683427  0.02944546  0.         -0.6915134 ]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 1055 is [True, False, False, False, True, False]
State prediction error at timestep 1055 is tensor(7.2603e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1055 of None
Current timestep = 1056. State = [[-0.12513898 -0.01203753]]. Action = [[-0.08719639  0.03066943  0.         -0.7433889 ]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 1056 is [True, False, False, False, True, False]
State prediction error at timestep 1056 is tensor(1.8932e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1056 of None
Current timestep = 1057. State = [[-0.12313668 -0.01343084]]. Action = [[ 0.07572744 -0.04585081  0.         -0.3193221 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 1057 is [True, False, False, False, True, False]
State prediction error at timestep 1057 is tensor(3.4418e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1057 of None
Current timestep = 1058. State = [[-0.12116978 -0.015362  ]]. Action = [[-0.02571255 -0.00970448  0.         -0.71460664]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 1058 is [True, False, False, False, True, False]
State prediction error at timestep 1058 is tensor(2.8432e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1058 of None
Current timestep = 1059. State = [[-0.11737714 -0.01488127]]. Action = [[ 0.06532843  0.01922003  0.         -0.8044461 ]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 1059 is [True, False, False, False, True, False]
State prediction error at timestep 1059 is tensor(2.2501e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1059 of None
Current timestep = 1060. State = [[-0.11017694 -0.01436609]]. Action = [[ 0.09185899  0.0026518   0.         -0.84652334]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 1060 is [True, False, False, False, True, False]
State prediction error at timestep 1060 is tensor(3.1815e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1060 of None
Current timestep = 1061. State = [[-0.10836434 -0.01821136]]. Action = [[-0.04415966 -0.07481723  0.         -0.73658264]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 1061 is [True, False, False, False, True, False]
State prediction error at timestep 1061 is tensor(3.5825e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1061 of None
Current timestep = 1062. State = [[-0.10413145 -0.02124777]]. Action = [[ 0.08508077 -0.01023141  0.         -0.9627791 ]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 1062 is [True, False, False, False, True, False]
State prediction error at timestep 1062 is tensor(7.5088e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1062 of None
Current timestep = 1063. State = [[-0.10128863 -0.01779781]]. Action = [[-0.01265222  0.08697372  0.         -0.28762347]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 1063 is [True, False, False, False, True, False]
State prediction error at timestep 1063 is tensor(1.1454e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1063 of None
Current timestep = 1064. State = [[-0.09681691 -0.01277614]]. Action = [[ 0.0793317   0.05226529  0.         -0.5511251 ]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 1064 is [True, False, False, False, True, False]
State prediction error at timestep 1064 is tensor(6.6123e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1064 of None
Current timestep = 1065. State = [[-0.09252325 -0.00669727]]. Action = [[ 0.03041369  0.08489015  0.         -0.43285728]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 1065 is [True, False, False, False, True, False]
State prediction error at timestep 1065 is tensor(2.0177e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1065 of None
Current timestep = 1066. State = [[-8.8903181e-02  8.7919245e-05]]. Action = [[ 0.04503442  0.07270428  0.         -0.96085083]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 1066 is [True, False, False, False, True, False]
State prediction error at timestep 1066 is tensor(3.2951e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1066 of None
Current timestep = 1067. State = [[-0.08319697  0.0017944 ]]. Action = [[ 0.08090482 -0.02863909  0.          0.07295573]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 1067 is [True, False, False, False, True, False]
State prediction error at timestep 1067 is tensor(9.7280e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1067 of None
Current timestep = 1068. State = [[-0.07797104  0.00614565]]. Action = [[ 0.04675538  0.08423541  0.         -0.6460788 ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 1068 is [True, False, False, False, True, False]
State prediction error at timestep 1068 is tensor(2.9969e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1068 of None
Current timestep = 1069. State = [[-0.07306383  0.00721395]]. Action = [[ 0.05595762 -0.04747493  0.         -0.87567806]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 1069 is [True, False, False, False, True, False]
State prediction error at timestep 1069 is tensor(2.5980e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1069 of None
Current timestep = 1070. State = [[-0.06612156  0.01168243]]. Action = [[ 0.0883889   0.09687867  0.         -0.63354385]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 1070 is [True, False, False, False, True, False]
State prediction error at timestep 1070 is tensor(5.7331e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1070 of None
Current timestep = 1071. State = [[-0.05846643  0.01595405]]. Action = [[ 0.08648572  0.01224546  0.         -0.5884435 ]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 1071 is [True, False, False, False, True, False]
State prediction error at timestep 1071 is tensor(8.7994e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1071 of None
Current timestep = 1072. State = [[-0.05311907  0.02105304]]. Action = [[ 0.03405524  0.07347886  0.         -0.8620126 ]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 1072 is [True, False, False, False, True, False]
State prediction error at timestep 1072 is tensor(1.0812e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1072 of None
Current timestep = 1073. State = [[-0.05349598  0.02876377]]. Action = [[-0.06076792  0.08476839  0.          0.35193682]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 1073 is [True, False, False, False, True, False]
State prediction error at timestep 1073 is tensor(2.0891e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1073 of None
Current timestep = 1074. State = [[-0.05198682  0.03423069]]. Action = [[0.03309844 0.02054887 0.         0.76201177]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 1074 is [True, False, False, False, True, False]
State prediction error at timestep 1074 is tensor(4.8299e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1074 of None
Current timestep = 1075. State = [[-0.23833796  0.01057818]]. Action = [[0.07982243 0.00348337 0.         0.12487328]]. Reward = [100.]
Curr episode timestep = 181
Scene graph at timestep 1075 is [True, False, False, False, True, False]
State prediction error at timestep 1075 is tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1075 of None
Current timestep = 1076. State = [[-0.23837937  0.01080973]]. Action = [[ 0.09542762  0.06641064  0.         -0.28828698]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1076 is [True, False, False, False, True, False]
State prediction error at timestep 1076 is tensor(4.4069e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1076 of None
Current timestep = 1077. State = [[-0.24135834  0.01372523]]. Action = [[-0.09048256  0.0236439   0.         -0.700665  ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1077 is [True, False, False, False, True, False]
State prediction error at timestep 1077 is tensor(1.9235e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1077 of None
Current timestep = 1078. State = [[-0.24627335  0.01084745]]. Action = [[-0.01788663 -0.07495221  0.         -0.6829225 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1078 is [True, False, False, False, True, False]
State prediction error at timestep 1078 is tensor(6.2942e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1078 of None
Current timestep = 1079. State = [[-0.24836795  0.00901342]]. Action = [[ 0.00231117  0.01022609  0.         -0.8313948 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1079 is [True, False, False, False, True, False]
State prediction error at timestep 1079 is tensor(4.7132e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1079 of None
Current timestep = 1080. State = [[-0.24596035  0.00595164]]. Action = [[ 0.0826843  -0.05635042  0.         -0.6348541 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1080 is [True, False, False, False, True, False]
State prediction error at timestep 1080 is tensor(2.9605e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1080 of None
Current timestep = 1081. State = [[-0.24548574  0.00590928]]. Action = [[-0.00871012  0.04595854  0.         -0.9089596 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1081 is [True, False, False, False, True, False]
State prediction error at timestep 1081 is tensor(2.7578e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1081 of None
Current timestep = 1082. State = [[-0.2429899   0.00188596]]. Action = [[ 0.07774431 -0.0916184   0.         -0.90666115]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1082 is [True, False, False, False, True, False]
State prediction error at timestep 1082 is tensor(4.7098e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1082 of None
Current timestep = 1083. State = [[-0.24542274 -0.00622895]]. Action = [[-0.09251606 -0.09188705  0.         -0.9258901 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1083 is [True, False, False, False, True, False]
State prediction error at timestep 1083 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1083 of None
Current timestep = 1084. State = [[-0.25189516 -0.01263586]]. Action = [[-0.07336403 -0.05087075  0.         -0.8807334 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 1084 is [True, False, False, False, True, False]
State prediction error at timestep 1084 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1084 of None
Current timestep = 1085. State = [[-0.25704768 -0.01380401]]. Action = [[-0.0468809   0.03415669  0.         -0.84772813]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 1085 is [True, False, False, False, True, False]
State prediction error at timestep 1085 is tensor(3.9801e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1085 of None
Current timestep = 1086. State = [[-0.25661534 -0.01791528]]. Action = [[ 0.061023   -0.07614845  0.         -0.54151785]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1086 is [True, False, False, False, True, False]
State prediction error at timestep 1086 is tensor(2.3931e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1086 of None
Current timestep = 1087. State = [[-0.251461   -0.01963569]]. Action = [[ 0.09295089  0.03683307  0.         -0.7898166 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 1087 is [True, False, False, False, True, False]
State prediction error at timestep 1087 is tensor(2.1806e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1087 of None
Current timestep = 1088. State = [[-0.2521668  -0.01953341]]. Action = [[-0.05530572  0.00841229  0.         -0.2605151 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 1088 is [True, False, False, False, True, False]
State prediction error at timestep 1088 is tensor(1.8451e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1088 of None
Current timestep = 1089. State = [[-0.25523654 -0.0183578 ]]. Action = [[-0.01113477  0.03727894  0.         -0.6688162 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 1089 is [True, False, False, False, True, False]
State prediction error at timestep 1089 is tensor(1.0040e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1089 of None
Current timestep = 1090. State = [[-0.25244752 -0.01995586]]. Action = [[ 0.09180168 -0.04024454  0.         -0.3407874 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 1090 is [True, False, False, False, True, False]
State prediction error at timestep 1090 is tensor(2.2120e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1090 of None
Current timestep = 1091. State = [[-0.24651073 -0.02512642]]. Action = [[ 0.08655701 -0.06646693  0.         -0.92183936]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 1091 is [True, False, False, False, True, False]
State prediction error at timestep 1091 is tensor(6.3499e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1091 of None
Current timestep = 1092. State = [[-0.2396085  -0.02438988]]. Action = [[0.09734645 0.07294974 0.         0.7450328 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 1092 is [True, False, False, False, True, False]
State prediction error at timestep 1092 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1092 of None
Current timestep = 1093. State = [[-0.23257904 -0.01832554]]. Action = [[ 0.09406898  0.09521506  0.         -0.87079287]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 1093 is [True, False, False, False, True, False]
State prediction error at timestep 1093 is tensor(8.2121e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1093 of None
Current timestep = 1094. State = [[-0.22638263 -0.01721738]]. Action = [[ 0.07339238 -0.02732909  0.         -0.49001455]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 1094 is [True, False, False, False, True, False]
State prediction error at timestep 1094 is tensor(1.7399e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1094 of None
Current timestep = 1095. State = [[-0.22734152 -0.01519902]]. Action = [[-0.08182965  0.05905742  0.         -0.19311196]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 1095 is [True, False, False, False, True, False]
State prediction error at timestep 1095 is tensor(3.5644e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1095 of None
Current timestep = 1096. State = [[-0.23236687 -0.0171045 ]]. Action = [[-0.07065175 -0.07533687  0.         -0.6559297 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 1096 is [True, False, False, False, True, False]
State prediction error at timestep 1096 is tensor(4.7386e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1096 of None
Current timestep = 1097. State = [[-0.23499498 -0.01992147]]. Action = [[-0.02572186 -0.01991265  0.         -0.45158213]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 1097 is [True, False, False, False, True, False]
State prediction error at timestep 1097 is tensor(3.6895e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1097 of None
Current timestep = 1098. State = [[-0.23331001 -0.02157719]]. Action = [[ 0.03823934 -0.02373701  0.         -0.7880529 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 1098 is [True, False, False, False, True, False]
State prediction error at timestep 1098 is tensor(4.9306e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1098 of None
Current timestep = 1099. State = [[-0.22697744 -0.01959351]]. Action = [[0.09922663 0.05190153 0.         0.05255508]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 1099 is [True, False, False, False, True, False]
State prediction error at timestep 1099 is tensor(2.7492e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1099 of None
Current timestep = 1100. State = [[-0.226298   -0.01903985]]. Action = [[-0.05782288 -0.0208616   0.         -0.96691126]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 1100 is [True, False, False, False, True, False]
State prediction error at timestep 1100 is tensor(2.7300e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1100 of None
Current timestep = 1101. State = [[-0.2230195 -0.0238243]]. Action = [[ 0.08981667 -0.08607151  0.         -0.1522935 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 1101 is [True, False, False, False, True, False]
State prediction error at timestep 1101 is tensor(3.3191e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1101 of None
Current timestep = 1102. State = [[-0.21753319 -0.0282877 ]]. Action = [[ 0.04360458 -0.03042741  0.         -0.7853236 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 1102 is [True, False, False, False, True, False]
State prediction error at timestep 1102 is tensor(7.4412e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1102 of None
Current timestep = 1103. State = [[-0.2126698  -0.02623854]]. Action = [[ 0.05093459  0.0739258   0.         -0.91782165]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 1103 is [True, False, False, False, True, False]
State prediction error at timestep 1103 is tensor(2.8440e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1103 of None
Current timestep = 1104. State = [[-0.21334782 -0.02438346]]. Action = [[-0.06459288  0.00434901  0.         -0.465643  ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 1104 is [True, False, False, False, True, False]
State prediction error at timestep 1104 is tensor(1.2647e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1104 of None
Current timestep = 1105. State = [[-0.21009946 -0.02013254]]. Action = [[0.08996782 0.0840987  0.         0.12566113]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 1105 is [True, False, False, False, True, False]
State prediction error at timestep 1105 is tensor(5.4835e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1105 of None
Current timestep = 1106. State = [[-0.20270392 -0.0206025 ]]. Action = [[ 0.08790388 -0.0591803   0.         -0.6899843 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 1106 is [True, False, False, False, True, False]
State prediction error at timestep 1106 is tensor(3.4140e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1106 of None
Current timestep = 1107. State = [[-0.1943002  -0.02437609]]. Action = [[ 0.09617341 -0.04059939  0.         -0.0195263 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 1107 is [True, False, False, False, True, False]
State prediction error at timestep 1107 is tensor(7.0959e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1107 of None
Current timestep = 1108. State = [[-0.18660401 -0.02302983]]. Action = [[ 0.0714295   0.05950285  0.         -0.8447648 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 1108 is [True, False, False, False, True, False]
State prediction error at timestep 1108 is tensor(1.4179e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1108 of None
Current timestep = 1109. State = [[-0.18116981 -0.0254364 ]]. Action = [[ 0.03557768 -0.07597819  0.         -0.6575254 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 1109 is [True, False, False, False, True, False]
State prediction error at timestep 1109 is tensor(4.7050e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1109 of None
Current timestep = 1110. State = [[-0.18095225 -0.02453464]]. Action = [[-0.06147596  0.06766584  0.         -0.9664545 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 1110 is [True, False, False, False, True, False]
State prediction error at timestep 1110 is tensor(2.4639e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1110 of None
Current timestep = 1111. State = [[-0.1786243  -0.02621643]]. Action = [[ 0.04249985 -0.06920938  0.         -0.68905115]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 1111 is [True, False, False, False, True, False]
State prediction error at timestep 1111 is tensor(3.3102e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1111 of None
Current timestep = 1112. State = [[-0.17706907 -0.02698288]]. Action = [[-0.03144218  0.02616572  0.         -0.8477705 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 1112 is [True, False, False, False, True, False]
State prediction error at timestep 1112 is tensor(3.4440e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1112 of None
Current timestep = 1113. State = [[-0.17447127 -0.02567317]]. Action = [[0.032863   0.01347061 0.         0.54677415]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 1113 is [True, False, False, False, True, False]
State prediction error at timestep 1113 is tensor(7.2192e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1113 of None
Current timestep = 1114. State = [[-0.16807516 -0.02637704]]. Action = [[ 0.08200528 -0.0233736   0.         -0.84893763]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 1114 is [True, False, False, False, True, False]
State prediction error at timestep 1114 is tensor(4.0682e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1114 of None
Current timestep = 1115. State = [[-0.16026838 -0.02753536]]. Action = [[ 0.0835359  -0.00695693  0.         -0.564944  ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 1115 is [True, False, False, False, True, False]
State prediction error at timestep 1115 is tensor(1.8550e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1115 of None
Current timestep = 1116. State = [[-0.15605018 -0.02585948]]. Action = [[ 0.00648563  0.04277364  0.         -0.53451043]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 1116 is [True, False, False, False, True, False]
State prediction error at timestep 1116 is tensor(5.7762e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1116 of None
Current timestep = 1117. State = [[-0.14989984 -0.02253697]]. Action = [[ 0.09221237  0.04274077  0.         -0.28569943]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 1117 is [True, False, False, False, True, False]
State prediction error at timestep 1117 is tensor(7.3974e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1117 of None
Current timestep = 1118. State = [[-0.14796174 -0.02356848]]. Action = [[-0.04433994 -0.04861156  0.         -0.7076104 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 1118 is [True, False, False, False, True, False]
State prediction error at timestep 1118 is tensor(1.4359e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1118 of None
Current timestep = 1119. State = [[-0.14748958 -0.02093152]]. Action = [[ 0.00250874  0.07655736  0.         -0.86480045]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 1119 is [True, False, False, False, True, False]
State prediction error at timestep 1119 is tensor(2.3759e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1119 of None
Current timestep = 1120. State = [[-0.14538985 -0.01488693]]. Action = [[ 0.02254696  0.06729715  0.         -0.8377102 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 1120 is [True, False, False, False, True, False]
State prediction error at timestep 1120 is tensor(5.0814e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1120 of None
Current timestep = 1121. State = [[-0.1396954  -0.00868472]]. Action = [[ 0.09208275  0.06534625  0.         -0.93048453]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 1121 is [True, False, False, False, True, False]
State prediction error at timestep 1121 is tensor(6.0898e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1121 of None
Current timestep = 1122. State = [[-0.13450886 -0.00815364]]. Action = [[ 0.04215004 -0.04904643  0.         -0.7185923 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 1122 is [True, False, False, False, True, False]
State prediction error at timestep 1122 is tensor(2.0900e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1122 of None
Current timestep = 1123. State = [[-0.13187131 -0.00473014]]. Action = [[ 0.00901685  0.07747778  0.         -0.661047  ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 1123 is [True, False, False, False, True, False]
State prediction error at timestep 1123 is tensor(5.0004e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1123 of None
Current timestep = 1124. State = [[-0.12708338 -0.00551903]]. Action = [[ 0.07237317 -0.07922648  0.         -0.8877823 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 1124 is [True, False, False, False, True, False]
State prediction error at timestep 1124 is tensor(3.9915e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1124 of None
Current timestep = 1125. State = [[-0.12030105 -0.00838827]]. Action = [[ 0.07077808 -0.02584478  0.          0.02156186]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 1125 is [True, False, False, False, True, False]
State prediction error at timestep 1125 is tensor(2.5666e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1125 of None
Current timestep = 1126. State = [[-0.11246928 -0.00980116]]. Action = [[ 0.0875316  -0.01483992  0.         -0.13814527]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 1126 is [True, False, False, False, True, False]
State prediction error at timestep 1126 is tensor(3.9485e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1126 of None
Current timestep = 1127. State = [[-0.106905   -0.01011239]]. Action = [[ 0.02821989  0.00496827  0.         -0.48518163]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 1127 is [True, False, False, False, True, False]
State prediction error at timestep 1127 is tensor(1.4284e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1127 of None
Current timestep = 1128. State = [[-0.10029525 -0.01245876]]. Action = [[ 0.07818621 -0.04590543  0.         -0.726132  ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 1128 is [True, False, False, False, True, False]
State prediction error at timestep 1128 is tensor(4.2957e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1128 of None
Current timestep = 1129. State = [[-0.09583813 -0.01499505]]. Action = [[ 0.00241216 -0.01562427  0.         -0.59481645]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 1129 is [True, False, False, False, True, False]
State prediction error at timestep 1129 is tensor(2.8722e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1129 of None
Current timestep = 1130. State = [[-0.09420297 -0.01651428]]. Action = [[-0.01929659 -0.01104017  0.         -0.24011242]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 1130 is [True, False, False, False, True, False]
State prediction error at timestep 1130 is tensor(6.2497e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1130 of None
Current timestep = 1131. State = [[-0.09109116 -0.01682754]]. Action = [[ 0.02715167  0.00887696  0.         -0.9061391 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 1131 is [True, False, False, False, True, False]
State prediction error at timestep 1131 is tensor(1.0327e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1131 of None
Current timestep = 1132. State = [[-0.09004068 -0.01404324]]. Action = [[-0.03517582  0.05580727  0.          0.5239022 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 1132 is [True, False, False, False, True, False]
State prediction error at timestep 1132 is tensor(1.9411e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1132 of None
Current timestep = 1133. State = [[-0.09131908 -0.01103624]]. Action = [[-0.04471576  0.02311687  0.          0.3211019 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 1133 is [True, False, False, False, True, False]
State prediction error at timestep 1133 is tensor(1.1678e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1133 of None
Current timestep = 1134. State = [[-0.0914048  -0.01261489]]. Action = [[-0.00907318 -0.05606854  0.         -0.7976726 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 1134 is [True, False, False, False, True, False]
State prediction error at timestep 1134 is tensor(3.9555e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1134 of None
Current timestep = 1135. State = [[-0.09342964 -0.01246419]]. Action = [[-0.06622599  0.02734155  0.         -0.23694402]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 1135 is [True, False, False, False, True, False]
State prediction error at timestep 1135 is tensor(1.0100e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1135 of None
Current timestep = 1136. State = [[-0.09471946 -0.01173385]]. Action = [[-0.01306573 -0.01037104  0.         -0.3013966 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 1136 is [True, False, False, False, True, False]
State prediction error at timestep 1136 is tensor(4.2361e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1136 of None
Current timestep = 1137. State = [[-0.09204341 -0.01478279]]. Action = [[ 0.04831748 -0.06337655  0.         -0.85158473]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 1137 is [True, False, False, False, True, False]
State prediction error at timestep 1137 is tensor(4.2056e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1137 of None
Current timestep = 1138. State = [[-0.08768489 -0.01927736]]. Action = [[ 0.05204385 -0.04980294  0.         -0.6993604 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 1138 is [True, False, False, False, True, False]
State prediction error at timestep 1138 is tensor(4.7875e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1138 of None
Current timestep = 1139. State = [[-0.08246269 -0.02487499]]. Action = [[ 0.06653171 -0.06789327  0.         -0.12631297]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 1139 is [True, False, False, False, True, False]
State prediction error at timestep 1139 is tensor(7.2127e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1139 of None
Current timestep = 1140. State = [[-0.0833108  -0.03002947]]. Action = [[-0.0774747  -0.0411715   0.         -0.65478635]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 1140 is [True, False, False, False, True, False]
State prediction error at timestep 1140 is tensor(3.7052e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1140 of None
Current timestep = 1141. State = [[-0.08533268 -0.03014286]]. Action = [[-0.01039128  0.04470109  0.         -0.55605316]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 1141 is [True, False, False, False, True, False]
State prediction error at timestep 1141 is tensor(3.7905e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1141 of None
Current timestep = 1142. State = [[-0.08187895 -0.03242068]]. Action = [[ 0.08048119 -0.05058587  0.         -0.971646  ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 1142 is [True, False, False, False, True, False]
State prediction error at timestep 1142 is tensor(4.1601e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1142 of None
Current timestep = 1143. State = [[-0.07580434 -0.03383682]]. Action = [[ 0.08401912  0.02474759  0.         -0.6642457 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 1143 is [True, False, False, False, True, False]
State prediction error at timestep 1143 is tensor(1.5908e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1143 of None
Current timestep = 1144. State = [[-0.07052808 -0.03271017]]. Action = [[ 0.06403816  0.03394213  0.         -0.60054034]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 1144 is [True, False, False, False, True, False]
State prediction error at timestep 1144 is tensor(8.0907e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1144 of None
Current timestep = 1145. State = [[-0.06402617 -0.03411396]]. Action = [[ 0.09853614 -0.02709263  0.         -0.48787272]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 1145 is [True, False, False, False, True, False]
State prediction error at timestep 1145 is tensor(2.5876e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1145 of None
Current timestep = 1146. State = [[-0.05661578 -0.03292703]]. Action = [[ 0.09537523  0.06045202  0.         -0.61026025]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 1146 is [True, False, False, False, True, False]
State prediction error at timestep 1146 is tensor(4.7832e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1146 of None
Current timestep = 1147. State = [[-0.05025896 -0.03207769]]. Action = [[ 7.0656888e-02  4.2301416e-04  0.0000000e+00 -7.4902940e-01]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 1147 is [True, False, False, False, True, False]
State prediction error at timestep 1147 is tensor(7.0335e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1147 of None
Current timestep = 1148. State = [[-0.2874176  -0.01741149]]. Action = [[ 0.07932553  0.03231651  0.         -0.87695646]]. Reward = [100.]
Curr episode timestep = 72
Scene graph at timestep 1148 is [True, False, False, False, True, False]
State prediction error at timestep 1148 is tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1148 of None
Current timestep = 1149. State = [[-0.29314905 -0.01195912]]. Action = [[-0.06687476  0.09399433  0.         -0.83169043]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1149 is [True, False, False, False, True, False]
State prediction error at timestep 1149 is tensor(7.2389e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1149 of None
Current timestep = 1150. State = [[-0.2956296  -0.00912987]]. Action = [[ 0.02032886 -0.01260941  0.         -0.67042875]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1150 is [True, False, False, False, True, False]
State prediction error at timestep 1150 is tensor(3.4976e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1150 of None
Current timestep = 1151. State = [[-0.29618138 -0.00939155]]. Action = [[ 0.00565772 -0.01541337  0.         -0.83661395]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1151 is [True, False, False, False, True, False]
State prediction error at timestep 1151 is tensor(8.4842e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1151 of None
Current timestep = 1152. State = [[-0.29894066 -0.00698121]]. Action = [[-0.03817373  0.04541791  0.         -0.58277655]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1152 is [True, False, False, False, True, False]
State prediction error at timestep 1152 is tensor(7.4199e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1152 of None
Current timestep = 1153. State = [[-0.29667193 -0.00842579]]. Action = [[ 0.09220896 -0.06728304  0.         -0.42042243]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1153 is [True, False, False, False, True, False]
State prediction error at timestep 1153 is tensor(1.3928e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1153 of None
Current timestep = 1154. State = [[-0.29796797 -0.00894094]]. Action = [[-0.07692246  0.02253642  0.         -0.02846122]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1154 is [True, False, False, False, True, False]
State prediction error at timestep 1154 is tensor(4.7926e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1154 of None
Current timestep = 1155. State = [[-0.30419546 -0.01122753]]. Action = [[-0.07492839 -0.06118195  0.         -0.7649868 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1155 is [True, False, False, False, True, False]
State prediction error at timestep 1155 is tensor(6.0317e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1155 of None
Current timestep = 1156. State = [[-0.30772945 -0.01042072]]. Action = [[-0.01395036  0.05101571  0.         -0.552985  ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1156 is [True, False, False, False, True, False]
State prediction error at timestep 1156 is tensor(1.9922e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1156 of None
Current timestep = 1157. State = [[-0.3079051  -0.00611094]]. Action = [[ 0.02863418  0.05410144  0.         -0.40875256]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 1157 is [True, False, False, False, True, False]
State prediction error at timestep 1157 is tensor(1.4027e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1157 of None
Current timestep = 1158. State = [[-0.30477193 -0.00380692]]. Action = [[ 0.0749879   0.00469265  0.         -0.85053444]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 1158 is [True, False, False, False, True, False]
State prediction error at timestep 1158 is tensor(2.0523e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1158 of None
Current timestep = 1159. State = [[-0.3008466  -0.00474721]]. Action = [[ 0.05844139 -0.02961574  0.         -0.8045704 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1159 is [True, False, False, False, True, False]
State prediction error at timestep 1159 is tensor(9.6463e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1159 of None
Current timestep = 1160. State = [[-0.3032583  -0.00426863]]. Action = [[-0.07998289  0.02530117  0.         -0.75513506]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 1160 is [True, False, False, False, True, False]
State prediction error at timestep 1160 is tensor(2.2818e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1160 of None
Current timestep = 1161. State = [[-0.30381766 -0.0004154 ]]. Action = [[ 0.0514577   0.0596781   0.         -0.40803927]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 1161 is [True, False, False, False, True, False]
State prediction error at timestep 1161 is tensor(1.7818e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1161 of None
Current timestep = 1162. State = [[-0.30238336  0.00612527]]. Action = [[ 0.02406172  0.08638293  0.         -0.9118134 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 1162 is [True, False, False, False, True, False]
State prediction error at timestep 1162 is tensor(1.6522e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1162 of None
Current timestep = 1163. State = [[-0.30383104  0.01235544]]. Action = [[-0.02220337  0.05733029  0.         -0.01547223]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 1163 is [True, False, False, False, True, False]
State prediction error at timestep 1163 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1163 of None
Current timestep = 1164. State = [[-0.30198058  0.01182206]]. Action = [[ 0.06658352 -0.06600628  0.         -0.6243484 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 1164 is [True, False, False, False, True, False]
State prediction error at timestep 1164 is tensor(1.0770e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1164 of None
Current timestep = 1165. State = [[-0.29577973  0.00745258]]. Action = [[ 0.09269357 -0.06448255  0.         -0.09683007]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 1165 is [True, False, False, False, True, False]
State prediction error at timestep 1165 is tensor(6.1070e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1165 of None
Current timestep = 1166. State = [[-0.28866372  0.00274613]]. Action = [[ 0.07866026 -0.05944178  0.         -0.020518  ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 1166 is [True, False, False, False, True, False]
State prediction error at timestep 1166 is tensor(8.4403e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1166 of None
Current timestep = 1167. State = [[-0.2875412  -0.00055186]]. Action = [[-0.05486237 -0.02667774  0.         -0.5774536 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 1167 is [True, False, False, False, True, False]
State prediction error at timestep 1167 is tensor(4.2984e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1167 of None
Current timestep = 1168. State = [[-0.28825298  0.00063678]]. Action = [[-0.01111086  0.04750507  0.          0.10253429]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 1168 is [True, False, False, False, True, False]
State prediction error at timestep 1168 is tensor(6.4910e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1168 of None
Current timestep = 1169. State = [[-0.28632075  0.00167821]]. Action = [[ 0.03032949 -0.00065513  0.         -0.35568786]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 1169 is [True, False, False, False, True, False]
State prediction error at timestep 1169 is tensor(8.5991e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1169 of None
Current timestep = 1170. State = [[-0.28604817 -0.00070558]]. Action = [[-0.0295862  -0.0434422   0.         -0.16125941]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 1170 is [True, False, False, False, True, False]
State prediction error at timestep 1170 is tensor(9.0215e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1170 of None
Current timestep = 1171. State = [[-0.2871514  -0.00637803]]. Action = [[-0.02986719 -0.07978181  0.         -0.2550903 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 1171 is [True, False, False, False, True, False]
State prediction error at timestep 1171 is tensor(1.3838e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1171 of None
Current timestep = 1172. State = [[-0.28421798 -0.00947725]]. Action = [[ 0.05523898  0.00032209  0.         -0.2898134 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 1172 is [True, False, False, False, True, False]
State prediction error at timestep 1172 is tensor(1.4175e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1172 of None
Current timestep = 1173. State = [[-0.28265953 -0.01250122]]. Action = [[-0.01843673 -0.04142538  0.         -0.56869197]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 1173 is [True, False, False, False, True, False]
State prediction error at timestep 1173 is tensor(3.5997e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1173 of None
Current timestep = 1174. State = [[-0.279283   -0.00987241]]. Action = [[ 0.06330509  0.09449904  0.         -0.39108855]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 1174 is [True, False, False, False, True, False]
State prediction error at timestep 1174 is tensor(9.6376e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1174 of None
Current timestep = 1175. State = [[-0.27524793 -0.01042499]]. Action = [[ 0.03971233 -0.05484558  0.         -0.72803336]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 1175 is [True, False, False, False, True, False]
State prediction error at timestep 1175 is tensor(4.4067e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1175 of None
Current timestep = 1176. State = [[-0.2777071  -0.01524748]]. Action = [[-0.0941721  -0.05474265  0.         -0.842644  ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 1176 is [True, False, False, False, True, False]
State prediction error at timestep 1176 is tensor(7.8761e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1176 of None
Current timestep = 1177. State = [[-0.28060758 -0.01983482]]. Action = [[-0.02042991 -0.04358044  0.         -0.6823157 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 1177 is [True, False, False, False, True, False]
State prediction error at timestep 1177 is tensor(5.7063e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1177 of None
Current timestep = 1178. State = [[-0.28560436 -0.02132608]]. Action = [[-0.09648146  0.01330739  0.         -0.7137234 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 1178 is [True, False, False, False, True, False]
State prediction error at timestep 1178 is tensor(3.8688e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1178 of None
Current timestep = 1179. State = [[-0.2872418  -0.02125654]]. Action = [[ 0.02418773  0.00730939  0.         -0.79400545]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 1179 is [True, False, False, False, True, False]
State prediction error at timestep 1179 is tensor(1.2061e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1179 of None
Current timestep = 1180. State = [[-0.29041395 -0.02032791]]. Action = [[-0.07062211  0.02305572  0.         -0.8994261 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 1180 is [True, False, False, False, True, False]
State prediction error at timestep 1180 is tensor(4.6963e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1180 of None
Current timestep = 1181. State = [[-0.28990877 -0.02318265]]. Action = [[ 0.06380668 -0.06527803  0.         -0.9159875 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 1181 is [True, False, False, False, True, False]
State prediction error at timestep 1181 is tensor(1.1574e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1181 of None
Current timestep = 1182. State = [[-0.29268083 -0.0214852 ]]. Action = [[-0.08801716  0.08008624  0.         -0.92503893]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 1182 is [True, False, False, False, True, False]
State prediction error at timestep 1182 is tensor(2.5187e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1182 of None
Current timestep = 1183. State = [[-0.2977386  -0.02389523]]. Action = [[-0.03759512 -0.09202697  0.         -0.48122352]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 1183 is [True, False, False, False, True, False]
State prediction error at timestep 1183 is tensor(4.6981e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1183 of None
Current timestep = 1184. State = [[-0.3021573  -0.02472698]]. Action = [[-0.04697035  0.04079478  0.          0.21860802]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 1184 is [True, False, False, False, True, False]
State prediction error at timestep 1184 is tensor(1.4920e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1184 of None
Current timestep = 1185. State = [[-0.30362034 -0.01989016]]. Action = [[ 0.02650747  0.07636348  0.         -0.9568014 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 1185 is [True, False, False, False, True, False]
State prediction error at timestep 1185 is tensor(3.3707e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1185 of None
Current timestep = 1186. State = [[-0.30248573 -0.01695475]]. Action = [[ 0.04619782  0.00501913  0.         -0.8293729 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 1186 is [True, False, False, False, True, False]
State prediction error at timestep 1186 is tensor(1.3612e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1186 of None
Current timestep = 1187. State = [[-0.3050467  -0.01588929]]. Action = [[-0.0475305   0.00782277  0.         -0.22420686]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 1187 is [True, False, False, False, True, False]
State prediction error at timestep 1187 is tensor(1.5403e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1187 of None
Current timestep = 1188. State = [[-0.3039529  -0.01086956]]. Action = [[ 0.08410976  0.08579751  0.         -0.51962674]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 1188 is [True, False, False, False, True, False]
State prediction error at timestep 1188 is tensor(8.0077e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1188 of None
Current timestep = 1189. State = [[-0.30763417 -0.00588056]]. Action = [[-0.09708945  0.03545482  0.         -0.8212987 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 1189 is [True, False, False, False, True, False]
State prediction error at timestep 1189 is tensor(4.3671e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1189 of None
Current timestep = 1190. State = [[-0.31382614 -0.00394207]]. Action = [[-0.03545971 -0.00198103  0.         -0.8677247 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 1190 is [True, False, False, False, True, False]
State prediction error at timestep 1190 is tensor(1.5117e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1190 of None
Current timestep = 1191. State = [[-0.3186846   0.00034284]]. Action = [[-0.03667605  0.06666488  0.         -0.73264945]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 1191 is [True, False, False, False, True, False]
State prediction error at timestep 1191 is tensor(5.4944e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1191 of None
Current timestep = 1192. State = [[-0.32594553  0.00062127]]. Action = [[-0.089678   -0.05490538  0.         -0.66643846]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 1192 is [True, False, False, False, True, False]
State prediction error at timestep 1192 is tensor(2.8012e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1192 of None
Current timestep = 1193. State = [[-0.32860386  0.00332991]]. Action = [[0.03342699 0.06618651 0.         0.2602285 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 1193 is [True, False, False, False, True, False]
State prediction error at timestep 1193 is tensor(1.1818e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1193 of None
Current timestep = 1194. State = [[-0.3309278   0.00887764]]. Action = [[-0.02810242  0.05251054  0.          0.04309821]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 1194 is [True, False, False, False, True, False]
State prediction error at timestep 1194 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1194 of None
Current timestep = 1195. State = [[-0.32876998  0.01036196]]. Action = [[ 0.09564371 -0.02512034  0.          0.25600123]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 1195 is [True, False, False, False, True, False]
State prediction error at timestep 1195 is tensor(7.8673e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1195 of None
Current timestep = 1196. State = [[-0.32972878  0.00628426]]. Action = [[-0.06057323 -0.08503329  0.          0.61429155]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 1196 is [True, False, False, False, True, False]
State prediction error at timestep 1196 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1196 of None
Current timestep = 1197. State = [[-0.33358437  0.00315858]]. Action = [[-0.03392972 -0.02033572  0.         -0.7513432 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 1197 is [True, False, False, False, True, False]
State prediction error at timestep 1197 is tensor(3.2285e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1197 of None
Current timestep = 1198. State = [[-3.3106595e-01 -2.0873898e-05]]. Action = [[ 0.08736751 -0.04942828  0.          0.01340187]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 1198 is [True, False, False, False, True, False]
State prediction error at timestep 1198 is tensor(3.8773e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1198 of None
Current timestep = 1199. State = [[-0.32965338 -0.00558544]]. Action = [[-0.01996429 -0.07388604  0.         -0.3387431 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 1199 is [True, False, False, False, True, False]
State prediction error at timestep 1199 is tensor(8.9454e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1199 of None
Current timestep = 1200. State = [[-0.32571548 -0.00620032]]. Action = [[ 0.08762742  0.0482563   0.         -0.54483336]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 1200 is [True, False, False, False, True, False]
State prediction error at timestep 1200 is tensor(1.8816e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1200 of None
Current timestep = 1201. State = [[-0.32370374 -0.00103492]]. Action = [[-0.00707787  0.0915662   0.         -0.7204219 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 1201 is [True, False, False, False, True, False]
State prediction error at timestep 1201 is tensor(1.6787e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1201 of None
Current timestep = 1202. State = [[-0.32694027  0.00173893]]. Action = [[-0.06151119  0.00812362  0.         -0.8962168 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 1202 is [True, False, False, False, True, False]
State prediction error at timestep 1202 is tensor(2.1991e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1202 of None
Current timestep = 1203. State = [[-0.3280694  -0.00044496]]. Action = [[ 0.01237915 -0.04728406  0.         -0.48273522]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 1203 is [True, False, False, False, True, False]
State prediction error at timestep 1203 is tensor(1.1267e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1203 of None
Current timestep = 1204. State = [[-0.3311678  -0.00566106]]. Action = [[-0.07391659 -0.07099027  0.         -0.96984357]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 1204 is [True, False, False, False, True, False]
State prediction error at timestep 1204 is tensor(4.0674e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1204 of None
Current timestep = 1205. State = [[-0.3328719  -0.00377795]]. Action = [[ 0.0052585  0.0923919  0.        -0.522233 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 1205 is [True, False, False, False, True, False]
State prediction error at timestep 1205 is tensor(2.8160e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1205 of None
Current timestep = 1206. State = [[-3.3334765e-01  4.7573136e-05]]. Action = [[-0.00180671  0.02316932  0.         -0.7857254 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 1206 is [True, False, False, False, True, False]
State prediction error at timestep 1206 is tensor(1.6062e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1206 of None
Current timestep = 1207. State = [[-3.3420137e-01 -3.1902033e-05]]. Action = [[-0.00791867 -0.02339049  0.         -0.8181647 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 1207 is [True, False, False, False, True, False]
State prediction error at timestep 1207 is tensor(3.3221e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1207 of None
Current timestep = 1208. State = [[-0.33485186  0.00269729]]. Action = [[-2.4389476e-04  6.2530972e-02  0.0000000e+00 -5.5931115e-01]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 1208 is [True, False, False, False, True, False]
State prediction error at timestep 1208 is tensor(5.2083e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1208 of None
Current timestep = 1209. State = [[-0.3315937   0.00192464]]. Action = [[ 0.0796872  -0.05931188  0.         -0.912636  ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 1209 is [True, False, False, False, True, False]
State prediction error at timestep 1209 is tensor(5.4906e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1209 of None
Current timestep = 1210. State = [[-0.33339572  0.00493741]]. Action = [[-0.08047302  0.08910615  0.         -0.7933212 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 1210 is [True, False, False, False, True, False]
State prediction error at timestep 1210 is tensor(5.0549e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1210 of None
Current timestep = 1211. State = [[-0.3347704   0.00377108]]. Action = [[ 0.03113524 -0.08392534  0.         -0.62814903]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 1211 is [True, False, False, False, True, False]
State prediction error at timestep 1211 is tensor(2.1084e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1211 of None
Current timestep = 1212. State = [[-0.33137068 -0.00060302]]. Action = [[ 0.06290262 -0.0432067   0.         -0.7693386 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 1212 is [True, False, False, False, True, False]
State prediction error at timestep 1212 is tensor(3.1500e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1212 of None
Current timestep = 1213. State = [[-0.32546535 -0.00553139]]. Action = [[ 0.08533848 -0.06541479  0.         -0.78609645]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 1213 is [True, False, False, False, True, False]
State prediction error at timestep 1213 is tensor(3.3637e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1213 of None
Current timestep = 1214. State = [[-0.3219374  -0.00921294]]. Action = [[ 0.01230456 -0.02164508  0.         -0.5127184 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 1214 is [True, False, False, False, True, False]
State prediction error at timestep 1214 is tensor(1.0149e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1214 of None
Current timestep = 1215. State = [[-0.31672662 -0.00714958]]. Action = [[ 0.08595023  0.07221081  0.         -0.38125622]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 1215 is [True, False, False, False, True, False]
State prediction error at timestep 1215 is tensor(1.5559e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1215 of None
Current timestep = 1216. State = [[-0.31259948 -0.00980265]]. Action = [[ 0.02262449 -0.0822895   0.         -0.1417628 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 1216 is [True, False, False, False, True, False]
State prediction error at timestep 1216 is tensor(3.0187e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1216 of None
Current timestep = 1217. State = [[-0.31495154 -0.01524455]]. Action = [[-0.09159543 -0.0438541   0.         -0.6953696 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 1217 is [True, False, False, False, True, False]
State prediction error at timestep 1217 is tensor(8.0444e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1217 of None
Current timestep = 1218. State = [[-0.317504   -0.02035649]]. Action = [[-0.02689479 -0.05178667  0.         -0.8496402 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 1218 is [True, False, False, False, True, False]
State prediction error at timestep 1218 is tensor(5.2442e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1218 of None
Current timestep = 1219. State = [[-0.31943157 -0.01895249]]. Action = [[-0.03825697  0.0829386   0.         -0.6944043 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 1219 is [True, False, False, False, True, False]
State prediction error at timestep 1219 is tensor(1.8589e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1219 of None
Current timestep = 1220. State = [[-0.3159868 -0.0143195]]. Action = [[ 0.09669866  0.05649342  0.         -0.8520359 ]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 1220 is [True, False, False, False, True, False]
State prediction error at timestep 1220 is tensor(8.5959e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1220 of None
Current timestep = 1221. State = [[-0.3098926  -0.01499056]]. Action = [[ 0.07050217 -0.0458901   0.         -0.8418429 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 1221 is [True, False, False, False, True, False]
State prediction error at timestep 1221 is tensor(2.3112e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1221 of None
Current timestep = 1222. State = [[-0.3073506  -0.01454836]]. Action = [[ 8.8164955e-04  3.9139397e-02  0.0000000e+00 -9.6933460e-01]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 1222 is [True, False, False, False, True, False]
State prediction error at timestep 1222 is tensor(9.1077e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1222 of None
Current timestep = 1223. State = [[-0.3027007  -0.01482107]]. Action = [[ 0.08418586 -0.02458693  0.         -0.7820538 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 1223 is [True, False, False, False, True, False]
State prediction error at timestep 1223 is tensor(6.7798e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1223 of None
Current timestep = 1224. State = [[-0.2960489  -0.01745305]]. Action = [[ 0.07424559 -0.03651521  0.         -0.00763029]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 1224 is [True, False, False, False, True, False]
State prediction error at timestep 1224 is tensor(1.5125e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1224 of None
Current timestep = 1225. State = [[-0.2956823  -0.01399037]]. Action = [[-0.06037663  0.09663344  0.         -0.5800028 ]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 1225 is [True, False, False, False, True, False]
State prediction error at timestep 1225 is tensor(1.1763e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1225 of None
Current timestep = 1226. State = [[-0.29679987 -0.00824091]]. Action = [[ 0.00309287  0.05701853  0.         -0.9301086 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 1226 is [True, False, False, False, True, False]
State prediction error at timestep 1226 is tensor(1.6018e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1226 of None
Current timestep = 1227. State = [[-0.29554605 -0.00922495]]. Action = [[ 0.02189302 -0.06592964  0.         -0.47955662]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 1227 is [True, False, False, False, True, False]
State prediction error at timestep 1227 is tensor(6.5707e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1227 of None
Current timestep = 1228. State = [[-0.29194275 -0.01140718]]. Action = [[ 0.05014906 -0.01446177  0.         -0.7239839 ]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 1228 is [True, False, False, False, True, False]
State prediction error at timestep 1228 is tensor(2.1941e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1228 of None
Current timestep = 1229. State = [[-0.28763327 -0.01419287]]. Action = [[ 0.04290739 -0.04938135  0.         -0.8576058 ]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 1229 is [True, False, False, False, True, False]
State prediction error at timestep 1229 is tensor(2.2746e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1229 of None
Current timestep = 1230. State = [[-0.28161755 -0.02000226]]. Action = [[ 0.0735907  -0.08480042  0.         -0.254511  ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 1230 is [True, False, False, False, True, False]
State prediction error at timestep 1230 is tensor(1.6878e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1230 of None
Current timestep = 1231. State = [[-0.27619898 -0.02345142]]. Action = [[ 0.03695378 -0.00751086  0.         -0.22533488]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 1231 is [True, False, False, False, True, False]
State prediction error at timestep 1231 is tensor(2.7872e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1231 of None
Current timestep = 1232. State = [[-0.26950034 -0.02760702]]. Action = [[ 0.08028    -0.06010081  0.         -0.63986504]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 1232 is [True, False, False, False, True, False]
State prediction error at timestep 1232 is tensor(3.5797e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1232 of None
Current timestep = 1233. State = [[-0.269349   -0.03326804]]. Action = [[-0.09095455 -0.05512861  0.         -0.43527913]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 1233 is [True, False, False, False, True, False]
State prediction error at timestep 1233 is tensor(5.2925e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1233 of None
Current timestep = 1234. State = [[-0.27313063 -0.03464916]]. Action = [[-0.06295697  0.03165049  0.         -0.8937974 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 1234 is [True, False, False, False, True, False]
State prediction error at timestep 1234 is tensor(2.8545e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1234 of None
Current timestep = 1235. State = [[-0.27820086 -0.03898623]]. Action = [[-0.08961632 -0.07996007  0.         -0.76634556]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 1235 is [True, False, False, False, True, False]
State prediction error at timestep 1235 is tensor(6.1323e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1235 of None
Current timestep = 1236. State = [[-0.27858138 -0.03978799]]. Action = [[ 0.03166533  0.05379183  0.         -0.70985603]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 1236 is [True, False, False, False, True, False]
State prediction error at timestep 1236 is tensor(3.2564e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1236 of None
Current timestep = 1237. State = [[-0.2764598  -0.04214654]]. Action = [[ 0.02232654 -0.05902008  0.         -0.642383  ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 1237 is [True, False, False, False, True, False]
State prediction error at timestep 1237 is tensor(3.1133e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1237 of None
Current timestep = 1238. State = [[-0.27977636 -0.04896703]]. Action = [[-0.09072367 -0.08432419  0.         -0.39771175]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 1238 is [True, False, False, False, True, False]
State prediction error at timestep 1238 is tensor(5.7237e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1238 of None
Current timestep = 1239. State = [[-0.2798956  -0.04844641]]. Action = [[ 0.05054165  0.08803352  0.         -0.75299925]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 1239 is [True, False, False, False, True, False]
State prediction error at timestep 1239 is tensor(1.1886e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1239 of None
Current timestep = 1240. State = [[-0.27483338 -0.04485564]]. Action = [[ 0.08982695  0.03192507  0.         -0.8025687 ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 1240 is [True, False, False, False, True, False]
State prediction error at timestep 1240 is tensor(1.7125e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1240 of None
Current timestep = 1241. State = [[-0.2687477  -0.04294585]]. Action = [[ 0.08945037  0.01861712  0.         -0.5480112 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 1241 is [True, False, False, False, True, False]
State prediction error at timestep 1241 is tensor(1.0502e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1241 of None
Current timestep = 1242. State = [[-0.26209822 -0.04377154]]. Action = [[ 0.09546857 -0.02731214  0.         -0.9223349 ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 1242 is [True, False, False, False, True, False]
State prediction error at timestep 1242 is tensor(1.2916e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1242 of None
Current timestep = 1243. State = [[-0.25541198 -0.04578322]]. Action = [[ 0.08295474 -0.02112381  0.         -0.8649683 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 1243 is [True, False, False, False, True, False]
State prediction error at timestep 1243 is tensor(2.6623e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1243 of None
Current timestep = 1244. State = [[-0.25111562 -0.04758509]]. Action = [[ 0.03061924 -0.01570282  0.         -0.5871847 ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 1244 is [True, False, False, False, True, False]
State prediction error at timestep 1244 is tensor(1.3472e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1244 of None
Current timestep = 1245. State = [[-0.25172305 -0.04745367]]. Action = [[-0.04868797  0.02235878  0.         -0.6244701 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 1245 is [True, False, False, False, True, False]
State prediction error at timestep 1245 is tensor(5.8373e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1245 of None
Current timestep = 1246. State = [[-0.24993986 -0.04652008]]. Action = [[ 0.04625051  0.01392424  0.         -0.4996726 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 1246 is [True, False, False, False, True, False]
State prediction error at timestep 1246 is tensor(7.9101e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1246 of None
Current timestep = 1247. State = [[-0.2493396  -0.04392685]]. Action = [[-0.02862331  0.04651751  0.         -0.79734546]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 1247 is [True, False, False, False, True, False]
State prediction error at timestep 1247 is tensor(9.4795e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1247 of None
Current timestep = 1248. State = [[-0.2503447 -0.0409896]]. Action = [[-0.02047736  0.02930921  0.         -0.890248  ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 1248 is [True, False, False, False, True, False]
State prediction error at timestep 1248 is tensor(3.5296e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1248 of None
Current timestep = 1249. State = [[-0.254684   -0.04088697]]. Action = [[-0.09282885 -0.02291608  0.         -0.42190266]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 1249 is [True, False, False, False, True, False]
State prediction error at timestep 1249 is tensor(3.4880e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1249 of None
Current timestep = 1250. State = [[-0.2610498  -0.04530942]]. Action = [[-0.09752279 -0.08188772  0.          0.10948849]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 1250 is [True, False, False, False, True, False]
State prediction error at timestep 1250 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1250 of None
Current timestep = 1251. State = [[-0.2588845  -0.04617618]]. Action = [[0.09920991 0.02770097 0.         0.45262408]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 1251 is [True, False, False, False, True, False]
State prediction error at timestep 1251 is tensor(5.3691e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1251 of None
Current timestep = 1252. State = [[-0.25082812 -0.04880729]]. Action = [[ 0.09754015 -0.0705214   0.         -0.51904887]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 1252 is [True, False, False, False, True, False]
State prediction error at timestep 1252 is tensor(1.8951e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1252 of None
Current timestep = 1253. State = [[-0.24804004 -0.0504657 ]]. Action = [[-0.02578274  0.01094522  0.         -0.96148455]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 1253 is [True, False, False, False, True, False]
State prediction error at timestep 1253 is tensor(1.1290e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1253 of None
Current timestep = 1254. State = [[-0.24461298 -0.05306839]]. Action = [[ 0.06348696 -0.04996267  0.         -0.59845334]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 1254 is [True, False, False, False, True, False]
State prediction error at timestep 1254 is tensor(1.0919e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1254 of None
Current timestep = 1255. State = [[-0.24616042 -0.05789686]]. Action = [[-0.09346042 -0.05493175  0.          0.20493793]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 1255 is [True, False, False, False, True, False]
State prediction error at timestep 1255 is tensor(8.7938e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1255 of None
Current timestep = 1256. State = [[-0.24952276 -0.06470953]]. Action = [[-0.0363066  -0.08551228  0.         -0.9072236 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 1256 is [True, False, False, False, True, False]
State prediction error at timestep 1256 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1256 of None
Current timestep = 1257. State = [[-0.25343022 -0.06740689]]. Action = [[-0.07106961  0.02048792  0.         -0.8779832 ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 1257 is [True, False, False, False, True, False]
State prediction error at timestep 1257 is tensor(2.9525e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1257 of None
Current timestep = 1258. State = [[-0.2542867  -0.07058775]]. Action = [[ 0.018503   -0.05055251  0.         -0.36549443]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 1258 is [True, False, False, False, True, False]
State prediction error at timestep 1258 is tensor(2.8872e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1258 of None
Current timestep = 1259. State = [[-0.24919827 -0.07345144]]. Action = [[ 0.0963669 -0.0062115  0.        -0.9197323]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 1259 is [True, False, False, False, True, False]
State prediction error at timestep 1259 is tensor(2.5138e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1259 of None
Current timestep = 1260. State = [[-0.24212117 -0.0774245 ]]. Action = [[ 0.09477479 -0.05422661  0.         -0.88942075]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 1260 is [True, False, False, False, True, False]
State prediction error at timestep 1260 is tensor(8.4473e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1260 of None
Current timestep = 1261. State = [[-0.24223214 -0.08177704]]. Action = [[-0.06831719 -0.02827542  0.         -0.83000535]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 1261 is [True, False, False, False, True, False]
State prediction error at timestep 1261 is tensor(3.9835e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1261 of None
Current timestep = 1262. State = [[-0.24501458 -0.081136  ]]. Action = [[-0.01524089  0.05719358  0.         -0.8177215 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 1262 is [True, False, False, False, True, False]
State prediction error at timestep 1262 is tensor(7.1170e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1262 of None
Current timestep = 1263. State = [[-0.2501638  -0.08279314]]. Action = [[-0.08357455 -0.04464105  0.         -0.9128683 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 1263 is [True, False, False, False, True, False]
State prediction error at timestep 1263 is tensor(4.4854e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1263 of None
Current timestep = 1264. State = [[-0.2515481  -0.08061545]]. Action = [[ 0.03385896  0.08564825  0.         -0.6490509 ]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 1264 is [True, False, False, False, True, False]
State prediction error at timestep 1264 is tensor(1.4168e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1264 of None
Current timestep = 1265. State = [[-0.2503304  -0.07665553]]. Action = [[ 0.02903027  0.03454008  0.         -0.04620576]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 1265 is [True, False, False, False, True, False]
State prediction error at timestep 1265 is tensor(6.4931e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1265 of None
Current timestep = 1266. State = [[-0.245871   -0.07573918]]. Action = [[ 0.09744146 -0.00922173  0.         -0.8851201 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 1266 is [True, False, False, False, True, False]
State prediction error at timestep 1266 is tensor(1.1416e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1266 of None
Current timestep = 1267. State = [[-0.24767475 -0.07491649]]. Action = [[-0.08290875  0.01840086  0.         -0.9141375 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 1267 is [True, False, False, False, True, False]
State prediction error at timestep 1267 is tensor(6.5355e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1267 of None
Current timestep = 1268. State = [[-0.2481338  -0.07247391]]. Action = [[ 0.06348216  0.0301128   0.         -0.6227844 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 1268 is [True, False, False, False, True, False]
State prediction error at timestep 1268 is tensor(4.7277e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1268 of None
Current timestep = 1269. State = [[-0.2432503  -0.07578766]]. Action = [[ 0.09155277 -0.09696534  0.         -0.42209506]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 1269 is [True, False, False, False, True, False]
State prediction error at timestep 1269 is tensor(1.2902e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1269 of None
Current timestep = 1270. State = [[-0.24393356 -0.07882964]]. Action = [[-0.06491734 -0.0073768   0.         -0.18630737]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 1270 is [True, False, False, False, True, False]
State prediction error at timestep 1270 is tensor(2.5483e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1270 of None
Current timestep = 1271. State = [[-0.24330589 -0.07679288]]. Action = [[ 0.06451709  0.04594059  0.         -0.37151164]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 1271 is [True, False, False, False, True, False]
State prediction error at timestep 1271 is tensor(2.8125e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1271 of None
Current timestep = 1272. State = [[-0.2453346  -0.07280982]]. Action = [[-0.05960497  0.04972508  0.         -0.77840185]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 1272 is [True, False, False, False, True, False]
State prediction error at timestep 1272 is tensor(4.5443e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1272 of None
Current timestep = 1273. State = [[-0.249978   -0.06950529]]. Action = [[-0.046301    0.03066511  0.         -0.94244725]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 1273 is [True, False, False, False, True, False]
State prediction error at timestep 1273 is tensor(1.8148e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1273 of None
Current timestep = 1274. State = [[-0.25634992 -0.07022853]]. Action = [[-0.08878693 -0.0412101   0.         -0.6752573 ]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 1274 is [True, False, False, False, True, False]
State prediction error at timestep 1274 is tensor(4.9816e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1274 of None
Current timestep = 1275. State = [[-0.2563215  -0.07389889]]. Action = [[ 0.06688156 -0.05762966  0.          0.23650837]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 1275 is [True, False, False, False, True, False]
State prediction error at timestep 1275 is tensor(3.4230e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1275 of None
Current timestep = 1276. State = [[-0.25506008 -0.07813508]]. Action = [[-0.00892921 -0.05102292  0.         -0.86752605]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 1276 is [True, False, False, False, True, False]
State prediction error at timestep 1276 is tensor(3.0610e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1276 of None
Current timestep = 1277. State = [[-0.2534773  -0.07526742]]. Action = [[ 0.03436292  0.09300715  0.         -0.37599283]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 1277 is [True, False, False, False, True, False]
State prediction error at timestep 1277 is tensor(1.3681e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1277 of None
Current timestep = 1278. State = [[-0.25065574 -0.07564649]]. Action = [[ 0.04113127 -0.06083804  0.         -0.92054087]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 1278 is [True, False, False, False, True, False]
State prediction error at timestep 1278 is tensor(3.2029e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1278 of None
Current timestep = 1279. State = [[-0.24688984 -0.0778164 ]]. Action = [[ 0.05046303 -0.00798474  0.         -0.852661  ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 1279 is [True, False, False, False, True, False]
State prediction error at timestep 1279 is tensor(3.8954e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1279 of None
Current timestep = 1280. State = [[-0.24885577 -0.08136068]]. Action = [[-0.07928297 -0.05673019  0.         -0.8396091 ]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 1280 is [True, False, False, False, True, False]
State prediction error at timestep 1280 is tensor(3.3118e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1280 of None
Current timestep = 1281. State = [[-0.2459918  -0.08140909]]. Action = [[0.09780724 0.04283866 0.         0.38112223]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 1281 is [True, False, False, False, True, False]
State prediction error at timestep 1281 is tensor(1.4105e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1281 of None
Current timestep = 1282. State = [[-0.24242447 -0.08448839]]. Action = [[ 0.01018615 -0.07682499  0.          0.02286553]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 1282 is [True, False, False, False, True, False]
State prediction error at timestep 1282 is tensor(3.2560e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1282 of None
Current timestep = 1283. State = [[-0.23715025 -0.08661352]]. Action = [[ 0.084736    0.01391109  0.         -0.14572728]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 1283 is [True, False, False, False, True, False]
State prediction error at timestep 1283 is tensor(1.4309e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1283 of None
Current timestep = 1284. State = [[-0.23186041 -0.0846763 ]]. Action = [[ 0.04619562  0.04471987  0.         -0.6840868 ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 1284 is [True, False, False, False, True, False]
State prediction error at timestep 1284 is tensor(1.4680e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1284 of None
Current timestep = 1285. State = [[-0.23365507 -0.08502229]]. Action = [[-0.08150493 -0.02223039  0.         -0.21252322]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 1285 is [True, False, False, False, True, False]
State prediction error at timestep 1285 is tensor(2.9497e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1285 of None
Current timestep = 1286. State = [[-0.23245946 -0.08873308]]. Action = [[ 0.05389855 -0.0513053   0.         -0.44657934]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 1286 is [True, False, False, False, True, False]
State prediction error at timestep 1286 is tensor(2.7785e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1286 of None
Current timestep = 1287. State = [[-0.23298027 -0.09139479]]. Action = [[-0.06192197 -0.00883316  0.         -0.854002  ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 1287 is [True, False, False, False, True, False]
State prediction error at timestep 1287 is tensor(3.3565e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1287 of None
Current timestep = 1288. State = [[-0.23339677 -0.09147678]]. Action = [[ 0.00591502  0.01860597  0.         -0.79667187]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 1288 is [True, False, False, False, True, False]
State prediction error at timestep 1288 is tensor(1.1306e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1288 of None
Current timestep = 1289. State = [[-0.22970347 -0.09367656]]. Action = [[ 0.05956312 -0.04614739  0.         -0.44919026]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 1289 is [True, False, False, False, True, False]
State prediction error at timestep 1289 is tensor(4.6380e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1289 of None
Current timestep = 1290. State = [[-0.22549735 -0.09718679]]. Action = [[ 0.0370087  -0.0351146   0.         -0.63652855]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 1290 is [True, False, False, False, True, False]
State prediction error at timestep 1290 is tensor(1.9080e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1290 of None
Current timestep = 1291. State = [[-0.22101869 -0.09919329]]. Action = [[ 0.05242779 -0.00658507  0.         -0.6548543 ]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 1291 is [True, False, False, False, True, False]
State prediction error at timestep 1291 is tensor(2.0520e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1291 of None
Current timestep = 1292. State = [[-0.21483962 -0.09956928]]. Action = [[0.07986916 0.00897529 0.         0.5091648 ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 1292 is [True, False, False, False, True, False]
State prediction error at timestep 1292 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1292 of None
Current timestep = 1293. State = [[-0.21537249 -0.10413778]]. Action = [[-0.07868246 -0.08321235  0.         -0.8487564 ]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 1293 is [True, False, False, False, True, False]
State prediction error at timestep 1293 is tensor(4.3218e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1293 of None
Current timestep = 1294. State = [[-0.21194945 -0.10407422]]. Action = [[ 0.09641225  0.06885672  0.         -0.90069056]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 1294 is [True, False, False, False, True, False]
State prediction error at timestep 1294 is tensor(6.0823e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1294 of None
Current timestep = 1295. State = [[-0.20775609 -0.09842584]]. Action = [[ 0.02113644  0.08329625  0.         -0.89146525]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 1295 is [True, False, False, False, True, False]
State prediction error at timestep 1295 is tensor(2.9323e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1295 of None
Current timestep = 1296. State = [[-0.20685576 -0.09328888]]. Action = [[-0.00466435  0.05188165  0.         -0.5479467 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 1296 is [True, False, False, False, True, False]
State prediction error at timestep 1296 is tensor(7.6846e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1296 of None
Current timestep = 1297. State = [[-0.20342118 -0.08814212]]. Action = [[ 0.0668815   0.06109775  0.         -0.1969788 ]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 1297 is [True, False, False, False, True, False]
State prediction error at timestep 1297 is tensor(6.9553e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1297 of None
Current timestep = 1298. State = [[-0.20435688 -0.08777482]]. Action = [[-0.06333319 -0.0452758   0.         -0.73215103]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 1298 is [True, False, False, False, True, False]
State prediction error at timestep 1298 is tensor(1.9233e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1298 of None
Current timestep = 1299. State = [[-0.20895204 -0.08799766]]. Action = [[-0.07394509  0.00793642  0.          0.01398289]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 1299 is [True, False, False, False, True, False]
State prediction error at timestep 1299 is tensor(8.1351e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1299 of None
Current timestep = 1300. State = [[-0.20859301 -0.08642615]]. Action = [[ 0.04062275  0.01395403  0.         -0.61276793]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 1300 is [True, False, False, False, True, False]
State prediction error at timestep 1300 is tensor(3.5287e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1300 of None
Current timestep = 1301. State = [[-0.2089688 -0.0811716]]. Action = [[-0.03642511  0.07932911  0.         -0.14271146]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 1301 is [True, False, False, False, True, False]
State prediction error at timestep 1301 is tensor(8.2140e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1301 of None
Current timestep = 1302. State = [[-0.21234    -0.07544266]]. Action = [[-0.0527289  0.0466967  0.        -0.6348136]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 1302 is [True, False, False, False, True, False]
State prediction error at timestep 1302 is tensor(3.4536e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1302 of None
Current timestep = 1303. State = [[-0.2126359  -0.07241819]]. Action = [[ 0.02603424  0.00528411  0.         -0.90737903]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 1303 is [True, False, False, False, True, False]
State prediction error at timestep 1303 is tensor(1.4333e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1303 of None
Current timestep = 1304. State = [[-0.21209058 -0.07299736]]. Action = [[ 0.00040098 -0.04221406  0.         -0.32449937]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 1304 is [True, False, False, False, True, False]
State prediction error at timestep 1304 is tensor(3.2727e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1304 of None
Current timestep = 1305. State = [[-0.21176043 -0.07099978]]. Action = [[ 0.00635847  0.04394463  0.         -0.67465353]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 1305 is [True, False, False, False, True, False]
State prediction error at timestep 1305 is tensor(1.0715e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1305 of None
Current timestep = 1306. State = [[-0.20970266 -0.0706571 ]]. Action = [[ 0.04080559 -0.03657904  0.         -0.48958158]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 1306 is [True, False, False, False, True, False]
State prediction error at timestep 1306 is tensor(7.2377e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1306 of None
Current timestep = 1307. State = [[-0.21278322 -0.07222565]]. Action = [[-0.09182087 -0.02333318  0.         -0.9246226 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 1307 is [True, False, False, False, True, False]
State prediction error at timestep 1307 is tensor(3.3484e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1307 of None
Current timestep = 1308. State = [[-0.21213825 -0.06976131]]. Action = [[ 0.06881092  0.05472029  0.         -0.61518306]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 1308 is [True, False, False, False, True, False]
State prediction error at timestep 1308 is tensor(1.7637e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1308 of None
Current timestep = 1309. State = [[-0.20719965 -0.06635672]]. Action = [[ 0.07221899  0.02565294  0.         -0.58316624]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 1309 is [True, False, False, False, True, False]
State prediction error at timestep 1309 is tensor(1.4345e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1309 of None
Current timestep = 1310. State = [[-0.20064111 -0.06817709]]. Action = [[ 0.09692533 -0.06310791  0.          0.08976173]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 1310 is [True, False, False, False, True, False]
State prediction error at timestep 1310 is tensor(1.8787e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1310 of None
Current timestep = 1311. State = [[-0.200417   -0.07164779]]. Action = [[-0.06498069 -0.0336284   0.         -0.53771615]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 1311 is [True, False, False, False, True, False]
State prediction error at timestep 1311 is tensor(2.2973e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1311 of None
Current timestep = 1312. State = [[-0.2019666  -0.07569492]]. Action = [[-0.00250663 -0.0559013   0.         -0.8714936 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 1312 is [True, False, False, False, True, False]
State prediction error at timestep 1312 is tensor(5.8099e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1312 of None
Current timestep = 1313. State = [[-0.19916533 -0.07603344]]. Action = [[ 0.05699157  0.0353036   0.         -0.7298754 ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 1313 is [True, False, False, False, True, False]
State prediction error at timestep 1313 is tensor(9.6764e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1313 of None
Current timestep = 1314. State = [[-0.19316524 -0.07399571]]. Action = [[ 0.0901315   0.02938005  0.         -0.8525403 ]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 1314 is [True, False, False, False, True, False]
State prediction error at timestep 1314 is tensor(4.3538e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1314 of None
Current timestep = 1315. State = [[-0.18901412 -0.06977294]]. Action = [[ 0.0321872   0.07211047  0.         -0.6594551 ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 1315 is [True, False, False, False, True, False]
State prediction error at timestep 1315 is tensor(4.5834e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1315 of None
Current timestep = 1316. State = [[-0.18484195 -0.06600977]]. Action = [[ 0.06460882  0.0338285   0.         -0.6503502 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 1316 is [True, False, False, False, True, False]
State prediction error at timestep 1316 is tensor(7.2756e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1316 of None
Current timestep = 1317. State = [[-0.18532537 -0.06063903]]. Action = [[-0.05147919  0.08298331  0.         -0.87063974]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 1317 is [True, False, False, False, True, False]
State prediction error at timestep 1317 is tensor(1.4568e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1317 of None
Current timestep = 1318. State = [[-0.1847962  -0.05687119]]. Action = [[ 0.03848187  0.01465325  0.         -0.65657234]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 1318 is [True, False, False, False, True, False]
State prediction error at timestep 1318 is tensor(2.5347e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1318 of None
Current timestep = 1319. State = [[-0.18411432 -0.05183614]]. Action = [[-0.00682615  0.07192609  0.         -0.21551633]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 1319 is [True, False, False, False, True, False]
State prediction error at timestep 1319 is tensor(4.2566e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1319 of None
Current timestep = 1320. State = [[-0.18240862 -0.04417273]]. Action = [[ 0.04019871  0.08616783  0.         -0.48289388]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 1320 is [True, False, False, False, True, False]
State prediction error at timestep 1320 is tensor(2.0119e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1320 of None
Current timestep = 1321. State = [[-0.17800607 -0.04030435]]. Action = [[ 0.07172098 -0.0064319   0.         -0.82458425]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 1321 is [True, False, False, False, True, False]
State prediction error at timestep 1321 is tensor(9.5050e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1321 of None
Current timestep = 1322. State = [[-0.17770329 -0.04020928]]. Action = [[-0.04159685 -0.02828344  0.         -0.4948498 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 1322 is [True, False, False, False, True, False]
State prediction error at timestep 1322 is tensor(1.4810e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1322 of None
Current timestep = 1323. State = [[-0.17785546 -0.04284726]]. Action = [[ 0.00466748 -0.06435225  0.         -0.77433926]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 1323 is [True, False, False, False, True, False]
State prediction error at timestep 1323 is tensor(1.5246e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1323 of None
Current timestep = 1324. State = [[-0.18012217 -0.0412183 ]]. Action = [[-0.06771756  0.04932771  0.         -0.9034629 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 1324 is [True, False, False, False, True, False]
State prediction error at timestep 1324 is tensor(2.3752e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1324 of None
Current timestep = 1325. State = [[-0.18040788 -0.03574982]]. Action = [[ 0.0175459   0.06135315  0.         -0.4332533 ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 1325 is [True, False, False, False, True, False]
State prediction error at timestep 1325 is tensor(2.0389e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1325 of None
Current timestep = 1326. State = [[-0.18037693 -0.0304878 ]]. Action = [[-0.01456378  0.04426081  0.         -0.52210903]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 1326 is [True, False, False, False, True, False]
State prediction error at timestep 1326 is tensor(6.0305e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1326 of None
Current timestep = 1327. State = [[-0.1768805  -0.02879704]]. Action = [[ 0.07611766 -0.01797123  0.         -0.29532468]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 1327 is [True, False, False, False, True, False]
State prediction error at timestep 1327 is tensor(1.1828e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1327 of None
Current timestep = 1328. State = [[-0.17007546 -0.03237385]]. Action = [[ 0.09089721 -0.08017521  0.         -0.91102135]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 1328 is [True, False, False, False, True, False]
State prediction error at timestep 1328 is tensor(2.9845e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1328 of None
Current timestep = 1329. State = [[-0.16891941 -0.03053783]]. Action = [[-0.04888198  0.07639188  0.         -0.66416514]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 1329 is [True, False, False, False, True, False]
State prediction error at timestep 1329 is tensor(3.2794e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1329 of None
Current timestep = 1330. State = [[-0.16755858 -0.02449298]]. Action = [[ 0.04893569  0.06907565  0.         -0.89399624]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 1330 is [True, False, False, False, True, False]
State prediction error at timestep 1330 is tensor(2.2438e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1330 of None
Current timestep = 1331. State = [[-0.16361463 -0.02470328]]. Action = [[ 0.05285705 -0.05870971  0.         -0.9169355 ]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 1331 is [True, False, False, False, True, False]
State prediction error at timestep 1331 is tensor(9.7814e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1331 of None
Current timestep = 1332. State = [[-0.1600042  -0.02160079]]. Action = [[ 0.0356329   0.08668809  0.         -0.50782627]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 1332 is [True, False, False, False, True, False]
State prediction error at timestep 1332 is tensor(6.1868e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1332 of None
Current timestep = 1333. State = [[-0.15896608 -0.01465165]]. Action = [[-0.00374769  0.07988537  0.         -0.6660867 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 1333 is [True, False, False, False, True, False]
State prediction error at timestep 1333 is tensor(5.0503e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1333 of None
Current timestep = 1334. State = [[-0.15791458 -0.01095448]]. Action = [[ 0.01920295  0.00812807  0.         -0.45966804]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 1334 is [True, False, False, False, True, False]
State prediction error at timestep 1334 is tensor(1.4898e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1334 of None
Current timestep = 1335. State = [[-0.15464158 -0.00603514]]. Action = [[ 0.05133567  0.07188644  0.         -0.23261756]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 1335 is [True, False, False, False, True, False]
State prediction error at timestep 1335 is tensor(2.1688e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1335 of None
Current timestep = 1336. State = [[-0.15126647  0.00102793]]. Action = [[0.03820821 0.07645794 0.         0.2173388 ]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 1336 is [True, False, False, False, True, False]
State prediction error at timestep 1336 is tensor(4.2006e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1336 of None
Current timestep = 1337. State = [[-0.14645913  0.00470853]]. Action = [[ 0.07345939  0.00087347  0.         -0.65589494]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 1337 is [True, False, False, False, True, False]
State prediction error at timestep 1337 is tensor(4.2149e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1337 of None
Current timestep = 1338. State = [[-0.14304277  0.00936115]]. Action = [[ 0.02045023  0.06423808  0.         -0.81356174]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 1338 is [True, False, False, False, True, False]
State prediction error at timestep 1338 is tensor(4.9205e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1338 of None
Current timestep = 1339. State = [[-0.13721225  0.01237983]]. Action = [[ 0.09602732 -0.00445436  0.         -0.90379155]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 1339 is [True, False, False, False, True, False]
State prediction error at timestep 1339 is tensor(1.3726e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1339 of None
Current timestep = 1340. State = [[-0.12900674  0.01485986]]. Action = [[0.09784704 0.02695373 0.         0.04975319]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 1340 is [True, False, False, False, True, False]
State prediction error at timestep 1340 is tensor(1.4815e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1340 of None
Current timestep = 1341. State = [[-0.12217642  0.01711166]]. Action = [[ 0.05973621  0.00955317  0.         -0.94873524]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 1341 is [True, False, False, False, True, False]
State prediction error at timestep 1341 is tensor(6.0061e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1341 of None
Current timestep = 1342. State = [[-0.11644475  0.01682243]]. Action = [[ 0.04868492 -0.03057165  0.         -0.9278042 ]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 1342 is [True, False, False, False, True, False]
State prediction error at timestep 1342 is tensor(3.0465e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1342 of None
Current timestep = 1343. State = [[-0.10905746  0.01479795]]. Action = [[ 0.0799059  -0.03689297  0.         -0.62325966]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 1343 is [True, False, False, False, True, False]
State prediction error at timestep 1343 is tensor(3.2657e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1343 of None
Current timestep = 1344. State = [[-0.10716777  0.01234988]]. Action = [[-0.06563288 -0.03617477  0.         -0.58254516]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 1344 is [True, False, False, False, True, False]
State prediction error at timestep 1344 is tensor(7.1243e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1344 of None
Current timestep = 1345. State = [[-0.10290746  0.00956991]]. Action = [[ 0.06915475 -0.04028763  0.         -0.8901026 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 1345 is [True, False, False, False, True, False]
State prediction error at timestep 1345 is tensor(2.2462e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1345 of None
Current timestep = 1346. State = [[-0.09856222  0.0085466 ]]. Action = [[-0.00245441  0.00519381  0.         -0.89192194]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 1346 is [True, False, False, False, True, False]
State prediction error at timestep 1346 is tensor(2.0725e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1346 of None
Current timestep = 1347. State = [[-0.0977763   0.00540194]]. Action = [[-0.04149488 -0.06355502  0.         -0.30584812]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 1347 is [True, False, False, False, True, False]
State prediction error at timestep 1347 is tensor(2.9115e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1347 of None
Current timestep = 1348. State = [[-0.09292604  0.00297038]]. Action = [[ 0.07032435 -0.00592761  0.         -0.47887707]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 1348 is [True, False, False, False, True, False]
State prediction error at timestep 1348 is tensor(1.0516e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1348 of None
Current timestep = 1349. State = [[-0.09027998 -0.00163936]]. Action = [[-0.03640841 -0.0759622   0.         -0.1029942 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 1349 is [True, False, False, False, True, False]
State prediction error at timestep 1349 is tensor(1.4846e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1349 of None
Current timestep = 1350. State = [[-0.0923959 -0.0092336]]. Action = [[-0.08116663 -0.09443805  0.         -0.88476783]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 1350 is [True, False, False, False, True, False]
State prediction error at timestep 1350 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1350 of None
Current timestep = 1351. State = [[-0.095063   -0.01175963]]. Action = [[-0.06097345  0.02308576  0.         -0.9186106 ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 1351 is [True, False, False, False, True, False]
State prediction error at timestep 1351 is tensor(7.8473e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1351 of None
Current timestep = 1352. State = [[-0.09360947 -0.01303422]]. Action = [[ 0.03163893 -0.02053597  0.         -0.89791334]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 1352 is [True, False, False, False, True, False]
State prediction error at timestep 1352 is tensor(3.3071e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1352 of None
Current timestep = 1353. State = [[-0.09485719 -0.01170761]]. Action = [[-0.06675991  0.05290494  0.         -0.9094753 ]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 1353 is [True, False, False, False, True, False]
State prediction error at timestep 1353 is tensor(3.2403e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1353 of None
Current timestep = 1354. State = [[-0.09238556 -0.00730526]]. Action = [[ 0.08446146  0.06510977  0.         -0.8928423 ]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 1354 is [True, False, False, False, True, False]
State prediction error at timestep 1354 is tensor(1.0060e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1354 of None
Current timestep = 1355. State = [[-0.08643409 -0.00502977]]. Action = [[ 0.07981718  0.00989018  0.         -0.85673857]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 1355 is [True, False, False, False, True, False]
State prediction error at timestep 1355 is tensor(6.4983e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1355 of None
Current timestep = 1356. State = [[-0.08015358 -0.00679215]]. Action = [[ 0.08519452 -0.03756971  0.         -0.7425443 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 1356 is [True, False, False, False, True, False]
State prediction error at timestep 1356 is tensor(2.1851e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1356 of None
Current timestep = 1357. State = [[-0.07546413 -0.00391483]]. Action = [[ 0.04627935  0.08808339  0.         -0.6347327 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 1357 is [True, False, False, False, True, False]
State prediction error at timestep 1357 is tensor(1.7137e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1357 of None
Current timestep = 1358. State = [[-0.0711886  -0.00225849]]. Action = [[ 0.05925585 -0.01301311  0.         -0.9509414 ]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 1358 is [True, False, False, False, True, False]
State prediction error at timestep 1358 is tensor(6.5602e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1358 of None
Current timestep = 1359. State = [[-0.07022464  0.00046466]]. Action = [[-0.0203277   0.06042445  0.         -0.9670225 ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 1359 is [True, False, False, False, True, False]
State prediction error at timestep 1359 is tensor(1.3719e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1359 of None
Current timestep = 1360. State = [[-0.06999     0.00420214]]. Action = [[ 0.00825008  0.0327963   0.         -0.7685144 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 1360 is [True, False, False, False, True, False]
State prediction error at timestep 1360 is tensor(1.4636e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1360 of None
Current timestep = 1361. State = [[-0.06846271  0.00867528]]. Action = [[ 0.02172613  0.05554182  0.         -0.7116014 ]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 1361 is [True, False, False, False, True, False]
State prediction error at timestep 1361 is tensor(5.6163e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1361 of None
Current timestep = 1362. State = [[-0.06293904  0.00721728]]. Action = [[ 0.09562484 -0.07813261  0.         -0.8844914 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 1362 is [True, False, False, False, True, False]
State prediction error at timestep 1362 is tensor(2.0067e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1362 of None
Current timestep = 1363. State = [[-0.05610567  0.0094389 ]]. Action = [[ 0.07703537  0.0809853   0.         -0.7705523 ]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 1363 is [True, False, False, False, True, False]
State prediction error at timestep 1363 is tensor(8.0183e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1363 of None
Current timestep = 1364. State = [[-0.1580992   0.09573231]]. Action = [[ 0.09575503 -0.05038714  0.         -0.00431257]]. Reward = [100.]
Curr episode timestep = 215
Scene graph at timestep 1364 is [True, False, False, False, True, False]
State prediction error at timestep 1364 is tensor(0.0094, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1364 of None
Current timestep = 1365. State = [[-0.16047186  0.08914255]]. Action = [[-0.08648663 -0.05312015  0.          0.4388516 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1365 is [True, False, False, False, True, False]
State prediction error at timestep 1365 is tensor(8.5444e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1365 of None
Current timestep = 1366. State = [[-0.16072108  0.08734025]]. Action = [[ 0.07733013  0.02661026  0.         -0.68681467]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1366 is [True, False, False, False, True, False]
State prediction error at timestep 1366 is tensor(4.2491e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1366 of None
Current timestep = 1367. State = [[-0.15680662  0.08712283]]. Action = [[ 0.06456155  0.01573348  0.         -0.83633304]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1367 is [True, False, False, False, True, False]
State prediction error at timestep 1367 is tensor(2.8253e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1367 of None
Current timestep = 1368. State = [[-0.1591412  0.082559 ]]. Action = [[-0.08043883 -0.07489727  0.         -0.8558853 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1368 is [True, False, False, False, True, False]
State prediction error at timestep 1368 is tensor(8.0101e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1368 of None
Current timestep = 1369. State = [[-0.15816505  0.08096068]]. Action = [[ 0.08872474  0.03912292  0.         -0.9063653 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1369 is [True, False, False, False, True, False]
State prediction error at timestep 1369 is tensor(2.3374e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1369 of None
Current timestep = 1370. State = [[-0.15310712  0.07694115]]. Action = [[ 0.06432968 -0.07105578  0.         -0.06813002]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1370 is [True, False, False, False, True, False]
State prediction error at timestep 1370 is tensor(6.3061e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1370 of None
Current timestep = 1371. State = [[-0.14768936  0.07301001]]. Action = [[ 0.06836603 -0.00625016  0.         -0.27139163]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1371 is [True, False, False, False, True, False]
State prediction error at timestep 1371 is tensor(1.4378e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1371 of None
Current timestep = 1372. State = [[-0.14106831  0.07170886]]. Action = [[ 0.08653242  0.01385717  0.         -0.04523414]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1372 is [True, False, False, False, True, False]
State prediction error at timestep 1372 is tensor(3.3186e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1372 of None
Current timestep = 1373. State = [[-0.13778163  0.07230903]]. Action = [[ 0.00334714  0.03565898  0.         -0.8583184 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 1373 is [True, False, False, False, True, False]
State prediction error at timestep 1373 is tensor(2.1450e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1373 of None
Current timestep = 1374. State = [[-0.13480198  0.07037131]]. Action = [[ 0.03854329 -0.03773654  0.         -0.7223384 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 1374 is [True, False, False, False, True, False]
State prediction error at timestep 1374 is tensor(5.1351e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1374 of None
Current timestep = 1375. State = [[-0.13664308  0.06739712]]. Action = [[-0.09015707 -0.02369262  0.         -0.003245  ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1375 is [True, False, False, False, True, False]
State prediction error at timestep 1375 is tensor(5.2290e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1375 of None
Current timestep = 1376. State = [[-0.13904002  0.06592149]]. Action = [[-0.02733859 -0.00866829  0.          0.2000829 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 1376 is [True, False, False, False, True, False]
State prediction error at timestep 1376 is tensor(4.9303e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1376 of None
Current timestep = 1377. State = [[-0.13559672  0.06469772]]. Action = [[ 0.07098544 -0.01316251  0.         -0.670155  ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 1377 is [True, False, False, False, True, False]
State prediction error at timestep 1377 is tensor(2.8402e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1377 of None
Current timestep = 1378. State = [[-0.13303082  0.06175729]]. Action = [[-0.00613928 -0.04288484  0.         -0.8748666 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 1378 is [True, False, False, False, True, False]
State prediction error at timestep 1378 is tensor(6.2367e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1378 of None
Current timestep = 1379. State = [[-0.1333708   0.05881127]]. Action = [[-0.0282314  -0.0265649   0.         -0.29396725]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 1379 is [True, False, False, False, True, False]
State prediction error at timestep 1379 is tensor(1.8010e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1379 of None
Current timestep = 1380. State = [[-0.12888725  0.05686707]]. Action = [[ 0.09062006 -0.0124773   0.         -0.48393583]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 1380 is [True, False, False, False, True, False]
State prediction error at timestep 1380 is tensor(3.2205e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1380 of None
Current timestep = 1381. State = [[-0.12282324  0.05492711]]. Action = [[ 0.05449791 -0.01520333  0.         -0.53455216]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 1381 is [True, False, False, False, True, False]
State prediction error at timestep 1381 is tensor(1.2394e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1381 of None
Current timestep = 1382. State = [[-0.12041146  0.0546153 ]]. Action = [[-0.00571083  0.018714    0.         -0.82059616]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 1382 is [True, False, False, False, True, False]
State prediction error at timestep 1382 is tensor(3.8507e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1382 of None
Current timestep = 1383. State = [[-0.11545242  0.05221642]]. Action = [[ 0.08215106 -0.04497085  0.         -0.6767431 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 1383 is [True, False, False, False, True, False]
State prediction error at timestep 1383 is tensor(3.4675e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1383 of None
Current timestep = 1384. State = [[-0.11439034  0.04719722]]. Action = [[-0.05447397 -0.05934117  0.         -0.9690784 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 1384 is [True, False, False, False, True, False]
State prediction error at timestep 1384 is tensor(6.2513e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1384 of None
Current timestep = 1385. State = [[-0.11032702  0.04816687]]. Action = [[ 0.09756956  0.07298518  0.         -0.11024904]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 1385 is [True, False, False, False, True, False]
State prediction error at timestep 1385 is tensor(1.2471e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1385 of None
Current timestep = 1386. State = [[-0.10357942  0.0501707 ]]. Action = [[ 0.06583876  0.0157909   0.         -0.8178938 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 1386 is [True, False, False, False, True, False]
State prediction error at timestep 1386 is tensor(3.3746e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1386 of None
Current timestep = 1387. State = [[-0.09998354  0.04878381]]. Action = [[ 0.00981351 -0.02739883  0.         -0.65662575]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 1387 is [True, False, False, False, True, False]
State prediction error at timestep 1387 is tensor(3.1924e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1387 of None
Current timestep = 1388. State = [[-0.09632382  0.04438341]]. Action = [[ 0.03757314 -0.0630127   0.         -0.5121678 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 1388 is [True, False, False, False, True, False]
State prediction error at timestep 1388 is tensor(2.8893e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1388 of None
Current timestep = 1389. State = [[-0.09307694  0.03941982]]. Action = [[ 0.01046781 -0.04871313  0.         -0.7317841 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 1389 is [True, False, False, False, True, False]
State prediction error at timestep 1389 is tensor(5.1605e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1389 of None
Current timestep = 1390. State = [[-0.09009548  0.04138668]]. Action = [[ 0.02151354  0.08442011  0.         -0.8893905 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 1390 is [True, False, False, False, True, False]
State prediction error at timestep 1390 is tensor(1.2216e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1390 of None
Current timestep = 1391. State = [[-0.08732566  0.04134791]]. Action = [[ 0.01795541 -0.04028783  0.         -0.76065964]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 1391 is [True, False, False, False, True, False]
State prediction error at timestep 1391 is tensor(2.3746e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1391 of None
Current timestep = 1392. State = [[-0.08085769  0.0422167 ]]. Action = [[ 0.09811992  0.0472291   0.         -0.4004804 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 1392 is [True, False, False, False, True, False]
State prediction error at timestep 1392 is tensor(1.4702e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1392 of None
Current timestep = 1393. State = [[-0.07601274  0.04451598]]. Action = [[ 0.02292335  0.02750523  0.         -0.31871748]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 1393 is [True, False, False, False, True, False]
State prediction error at timestep 1393 is tensor(1.9109e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1393 of None
Current timestep = 1394. State = [[-0.07181298  0.04680342]]. Action = [[ 0.04854173  0.03102101  0.         -0.927398  ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 1394 is [True, False, False, False, True, False]
State prediction error at timestep 1394 is tensor(8.4595e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1394 of None
Current timestep = 1395. State = [[-0.06825045  0.04887036]]. Action = [[ 0.02347004  0.02159784  0.         -0.51548743]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 1395 is [True, False, False, False, True, False]
State prediction error at timestep 1395 is tensor(2.0387e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1395 of None
Current timestep = 1396. State = [[-0.0640754   0.04654071]]. Action = [[ 0.04608255 -0.06393079  0.         -0.72726023]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 1396 is [True, False, False, False, True, False]
State prediction error at timestep 1396 is tensor(3.0177e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1396 of None
Current timestep = 1397. State = [[-0.05692817  0.04334869]]. Action = [[ 0.08991951 -0.0256952   0.         -0.94636333]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 1397 is [True, False, False, False, True, False]
State prediction error at timestep 1397 is tensor(5.2009e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1397 of None
Current timestep = 1398. State = [[-0.0834576   0.16116378]]. Action = [[ 0.08661037 -0.00949944  0.         -0.24454987]]. Reward = [100.]
Curr episode timestep = 33
Scene graph at timestep 1398 is [True, False, False, False, False, True]
State prediction error at timestep 1398 is tensor(0.0077, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1398 of None
Current timestep = 1399. State = [[-0.08151449  0.16211493]]. Action = [[ 0.09705085  0.05166797  0.         -0.8821281 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1399 is [True, False, False, False, False, True]
State prediction error at timestep 1399 is tensor(4.1760e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1399 of None
Current timestep = 1400. State = [[-0.07290704  0.15917301]]. Action = [[ 0.09272402 -0.0970652   0.         -0.76366746]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1400 is [True, False, False, False, False, True]
State prediction error at timestep 1400 is tensor(3.3847e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1400 of None
Current timestep = 1401. State = [[-0.06630456  0.15248635]]. Action = [[ 0.03126187 -0.08077791  0.         -0.76760936]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1401 is [True, False, False, False, False, True]
State prediction error at timestep 1401 is tensor(5.8806e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1401 of None
Current timestep = 1402. State = [[-0.05799278  0.14789349]]. Action = [[ 0.09812183 -0.03169487  0.         -0.98321664]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1402 is [True, False, False, False, False, True]
State prediction error at timestep 1402 is tensor(3.1282e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1402 of None
Current timestep = 1403. State = [[-0.04800857  0.14159721]]. Action = [[ 0.09748056 -0.08014177  0.         -0.596073  ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1403 is [False, True, False, False, False, True]
State prediction error at timestep 1403 is tensor(7.0132e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1403 of None
Current timestep = 1404. State = [[-0.03854549  0.13469319]]. Action = [[ 0.08120745 -0.05416339  0.         -0.93022794]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1404 is [False, True, False, False, False, True]
State prediction error at timestep 1404 is tensor(8.9371e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1404 of None
Current timestep = 1405. State = [[-0.03127143  0.13144162]]. Action = [[ 0.04641805  0.01285069  0.         -0.5972085 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1405 is [False, True, False, False, False, True]
State prediction error at timestep 1405 is tensor(5.0282e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1405 of None
Current timestep = 1406. State = [[-0.02855961  0.12643377]]. Action = [[-0.02824113 -0.06656893  0.         -0.70942897]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1406 is [False, True, False, False, False, True]
State prediction error at timestep 1406 is tensor(4.3796e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1406 of None
Current timestep = 1407. State = [[-0.32442164 -0.02130655]]. Action = [[ 0.09435541  0.00710772  0.         -0.9833321 ]]. Reward = [100.]
Curr episode timestep = 8
Scene graph at timestep 1407 is [True, False, False, False, True, False]
State prediction error at timestep 1407 is tensor(0.0564, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1407 of None
Current timestep = 1408. State = [[-0.3226514  -0.02837231]]. Action = [[ 0.09141212 -0.08156909  0.         -0.08089077]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1408 is [True, False, False, False, True, False]
State prediction error at timestep 1408 is tensor(1.6778e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1408 of None
Current timestep = 1409. State = [[-0.32035035 -0.03612699]]. Action = [[ 0.0132096  -0.07309064  0.         -0.52677315]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1409 is [True, False, False, False, True, False]
State prediction error at timestep 1409 is tensor(3.6968e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1409 of None
Current timestep = 1410. State = [[-0.3170987  -0.04417762]]. Action = [[ 0.06501979 -0.07862104  0.         -0.5335116 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1410 is [True, False, False, False, True, False]
State prediction error at timestep 1410 is tensor(2.3602e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1410 of None
Current timestep = 1411. State = [[-0.31166482 -0.05286158]]. Action = [[ 0.07892063 -0.08511765  0.         -0.79461324]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1411 is [True, False, False, False, True, False]
State prediction error at timestep 1411 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1411 of None
Current timestep = 1412. State = [[-0.31072876 -0.05674356]]. Action = [[-0.03386497  0.01962028  0.          0.12000525]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1412 is [True, False, False, False, True, False]
State prediction error at timestep 1412 is tensor(7.9852e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1412 of None
Current timestep = 1413. State = [[-0.3104788  -0.05861307]]. Action = [[ 0.0267018  -0.00435033  0.         -0.07464898]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1413 is [True, False, False, False, True, False]
State prediction error at timestep 1413 is tensor(3.5558e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1413 of None
Current timestep = 1414. State = [[-0.30577725 -0.05622313]]. Action = [[ 0.0910065   0.08141749  0.         -0.8922503 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1414 is [True, False, False, False, True, False]
State prediction error at timestep 1414 is tensor(5.9532e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1414 of None
Current timestep = 1415. State = [[-0.30661514 -0.05279822]]. Action = [[-0.06501015  0.04100538  0.         -0.966342  ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1415 is [True, False, False, False, True, False]
State prediction error at timestep 1415 is tensor(3.3096e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1415 of None
Current timestep = 1416. State = [[-0.3115691  -0.05650124]]. Action = [[-0.05306697 -0.08436137  0.         -0.7887348 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 1416 is [True, False, False, False, True, False]
State prediction error at timestep 1416 is tensor(5.0388e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1416 of None
Current timestep = 1417. State = [[-0.31735334 -0.05781071]]. Action = [[-0.07400557  0.04080658  0.         -0.5449094 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 1417 is [True, False, False, False, True, False]
State prediction error at timestep 1417 is tensor(8.3058e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1417 of None
Current timestep = 1418. State = [[-0.32158074 -0.05737076]]. Action = [[-0.02845391 -0.00110196  0.          0.2603743 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1418 is [True, False, False, False, True, False]
State prediction error at timestep 1418 is tensor(1.7336e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1418 of None
Current timestep = 1419. State = [[-0.31999215 -0.0605278 ]]. Action = [[ 0.0711289  -0.06037474  0.         -0.85977256]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 1419 is [True, False, False, False, True, False]
State prediction error at timestep 1419 is tensor(2.4562e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1419 of None
Current timestep = 1420. State = [[-0.31702465 -0.06072453]]. Action = [[ 0.03417291  0.03290797  0.         -0.11194384]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 1420 is [True, False, False, False, True, False]
State prediction error at timestep 1420 is tensor(1.9175e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1420 of None
Current timestep = 1421. State = [[-0.31981367 -0.06387063]]. Action = [[-0.07287131 -0.0783613   0.         -0.25946528]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 1421 is [True, False, False, False, True, False]
State prediction error at timestep 1421 is tensor(6.3977e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1421 of None
Current timestep = 1422. State = [[-0.32248017 -0.06555197]]. Action = [[-0.00922798  0.02382763  0.         -0.48685837]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 1422 is [True, False, False, False, True, False]
State prediction error at timestep 1422 is tensor(1.1916e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1422 of None
Current timestep = 1423. State = [[-0.31878686 -0.06339079]]. Action = [[ 0.093202    0.03426743  0.         -0.34102488]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 1423 is [True, False, False, False, True, False]
State prediction error at timestep 1423 is tensor(2.2346e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1423 of None
Current timestep = 1424. State = [[-0.32037702 -0.06036802]]. Action = [[-0.09028151  0.03961969  0.         -0.6499387 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 1424 is [True, False, False, False, True, False]
State prediction error at timestep 1424 is tensor(4.7769e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1424 of None
Current timestep = 1425. State = [[-0.3239087  -0.06345217]]. Action = [[-0.00524896 -0.08709284  0.          0.06635392]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 1425 is [True, False, False, False, True, False]
State prediction error at timestep 1425 is tensor(6.7865e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1425 of None
Current timestep = 1426. State = [[-0.32969534 -0.06261056]]. Action = [[-0.09811535  0.07274549  0.         -0.6838397 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 1426 is [True, False, False, False, True, False]
State prediction error at timestep 1426 is tensor(4.7857e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1426 of None
Current timestep = 1427. State = [[-0.3331905  -0.05829797]]. Action = [[0.01409409 0.04294898 0.         0.07176292]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 1427 is [True, False, False, False, True, False]
State prediction error at timestep 1427 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1427 of None
Current timestep = 1428. State = [[-0.33829537 -0.0601324 ]]. Action = [[-0.08384614 -0.07377994  0.         -0.6325352 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 1428 is [True, False, False, False, True, False]
State prediction error at timestep 1428 is tensor(2.4059e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1428 of None
Current timestep = 1429. State = [[-0.34281448 -0.06606553]]. Action = [[-0.02029712 -0.07296131  0.         -0.3427359 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 1429 is [True, False, False, False, True, False]
State prediction error at timestep 1429 is tensor(2.1658e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1429 of None
Current timestep = 1430. State = [[-0.34118375 -0.06451847]]. Action = [[ 0.08420087  0.09263999  0.         -0.9216522 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 1430 is [True, False, False, False, True, False]
State prediction error at timestep 1430 is tensor(1.2489e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1430 of None
Current timestep = 1431. State = [[-0.34367836 -0.06400517]]. Action = [[-0.08173792 -0.06032696  0.         -0.5071368 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 1431 is [True, False, False, False, True, False]
State prediction error at timestep 1431 is tensor(6.7688e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1431 of None
Current timestep = 1432. State = [[-0.3432799  -0.06802376]]. Action = [[ 0.08553085 -0.05176619  0.         -0.5313134 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 1432 is [True, False, False, False, True, False]
State prediction error at timestep 1432 is tensor(2.6508e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1432 of None
Current timestep = 1433. State = [[-0.3414564  -0.07256891]]. Action = [[ 0.0058985  -0.05501714  0.         -0.5493508 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 1433 is [True, False, False, False, True, False]
State prediction error at timestep 1433 is tensor(9.1290e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1433 of None
Current timestep = 1434. State = [[-0.33975255 -0.07861045]]. Action = [[ 0.03532482 -0.07403848  0.         -0.48448443]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 1434 is [True, False, False, False, True, False]
State prediction error at timestep 1434 is tensor(9.9672e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1434 of None
Current timestep = 1435. State = [[-0.33941486 -0.08336999]]. Action = [[-0.01313525 -0.02958941  0.         -0.9293979 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 1435 is [True, False, False, False, True, False]
State prediction error at timestep 1435 is tensor(3.8005e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1435 of None
Current timestep = 1436. State = [[-0.33711872 -0.08954153]]. Action = [[ 0.05116523 -0.07796385  0.         -0.76002586]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 1436 is [True, False, False, False, True, False]
State prediction error at timestep 1436 is tensor(5.3936e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1436 of None
Current timestep = 1437. State = [[-0.33157775 -0.09190132]]. Action = [[ 0.0777544  0.0251906  0.        -0.7949733]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 1437 is [True, False, False, False, True, False]
State prediction error at timestep 1437 is tensor(2.5473e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1437 of None
Current timestep = 1438. State = [[-0.3297558  -0.09052218]]. Action = [[-0.01970126  0.03733427  0.         -0.3625378 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 1438 is [True, False, False, False, True, False]
State prediction error at timestep 1438 is tensor(1.6358e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1438 of None
Current timestep = 1439. State = [[-0.32591406 -0.09285709]]. Action = [[ 0.08224422 -0.05060969  0.         -0.6409383 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 1439 is [True, False, False, False, True, False]
State prediction error at timestep 1439 is tensor(2.1382e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1439 of None
Current timestep = 1440. State = [[-0.3208493  -0.09129675]]. Action = [[ 0.04151287  0.07554708  0.         -0.7123888 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 1440 is [True, False, False, False, True, False]
State prediction error at timestep 1440 is tensor(4.4212e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1440 of None
Current timestep = 1441. State = [[-0.32165352 -0.0882567 ]]. Action = [[-0.05832456  0.02984481  0.         -0.613382  ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 1441 is [True, False, False, False, True, False]
State prediction error at timestep 1441 is tensor(2.3376e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1441 of None
Current timestep = 1442. State = [[-0.3271184 -0.0852382]]. Action = [[-0.09388071  0.05565118  0.         -0.8444556 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 1442 is [True, False, False, False, True, False]
State prediction error at timestep 1442 is tensor(3.9916e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1442 of None
Current timestep = 1443. State = [[-0.33194357 -0.08797175]]. Action = [[-0.05045953 -0.07591507  0.         -0.96387494]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 1443 is [True, False, False, False, True, False]
State prediction error at timestep 1443 is tensor(2.0816e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1443 of None
Current timestep = 1444. State = [[-0.33279672 -0.08823975]]. Action = [[ 0.01312707  0.04706381  0.         -0.2503556 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 1444 is [True, False, False, False, True, False]
State prediction error at timestep 1444 is tensor(3.8198e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1444 of None
Current timestep = 1445. State = [[-0.32904398 -0.09148388]]. Action = [[ 0.07317563 -0.09667181  0.         -0.47304666]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 1445 is [True, False, False, False, True, False]
State prediction error at timestep 1445 is tensor(2.1187e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1445 of None
Current timestep = 1446. State = [[-0.33028528 -0.09675861]]. Action = [[-0.08041535 -0.0436478   0.         -0.48182476]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 1446 is [True, False, False, False, True, False]
State prediction error at timestep 1446 is tensor(7.2848e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1446 of None
Current timestep = 1447. State = [[-0.33310872 -0.09911584]]. Action = [[-0.00861283 -0.00743519  0.         -0.5445827 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 1447 is [True, False, False, False, True, False]
State prediction error at timestep 1447 is tensor(9.0218e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1447 of None
Current timestep = 1448. State = [[-0.33618388 -0.10054773]]. Action = [[-0.04641904 -0.01200153  0.         -0.85176027]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 1448 is [True, False, False, False, True, False]
State prediction error at timestep 1448 is tensor(9.6985e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1448 of None
Current timestep = 1449. State = [[-0.33458242 -0.10148884]]. Action = [[ 0.07263679 -0.00414701  0.         -0.57708156]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 1449 is [True, False, False, False, True, False]
State prediction error at timestep 1449 is tensor(5.7651e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1449 of None
Current timestep = 1450. State = [[-0.33547005 -0.09751343]]. Action = [[-0.05643113  0.08771076  0.         -0.46183515]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 1450 is [True, False, False, False, True, False]
State prediction error at timestep 1450 is tensor(1.8622e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1450 of None
Current timestep = 1451. State = [[-0.3376429  -0.09662613]]. Action = [[ 0.00471745 -0.03546288  0.         -0.22717857]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 1451 is [True, False, False, False, True, False]
State prediction error at timestep 1451 is tensor(8.1097e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1451 of None
Current timestep = 1452. State = [[-0.33462217 -0.09443413]]. Action = [[0.07964853 0.0544878  0.         0.12736976]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 1452 is [True, False, False, False, True, False]
State prediction error at timestep 1452 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1452 of None
Current timestep = 1453. State = [[-0.33629376 -0.08789363]]. Action = [[-0.06894267  0.08752889  0.         -0.8336863 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 1453 is [True, False, False, False, True, False]
State prediction error at timestep 1453 is tensor(2.0443e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1453 of None
Current timestep = 1454. State = [[-0.33913177 -0.08506571]]. Action = [[ 0.00747446 -0.01344357  0.         -0.21948868]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 1454 is [True, False, False, False, True, False]
State prediction error at timestep 1454 is tensor(9.6029e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1454 of None
Current timestep = 1455. State = [[-0.34497362 -0.08425029]]. Action = [[-0.09679817  0.0084038   0.         -0.89796233]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 1455 is [True, False, False, False, True, False]
State prediction error at timestep 1455 is tensor(2.2579e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1455 of None
Current timestep = 1456. State = [[-0.34633535 -0.08195104]]. Action = [[ 0.06202967  0.02549142  0.         -0.8914491 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 1456 is [True, False, False, False, True, False]
State prediction error at timestep 1456 is tensor(1.6072e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1456 of None
Current timestep = 1457. State = [[-0.34755537 -0.0807965 ]]. Action = [[-0.03697713 -0.01195793  0.          0.17579103]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 1457 is [True, False, False, False, True, False]
State prediction error at timestep 1457 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1457 of None
Current timestep = 1458. State = [[-0.3501911  -0.07858364]]. Action = [[-0.01756578  0.03755382  0.         -0.6968808 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 1458 is [True, False, False, False, True, False]
State prediction error at timestep 1458 is tensor(1.2747e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1458 of None
Current timestep = 1459. State = [[-0.34814513 -0.07493366]]. Action = [[ 0.0703151   0.03160322  0.         -0.9185168 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 1459 is [True, False, False, False, True, False]
State prediction error at timestep 1459 is tensor(2.4316e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1459 of None
Current timestep = 1460. State = [[-0.34242085 -0.07663618]]. Action = [[ 0.09121647 -0.08113972  0.          0.01310885]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 1460 is [True, False, False, False, True, False]
State prediction error at timestep 1460 is tensor(7.6995e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1460 of None
Current timestep = 1461. State = [[-0.33872    -0.08060494]]. Action = [[ 0.024734   -0.04940943  0.          0.393471  ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 1461 is [True, False, False, False, True, False]
State prediction error at timestep 1461 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1461 of None
Current timestep = 1462. State = [[-0.3371985  -0.07859045]]. Action = [[ 0.00945272  0.06731091  0.         -0.6063131 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 1462 is [True, False, False, False, True, False]
State prediction error at timestep 1462 is tensor(1.6093e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1462 of None
Current timestep = 1463. State = [[-0.33954945 -0.07227065]]. Action = [[-0.06115425  0.08571716  0.         -0.3155728 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 1463 is [True, False, False, False, True, False]
State prediction error at timestep 1463 is tensor(5.4700e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1463 of None
Current timestep = 1464. State = [[-0.34206602 -0.06960419]]. Action = [[-0.02022935 -0.00361276  0.         -0.4273045 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 1464 is [True, False, False, False, True, False]
State prediction error at timestep 1464 is tensor(2.0783e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1464 of None
Current timestep = 1465. State = [[-0.3468303  -0.07141021]]. Action = [[-0.08611277 -0.03898247  0.         -0.4260518 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 1465 is [True, False, False, False, True, False]
State prediction error at timestep 1465 is tensor(1.9564e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1465 of None
Current timestep = 1466. State = [[-0.35160807 -0.06881233]]. Action = [[-0.04781793  0.07826246  0.         -0.8590573 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 1466 is [True, False, False, False, True, False]
State prediction error at timestep 1466 is tensor(5.2596e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1466 of None
Current timestep = 1467. State = [[-0.34931195 -0.06833114]]. Action = [[ 0.09439484 -0.04988335  0.         -0.5023425 ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 1467 is [True, False, False, False, True, False]
State prediction error at timestep 1467 is tensor(3.4129e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1467 of None
Current timestep = 1468. State = [[-0.3468737  -0.06642083]]. Action = [[-0.01192799  0.05389638  0.         -0.6325096 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 1468 is [True, False, False, False, True, False]
State prediction error at timestep 1468 is tensor(1.9363e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1468 of None
Current timestep = 1469. State = [[-0.3498795  -0.06816651]]. Action = [[-0.06748673 -0.07299529  0.          0.6243311 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 1469 is [True, False, False, False, True, False]
State prediction error at timestep 1469 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1469 of None
Current timestep = 1470. State = [[-0.3476631  -0.07139411]]. Action = [[ 0.08319069 -0.02175815  0.         -0.8122523 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 1470 is [True, False, False, False, True, False]
State prediction error at timestep 1470 is tensor(5.1352e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1470 of None
Current timestep = 1471. State = [[-0.34605044 -0.07149535]]. Action = [[-0.02528465  0.01404089  0.         -0.9704809 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 1471 is [True, False, False, False, True, False]
State prediction error at timestep 1471 is tensor(6.1288e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1471 of None
Current timestep = 1472. State = [[-0.3494167  -0.06718493]]. Action = [[-0.06717837  0.08191698  0.         -0.611097  ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 1472 is [True, False, False, False, True, False]
State prediction error at timestep 1472 is tensor(1.5957e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1472 of None
Current timestep = 1473. State = [[-0.35486525 -0.06502707]]. Action = [[-0.07691336 -0.00418216  0.         -0.22784746]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 1473 is [True, False, False, False, True, False]
State prediction error at timestep 1473 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1473 of None
Current timestep = 1474. State = [[-0.35929608 -0.06333411]]. Action = [[-0.04179321  0.03441174  0.         -0.69548357]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 1474 is [True, False, False, False, True, False]
State prediction error at timestep 1474 is tensor(1.1411e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1474 of None
Current timestep = 1475. State = [[-0.35752222 -0.06363074]]. Action = [[ 0.08087151 -0.03734853  0.         -0.72910655]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 1475 is [True, False, False, False, True, False]
State prediction error at timestep 1475 is tensor(1.0008e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1475 of None
Current timestep = 1476. State = [[-0.3522174  -0.06179075]]. Action = [[ 0.0735715   0.04133809  0.         -0.6161209 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 1476 is [True, False, False, False, True, False]
State prediction error at timestep 1476 is tensor(4.0851e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1476 of None
Current timestep = 1477. State = [[-0.35408574 -0.06039697]]. Action = [[-0.0870919  -0.00704613  0.         -0.28780663]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 1477 is [True, False, False, False, True, False]
State prediction error at timestep 1477 is tensor(2.9666e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1477 of None
Current timestep = 1478. State = [[-0.35454172 -0.06473761]]. Action = [[ 0.05740041 -0.09032301  0.         -0.62985075]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 1478 is [True, False, False, False, True, False]
State prediction error at timestep 1478 is tensor(1.4342e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1478 of None
Current timestep = 1479. State = [[-0.3541512  -0.07120603]]. Action = [[-0.01571634 -0.0717415   0.         -0.73753273]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 1479 is [True, False, False, False, True, False]
State prediction error at timestep 1479 is tensor(8.1113e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1479 of None
Current timestep = 1480. State = [[-0.3563891  -0.07683001]]. Action = [[-0.03741054 -0.05103081  0.          0.0985502 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 1480 is [True, False, False, False, True, False]
State prediction error at timestep 1480 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1480 of None
Current timestep = 1481. State = [[-0.35583276 -0.07629383]]. Action = [[ 0.03568148  0.0634908   0.         -0.64720327]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 1481 is [True, False, False, False, True, False]
State prediction error at timestep 1481 is tensor(1.0720e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1481 of None
Current timestep = 1482. State = [[-0.35552412 -0.07275417]]. Action = [[-0.01122846  0.04197266  0.         -0.7076374 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 1482 is [True, False, False, False, True, False]
State prediction error at timestep 1482 is tensor(2.0762e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1482 of None
Current timestep = 1483. State = [[-0.35641012 -0.07352514]]. Action = [[-0.00915386 -0.03740303  0.         -0.04390597]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 1483 is [True, False, False, False, True, False]
State prediction error at timestep 1483 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1483 of None
Current timestep = 1484. State = [[-0.35348016 -0.07826435]]. Action = [[ 0.070034  -0.0668729  0.        -0.5180769]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 1484 is [True, False, False, False, True, False]
State prediction error at timestep 1484 is tensor(5.5106e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1484 of None
Current timestep = 1485. State = [[-0.34714422 -0.0817953 ]]. Action = [[ 0.08975715 -0.02470717  0.         -0.5370844 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 1485 is [True, False, False, False, True, False]
State prediction error at timestep 1485 is tensor(8.6032e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1485 of None
Current timestep = 1486. State = [[-0.34426007 -0.07998571]]. Action = [[-0.00361608  0.05855239  0.         -0.81621933]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 1486 is [True, False, False, False, True, False]
State prediction error at timestep 1486 is tensor(1.8717e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1486 of None
Current timestep = 1487. State = [[-0.34547552 -0.0816595 ]]. Action = [[-0.02945518 -0.05921675  0.         -0.6373097 ]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 1487 is [True, False, False, False, True, False]
State prediction error at timestep 1487 is tensor(1.0388e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1487 of None
Current timestep = 1488. State = [[-0.35077202 -0.08627023]]. Action = [[-0.09534571 -0.03836774  0.         -0.6043385 ]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 1488 is [True, False, False, False, True, False]
State prediction error at timestep 1488 is tensor(1.8366e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1488 of None
Current timestep = 1489. State = [[-0.35258234 -0.0850215 ]]. Action = [[ 0.01969709  0.07493318  0.         -0.43993133]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 1489 is [True, False, False, False, True, False]
State prediction error at timestep 1489 is tensor(1.0732e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1489 of None
Current timestep = 1490. State = [[-0.35565892 -0.08250202]]. Action = [[-0.06958375  0.01552025  0.         -0.71233237]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 1490 is [True, False, False, False, True, False]
State prediction error at timestep 1490 is tensor(8.3384e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1490 of None
Current timestep = 1491. State = [[-0.36246958 -0.08526583]]. Action = [[-0.09398177 -0.0544043   0.         -0.23656052]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 1491 is [True, False, False, False, True, False]
State prediction error at timestep 1491 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1491 of None
Current timestep = 1492. State = [[-0.36329404 -0.0910348 ]]. Action = [[ 0.06141139 -0.07327241  0.         -0.5170065 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 1492 is [True, False, False, False, True, False]
State prediction error at timestep 1492 is tensor(1.7866e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1492 of None
Current timestep = 1493. State = [[-0.35842153 -0.08961091]]. Action = [[ 0.07911813  0.08302071  0.         -0.5014751 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 1493 is [True, False, False, False, True, False]
State prediction error at timestep 1493 is tensor(9.6700e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1493 of None
Current timestep = 1494. State = [[-0.3604957  -0.08397084]]. Action = [[-0.09908582  0.06418464  0.         -0.39712107]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 1494 is [True, False, False, False, True, False]
State prediction error at timestep 1494 is tensor(2.8801e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1494 of None
Current timestep = 1495. State = [[-0.36095527 -0.07824595]]. Action = [[0.0677753  0.05868321 0.         0.44777286]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 1495 is [True, False, False, False, True, False]
State prediction error at timestep 1495 is tensor(9.3470e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1495 of None
Current timestep = 1496. State = [[-0.35613808 -0.07391522]]. Action = [[ 0.07622337  0.0207998   0.         -0.55408245]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 1496 is [True, False, False, False, True, False]
State prediction error at timestep 1496 is tensor(4.7464e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1496 of None
Current timestep = 1497. State = [[-0.35466266 -0.07470473]]. Action = [[-0.00533845 -0.05744336  0.         -0.79199034]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 1497 is [True, False, False, False, True, False]
State prediction error at timestep 1497 is tensor(2.7534e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1497 of None
Current timestep = 1498. State = [[-0.35886776 -0.07567634]]. Action = [[-0.08211075  0.0065829   0.         -0.08971697]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 1498 is [True, False, False, False, True, False]
State prediction error at timestep 1498 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1498 of None
Current timestep = 1499. State = [[-0.36340696 -0.07285483]]. Action = [[-0.03772683  0.05300308  0.         -0.38309097]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 1499 is [True, False, False, False, True, False]
State prediction error at timestep 1499 is tensor(6.9288e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1499 of None
Current timestep = 1500. State = [[-0.3652094  -0.07376627]]. Action = [[-0.00167582 -0.05632982  0.         -0.662361  ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 1500 is [True, False, False, False, True, False]
State prediction error at timestep 1500 is tensor(7.4999e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1500 of None
Current timestep = 1501. State = [[-0.36228874 -0.07237925]]. Action = [[ 0.07641757  0.05021597  0.         -0.77442527]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 1501 is [True, False, False, False, True, False]
State prediction error at timestep 1501 is tensor(2.8870e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1501 of None
Current timestep = 1502. State = [[-0.36403722 -0.07038511]]. Action = [[-0.07547048 -0.00234414  0.         -0.23870206]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 1502 is [True, False, False, False, True, False]
State prediction error at timestep 1502 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1502 of None
Current timestep = 1503. State = [[-0.3672252  -0.07006419]]. Action = [[-0.00917916 -0.00119355  0.          0.36137593]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 1503 is [True, False, False, False, True, False]
State prediction error at timestep 1503 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1503 of None
Current timestep = 1504. State = [[-0.36776888 -0.06566741]]. Action = [[ 0.01376611  0.07757581  0.         -0.05945808]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 1504 is [True, False, False, False, True, False]
State prediction error at timestep 1504 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1504 of None
Current timestep = 1505. State = [[-0.36868355 -0.06415922]]. Action = [[-0.00978637 -0.03279591  0.          0.31822526]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 1505 is [True, False, False, False, True, False]
State prediction error at timestep 1505 is tensor(9.3929e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1505 of None
Current timestep = 1506. State = [[-0.36960033 -0.0644743 ]]. Action = [[ 0.          0.          0.         -0.52280647]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 1506 is [True, False, False, False, True, False]
State prediction error at timestep 1506 is tensor(1.7643e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1506 of None
Current timestep = 1507. State = [[-0.3708507  -0.06396674]]. Action = [[-0.0146907   0.00323663  0.         -0.19222665]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 1507 is [True, False, False, False, True, False]
State prediction error at timestep 1507 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1507 of None
Current timestep = 1508. State = [[-0.37170172 -0.06356879]]. Action = [[ 0.          0.          0.         -0.76453954]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 1508 is [True, False, False, False, True, False]
State prediction error at timestep 1508 is tensor(4.9010e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1508 of None
Current timestep = 1509. State = [[-0.36857018 -0.0597515 ]]. Action = [[ 0.07394776  0.06464661  0.         -0.9034761 ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 1509 is [True, False, False, False, True, False]
State prediction error at timestep 1509 is tensor(2.9064e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1509 of None
Current timestep = 1510. State = [[-0.36237624 -0.05664517]]. Action = [[ 0.09394019 -0.00097225  0.         -0.20749569]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 1510 is [True, False, False, False, True, False]
State prediction error at timestep 1510 is tensor(8.8999e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1510 of None
Current timestep = 1511. State = [[-0.36003125 -0.05142426]]. Action = [[-0.00560983  0.08016712  0.         -0.49738204]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 1511 is [True, False, False, False, True, False]
State prediction error at timestep 1511 is tensor(3.2197e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1511 of None
Current timestep = 1512. State = [[-0.35956854 -0.04864528]]. Action = [[ 0.01796456 -0.01265235  0.         -0.42820728]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 1512 is [True, False, False, False, True, False]
State prediction error at timestep 1512 is tensor(9.6721e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1512 of None
Current timestep = 1513. State = [[-0.35651082 -0.04375273]]. Action = [[ 0.05829137  0.08136978  0.         -0.8161264 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 1513 is [True, False, False, False, True, False]
State prediction error at timestep 1513 is tensor(4.2622e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1513 of None
Current timestep = 1514. State = [[-0.35297865 -0.04281399]]. Action = [[ 0.04033542 -0.05504761  0.         -0.80720294]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 1514 is [True, False, False, False, True, False]
State prediction error at timestep 1514 is tensor(1.7005e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1514 of None
Current timestep = 1515. State = [[-0.3527591  -0.04467203]]. Action = [[-0.02896883 -0.02203199  0.         -0.7607705 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 1515 is [True, False, False, False, True, False]
State prediction error at timestep 1515 is tensor(2.9500e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1515 of None
Current timestep = 1516. State = [[-0.35647565 -0.04265001]]. Action = [[-0.07586641  0.05040949  0.         -0.87356627]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 1516 is [True, False, False, False, True, False]
State prediction error at timestep 1516 is tensor(8.3284e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1516 of None
Current timestep = 1517. State = [[-0.35739136 -0.04318071]]. Action = [[ 0.01373623 -0.04459542  0.          0.5976579 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 1517 is [True, False, False, False, True, False]
State prediction error at timestep 1517 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1517 of None
Current timestep = 1518. State = [[-0.3587272  -0.04690979]]. Action = [[-0.04760826 -0.05006428  0.         -0.7869671 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 1518 is [True, False, False, False, True, False]
State prediction error at timestep 1518 is tensor(4.2980e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1518 of None
Current timestep = 1519. State = [[-0.3594717  -0.04582153]]. Action = [[-0.00137245  0.05791663  0.         -0.8542698 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 1519 is [True, False, False, False, True, False]
State prediction error at timestep 1519 is tensor(1.9733e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1519 of None
Current timestep = 1520. State = [[-0.35688588 -0.04380724]]. Action = [[ 0.04814801  0.00267621  0.         -0.23795784]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 1520 is [True, False, False, False, True, False]
State prediction error at timestep 1520 is tensor(5.1639e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1520 of None
Current timestep = 1521. State = [[-0.35656092 -0.04477284]]. Action = [[-0.02657217 -0.02800652  0.         -0.5404532 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 1521 is [True, False, False, False, True, False]
State prediction error at timestep 1521 is tensor(2.7064e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1521 of None
Current timestep = 1522. State = [[-0.3530449  -0.04142835]]. Action = [[ 0.08429498  0.08066512  0.         -0.2321974 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 1522 is [True, False, False, False, True, False]
State prediction error at timestep 1522 is tensor(5.0400e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1522 of None
Current timestep = 1523. State = [[-0.3468964  -0.03553377]]. Action = [[ 0.0810309   0.05231302  0.         -0.19847953]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 1523 is [True, False, False, False, True, False]
State prediction error at timestep 1523 is tensor(3.6149e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1523 of None
Current timestep = 1524. State = [[-0.34111792 -0.03259902]]. Action = [[ 0.07130962  0.00291495  0.         -0.86641294]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 1524 is [True, False, False, False, True, False]
State prediction error at timestep 1524 is tensor(2.6061e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1524 of None
Current timestep = 1525. State = [[-0.33799556 -0.02690761]]. Action = [[ 0.01909421  0.09049363  0.         -0.8941703 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 1525 is [True, False, False, False, True, False]
State prediction error at timestep 1525 is tensor(3.7559e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1525 of None
Current timestep = 1526. State = [[-0.33439898 -0.01938994]]. Action = [[ 0.06172069  0.07270939  0.         -0.68176734]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 1526 is [True, False, False, False, True, False]
State prediction error at timestep 1526 is tensor(4.4972e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1526 of None
Current timestep = 1527. State = [[-0.33121866 -0.01175483]]. Action = [[ 0.03134174  0.07710395  0.         -0.8758596 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 1527 is [True, False, False, False, True, False]
State prediction error at timestep 1527 is tensor(3.0818e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1527 of None
Current timestep = 1528. State = [[-0.32593104 -0.01037855]]. Action = [[ 0.08660417 -0.05242452  0.         -0.2311151 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 1528 is [True, False, False, False, True, False]
State prediction error at timestep 1528 is tensor(1.1382e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1528 of None
Current timestep = 1529. State = [[-0.3255779 -0.0071   ]]. Action = [[-0.06386159  0.06692737  0.         -0.7551671 ]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 1529 is [True, False, False, False, True, False]
State prediction error at timestep 1529 is tensor(1.8741e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1529 of None
Current timestep = 1530. State = [[-0.325739   -0.00856805]]. Action = [[ 0.0204346  -0.09411113  0.         -0.46097028]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 1530 is [True, False, False, False, True, False]
State prediction error at timestep 1530 is tensor(7.2504e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1530 of None
Current timestep = 1531. State = [[-0.32101586 -0.01196702]]. Action = [[ 0.06742779 -0.03344281  0.         -0.6960237 ]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 1531 is [True, False, False, False, True, False]
State prediction error at timestep 1531 is tensor(2.7864e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1531 of None
Current timestep = 1532. State = [[-0.32167423 -0.01190614]]. Action = [[-0.08365349  0.01322056  0.         -0.58872706]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 1532 is [True, False, False, False, True, False]
State prediction error at timestep 1532 is tensor(5.8150e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1532 of None
Current timestep = 1533. State = [[-0.32314572 -0.0095104 ]]. Action = [[-0.00136928  0.03305272  0.         -0.5024808 ]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 1533 is [True, False, False, False, True, False]
State prediction error at timestep 1533 is tensor(7.7836e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1533 of None
Current timestep = 1534. State = [[-0.32522047 -0.00776596]]. Action = [[-0.04925194  0.00616614  0.         -0.9353517 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 1534 is [True, False, False, False, True, False]
State prediction error at timestep 1534 is tensor(7.4654e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1534 of None
Current timestep = 1535. State = [[-0.3286733  -0.00755073]]. Action = [[-0.05242554 -0.00778204  0.         -0.6377195 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 1535 is [True, False, False, False, True, False]
State prediction error at timestep 1535 is tensor(1.4143e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1535 of None
Current timestep = 1536. State = [[-0.32811975 -0.00957955]]. Action = [[ 0.03644896 -0.04076827  0.         -0.81243217]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 1536 is [True, False, False, False, True, False]
State prediction error at timestep 1536 is tensor(7.0697e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1536 of None
Current timestep = 1537. State = [[-0.33003154 -0.00808927]]. Action = [[-0.06343751  0.05304278  0.          0.21071076]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 1537 is [True, False, False, False, True, False]
State prediction error at timestep 1537 is tensor(1.7296e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1537 of None
Current timestep = 1538. State = [[-0.3362856  -0.00578794]]. Action = [[-0.09138893  0.0126405   0.         -0.49768174]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 1538 is [True, False, False, False, True, False]
State prediction error at timestep 1538 is tensor(1.1038e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1538 of None
Current timestep = 1539. State = [[-0.3436113  -0.00666181]]. Action = [[-0.09063912 -0.03072602  0.         -0.05406332]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 1539 is [True, False, False, False, True, False]
State prediction error at timestep 1539 is tensor(4.8801e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1539 of None
Current timestep = 1540. State = [[-0.34475982 -0.00500247]]. Action = [[ 0.05301531  0.04683978  0.         -0.84806764]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 1540 is [True, False, False, False, True, False]
State prediction error at timestep 1540 is tensor(3.8614e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1540 of None
Current timestep = 1541. State = [[-0.3421569  0.0005633]]. Action = [[0.0498575  0.073539   0.         0.07895303]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 1541 is [True, False, False, False, True, False]
State prediction error at timestep 1541 is tensor(8.7093e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1541 of None
Current timestep = 1542. State = [[-3.3738998e-01 -1.8085419e-05]]. Action = [[ 0.09459671 -0.07086156  0.          0.509972  ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 1542 is [True, False, False, False, True, False]
State prediction error at timestep 1542 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1542 of None
Current timestep = 1543. State = [[-0.33538777  0.00245305]]. Action = [[ 0.00475696  0.08286495  0.         -0.83187175]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 1543 is [True, False, False, False, True, False]
State prediction error at timestep 1543 is tensor(1.0216e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1543 of None
Current timestep = 1544. State = [[-0.33835468  0.00937689]]. Action = [[-0.04765313  0.08107295  0.         -0.2557959 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 1544 is [True, False, False, False, True, False]
State prediction error at timestep 1544 is tensor(5.4540e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1544 of None
Current timestep = 1545. State = [[-0.3382874   0.00994796]]. Action = [[ 0.04558023 -0.05503822  0.         -0.6408993 ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 1545 is [True, False, False, False, True, False]
State prediction error at timestep 1545 is tensor(3.3490e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1545 of None
Current timestep = 1546. State = [[-0.33548206  0.00771791]]. Action = [[ 0.04017212 -0.02685679  0.         -0.7234757 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 1546 is [True, False, False, False, True, False]
State prediction error at timestep 1546 is tensor(1.3386e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1546 of None
Current timestep = 1547. State = [[-0.33550495  0.00687707]]. Action = [[-0.02579595 -0.00674258  0.         -0.26777458]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 1547 is [True, False, False, False, True, False]
State prediction error at timestep 1547 is tensor(8.6321e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1547 of None
Current timestep = 1548. State = [[-0.33166707  0.00838458]]. Action = [[ 0.09103108  0.02999013  0.         -0.2920252 ]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 1548 is [True, False, False, False, True, False]
State prediction error at timestep 1548 is tensor(4.8015e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1548 of None
Current timestep = 1549. State = [[-0.33109683  0.00592318]]. Action = [[-0.05537944 -0.07016839  0.         -0.00305444]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 1549 is [True, False, False, False, True, False]
State prediction error at timestep 1549 is tensor(4.6362e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1549 of None
Current timestep = 1550. State = [[-0.33344173  0.00058798]]. Action = [[-0.03503548 -0.06384418  0.         -0.31496972]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 1550 is [True, False, False, False, True, False]
State prediction error at timestep 1550 is tensor(1.1038e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1550 of None
Current timestep = 1551. State = [[-0.33056015 -0.00565586]]. Action = [[ 0.06522656 -0.07383941  0.          0.13847208]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 1551 is [True, False, False, False, True, False]
State prediction error at timestep 1551 is tensor(3.6576e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1551 of None
Current timestep = 1552. State = [[-0.32844862 -0.00743919]]. Action = [[-0.011117    0.02860174  0.         -0.8360892 ]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 1552 is [True, False, False, False, True, False]
State prediction error at timestep 1552 is tensor(7.3189e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1552 of None
Current timestep = 1553. State = [[-0.32563037 -0.00419922]]. Action = [[ 0.05042086  0.06655555  0.         -0.24976069]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 1553 is [True, False, False, False, True, False]
State prediction error at timestep 1553 is tensor(2.6299e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1553 of None
Current timestep = 1554. State = [[-0.32613826 -0.00732537]]. Action = [[-0.05072854 -0.09660832  0.         -0.4290402 ]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 1554 is [True, False, False, False, True, False]
State prediction error at timestep 1554 is tensor(4.6472e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1554 of None
Current timestep = 1555. State = [[-0.32432035 -0.00858754]]. Action = [[ 0.05544888  0.04680622  0.         -0.711895  ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 1555 is [True, False, False, False, True, False]
State prediction error at timestep 1555 is tensor(1.1702e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1555 of None
Current timestep = 1556. State = [[-0.3197509  -0.00614892]]. Action = [[0.05991981 0.03441165 0.         0.2664144 ]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 1556 is [True, False, False, False, True, False]
State prediction error at timestep 1556 is tensor(4.4918e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1556 of None
Current timestep = 1557. State = [[-0.32137492 -0.00887715]]. Action = [[-0.08043455 -0.0690106   0.         -0.82693183]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 1557 is [True, False, False, False, True, False]
State prediction error at timestep 1557 is tensor(3.3242e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1557 of None
Current timestep = 1558. State = [[-0.31964347 -0.01334282]]. Action = [[ 0.07867997 -0.03954376  0.         -0.59647644]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 1558 is [True, False, False, False, True, False]
State prediction error at timestep 1558 is tensor(8.4341e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1558 of None
Current timestep = 1559. State = [[-0.31402802 -0.01213884]]. Action = [[ 0.06450229  0.0614487   0.         -0.60428363]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 1559 is [True, False, False, False, True, False]
State prediction error at timestep 1559 is tensor(2.0703e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1559 of None
Current timestep = 1560. State = [[-0.3076315  -0.01219247]]. Action = [[ 0.08485612 -0.02895701  0.         -0.8050421 ]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 1560 is [True, False, False, False, True, False]
State prediction error at timestep 1560 is tensor(1.4712e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1560 of None
Current timestep = 1561. State = [[-0.3042948  -0.01207235]]. Action = [[ 0.00475438  0.0251596   0.         -0.17017299]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 1561 is [True, False, False, False, True, False]
State prediction error at timestep 1561 is tensor(8.3681e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1561 of None
Current timestep = 1562. State = [[-0.30566594 -0.01552047]]. Action = [[-0.05248536 -0.07535119  0.         -0.4587382 ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 1562 is [True, False, False, False, True, False]
State prediction error at timestep 1562 is tensor(2.2361e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1562 of None
Current timestep = 1563. State = [[-0.30340868 -0.02263058]]. Action = [[ 0.05084837 -0.08638042  0.         -0.09675729]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 1563 is [True, False, False, False, True, False]
State prediction error at timestep 1563 is tensor(1.9140e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1563 of None
Current timestep = 1564. State = [[-0.3042584  -0.02916824]]. Action = [[-0.0784737  -0.05795515  0.         -0.7308953 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 1564 is [True, False, False, False, True, False]
State prediction error at timestep 1564 is tensor(7.5588e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1564 of None
Current timestep = 1565. State = [[-0.30224296 -0.03464671]]. Action = [[ 0.06100375 -0.04862006  0.         -0.7792965 ]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 1565 is [True, False, False, False, True, False]
State prediction error at timestep 1565 is tensor(2.3207e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1565 of None
Current timestep = 1566. State = [[-0.2993262  -0.03839156]]. Action = [[ 4.515797e-05 -1.621811e-02  0.000000e+00 -3.077377e-01]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 1566 is [True, False, False, False, True, False]
State prediction error at timestep 1566 is tensor(4.1845e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1566 of None
Current timestep = 1567. State = [[-0.29939228 -0.03912519]]. Action = [[-0.02732915  0.02502031  0.          0.0771749 ]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 1567 is [True, False, False, False, True, False]
State prediction error at timestep 1567 is tensor(2.8216e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1567 of None
Current timestep = 1568. State = [[-0.29870978 -0.04107495]]. Action = [[ 0.01213136 -0.02822347  0.         -0.7284087 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 1568 is [True, False, False, False, True, False]
State prediction error at timestep 1568 is tensor(1.0729e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1568 of None
Current timestep = 1569. State = [[-0.29452404 -0.04516258]]. Action = [[ 0.06702337 -0.04298259  0.          0.0164541 ]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 1569 is [True, False, False, False, True, False]
State prediction error at timestep 1569 is tensor(1.1770e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1569 of None
Current timestep = 1570. State = [[-0.29245308 -0.05040628]]. Action = [[-0.00886609 -0.0550603   0.         -0.86574405]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 1570 is [True, False, False, False, True, False]
State prediction error at timestep 1570 is tensor(7.6112e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1570 of None
Current timestep = 1571. State = [[-0.2886635  -0.05714928]]. Action = [[ 0.06602902 -0.07394993  0.         -0.37741292]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 1571 is [True, False, False, False, True, False]
State prediction error at timestep 1571 is tensor(2.8540e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1571 of None
Current timestep = 1572. State = [[-0.2878997  -0.06454746]]. Action = [[-0.0400197  -0.07139832  0.         -0.45305765]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 1572 is [True, False, False, False, True, False]
State prediction error at timestep 1572 is tensor(3.4426e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1572 of None
Current timestep = 1573. State = [[-0.2910604  -0.06406691]]. Action = [[-0.06047366  0.08977448  0.         -0.67510414]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 1573 is [True, False, False, False, True, False]
State prediction error at timestep 1573 is tensor(4.5476e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1573 of None
Current timestep = 1574. State = [[-0.2888765  -0.06179972]]. Action = [[ 0.08222727  0.01709809  0.         -0.25251687]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 1574 is [True, False, False, False, True, False]
State prediction error at timestep 1574 is tensor(3.0322e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1574 of None
Current timestep = 1575. State = [[-0.2863955  -0.06224827]]. Action = [[-0.00272568 -0.0070509   0.         -0.10310054]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 1575 is [True, False, False, False, True, False]
State prediction error at timestep 1575 is tensor(1.6174e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1575 of None
Current timestep = 1576. State = [[-0.29025364 -0.05879387]]. Action = [[-0.09113771  0.08624838  0.         -0.9587875 ]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 1576 is [True, False, False, False, True, False]
State prediction error at timestep 1576 is tensor(3.3324e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1576 of None
Current timestep = 1577. State = [[-0.29568025 -0.05829864]]. Action = [[-0.06109465 -0.03486445  0.         -0.49530065]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 1577 is [True, False, False, False, True, False]
State prediction error at timestep 1577 is tensor(2.2037e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1577 of None
Current timestep = 1578. State = [[-0.29646292 -0.06336458]]. Action = [[ 0.02502977 -0.08023737  0.         -0.57656276]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 1578 is [True, False, False, False, True, False]
State prediction error at timestep 1578 is tensor(3.3518e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1578 of None
Current timestep = 1579. State = [[-0.29163542 -0.06261386]]. Action = [[ 0.09653571  0.06629891  0.         -0.8591011 ]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 1579 is [True, False, False, False, True, False]
State prediction error at timestep 1579 is tensor(1.1448e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1579 of None
Current timestep = 1580. State = [[-0.29100257 -0.0627258 ]]. Action = [[-0.03625537 -0.04521196  0.         -0.46587086]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 1580 is [True, False, False, False, True, False]
State prediction error at timestep 1580 is tensor(3.1597e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1580 of None
Current timestep = 1581. State = [[-0.29642582 -0.06774984]]. Action = [[-0.09243561 -0.07270838  0.         -0.7786495 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 1581 is [True, False, False, False, True, False]
State prediction error at timestep 1581 is tensor(3.6716e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1581 of None
Current timestep = 1582. State = [[-0.3019631  -0.07100762]]. Action = [[-0.05973699 -0.00874119  0.         -0.57766294]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 1582 is [True, False, False, False, True, False]
State prediction error at timestep 1582 is tensor(3.3581e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1582 of None
Current timestep = 1583. State = [[-0.30772966 -0.06845812]]. Action = [[-0.07469294  0.07087081  0.         -0.44047046]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 1583 is [True, False, False, False, True, False]
State prediction error at timestep 1583 is tensor(2.4573e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1583 of None
Current timestep = 1584. State = [[-0.3128033  -0.06957673]]. Action = [[-0.04463828 -0.05743016  0.         -0.14008516]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 1584 is [True, False, False, False, True, False]
State prediction error at timestep 1584 is tensor(5.9554e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1584 of None
Current timestep = 1585. State = [[-0.31894597 -0.07214393]]. Action = [[-0.07935236 -0.01193292  0.         -0.74438226]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 1585 is [True, False, False, False, True, False]
State prediction error at timestep 1585 is tensor(2.5331e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1585 of None
Current timestep = 1586. State = [[-0.32012916 -0.07013635]]. Action = [[ 0.05003368  0.05341775  0.         -0.9263798 ]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 1586 is [True, False, False, False, True, False]
State prediction error at timestep 1586 is tensor(5.6426e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1586 of None
Current timestep = 1587. State = [[-0.32178906 -0.06978457]]. Action = [[-0.03127637 -0.02873291  0.         -0.85715306]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 1587 is [True, False, False, False, True, False]
State prediction error at timestep 1587 is tensor(1.5772e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1587 of None
Current timestep = 1588. State = [[-0.326864   -0.06632855]]. Action = [[-0.05844727  0.08253866  0.         -0.8444727 ]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 1588 is [True, False, False, False, True, False]
State prediction error at timestep 1588 is tensor(1.7552e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1588 of None
Current timestep = 1589. State = [[-0.3313337  -0.06540549]]. Action = [[-0.02393599 -0.03517073  0.         -0.763294  ]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 1589 is [True, False, False, False, True, False]
State prediction error at timestep 1589 is tensor(4.4404e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1589 of None
Current timestep = 1590. State = [[-0.33613124 -0.07075385]]. Action = [[-0.05010389 -0.09119393  0.         -0.05000705]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 1590 is [True, False, False, False, True, False]
State prediction error at timestep 1590 is tensor(8.6128e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1590 of None
Current timestep = 1591. State = [[-0.3387045  -0.07017986]]. Action = [[ 0.01314026  0.07390831  0.         -0.5191929 ]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 1591 is [True, False, False, False, True, False]
State prediction error at timestep 1591 is tensor(3.0212e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1591 of None
Current timestep = 1592. State = [[-0.34173214 -0.06938265]]. Action = [[-0.03526691 -0.03010491  0.         -0.72771907]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 1592 is [True, False, False, False, True, False]
State prediction error at timestep 1592 is tensor(2.1418e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1592 of None
Current timestep = 1593. State = [[-0.3484901  -0.06746729]]. Action = [[-0.08804789  0.05215158  0.         -0.573751  ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 1593 is [True, False, False, False, True, False]
State prediction error at timestep 1593 is tensor(2.9458e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1593 of None
Current timestep = 1594. State = [[-0.35046732 -0.06798259]]. Action = [[ 0.05260564 -0.04732063  0.         -0.6686374 ]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 1594 is [True, False, False, False, True, False]
State prediction error at timestep 1594 is tensor(1.0366e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1594 of None
Current timestep = 1595. State = [[-0.35018438 -0.07098169]]. Action = [[ 0.00050581 -0.03692007  0.         -0.23389882]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 1595 is [True, False, False, False, True, False]
State prediction error at timestep 1595 is tensor(4.1083e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1595 of None
Current timestep = 1596. State = [[-0.35096464 -0.07236941]]. Action = [[-0.00200368 -0.00232445  0.         -0.82122916]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 1596 is [True, False, False, False, True, False]
State prediction error at timestep 1596 is tensor(4.3945e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1596 of None
Current timestep = 1597. State = [[-0.34795547 -0.06803186]]. Action = [[ 0.07771298  0.08672263  0.         -0.69294894]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 1597 is [True, False, False, False, True, False]
State prediction error at timestep 1597 is tensor(3.6908e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1597 of None
Current timestep = 1598. State = [[-0.34871477 -0.06164338]]. Action = [[-0.04596464  0.06383646  0.         -0.6147048 ]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 1598 is [True, False, False, False, True, False]
State prediction error at timestep 1598 is tensor(1.5800e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1598 of None
Current timestep = 1599. State = [[-0.3465445  -0.06271299]]. Action = [[ 0.09428766 -0.07882603  0.         -0.67831   ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 1599 is [True, False, False, False, True, False]
State prediction error at timestep 1599 is tensor(1.0437e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1599 of None
Current timestep = 1600. State = [[-0.345914   -0.06035449]]. Action = [[-0.04576259  0.08596749  0.         -0.6107724 ]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 1600 is [True, False, False, False, True, False]
State prediction error at timestep 1600 is tensor(2.1404e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1600 of None
Current timestep = 1601. State = [[-0.3448182  -0.05910198]]. Action = [[ 0.06014735 -0.03665128  0.         -0.76206374]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 1601 is [True, False, False, False, True, False]
State prediction error at timestep 1601 is tensor(8.4811e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1601 of None
Current timestep = 1602. State = [[-0.3428607  -0.06051172]]. Action = [[ 0.01091348 -0.02066404  0.         -0.47878003]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 1602 is [True, False, False, False, True, False]
State prediction error at timestep 1602 is tensor(3.9317e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1602 of None
Current timestep = 1603. State = [[-0.33757412 -0.06148701]]. Action = [[ 0.09807184 -0.01429862  0.         -0.12128216]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 1603 is [True, False, False, False, True, False]
State prediction error at timestep 1603 is tensor(2.9681e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1603 of None
Current timestep = 1604. State = [[-0.3342855  -0.05973168]]. Action = [[ 0.00148389  0.03669157  0.         -0.18146634]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 1604 is [True, False, False, False, True, False]
State prediction error at timestep 1604 is tensor(2.9727e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1604 of None
Current timestep = 1605. State = [[-0.3334493  -0.05823391]]. Action = [[ 0.00400921  0.00427102  0.         -0.5880833 ]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 1605 is [True, False, False, False, True, False]
State prediction error at timestep 1605 is tensor(4.2304e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1605 of None
Current timestep = 1606. State = [[-0.33023876 -0.05378582]]. Action = [[ 0.053567    0.07892463  0.         -0.7167139 ]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 1606 is [True, False, False, False, True, False]
State prediction error at timestep 1606 is tensor(2.2626e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1606 of None
Current timestep = 1607. State = [[-0.33291695 -0.04880765]]. Action = [[-0.09862085  0.04330059  0.         -0.57767   ]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 1607 is [True, False, False, False, True, False]
State prediction error at timestep 1607 is tensor(5.9873e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1607 of None
Current timestep = 1608. State = [[-0.33792615 -0.05093448]]. Action = [[-0.05290151 -0.07766657  0.         -0.07640558]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 1608 is [True, False, False, False, True, False]
State prediction error at timestep 1608 is tensor(6.0744e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1608 of None
Current timestep = 1609. State = [[-0.34065348 -0.05037188]]. Action = [[-0.02460058  0.05243569  0.         -0.77441   ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 1609 is [True, False, False, False, True, False]
State prediction error at timestep 1609 is tensor(1.9833e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1609 of None
Current timestep = 1610. State = [[-0.34424424 -0.04719115]]. Action = [[-0.05625927  0.02574951  0.         -0.7585498 ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 1610 is [True, False, False, False, True, False]
State prediction error at timestep 1610 is tensor(9.6080e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1610 of None
Current timestep = 1611. State = [[-0.343675   -0.04168775]]. Action = [[ 0.05365189  0.07696567  0.         -0.70834446]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 1611 is [True, False, False, False, True, False]
State prediction error at timestep 1611 is tensor(2.3611e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1611 of None
Current timestep = 1612. State = [[-0.3392392  -0.03349484]]. Action = [[ 0.07946243  0.08725322  0.         -0.7621803 ]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 1612 is [True, False, False, False, True, False]
State prediction error at timestep 1612 is tensor(7.1084e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1612 of None
Current timestep = 1613. State = [[-0.336794   -0.03107269]]. Action = [[ 0.02112398 -0.04007423  0.         -0.69717133]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 1613 is [True, False, False, False, True, False]
State prediction error at timestep 1613 is tensor(1.7718e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1613 of None
Current timestep = 1614. State = [[-0.33559236 -0.03127654]]. Action = [[ 0.01892622 -0.00748711  0.         -0.7876028 ]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 1614 is [True, False, False, False, True, False]
State prediction error at timestep 1614 is tensor(6.6493e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1614 of None
Current timestep = 1615. State = [[-0.33729473 -0.02803586]]. Action = [[-0.04254669  0.05186326  0.         -0.4612509 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 1615 is [True, False, False, False, True, False]
State prediction error at timestep 1615 is tensor(6.0377e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1615 of None
Current timestep = 1616. State = [[-0.33552438 -0.02211008]]. Action = [[ 0.06785125  0.06653131  0.         -0.3834238 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 1616 is [True, False, False, False, True, False]
State prediction error at timestep 1616 is tensor(3.8111e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1616 of None
Current timestep = 1617. State = [[-0.3305042  -0.01454564]]. Action = [[ 0.07489002  0.08121078  0.         -0.79010046]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 1617 is [True, False, False, False, True, False]
State prediction error at timestep 1617 is tensor(5.1712e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1617 of None
Current timestep = 1618. State = [[-0.33204564 -0.0081458 ]]. Action = [[-0.07344447  0.04837538  0.         -0.76371807]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 1618 is [True, False, False, False, True, False]
State prediction error at timestep 1618 is tensor(1.5783e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1618 of None
Current timestep = 1619. State = [[-0.33629075 -0.00416775]]. Action = [[-0.0354856   0.01902395  0.         -0.07621408]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 1619 is [True, False, False, False, True, False]
State prediction error at timestep 1619 is tensor(5.9026e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1619 of None
Current timestep = 1620. State = [[-0.3339712 -0.0034412]]. Action = [[ 0.08381989 -0.02907177  0.         -0.85217476]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 1620 is [True, False, False, False, True, False]
State prediction error at timestep 1620 is tensor(3.1267e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1620 of None
Current timestep = 1621. State = [[-0.32818377  0.0012094 ]]. Action = [[ 0.07775257  0.08091376  0.         -0.48135138]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 1621 is [True, False, False, False, True, False]
State prediction error at timestep 1621 is tensor(1.8535e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1621 of None
Current timestep = 1622. State = [[-0.3229942   0.00950091]]. Action = [[ 0.0661334   0.08933533  0.         -0.81101793]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 1622 is [True, False, False, False, True, False]
State prediction error at timestep 1622 is tensor(3.2444e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1622 of None
Current timestep = 1623. State = [[-0.31909794  0.01432922]]. Action = [[ 0.04264951  0.01147727  0.         -0.85353166]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 1623 is [True, False, False, False, True, False]
State prediction error at timestep 1623 is tensor(1.4397e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1623 of None
Current timestep = 1624. State = [[-0.31673387  0.01126834]]. Action = [[ 0.01028098 -0.09853955  0.         -0.73803717]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 1624 is [True, False, False, False, True, False]
State prediction error at timestep 1624 is tensor(3.2290e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1624 of None
Current timestep = 1625. State = [[-0.31387016  0.01003097]]. Action = [[ 0.02457152  0.01321409  0.         -0.3272258 ]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 1625 is [True, False, False, False, True, False]
State prediction error at timestep 1625 is tensor(2.5634e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1625 of None
Current timestep = 1626. State = [[-0.31060648  0.0094403 ]]. Action = [[ 0.02065052 -0.03146561  0.         -0.8763038 ]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 1626 is [True, False, False, False, True, False]
State prediction error at timestep 1626 is tensor(9.2773e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1626 of None
Current timestep = 1627. State = [[-0.30619943  0.00850841]]. Action = [[ 0.04090896 -0.00935759  0.          0.05188799]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 1627 is [True, False, False, False, True, False]
State prediction error at timestep 1627 is tensor(1.9429e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1627 of None
Current timestep = 1628. State = [[-0.30008027  0.00413479]]. Action = [[ 0.06036925 -0.08309539  0.         -0.82125866]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 1628 is [True, False, False, False, True, False]
State prediction error at timestep 1628 is tensor(2.5064e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1628 of None
Current timestep = 1629. State = [[-0.29489774  0.00089692]]. Action = [[ 0.02425084 -0.00848449  0.         -0.39107227]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 1629 is [True, False, False, False, True, False]
State prediction error at timestep 1629 is tensor(1.0386e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1629 of None
Current timestep = 1630. State = [[-0.29466838 -0.00196722]]. Action = [[-0.05923266 -0.03753477  0.         -0.3578285 ]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 1630 is [True, False, False, False, True, False]
State prediction error at timestep 1630 is tensor(1.7341e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1630 of None
Current timestep = 1631. State = [[-0.28993264 -0.00596785]]. Action = [[ 0.08959835 -0.04094351  0.         -0.4494791 ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 1631 is [True, False, False, False, True, False]
State prediction error at timestep 1631 is tensor(3.1123e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1631 of None
Current timestep = 1632. State = [[-0.2867061  -0.00970227]]. Action = [[-0.03217717 -0.02740645  0.         -0.59112406]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 1632 is [True, False, False, False, True, False]
State prediction error at timestep 1632 is tensor(1.7746e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1632 of None
Current timestep = 1633. State = [[-0.28107432 -0.0086189 ]]. Action = [[ 0.09232169  0.06127132  0.         -0.8850157 ]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 1633 is [True, False, False, False, True, False]
State prediction error at timestep 1633 is tensor(2.4704e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1633 of None
Current timestep = 1634. State = [[-0.2794213  -0.00310285]]. Action = [[-0.05197116  0.09033776  0.         -0.57275903]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 1634 is [True, False, False, False, True, False]
State prediction error at timestep 1634 is tensor(1.4056e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1634 of None
Current timestep = 1635. State = [[-0.275235   -0.00340054]]. Action = [[ 0.09661179 -0.05578804  0.         -0.6278969 ]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 1635 is [True, False, False, False, True, False]
State prediction error at timestep 1635 is tensor(3.8611e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1635 of None
Current timestep = 1636. State = [[-0.27221003 -0.00904494]]. Action = [[-0.0220826  -0.07533172  0.         -0.15493882]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 1636 is [True, False, False, False, True, False]
State prediction error at timestep 1636 is tensor(1.1510e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1636 of None
Current timestep = 1637. State = [[-0.26784328 -0.00842911]]. Action = [[ 0.07102174  0.06922332  0.         -0.31285155]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 1637 is [True, False, False, False, True, False]
State prediction error at timestep 1637 is tensor(4.0600e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1637 of None
Current timestep = 1638. State = [[-0.26712507 -0.00443579]]. Action = [[-0.04690771  0.04452623  0.         -0.3574785 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 1638 is [True, False, False, False, True, False]
State prediction error at timestep 1638 is tensor(5.9688e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1638 of None
Current timestep = 1639. State = [[-0.26282346 -0.00647008]]. Action = [[ 0.09978428 -0.07112168  0.         -0.4370368 ]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 1639 is [True, False, False, False, True, False]
State prediction error at timestep 1639 is tensor(4.5134e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1639 of None
Current timestep = 1640. State = [[-0.25544935 -0.00754625]]. Action = [[ 0.07147831  0.02150886  0.         -0.3007213 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 1640 is [True, False, False, False, True, False]
State prediction error at timestep 1640 is tensor(1.2352e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1640 of None
Current timestep = 1641. State = [[-0.24801537 -0.00654779]]. Action = [[ 0.08329988  0.01280143  0.         -0.63920933]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 1641 is [True, False, False, False, True, False]
State prediction error at timestep 1641 is tensor(2.1453e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1641 of None
Current timestep = 1642. State = [[-0.24019282 -0.00363344]]. Action = [[ 0.08472348  0.05277694  0.         -0.79683006]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 1642 is [True, False, False, False, True, False]
State prediction error at timestep 1642 is tensor(1.5573e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1642 of None
Current timestep = 1643. State = [[-2.3218159e-01  2.3854449e-05]]. Action = [[ 0.08807445  0.04153679  0.         -0.8552243 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 1643 is [True, False, False, False, True, False]
State prediction error at timestep 1643 is tensor(1.2521e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1643 of None
Current timestep = 1644. State = [[-0.22519185  0.00054324]]. Action = [[ 0.06133708 -0.01821168  0.         -0.80003357]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 1644 is [True, False, False, False, True, False]
State prediction error at timestep 1644 is tensor(1.0796e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1644 of None
Current timestep = 1645. State = [[-0.21672796 -0.00076929]]. Action = [[ 0.09841695 -0.01963865  0.         -0.7311405 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 1645 is [True, False, False, False, True, False]
State prediction error at timestep 1645 is tensor(2.7047e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1645 of None
Current timestep = 1646. State = [[-2.1197842e-01 -1.2301501e-04]]. Action = [[-0.00544076  0.02358498  0.         -0.84823257]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 1646 is [True, False, False, False, True, False]
State prediction error at timestep 1646 is tensor(1.0358e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1646 of None
Current timestep = 1647. State = [[-0.20599668 -0.00051752]]. Action = [[ 0.07541604 -0.024414    0.         -0.45978868]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 1647 is [True, False, False, False, True, False]
State prediction error at timestep 1647 is tensor(6.4051e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1647 of None
Current timestep = 1648. State = [[-0.19902997  0.00205809]]. Action = [[ 0.05241368  0.06286953  0.         -0.8480818 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 1648 is [True, False, False, False, True, False]
State prediction error at timestep 1648 is tensor(8.5191e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1648 of None
Current timestep = 1649. State = [[-0.1941107   0.00764973]]. Action = [[ 0.02523375  0.06938312  0.         -0.8499831 ]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 1649 is [True, False, False, False, True, False]
State prediction error at timestep 1649 is tensor(2.0354e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1649 of None
Current timestep = 1650. State = [[-0.19354619  0.01054952]]. Action = [[-0.04883651  0.00151292  0.         -0.7860339 ]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 1650 is [True, False, False, False, True, False]
State prediction error at timestep 1650 is tensor(2.8530e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1650 of None
Current timestep = 1651. State = [[-0.18945588  0.01401622]]. Action = [[ 0.06933381  0.0469811   0.         -0.88013697]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 1651 is [True, False, False, False, True, False]
State prediction error at timestep 1651 is tensor(1.0603e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1651 of None
Current timestep = 1652. State = [[-0.18106434  0.01929753]]. Action = [[ 0.09752681  0.05675072  0.         -0.9371519 ]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 1652 is [True, False, False, False, True, False]
State prediction error at timestep 1652 is tensor(2.2857e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1652 of None
Current timestep = 1653. State = [[-0.1785018   0.02238937]]. Action = [[-0.04441602  0.00337964  0.         -0.8585505 ]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 1653 is [True, False, False, False, True, False]
State prediction error at timestep 1653 is tensor(1.8030e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1653 of None
Current timestep = 1654. State = [[-0.17712237  0.02665006]]. Action = [[ 0.01827395  0.05360385  0.         -0.42771912]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 1654 is [True, False, False, False, True, False]
State prediction error at timestep 1654 is tensor(2.6288e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1654 of None
Current timestep = 1655. State = [[-0.17325996  0.02776952]]. Action = [[ 0.04165762 -0.0382336   0.         -0.79838973]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 1655 is [True, False, False, False, True, False]
State prediction error at timestep 1655 is tensor(3.9127e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1655 of None
Current timestep = 1656. State = [[-0.16707686  0.02604996]]. Action = [[ 0.07038554 -0.03688081  0.         -0.7869717 ]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 1656 is [True, False, False, False, True, False]
State prediction error at timestep 1656 is tensor(1.9321e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1656 of None
Current timestep = 1657. State = [[-0.16069703  0.02163264]]. Action = [[ 0.05251683 -0.07937521  0.         -0.72964275]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 1657 is [True, False, False, False, True, False]
State prediction error at timestep 1657 is tensor(4.3945e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1657 of None
Current timestep = 1658. State = [[-0.15320139  0.01828232]]. Action = [[ 0.07948964 -0.021679    0.         -0.61684215]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 1658 is [True, False, False, False, True, False]
State prediction error at timestep 1658 is tensor(1.7134e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1658 of None
Current timestep = 1659. State = [[-0.14432366  0.02171581]]. Action = [[ 0.09657379  0.09060266  0.         -0.20989233]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 1659 is [True, False, False, False, True, False]
State prediction error at timestep 1659 is tensor(1.2727e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1659 of None
Current timestep = 1660. State = [[-0.13529435  0.01939871]]. Action = [[ 0.09117358 -0.09094118  0.         -0.8396182 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 1660 is [True, False, False, False, True, False]
State prediction error at timestep 1660 is tensor(3.3407e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1660 of None
Current timestep = 1661. State = [[-0.12668797  0.01934082]]. Action = [[ 0.07898828  0.06408706  0.         -0.8880428 ]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 1661 is [True, False, False, False, True, False]
State prediction error at timestep 1661 is tensor(3.4341e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1661 of None
Current timestep = 1662. State = [[-0.12087274  0.02204718]]. Action = [[ 0.03051157  0.03179351  0.         -0.9364653 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 1662 is [True, False, False, False, True, False]
State prediction error at timestep 1662 is tensor(5.0584e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1662 of None
Current timestep = 1663. State = [[-0.11297938  0.01876758]]. Action = [[ 0.0967861  -0.07762703  0.         -0.71535385]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 1663 is [True, False, False, False, True, False]
State prediction error at timestep 1663 is tensor(2.6555e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1663 of None
Current timestep = 1664. State = [[-0.1037234   0.01476115]]. Action = [[ 0.08286267 -0.02220377  0.         -0.9024923 ]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 1664 is [True, False, False, False, True, False]
State prediction error at timestep 1664 is tensor(4.2010e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1664 of None
Current timestep = 1665. State = [[-0.09552611  0.0177312 ]]. Action = [[ 0.06809927  0.09080148  0.         -0.8703511 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 1665 is [True, False, False, False, True, False]
State prediction error at timestep 1665 is tensor(2.0866e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1665 of None
Current timestep = 1666. State = [[-0.08755176  0.02138435]]. Action = [[ 0.07680006  0.0308988   0.         -0.84049356]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 1666 is [True, False, False, False, True, False]
State prediction error at timestep 1666 is tensor(1.6225e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1666 of None
Current timestep = 1667. State = [[-0.0783779  0.0198742]]. Action = [[ 0.09410235 -0.04497167  0.         -0.76102376]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 1667 is [True, False, False, False, True, False]
State prediction error at timestep 1667 is tensor(2.0024e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1667 of None
Current timestep = 1668. State = [[-0.07105423  0.02071594]]. Action = [[ 0.04182125  0.04863573  0.         -0.8433583 ]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 1668 is [True, False, False, False, True, False]
State prediction error at timestep 1668 is tensor(1.1254e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1668 of None
Current timestep = 1669. State = [[-0.06648476  0.02049259]]. Action = [[ 0.01126856 -0.03056304  0.         -0.97069377]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 1669 is [True, False, False, False, True, False]
State prediction error at timestep 1669 is tensor(5.1517e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1669 of None
Current timestep = 1670. State = [[-0.06299644  0.01661311]]. Action = [[ 5.0415844e-04 -6.3578650e-02  0.0000000e+00 -8.2695711e-01]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 1670 is [True, False, False, False, True, False]
State prediction error at timestep 1670 is tensor(3.2637e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1670 of None
Current timestep = 1671. State = [[-0.05549435  0.01372973]]. Action = [[ 0.09088442 -0.01846872  0.         -0.83875513]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 1671 is [True, False, False, False, True, False]
State prediction error at timestep 1671 is tensor(2.3185e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1671 of None
Current timestep = 1672. State = [[-0.28295675  0.04075646]]. Action = [[ 0.0230919  -0.04735439  0.         -0.7055131 ]]. Reward = [100.]
Curr episode timestep = 264
Scene graph at timestep 1672 is [True, False, False, False, True, False]
State prediction error at timestep 1672 is tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1672 of None
Current timestep = 1673. State = [[-0.28413376  0.0353615 ]]. Action = [[-0.07328226 -0.0476846   0.         -0.80112505]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1673 is [True, False, False, False, True, False]
State prediction error at timestep 1673 is tensor(3.5258e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1673 of None
Current timestep = 1674. State = [[-0.28665677  0.03801249]]. Action = [[ 0.00353837  0.09666849  0.         -0.67772365]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1674 is [True, False, False, False, True, False]
State prediction error at timestep 1674 is tensor(1.7040e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1674 of None
Current timestep = 1675. State = [[-0.28712654  0.04424414]]. Action = [[ 0.01923192  0.07708216  0.         -0.7744042 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1675 is [True, False, False, False, True, False]
State prediction error at timestep 1675 is tensor(5.8815e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1675 of None
Current timestep = 1676. State = [[-0.29130313  0.04962454]]. Action = [[-0.06451903  0.05820759  0.         -0.46354973]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1676 is [True, False, False, False, True, False]
State prediction error at timestep 1676 is tensor(1.1619e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1676 of None
Current timestep = 1677. State = [[-0.2905508   0.05019481]]. Action = [[ 0.0848802  -0.03380442  0.         -0.091591  ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1677 is [True, False, False, False, True, False]
State prediction error at timestep 1677 is tensor(3.7685e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1677 of None
Current timestep = 1678. State = [[-0.28591204  0.04603922]]. Action = [[ 0.06751978 -0.07137451  0.         -0.8927261 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1678 is [True, False, False, False, True, False]
State prediction error at timestep 1678 is tensor(2.9492e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1678 of None
Current timestep = 1679. State = [[-0.280074    0.04037496]]. Action = [[ 0.07996029 -0.0712379   0.         -0.57330537]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1679 is [True, False, False, False, True, False]
State prediction error at timestep 1679 is tensor(5.1996e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1679 of None
Current timestep = 1680. State = [[-0.2736533   0.03746854]]. Action = [[ 0.07203568 -0.00747814  0.         -0.9745457 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1680 is [True, False, False, False, True, False]
State prediction error at timestep 1680 is tensor(5.1832e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1680 of None
Current timestep = 1681. State = [[-0.2746187   0.03850295]]. Action = [[-0.08771898  0.03553853  0.         -0.7283132 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 1681 is [True, False, False, False, True, False]
State prediction error at timestep 1681 is tensor(3.6591e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1681 of None
Current timestep = 1682. State = [[-0.27518559  0.04237318]]. Action = [[ 0.02652796  0.0620432   0.         -0.620378  ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 1682 is [True, False, False, False, True, False]
State prediction error at timestep 1682 is tensor(9.5381e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1682 of None
Current timestep = 1683. State = [[-0.27132013  0.04628229]]. Action = [[ 0.06587013  0.04464015  0.         -0.78176564]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1683 is [True, False, False, False, True, False]
State prediction error at timestep 1683 is tensor(1.8354e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1683 of None
Current timestep = 1684. State = [[-0.2676408   0.05056009]]. Action = [[ 0.03666935  0.05894949  0.         -0.7448701 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 1684 is [True, False, False, False, True, False]
State prediction error at timestep 1684 is tensor(9.9294e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1684 of None
Current timestep = 1685. State = [[-0.2643107   0.04880192]]. Action = [[ 0.0391274  -0.07461755  0.         -0.40704024]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 1685 is [True, False, False, False, True, False]
State prediction error at timestep 1685 is tensor(6.2501e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1685 of None
Current timestep = 1686. State = [[-0.2656009   0.04856697]]. Action = [[-0.06776907  0.03115182  0.         -0.7700919 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 1686 is [True, False, False, False, True, False]
State prediction error at timestep 1686 is tensor(1.5524e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1686 of None
Current timestep = 1687. State = [[-0.26727748  0.05226986]]. Action = [[-0.01137464  0.04734541  0.         -0.9698695 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 1687 is [True, False, False, False, True, False]
State prediction error at timestep 1687 is tensor(1.5699e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1687 of None
Current timestep = 1688. State = [[-0.27198055  0.05901311]]. Action = [[-0.0938884   0.09028421  0.         -0.567533  ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 1688 is [True, False, False, False, True, False]
State prediction error at timestep 1688 is tensor(1.1304e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1688 of None
Current timestep = 1689. State = [[-0.2738512   0.05939943]]. Action = [[ 0.01437788 -0.07163261  0.         -0.658916  ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 1689 is [True, False, False, False, True, False]
State prediction error at timestep 1689 is tensor(5.5471e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1689 of None
Current timestep = 1690. State = [[-0.2734117   0.05921738]]. Action = [[ 0.00077812  0.01483136  0.         -0.45691794]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 1690 is [True, False, False, False, True, False]
State prediction error at timestep 1690 is tensor(1.2629e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1690 of None
Current timestep = 1691. State = [[-0.27565745  0.06257147]]. Action = [[-0.0460951   0.04167456  0.         -0.6569721 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 1691 is [True, False, False, False, True, False]
State prediction error at timestep 1691 is tensor(1.0699e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1691 of None
Current timestep = 1692. State = [[-0.2771867   0.06890135]]. Action = [[ 0.00396688  0.0816607   0.         -0.4384622 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 1692 is [True, False, False, False, True, False]
State prediction error at timestep 1692 is tensor(3.5277e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1692 of None
Current timestep = 1693. State = [[-0.2775059   0.07273313]]. Action = [[ 0.00866449  0.00650449  0.         -0.21684283]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 1693 is [True, False, False, False, True, False]
State prediction error at timestep 1693 is tensor(1.7705e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1693 of None
Current timestep = 1694. State = [[-0.2801781  0.0764796]]. Action = [[-0.04557185  0.04628921  0.         -0.38653332]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 1694 is [True, False, False, False, True, False]
State prediction error at timestep 1694 is tensor(6.4283e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1694 of None
Current timestep = 1695. State = [[-0.27803585  0.07770023]]. Action = [[ 0.08618394 -0.02490616  0.         -0.09967303]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 1695 is [True, False, False, False, True, False]
State prediction error at timestep 1695 is tensor(2.6053e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1695 of None
Current timestep = 1696. State = [[-0.27183405  0.07473392]]. Action = [[ 0.08682162 -0.05936402  0.         -0.28481412]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 1696 is [True, False, False, False, True, False]
State prediction error at timestep 1696 is tensor(4.9029e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1696 of None
Current timestep = 1697. State = [[-0.26497427  0.07583116]]. Action = [[ 0.08498115  0.05385406  0.         -0.5652824 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 1697 is [True, False, False, False, True, False]
State prediction error at timestep 1697 is tensor(1.0821e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1697 of None
Current timestep = 1698. State = [[-0.25764933  0.07716634]]. Action = [[ 0.08977907 -0.00255025  0.         -0.84777635]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 1698 is [True, False, False, False, True, False]
State prediction error at timestep 1698 is tensor(6.9670e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1698 of None
Current timestep = 1699. State = [[-0.25205803  0.07300317]]. Action = [[ 0.03818346 -0.08252485  0.          0.03703737]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 1699 is [True, False, False, False, True, False]
State prediction error at timestep 1699 is tensor(1.3932e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1699 of None
Current timestep = 1700. State = [[-0.2487492   0.06721725]]. Action = [[ 0.0057864 -0.0653934  0.        -0.2415511]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 1700 is [True, False, False, False, True, False]
State prediction error at timestep 1700 is tensor(2.1710e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1700 of None
Current timestep = 1701. State = [[-0.24631973  0.0669409 ]]. Action = [[ 0.00320102  0.042414    0.         -0.6508081 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 1701 is [True, False, False, False, True, False]
State prediction error at timestep 1701 is tensor(1.2686e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1701 of None
Current timestep = 1702. State = [[-0.24054448  0.0656857 ]]. Action = [[ 0.0785225  -0.03690835  0.         -0.7122679 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 1702 is [True, False, False, False, True, False]
State prediction error at timestep 1702 is tensor(1.0803e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1702 of None
Current timestep = 1703. State = [[-0.2341961   0.06817253]]. Action = [[ 0.0493095   0.08633279  0.         -0.51743555]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 1703 is [True, False, False, False, True, False]
State prediction error at timestep 1703 is tensor(9.7782e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1703 of None
Current timestep = 1704. State = [[-0.23202531  0.07378916]]. Action = [[-0.01337463  0.07465754  0.         -0.4596874 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 1704 is [True, False, False, False, True, False]
State prediction error at timestep 1704 is tensor(3.6427e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1704 of None
Current timestep = 1705. State = [[-0.2282132   0.07389915]]. Action = [[ 0.05861118 -0.041881    0.         -0.71099573]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 1705 is [True, False, False, False, True, False]
State prediction error at timestep 1705 is tensor(1.0719e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1705 of None
Current timestep = 1706. State = [[-0.22210371  0.07204424]]. Action = [[ 0.0615276  -0.01302437  0.         -0.16466498]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 1706 is [True, False, False, False, True, False]
State prediction error at timestep 1706 is tensor(2.8780e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1706 of None
Current timestep = 1707. State = [[-0.21563281  0.07471132]]. Action = [[ 0.06571471  0.06604176  0.         -0.73285365]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 1707 is [True, False, False, False, True, False]
State prediction error at timestep 1707 is tensor(6.5860e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1707 of None
Current timestep = 1708. State = [[-0.2114477   0.07548775]]. Action = [[ 0.0177145  -0.02219344  0.         -0.81022346]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 1708 is [True, False, False, False, True, False]
State prediction error at timestep 1708 is tensor(1.7933e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1708 of None
Current timestep = 1709. State = [[-0.20552169  0.07905549]]. Action = [[0.07867935 0.08032412 0.         0.02529085]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 1709 is [True, False, False, False, True, False]
State prediction error at timestep 1709 is tensor(7.3926e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1709 of None
Current timestep = 1710. State = [[-0.19998859  0.07808587]]. Action = [[ 0.0373121 -0.0697156  0.        -0.8838999]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 1710 is [True, False, False, False, True, False]
State prediction error at timestep 1710 is tensor(8.9609e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1710 of None
Current timestep = 1711. State = [[-0.19511357  0.07307814]]. Action = [[ 0.03431391 -0.06754814  0.         -0.7167374 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 1711 is [True, False, False, False, True, False]
State prediction error at timestep 1711 is tensor(4.9034e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1711 of None
Current timestep = 1712. State = [[-0.18842223  0.0688681 ]]. Action = [[ 0.06822378 -0.04276764  0.         -0.8137904 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 1712 is [True, False, False, False, True, False]
State prediction error at timestep 1712 is tensor(5.4099e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1712 of None
Current timestep = 1713. State = [[-0.18468894  0.0707431 ]]. Action = [[-0.01084477  0.07002831  0.         -0.05239719]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 1713 is [True, False, False, False, True, False]
State prediction error at timestep 1713 is tensor(4.5787e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1713 of None
Current timestep = 1714. State = [[-0.18651143  0.06861597]]. Action = [[-0.08139788 -0.08490393  0.         -0.696811  ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 1714 is [True, False, False, False, True, False]
State prediction error at timestep 1714 is tensor(1.2018e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1714 of None
Current timestep = 1715. State = [[-0.18337059  0.06195351]]. Action = [[ 0.06571689 -0.08738645  0.         -0.56102246]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 1715 is [True, False, False, False, True, False]
State prediction error at timestep 1715 is tensor(2.7160e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1715 of None
Current timestep = 1716. State = [[-0.17644821  0.05553998]]. Action = [[ 0.05704997 -0.06301095  0.         -0.58080816]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 1716 is [True, False, False, False, True, False]
State prediction error at timestep 1716 is tensor(3.5738e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1716 of None
Current timestep = 1717. State = [[-0.16896348  0.05588783]]. Action = [[ 0.07513412  0.06851494  0.         -0.5490934 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 1717 is [True, False, False, False, True, False]
State prediction error at timestep 1717 is tensor(1.4857e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1717 of None
Current timestep = 1718. State = [[-0.16162474  0.05684033]]. Action = [[ 0.07182471  0.00418737  0.         -0.6338285 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 1718 is [True, False, False, False, True, False]
State prediction error at timestep 1718 is tensor(1.9058e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1718 of None
Current timestep = 1719. State = [[-0.1551968   0.05597356]]. Action = [[ 5.4696076e-02 -5.7607889e-05  0.0000000e+00 -8.3559591e-01]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 1719 is [True, False, False, False, True, False]
State prediction error at timestep 1719 is tensor(3.5677e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1719 of None
Current timestep = 1720. State = [[-0.15309808  0.05208251]]. Action = [[-0.02740645 -0.06009151  0.         -0.8782302 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 1720 is [True, False, False, False, True, False]
State prediction error at timestep 1720 is tensor(5.6494e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1720 of None
Current timestep = 1721. State = [[-0.15134557  0.05364834]]. Action = [[ 0.01408078  0.08125822  0.         -0.8359201 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 1721 is [True, False, False, False, True, False]
State prediction error at timestep 1721 is tensor(4.4809e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1721 of None
Current timestep = 1722. State = [[-0.1473827   0.05947341]]. Action = [[ 0.05234838  0.08011901  0.         -0.8563082 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 1722 is [True, False, False, False, True, False]
State prediction error at timestep 1722 is tensor(5.7622e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1722 of None
Current timestep = 1723. State = [[-0.14103967  0.06390204]]. Action = [[ 0.08737027  0.04288905  0.         -0.27130115]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 1723 is [True, False, False, False, True, False]
State prediction error at timestep 1723 is tensor(1.1525e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1723 of None
Current timestep = 1724. State = [[-0.13366129  0.06226039]]. Action = [[ 0.08515895 -0.0593267   0.         -0.01109344]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 1724 is [True, False, False, False, True, False]
State prediction error at timestep 1724 is tensor(5.4813e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1724 of None
Current timestep = 1725. State = [[-0.12535794  0.06361515]]. Action = [[ 0.09708088  0.06405646  0.         -0.66150177]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 1725 is [True, False, False, False, True, False]
State prediction error at timestep 1725 is tensor(2.6274e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1725 of None
Current timestep = 1726. State = [[-0.11661448  0.06587062]]. Action = [[ 0.09920441  0.01368304  0.         -0.86024415]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 1726 is [True, False, False, False, True, False]
State prediction error at timestep 1726 is tensor(1.9046e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1726 of None
Current timestep = 1727. State = [[-0.113424    0.06870487]]. Action = [[-0.02519943  0.04651833  0.         -0.312806  ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 1727 is [True, False, False, False, True, False]
State prediction error at timestep 1727 is tensor(7.4935e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1727 of None
Current timestep = 1728. State = [[-0.10777581  0.07226861]]. Action = [[ 0.09941635  0.03663514  0.         -0.79094756]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 1728 is [True, False, False, False, True, False]
State prediction error at timestep 1728 is tensor(9.3910e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1728 of None
Current timestep = 1729. State = [[-0.10043335  0.0697943 ]]. Action = [[ 0.05980393 -0.08027185  0.         -0.605449  ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 1729 is [True, False, False, False, True, False]
State prediction error at timestep 1729 is tensor(1.5009e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1729 of None
Current timestep = 1730. State = [[-0.09430915  0.06647972]]. Action = [[ 0.04175606 -0.02700537  0.         -0.84627867]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 1730 is [True, False, False, False, True, False]
State prediction error at timestep 1730 is tensor(5.3680e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1730 of None
Current timestep = 1731. State = [[-0.08664674  0.06473765]]. Action = [[ 0.08009882 -0.01852815  0.         -0.943528  ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 1731 is [True, False, False, False, True, False]
State prediction error at timestep 1731 is tensor(3.3684e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1731 of None
Current timestep = 1732. State = [[-0.08278552  0.0597122 ]]. Action = [[-0.0273492  -0.08822489  0.         -0.84670913]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 1732 is [True, False, False, False, True, False]
State prediction error at timestep 1732 is tensor(4.1895e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1732 of None
Current timestep = 1733. State = [[-0.07900649  0.05622024]]. Action = [[ 0.02703578 -0.01437565  0.         -0.80894196]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 1733 is [True, False, False, False, True, False]
State prediction error at timestep 1733 is tensor(2.5414e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1733 of None
Current timestep = 1734. State = [[-0.07325014  0.05565635]]. Action = [[ 0.0472954   0.00923711  0.         -0.9525043 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 1734 is [True, False, False, False, True, False]
State prediction error at timestep 1734 is tensor(1.7564e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1734 of None
Current timestep = 1735. State = [[-0.06476422  0.05413339]]. Action = [[ 0.09691853 -0.02208056  0.         -0.9540326 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 1735 is [True, False, False, False, True, False]
State prediction error at timestep 1735 is tensor(3.3999e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1735 of None
Current timestep = 1736. State = [[-0.05605804  0.04973467]]. Action = [[ 0.07488558 -0.05619976  0.         -0.9466437 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 1736 is [True, False, False, False, True, False]
State prediction error at timestep 1736 is tensor(2.7515e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1736 of None
Current timestep = 1737. State = [[-0.05169939  0.04417126]]. Action = [[-0.00834543 -0.05556078  0.         -0.9153796 ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 1737 is [True, False, False, False, True, False]
State prediction error at timestep 1737 is tensor(4.5485e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1737 of None
Current timestep = 1738. State = [[-0.2436235   0.22927436]]. Action = [[ 0.09435476  0.01356646  0.         -0.89737916]]. Reward = [100.]
Curr episode timestep = 65
Scene graph at timestep 1738 is [True, False, False, False, False, True]
State prediction error at timestep 1738 is tensor(0.0349, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1738 of None
Current timestep = 1739. State = [[-0.23984715  0.22433415]]. Action = [[ 0.03309176 -0.06696457  0.         -0.5584903 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1739 is [True, False, False, False, False, True]
State prediction error at timestep 1739 is tensor(2.5000e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1739 of None
Current timestep = 1740. State = [[-0.23646997  0.2203467 ]]. Action = [[ 0.02521653 -0.05615305  0.         -0.25845784]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1740 is [True, False, False, False, False, True]
State prediction error at timestep 1740 is tensor(4.0021e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1740 of None
Current timestep = 1741. State = [[-0.23213443  0.21684787]]. Action = [[ 0.04196151 -0.0454474   0.          0.02392888]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1741 is [True, False, False, False, False, True]
State prediction error at timestep 1741 is tensor(7.2124e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1741 of None
Current timestep = 1742. State = [[-0.2268165  0.2145018]]. Action = [[ 0.04744909 -0.01890571  0.         -0.2289741 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1742 is [True, False, False, False, False, True]
State prediction error at timestep 1742 is tensor(3.8526e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1742 of None
Current timestep = 1743. State = [[-0.22176099  0.21171625]]. Action = [[ 0.03566801 -0.03592521  0.         -0.6957123 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1743 is [True, False, False, False, False, True]
State prediction error at timestep 1743 is tensor(1.6478e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1743 of None
Current timestep = 1744. State = [[-0.21478793  0.20612447]]. Action = [[ 0.07671688 -0.07694276  0.         -0.31303108]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1744 is [True, False, False, False, False, True]
State prediction error at timestep 1744 is tensor(7.7566e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1744 of None
Current timestep = 1745. State = [[-0.2086797   0.20620151]]. Action = [[0.03535805 0.07273252 0.         0.4261303 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1745 is [True, False, False, False, False, True]
State prediction error at timestep 1745 is tensor(2.9404e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1745 of None
Current timestep = 1746. State = [[-0.20178875  0.20521072]]. Action = [[ 0.08093139 -0.03276385  0.         -0.20245183]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1746 is [True, False, False, False, False, True]
State prediction error at timestep 1746 is tensor(4.7752e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1746 of None
Current timestep = 1747. State = [[-0.1987698   0.20263432]]. Action = [[-0.0270926  -0.01148713  0.         -0.16374683]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 1747 is [True, False, False, False, False, True]
State prediction error at timestep 1747 is tensor(9.9550e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1747 of None
Current timestep = 1748. State = [[-0.19384764  0.19912803]]. Action = [[ 0.07348443 -0.04446283  0.         -0.2809378 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 1748 is [True, False, False, False, False, True]
State prediction error at timestep 1748 is tensor(4.1577e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1748 of None
Current timestep = 1749. State = [[-0.18568929  0.19403681]]. Action = [[ 0.08391192 -0.04965702  0.         -0.632849  ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1749 is [True, False, False, False, False, True]
State prediction error at timestep 1749 is tensor(3.6191e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1749 of None
Current timestep = 1750. State = [[-0.17655826  0.18835174]]. Action = [[ 0.09128682 -0.05105707  0.         -0.39308524]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 1750 is [True, False, False, False, False, True]
State prediction error at timestep 1750 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1750 of None
Current timestep = 1751. State = [[-0.1678819   0.18532363]]. Action = [[ 0.07536588  0.0086294   0.         -0.7117629 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 1751 is [True, False, False, False, False, True]
State prediction error at timestep 1751 is tensor(1.9918e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1751 of None
Current timestep = 1752. State = [[-0.16542083  0.18312499]]. Action = [[-0.04449433 -0.01557139  0.         -0.6173587 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 1752 is [True, False, False, False, False, True]
State prediction error at timestep 1752 is tensor(3.4970e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1752 of None
Current timestep = 1753. State = [[-0.16080151  0.17771709]]. Action = [[ 0.07327572 -0.07420906  0.          0.5114329 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 1753 is [True, False, False, False, False, True]
State prediction error at timestep 1753 is tensor(6.8411e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1753 of None
Current timestep = 1754. State = [[-0.15873237  0.17685713]]. Action = [[-0.03914407  0.05539382  0.         -0.6486526 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 1754 is [True, False, False, False, False, True]
State prediction error at timestep 1754 is tensor(6.5000e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1754 of None
Current timestep = 1755. State = [[-0.15353364  0.17443927]]. Action = [[ 0.09469566 -0.0572364   0.         -0.8951523 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 1755 is [True, False, False, False, False, True]
State prediction error at timestep 1755 is tensor(1.4451e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1755 of None
Current timestep = 1756. State = [[-0.14503717  0.16967   ]]. Action = [[ 0.08749082 -0.0349444   0.         -0.6028179 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 1756 is [True, False, False, False, False, True]
State prediction error at timestep 1756 is tensor(3.9090e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1756 of None
Current timestep = 1757. State = [[-0.13625042  0.16269983]]. Action = [[ 0.0884442  -0.08405095  0.         -0.5768473 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 1757 is [True, False, False, False, False, True]
State prediction error at timestep 1757 is tensor(6.7916e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1757 of None
Current timestep = 1758. State = [[-0.13072594  0.15718292]]. Action = [[ 0.01494877 -0.02494202  0.         -0.50668067]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 1758 is [True, False, False, False, False, True]
State prediction error at timestep 1758 is tensor(5.4305e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1758 of None
Current timestep = 1759. State = [[-0.12494686  0.15262014]]. Action = [[ 0.0616898  -0.03986218  0.         -0.90288126]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 1759 is [True, False, False, False, False, True]
State prediction error at timestep 1759 is tensor(2.5827e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1759 of None
Current timestep = 1760. State = [[-0.11942986  0.1495689 ]]. Action = [[ 3.3287145e-02 -5.0304830e-04  0.0000000e+00 -7.9187071e-01]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 1760 is [True, False, False, False, False, True]
State prediction error at timestep 1760 is tensor(3.2766e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1760 of None
Current timestep = 1761. State = [[-0.11221518  0.14637569]]. Action = [[ 0.0861763  -0.0259764   0.         -0.13760573]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 1761 is [True, False, False, False, False, True]
State prediction error at timestep 1761 is tensor(1.4834e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1761 of None
Current timestep = 1762. State = [[-0.10319089  0.14302048]]. Action = [[ 0.09533388 -0.01180375  0.         -0.6936704 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 1762 is [True, False, False, False, False, True]
State prediction error at timestep 1762 is tensor(3.2380e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1762 of None
Current timestep = 1763. State = [[-0.09444351  0.13711405]]. Action = [[ 0.08037389 -0.06937788  0.         -0.88477194]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 1763 is [True, False, False, False, False, True]
State prediction error at timestep 1763 is tensor(5.5408e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1763 of None
Current timestep = 1764. State = [[-0.08867388  0.13066188]]. Action = [[ 0.02109213 -0.04866524  0.         -0.93793947]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 1764 is [True, False, False, False, False, True]
State prediction error at timestep 1764 is tensor(6.6786e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1764 of None
Current timestep = 1765. State = [[-0.08220362  0.12598075]]. Action = [[ 0.06741764 -0.02510997  0.         -0.79417276]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 1765 is [True, False, False, False, False, True]
State prediction error at timestep 1765 is tensor(7.5308e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1765 of None
Current timestep = 1766. State = [[-0.07350866  0.1188555 ]]. Action = [[ 0.08882446 -0.08522927  0.         -0.13814944]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 1766 is [True, False, False, False, True, False]
State prediction error at timestep 1766 is tensor(2.4348e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1766 of None
Current timestep = 1767. State = [[-0.06540523  0.10951551]]. Action = [[ 0.05884107 -0.09121121  0.         -0.78549224]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 1767 is [True, False, False, False, True, False]
State prediction error at timestep 1767 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1767 of None
Current timestep = 1768. State = [[-0.05698023  0.10732117]]. Action = [[ 0.08302874  0.06252385  0.         -0.502116  ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 1768 is [True, False, False, False, True, False]
State prediction error at timestep 1768 is tensor(3.8181e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1768 of None
Current timestep = 1769. State = [[-0.09835657  0.01984044]]. Action = [[ 0.0904263   0.00125293  0.         -0.87841773]]. Reward = [100.]
Curr episode timestep = 30
Scene graph at timestep 1769 is [True, False, False, False, True, False]
State prediction error at timestep 1769 is tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1769 of None
Current timestep = 1770. State = [[-0.09755748  0.02070084]]. Action = [[ 0.05275465 -0.02642842  0.         -0.7492621 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1770 is [True, False, False, False, True, False]
State prediction error at timestep 1770 is tensor(5.6262e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1770 of None
Current timestep = 1771. State = [[-0.09522039  0.02144944]]. Action = [[ 0.00436926  0.03832377  0.         -0.9210421 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1771 is [True, False, False, False, True, False]
State prediction error at timestep 1771 is tensor(6.9497e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1771 of None
Current timestep = 1772. State = [[-0.09247868  0.01874485]]. Action = [[ 0.03883903 -0.06793281  0.         -0.8481617 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1772 is [True, False, False, False, True, False]
State prediction error at timestep 1772 is tensor(3.1419e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1772 of None
Current timestep = 1773. State = [[-0.08705529  0.01647364]]. Action = [[ 0.07668973  0.00678667  0.         -0.943974  ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1773 is [True, False, False, False, True, False]
State prediction error at timestep 1773 is tensor(9.5561e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1773 of None
Current timestep = 1774. State = [[-0.07997543  0.013744  ]]. Action = [[ 0.09160312 -0.03857423  0.         -0.14034313]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1774 is [True, False, False, False, True, False]
State prediction error at timestep 1774 is tensor(8.7718e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1774 of None
Current timestep = 1775. State = [[-0.0725705   0.00848698]]. Action = [[ 0.08434374 -0.05901128  0.         -0.72236776]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1775 is [True, False, False, False, True, False]
State prediction error at timestep 1775 is tensor(5.6559e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1775 of None
Current timestep = 1776. State = [[-0.06723759  0.00329072]]. Action = [[ 0.0376467  -0.03912612  0.         -0.6155642 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1776 is [True, False, False, False, True, False]
State prediction error at timestep 1776 is tensor(4.0439e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1776 of None
Current timestep = 1777. State = [[-0.06045488 -0.00046171]]. Action = [[ 0.0897489  -0.01787953  0.         -0.94684696]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1777 is [True, False, False, False, True, False]
State prediction error at timestep 1777 is tensor(1.9424e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1777 of None
Current timestep = 1778. State = [[-0.05495013  0.00028044]]. Action = [[ 0.03591975  0.06024749  0.         -0.4505434 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 1778 is [True, False, False, False, True, False]
State prediction error at timestep 1778 is tensor(2.8033e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1778 of None
Current timestep = 1779. State = [[-0.05523736  0.00389858]]. Action = [[-0.05696688  0.06052985  0.         -0.81554776]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 1779 is [True, False, False, False, True, False]
State prediction error at timestep 1779 is tensor(2.0866e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1779 of None
Current timestep = 1780. State = [[-0.05113478  0.00841683]]. Action = [[ 0.09964075  0.06158329  0.         -0.7652651 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1780 is [True, False, False, False, True, False]
State prediction error at timestep 1780 is tensor(3.5895e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1780 of None
Current timestep = 1781. State = [[-0.2815593 -0.1490383]]. Action = [[ 0.05907064  0.08270202  0.         -0.75670606]]. Reward = [100.]
Curr episode timestep = 11
Scene graph at timestep 1781 is [True, False, False, True, False, False]
State prediction error at timestep 1781 is tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1781 of None
Current timestep = 1782. State = [[-0.2878091  -0.14006086]]. Action = [[-0.01842211  0.08583543  0.         -0.5729357 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1782 is [True, False, False, True, False, False]
State prediction error at timestep 1782 is tensor(7.9344e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1782 of None
Current timestep = 1783. State = [[-0.28979284 -0.13223979]]. Action = [[ 0.03867579  0.06148899  0.         -0.1876607 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1783 is [True, False, False, True, False, False]
State prediction error at timestep 1783 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1783 of None
Current timestep = 1784. State = [[-0.28756043 -0.12766908]]. Action = [[ 0.08389056  0.00204317  0.         -0.6473361 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1784 is [True, False, False, True, False, False]
State prediction error at timestep 1784 is tensor(1.7790e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1784 of None
Current timestep = 1785. State = [[-0.291359   -0.12189332]]. Action = [[-0.081562    0.07186205  0.         -0.931586  ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1785 is [True, False, False, False, True, False]
State prediction error at timestep 1785 is tensor(1.8784e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1785 of None
Current timestep = 1786. State = [[-0.2978495  -0.11786293]]. Action = [[-0.02479463 -0.00346401  0.         -0.817105  ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1786 is [True, False, False, False, True, False]
State prediction error at timestep 1786 is tensor(1.5974e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1786 of None
Current timestep = 1787. State = [[-0.30585667 -0.12056321]]. Action = [[-0.09059093 -0.09216173  0.         -0.6598932 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1787 is [True, False, False, False, True, False]
State prediction error at timestep 1787 is tensor(6.6810e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1787 of None
Current timestep = 1788. State = [[-0.3064421  -0.11875362]]. Action = [[ 0.09617456  0.08313086  0.         -0.9631319 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1788 is [True, False, False, False, True, False]
State prediction error at timestep 1788 is tensor(1.8427e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1788 of None
Current timestep = 1789. State = [[-0.30601257 -0.11077601]]. Action = [[-0.00858521  0.08299454  0.         -0.57811314]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1789 is [True, False, False, False, True, False]
State prediction error at timestep 1789 is tensor(4.4140e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1789 of None
Current timestep = 1790. State = [[-0.30300122 -0.1089056 ]]. Action = [[ 0.09622141 -0.05003905  0.         -0.8081058 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 1790 is [True, False, False, False, True, False]
State prediction error at timestep 1790 is tensor(8.0444e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1790 of None
Current timestep = 1791. State = [[-0.29632148 -0.11246215]]. Action = [[ 0.09166748 -0.07487074  0.         -0.6785058 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 1791 is [True, False, False, False, True, False]
State prediction error at timestep 1791 is tensor(2.8371e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1791 of None
Current timestep = 1792. State = [[-0.29484165 -0.11805507]]. Action = [[-0.03218242 -0.08108553  0.          0.01271915]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1792 is [True, False, False, False, True, False]
State prediction error at timestep 1792 is tensor(1.2852e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1792 of None
Current timestep = 1793. State = [[-0.2985793  -0.11746309]]. Action = [[-0.07450239  0.06798013  0.         -0.55064833]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 1793 is [True, False, False, False, True, False]
State prediction error at timestep 1793 is tensor(1.0097e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1793 of None
Current timestep = 1794. State = [[-0.29785737 -0.11814207]]. Action = [[ 0.05624536 -0.04654605  0.         -0.82665   ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 1794 is [True, False, False, False, True, False]
State prediction error at timestep 1794 is tensor(1.7558e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1794 of None
Current timestep = 1795. State = [[-0.2956395  -0.11665821]]. Action = [[-0.00158801  0.06294505  0.         -0.8157243 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 1795 is [True, False, False, False, True, False]
State prediction error at timestep 1795 is tensor(1.6623e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1795 of None
Current timestep = 1796. State = [[-0.29213277 -0.1157001 ]]. Action = [[ 0.05491026 -0.01112531  0.         -0.44309914]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 1796 is [True, False, False, False, True, False]
State prediction error at timestep 1796 is tensor(4.4698e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1796 of None
Current timestep = 1797. State = [[-0.28866655 -0.11333123]]. Action = [[ 0.02296343  0.05384643  0.         -0.5378617 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 1797 is [True, False, False, False, True, False]
State prediction error at timestep 1797 is tensor(8.0298e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1797 of None
Current timestep = 1798. State = [[-0.28651455 -0.11564268]]. Action = [[ 0.01354922 -0.07679864  0.         -0.80259836]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 1798 is [True, False, False, False, True, False]
State prediction error at timestep 1798 is tensor(4.1811e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1798 of None
Current timestep = 1799. State = [[-0.2821362 -0.1171253]]. Action = [[ 0.06172613  0.01790416  0.         -0.82472545]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 1799 is [True, False, False, False, True, False]
State prediction error at timestep 1799 is tensor(1.5860e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1799 of None
Current timestep = 1800. State = [[-0.28203502 -0.11546529]]. Action = [[-0.05264686  0.02968473  0.         -0.06721246]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 1800 is [True, False, False, False, True, False]
State prediction error at timestep 1800 is tensor(3.4432e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1800 of None
Current timestep = 1801. State = [[-0.28567588 -0.11195721]]. Action = [[-0.06121346  0.05933806  0.         -0.4776345 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 1801 is [True, False, False, False, True, False]
State prediction error at timestep 1801 is tensor(1.8278e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1801 of None
Current timestep = 1802. State = [[-0.28758195 -0.11318872]]. Action = [[-0.01255842 -0.05826547  0.         -0.31363082]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 1802 is [True, False, False, False, True, False]
State prediction error at timestep 1802 is tensor(1.4070e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1802 of None
Current timestep = 1803. State = [[-0.28702596 -0.11627214]]. Action = [[ 0.0086786  -0.02811949  0.         -0.69296694]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 1803 is [True, False, False, False, True, False]
State prediction error at timestep 1803 is tensor(1.1146e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1803 of None
Current timestep = 1804. State = [[-0.28886446 -0.11739641]]. Action = [[-5.4927673e-02 -7.4761361e-04  0.0000000e+00 -8.8060617e-01]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 1804 is [True, False, False, False, True, False]
State prediction error at timestep 1804 is tensor(3.6187e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1804 of None
Current timestep = 1805. State = [[-0.28636834 -0.11649942]]. Action = [[ 0.07380081  0.021306    0.         -0.5467979 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 1805 is [True, False, False, False, True, False]
State prediction error at timestep 1805 is tensor(3.3900e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1805 of None
Current timestep = 1806. State = [[-0.28635016 -0.11440924]]. Action = [[-0.04734612  0.02678973  0.         -0.51199645]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 1806 is [True, False, False, False, True, False]
State prediction error at timestep 1806 is tensor(3.8876e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1806 of None
Current timestep = 1807. State = [[-0.2837506  -0.11262846]]. Action = [[ 0.07715242  0.01467578  0.         -0.74130213]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 1807 is [True, False, False, False, True, False]
State prediction error at timestep 1807 is tensor(3.4482e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1807 of None
Current timestep = 1808. State = [[-0.28339192 -0.11184904]]. Action = [[-0.03754959 -0.00117917  0.         -0.7551015 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 1808 is [True, False, False, False, True, False]
State prediction error at timestep 1808 is tensor(2.5196e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1808 of None
Current timestep = 1809. State = [[-0.2839942  -0.10741147]]. Action = [[ 0.00699542  0.08463041  0.         -0.4297595 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 1809 is [True, False, False, False, True, False]
State prediction error at timestep 1809 is tensor(2.6373e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1809 of None
Current timestep = 1810. State = [[-0.2877662 -0.1071821]]. Action = [[-0.07755281 -0.05553168  0.         -0.6759834 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 1810 is [True, False, False, False, True, False]
State prediction error at timestep 1810 is tensor(2.1570e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1810 of None
Current timestep = 1811. State = [[-0.2869853  -0.10828747]]. Action = [[ 0.06335574  0.00191108  0.         -0.7104488 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 1811 is [True, False, False, False, True, False]
State prediction error at timestep 1811 is tensor(2.8036e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1811 of None
Current timestep = 1812. State = [[-0.2880784  -0.10521829]]. Action = [[-0.05487019  0.05427705  0.          0.09820938]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 1812 is [True, False, False, False, True, False]
State prediction error at timestep 1812 is tensor(2.3440e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1812 of None
Current timestep = 1813. State = [[-0.28606498 -0.10462391]]. Action = [[ 0.08284376 -0.0333394   0.         -0.5017679 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 1813 is [True, False, False, False, True, False]
State prediction error at timestep 1813 is tensor(1.5472e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1813 of None
Current timestep = 1814. State = [[-0.28392652 -0.10207213]]. Action = [[-0.00131704  0.05787624  0.         -0.82913315]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 1814 is [True, False, False, False, True, False]
State prediction error at timestep 1814 is tensor(1.1130e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1814 of None
Current timestep = 1815. State = [[-0.2821778  -0.10160276]]. Action = [[ 0.03604389 -0.03490816  0.         -0.75467485]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 1815 is [True, False, False, False, True, False]
State prediction error at timestep 1815 is tensor(2.7866e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1815 of None
Current timestep = 1816. State = [[-0.27676794 -0.0988495 ]]. Action = [[ 0.09074233  0.06121761  0.         -0.66479677]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 1816 is [True, False, False, False, True, False]
State prediction error at timestep 1816 is tensor(1.9482e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1816 of None
Current timestep = 1817. State = [[-0.2711895  -0.10076292]]. Action = [[ 0.06018043 -0.08893728  0.         -0.64356107]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 1817 is [True, False, False, False, True, False]
State prediction error at timestep 1817 is tensor(1.8579e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1817 of None
Current timestep = 1818. State = [[-0.2720336  -0.10368676]]. Action = [[-0.07026514 -0.0102787   0.         -0.5381656 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 1818 is [True, False, False, False, True, False]
State prediction error at timestep 1818 is tensor(1.4947e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1818 of None
Current timestep = 1819. State = [[-0.27834478 -0.09947599]]. Action = [[-0.09874985  0.09770902  0.          0.17209446]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 1819 is [True, False, False, False, True, False]
State prediction error at timestep 1819 is tensor(3.9950e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1819 of None
Current timestep = 1820. State = [[-0.27843723 -0.09852391]]. Action = [[ 0.06813201 -0.04476867  0.         -0.18503672]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 1820 is [True, False, False, False, True, False]
State prediction error at timestep 1820 is tensor(3.2477e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1820 of None
Current timestep = 1821. State = [[-0.27825603 -0.09791989]]. Action = [[-0.04736303  0.03470541  0.         -0.76785135]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 1821 is [True, False, False, False, True, False]
State prediction error at timestep 1821 is tensor(2.3559e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1821 of None
Current timestep = 1822. State = [[-0.2744684  -0.10045859]]. Action = [[ 0.0932044  -0.07383949  0.         -0.28790236]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 1822 is [True, False, False, False, True, False]
State prediction error at timestep 1822 is tensor(8.2615e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1822 of None
Current timestep = 1823. State = [[-0.26601616 -0.10446534]]. Action = [[ 0.09685073 -0.03725599  0.         -0.8590472 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 1823 is [True, False, False, False, True, False]
State prediction error at timestep 1823 is tensor(4.3935e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1823 of None
Current timestep = 1824. State = [[-0.2578483  -0.10502578]]. Action = [[ 0.08001509  0.0167551   0.         -0.91127473]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 1824 is [True, False, False, False, True, False]
State prediction error at timestep 1824 is tensor(2.8462e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1824 of None
Current timestep = 1825. State = [[-0.24949963 -0.10827655]]. Action = [[ 0.09145106 -0.06778525  0.         -0.9494584 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 1825 is [True, False, False, False, True, False]
State prediction error at timestep 1825 is tensor(4.7997e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1825 of None
Current timestep = 1826. State = [[-0.24111003 -0.10799386]]. Action = [[ 0.08312098  0.05502728  0.         -0.7732617 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 1826 is [True, False, False, False, True, False]
State prediction error at timestep 1826 is tensor(2.8144e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1826 of None
Current timestep = 1827. State = [[-0.23418814 -0.10243751]]. Action = [[0.0625328  0.08981194 0.         0.13353443]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 1827 is [True, False, False, False, True, False]
State prediction error at timestep 1827 is tensor(2.3584e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1827 of None
Current timestep = 1828. State = [[-0.22747304 -0.10008551]]. Action = [[ 0.07309426 -0.00462055  0.         -0.532084  ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 1828 is [True, False, False, False, True, False]
State prediction error at timestep 1828 is tensor(2.3425e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1828 of None
Current timestep = 1829. State = [[-0.22628091 -0.10183021]]. Action = [[-0.05264845 -0.03281392  0.         -0.68304   ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 1829 is [True, False, False, False, True, False]
State prediction error at timestep 1829 is tensor(7.5876e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1829 of None
Current timestep = 1830. State = [[-0.2216232  -0.10105135]]. Action = [[ 0.0876791   0.03726623  0.         -0.64262164]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 1830 is [True, False, False, False, True, False]
State prediction error at timestep 1830 is tensor(5.3664e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1830 of None
Current timestep = 1831. State = [[-0.21470486 -0.10065548]]. Action = [[ 0.05835683 -0.01685304  0.          0.1572212 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 1831 is [True, False, False, False, True, False]
State prediction error at timestep 1831 is tensor(4.6755e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1831 of None
Current timestep = 1832. State = [[-0.20775874 -0.1004049 ]]. Action = [[ 0.06880889  0.00942089  0.         -0.43854713]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 1832 is [True, False, False, False, True, False]
State prediction error at timestep 1832 is tensor(5.2721e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1832 of None
Current timestep = 1833. State = [[-0.19985469 -0.09863151]]. Action = [[ 0.08317616  0.02503832  0.         -0.8865893 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 1833 is [True, False, False, False, True, False]
State prediction error at timestep 1833 is tensor(5.8726e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1833 of None
Current timestep = 1834. State = [[-0.1906923  -0.10209255]]. Action = [[ 0.09821031 -0.09029721  0.         -0.739064  ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 1834 is [True, False, False, False, True, False]
State prediction error at timestep 1834 is tensor(1.6042e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1834 of None
Current timestep = 1835. State = [[-0.18297966 -0.10356525]]. Action = [[ 0.05294824  0.02271758  0.         -0.92449   ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 1835 is [True, False, False, False, True, False]
State prediction error at timestep 1835 is tensor(1.8539e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1835 of None
Current timestep = 1836. State = [[-0.17525442 -0.10270818]]. Action = [[ 0.07750366  0.01019867  0.         -0.75720966]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 1836 is [True, False, False, False, True, False]
State prediction error at timestep 1836 is tensor(2.5332e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1836 of None
Current timestep = 1837. State = [[-0.16656297 -0.1012603 ]]. Action = [[ 0.08428878  0.02574224  0.         -0.6927864 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 1837 is [True, False, False, False, True, False]
State prediction error at timestep 1837 is tensor(5.0496e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1837 of None
Current timestep = 1838. State = [[-0.15975237 -0.1026621 ]]. Action = [[ 0.03889961 -0.04045258  0.         -0.7559243 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 1838 is [True, False, False, False, True, False]
State prediction error at timestep 1838 is tensor(6.5720e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1838 of None
Current timestep = 1839. State = [[-0.15328829 -0.10804353]]. Action = [[ 0.05067878 -0.07852243  0.         -0.7589383 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 1839 is [True, False, False, False, True, False]
State prediction error at timestep 1839 is tensor(3.8933e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1839 of None
Current timestep = 1840. State = [[-0.1447682 -0.1067833]]. Action = [[ 0.08663941  0.0830837   0.         -0.9291663 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 1840 is [True, False, False, False, True, False]
State prediction error at timestep 1840 is tensor(1.4303e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1840 of None
Current timestep = 1841. State = [[-0.13694428 -0.1089472 ]]. Action = [[ 0.05400806 -0.0819566   0.         -0.56847966]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 1841 is [True, False, False, False, True, False]
State prediction error at timestep 1841 is tensor(2.2777e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1841 of None
Current timestep = 1842. State = [[-0.13325568 -0.10921534]]. Action = [[-0.01948286  0.05166102  0.         -0.9072381 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 1842 is [True, False, False, False, True, False]
State prediction error at timestep 1842 is tensor(1.9445e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1842 of None
Current timestep = 1843. State = [[-0.12638047 -0.10743468]]. Action = [[ 0.09561471  0.01533743  0.         -0.08793694]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 1843 is [True, False, False, False, True, False]
State prediction error at timestep 1843 is tensor(1.9679e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1843 of None
Current timestep = 1844. State = [[-0.12056742 -0.1102924 ]]. Action = [[ 0.00926296 -0.06213548  0.         -0.78983545]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 1844 is [True, False, False, False, True, False]
State prediction error at timestep 1844 is tensor(1.0804e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1844 of None
Current timestep = 1845. State = [[-0.11320037 -0.11262002]]. Action = [[ 0.08525968 -0.00187141  0.         -0.8654617 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 1845 is [True, False, False, False, True, False]
State prediction error at timestep 1845 is tensor(1.5701e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1845 of None
Current timestep = 1846. State = [[-0.10387298 -0.11020105]]. Action = [[ 0.09131236  0.0592492   0.         -0.31205273]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 1846 is [True, False, False, False, True, False]
State prediction error at timestep 1846 is tensor(4.1841e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1846 of None
Current timestep = 1847. State = [[-0.09492148 -0.10787147]]. Action = [[ 0.08345438  0.01496375  0.         -0.86966616]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 1847 is [True, False, False, False, True, False]
State prediction error at timestep 1847 is tensor(3.4222e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1847 of None
Current timestep = 1848. State = [[-0.09233151 -0.1049488 ]]. Action = [[-0.0473764  0.0492112  0.        -0.6402328]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 1848 is [True, False, False, False, True, False]
State prediction error at timestep 1848 is tensor(6.0399e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1848 of None
Current timestep = 1849. State = [[-0.08876468 -0.10420132]]. Action = [[ 0.05346363 -0.02040379  0.         -0.95473397]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 1849 is [True, False, False, False, True, False]
State prediction error at timestep 1849 is tensor(5.0077e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1849 of None
Current timestep = 1850. State = [[-0.08277335 -0.10553682]]. Action = [[ 0.04962225 -0.02335776  0.         -0.90588105]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 1850 is [True, False, False, False, True, False]
State prediction error at timestep 1850 is tensor(8.5956e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1850 of None
Current timestep = 1851. State = [[-0.07848878 -0.10197827]]. Action = [[ 0.01584011  0.0788923   0.         -0.58992314]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 1851 is [True, False, False, False, True, False]
State prediction error at timestep 1851 is tensor(9.9662e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1851 of None
Current timestep = 1852. State = [[-0.07208752 -0.09518264]]. Action = [[ 0.08507181  0.07716959  0.         -0.3689602 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 1852 is [True, False, False, False, True, False]
State prediction error at timestep 1852 is tensor(2.7856e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1852 of None
Current timestep = 1853. State = [[-0.0654082  -0.09294982]]. Action = [[ 0.05794395 -0.02189634  0.         -0.84997106]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 1853 is [True, False, False, False, True, False]
State prediction error at timestep 1853 is tensor(2.0797e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1853 of None
Current timestep = 1854. State = [[-0.05740559 -0.09461413]]. Action = [[ 0.0964966  -0.03944132  0.         -0.86289054]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 1854 is [True, False, False, False, True, False]
State prediction error at timestep 1854 is tensor(2.5723e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1854 of None
Current timestep = 1855. State = [[-0.05230294 -0.09334875]]. Action = [[ 0.01313113  0.03815595  0.         -0.8259529 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 1855 is [True, False, False, False, True, False]
State prediction error at timestep 1855 is tensor(1.5153e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1855 of None
Current timestep = 1856. State = [[-0.29925084  0.03232523]]. Action = [[ 0.09897978  0.01397097  0.         -0.70853794]]. Reward = [100.]
Curr episode timestep = 74
Scene graph at timestep 1856 is [True, False, False, False, True, False]
State prediction error at timestep 1856 is tensor(0.0392, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1856 of None
Current timestep = 1857. State = [[-0.29514483  0.03273948]]. Action = [[ 0.06242628 -0.04441774  0.         -0.82620376]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1857 is [True, False, False, False, True, False]
State prediction error at timestep 1857 is tensor(1.9875e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1857 of None
Current timestep = 1858. State = [[-0.28848568  0.03206531]]. Action = [[ 0.09838814  0.02061449  0.         -0.75875086]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1858 is [True, False, False, False, True, False]
State prediction error at timestep 1858 is tensor(5.3281e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1858 of None
Current timestep = 1859. State = [[-0.28250507  0.03242031]]. Action = [[ 0.0588064   0.00780859  0.         -0.7821095 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1859 is [True, False, False, False, True, False]
State prediction error at timestep 1859 is tensor(7.4005e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1859 of None
Current timestep = 1860. State = [[-0.28331184  0.03511177]]. Action = [[-0.06846181  0.055109    0.         -0.8908238 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1860 is [True, False, False, False, True, False]
State prediction error at timestep 1860 is tensor(8.8325e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1860 of None
Current timestep = 1861. State = [[-0.28194365  0.03668024]]. Action = [[ 0.05740129 -0.00269495  0.         -0.8730419 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1861 is [True, False, False, False, True, False]
State prediction error at timestep 1861 is tensor(1.5426e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1861 of None
Current timestep = 1862. State = [[-0.27698275  0.03431945]]. Action = [[ 0.05684359 -0.0496972   0.         -0.73200095]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1862 is [True, False, False, False, True, False]
State prediction error at timestep 1862 is tensor(1.1907e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1862 of None
Current timestep = 1863. State = [[-0.27467442  0.03617789]]. Action = [[-0.00588318  0.06574651  0.         -0.5602697 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1863 is [True, False, False, False, True, False]
State prediction error at timestep 1863 is tensor(1.2904e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1863 of None
Current timestep = 1864. State = [[-0.27244914  0.03366197]]. Action = [[ 0.02617849 -0.09256184  0.          0.02551508]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1864 is [True, False, False, False, True, False]
State prediction error at timestep 1864 is tensor(2.6460e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1864 of None
Current timestep = 1865. State = [[-0.27016684  0.03435011]]. Action = [[ 0.00605075  0.06551861  0.         -0.6097126 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 1865 is [True, False, False, False, True, False]
State prediction error at timestep 1865 is tensor(3.6466e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1865 of None
Current timestep = 1866. State = [[-0.27170727  0.03863417]]. Action = [[-0.05632595  0.04344475  0.         -0.76245856]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 1866 is [True, False, False, False, True, False]
State prediction error at timestep 1866 is tensor(2.0101e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1866 of None
Current timestep = 1867. State = [[-0.26956224  0.03814193]]. Action = [[ 0.05805535 -0.04868877  0.         -0.16277081]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1867 is [True, False, False, False, True, False]
State prediction error at timestep 1867 is tensor(9.3350e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1867 of None
Current timestep = 1868. State = [[-0.26293775  0.03754718]]. Action = [[ 0.08453993  0.00989252  0.         -0.6650907 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 1868 is [True, False, False, False, True, False]
State prediction error at timestep 1868 is tensor(1.0058e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1868 of None
Current timestep = 1869. State = [[-0.25994998  0.03731063]]. Action = [[-0.01077138 -0.01172262  0.         -0.4297573 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 1869 is [True, False, False, False, True, False]
State prediction error at timestep 1869 is tensor(2.4212e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1869 of None
Current timestep = 1870. State = [[-0.2614155   0.03444027]]. Action = [[-0.05361594 -0.05505177  0.         -0.1422652 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 1870 is [True, False, False, False, True, False]
State prediction error at timestep 1870 is tensor(2.2134e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1870 of None
Current timestep = 1871. State = [[-0.26439533  0.02903487]]. Action = [[-0.06303779 -0.07839976  0.         -0.7530328 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 1871 is [True, False, False, False, True, False]
State prediction error at timestep 1871 is tensor(5.4071e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1871 of None
Current timestep = 1872. State = [[-0.2620485   0.02690267]]. Action = [[ 0.06236143  0.01004595  0.         -0.76081103]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 1872 is [True, False, False, False, True, False]
State prediction error at timestep 1872 is tensor(3.5712e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1872 of None
Current timestep = 1873. State = [[-0.26064348  0.0303473 ]]. Action = [[-0.02603228  0.0733921   0.         -0.8770242 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 1873 is [True, False, False, False, True, False]
State prediction error at timestep 1873 is tensor(4.3798e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1873 of None
Current timestep = 1874. State = [[-0.2580234   0.03240866]]. Action = [[ 5.4738827e-02  6.7292154e-04  0.0000000e+00 -7.4495256e-01]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 1874 is [True, False, False, False, True, False]
State prediction error at timestep 1874 is tensor(1.1544e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1874 of None
Current timestep = 1875. State = [[-0.25171888  0.03421882]]. Action = [[ 0.09340503  0.03768169  0.         -0.85169965]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 1875 is [True, False, False, False, True, False]
State prediction error at timestep 1875 is tensor(1.1787e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1875 of None
Current timestep = 1876. State = [[-0.24663727  0.03191364]]. Action = [[ 0.04228159 -0.06326541  0.         -0.6457213 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 1876 is [True, False, False, False, True, False]
State prediction error at timestep 1876 is tensor(4.4600e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1876 of None
Current timestep = 1877. State = [[-0.24521655  0.0323409 ]]. Action = [[-0.01319232  0.0505579   0.         -0.49977982]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 1877 is [True, False, False, False, True, False]
State prediction error at timestep 1877 is tensor(1.2756e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1877 of None
Current timestep = 1878. State = [[-0.24432692  0.03225898]]. Action = [[ 0.01024916 -0.02764376  0.         -0.8158646 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 1878 is [True, False, False, False, True, False]
State prediction error at timestep 1878 is tensor(7.0413e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1878 of None
Current timestep = 1879. State = [[-0.23924173  0.03191116]]. Action = [[ 0.08360856  0.01056778  0.         -0.22749102]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 1879 is [True, False, False, False, True, False]
State prediction error at timestep 1879 is tensor(5.0186e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1879 of None
Current timestep = 1880. State = [[-0.2342738   0.03482784]]. Action = [[ 0.04041148  0.05740721  0.         -0.93655074]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 1880 is [True, False, False, False, True, False]
State prediction error at timestep 1880 is tensor(4.9139e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1880 of None
Current timestep = 1881. State = [[-0.23090078  0.0350062 ]]. Action = [[ 0.02841779 -0.02978934  0.         -0.861331  ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 1881 is [True, False, False, False, True, False]
State prediction error at timestep 1881 is tensor(7.5406e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1881 of None
Current timestep = 1882. State = [[-0.2273582   0.03500159]]. Action = [[ 0.0343935   0.01571555  0.         -0.8235196 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 1882 is [True, False, False, False, True, False]
State prediction error at timestep 1882 is tensor(7.8200e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1882 of None
Current timestep = 1883. State = [[-0.22803968  0.03294082]]. Action = [[-0.0603149  -0.05142903  0.         -0.5707674 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 1883 is [True, False, False, False, True, False]
State prediction error at timestep 1883 is tensor(1.0406e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1883 of None
Current timestep = 1884. State = [[-0.22402792  0.03382688]]. Action = [[ 0.0971375   0.04653385  0.         -0.80799425]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 1884 is [True, False, False, False, True, False]
State prediction error at timestep 1884 is tensor(2.9609e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1884 of None
Current timestep = 1885. State = [[-0.21633412  0.03405117]]. Action = [[ 0.07576165 -0.02058937  0.         -0.75077546]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 1885 is [True, False, False, False, True, False]
State prediction error at timestep 1885 is tensor(2.0955e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1885 of None
Current timestep = 1886. State = [[-0.21614993  0.03427108]]. Action = [[-0.08312432  0.01446337  0.         -0.40944278]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 1886 is [True, False, False, False, True, False]
State prediction error at timestep 1886 is tensor(8.3867e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1886 of None
Current timestep = 1887. State = [[-0.21871066  0.034274  ]]. Action = [[-0.03664871 -0.01398251  0.         -0.536661  ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 1887 is [True, False, False, False, True, False]
State prediction error at timestep 1887 is tensor(3.1647e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1887 of None
Current timestep = 1888. State = [[-0.21793503  0.03775071]]. Action = [[ 0.02030639  0.07032073  0.         -0.92188424]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 1888 is [True, False, False, False, True, False]
State prediction error at timestep 1888 is tensor(8.9018e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1888 of None
Current timestep = 1889. State = [[-0.22028434  0.04098106]]. Action = [[-0.06897272  0.01248901  0.         -0.8301486 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 1889 is [True, False, False, False, True, False]
State prediction error at timestep 1889 is tensor(1.2472e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1889 of None
Current timestep = 1890. State = [[-0.22268672  0.04557751]]. Action = [[-0.01582736  0.06545574  0.          0.27716565]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 1890 is [True, False, False, False, True, False]
State prediction error at timestep 1890 is tensor(3.4086e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1890 of None
Current timestep = 1891. State = [[-0.22222531  0.04960703]]. Action = [[ 0.02571592  0.02168594  0.         -0.6458976 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 1891 is [True, False, False, False, True, False]
State prediction error at timestep 1891 is tensor(2.6588e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1891 of None
Current timestep = 1892. State = [[-0.21722038  0.05114403]]. Action = [[ 0.09886879 -0.00128486  0.         -0.69277203]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 1892 is [True, False, False, False, True, False]
State prediction error at timestep 1892 is tensor(3.6839e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1892 of None
Current timestep = 1893. State = [[-0.21315081  0.05226429]]. Action = [[ 0.03316992  0.0108629   0.         -0.8196763 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 1893 is [True, False, False, False, True, False]
State prediction error at timestep 1893 is tensor(1.8289e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1893 of None
Current timestep = 1894. State = [[-0.21079546  0.05588965]]. Action = [[ 0.02693983  0.05497213  0.         -0.9027095 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 1894 is [True, False, False, False, True, False]
State prediction error at timestep 1894 is tensor(1.8761e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1894 of None
Current timestep = 1895. State = [[-0.20779178  0.06165573]]. Action = [[ 0.04733025  0.07026159  0.         -0.65080225]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 1895 is [True, False, False, False, True, False]
State prediction error at timestep 1895 is tensor(2.4491e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1895 of None
Current timestep = 1896. State = [[-0.20261532  0.06356124]]. Action = [[ 0.07819296 -0.01798223  0.         -0.17672324]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 1896 is [True, False, False, False, True, False]
State prediction error at timestep 1896 is tensor(4.2900e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1896 of None
Current timestep = 1897. State = [[-0.20273897  0.06680214]]. Action = [[-0.0596168   0.05858649  0.         -0.79914665]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 1897 is [True, False, False, False, True, False]
State prediction error at timestep 1897 is tensor(1.4787e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1897 of None
Current timestep = 1898. State = [[-0.20545411  0.07027982]]. Action = [[-0.03143997  0.01399678  0.         -0.38565528]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 1898 is [True, False, False, False, True, False]
State prediction error at timestep 1898 is tensor(2.6309e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1898 of None
Current timestep = 1899. State = [[-0.20168336  0.07237519]]. Action = [[ 0.09324697  0.01030202  0.         -0.42660886]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 1899 is [True, False, False, False, True, False]
State prediction error at timestep 1899 is tensor(1.4258e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1899 of None
Current timestep = 1900. State = [[-0.19379094  0.07376204]]. Action = [[ 0.09886215  0.00664421  0.         -0.6916085 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 1900 is [True, False, False, False, True, False]
State prediction error at timestep 1900 is tensor(1.2830e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1900 of None
Current timestep = 1901. State = [[-0.18849443  0.0745644 ]]. Action = [[ 0.0297677   0.00130385  0.         -0.63238513]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 1901 is [True, False, False, False, True, False]
State prediction error at timestep 1901 is tensor(1.0460e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1901 of None
Current timestep = 1902. State = [[-0.19010548  0.07287572]]. Action = [[-0.08761518 -0.05005683  0.         -0.3332963 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 1902 is [True, False, False, False, True, False]
State prediction error at timestep 1902 is tensor(1.0296e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1902 of None
Current timestep = 1903. State = [[-0.18687004  0.07571587]]. Action = [[ 0.09856325  0.0747861   0.         -0.77648604]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 1903 is [True, False, False, False, True, False]
State prediction error at timestep 1903 is tensor(1.2109e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1903 of None
Current timestep = 1904. State = [[-0.18287559  0.07414815]]. Action = [[-0.01163606 -0.08594088  0.         -0.77213097]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 1904 is [True, False, False, False, True, False]
State prediction error at timestep 1904 is tensor(2.1725e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1904 of None
Current timestep = 1905. State = [[-0.17641215  0.06980823]]. Action = [[ 0.09049756 -0.0459156   0.         -0.5587641 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 1905 is [True, False, False, False, True, False]
State prediction error at timestep 1905 is tensor(1.8301e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1905 of None
Current timestep = 1906. State = [[-0.17013086  0.06857775]]. Action = [[ 0.02973763  0.00824513  0.         -0.71655065]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 1906 is [True, False, False, False, True, False]
State prediction error at timestep 1906 is tensor(1.7877e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1906 of None
Current timestep = 1907. State = [[-0.16246216  0.07159998]]. Action = [[ 0.09569908  0.06417068  0.         -0.5787287 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 1907 is [True, False, False, False, True, False]
State prediction error at timestep 1907 is tensor(6.8461e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1907 of None
Current timestep = 1908. State = [[-0.15307441  0.06867906]]. Action = [[ 0.0974442  -0.08665821  0.         -0.9134974 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 1908 is [True, False, False, False, True, False]
State prediction error at timestep 1908 is tensor(2.9915e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1908 of None
Current timestep = 1909. State = [[-0.1430981   0.06068612]]. Action = [[ 0.09631068 -0.09469365  0.         -0.7992354 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 1909 is [True, False, False, False, True, False]
State prediction error at timestep 1909 is tensor(8.0053e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1909 of None
Current timestep = 1910. State = [[-0.13398129  0.05989108]]. Action = [[ 0.07650136  0.06920541  0.         -0.77765346]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 1910 is [True, False, False, False, True, False]
State prediction error at timestep 1910 is tensor(4.1617e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1910 of None
Current timestep = 1911. State = [[-0.12659872  0.06100461]]. Action = [[ 0.05684077  0.00949262  0.         -0.5884664 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 1911 is [True, False, False, False, True, False]
State prediction error at timestep 1911 is tensor(5.5787e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1911 of None
Current timestep = 1912. State = [[-0.11915951  0.05986455]]. Action = [[ 0.06818905 -0.00962995  0.         -0.8729386 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 1912 is [True, False, False, False, True, False]
State prediction error at timestep 1912 is tensor(2.1131e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1912 of None
Current timestep = 1913. State = [[-0.1127356  0.0619774]]. Action = [[ 0.04213234  0.06545305  0.         -0.82139254]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 1913 is [True, False, False, False, True, False]
State prediction error at timestep 1913 is tensor(1.2506e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1913 of None
Current timestep = 1914. State = [[-0.10498349  0.06176143]]. Action = [[ 0.08610512 -0.03082997  0.         -0.5195101 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 1914 is [True, False, False, False, True, False]
State prediction error at timestep 1914 is tensor(5.1464e-08, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1914 of None
Current timestep = 1915. State = [[-0.09587408  0.05843098]]. Action = [[ 0.08591033 -0.03912504  0.         -0.6427419 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 1915 is [True, False, False, False, True, False]
State prediction error at timestep 1915 is tensor(1.8113e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1915 of None
Current timestep = 1916. State = [[-0.08627877  0.05494204]]. Action = [[ 0.09124523 -0.03186328  0.         -0.618557  ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 1916 is [True, False, False, False, True, False]
State prediction error at timestep 1916 is tensor(1.3515e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1916 of None
Current timestep = 1917. State = [[-0.07608378  0.05225679]]. Action = [[ 0.09860138 -0.01589103  0.         -0.9454941 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 1917 is [True, False, False, False, True, False]
State prediction error at timestep 1917 is tensor(3.8192e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1917 of None
Current timestep = 1918. State = [[-0.06594805  0.05437987]]. Action = [[ 0.09495152  0.07299062  0.         -0.8736948 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 1918 is [True, False, False, False, True, False]
State prediction error at timestep 1918 is tensor(3.0654e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1918 of None
Current timestep = 1919. State = [[-0.05617046  0.05796884]]. Action = [[ 0.09459513  0.04552574  0.         -0.5537609 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 1919 is [True, False, False, False, True, False]
State prediction error at timestep 1919 is tensor(1.1310e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1919 of None
Current timestep = 1920. State = [[-0.26287323  0.16813199]]. Action = [[ 0.05110628  0.00377031  0.         -0.9517304 ]]. Reward = [100.]
Curr episode timestep = 63
Scene graph at timestep 1920 is [True, False, False, False, False, True]
State prediction error at timestep 1920 is tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1920 of None
Current timestep = 1921. State = [[-0.2642703   0.17463817]]. Action = [[ 0.08090722  0.03760154  0.         -0.38379008]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1921 is [True, False, False, False, False, True]
State prediction error at timestep 1921 is tensor(1.9444e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1921 of None
Current timestep = 1922. State = [[-0.2616548  0.1784284]]. Action = [[0.05213446 0.02674342 0.         0.06165564]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1922 is [True, False, False, False, False, True]
State prediction error at timestep 1922 is tensor(5.8972e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1922 of None
Current timestep = 1923. State = [[-0.261152    0.17782006]]. Action = [[ 0.00381362 -0.05460559  0.         -0.7366911 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1923 is [True, False, False, False, False, True]
State prediction error at timestep 1923 is tensor(3.4333e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1923 of None
Current timestep = 1924. State = [[-0.2577336   0.17979273]]. Action = [[ 0.08233266  0.04908536  0.         -0.3167265 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1924 is [True, False, False, False, False, True]
State prediction error at timestep 1924 is tensor(8.3922e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1924 of None
Current timestep = 1925. State = [[-0.25211594  0.18512526]]. Action = [[0.07685802 0.06920952 0.         0.11197209]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1925 is [True, False, False, False, False, True]
State prediction error at timestep 1925 is tensor(3.7767e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1925 of None
Current timestep = 1926. State = [[-0.24547009  0.19048753]]. Action = [[ 0.09105373  0.06019039  0.         -0.7933515 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1926 is [True, False, False, False, False, True]
State prediction error at timestep 1926 is tensor(3.3913e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1926 of None
Current timestep = 1927. State = [[-0.23965275  0.19628714]]. Action = [[ 0.05686215  0.07409094  0.         -0.30306876]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1927 is [True, False, False, False, False, True]
State prediction error at timestep 1927 is tensor(6.7433e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1927 of None
Current timestep = 1928. State = [[-0.23477644  0.19911768]]. Action = [[ 0.04841984  0.00116281  0.         -0.32259727]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1928 is [True, False, False, False, False, True]
State prediction error at timestep 1928 is tensor(1.8961e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1928 of None
Current timestep = 1929. State = [[-0.22801703  0.20206586]]. Action = [[ 0.08190177  0.0421233   0.         -0.35310698]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 1929 is [True, False, False, False, False, True]
State prediction error at timestep 1929 is tensor(1.9127e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1929 of None
Current timestep = 1930. State = [[-0.22052051  0.20370764]]. Action = [[ 0.06989764 -0.00488383  0.         -0.35010666]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 1930 is [True, False, False, False, False, True]
State prediction error at timestep 1930 is tensor(3.5850e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1930 of None
Current timestep = 1931. State = [[-0.21713905  0.20107122]]. Action = [[-0.02301572 -0.07435984  0.         -0.6188351 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1931 is [True, False, False, False, False, True]
State prediction error at timestep 1931 is tensor(1.7348e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1931 of None
Current timestep = 1932. State = [[-0.21415654  0.1990101 ]]. Action = [[ 0.01682633 -0.02533578  0.         -0.42635095]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 1932 is [True, False, False, False, False, True]
State prediction error at timestep 1932 is tensor(2.0138e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1932 of None
Current timestep = 1933. State = [[-0.20715263  0.19693688]]. Action = [[ 0.07995894 -0.04197753  0.         -0.6603297 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 1933 is [True, False, False, False, False, True]
State prediction error at timestep 1933 is tensor(1.4447e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1933 of None
Current timestep = 1934. State = [[-0.19887948  0.19713238]]. Action = [[ 0.06717233  0.02488305  0.         -0.55292046]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 1934 is [True, False, False, False, False, True]
State prediction error at timestep 1934 is tensor(2.5070e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1934 of None
Current timestep = 1935. State = [[-0.18991755  0.19913797]]. Action = [[ 0.08984461  0.03162088  0.         -0.5461089 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 1935 is [True, False, False, False, False, True]
State prediction error at timestep 1935 is tensor(2.8004e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1935 of None
Current timestep = 1936. State = [[-0.1807645   0.19886942]]. Action = [[ 0.08139489 -0.01575084  0.         -0.37525028]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 1936 is [True, False, False, False, False, True]
State prediction error at timestep 1936 is tensor(6.8954e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1936 of None
Current timestep = 1937. State = [[-0.17306682  0.20027202]]. Action = [[ 0.0544528   0.04624141  0.         -0.7306067 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 1937 is [True, False, False, False, False, True]
State prediction error at timestep 1937 is tensor(4.1154e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1937 of None
Current timestep = 1938. State = [[-0.16940545  0.19993222]]. Action = [[-0.01183562 -0.02970932  0.         -0.6664095 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 1938 is [True, False, False, False, False, True]
State prediction error at timestep 1938 is tensor(6.2759e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1938 of None
Current timestep = 1939. State = [[-0.16245863  0.1980295 ]]. Action = [[ 0.09385186 -0.02285971  0.         -0.11423606]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 1939 is [True, False, False, False, False, True]
State prediction error at timestep 1939 is tensor(2.8674e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1939 of None
Current timestep = 1940. State = [[-0.15302339  0.1988754 ]]. Action = [[ 0.0871131   0.03944009  0.         -0.8488684 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 1940 is [True, False, False, False, False, True]
State prediction error at timestep 1940 is tensor(6.2312e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1940 of None
Current timestep = 1941. State = [[-0.14659499  0.19671243]]. Action = [[ 0.02624219 -0.0580528   0.         -0.6727619 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 1941 is [True, False, False, False, False, True]
State prediction error at timestep 1941 is tensor(1.5764e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1941 of None
Current timestep = 1942. State = [[-0.14567961  0.19820516]]. Action = [[-0.05279512  0.06339177  0.          0.5834861 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 1942 is [True, False, False, False, False, True]
State prediction error at timestep 1942 is tensor(3.8457e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1942 of None
Current timestep = 1943. State = [[-0.14315915  0.19717923]]. Action = [[ 0.03501732 -0.06515421  0.         -0.790413  ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 1943 is [True, False, False, False, False, True]
State prediction error at timestep 1943 is tensor(7.3670e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1943 of None
Current timestep = 1944. State = [[-0.13593277  0.19930936]]. Action = [[ 0.09111429  0.07824595  0.         -0.79547375]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 1944 is [True, False, False, False, False, True]
State prediction error at timestep 1944 is tensor(5.4843e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1944 of None
Current timestep = 1945. State = [[-0.127302    0.20042537]]. Action = [[ 0.08742227 -0.01804169  0.         -0.7672271 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 1945 is [True, False, False, False, False, True]
State prediction error at timestep 1945 is tensor(4.7392e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1945 of None
Current timestep = 1946. State = [[-0.11865479  0.19711299]]. Action = [[ 0.08082945 -0.05395535  0.          0.07567227]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 1946 is [True, False, False, False, False, True]
State prediction error at timestep 1946 is tensor(3.0053e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1946 of None
Current timestep = 1947. State = [[-0.10947992  0.19754559]]. Action = [[ 0.09207381  0.05135297  0.         -0.44055504]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 1947 is [True, False, False, False, False, True]
State prediction error at timestep 1947 is tensor(3.2066e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1947 of None
Current timestep = 1948. State = [[-0.1010514   0.19765927]]. Action = [[ 0.07332804 -0.01186786  0.         -0.29884237]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 1948 is [True, False, False, False, False, True]
State prediction error at timestep 1948 is tensor(7.0400e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1948 of None
Current timestep = 1949. State = [[-0.09176003  0.19428487]]. Action = [[ 0.09595556 -0.0481325   0.         -0.8097831 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 1949 is [True, False, False, False, False, True]
State prediction error at timestep 1949 is tensor(3.2360e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1949 of None
Current timestep = 1950. State = [[-0.08181375  0.1884756 ]]. Action = [[ 0.0895186  -0.06900825  0.         -0.3907584 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 1950 is [True, False, False, False, False, True]
State prediction error at timestep 1950 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1950 of None
Current timestep = 1951. State = [[-0.07229534  0.18126291]]. Action = [[ 0.07584152 -0.07801175  0.         -0.5753095 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 1951 is [True, False, False, False, False, True]
State prediction error at timestep 1951 is tensor(5.3622e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1951 of None
Current timestep = 1952. State = [[-0.0619482   0.17384449]]. Action = [[ 0.0948089 -0.0689554  0.        -0.7652713]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 1952 is [True, False, False, False, False, True]
State prediction error at timestep 1952 is tensor(2.8872e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1952 of None
Current timestep = 1953. State = [[-0.05123952  0.16960469]]. Action = [[ 0.09144694 -0.00050635  0.         -0.4477439 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 1953 is [True, False, False, False, False, True]
State prediction error at timestep 1953 is tensor(4.2077e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1953 of None
Current timestep = 1954. State = [[-0.0403554   0.16311008]]. Action = [[ 0.09842681 -0.08100007  0.         -0.90997064]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 1954 is [False, True, False, False, False, True]
State prediction error at timestep 1954 is tensor(4.8676e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1954 of None
Current timestep = 1955. State = [[-0.03145694  0.15992463]]. Action = [[ 0.05352952  0.03323633  0.         -0.6597194 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 1955 is [False, True, False, False, False, True]
State prediction error at timestep 1955 is tensor(2.4994e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1955 of None
Current timestep = 1956. State = [[-0.02245506  0.15835874]]. Action = [[ 0.08799914 -0.00120988  0.         -0.91161495]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 1956 is [False, True, False, False, False, True]
State prediction error at timestep 1956 is tensor(1.7372e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1956 of None
Current timestep = 1957. State = [[-0.01292814  0.15407328]]. Action = [[ 0.08352155 -0.04222352  0.         -0.6951729 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 1957 is [False, True, False, False, False, True]
State prediction error at timestep 1957 is tensor(1.8514e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1957 of None
Current timestep = 1958. State = [[-0.00445117  0.14697905]]. Action = [[ 0.06113096 -0.07621981  0.         -0.91281414]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 1958 is [False, True, False, False, False, True]
State prediction error at timestep 1958 is tensor(2.8498e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1958 of None
Current timestep = 1959. State = [[0.0012409  0.14072146]]. Action = [[ 0.01152183 -0.04106839  0.         -0.88417184]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 1959 is [False, True, False, False, False, True]
State prediction error at timestep 1959 is tensor(2.2269e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1959 of None
Current timestep = 1960. State = [[0.0089474  0.13576292]]. Action = [[ 0.08292831 -0.03641438  0.         -0.8593296 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 1960 is [False, True, False, False, False, True]
State prediction error at timestep 1960 is tensor(3.1835e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1960 of None
Current timestep = 1961. State = [[0.01755805 0.13381363]]. Action = [[ 0.07011426  0.0231062   0.         -0.6151179 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 1961 is [False, True, False, False, False, True]
State prediction error at timestep 1961 is tensor(3.4540e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1961 of None
Current timestep = 1962. State = [[0.02594111 0.13453093]]. Action = [[ 0.08100171  0.0388147   0.         -0.56858146]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 1962 is [False, True, False, False, False, True]
State prediction error at timestep 1962 is tensor(2.1038e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1962 of None
Current timestep = 1963. State = [[0.0347231 0.1330164]]. Action = [[ 0.09051544 -0.02232581  0.         -0.58567834]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 1963 is [False, True, False, False, False, True]
State prediction error at timestep 1963 is tensor(6.0598e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1963 of None
Current timestep = 1964. State = [[0.04190066 0.12705594]]. Action = [[ 0.04884889 -0.0793339   0.         -0.862255  ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 1964 is [False, True, False, False, False, True]
State prediction error at timestep 1964 is tensor(2.7359e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1964 of None
Current timestep = 1965. State = [[-0.36965102 -0.10498127]]. Action = [[ 0.08550086  0.02818581  0.         -0.41448057]]. Reward = [100.]
Curr episode timestep = 44
Scene graph at timestep 1965 is [True, False, False, False, True, False]
State prediction error at timestep 1965 is tensor(0.1145, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1965 of None
Current timestep = 1966. State = [[-0.36848816 -0.10353128]]. Action = [[ 0.06812888  0.08478046  0.         -0.9000474 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1966 is [True, False, False, False, True, False]
State prediction error at timestep 1966 is tensor(6.7493e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1966 of None
Current timestep = 1967. State = [[-0.36733976 -0.09658659]]. Action = [[-0.00279196  0.07221907  0.         -0.37298876]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1967 is [True, False, False, False, True, False]
State prediction error at timestep 1967 is tensor(3.6378e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1967 of None
Current timestep = 1968. State = [[-0.36590403 -0.09123868]]. Action = [[ 0.03786645  0.03707064  0.         -0.6908964 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1968 is [True, False, False, False, True, False]
State prediction error at timestep 1968 is tensor(3.3381e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1968 of None
Current timestep = 1969. State = [[-0.36871427 -0.08647712]]. Action = [[-0.07474022  0.04994749  0.         -0.75595236]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1969 is [True, False, False, False, True, False]
State prediction error at timestep 1969 is tensor(1.5092e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1969 of None
Current timestep = 1970. State = [[-0.37144998 -0.08408246]]. Action = [[ 0.         0.         0.        -0.9361255]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1970 is [True, False, False, False, True, False]
State prediction error at timestep 1970 is tensor(6.1142e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1970 of None
Current timestep = 1971. State = [[-0.37108275 -0.08731861]]. Action = [[ 0.02567727 -0.08454324  0.         -0.83535886]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1971 is [True, False, False, False, True, False]
State prediction error at timestep 1971 is tensor(2.3483e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1971 of None
Current timestep = 1972. State = [[-0.37317687 -0.08525445]]. Action = [[-0.04715445  0.08276571  0.         -0.39572877]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1972 is [True, False, False, False, True, False]
State prediction error at timestep 1972 is tensor(2.7685e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1972 of None
Current timestep = 1973. State = [[-0.3752661  -0.08223303]]. Action = [[ 0.          0.          0.         -0.38821363]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1973 is [True, False, False, False, True, False]
State prediction error at timestep 1973 is tensor(4.5394e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1973 of None
Current timestep = 1974. State = [[-0.37611547 -0.08131333]]. Action = [[ 0.         0.         0.        -0.2936008]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 1974 is [True, False, False, False, True, False]
State prediction error at timestep 1974 is tensor(8.8589e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1974 of None
Current timestep = 1975. State = [[-0.37469468 -0.08410983]]. Action = [[ 0.04365645 -0.06973646  0.         -0.5138742 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 1975 is [True, False, False, False, True, False]
State prediction error at timestep 1975 is tensor(1.6996e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1975 of None
Current timestep = 1976. State = [[-0.3732768  -0.08470964]]. Action = [[ 0.0150234   0.01975279  0.         -0.7960105 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1976 is [True, False, False, False, True, False]
State prediction error at timestep 1976 is tensor(7.5553e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1976 of None
Current timestep = 1977. State = [[-0.37039784 -0.08079958]]. Action = [[ 0.0544259  0.0564254  0.        -0.8069946]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 1977 is [True, False, False, False, True, False]
State prediction error at timestep 1977 is tensor(3.6749e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1977 of None
Current timestep = 1978. State = [[-0.3689616  -0.07828616]]. Action = [[0.        0.        0.        0.5392649]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 1978 is [True, False, False, False, True, False]
State prediction error at timestep 1978 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1978 of None
Current timestep = 1979. State = [[-0.3644459  -0.08000795]]. Action = [[ 0.09184889 -0.04831576  0.         -0.7950554 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 1979 is [True, False, False, False, True, False]
State prediction error at timestep 1979 is tensor(1.6414e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1979 of None
Current timestep = 1980. State = [[-0.35689718 -0.08233467]]. Action = [[ 0.09173305 -0.02927633  0.         -0.8918869 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 1980 is [True, False, False, False, True, False]
State prediction error at timestep 1980 is tensor(3.3301e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1980 of None
Current timestep = 1981. State = [[-0.3523778  -0.07836258]]. Action = [[ 0.01642291  0.09061538  0.         -0.02220398]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 1981 is [True, False, False, False, True, False]
State prediction error at timestep 1981 is tensor(7.7018e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1981 of None
Current timestep = 1982. State = [[-0.3513082  -0.07872551]]. Action = [[-0.009361   -0.06820448  0.          0.00753677]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 1982 is [True, False, False, False, True, False]
State prediction error at timestep 1982 is tensor(8.4840e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1982 of None
Current timestep = 1983. State = [[-0.34724918 -0.08114345]]. Action = [[ 0.06964665 -0.00649688  0.         -0.48664165]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 1983 is [True, False, False, False, True, False]
State prediction error at timestep 1983 is tensor(1.1710e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1983 of None
Current timestep = 1984. State = [[-0.3462511  -0.08122499]]. Action = [[-0.04341775  0.01023698  0.         -0.21987301]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 1984 is [True, False, False, False, True, False]
State prediction error at timestep 1984 is tensor(1.8018e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1984 of None
Current timestep = 1985. State = [[-0.34451792 -0.07727595]]. Action = [[ 0.03909791  0.07827578  0.         -0.5398673 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 1985 is [True, False, False, False, True, False]
State prediction error at timestep 1985 is tensor(2.0693e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1985 of None
Current timestep = 1986. State = [[-0.34078413 -0.0762675 ]]. Action = [[ 0.03837771 -0.03304434  0.         -0.42649412]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 1986 is [True, False, False, False, True, False]
State prediction error at timestep 1986 is tensor(3.9355e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1986 of None
Current timestep = 1987. State = [[-0.33674082 -0.07471659]]. Action = [[ 0.04109595  0.04112989  0.         -0.9625064 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 1987 is [True, False, False, False, True, False]
State prediction error at timestep 1987 is tensor(7.9454e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1987 of None
Current timestep = 1988. State = [[-0.3314561  -0.07505327]]. Action = [[ 0.06395883 -0.04014832  0.         -0.88703537]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 1988 is [True, False, False, False, True, False]
State prediction error at timestep 1988 is tensor(1.0751e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1988 of None
Current timestep = 1989. State = [[-0.32426077 -0.07801393]]. Action = [[ 0.08578362 -0.04414229  0.         -0.6027436 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 1989 is [True, False, False, False, True, False]
State prediction error at timestep 1989 is tensor(2.0286e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1989 of None
Current timestep = 1990. State = [[-0.3185194  -0.07509975]]. Action = [[0.03819359 0.08075907 0.         0.26856446]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 1990 is [True, False, False, False, True, False]
State prediction error at timestep 1990 is tensor(3.5450e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1990 of None
Current timestep = 1991. State = [[-0.31481287 -0.06992225]]. Action = [[ 0.02544846  0.04946906  0.         -0.73318005]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 1991 is [True, False, False, False, True, False]
State prediction error at timestep 1991 is tensor(3.9065e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1991 of None
Current timestep = 1992. State = [[-0.31077853 -0.06909008]]. Action = [[ 0.04076535 -0.02471791  0.         -0.79655915]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 1992 is [True, False, False, False, True, False]
State prediction error at timestep 1992 is tensor(1.4831e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1992 of None
Current timestep = 1993. State = [[-0.3052592  -0.06512582]]. Action = [[ 0.0615551   0.0812721   0.         -0.47573227]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 1993 is [True, False, False, False, True, False]
State prediction error at timestep 1993 is tensor(2.8160e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1993 of None
Current timestep = 1994. State = [[-0.30546656 -0.0587981 ]]. Action = [[-0.0674432   0.06468602  0.         -0.6885917 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 1994 is [True, False, False, False, True, False]
State prediction error at timestep 1994 is tensor(1.4420e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1994 of None
Current timestep = 1995. State = [[-0.30884945 -0.05984632]]. Action = [[-0.05415574 -0.07464801  0.         -0.53470546]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 1995 is [True, False, False, False, True, False]
State prediction error at timestep 1995 is tensor(1.3332e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1995 of None
Current timestep = 1996. State = [[-0.30516717 -0.06209835]]. Action = [[ 0.09208437 -0.01363173  0.         -0.87659377]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 1996 is [True, False, False, False, True, False]
State prediction error at timestep 1996 is tensor(8.4038e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1996 of None
Current timestep = 1997. State = [[-0.2968546  -0.06352761]]. Action = [[ 0.09449459 -0.03150766  0.         -0.17506123]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 1997 is [True, False, False, False, True, False]
State prediction error at timestep 1997 is tensor(3.0010e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1997 of None
Current timestep = 1998. State = [[-0.29416722 -0.06440629]]. Action = [[-0.03637107 -0.00415237  0.         -0.68203664]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 1998 is [True, False, False, False, True, False]
State prediction error at timestep 1998 is tensor(9.7560e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1998 of None
Current timestep = 1999. State = [[-0.28931323 -0.06716904]]. Action = [[ 0.09327202 -0.05342165  0.         -0.02151436]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 1999 is [True, False, False, False, True, False]
State prediction error at timestep 1999 is tensor(1.1557e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1999 of None
Current timestep = 2000. State = [[-0.28261825 -0.06419622]]. Action = [[ 0.05445424  0.09195318  0.         -0.8316987 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 2000 is [True, False, False, False, True, False]
State prediction error at timestep 2000 is tensor(1.7486e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2000 of None
Current timestep = 2001. State = [[-0.2790708  -0.06259216]]. Action = [[ 0.01046504 -0.02252548  0.         -0.8587677 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 2001 is [True, False, False, False, True, False]
State prediction error at timestep 2001 is tensor(7.5656e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2001 of None
Current timestep = 2002. State = [[-0.27819294 -0.06000337]]. Action = [[-0.01880264  0.0630454   0.         -0.29399776]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 2002 is [True, False, False, False, True, False]
State prediction error at timestep 2002 is tensor(1.3269e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2002 of None
Current timestep = 2003. State = [[-0.2733766  -0.05830475]]. Action = [[ 0.08644039 -0.00750777  0.          0.05622804]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 2003 is [True, False, False, False, True, False]
State prediction error at timestep 2003 is tensor(5.6612e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2003 of None
Current timestep = 2004. State = [[-0.2649534  -0.05923241]]. Action = [[ 0.09565613 -0.0233767   0.         -0.60677063]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 2004 is [True, False, False, False, True, False]
State prediction error at timestep 2004 is tensor(9.5907e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2004 of None
Current timestep = 2005. State = [[-0.26053068 -0.06060703]]. Action = [[-5.6343526e-04 -1.6800463e-02  0.0000000e+00 -6.3885009e-01]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 2005 is [True, False, False, False, True, False]
State prediction error at timestep 2005 is tensor(2.8066e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2005 of None
Current timestep = 2006. State = [[-0.2565321 -0.0626408]]. Action = [[ 0.04263534 -0.02815656  0.         -0.8709452 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 2006 is [True, False, False, False, True, False]
State prediction error at timestep 2006 is tensor(9.1182e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2006 of None
Current timestep = 2007. State = [[-0.25132075 -0.06241086]]. Action = [[ 0.0454402   0.02542854  0.         -0.95589876]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 2007 is [True, False, False, False, True, False]
State prediction error at timestep 2007 is tensor(4.3630e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2007 of None
Current timestep = 2008. State = [[-0.24484134 -0.06033151]]. Action = [[ 0.07095539  0.02868796  0.         -0.5591527 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 2008 is [True, False, False, False, True, False]
State prediction error at timestep 2008 is tensor(7.6130e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2008 of None
Current timestep = 2009. State = [[-0.23877202 -0.0583697 ]]. Action = [[ 0.04935346  0.01974626  0.         -0.6800873 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 2009 is [True, False, False, False, True, False]
State prediction error at timestep 2009 is tensor(5.7805e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2009 of None
Current timestep = 2010. State = [[-0.2353487  -0.05616626]]. Action = [[ 0.00688933  0.02865698  0.         -0.7508777 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 2010 is [True, False, False, False, True, False]
State prediction error at timestep 2010 is tensor(2.3820e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2010 of None
Current timestep = 2011. State = [[-0.23443386 -0.05789305]]. Action = [[-0.02157172 -0.05488678  0.         -0.93139184]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 2011 is [True, False, False, False, True, False]
State prediction error at timestep 2011 is tensor(6.9276e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2011 of None
Current timestep = 2012. State = [[-0.23154336 -0.05610529]]. Action = [[ 0.03623939  0.06610834  0.         -0.7817328 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 2012 is [True, False, False, False, True, False]
State prediction error at timestep 2012 is tensor(2.1588e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2012 of None
Current timestep = 2013. State = [[-0.22462979 -0.04980788]]. Action = [[ 0.09569377  0.07844646  0.         -0.8088839 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 2013 is [True, False, False, False, True, False]
State prediction error at timestep 2013 is tensor(2.7958e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2013 of None
Current timestep = 2014. State = [[-0.21834095 -0.04336456]]. Action = [[ 0.05377523  0.06181552  0.         -0.7685736 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 2014 is [True, False, False, False, True, False]
State prediction error at timestep 2014 is tensor(2.6124e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2014 of None
Current timestep = 2015. State = [[-0.21121551 -0.04270652]]. Action = [[ 0.09192357 -0.04688544  0.         -0.808489  ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 2015 is [True, False, False, False, True, False]
State prediction error at timestep 2015 is tensor(6.4486e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2015 of None
Current timestep = 2016. State = [[-0.20320931 -0.0386441 ]]. Action = [[ 0.08550335  0.08809353  0.         -0.96385396]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 2016 is [True, False, False, False, True, False]
State prediction error at timestep 2016 is tensor(2.1933e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2016 of None
Current timestep = 2017. State = [[-0.19489874 -0.03847489]]. Action = [[ 0.092302   -0.06659249  0.         -0.65448356]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 2017 is [True, False, False, False, True, False]
State prediction error at timestep 2017 is tensor(2.1495e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2017 of None
Current timestep = 2018. State = [[-0.18887012 -0.03974574]]. Action = [[ 0.0309756  -0.00303738  0.         -0.7062577 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 2018 is [True, False, False, False, True, False]
State prediction error at timestep 2018 is tensor(1.0037e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2018 of None
Current timestep = 2019. State = [[-0.18202245 -0.04290465]]. Action = [[ 0.07469904 -0.06803475  0.         -0.6049546 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 2019 is [True, False, False, False, True, False]
State prediction error at timestep 2019 is tensor(8.4497e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2019 of None
Current timestep = 2020. State = [[-0.1746231  -0.04667476]]. Action = [[ 0.05559728 -0.03652976  0.         -0.7285415 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 2020 is [True, False, False, False, True, False]
State prediction error at timestep 2020 is tensor(1.3404e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2020 of None
Current timestep = 2021. State = [[-0.16613345 -0.05270179]]. Action = [[ 0.08222831 -0.08994848  0.         -0.6844352 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 2021 is [True, False, False, False, True, False]
State prediction error at timestep 2021 is tensor(4.1303e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2021 of None
Current timestep = 2022. State = [[-0.1561911  -0.05419269]]. Action = [[ 0.09533126  0.04098647  0.         -0.9587974 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 2022 is [True, False, False, False, True, False]
State prediction error at timestep 2022 is tensor(2.8254e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2022 of None
Current timestep = 2023. State = [[-0.15404488 -0.05794112]]. Action = [[-0.08202682 -0.07628561  0.         -0.77033055]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 2023 is [True, False, False, False, True, False]
State prediction error at timestep 2023 is tensor(8.9583e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2023 of None
Current timestep = 2024. State = [[-0.15326893 -0.06166709]]. Action = [[-0.00212868 -0.00910901  0.         -0.82584774]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 2024 is [True, False, False, False, True, False]
State prediction error at timestep 2024 is tensor(3.1544e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2024 of None
Current timestep = 2025. State = [[-0.1489336  -0.06328239]]. Action = [[ 0.04242999 -0.00263275  0.         -0.8742029 ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 2025 is [True, False, False, False, True, False]
State prediction error at timestep 2025 is tensor(1.2151e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2025 of None
Current timestep = 2026. State = [[-0.1411635  -0.06024028]]. Action = [[ 0.09526714  0.08058266  0.         -0.91496855]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 2026 is [True, False, False, False, True, False]
State prediction error at timestep 2026 is tensor(1.1941e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2026 of None
Current timestep = 2027. State = [[-0.1332156  -0.05640807]]. Action = [[ 0.07730251  0.03866977  0.         -0.9687396 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 2027 is [True, False, False, False, True, False]
State prediction error at timestep 2027 is tensor(1.3163e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2027 of None
Current timestep = 2028. State = [[-0.12950312 -0.0512904 ]]. Action = [[ 0.00082098  0.07941421  0.         -0.6171808 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 2028 is [True, False, False, False, True, False]
State prediction error at timestep 2028 is tensor(1.0714e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2028 of None
Current timestep = 2029. State = [[-0.12398993 -0.04928464]]. Action = [[ 0.0843965  -0.01380116  0.         -0.83562875]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 2029 is [True, False, False, False, True, False]
State prediction error at timestep 2029 is tensor(5.6698e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2029 of None
Current timestep = 2030. State = [[-0.1159053  -0.04480672]]. Action = [[ 0.09314505  0.08567577  0.         -0.58725524]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 2030 is [True, False, False, False, True, False]
State prediction error at timestep 2030 is tensor(1.3211e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2030 of None
Current timestep = 2031. State = [[-0.10944095 -0.03806236]]. Action = [[ 0.05643214  0.06884065  0.         -0.8484169 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 2031 is [True, False, False, False, True, False]
State prediction error at timestep 2031 is tensor(1.4323e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2031 of None
Current timestep = 2032. State = [[-0.10210279 -0.034367  ]]. Action = [[ 0.09380541  0.00930797  0.         -0.8270561 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 2032 is [True, False, False, False, True, False]
State prediction error at timestep 2032 is tensor(5.7628e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2032 of None
Current timestep = 2033. State = [[-0.09449621 -0.03259886]]. Action = [[ 0.07470522  0.00577454  0.         -0.82019645]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 2033 is [True, False, False, False, True, False]
State prediction error at timestep 2033 is tensor(3.7147e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2033 of None
Current timestep = 2034. State = [[-0.08889905 -0.03151507]]. Action = [[ 0.03651751 -0.00283839  0.         -0.90369964]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 2034 is [True, False, False, False, True, False]
State prediction error at timestep 2034 is tensor(3.3762e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2034 of None
Current timestep = 2035. State = [[-0.08132984 -0.03218195]]. Action = [[ 0.09208237 -0.030466    0.         -0.72213954]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 2035 is [True, False, False, False, True, False]
State prediction error at timestep 2035 is tensor(8.7874e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2035 of None
Current timestep = 2036. State = [[-0.07459021 -0.03023032]]. Action = [[ 0.04054131  0.04326954  0.         -0.9238293 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 2036 is [True, False, False, False, True, False]
State prediction error at timestep 2036 is tensor(1.4454e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2036 of None
Current timestep = 2037. State = [[-0.06819779 -0.0256803 ]]. Action = [[ 0.06020848  0.05274182  0.         -0.9693901 ]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 2037 is [True, False, False, False, True, False]
State prediction error at timestep 2037 is tensor(5.5878e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2037 of None
Current timestep = 2038. State = [[-0.05973491 -0.02300095]]. Action = [[ 0.09347314  0.00683286  0.         -0.93180645]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 2038 is [True, False, False, False, True, False]
State prediction error at timestep 2038 is tensor(1.1048e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2038 of None
Current timestep = 2039. State = [[-0.05064383 -0.02155653]]. Action = [[ 0.08544447  0.01142766  0.         -0.2780999 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 2039 is [True, False, False, False, True, False]
State prediction error at timestep 2039 is tensor(2.0416e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2039 of None
Current timestep = 2040. State = [[-0.17177156  0.07234837]]. Action = [[ 0.05139545  0.04231209  0.         -0.7540103 ]]. Reward = [100.]
Curr episode timestep = 74
Scene graph at timestep 2040 is [True, False, False, False, True, False]
State prediction error at timestep 2040 is tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2040 of None
Current timestep = 2041. State = [[-0.17622805  0.07409831]]. Action = [[ 0.01619732 -0.00597315  0.         -0.5580121 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2041 is [True, False, False, False, True, False]
State prediction error at timestep 2041 is tensor(4.4783e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2041 of None
Current timestep = 2042. State = [[-0.17977385  0.07232169]]. Action = [[-0.02212454 -0.03945807  0.         -0.68056613]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2042 is [True, False, False, False, True, False]
State prediction error at timestep 2042 is tensor(1.8825e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2042 of None
Current timestep = 2043. State = [[-0.18128738  0.07201996]]. Action = [[ 0.03380539  0.01667565  0.         -0.87480676]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2043 is [True, False, False, False, True, False]
State prediction error at timestep 2043 is tensor(6.2629e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2043 of None
Current timestep = 2044. State = [[-0.18491825  0.07302288]]. Action = [[-0.0419982   0.0153872   0.         -0.53497934]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2044 is [True, False, False, False, True, False]
State prediction error at timestep 2044 is tensor(4.2259e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2044 of None
Current timestep = 2045. State = [[-0.19038162  0.07357406]]. Action = [[-0.04246745  0.00265889  0.         -0.8503483 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2045 is [True, False, False, False, True, False]
State prediction error at timestep 2045 is tensor(3.6793e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2045 of None
Current timestep = 2046. State = [[-0.18912162  0.07346479]]. Action = [[ 0.09808452 -0.00053758  0.         -0.0620988 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2046 is [True, False, False, False, True, False]
State prediction error at timestep 2046 is tensor(2.7927e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2046 of None
Current timestep = 2047. State = [[-0.18398982  0.06861549]]. Action = [[ 0.08413579 -0.08464219  0.         -0.7091573 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2047 is [True, False, False, False, True, False]
State prediction error at timestep 2047 is tensor(2.0301e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2047 of None
Current timestep = 2048. State = [[-0.17762655  0.06660638]]. Action = [[ 0.09754377  0.03041879  0.         -0.5370428 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2048 is [True, False, False, False, True, False]
State prediction error at timestep 2048 is tensor(1.6921e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2048 of None
Current timestep = 2049. State = [[-0.17250273  0.06429368]]. Action = [[ 0.05517866 -0.03645685  0.         -0.4247142 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2049 is [True, False, False, False, True, False]
State prediction error at timestep 2049 is tensor(2.6195e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2049 of None
Current timestep = 2050. State = [[-0.1672917   0.06086146]]. Action = [[ 0.0676359  -0.02245198  0.         -0.7069708 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2050 is [True, False, False, False, True, False]
State prediction error at timestep 2050 is tensor(1.4036e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2050 of None
Current timestep = 2051. State = [[-0.16093378  0.05490771]]. Action = [[ 0.07429614 -0.07619172  0.         -0.8136693 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2051 is [True, False, False, False, True, False]
State prediction error at timestep 2051 is tensor(4.1926e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2051 of None
Current timestep = 2052. State = [[-0.15359665  0.04708311]]. Action = [[ 0.07782354 -0.07798155  0.         -0.64201164]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2052 is [True, False, False, False, True, False]
State prediction error at timestep 2052 is tensor(5.0854e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2052 of None
Current timestep = 2053. State = [[-0.14740324  0.039268  ]]. Action = [[ 0.04158098 -0.06985439  0.         -0.8442948 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2053 is [True, False, False, False, True, False]
State prediction error at timestep 2053 is tensor(5.3663e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2053 of None
Current timestep = 2054. State = [[-0.1417257  0.0321725]]. Action = [[ 0.04378786 -0.05608621  0.         -0.6917757 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2054 is [True, False, False, False, True, False]
State prediction error at timestep 2054 is tensor(3.0801e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2054 of None
Current timestep = 2055. State = [[-0.14025688  0.02607686]]. Action = [[-0.04934667 -0.04336429  0.         -0.16025674]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2055 is [True, False, False, False, True, False]
State prediction error at timestep 2055 is tensor(2.4949e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2055 of None
Current timestep = 2056. State = [[-0.1365402   0.02187058]]. Action = [[ 0.05278175 -0.01491598  0.         -0.71469307]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2056 is [True, False, False, False, True, False]
State prediction error at timestep 2056 is tensor(1.0299e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2056 of None
Current timestep = 2057. State = [[-0.12873363  0.02256775]]. Action = [[ 0.09201544  0.06728884  0.         -0.8123585 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2057 is [True, False, False, False, True, False]
State prediction error at timestep 2057 is tensor(1.2728e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2057 of None
Current timestep = 2058. State = [[-0.12067601  0.01925998]]. Action = [[ 0.07859137 -0.06698947  0.         -0.6260587 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2058 is [True, False, False, False, True, False]
State prediction error at timestep 2058 is tensor(9.0904e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2058 of None
Current timestep = 2059. State = [[-0.11846516  0.01999392]]. Action = [[-0.03980444  0.08463757  0.         -0.8456797 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2059 is [True, False, False, False, True, False]
State prediction error at timestep 2059 is tensor(1.9282e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2059 of None
Current timestep = 2060. State = [[-0.11380815  0.02273794]]. Action = [[ 0.08982819  0.02738572  0.         -0.6167861 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2060 is [True, False, False, False, True, False]
State prediction error at timestep 2060 is tensor(5.3818e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2060 of None
Current timestep = 2061. State = [[-0.10596013  0.02146491]]. Action = [[ 0.08414281 -0.02955075  0.         -0.74389136]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2061 is [True, False, False, False, True, False]
State prediction error at timestep 2061 is tensor(7.7384e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2061 of None
Current timestep = 2062. State = [[-0.09762493  0.02265315]]. Action = [[ 0.09217752  0.05346137  0.         -0.9119563 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2062 is [True, False, False, False, True, False]
State prediction error at timestep 2062 is tensor(1.7915e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2062 of None
Current timestep = 2063. State = [[-0.09068456  0.02029247]]. Action = [[ 0.05725295 -0.0682315   0.         -0.83147734]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2063 is [True, False, False, False, True, False]
State prediction error at timestep 2063 is tensor(1.2464e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2063 of None
Current timestep = 2064. State = [[-0.08832072  0.01623944]]. Action = [[-0.02924123 -0.03566024  0.         -0.95203453]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2064 is [True, False, False, False, True, False]
State prediction error at timestep 2064 is tensor(1.8756e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2064 of None
Current timestep = 2065. State = [[-0.08339366  0.0150313 ]]. Action = [[ 0.07122745  0.00488486  0.         -0.8950248 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2065 is [True, False, False, False, True, False]
State prediction error at timestep 2065 is tensor(1.0124e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2065 of None
Current timestep = 2066. State = [[-0.07528898  0.01660737]]. Action = [[ 0.08610214  0.03742514  0.         -0.90061045]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2066 is [True, False, False, False, True, False]
State prediction error at timestep 2066 is tensor(8.9208e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2066 of None
Current timestep = 2067. State = [[-0.06704247  0.01931627]]. Action = [[ 0.08196724  0.03823162  0.         -0.7759532 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2067 is [True, False, False, False, True, False]
State prediction error at timestep 2067 is tensor(2.8126e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2067 of None
Current timestep = 2068. State = [[-0.05813916  0.02292372]]. Action = [[ 0.09958778  0.05242372  0.         -0.6836162 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2068 is [True, False, False, False, True, False]
State prediction error at timestep 2068 is tensor(4.1398e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2068 of None
Current timestep = 2069. State = [[-0.37596616 -0.03393117]]. Action = [[ 0.08022767  0.0657806   0.         -0.7379656 ]]. Reward = [100.]
Curr episode timestep = 28
Scene graph at timestep 2069 is [True, False, False, False, True, False]
State prediction error at timestep 2069 is tensor(0.0537, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2069 of None
Current timestep = 2070. State = [[-0.37577745 -0.02652969]]. Action = [[ 0.05184052  0.07145155  0.         -0.7491648 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2070 is [True, False, False, False, True, False]
State prediction error at timestep 2070 is tensor(5.7785e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2070 of None
Current timestep = 2071. State = [[-0.37597844 -0.02292654]]. Action = [[ 0.          0.          0.         -0.12619627]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2071 is [True, False, False, False, True, False]
State prediction error at timestep 2071 is tensor(8.8233e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2071 of None
Current timestep = 2072. State = [[-0.37719285 -0.02166511]]. Action = [[ 0.         0.         0.        -0.6996737]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2072 is [True, False, False, False, True, False]
State prediction error at timestep 2072 is tensor(7.0987e-08, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2072 of None
Current timestep = 2073. State = [[-0.37815192 -0.02069011]]. Action = [[ 0.         0.         0.        -0.4586407]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2073 is [True, False, False, False, True, False]
State prediction error at timestep 2073 is tensor(7.2627e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2073 of None
Current timestep = 2074. State = [[-0.37666395 -0.02167641]]. Action = [[ 0.04360054 -0.0365596   0.         -0.9594409 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2074 is [True, False, False, False, True, False]
State prediction error at timestep 2074 is tensor(3.7440e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2074 of None
Current timestep = 2075. State = [[-0.37459236 -0.0258627 ]]. Action = [[ 0.01956846 -0.0724463   0.         -0.7488304 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2075 is [True, False, False, False, True, False]
State prediction error at timestep 2075 is tensor(1.9991e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2075 of None
Current timestep = 2076. State = [[-0.37361354 -0.02801207]]. Action = [[ 0.         0.         0.        -0.7745847]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2076 is [True, False, False, False, True, False]
State prediction error at timestep 2076 is tensor(1.7070e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2076 of None
Current timestep = 2077. State = [[-0.36935604 -0.02401488]]. Action = [[ 0.08058866  0.08236361  0.         -0.05239803]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2077 is [True, False, False, False, True, False]
State prediction error at timestep 2077 is tensor(8.6544e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2077 of None
Current timestep = 2078. State = [[-0.36518547 -0.01745427]]. Action = [[ 0.04052996  0.07463264  0.         -0.5825109 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2078 is [True, False, False, False, True, False]
State prediction error at timestep 2078 is tensor(3.5339e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2078 of None
Current timestep = 2079. State = [[-0.36665535 -0.01818576]]. Action = [[-0.06103964 -0.07947865  0.         -0.62652385]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2079 is [True, False, False, False, True, False]
State prediction error at timestep 2079 is tensor(2.3145e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2079 of None
Current timestep = 2080. State = [[-0.36412007 -0.02387348]]. Action = [[ 0.07502728 -0.06857237  0.          0.07422733]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2080 is [True, False, False, False, True, False]
State prediction error at timestep 2080 is tensor(5.5026e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2080 of None
Current timestep = 2081. State = [[-0.3588211 -0.0298616]]. Action = [[ 0.04359373 -0.06797627  0.         -0.6650615 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2081 is [True, False, False, False, True, False]
State prediction error at timestep 2081 is tensor(3.5685e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2081 of None
Current timestep = 2082. State = [[-0.3525867  -0.03688909]]. Action = [[ 0.06869035 -0.08216002  0.         -0.54166996]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2082 is [True, False, False, False, True, False]
State prediction error at timestep 2082 is tensor(3.4474e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2082 of None
Current timestep = 2083. State = [[-0.34452266 -0.03961242]]. Action = [[ 0.08879609  0.0183474   0.         -0.80585766]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2083 is [True, False, False, False, True, False]
State prediction error at timestep 2083 is tensor(3.1433e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2083 of None
Current timestep = 2084. State = [[-0.34374598 -0.04210993]]. Action = [[-0.08013237 -0.03161792  0.         -0.8468472 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2084 is [True, False, False, False, True, False]
State prediction error at timestep 2084 is tensor(2.0215e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2084 of None
Current timestep = 2085. State = [[-0.3442489  -0.04215766]]. Action = [[ 0.00520352  0.04512084  0.         -0.9250009 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2085 is [True, False, False, False, True, False]
State prediction error at timestep 2085 is tensor(1.0968e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2085 of None
Current timestep = 2086. State = [[-0.33931267 -0.04528967]]. Action = [[ 0.08555204 -0.06736097  0.          0.00294006]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2086 is [True, False, False, False, True, False]
State prediction error at timestep 2086 is tensor(3.4998e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2086 of None
Current timestep = 2087. State = [[-0.33657596 -0.05003743]]. Action = [[-0.0157382  -0.03408208  0.         -0.6100067 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2087 is [True, False, False, False, True, False]
State prediction error at timestep 2087 is tensor(2.3170e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2087 of None
Current timestep = 2088. State = [[-0.3315963  -0.04887649]]. Action = [[ 0.08864117  0.06713737  0.         -0.5611474 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2088 is [True, False, False, False, True, False]
State prediction error at timestep 2088 is tensor(1.7945e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2088 of None
Current timestep = 2089. State = [[-0.3295706  -0.04783912]]. Action = [[-0.02316185 -0.00514565  0.         -0.75909203]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2089 is [True, False, False, False, True, False]
State prediction error at timestep 2089 is tensor(7.8149e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2089 of None
Current timestep = 2090. State = [[-0.32563168 -0.05286438]]. Action = [[ 0.07589506 -0.08673968  0.         -0.6877132 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2090 is [True, False, False, False, True, False]
State prediction error at timestep 2090 is tensor(1.2856e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2090 of None
Current timestep = 2091. State = [[-0.3181157  -0.05839587]]. Action = [[ 0.0876822 -0.0438421  0.        -0.6295253]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2091 is [True, False, False, False, True, False]
State prediction error at timestep 2091 is tensor(3.4292e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2091 of None
Current timestep = 2092. State = [[-0.31069747 -0.06117422]]. Action = [[ 0.07064772 -0.00942732  0.         -0.80206776]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2092 is [True, False, False, False, True, False]
State prediction error at timestep 2092 is tensor(3.2981e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2092 of None
Current timestep = 2093. State = [[-0.30634722 -0.05785631]]. Action = [[ 0.01754422  0.09089483  0.         -0.53692394]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2093 is [True, False, False, False, True, False]
State prediction error at timestep 2093 is tensor(2.6725e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2093 of None
Current timestep = 2094. State = [[-0.301073   -0.05068976]]. Action = [[ 0.07702167  0.09916077  0.         -0.907673  ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2094 is [True, False, False, False, True, False]
State prediction error at timestep 2094 is tensor(2.6324e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2094 of None
Current timestep = 2095. State = [[-0.2987472  -0.05153637]]. Action = [[-0.01690278 -0.09326633  0.         -0.6348256 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2095 is [True, False, False, False, True, False]
State prediction error at timestep 2095 is tensor(6.6009e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2095 of None
Current timestep = 2096. State = [[-0.29374412 -0.05086203]]. Action = [[ 0.08987369  0.06927032  0.         -0.73856807]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2096 is [True, False, False, False, True, False]
State prediction error at timestep 2096 is tensor(1.8937e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2096 of None
Current timestep = 2097. State = [[-0.2857927  -0.05020029]]. Action = [[ 0.09323671 -0.02965726  0.         -0.5148325 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2097 is [True, False, False, False, True, False]
State prediction error at timestep 2097 is tensor(1.0752e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2097 of None
Current timestep = 2098. State = [[-0.27922246 -0.05377376]]. Action = [[ 0.0505309  -0.06055908  0.         -0.72134393]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2098 is [True, False, False, False, True, False]
State prediction error at timestep 2098 is tensor(2.9834e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2098 of None
Current timestep = 2099. State = [[-0.27902597 -0.05348885]]. Action = [[-0.06843056  0.04477815  0.         -0.7533258 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2099 is [True, False, False, False, True, False]
State prediction error at timestep 2099 is tensor(2.4547e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2099 of None
Current timestep = 2100. State = [[-0.2759298  -0.05231194]]. Action = [[ 0.07355393 -0.00167563  0.         -0.8772686 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 2100 is [True, False, False, False, True, False]
State prediction error at timestep 2100 is tensor(5.5269e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2100 of None
Current timestep = 2101. State = [[-0.26958033 -0.0553563 ]]. Action = [[ 0.05479223 -0.06292859  0.         -0.4396646 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 2101 is [True, False, False, False, True, False]
State prediction error at timestep 2101 is tensor(5.6735e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2101 of None
Current timestep = 2102. State = [[-0.2615192 -0.0555158]]. Action = [[ 0.09276492  0.03549366  0.         -0.76898867]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 2102 is [True, False, False, False, True, False]
State prediction error at timestep 2102 is tensor(1.5001e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2102 of None
Current timestep = 2103. State = [[-0.26134557 -0.05472497]]. Action = [[-0.09684883  0.00115497  0.         -0.72193503]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 2103 is [True, False, False, False, True, False]
State prediction error at timestep 2103 is tensor(3.7177e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2103 of None
Current timestep = 2104. State = [[-0.25823593 -0.0583452 ]]. Action = [[ 0.09229407 -0.0734306   0.         -0.6368722 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 2104 is [True, False, False, False, True, False]
State prediction error at timestep 2104 is tensor(1.2772e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2104 of None
Current timestep = 2105. State = [[-0.2527614  -0.05754874]]. Action = [[ 0.0234257   0.06532428  0.         -0.66746515]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 2105 is [True, False, False, False, True, False]
State prediction error at timestep 2105 is tensor(8.9999e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2105 of None
Current timestep = 2106. State = [[-0.2500141  -0.05348226]]. Action = [[ 0.00564619  0.04849797  0.         -0.88531405]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 2106 is [True, False, False, False, True, False]
State prediction error at timestep 2106 is tensor(1.5220e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2106 of None
Current timestep = 2107. State = [[-0.25213006 -0.05000393]]. Action = [[-0.0789506   0.03757674  0.         -0.9002422 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 2107 is [True, False, False, False, True, False]
State prediction error at timestep 2107 is tensor(8.3496e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2107 of None
Current timestep = 2108. State = [[-0.25182968 -0.04769942]]. Action = [[ 0.02487864  0.01530015  0.         -0.9506971 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 2108 is [True, False, False, False, True, False]
State prediction error at timestep 2108 is tensor(4.4025e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2108 of None
Current timestep = 2109. State = [[-0.25128344 -0.04517844]]. Action = [[-0.02153303  0.02786226  0.         -0.47561765]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 2109 is [True, False, False, False, True, False]
State prediction error at timestep 2109 is tensor(8.4535e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2109 of None
Current timestep = 2110. State = [[-0.24744388 -0.04327958]]. Action = [[ 0.07634465  0.00492861  0.         -0.66831815]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 2110 is [True, False, False, False, True, False]
State prediction error at timestep 2110 is tensor(8.7427e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2110 of None
Current timestep = 2111. State = [[-0.2427764  -0.04127443]]. Action = [[ 0.04129284  0.0192      0.         -0.6090237 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 2111 is [True, False, False, False, True, False]
State prediction error at timestep 2111 is tensor(1.2178e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2111 of None
Current timestep = 2112. State = [[-0.23690172 -0.03865945]]. Action = [[ 0.08373549  0.02424316  0.         -0.5177543 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 2112 is [True, False, False, False, True, False]
State prediction error at timestep 2112 is tensor(6.0027e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2112 of None
Current timestep = 2113. State = [[-0.23207997 -0.03735072]]. Action = [[ 0.03752174 -0.00391766  0.         -0.64594495]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 2113 is [True, False, False, False, True, False]
State prediction error at timestep 2113 is tensor(4.8336e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2113 of None
Current timestep = 2114. State = [[-0.22531745 -0.03798983]]. Action = [[ 0.09741122 -0.02319481  0.         -0.9294714 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 2114 is [True, False, False, False, True, False]
State prediction error at timestep 2114 is tensor(5.3238e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2114 of None
Current timestep = 2115. State = [[-0.22233586 -0.03606964]]. Action = [[-0.0195099   0.04421837  0.         -0.7734585 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 2115 is [True, False, False, False, True, False]
State prediction error at timestep 2115 is tensor(1.3189e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2115 of None
Current timestep = 2116. State = [[-0.2186755  -0.03727952]]. Action = [[ 0.06011402 -0.05739626  0.         -0.5614508 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 2116 is [True, False, False, False, True, False]
State prediction error at timestep 2116 is tensor(5.8219e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2116 of None
Current timestep = 2117. State = [[-0.21251364 -0.03468822]]. Action = [[ 0.0669065   0.07980285  0.         -0.40596902]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 2117 is [True, False, False, False, True, False]
State prediction error at timestep 2117 is tensor(9.7203e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2117 of None
Current timestep = 2118. State = [[-0.2061969  -0.03637329]]. Action = [[ 0.06372831 -0.08383036  0.         -0.61683446]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 2118 is [True, False, False, False, True, False]
State prediction error at timestep 2118 is tensor(7.6785e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2118 of None
Current timestep = 2119. State = [[-0.20554157 -0.03954975]]. Action = [[-0.06483383 -0.01658482  0.         -0.80676067]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 2119 is [True, False, False, False, True, False]
State prediction error at timestep 2119 is tensor(9.6807e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2119 of None
Current timestep = 2120. State = [[-0.20141953 -0.03615733]]. Action = [[ 0.09061628  0.08121691  0.         -0.9499032 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 2120 is [True, False, False, False, True, False]
State prediction error at timestep 2120 is tensor(2.6065e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2120 of None
Current timestep = 2121. State = [[-0.19337298 -0.03538225]]. Action = [[ 0.08776952 -0.03268515  0.          0.03675807]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 2121 is [True, False, False, False, True, False]
State prediction error at timestep 2121 is tensor(5.9270e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2121 of None
Current timestep = 2122. State = [[-0.18466651 -0.03514344]]. Action = [[ 0.0944695   0.02260832  0.         -0.48396862]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 2122 is [True, False, False, False, True, False]
State prediction error at timestep 2122 is tensor(1.9936e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2122 of None
Current timestep = 2123. State = [[-0.17567632 -0.03398533]]. Action = [[ 0.09537133  0.01328667  0.         -0.72856355]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 2123 is [True, False, False, False, True, False]
State prediction error at timestep 2123 is tensor(4.9900e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2123 of None
Current timestep = 2124. State = [[-0.16768724 -0.03732103]]. Action = [[ 0.06856572 -0.07170288  0.         -0.6965709 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 2124 is [True, False, False, False, True, False]
State prediction error at timestep 2124 is tensor(1.5414e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2124 of None
Current timestep = 2125. State = [[-0.15861483 -0.04081505]]. Action = [[ 0.0976556  -0.02019124  0.         -0.9433741 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 2125 is [True, False, False, False, True, False]
State prediction error at timestep 2125 is tensor(1.9848e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2125 of None
Current timestep = 2126. State = [[-0.14928618 -0.038696  ]]. Action = [[ 0.08621324  0.06819778  0.         -0.8169987 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 2126 is [True, False, False, False, True, False]
State prediction error at timestep 2126 is tensor(1.5628e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2126 of None
Current timestep = 2127. State = [[-0.14308035 -0.0374213 ]]. Action = [[ 0.02704117 -0.00460273  0.         -0.9553156 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 2127 is [True, False, False, False, True, False]
State prediction error at timestep 2127 is tensor(2.5082e-08, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2127 of None
Current timestep = 2128. State = [[-0.13738495 -0.03401256]]. Action = [[ 0.04683531  0.0741713   0.         -0.8506223 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 2128 is [True, False, False, False, True, False]
State prediction error at timestep 2128 is tensor(2.0879e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2128 of None
Current timestep = 2129. State = [[-0.1337232  -0.03285066]]. Action = [[-0.00373783 -0.02141617  0.         -0.6351721 ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 2129 is [True, False, False, False, True, False]
State prediction error at timestep 2129 is tensor(4.2606e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2129 of None
Current timestep = 2130. State = [[-0.12940648 -0.02951805]]. Action = [[ 0.03632654  0.07074923  0.         -0.8500497 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 2130 is [True, False, False, False, True, False]
State prediction error at timestep 2130 is tensor(8.7619e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2130 of None
Current timestep = 2131. State = [[-0.12367807 -0.02504462]]. Action = [[ 0.05112118  0.03562803  0.         -0.86496997]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 2131 is [True, False, False, False, True, False]
State prediction error at timestep 2131 is tensor(3.2355e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2131 of None
Current timestep = 2132. State = [[-0.11652987 -0.02073403]]. Action = [[ 0.07496034  0.04555864  0.         -0.77108985]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 2132 is [True, False, False, False, True, False]
State prediction error at timestep 2132 is tensor(6.8459e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2132 of None
Current timestep = 2133. State = [[-0.10793889 -0.01806595]]. Action = [[ 0.09433389  0.00582851  0.         -0.637296  ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 2133 is [True, False, False, False, True, False]
State prediction error at timestep 2133 is tensor(5.1255e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2133 of None
Current timestep = 2134. State = [[-0.1026051  -0.01644209]]. Action = [[ 0.0134153   0.00845905  0.         -0.87577254]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 2134 is [True, False, False, False, True, False]
State prediction error at timestep 2134 is tensor(4.6190e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2134 of None
Current timestep = 2135. State = [[-0.09525192 -0.01465901]]. Action = [[ 0.0975268   0.01139613  0.         -0.5766652 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 2135 is [True, False, False, False, True, False]
State prediction error at timestep 2135 is tensor(7.1678e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2135 of None
Current timestep = 2136. State = [[-0.08581326 -0.00960254]]. Action = [[ 0.09824861  0.07747155  0.         -0.88086325]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 2136 is [True, False, False, False, True, False]
State prediction error at timestep 2136 is tensor(3.3815e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2136 of None
Current timestep = 2137. State = [[-0.07856223 -0.00691663]]. Action = [[ 0.0513319  -0.00924149  0.         -0.72224313]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 2137 is [True, False, False, False, True, False]
State prediction error at timestep 2137 is tensor(2.3011e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2137 of None
Current timestep = 2138. State = [[-0.07489213 -0.00372557]]. Action = [[-0.00267905  0.04866091  0.         -0.3994099 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 2138 is [True, False, False, False, True, False]
State prediction error at timestep 2138 is tensor(3.4635e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2138 of None
Current timestep = 2139. State = [[-0.06902101 -0.00114858]]. Action = [[ 0.0733748   0.00220177  0.         -0.7024549 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 2139 is [True, False, False, False, True, False]
State prediction error at timestep 2139 is tensor(1.8191e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2139 of None
Current timestep = 2140. State = [[-0.06031899  0.0025441 ]]. Action = [[ 0.09269846  0.05226893  0.         -0.8589531 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 2140 is [True, False, False, False, True, False]
State prediction error at timestep 2140 is tensor(2.0020e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2140 of None
Current timestep = 2141. State = [[-0.05232677  0.00536398]]. Action = [[ 0.06721617  0.00816886  0.         -0.7852907 ]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 2141 is [True, False, False, False, True, False]
State prediction error at timestep 2141 is tensor(6.9968e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2141 of None
Current timestep = 2142. State = [[-0.26301754 -0.01021509]]. Action = [[ 0.09659994 -0.02690257  0.         -0.9557064 ]]. Reward = [100.]
Curr episode timestep = 72
Scene graph at timestep 2142 is [True, False, False, False, True, False]
State prediction error at timestep 2142 is tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2142 of None
Current timestep = 2143. State = [[-0.26424626 -0.01303921]]. Action = [[ 0.01310309  0.00549413  0.         -0.4903974 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2143 is [True, False, False, False, True, False]
State prediction error at timestep 2143 is tensor(1.9901e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2143 of None
Current timestep = 2144. State = [[-0.26529825 -0.00906312]]. Action = [[-0.02182757  0.09208221  0.         -0.88825953]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2144 is [True, False, False, False, True, False]
State prediction error at timestep 2144 is tensor(1.1248e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2144 of None
Current timestep = 2145. State = [[-0.2687241  -0.01071882]]. Action = [[-0.04895104 -0.08085679  0.         -0.70770276]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2145 is [True, False, False, False, True, False]
State prediction error at timestep 2145 is tensor(3.3581e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2145 of None
Current timestep = 2146. State = [[-0.26727015 -0.01203025]]. Action = [[ 0.0693872   0.03085137  0.         -0.6876879 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2146 is [True, False, False, False, True, False]
State prediction error at timestep 2146 is tensor(9.3445e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2146 of None
Current timestep = 2147. State = [[-0.26128328 -0.01571045]]. Action = [[ 0.09772278 -0.07560444  0.         -0.7019553 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2147 is [True, False, False, False, True, False]
State prediction error at timestep 2147 is tensor(2.2246e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2147 of None
Current timestep = 2148. State = [[-0.25526452 -0.02204179]]. Action = [[ 0.06936122 -0.06374541  0.         -0.77969414]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2148 is [True, False, False, False, True, False]
State prediction error at timestep 2148 is tensor(5.4620e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2148 of None
Current timestep = 2149. State = [[-0.24836665 -0.02733426]]. Action = [[ 0.09229455 -0.04048368  0.         -0.6248826 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2149 is [True, False, False, False, True, False]
State prediction error at timestep 2149 is tensor(2.0506e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2149 of None
Current timestep = 2150. State = [[-0.24175672 -0.03459946]]. Action = [[ 0.06587394 -0.08848347  0.         -0.7685342 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2150 is [True, False, False, False, True, False]
State prediction error at timestep 2150 is tensor(2.8773e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2150 of None
Current timestep = 2151. State = [[-0.23522982 -0.04096248]]. Action = [[ 0.06960637 -0.03665306  0.         -0.35014975]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2151 is [True, False, False, False, True, False]
State prediction error at timestep 2151 is tensor(1.7554e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2151 of None
Current timestep = 2152. State = [[-0.22975564 -0.04170646]]. Action = [[ 0.04471863  0.05112544  0.         -0.81643754]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2152 is [True, False, False, False, True, False]
State prediction error at timestep 2152 is tensor(8.7731e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2152 of None
Current timestep = 2153. State = [[-0.22492093 -0.04532203]]. Action = [[ 0.04553283 -0.061931    0.         -0.78082895]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2153 is [True, False, False, False, True, False]
State prediction error at timestep 2153 is tensor(1.2503e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2153 of None
Current timestep = 2154. State = [[-0.22134317 -0.0452903 ]]. Action = [[ 0.01697206  0.07255734  0.         -0.86938906]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2154 is [True, False, False, False, True, False]
State prediction error at timestep 2154 is tensor(4.0650e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2154 of None
Current timestep = 2155. State = [[-0.21890531 -0.04208864]]. Action = [[ 0.01390644  0.05086664  0.         -0.4359535 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2155 is [True, False, False, False, True, False]
State prediction error at timestep 2155 is tensor(1.8595e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2155 of None
Current timestep = 2156. State = [[-0.21549776 -0.04162839]]. Action = [[ 0.03828648 -0.00673381  0.         -0.8118084 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2156 is [True, False, False, False, True, False]
State prediction error at timestep 2156 is tensor(1.5307e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2156 of None
Current timestep = 2157. State = [[-0.21654133 -0.04573384]]. Action = [[-0.07199503 -0.06882069  0.          0.03345966]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2157 is [True, False, False, False, True, False]
State prediction error at timestep 2157 is tensor(5.3685e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2157 of None
Current timestep = 2158. State = [[-0.2143294  -0.04661423]]. Action = [[ 0.0574482   0.03282958  0.         -0.62578714]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2158 is [True, False, False, False, True, False]
State prediction error at timestep 2158 is tensor(5.1908e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2158 of None
Current timestep = 2159. State = [[-0.2104304  -0.04221795]]. Action = [[ 0.02678014  0.07359334  0.         -0.8975516 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2159 is [True, False, False, False, True, False]
State prediction error at timestep 2159 is tensor(3.8469e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2159 of None
Current timestep = 2160. State = [[-0.20577782 -0.03526317]]. Action = [[ 0.06463177  0.08748663  0.         -0.5327623 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2160 is [True, False, False, False, True, False]
State prediction error at timestep 2160 is tensor(4.4778e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2160 of None
Current timestep = 2161. State = [[-0.20117629 -0.03599135]]. Action = [[ 0.04417754 -0.08374321  0.         -0.40641427]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2161 is [True, False, False, False, True, False]
State prediction error at timestep 2161 is tensor(5.3816e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2161 of None
Current timestep = 2162. State = [[-0.19432785 -0.04162196]]. Action = [[ 0.09141605 -0.07573875  0.         -0.6833906 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2162 is [True, False, False, False, True, False]
State prediction error at timestep 2162 is tensor(3.3772e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2162 of None
Current timestep = 2163. State = [[-0.186474   -0.04642794]]. Action = [[ 0.07788203 -0.04959209  0.         -0.9528366 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2163 is [True, False, False, False, True, False]
State prediction error at timestep 2163 is tensor(3.0884e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2163 of None
Current timestep = 2164. State = [[-0.17771994 -0.04733382]]. Action = [[ 0.09784154  0.02051841  0.         -0.55809426]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2164 is [True, False, False, False, True, False]
State prediction error at timestep 2164 is tensor(7.6157e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2164 of None
Current timestep = 2165. State = [[-0.17129377 -0.04440072]]. Action = [[ 0.03933606  0.05708695  0.         -0.8669518 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2165 is [True, False, False, False, True, False]
State prediction error at timestep 2165 is tensor(3.5121e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2165 of None
Current timestep = 2166. State = [[-0.16523796 -0.0443752 ]]. Action = [[ 0.06242806 -0.02697437  0.         -0.92268294]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2166 is [True, False, False, False, True, False]
State prediction error at timestep 2166 is tensor(3.3222e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2166 of None
Current timestep = 2167. State = [[-0.15702324 -0.04185816]]. Action = [[ 0.0930252   0.07091851  0.         -0.7666979 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2167 is [True, False, False, False, True, False]
State prediction error at timestep 2167 is tensor(8.1077e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2167 of None
Current timestep = 2168. State = [[-0.14875129 -0.03709099]]. Action = [[ 0.07949234  0.05668362  0.         -0.8910675 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2168 is [True, False, False, False, True, False]
State prediction error at timestep 2168 is tensor(1.5791e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2168 of None
Current timestep = 2169. State = [[-0.14030421 -0.03394375]]. Action = [[ 0.08919057  0.02434828  0.         -0.58589923]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2169 is [True, False, False, False, True, False]
State prediction error at timestep 2169 is tensor(1.5472e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2169 of None
Current timestep = 2170. State = [[-0.13446578 -0.03328405]]. Action = [[ 0.02543271 -0.00946163  0.         -0.748123  ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2170 is [True, False, False, False, True, False]
State prediction error at timestep 2170 is tensor(1.5824e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2170 of None
Current timestep = 2171. State = [[-0.12915353 -0.0313881 ]]. Action = [[ 0.04448114  0.0334642   0.         -0.7982858 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2171 is [True, False, False, False, True, False]
State prediction error at timestep 2171 is tensor(7.3514e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2171 of None
Current timestep = 2172. State = [[-0.12196545 -0.03026235]]. Action = [[ 0.07308481 -0.00858855  0.         -0.8102075 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2172 is [True, False, False, False, True, False]
State prediction error at timestep 2172 is tensor(4.1938e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2172 of None
Current timestep = 2173. State = [[-0.11273132 -0.02970433]]. Action = [[ 0.09639398  0.00436942  0.         -0.8183365 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 2173 is [True, False, False, False, True, False]
State prediction error at timestep 2173 is tensor(1.1644e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2173 of None
Current timestep = 2174. State = [[-0.10472322 -0.02784321]]. Action = [[ 0.05621586  0.02564182  0.         -0.8970431 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 2174 is [True, False, False, False, True, False]
State prediction error at timestep 2174 is tensor(7.2185e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2174 of None
Current timestep = 2175. State = [[-0.09661518 -0.02496804]]. Action = [[ 0.07963467  0.03256858  0.         -0.7774067 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 2175 is [True, False, False, False, True, False]
State prediction error at timestep 2175 is tensor(1.0310e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2175 of None
Current timestep = 2176. State = [[-0.08772786 -0.02557169]]. Action = [[ 0.08199871 -0.04146483  0.         -0.7201262 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 2176 is [True, False, False, False, True, False]
State prediction error at timestep 2176 is tensor(1.5984e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2176 of None
Current timestep = 2177. State = [[-0.07926922 -0.02804655]]. Action = [[ 0.06591887 -0.03164613  0.         -0.6922244 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 2177 is [True, False, False, False, True, False]
State prediction error at timestep 2177 is tensor(2.4863e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2177 of None
Current timestep = 2178. State = [[-0.06961406 -0.03210418]]. Action = [[ 0.09556199 -0.06070488  0.         -0.67568827]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 2178 is [True, False, False, False, True, False]
State prediction error at timestep 2178 is tensor(3.0737e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2178 of None
Current timestep = 2179. State = [[-0.05891626 -0.03505739]]. Action = [[ 0.09911758 -0.01317322  0.         -0.8914578 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 2179 is [True, False, False, False, True, False]
State prediction error at timestep 2179 is tensor(3.8848e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2179 of None
Current timestep = 2180. State = [[-0.31939977 -0.07141694]]. Action = [[ 0.09520493  0.06124016  0.         -0.9179528 ]]. Reward = [100.]
Curr episode timestep = 37
Scene graph at timestep 2180 is [True, False, False, False, True, False]
State prediction error at timestep 2180 is tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2180 of None
Current timestep = 2181. State = [[-0.31826043 -0.07642271]]. Action = [[-0.03626205 -0.02979593  0.         -0.7330902 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2181 is [True, False, False, False, True, False]
State prediction error at timestep 2181 is tensor(2.1591e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2181 of None
Current timestep = 2182. State = [[-0.31660485 -0.08103891]]. Action = [[ 0.04209018 -0.04719483  0.         -0.7463738 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2182 is [True, False, False, False, True, False]
State prediction error at timestep 2182 is tensor(1.4574e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2182 of None
Current timestep = 2183. State = [[-0.31350154 -0.0836168 ]]. Action = [[ 0.03481861 -0.00092122  0.         -0.08596969]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2183 is [True, False, False, False, True, False]
State prediction error at timestep 2183 is tensor(3.3176e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2183 of None
Current timestep = 2184. State = [[-0.31239754 -0.08502482]]. Action = [[-0.00274123 -0.00683625  0.         -0.52560395]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2184 is [True, False, False, False, True, False]
State prediction error at timestep 2184 is tensor(1.6479e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2184 of None
Current timestep = 2185. State = [[-0.30882096 -0.08537897]]. Action = [[ 0.07262746  0.01289845  0.         -0.63804   ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2185 is [True, False, False, False, True, False]
State prediction error at timestep 2185 is tensor(4.6987e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2185 of None
Current timestep = 2186. State = [[-0.30418703 -0.08104638]]. Action = [[ 0.05497346  0.08381572  0.         -0.52441454]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2186 is [True, False, False, False, True, False]
State prediction error at timestep 2186 is tensor(2.5654e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2186 of None
Current timestep = 2187. State = [[-0.29855716 -0.08018281]]. Action = [[ 0.0846254  -0.03738692  0.         -0.8490511 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2187 is [True, False, False, False, True, False]
State prediction error at timestep 2187 is tensor(8.2365e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2187 of None
Current timestep = 2188. State = [[-0.29136077 -0.07762814]]. Action = [[ 0.09710243  0.06272978  0.         -0.81101733]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2188 is [True, False, False, False, True, False]
State prediction error at timestep 2188 is tensor(1.9698e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2188 of None
Current timestep = 2189. State = [[-0.2894585  -0.07237455]]. Action = [[-0.02332053  0.05923373  0.         -0.7125813 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2189 is [True, False, False, False, True, False]
State prediction error at timestep 2189 is tensor(1.9732e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2189 of None
Current timestep = 2190. State = [[-0.2898     -0.06550808]]. Action = [[ 0.00478889  0.08785314  0.         -0.8048503 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2190 is [True, False, False, False, True, False]
State prediction error at timestep 2190 is tensor(1.8078e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2190 of None
Current timestep = 2191. State = [[-0.28849533 -0.05794818]]. Action = [[ 0.02918658  0.07463581  0.         -0.75920856]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2191 is [True, False, False, False, True, False]
State prediction error at timestep 2191 is tensor(2.9926e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2191 of None
Current timestep = 2192. State = [[-0.289468   -0.05312231]]. Action = [[-0.03274957  0.01990362  0.         -0.78873605]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2192 is [True, False, False, False, True, False]
State prediction error at timestep 2192 is tensor(1.4798e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2192 of None
Current timestep = 2193. State = [[-0.28888574 -0.04868826]]. Action = [[ 0.03100256  0.04281905  0.         -0.87073946]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2193 is [True, False, False, False, True, False]
State prediction error at timestep 2193 is tensor(1.2339e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2193 of None
Current timestep = 2194. State = [[-0.2924    -0.0481755]]. Action = [[-0.09240369 -0.04769427  0.         -0.17139363]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2194 is [True, False, False, False, True, False]
State prediction error at timestep 2194 is tensor(1.8866e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2194 of None
Current timestep = 2195. State = [[-0.291046   -0.04729789]]. Action = [[ 0.08121882  0.01639817  0.         -0.8673735 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2195 is [True, False, False, False, True, False]
State prediction error at timestep 2195 is tensor(3.2640e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2195 of None
Current timestep = 2196. State = [[-0.28428513 -0.04875446]]. Action = [[ 0.08313558 -0.06425627  0.         -0.68542695]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2196 is [True, False, False, False, True, False]
State prediction error at timestep 2196 is tensor(5.6121e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2196 of None
Current timestep = 2197. State = [[-0.28136873 -0.05414415]]. Action = [[-0.01424632 -0.08530056  0.         -0.36598223]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2197 is [True, False, False, False, True, False]
State prediction error at timestep 2197 is tensor(2.3283e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2197 of None
Current timestep = 2198. State = [[-0.28348964 -0.05185653]]. Action = [[-0.0670972   0.09793491  0.         -0.43774086]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2198 is [True, False, False, False, True, False]
State prediction error at timestep 2198 is tensor(9.6738e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2198 of None
Current timestep = 2199. State = [[-0.28264344 -0.05274297]]. Action = [[ 0.03642911 -0.07555277  0.         -0.8339595 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2199 is [True, False, False, False, True, False]
State prediction error at timestep 2199 is tensor(1.8416e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2199 of None
Current timestep = 2200. State = [[-0.27972323 -0.05834058]]. Action = [[ 0.01355038 -0.06608024  0.         -0.64054656]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2200 is [True, False, False, False, True, False]
State prediction error at timestep 2200 is tensor(2.5630e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2200 of None
Current timestep = 2201. State = [[-0.27500415 -0.05663858]]. Action = [[ 0.06410051  0.08586755  0.         -0.9416331 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2201 is [True, False, False, False, True, False]
State prediction error at timestep 2201 is tensor(3.1218e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2201 of None
Current timestep = 2202. State = [[-0.27599496 -0.05144817]]. Action = [[-0.07961445  0.0587888   0.         -0.79323775]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2202 is [True, False, False, False, True, False]
State prediction error at timestep 2202 is tensor(1.1577e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2202 of None
Current timestep = 2203. State = [[-0.2740518  -0.04554152]]. Action = [[ 0.08225162  0.07433679  0.         -0.7416922 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2203 is [True, False, False, False, True, False]
State prediction error at timestep 2203 is tensor(2.3200e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2203 of None
Current timestep = 2204. State = [[-0.26708376 -0.04502689]]. Action = [[ 0.09204487 -0.04965553  0.         -0.8018539 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2204 is [True, False, False, False, True, False]
State prediction error at timestep 2204 is tensor(7.4959e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2204 of None
Current timestep = 2205. State = [[-0.26688504 -0.04136061]]. Action = [[-0.07394211  0.09177326  0.         -0.96471226]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2205 is [True, False, False, False, True, False]
State prediction error at timestep 2205 is tensor(2.2193e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2205 of None
Current timestep = 2206. State = [[-0.2676333  -0.03999778]]. Action = [[ 0.0273067  -0.03989367  0.         -0.8492055 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2206 is [True, False, False, False, True, False]
State prediction error at timestep 2206 is tensor(1.5530e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2206 of None
Current timestep = 2207. State = [[-0.26373738 -0.0419675 ]]. Action = [[ 0.06787015 -0.03262566  0.         -0.6918812 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2207 is [True, False, False, False, True, False]
State prediction error at timestep 2207 is tensor(7.8789e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2207 of None
Current timestep = 2208. State = [[-0.25857627 -0.03971643]]. Action = [[ 0.0649158   0.05449963  0.         -0.75414354]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2208 is [True, False, False, False, True, False]
State prediction error at timestep 2208 is tensor(5.7600e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2208 of None
Current timestep = 2209. State = [[-0.2524589  -0.03379294]]. Action = [[ 0.08581959  0.07444077  0.         -0.6309246 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2209 is [True, False, False, False, True, False]
State prediction error at timestep 2209 is tensor(3.2228e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2209 of None
Current timestep = 2210. State = [[-0.24839596 -0.03078014]]. Action = [[ 2.9320665e-02 -4.1835755e-04  0.0000000e+00 -7.7886093e-01]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2210 is [True, False, False, False, True, False]
State prediction error at timestep 2210 is tensor(3.6661e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2210 of None
Current timestep = 2211. State = [[-0.2490781  -0.02520114]]. Action = [[-0.04305769  0.09498348  0.         -0.7106919 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 2211 is [True, False, False, False, True, False]
State prediction error at timestep 2211 is tensor(8.3473e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2211 of None
Current timestep = 2212. State = [[-0.24646135 -0.01998114]]. Action = [[ 0.07238346  0.02768073  0.         -0.56036866]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 2212 is [True, False, False, False, True, False]
State prediction error at timestep 2212 is tensor(3.3139e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2212 of None
Current timestep = 2213. State = [[-0.24337539 -0.01483324]]. Action = [[ 0.01331724  0.05839355  0.         -0.816988  ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 2213 is [True, False, False, False, True, False]
State prediction error at timestep 2213 is tensor(7.8384e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2213 of None
Current timestep = 2214. State = [[-0.24371399 -0.01352919]]. Action = [[-0.03086914 -0.03674706  0.         -0.9732305 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 2214 is [True, False, False, False, True, False]
State prediction error at timestep 2214 is tensor(1.0201e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2214 of None
Current timestep = 2215. State = [[-0.24301122 -0.01029027]]. Action = [[ 0.01245217  0.05803441  0.         -0.73475826]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 2215 is [True, False, False, False, True, False]
State prediction error at timestep 2215 is tensor(8.0048e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2215 of None
Current timestep = 2216. State = [[-0.23854691 -0.01082675]]. Action = [[ 0.0673211  -0.07034144  0.         -0.5943527 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 2216 is [True, False, False, False, True, False]
State prediction error at timestep 2216 is tensor(2.7238e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2216 of None
Current timestep = 2217. State = [[-0.2364811  -0.01415637]]. Action = [[-0.02319967 -0.04546806  0.         -0.5879204 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 2217 is [True, False, False, False, True, False]
State prediction error at timestep 2217 is tensor(2.1086e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2217 of None
Current timestep = 2218. State = [[-0.23232964 -0.01374148]]. Action = [[ 0.06740948  0.026627    0.         -0.9394976 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 2218 is [True, False, False, False, True, False]
State prediction error at timestep 2218 is tensor(2.2648e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2218 of None
Current timestep = 2219. State = [[-0.22584271 -0.01122862]]. Action = [[ 0.07046141  0.02833051  0.         -0.8812407 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 2219 is [True, False, False, False, True, False]
State prediction error at timestep 2219 is tensor(1.0304e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2219 of None
Current timestep = 2220. State = [[-0.21790412 -0.01285801]]. Action = [[ 0.0945126  -0.05455989  0.         -0.8523961 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 2220 is [True, False, False, False, True, False]
State prediction error at timestep 2220 is tensor(1.5866e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2220 of None
Current timestep = 2221. State = [[-0.21194637 -0.0102969 ]]. Action = [[ 0.03579352  0.08383629  0.         -0.79426634]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 2221 is [True, False, False, False, True, False]
State prediction error at timestep 2221 is tensor(4.2366e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2221 of None
Current timestep = 2222. State = [[-0.20848954 -0.01216457]]. Action = [[ 0.01526804 -0.08552314  0.         -0.4898486 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 2222 is [True, False, False, False, True, False]
State prediction error at timestep 2222 is tensor(4.8579e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2222 of None
Current timestep = 2223. State = [[-0.20438018 -0.01318077]]. Action = [[ 0.0359166   0.03178173  0.         -0.6424788 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 2223 is [True, False, False, False, True, False]
State prediction error at timestep 2223 is tensor(8.9088e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2223 of None
Current timestep = 2224. State = [[-0.19807166 -0.01206287]]. Action = [[ 0.07250495  0.01042271  0.         -0.8684698 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 2224 is [True, False, False, False, True, False]
State prediction error at timestep 2224 is tensor(4.8359e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2224 of None
Current timestep = 2225. State = [[-0.19095331 -0.01535383]]. Action = [[ 0.06600267 -0.06813071  0.         -0.8549006 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 2225 is [True, False, False, False, True, False]
State prediction error at timestep 2225 is tensor(9.5524e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2225 of None
Current timestep = 2226. State = [[-0.18289761 -0.02112836]]. Action = [[ 0.08178654 -0.06498727  0.         -0.6865346 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 2226 is [True, False, False, False, True, False]
State prediction error at timestep 2226 is tensor(1.3002e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2226 of None
Current timestep = 2227. State = [[-0.17447276 -0.02526459]]. Action = [[ 0.07713566 -0.02416232  0.         -0.6715404 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 2227 is [True, False, False, False, True, False]
State prediction error at timestep 2227 is tensor(2.2033e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2227 of None
Current timestep = 2228. State = [[-0.16556002 -0.02413305]]. Action = [[ 0.09033356  0.06070095  0.         -0.4349326 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 2228 is [True, False, False, False, True, False]
State prediction error at timestep 2228 is tensor(2.3108e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2228 of None
Current timestep = 2229. State = [[-0.15637791 -0.02169262]]. Action = [[ 0.0926056   0.03279562  0.         -0.89564043]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 2229 is [True, False, False, False, True, False]
State prediction error at timestep 2229 is tensor(2.8302e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2229 of None
Current timestep = 2230. State = [[-0.14794952 -0.0252117 ]]. Action = [[ 0.07244848 -0.07575184  0.         -0.36236298]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 2230 is [True, False, False, False, True, False]
State prediction error at timestep 2230 is tensor(1.7679e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2230 of None
Current timestep = 2231. State = [[-0.13863687 -0.02642175]]. Action = [[ 0.09654432  0.03705608  0.         -0.8491398 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 2231 is [True, False, False, False, True, False]
State prediction error at timestep 2231 is tensor(2.8214e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2231 of None
Current timestep = 2232. State = [[-0.1300442  -0.02607221]]. Action = [[ 0.06910076  0.00314766  0.         -0.6684801 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 2232 is [True, False, False, False, True, False]
State prediction error at timestep 2232 is tensor(3.8428e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2232 of None
Current timestep = 2233. State = [[-0.1212923  -0.02414992]]. Action = [[ 0.08581955  0.0478408   0.         -0.8084413 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 2233 is [True, False, False, False, True, False]
State prediction error at timestep 2233 is tensor(1.4588e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2233 of None
Current timestep = 2234. State = [[-0.11186824 -0.02032634]]. Action = [[ 0.09276981  0.05524457  0.         -0.8084444 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 2234 is [True, False, False, False, True, False]
State prediction error at timestep 2234 is tensor(1.5735e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2234 of None
Current timestep = 2235. State = [[-0.10442881 -0.01469763]]. Action = [[ 0.04935656  0.07834812  0.         -0.3738699 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 2235 is [True, False, False, False, True, False]
State prediction error at timestep 2235 is tensor(1.4732e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2235 of None
Current timestep = 2236. State = [[-0.09735556 -0.00756764]]. Action = [[ 0.06843627  0.08428133  0.         -0.9085394 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 2236 is [True, False, False, False, True, False]
State prediction error at timestep 2236 is tensor(1.9511e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2236 of None
Current timestep = 2237. State = [[-0.08855074 -0.00208347]]. Action = [[ 0.09685425  0.03810836  0.         -0.6599349 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 2237 is [True, False, False, False, True, False]
State prediction error at timestep 2237 is tensor(1.6497e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2237 of None
Current timestep = 2238. State = [[-0.07926887  0.00234431]]. Action = [[ 0.08923567  0.03934874  0.         -0.7693007 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 2238 is [True, False, False, False, True, False]
State prediction error at timestep 2238 is tensor(1.3597e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2238 of None
Current timestep = 2239. State = [[-0.06994322  0.00559737]]. Action = [[ 0.09114068  0.01416167  0.         -0.46581817]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 2239 is [True, False, False, False, True, False]
State prediction error at timestep 2239 is tensor(5.6086e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2239 of None
Current timestep = 2240. State = [[-0.06192259  0.00754064]]. Action = [[ 0.05843974  0.00253371  0.         -0.8860392 ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 2240 is [True, False, False, False, True, False]
State prediction error at timestep 2240 is tensor(4.7704e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2240 of None
Current timestep = 2241. State = [[-0.05302174  0.01248717]]. Action = [[ 0.09205598  0.07077346  0.         -0.8242326 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 2241 is [True, False, False, False, True, False]
State prediction error at timestep 2241 is tensor(1.9879e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2241 of None
Current timestep = 2242. State = [[-0.37289354 -0.08627842]]. Action = [[ 0.09875721  0.05986457  0.         -0.90077627]]. Reward = [100.]
Curr episode timestep = 61
Scene graph at timestep 2242 is [True, False, False, False, True, False]
State prediction error at timestep 2242 is tensor(0.0572, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2242 of None
Current timestep = 2243. State = [[-0.37605235 -0.08297321]]. Action = [[ 0.          0.          0.         -0.19837606]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2243 is [True, False, False, False, True, False]
State prediction error at timestep 2243 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2243 of None
Current timestep = 2244. State = [[-0.37386465 -0.07678714]]. Action = [[ 0.08333495  0.09629221  0.         -0.87656265]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2244 is [True, False, False, False, True, False]
State prediction error at timestep 2244 is tensor(3.8566e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2244 of None
Current timestep = 2245. State = [[-0.3707451  -0.06892308]]. Action = [[ 0.04937898  0.05695754  0.         -0.29824537]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2245 is [True, False, False, False, True, False]
State prediction error at timestep 2245 is tensor(4.3340e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2245 of None
Current timestep = 2246. State = [[-0.3723458  -0.06443328]]. Action = [[-0.03300421  0.01321103  0.         -0.84742904]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2246 is [True, False, False, False, True, False]
State prediction error at timestep 2246 is tensor(2.0703e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2246 of None
Current timestep = 2247. State = [[-0.3723685  -0.06174603]]. Action = [[ 0.04563809  0.01203857  0.         -0.7173923 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2247 is [True, False, False, False, True, False]
State prediction error at timestep 2247 is tensor(1.3953e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2247 of None
Current timestep = 2248. State = [[-0.36910677 -0.05944059]]. Action = [[ 0.06425517  0.00355053  0.         -0.61138594]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2248 is [True, False, False, False, True, False]
State prediction error at timestep 2248 is tensor(1.1603e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2248 of None
Current timestep = 2249. State = [[-0.3685209 -0.0578968]]. Action = [[-0.01191027 -0.0022737   0.          0.09164095]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2249 is [True, False, False, False, True, False]
State prediction error at timestep 2249 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2249 of None
Current timestep = 2250. State = [[-0.37174416 -0.05387419]]. Action = [[-0.05328181  0.061751    0.         -0.956331  ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2250 is [True, False, False, False, True, False]
State prediction error at timestep 2250 is tensor(2.3983e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2250 of None
Current timestep = 2251. State = [[-0.37356335 -0.05114742]]. Action = [[ 0.          0.          0.         -0.60929036]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2251 is [True, False, False, False, True, False]
State prediction error at timestep 2251 is tensor(4.2082e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2251 of None
Current timestep = 2252. State = [[-0.37385374 -0.05012566]]. Action = [[ 0.         0.         0.        -0.8488882]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2252 is [True, False, False, False, True, False]
State prediction error at timestep 2252 is tensor(5.1344e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2252 of None
Current timestep = 2253. State = [[-0.36932188 -0.05248547]]. Action = [[ 0.09559562 -0.06524719  0.         -0.4252128 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2253 is [True, False, False, False, True, False]
State prediction error at timestep 2253 is tensor(3.1387e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2253 of None
Current timestep = 2254. State = [[-0.36394188 -0.05009172]]. Action = [[ 0.04876322  0.07105371  0.         -0.16609746]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2254 is [True, False, False, False, True, False]
State prediction error at timestep 2254 is tensor(2.3818e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2254 of None
Current timestep = 2255. State = [[-0.36234242 -0.05137771]]. Action = [[-0.0143524  -0.08515617  0.         -0.8538518 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2255 is [True, False, False, False, True, False]
State prediction error at timestep 2255 is tensor(5.7111e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2255 of None
Current timestep = 2256. State = [[-0.3580334  -0.05220739]]. Action = [[ 0.0770774   0.03092421  0.         -0.9601101 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2256 is [True, False, False, False, True, False]
State prediction error at timestep 2256 is tensor(2.0355e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2256 of None
Current timestep = 2257. State = [[-0.35742408 -0.04701392]]. Action = [[-0.05438379  0.08521523  0.         -0.40065557]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2257 is [True, False, False, False, True, False]
State prediction error at timestep 2257 is tensor(2.1965e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2257 of None
Current timestep = 2258. State = [[-0.35484222 -0.04291519]]. Action = [[ 0.07678554  0.01988445  0.         -0.18565059]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2258 is [True, False, False, False, True, False]
State prediction error at timestep 2258 is tensor(3.5530e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2258 of None
Current timestep = 2259. State = [[-0.34819305 -0.03921575]]. Action = [[ 0.08133716  0.04177692  0.         -0.4728788 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2259 is [True, False, False, False, True, False]
State prediction error at timestep 2259 is tensor(2.6466e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2259 of None
Current timestep = 2260. State = [[-0.3428025  -0.03956078]]. Action = [[ 0.04512591 -0.050362    0.         -0.89649403]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2260 is [True, False, False, False, True, False]
State prediction error at timestep 2260 is tensor(7.9381e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2260 of None
Current timestep = 2261. State = [[-0.34117463 -0.03596712]]. Action = [[-0.01769609  0.0894675   0.         -0.624701  ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2261 is [True, False, False, False, True, False]
State prediction error at timestep 2261 is tensor(1.6666e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2261 of None
Current timestep = 2262. State = [[-0.33910802 -0.03645928]]. Action = [[ 0.02981282 -0.07394589  0.         -0.05849141]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2262 is [True, False, False, False, True, False]
State prediction error at timestep 2262 is tensor(1.2603e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2262 of None
Current timestep = 2263. State = [[-0.335442   -0.03674796]]. Action = [[ 0.03237689  0.02736867  0.         -0.65549874]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2263 is [True, False, False, False, True, False]
State prediction error at timestep 2263 is tensor(1.1207e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2263 of None
Current timestep = 2264. State = [[-0.33485138 -0.03586908]]. Action = [[-0.03375189 -0.00334872  0.         -0.00227123]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2264 is [True, False, False, False, True, False]
State prediction error at timestep 2264 is tensor(2.1939e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2264 of None
Current timestep = 2265. State = [[-0.33518603 -0.0379641 ]]. Action = [[-0.01689656 -0.0430889   0.         -0.06681818]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2265 is [True, False, False, False, True, False]
State prediction error at timestep 2265 is tensor(1.3205e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2265 of None
Current timestep = 2266. State = [[-0.338066   -0.04391726]]. Action = [[-0.07845607 -0.08792026  0.         -0.70493734]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2266 is [True, False, False, False, True, False]
State prediction error at timestep 2266 is tensor(3.2054e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2266 of None
Current timestep = 2267. State = [[-0.3350385  -0.04503379]]. Action = [[ 0.09220923  0.04623552  0.         -0.8830076 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2267 is [True, False, False, False, True, False]
State prediction error at timestep 2267 is tensor(2.1198e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2267 of None
Current timestep = 2268. State = [[-0.32900673 -0.0469512 ]]. Action = [[ 0.04575998 -0.05873357  0.         -0.4975419 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2268 is [True, False, False, False, True, False]
State prediction error at timestep 2268 is tensor(2.9029e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2268 of None
Current timestep = 2269. State = [[-0.32146746 -0.04815847]]. Action = [[ 0.09625603  0.0162185   0.         -0.9787694 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2269 is [True, False, False, False, True, False]
State prediction error at timestep 2269 is tensor(1.3048e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2269 of None
Current timestep = 2270. State = [[-0.31512585 -0.04332389]]. Action = [[ 0.04860901  0.09195871  0.         -0.876549  ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2270 is [True, False, False, False, True, False]
State prediction error at timestep 2270 is tensor(3.0205e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2270 of None
Current timestep = 2271. State = [[-0.31342575 -0.03825989]]. Action = [[-0.01472108  0.044573    0.         -0.8148338 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2271 is [True, False, False, False, True, False]
State prediction error at timestep 2271 is tensor(1.6548e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2271 of None
Current timestep = 2272. State = [[-0.31105947 -0.04013561]]. Action = [[ 0.03613932 -0.06976211  0.         -0.68719935]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2272 is [True, False, False, False, True, False]
State prediction error at timestep 2272 is tensor(2.7305e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2272 of None
Current timestep = 2273. State = [[-0.3067266  -0.04595697]]. Action = [[ 0.04403412 -0.07442878  0.         -0.45899975]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 2273 is [True, False, False, False, True, False]
State prediction error at timestep 2273 is tensor(1.0469e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2273 of None
Current timestep = 2274. State = [[-0.3079067  -0.04823638]]. Action = [[-0.08431592  0.01115428  0.         -0.6367619 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 2274 is [True, False, False, False, True, False]
State prediction error at timestep 2274 is tensor(1.1808e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2274 of None
Current timestep = 2275. State = [[-0.30817056 -0.04394155]]. Action = [[ 0.02351715  0.08951546  0.         -0.9115758 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 2275 is [True, False, False, False, True, False]
State prediction error at timestep 2275 is tensor(1.9477e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2275 of None
Current timestep = 2276. State = [[-0.3055868  -0.03657198]]. Action = [[ 0.03890703  0.08783453  0.         -0.52458966]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 2276 is [True, False, False, False, True, False]
State prediction error at timestep 2276 is tensor(3.3812e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2276 of None
Current timestep = 2277. State = [[-0.30175298 -0.03208843]]. Action = [[ 0.05932985  0.01785298  0.         -0.64973783]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 2277 is [True, False, False, False, True, False]
State prediction error at timestep 2277 is tensor(1.6162e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2277 of None
Current timestep = 2278. State = [[-0.3001084  -0.02968937]]. Action = [[0.00057664 0.01587118 0.         0.08637691]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 2278 is [True, False, False, False, True, False]
State prediction error at timestep 2278 is tensor(2.7034e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2278 of None
Current timestep = 2279. State = [[-0.30117118 -0.03034023]]. Action = [[-0.02641135 -0.03942272  0.         -0.8412722 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 2279 is [True, False, False, False, True, False]
State prediction error at timestep 2279 is tensor(2.9399e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2279 of None
Current timestep = 2280. State = [[-0.2977221  -0.03197771]]. Action = [[ 0.07914574 -0.02286188  0.         -0.8599236 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 2280 is [True, False, False, False, True, False]
State prediction error at timestep 2280 is tensor(3.0077e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2280 of None
Current timestep = 2281. State = [[-0.29466227 -0.03484796]]. Action = [[ 0.00458811 -0.05127779  0.         -0.83575076]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 2281 is [True, False, False, False, True, False]
State prediction error at timestep 2281 is tensor(1.2763e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2281 of None
Current timestep = 2282. State = [[-0.28953457 -0.03494429]]. Action = [[ 0.08188529  0.02654404  0.         -0.92763484]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 2282 is [True, False, False, False, True, False]
State prediction error at timestep 2282 is tensor(1.8870e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2282 of None
Current timestep = 2283. State = [[-0.2852897  -0.03453315]]. Action = [[ 0.02152716 -0.0075549   0.         -0.5980332 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 2283 is [True, False, False, False, True, False]
State prediction error at timestep 2283 is tensor(1.1929e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2283 of None
Current timestep = 2284. State = [[-0.27899683 -0.03209264]]. Action = [[ 0.09459274  0.05183373  0.         -0.8822773 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 2284 is [True, False, False, False, True, False]
State prediction error at timestep 2284 is tensor(1.1324e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2284 of None
Current timestep = 2285. State = [[-0.27556068 -0.03379085]]. Action = [[-0.00600011 -0.06539983  0.         -0.6045402 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 2285 is [True, False, False, False, True, False]
State prediction error at timestep 2285 is tensor(3.4285e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2285 of None
Current timestep = 2286. State = [[-0.27435383 -0.03448338]]. Action = [[-0.00374709  0.02753227  0.         -0.92351466]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 2286 is [True, False, False, False, True, False]
State prediction error at timestep 2286 is tensor(3.3582e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2286 of None
Current timestep = 2287. State = [[-0.27046108 -0.03565948]]. Action = [[ 0.05343831 -0.03387024  0.         -0.786589  ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 2287 is [True, False, False, False, True, False]
State prediction error at timestep 2287 is tensor(5.1157e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2287 of None
Current timestep = 2288. State = [[-0.2660071  -0.03328087]]. Action = [[ 0.03335134  0.07000122  0.         -0.75271744]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 2288 is [True, False, False, False, True, False]
State prediction error at timestep 2288 is tensor(4.1545e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2288 of None
Current timestep = 2289. State = [[-0.25977382 -0.03067924]]. Action = [[ 0.0849565   0.01035764  0.         -0.7569994 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 2289 is [True, False, False, False, True, False]
State prediction error at timestep 2289 is tensor(1.3825e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2289 of None
Current timestep = 2290. State = [[-0.2568195  -0.03482399]]. Action = [[-0.01601676 -0.09237526  0.         -0.46521544]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 2290 is [True, False, False, False, True, False]
State prediction error at timestep 2290 is tensor(1.3298e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2290 of None
Current timestep = 2291. State = [[-0.2526489  -0.03938706]]. Action = [[ 0.05691112 -0.03141432  0.         -0.8102801 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 2291 is [True, False, False, False, True, False]
State prediction error at timestep 2291 is tensor(1.9633e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2291 of None
Current timestep = 2292. State = [[-0.25303644 -0.04146956]]. Action = [[-0.08023644 -0.0095259   0.         -0.91491175]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 2292 is [True, False, False, False, True, False]
State prediction error at timestep 2292 is tensor(1.7038e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2292 of None
Current timestep = 2293. State = [[-0.25425643 -0.04335964]]. Action = [[-0.01299314 -0.01985522  0.         -0.7924722 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 2293 is [True, False, False, False, True, False]
State prediction error at timestep 2293 is tensor(9.7479e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2293 of None
Current timestep = 2294. State = [[-0.25396872 -0.04164953]]. Action = [[-0.00752712  0.05599835  0.         -0.35609853]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 2294 is [True, False, False, False, True, False]
State prediction error at timestep 2294 is tensor(1.4753e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2294 of None
Current timestep = 2295. State = [[-0.24900948 -0.03831988]]. Action = [[ 0.09540071  0.03628919  0.         -0.08933926]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 2295 is [True, False, False, False, True, False]
State prediction error at timestep 2295 is tensor(2.1095e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2295 of None
Current timestep = 2296. State = [[-0.24413474 -0.03931774]]. Action = [[ 0.03528715 -0.04461243  0.         -0.3151809 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 2296 is [True, False, False, False, True, False]
State prediction error at timestep 2296 is tensor(3.2011e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2296 of None
Current timestep = 2297. State = [[-0.24630308 -0.04257752]]. Action = [[-0.08929912 -0.03615852  0.         -0.5353973 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 2297 is [True, False, False, False, True, False]
State prediction error at timestep 2297 is tensor(2.4438e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2297 of None
Current timestep = 2298. State = [[-0.24502863 -0.04159499]]. Action = [[ 0.06597417  0.04662057  0.         -0.78674734]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 2298 is [True, False, False, False, True, False]
State prediction error at timestep 2298 is tensor(7.3362e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2298 of None
Current timestep = 2299. State = [[-0.23857158 -0.03665915]]. Action = [[ 0.09137756  0.07070244  0.         -0.8401236 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 2299 is [True, False, False, False, True, False]
State prediction error at timestep 2299 is tensor(9.1067e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2299 of None
Current timestep = 2300. State = [[-0.23379578 -0.03210286]]. Action = [[ 0.04165796  0.04037599  0.         -0.9108569 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 2300 is [True, False, False, False, True, False]
State prediction error at timestep 2300 is tensor(9.4311e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2300 of None
Current timestep = 2301. State = [[-0.22923417 -0.03454778]]. Action = [[ 0.05897368 -0.08367934  0.         -0.90852666]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 2301 is [True, False, False, False, True, False]
State prediction error at timestep 2301 is tensor(8.1873e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2301 of None
Current timestep = 2302. State = [[-0.22685535 -0.03950002]]. Action = [[-0.00553359 -0.05372531  0.         -0.7197338 ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 2302 is [True, False, False, False, True, False]
State prediction error at timestep 2302 is tensor(2.0375e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2302 of None
Current timestep = 2303. State = [[-0.22219905 -0.04225801]]. Action = [[ 0.07128317 -0.01715165  0.         -0.5977043 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 2303 is [True, False, False, False, True, False]
State prediction error at timestep 2303 is tensor(4.8786e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2303 of None
Current timestep = 2304. State = [[-0.21563146 -0.04239465]]. Action = [[ 0.0679651   0.01602217  0.         -0.7240249 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 2304 is [True, False, False, False, True, False]
State prediction error at timestep 2304 is tensor(3.5533e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2304 of None
Current timestep = 2305. State = [[-0.20827875 -0.04333621]]. Action = [[ 0.08273504 -0.01972803  0.         -0.83090305]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 2305 is [True, False, False, False, True, False]
State prediction error at timestep 2305 is tensor(2.8191e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2305 of None
Current timestep = 2306. State = [[-0.20202851 -0.0431815 ]]. Action = [[ 0.04896792  0.02386029  0.         -0.8556394 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 2306 is [True, False, False, False, True, False]
State prediction error at timestep 2306 is tensor(4.9619e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2306 of None
Current timestep = 2307. State = [[-0.1972117  -0.04548841]]. Action = [[ 0.03494831 -0.05036763  0.         -0.9135217 ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 2307 is [True, False, False, False, True, False]
State prediction error at timestep 2307 is tensor(6.0293e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2307 of None
Current timestep = 2308. State = [[-0.19033521 -0.04284389]]. Action = [[ 0.0842107   0.09209675  0.         -0.8809313 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 2308 is [True, False, False, False, True, False]
State prediction error at timestep 2308 is tensor(7.1568e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2308 of None
Current timestep = 2309. State = [[-0.18536094 -0.04367882]]. Action = [[ 0.01876233 -0.06399553  0.         -0.9486506 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 2309 is [True, False, False, False, True, False]
State prediction error at timestep 2309 is tensor(3.5796e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2309 of None
Current timestep = 2310. State = [[-0.17810911 -0.04558782]]. Action = [[ 0.09476048  0.00363821  0.         -0.8872919 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 2310 is [True, False, False, False, True, False]
State prediction error at timestep 2310 is tensor(1.7058e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2310 of None
Current timestep = 2311. State = [[-0.16955173 -0.04624362]]. Action = [[ 0.07996715 -0.00518726  0.         -0.8330331 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 2311 is [True, False, False, False, True, False]
State prediction error at timestep 2311 is tensor(4.7678e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2311 of None
Current timestep = 2312. State = [[-0.16108476 -0.04687615]]. Action = [[ 0.08210901 -0.00086187  0.         -0.6176252 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 2312 is [True, False, False, False, True, False]
State prediction error at timestep 2312 is tensor(5.2472e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2312 of None
Current timestep = 2313. State = [[-0.15256785 -0.04768902]]. Action = [[ 0.07995523 -0.00611187  0.         -0.418005  ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 2313 is [True, False, False, False, True, False]
State prediction error at timestep 2313 is tensor(3.3817e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2313 of None
Current timestep = 2314. State = [[-0.14755824 -0.04911528]]. Action = [[ 0.00468208 -0.01537731  0.         -0.82334393]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 2314 is [True, False, False, False, True, False]
State prediction error at timestep 2314 is tensor(3.4159e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2314 of None
Current timestep = 2315. State = [[-0.14247413 -0.04785452]]. Action = [[ 0.04633599  0.04322561  0.         -0.9473111 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 2315 is [True, False, False, False, True, False]
State prediction error at timestep 2315 is tensor(1.7173e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2315 of None
Current timestep = 2316. State = [[-0.13458785 -0.04446819]]. Action = [[ 0.08752788  0.04658736  0.         -0.9412108 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 2316 is [True, False, False, False, True, False]
State prediction error at timestep 2316 is tensor(4.0767e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2316 of None
Current timestep = 2317. State = [[-0.12554984 -0.04164551]]. Action = [[ 0.09042872  0.02648198  0.         -0.9131871 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 2317 is [True, False, False, False, True, False]
State prediction error at timestep 2317 is tensor(7.2439e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2317 of None
Current timestep = 2318. State = [[-0.11591881 -0.04278436]]. Action = [[ 0.09872771 -0.04298232  0.         -0.7976482 ]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 2318 is [True, False, False, False, True, False]
State prediction error at timestep 2318 is tensor(1.0053e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2318 of None
Current timestep = 2319. State = [[-0.10661539 -0.04342104]]. Action = [[ 0.08291448  0.01095937  0.         -0.7968614 ]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 2319 is [True, False, False, False, True, False]
State prediction error at timestep 2319 is tensor(1.6065e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2319 of None
Current timestep = 2320. State = [[-0.09712929 -0.04675644]]. Action = [[ 0.091631   -0.07062218  0.         -0.38416815]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 2320 is [True, False, False, False, True, False]
State prediction error at timestep 2320 is tensor(3.1457e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2320 of None
Current timestep = 2321. State = [[-0.08688318 -0.05139721]]. Action = [[ 0.09670518 -0.04468177  0.         -0.87997895]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 2321 is [True, False, False, False, True, False]
State prediction error at timestep 2321 is tensor(3.5400e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2321 of None
Current timestep = 2322. State = [[-0.07687625 -0.05452054]]. Action = [[ 0.0857789  -0.02023631  0.         -0.59540415]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 2322 is [True, False, False, False, True, False]
State prediction error at timestep 2322 is tensor(4.2010e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2322 of None
Current timestep = 2323. State = [[-0.06667214 -0.05910169]]. Action = [[ 0.09310306 -0.06021294  0.         -0.91696554]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 2323 is [True, False, False, False, True, False]
State prediction error at timestep 2323 is tensor(6.0350e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2323 of None
Current timestep = 2324. State = [[-0.05618932 -0.06184841]]. Action = [[ 0.09317856  0.00473066  0.         -0.908568  ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 2324 is [True, False, False, False, True, False]
State prediction error at timestep 2324 is tensor(3.3018e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2324 of None
Current timestep = 2325. State = [[-0.2888549  -0.01213128]]. Action = [[ 0.06608974 -0.06399299  0.         -0.8396954 ]]. Reward = [100.]
Curr episode timestep = 82
Scene graph at timestep 2325 is [True, False, False, False, True, False]
State prediction error at timestep 2325 is tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2325 of None
Current timestep = 2326. State = [[-0.2840051  -0.02044982]]. Action = [[ 0.02850623 -0.07797135  0.         -0.49231458]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2326 is [True, False, False, False, True, False]
State prediction error at timestep 2326 is tensor(5.1539e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2326 of None
Current timestep = 2327. State = [[-0.28455344 -0.02131122]]. Action = [[-0.05363232  0.06723709  0.         -0.8485627 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2327 is [True, False, False, False, True, False]
State prediction error at timestep 2327 is tensor(8.4617e-08, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2327 of None
Current timestep = 2328. State = [[-0.28113842 -0.01925429]]. Action = [[ 0.09348271  0.03412519  0.         -0.75547576]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2328 is [True, False, False, False, True, False]
State prediction error at timestep 2328 is tensor(4.3129e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2328 of None
Current timestep = 2329. State = [[-0.27488986 -0.01438491]]. Action = [[ 0.06742091  0.09663243  0.         -0.6139519 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2329 is [True, False, False, False, True, False]
State prediction error at timestep 2329 is tensor(1.0867e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2329 of None
Current timestep = 2330. State = [[-0.2683036  -0.00764719]]. Action = [[ 0.0919218   0.08551868  0.         -0.74190986]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2330 is [True, False, False, False, True, False]
State prediction error at timestep 2330 is tensor(3.7732e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2330 of None
Current timestep = 2331. State = [[-0.26644236 -0.00324621]]. Action = [[-0.01863408  0.0336472   0.         -0.80526406]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2331 is [True, False, False, False, True, False]
State prediction error at timestep 2331 is tensor(1.2995e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2331 of None
Current timestep = 2332. State = [[-0.2640736  -0.00311089]]. Action = [[ 0.05172678 -0.0269513   0.         -0.8354241 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2332 is [True, False, False, False, True, False]
State prediction error at timestep 2332 is tensor(3.6272e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2332 of None
Current timestep = 2333. State = [[-0.25897828 -0.00130277]]. Action = [[ 0.06611264  0.04139683  0.         -0.8052887 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2333 is [True, False, False, False, True, False]
State prediction error at timestep 2333 is tensor(1.8850e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2333 of None
Current timestep = 2334. State = [[-0.25319943 -0.00068936]]. Action = [[ 0.06672651 -0.02326254  0.         -0.54855627]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2334 is [True, False, False, False, True, False]
State prediction error at timestep 2334 is tensor(3.7895e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2334 of None
Current timestep = 2335. State = [[-0.24554807 -0.0035642 ]]. Action = [[ 0.09442148 -0.05495238  0.         -0.563031  ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2335 is [True, False, False, False, True, False]
State prediction error at timestep 2335 is tensor(4.2215e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2335 of None
Current timestep = 2336. State = [[-0.23661011 -0.00545667]]. Action = [[ 0.09516745 -0.00840105  0.         -0.62465274]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2336 is [True, False, False, False, True, False]
State prediction error at timestep 2336 is tensor(1.8155e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2336 of None
Current timestep = 2337. State = [[-0.22769585 -0.00315908]]. Action = [[ 0.08902691  0.05314296  0.         -0.69848347]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2337 is [True, False, False, False, True, False]
State prediction error at timestep 2337 is tensor(1.0311e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2337 of None
Current timestep = 2338. State = [[-0.21903515  0.00175115]]. Action = [[ 0.08721199  0.06723731  0.         -0.96170485]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2338 is [True, False, False, False, True, False]
State prediction error at timestep 2338 is tensor(3.0673e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2338 of None
Current timestep = 2339. State = [[-0.21177924  0.00568234]]. Action = [[ 0.05755437  0.03379355  0.         -0.8144705 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2339 is [True, False, False, False, True, False]
State prediction error at timestep 2339 is tensor(9.8194e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2339 of None
Current timestep = 2340. State = [[-0.2046793   0.00794284]]. Action = [[ 0.06574263  0.01594424  0.         -0.91365886]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2340 is [True, False, False, False, True, False]
State prediction error at timestep 2340 is tensor(7.4658e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2340 of None
Current timestep = 2341. State = [[-0.19741584  0.01041961]]. Action = [[ 0.06086802  0.02907821  0.         -0.8698179 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2341 is [True, False, False, False, True, False]
State prediction error at timestep 2341 is tensor(7.9968e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2341 of None
Current timestep = 2342. State = [[-0.19014387  0.01483802]]. Action = [[ 0.0622376   0.05732661  0.         -0.9149503 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2342 is [True, False, False, False, True, False]
State prediction error at timestep 2342 is tensor(1.3791e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2342 of None
Current timestep = 2343. State = [[-0.18294983  0.02029194]]. Action = [[ 0.06126256  0.05640531  0.         -0.8595048 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2343 is [True, False, False, False, True, False]
State prediction error at timestep 2343 is tensor(1.8791e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2343 of None
Current timestep = 2344. State = [[-0.17451753  0.01919955]]. Action = [[ 0.08318286 -0.07791068  0.         -0.9511274 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2344 is [True, False, False, False, True, False]
State prediction error at timestep 2344 is tensor(1.5235e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2344 of None
Current timestep = 2345. State = [[-0.1652794   0.01684099]]. Action = [[ 0.07751501 -0.01970569  0.         -0.84599245]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2345 is [True, False, False, False, True, False]
State prediction error at timestep 2345 is tensor(1.1851e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2345 of None
Current timestep = 2346. State = [[-0.1554951   0.01834728]]. Action = [[ 0.08943015  0.0334345   0.         -0.864728  ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2346 is [True, False, False, False, True, False]
State prediction error at timestep 2346 is tensor(1.5643e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2346 of None
Current timestep = 2347. State = [[-0.14688915  0.01804673]]. Action = [[ 0.05791114 -0.03293882  0.         -0.9362595 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2347 is [True, False, False, False, True, False]
State prediction error at timestep 2347 is tensor(1.8039e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2347 of None
Current timestep = 2348. State = [[-0.13868259  0.01477294]]. Action = [[ 0.06150299 -0.05156053  0.         -0.5425628 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2348 is [True, False, False, False, True, False]
State prediction error at timestep 2348 is tensor(3.6371e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2348 of None
Current timestep = 2349. State = [[-0.12853298  0.01389566]]. Action = [[ 0.09893209  0.01621941  0.         -0.46746677]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2349 is [True, False, False, False, True, False]
State prediction error at timestep 2349 is tensor(3.8686e-08, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2349 of None
Current timestep = 2350. State = [[-0.1184213   0.01627747]]. Action = [[ 0.08161073  0.04520065  0.         -0.9336152 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2350 is [True, False, False, False, True, False]
State prediction error at timestep 2350 is tensor(2.2008e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2350 of None
Current timestep = 2351. State = [[-0.10817198  0.01452568]]. Action = [[ 0.09440858 -0.05751735  0.         -0.78297764]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2351 is [True, False, False, False, True, False]
State prediction error at timestep 2351 is tensor(1.0550e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2351 of None
Current timestep = 2352. State = [[-0.09860861  0.01554144]]. Action = [[ 0.07231136  0.06030319  0.         -0.82820183]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2352 is [True, False, False, False, True, False]
State prediction error at timestep 2352 is tensor(3.2715e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2352 of None
Current timestep = 2353. State = [[-0.09083024  0.02017839]]. Action = [[ 0.05319159  0.06287987  0.         -0.7361665 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2353 is [True, False, False, False, True, False]
State prediction error at timestep 2353 is tensor(8.6802e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2353 of None
Current timestep = 2354. State = [[-0.08152942  0.02383875]]. Action = [[ 0.09956909  0.032043    0.         -0.842984  ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2354 is [True, False, False, False, True, False]
State prediction error at timestep 2354 is tensor(1.9221e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2354 of None
Current timestep = 2355. State = [[-0.07253298  0.02864068]]. Action = [[ 0.07111356  0.0694612   0.         -0.64142644]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2355 is [True, False, False, False, True, False]
State prediction error at timestep 2355 is tensor(1.9857e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2355 of None
Current timestep = 2356. State = [[-0.06290396  0.02798913]]. Action = [[ 0.09887465 -0.06490153  0.         -0.86991036]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 2356 is [True, False, False, False, True, False]
State prediction error at timestep 2356 is tensor(2.5910e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2356 of None
Current timestep = 2357. State = [[-0.05327172  0.02609655]]. Action = [[ 0.07799313 -0.00864387  0.         -0.66841626]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 2357 is [True, False, False, False, True, False]
State prediction error at timestep 2357 is tensor(1.7995e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2357 of None
Current timestep = 2358. State = [[-0.27649388  0.14272636]]. Action = [[ 0.09784179 -0.03557031  0.         -0.64178276]]. Reward = [100.]
Curr episode timestep = 32
Scene graph at timestep 2358 is [True, False, False, False, False, True]
State prediction error at timestep 2358 is tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2358 of None
Current timestep = 2359. State = [[-0.26928055  0.14379452]]. Action = [[ 0.09120456 -0.01693121  0.         -0.5568563 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2359 is [True, False, False, False, False, True]
State prediction error at timestep 2359 is tensor(1.0032e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2359 of None
Current timestep = 2360. State = [[-0.26423043  0.13791297]]. Action = [[ 0.0343905  -0.09581011  0.         -0.27851504]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2360 is [True, False, False, False, False, True]
State prediction error at timestep 2360 is tensor(3.0353e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2360 of None
Current timestep = 2361. State = [[-0.25817624  0.13320363]]. Action = [[ 0.07727133 -0.01959458  0.         -0.8316868 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2361 is [True, False, False, False, False, True]
State prediction error at timestep 2361 is tensor(1.0469e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2361 of None
Current timestep = 2362. State = [[-0.25284523  0.12722075]]. Action = [[ 0.03385033 -0.08031459  0.         -0.46478105]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2362 is [True, False, False, False, False, True]
State prediction error at timestep 2362 is tensor(5.0706e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2362 of None
Current timestep = 2363. State = [[-0.24761659  0.12346067]]. Action = [[ 0.05007774  0.00062627  0.         -0.56424415]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2363 is [True, False, False, False, True, False]
State prediction error at timestep 2363 is tensor(3.6601e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2363 of None
Current timestep = 2364. State = [[-0.242618    0.12195749]]. Action = [[ 0.03908857  0.00515439  0.         -0.59582984]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2364 is [True, False, False, False, True, False]
State prediction error at timestep 2364 is tensor(6.5929e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2364 of None
Current timestep = 2365. State = [[-0.23575814  0.11606571]]. Action = [[ 0.08112583 -0.08679802  0.          0.3822986 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2365 is [True, False, False, False, True, False]
State prediction error at timestep 2365 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2365 of None
Current timestep = 2366. State = [[-0.23073007  0.11007726]]. Action = [[ 0.01430281 -0.03350704  0.         -0.8157725 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2366 is [True, False, False, False, True, False]
State prediction error at timestep 2366 is tensor(3.5805e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2366 of None
Current timestep = 2367. State = [[-0.22364247  0.10405923]]. Action = [[ 0.09260821 -0.06097255  0.         -0.38853717]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2367 is [True, False, False, False, True, False]
State prediction error at timestep 2367 is tensor(3.3750e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2367 of None
Current timestep = 2368. State = [[-0.21602704  0.10258249]]. Action = [[ 0.06226272  0.05081921  0.         -0.93208367]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2368 is [True, False, False, False, True, False]
State prediction error at timestep 2368 is tensor(2.2099e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2368 of None
Current timestep = 2369. State = [[-0.20801258  0.10186289]]. Action = [[ 9.0263061e-02  1.9625574e-04  0.0000000e+00 -8.5157400e-01]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2369 is [True, False, False, False, True, False]
State prediction error at timestep 2369 is tensor(1.5452e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2369 of None
Current timestep = 2370. State = [[-0.20209296  0.09699143]]. Action = [[ 0.02838526 -0.06167376  0.         -0.73684573]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2370 is [True, False, False, False, True, False]
State prediction error at timestep 2370 is tensor(3.1762e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2370 of None
Current timestep = 2371. State = [[-0.1942816   0.09459141]]. Action = [[ 0.09864093  0.02235     0.         -0.46603304]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2371 is [True, False, False, False, True, False]
State prediction error at timestep 2371 is tensor(1.6013e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2371 of None
Current timestep = 2372. State = [[-0.18785904  0.09218308]]. Action = [[ 0.0326222  -0.02636062  0.         -0.86586714]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2372 is [True, False, False, False, True, False]
State prediction error at timestep 2372 is tensor(1.0152e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2372 of None
Current timestep = 2373. State = [[-0.17977709  0.08702444]]. Action = [[ 0.09796516 -0.05972104  0.         -0.7609805 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2373 is [True, False, False, False, True, False]
State prediction error at timestep 2373 is tensor(4.4679e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2373 of None
Current timestep = 2374. State = [[-0.17004934  0.08373223]]. Action = [[ 0.09391833  0.00212015  0.         -0.11098039]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2374 is [True, False, False, False, True, False]
State prediction error at timestep 2374 is tensor(3.5951e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2374 of None
Current timestep = 2375. State = [[-0.1635787  0.0841542]]. Action = [[ 0.02885778  0.03983059  0.         -0.603855  ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2375 is [True, False, False, False, True, False]
State prediction error at timestep 2375 is tensor(4.6894e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2375 of None
Current timestep = 2376. State = [[-0.15587652  0.08614046]]. Action = [[ 0.09418886  0.04026983  0.         -0.64929926]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2376 is [True, False, False, False, True, False]
State prediction error at timestep 2376 is tensor(1.1802e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2376 of None
Current timestep = 2377. State = [[-0.14706787  0.08362027]]. Action = [[ 0.08142602 -0.05583203  0.         -0.43448043]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2377 is [True, False, False, False, True, False]
State prediction error at timestep 2377 is tensor(5.8749e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2377 of None
Current timestep = 2378. State = [[-0.13947463  0.08284084]]. Action = [[ 0.05691401  0.03261764  0.         -0.23025393]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2378 is [True, False, False, False, True, False]
State prediction error at timestep 2378 is tensor(6.3146e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2378 of None
Current timestep = 2379. State = [[-0.1345169   0.08044829]]. Action = [[ 0.01479296 -0.05477738  0.         -0.62866175]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2379 is [True, False, False, False, True, False]
State prediction error at timestep 2379 is tensor(3.9055e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2379 of None
Current timestep = 2380. State = [[-0.12723441  0.07703998]]. Action = [[ 0.08189326 -0.02936159  0.         -0.21399802]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2380 is [True, False, False, False, True, False]
State prediction error at timestep 2380 is tensor(3.3667e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2380 of None
Current timestep = 2381. State = [[-0.11810981  0.07285659]]. Action = [[ 0.08225248 -0.0521356   0.         -0.9452148 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2381 is [True, False, False, False, True, False]
State prediction error at timestep 2381 is tensor(2.8683e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2381 of None
Current timestep = 2382. State = [[-0.1082819   0.07090043]]. Action = [[ 0.0939435   0.01052686  0.         -0.8058355 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2382 is [True, False, False, False, True, False]
State prediction error at timestep 2382 is tensor(2.2693e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2382 of None
Current timestep = 2383. State = [[-0.09975891  0.06964643]]. Action = [[ 0.06230449 -0.00980018  0.         -0.6657971 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2383 is [True, False, False, False, True, False]
State prediction error at timestep 2383 is tensor(1.3619e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2383 of None
Current timestep = 2384. State = [[-0.09036309  0.06884126]]. Action = [[ 0.09787103  0.00896859  0.         -0.6292691 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2384 is [True, False, False, False, True, False]
State prediction error at timestep 2384 is tensor(1.1748e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2384 of None
Current timestep = 2385. State = [[-0.08132293  0.07097036]]. Action = [[ 0.0748033   0.05718311  0.         -0.5892274 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2385 is [True, False, False, False, True, False]
State prediction error at timestep 2385 is tensor(4.1936e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2385 of None
Current timestep = 2386. State = [[-0.07201397  0.07111561]]. Action = [[ 0.09466133 -0.01654427  0.         -0.7468144 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2386 is [True, False, False, False, True, False]
State prediction error at timestep 2386 is tensor(1.2430e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2386 of None
Current timestep = 2387. State = [[-0.06333797  0.07175072]]. Action = [[ 0.06932134  0.03261701  0.         -0.868394  ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2387 is [True, False, False, False, True, False]
State prediction error at timestep 2387 is tensor(3.1533e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2387 of None
Current timestep = 2388. State = [[-0.05461646  0.07233539]]. Action = [[ 0.08422663  0.00163013  0.         -0.8645483 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2388 is [True, False, False, False, True, False]
State prediction error at timestep 2388 is tensor(2.2941e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2388 of None
Current timestep = 2389. State = [[-0.24545261 -0.02619015]]. Action = [[ 0.06231455  0.03740575  0.         -0.43248796]]. Reward = [100.]
Curr episode timestep = 30
Scene graph at timestep 2389 is [True, False, False, False, True, False]
State prediction error at timestep 2389 is tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2389 of None
Current timestep = 2390. State = [[-0.23805816 -0.03384442]]. Action = [[ 0.07589338 -0.08475794  0.         -0.738066  ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2390 is [True, False, False, False, True, False]
State prediction error at timestep 2390 is tensor(4.7627e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2390 of None
Current timestep = 2391. State = [[-0.23232731 -0.03528214]]. Action = [[ 0.04806887  0.04527379  0.         -0.4925158 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2391 is [True, False, False, False, True, False]
State prediction error at timestep 2391 is tensor(4.8028e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2391 of None
Current timestep = 2392. State = [[-0.23114093 -0.03295851]]. Action = [[-0.02639691  0.04484666  0.         -0.94690984]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2392 is [True, False, False, False, True, False]
State prediction error at timestep 2392 is tensor(8.2309e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2392 of None
Current timestep = 2393. State = [[-0.23011352 -0.02873388]]. Action = [[ 0.01844903  0.07329576  0.         -0.5744142 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2393 is [True, False, False, False, True, False]
State prediction error at timestep 2393 is tensor(1.8783e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2393 of None
Current timestep = 2394. State = [[-0.22723612 -0.02228764]]. Action = [[ 0.04261561  0.09039498  0.         -0.49898744]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2394 is [True, False, False, False, True, False]
State prediction error at timestep 2394 is tensor(5.0241e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2394 of None
Current timestep = 2395. State = [[-0.22494835 -0.02304367]]. Action = [[ 0.01644798 -0.07484659  0.         -0.3312645 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2395 is [True, False, False, False, True, False]
State prediction error at timestep 2395 is tensor(7.6670e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2395 of None
Current timestep = 2396. State = [[-0.2194666  -0.02472168]]. Action = [[ 0.08991004  0.00542714  0.         -0.8344941 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2396 is [True, False, False, False, True, False]
State prediction error at timestep 2396 is tensor(5.5847e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2396 of None
Current timestep = 2397. State = [[-0.21301618 -0.0220439 ]]. Action = [[ 0.068923    0.05073839  0.         -0.91937625]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2397 is [True, False, False, False, True, False]
State prediction error at timestep 2397 is tensor(1.8785e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2397 of None
Current timestep = 2398. State = [[-0.20664938 -0.02289731]]. Action = [[ 0.07287125 -0.05063012  0.         -0.5934104 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2398 is [True, False, False, False, True, False]
State prediction error at timestep 2398 is tensor(1.8574e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2398 of None
Current timestep = 2399. State = [[-0.20014589 -0.01953916]]. Action = [[ 0.06884853  0.0937571   0.         -0.6599295 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2399 is [True, False, False, False, True, False]
State prediction error at timestep 2399 is tensor(7.6935e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2399 of None
Current timestep = 2400. State = [[-0.19689007 -0.01602919]]. Action = [[ 0.00498621  0.01107061  0.         -0.5636652 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2400 is [True, False, False, False, True, False]
State prediction error at timestep 2400 is tensor(7.5737e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2400 of None
Current timestep = 2401. State = [[-0.19179595 -0.01105638]]. Action = [[ 0.07576319  0.07988025  0.         -0.7469119 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2401 is [True, False, False, False, True, False]
State prediction error at timestep 2401 is tensor(5.7531e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2401 of None
Current timestep = 2402. State = [[-0.18545023 -0.00624738]]. Action = [[ 0.06529222  0.03370104  0.         -0.34557545]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2402 is [True, False, False, False, True, False]
State prediction error at timestep 2402 is tensor(2.5238e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2402 of None
Current timestep = 2403. State = [[-0.17949045 -0.00408931]]. Action = [[ 0.05678835  0.00283074  0.         -0.66759837]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2403 is [True, False, False, False, True, False]
State prediction error at timestep 2403 is tensor(1.5891e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2403 of None
Current timestep = 2404. State = [[-0.17188153 -0.00045367]]. Action = [[ 0.09129449  0.05107193  0.         -0.91328835]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2404 is [True, False, False, False, True, False]
State prediction error at timestep 2404 is tensor(1.5524e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2404 of None
Current timestep = 2405. State = [[-0.16707544  0.0059667 ]]. Action = [[ 0.01441729  0.07727439  0.         -0.5973151 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2405 is [True, False, False, False, True, False]
State prediction error at timestep 2405 is tensor(3.2212e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2405 of None
Current timestep = 2406. State = [[-0.16200396  0.01057219]]. Action = [[ 0.06080169  0.0188597   0.         -0.7852802 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2406 is [True, False, False, False, True, False]
State prediction error at timestep 2406 is tensor(3.6825e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2406 of None
Current timestep = 2407. State = [[-0.15722638  0.01684282]]. Action = [[ 0.02901047  0.08286301  0.         -0.5482693 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2407 is [True, False, False, False, True, False]
State prediction error at timestep 2407 is tensor(2.2793e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2407 of None
Current timestep = 2408. State = [[-0.15289578  0.01919267]]. Action = [[ 0.03499479 -0.03542364  0.         -0.89771336]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2408 is [True, False, False, False, True, False]
State prediction error at timestep 2408 is tensor(4.7372e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2408 of None
Current timestep = 2409. State = [[-0.14984503  0.02264221]]. Action = [[-9.3117356e-05  5.4093756e-02  0.0000000e+00 -6.0097694e-01]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2409 is [True, False, False, False, True, False]
State prediction error at timestep 2409 is tensor(1.9446e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2409 of None
Current timestep = 2410. State = [[-0.15079035  0.03081552]]. Action = [[-0.05994172  0.0959824   0.         -0.44231772]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2410 is [True, False, False, False, True, False]
State prediction error at timestep 2410 is tensor(9.2655e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2410 of None
Current timestep = 2411. State = [[-0.14667957  0.03707615]]. Action = [[ 0.09223992  0.02533235  0.         -0.8628701 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2411 is [True, False, False, False, True, False]
State prediction error at timestep 2411 is tensor(9.1239e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2411 of None
Current timestep = 2412. State = [[-0.14176174  0.04168662]]. Action = [[ 0.01642542  0.03405217  0.         -0.6934314 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2412 is [True, False, False, False, True, False]
State prediction error at timestep 2412 is tensor(5.8712e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2412 of None
Current timestep = 2413. State = [[-0.13518366  0.04573154]]. Action = [[ 0.0892062  0.0216796  0.        -0.8165344]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2413 is [True, False, False, False, True, False]
State prediction error at timestep 2413 is tensor(9.2338e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2413 of None
Current timestep = 2414. State = [[-0.12860793  0.04654478]]. Action = [[ 0.0488174  -0.03012504  0.         -0.8773592 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2414 is [True, False, False, False, True, False]
State prediction error at timestep 2414 is tensor(3.4590e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2414 of None
Current timestep = 2415. State = [[-0.1213041   0.04270211]]. Action = [[ 0.07615846 -0.08519004  0.         -0.8384887 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2415 is [True, False, False, False, True, False]
State prediction error at timestep 2415 is tensor(2.0530e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2415 of None
Current timestep = 2416. State = [[-0.11202762  0.04007923]]. Action = [[ 0.09647613 -0.01305053  0.         -0.51635927]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2416 is [True, False, False, False, True, False]
State prediction error at timestep 2416 is tensor(1.3354e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2416 of None
Current timestep = 2417. State = [[-0.1033597  0.0394556]]. Action = [[ 0.07106823 -0.00207759  0.         -0.4863881 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2417 is [True, False, False, False, True, False]
State prediction error at timestep 2417 is tensor(1.5160e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2417 of None
Current timestep = 2418. State = [[-0.09626716  0.03809765]]. Action = [[ 0.05028272 -0.02012328  0.         -0.905594  ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2418 is [True, False, False, False, True, False]
State prediction error at timestep 2418 is tensor(1.0960e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2418 of None
Current timestep = 2419. State = [[-0.08920888  0.03682484]]. Action = [[ 0.05972619 -0.00414924  0.         -0.89351773]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2419 is [True, False, False, False, True, False]
State prediction error at timestep 2419 is tensor(9.8648e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2419 of None
Current timestep = 2420. State = [[-0.08279164  0.03613547]]. Action = [[ 0.04192575  0.00140314  0.         -0.86978465]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 2420 is [True, False, False, False, True, False]
State prediction error at timestep 2420 is tensor(1.1687e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2420 of None
Current timestep = 2421. State = [[-0.07457474  0.03574549]]. Action = [[ 0.09004005  0.0046204   0.         -0.9455578 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 2421 is [True, False, False, False, True, False]
State prediction error at timestep 2421 is tensor(1.7050e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2421 of None
Current timestep = 2422. State = [[-0.06488644  0.03387958]]. Action = [[ 0.09574192 -0.02489594  0.         -0.7510872 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 2422 is [True, False, False, False, True, False]
State prediction error at timestep 2422 is tensor(1.0302e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2422 of None
Current timestep = 2423. State = [[-0.0564202   0.03353754]]. Action = [[ 0.06609877  0.02512067  0.         -0.35517013]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 2423 is [True, False, False, False, True, False]
State prediction error at timestep 2423 is tensor(1.5354e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2423 of None
Current timestep = 2424. State = [[-0.2973365  -0.02136903]]. Action = [[ 0.08175749  0.01042636  0.         -0.8608798 ]]. Reward = [100.]
Curr episode timestep = 34
Scene graph at timestep 2424 is [True, False, False, False, True, False]
State prediction error at timestep 2424 is tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2424 of None
Current timestep = 2425. State = [[-0.29476765 -0.0281835 ]]. Action = [[ 0.01685073 -0.05333019  0.         -0.8019577 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2425 is [True, False, False, False, True, False]
State prediction error at timestep 2425 is tensor(2.1910e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2425 of None
Current timestep = 2426. State = [[-0.29042256 -0.03070698]]. Action = [[ 0.07665017  0.01319332  0.         -0.84055257]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2426 is [True, False, False, False, True, False]
State prediction error at timestep 2426 is tensor(6.5930e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2426 of None
Current timestep = 2427. State = [[-0.29026285 -0.03461227]]. Action = [[-0.04025168 -0.05235068  0.         -0.6812437 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2427 is [True, False, False, False, True, False]
State prediction error at timestep 2427 is tensor(2.1666e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2427 of None
Current timestep = 2428. State = [[-0.2897215  -0.04264843]]. Action = [[ 0.03204664 -0.0965589   0.         -0.81812835]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2428 is [True, False, False, False, True, False]
State prediction error at timestep 2428 is tensor(4.2717e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2428 of None
Current timestep = 2429. State = [[-0.28557527 -0.05175976]]. Action = [[ 0.06615584 -0.08536029  0.         -0.5382054 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2429 is [True, False, False, False, True, False]
State prediction error at timestep 2429 is tensor(2.6507e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2429 of None
Current timestep = 2430. State = [[-0.28007522 -0.06087805]]. Action = [[ 0.06895471 -0.08610424  0.         -0.55149347]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2430 is [True, False, False, False, True, False]
State prediction error at timestep 2430 is tensor(4.0943e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2430 of None
Current timestep = 2431. State = [[-0.2777199  -0.06865124]]. Action = [[-0.0031734  -0.0542526   0.         -0.88182247]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2431 is [True, False, False, False, True, False]
State prediction error at timestep 2431 is tensor(3.8962e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2431 of None
Current timestep = 2432. State = [[-0.27561817 -0.07500511]]. Action = [[ 0.0318355  -0.04017447  0.         -0.47271442]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2432 is [True, False, False, False, True, False]
State prediction error at timestep 2432 is tensor(1.6200e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2432 of None
Current timestep = 2433. State = [[-0.27328974 -0.07455576]]. Action = [[ 0.0229197  0.0867986  0.        -0.4788344]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2433 is [True, False, False, False, True, False]
State prediction error at timestep 2433 is tensor(3.6806e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2433 of None
Current timestep = 2434. State = [[-0.26913747 -0.07517108]]. Action = [[ 0.07237072 -0.01974927  0.         -0.6899183 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2434 is [True, False, False, False, True, False]
State prediction error at timestep 2434 is tensor(4.3954e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2434 of None
Current timestep = 2435. State = [[-0.26347017 -0.07640147]]. Action = [[ 0.07552034  0.01736271  0.         -0.8412856 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2435 is [True, False, False, False, True, False]
State prediction error at timestep 2435 is tensor(1.9160e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2435 of None
Current timestep = 2436. State = [[-0.26430458 -0.07988654]]. Action = [[-0.06566152 -0.05071032  0.         -0.837077  ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2436 is [True, False, False, False, True, False]
State prediction error at timestep 2436 is tensor(1.5327e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2436 of None
Current timestep = 2437. State = [[-0.26218072 -0.08240447]]. Action = [[ 0.07568691  0.00474111  0.         -0.7912909 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2437 is [True, False, False, False, True, False]
State prediction error at timestep 2437 is tensor(6.8093e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2437 of None
Current timestep = 2438. State = [[-0.25654575 -0.08424146]]. Action = [[ 0.06904859 -0.01938321  0.         -0.42422986]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2438 is [True, False, False, False, True, False]
State prediction error at timestep 2438 is tensor(1.3495e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2438 of None
Current timestep = 2439. State = [[-0.251135   -0.08112506]]. Action = [[ 0.06205701  0.08680419  0.         -0.78986144]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2439 is [True, False, False, False, True, False]
State prediction error at timestep 2439 is tensor(1.3174e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2439 of None
Current timestep = 2440. State = [[-0.24478392 -0.07411634]]. Action = [[ 0.09110708  0.09304314  0.         -0.92645544]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2440 is [True, False, False, False, True, False]
State prediction error at timestep 2440 is tensor(2.7255e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2440 of None
Current timestep = 2441. State = [[-0.24024372 -0.07313029]]. Action = [[ 0.03674013 -0.04383235  0.         -0.8728311 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2441 is [True, False, False, False, True, False]
State prediction error at timestep 2441 is tensor(4.3965e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2441 of None
Current timestep = 2442. State = [[-0.24040046 -0.06991741]]. Action = [[-0.0388041   0.08089615  0.         -0.8659897 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2442 is [True, False, False, False, True, False]
State prediction error at timestep 2442 is tensor(1.8819e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2442 of None
Current timestep = 2443. State = [[-0.24065836 -0.0708991 ]]. Action = [[ 0.00362249 -0.07739653  0.          0.23977077]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2443 is [True, False, False, False, True, False]
State prediction error at timestep 2443 is tensor(3.6495e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2443 of None
Current timestep = 2444. State = [[-0.23561923 -0.06933311]]. Action = [[ 0.08544039  0.06076425  0.         -0.930169  ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2444 is [True, False, False, False, True, False]
State prediction error at timestep 2444 is tensor(4.7755e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2444 of None
Current timestep = 2445. State = [[-0.22951801 -0.06828233]]. Action = [[ 0.05889871 -0.02969915  0.         -0.8536893 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2445 is [True, False, False, False, True, False]
State prediction error at timestep 2445 is tensor(1.8449e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2445 of None
Current timestep = 2446. State = [[-0.22352661 -0.0713158 ]]. Action = [[ 0.06074723 -0.05936772  0.         -0.8269289 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2446 is [True, False, False, False, True, False]
State prediction error at timestep 2446 is tensor(9.0977e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2446 of None
Current timestep = 2447. State = [[-0.21644402 -0.06996359]]. Action = [[ 0.07756708  0.05481762  0.         -0.9436164 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2447 is [True, False, False, False, True, False]
State prediction error at timestep 2447 is tensor(5.1045e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2447 of None
Current timestep = 2448. State = [[-0.21095186 -0.06588157]]. Action = [[ 0.03731804  0.04449791  0.         -0.62982047]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2448 is [True, False, False, False, True, False]
State prediction error at timestep 2448 is tensor(1.5105e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2448 of None
Current timestep = 2449. State = [[-0.20488308 -0.062561  ]]. Action = [[ 0.07070845  0.03027869  0.         -0.62948555]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2449 is [True, False, False, False, True, False]
State prediction error at timestep 2449 is tensor(8.7300e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2449 of None
Current timestep = 2450. State = [[-0.19717658 -0.05827319]]. Action = [[ 0.08634908  0.05588887  0.         -0.9271517 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2450 is [True, False, False, False, True, False]
State prediction error at timestep 2450 is tensor(5.1001e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2450 of None
Current timestep = 2451. State = [[-0.18928361 -0.05417265]]. Action = [[ 0.0808685  0.0346993  0.        -0.9435164]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2451 is [True, False, False, False, True, False]
State prediction error at timestep 2451 is tensor(1.1832e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2451 of None
Current timestep = 2452. State = [[-0.1806611  -0.05493348]]. Action = [[ 0.09331868 -0.05235102  0.         -0.7093009 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2452 is [True, False, False, False, True, False]
State prediction error at timestep 2452 is tensor(5.9947e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2452 of None
Current timestep = 2453. State = [[-0.17251456 -0.05665411]]. Action = [[ 0.06699588 -0.01656963  0.         -0.9520536 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2453 is [True, False, False, False, True, False]
State prediction error at timestep 2453 is tensor(1.6097e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2453 of None
Current timestep = 2454. State = [[-0.16398539 -0.05738796]]. Action = [[ 0.08336391 -0.01024508  0.         -0.7941504 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2454 is [True, False, False, False, True, False]
State prediction error at timestep 2454 is tensor(1.1569e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2454 of None
Current timestep = 2455. State = [[-0.15848051 -0.05407442]]. Action = [[ 0.0089015   0.06881996  0.         -0.5527067 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 2455 is [True, False, False, False, True, False]
State prediction error at timestep 2455 is tensor(8.2048e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2455 of None
Current timestep = 2456. State = [[-0.15367424 -0.04945567]]. Action = [[ 0.03703297  0.0451334   0.         -0.9417611 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 2456 is [True, False, False, False, True, False]
State prediction error at timestep 2456 is tensor(9.6562e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2456 of None
Current timestep = 2457. State = [[-0.14847799 -0.05064555]]. Action = [[ 0.031034   -0.06355295  0.         -0.95257026]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 2457 is [True, False, False, False, True, False]
State prediction error at timestep 2457 is tensor(4.6862e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2457 of None
Current timestep = 2458. State = [[-0.1432271  -0.04898747]]. Action = [[ 0.03188118  0.05966688  0.         -0.83455473]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 2458 is [True, False, False, False, True, False]
State prediction error at timestep 2458 is tensor(7.3602e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2458 of None
Current timestep = 2459. State = [[-0.14221954 -0.04692378]]. Action = [[-0.05401446 -0.00353578  0.         -0.82887137]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 2459 is [True, False, False, False, True, False]
State prediction error at timestep 2459 is tensor(2.3863e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2459 of None
Current timestep = 2460. State = [[-0.13717966 -0.04535126]]. Action = [[ 0.08266122  0.01754208  0.         -0.89889616]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 2460 is [True, False, False, False, True, False]
State prediction error at timestep 2460 is tensor(1.8818e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2460 of None
Current timestep = 2461. State = [[-0.12884486 -0.04263567]]. Action = [[ 0.07742798  0.0309611   0.         -0.8054025 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 2461 is [True, False, False, False, True, False]
State prediction error at timestep 2461 is tensor(7.3011e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2461 of None
Current timestep = 2462. State = [[-0.11994024 -0.03718591]]. Action = [[ 0.0952531   0.07656565  0.         -0.93059874]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 2462 is [True, False, False, False, True, False]
State prediction error at timestep 2462 is tensor(2.0561e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2462 of None
Current timestep = 2463. State = [[-0.11116857 -0.03434538]]. Action = [[ 0.08767491 -0.00425564  0.         -0.52478206]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 2463 is [True, False, False, False, True, False]
State prediction error at timestep 2463 is tensor(1.8448e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2463 of None
Current timestep = 2464. State = [[-0.10265495 -0.03297056]]. Action = [[ 0.08365018  0.01436893  0.         -0.88173735]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 2464 is [True, False, False, False, True, False]
State prediction error at timestep 2464 is tensor(1.5203e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2464 of None
Current timestep = 2465. State = [[-0.09820029 -0.03215728]]. Action = [[-0.0012836  -0.00424589  0.         -0.7283889 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 2465 is [True, False, False, False, True, False]
State prediction error at timestep 2465 is tensor(1.1750e-08, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2465 of None
Current timestep = 2466. State = [[-0.09116256 -0.03242287]]. Action = [[ 0.09639818 -0.01472096  0.         -0.8262749 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 2466 is [True, False, False, False, True, False]
State prediction error at timestep 2466 is tensor(5.1179e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2466 of None
Current timestep = 2467. State = [[-0.08249456 -0.03302027]]. Action = [[ 0.07550306 -0.01012123  0.         -0.52528226]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 2467 is [True, False, False, False, True, False]
State prediction error at timestep 2467 is tensor(1.3513e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2467 of None
Current timestep = 2468. State = [[-0.07417176 -0.02933407]]. Action = [[ 0.07803207  0.07634742  0.         -0.8234763 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 2468 is [True, False, False, False, True, False]
State prediction error at timestep 2468 is tensor(1.7916e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2468 of None
Current timestep = 2469. State = [[-0.06539922 -0.02470292]]. Action = [[ 0.09048951  0.0422091   0.         -0.867611  ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 2469 is [True, False, False, False, True, False]
State prediction error at timestep 2469 is tensor(2.2307e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2469 of None
Current timestep = 2470. State = [[-0.06121172 -0.01968993]]. Action = [[-0.01301849  0.06316798  0.         -0.78624475]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 2470 is [True, False, False, False, True, False]
State prediction error at timestep 2470 is tensor(4.0344e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2470 of None
Current timestep = 2471. State = [[-0.05498954 -0.01654585]]. Action = [[ 0.08827872  0.00771691  0.         -0.77769184]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 2471 is [True, False, False, False, True, False]
State prediction error at timestep 2471 is tensor(2.0360e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2471 of None
Current timestep = 2472. State = [[-0.18758301 -0.03875548]]. Action = [[ 0.09766085  0.06418552  0.         -0.92766166]]. Reward = [100.]
Curr episode timestep = 47
Scene graph at timestep 2472 is [True, False, False, False, True, False]
State prediction error at timestep 2472 is tensor(0.0093, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2472 of None
Current timestep = 2473. State = [[-0.18350653 -0.03641191]]. Action = [[ 0.05319432  0.0009052   0.         -0.4232291 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2473 is [True, False, False, False, True, False]
State prediction error at timestep 2473 is tensor(1.7740e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2473 of None
Current timestep = 2474. State = [[-0.17858599 -0.03414893]]. Action = [[ 0.08711655  0.05027486  0.         -0.8674808 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2474 is [True, False, False, False, True, False]
State prediction error at timestep 2474 is tensor(4.6222e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2474 of None
Current timestep = 2475. State = [[-0.17811148 -0.03569273]]. Action = [[-0.02772795 -0.05743     0.         -0.8499254 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2475 is [True, False, False, False, True, False]
State prediction error at timestep 2475 is tensor(1.9348e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2475 of None
Current timestep = 2476. State = [[-0.17539486 -0.03816486]]. Action = [[ 0.07686878 -0.01479381  0.         -0.6933471 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2476 is [True, False, False, False, True, False]
State prediction error at timestep 2476 is tensor(1.4280e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2476 of None
Current timestep = 2477. State = [[-0.16989924 -0.03789281]]. Action = [[ 0.0743125   0.01923678  0.         -0.71930385]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2477 is [True, False, False, False, True, False]
State prediction error at timestep 2477 is tensor(1.5347e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2477 of None
Current timestep = 2478. State = [[-0.16347095 -0.03849414]]. Action = [[ 0.08682404 -0.01960018  0.         -0.82699203]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2478 is [True, False, False, False, True, False]
State prediction error at timestep 2478 is tensor(1.4837e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2478 of None
Current timestep = 2479. State = [[-0.16052485 -0.03897335]]. Action = [[-0.00132357  0.00583401  0.         -0.84939784]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2479 is [True, False, False, False, True, False]
State prediction error at timestep 2479 is tensor(7.0440e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2479 of None
Current timestep = 2480. State = [[-0.15697761 -0.03602931]]. Action = [[ 0.05692852  0.05961683  0.         -0.85728705]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2480 is [True, False, False, False, True, False]
State prediction error at timestep 2480 is tensor(5.0710e-08, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2480 of None
Current timestep = 2481. State = [[-0.15200913 -0.03284989]]. Action = [[ 0.05559719  0.02733349  0.         -0.70793706]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2481 is [True, False, False, False, True, False]
State prediction error at timestep 2481 is tensor(7.3116e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2481 of None
Current timestep = 2482. State = [[-0.14622812 -0.03121643]]. Action = [[ 0.06735522  0.01057839  0.         -0.89356846]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2482 is [True, False, False, False, True, False]
State prediction error at timestep 2482 is tensor(1.3734e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2482 of None
Current timestep = 2483. State = [[-0.13864887 -0.03032468]]. Action = [[ 0.09295399  0.00576945  0.         -0.42786747]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2483 is [True, False, False, False, True, False]
State prediction error at timestep 2483 is tensor(1.7074e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2483 of None
Current timestep = 2484. State = [[-0.1308825  -0.02605999]]. Action = [[ 0.07935341  0.0760541   0.         -0.79419327]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2484 is [True, False, False, False, True, False]
State prediction error at timestep 2484 is tensor(1.2973e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2484 of None
Current timestep = 2485. State = [[-0.1243425  -0.02189311]]. Action = [[ 0.06002095  0.02911598  0.         -0.8993541 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2485 is [True, False, False, False, True, False]
State prediction error at timestep 2485 is tensor(1.1742e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2485 of None
Current timestep = 2486. State = [[-0.11928547 -0.01996018]]. Action = [[ 0.03430182  0.00646368  0.         -0.12151176]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2486 is [True, False, False, False, True, False]
State prediction error at timestep 2486 is tensor(1.4466e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2486 of None
Current timestep = 2487. State = [[-0.11257955 -0.01850183]]. Action = [[ 0.07711174  0.01002266  0.         -0.848786  ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2487 is [True, False, False, False, True, False]
State prediction error at timestep 2487 is tensor(1.3483e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2487 of None
Current timestep = 2488. State = [[-0.10612844 -0.01667794]]. Action = [[ 0.04493717  0.01601198  0.         -0.9351943 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2488 is [True, False, False, False, True, False]
State prediction error at timestep 2488 is tensor(7.3000e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2488 of None
Current timestep = 2489. State = [[-0.0978737  -0.01580903]]. Action = [[ 0.09535826 -0.00615273  0.         -0.61567634]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2489 is [True, False, False, False, True, False]
State prediction error at timestep 2489 is tensor(2.5421e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2489 of None
Current timestep = 2490. State = [[-0.08967884 -0.01600364]]. Action = [[ 0.06299942 -0.01105327  0.         -0.61708736]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2490 is [True, False, False, False, True, False]
State prediction error at timestep 2490 is tensor(5.6586e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2490 of None
Current timestep = 2491. State = [[-0.0846345  -0.01907698]]. Action = [[ 0.00783949 -0.06252368  0.         -0.8448036 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2491 is [True, False, False, False, True, False]
State prediction error at timestep 2491 is tensor(8.9993e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2491 of None
Current timestep = 2492. State = [[-0.07666132 -0.01691847]]. Action = [[ 0.098485    0.07726877  0.         -0.4965498 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2492 is [True, False, False, False, True, False]
State prediction error at timestep 2492 is tensor(5.6921e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2492 of None
Current timestep = 2493. State = [[-0.06663433 -0.01648705]]. Action = [[ 0.09592225 -0.03735077  0.         -0.8886362 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2493 is [True, False, False, False, True, False]
State prediction error at timestep 2493 is tensor(2.4681e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2493 of None
Current timestep = 2494. State = [[-0.05662998 -0.01562416]]. Action = [[ 0.09309375  0.03827003  0.         -0.91816604]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2494 is [True, False, False, False, True, False]
State prediction error at timestep 2494 is tensor(1.8139e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2494 of None
Current timestep = 2495. State = [[-0.19429903 -0.05087306]]. Action = [[ 9.9653862e-02  3.2458454e-04  0.0000000e+00 -8.6895460e-01]]. Reward = [100.]
Curr episode timestep = 22
Scene graph at timestep 2495 is [True, False, False, False, True, False]
State prediction error at timestep 2495 is tensor(0.0108, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2495 of None
Current timestep = 2496. State = [[-0.19484216 -0.04620333]]. Action = [[ 0.05269981  0.06852942  0.         -0.78056955]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2496 is [True, False, False, False, True, False]
State prediction error at timestep 2496 is tensor(1.5728e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2496 of None
Current timestep = 2497. State = [[-0.19056632 -0.03900505]]. Action = [[ 0.0826522   0.0840857   0.         -0.78065485]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2497 is [True, False, False, False, True, False]
State prediction error at timestep 2497 is tensor(1.4877e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2497 of None
Current timestep = 2498. State = [[-0.18869169 -0.03793436]]. Action = [[ 0.01307543 -0.051146    0.         -0.5756362 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2498 is [True, False, False, False, True, False]
State prediction error at timestep 2498 is tensor(1.6561e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2498 of None
Current timestep = 2499. State = [[-0.18477923 -0.04082424]]. Action = [[ 0.08345955 -0.04477764  0.         -0.8934349 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2499 is [True, False, False, False, True, False]
State prediction error at timestep 2499 is tensor(1.2414e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2499 of None
Current timestep = 2500. State = [[-0.17878398 -0.04153106]]. Action = [[ 0.08315114  0.00794468  0.         -0.8506928 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2500 is [True, False, False, False, True, False]
State prediction error at timestep 2500 is tensor(4.9315e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2500 of None
Current timestep = 2501. State = [[-0.17591052 -0.04085981]]. Action = [[ 0.01055846  0.00914226  0.         -0.97273016]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2501 is [True, False, False, False, True, False]
State prediction error at timestep 2501 is tensor(2.6250e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2501 of None
Current timestep = 2502. State = [[-0.1711747  -0.04413375]]. Action = [[ 0.08203473 -0.06944852  0.         -0.97055864]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2502 is [True, False, False, False, True, False]
State prediction error at timestep 2502 is tensor(1.0439e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2502 of None
Current timestep = 2503. State = [[-0.16392031 -0.04373168]]. Action = [[ 0.08873016  0.05634066  0.         -0.77619445]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2503 is [True, False, False, False, True, False]
State prediction error at timestep 2503 is tensor(9.1335e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2503 of None
Current timestep = 2504. State = [[-0.15630665 -0.03828235]]. Action = [[ 0.09129002  0.0860965   0.         -0.70024097]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2504 is [True, False, False, False, True, False]
State prediction error at timestep 2504 is tensor(1.3089e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2504 of None
Current timestep = 2505. State = [[-0.14843851 -0.03592882]]. Action = [[ 0.09311663 -0.00093082  0.         -0.7426754 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2505 is [True, False, False, False, True, False]
State prediction error at timestep 2505 is tensor(2.9051e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2505 of None
Current timestep = 2506. State = [[-0.14170504 -0.0334103 ]]. Action = [[ 0.06151254  0.05063815  0.         -0.85590595]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2506 is [True, False, False, False, True, False]
State prediction error at timestep 2506 is tensor(2.8654e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2506 of None
Current timestep = 2507. State = [[-0.13652427 -0.02904319]]. Action = [[ 0.04331943  0.05561198  0.         -0.5915703 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2507 is [True, False, False, False, True, False]
State prediction error at timestep 2507 is tensor(1.8864e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2507 of None
Current timestep = 2508. State = [[-0.13224384 -0.02927085]]. Action = [[ 0.02893322 -0.04682605  0.         -0.74315786]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2508 is [True, False, False, False, True, False]
State prediction error at timestep 2508 is tensor(3.1452e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2508 of None
Current timestep = 2509. State = [[-0.12531303 -0.03280487]]. Action = [[ 0.08148069 -0.05336121  0.         -0.86916316]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2509 is [True, False, False, False, True, False]
State prediction error at timestep 2509 is tensor(4.4832e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2509 of None
Current timestep = 2510. State = [[-0.11627593 -0.03160372]]. Action = [[ 0.09168638  0.0532606   0.         -0.6416349 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2510 is [True, False, False, False, True, False]
State prediction error at timestep 2510 is tensor(1.1577e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2510 of None
Current timestep = 2511. State = [[-0.10686319 -0.03006984]]. Action = [[ 0.0926559  -0.00146932  0.         -0.68956816]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2511 is [True, False, False, False, True, False]
State prediction error at timestep 2511 is tensor(5.0363e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2511 of None
Current timestep = 2512. State = [[-0.09721704 -0.0267626 ]]. Action = [[ 0.09463734  0.06348205  0.         -0.92190796]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2512 is [True, False, False, False, True, False]
State prediction error at timestep 2512 is tensor(2.6014e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2512 of None
Current timestep = 2513. State = [[-0.08736691 -0.02477718]]. Action = [[ 9.747475e-02 -7.147640e-04  0.000000e+00 -9.066378e-01]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2513 is [True, False, False, False, True, False]
State prediction error at timestep 2513 is tensor(2.4404e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2513 of None
Current timestep = 2514. State = [[-0.07725668 -0.02219013]]. Action = [[ 0.0980131   0.04691119  0.         -0.83061355]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2514 is [True, False, False, False, True, False]
State prediction error at timestep 2514 is tensor(1.9987e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2514 of None
Current timestep = 2515. State = [[-0.06940376 -0.01706415]]. Action = [[ 0.0507931   0.06865618  0.         -0.8605963 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2515 is [True, False, False, False, True, False]
State prediction error at timestep 2515 is tensor(1.0434e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2515 of None
Current timestep = 2516. State = [[-0.06056752 -0.01525406]]. Action = [[ 0.09516294 -0.01705646  0.         -0.90057755]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2516 is [True, False, False, False, True, False]
State prediction error at timestep 2516 is tensor(1.9853e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2516 of None
Current timestep = 2517. State = [[-0.05079537 -0.01089776]]. Action = [[ 0.08918827  0.08270869  0.         -0.8594956 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2517 is [True, False, False, False, True, False]
State prediction error at timestep 2517 is tensor(3.7358e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2517 of None
Current timestep = 2518. State = [[-0.28477895  0.04201512]]. Action = [[ 0.09407657  0.05495631  0.         -0.77391624]]. Reward = [100.]
Curr episode timestep = 22
Scene graph at timestep 2518 is [True, False, False, False, True, False]
State prediction error at timestep 2518 is tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2518 of None
Current timestep = 2519. State = [[-0.27907285  0.03420635]]. Action = [[ 0.07798136 -0.06237192  0.         -0.56695163]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2519 is [True, False, False, False, True, False]
State prediction error at timestep 2519 is tensor(3.6026e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2519 of None
Current timestep = 2520. State = [[-0.27259728  0.03075035]]. Action = [[ 0.09200599  0.01038881  0.         -0.565984  ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2520 is [True, False, False, False, True, False]
State prediction error at timestep 2520 is tensor(1.6487e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2520 of None
Current timestep = 2521. State = [[-0.27329192  0.02469922]]. Action = [[-0.08422699 -0.08904276  0.         -0.7116835 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2521 is [True, False, False, False, True, False]
State prediction error at timestep 2521 is tensor(4.6816e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2521 of None
Current timestep = 2522. State = [[-0.27275765  0.01914011]]. Action = [[ 0.05970078 -0.02474084  0.         -0.49152493]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2522 is [True, False, False, False, True, False]
State prediction error at timestep 2522 is tensor(2.8700e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2522 of None
Current timestep = 2523. State = [[-0.26980504  0.01250595]]. Action = [[ 0.02802243 -0.07712904  0.         -0.19261414]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2523 is [True, False, False, False, True, False]
State prediction error at timestep 2523 is tensor(1.4087e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2523 of None
Current timestep = 2524. State = [[-0.26561388  0.0107083 ]]. Action = [[ 0.06278457  0.05033161  0.         -0.8509804 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2524 is [True, False, False, False, True, False]
State prediction error at timestep 2524 is tensor(5.4971e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2524 of None
Current timestep = 2525. State = [[-0.26366872  0.00936518]]. Action = [[-0.00187846 -0.01753171  0.         -0.55974805]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2525 is [True, False, False, False, True, False]
State prediction error at timestep 2525 is tensor(3.3035e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2525 of None
Current timestep = 2526. State = [[-0.25951797  0.00874809]]. Action = [[ 0.07668675  0.02789957  0.         -0.55432785]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2526 is [True, False, False, False, True, False]
State prediction error at timestep 2526 is tensor(1.2200e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2526 of None
Current timestep = 2527. State = [[-0.25372648  0.00873321]]. Action = [[ 0.06769619  0.01079659  0.         -0.83358383]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2527 is [True, False, False, False, True, False]
State prediction error at timestep 2527 is tensor(1.3068e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2527 of None
Current timestep = 2528. State = [[-0.25008315  0.00837932]]. Action = [[ 0.02187879  0.00638129  0.         -0.87343276]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2528 is [True, False, False, False, True, False]
State prediction error at timestep 2528 is tensor(1.6636e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2528 of None
Current timestep = 2529. State = [[-0.24629396  0.00756899]]. Action = [[ 0.04629543 -0.00552423  0.         -0.33335853]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2529 is [True, False, False, False, True, False]
State prediction error at timestep 2529 is tensor(3.0488e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2529 of None
Current timestep = 2530. State = [[-0.24056369  0.00880983]]. Action = [[ 0.07072299  0.03954475  0.         -0.00425118]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2530 is [True, False, False, False, True, False]
State prediction error at timestep 2530 is tensor(8.0532e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2530 of None
Current timestep = 2531. State = [[-0.23490942  0.0142313 ]]. Action = [[ 0.05702379  0.09192089  0.         -0.50075865]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2531 is [True, False, False, False, True, False]
State prediction error at timestep 2531 is tensor(1.0184e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2531 of None
Current timestep = 2532. State = [[-0.23163395  0.01848792]]. Action = [[ 0.01707669  0.02755687  0.         -0.8116563 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2532 is [True, False, False, False, True, False]
State prediction error at timestep 2532 is tensor(4.6997e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2532 of None
Current timestep = 2533. State = [[-0.23258936  0.02352503]]. Action = [[-0.05094678  0.06970263  0.         -0.8860409 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2533 is [True, False, False, False, True, False]
State prediction error at timestep 2533 is tensor(7.4538e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2533 of None
Current timestep = 2534. State = [[-0.22905605  0.02389624]]. Action = [[ 0.08216185 -0.05552244  0.         -0.6124934 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2534 is [True, False, False, False, True, False]
State prediction error at timestep 2534 is tensor(5.4589e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2534 of None
Current timestep = 2535. State = [[-0.22213988  0.02068969]]. Action = [[ 0.06547017 -0.052723    0.         -0.77220094]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2535 is [True, False, False, False, True, False]
State prediction error at timestep 2535 is tensor(1.2247e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2535 of None
Current timestep = 2536. State = [[-0.21626379  0.01552769]]. Action = [[ 0.03992713 -0.08343159  0.         -0.5379461 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2536 is [True, False, False, False, True, False]
State prediction error at timestep 2536 is tensor(1.5572e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2536 of None
Current timestep = 2537. State = [[-0.20849475  0.01741041]]. Action = [[ 0.09142292  0.08498282  0.         -0.83544195]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2537 is [True, False, False, False, True, False]
State prediction error at timestep 2537 is tensor(1.8372e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2537 of None
Current timestep = 2538. State = [[-0.20308468  0.01561109]]. Action = [[ 0.01529805 -0.08786772  0.         -0.86490387]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2538 is [True, False, False, False, True, False]
State prediction error at timestep 2538 is tensor(8.6687e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2538 of None
Current timestep = 2539. State = [[-0.19714257  0.01465537]]. Action = [[ 0.06145225  0.03058773  0.         -0.48959982]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2539 is [True, False, False, False, True, False]
State prediction error at timestep 2539 is tensor(5.6966e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2539 of None
Current timestep = 2540. State = [[-0.1888153  0.0156727]]. Action = [[ 0.08985168  0.00942956  0.         -0.8792976 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2540 is [True, False, False, False, True, False]
State prediction error at timestep 2540 is tensor(9.2763e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2540 of None
Current timestep = 2541. State = [[-0.17930178  0.01199518]]. Action = [[ 0.09522834 -0.07269131  0.         -0.6652236 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2541 is [True, False, False, False, True, False]
State prediction error at timestep 2541 is tensor(1.0578e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2541 of None
Current timestep = 2542. State = [[-0.17000756  0.01220889]]. Action = [[ 0.08363289  0.05987776  0.         -0.8858872 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2542 is [True, False, False, False, True, False]
State prediction error at timestep 2542 is tensor(1.8376e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2542 of None
Current timestep = 2543. State = [[-0.16087458  0.01175208]]. Action = [[ 0.08817842 -0.02899572  0.         -0.4708364 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2543 is [True, False, False, False, True, False]
State prediction error at timestep 2543 is tensor(1.7480e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2543 of None
Current timestep = 2544. State = [[-0.15532571  0.00827373]]. Action = [[ 0.00567572 -0.04186909  0.         -0.79812306]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2544 is [True, False, False, False, True, False]
State prediction error at timestep 2544 is tensor(5.3876e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2544 of None
Current timestep = 2545. State = [[-0.14811137  0.00526492]]. Action = [[ 0.08243013 -0.02116461  0.         -0.9018988 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2545 is [True, False, False, False, True, False]
State prediction error at timestep 2545 is tensor(1.3100e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2545 of None
Current timestep = 2546. State = [[-0.1398613   0.00769901]]. Action = [[ 0.06682945  0.07783713  0.         -0.6644622 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2546 is [True, False, False, False, True, False]
State prediction error at timestep 2546 is tensor(5.4311e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2546 of None
Current timestep = 2547. State = [[-0.13185228  0.01018921]]. Action = [[ 0.07426517  0.01520483  0.         -0.69051206]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2547 is [True, False, False, False, True, False]
State prediction error at timestep 2547 is tensor(5.9932e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2547 of None
Current timestep = 2548. State = [[-0.12446628  0.01328316]]. Action = [[ 0.0587197   0.05640254  0.         -0.58119607]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2548 is [True, False, False, False, True, False]
State prediction error at timestep 2548 is tensor(7.8799e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2548 of None
Current timestep = 2549. State = [[-0.11627178  0.01511319]]. Action = [[ 0.08583894  0.00391001  0.         -0.9239726 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 2549 is [True, False, False, False, True, False]
State prediction error at timestep 2549 is tensor(1.4919e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2549 of None
Current timestep = 2550. State = [[-0.10762408  0.018415  ]]. Action = [[ 0.08058359  0.06035123  0.         -0.63321006]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 2550 is [True, False, False, False, True, False]
State prediction error at timestep 2550 is tensor(9.6120e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2550 of None
Current timestep = 2551. State = [[-0.09861014  0.01991446]]. Action = [[ 0.09119179 -0.01085284  0.         -0.6261071 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 2551 is [True, False, False, False, True, False]
State prediction error at timestep 2551 is tensor(8.7646e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2551 of None
Current timestep = 2552. State = [[-0.09124352  0.02123073]]. Action = [[ 0.04746658  0.02408181  0.         -0.75217855]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 2552 is [True, False, False, False, True, False]
State prediction error at timestep 2552 is tensor(2.3118e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2552 of None
Current timestep = 2553. State = [[-0.08252993  0.02399228]]. Action = [[ 0.09841574  0.03255159  0.         -0.52145123]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 2553 is [True, False, False, False, True, False]
State prediction error at timestep 2553 is tensor(9.8729e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2553 of None
Current timestep = 2554. State = [[-0.07639553  0.02509021]]. Action = [[ 0.01596489 -0.00834396  0.         -0.814631  ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 2554 is [True, False, False, False, True, False]
State prediction error at timestep 2554 is tensor(2.0201e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2554 of None
Current timestep = 2555. State = [[-0.07054289  0.02541717]]. Action = [[ 0.04968239 -0.00253061  0.         -0.74870706]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 2555 is [True, False, False, False, True, False]
State prediction error at timestep 2555 is tensor(2.4657e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2555 of None
Current timestep = 2556. State = [[-0.06172919  0.02882485]]. Action = [[ 0.09630702  0.05847687  0.         -0.65723276]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 2556 is [True, False, False, False, True, False]
State prediction error at timestep 2556 is tensor(3.7179e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2556 of None
Current timestep = 2557. State = [[-0.05184567  0.03406752]]. Action = [[ 0.09819251  0.05987018  0.         -0.7996721 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 2557 is [True, False, False, False, True, False]
State prediction error at timestep 2557 is tensor(2.5708e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2557 of None
Current timestep = 2558. State = [[-0.25896195 -0.0205308 ]]. Action = [[ 0.09730957  0.05449406  0.         -0.7735882 ]]. Reward = [100.]
Curr episode timestep = 39
Scene graph at timestep 2558 is [True, False, False, False, True, False]
State prediction error at timestep 2558 is tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2558 of None
Current timestep = 2559. State = [[-0.2521605  -0.02465001]]. Action = [[ 0.06805713 -0.01222992  0.         -0.8944855 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2559 is [True, False, False, False, True, False]
State prediction error at timestep 2559 is tensor(5.7042e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2559 of None
Current timestep = 2560. State = [[-0.24461731 -0.03096388]]. Action = [[ 0.08827225 -0.09742757  0.         -0.82017446]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2560 is [True, False, False, False, True, False]
State prediction error at timestep 2560 is tensor(2.6801e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2560 of None
Current timestep = 2561. State = [[-0.23683073 -0.03794476]]. Action = [[ 0.07421487 -0.05642651  0.         -0.640558  ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2561 is [True, False, False, False, True, False]
State prediction error at timestep 2561 is tensor(3.0160e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2561 of None
Current timestep = 2562. State = [[-0.23044902 -0.03757869]]. Action = [[ 0.05100841  0.07426602  0.         -0.65123886]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2562 is [True, False, False, False, True, False]
State prediction error at timestep 2562 is tensor(4.1416e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2562 of None
Current timestep = 2563. State = [[-0.22367077 -0.03981237]]. Action = [[ 0.07521383 -0.05825239  0.         -0.87996364]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2563 is [True, False, False, False, True, False]
State prediction error at timestep 2563 is tensor(5.0399e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2563 of None
Current timestep = 2564. State = [[-0.21558745 -0.04024421]]. Action = [[ 0.08637536  0.05096082  0.         -0.76191944]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2564 is [True, False, False, False, True, False]
State prediction error at timestep 2564 is tensor(1.2419e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2564 of None
Current timestep = 2565. State = [[-0.21278088 -0.03680744]]. Action = [[-0.02814179  0.06293926  0.         -0.69253373]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2565 is [True, False, False, False, True, False]
State prediction error at timestep 2565 is tensor(6.1405e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2565 of None
Current timestep = 2566. State = [[-0.21056563 -0.03896263]]. Action = [[ 0.02599946 -0.06810176  0.         -0.66862214]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2566 is [True, False, False, False, True, False]
State prediction error at timestep 2566 is tensor(1.4331e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2566 of None
Current timestep = 2567. State = [[-0.20851742 -0.04341855]]. Action = [[-0.00874209 -0.03904347  0.         -0.931221  ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2567 is [True, False, False, False, True, False]
State prediction error at timestep 2567 is tensor(3.1896e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2567 of None
Current timestep = 2568. State = [[-0.2026258  -0.04075132]]. Action = [[ 0.09131273  0.08893222  0.         -0.9819074 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2568 is [True, False, False, False, True, False]
State prediction error at timestep 2568 is tensor(5.9732e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2568 of None
Current timestep = 2569. State = [[-0.19568267 -0.03430849]]. Action = [[ 0.06644397  0.07839838  0.         -0.9468103 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2569 is [True, False, False, False, True, False]
State prediction error at timestep 2569 is tensor(3.0483e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2569 of None
Current timestep = 2570. State = [[-0.18850231 -0.03515083]]. Action = [[ 0.08314008 -0.07183892  0.         -0.7363318 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2570 is [True, False, False, False, True, False]
State prediction error at timestep 2570 is tensor(3.0337e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2570 of None
Current timestep = 2571. State = [[-0.18272029 -0.0335333 ]]. Action = [[ 0.0391589   0.06752325  0.         -0.9234671 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2571 is [True, False, False, False, True, False]
State prediction error at timestep 2571 is tensor(5.3196e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2571 of None
Current timestep = 2572. State = [[-0.17712407 -0.02837606]]. Action = [[ 0.06226287  0.05713234  0.         -0.6947845 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2572 is [True, False, False, False, True, False]
State prediction error at timestep 2572 is tensor(2.0698e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2572 of None
Current timestep = 2573. State = [[-0.16915916 -0.03028578]]. Action = [[ 0.0964208  -0.08590071  0.         -0.05675614]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2573 is [True, False, False, False, True, False]
State prediction error at timestep 2573 is tensor(4.2445e-08, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2573 of None
Current timestep = 2574. State = [[-0.16520791 -0.03179998]]. Action = [[-0.01812062  0.01053488  0.         -0.84896106]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2574 is [True, False, False, False, True, False]
State prediction error at timestep 2574 is tensor(1.1158e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2574 of None
Current timestep = 2575. State = [[-0.16481516 -0.03132674]]. Action = [[-0.0284037  -0.00147571  0.         -0.34198785]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2575 is [True, False, False, False, True, False]
State prediction error at timestep 2575 is tensor(1.7871e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2575 of None
Current timestep = 2576. State = [[-0.1607764  -0.02872045]]. Action = [[ 0.05900962  0.04428393  0.         -0.6367127 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2576 is [True, False, False, False, True, False]
State prediction error at timestep 2576 is tensor(1.6053e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2576 of None
Current timestep = 2577. State = [[-0.1556451  -0.02504464]]. Action = [[ 0.03800092  0.03702963  0.         -0.66380537]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2577 is [True, False, False, False, True, False]
State prediction error at timestep 2577 is tensor(1.2834e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2577 of None
Current timestep = 2578. State = [[-0.15038389 -0.01920475]]. Action = [[ 0.05464328  0.08013278  0.         -0.82471824]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2578 is [True, False, False, False, True, False]
State prediction error at timestep 2578 is tensor(9.3169e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2578 of None
Current timestep = 2579. State = [[-0.14502127 -0.01510362]]. Action = [[ 0.05234582  0.01611527  0.         -0.772794  ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2579 is [True, False, False, False, True, False]
State prediction error at timestep 2579 is tensor(1.0616e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2579 of None
Current timestep = 2580. State = [[-0.13828735 -0.01393769]]. Action = [[ 0.07978318 -0.00661647  0.         -0.9025687 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2580 is [True, False, False, False, True, False]
State prediction error at timestep 2580 is tensor(2.1723e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2580 of None
Current timestep = 2581. State = [[-0.13103394 -0.01633147]]. Action = [[ 0.07026949 -0.05933445  0.         -0.8686304 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2581 is [True, False, False, False, True, False]
State prediction error at timestep 2581 is tensor(9.2139e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2581 of None
Current timestep = 2582. State = [[-0.12354147 -0.01662663]]. Action = [[ 0.07380874  0.02091704  0.         -0.39645743]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2582 is [True, False, False, False, True, False]
State prediction error at timestep 2582 is tensor(1.3852e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2582 of None
Current timestep = 2583. State = [[-0.11756011 -0.01254975]]. Action = [[ 0.04163959  0.06583471  0.         -0.7715742 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2583 is [True, False, False, False, True, False]
State prediction error at timestep 2583 is tensor(1.6570e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2583 of None
Current timestep = 2584. State = [[-0.11046524 -0.01286371]]. Action = [[ 0.08106177 -0.05239772  0.         -0.94584733]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2584 is [True, False, False, False, True, False]
State prediction error at timestep 2584 is tensor(5.0458e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2584 of None
Current timestep = 2585. State = [[-0.10198589 -0.01023222]]. Action = [[ 0.08498668  0.07845164  0.         -0.9080327 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2585 is [True, False, False, False, True, False]
State prediction error at timestep 2585 is tensor(6.5480e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2585 of None
Current timestep = 2586. State = [[-0.09342734 -0.0070095 ]]. Action = [[ 0.08578796  0.0161074   0.         -0.9608565 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2586 is [True, False, False, False, True, False]
State prediction error at timestep 2586 is tensor(1.4508e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2586 of None
Current timestep = 2587. State = [[-0.08475182 -0.00629847]]. Action = [[ 0.08406638 -0.00159744  0.          0.05365336]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2587 is [True, False, False, False, True, False]
State prediction error at timestep 2587 is tensor(1.5090e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2587 of None
Current timestep = 2588. State = [[-0.08081529 -0.00709165]]. Action = [[-0.02120728 -0.01999475  0.         -0.792069  ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2588 is [True, False, False, False, True, False]
State prediction error at timestep 2588 is tensor(6.6057e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2588 of None
Current timestep = 2589. State = [[-0.07420093 -0.00471024]]. Action = [[ 0.09401996  0.05348981  0.         -0.8176006 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 2589 is [True, False, False, False, True, False]
State prediction error at timestep 2589 is tensor(2.0284e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2589 of None
Current timestep = 2590. State = [[-0.0649839  -0.00572854]]. Action = [[ 0.08559326 -0.05603862  0.         -0.77112305]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 2590 is [True, False, False, False, True, False]
State prediction error at timestep 2590 is tensor(1.6060e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2590 of None
Current timestep = 2591. State = [[-0.05626842 -0.00633392]]. Action = [[ 0.07301528  0.01881385  0.         -0.9121798 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 2591 is [True, False, False, False, True, False]
State prediction error at timestep 2591 is tensor(2.6133e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2591 of None
Current timestep = 2592. State = [[-0.24501005 -0.20497738]]. Action = [[ 0.08533881  0.03859635  0.         -0.8369191 ]]. Reward = [100.]
Curr episode timestep = 33
Scene graph at timestep 2592 is [True, False, False, True, False, False]
State prediction error at timestep 2592 is tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2592 of None
Current timestep = 2593. State = [[-0.24182603 -0.21233799]]. Action = [[-0.00217191 -0.08357091  0.         -0.72028184]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2593 is [True, False, False, True, False, False]
State prediction error at timestep 2593 is tensor(3.7852e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2593 of None
Current timestep = 2594. State = [[-0.23945445 -0.21496227]]. Action = [[ 0.03906626  0.03986204  0.         -0.9635176 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2594 is [True, False, False, True, False, False]
State prediction error at timestep 2594 is tensor(1.5544e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2594 of None
Current timestep = 2595. State = [[-0.23776302 -0.21468419]]. Action = [[ 0.00341354  0.02387206  0.         -0.892578  ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2595 is [True, False, False, True, False, False]
State prediction error at timestep 2595 is tensor(3.1280e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2595 of None
Current timestep = 2596. State = [[-0.23254927 -0.21596888]]. Action = [[ 0.09254017 -0.01235891  0.         -0.8502975 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2596 is [True, False, False, True, False, False]
State prediction error at timestep 2596 is tensor(3.2764e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2596 of None
Current timestep = 2597. State = [[-0.22608772 -0.21278517]]. Action = [[ 0.06197428  0.0864333   0.         -0.5944854 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2597 is [True, False, False, True, False, False]
State prediction error at timestep 2597 is tensor(7.5253e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2597 of None
Current timestep = 2598. State = [[-0.22012809 -0.2124689 ]]. Action = [[ 0.06594992 -0.03840831  0.         -0.9108563 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2598 is [True, False, False, True, False, False]
State prediction error at timestep 2598 is tensor(3.2072e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2598 of None
Current timestep = 2599. State = [[-0.21563134 -0.21154557]]. Action = [[ 0.03104023  0.04060534  0.         -0.9629386 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2599 is [True, False, False, True, False, False]
State prediction error at timestep 2599 is tensor(1.5139e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2599 of None
Current timestep = 2600. State = [[-0.2100164  -0.21011624]]. Action = [[ 0.07213809  0.003685    0.         -0.880894  ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2600 is [True, False, False, True, False, False]
State prediction error at timestep 2600 is tensor(1.9475e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2600 of None
Current timestep = 2601. State = [[-0.20254262 -0.20487677]]. Action = [[ 0.08553178  0.0902992   0.         -0.8953395 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2601 is [True, False, False, True, False, False]
State prediction error at timestep 2601 is tensor(1.2460e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2601 of None
Current timestep = 2602. State = [[-0.19415452 -0.20472495]]. Action = [[ 0.09582495 -0.07195801  0.         -0.7937102 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2602 is [True, False, False, True, False, False]
State prediction error at timestep 2602 is tensor(1.4138e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2602 of None
Current timestep = 2603. State = [[-0.19155565 -0.2037045 ]]. Action = [[-0.04413113  0.05082602  0.         -0.9405828 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2603 is [True, False, False, True, False, False]
State prediction error at timestep 2603 is tensor(5.6381e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2603 of None
Current timestep = 2604. State = [[-0.18924396 -0.20437908]]. Action = [[ 0.04599864 -0.05795668  0.         -0.936044  ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2604 is [True, False, False, True, False, False]
State prediction error at timestep 2604 is tensor(6.3169e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2604 of None
Current timestep = 2605. State = [[-0.1847131  -0.20431668]]. Action = [[ 0.0381894   0.01866784  0.         -0.8963968 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2605 is [True, False, False, True, False, False]
State prediction error at timestep 2605 is tensor(1.0868e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2605 of None
Current timestep = 2606. State = [[-0.17803812 -0.20574924]]. Action = [[ 0.08102136 -0.05121383  0.         -0.5363312 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2606 is [True, False, False, True, False, False]
State prediction error at timestep 2606 is tensor(1.7444e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2606 of None
Current timestep = 2607. State = [[-0.169317   -0.20533796]]. Action = [[ 0.09583319  0.02664385  0.         -0.7573814 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2607 is [True, False, False, True, False, False]
State prediction error at timestep 2607 is tensor(2.2551e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2607 of None
Current timestep = 2608. State = [[-0.16274032 -0.20045318]]. Action = [[ 0.04342248  0.0742312   0.         -0.9009627 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2608 is [True, False, False, True, False, False]
State prediction error at timestep 2608 is tensor(1.8607e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2608 of None
Current timestep = 2609. State = [[-0.15602677 -0.19658126]]. Action = [[ 0.07682408  0.02217491  0.         -0.95833254]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2609 is [True, False, False, True, False, False]
State prediction error at timestep 2609 is tensor(4.7422e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2609 of None
Current timestep = 2610. State = [[-0.14783561 -0.1979759 ]]. Action = [[ 0.08724452 -0.05695824  0.         -0.9014051 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2610 is [True, False, False, True, False, False]
State prediction error at timestep 2610 is tensor(1.1482e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2610 of None
Current timestep = 2611. State = [[-0.13896127 -0.19462717]]. Action = [[ 0.09200267  0.08787089  0.         -0.8760678 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2611 is [True, False, False, True, False, False]
State prediction error at timestep 2611 is tensor(2.1647e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2611 of None
Current timestep = 2612. State = [[-0.13039467 -0.18686776]]. Action = [[ 0.08593035  0.08965103  0.         -0.9740953 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2612 is [True, False, False, True, False, False]
State prediction error at timestep 2612 is tensor(1.9206e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2612 of None
Current timestep = 2613. State = [[-0.12144525 -0.18147671]]. Action = [[ 0.0978286  0.0293375  0.        -0.9498906]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2613 is [True, False, False, True, False, False]
State prediction error at timestep 2613 is tensor(7.5470e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2613 of None
Current timestep = 2614. State = [[-0.11961748 -0.17815086]]. Action = [[-0.06389409  0.02479436  0.         -0.52030396]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2614 is [True, False, False, True, False, False]
State prediction error at timestep 2614 is tensor(2.1297e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2614 of None
Current timestep = 2615. State = [[-0.11502406 -0.17438202]]. Action = [[ 0.0897794   0.03312694  0.         -0.7752155 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2615 is [True, False, False, True, False, False]
State prediction error at timestep 2615 is tensor(1.1262e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2615 of None
Current timestep = 2616. State = [[-0.11208952 -0.17484942]]. Action = [[-0.03129237 -0.05757406  0.         -0.9279689 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2616 is [True, False, False, True, False, False]
State prediction error at timestep 2616 is tensor(1.2722e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2616 of None
Current timestep = 2617. State = [[-0.10629769 -0.17374977]]. Action = [[ 0.08775032  0.03326825  0.         -0.80279595]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2617 is [True, False, False, True, False, False]
State prediction error at timestep 2617 is tensor(3.6840e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2617 of None
Current timestep = 2618. State = [[-0.1021296  -0.16882418]]. Action = [[-0.00733786  0.05864487  0.         -0.957828  ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2618 is [True, False, False, True, False, False]
State prediction error at timestep 2618 is tensor(9.4590e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2618 of None
Current timestep = 2619. State = [[-0.09709936 -0.16397373]]. Action = [[ 0.06329574  0.03812677  0.         -0.93086016]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2619 is [True, False, False, True, False, False]
State prediction error at timestep 2619 is tensor(4.9572e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2619 of None
Current timestep = 2620. State = [[-0.08990256 -0.15829317]]. Action = [[ 0.07510442  0.06183412  0.         -0.90715456]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2620 is [True, False, False, True, False, False]
State prediction error at timestep 2620 is tensor(7.1125e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2620 of None
Current timestep = 2621. State = [[-0.08306342 -0.1580642 ]]. Action = [[ 0.06154979 -0.06145897  0.         -0.30807954]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2621 is [True, False, False, True, False, False]
State prediction error at timestep 2621 is tensor(2.0676e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2621 of None
Current timestep = 2622. State = [[-0.07519595 -0.15452017]]. Action = [[ 0.08957411  0.08210508  0.         -0.8343383 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2622 is [True, False, False, True, False, False]
State prediction error at timestep 2622 is tensor(7.5351e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2622 of None
Current timestep = 2623. State = [[-0.06701966 -0.14796296]]. Action = [[ 0.08478064  0.06020186  0.         -0.75133026]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 2623 is [True, False, False, True, False, False]
State prediction error at timestep 2623 is tensor(1.5132e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2623 of None
Current timestep = 2624. State = [[-0.05980299 -0.14390838]]. Action = [[ 0.06746664  0.01699581  0.         -0.90291876]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 2624 is [True, False, False, True, False, False]
State prediction error at timestep 2624 is tensor(3.0020e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2624 of None
Current timestep = 2625. State = [[-0.05447315 -0.14323983]]. Action = [[ 0.03459647 -0.02232662  0.         -0.7918508 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 2625 is [True, False, False, True, False, False]
State prediction error at timestep 2625 is tensor(1.3488e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2625 of None
Current timestep = 2626. State = [[-0.0469012  -0.14273547]]. Action = [[ 0.09545089  0.00340816  0.         -0.80649453]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 2626 is [False, True, False, True, False, False]
State prediction error at timestep 2626 is tensor(1.2190e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2626 of None
Current timestep = 2627. State = [[-0.03809466 -0.13852422]]. Action = [[ 0.08841839  0.06600191  0.         -0.6870241 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 2627 is [False, True, False, True, False, False]
State prediction error at timestep 2627 is tensor(9.7532e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2627 of None
Current timestep = 2628. State = [[-0.02911515 -0.13566497]]. Action = [[ 0.09494448  0.00108922  0.         -0.85708284]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 2628 is [False, True, False, True, False, False]
State prediction error at timestep 2628 is tensor(1.0059e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2628 of None
Current timestep = 2629. State = [[-0.02027949 -0.13530107]]. Action = [[ 0.08565947 -0.00945143  0.         -0.6392133 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 2629 is [False, True, False, True, False, False]
State prediction error at timestep 2629 is tensor(6.3150e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2629 of None
Current timestep = 2630. State = [[-0.01115752 -0.13504428]]. Action = [[ 0.09343369  0.00112373  0.         -0.9376169 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 2630 is [False, True, False, True, False, False]
State prediction error at timestep 2630 is tensor(1.8798e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2630 of None
Current timestep = 2631. State = [[-0.00176564 -0.13339081]]. Action = [[ 0.09321416  0.02638242  0.         -0.85973006]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 2631 is [False, True, False, True, False, False]
State prediction error at timestep 2631 is tensor(1.9745e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2631 of None
Current timestep = 2632. State = [[ 0.00749859 -0.13007212]]. Action = [[ 0.08978932  0.04495085  0.         -0.8755598 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 2632 is [False, True, False, True, False, False]
State prediction error at timestep 2632 is tensor(1.4759e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2632 of None
Current timestep = 2633. State = [[ 0.01714394 -0.12937883]]. Action = [[ 0.09806908 -0.01979826  0.         -0.88351905]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 2633 is [False, True, False, True, False, False]
State prediction error at timestep 2633 is tensor(1.8696e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2633 of None
Current timestep = 2634. State = [[ 0.02675748 -0.12744176]]. Action = [[ 0.09080463  0.04443187  0.         -0.81329435]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 2634 is [False, True, False, True, False, False]
State prediction error at timestep 2634 is tensor(2.1005e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2634 of None
Current timestep = 2635. State = [[-0.24363212 -0.05985766]]. Action = [[ 0.03026444  0.02044568  0.         -0.9422275 ]]. Reward = [100.]
Curr episode timestep = 42
Scene graph at timestep 2635 is [True, False, False, False, True, False]
State prediction error at timestep 2635 is tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2635 of None
Current timestep = 2636. State = [[-0.24081084 -0.06229199]]. Action = [[ 0.0313508   0.01815734  0.         -0.4017831 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2636 is [True, False, False, False, True, False]
State prediction error at timestep 2636 is tensor(1.6410e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2636 of None
Current timestep = 2637. State = [[-0.23559602 -0.0606588 ]]. Action = [[ 0.08878595  0.03414375  0.         -0.49829948]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2637 is [True, False, False, False, True, False]
State prediction error at timestep 2637 is tensor(1.3027e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2637 of None
Current timestep = 2638. State = [[-0.22887518 -0.06289694]]. Action = [[ 0.08756008 -0.06050719  0.         -0.9150062 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2638 is [True, False, False, False, True, False]
State prediction error at timestep 2638 is tensor(1.2768e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2638 of None
Current timestep = 2639. State = [[-0.22160637 -0.06797945]]. Action = [[ 0.08906192 -0.05791963  0.         -0.9686023 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2639 is [True, False, False, False, True, False]
State prediction error at timestep 2639 is tensor(1.3549e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2639 of None
Current timestep = 2640. State = [[-0.21677656 -0.07523514]]. Action = [[ 0.02735294 -0.09287494  0.         -0.74974996]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2640 is [True, False, False, False, True, False]
State prediction error at timestep 2640 is tensor(2.9795e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2640 of None
Current timestep = 2641. State = [[-0.21241294 -0.07542229]]. Action = [[ 0.04711635  0.07663693  0.         -0.78224945]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2641 is [True, False, False, False, True, False]
State prediction error at timestep 2641 is tensor(1.5231e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2641 of None
Current timestep = 2642. State = [[-0.20830464 -0.07360417]]. Action = [[ 0.03345793  0.01377877  0.         -0.8349968 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2642 is [True, False, False, False, True, False]
State prediction error at timestep 2642 is tensor(1.3281e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2642 of None
Current timestep = 2643. State = [[-0.20204768 -0.0777027 ]]. Action = [[ 0.08095754 -0.0766751   0.          0.09207428]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2643 is [True, False, False, False, True, False]
State prediction error at timestep 2643 is tensor(2.9854e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2643 of None
Current timestep = 2644. State = [[-0.19580725 -0.0788284 ]]. Action = [[ 0.04936793  0.03928129  0.         -0.76957303]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2644 is [True, False, False, False, True, False]
State prediction error at timestep 2644 is tensor(2.5103e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2644 of None
Current timestep = 2645. State = [[-0.19004665 -0.07999712]]. Action = [[ 0.05484832 -0.0292357   0.         -0.8121698 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2645 is [True, False, False, False, True, False]
State prediction error at timestep 2645 is tensor(3.1335e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2645 of None
Current timestep = 2646. State = [[-0.18263248 -0.07745127]]. Action = [[ 0.08512983  0.07951904  0.         -0.90984094]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2646 is [True, False, False, False, True, False]
State prediction error at timestep 2646 is tensor(1.1109e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2646 of None
Current timestep = 2647. State = [[-0.17441465 -0.07095636]]. Action = [[ 0.08932292  0.08788291  0.         -0.8837516 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2647 is [True, False, False, False, True, False]
State prediction error at timestep 2647 is tensor(1.5848e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2647 of None
Current timestep = 2648. State = [[-0.16604598 -0.06848409]]. Action = [[ 0.08992472 -0.00970326  0.         -0.9166696 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2648 is [True, False, False, False, True, False]
State prediction error at timestep 2648 is tensor(1.3708e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2648 of None
Current timestep = 2649. State = [[-0.1576406  -0.06469802]]. Action = [[ 0.08637462  0.07006551  0.         -0.77175057]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2649 is [True, False, False, False, True, False]
State prediction error at timestep 2649 is tensor(1.0277e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2649 of None
Current timestep = 2650. State = [[-0.14965038 -0.05980786]]. Action = [[ 0.07978497  0.04259374  0.         -0.98221195]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2650 is [True, False, False, False, True, False]
State prediction error at timestep 2650 is tensor(1.7285e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2650 of None
Current timestep = 2651. State = [[-0.1414496  -0.05305428]]. Action = [[ 0.08672672  0.08792081  0.         -0.9250302 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2651 is [True, False, False, False, True, False]
State prediction error at timestep 2651 is tensor(9.8302e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2651 of None
Current timestep = 2652. State = [[-0.1340816  -0.04612318]]. Action = [[ 0.06609756  0.05888949  0.         -0.76831734]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2652 is [True, False, False, False, True, False]
State prediction error at timestep 2652 is tensor(2.1880e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2652 of None
Current timestep = 2653. State = [[-0.1285626  -0.03973168]]. Action = [[ 0.03610616  0.05795994  0.         -0.8583876 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2653 is [True, False, False, False, True, False]
State prediction error at timestep 2653 is tensor(3.7684e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2653 of None
Current timestep = 2654. State = [[-0.12340674 -0.03340178]]. Action = [[ 0.04309703  0.05247778  0.         -0.8096452 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2654 is [True, False, False, False, True, False]
State prediction error at timestep 2654 is tensor(1.0148e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2654 of None
Current timestep = 2655. State = [[-0.11546094 -0.03059407]]. Action = [[ 0.09432738 -0.01779637  0.         -0.73064005]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2655 is [True, False, False, False, True, False]
State prediction error at timestep 2655 is tensor(4.4439e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2655 of None
Current timestep = 2656. State = [[-0.10617161 -0.02765783]]. Action = [[ 0.08852609  0.02977822  0.         -0.85697067]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2656 is [True, False, False, False, True, False]
State prediction error at timestep 2656 is tensor(7.9823e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2656 of None
Current timestep = 2657. State = [[-0.09804944 -0.0264822 ]]. Action = [[ 0.06240096 -0.0266965   0.         -0.8227333 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2657 is [True, False, False, False, True, False]
State prediction error at timestep 2657 is tensor(1.1000e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2657 of None
Current timestep = 2658. State = [[-0.08859822 -0.02514847]]. Action = [[ 0.09894402  0.01468871  0.         -0.9624532 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2658 is [True, False, False, False, True, False]
State prediction error at timestep 2658 is tensor(1.9337e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2658 of None
Current timestep = 2659. State = [[-0.07866497 -0.02147581]]. Action = [[ 0.08880944  0.04499418  0.         -0.88979185]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2659 is [True, False, False, False, True, False]
State prediction error at timestep 2659 is tensor(2.3798e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2659 of None
Current timestep = 2660. State = [[-0.0698007  -0.01581045]]. Action = [[ 0.07279123  0.06802214  0.         -0.8987874 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2660 is [True, False, False, False, True, False]
State prediction error at timestep 2660 is tensor(1.5113e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2660 of None
Current timestep = 2661. State = [[-0.06063188 -0.01173958]]. Action = [[ 0.08869524  0.02112672  0.         -0.92083126]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2661 is [True, False, False, False, True, False]
State prediction error at timestep 2661 is tensor(9.2166e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2661 of None
Current timestep = 2662. State = [[-0.05088818 -0.01126624]]. Action = [[ 0.08886362 -0.0218908   0.         -0.9292239 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2662 is [True, False, False, False, True, False]
State prediction error at timestep 2662 is tensor(1.8115e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2662 of None
Current timestep = 2663. State = [[-0.31625807  0.12765358]]. Action = [[ 0.0964782  -0.00924426  0.         -0.9079899 ]]. Reward = [100.]
Curr episode timestep = 27
Scene graph at timestep 2663 is [True, False, False, False, False, True]
State prediction error at timestep 2663 is tensor(0.0458, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2663 of None
Current timestep = 2664. State = [[-0.31173944  0.12973191]]. Action = [[0.03609025 0.09232058 0.         0.11904109]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2664 is [True, False, False, False, False, True]
State prediction error at timestep 2664 is tensor(6.4028e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2664 of None
Current timestep = 2665. State = [[-0.30625588  0.12849274]]. Action = [[ 0.082211   -0.07646605  0.         -0.7458658 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2665 is [True, False, False, False, False, True]
State prediction error at timestep 2665 is tensor(2.0571e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2665 of None
Current timestep = 2666. State = [[-0.2997343   0.12156244]]. Action = [[ 0.06145597 -0.0950961   0.         -0.6444911 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2666 is [True, False, False, False, True, False]
State prediction error at timestep 2666 is tensor(3.0305e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2666 of None
Current timestep = 2667. State = [[-0.29280064  0.11363659]]. Action = [[ 0.06675562 -0.09368156  0.         -0.69382954]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2667 is [True, False, False, False, True, False]
State prediction error at timestep 2667 is tensor(3.9489e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2667 of None
Current timestep = 2668. State = [[-0.2890474   0.10829154]]. Action = [[-0.00958302 -0.03550688  0.         -0.34756517]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2668 is [True, False, False, False, True, False]
State prediction error at timestep 2668 is tensor(2.8095e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2668 of None
Current timestep = 2669. State = [[-0.2861886   0.10876979]]. Action = [[ 0.01784478  0.05239888  0.         -0.6230415 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2669 is [True, False, False, False, True, False]
State prediction error at timestep 2669 is tensor(4.9029e-08, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2669 of None
Current timestep = 2670. State = [[-0.2821799  0.1063287]]. Action = [[ 0.0351579  -0.05532643  0.         -0.47135663]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2670 is [True, False, False, False, True, False]
State prediction error at timestep 2670 is tensor(9.9118e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2670 of None
Current timestep = 2671. State = [[-0.27878943  0.09939819]]. Action = [[ 0.00859065 -0.08479022  0.         -0.8155346 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2671 is [True, False, False, False, True, False]
State prediction error at timestep 2671 is tensor(2.6311e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2671 of None
Current timestep = 2672. State = [[-0.27174413  0.09075743]]. Action = [[ 0.09566122 -0.09380861  0.         -0.03270143]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2672 is [True, False, False, False, True, False]
State prediction error at timestep 2672 is tensor(2.3488e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2672 of None
Current timestep = 2673. State = [[-0.2634512   0.08289274]]. Action = [[ 0.07053667 -0.06148959  0.         -0.49879032]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2673 is [True, False, False, False, True, False]
State prediction error at timestep 2673 is tensor(5.5712e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2673 of None
Current timestep = 2674. State = [[-0.2554312   0.07552305]]. Action = [[ 0.07522183 -0.06461491  0.         -0.23333848]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2674 is [True, False, False, False, True, False]
State prediction error at timestep 2674 is tensor(1.2542e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2674 of None
Current timestep = 2675. State = [[-0.24988241  0.07552429]]. Action = [[ 0.02678943  0.08908706  0.         -0.83198345]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2675 is [True, False, False, False, True, False]
State prediction error at timestep 2675 is tensor(3.2160e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2675 of None
Current timestep = 2676. State = [[-0.24783789  0.07488232]]. Action = [[-0.00896437 -0.02134173  0.         -0.73056066]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2676 is [True, False, False, False, True, False]
State prediction error at timestep 2676 is tensor(3.1991e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2676 of None
Current timestep = 2677. State = [[-0.24660374  0.07708728]]. Action = [[ 0.00171582  0.08639116  0.         -0.6246136 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2677 is [True, False, False, False, True, False]
State prediction error at timestep 2677 is tensor(2.1822e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2677 of None
Current timestep = 2678. State = [[-0.24246608  0.07641786]]. Action = [[ 0.06634616 -0.03881246  0.         -0.90289503]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2678 is [True, False, False, False, True, False]
State prediction error at timestep 2678 is tensor(1.1397e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2678 of None
Current timestep = 2679. State = [[-0.23519655  0.0700648 ]]. Action = [[ 0.08965149 -0.08391587  0.         -0.5610941 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2679 is [True, False, False, False, True, False]
State prediction error at timestep 2679 is tensor(3.5527e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2679 of None
Current timestep = 2680. State = [[-0.2282258  0.0667224]]. Action = [[ 0.06221274  0.00872941  0.         -0.9028052 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2680 is [True, False, False, False, True, False]
State prediction error at timestep 2680 is tensor(1.0119e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2680 of None
Current timestep = 2681. State = [[-0.22069089  0.06500196]]. Action = [[ 0.08749899 -0.01173045  0.         -0.7134093 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2681 is [True, False, False, False, True, False]
State prediction error at timestep 2681 is tensor(1.1648e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2681 of None
Current timestep = 2682. State = [[-0.21311133  0.05989933]]. Action = [[ 0.06953762 -0.07074114  0.         -0.72253   ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2682 is [True, False, False, False, True, False]
State prediction error at timestep 2682 is tensor(2.9024e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2682 of None
Current timestep = 2683. State = [[-0.2077649   0.05747423]]. Action = [[ 0.02734733  0.01805805  0.         -0.2861225 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2683 is [True, False, False, False, True, False]
State prediction error at timestep 2683 is tensor(8.9703e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2683 of None
Current timestep = 2684. State = [[-0.20113452  0.05757805]]. Action = [[ 0.07933559  0.01748152  0.         -0.880741  ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2684 is [True, False, False, False, True, False]
State prediction error at timestep 2684 is tensor(3.8532e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2684 of None
Current timestep = 2685. State = [[-0.19493356  0.05511173]]. Action = [[ 0.04150464 -0.03835738  0.         -0.36236954]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2685 is [True, False, False, False, True, False]
State prediction error at timestep 2685 is tensor(1.4554e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2685 of None
Current timestep = 2686. State = [[-0.18792327  0.05397395]]. Action = [[ 0.07504847  0.01887796  0.         -0.75378025]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2686 is [True, False, False, False, True, False]
State prediction error at timestep 2686 is tensor(4.6556e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2686 of None
Current timestep = 2687. State = [[-0.18357648  0.05187688]]. Action = [[ 0.00158048 -0.03510615  0.         -0.7342968 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2687 is [True, False, False, False, True, False]
State prediction error at timestep 2687 is tensor(7.5819e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2687 of None
Current timestep = 2688. State = [[-0.17640619  0.04827967]]. Action = [[ 0.09703518 -0.03776228  0.         -0.04367238]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2688 is [True, False, False, False, True, False]
State prediction error at timestep 2688 is tensor(1.3792e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2688 of None
Current timestep = 2689. State = [[-0.1671465   0.04767909]]. Action = [[ 0.08816569  0.02996954  0.         -0.8939085 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2689 is [True, False, False, False, True, False]
State prediction error at timestep 2689 is tensor(1.9566e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2689 of None
Current timestep = 2690. State = [[-0.15952165  0.0455653 ]]. Action = [[ 0.05715434 -0.04104413  0.         -0.8685111 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2690 is [True, False, False, False, True, False]
State prediction error at timestep 2690 is tensor(1.0160e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2690 of None
Current timestep = 2691. State = [[-0.15069069  0.04294999]]. Action = [[ 0.09582176 -0.01156481  0.         -0.49749053]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2691 is [True, False, False, False, True, False]
State prediction error at timestep 2691 is tensor(1.8974e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2691 of None
Current timestep = 2692. State = [[-0.14188148  0.04069822]]. Action = [[ 0.07325671 -0.01764683  0.         -0.70629996]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2692 is [True, False, False, False, True, False]
State prediction error at timestep 2692 is tensor(7.0298e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2692 of None
Current timestep = 2693. State = [[-0.13758735  0.03886379]]. Action = [[-0.01176012 -0.00910514  0.         -0.6728122 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2693 is [True, False, False, False, True, False]
State prediction error at timestep 2693 is tensor(9.8596e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2693 of None
Current timestep = 2694. State = [[-0.1307204   0.03784419]]. Action = [[ 0.09035919 -0.00121144  0.         -0.7919268 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 2694 is [True, False, False, False, True, False]
State prediction error at timestep 2694 is tensor(2.2021e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2694 of None
Current timestep = 2695. State = [[-0.12175348  0.03303387]]. Action = [[ 0.07757784 -0.08011369  0.         -0.82893944]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 2695 is [True, False, False, False, True, False]
State prediction error at timestep 2695 is tensor(1.5753e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2695 of None
Current timestep = 2696. State = [[-0.11398708  0.03241415]]. Action = [[0.05593229 0.05332489 0.         0.06145942]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 2696 is [True, False, False, False, True, False]
State prediction error at timestep 2696 is tensor(1.0596e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2696 of None
Current timestep = 2697. State = [[-0.10533213  0.03778775]]. Action = [[ 0.09524874  0.09472444  0.         -0.94982886]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 2697 is [True, False, False, False, True, False]
State prediction error at timestep 2697 is tensor(2.3518e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2697 of None
Current timestep = 2698. State = [[-0.09644592  0.03656217]]. Action = [[ 0.08193178 -0.0714277   0.         -0.7156857 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 2698 is [True, False, False, False, True, False]
State prediction error at timestep 2698 is tensor(8.8112e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2698 of None
Current timestep = 2699. State = [[-0.08739985  0.03669471]]. Action = [[ 0.08646827  0.05170558  0.         -0.24068081]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 2699 is [True, False, False, False, True, False]
State prediction error at timestep 2699 is tensor(1.6221e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2699 of None
Current timestep = 2700. State = [[-0.07798221  0.03565212]]. Action = [[ 0.09277431 -0.04039028  0.         -0.68945   ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 2700 is [True, False, False, False, True, False]
State prediction error at timestep 2700 is tensor(4.1502e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2700 of None
Current timestep = 2701. State = [[-0.06817462  0.03134016]]. Action = [[ 0.09120803 -0.05457911  0.         -0.72834873]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 2701 is [True, False, False, False, True, False]
State prediction error at timestep 2701 is tensor(3.5981e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2701 of None
Current timestep = 2702. State = [[-0.05825812  0.03101483]]. Action = [[ 0.0915577   0.04055733  0.         -0.86246425]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 2702 is [True, False, False, False, True, False]
State prediction error at timestep 2702 is tensor(2.2134e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2702 of None
Current timestep = 2703. State = [[-0.05106526  0.03435507]]. Action = [[ 0.03785305  0.05631358  0.         -0.8594533 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 2703 is [True, False, False, False, True, False]
State prediction error at timestep 2703 is tensor(8.1112e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2703 of None
Current timestep = 2704. State = [[-0.24412885  0.06808619]]. Action = [[ 0.09812345 -0.00579919  0.         -0.83599627]]. Reward = [100.]
Curr episode timestep = 40
Scene graph at timestep 2704 is [True, False, False, False, True, False]
State prediction error at timestep 2704 is tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2704 of None
Current timestep = 2705. State = [[-0.24272661  0.06431858]]. Action = [[ 0.07990531 -0.04007232  0.         -0.29462934]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2705 is [True, False, False, False, True, False]
State prediction error at timestep 2705 is tensor(1.2086e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2705 of None
Current timestep = 2706. State = [[-0.24260338  0.06497575]]. Action = [[-0.02384734  0.02988703  0.         -0.6910802 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2706 is [True, False, False, False, True, False]
State prediction error at timestep 2706 is tensor(4.4886e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2706 of None
Current timestep = 2707. State = [[-0.23901957  0.06248827]]. Action = [[ 0.0971394  -0.07255165  0.         -0.19763553]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2707 is [True, False, False, False, True, False]
State prediction error at timestep 2707 is tensor(6.9399e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2707 of None
Current timestep = 2708. State = [[-0.23228185  0.0609751 ]]. Action = [[ 0.08605971  0.01689334  0.         -0.5671066 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2708 is [True, False, False, False, True, False]
State prediction error at timestep 2708 is tensor(2.6016e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2708 of None
Current timestep = 2709. State = [[-0.22526886  0.06171551]]. Action = [[ 0.08826572  0.01930466  0.         -0.76144546]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2709 is [True, False, False, False, True, False]
State prediction error at timestep 2709 is tensor(1.4834e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2709 of None
Current timestep = 2710. State = [[-0.22189306  0.06370082]]. Action = [[ 0.0058849   0.04023173  0.         -0.6030538 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2710 is [True, False, False, False, True, False]
State prediction error at timestep 2710 is tensor(8.8621e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2710 of None
Current timestep = 2711. State = [[-0.2173989   0.06598614]]. Action = [[ 0.07188661  0.02944567  0.         -0.9048659 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2711 is [True, False, False, False, True, False]
State prediction error at timestep 2711 is tensor(2.0425e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2711 of None
Current timestep = 2712. State = [[-0.21337977  0.07105489]]. Action = [[ 0.02620525  0.08864998  0.         -0.8516239 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2712 is [True, False, False, False, True, False]
State prediction error at timestep 2712 is tensor(1.3172e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2712 of None
Current timestep = 2713. State = [[-0.2079442   0.07718508]]. Action = [[ 0.08149933  0.06894753  0.         -0.7641387 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2713 is [True, False, False, False, True, False]
State prediction error at timestep 2713 is tensor(1.3071e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2713 of None
Current timestep = 2714. State = [[-0.20079046  0.07707306]]. Action = [[ 0.08069894 -0.05057026  0.         -0.5075058 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2714 is [True, False, False, False, True, False]
State prediction error at timestep 2714 is tensor(2.0490e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2714 of None
Current timestep = 2715. State = [[-0.19258098  0.07436524]]. Action = [[ 0.08715501 -0.03213695  0.         -0.43342662]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2715 is [True, False, False, False, True, False]
State prediction error at timestep 2715 is tensor(6.2771e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2715 of None
Current timestep = 2716. State = [[-0.18347576  0.07140332]]. Action = [[ 0.09146854 -0.04053068  0.         -0.8126478 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2716 is [True, False, False, False, True, False]
State prediction error at timestep 2716 is tensor(1.9164e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2716 of None
Current timestep = 2717. State = [[-0.17526966  0.07012118]]. Action = [[ 0.06228212  0.00170811  0.         -0.6245447 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2717 is [True, False, False, False, True, False]
State prediction error at timestep 2717 is tensor(9.1588e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2717 of None
Current timestep = 2718. State = [[-0.16614597  0.0685251 ]]. Action = [[ 0.09235417 -0.02665989  0.         -0.6951476 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2718 is [True, False, False, False, True, False]
State prediction error at timestep 2718 is tensor(2.0646e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2718 of None
Current timestep = 2719. State = [[-0.15620169  0.06995246]]. Action = [[ 0.09022901  0.05356736  0.         -0.665027  ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2719 is [True, False, False, False, True, False]
State prediction error at timestep 2719 is tensor(1.4120e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2719 of None
Current timestep = 2720. State = [[-0.14879863  0.06982104]]. Action = [[ 0.03737656 -0.02577933  0.         -0.7154621 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2720 is [True, False, False, False, True, False]
State prediction error at timestep 2720 is tensor(5.3113e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2720 of None
Current timestep = 2721. State = [[-0.13987426  0.066067  ]]. Action = [[ 0.09197878 -0.05588511  0.         -0.19717252]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2721 is [True, False, False, False, True, False]
State prediction error at timestep 2721 is tensor(7.2234e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2721 of None
Current timestep = 2722. State = [[-0.13062233  0.06210016]]. Action = [[ 0.06564743 -0.03459952  0.         -0.8452849 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2722 is [True, False, False, False, True, False]
State prediction error at timestep 2722 is tensor(3.4062e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2722 of None
Current timestep = 2723. State = [[-0.12068447  0.06271444]]. Action = [[ 0.09403122  0.0494621   0.         -0.4892943 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2723 is [True, False, False, False, True, False]
State prediction error at timestep 2723 is tensor(6.4042e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2723 of None
Current timestep = 2724. State = [[-0.11139341  0.06365856]]. Action = [[ 0.07037184  0.00537816  0.         -0.89690506]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2724 is [True, False, False, False, True, False]
State prediction error at timestep 2724 is tensor(1.5831e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2724 of None
Current timestep = 2725. State = [[-0.10401846  0.06368105]]. Action = [[ 0.04329861  0.00599338  0.         -0.532647  ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2725 is [True, False, False, False, True, False]
State prediction error at timestep 2725 is tensor(2.0507e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2725 of None
Current timestep = 2726. State = [[-0.0965229   0.05987274]]. Action = [[ 0.05962595 -0.07351071  0.         -0.8627747 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2726 is [True, False, False, False, True, False]
State prediction error at timestep 2726 is tensor(1.2432e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2726 of None
Current timestep = 2727. State = [[-0.0873494   0.06139563]]. Action = [[ 0.08693368  0.08335748  0.         -0.79002064]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2727 is [True, False, False, False, True, False]
State prediction error at timestep 2727 is tensor(1.6226e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2727 of None
Current timestep = 2728. State = [[-0.07774258  0.0665486 ]]. Action = [[ 0.09107739  0.06313965  0.         -0.84241205]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2728 is [True, False, False, False, True, False]
State prediction error at timestep 2728 is tensor(2.5259e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2728 of None
Current timestep = 2729. State = [[-0.06831333  0.06870122]]. Action = [[ 0.08770838  0.00544956  0.         -0.90682364]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2729 is [True, False, False, False, True, False]
State prediction error at timestep 2729 is tensor(3.2109e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2729 of None
Current timestep = 2730. State = [[-0.05874511  0.07111841]]. Action = [[ 0.091828    0.04338133  0.         -0.5418366 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2730 is [True, False, False, False, True, False]
State prediction error at timestep 2730 is tensor(1.3072e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2730 of None
Current timestep = 2731. State = [[-0.04851228  0.07205521]]. Action = [[ 0.09636822  0.05973386  0.         -0.9039196 ]]. Reward = [100.]
Curr episode timestep = 26
Scene graph at timestep 2731 is [False, True, False, False, True, False]
State prediction error at timestep 2731 is tensor(1.3377e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2731 of None
Current timestep = 2732. State = [[-0.14226748  0.14223011]]. Action = [[ 0.08904711  0.04691745  0.         -0.80732244]]. Reward = [100.]
Curr episode timestep = 0
Scene graph at timestep 2732 is [True, False, False, False, False, True]
State prediction error at timestep 2732 is tensor(0.0071, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2732 of None
Current timestep = 2733. State = [[-0.13307826  0.13839632]]. Action = [[ 0.09577129 -0.04846325  0.         -0.8204445 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2733 is [True, False, False, False, False, True]
State prediction error at timestep 2733 is tensor(4.1902e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2733 of None
Current timestep = 2734. State = [[-0.12351543  0.13514152]]. Action = [[ 0.09693799 -0.02712568  0.         -0.80798465]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2734 is [True, False, False, False, False, True]
State prediction error at timestep 2734 is tensor(2.4387e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2734 of None
Current timestep = 2735. State = [[-0.11459839  0.12993367]]. Action = [[ 0.07593674 -0.07175408  0.         -0.4473405 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2735 is [True, False, False, False, False, True]
State prediction error at timestep 2735 is tensor(1.2158e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2735 of None
Current timestep = 2736. State = [[-0.10498532  0.12200519]]. Action = [[ 0.09257882 -0.09414797  0.         -0.88111144]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 2737. State = [[-0.09438013  0.11468851]]. Action = [[ 0.09715315 -0.05631727  0.         -0.7891491 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 2738. State = [[-0.08426941  0.11232722]]. Action = [[ 0.08410301  0.0315279   0.         -0.5869868 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 2739. State = [[-0.07441932  0.11067872]]. Action = [[ 0.09058835 -0.00480773  0.         -0.9361629 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 2740. State = [[-0.06420741  0.106374  ]]. Action = [[ 0.09444378 -0.0406526   0.         -0.8138628 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 2741. State = [[-0.05371407  0.10408021]]. Action = [[ 0.09794851  0.02224903  0.         -0.7821951 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 2742. State = [[-0.10003649  0.03332631]]. Action = [[ 0.09122253  0.00485425  0.         -0.597492  ]]. Reward = [100.]
Curr episode timestep = 9
Current timestep = 2743. State = [[-0.09108471  0.0391753 ]]. Action = [[ 0.09465516  0.07047515  0.         -0.59839237]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2744. State = [[-0.08410679  0.04292967]]. Action = [[ 0.04903666  0.00300586  0.         -0.73896384]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2745. State = [[-0.07586468  0.04727948]]. Action = [[ 0.09138852  0.05010881  0.         -0.6898271 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2746. State = [[-0.06770612  0.05163297]]. Action = [[ 0.06359901  0.02477701  0.         -0.9737344 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 2747. State = [[-0.05827929  0.05277822]]. Action = [[ 0.09691714 -0.0253792   0.         -0.8414089 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 2748. State = [[-0.30762318  0.09156835]]. Action = [[ 0.09826534 -0.05146432  0.         -0.6829635 ]]. Reward = [100.]
Curr episode timestep = 5
Current timestep = 2749. State = [[-0.3039965   0.09824392]]. Action = [[ 0.02691963  0.04832805  0.         -0.83009756]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2750. State = [[-0.29917118  0.09974257]]. Action = [[ 0.07979477 -0.03391124  0.         -0.8413407 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2751. State = [[-0.29343668  0.09707169]]. Action = [[ 0.05408824 -0.06607836  0.         -0.737723  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2752. State = [[-0.28627968  0.09935538]]. Action = [[ 0.08551904  0.06185     0.         -0.6706085 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 2753. State = [[-0.27846923  0.09887117]]. Action = [[ 0.0760135  -0.06195331  0.         -0.5398241 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 2754. State = [[-0.27115214  0.09553291]]. Action = [[ 0.05645818 -0.04605009  0.         -0.35747617]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 2755. State = [[-0.2641516   0.09483547]]. Action = [[ 0.0540156   0.00852577  0.         -0.8848397 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 2756. State = [[-0.2574922   0.09240775]]. Action = [[ 0.04562355 -0.05291839  0.         -0.61981916]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 2757. State = [[-0.24916075  0.08973871]]. Action = [[ 0.08029347 -0.01698782  0.         -0.73174095]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 2758. State = [[-0.23960328  0.08945104]]. Action = [[ 0.08690267  0.02001002  0.         -0.30912113]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 2759. State = [[-0.23070894  0.08996397]]. Action = [[ 0.07130802  0.01714005  0.         -0.5224969 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 2760. State = [[-0.22125378  0.08545086]]. Action = [[ 0.08969411 -0.08311394  0.         -0.89733815]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 2761. State = [[-0.21194805  0.07997789]]. Action = [[ 0.07067933 -0.03982109  0.         -0.76545405]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 2762. State = [[-0.2070071   0.07301966]]. Action = [[-0.01335602 -0.09113362  0.         -0.5332495 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 2763. State = [[-0.19937055  0.06500317]]. Action = [[ 0.08902461 -0.08044786  0.         -0.90159655]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 2764. State = [[-0.19044624  0.06425128]]. Action = [[ 0.06530019  0.07108495  0.         -0.6361171 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 2765. State = [[-0.18162553  0.06835208]]. Action = [[ 0.08820672  0.07693589  0.         -0.92185545]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 2766. State = [[-0.17354181  0.06779787]]. Action = [[ 0.06629627 -0.03163683  0.         -0.5958489 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 2767. State = [[-0.16525388  0.06444518]]. Action = [[ 0.07888991 -0.02864806  0.         -0.87438375]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 2768. State = [[-0.1563029  0.0629032]]. Action = [[ 0.08582842  0.00889035  0.         -0.82475835]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 2769. State = [[-0.14952949  0.06658485]]. Action = [[ 0.04105035  0.08809905  0.         -0.36624742]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 2770. State = [[-0.14243591  0.0671543 ]]. Action = [[ 0.0760069  -0.03075485  0.         -0.62763906]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 2771. State = [[-0.13346781  0.06686959]]. Action = [[ 0.09233271  0.01705017  0.         -0.9196357 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 2772. State = [[-0.12359907  0.06398007]]. Action = [[ 0.09836506 -0.05937947  0.         -0.7850795 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 2773. State = [[-0.11369964  0.05935583]]. Action = [[ 0.08783907 -0.04830515  0.         -0.8825199 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 2774. State = [[-0.10361533  0.05715117]]. Action = [[ 9.3538351e-02  5.6432188e-04  0.0000000e+00 -6.0912085e-01]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 2775. State = [[-0.09369893  0.05863107]]. Action = [[ 0.08836771  0.04785185  0.         -0.530252  ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 2776. State = [[-0.08345509  0.05883668]]. Action = [[ 0.09918004 -0.00918615  0.         -0.74102044]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 2777. State = [[-0.07293522  0.05954826]]. Action = [[ 0.09745202  0.03201506  0.         -0.9633391 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 2778. State = [[-0.06251629  0.06149953]]. Action = [[ 0.0973139   0.03186538  0.         -0.8326228 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 2779. State = [[-0.05219758  0.06448125]]. Action = [[ 0.09629703  0.0481903   0.         -0.9041255 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 2780. State = [[-0.08549587 -0.0732154 ]]. Action = [[ 0.07281245  0.01405795  0.         -0.78434014]]. Reward = [100.]
Curr episode timestep = 31
Current timestep = 2781. State = [[-0.08610637 -0.06778862]]. Action = [[ 0.04542541  0.03341239  0.         -0.9050433 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2782. State = [[-0.08015057 -0.06244683]]. Action = [[ 0.09877268  0.05962282  0.         -0.8530841 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2783. State = [[-0.07337917 -0.05581153]]. Action = [[ 0.08883259  0.06749078  0.         -0.905035  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2784. State = [[-0.06637819 -0.05236373]]. Action = [[ 0.09664411 -0.00246696  0.         -0.78957707]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 2785. State = [[-0.05888976 -0.05069488]]. Action = [[ 0.09651249  0.00742407  0.         -0.8822849 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 2786. State = [[-0.05138348 -0.04595055]]. Action = [[ 0.09072386  0.06935226  0.         -0.73746586]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 2787. State = [[-0.24727497 -0.02014131]]. Action = [[ 0.08864432  0.02572323  0.         -0.86773   ]]. Reward = [100.]
Curr episode timestep = 6
Current timestep = 2788. State = [[-0.24015786 -0.02237748]]. Action = [[ 0.0955564   0.00742197  0.         -0.89743495]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2789. State = [[-0.2352625  -0.02521753]]. Action = [[ 0.04113107 -0.03664842  0.         -0.8009825 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2790. State = [[-0.22907138 -0.02838034]]. Action = [[ 0.09389656 -0.01580438  0.         -0.12422055]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2791. State = [[-0.22721386 -0.03409648]]. Action = [[-0.02943422 -0.07490173  0.         -0.50077075]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 2792. State = [[-0.22421205 -0.04167489]]. Action = [[ 0.06019951 -0.07513672  0.         -0.39519322]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 2793. State = [[-0.2191383  -0.04921658]]. Action = [[ 0.05206651 -0.06714733  0.         -0.89252   ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 2794. State = [[-0.2126964  -0.05417174]]. Action = [[ 0.07968915 -0.01572466  0.         -0.8573791 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 2795. State = [[-0.21012424 -0.05455651]]. Action = [[-0.01544766  0.04665446  0.         -0.8751418 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 2796. State = [[-0.20578945 -0.05255609]]. Action = [[ 0.08016709  0.04913402  0.         -0.6876114 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 2797. State = [[-0.19829683 -0.05421148]]. Action = [[ 0.09622227 -0.03699049  0.         -0.76329917]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 2798. State = [[-0.19130321 -0.05866982]]. Action = [[ 0.06761747 -0.04558512  0.         -0.87584877]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 2799. State = [[-0.18339168 -0.05686238]]. Action = [[ 0.09855955  0.08639688  0.         -0.93280333]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 2800. State = [[-0.17575315 -0.05572392]]. Action = [[ 0.077485   -0.01081984  0.         -0.59259665]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 2801. State = [[-0.1675231  -0.06036056]]. Action = [[ 0.09213901 -0.07675973  0.         -0.77450144]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 2802. State = [[-0.15941145 -0.06293372]]. Action = [[ 0.07316638  0.00814253  0.         -0.82653415]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 2803. State = [[-0.15266074 -0.0627713 ]]. Action = [[ 0.05147324  0.01535799  0.         -0.8546611 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 2804. State = [[-0.14435299 -0.0623655 ]]. Action = [[ 0.09313723  0.0109484   0.         -0.67146206]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 2805. State = [[-0.13661729 -0.0611972 ]]. Action = [[ 0.05647845  0.02563696  0.         -0.7985892 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 2806. State = [[-0.12893477 -0.05678708]]. Action = [[ 0.07457408  0.07713374  0.         -0.6145674 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 2807. State = [[-0.12264358 -0.05488056]]. Action = [[ 0.03696304 -0.01086577  0.         -0.53921187]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 2808. State = [[-0.11802109 -0.05462014]]. Action = [[ 0.01728467  0.00200603  0.         -0.7178273 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 2809. State = [[-0.11570409 -0.05159264]]. Action = [[-0.02068348  0.0490085   0.         -0.78826845]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 2810. State = [[-0.11177157 -0.04769583]]. Action = [[ 0.0382211   0.03164449  0.         -0.703161  ]]. Reward = [0.]
