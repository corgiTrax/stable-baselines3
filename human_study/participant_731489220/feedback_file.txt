Current timestep = 0. State = [[-0.2582708   0.01024858]]. Action = [[-0.02517132 -0.00313229  0.08415417 -0.03610903]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [True, False, False, False, True, False]
State prediction error at timestep 0 is 0.012
Current timestep = 1. State = [[-0.25915354  0.01067328]]. Action = [[ 0.01121883  0.03684529 -0.07181501 -0.24135602]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False]
State prediction error at timestep 1 is 0.012
Current timestep = 2. State = [[-0.26001275  0.0126455 ]]. Action = [[-0.06113325  0.04126974  0.03300034  0.97395396]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, True, False]
State prediction error at timestep 2 is 0.012
Current timestep = 3. State = [[-0.2632868   0.01589616]]. Action = [[-0.06263261  0.07551753 -0.02271957 -0.21903908]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, True, False]
State prediction error at timestep 3 is 0.012
Current timestep = 4. State = [[-0.26667622  0.01840981]]. Action = [[-0.02606332 -0.08540395 -0.09080984  0.91687274]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, True, False]
State prediction error at timestep 4 is 0.012
Current timestep = 5. State = [[-0.27046862  0.01760711]]. Action = [[-0.07761858  0.08164795 -0.07904283 -0.8448607 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, True, False]
State prediction error at timestep 5 is 0.012
Current timestep = 6. State = [[-0.2724813   0.01934353]]. Action = [[ 0.09810986 -0.04243719 -0.07681088 -0.2252906 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, True, False]
State prediction error at timestep 6 is 0.012
Current timestep = 7. State = [[-0.2711584   0.01973974]]. Action = [[-0.05269296  0.07933923 -0.05097861  0.7123525 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, True, False]
State prediction error at timestep 7 is 0.012
Current timestep = 8. State = [[-0.2708412   0.02317443]]. Action = [[ 0.0754961   0.04299169 -0.08663189 -0.08161724]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, True, False]
State prediction error at timestep 8 is 0.012
Current timestep = 9. State = [[-0.26925895  0.02508502]]. Action = [[-0.07022719 -0.05783322  0.0835178   0.24431825]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, True, False]
State prediction error at timestep 9 is 0.012
Current timestep = 10. State = [[-0.26993945  0.02263628]]. Action = [[ 0.06681105 -0.08201386 -0.0795724  -0.67114556]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, True, False]
State prediction error at timestep 10 is 0.012
Current timestep = 11. State = [[-0.26839983  0.01784727]]. Action = [[-0.00926805 -0.06453748  0.05081462 -0.9684069 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, True, False]
State prediction error at timestep 11 is 0.012
Current timestep = 12. State = [[-0.26805764  0.01246909]]. Action = [[-0.00988554 -0.09839112  0.08039667 -0.614913  ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, True, False]
State prediction error at timestep 12 is 0.012
Current timestep = 13. State = [[-0.2671095   0.00645619]]. Action = [[ 0.09057599 -0.05426887  0.07797232  0.24568582]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, True, False]
State prediction error at timestep 13 is 0.012
Current timestep = 14. State = [[-0.26281285  0.00261762]]. Action = [[ 0.07226252  0.01412418 -0.09395985 -0.4160719 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, True, False]
State prediction error at timestep 14 is 0.012
Current timestep = 15. State = [[-0.25934625  0.00101239]]. Action = [[-0.05909092 -0.05171558 -0.0525969   0.7692232 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, True, False]
State prediction error at timestep 15 is 0.012
Current timestep = 16. State = [[-2.6166517e-01 -9.2953815e-05]]. Action = [[-0.08847439  0.07359082 -0.01290637  0.7894316 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, True, False]
State prediction error at timestep 16 is 0.012
Current timestep = 17. State = [[-0.26541334  0.0032411 ]]. Action = [[ 0.00787131  0.08607116 -0.07212043 -0.33679414]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, True, False]
State prediction error at timestep 17 is 0.012
Current timestep = 18. State = [[-0.2670702   0.00863108]]. Action = [[-0.03301679  0.08093991 -0.04848113 -0.731575  ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, True, False]
State prediction error at timestep 18 is 0.012
Current timestep = 19. State = [[-0.26835513  0.01282883]]. Action = [[ 0.00312903 -0.03759826  0.05114145 -0.25821555]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, True, False]
State prediction error at timestep 19 is 0.012
Current timestep = 20. State = [[-0.26812196  0.01389934]]. Action = [[ 0.0632496   0.05764089 -0.0382315   0.49787724]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, True, False]
State prediction error at timestep 20 is 0.012
Current timestep = 21. State = [[-0.26485807  0.01614823]]. Action = [[ 0.05672931  0.00467298 -0.07356826  0.501621  ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, True, False]
State prediction error at timestep 21 is 0.012
Current timestep = 22. State = [[-0.26090282  0.01859822]]. Action = [[ 0.06753404  0.09819474  0.039411   -0.9514527 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [True, False, False, False, True, False]
State prediction error at timestep 22 is 0.012
Current timestep = 23. State = [[-0.25739995  0.02375886]]. Action = [[-0.02280841  0.06887992  0.05683497  0.03624845]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [True, False, False, False, True, False]
State prediction error at timestep 23 is 0.012
Current timestep = 24. State = [[-0.2564405   0.02949097]]. Action = [[ 0.03349089  0.09955809  0.05350745 -0.682824  ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [True, False, False, False, True, False]
State prediction error at timestep 24 is 0.012
Current timestep = 25. State = [[-0.25544998  0.03372465]]. Action = [[-0.0462237  -0.08078437  0.09888066  0.63734305]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [True, False, False, False, True, False]
State prediction error at timestep 25 is 0.012
Current timestep = 26. State = [[-0.25628605  0.03277216]]. Action = [[ 0.04534339  0.01859118 -0.00705447 -0.01341397]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [True, False, False, False, True, False]
State prediction error at timestep 26 is 0.012
Current timestep = 27. State = [[-0.25576115  0.03189843]]. Action = [[-0.05272523 -0.06325215  0.00538734 -0.01878482]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [True, False, False, False, True, False]
State prediction error at timestep 27 is 0.012
Current timestep = 28. State = [[-0.2585182  0.0297081]]. Action = [[-7.3070809e-02  1.4945790e-02 -7.2551519e-04 -9.1120285e-01]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [True, False, False, False, True, False]
State prediction error at timestep 28 is 0.012
Current timestep = 29. State = [[-0.26129794  0.03019338]]. Action = [[ 0.05071848  0.05536649 -0.01994523 -0.4208697 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [True, False, False, False, True, False]
State prediction error at timestep 29 is 0.012
Current timestep = 30. State = [[-0.260854    0.03320119]]. Action = [[-0.01370352  0.06336819 -0.09457915 -0.95380545]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [True, False, False, False, True, False]
State prediction error at timestep 30 is 0.012
Current timestep = 31. State = [[-0.26120728  0.03671009]]. Action = [[-0.02395083  0.01285665 -0.02076205  0.84736323]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [True, False, False, False, True, False]
State prediction error at timestep 31 is 0.012
Current timestep = 32. State = [[-0.26205814  0.03740717]]. Action = [[ 4.3716282e-04 -7.0835866e-02 -7.5898826e-02 -4.9097490e-01]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [True, False, False, False, True, False]
State prediction error at timestep 32 is 0.012
Current timestep = 33. State = [[-0.2636745   0.03400699]]. Action = [[-0.07968862 -0.07912775  0.08637451 -0.9374181 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [True, False, False, False, True, False]
State prediction error at timestep 33 is 0.012
Current timestep = 34. State = [[-0.26673943  0.03024608]]. Action = [[ 0.0229729   0.01553579 -0.09458311  0.09854746]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [True, False, False, False, True, False]
State prediction error at timestep 34 is 0.012
Current timestep = 35. State = [[-0.26734692  0.02883595]]. Action = [[-0.02379552 -0.03595639  0.03375626  0.6699455 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [True, False, False, False, True, False]
State prediction error at timestep 35 is 0.012
Current timestep = 36. State = [[-0.26691997  0.0271284 ]]. Action = [[ 0.09312334 -0.00839349  0.06660537  0.02484822]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [True, False, False, False, True, False]
State prediction error at timestep 36 is 0.012
Current timestep = 37. State = [[-0.26263577  0.02548637]]. Action = [[ 0.0663007  -0.04746206  0.0988551   0.314659  ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [True, False, False, False, True, False]
State prediction error at timestep 37 is 0.012
Current timestep = 38. State = [[-0.2592076   0.02229017]]. Action = [[-0.03301517 -0.06903735 -0.06527947 -0.56067777]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [True, False, False, False, True, False]
State prediction error at timestep 38 is 0.012
Current timestep = 39. State = [[-0.2594605   0.01824745]]. Action = [[-0.02143808 -0.03881108 -0.03790156  0.5556381 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [True, False, False, False, True, False]
State prediction error at timestep 39 is 0.012
Current timestep = 40. State = [[-0.26201013  0.01678267]]. Action = [[-0.09060122  0.09276371 -0.07957199  0.32077074]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [True, False, False, False, True, False]
State prediction error at timestep 40 is 0.012
Current timestep = 41. State = [[-0.2648744   0.01892882]]. Action = [[ 0.04349054 -0.03881253  0.08305307 -0.17703742]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [True, False, False, False, True, False]
State prediction error at timestep 41 is 0.012
Current timestep = 42. State = [[-0.26537704  0.01860812]]. Action = [[-0.03742965  0.00716915  0.0617476   0.46081853]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [True, False, False, False, True, False]
State prediction error at timestep 42 is 0.012
Current timestep = 43. State = [[-0.26574954  0.01947013]]. Action = [[ 0.06237604  0.05458137  0.02491368 -0.7390872 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [True, False, False, False, True, False]
State prediction error at timestep 43 is 0.012
Current timestep = 44. State = [[-0.26399565  0.02267933]]. Action = [[-0.00907054  0.07323664  0.05582912 -0.0730992 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [True, False, False, False, True, False]
State prediction error at timestep 44 is 0.012
Current timestep = 45. State = [[-0.26263648  0.02617666]]. Action = [[ 0.04537082 -0.01607694  0.02252619 -0.51758724]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [True, False, False, False, True, False]
State prediction error at timestep 45 is 0.012
Current timestep = 46. State = [[-0.2603628   0.02750506]]. Action = [[0.03811892 0.04228497 0.09190296 0.02757192]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [True, False, False, False, True, False]
State prediction error at timestep 46 is 0.012
Current timestep = 47. State = [[-0.2582349   0.02892819]]. Action = [[-0.01317835 -0.02618026  0.0384618   0.755185  ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [True, False, False, False, True, False]
State prediction error at timestep 47 is 0.012
Current timestep = 48. State = [[-0.25874373  0.02889376]]. Action = [[-0.04631549  0.02226819 -0.08048056  0.37288344]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [True, False, False, False, True, False]
State prediction error at timestep 48 is 0.012
Current timestep = 49. State = [[-0.25984     0.03004584]]. Action = [[ 0.04538212  0.03099369 -0.08087294  0.8847685 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [True, False, False, False, True, False]
State prediction error at timestep 49 is 0.012
Current timestep = 50. State = [[-0.2590516   0.03034502]]. Action = [[-0.03130955 -0.08020533 -0.04806885 -0.02700591]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [True, False, False, False, True, False]
State prediction error at timestep 50 is 0.012
Current timestep = 51. State = [[-0.25890544  0.02908935]]. Action = [[ 0.08275392  0.09060951 -0.01434544  0.1242373 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 51 is [True, False, False, False, True, False]
State prediction error at timestep 51 is 0.012
Current timestep = 52. State = [[-0.25459823  0.03037846]]. Action = [[ 0.07275843 -0.08305749  0.07526415  0.5712166 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 52 is [True, False, False, False, True, False]
State prediction error at timestep 52 is 0.012
Current timestep = 53. State = [[-0.25144798  0.02779917]]. Action = [[-0.04576635 -0.02269816 -0.0494803  -0.8974389 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 53 is [True, False, False, False, True, False]
State prediction error at timestep 53 is 0.012
Current timestep = 54. State = [[-0.25235173  0.02470335]]. Action = [[-0.04895029 -0.08923292  0.08332331  0.16367233]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 54 is [True, False, False, False, True, False]
State prediction error at timestep 54 is 0.012
Current timestep = 55. State = [[-0.2551204   0.01957026]]. Action = [[-0.03475114 -0.07091607 -0.03284355  0.7207265 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 55 is [True, False, False, False, True, False]
State prediction error at timestep 55 is 0.012
Current timestep = 56. State = [[-0.25721657  0.01592553]]. Action = [[ 0.02381404  0.04445919 -0.05927184  0.91396666]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 56 is [True, False, False, False, True, False]
State prediction error at timestep 56 is 0.012
Current timestep = 57. State = [[-0.2554137   0.01522156]]. Action = [[ 0.09283268 -0.06270957  0.09320115 -0.27012765]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 57 is [True, False, False, False, True, False]
State prediction error at timestep 57 is 0.012
Current timestep = 58. State = [[-0.2517838   0.01189465]]. Action = [[-0.00675305 -0.07176851 -0.03619952  0.02913284]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 58 is [True, False, False, False, True, False]
State prediction error at timestep 58 is 0.012
Current timestep = 59. State = [[-0.2522606   0.00955043]]. Action = [[-0.08985103  0.09186571  0.01365498 -0.01006943]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 59 is [True, False, False, False, True, False]
State prediction error at timestep 59 is 0.012
Current timestep = 60. State = [[-0.25475708  0.01272826]]. Action = [[ 0.03257651  0.06013202 -0.01982924  0.36233544]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 60 is [True, False, False, False, True, False]
State prediction error at timestep 60 is 0.012
Current timestep = 61. State = [[-0.25333434  0.01604131]]. Action = [[ 0.08748408 -0.0035544   0.04789095  0.6086904 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 61 is [True, False, False, False, True, False]
State prediction error at timestep 61 is 0.012
Current timestep = 62. State = [[-0.2498405   0.01613128]]. Action = [[-0.0061772  -0.06493673 -0.0312747  -0.59949154]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 62 is [True, False, False, False, True, False]
State prediction error at timestep 62 is 0.012
Current timestep = 63. State = [[-0.2484495   0.01482912]]. Action = [[ 0.03622233  0.06289604  0.06601017 -0.9037737 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 63 is [True, False, False, False, True, False]
State prediction error at timestep 63 is 0.012
Current timestep = 64. State = [[-0.24726264  0.01649833]]. Action = [[-0.0444268   0.00884514 -0.09802714 -0.55001134]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 64 is [True, False, False, False, True, False]
State prediction error at timestep 64 is 0.012
Current timestep = 65. State = [[-0.24941617  0.01760597]]. Action = [[-0.07457881  0.00533535  0.06909239 -0.73126566]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 65 is [True, False, False, False, True, False]
State prediction error at timestep 65 is 0.012
Current timestep = 66. State = [[-0.25222686  0.01723376]]. Action = [[ 0.02870005 -0.06568596 -0.09837475 -0.78596085]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 66 is [True, False, False, False, True, False]
State prediction error at timestep 66 is 0.012
Current timestep = 67. State = [[-0.25107065  0.0143679 ]]. Action = [[ 0.09941655 -0.03260429  0.0816211   0.7270007 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 67 is [True, False, False, False, True, False]
State prediction error at timestep 67 is 0.012
Current timestep = 68. State = [[-0.24725825  0.01338462]]. Action = [[0.0126427  0.08787294 0.07834474 0.43771553]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 68 is [True, False, False, False, True, False]
State prediction error at timestep 68 is 0.012
Current timestep = 69. State = [[-0.2460612   0.01523493]]. Action = [[-0.08297069 -0.05488757  0.05622382  0.3013432 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 69 is [True, False, False, False, True, False]
State prediction error at timestep 69 is 0.012
Current timestep = 70. State = [[-0.24889883  0.01389375]]. Action = [[-0.01454542 -0.02396128 -0.07411633  0.02888215]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 70 is [True, False, False, False, True, False]
State prediction error at timestep 70 is 0.012
Current timestep = 71. State = [[-0.250571    0.01238581]]. Action = [[ 0.00488553 -0.00518494  0.036042   -0.54344183]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 71 is [True, False, False, False, True, False]
State prediction error at timestep 71 is 0.012
Current timestep = 72. State = [[-0.25189403  0.01123376]]. Action = [[-0.06774455 -0.02733359 -0.00795063  0.9019809 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 72 is [True, False, False, False, True, False]
State prediction error at timestep 72 is 0.012
Current timestep = 73. State = [[-0.25455713  0.01139276]]. Action = [[ 0.01881512  0.09733189  0.04219944 -0.14095664]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 73 is [True, False, False, False, True, False]
State prediction error at timestep 73 is 0.012
Current timestep = 74. State = [[-0.25473374  0.01343981]]. Action = [[-0.01836509 -0.0853783   0.02358713 -0.5593137 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 74 is [True, False, False, False, True, False]
State prediction error at timestep 74 is 0.012
Current timestep = 75. State = [[-0.25620782  0.01037146]]. Action = [[-0.04543436 -0.07269826  0.09658947 -0.39439988]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 75 is [True, False, False, False, True, False]
State prediction error at timestep 75 is 0.012
Current timestep = 76. State = [[-0.2590181   0.00666396]]. Action = [[-3.7618410e-02  1.8163025e-04 -4.0399708e-02  7.1356511e-01]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 76 is [True, False, False, False, True, False]
State prediction error at timestep 76 is 0.012
Current timestep = 77. State = [[-0.26126328  0.0041724 ]]. Action = [[-0.01348653 -0.07660855 -0.0293747  -0.311545  ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 77 is [True, False, False, False, True, False]
State prediction error at timestep 77 is 0.012
Current timestep = 78. State = [[-0.26243553 -0.00064759]]. Action = [[ 0.0088176  -0.09705828  0.04007175  0.51455307]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 78 is [True, False, False, False, True, False]
State prediction error at timestep 78 is 0.012
Current timestep = 79. State = [[-0.26393005 -0.00654268]]. Action = [[-0.08410595 -0.05526781 -0.08487031 -0.64967614]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 79 is [True, False, False, False, True, False]
State prediction error at timestep 79 is 0.012
Current timestep = 80. State = [[-0.2671591  -0.01144177]]. Action = [[-0.00273821 -0.06441283 -0.0241676  -0.23225856]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 80 is [True, False, False, False, True, False]
State prediction error at timestep 80 is 0.012
Current timestep = 81. State = [[-0.26785216 -0.01574514]]. Action = [[ 0.0523889  -0.02938996 -0.06605877 -0.47577   ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 81 is [True, False, False, False, True, False]
State prediction error at timestep 81 is 0.012
Current timestep = 82. State = [[-0.26771113 -0.01694443]]. Action = [[-0.08084679  0.09289929 -0.05120718 -0.83660877]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 82 is [True, False, False, False, True, False]
State prediction error at timestep 82 is 0.012
Current timestep = 83. State = [[-0.26839063 -0.01400368]]. Action = [[ 0.09557936  0.0084514   0.03005014 -0.7967107 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 83 is [True, False, False, False, True, False]
State prediction error at timestep 83 is 0.012
Current timestep = 84. State = [[-0.26558062 -0.01254576]]. Action = [[ 1.0477938e-02 -7.7143312e-04 -8.6157724e-02 -9.0358460e-01]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 84 is [True, False, False, False, True, False]
State prediction error at timestep 84 is 0.012
Current timestep = 85. State = [[-0.2635343  -0.01160243]]. Action = [[ 0.03765007  0.03227519 -0.03392147 -0.30874026]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 85 is [True, False, False, False, True, False]
State prediction error at timestep 85 is 0.012
Current timestep = 86. State = [[-0.26162192 -0.01105075]]. Action = [[-0.01675708 -0.05415622  0.066994   -0.28540534]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 86 is [True, False, False, False, True, False]
State prediction error at timestep 86 is 0.012
Current timestep = 87. State = [[-0.26245233 -0.01287435]]. Action = [[-0.05287606 -0.01641592  0.01526015 -0.12867564]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 87 is [True, False, False, False, True, False]
State prediction error at timestep 87 is 0.012
Current timestep = 88. State = [[-0.26462367 -0.01425491]]. Action = [[-0.00321083 -0.00711001 -0.05035846  0.3568728 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 88 is [True, False, False, False, True, False]
State prediction error at timestep 88 is 0.012
Current timestep = 89. State = [[-0.2661481  -0.01635836]]. Action = [[-5.0467383e-02 -9.0453409e-02  3.1928718e-04  9.8299289e-01]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 89 is [True, False, False, False, True, False]
State prediction error at timestep 89 is 0.012
Current timestep = 90. State = [[-0.26985657 -0.01886846]]. Action = [[-0.06923585  0.08169415 -0.01754173  0.30456305]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 90 is [True, False, False, False, True, False]
State prediction error at timestep 90 is 0.012
Current timestep = 91. State = [[-0.27469787 -0.01638277]]. Action = [[-0.0972987   0.05307455 -0.09755058 -0.79303753]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 91 is [True, False, False, False, True, False]
State prediction error at timestep 91 is 0.012
Current timestep = 92. State = [[-0.2791088  -0.01448137]]. Action = [[ 0.02130534 -0.06689826  0.01533963 -0.19529057]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 92 is [True, False, False, False, True, False]
State prediction error at timestep 92 is 0.012
Current timestep = 93. State = [[-0.28048193 -0.01510944]]. Action = [[ 0.0036811   0.06034426 -0.0312944   0.37502968]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 93 is [True, False, False, False, True, False]
State prediction error at timestep 93 is 0.012
Current timestep = 94. State = [[-0.2799245  -0.01339361]]. Action = [[0.03166024 0.00575425 0.01886453 0.10213578]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 94 is [True, False, False, False, True, False]
State prediction error at timestep 94 is 0.012
Current timestep = 95. State = [[-0.27921098 -0.01189407]]. Action = [[-0.02989867  0.04017638 -0.06231183 -0.81921107]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 95 is [True, False, False, False, True, False]
State prediction error at timestep 95 is 0.012
Current timestep = 96. State = [[-0.27996922 -0.00957904]]. Action = [[-0.00971439  0.0301424  -0.07408705 -0.04370892]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 96 is [True, False, False, False, True, False]
State prediction error at timestep 96 is 0.012
Current timestep = 97. State = [[-0.27946925 -0.0070693 ]]. Action = [[ 0.0807774   0.04114463  0.08333304 -0.6593675 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 97 is [True, False, False, False, True, False]
State prediction error at timestep 97 is 0.012
Current timestep = 98. State = [[-0.27716106 -0.00459709]]. Action = [[-0.03965494  0.01769154  0.01191881  0.92147255]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 98 is [True, False, False, False, True, False]
State prediction error at timestep 98 is 0.012
Current timestep = 99. State = [[-0.27811062 -0.00269087]]. Action = [[-0.03942654  0.02698264 -0.08467113 -0.16999316]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 99 is [True, False, False, False, True, False]
State prediction error at timestep 99 is 0.012
Current timestep = 100. State = [[-0.28054258 -0.0024455 ]]. Action = [[-0.06031826 -0.08776253 -0.00947938  0.11940181]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 100 is [True, False, False, False, True, False]
State prediction error at timestep 100 is 0.012
Current timestep = 101. State = [[-0.28517902 -0.00544383]]. Action = [[-0.09161872 -0.01099446  0.04641641  0.28773856]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 101 is [True, False, False, False, True, False]
State prediction error at timestep 101 is 0.012
Current timestep = 102. State = [[-0.28940585 -0.00633761]]. Action = [[0.03710111 0.04353496 0.02696779 0.2768674 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 102 is [True, False, False, False, True, False]
State prediction error at timestep 102 is 0.012
Current timestep = 103. State = [[-0.2882248  -0.00530888]]. Action = [[ 0.08918381 -0.00831923 -0.08352672 -0.28873467]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 103 is [True, False, False, False, True, False]
State prediction error at timestep 103 is 0.012
Current timestep = 104. State = [[-0.2852982  -0.00580569]]. Action = [[-0.04273349 -0.04148028  0.08754414 -0.7239744 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 104 is [True, False, False, False, True, False]
State prediction error at timestep 104 is 0.012
Current timestep = 105. State = [[-0.28577492 -0.007884  ]]. Action = [[-0.01482176 -0.03528193 -0.02799021 -0.9768368 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 105 is [True, False, False, False, True, False]
State prediction error at timestep 105 is 0.012
Current timestep = 106. State = [[-0.28540733 -0.01002954]]. Action = [[ 0.08357575 -0.01348406  0.08208784 -0.11461991]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 106 is [True, False, False, False, True, False]
State prediction error at timestep 106 is 0.012
Current timestep = 107. State = [[-0.2826892  -0.01146926]]. Action = [[-0.01091077 -0.00968432  0.08984665 -0.08456141]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 107 is [True, False, False, False, True, False]
State prediction error at timestep 107 is 0.012
Current timestep = 108. State = [[-0.28208977 -0.0125922 ]]. Action = [[-0.01592769 -0.02231164 -0.00850479 -0.52216256]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 108 is [True, False, False, False, True, False]
State prediction error at timestep 108 is 0.012
Current timestep = 109. State = [[-0.28177997 -0.01305915]]. Action = [[ 0.058874    0.04144724 -0.0447047  -0.8177222 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 109 is [True, False, False, False, True, False]
State prediction error at timestep 109 is 0.012
Current timestep = 110. State = [[-0.2783942  -0.01182672]]. Action = [[ 0.08087202  0.00300796  0.06354868 -0.9461646 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 110 is [True, False, False, False, True, False]
State prediction error at timestep 110 is 0.012
Current timestep = 111. State = [[-0.27338237 -0.0100154 ]]. Action = [[ 0.08202185  0.07949492 -0.05382702  0.9906614 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 111 is [True, False, False, False, True, False]
State prediction error at timestep 111 is 0.012
Current timestep = 112. State = [[-0.2672068  -0.00691658]]. Action = [[ 0.08528724 -0.01235012  0.06995175 -0.96350336]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 112 is [True, False, False, False, True, False]
State prediction error at timestep 112 is 0.012
Current timestep = 113. State = [[-0.26345807 -0.0056853 ]]. Action = [[-0.07417892  0.0336945   0.06228643  0.84478045]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 113 is [True, False, False, False, True, False]
State prediction error at timestep 113 is 0.012
Current timestep = 114. State = [[-0.26360285 -0.00269104]]. Action = [[ 0.06916561  0.0973826  -0.03375982  0.2454791 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 114 is [True, False, False, False, True, False]
State prediction error at timestep 114 is 0.012
Current timestep = 115. State = [[-0.2616858   0.00280926]]. Action = [[-0.01158882  0.08103619  0.08105295 -0.38037252]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 115 is [True, False, False, False, True, False]
State prediction error at timestep 115 is 0.012
Current timestep = 116. State = [[-0.2605014   0.00715909]]. Action = [[ 0.03212031 -0.03029605 -0.07179489  0.67524683]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 116 is [True, False, False, False, True, False]
State prediction error at timestep 116 is 0.012
Current timestep = 117. State = [[-0.25861174  0.00896586]]. Action = [[0.05970105 0.08509628 0.01517849 0.4118315 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 117 is [True, False, False, False, True, False]
State prediction error at timestep 117 is 0.012
Current timestep = 118. State = [[-0.25575417  0.01275058]]. Action = [[-0.00548008  0.03136968  0.09019355  0.8506783 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 118 is [True, False, False, False, True, False]
State prediction error at timestep 118 is 0.012
Current timestep = 119. State = [[-0.25379917  0.01604975]]. Action = [[ 0.07496005  0.0512901   0.06044472 -0.5467224 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 119 is [True, False, False, False, True, False]
State prediction error at timestep 119 is 0.012
Current timestep = 120. State = [[-0.2503615   0.01868959]]. Action = [[ 0.01337998 -0.0130128  -0.07320319 -0.27900124]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 120 is [True, False, False, False, True, False]
State prediction error at timestep 120 is 0.012
Current timestep = 121. State = [[-0.2498932   0.02009581]]. Action = [[-0.07190643  0.06262528  0.08503192 -0.14114434]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 121 is [True, False, False, False, True, False]
State prediction error at timestep 121 is 0.012
Current timestep = 122. State = [[-0.2506056   0.02249493]]. Action = [[ 0.08701735 -0.01347913 -0.01041719  0.5711534 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 122 is [True, False, False, False, True, False]
State prediction error at timestep 122 is 0.012
Current timestep = 123. State = [[-0.24848826  0.02236895]]. Action = [[-0.01879687 -0.03573602  0.01343177  0.10692334]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 123 is [True, False, False, False, True, False]
State prediction error at timestep 123 is 0.012
Current timestep = 124. State = [[-0.24796763  0.02073096]]. Action = [[ 0.01601466 -0.02323282  0.05927012  0.21763086]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 124 is [True, False, False, False, True, False]
State prediction error at timestep 124 is 0.012
Current timestep = 125. State = [[-0.24859914  0.01942308]]. Action = [[-0.07914612  0.01010527 -0.01630551 -0.05132365]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 125 is [True, False, False, False, True, False]
State prediction error at timestep 125 is 0.012
Current timestep = 126. State = [[-0.25030988  0.01926365]]. Action = [[ 0.06825583 -0.00703262  0.04944303 -0.04624939]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 126 is [True, False, False, False, True, False]
State prediction error at timestep 126 is 0.012
Current timestep = 127. State = [[-0.24958993  0.01904368]]. Action = [[-0.04754002  0.00680681 -0.01599861  0.01879144]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 127 is [True, False, False, False, True, False]
State prediction error at timestep 127 is 0.012
Current timestep = 128. State = [[-0.25215364  0.01949613]]. Action = [[-0.09623236  0.02034541 -0.01810242  0.18736851]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 128 is [True, False, False, False, True, False]
State prediction error at timestep 128 is 0.012
Current timestep = 129. State = [[-0.25793707  0.02151056]]. Action = [[-0.09710603  0.07774549 -0.08365448 -0.909334  ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 129 is [True, False, False, False, True, False]
State prediction error at timestep 129 is 0.012
Current timestep = 130. State = [[-0.26420262  0.02368777]]. Action = [[-0.0848588  -0.08023626  0.01014981  0.97973585]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 130 is [True, False, False, False, True, False]
State prediction error at timestep 130 is 0.012
Current timestep = 131. State = [[-0.26950395  0.0231757 ]]. Action = [[ 0.02452739  0.08706162  0.05962651 -0.33817333]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 131 is [True, False, False, False, True, False]
State prediction error at timestep 131 is 0.012
Current timestep = 132. State = [[-0.2700682   0.02462222]]. Action = [[-1.5713274e-04 -7.2476134e-02 -2.7982354e-02 -9.3395925e-01]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 132 is [True, False, False, False, True, False]
State prediction error at timestep 132 is 0.012
Current timestep = 133. State = [[-0.26999623  0.02184158]]. Action = [[ 0.01759513 -0.06927857  0.01507185  0.3322369 ]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 133 is [True, False, False, False, True, False]
State prediction error at timestep 133 is 0.012
Current timestep = 134. State = [[-0.26811033  0.01705644]]. Action = [[ 0.08368777 -0.08932294 -0.02894814 -0.1830532 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 134 is [True, False, False, False, True, False]
State prediction error at timestep 134 is 0.012
Current timestep = 135. State = [[-0.2655604   0.01263372]]. Action = [[-0.04159392  0.02638268 -0.0351847  -0.263579  ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 135 is [True, False, False, False, True, False]
State prediction error at timestep 135 is 0.012
Current timestep = 136. State = [[-0.26497445  0.01170068]]. Action = [[ 0.04214465 -0.01857676  0.0467592  -0.5455249 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 136 is [True, False, False, False, True, False]
State prediction error at timestep 136 is 0.012
Current timestep = 137. State = [[-0.26303414  0.01148038]]. Action = [[ 0.04537598  0.04021681 -0.09451013 -0.8251441 ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 137 is [True, False, False, False, True, False]
State prediction error at timestep 137 is 0.012
Current timestep = 138. State = [[-0.2605386   0.01142653]]. Action = [[-0.00896082 -0.08648797  0.0059223  -0.6011182 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 138 is [True, False, False, False, True, False]
State prediction error at timestep 138 is 0.012
Current timestep = 139. State = [[-0.2600113   0.00714855]]. Action = [[ 0.00144257 -0.09740138 -0.08489161  0.4732709 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 139 is [True, False, False, False, True, False]
State prediction error at timestep 139 is 0.012
Current timestep = 140. State = [[-0.25898173  0.00327141]]. Action = [[ 0.0879296   0.06759537 -0.04926252  0.75975275]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 140 is [True, False, False, False, True, False]
State prediction error at timestep 140 is 0.012
Current timestep = 141. State = [[-0.2549153   0.00538068]]. Action = [[ 0.04135331  0.09023546 -0.01241406 -0.06988275]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 141 is [True, False, False, False, True, False]
State prediction error at timestep 141 is 0.012
Current timestep = 142. State = [[-0.2521686   0.01038653]]. Action = [[-0.02416668  0.06962629  0.05774819  0.17399645]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 142 is [True, False, False, False, True, False]
State prediction error at timestep 142 is 0.012
Current timestep = 143. State = [[-0.2514578   0.01599238]]. Action = [[ 0.04110511  0.09079217 -0.08798521 -0.52428895]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 143 is [True, False, False, False, True, False]
State prediction error at timestep 143 is 0.012
Current timestep = 144. State = [[-0.24880537  0.02090438]]. Action = [[ 0.06174278 -0.00877477 -0.0686432  -0.70893675]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 144 is [True, False, False, False, True, False]
State prediction error at timestep 144 is 0.012
Current timestep = 145. State = [[-0.24454331  0.02200477]]. Action = [[ 0.08646726 -0.02543203 -0.01597602  0.4767716 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 145 is [True, False, False, False, True, False]
State prediction error at timestep 145 is 0.012
Current timestep = 146. State = [[-0.24006532  0.02081754]]. Action = [[ 0.00307836 -0.03747223 -0.05400804  0.24625003]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 146 is [True, False, False, False, True, False]
State prediction error at timestep 146 is 0.012
Current timestep = 147. State = [[-0.23953672  0.01935835]]. Action = [[-0.07419313  0.01984207  0.0421484  -0.9420088 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 147 is [True, False, False, False, True, False]
State prediction error at timestep 147 is 0.012
Current timestep = 148. State = [[-0.24218269  0.01968903]]. Action = [[-0.02395105  0.01243401 -0.06443793 -0.21106172]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 148 is [True, False, False, False, True, False]
State prediction error at timestep 148 is 0.012
Current timestep = 149. State = [[-0.24454594  0.02140694]]. Action = [[-0.01996619  0.07638253  0.06264653 -0.31137848]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 149 is [True, False, False, False, True, False]
State prediction error at timestep 149 is 0.012
Current timestep = 150. State = [[-0.24556841  0.02389423]]. Action = [[ 0.00639953 -0.04726395 -0.02848524 -0.23423773]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 150 is [True, False, False, False, True, False]
State prediction error at timestep 150 is 0.012
Current timestep = 151. State = [[-0.24667086  0.02442623]]. Action = [[-0.03535977  0.077981    0.01392361 -0.5698542 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 151 is [True, False, False, False, True, False]
State prediction error at timestep 151 is 0.012
Current timestep = 152. State = [[-0.24905328  0.02646672]]. Action = [[-0.08546834 -0.04167936  0.08332638 -0.30824268]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 152 is [True, False, False, False, True, False]
State prediction error at timestep 152 is 0.012
Current timestep = 153. State = [[-0.25316063  0.02507431]]. Action = [[-0.01909339 -0.05993737 -0.02686805 -0.49667573]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 153 is [True, False, False, False, True, False]
State prediction error at timestep 153 is 0.012
Current timestep = 154. State = [[-0.25564197  0.02107659]]. Action = [[-0.01765736 -0.09105944  0.08477192  0.677847  ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 154 is [True, False, False, False, True, False]
State prediction error at timestep 154 is 0.012
Current timestep = 155. State = [[-0.2582076   0.01609514]]. Action = [[-0.06454287 -0.02857007 -0.08038177 -0.58711743]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 155 is [True, False, False, False, True, False]
State prediction error at timestep 155 is 0.012
Current timestep = 156. State = [[-0.25960886  0.01237299]]. Action = [[ 0.09631538 -0.06606284  0.08758994  0.2608112 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 156 is [True, False, False, False, True, False]
State prediction error at timestep 156 is 0.012
Current timestep = 157. State = [[-0.25789428  0.00776133]]. Action = [[-0.05680401 -0.06990388 -0.05040084  0.16281736]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 157 is [True, False, False, False, True, False]
State prediction error at timestep 157 is 0.012
Current timestep = 158. State = [[-0.25917804  0.00265546]]. Action = [[-0.01908929 -0.07745232  0.073628   -0.32034814]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 158 is [True, False, False, False, True, False]
State prediction error at timestep 158 is 0.012
Current timestep = 159. State = [[-0.25926903 -0.00282881]]. Action = [[ 0.08050441 -0.07333989 -0.03609399  0.94406533]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 159 is [True, False, False, False, True, False]
State prediction error at timestep 159 is 0.012
Current timestep = 160. State = [[-0.2564373 -0.0074006]]. Action = [[ 0.02443065 -0.00784156  0.02658243 -0.8740796 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 160 is [True, False, False, False, True, False]
State prediction error at timestep 160 is 0.012
Current timestep = 161. State = [[-0.25324127 -0.00873586]]. Action = [[0.07942613 0.03452214 0.06676128 0.36968005]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 161 is [True, False, False, False, True, False]
State prediction error at timestep 161 is 0.012
Current timestep = 162. State = [[-0.24943611 -0.00813573]]. Action = [[-0.00881167 -0.00804116  0.04567108 -0.33206046]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 162 is [True, False, False, False, True, False]
State prediction error at timestep 162 is 0.012
Current timestep = 163. State = [[-0.24898154 -0.00717863]]. Action = [[-0.03323823  0.05922397 -0.0702532   0.6142738 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 163 is [True, False, False, False, True, False]
State prediction error at timestep 163 is 0.012
Current timestep = 164. State = [[-0.24939348 -0.00429876]]. Action = [[ 0.03466316  0.0387822  -0.08805623 -0.14046508]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 164 is [True, False, False, False, True, False]
State prediction error at timestep 164 is 0.012
Current timestep = 165. State = [[-0.2470723  -0.00099004]]. Action = [[ 0.09909924  0.05962933 -0.06600879 -0.28255308]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 165 is [True, False, False, False, True, False]
State prediction error at timestep 165 is 0.012
Current timestep = 166. State = [[-0.24221385  0.00237029]]. Action = [[ 0.03544044  0.01555784  0.01475412 -0.71008694]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 166 is [True, False, False, False, True, False]
State prediction error at timestep 166 is 0.012
Current timestep = 167. State = [[-0.2382123   0.00387151]]. Action = [[ 0.06100287 -0.01755409 -0.08310144 -0.9477239 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 167 is [True, False, False, False, True, False]
State prediction error at timestep 167 is 0.012
Current timestep = 168. State = [[-0.23424715  0.00480192]]. Action = [[ 0.05557228  0.06844025 -0.06573057  0.3619163 ]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 168 is [True, False, False, False, True, False]
State prediction error at timestep 168 is 0.012
Current timestep = 169. State = [[-0.22916523  0.00589455]]. Action = [[ 0.08749374 -0.09507672  0.05334998 -0.6846394 ]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 169 is [True, False, False, False, True, False]
State prediction error at timestep 169 is 0.012
Current timestep = 170. State = [[-0.22499841  0.00424404]]. Action = [[ 0.00155808  0.0683658  -0.0212245  -0.57995296]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 170 is [True, False, False, False, True, False]
State prediction error at timestep 170 is 0.012
Current timestep = 171. State = [[-0.22236276  0.00607191]]. Action = [[ 0.04960083  0.02149124  0.04392467 -0.50004685]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 171 is [True, False, False, False, True, False]
State prediction error at timestep 171 is 0.012
Current timestep = 172. State = [[-0.22067976  0.00849445]]. Action = [[-0.04574952  0.06167934 -0.00382785 -0.32204366]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 172 is [True, False, False, False, True, False]
State prediction error at timestep 172 is 0.012
Current timestep = 173. State = [[-0.22178885  0.00995791]]. Action = [[-0.0430637  -0.09628773  0.04409655  0.6125511 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 173 is [True, False, False, False, True, False]
State prediction error at timestep 173 is 0.012
Current timestep = 174. State = [[-0.2252905  0.007594 ]]. Action = [[-0.07040967  0.01563574  0.09173442  0.65946627]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 174 is [True, False, False, False, True, False]
State prediction error at timestep 174 is 0.012
Current timestep = 175. State = [[-0.22889681  0.00762061]]. Action = [[-0.00135913  0.03624814  0.07527515 -0.50893474]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 175 is [True, False, False, False, True, False]
State prediction error at timestep 175 is 0.012
Current timestep = 176. State = [[-0.22905168  0.00871422]]. Action = [[ 0.07167061 -0.01313334  0.09221774 -0.30285203]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 176 is [True, False, False, False, True, False]
State prediction error at timestep 176 is 0.012
Current timestep = 177. State = [[-0.2268793   0.00979002]]. Action = [[ 0.00078374  0.07220586 -0.00734807 -0.06658101]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 177 is [True, False, False, False, True, False]
State prediction error at timestep 177 is 0.012
Current timestep = 178. State = [[-0.22528565  0.01352702]]. Action = [[ 0.0339006   0.06569939  0.02012752 -0.03266454]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 178 is [True, False, False, False, True, False]
State prediction error at timestep 178 is 0.012
Current timestep = 179. State = [[-0.22281516  0.01584387]]. Action = [[ 0.0317174  -0.08609602  0.02552479 -0.6378873 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 179 is [True, False, False, False, True, False]
State prediction error at timestep 179 is 0.012
Current timestep = 180. State = [[-0.22149102  0.01313988]]. Action = [[-0.02266153 -0.04613214 -0.05246865  0.69155   ]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 180 is [True, False, False, False, True, False]
State prediction error at timestep 180 is 0.012
Current timestep = 181. State = [[-0.22269599  0.01097857]]. Action = [[-0.05102316  0.03555208  0.05710242  0.8183851 ]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 181 is [True, False, False, False, True, False]
State prediction error at timestep 181 is 0.012
Current timestep = 182. State = [[-0.22386785  0.01005174]]. Action = [[ 0.04255792 -0.08809259  0.07322729 -0.8239961 ]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 182 is [True, False, False, False, True, False]
State prediction error at timestep 182 is 0.012
Current timestep = 183. State = [[-0.22456142  0.00818255]]. Action = [[-0.07077293  0.08616778  0.07944613 -0.18445301]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 183 is [True, False, False, False, True, False]
State prediction error at timestep 183 is 0.012
Current timestep = 184. State = [[-0.22629125  0.01064494]]. Action = [[0.02589329 0.02521404 0.04560284 0.8529171 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 184 is [True, False, False, False, True, False]
State prediction error at timestep 184 is 0.012
Current timestep = 185. State = [[-0.2252416  0.0128369]]. Action = [[ 0.06569769  0.01783788 -0.08351611 -0.38379776]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 185 is [True, False, False, False, True, False]
State prediction error at timestep 185 is 0.012
Current timestep = 186. State = [[-0.2232609   0.01312971]]. Action = [[-0.05819391 -0.06710884  0.01129653 -0.94576174]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 186 is [True, False, False, False, True, False]
State prediction error at timestep 186 is 0.012
Current timestep = 187. State = [[-0.22377288  0.01247932]]. Action = [[0.07454874 0.09273987 0.05538996 0.47669947]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 187 is [True, False, False, False, True, False]
State prediction error at timestep 187 is 0.012
Current timestep = 188. State = [[-0.22045986  0.01517293]]. Action = [[ 0.05260085  0.0025412   0.00820528 -0.57161003]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 188 is [True, False, False, False, True, False]
State prediction error at timestep 188 is 0.012
Current timestep = 189. State = [[-0.21635617  0.01787189]]. Action = [[0.0878674  0.09567057 0.06605928 0.1119225 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 189 is [True, False, False, False, True, False]
State prediction error at timestep 189 is 0.012
Current timestep = 190. State = [[-0.21221165  0.02060907]]. Action = [[-0.05437192 -0.08486065 -0.0335448   0.78376555]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 190 is [True, False, False, False, True, False]
State prediction error at timestep 190 is 0.012
Current timestep = 191. State = [[-0.21295653  0.01880005]]. Action = [[-0.00622382 -0.00950444  0.02845653 -0.7951282 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 191 is [True, False, False, False, True, False]
State prediction error at timestep 191 is 0.012
Current timestep = 192. State = [[-0.21256433  0.01822344]]. Action = [[0.07846951 0.03925348 0.06481846 0.23868382]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 192 is [True, False, False, False, True, False]
State prediction error at timestep 192 is 0.012
Current timestep = 193. State = [[-0.20814894  0.01783244]]. Action = [[ 0.08475376 -0.09730351  0.07400119 -0.85029477]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 193 is [True, False, False, False, True, False]
State prediction error at timestep 193 is 0.012
Current timestep = 194. State = [[-0.20384146  0.01599403]]. Action = [[ 0.02459947  0.09512203 -0.03304484 -0.0240348 ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 194 is [True, False, False, False, True, False]
State prediction error at timestep 194 is 0.012
Current timestep = 195. State = [[-0.20119286  0.01726295]]. Action = [[-0.02676065 -0.06845657  0.04891325  0.64145064]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 195 is [True, False, False, False, True, False]
State prediction error at timestep 195 is 0.012
Current timestep = 196. State = [[-0.20169847  0.01474198]]. Action = [[-0.01997313 -0.0633789   0.09127475 -0.46609902]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 196 is [True, False, False, False, True, False]
State prediction error at timestep 196 is 0.012
Current timestep = 197. State = [[-0.2035188   0.01307786]]. Action = [[-0.02913294  0.09803899  0.099008   -0.04217392]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 197 is [True, False, False, False, True, False]
State prediction error at timestep 197 is 0.012
Current timestep = 198. State = [[-0.2048398   0.01598108]]. Action = [[-0.00518145  0.02210631 -0.09389158 -0.13174242]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 198 is [True, False, False, False, True, False]
State prediction error at timestep 198 is 0.012
Current timestep = 199. State = [[-0.20538306  0.01846526]]. Action = [[0.01377072 0.03175464 0.08283656 0.46658075]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 199 is [True, False, False, False, True, False]
State prediction error at timestep 199 is 0.012
Current timestep = 200. State = [[-0.20357537  0.01942258]]. Action = [[ 0.08866837 -0.06372884 -0.04892212  0.8047106 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 200 is [True, False, False, False, True, False]
State prediction error at timestep 200 is 0.012
Current timestep = 201. State = [[-0.20175776  0.01828516]]. Action = [[-0.09963728  0.04562307 -0.0738671  -0.7303585 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 201 is [True, False, False, False, True, False]
State prediction error at timestep 201 is 0.012
Current timestep = 202. State = [[-0.20403984  0.02043558]]. Action = [[ 0.01372969  0.07401478  0.02453931 -0.37497103]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 202 is [True, False, False, False, True, False]
State prediction error at timestep 202 is 0.012
Current timestep = 203. State = [[-0.20404173  0.02418232]]. Action = [[0.03079679 0.02936555 0.08133461 0.88116693]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 203 is [True, False, False, False, True, False]
State prediction error at timestep 203 is 0.012
Current timestep = 204. State = [[-0.20432432  0.02664846]]. Action = [[-0.09553662  0.0074361   0.07375055  0.56615937]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 204 is [True, False, False, False, True, False]
State prediction error at timestep 204 is 0.012
Current timestep = 205. State = [[-0.20639403  0.0276432 ]]. Action = [[ 0.07862469 -0.01221822  0.05229449 -0.00350201]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 205 is [True, False, False, False, True, False]
State prediction error at timestep 205 is 0.012
Current timestep = 206. State = [[-0.20510809  0.02704408]]. Action = [[-0.02758104 -0.02839027 -0.05051571  0.43885493]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 206 is [True, False, False, False, True, False]
State prediction error at timestep 206 is 0.012
Current timestep = 207. State = [[-0.20630135  0.02513611]]. Action = [[-0.06656671 -0.04742297 -0.0952935   0.9427171 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 207 is [True, False, False, False, True, False]
State prediction error at timestep 207 is 0.012
Current timestep = 208. State = [[-0.20769651  0.02209075]]. Action = [[ 0.09372016 -0.05449561 -0.08689364  0.99166226]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 208 is [True, False, False, False, True, False]
State prediction error at timestep 208 is 0.012
