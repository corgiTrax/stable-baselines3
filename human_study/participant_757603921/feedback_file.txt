Current timestep = 0. State = [[-0.32604954 -0.08628346]]. Action = [[0.00435984 0.09830839 0.         0.7271644 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [True, False, False, False, True, False]
State prediction error at timestep 0 is tensor(0.0668, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 0 of 0
Current timestep = 1. State = [[-0.33171427 -0.08338372]]. Action = [[-0.08950704 -0.00990598  0.          0.9261991 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False]
State prediction error at timestep 1 is tensor(0.0582, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1 of -1
Current timestep = 2. State = [[-0.33283383 -0.08530016]]. Action = [[ 0.05919486 -0.05022838  0.          0.01757967]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, True, False]
State prediction error at timestep 2 is tensor(0.0498, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2 of -1
Current timestep = 3. State = [[-0.32827213 -0.08361222]]. Action = [[ 0.07941776  0.04839816  0.         -0.50814736]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, True, False]
State prediction error at timestep 3 is tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 3 of -1
Current timestep = 4. State = [[-0.32541126 -0.08398188]]. Action = [[ 0.02240409 -0.05186519  0.          0.06079757]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, True, False]
State prediction error at timestep 4 is tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 4 of 1
Current timestep = 5. State = [[-0.3279662  -0.08312573]]. Action = [[-0.06502679  0.04306696  0.         -0.71754336]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, True, False]
State prediction error at timestep 5 is tensor(0.0098, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 5 of 1
Current timestep = 6. State = [[-0.33477807 -0.08681148]]. Action = [[-0.09400448 -0.09524496  0.         -0.55266786]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, True, False]
State prediction error at timestep 6 is tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 6 of -1
Current timestep = 7. State = [[-0.34229863 -0.08950663]]. Action = [[-0.0857187   0.01574723  0.          0.7504574 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, True, False]
State prediction error at timestep 7 is tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 7 of -1
Current timestep = 8. State = [[-0.34299374 -0.09305683]]. Action = [[ 0.06539709 -0.06977711  0.          0.35996807]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, True, False]
State prediction error at timestep 8 is tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 8 of -1
Current timestep = 9. State = [[-0.33896425 -0.09809548]]. Action = [[ 0.05116279 -0.04866131  0.          0.96614456]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, True, False]
State prediction error at timestep 9 is tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 9 of -1
Current timestep = 10. State = [[-0.34125715 -0.09591389]]. Action = [[-0.09368991  0.09748255  0.          0.9563663 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, True, False]
State prediction error at timestep 10 is tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 10 of 1
Current timestep = 11. State = [[-0.34793916 -0.08930111]]. Action = [[-0.06638829  0.08794015  0.         -0.7741786 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, True, False]
State prediction error at timestep 11 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 11 of -1
Current timestep = 12. State = [[-0.3524624  -0.09053832]]. Action = [[-0.02063052 -0.07996082  0.         -0.95365757]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, True, False]
State prediction error at timestep 12 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 12 of -1
Current timestep = 13. State = [[-0.3514295  -0.09692329]]. Action = [[ 0.06858302 -0.08356242  0.          0.7996118 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, True, False]
State prediction error at timestep 13 is tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 13 of -1
Current timestep = 14. State = [[-0.34905943 -0.10315949]]. Action = [[ 0.03609545 -0.07319944  0.          0.99147654]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, True, False]
State prediction error at timestep 14 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 14 of -1
Current timestep = 15. State = [[-0.34915546 -0.10751182]]. Action = [[-0.00918569 -0.03283177  0.         -0.2122258 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, True, False]
State prediction error at timestep 15 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 15 of -1
Current timestep = 16. State = [[-0.3515942  -0.11427713]]. Action = [[-0.03364155 -0.09511052  0.         -0.46554613]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, True, False]
State prediction error at timestep 16 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 16 of -1
Current timestep = 17. State = [[-0.35040814 -0.1148967 ]]. Action = [[ 0.06322096  0.07910722  0.         -0.04464006]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, True, False]
State prediction error at timestep 17 is tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 17 of -1
Current timestep = 18. State = [[-0.3524692 -0.1103159]]. Action = [[-0.07435532  0.06398845  0.         -0.7987755 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, True, False]
State prediction error at timestep 18 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 18 of -1
Current timestep = 19. State = [[-0.35576046 -0.10809396]]. Action = [[-0.01469477  0.01627866  0.         -0.61246777]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, True, False]
State prediction error at timestep 19 is tensor(8.1825e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 19 of -1
Current timestep = 20. State = [[-0.35278073 -0.10612503]]. Action = [[0.08603799 0.024982   0.         0.3092873 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, True, False]
State prediction error at timestep 20 is tensor(0.0074, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 20 of -1
Current timestep = 21. State = [[-0.3550868  -0.10469898]]. Action = [[-0.09342981  0.00973568  0.          0.03301167]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, True, False]
State prediction error at timestep 21 is tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 21 of 0
Current timestep = 22. State = [[-0.35582712 -0.10855046]]. Action = [[ 0.06792136 -0.09266461  0.         -0.5378331 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [True, False, False, False, True, False]
State prediction error at timestep 22 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 22 of -1
Current timestep = 23. State = [[-0.35017213 -0.11557343]]. Action = [[ 0.08799578 -0.09001543  0.          0.2031076 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [True, False, False, False, True, False]
State prediction error at timestep 23 is tensor(0.0071, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 23 of -1
Current timestep = 24. State = [[-0.34369612 -0.12251005]]. Action = [[ 0.0728355  -0.08311383  0.         -0.6254212 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [True, False, False, False, True, False]
State prediction error at timestep 24 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 24 of 1
Current timestep = 25. State = [[-0.3377389  -0.12884787]]. Action = [[ 0.05835367 -0.06599835  0.         -0.70566994]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [True, False, False, True, False, False]
State prediction error at timestep 25 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 25 of 1
Current timestep = 26. State = [[-0.33392596 -0.13457203]]. Action = [[ 0.0173382  -0.05239539  0.         -0.49140763]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [True, False, False, True, False, False]
State prediction error at timestep 26 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 26 of 1
Current timestep = 27. State = [[-0.32837385 -0.1401542 ]]. Action = [[ 0.07420024 -0.04883717  0.         -0.835879  ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [True, False, False, True, False, False]
State prediction error at timestep 27 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 27 of 1
Current timestep = 28. State = [[-0.32824698 -0.14035934]]. Action = [[-0.07985157  0.07251924  0.          0.7132039 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [True, False, False, True, False, False]
State prediction error at timestep 28 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 28 of 1
Current timestep = 29. State = [[-0.32628474 -0.13684319]]. Action = [[ 0.07670202  0.05802803  0.         -0.19587827]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [True, False, False, True, False, False]
State prediction error at timestep 29 is tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 29 of 1
Current timestep = 30. State = [[-0.321943   -0.13335118]]. Action = [[0.03694012 0.04306033 0.         0.9131191 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [True, False, False, True, False, False]
State prediction error at timestep 30 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 30 of 1
Current timestep = 31. State = [[-0.32080027 -0.12937853]]. Action = [[-0.00812083  0.05602711  0.         -0.68334305]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [True, False, False, True, False, False]
State prediction error at timestep 31 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 31 of 1
Current timestep = 32. State = [[-0.3164619  -0.13093102]]. Action = [[ 0.0912912  -0.0716596   0.         -0.00536567]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [True, False, False, True, False, False]
State prediction error at timestep 32 is tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 32 of 1
Current timestep = 33. State = [[-0.31432784 -0.12989834]]. Action = [[-0.03129195  0.06556394  0.         -0.4254552 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [True, False, False, True, False, False]
State prediction error at timestep 33 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 33 of 1
Current timestep = 34. State = [[-0.31661296 -0.12517843]]. Action = [[-0.03610037  0.05634316  0.         -0.9828412 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [True, False, False, True, False, False]
State prediction error at timestep 34 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 34 of 1
Current timestep = 35. State = [[-0.31544557 -0.1241592 ]]. Action = [[ 0.04630192 -0.02533211  0.          0.7350012 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [True, False, False, False, True, False]
State prediction error at timestep 35 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 35 of -1
Current timestep = 36. State = [[-0.31758782 -0.12670062]]. Action = [[-0.07427216 -0.04649166  0.         -0.93597376]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [True, False, False, True, False, False]
State prediction error at timestep 36 is tensor(7.4198e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 36 of -1
Current timestep = 37. State = [[-0.3207009  -0.13258803]]. Action = [[-0.02494332 -0.08635371  0.         -0.66208404]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [True, False, False, True, False, False]
State prediction error at timestep 37 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 37 of -1
Current timestep = 38. State = [[-0.32010376 -0.13407084]]. Action = [[ 0.02402425  0.02873772  0.         -0.67687416]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [True, False, False, True, False, False]
State prediction error at timestep 38 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 38 of -1
Current timestep = 39. State = [[-0.32327986 -0.12985796]]. Action = [[-0.08623265  0.07572763  0.         -0.49613696]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [True, False, False, True, False, False]
State prediction error at timestep 39 is tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 39 of -1
Current timestep = 40. State = [[-0.3233287  -0.13113004]]. Action = [[ 0.06105245 -0.07874294  0.         -0.47346008]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [True, False, False, True, False, False]
State prediction error at timestep 40 is tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 40 of -1
Current timestep = 41. State = [[-0.31631708 -0.13499852]]. Action = [[ 0.09669667 -0.03416796  0.         -0.42110026]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [True, False, False, True, False, False]
State prediction error at timestep 41 is tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 41 of -1
Current timestep = 42. State = [[-0.3106262  -0.13120608]]. Action = [[ 0.03487469  0.09661389  0.         -0.67992127]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [True, False, False, True, False, False]
State prediction error at timestep 42 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 42 of 1
Current timestep = 43. State = [[-0.30942228 -0.12987098]]. Action = [[-0.01424475 -0.0328887   0.          0.8898337 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [True, False, False, True, False, False]
State prediction error at timestep 43 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 43 of 1
Current timestep = 44. State = [[-0.30711982 -0.12996835]]. Action = [[ 0.04209391  0.01490337  0.         -0.27658153]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [True, False, False, True, False, False]
State prediction error at timestep 44 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 44 of 1
Current timestep = 45. State = [[-0.30260995 -0.1313554 ]]. Action = [[ 0.05487359 -0.03917608  0.          0.5454341 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [True, False, False, True, False, False]
State prediction error at timestep 45 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 45 of 1
Current timestep = 46. State = [[-0.29964247 -0.12924251]]. Action = [[0.01230665 0.06245907 0.         0.6040498 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [True, False, False, True, False, False]
State prediction error at timestep 46 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 46 of 1
Current timestep = 47. State = [[-0.30011895 -0.12278006]]. Action = [[-0.0302154   0.09094513  0.         -0.19556057]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [True, False, False, False, True, False]
State prediction error at timestep 47 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 47 of 1
Current timestep = 48. State = [[-0.29711604 -0.12177137]]. Action = [[ 0.07561762 -0.04881839  0.         -0.71755445]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [True, False, False, False, True, False]
State prediction error at timestep 48 is tensor(1.8560e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 48 of 1
Current timestep = 49. State = [[-0.2907111  -0.11869177]]. Action = [[ 0.06947399  0.0730006   0.         -0.43536192]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [True, False, False, False, True, False]
State prediction error at timestep 49 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 49 of 1
Current timestep = 50. State = [[-0.28548035 -0.11166776]]. Action = [[ 0.04566217  0.07803834  0.         -0.8383709 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [True, False, False, False, True, False]
State prediction error at timestep 50 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 50 of 1
Current timestep = 51. State = [[-0.28790063 -0.10773958]]. Action = [[-0.09458137  0.01098752  0.          0.41593397]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 51 is [True, False, False, False, True, False]
State prediction error at timestep 51 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 51 of 1
Current timestep = 52. State = [[-0.29142427 -0.11081928]]. Action = [[-0.0323405  -0.08168872  0.         -0.46642274]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 52 is [True, False, False, False, True, False]
State prediction error at timestep 52 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 52 of -1
Current timestep = 53. State = [[-0.2953689 -0.1142242]]. Action = [[-0.07284938 -0.02454118  0.         -0.2861967 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 53 is [True, False, False, False, True, False]
State prediction error at timestep 53 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 53 of -1
Current timestep = 54. State = [[-0.2947751  -0.11905435]]. Action = [[ 0.04461236 -0.08114024  0.          0.00438201]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 54 is [True, False, False, False, True, False]
State prediction error at timestep 54 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 54 of -1
Current timestep = 55. State = [[-0.29524747 -0.12520516]]. Action = [[-0.05125795 -0.06837062  0.          0.32886505]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 55 is [True, False, False, True, False, False]
State prediction error at timestep 55 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 55 of 1
Current timestep = 56. State = [[-0.29649398 -0.13106449]]. Action = [[-0.01432599 -0.05640483  0.         -0.21491706]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 56 is [True, False, False, True, False, False]
State prediction error at timestep 56 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 56 of -1
Current timestep = 57. State = [[-0.2995193  -0.13100384]]. Action = [[-0.06656051  0.06167503  0.          0.8706775 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 57 is [True, False, False, True, False, False]
State prediction error at timestep 57 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 57 of -1
Current timestep = 58. State = [[-0.29773045 -0.12670211]]. Action = [[0.07269277 0.06735183 0.         0.267722  ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 58 is [True, False, False, True, False, False]
State prediction error at timestep 58 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 58 of -1
Current timestep = 59. State = [[-0.2959638 -0.1213507]]. Action = [[-0.00653411  0.06633253  0.         -0.56144327]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 59 is [True, False, False, False, True, False]
State prediction error at timestep 59 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 59 of 1
Current timestep = 60. State = [[-0.29335406 -0.11997779]]. Action = [[ 0.05776749 -0.02019768  0.          0.44404376]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 60 is [True, False, False, False, True, False]
State prediction error at timestep 60 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 60 of 1
Current timestep = 61. State = [[-0.2959398  -0.12082845]]. Action = [[-0.08621805 -0.00935709  0.         -0.5938686 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 61 is [True, False, False, False, True, False]
State prediction error at timestep 61 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 61 of 1
Current timestep = 62. State = [[-0.29735297 -0.12289931]]. Action = [[ 0.03001989 -0.03496788  0.          0.795115  ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 62 is [True, False, False, False, True, False]
State prediction error at timestep 62 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 62 of -1
Current timestep = 63. State = [[-0.29486176 -0.12307972]]. Action = [[ 0.04511111  0.01294049  0.         -0.4803747 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 63 is [True, False, False, False, True, False]
State prediction error at timestep 63 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 63 of -1
Current timestep = 64. State = [[-0.29620603 -0.12299392]]. Action = [[-0.0475939  -0.00944435  0.          0.22260606]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 64 is [True, False, False, False, True, False]
State prediction error at timestep 64 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 64 of -1
Current timestep = 65. State = [[-0.2994918  -0.12329167]]. Action = [[-0.03391805  0.00187705  0.          0.62908614]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 65 is [True, False, False, False, True, False]
State prediction error at timestep 65 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 65 of -1
Current timestep = 66. State = [[-0.30542126 -0.12573975]]. Action = [[-0.09143939 -0.04285922  0.          0.8363477 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 66 is [True, False, False, True, False, False]
State prediction error at timestep 66 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 66 of -1
Current timestep = 67. State = [[-0.3109758 -0.1322867]]. Action = [[-0.04779695 -0.09210392  0.         -0.8812647 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 67 is [True, False, False, True, False, False]
State prediction error at timestep 67 is tensor(5.7290e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 67 of -1
Current timestep = 68. State = [[-0.31079093 -0.1375739 ]]. Action = [[ 0.04651662 -0.03534218  0.          0.05093992]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 68 is [True, False, False, True, False, False]
State prediction error at timestep 68 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 68 of -1
Current timestep = 69. State = [[-0.3071805  -0.13865803]]. Action = [[ 0.05559818  0.01111595  0.         -0.00063223]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 69 is [True, False, False, True, False, False]
State prediction error at timestep 69 is tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 69 of -1
Current timestep = 70. State = [[-0.3016042  -0.14107613]]. Action = [[ 0.08470782 -0.04990938  0.         -0.6769558 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 70 is [True, False, False, True, False, False]
State prediction error at timestep 70 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 70 of -1
Current timestep = 71. State = [[-0.3027248  -0.14478077]]. Action = [[-0.07705496 -0.03030247  0.          0.5788373 ]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 71 is [True, False, False, True, False, False]
State prediction error at timestep 71 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 71 of -1
Current timestep = 72. State = [[-0.30804276 -0.14773777]]. Action = [[-0.05333959 -0.01818273  0.         -0.58698285]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 72 is [True, False, False, True, False, False]
State prediction error at timestep 72 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 72 of -1
Current timestep = 73. State = [[-0.30781034 -0.15025079]]. Action = [[ 0.05389104 -0.01854485  0.          0.84114015]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 73 is [True, False, False, True, False, False]
State prediction error at timestep 73 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 73 of -1
Current timestep = 74. State = [[-0.30754927 -0.15587126]]. Action = [[-0.01340523 -0.08533397  0.          0.6781907 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 74 is [True, False, False, True, False, False]
State prediction error at timestep 74 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 74 of -1
Current timestep = 75. State = [[-0.30464518 -0.16049537]]. Action = [[ 0.07226212 -0.02264948  0.          0.14517605]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 75 is [True, False, False, True, False, False]
State prediction error at timestep 75 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 75 of -1
Current timestep = 76. State = [[-0.29860172 -0.16370107]]. Action = [[ 0.0811568  -0.03358645  0.          0.21487403]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 76 is [True, False, False, True, False, False]
State prediction error at timestep 76 is tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 76 of -1
Current timestep = 77. State = [[-0.2984852  -0.16703811]]. Action = [[-0.05150951 -0.02595834  0.          0.7335987 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 77 is [True, False, False, True, False, False]
State prediction error at timestep 77 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 77 of 1
Current timestep = 78. State = [[-0.2958332 -0.1647519]]. Action = [[ 0.08312302  0.08781122  0.         -0.8827482 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 78 is [True, False, False, True, False, False]
State prediction error at timestep 78 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 78 of 1
Current timestep = 79. State = [[-0.29402328 -0.1621253 ]]. Action = [[-0.0095064   0.01290375  0.          0.48347354]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 79 is [True, False, False, True, False, False]
State prediction error at timestep 79 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 79 of 1
Current timestep = 80. State = [[-0.29020804 -0.16485168]]. Action = [[ 0.08309726 -0.05914317  0.         -0.6986313 ]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 80 is [True, False, False, True, False, False]
State prediction error at timestep 80 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 80 of 1
Current timestep = 81. State = [[-0.29119378 -0.16308434]]. Action = [[-0.08528312  0.09084871  0.         -0.3434205 ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 81 is [True, False, False, True, False, False]
State prediction error at timestep 81 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 81 of 1
Current timestep = 82. State = [[-0.29232132 -0.15814638]]. Action = [[ 0.03919614  0.0464598   0.         -0.330307  ]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 82 is [True, False, False, True, False, False]
State prediction error at timestep 82 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 82 of 1
Current timestep = 83. State = [[-0.28916457 -0.15775312]]. Action = [[ 0.05920661 -0.03986378  0.          0.7037437 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 83 is [True, False, False, True, False, False]
State prediction error at timestep 83 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 83 of 1
Current timestep = 84. State = [[-0.28963542 -0.1537096 ]]. Action = [[-0.03906494  0.09009006  0.          0.4130168 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 84 is [True, False, False, True, False, False]
State prediction error at timestep 84 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 84 of 1
Current timestep = 85. State = [[-0.2962679  -0.15128219]]. Action = [[-0.09347825 -0.01775004  0.         -0.20194417]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 85 is [True, False, False, True, False, False]
State prediction error at timestep 85 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 85 of 1
Current timestep = 86. State = [[-0.30251017 -0.14840657]]. Action = [[-0.04820837  0.05471358  0.         -0.0404582 ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 86 is [True, False, False, True, False, False]
State prediction error at timestep 86 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 86 of 1
Current timestep = 87. State = [[-0.30873665 -0.14448665]]. Action = [[-0.07200931  0.03333617  0.         -0.8988223 ]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 87 is [True, False, False, True, False, False]
State prediction error at timestep 87 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 87 of 1
Current timestep = 88. State = [[-0.3101942  -0.13910116]]. Action = [[0.03767733 0.06642061 0.         0.15204561]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 88 is [True, False, False, True, False, False]
State prediction error at timestep 88 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 88 of -1
Current timestep = 89. State = [[-0.3085141 -0.1310077]]. Action = [[0.03719044 0.08723495 0.         0.8470986 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 89 is [True, False, False, True, False, False]
State prediction error at timestep 89 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 89 of -1
Current timestep = 90. State = [[-0.30667928 -0.12688777]]. Action = [[ 0.03684954 -0.01303044  0.         -0.3289926 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 90 is [True, False, False, True, False, False]
State prediction error at timestep 90 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 90 of -1
Current timestep = 91. State = [[-0.30771106 -0.13016786]]. Action = [[-0.02264889 -0.09803431  0.          0.80704355]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 91 is [True, False, False, True, False, False]
State prediction error at timestep 91 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 91 of -1
Current timestep = 92. State = [[-0.31145984 -0.13492118]]. Action = [[-0.04844204 -0.05584633  0.          0.11055601]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 92 is [True, False, False, True, False, False]
State prediction error at timestep 92 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 92 of -1
Current timestep = 93. State = [[-0.31125012 -0.13218999]]. Action = [[ 0.04525537  0.08507469  0.         -0.82210153]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 93 is [True, False, False, True, False, False]
State prediction error at timestep 93 is tensor(8.0360e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 93 of -1
Current timestep = 94. State = [[-0.31156763 -0.13084571]]. Action = [[-0.02491487 -0.03422561  0.         -0.63495207]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 94 is [True, False, False, True, False, False]
State prediction error at timestep 94 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 94 of -1
Current timestep = 95. State = [[-0.31193754 -0.12713897]]. Action = [[ 0.01080821  0.08319134  0.         -0.91200155]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 95 is [True, False, False, True, False, False]
State prediction error at timestep 95 is tensor(5.7264e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 95 of -1
Current timestep = 96. State = [[-0.3130952  -0.12664531]]. Action = [[-0.02343336 -0.04828848  0.         -0.6298077 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 96 is [True, False, False, True, False, False]
State prediction error at timestep 96 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 96 of -1
Current timestep = 97. State = [[-0.3103899  -0.12735245]]. Action = [[ 0.07194784  0.00362638  0.         -0.0682469 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 97 is [True, False, False, True, False, False]
State prediction error at timestep 97 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 97 of 1
Current timestep = 98. State = [[-0.30815062 -0.12516585]]. Action = [[ 0.00492929  0.03182653  0.         -0.6283403 ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 98 is [True, False, False, True, False, False]
State prediction error at timestep 98 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 98 of 1
Current timestep = 99. State = [[-0.30719927 -0.11941685]]. Action = [[0.01584797 0.08620501 0.         0.14303756]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 99 is [True, False, False, False, True, False]
State prediction error at timestep 99 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 99 of 1
Current timestep = 100. State = [[-0.30384535 -0.11331061]]. Action = [[ 0.06324964  0.0521422   0.         -0.6068828 ]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 100 is [True, False, False, False, True, False]
State prediction error at timestep 100 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 100 of 1
Current timestep = 101. State = [[-0.29784504 -0.10577376]]. Action = [[ 0.09075237  0.08784056  0.         -0.89793307]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 101 is [True, False, False, False, True, False]
State prediction error at timestep 101 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 101 of 1
Current timestep = 102. State = [[-0.2960276  -0.09873932]]. Action = [[-0.00963788  0.05368953  0.         -0.5304385 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 102 is [True, False, False, False, True, False]
State prediction error at timestep 102 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 102 of 1
Current timestep = 103. State = [[-0.29357332 -0.09863793]]. Action = [[ 0.0599331  -0.06442684  0.          0.4590013 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 103 is [True, False, False, False, True, False]
State prediction error at timestep 103 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 103 of 1
Current timestep = 104. State = [[-0.28861868 -0.09723202]]. Action = [[ 0.06378921  0.03508189  0.         -0.3127653 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 104 is [True, False, False, False, True, False]
State prediction error at timestep 104 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 104 of 1
Current timestep = 105. State = [[-0.28286713 -0.09815231]]. Action = [[ 0.06867541 -0.06425261  0.         -0.25303042]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 105 is [True, False, False, False, True, False]
State prediction error at timestep 105 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 105 of 1
Current timestep = 106. State = [[-0.27901155 -0.09408323]]. Action = [[ 0.01808982  0.0984797   0.         -0.13837785]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 106 is [True, False, False, False, True, False]
State prediction error at timestep 106 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 106 of 1
Current timestep = 107. State = [[-0.27495492 -0.09076089]]. Action = [[ 0.05512988 -0.00931183  0.          0.5495707 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 107 is [True, False, False, False, True, False]
State prediction error at timestep 107 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 107 of 1
Current timestep = 108. State = [[-0.26891235 -0.08859302]]. Action = [[0.07084704 0.02535234 0.         0.5779476 ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 108 is [True, False, False, False, True, False]
State prediction error at timestep 108 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 108 of 1
Current timestep = 109. State = [[-0.26679406 -0.08504084]]. Action = [[-0.02255969  0.03834336  0.          0.51452816]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 109 is [True, False, False, False, True, False]
State prediction error at timestep 109 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 109 of 1
Current timestep = 110. State = [[-0.2674451 -0.0785948]]. Action = [[-0.02598997  0.09033609  0.          0.4872887 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 110 is [True, False, False, False, True, False]
State prediction error at timestep 110 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 110 of 1
Current timestep = 111. State = [[-0.26893333 -0.07079858]]. Action = [[-0.0328203   0.08112409  0.          0.12228632]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 111 is [True, False, False, False, True, False]
State prediction error at timestep 111 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 111 of 1
Current timestep = 112. State = [[-0.26897514 -0.0711905 ]]. Action = [[ 0.00193633 -0.08566135  0.         -0.8266593 ]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 112 is [True, False, False, False, True, False]
State prediction error at timestep 112 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 112 of -1
Current timestep = 113. State = [[-0.26417553 -0.07607307]]. Action = [[ 0.07584275 -0.07316059  0.          0.7467475 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 113 is [True, False, False, False, True, False]
State prediction error at timestep 113 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 113 of 1
Current timestep = 114. State = [[-0.2639875  -0.07685893]]. Action = [[-0.07258598  0.01798733  0.         -0.16474545]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 114 is [True, False, False, False, True, False]
State prediction error at timestep 114 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 114 of 1
Current timestep = 115. State = [[-0.2626856  -0.07121593]]. Action = [[0.05169223 0.09331284 0.         0.494362  ]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 115 is [True, False, False, False, True, False]
State prediction error at timestep 115 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 115 of 1
Current timestep = 116. State = [[-0.256366   -0.07173011]]. Action = [[ 0.09708028 -0.08363806  0.          0.41211677]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 116 is [True, False, False, False, True, False]
State prediction error at timestep 116 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 116 of 1
Current timestep = 117. State = [[-0.25306663 -0.07467744]]. Action = [[-0.00508133 -0.02213638  0.          0.85394955]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 117 is [True, False, False, False, True, False]
State prediction error at timestep 117 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 117 of 1
Current timestep = 118. State = [[-0.2521276  -0.07065229]]. Action = [[ 0.0048445   0.09395594  0.         -0.66736186]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 118 is [True, False, False, False, True, False]
State prediction error at timestep 118 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 118 of -1
Current timestep = 119. State = [[-0.25429553 -0.06388917]]. Action = [[-0.05536299  0.07616051  0.         -0.2226156 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 119 is [True, False, False, False, True, False]
State prediction error at timestep 119 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 119 of -1
Current timestep = 120. State = [[-0.25361356 -0.06207884]]. Action = [[ 0.04226313 -0.02303165  0.          0.16313767]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 120 is [True, False, False, False, True, False]
State prediction error at timestep 120 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 120 of 1
Current timestep = 121. State = [[-0.24768145 -0.06580479]]. Action = [[ 0.09108762 -0.07611603  0.          0.20937157]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 121 is [True, False, False, False, True, False]
State prediction error at timestep 121 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 121 of 1
Current timestep = 122. State = [[-0.2432854 -0.0660891]]. Action = [[0.02296798 0.03336019 0.         0.6485653 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 122 is [True, False, False, False, True, False]
State prediction error at timestep 122 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 122 of 1
Current timestep = 123. State = [[-0.24547684 -0.06764878]]. Action = [[-0.07890707 -0.04992961  0.         -0.42488313]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 123 is [True, False, False, False, True, False]
State prediction error at timestep 123 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 123 of 1
Current timestep = 124. State = [[-0.24431852 -0.0649255 ]]. Action = [[0.05081276 0.0851158  0.         0.04415643]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 124 is [True, False, False, False, True, False]
State prediction error at timestep 124 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 124 of 1
Current timestep = 125. State = [[-0.23933288 -0.05862859]]. Action = [[ 0.06842866  0.07005458  0.         -0.78340095]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 125 is [True, False, False, False, True, False]
State prediction error at timestep 125 is tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 125 of 1
Current timestep = 126. State = [[-0.23402178 -0.05691854]]. Action = [[ 0.06383165 -0.02284     0.         -0.11913276]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 126 is [True, False, False, False, True, False]
State prediction error at timestep 126 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 126 of 1
Current timestep = 127. State = [[-0.2303964  -0.05282816]]. Action = [[0.02766979 0.08074283 0.         0.6504481 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 127 is [True, False, False, False, True, False]
State prediction error at timestep 127 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 127 of 1
Current timestep = 128. State = [[-0.2309656  -0.04937926]]. Action = [[-0.03693487  0.00779587  0.         -0.7680221 ]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 128 is [True, False, False, False, True, False]
State prediction error at timestep 128 is tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 128 of 1
Current timestep = 129. State = [[-0.22996718 -0.04981443]]. Action = [[ 0.02829767 -0.03170167  0.         -0.9311741 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 129 is [True, False, False, False, True, False]
State prediction error at timestep 129 is tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 129 of 1
Current timestep = 130. State = [[-0.2287457  -0.05069143]]. Action = [[-0.00630493 -0.01349183  0.          0.8970611 ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 130 is [True, False, False, False, True, False]
State prediction error at timestep 130 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 130 of 1
Current timestep = 131. State = [[-0.22596292 -0.04928607]]. Action = [[ 0.04252101  0.02527147  0.         -0.89336056]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 131 is [True, False, False, False, True, False]
State prediction error at timestep 131 is tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 131 of 1
Current timestep = 132. State = [[-0.2281417  -0.04855921]]. Action = [[-0.08844581 -0.01023941  0.          0.83049643]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 132 is [True, False, False, False, True, False]
State prediction error at timestep 132 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 132 of 1
Current timestep = 133. State = [[-0.22734988 -0.04712214]]. Action = [[ 0.05265195  0.02413195  0.         -0.47506392]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 133 is [True, False, False, False, True, False]
State prediction error at timestep 133 is tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 133 of 1
Current timestep = 134. State = [[-0.22579956 -0.04122594]]. Action = [[-0.00517105  0.09295257  0.          0.12359798]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 134 is [True, False, False, False, True, False]
State prediction error at timestep 134 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 134 of 1
Current timestep = 135. State = [[-0.22295506 -0.03386254]]. Action = [[ 0.05895848  0.07455271  0.         -0.09302485]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 135 is [True, False, False, False, True, False]
State prediction error at timestep 135 is tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 135 of 1
Current timestep = 136. State = [[-0.22247376 -0.03379122]]. Action = [[-0.02425449 -0.0673735   0.         -0.8911822 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 136 is [True, False, False, False, True, False]
State prediction error at timestep 136 is tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 136 of 1
Current timestep = 137. State = [[-0.22376597 -0.03347622]]. Action = [[-0.02174272  0.02588492  0.         -0.02167219]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 137 is [True, False, False, False, True, False]
State prediction error at timestep 137 is tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 137 of 1
Current timestep = 138. State = [[-0.22154316 -0.03479359]]. Action = [[ 0.05154159 -0.05533413  0.          0.8125888 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 138 is [True, False, False, False, True, False]
State prediction error at timestep 138 is tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 138 of 1
Current timestep = 139. State = [[-0.21533082 -0.04015803]]. Action = [[ 0.08771146 -0.08453571  0.         -0.04593003]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 139 is [True, False, False, False, True, False]
State prediction error at timestep 139 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 139 of 1
Current timestep = 140. State = [[-0.20946197 -0.04130628]]. Action = [[ 0.05226319  0.02960343  0.         -0.44906223]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 140 is [True, False, False, False, True, False]
State prediction error at timestep 140 is tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 140 of 1
Current timestep = 141. State = [[-0.21055268 -0.03649854]]. Action = [[-0.07586329  0.08657771  0.         -0.6654726 ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 141 is [True, False, False, False, True, False]
State prediction error at timestep 141 is tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 141 of 1
Current timestep = 142. State = [[-0.21204104 -0.03132943]]. Action = [[0.00252124 0.05027034 0.         0.05026305]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 142 is [True, False, False, False, True, False]
State prediction error at timestep 142 is tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 142 of 1
Current timestep = 143. State = [[-0.21352652 -0.03395812]]. Action = [[-0.03480631 -0.09210108  0.          0.6431854 ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 143 is [True, False, False, False, True, False]
State prediction error at timestep 143 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 143 of 1
Current timestep = 144. State = [[-0.20994613 -0.03269849]]. Action = [[0.08892777 0.07524056 0.         0.2503463 ]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 144 is [True, False, False, False, True, False]
State prediction error at timestep 144 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 144 of -1
Current timestep = 145. State = [[-0.21126805 -0.03290965]]. Action = [[-0.08753451 -0.05155198  0.          0.4111985 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 145 is [True, False, False, False, True, False]
State prediction error at timestep 145 is tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 145 of 1
Current timestep = 146. State = [[-0.21679607 -0.02983658]]. Action = [[-0.06985109  0.08334196  0.          0.67337203]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 146 is [True, False, False, False, True, False]
State prediction error at timestep 146 is tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 146 of 1
Current timestep = 147. State = [[-0.21586846 -0.03084756]]. Action = [[ 0.07207961 -0.07817389  0.          0.10650051]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 147 is [True, False, False, False, True, False]
State prediction error at timestep 147 is tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 147 of -1
Current timestep = 148. State = [[-0.2114461  -0.03143278]]. Action = [[ 0.05060751  0.02689125  0.         -0.7677144 ]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 148 is [True, False, False, False, True, False]
State prediction error at timestep 148 is tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 148 of -1
Current timestep = 149. State = [[-0.20715521 -0.03439018]]. Action = [[ 0.05246355 -0.07405104  0.         -0.9420371 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 149 is [True, False, False, False, True, False]
State prediction error at timestep 149 is tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 149 of 1
Current timestep = 150. State = [[-0.20067795 -0.03264584]]. Action = [[0.09456737 0.08233278 0.         0.4202695 ]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 150 is [True, False, False, False, True, False]
State prediction error at timestep 150 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 150 of 1
Current timestep = 151. State = [[-0.194895   -0.03047846]]. Action = [[ 0.0580707   0.00080253  0.         -0.58421594]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 151 is [True, False, False, False, True, False]
State prediction error at timestep 151 is tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 151 of 1
Current timestep = 152. State = [[-0.19435231 -0.03405046]]. Action = [[-0.03988459 -0.07052197  0.          0.24287748]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 152 is [True, False, False, False, True, False]
State prediction error at timestep 152 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 152 of 1
Current timestep = 153. State = [[-0.19343817 -0.0315088 ]]. Action = [[0.02129662 0.09845557 0.         0.75283575]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 153 is [True, False, False, False, True, False]
State prediction error at timestep 153 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 153 of 1
Current timestep = 154. State = [[-0.19414361 -0.02573   ]]. Action = [[-0.03655013  0.05905802  0.         -0.8628381 ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 154 is [True, False, False, False, True, False]
State prediction error at timestep 154 is tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 154 of 1
Current timestep = 155. State = [[-0.1961249  -0.02712854]]. Action = [[-0.03285317 -0.07403813  0.         -0.31346142]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 155 is [True, False, False, False, True, False]
State prediction error at timestep 155 is tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 155 of 1
Current timestep = 156. State = [[-0.1965848  -0.02600458]]. Action = [[-0.00386408  0.05630472  0.         -0.22880358]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 156 is [True, False, False, False, True, False]
State prediction error at timestep 156 is tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 156 of -1
Current timestep = 157. State = [[-0.19487792 -0.02135435]]. Action = [[0.03188857 0.05059979 0.         0.60085917]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 157 is [True, False, False, False, True, False]
State prediction error at timestep 157 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 157 of -1
Current timestep = 158. State = [[-0.19437589 -0.01769957]]. Action = [[-0.00967928  0.02617671  0.         -0.588125  ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 158 is [True, False, False, False, True, False]
State prediction error at timestep 158 is tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 158 of 1
Current timestep = 159. State = [[-0.19447374 -0.01107977]]. Action = [[ 0.00446083  0.09661204  0.         -0.47246146]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 159 is [True, False, False, False, True, False]
State prediction error at timestep 159 is tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 159 of 1
Current timestep = 160. State = [[-0.19471611 -0.00689492]]. Action = [[1.7080456e-04 2.0818263e-03 0.0000000e+00 3.1683111e-01]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 160 is [True, False, False, False, True, False]
State prediction error at timestep 160 is tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 160 of -1
Current timestep = 161. State = [[-0.1940991  -0.00281961]]. Action = [[ 0.01920576  0.05128143  0.         -0.75328815]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 161 is [True, False, False, False, True, False]
State prediction error at timestep 161 is tensor(0.0084, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 161 of -1
Current timestep = 162. State = [[-0.19170114  0.00115242]]. Action = [[0.04730812 0.0222197  0.         0.15239525]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 162 is [True, False, False, False, True, False]
State prediction error at timestep 162 is tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 162 of -1
Current timestep = 163. State = [[-0.19048285  0.00294765]]. Action = [[ 0.00289206 -0.00466044  0.          0.6553782 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 163 is [True, False, False, False, True, False]
State prediction error at timestep 163 is tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 163 of -1
Current timestep = 164. State = [[-0.19436988  0.00691432]]. Action = [[-0.08365659  0.0556621   0.         -0.12020957]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 164 is [True, False, False, False, True, False]
State prediction error at timestep 164 is tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 164 of -1
Current timestep = 165. State = [[-0.1986029   0.00828608]]. Action = [[-0.04118704 -0.03397099  0.          0.90241694]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 165 is [True, False, False, False, True, False]
State prediction error at timestep 165 is tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 165 of -1
Current timestep = 166. State = [[-0.19864711  0.00525802]]. Action = [[ 0.02168028 -0.06759585  0.          0.53380895]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 166 is [True, False, False, False, True, False]
State prediction error at timestep 166 is tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 166 of -1
Current timestep = 167. State = [[-0.19991526  0.00766845]]. Action = [[-0.04046901  0.07271495  0.          0.43431664]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 167 is [True, False, False, False, True, False]
State prediction error at timestep 167 is tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 167 of -1
Current timestep = 168. State = [[-0.19646017  0.00594696]]. Action = [[ 0.09719022 -0.08895537  0.          0.57576025]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 168 is [True, False, False, False, True, False]
State prediction error at timestep 168 is tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 168 of -1
Current timestep = 169. State = [[-0.1889359   0.00320512]]. Action = [[ 0.09555476 -0.0066031   0.         -0.930956  ]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 169 is [True, False, False, False, True, False]
State prediction error at timestep 169 is tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 169 of 1
Current timestep = 170. State = [[-0.18181492 -0.00144749]]. Action = [[ 0.07673233 -0.07869744  0.         -0.7685187 ]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 170 is [True, False, False, False, True, False]
State prediction error at timestep 170 is tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 170 of 1
Current timestep = 171. State = [[-0.18240005 -0.00137286]]. Action = [[-0.08804949  0.06179111  0.         -0.89281017]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 171 is [True, False, False, False, True, False]
State prediction error at timestep 171 is tensor(0.0086, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 171 of 1
Current timestep = 172. State = [[-0.18039007 -0.00285578]]. Action = [[ 0.08123485 -0.05144779  0.          0.9139402 ]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 172 is [True, False, False, False, True, False]
State prediction error at timestep 172 is tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 172 of 1
Current timestep = 173. State = [[-0.17886774 -0.00785051]]. Action = [[-0.0323775  -0.05541135  0.          0.8952229 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 173 is [True, False, False, False, True, False]
State prediction error at timestep 173 is tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 173 of 1
Current timestep = 174. State = [[-0.1788441  -0.01327886]]. Action = [[-0.00756778 -0.05580664  0.         -0.904968  ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 174 is [True, False, False, False, True, False]
State prediction error at timestep 174 is tensor(0.0082, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 174 of -1
Current timestep = 175. State = [[-0.17868954 -0.011245  ]]. Action = [[-0.01202302  0.09660531  0.         -0.7786459 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 175 is [True, False, False, False, True, False]
State prediction error at timestep 175 is tensor(0.0076, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 175 of 1
Current timestep = 176. State = [[-0.1769987  -0.00850854]]. Action = [[ 0.03216473  0.0139678   0.         -0.30833042]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 176 is [True, False, False, False, True, False]
State prediction error at timestep 176 is tensor(0.0070, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 176 of 1
Current timestep = 177. State = [[-0.17443098 -0.00758082]]. Action = [[0.02912969 0.01657975 0.         0.2923298 ]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 177 is [True, False, False, False, True, False]
State prediction error at timestep 177 is tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 177 of 1
Current timestep = 178. State = [[-0.17748794 -0.00958124]]. Action = [[-0.09049254 -0.04499964  0.          0.37014747]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 178 is [True, False, False, False, True, False]
State prediction error at timestep 178 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 178 of 1
Current timestep = 179. State = [[-0.17869838 -0.01233533]]. Action = [[ 0.01767874 -0.02601907  0.          0.9538131 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 179 is [True, False, False, False, True, False]
State prediction error at timestep 179 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 179 of -1
Current timestep = 180. State = [[-0.17631173 -0.00912218]]. Action = [[ 0.04057462  0.08514365  0.         -0.79016966]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 180 is [True, False, False, False, True, False]
State prediction error at timestep 180 is tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 180 of -1
Current timestep = 181. State = [[-0.17162572 -0.00760052]]. Action = [[ 0.07994813 -0.01810307  0.         -0.8050843 ]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 181 is [True, False, False, False, True, False]
State prediction error at timestep 181 is tensor(0.0072, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 181 of -1
Current timestep = 182. State = [[-0.1689639 -0.0045527]]. Action = [[0.01356505 0.0697303  0.         0.3674909 ]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 182 is [True, False, False, False, True, False]
State prediction error at timestep 182 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 182 of 1
Current timestep = 183. State = [[-0.1719238   0.00257965]]. Action = [[-0.06525502  0.09692695  0.          0.36383045]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 183 is [True, False, False, False, True, False]
State prediction error at timestep 183 is tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 183 of 1
Current timestep = 184. State = [[-0.17831     0.00618824]]. Action = [[-0.09015813 -0.00381263  0.          0.7607399 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 184 is [True, False, False, False, True, False]
State prediction error at timestep 184 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 184 of -1
Current timestep = 185. State = [[-0.18553129  0.00322632]]. Action = [[-0.0958179  -0.08443887  0.          0.2525456 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 185 is [True, False, False, False, True, False]
State prediction error at timestep 185 is tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 185 of -1
Current timestep = 186. State = [[-0.18468727  0.00126012]]. Action = [[ 0.08509869 -0.00933363  0.         -0.11706871]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 186 is [True, False, False, False, True, False]
State prediction error at timestep 186 is tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 186 of -1
Current timestep = 187. State = [[-0.18582462  0.00457919]]. Action = [[-0.07587193  0.0616359   0.          0.2082479 ]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 187 is [True, False, False, False, True, False]
State prediction error at timestep 187 is tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 187 of -1
Current timestep = 188. State = [[-0.18790537  0.01163382]]. Action = [[0.00398537 0.0886547  0.         0.9212539 ]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 188 is [True, False, False, False, True, False]
State prediction error at timestep 188 is tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 188 of -1
Current timestep = 189. State = [[-0.19089054  0.01823821]]. Action = [[-0.04550817  0.0560961   0.          0.7754686 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 189 is [True, False, False, False, True, False]
State prediction error at timestep 189 is tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 189 of -1
Current timestep = 190. State = [[-0.19623846  0.01687727]]. Action = [[-0.07004695 -0.08967771  0.          0.72013116]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 190 is [True, False, False, False, True, False]
State prediction error at timestep 190 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 190 of -1
Current timestep = 191. State = [[-0.1966679   0.01945068]]. Action = [[ 0.04908953  0.08204625  0.         -0.6357826 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 191 is [True, False, False, False, True, False]
State prediction error at timestep 191 is tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 191 of -1
Current timestep = 192. State = [[-0.19521356  0.02483316]]. Action = [[0.02543334 0.04139624 0.         0.7523606 ]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 192 is [True, False, False, False, True, False]
State prediction error at timestep 192 is tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 192 of -1
Current timestep = 193. State = [[-0.19552618  0.03200317]]. Action = [[0.00015797 0.09527317 0.         0.15009761]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 193 is [True, False, False, False, True, False]
State prediction error at timestep 193 is tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 193 of -1
Current timestep = 194. State = [[-0.19405827  0.0343169 ]]. Action = [[ 0.05227666 -0.03409019  0.          0.80588984]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 194 is [True, False, False, False, True, False]
State prediction error at timestep 194 is tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 194 of -1
Current timestep = 195. State = [[-0.19456466  0.03713453]]. Action = [[-0.02402858  0.05268981  0.         -0.6794629 ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 195 is [True, False, False, False, True, False]
State prediction error at timestep 195 is tensor(0.0074, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 195 of -1
Current timestep = 196. State = [[-0.19304281  0.03541024]]. Action = [[ 0.05457634 -0.08470879  0.          0.7906487 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 196 is [True, False, False, False, True, False]
State prediction error at timestep 196 is tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 196 of -1
Current timestep = 197. State = [[-0.19168687  0.03328458]]. Action = [[-0.00245057 -0.00754982  0.          0.01692247]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 197 is [True, False, False, False, True, False]
State prediction error at timestep 197 is tensor(0.0075, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 197 of -1
Current timestep = 198. State = [[-0.19088767  0.03148764]]. Action = [[ 0.01095527 -0.03721435  0.          0.42870998]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 198 is [True, False, False, False, True, False]
State prediction error at timestep 198 is tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 198 of 1
Current timestep = 199. State = [[-0.19328634  0.03296509]]. Action = [[-0.06501761  0.04722264  0.         -0.8182277 ]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 199 is [True, False, False, False, True, False]
State prediction error at timestep 199 is tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 199 of 1
Current timestep = 200. State = [[-0.19145304  0.03669331]]. Action = [[0.07332624 0.04306454 0.         0.81678045]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 200 is [True, False, False, False, True, False]
State prediction error at timestep 200 is tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 200 of 1
Current timestep = 201. State = [[-0.18771978  0.04198232]]. Action = [[ 0.0352449   0.07522555  0.         -0.77157456]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 201 is [True, False, False, False, True, False]
State prediction error at timestep 201 is tensor(0.0065, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 201 of 1
Current timestep = 202. State = [[-0.18280095  0.04360179]]. Action = [[ 0.07693427 -0.01898524  0.          0.49586034]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 202 is [True, False, False, False, True, False]
State prediction error at timestep 202 is tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 202 of 1
Current timestep = 203. State = [[-0.17663735  0.04701686]]. Action = [[ 0.07554697  0.0733413   0.         -0.3434313 ]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 203 is [True, False, False, False, True, False]
State prediction error at timestep 203 is tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 203 of 1
Current timestep = 204. State = [[-0.17643163  0.05169289]]. Action = [[-0.05175463  0.0433543   0.          0.18024302]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 204 is [True, False, False, False, True, False]
State prediction error at timestep 204 is tensor(0.0070, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 204 of 1
Current timestep = 205. State = [[-0.17768109  0.05342348]]. Action = [[-0.00689612 -0.00936036  0.          0.55917025]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 205 is [True, False, False, False, True, False]
State prediction error at timestep 205 is tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 205 of 1
Current timestep = 206. State = [[-0.18185009  0.05732679]]. Action = [[-0.09060473  0.06068487  0.          0.3682568 ]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 206 is [True, False, False, False, True, False]
State prediction error at timestep 206 is tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 206 of 1
Current timestep = 207. State = [[-0.1869948   0.05875602]]. Action = [[-0.06376418 -0.03642128  0.          0.44454873]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 207 is [True, False, False, False, True, False]
State prediction error at timestep 207 is tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 207 of -1
Current timestep = 208. State = [[-0.1929423   0.06392606]]. Action = [[-0.08823213  0.09085185  0.         -0.39094877]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 208 is [True, False, False, False, True, False]
State prediction error at timestep 208 is tensor(0.0086, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 208 of -1
Current timestep = 209. State = [[-0.19349775  0.06354136]]. Action = [[ 0.04582375 -0.094453    0.          0.2966987 ]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 209 is [True, False, False, False, True, False]
State prediction error at timestep 209 is tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 209 of -1
Current timestep = 210. State = [[-0.19180627  0.06365147]]. Action = [[ 0.014509    0.03333455  0.         -0.9243385 ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 210 is [True, False, False, False, True, False]
State prediction error at timestep 210 is tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 210 of -1
Current timestep = 211. State = [[-0.18734112  0.06056955]]. Action = [[ 0.08574314 -0.09190284  0.         -0.45403588]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 211 is [True, False, False, False, True, False]
State prediction error at timestep 211 is tensor(0.0073, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 211 of -1
Current timestep = 212. State = [[-0.18470702  0.06016444]]. Action = [[0.0029633  0.04361337 0.         0.36915874]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 212 is [True, False, False, False, True, False]
State prediction error at timestep 212 is tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 212 of 1
Current timestep = 213. State = [[-0.18255614  0.06298617]]. Action = [[0.03910495 0.03370749 0.         0.4838884 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 213 is [True, False, False, False, True, False]
State prediction error at timestep 213 is tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 213 of 1
Current timestep = 214. State = [[-0.18384135  0.06238133]]. Action = [[-0.05320776 -0.0346716   0.         -0.74210274]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 214 is [True, False, False, False, True, False]
State prediction error at timestep 214 is tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 214 of 1
Current timestep = 215. State = [[-0.1818847   0.06076659]]. Action = [[ 0.06456577 -0.01356386  0.         -0.71318984]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 215 is [True, False, False, False, True, False]
State prediction error at timestep 215 is tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 215 of 1
Current timestep = 216. State = [[-0.1765432   0.05832155]]. Action = [[ 0.06609393 -0.03280894  0.         -0.00589621]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 216 is [True, False, False, False, True, False]
State prediction error at timestep 216 is tensor(0.0073, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 216 of 1
Current timestep = 217. State = [[-0.17817968  0.06041689]]. Action = [[-0.08878118  0.06966198  0.          0.8754654 ]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 217 is [True, False, False, False, True, False]
State prediction error at timestep 217 is tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 217 of 1
Current timestep = 218. State = [[-0.1823365   0.06580608]]. Action = [[-0.03950244  0.06750295  0.         -0.11969459]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 218 is [True, False, False, False, True, False]
State prediction error at timestep 218 is tensor(0.0080, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 218 of 1
Current timestep = 219. State = [[-0.17990777  0.07030046]]. Action = [[ 0.0869898   0.04343493  0.         -0.5068014 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 219 is [True, False, False, False, True, False]
State prediction error at timestep 219 is tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 219 of -1
Current timestep = 220. State = [[-0.17366569  0.06752568]]. Action = [[ 0.08682571 -0.08567899  0.         -0.7303246 ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 220 is [True, False, False, False, True, False]
State prediction error at timestep 220 is tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 220 of -1
Current timestep = 221. State = [[-0.17090896  0.06066396]]. Action = [[-0.00633837 -0.08751322  0.         -0.78397393]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 221 is [True, False, False, False, True, False]
State prediction error at timestep 221 is tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 221 of -1
Current timestep = 222. State = [[-0.16636378  0.05768238]]. Action = [[0.07594497 0.00119527 0.         0.01202857]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 222 is [True, False, False, False, True, False]
State prediction error at timestep 222 is tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 222 of -1
Current timestep = 223. State = [[-0.16307454  0.06148645]]. Action = [[ 0.00807478  0.09114093  0.         -0.9714251 ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 223 is [True, False, False, False, True, False]
State prediction error at timestep 223 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 223 of 1
Current timestep = 224. State = [[-0.15927911  0.06859486]]. Action = [[ 0.06223301  0.09758142  0.         -0.95955175]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 224 is [True, False, False, False, True, False]
State prediction error at timestep 224 is tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 224 of 1
Current timestep = 225. State = [[-0.15342274  0.06910577]]. Action = [[ 0.07572899 -0.04604251  0.         -0.7920848 ]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 225 is [True, False, False, False, True, False]
State prediction error at timestep 225 is tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 225 of 1
Current timestep = 226. State = [[-0.14952305  0.07176983]]. Action = [[ 0.01904567  0.07937475  0.         -0.35485065]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 226 is [True, False, False, False, True, False]
State prediction error at timestep 226 is tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 226 of 1
Current timestep = 227. State = [[-0.14488453  0.07900105]]. Action = [[ 0.06985094  0.09647851  0.         -0.7158635 ]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 227 is [True, False, False, False, True, False]
State prediction error at timestep 227 is tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 227 of 1
Current timestep = 228. State = [[-0.14395411  0.07910792]]. Action = [[-0.04081057 -0.06927603  0.         -0.8156085 ]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 228 is [True, False, False, False, True, False]
State prediction error at timestep 228 is tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 228 of 1
Current timestep = 229. State = [[-0.13970461  0.07768551]]. Action = [[ 0.08945058 -0.00597648  0.         -0.27850914]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 229 is [True, False, False, False, True, False]
State prediction error at timestep 229 is tensor(0.0062, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 229 of 1
Current timestep = 230. State = [[-0.1376815   0.07516985]]. Action = [[-0.04086249 -0.05759763  0.          0.88833666]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 230 is [True, False, False, False, True, False]
State prediction error at timestep 230 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 230 of 1
Current timestep = 231. State = [[-0.13865303  0.07730635]]. Action = [[-0.03124569  0.06278478  0.          0.2243985 ]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 231 is [True, False, False, False, True, False]
State prediction error at timestep 231 is tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 231 of 1
Current timestep = 232. State = [[-0.13750094  0.07633838]]. Action = [[ 0.01617537 -0.07004587  0.         -0.3424722 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 232 is [True, False, False, False, True, False]
State prediction error at timestep 232 is tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 232 of 1
Current timestep = 233. State = [[-0.13843875  0.07117724]]. Action = [[-0.05970374 -0.07662632  0.         -0.18139285]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 233 is [True, False, False, False, True, False]
State prediction error at timestep 233 is tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 233 of 1
Current timestep = 234. State = [[-0.14247061  0.07075926]]. Action = [[-0.08347704  0.0280183   0.          0.30083787]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 234 is [True, False, False, False, True, False]
State prediction error at timestep 234 is tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 234 of 1
Current timestep = 235. State = [[-0.14190473  0.07477896]]. Action = [[ 0.04641772  0.05778327  0.         -0.9027261 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 235 is [True, False, False, False, True, False]
State prediction error at timestep 235 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 235 of -1
Current timestep = 236. State = [[-0.1385398   0.07255248]]. Action = [[ 0.03241428 -0.08501082  0.          0.93453264]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 236 is [True, False, False, False, True, False]
State prediction error at timestep 236 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 236 of -1
Current timestep = 237. State = [[-0.13531524  0.07483489]]. Action = [[0.03444529 0.09647777 0.         0.07204235]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 237 is [True, False, False, False, True, False]
State prediction error at timestep 237 is tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 237 of 1
Current timestep = 238. State = [[-0.13464071  0.07870491]]. Action = [[-0.00927033  0.02194519  0.          0.56847453]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 238 is [True, False, False, False, True, False]
State prediction error at timestep 238 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 238 of 1
Current timestep = 239. State = [[-0.13206707  0.08246841]]. Action = [[0.05748304 0.05466679 0.         0.13437736]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 239 is [True, False, False, False, True, False]
State prediction error at timestep 239 is tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 239 of -1
Current timestep = 240. State = [[-0.1283938   0.08532086]]. Action = [[0.04749184 0.02089548 0.         0.3643067 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 240 is [True, False, False, False, True, False]
State prediction error at timestep 240 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 240 of -1
Current timestep = 241. State = [[-0.1233606   0.08490746]]. Action = [[ 0.07509636 -0.02476623  0.          0.61162007]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 241 is [True, False, False, False, True, False]
State prediction error at timestep 241 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 241 of 1
Current timestep = 242. State = [[-0.12472299  0.08789282]]. Action = [[-0.08197153  0.06947849  0.         -0.4442894 ]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 242 is [True, False, False, False, True, False]
State prediction error at timestep 242 is tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 242 of 1
Current timestep = 243. State = [[-0.1280301   0.08656139]]. Action = [[-0.03006925 -0.08050267  0.         -0.09533995]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 243 is [True, False, False, False, True, False]
State prediction error at timestep 243 is tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 243 of -1
Current timestep = 244. State = [[-0.13140567  0.08632574]]. Action = [[-0.05990005  0.02562719  0.         -0.79515374]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 244 is [True, False, False, False, True, False]
State prediction error at timestep 244 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 244 of 1
Current timestep = 245. State = [[-0.13112621  0.08727361]]. Action = [[ 0.03679026 -0.00695396  0.         -0.73625743]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 245 is [True, False, False, False, True, False]
State prediction error at timestep 245 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 245 of -1
Current timestep = 246. State = [[-0.13218664  0.09136581]]. Action = [[-0.04095214  0.07535996  0.         -0.0526951 ]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 246 is [True, False, False, False, True, False]
State prediction error at timestep 246 is tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 246 of -1
Current timestep = 247. State = [[-0.13586143  0.09895125]]. Action = [[-0.04466585  0.0921581   0.         -0.15539491]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 247 is [True, False, False, False, True, False]
State prediction error at timestep 247 is tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 247 of -1
Current timestep = 248. State = [[-0.13649772  0.1034805 ]]. Action = [[0.02976919 0.0125159  0.         0.38804114]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 248 is [True, False, False, False, True, False]
State prediction error at timestep 248 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 248 of -1
Current timestep = 249. State = [[-0.13629426  0.10286664]]. Action = [[ 0.00246014 -0.04358081  0.         -0.7978471 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 249 is [True, False, False, False, True, False]
State prediction error at timestep 249 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 249 of -1
Current timestep = 250. State = [[-0.1389432   0.10079917]]. Action = [[-0.05156515 -0.03629091  0.          0.08200145]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 250 is [True, False, False, False, True, False]
State prediction error at timestep 250 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 250 of -1
Current timestep = 251. State = [[-0.13653396  0.10073074]]. Action = [[0.08709662 0.00837266 0.         0.94330657]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 251 is [True, False, False, False, True, False]
State prediction error at timestep 251 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 251 of -1
Current timestep = 252. State = [[-0.13025786  0.10561068]]. Action = [[ 0.08631489  0.09272713  0.         -0.6194521 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 252 is [True, False, False, False, True, False]
State prediction error at timestep 252 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 252 of -1
Current timestep = 253. State = [[-0.1303359   0.11324108]]. Action = [[-0.04857055  0.09586876  0.         -0.8636244 ]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 253 is [True, False, False, False, True, False]
State prediction error at timestep 253 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 253 of -1
Current timestep = 254. State = [[-0.13344745  0.11794141]]. Action = [[-0.02812013  0.02078922  0.         -0.71523464]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 254 is [True, False, False, False, True, False]
State prediction error at timestep 254 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 254 of 1
Current timestep = 255. State = [[-0.12988724  0.11790083]]. Action = [[ 0.0994565  -0.03283657  0.         -0.9035883 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 255 is [True, False, False, False, True, False]
State prediction error at timestep 255 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 255 of -1
Current timestep = 256. State = [[-0.1309148   0.12157302]]. Action = [[-0.07849582  0.07801253  0.          0.43622065]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 256 is [True, False, False, False, True, False]
State prediction error at timestep 256 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 256 of -1
Current timestep = 257. State = [[-0.13608006  0.12654507]]. Action = [[-0.05918264  0.03048659  0.         -0.3217733 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 257 is [True, False, False, False, False, True]
State prediction error at timestep 257 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 257 of -1
Current timestep = 258. State = [[-0.14190951  0.13059914]]. Action = [[-0.07654908  0.02840734  0.          0.4440825 ]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 258 is [True, False, False, False, False, True]
State prediction error at timestep 258 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 258 of -1
Current timestep = 259. State = [[-0.1438341  0.1316202]]. Action = [[ 0.01486643 -0.03232167  0.          0.0818305 ]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 259 is [True, False, False, False, False, True]
State prediction error at timestep 259 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 259 of -1
Current timestep = 260. State = [[-0.14599082  0.1295161 ]]. Action = [[-0.04533646 -0.05408154  0.          0.7749729 ]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 260 is [True, False, False, False, False, True]
State prediction error at timestep 260 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 260 of -1
Current timestep = 261. State = [[-0.14849055  0.12654239]]. Action = [[-0.02607497 -0.05251015  0.          0.7587775 ]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 261 is [True, False, False, False, False, True]
State prediction error at timestep 261 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 261 of -1
Current timestep = 262. State = [[-0.14801502  0.12393412]]. Action = [[ 0.02473682 -0.03467803  0.          0.7109134 ]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 262 is [True, False, False, False, True, False]
State prediction error at timestep 262 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 262 of -1
Current timestep = 263. State = [[-0.14295629  0.12665437]]. Action = [[ 0.09784009  0.0788203   0.         -0.59474194]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 263 is [True, False, False, False, False, True]
State prediction error at timestep 263 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 263 of -1
Current timestep = 264. State = [[-0.14172901  0.13243005]]. Action = [[-0.02011391  0.07926836  0.          0.46190405]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 264 is [True, False, False, False, False, True]
State prediction error at timestep 264 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 264 of -1
Current timestep = 265. State = [[-0.1438126   0.13900204]]. Action = [[-0.01908513  0.08302093  0.          0.5394286 ]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 265 is [True, False, False, False, False, True]
State prediction error at timestep 265 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 265 of -1
Current timestep = 266. State = [[-0.1444172   0.14361621]]. Action = [[0.0172927  0.03423665 0.         0.687191  ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 266 is [True, False, False, False, False, True]
State prediction error at timestep 266 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 266 of -1
Current timestep = 267. State = [[-0.14657304  0.14740206]]. Action = [[-0.0365607   0.04103025  0.         -0.17120266]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 267 is [True, False, False, False, False, True]
State prediction error at timestep 267 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 267 of -1
Current timestep = 268. State = [[-0.14737569  0.14479594]]. Action = [[ 0.01518114 -0.09625083  0.          0.3859836 ]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 268 is [True, False, False, False, False, True]
State prediction error at timestep 268 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 268 of -1
Current timestep = 269. State = [[-0.15087032  0.1401713 ]]. Action = [[-0.08201802 -0.05720729  0.          0.5441581 ]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 269 is [True, False, False, False, False, True]
State prediction error at timestep 269 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 269 of -1
Current timestep = 270. State = [[-0.14995752  0.14203812]]. Action = [[ 0.07376685  0.06435498  0.         -0.5405913 ]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 270 is [True, False, False, False, False, True]
State prediction error at timestep 270 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 270 of -1
Current timestep = 271. State = [[-0.1502895   0.14844668]]. Action = [[-0.04888815  0.08321928  0.          0.24321699]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 271 is [True, False, False, False, False, True]
State prediction error at timestep 271 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 271 of -1
Current timestep = 272. State = [[-0.15258154  0.15026867]]. Action = [[-0.02261613 -0.03272803  0.          0.6678226 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 272 is [True, False, False, False, False, True]
State prediction error at timestep 272 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 272 of -1
Current timestep = 273. State = [[-0.15115501  0.14738019]]. Action = [[ 0.036447   -0.05960534  0.          0.9594712 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 273 is [True, False, False, False, False, True]
State prediction error at timestep 273 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 273 of -1
Current timestep = 274. State = [[-0.146992   0.1460625]]. Action = [[ 0.0561899   0.00244695  0.         -0.19566262]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 274 is [True, False, False, False, False, True]
State prediction error at timestep 274 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 274 of -1
Current timestep = 275. State = [[-0.14475614  0.1413443 ]]. Action = [[-0.00026821 -0.09472539  0.         -0.22328949]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 275 is [True, False, False, False, False, True]
State prediction error at timestep 275 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 275 of 1
Current timestep = 276. State = [[-0.14108473  0.13946602]]. Action = [[0.05623216 0.02401499 0.         0.74504995]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 276 is [True, False, False, False, False, True]
State prediction error at timestep 276 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 276 of 1
Current timestep = 277. State = [[-0.1399343   0.14399695]]. Action = [[-0.01960106  0.09241713  0.          0.49902916]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 277 is [True, False, False, False, False, True]
State prediction error at timestep 277 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 277 of 1
Current timestep = 278. State = [[-0.1445461   0.15144457]]. Action = [[-0.08759972  0.09689081  0.         -0.5990707 ]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 278 is [True, False, False, False, False, True]
State prediction error at timestep 278 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 278 of -1
Current timestep = 279. State = [[-0.14269558  0.15116727]]. Action = [[ 0.09181374 -0.0749571   0.         -0.8164859 ]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 279 is [True, False, False, False, False, True]
State prediction error at timestep 279 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 279 of -1
Current timestep = 280. State = [[-0.14046912  0.14702047]]. Action = [[-0.01049071 -0.04432401  0.          0.18721366]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 280 is [True, False, False, False, False, True]
State prediction error at timestep 280 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 280 of -1
Current timestep = 281. State = [[-0.14365067  0.14929216]]. Action = [[-0.07085832  0.06953662  0.         -0.5649133 ]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 281 is [True, False, False, False, False, True]
State prediction error at timestep 281 is tensor(9.2452e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 281 of 1
Current timestep = 282. State = [[-0.14551888  0.15361859]]. Action = [[0.00328925 0.03663824 0.         0.6429621 ]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 282 is [True, False, False, False, False, True]
State prediction error at timestep 282 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 282 of -1
Current timestep = 283. State = [[-0.14758185  0.15948398]]. Action = [[-0.03291458  0.08114182  0.         -0.9258875 ]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 283 is [True, False, False, False, False, True]
State prediction error at timestep 283 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 283 of -1
Current timestep = 284. State = [[-0.15294906  0.16224095]]. Action = [[-0.07856747 -0.01494873  0.         -0.7231158 ]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 284 is [True, False, False, False, False, True]
State prediction error at timestep 284 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 284 of -1
Current timestep = 285. State = [[-0.15121816  0.15942776]]. Action = [[ 0.09436589 -0.07188525  0.          0.9138514 ]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 285 is [True, False, False, False, False, True]
State prediction error at timestep 285 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 285 of -1
Current timestep = 286. State = [[-0.15313096  0.16224883]]. Action = [[-0.08611529  0.08837014  0.          0.9141388 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 286 is [True, False, False, False, False, True]
State prediction error at timestep 286 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 286 of 1
Current timestep = 287. State = [[-0.15991558  0.16891108]]. Action = [[-0.07910945  0.05849189  0.          0.19527364]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 287 is [True, False, False, False, False, True]
State prediction error at timestep 287 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 287 of -1
Current timestep = 288. State = [[-0.16051243  0.17549519]]. Action = [[ 0.06307375  0.06893954  0.         -0.42324352]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 288 is [True, False, False, False, False, True]
State prediction error at timestep 288 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 288 of 1
Current timestep = 289. State = [[-0.15695845  0.1745352 ]]. Action = [[ 0.05924817 -0.08241282  0.          0.58740675]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 289 is [True, False, False, False, False, True]
State prediction error at timestep 289 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 289 of -1
Current timestep = 290. State = [[-0.15919684  0.1728396 ]]. Action = [[-0.07942462 -0.00757337  0.         -0.234788  ]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 290 is [True, False, False, False, False, True]
State prediction error at timestep 290 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 290 of 1
Current timestep = 291. State = [[-0.16433334  0.17124298]]. Action = [[-0.06274574 -0.05055941  0.         -0.15693855]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 291 is [True, False, False, False, False, True]
State prediction error at timestep 291 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 291 of -1
Current timestep = 292. State = [[-0.16709101  0.17161666]]. Action = [[-0.01783489  0.0163575   0.          0.37214506]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 292 is [True, False, False, False, False, True]
State prediction error at timestep 292 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 292 of -1
Current timestep = 293. State = [[-0.16905178  0.1696861 ]]. Action = [[-0.02403297 -0.06113232  0.         -0.8035481 ]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 293 is [True, False, False, False, False, True]
State prediction error at timestep 293 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 293 of -1
Current timestep = 294. State = [[-0.16533771  0.16486408]]. Action = [[ 0.09172811 -0.06494377  0.          0.61274755]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 294 is [True, False, False, False, False, True]
State prediction error at timestep 294 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 294 of -1
Current timestep = 295. State = [[-0.16381517  0.16526023]]. Action = [[-0.02217936  0.06050154  0.         -0.9092387 ]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 295 is [True, False, False, False, False, True]
State prediction error at timestep 295 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 295 of -1
Current timestep = 296. State = [[-0.16027352  0.16194703]]. Action = [[ 0.08221557 -0.08772956  0.          0.843593  ]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 296 is [True, False, False, False, False, True]
State prediction error at timestep 296 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 296 of 1
Current timestep = 297. State = [[-0.15868586  0.16274036]]. Action = [[-0.01796499  0.08799817  0.          0.6509352 ]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 297 is [True, False, False, False, False, True]
State prediction error at timestep 297 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 297 of 1
Current timestep = 298. State = [[-0.15703088  0.16825336]]. Action = [[0.04791855 0.07942767 0.         0.4333012 ]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 298 is [True, False, False, False, False, True]
State prediction error at timestep 298 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 298 of 1
Current timestep = 299. State = [[-0.15575136  0.16677323]]. Action = [[ 0.00374528 -0.06645299  0.         -0.90101326]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 299 is [True, False, False, False, False, True]
State prediction error at timestep 299 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 299 of -1
Current timestep = 300. State = [[-0.16005522  0.16830768]]. Action = [[-0.09265377  0.07251046  0.         -0.68161917]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 300 is [True, False, False, False, False, True]
State prediction error at timestep 300 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 300 of 1
Current timestep = 301. State = [[-0.15913701  0.16831063]]. Action = [[ 0.07747776 -0.04275792  0.          0.5258595 ]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 301 is [True, False, False, False, False, True]
State prediction error at timestep 301 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 301 of -1
Current timestep = 302. State = [[-0.16142125  0.16963497]]. Action = [[-0.08779467  0.04861601  0.         -0.26537633]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 302 is [True, False, False, False, False, True]
State prediction error at timestep 302 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 302 of 1
Current timestep = 303. State = [[-0.16295205  0.17379814]]. Action = [[0.02614463 0.04828603 0.         0.5897374 ]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 303 is [True, False, False, False, False, True]
State prediction error at timestep 303 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 303 of -1
Current timestep = 304. State = [[-0.16437039  0.17474303]]. Action = [[-0.03100102 -0.02066596  0.         -0.67552096]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 304 is [True, False, False, False, False, True]
State prediction error at timestep 304 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 304 of -1
Current timestep = 305. State = [[-0.16718456  0.17971347]]. Action = [[-0.0295672   0.09648068  0.          0.40303898]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 305 is [True, False, False, False, False, True]
State prediction error at timestep 305 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 305 of -1
Current timestep = 306. State = [[-0.16682792  0.18261103]]. Action = [[ 0.04325456 -0.01254253  0.          0.705428  ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 306 is [True, False, False, False, False, True]
State prediction error at timestep 306 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 306 of -1
Current timestep = 307. State = [[-0.1616217   0.18562114]]. Action = [[ 0.09883358  0.05700824  0.         -0.21665931]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 307 is [True, False, False, False, False, True]
State prediction error at timestep 307 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 307 of -1
Current timestep = 308. State = [[-0.16057314  0.18419251]]. Action = [[-0.03776412 -0.07273313  0.         -0.67267525]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 308 is [True, False, False, False, False, True]
State prediction error at timestep 308 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 308 of -1
Current timestep = 309. State = [[-0.16550899  0.1823896 ]]. Action = [[-0.07849778 -0.00760549  0.          0.98860264]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 309 is [True, False, False, False, False, True]
State prediction error at timestep 309 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 309 of -1
Current timestep = 310. State = [[-0.16557649  0.18632524]]. Action = [[0.06157809 0.08022124 0.         0.25830936]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 310 is [True, False, False, False, False, True]
State prediction error at timestep 310 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 310 of -1
Current timestep = 311. State = [[-0.16518693  0.18973836]]. Action = [[-0.01737443  0.0153121   0.          0.8491286 ]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 311 is [True, False, False, False, False, True]
State prediction error at timestep 311 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 311 of -1
Current timestep = 312. State = [[-0.16295382  0.18993455]]. Action = [[ 0.05573972 -0.01705371  0.         -0.9897855 ]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 312 is [True, False, False, False, False, True]
State prediction error at timestep 312 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 312 of -1
Current timestep = 313. State = [[-0.1617669  0.192455 ]]. Action = [[-0.00892504  0.05458424  0.         -0.9649984 ]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 313 is [True, False, False, False, False, True]
State prediction error at timestep 313 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 313 of -1
Current timestep = 314. State = [[-0.15765797  0.19770986]]. Action = [[0.09055152 0.07093327 0.         0.8119439 ]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 314 is [True, False, False, False, False, True]
State prediction error at timestep 314 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 314 of -1
Current timestep = 315. State = [[-0.15090004  0.20210113]]. Action = [[ 0.08848495  0.0481549   0.         -0.8448168 ]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 315 is [True, False, False, False, False, True]
State prediction error at timestep 315 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 315 of -1
Current timestep = 316. State = [[-0.14799799  0.20815162]]. Action = [[0.00266334 0.09164438 0.         0.8042501 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 316 is [True, False, False, False, False, True]
State prediction error at timestep 316 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 316 of -1
Current timestep = 317. State = [[-0.15123585  0.21379386]]. Action = [[-0.07665074  0.04333792  0.          0.86585593]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 317 is [True, False, False, False, False, True]
State prediction error at timestep 317 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 317 of -1
Current timestep = 318. State = [[-0.15036628  0.22099355]]. Action = [[ 0.06426895  0.09354327  0.         -0.5156829 ]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 318 is [True, False, False, False, False, True]
State prediction error at timestep 318 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 318 of -1
Current timestep = 319. State = [[-0.14671762  0.22058736]]. Action = [[ 0.02923126 -0.09432385  0.         -0.57485414]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 319 is [True, False, False, False, False, True]
State prediction error at timestep 319 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 319 of -1
Current timestep = 320. State = [[-0.14510533  0.21663618]]. Action = [[-0.01107866 -0.06236773  0.         -0.59981394]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 320 is [True, False, False, False, False, True]
State prediction error at timestep 320 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 320 of -1
Current timestep = 321. State = [[-0.14134045  0.21790192]]. Action = [[ 0.05481673  0.03805392  0.         -0.3624661 ]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 321 is [True, False, False, False, False, True]
State prediction error at timestep 321 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 321 of -1
Current timestep = 322. State = [[-0.14180517  0.2244762 ]]. Action = [[-0.06475754  0.08998371  0.          0.4657402 ]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 322 is [True, False, False, False, False, True]
State prediction error at timestep 322 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 322 of 1
Current timestep = 323. State = [[-0.14487253  0.23339346]]. Action = [[-0.03989882  0.09503321  0.         -0.27608824]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 323 is [True, False, False, False, False, True]
State prediction error at timestep 323 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 323 of -1
Current timestep = 324. State = [[-0.1412955  0.2362773]]. Action = [[ 0.09223912 -0.03279806  0.          0.13785195]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 324 is [True, False, False, False, False, True]
State prediction error at timestep 324 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 324 of -1
Current timestep = 325. State = [[-0.13920128  0.24138023]]. Action = [[-0.01711448  0.09511273  0.          0.07192707]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 325 is [True, False, False, False, False, True]
State prediction error at timestep 325 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 325 of -1
Current timestep = 326. State = [[-0.14150217  0.2427063 ]]. Action = [[-0.0482438  -0.06268431  0.         -0.742849  ]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 326 is [True, False, False, False, False, True]
State prediction error at timestep 326 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 326 of -1
Current timestep = 327. State = [[-0.14499599  0.24656427]]. Action = [[-0.05102569  0.07198676  0.          0.75207543]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 327 is [True, False, False, False, False, True]
State prediction error at timestep 327 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 327 of -1
Current timestep = 328. State = [[-0.1459157  0.2501551]]. Action = [[ 0.01384504 -0.00471273  0.         -0.8529344 ]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 328 is [True, False, False, False, False, True]
State prediction error at timestep 328 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 328 of -1
Current timestep = 329. State = [[-0.14221276  0.25214723]]. Action = [[0.07106968 0.01326203 0.         0.26859272]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 329 is [True, False, False, False, False, True]
State prediction error at timestep 329 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 329 of -1
Current timestep = 330. State = [[-0.14454307  0.25549012]]. Action = [[-0.0908858   0.03555351  0.         -0.9468923 ]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 330 is [True, False, False, False, False, True]
State prediction error at timestep 330 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 330 of -1
Current timestep = 331. State = [[-0.1495611   0.25931707]]. Action = [[-0.04725071  0.02498517  0.          0.68955314]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 331 is [True, False, False, False, False, True]
State prediction error at timestep 331 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 331 of -1
Current timestep = 332. State = [[-0.15058604  0.2662085 ]]. Action = [[ 0.02551235  0.09656525  0.         -0.0259434 ]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 332 is [True, False, False, False, False, True]
State prediction error at timestep 332 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 332 of -1
Current timestep = 333. State = [[-0.15070882  0.27290523]]. Action = [[ 0.00685941  0.05683682  0.         -0.9674923 ]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 333 is [True, False, False, False, False, True]
State prediction error at timestep 333 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 333 of -1
Current timestep = 334. State = [[-0.15350032  0.2784737 ]]. Action = [[-0.03953345  0.05135655  0.         -0.62141484]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 334 is [True, False, False, False, False, True]
State prediction error at timestep 334 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 334 of -1
Current timestep = 335. State = [[-0.15877381  0.28368473]]. Action = [[-0.06156644  0.04105014  0.         -0.7084966 ]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 335 is [True, False, False, False, False, True]
State prediction error at timestep 335 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 335 of -1
Current timestep = 336. State = [[-0.16006657  0.28685567]]. Action = [[0.03370994 0.00332364 0.         0.01519179]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 336 is [True, False, False, False, False, True]
State prediction error at timestep 336 is tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 336 of -1
Current timestep = 337. State = [[-0.16492994  0.29308367]]. Action = [[-0.09313719  0.09079982  0.         -0.39137757]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 337 is [True, False, False, False, False, True]
State prediction error at timestep 337 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 337 of -1
Current timestep = 338. State = [[-0.16938685  0.30176127]]. Action = [[-0.00429375  0.08556373  0.         -0.6115861 ]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 338 is [True, False, False, False, False, True]
State prediction error at timestep 338 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 338 of -1
Current timestep = 339. State = [[-0.17537329  0.3062028 ]]. Action = [[-0.08342199 -0.00399186  0.         -0.883409  ]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 339 is [True, False, False, False, False, True]
State prediction error at timestep 339 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 339 of -1
Current timestep = 340. State = [[-0.1835612   0.31080648]]. Action = [[-0.08373846  0.0451277   0.         -0.5983235 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 340 is [True, False, False, False, False, True]
State prediction error at timestep 340 is tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 340 of -1
Current timestep = 341. State = [[-0.18330437  0.30969462]]. Action = [[ 0.09044107 -0.09316058  0.         -0.71591055]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 341 is [True, False, False, False, False, True]
State prediction error at timestep 341 is tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 341 of -1
Current timestep = 342. State = [[-0.18663485  0.31191695]]. Action = [[-0.09746999  0.07275557  0.         -0.3259989 ]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 342 is [True, False, False, False, False, True]
State prediction error at timestep 342 is tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 342 of -1
Current timestep = 343. State = [[-0.18622008  0.3160277 ]]. Action = [[ 0.0940171   0.01421843  0.         -0.5207713 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 343 is [True, False, False, False, False, True]
State prediction error at timestep 343 is tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 343 of -1
Current timestep = 344. State = [[-0.18568222  0.3206197 ]]. Action = [[-0.01511065  0.06502641  0.         -0.79018635]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 344 is [True, False, False, False, False, True]
State prediction error at timestep 344 is tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 344 of -1
Current timestep = 345. State = [[-0.18315001  0.3272234 ]]. Action = [[ 0.08134983  0.08486845  0.         -0.67144334]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 345 is [True, False, False, False, False, True]
State prediction error at timestep 345 is tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 345 of -1
Current timestep = 346. State = [[-0.17986745  0.3300217 ]]. Action = [[ 0.03537028  0.00154577  0.         -0.98031485]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 346 is [True, False, False, False, False, True]
State prediction error at timestep 346 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 346 of -1
Current timestep = 347. State = [[-0.17465194  0.32992926]]. Action = [[ 0.08475111 -0.01040639  0.         -0.8524754 ]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 347 is [True, False, False, False, False, True]
State prediction error at timestep 347 is tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 347 of -1
Current timestep = 348. State = [[-0.17170586  0.33394983]]. Action = [[0.00296313 0.08765876 0.         0.04743743]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 348 is [True, False, False, False, False, True]
State prediction error at timestep 348 is tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 348 of 1
Current timestep = 349. State = [[-0.16840084  0.33191663]]. Action = [[ 0.05037541 -0.09783629  0.         -0.16957456]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 349 is [True, False, False, False, False, True]
State prediction error at timestep 349 is tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 349 of 1
Current timestep = 350. State = [[-0.16698031  0.3282414 ]]. Action = [[-0.02853192 -0.03300735  0.          0.59095955]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 350 is [True, False, False, False, False, True]
State prediction error at timestep 350 is tensor(0.0062, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 350 of 1
Current timestep = 351. State = [[-0.1624929   0.33165166]]. Action = [[ 0.08826835  0.09366838  0.         -0.52496076]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 351 is [True, False, False, False, False, True]
State prediction error at timestep 351 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 351 of 1
Current timestep = 352. State = [[-0.15597293  0.33667675]]. Action = [[ 0.0554333   0.05001018  0.         -0.02806562]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 352 is [True, False, False, False, False, True]
State prediction error at timestep 352 is tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 352 of 1
Current timestep = 353. State = [[-0.15733522  0.34305474]]. Action = [[-0.0900659  0.0891958  0.         0.1857959]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 353 is [True, False, False, False, False, True]
State prediction error at timestep 353 is tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 353 of 1
Current timestep = 354. State = [[-0.16026852  0.34589034]]. Action = [[-0.03023476 -0.0240262   0.         -0.31963253]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 354 is [True, False, False, False, False, True]
State prediction error at timestep 354 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 354 of 1
Current timestep = 355. State = [[-0.16029125  0.3471423 ]]. Action = [[0.         0.         0.         0.57856095]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 355 is [True, False, False, False, False, True]
State prediction error at timestep 355 is tensor(0.0065, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 355 of -1
Current timestep = 356. State = [[-0.16229592  0.35040566]]. Action = [[-0.05443522  0.02980927  0.          0.3672756 ]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 356 is [True, False, False, False, False, True]
State prediction error at timestep 356 is tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 356 of -1
Current timestep = 357. State = [[-0.16343606  0.35322374]]. Action = [[ 0.         0.         0.        -0.9120501]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 357 is [True, False, False, False, False, True]
State prediction error at timestep 357 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 357 of -1
Current timestep = 358. State = [[-0.16317368  0.35507545]]. Action = [[ 0.         0.         0.        -0.8673454]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 358 is [True, False, False, False, False, True]
State prediction error at timestep 358 is tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 358 of -1
Current timestep = 359. State = [[-0.1628716   0.35669547]]. Action = [[0.        0.        0.        0.8171835]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 359 is [True, False, False, False, False, True]
State prediction error at timestep 359 is tensor(0.0062, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 359 of -1
Current timestep = 360. State = [[-0.16259272  0.35811198]]. Action = [[0.         0.         0.         0.47371292]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 360 is [True, False, False, False, False, True]
State prediction error at timestep 360 is tensor(0.0070, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 360 of -1
Current timestep = 361. State = [[-0.16232888  0.35931185]]. Action = [[0.        0.        0.        0.8961854]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 361 is [True, False, False, False, False, True]
State prediction error at timestep 361 is tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 361 of -1
Current timestep = 362. State = [[-0.16207623  0.36029297]]. Action = [[ 0.          0.          0.         -0.38213116]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 362 is [True, False, False, False, False, True]
State prediction error at timestep 362 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 362 of -1
Current timestep = 363. State = [[-0.16184655  0.36104104]]. Action = [[0.         0.         0.         0.89442587]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 363 is [True, False, False, False, False, True]
State prediction error at timestep 363 is tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 363 of -1
Current timestep = 364. State = [[-0.16163097  0.36159298]]. Action = [[ 0.          0.          0.         -0.66068006]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 364 is [True, False, False, False, False, True]
State prediction error at timestep 364 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 364 of -1
Current timestep = 365. State = [[-0.16144818  0.36202046]]. Action = [[0.        0.        0.        0.5201827]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 365 is [True, False, False, False, False, True]
State prediction error at timestep 365 is tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 365 of -1
Current timestep = 366. State = [[-0.16130573  0.3623571 ]]. Action = [[ 0.          0.          0.         -0.69236124]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 366 is [True, False, False, False, False, True]
State prediction error at timestep 366 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 366 of -1
Current timestep = 367. State = [[-0.1611673   0.36263224]]. Action = [[ 0.          0.          0.         -0.05718416]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 367 is [True, False, False, False, False, True]
State prediction error at timestep 367 is tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 367 of -1
Current timestep = 368. State = [[-0.16103442  0.36286044]]. Action = [[ 0.          0.          0.         -0.49599755]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 368 is [True, False, False, False, False, True]
State prediction error at timestep 368 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 368 of -1
Current timestep = 369. State = [[-0.16091874  0.36304948]]. Action = [[ 0.          0.          0.         -0.49725592]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 369 is [True, False, False, False, False, True]
State prediction error at timestep 369 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 369 of -1
Current timestep = 370. State = [[-0.16082104  0.36320853]]. Action = [[ 0.         0.         0.        -0.4080032]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 370 is [True, False, False, False, False, True]
State prediction error at timestep 370 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 370 of -1
Current timestep = 371. State = [[-0.16074552  0.3633417 ]]. Action = [[0.         0.         0.         0.29606748]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 371 is [True, False, False, False, False, True]
State prediction error at timestep 371 is tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 371 of -1
Current timestep = 372. State = [[-0.16068867  0.3634541 ]]. Action = [[0.        0.        0.        0.6218002]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 372 is [True, False, False, False, False, True]
State prediction error at timestep 372 is tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 372 of -1
Current timestep = 373. State = [[-0.16064681  0.36354977]]. Action = [[ 0.         0.         0.        -0.8390483]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 373 is [True, False, False, False, False, True]
State prediction error at timestep 373 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 373 of -1
Current timestep = 374. State = [[-0.16061711  0.36363202]]. Action = [[0.        0.        0.        0.5721855]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 374 is [True, False, False, False, False, True]
State prediction error at timestep 374 is tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 374 of -1
Current timestep = 375. State = [[-0.16059726  0.3637033 ]]. Action = [[ 0.         0.         0.        -0.8111019]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 375 is [True, False, False, False, False, True]
State prediction error at timestep 375 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 375 of -1
Current timestep = 376. State = [[-0.16058527  0.36376572]]. Action = [[0.       0.       0.       0.500394]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 376 is [True, False, False, False, False, True]
State prediction error at timestep 376 is tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 376 of -1
Current timestep = 377. State = [[-0.1605779  0.3638193]]. Action = [[ 0.          0.          0.         -0.05052453]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 377 is [True, False, False, False, False, True]
State prediction error at timestep 377 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 377 of -1
Current timestep = 378. State = [[-0.16057263  0.36386508]]. Action = [[0.         0.         0.         0.18807507]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 378 is [True, False, False, False, False, True]
State prediction error at timestep 378 is tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 378 of -1
Current timestep = 379. State = [[-0.16056894  0.36390463]]. Action = [[0.         0.         0.         0.61992025]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 379 is [True, False, False, False, False, True]
State prediction error at timestep 379 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 379 of -1
Current timestep = 380. State = [[-0.16056651  0.36393884]]. Action = [[0.         0.         0.         0.01045609]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 380 is [True, False, False, False, False, True]
State prediction error at timestep 380 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 380 of -1
Current timestep = 381. State = [[-0.1605651   0.36396858]]. Action = [[ 0.          0.          0.         -0.72453743]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 381 is [True, False, False, False, False, True]
State prediction error at timestep 381 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 381 of -1
Current timestep = 382. State = [[-0.16056445  0.3639945 ]]. Action = [[0.       0.       0.       0.513904]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 382 is [True, False, False, False, False, True]
State prediction error at timestep 382 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 382 of -1
Current timestep = 383. State = [[-0.16056441  0.3640171 ]]. Action = [[ 0.         0.         0.        -0.8578848]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 383 is [True, False, False, False, False, True]
State prediction error at timestep 383 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 383 of -1
Current timestep = 384. State = [[-0.16056478  0.36403683]]. Action = [[0.       0.       0.       0.666121]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 384 is [True, False, False, False, False, True]
State prediction error at timestep 384 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 384 of -1
Current timestep = 385. State = [[-0.16056547  0.36405408]]. Action = [[ 0.        0.        0.       -0.284701]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 385 is [True, False, False, False, False, True]
State prediction error at timestep 385 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 385 of -1
Current timestep = 386. State = [[-0.16056633  0.36406916]]. Action = [[ 0.          0.          0.         -0.45295715]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 386 is [True, False, False, False, False, True]
State prediction error at timestep 386 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 386 of -1
Current timestep = 387. State = [[-0.16056733  0.36408234]]. Action = [[ 0.          0.          0.         -0.74306345]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 387 is [True, False, False, False, False, True]
State prediction error at timestep 387 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 387 of -1
Current timestep = 388. State = [[-0.16056837  0.3640939 ]]. Action = [[0.         0.         0.         0.12256789]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 388 is [True, False, False, False, False, True]
State prediction error at timestep 388 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 388 of -1
Current timestep = 389. State = [[-0.16056944  0.3641041 ]]. Action = [[0.        0.        0.        0.6385119]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 389 is [True, False, False, False, False, True]
State prediction error at timestep 389 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 389 of -1
Current timestep = 390. State = [[-0.16057049  0.36411306]]. Action = [[0.         0.         0.         0.03588295]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 390 is [True, False, False, False, False, True]
State prediction error at timestep 390 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 390 of -1
Current timestep = 391. State = [[-0.16057146  0.36412096]]. Action = [[0.         0.         0.         0.67674005]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 391 is [True, False, False, False, False, True]
State prediction error at timestep 391 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 391 of -1
Current timestep = 392. State = [[-0.1605721  0.3641281]]. Action = [[ 0.         0.         0.        -0.6248566]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 392 is [True, False, False, False, False, True]
State prediction error at timestep 392 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 392 of -1
Current timestep = 393. State = [[-0.16057241  0.3641346 ]]. Action = [[ 0.          0.          0.         -0.32156438]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 393 is [True, False, False, False, False, True]
State prediction error at timestep 393 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 393 of -1
Current timestep = 394. State = [[-0.16057241  0.36414045]]. Action = [[0.         0.         0.         0.38059616]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 394 is [True, False, False, False, False, True]
State prediction error at timestep 394 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 394 of -1
Current timestep = 395. State = [[-0.16057213  0.36414576]]. Action = [[0.         0.         0.         0.20561457]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 395 is [True, False, False, False, False, True]
State prediction error at timestep 395 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 395 of -1
Current timestep = 396. State = [[-0.1605716   0.36415052]]. Action = [[ 0.         0.         0.        -0.5573729]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 396 is [True, False, False, False, False, True]
State prediction error at timestep 396 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 396 of -1
Current timestep = 397. State = [[-0.16057086  0.36415488]]. Action = [[ 0.          0.          0.         -0.15996277]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 397 is [True, False, False, False, False, True]
State prediction error at timestep 397 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 397 of -1
Current timestep = 398. State = [[-0.16056994  0.36415884]]. Action = [[0.         0.         0.         0.04907501]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 398 is [True, False, False, False, False, True]
State prediction error at timestep 398 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 398 of -1
Current timestep = 399. State = [[-0.16056892  0.36416256]]. Action = [[ 0.          0.          0.         -0.07930303]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 399 is [True, False, False, False, False, True]
State prediction error at timestep 399 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 399 of -1
Current timestep = 400. State = [[-0.16056791  0.36416623]]. Action = [[ 0.         0.         0.        -0.1047985]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 400 is [True, False, False, False, False, True]
State prediction error at timestep 400 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 400 of -1
Current timestep = 401. State = [[-0.1605669   0.36416987]]. Action = [[ 0.          0.          0.         -0.97622836]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 401 is [True, False, False, False, False, True]
State prediction error at timestep 401 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 401 of -1
Current timestep = 402. State = [[-0.1605659  0.3641735]]. Action = [[0.        0.        0.        0.8046428]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 402 is [True, False, False, False, False, True]
State prediction error at timestep 402 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 402 of -1
Current timestep = 403. State = [[-0.16056491  0.36417708]]. Action = [[ 0.         0.         0.        -0.5907565]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 403 is [True, False, False, False, False, True]
State prediction error at timestep 403 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 403 of -1
Current timestep = 404. State = [[-0.16056393  0.36418062]]. Action = [[ 0.          0.          0.         -0.37642318]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 404 is [True, False, False, False, False, True]
State prediction error at timestep 404 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 404 of -1
Current timestep = 405. State = [[-0.16056296  0.36418414]]. Action = [[ 0.         0.         0.        -0.4635517]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 405 is [True, False, False, False, False, True]
State prediction error at timestep 405 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 405 of -1
Current timestep = 406. State = [[-0.16056201  0.36418763]]. Action = [[ 0.         0.         0.        -0.5609902]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 406 is [True, False, False, False, False, True]
State prediction error at timestep 406 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 406 of -1
Current timestep = 407. State = [[-0.16056105  0.3641911 ]]. Action = [[ 0.         0.         0.        -0.3572675]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 407 is [True, False, False, False, False, True]
State prediction error at timestep 407 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 407 of -1
Current timestep = 408. State = [[-0.1605601  0.3641945]]. Action = [[0.         0.         0.         0.66636896]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 408 is [True, False, False, False, False, True]
State prediction error at timestep 408 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 408 of -1
Current timestep = 409. State = [[-0.16055918  0.3641979 ]]. Action = [[ 0.          0.          0.         -0.44370413]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 409 is [True, False, False, False, False, True]
State prediction error at timestep 409 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 409 of -1
Current timestep = 410. State = [[-0.16055824  0.36420128]]. Action = [[ 0.          0.          0.         -0.43914485]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 410 is [True, False, False, False, False, True]
State prediction error at timestep 410 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 410 of -1
Current timestep = 411. State = [[-0.16055733  0.36420462]]. Action = [[0.        0.        0.        0.7584069]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 411 is [True, False, False, False, False, True]
State prediction error at timestep 411 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 411 of -1
Current timestep = 412. State = [[-0.16055642  0.36420792]]. Action = [[0.         0.         0.         0.45865715]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 412 is [True, False, False, False, False, True]
State prediction error at timestep 412 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 412 of -1
Current timestep = 413. State = [[-0.16055551  0.3642112 ]]. Action = [[ 0.         0.         0.        -0.5520845]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 413 is [True, False, False, False, False, True]
State prediction error at timestep 413 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 413 of -1
Current timestep = 414. State = [[-0.16055462  0.36421445]]. Action = [[0.       0.       0.       0.866155]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 414 is [True, False, False, False, False, True]
State prediction error at timestep 414 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 414 of -1
Current timestep = 415. State = [[-0.16055374  0.36421767]]. Action = [[ 0.         0.         0.        -0.8851384]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 415 is [True, False, False, False, False, True]
State prediction error at timestep 415 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 415 of -1
Current timestep = 416. State = [[-0.16055286  0.3642209 ]]. Action = [[ 0.       0.       0.      -0.34841]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 416 is [True, False, False, False, False, True]
State prediction error at timestep 416 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 416 of -1
Current timestep = 417. State = [[-0.16055198  0.36422405]]. Action = [[0.         0.         0.         0.61751986]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 417 is [True, False, False, False, False, True]
State prediction error at timestep 417 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 417 of -1
Current timestep = 418. State = [[-0.16055113  0.36422718]]. Action = [[0.        0.        0.        0.2206943]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 418 is [True, False, False, False, False, True]
State prediction error at timestep 418 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 418 of -1
Current timestep = 419. State = [[-0.16055027  0.36423028]]. Action = [[0.         0.         0.         0.32666194]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 419 is [True, False, False, False, False, True]
State prediction error at timestep 419 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 419 of -1
Current timestep = 420. State = [[-0.16054942  0.36423337]]. Action = [[0.         0.         0.         0.00802314]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 420 is [True, False, False, False, False, True]
State prediction error at timestep 420 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 420 of -1
Current timestep = 421. State = [[-0.16054858  0.3642364 ]]. Action = [[0.         0.         0.         0.47646832]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 421 is [True, False, False, False, False, True]
State prediction error at timestep 421 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 421 of -1
Current timestep = 422. State = [[-0.16054775  0.36423945]]. Action = [[ 0.          0.          0.         -0.19884676]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 422 is [True, False, False, False, False, True]
State prediction error at timestep 422 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 422 of -1
Current timestep = 423. State = [[-0.16054693  0.36424243]]. Action = [[0.        0.        0.        0.6061262]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 423 is [True, False, False, False, False, True]
State prediction error at timestep 423 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 423 of -1
Current timestep = 424. State = [[-0.16054611  0.3642454 ]]. Action = [[ 0.         0.         0.        -0.5715908]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 424 is [True, False, False, False, False, True]
State prediction error at timestep 424 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 424 of -1
Current timestep = 425. State = [[-0.1605453   0.36424837]]. Action = [[ 0.          0.          0.         -0.64811003]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 425 is [True, False, False, False, False, True]
State prediction error at timestep 425 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 425 of -1
Current timestep = 426. State = [[-0.1605445  0.3642513]]. Action = [[0.        0.        0.        0.7920022]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 426 is [True, False, False, False, False, True]
State prediction error at timestep 426 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 426 of -1
Current timestep = 427. State = [[-0.16054371  0.36425418]]. Action = [[0.         0.         0.         0.49858832]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 427 is [True, False, False, False, False, True]
State prediction error at timestep 427 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 427 of -1
Current timestep = 428. State = [[-0.16054292  0.36425707]]. Action = [[0.         0.         0.         0.36652088]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 428 is [True, False, False, False, False, True]
State prediction error at timestep 428 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 428 of -1
Current timestep = 429. State = [[-0.16054215  0.3642599 ]]. Action = [[0.        0.        0.        0.8607216]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 429 is [True, False, False, False, False, True]
State prediction error at timestep 429 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 429 of -1
Current timestep = 430. State = [[-0.16054137  0.36426273]]. Action = [[0.         0.         0.         0.75675416]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 430 is [True, False, False, False, False, True]
State prediction error at timestep 430 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 430 of -1
Current timestep = 431. State = [[-0.1605406   0.36426553]]. Action = [[ 0.         0.         0.        -0.8351935]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 431 is [True, False, False, False, False, True]
State prediction error at timestep 431 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 431 of -1
Current timestep = 432. State = [[-0.16053984  0.36426827]]. Action = [[0.         0.         0.         0.33083904]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 432 is [True, False, False, False, False, True]
State prediction error at timestep 432 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 432 of -1
Current timestep = 433. State = [[-0.16053909  0.36427104]]. Action = [[ 0.          0.          0.         -0.22605753]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 433 is [True, False, False, False, False, True]
State prediction error at timestep 433 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 433 of -1
Current timestep = 434. State = [[-0.16053835  0.36427376]]. Action = [[ 0.          0.          0.         -0.23186761]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 434 is [True, False, False, False, False, True]
State prediction error at timestep 434 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 434 of -1
Current timestep = 435. State = [[-0.1605376   0.36427647]]. Action = [[0.        0.        0.        0.5725939]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 435 is [True, False, False, False, False, True]
State prediction error at timestep 435 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 435 of -1
Current timestep = 436. State = [[-0.16053687  0.36427912]]. Action = [[0.         0.         0.         0.40965366]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 436 is [True, False, False, False, False, True]
State prediction error at timestep 436 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 436 of -1
Current timestep = 437. State = [[-0.16053616  0.36428177]]. Action = [[0.        0.        0.        0.8910637]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 437 is [True, False, False, False, False, True]
State prediction error at timestep 437 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 437 of -1
Current timestep = 438. State = [[-0.16053542  0.3642844 ]]. Action = [[ 0.         0.         0.        -0.8785033]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 438 is [True, False, False, False, False, True]
State prediction error at timestep 438 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 438 of -1
Current timestep = 439. State = [[-0.16053472  0.36428702]]. Action = [[ 0.          0.          0.         -0.69879687]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 439 is [True, False, False, False, False, True]
State prediction error at timestep 439 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 439 of -1
Current timestep = 440. State = [[-0.16053401  0.36428958]]. Action = [[0.        0.        0.        0.9271562]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 440 is [True, False, False, False, False, True]
State prediction error at timestep 440 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 440 of -1
Current timestep = 441. State = [[-0.16053331  0.36429214]]. Action = [[ 0.         0.         0.        -0.7731558]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 441 is [True, False, False, False, False, True]
State prediction error at timestep 441 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 441 of -1
Current timestep = 442. State = [[-0.16053262  0.36429468]]. Action = [[ 0.          0.          0.         -0.53166795]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 442 is [True, False, False, False, False, True]
State prediction error at timestep 442 is tensor(6.6935e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 442 of -1
Current timestep = 443. State = [[-0.16053194  0.3642972 ]]. Action = [[0.        0.        0.        0.5563626]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 443 is [True, False, False, False, False, True]
State prediction error at timestep 443 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 443 of -1
Current timestep = 444. State = [[-0.16053125  0.36429968]]. Action = [[ 0.          0.          0.         -0.64739084]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 444 is [True, False, False, False, False, True]
State prediction error at timestep 444 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 444 of -1
Current timestep = 445. State = [[-0.16053058  0.36430216]]. Action = [[ 0.         0.         0.        -0.6034356]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 445 is [True, False, False, False, False, True]
State prediction error at timestep 445 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 445 of -1
Current timestep = 446. State = [[-0.16052991  0.3643046 ]]. Action = [[ 0.          0.          0.         -0.06419969]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 446 is [True, False, False, False, False, True]
State prediction error at timestep 446 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 446 of -1
Current timestep = 447. State = [[-0.16052926  0.36430702]]. Action = [[ 0.          0.          0.         -0.43044984]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 447 is [True, False, False, False, False, True]
State prediction error at timestep 447 is tensor(6.3718e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 447 of -1
Current timestep = 448. State = [[-0.1605286   0.36430943]]. Action = [[0.         0.         0.         0.18595815]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 448 is [True, False, False, False, False, True]
State prediction error at timestep 448 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 448 of -1
Current timestep = 449. State = [[-0.16052794  0.3643118 ]]. Action = [[ 0.          0.          0.         -0.49518204]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 449 is [True, False, False, False, False, True]
State prediction error at timestep 449 is tensor(7.5392e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 449 of -1
Current timestep = 450. State = [[-0.1605273   0.36431417]]. Action = [[0.         0.         0.         0.84018207]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 450 is [True, False, False, False, False, True]
State prediction error at timestep 450 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 450 of -1
Current timestep = 451. State = [[-0.16052666  0.36431652]]. Action = [[ 0.          0.          0.         -0.26771855]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 451 is [True, False, False, False, False, True]
State prediction error at timestep 451 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 451 of -1
Current timestep = 452. State = [[-0.16052604  0.36431885]]. Action = [[ 0.          0.          0.         -0.30851853]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 452 is [True, False, False, False, False, True]
State prediction error at timestep 452 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 452 of -1
Current timestep = 453. State = [[-0.1605254   0.36432114]]. Action = [[0.        0.        0.        0.5651592]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 453 is [True, False, False, False, False, True]
State prediction error at timestep 453 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 453 of -1
Current timestep = 454. State = [[-0.16052479  0.3643234 ]]. Action = [[0.         0.         0.         0.82123554]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 454 is [True, False, False, False, False, True]
State prediction error at timestep 454 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 454 of -1
Current timestep = 455. State = [[-0.16052417  0.36432567]]. Action = [[0.       0.       0.       0.670326]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 455 is [True, False, False, False, False, True]
State prediction error at timestep 455 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 455 of -1
Current timestep = 456. State = [[-0.16052356  0.3643279 ]]. Action = [[0.        0.        0.        0.1411736]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 456 is [True, False, False, False, False, True]
State prediction error at timestep 456 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 456 of -1
Current timestep = 457. State = [[-0.16052295  0.36433014]]. Action = [[ 0.         0.         0.        -0.9862044]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 457 is [True, False, False, False, False, True]
State prediction error at timestep 457 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 457 of -1
Current timestep = 458. State = [[-0.16052236  0.36433235]]. Action = [[0.         0.         0.         0.82032573]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 458 is [True, False, False, False, False, True]
State prediction error at timestep 458 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 458 of -1
Current timestep = 459. State = [[-0.16052176  0.36433452]]. Action = [[ 0.          0.          0.         -0.18487632]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 459 is [True, False, False, False, False, True]
State prediction error at timestep 459 is tensor(8.7874e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 459 of -1
Current timestep = 460. State = [[-0.16052118  0.36433667]]. Action = [[0.        0.        0.        0.8785238]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 460 is [True, False, False, False, False, True]
State prediction error at timestep 460 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 460 of -1
Current timestep = 461. State = [[-0.1605206   0.36433882]]. Action = [[ 0.        0.        0.       -0.942462]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 461 is [True, False, False, False, False, True]
State prediction error at timestep 461 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 461 of -1
Current timestep = 462. State = [[-0.16052002  0.36434096]]. Action = [[0.        0.        0.        0.6252421]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 462 is [True, False, False, False, False, True]
State prediction error at timestep 462 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 462 of -1
Current timestep = 463. State = [[-0.16051944  0.36434305]]. Action = [[0.        0.        0.        0.7534549]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 463 is [True, False, False, False, False, True]
State prediction error at timestep 463 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 463 of -1
Current timestep = 464. State = [[-0.16051887  0.36434513]]. Action = [[0.        0.        0.        0.6332376]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 464 is [True, False, False, False, False, True]
State prediction error at timestep 464 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 464 of -1
Current timestep = 465. State = [[-0.16051832  0.36434722]]. Action = [[0.        0.        0.        0.8887577]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 465 is [True, False, False, False, False, True]
State prediction error at timestep 465 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 465 of -1
Current timestep = 466. State = [[-0.16051775  0.36434928]]. Action = [[0.         0.         0.         0.58135915]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 466 is [True, False, False, False, False, True]
State prediction error at timestep 466 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 466 of -1
Current timestep = 467. State = [[-0.1605172  0.3643513]]. Action = [[0.         0.         0.         0.47221017]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 467 is [True, False, False, False, False, True]
State prediction error at timestep 467 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 467 of -1
Current timestep = 468. State = [[-0.16051666  0.3643533 ]]. Action = [[ 0.         0.         0.        -0.4164039]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 468 is [True, False, False, False, False, True]
State prediction error at timestep 468 is tensor(6.5102e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 468 of -1
Current timestep = 469. State = [[-0.16051611  0.3643553 ]]. Action = [[0.         0.         0.         0.90955865]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 469 is [True, False, False, False, False, True]
State prediction error at timestep 469 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 469 of -1
Current timestep = 470. State = [[-0.16051558  0.3643573 ]]. Action = [[ 0.         0.         0.        -0.8420554]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 470 is [True, False, False, False, False, True]
State prediction error at timestep 470 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 470 of -1
Current timestep = 471. State = [[-0.16051506  0.36435926]]. Action = [[ 0.          0.          0.         -0.45486003]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 471 is [True, False, False, False, False, True]
State prediction error at timestep 471 is tensor(6.9157e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 471 of -1
Current timestep = 472. State = [[-0.16051452  0.3643612 ]]. Action = [[ 0.          0.          0.         -0.27352202]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 472 is [True, False, False, False, False, True]
State prediction error at timestep 472 is tensor(6.8876e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 472 of -1
Current timestep = 473. State = [[-0.160514   0.3643631]]. Action = [[0.        0.        0.        0.8521826]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 473 is [True, False, False, False, False, True]
State prediction error at timestep 473 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 473 of -1
Current timestep = 474. State = [[-0.16051349  0.36436504]]. Action = [[ 0.          0.          0.         -0.48906738]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 474 is [True, False, False, False, False, True]
State prediction error at timestep 474 is tensor(8.4014e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 474 of -1
Current timestep = 475. State = [[-0.16051297  0.36436692]]. Action = [[ 0.          0.          0.         -0.81449246]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 475 is [True, False, False, False, False, True]
State prediction error at timestep 475 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 475 of -1
Current timestep = 476. State = [[-0.16051246  0.3643688 ]]. Action = [[ 0.          0.          0.         -0.44033217]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 476 is [True, False, False, False, False, True]
State prediction error at timestep 476 is tensor(8.4077e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 476 of -1
Current timestep = 477. State = [[-0.16051197  0.36437064]]. Action = [[ 0.         0.         0.        -0.4698329]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 477 is [True, False, False, False, False, True]
State prediction error at timestep 477 is tensor(8.4127e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 477 of -1
Current timestep = 478. State = [[-0.16051146  0.3643725 ]]. Action = [[0.         0.         0.         0.41119623]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 478 is [True, False, False, False, False, True]
State prediction error at timestep 478 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 478 of -1
Current timestep = 479. State = [[-0.16051097  0.36437434]]. Action = [[ 0.          0.          0.         -0.38336653]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 479 is [True, False, False, False, False, True]
State prediction error at timestep 479 is tensor(7.7512e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 479 of -1
Current timestep = 480. State = [[-0.16051048  0.36437613]]. Action = [[0.         0.         0.         0.37579477]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 480 is [True, False, False, False, False, True]
State prediction error at timestep 480 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 480 of -1
Current timestep = 481. State = [[-0.16051     0.36437795]]. Action = [[ 0.         0.         0.        -0.9242843]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 481 is [True, False, False, False, False, True]
State prediction error at timestep 481 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 481 of -1
Current timestep = 482. State = [[-0.16050951  0.3643797 ]]. Action = [[ 0.         0.         0.        -0.8889579]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 482 is [True, False, False, False, False, True]
State prediction error at timestep 482 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 482 of -1
Current timestep = 483. State = [[-0.16050903  0.3643815 ]]. Action = [[0.         0.         0.         0.74254227]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 483 is [True, False, False, False, False, True]
State prediction error at timestep 483 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 483 of -1
Current timestep = 484. State = [[-0.16050857  0.36438322]]. Action = [[0.        0.        0.        0.8688258]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 484 is [True, False, False, False, False, True]
State prediction error at timestep 484 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 484 of -1
Current timestep = 485. State = [[-0.1605081   0.36438495]]. Action = [[0.         0.         0.         0.06038952]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 485 is [True, False, False, False, False, True]
State prediction error at timestep 485 is tensor(8.0855e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 485 of -1
Current timestep = 486. State = [[-0.16050763  0.36438668]]. Action = [[0.        0.        0.        0.4632485]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 486 is [True, False, False, False, False, True]
State prediction error at timestep 486 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 486 of -1
Current timestep = 487. State = [[-0.16050719  0.36438838]]. Action = [[0.        0.        0.        0.6499336]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 487 is [True, False, False, False, False, True]
State prediction error at timestep 487 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 487 of -1
Current timestep = 488. State = [[-0.16050673  0.36439008]]. Action = [[ 0.          0.          0.         -0.21161675]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 488 is [True, False, False, False, False, True]
State prediction error at timestep 488 is tensor(4.8766e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 488 of -1
Current timestep = 489. State = [[-0.16050628  0.36439174]]. Action = [[ 0.         0.         0.        -0.6363207]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 489 is [True, False, False, False, False, True]
State prediction error at timestep 489 is tensor(7.9985e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 489 of -1
Current timestep = 490. State = [[-0.16050583  0.3643934 ]]. Action = [[0.         0.         0.         0.93753874]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 490 is [True, False, False, False, False, True]
State prediction error at timestep 490 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 490 of -1
Current timestep = 491. State = [[-0.16050538  0.36439505]]. Action = [[ 0.         0.         0.        -0.6439882]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 491 is [True, False, False, False, False, True]
State prediction error at timestep 491 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 491 of -1
Current timestep = 492. State = [[-0.16050495  0.36439666]]. Action = [[ 0.         0.         0.        -0.4835863]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 492 is [True, False, False, False, False, True]
State prediction error at timestep 492 is tensor(8.5997e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 492 of -1
Current timestep = 493. State = [[-0.16050452  0.3643983 ]]. Action = [[0.        0.        0.        0.7280729]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 493 is [True, False, False, False, False, True]
State prediction error at timestep 493 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 493 of -1
Current timestep = 494. State = [[-0.16050409  0.36439988]]. Action = [[0.         0.         0.         0.54709077]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 494 is [True, False, False, False, False, True]
State prediction error at timestep 494 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 494 of -1
Current timestep = 495. State = [[-0.16050366  0.36440146]]. Action = [[ 0.        0.        0.       -0.606848]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 495 is [True, False, False, False, False, True]
State prediction error at timestep 495 is tensor(7.8738e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 495 of -1
Current timestep = 496. State = [[-0.16050324  0.36440304]]. Action = [[0.         0.         0.         0.72983277]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 496 is [True, False, False, False, False, True]
State prediction error at timestep 496 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 496 of -1
Current timestep = 497. State = [[-0.16050282  0.36440462]]. Action = [[0.         0.         0.         0.35793662]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 497 is [True, False, False, False, False, True]
State prediction error at timestep 497 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 497 of -1
Current timestep = 498. State = [[-0.1605024   0.36440614]]. Action = [[ 0.          0.          0.         -0.71756387]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 498 is [True, False, False, False, False, True]
State prediction error at timestep 498 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 498 of -1
Current timestep = 499. State = [[-0.160502   0.3644077]]. Action = [[0.        0.        0.        0.0532974]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 499 is [True, False, False, False, False, True]
State prediction error at timestep 499 is tensor(6.5136e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 499 of -1
Current timestep = 500. State = [[-0.16050158  0.3644092 ]]. Action = [[0.        0.        0.        0.4783069]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 500 is [True, False, False, False, False, True]
State prediction error at timestep 500 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 500 of -1
Current timestep = 501. State = [[-0.16050118  0.3644107 ]]. Action = [[0.        0.        0.        0.3063476]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 501 is [True, False, False, False, False, True]
State prediction error at timestep 501 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 501 of -1
Current timestep = 502. State = [[-0.16050078  0.3644122 ]]. Action = [[ 0.         0.         0.        -0.7804261]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 502 is [True, False, False, False, False, True]
State prediction error at timestep 502 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 502 of -1
Current timestep = 503. State = [[-0.16050039  0.36441368]]. Action = [[0.        0.        0.        0.4605019]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 503 is [True, False, False, False, False, True]
State prediction error at timestep 503 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 503 of -1
Current timestep = 504. State = [[-0.1605      0.36441514]]. Action = [[ 0.         0.         0.        -0.6357685]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 504 is [True, False, False, False, False, True]
State prediction error at timestep 504 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 504 of -1
Current timestep = 505. State = [[-0.1604996  0.3644166]]. Action = [[0.         0.         0.         0.79704356]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 505 is [True, False, False, False, False, True]
State prediction error at timestep 505 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 505 of -1
Current timestep = 506. State = [[-0.16049923  0.36441803]]. Action = [[ 0.          0.          0.         -0.10894066]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 506 is [True, False, False, False, False, True]
State prediction error at timestep 506 is tensor(5.3459e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 506 of -1
Current timestep = 507. State = [[-0.16049884  0.36441946]]. Action = [[ 0.          0.          0.         -0.15240788]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 507 is [True, False, False, False, False, True]
State prediction error at timestep 507 is tensor(6.4530e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 507 of -1
Current timestep = 508. State = [[-0.16049847  0.3644209 ]]. Action = [[0.        0.        0.        0.8730521]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 508 is [True, False, False, False, False, True]
State prediction error at timestep 508 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 508 of -1
Current timestep = 509. State = [[-0.1604981  0.3644223]]. Action = [[ 0.          0.          0.         -0.96890813]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 509 is [True, False, False, False, False, True]
State prediction error at timestep 509 is tensor(9.2074e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 509 of -1
Current timestep = 510. State = [[-0.16049773  0.36442366]]. Action = [[ 0.          0.          0.         -0.20282602]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 510 is [True, False, False, False, False, True]
State prediction error at timestep 510 is tensor(5.2918e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 510 of -1
Current timestep = 511. State = [[-0.16049735  0.36442503]]. Action = [[ 0.         0.         0.        -0.4395532]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 511 is [True, False, False, False, False, True]
State prediction error at timestep 511 is tensor(8.2433e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 511 of -1
Current timestep = 512. State = [[-0.160497   0.3644264]]. Action = [[ 0.          0.          0.         -0.95745987]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 512 is [True, False, False, False, False, True]
State prediction error at timestep 512 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 512 of -1
Current timestep = 513. State = [[-0.16049662  0.36442778]]. Action = [[0.         0.         0.         0.55723786]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 513 is [True, False, False, False, False, True]
State prediction error at timestep 513 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 513 of -1
Current timestep = 514. State = [[-0.16049626  0.36442912]]. Action = [[0.        0.        0.        0.9030049]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 514 is [True, False, False, False, False, True]
State prediction error at timestep 514 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 514 of -1
Current timestep = 515. State = [[-0.16049592  0.36443043]]. Action = [[ 0.         0.         0.        -0.9159209]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 515 is [True, False, False, False, False, True]
State prediction error at timestep 515 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 515 of -1
Current timestep = 516. State = [[-0.16049556  0.36443177]]. Action = [[ 0.          0.          0.         -0.64068407]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 516 is [True, False, False, False, False, True]
State prediction error at timestep 516 is tensor(9.4898e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 516 of -1
Current timestep = 517. State = [[-0.16049522  0.36443305]]. Action = [[0.        0.        0.        0.2967435]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 517 is [True, False, False, False, False, True]
State prediction error at timestep 517 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 517 of -1
Current timestep = 518. State = [[-0.16049488  0.36443436]]. Action = [[0.         0.         0.         0.17833948]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 518 is [True, False, False, False, False, True]
State prediction error at timestep 518 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 518 of -1
Current timestep = 519. State = [[-0.16049454  0.36443564]]. Action = [[ 0.          0.          0.         -0.76105946]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 519 is [True, False, False, False, False, True]
State prediction error at timestep 519 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 519 of -1
Current timestep = 520. State = [[-0.1604942   0.36443692]]. Action = [[ 0.         0.         0.        -0.5565116]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 520 is [True, False, False, False, False, True]
State prediction error at timestep 520 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 520 of -1
Current timestep = 521. State = [[-0.16049387  0.36443818]]. Action = [[0.         0.         0.         0.21671021]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 521 is [True, False, False, False, False, True]
State prediction error at timestep 521 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 521 of -1
Current timestep = 522. State = [[-0.16049352  0.36443943]]. Action = [[0.        0.        0.        0.9254383]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 522 is [True, False, False, False, False, True]
State prediction error at timestep 522 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 522 of -1
Current timestep = 523. State = [[-0.1604932   0.36444068]]. Action = [[0.        0.        0.        0.7988925]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 523 is [True, False, False, False, False, True]
State prediction error at timestep 523 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 523 of -1
Current timestep = 524. State = [[-0.16049287  0.3644419 ]]. Action = [[0.         0.         0.         0.40824163]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 524 is [True, False, False, False, False, True]
State prediction error at timestep 524 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 524 of -1
Current timestep = 525. State = [[-0.16049255  0.36444312]]. Action = [[ 0.          0.          0.         -0.06315058]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 525 is [True, False, False, False, False, True]
State prediction error at timestep 525 is tensor(3.9325e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 525 of -1
Current timestep = 526. State = [[-0.16049223  0.36444432]]. Action = [[ 0.        0.        0.       -0.962421]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 526 is [True, False, False, False, False, True]
State prediction error at timestep 526 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 526 of -1
Current timestep = 527. State = [[-0.16049191  0.3644455 ]]. Action = [[0.         0.         0.         0.17024064]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 527 is [True, False, False, False, False, True]
State prediction error at timestep 527 is tensor(8.2855e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 527 of -1
Current timestep = 528. State = [[-0.1604916  0.3644467]]. Action = [[ 0.          0.          0.         -0.69375557]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 528 is [True, False, False, False, False, True]
State prediction error at timestep 528 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 528 of -1
Current timestep = 529. State = [[-0.16049129  0.3644479 ]]. Action = [[0.        0.        0.        0.5871321]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 529 is [True, False, False, False, False, True]
State prediction error at timestep 529 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 529 of -1
Current timestep = 530. State = [[-0.16049097  0.36444905]]. Action = [[0.        0.        0.        0.7452359]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 530 is [True, False, False, False, False, True]
State prediction error at timestep 530 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 530 of -1
Current timestep = 531. State = [[-0.16049068  0.3644502 ]]. Action = [[0.        0.        0.        0.8807553]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 531 is [True, False, False, False, False, True]
State prediction error at timestep 531 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 531 of -1
Current timestep = 532. State = [[-0.16049038  0.36445135]]. Action = [[0.         0.         0.         0.12171412]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 532 is [True, False, False, False, False, True]
State prediction error at timestep 532 is tensor(4.0062e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 532 of -1
Current timestep = 533. State = [[-0.16049008  0.36445248]]. Action = [[ 0.          0.          0.         -0.20638639]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 533 is [True, False, False, False, False, True]
State prediction error at timestep 533 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 533 of -1
Current timestep = 534. State = [[-0.16048978  0.3644536 ]]. Action = [[ 0.          0.          0.         -0.14587939]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 534 is [True, False, False, False, False, True]
State prediction error at timestep 534 is tensor(9.1208e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 534 of -1
Current timestep = 535. State = [[-0.16048948  0.36445472]]. Action = [[0.        0.        0.        0.8339369]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 535 is [True, False, False, False, False, True]
State prediction error at timestep 535 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 535 of -1
Current timestep = 536. State = [[-0.16048919  0.36445582]]. Action = [[0.        0.        0.        0.8299202]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 536 is [True, False, False, False, False, True]
State prediction error at timestep 536 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 536 of -1
Current timestep = 537. State = [[-0.1604889   0.36445692]]. Action = [[ 0.         0.         0.        -0.7004384]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 537 is [True, False, False, False, False, True]
State prediction error at timestep 537 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 537 of -1
Current timestep = 538. State = [[-0.16048862  0.36445802]]. Action = [[0.         0.         0.         0.38867044]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 538 is [True, False, False, False, False, True]
State prediction error at timestep 538 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 538 of -1
Current timestep = 539. State = [[-0.16048834  0.3644591 ]]. Action = [[ 0.         0.         0.        -0.9669245]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 539 is [True, False, False, False, False, True]
State prediction error at timestep 539 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 539 of -1
Current timestep = 540. State = [[-0.16048805  0.36446014]]. Action = [[ 0.         0.         0.        -0.5994326]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 540 is [True, False, False, False, False, True]
State prediction error at timestep 540 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 540 of -1
Current timestep = 541. State = [[-0.16048777  0.3644612 ]]. Action = [[ 0.         0.         0.        -0.4597714]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 541 is [True, False, False, False, False, True]
State prediction error at timestep 541 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 541 of -1
Current timestep = 542. State = [[-0.1604875   0.36446226]]. Action = [[ 0.         0.         0.        -0.9391753]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 542 is [True, False, False, False, False, True]
State prediction error at timestep 542 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 542 of -1
Current timestep = 543. State = [[-0.16048723  0.3644633 ]]. Action = [[0.         0.         0.         0.72746456]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 543 is [True, False, False, False, False, True]
State prediction error at timestep 543 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 543 of -1
Current timestep = 544. State = [[-0.16048697  0.36446434]]. Action = [[ 0.         0.         0.        -0.7503204]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 544 is [True, False, False, False, False, True]
State prediction error at timestep 544 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 544 of -1
Current timestep = 545. State = [[-0.1604867   0.36446536]]. Action = [[0.        0.        0.        0.7835982]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 545 is [True, False, False, False, False, True]
State prediction error at timestep 545 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 545 of -1
Current timestep = 546. State = [[-0.16048643  0.36446637]]. Action = [[ 0.          0.          0.         -0.28624034]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 546 is [True, False, False, False, False, True]
State prediction error at timestep 546 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 546 of -1
Current timestep = 547. State = [[-0.16048616  0.36446738]]. Action = [[0.         0.         0.         0.18007231]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 547 is [True, False, False, False, False, True]
State prediction error at timestep 547 is tensor(7.3642e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 547 of -1
Current timestep = 548. State = [[-0.16048591  0.36446837]]. Action = [[0.         0.         0.         0.51910245]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 548 is [True, False, False, False, False, True]
State prediction error at timestep 548 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 548 of -1
Current timestep = 549. State = [[-0.16048564  0.36446935]]. Action = [[0.         0.         0.         0.04754496]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 549 is [True, False, False, False, False, True]
State prediction error at timestep 549 is tensor(2.2353e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 549 of -1
Current timestep = 550. State = [[-0.16048539  0.36447033]]. Action = [[ 0.          0.          0.         -0.05319291]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 550 is [True, False, False, False, False, True]
State prediction error at timestep 550 is tensor(5.3178e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 550 of -1
Current timestep = 551. State = [[-0.16048513  0.3644713 ]]. Action = [[ 0.          0.          0.         -0.00290382]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 551 is [True, False, False, False, False, True]
State prediction error at timestep 551 is tensor(3.4547e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 551 of -1
Current timestep = 552. State = [[-0.16048488  0.36447227]]. Action = [[ 0.          0.          0.         -0.89354837]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 552 is [True, False, False, False, False, True]
State prediction error at timestep 552 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 552 of -1
Current timestep = 553. State = [[-0.16048464  0.36447322]]. Action = [[ 0.          0.          0.         -0.09094656]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 553 is [True, False, False, False, False, True]
State prediction error at timestep 553 is tensor(8.8306e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 553 of -1
Current timestep = 554. State = [[-0.16048439  0.36447415]]. Action = [[ 0.          0.          0.         -0.16217524]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 554 is [True, False, False, False, False, True]
State prediction error at timestep 554 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 554 of -1
Current timestep = 555. State = [[-0.16048415  0.3644751 ]]. Action = [[ 0.          0.          0.         -0.88569695]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 555 is [True, False, False, False, False, True]
State prediction error at timestep 555 is tensor(8.8811e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 555 of -1
Current timestep = 556. State = [[-0.16048391  0.36447603]]. Action = [[ 0.        0.        0.       -0.459764]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 556 is [True, False, False, False, False, True]
State prediction error at timestep 556 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 556 of -1
Current timestep = 557. State = [[-0.16048367  0.36447695]]. Action = [[0.         0.         0.         0.16047096]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 557 is [True, False, False, False, False, True]
State prediction error at timestep 557 is tensor(4.3405e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 557 of -1
Current timestep = 558. State = [[-0.16048343  0.36447784]]. Action = [[ 0.          0.          0.         -0.22315603]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 558 is [True, False, False, False, False, True]
State prediction error at timestep 558 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 558 of -1
Current timestep = 559. State = [[-0.1604832   0.36447874]]. Action = [[0.        0.        0.        0.7899771]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 559 is [True, False, False, False, False, True]
State prediction error at timestep 559 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 559 of -1
Current timestep = 560. State = [[-0.16048296  0.36447963]]. Action = [[0.        0.        0.        0.6725073]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 560 is [True, False, False, False, False, True]
State prediction error at timestep 560 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 560 of -1
Current timestep = 561. State = [[-0.16048273  0.36448053]]. Action = [[ 0.         0.         0.        -0.9334449]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 561 is [True, False, False, False, False, True]
State prediction error at timestep 561 is tensor(9.0059e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 561 of -1
Current timestep = 562. State = [[-0.16048251  0.36448142]]. Action = [[0.         0.         0.         0.73230386]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 562 is [True, False, False, False, False, True]
State prediction error at timestep 562 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 562 of -1
Current timestep = 563. State = [[-0.16048227  0.36448228]]. Action = [[ 0.          0.          0.         -0.22979093]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 563 is [True, False, False, False, False, True]
State prediction error at timestep 563 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 563 of -1
Current timestep = 564. State = [[-0.16048205  0.36448315]]. Action = [[0.         0.         0.         0.03817797]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 564 is [True, False, False, False, False, True]
State prediction error at timestep 564 is tensor(1.5931e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 564 of -1
Current timestep = 565. State = [[-0.16048184  0.364484  ]]. Action = [[0.        0.        0.        0.5606903]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 565 is [True, False, False, False, False, True]
State prediction error at timestep 565 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 565 of -1
Current timestep = 566. State = [[-0.16048162  0.36448485]]. Action = [[0.         0.         0.         0.50843644]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 566 is [True, False, False, False, False, True]
State prediction error at timestep 566 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 566 of -1
Current timestep = 567. State = [[-0.1604814  0.3644857]]. Action = [[ 0.          0.          0.         -0.40147614]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 567 is [True, False, False, False, False, True]
State prediction error at timestep 567 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 567 of -1
Current timestep = 568. State = [[-0.16048118  0.36448655]]. Action = [[0.         0.         0.         0.31817627]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 568 is [True, False, False, False, False, True]
State prediction error at timestep 568 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 568 of -1
Current timestep = 569. State = [[-0.16048096  0.36448735]]. Action = [[0.        0.        0.        0.6203221]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 569 is [True, False, False, False, False, True]
State prediction error at timestep 569 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 569 of -1
Current timestep = 570. State = [[-0.16048075  0.36448818]]. Action = [[0.         0.         0.         0.65340745]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 570 is [True, False, False, False, False, True]
State prediction error at timestep 570 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 570 of -1
Current timestep = 571. State = [[-0.16048054  0.364489  ]]. Action = [[ 0.          0.          0.         -0.07661211]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 571 is [True, False, False, False, False, True]
State prediction error at timestep 571 is tensor(8.8151e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 571 of -1
Current timestep = 572. State = [[-0.16048034  0.3644898 ]]. Action = [[ 0.          0.          0.         -0.20049226]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 572 is [True, False, False, False, False, True]
State prediction error at timestep 572 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 572 of -1
Current timestep = 573. State = [[-0.16048013  0.3644906 ]]. Action = [[ 0.          0.          0.         -0.85362554]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 573 is [True, False, False, False, False, True]
State prediction error at timestep 573 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 573 of -1
Current timestep = 574. State = [[-0.16047993  0.3644914 ]]. Action = [[0.        0.        0.        0.3786143]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 574 is [True, False, False, False, False, True]
State prediction error at timestep 574 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 574 of -1
Current timestep = 575. State = [[-0.16047972  0.36449218]]. Action = [[ 0.         0.         0.        -0.5636531]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 575 is [True, False, False, False, False, True]
State prediction error at timestep 575 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 575 of -1
Current timestep = 576. State = [[-0.16047953  0.36449295]]. Action = [[0.        0.        0.        0.4546529]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 576 is [True, False, False, False, False, True]
State prediction error at timestep 576 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 576 of -1
Current timestep = 577. State = [[-0.16047934  0.36449373]]. Action = [[ 0.         0.         0.        -0.5292726]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 577 is [True, False, False, False, False, True]
State prediction error at timestep 577 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 577 of -1
Current timestep = 578. State = [[-0.16047913  0.3644945 ]]. Action = [[0.        0.        0.        0.6145737]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 578 is [True, False, False, False, False, True]
State prediction error at timestep 578 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 578 of -1
Current timestep = 579. State = [[-0.16047893  0.36449525]]. Action = [[0.         0.         0.         0.10423553]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 579 is [True, False, False, False, False, True]
State prediction error at timestep 579 is tensor(1.2668e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 579 of -1
Current timestep = 580. State = [[-0.16047874  0.364496  ]]. Action = [[ 0.         0.         0.        -0.3242805]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 580 is [True, False, False, False, False, True]
State prediction error at timestep 580 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 580 of -1
Current timestep = 581. State = [[-0.16047856  0.36449674]]. Action = [[0.         0.         0.         0.74027205]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 581 is [True, False, False, False, False, True]
State prediction error at timestep 581 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 581 of -1
Current timestep = 582. State = [[-0.16047837  0.36449748]]. Action = [[ 0.         0.         0.        -0.7260006]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 582 is [True, False, False, False, False, True]
State prediction error at timestep 582 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 582 of -1
Current timestep = 583. State = [[-0.16047817  0.36449823]]. Action = [[ 0.          0.          0.         -0.40672982]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 583 is [True, False, False, False, False, True]
State prediction error at timestep 583 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 583 of -1
Current timestep = 584. State = [[-0.160478    0.36449894]]. Action = [[0.         0.         0.         0.20813835]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 584 is [True, False, False, False, False, True]
State prediction error at timestep 584 is tensor(3.8129e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 584 of -1
Current timestep = 585. State = [[-0.16047782  0.36449966]]. Action = [[ 0.          0.          0.         -0.04491109]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 585 is [True, False, False, False, False, True]
State prediction error at timestep 585 is tensor(6.9816e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 585 of -1
Current timestep = 586. State = [[-0.16047764  0.36450037]]. Action = [[0.         0.         0.         0.26233435]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 586 is [True, False, False, False, False, True]
State prediction error at timestep 586 is tensor(6.9423e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 586 of -1
Current timestep = 587. State = [[-0.16047744  0.3645011 ]]. Action = [[0.         0.         0.         0.30455875]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 587 is [True, False, False, False, False, True]
State prediction error at timestep 587 is tensor(9.4663e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 587 of -1
Current timestep = 588. State = [[-0.16047727  0.36450177]]. Action = [[0.        0.        0.        0.6991911]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 588 is [True, False, False, False, False, True]
State prediction error at timestep 588 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 588 of -1
Current timestep = 589. State = [[-0.1604771  0.3645025]]. Action = [[0.         0.         0.         0.86013424]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 589 is [True, False, False, False, False, True]
State prediction error at timestep 589 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 589 of -1
Current timestep = 590. State = [[-0.16047692  0.36450318]]. Action = [[ 0.          0.          0.         -0.59748125]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 590 is [True, False, False, False, False, True]
State prediction error at timestep 590 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 590 of -1
Current timestep = 591. State = [[-0.16047674  0.36450386]]. Action = [[ 0.         0.         0.        -0.1676271]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 591 is [True, False, False, False, False, True]
State prediction error at timestep 591 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 591 of -1
Current timestep = 592. State = [[-0.16047658  0.36450452]]. Action = [[0.        0.        0.        0.1473434]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 592 is [True, False, False, False, False, True]
State prediction error at timestep 592 is tensor(1.5762e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 592 of -1
Current timestep = 593. State = [[-0.1604764  0.3645052]]. Action = [[ 0.          0.          0.         -0.99452937]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 593 is [True, False, False, False, False, True]
State prediction error at timestep 593 is tensor(6.8437e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 593 of -1
Current timestep = 594. State = [[-0.16047624  0.36450586]]. Action = [[ 0.          0.          0.         -0.26837194]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 594 is [True, False, False, False, False, True]
State prediction error at timestep 594 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 594 of -1
Current timestep = 595. State = [[-0.16047607  0.3645065 ]]. Action = [[ 0.         0.         0.        -0.6931415]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 595 is [True, False, False, False, False, True]
State prediction error at timestep 595 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 595 of -1
Current timestep = 596. State = [[-0.16047591  0.36450717]]. Action = [[ 0.          0.          0.         -0.47436833]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 596 is [True, False, False, False, False, True]
State prediction error at timestep 596 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 596 of -1
Current timestep = 597. State = [[-0.16047575  0.36450782]]. Action = [[ 0.          0.          0.         -0.64429134]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 597 is [True, False, False, False, False, True]
State prediction error at timestep 597 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 597 of -1
Current timestep = 598. State = [[-0.16047558  0.36450848]]. Action = [[ 0.          0.          0.         -0.44294715]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 598 is [True, False, False, False, False, True]
State prediction error at timestep 598 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 598 of -1
Current timestep = 599. State = [[-0.16047542  0.3645091 ]]. Action = [[ 0.          0.          0.         -0.93026686]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 599 is [True, False, False, False, False, True]
State prediction error at timestep 599 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 599 of -1
Current timestep = 600. State = [[-0.16047527  0.36450973]]. Action = [[ 0.         0.         0.        -0.7782893]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 600 is [True, False, False, False, False, True]
State prediction error at timestep 600 is tensor(9.5258e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 600 of -1
Current timestep = 601. State = [[-0.1604751   0.36451036]]. Action = [[ 0.          0.          0.         -0.80734515]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 601 is [True, False, False, False, False, True]
State prediction error at timestep 601 is tensor(9.0249e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 601 of -1
Current timestep = 602. State = [[-0.16047496  0.36451098]]. Action = [[ 0.        0.        0.       -0.549729]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 602 is [True, False, False, False, False, True]
State prediction error at timestep 602 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 602 of -1
Current timestep = 603. State = [[-0.16047479  0.3645116 ]]. Action = [[ 0.          0.          0.         -0.85921824]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 603 is [True, False, False, False, False, True]
State prediction error at timestep 603 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 603 of -1
Current timestep = 604. State = [[-0.16047464  0.3645122 ]]. Action = [[0.         0.         0.         0.39411402]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 604 is [True, False, False, False, False, True]
State prediction error at timestep 604 is tensor(8.1811e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 604 of -1
Current timestep = 605. State = [[-0.1604745  0.3645128]]. Action = [[0.         0.         0.         0.01446915]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 605 is [True, False, False, False, False, True]
State prediction error at timestep 605 is tensor(3.2727e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 605 of -1
Current timestep = 606. State = [[-0.16047435  0.3645134 ]]. Action = [[0.         0.         0.         0.71205354]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 606 is [True, False, False, False, False, True]
State prediction error at timestep 606 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 606 of -1
Current timestep = 607. State = [[-0.1604742  0.364514 ]]. Action = [[ 0.         0.         0.        -0.5919237]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 607 is [True, False, False, False, False, True]
State prediction error at timestep 607 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 607 of -1
Current timestep = 608. State = [[-0.16047405  0.3645146 ]]. Action = [[ 0.          0.          0.         -0.73383105]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 608 is [True, False, False, False, False, True]
State prediction error at timestep 608 is tensor(9.0270e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 608 of -1
Current timestep = 609. State = [[-0.1604739  0.3645152]]. Action = [[0.         0.         0.         0.09851658]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 609 is [True, False, False, False, False, True]
State prediction error at timestep 609 is tensor(2.2959e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 609 of -1
Current timestep = 610. State = [[-0.16047375  0.36451575]]. Action = [[0.        0.        0.        0.4688642]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 610 is [True, False, False, False, False, True]
State prediction error at timestep 610 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 610 of -1
Current timestep = 611. State = [[-0.16047361  0.36451632]]. Action = [[0.         0.         0.         0.13070941]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 611 is [True, False, False, False, False, True]
State prediction error at timestep 611 is tensor(7.7554e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 611 of -1
Current timestep = 612. State = [[-0.16047347  0.36451688]]. Action = [[ 0.         0.         0.        -0.4322734]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 612 is [True, False, False, False, False, True]
State prediction error at timestep 612 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 612 of -1
Current timestep = 613. State = [[-0.16047333  0.36451745]]. Action = [[ 0.         0.         0.        -0.3120215]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 613 is [True, False, False, False, False, True]
State prediction error at timestep 613 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 613 of -1
Current timestep = 614. State = [[-0.1604732   0.36451802]]. Action = [[ 0.         0.         0.        -0.7704697]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 614 is [True, False, False, False, False, True]
State prediction error at timestep 614 is tensor(8.9952e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 614 of -1
Current timestep = 615. State = [[-0.16047305  0.36451858]]. Action = [[0.         0.         0.         0.86611557]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 615 is [True, False, False, False, False, True]
State prediction error at timestep 615 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 615 of -1
Current timestep = 616. State = [[-0.16047291  0.36451912]]. Action = [[ 0.         0.         0.        -0.5701419]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 616 is [True, False, False, False, False, True]
State prediction error at timestep 616 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 616 of -1
Current timestep = 617. State = [[-0.16047278  0.36451966]]. Action = [[ 0.         0.         0.        -0.7294991]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 617 is [True, False, False, False, False, True]
State prediction error at timestep 617 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 617 of -1
Current timestep = 618. State = [[-0.16047265  0.36452022]]. Action = [[0.        0.        0.        0.7482507]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 618 is [True, False, False, False, False, True]
State prediction error at timestep 618 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 618 of -1
Current timestep = 619. State = [[-0.16047251  0.36452073]]. Action = [[ 0.         0.         0.        -0.9464555]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 619 is [True, False, False, False, False, True]
State prediction error at timestep 619 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 619 of -1
Current timestep = 620. State = [[-0.1604724   0.36452127]]. Action = [[0.         0.         0.         0.40280783]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 620 is [True, False, False, False, False, True]
State prediction error at timestep 620 is tensor(9.2799e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 620 of -1
Current timestep = 621. State = [[-0.16047226  0.3645218 ]]. Action = [[ 0.         0.         0.        -0.5226468]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 621 is [True, False, False, False, False, True]
State prediction error at timestep 621 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 621 of -1
Current timestep = 622. State = [[-0.16047212  0.3645223 ]]. Action = [[ 0.          0.          0.         -0.52627933]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 622 is [True, False, False, False, False, True]
State prediction error at timestep 622 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 622 of -1
Current timestep = 623. State = [[-0.160472    0.36452284]]. Action = [[0.         0.         0.         0.31083107]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 623 is [True, False, False, False, False, True]
State prediction error at timestep 623 is tensor(8.0170e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 623 of -1
Current timestep = 624. State = [[-0.16047187  0.36452335]]. Action = [[0.        0.        0.        0.7219341]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 624 is [True, False, False, False, False, True]
State prediction error at timestep 624 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 624 of -1
Current timestep = 625. State = [[-0.16047175  0.36452386]]. Action = [[ 0.         0.         0.        -0.2174781]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 625 is [True, False, False, False, False, True]
State prediction error at timestep 625 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 625 of -1
Current timestep = 626. State = [[-0.16047163  0.36452436]]. Action = [[0.       0.       0.       0.641742]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 626 is [True, False, False, False, False, True]
State prediction error at timestep 626 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 626 of -1
Current timestep = 627. State = [[-0.16047151  0.36452487]]. Action = [[ 0.          0.          0.         -0.91234654]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 627 is [True, False, False, False, False, True]
State prediction error at timestep 627 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 627 of -1
Current timestep = 628. State = [[-0.16047138  0.36452535]]. Action = [[ 0.          0.          0.         -0.33041108]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 628 is [True, False, False, False, False, True]
State prediction error at timestep 628 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 628 of -1
Current timestep = 629. State = [[-0.16047126  0.36452585]]. Action = [[0.         0.         0.         0.10108316]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 629 is [True, False, False, False, False, True]
State prediction error at timestep 629 is tensor(1.9636e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 629 of -1
Current timestep = 630. State = [[-0.16047114  0.36452633]]. Action = [[0.         0.         0.         0.53758264]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 630 is [True, False, False, False, False, True]
State prediction error at timestep 630 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 630 of -1
Current timestep = 631. State = [[-0.16047102  0.3645268 ]]. Action = [[0.        0.        0.        0.8661151]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 631 is [True, False, False, False, False, True]
State prediction error at timestep 631 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 631 of -1
Current timestep = 632. State = [[-0.16047092  0.3645273 ]]. Action = [[ 0.         0.         0.        -0.9745148]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 632 is [True, False, False, False, False, True]
State prediction error at timestep 632 is tensor(7.9261e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 632 of -1
Current timestep = 633. State = [[-0.1604708   0.36452776]]. Action = [[ 0.          0.          0.         -0.48796022]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 633 is [True, False, False, False, False, True]
State prediction error at timestep 633 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 633 of -1
Current timestep = 634. State = [[-0.16047068  0.36452824]]. Action = [[ 0.         0.         0.        -0.2990117]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 634 is [True, False, False, False, False, True]
State prediction error at timestep 634 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 634 of -1
Current timestep = 635. State = [[-0.16047058  0.36452872]]. Action = [[ 0.         0.         0.        -0.9040153]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 635 is [True, False, False, False, False, True]
State prediction error at timestep 635 is tensor(8.0511e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 635 of -1
Current timestep = 636. State = [[-0.16047046  0.36452916]]. Action = [[0.       0.       0.       0.452729]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 636 is [True, False, False, False, False, True]
State prediction error at timestep 636 is tensor(9.6597e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 636 of -1
Current timestep = 637. State = [[-0.16047035  0.3645296 ]]. Action = [[0.        0.        0.        0.5270866]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 637 is [True, False, False, False, False, True]
State prediction error at timestep 637 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 637 of -1
Current timestep = 638. State = [[-0.16047023  0.3645301 ]]. Action = [[ 0.         0.         0.        -0.6168689]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 638 is [True, False, False, False, False, True]
State prediction error at timestep 638 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 638 of -1
Current timestep = 639. State = [[-0.16047013  0.36453053]]. Action = [[0.        0.        0.        0.0184952]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 639 is [True, False, False, False, False, True]
State prediction error at timestep 639 is tensor(2.4437e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 639 of -1
Current timestep = 640. State = [[-0.16047002  0.36453098]]. Action = [[0.         0.         0.         0.88429797]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 640 is [True, False, False, False, False, True]
State prediction error at timestep 640 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 640 of -1
Current timestep = 641. State = [[-0.16046992  0.36453143]]. Action = [[ 0.         0.         0.        -0.7987008]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 641 is [True, False, False, False, False, True]
State prediction error at timestep 641 is tensor(8.9019e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 641 of -1
Current timestep = 642. State = [[-0.16046982  0.36453184]]. Action = [[ 0.          0.          0.         -0.60850656]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 642 is [True, False, False, False, False, True]
State prediction error at timestep 642 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 642 of -1
Current timestep = 643. State = [[-0.16046971  0.3645323 ]]. Action = [[0.         0.         0.         0.06486034]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 643 is [True, False, False, False, False, True]
State prediction error at timestep 643 is tensor(1.2048e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 643 of -1
Current timestep = 644. State = [[-0.1604696  0.3645327]]. Action = [[ 0.          0.          0.         -0.11470574]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 644 is [True, False, False, False, False, True]
State prediction error at timestep 644 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 644 of -1
Current timestep = 645. State = [[-0.1604695   0.36453316]]. Action = [[ 0.         0.         0.        -0.9231138]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 645 is [True, False, False, False, False, True]
State prediction error at timestep 645 is tensor(9.8210e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 645 of -1
Current timestep = 646. State = [[-0.1604694   0.36453357]]. Action = [[0.        0.        0.        0.7568824]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 646 is [True, False, False, False, False, True]
State prediction error at timestep 646 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 646 of -1
Current timestep = 647. State = [[-0.1604693  0.364534 ]]. Action = [[ 0.          0.          0.         -0.34605855]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 647 is [True, False, False, False, False, True]
State prediction error at timestep 647 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 647 of -1
Current timestep = 648. State = [[-0.1604692  0.3645344]]. Action = [[ 0.         0.         0.        -0.9284032]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 648 is [True, False, False, False, False, True]
State prediction error at timestep 648 is tensor(8.4046e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 648 of -1
Current timestep = 649. State = [[-0.1604691   0.36453483]]. Action = [[ 0.         0.         0.        -0.8256923]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 649 is [True, False, False, False, False, True]
State prediction error at timestep 649 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 649 of -1
Current timestep = 650. State = [[-0.16046901  0.36453524]]. Action = [[0.       0.       0.       0.643065]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 650 is [True, False, False, False, False, True]
State prediction error at timestep 650 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 650 of -1
Current timestep = 651. State = [[-0.1604689   0.36453563]]. Action = [[0.         0.         0.         0.68374264]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 651 is [True, False, False, False, False, True]
State prediction error at timestep 651 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 651 of -1
Current timestep = 652. State = [[-0.16046882  0.36453605]]. Action = [[ 0.          0.          0.         -0.88395876]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 652 is [True, False, False, False, False, True]
State prediction error at timestep 652 is tensor(9.0246e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 652 of -1
Current timestep = 653. State = [[-0.16046871  0.36453643]]. Action = [[ 0.         0.         0.        -0.8688735]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 653 is [True, False, False, False, False, True]
State prediction error at timestep 653 is tensor(8.4489e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 653 of -1
Current timestep = 654. State = [[-0.16046862  0.36453682]]. Action = [[0.         0.         0.         0.50153756]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 654 is [True, False, False, False, False, True]
State prediction error at timestep 654 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 654 of -1
Current timestep = 655. State = [[-0.16046853  0.3645372 ]]. Action = [[0.         0.         0.         0.15135801]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 655 is [True, False, False, False, False, True]
State prediction error at timestep 655 is tensor(2.5619e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 655 of -1
Current timestep = 656. State = [[-0.16046844  0.36453763]]. Action = [[ 0.          0.          0.         -0.25673497]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 656 is [True, False, False, False, False, True]
State prediction error at timestep 656 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 656 of -1
Current timestep = 657. State = [[-0.16046835  0.36453798]]. Action = [[ 0.        0.        0.       -0.625294]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 657 is [True, False, False, False, False, True]
State prediction error at timestep 657 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 657 of -1
Current timestep = 658. State = [[-0.16046827  0.36453837]]. Action = [[ 0.          0.          0.         -0.35349816]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 658 is [True, False, False, False, False, True]
State prediction error at timestep 658 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 658 of -1
Current timestep = 659. State = [[-0.16046818  0.36453876]]. Action = [[ 0.         0.         0.        -0.2130925]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 659 is [True, False, False, False, False, True]
State prediction error at timestep 659 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 659 of -1
Current timestep = 660. State = [[-0.16046809  0.36453915]]. Action = [[0.         0.         0.         0.34888315]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 660 is [True, False, False, False, False, True]
State prediction error at timestep 660 is tensor(6.1433e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 660 of -1
Current timestep = 661. State = [[-0.160468   0.3645395]]. Action = [[0.         0.         0.         0.12425625]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 661 is [True, False, False, False, False, True]
State prediction error at timestep 661 is tensor(7.4400e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 661 of -1
Current timestep = 662. State = [[-0.16046791  0.36453986]]. Action = [[0.        0.        0.        0.8695978]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 662 is [True, False, False, False, False, True]
State prediction error at timestep 662 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 662 of -1
Current timestep = 663. State = [[-0.16046782  0.36454025]]. Action = [[ 0.         0.         0.        -0.5095404]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 663 is [True, False, False, False, False, True]
State prediction error at timestep 663 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 663 of -1
Current timestep = 664. State = [[-0.16046774  0.3645406 ]]. Action = [[0.        0.        0.        0.9232484]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 664 is [True, False, False, False, False, True]
State prediction error at timestep 664 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 664 of -1
Current timestep = 665. State = [[-0.16046765  0.36454096]]. Action = [[ 0.          0.          0.         -0.15355593]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 665 is [True, False, False, False, False, True]
State prediction error at timestep 665 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 665 of -1
Current timestep = 666. State = [[-0.16046757  0.36454132]]. Action = [[ 0.          0.          0.         -0.95995116]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 666 is [True, False, False, False, False, True]
State prediction error at timestep 666 is tensor(5.9940e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 666 of -1
Current timestep = 667. State = [[-0.16046749  0.36454168]]. Action = [[ 0.        0.        0.       -0.948194]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 667 is [True, False, False, False, False, True]
State prediction error at timestep 667 is tensor(7.1102e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 667 of -1
Current timestep = 668. State = [[-0.1604674   0.36454204]]. Action = [[0.         0.         0.         0.07044137]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 668 is [True, False, False, False, False, True]
State prediction error at timestep 668 is tensor(9.0085e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 668 of -1
Current timestep = 669. State = [[-0.16046733  0.36454237]]. Action = [[0.        0.        0.        0.1305865]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 669 is [True, False, False, False, False, True]
State prediction error at timestep 669 is tensor(3.9303e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 669 of -1
Current timestep = 670. State = [[-0.16046725  0.36454272]]. Action = [[ 0.          0.          0.         -0.78715354]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 670 is [True, False, False, False, False, True]
State prediction error at timestep 670 is tensor(7.7978e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 670 of -1
Current timestep = 671. State = [[-0.16046716  0.36454305]]. Action = [[ 0.         0.         0.        -0.6783484]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 671 is [True, False, False, False, False, True]
State prediction error at timestep 671 is tensor(8.7639e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 671 of -1
Current timestep = 672. State = [[-0.16046709  0.3645434 ]]. Action = [[ 0.         0.         0.        -0.0894987]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 672 is [True, False, False, False, False, True]
State prediction error at timestep 672 is tensor(8.9060e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 672 of -1
Current timestep = 673. State = [[-0.16046701  0.36454374]]. Action = [[0.        0.        0.        0.4059856]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 673 is [True, False, False, False, False, True]
State prediction error at timestep 673 is tensor(7.7363e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 673 of -1
Current timestep = 674. State = [[-0.16046694  0.36454406]]. Action = [[0.         0.         0.         0.60107803]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 674 is [True, False, False, False, False, True]
State prediction error at timestep 674 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 674 of -1
Current timestep = 675. State = [[-0.16046686  0.3645444 ]]. Action = [[ 0.        0.        0.       -0.498298]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 675 is [True, False, False, False, False, True]
State prediction error at timestep 675 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 675 of -1
Current timestep = 676. State = [[-0.16046679  0.36454472]]. Action = [[0.         0.         0.         0.66860604]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 676 is [True, False, False, False, False, True]
State prediction error at timestep 676 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 676 of -1
Current timestep = 677. State = [[-0.16046672  0.36454505]]. Action = [[ 0.          0.          0.         -0.58951724]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 677 is [True, False, False, False, False, True]
State prediction error at timestep 677 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 677 of -1
Current timestep = 678. State = [[-0.16046664  0.36454538]]. Action = [[0.         0.         0.         0.39059925]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 678 is [True, False, False, False, False, True]
State prediction error at timestep 678 is tensor(5.1025e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 678 of -1
Current timestep = 679. State = [[-0.16046657  0.3645457 ]]. Action = [[ 0.          0.          0.         -0.80964535]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 679 is [True, False, False, False, False, True]
State prediction error at timestep 679 is tensor(6.6249e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 679 of -1
Current timestep = 680. State = [[-0.16046649  0.364546  ]]. Action = [[ 0.         0.         0.        -0.6768138]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 680 is [True, False, False, False, False, True]
State prediction error at timestep 680 is tensor(7.5995e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 680 of -1
Current timestep = 681. State = [[-0.16046642  0.36454633]]. Action = [[0.         0.         0.         0.01663375]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 681 is [True, False, False, False, False, True]
State prediction error at timestep 681 is tensor(1.9011e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 681 of -1
Current timestep = 682. State = [[-0.16046636  0.36454663]]. Action = [[0.         0.         0.         0.30121553]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 682 is [True, False, False, False, False, True]
State prediction error at timestep 682 is tensor(4.1012e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 682 of -1
Current timestep = 683. State = [[-0.16046628  0.36454692]]. Action = [[ 0.         0.         0.        -0.6607704]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 683 is [True, False, False, False, False, True]
State prediction error at timestep 683 is tensor(9.9604e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 683 of -1
Current timestep = 684. State = [[-0.16046621  0.36454725]]. Action = [[ 0.          0.          0.         -0.06708014]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 684 is [True, False, False, False, False, True]
State prediction error at timestep 684 is tensor(8.9031e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 684 of -1
Current timestep = 685. State = [[-0.16046615  0.36454755]]. Action = [[0.         0.         0.         0.19499183]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 685 is [True, False, False, False, False, True]
State prediction error at timestep 685 is tensor(6.2078e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 685 of -1
Current timestep = 686. State = [[-0.16046607  0.36454785]]. Action = [[0.         0.         0.         0.35482526]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 686 is [True, False, False, False, False, True]
State prediction error at timestep 686 is tensor(5.5920e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 686 of -1
Current timestep = 687. State = [[-0.16046602  0.36454815]]. Action = [[0.         0.         0.         0.12198651]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 687 is [True, False, False, False, False, True]
State prediction error at timestep 687 is tensor(1.4017e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 687 of -1
Current timestep = 688. State = [[-0.16046594  0.36454844]]. Action = [[ 0.          0.          0.         -0.09466171]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 688 is [True, False, False, False, False, True]
State prediction error at timestep 688 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 688 of -1
Current timestep = 689. State = [[-0.16046588  0.36454874]]. Action = [[ 0.         0.         0.        -0.6406044]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 689 is [True, False, False, False, False, True]
State prediction error at timestep 689 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 689 of -1
Current timestep = 690. State = [[-0.16046582  0.36454904]]. Action = [[0.        0.        0.        0.3500383]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 690 is [True, False, False, False, False, True]
State prediction error at timestep 690 is tensor(4.2657e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 690 of -1
Current timestep = 691. State = [[-0.16046575  0.3645493 ]]. Action = [[0.         0.         0.         0.12974787]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 691 is [True, False, False, False, False, True]
State prediction error at timestep 691 is tensor(6.1468e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 691 of -1
Current timestep = 692. State = [[-0.16046569  0.3645496 ]]. Action = [[ 0.          0.          0.         -0.42917657]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 692 is [True, False, False, False, False, True]
State prediction error at timestep 692 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 692 of -1
Current timestep = 693. State = [[-0.16046563  0.36454988]]. Action = [[ 0.          0.          0.         -0.27186716]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 693 is [True, False, False, False, False, True]
State prediction error at timestep 693 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 693 of -1
Current timestep = 694. State = [[-0.16046557  0.36455017]]. Action = [[0.         0.         0.         0.09541142]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 694 is [True, False, False, False, False, True]
State prediction error at timestep 694 is tensor(2.9430e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 694 of -1
Current timestep = 695. State = [[-0.16046551  0.36455044]]. Action = [[0.         0.         0.         0.53533506]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 695 is [True, False, False, False, False, True]
State prediction error at timestep 695 is tensor(9.2330e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 695 of -1
Current timestep = 696. State = [[-0.16046545  0.3645507 ]]. Action = [[ 0.         0.         0.        -0.7333393]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 696 is [True, False, False, False, False, True]
State prediction error at timestep 696 is tensor(9.8924e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 696 of -1
Current timestep = 697. State = [[-0.16046539  0.36455098]]. Action = [[ 0.         0.         0.        -0.6663655]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 697 is [True, False, False, False, False, True]
State prediction error at timestep 697 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 697 of -1
Current timestep = 698. State = [[-0.16046533  0.36455128]]. Action = [[0.        0.        0.        0.6250286]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 698 is [True, False, False, False, False, True]
State prediction error at timestep 698 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 698 of -1
Current timestep = 699. State = [[-0.16046527  0.36455154]]. Action = [[ 0.          0.          0.         -0.25646454]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 699 is [True, False, False, False, False, True]
State prediction error at timestep 699 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 699 of -1
Current timestep = 700. State = [[-0.16046521  0.3645518 ]]. Action = [[ 0.          0.          0.         -0.28851032]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 700 is [True, False, False, False, False, True]
State prediction error at timestep 700 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 700 of -1
Current timestep = 701. State = [[-0.16046515  0.36455205]]. Action = [[0.        0.        0.        0.7297553]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 701 is [True, False, False, False, False, True]
State prediction error at timestep 701 is tensor(9.8149e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 701 of -1
Current timestep = 702. State = [[-0.16046509  0.36455232]]. Action = [[ 0.          0.          0.         -0.04765844]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 702 is [True, False, False, False, False, True]
State prediction error at timestep 702 is tensor(8.5652e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 702 of -1
Current timestep = 703. State = [[-0.16046503  0.3645526 ]]. Action = [[0.        0.        0.        0.6511451]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 703 is [True, False, False, False, False, True]
State prediction error at timestep 703 is tensor(9.5037e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 703 of -1
Current timestep = 704. State = [[-0.16046497  0.36455286]]. Action = [[0.         0.         0.         0.39145303]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 704 is [True, False, False, False, False, True]
State prediction error at timestep 704 is tensor(5.2939e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 704 of -1
Current timestep = 705. State = [[-0.16046493  0.3645531 ]]. Action = [[ 0.          0.          0.         -0.63865125]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 705 is [True, False, False, False, False, True]
State prediction error at timestep 705 is tensor(8.6762e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 705 of -1
Current timestep = 706. State = [[-0.16046487  0.36455336]]. Action = [[0.         0.         0.         0.03575218]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 706 is [True, False, False, False, False, True]
State prediction error at timestep 706 is tensor(1.9569e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 706 of -1
Current timestep = 707. State = [[-0.16046481  0.3645536 ]]. Action = [[0.         0.         0.         0.44186604]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 707 is [True, False, False, False, False, True]
State prediction error at timestep 707 is tensor(6.8759e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 707 of -1
Current timestep = 708. State = [[-0.16046476  0.36455387]]. Action = [[ 0.          0.          0.         -0.84113634]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 708 is [True, False, False, False, False, True]
State prediction error at timestep 708 is tensor(9.5116e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 708 of -1
Current timestep = 709. State = [[-0.1604647  0.3645541]]. Action = [[ 0.         0.         0.        -0.2161122]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 709 is [True, False, False, False, False, True]
State prediction error at timestep 709 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 709 of -1
Current timestep = 710. State = [[-0.16046466  0.36455435]]. Action = [[ 0.          0.          0.         -0.33603764]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 710 is [True, False, False, False, False, True]
State prediction error at timestep 710 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 710 of -1
Current timestep = 711. State = [[-0.1604646   0.36455458]]. Action = [[ 0.          0.          0.         -0.49220932]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 711 is [True, False, False, False, False, True]
State prediction error at timestep 711 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 711 of -1
Current timestep = 712. State = [[-0.16046456  0.36455482]]. Action = [[0.         0.         0.         0.45929623]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 712 is [True, False, False, False, False, True]
State prediction error at timestep 712 is tensor(8.6205e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 712 of -1
Current timestep = 713. State = [[-0.1604645   0.36455506]]. Action = [[ 0.         0.         0.        -0.5553714]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 713 is [True, False, False, False, False, True]
State prediction error at timestep 713 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 713 of -1
Current timestep = 714. State = [[-0.16046445  0.3645553 ]]. Action = [[ 0.         0.         0.        -0.9738809]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 714 is [True, False, False, False, False, True]
State prediction error at timestep 714 is tensor(6.3202e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 714 of -1
Current timestep = 715. State = [[-0.1604644   0.36455554]]. Action = [[0.        0.        0.        0.5270872]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 715 is [True, False, False, False, False, True]
State prediction error at timestep 715 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 715 of -1
Current timestep = 716. State = [[-0.16046435  0.36455578]]. Action = [[0.         0.         0.         0.15434384]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 716 is [True, False, False, False, False, True]
State prediction error at timestep 716 is tensor(2.5201e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 716 of -1
Current timestep = 717. State = [[-0.1604643  0.364556 ]]. Action = [[ 0.          0.          0.         -0.08699864]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 717 is [True, False, False, False, False, True]
State prediction error at timestep 717 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 717 of -1
Current timestep = 718. State = [[-0.16046426  0.36455622]]. Action = [[ 0.          0.          0.         -0.60174143]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 718 is [True, False, False, False, False, True]
State prediction error at timestep 718 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 718 of -1
Current timestep = 719. State = [[-0.16046421  0.36455646]]. Action = [[0.         0.         0.         0.65436435]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 719 is [True, False, False, False, False, True]
State prediction error at timestep 719 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 719 of -1
Current timestep = 720. State = [[-0.16046417  0.3645567 ]]. Action = [[ 0.          0.          0.         -0.33743894]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 720 is [True, False, False, False, False, True]
State prediction error at timestep 720 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 720 of -1
Current timestep = 721. State = [[-0.16046411  0.3645569 ]]. Action = [[ 0.          0.          0.         -0.56218326]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 721 is [True, False, False, False, False, True]
State prediction error at timestep 721 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 721 of -1
Current timestep = 722. State = [[-0.16046406  0.36455715]]. Action = [[0.        0.        0.        0.4473691]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 722 is [True, False, False, False, False, True]
State prediction error at timestep 722 is tensor(7.2283e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 722 of -1
Current timestep = 723. State = [[-0.16046402  0.36455736]]. Action = [[ 0.          0.          0.         -0.43042582]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 723 is [True, False, False, False, False, True]
State prediction error at timestep 723 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 723 of -1
Current timestep = 724. State = [[-0.16046397  0.36455756]]. Action = [[ 0.          0.          0.         -0.11138403]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 724 is [True, False, False, False, False, True]
State prediction error at timestep 724 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 724 of -1
Current timestep = 725. State = [[-0.16046393  0.3645578 ]]. Action = [[0.        0.        0.        0.6928265]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 725 is [True, False, False, False, False, True]
State prediction error at timestep 725 is tensor(9.7308e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 725 of -1
Current timestep = 726. State = [[-0.16046388  0.364558  ]]. Action = [[0.         0.         0.         0.14196181]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 726 is [True, False, False, False, False, True]
State prediction error at timestep 726 is tensor(2.4941e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 726 of -1
Current timestep = 727. State = [[-0.16046384  0.36455822]]. Action = [[0.        0.        0.        0.0943439]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 727 is [True, False, False, False, False, True]
State prediction error at timestep 727 is tensor(8.5063e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 727 of -1
Current timestep = 728. State = [[-0.16046381  0.36455843]]. Action = [[0.        0.        0.        0.9274485]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 728 is [True, False, False, False, False, True]
State prediction error at timestep 728 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 728 of -1
Current timestep = 729. State = [[-0.16046377  0.36455864]]. Action = [[0.        0.        0.        0.1303283]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 729 is [True, False, False, False, False, True]
State prediction error at timestep 729 is tensor(1.3291e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 729 of -1
Current timestep = 730. State = [[-0.16046372  0.36455885]]. Action = [[0.        0.        0.        0.5952611]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 730 is [True, False, False, False, False, True]
State prediction error at timestep 730 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 730 of -1
Current timestep = 731. State = [[-0.16046368  0.36455905]]. Action = [[ 0.          0.          0.         -0.44066703]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 731 is [True, False, False, False, False, True]
State prediction error at timestep 731 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 731 of -1
Current timestep = 732. State = [[-0.16046363  0.36455926]]. Action = [[0.       0.       0.       0.787797]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 732 is [True, False, False, False, False, True]
State prediction error at timestep 732 is tensor(9.3309e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 732 of -1
Current timestep = 733. State = [[-0.1604636   0.36455944]]. Action = [[ 0.          0.          0.         -0.80618584]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 733 is [True, False, False, False, False, True]
State prediction error at timestep 733 is tensor(6.4601e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 733 of -1
Current timestep = 734. State = [[-0.16046356  0.36455965]]. Action = [[ 0.          0.          0.         -0.36727935]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 734 is [True, False, False, False, False, True]
State prediction error at timestep 734 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 734 of -1
Current timestep = 735. State = [[-0.16046351  0.36455986]]. Action = [[ 0.          0.          0.         -0.23362768]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 735 is [True, False, False, False, False, True]
State prediction error at timestep 735 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 735 of -1
Current timestep = 736. State = [[-0.16046348  0.36456004]]. Action = [[0.        0.        0.        0.3920176]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 736 is [True, False, False, False, False, True]
State prediction error at timestep 736 is tensor(3.4163e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 736 of -1
Current timestep = 737. State = [[-0.16046344  0.36456025]]. Action = [[ 0.         0.         0.        -0.7951668]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 737 is [True, False, False, False, False, True]
State prediction error at timestep 737 is tensor(6.6502e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 737 of -1
Current timestep = 738. State = [[-0.1604634   0.36456046]]. Action = [[ 0.         0.         0.        -0.5092714]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 738 is [True, False, False, False, False, True]
State prediction error at timestep 738 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 738 of -1
Current timestep = 739. State = [[-0.16046336  0.36456063]]. Action = [[ 0.          0.          0.         -0.40313232]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 739 is [True, False, False, False, False, True]
State prediction error at timestep 739 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 739 of -1
Current timestep = 740. State = [[-0.16046332  0.3645608 ]]. Action = [[ 0.          0.          0.         -0.15009809]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 740 is [True, False, False, False, False, True]
State prediction error at timestep 740 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 740 of -1
Current timestep = 741. State = [[-0.16046329  0.36456102]]. Action = [[0.       0.       0.       0.770056]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 741 is [True, False, False, False, False, True]
State prediction error at timestep 741 is tensor(8.8854e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 741 of -1
Current timestep = 742. State = [[-0.16046324  0.3645612 ]]. Action = [[0.         0.         0.         0.74769783]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 742 is [True, False, False, False, False, True]
State prediction error at timestep 742 is tensor(8.4111e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 742 of -1
Current timestep = 743. State = [[-0.16046321  0.36456138]]. Action = [[ 0.          0.          0.         -0.69986457]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 743 is [True, False, False, False, False, True]
State prediction error at timestep 743 is tensor(7.0586e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 743 of -1
Current timestep = 744. State = [[-0.16046317  0.36456156]]. Action = [[0.        0.        0.        0.9816427]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 744 is [True, False, False, False, False, True]
State prediction error at timestep 744 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 744 of -1
Current timestep = 745. State = [[-0.16046314  0.36456177]]. Action = [[ 0.          0.          0.         -0.47260547]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 745 is [True, False, False, False, False, True]
State prediction error at timestep 745 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 745 of -1
Current timestep = 746. State = [[-0.16046311  0.36456195]]. Action = [[ 0.          0.          0.         -0.70992637]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 746 is [True, False, False, False, False, True]
State prediction error at timestep 746 is tensor(7.9847e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 746 of -1
Current timestep = 747. State = [[-0.16046306  0.36456212]]. Action = [[0.         0.         0.         0.66567945]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 747 is [True, False, False, False, False, True]
State prediction error at timestep 747 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 747 of -1
Current timestep = 748. State = [[-0.16046304  0.3645623 ]]. Action = [[0.        0.        0.        0.5638969]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 748 is [True, False, False, False, False, True]
State prediction error at timestep 748 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 748 of -1
Current timestep = 749. State = [[-0.160463    0.36456248]]. Action = [[0.        0.        0.        0.7788708]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 749 is [True, False, False, False, False, True]
State prediction error at timestep 749 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 749 of -1
Current timestep = 750. State = [[-0.16046298  0.36456266]]. Action = [[0.         0.         0.         0.29252303]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 750 is [True, False, False, False, False, True]
State prediction error at timestep 750 is tensor(2.6538e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 750 of -1
Current timestep = 751. State = [[-0.16046293  0.3645628 ]]. Action = [[0.       0.       0.       0.419371]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 751 is [True, False, False, False, False, True]
State prediction error at timestep 751 is tensor(6.4033e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 751 of -1
Current timestep = 752. State = [[-0.1604629  0.364563 ]]. Action = [[ 0.          0.          0.         -0.98515445]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 752 is [True, False, False, False, False, True]
State prediction error at timestep 752 is tensor(4.3024e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 752 of -1
Current timestep = 753. State = [[-0.16046287  0.36456317]]. Action = [[0.         0.         0.         0.42442155]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 753 is [True, False, False, False, False, True]
State prediction error at timestep 753 is tensor(5.4374e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 753 of -1
Current timestep = 754. State = [[-0.16046284  0.36456335]]. Action = [[0.         0.         0.         0.42666817]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 754 is [True, False, False, False, False, True]
State prediction error at timestep 754 is tensor(5.2980e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 754 of -1
Current timestep = 755. State = [[-0.16046281  0.3645635 ]]. Action = [[ 0.          0.          0.         -0.05131119]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 755 is [True, False, False, False, False, True]
State prediction error at timestep 755 is tensor(8.7191e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 755 of -1
Current timestep = 756. State = [[-0.16046278  0.36456367]]. Action = [[ 0.         0.         0.        -0.8566699]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 756 is [True, False, False, False, False, True]
State prediction error at timestep 756 is tensor(7.3395e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 756 of -1
Current timestep = 757. State = [[-0.16046274  0.36456382]]. Action = [[ 0.          0.          0.         -0.08020759]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 757 is [True, False, False, False, False, True]
State prediction error at timestep 757 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 757 of -1
Current timestep = 758. State = [[-0.1604627  0.364564 ]]. Action = [[0.         0.         0.         0.23854339]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 758 is [True, False, False, False, False, True]
State prediction error at timestep 758 is tensor(5.8241e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 758 of -1
Current timestep = 759. State = [[-0.16046268  0.36456415]]. Action = [[ 0.          0.          0.         -0.05851662]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 759 is [True, False, False, False, False, True]
State prediction error at timestep 759 is tensor(8.5374e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 759 of -1
Current timestep = 760. State = [[-0.16046265  0.36456433]]. Action = [[0.        0.        0.        0.6990793]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 760 is [True, False, False, False, False, True]
State prediction error at timestep 760 is tensor(9.4630e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 760 of -1
Current timestep = 761. State = [[-0.16046262  0.36456448]]. Action = [[0.         0.         0.         0.79670095]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 761 is [True, False, False, False, False, True]
State prediction error at timestep 761 is tensor(7.9103e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 761 of -1
Current timestep = 762. State = [[-0.16046259  0.36456466]]. Action = [[ 0.        0.        0.       -0.076774]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 762 is [True, False, False, False, False, True]
State prediction error at timestep 762 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 762 of -1
Current timestep = 763. State = [[-0.16046257  0.3645648 ]]. Action = [[ 0.          0.          0.         -0.95579207]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 763 is [True, False, False, False, False, True]
State prediction error at timestep 763 is tensor(5.3920e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 763 of -1
Current timestep = 764. State = [[-0.16046254  0.36456496]]. Action = [[0.         0.         0.         0.44973445]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 764 is [True, False, False, False, False, True]
State prediction error at timestep 764 is tensor(5.7274e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 764 of -1
Current timestep = 765. State = [[-0.16046251  0.3645651 ]]. Action = [[ 0.          0.          0.         -0.04935896]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 765 is [True, False, False, False, False, True]
State prediction error at timestep 765 is tensor(8.4740e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 765 of -1
Current timestep = 766. State = [[-0.16046248  0.36456525]]. Action = [[0.         0.         0.         0.14938378]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 766 is [True, False, False, False, False, True]
State prediction error at timestep 766 is tensor(2.8296e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 766 of -1
Current timestep = 767. State = [[-0.16046245  0.36456543]]. Action = [[ 0.          0.          0.         -0.43014044]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 767 is [True, False, False, False, False, True]
State prediction error at timestep 767 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 767 of -1
Current timestep = 768. State = [[-0.16046242  0.36456558]]. Action = [[0.        0.        0.        0.1938467]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 768 is [True, False, False, False, False, True]
State prediction error at timestep 768 is tensor(3.9819e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 768 of -1
Current timestep = 769. State = [[-0.1604624   0.36456573]]. Action = [[ 0.         0.         0.        -0.9299952]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 769 is [True, False, False, False, False, True]
State prediction error at timestep 769 is tensor(5.1769e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 769 of -1
Current timestep = 770. State = [[-0.16046238  0.36456588]]. Action = [[ 0.          0.          0.         -0.49463207]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 770 is [True, False, False, False, False, True]
State prediction error at timestep 770 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 770 of -1
Current timestep = 771. State = [[-0.16046235  0.36456603]]. Action = [[ 0.         0.         0.        -0.5603206]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 771 is [True, False, False, False, False, True]
State prediction error at timestep 771 is tensor(9.6609e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 771 of -1
Current timestep = 772. State = [[-0.16046232  0.36456618]]. Action = [[0.         0.         0.         0.55913854]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 772 is [True, False, False, False, False, True]
State prediction error at timestep 772 is tensor(9.7256e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 772 of -1
Current timestep = 773. State = [[-0.16046229  0.3645663 ]]. Action = [[ 0.          0.          0.         -0.32253355]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 773 is [True, False, False, False, False, True]
State prediction error at timestep 773 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 773 of -1
Current timestep = 774. State = [[-0.16046228  0.36456645]]. Action = [[0.         0.         0.         0.36484742]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 774 is [True, False, False, False, False, True]
State prediction error at timestep 774 is tensor(1.7868e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 774 of -1
Current timestep = 775. State = [[-0.16046225  0.3645666 ]]. Action = [[ 0.          0.          0.         -0.77724373]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 775 is [True, False, False, False, False, True]
State prediction error at timestep 775 is tensor(8.6994e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 775 of -1
Current timestep = 776. State = [[-0.16046222  0.36456674]]. Action = [[ 0.          0.          0.         -0.35279083]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 776 is [True, False, False, False, False, True]
State prediction error at timestep 776 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 776 of -1
Current timestep = 777. State = [[-0.1604622  0.3645669]]. Action = [[ 0.         0.         0.        -0.6421545]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 777 is [True, False, False, False, False, True]
State prediction error at timestep 777 is tensor(8.0584e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 777 of -1
Current timestep = 778. State = [[-0.16046217  0.364567  ]]. Action = [[0.        0.        0.        0.4817524]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 778 is [True, False, False, False, False, True]
State prediction error at timestep 778 is tensor(9.3032e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 778 of -1
Current timestep = 779. State = [[-0.16046216  0.36456716]]. Action = [[ 0.          0.          0.         -0.49122453]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 779 is [True, False, False, False, False, True]
State prediction error at timestep 779 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 779 of -1
Current timestep = 780. State = [[-0.16046213  0.36456728]]. Action = [[0.         0.         0.         0.73068976]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 780 is [True, False, False, False, False, True]
State prediction error at timestep 780 is tensor(8.6438e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 780 of -1
Current timestep = 781. State = [[-0.16046211  0.36456743]]. Action = [[ 0.         0.         0.        -0.9287975]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 781 is [True, False, False, False, False, True]
State prediction error at timestep 781 is tensor(7.8125e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 781 of -1
Current timestep = 782. State = [[-0.16046208  0.36456758]]. Action = [[0.        0.        0.        0.6651292]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 782 is [True, False, False, False, False, True]
State prediction error at timestep 782 is tensor(7.1114e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 782 of -1
Current timestep = 783. State = [[-0.16046205  0.3645677 ]]. Action = [[ 0.         0.         0.        -0.8341247]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 783 is [True, False, False, False, False, True]
State prediction error at timestep 783 is tensor(5.6135e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 783 of -1
Current timestep = 784. State = [[-0.16046204  0.36456782]]. Action = [[0.         0.         0.         0.93330765]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 784 is [True, False, False, False, False, True]
State prediction error at timestep 784 is tensor(8.6229e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 784 of -1
Current timestep = 785. State = [[-0.16046202  0.36456797]]. Action = [[0.        0.        0.        0.7284874]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 785 is [True, False, False, False, False, True]
State prediction error at timestep 785 is tensor(7.5773e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 785 of -1
Current timestep = 786. State = [[-0.16046199  0.36456808]]. Action = [[0.        0.        0.        0.1943618]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 786 is [True, False, False, False, False, True]
State prediction error at timestep 786 is tensor(4.7889e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 786 of -1
Current timestep = 787. State = [[-0.16046198  0.36456823]]. Action = [[0.         0.         0.         0.15935004]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 787 is [True, False, False, False, False, True]
State prediction error at timestep 787 is tensor(1.6615e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 787 of -1
Current timestep = 788. State = [[-0.16046195  0.36456835]]. Action = [[ 0.         0.         0.        -0.3042925]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 788 is [True, False, False, False, False, True]
State prediction error at timestep 788 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 788 of -1
Current timestep = 789. State = [[-0.16046193  0.36456847]]. Action = [[0.        0.        0.        0.4734261]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 789 is [True, False, False, False, False, True]
State prediction error at timestep 789 is tensor(7.3881e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 789 of -1
Current timestep = 790. State = [[-0.1604619   0.36456862]]. Action = [[0.         0.         0.         0.94523203]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 790 is [True, False, False, False, False, True]
State prediction error at timestep 790 is tensor(8.6514e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 790 of -1
Current timestep = 791. State = [[-0.16046189  0.36456874]]. Action = [[ 0.         0.         0.        -0.9339797]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 791 is [True, False, False, False, False, True]
State prediction error at timestep 791 is tensor(4.5735e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 791 of -1
Current timestep = 792. State = [[-0.16046187  0.36456886]]. Action = [[ 0.         0.         0.        -0.5914818]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 792 is [True, False, False, False, False, True]
State prediction error at timestep 792 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 792 of -1
Current timestep = 793. State = [[-0.16046184  0.36456898]]. Action = [[0.        0.        0.        0.6656351]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 793 is [True, False, False, False, False, True]
State prediction error at timestep 793 is tensor(6.9910e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 793 of -1
Current timestep = 794. State = [[-0.16046183  0.3645691 ]]. Action = [[ 0.          0.          0.         -0.67407846]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 794 is [True, False, False, False, False, True]
State prediction error at timestep 794 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 794 of -1
Current timestep = 795. State = [[-0.16046181  0.36456922]]. Action = [[ 0.         0.         0.        -0.9609477]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 795 is [True, False, False, False, False, True]
State prediction error at timestep 795 is tensor(4.3097e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 795 of -1
Current timestep = 796. State = [[-0.1604618   0.36456934]]. Action = [[0.         0.         0.         0.46438336]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 796 is [True, False, False, False, False, True]
State prediction error at timestep 796 is tensor(6.9428e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 796 of -1
Current timestep = 797. State = [[-0.16046177  0.36456946]]. Action = [[ 0.          0.          0.         -0.43778956]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 797 is [True, False, False, False, False, True]
State prediction error at timestep 797 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 797 of -1
Current timestep = 798. State = [[-0.16046175  0.36456957]]. Action = [[ 0.          0.          0.         -0.48944616]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 798 is [True, False, False, False, False, True]
State prediction error at timestep 798 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 798 of -1
Current timestep = 799. State = [[-0.16046174  0.3645697 ]]. Action = [[ 0.          0.          0.         -0.27520728]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 799 is [True, False, False, False, False, True]
State prediction error at timestep 799 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 799 of -1
Current timestep = 800. State = [[-0.16046172  0.3645698 ]]. Action = [[ 0.         0.         0.        -0.8149891]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 800 is [True, False, False, False, False, True]
State prediction error at timestep 800 is tensor(6.2259e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 800 of -1
Current timestep = 801. State = [[-0.1604617   0.36456993]]. Action = [[0.        0.        0.        0.0817647]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 801 is [True, False, False, False, False, True]
State prediction error at timestep 801 is tensor(1.9617e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 801 of -1
Current timestep = 802. State = [[-0.16046168  0.36457005]]. Action = [[0.        0.        0.        0.9397948]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 802 is [True, False, False, False, False, True]
State prediction error at timestep 802 is tensor(9.0305e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 802 of -1
Current timestep = 803. State = [[-0.16046166  0.36457017]]. Action = [[ 0.         0.         0.        -0.6628762]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 803 is [True, False, False, False, False, True]
State prediction error at timestep 803 is tensor(7.9689e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 803 of -1
Current timestep = 804. State = [[-0.16046165  0.3645703 ]]. Action = [[0.         0.         0.         0.35408235]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 804 is [True, False, False, False, False, True]
State prediction error at timestep 804 is tensor(2.5007e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 804 of -1
Current timestep = 805. State = [[-0.16046163  0.36457038]]. Action = [[0.         0.         0.         0.39641988]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 805 is [True, False, False, False, False, True]
State prediction error at timestep 805 is tensor(3.4469e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 805 of -1
Current timestep = 806. State = [[-0.16046162  0.3645705 ]]. Action = [[0.        0.        0.        0.1337645]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 806 is [True, False, False, False, False, True]
State prediction error at timestep 806 is tensor(3.6738e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 806 of -1
Current timestep = 807. State = [[-0.1604616   0.36457062]]. Action = [[0.         0.         0.         0.49878502]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 807 is [True, False, False, False, False, True]
State prediction error at timestep 807 is tensor(7.1187e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 807 of -1
Current timestep = 808. State = [[-0.16046159  0.3645707 ]]. Action = [[0.        0.        0.        0.6688036]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 808 is [True, False, False, False, False, True]
State prediction error at timestep 808 is tensor(8.2970e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 808 of -1
Current timestep = 809. State = [[-0.16046157  0.36457083]]. Action = [[0.        0.        0.        0.8682928]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 809 is [True, False, False, False, False, True]
State prediction error at timestep 809 is tensor(6.9804e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 809 of -1
Current timestep = 810. State = [[-0.16046156  0.36457095]]. Action = [[0.         0.         0.         0.01990986]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 810 is [True, False, False, False, False, True]
State prediction error at timestep 810 is tensor(4.9282e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 810 of -1
Current timestep = 811. State = [[-0.16046153  0.36457103]]. Action = [[0.         0.         0.         0.30447555]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 811 is [True, False, False, False, False, True]
State prediction error at timestep 811 is tensor(8.9427e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 811 of -1
Current timestep = 812. State = [[-0.16046152  0.36457115]]. Action = [[ 0.          0.          0.         -0.15743566]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 812 is [True, False, False, False, False, True]
State prediction error at timestep 812 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 812 of -1
Current timestep = 813. State = [[-0.1604615   0.36457124]]. Action = [[ 0.          0.          0.         -0.57907885]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 813 is [True, False, False, False, False, True]
State prediction error at timestep 813 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 813 of -1
Current timestep = 814. State = [[-0.16046149  0.36457136]]. Action = [[ 0.         0.         0.        -0.7108957]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 814 is [True, False, False, False, False, True]
State prediction error at timestep 814 is tensor(6.8517e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 814 of -1
Current timestep = 815. State = [[-0.16046149  0.36457145]]. Action = [[ 0.         0.         0.        -0.7306441]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 815 is [True, False, False, False, False, True]
State prediction error at timestep 815 is tensor(5.5369e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 815 of -1
Current timestep = 816. State = [[-0.16046147  0.36457157]]. Action = [[ 0.         0.         0.        -0.7341963]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 816 is [True, False, False, False, False, True]
State prediction error at timestep 816 is tensor(5.6958e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 816 of -1
Current timestep = 817. State = [[-0.16046146  0.36457166]]. Action = [[0.         0.         0.         0.05459583]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 817 is [True, False, False, False, False, True]
State prediction error at timestep 817 is tensor(2.8199e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 817 of -1
Current timestep = 818. State = [[-0.16046144  0.36457178]]. Action = [[ 0.          0.          0.         -0.73186475]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 818 is [True, False, False, False, False, True]
State prediction error at timestep 818 is tensor(9.0765e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 818 of -1
Current timestep = 819. State = [[-0.16046143  0.36457187]]. Action = [[ 0.          0.          0.         -0.34337473]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 819 is [True, False, False, False, False, True]
State prediction error at timestep 819 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 819 of -1
Current timestep = 820. State = [[-0.16046141  0.36457196]]. Action = [[ 0.         0.         0.        -0.2348218]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 820 is [True, False, False, False, False, True]
State prediction error at timestep 820 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 820 of -1
Current timestep = 821. State = [[-0.1604614   0.36457208]]. Action = [[ 0.          0.          0.         -0.36260265]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 821 is [True, False, False, False, False, True]
State prediction error at timestep 821 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 821 of -1
Current timestep = 822. State = [[-0.16046138  0.36457217]]. Action = [[0.         0.         0.         0.26641238]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 822 is [True, False, False, False, False, True]
State prediction error at timestep 822 is tensor(6.2277e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 822 of -1
Current timestep = 823. State = [[-0.16046137  0.36457226]]. Action = [[0.        0.        0.        0.8933635]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 823 is [True, False, False, False, False, True]
State prediction error at timestep 823 is tensor(8.4590e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 823 of -1
Current timestep = 824. State = [[-0.16046135  0.36457235]]. Action = [[ 0.         0.         0.        -0.7130333]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 824 is [True, False, False, False, False, True]
State prediction error at timestep 824 is tensor(9.6138e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 824 of -1
Current timestep = 825. State = [[-0.16046135  0.36457247]]. Action = [[ 0.          0.          0.         -0.53999037]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 825 is [True, False, False, False, False, True]
State prediction error at timestep 825 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 825 of -1
Current timestep = 826. State = [[-0.16046134  0.36457255]]. Action = [[ 0.          0.          0.         -0.59750414]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 826 is [True, False, False, False, False, True]
State prediction error at timestep 826 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 826 of -1
Current timestep = 827. State = [[-0.16046132  0.36457264]]. Action = [[0.       0.       0.       0.856966]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 827 is [True, False, False, False, False, True]
State prediction error at timestep 827 is tensor(5.7378e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 827 of -1
Current timestep = 828. State = [[-0.1604613   0.36457273]]. Action = [[ 0.          0.          0.         -0.83941984]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 828 is [True, False, False, False, False, True]
State prediction error at timestep 828 is tensor(4.5830e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 828 of -1
Current timestep = 829. State = [[-0.16046129  0.36457282]]. Action = [[0.         0.         0.         0.29857314]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 829 is [True, False, False, False, False, True]
State prediction error at timestep 829 is tensor(4.5852e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 829 of -1
Current timestep = 830. State = [[-0.16046129  0.3645729 ]]. Action = [[0.         0.         0.         0.14996803]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 830 is [True, False, False, False, False, True]
State prediction error at timestep 830 is tensor(6.4265e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 830 of -1
Current timestep = 831. State = [[-0.16046128  0.364573  ]]. Action = [[0.         0.         0.         0.11786914]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 831 is [True, False, False, False, False, True]
State prediction error at timestep 831 is tensor(9.3185e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 831 of -1
Current timestep = 832. State = [[-0.16046126  0.36457312]]. Action = [[ 0.         0.         0.        -0.8633492]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 832 is [True, False, False, False, False, True]
State prediction error at timestep 832 is tensor(4.5855e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 832 of -1
Current timestep = 833. State = [[-0.16046125  0.3645732 ]]. Action = [[ 0.          0.          0.         -0.37987006]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 833 is [True, False, False, False, False, True]
State prediction error at timestep 833 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 833 of -1
Current timestep = 834. State = [[-0.16046125  0.3645733 ]]. Action = [[ 0.         0.         0.        -0.9148998]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 834 is [True, False, False, False, False, True]
State prediction error at timestep 834 is tensor(3.1314e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 834 of -1
Current timestep = 835. State = [[-0.16046123  0.3645734 ]]. Action = [[0.        0.        0.        0.4705906]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 835 is [True, False, False, False, False, True]
State prediction error at timestep 835 is tensor(6.2251e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 835 of -1
Current timestep = 836. State = [[-0.16046122  0.36457345]]. Action = [[ 0.          0.          0.         -0.24209172]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 836 is [True, False, False, False, False, True]
State prediction error at timestep 836 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 836 of -1
Current timestep = 837. State = [[-0.16046122  0.36457354]]. Action = [[ 0.          0.          0.         -0.08458412]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 837 is [True, False, False, False, False, True]
State prediction error at timestep 837 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 837 of -1
Current timestep = 838. State = [[-0.1604612   0.36457363]]. Action = [[ 0.         0.         0.        -0.8391448]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 838 is [True, False, False, False, False, True]
State prediction error at timestep 838 is tensor(6.5890e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 838 of -1
Current timestep = 839. State = [[-0.16046119  0.36457372]]. Action = [[ 0.          0.          0.         -0.52575296]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 839 is [True, False, False, False, False, True]
State prediction error at timestep 839 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 839 of -1
Current timestep = 840. State = [[-0.16046119  0.3645738 ]]. Action = [[ 0.          0.          0.         -0.49116993]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 840 is [True, False, False, False, False, True]
State prediction error at timestep 840 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 840 of -1
Current timestep = 841. State = [[-0.16046117  0.3645739 ]]. Action = [[0.        0.        0.        0.7941878]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 841 is [True, False, False, False, False, True]
State prediction error at timestep 841 is tensor(6.5551e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 841 of -1
Current timestep = 842. State = [[-0.16046116  0.364574  ]]. Action = [[0.         0.         0.         0.09056163]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 842 is [True, False, False, False, False, True]
State prediction error at timestep 842 is tensor(1.4926e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 842 of -1
Current timestep = 843. State = [[-0.16046116  0.36457407]]. Action = [[ 0.          0.          0.         -0.17192543]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 843 is [True, False, False, False, False, True]
State prediction error at timestep 843 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 843 of -1
Current timestep = 844. State = [[-0.16046114  0.36457413]]. Action = [[0.        0.        0.        0.7115265]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 844 is [True, False, False, False, False, True]
State prediction error at timestep 844 is tensor(6.5551e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 844 of -1
Current timestep = 845. State = [[-0.16046113  0.36457422]]. Action = [[ 0.          0.          0.         -0.33265114]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 845 is [True, False, False, False, False, True]
State prediction error at timestep 845 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 845 of -1
Current timestep = 846. State = [[-0.16046113  0.3645743 ]]. Action = [[ 0.        0.        0.       -0.301202]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 846 is [True, False, False, False, False, True]
State prediction error at timestep 846 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 846 of -1
Current timestep = 847. State = [[-0.16046111  0.3645744 ]]. Action = [[0.        0.        0.        0.6939491]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 847 is [True, False, False, False, False, True]
State prediction error at timestep 847 is tensor(6.5100e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 847 of -1
Current timestep = 848. State = [[-0.16046111  0.36457446]]. Action = [[ 0.         0.         0.        -0.8935709]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 848 is [True, False, False, False, False, True]
State prediction error at timestep 848 is tensor(3.4588e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 848 of -1
Current timestep = 849. State = [[-0.1604611   0.36457455]]. Action = [[0.         0.         0.         0.17492425]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 849 is [True, False, False, False, False, True]
State prediction error at timestep 849 is tensor(5.0297e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 849 of -1
Current timestep = 850. State = [[-0.1604611   0.36457464]]. Action = [[ 0.          0.          0.         -0.81479406]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 850 is [True, False, False, False, False, True]
State prediction error at timestep 850 is tensor(4.5634e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 850 of -1
Current timestep = 851. State = [[-0.16046108  0.3645747 ]]. Action = [[0.        0.        0.        0.6278722]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 851 is [True, False, False, False, False, True]
State prediction error at timestep 851 is tensor(5.8564e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 851 of -1
Current timestep = 852. State = [[-0.16046108  0.3645748 ]]. Action = [[0.         0.         0.         0.17489731]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 852 is [True, False, False, False, False, True]
State prediction error at timestep 852 is tensor(3.2572e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 852 of -1
Current timestep = 853. State = [[-0.16046107  0.36457485]]. Action = [[ 0.          0.          0.         -0.82616574]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 853 is [True, False, False, False, False, True]
State prediction error at timestep 853 is tensor(3.7316e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 853 of -1
Current timestep = 854. State = [[-0.16046107  0.36457494]]. Action = [[ 0.          0.          0.         -0.95872736]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 854 is [True, False, False, False, False, True]
State prediction error at timestep 854 is tensor(2.7588e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 854 of -1
Current timestep = 855. State = [[-0.16046105  0.36457503]]. Action = [[ 0.         0.         0.        -0.9645824]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 855 is [True, False, False, False, False, True]
State prediction error at timestep 855 is tensor(3.7627e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 855 of -1
Current timestep = 856. State = [[-0.16046105  0.3645751 ]]. Action = [[0.        0.        0.        0.6229603]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 856 is [True, False, False, False, False, True]
State prediction error at timestep 856 is tensor(7.1729e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 856 of -1
Current timestep = 857. State = [[-0.16046104  0.36457518]]. Action = [[ 0.        0.        0.       -0.314678]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 857 is [True, False, False, False, False, True]
State prediction error at timestep 857 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 857 of -1
Current timestep = 858. State = [[-0.16046104  0.36457524]]. Action = [[ 0.          0.          0.         -0.02301222]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 858 is [True, False, False, False, False, True]
State prediction error at timestep 858 is tensor(6.3957e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 858 of -1
Current timestep = 859. State = [[-0.16046102  0.36457533]]. Action = [[0.        0.        0.        0.4673611]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 859 is [True, False, False, False, False, True]
State prediction error at timestep 859 is tensor(5.2022e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 859 of -1
Current timestep = 860. State = [[-0.16046102  0.3645754 ]]. Action = [[ 0.          0.          0.         -0.85296804]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 860 is [True, False, False, False, False, True]
State prediction error at timestep 860 is tensor(3.6330e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 860 of -1
Current timestep = 861. State = [[-0.16046101  0.36457545]]. Action = [[0.         0.         0.         0.30336475]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 861 is [True, False, False, False, False, True]
State prediction error at timestep 861 is tensor(9.2001e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 861 of -1
Current timestep = 862. State = [[-0.16046101  0.36457554]]. Action = [[0.        0.        0.        0.8426889]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 862 is [True, False, False, False, False, True]
State prediction error at timestep 862 is tensor(6.2876e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 862 of -1
Current timestep = 863. State = [[-0.160461   0.3645756]]. Action = [[ 0.          0.          0.         -0.02901751]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 863 is [True, False, False, False, False, True]
State prediction error at timestep 863 is tensor(6.4068e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 863 of -1
Current timestep = 864. State = [[-0.160461    0.36457568]]. Action = [[ 0.          0.          0.         -0.36638826]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 864 is [True, False, False, False, False, True]
State prediction error at timestep 864 is tensor(9.6678e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 864 of -1
Current timestep = 865. State = [[-0.160461    0.36457574]]. Action = [[ 0.          0.          0.         -0.10269314]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 865 is [True, False, False, False, False, True]
State prediction error at timestep 865 is tensor(9.7052e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 865 of -1
Current timestep = 866. State = [[-0.16046098  0.3645758 ]]. Action = [[ 0.          0.          0.         -0.26973242]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 866 is [True, False, False, False, False, True]
State prediction error at timestep 866 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 866 of -1
Current timestep = 867. State = [[-0.16046098  0.3645759 ]]. Action = [[0.        0.        0.        0.8168584]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 867 is [True, False, False, False, False, True]
State prediction error at timestep 867 is tensor(5.1501e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 867 of -1
Current timestep = 868. State = [[-0.16046096  0.36457595]]. Action = [[ 0.          0.          0.         -0.00082082]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 868 is [True, False, False, False, False, True]
State prediction error at timestep 868 is tensor(5.7800e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 868 of -1
Current timestep = 869. State = [[-0.16046096  0.364576  ]]. Action = [[ 0.          0.          0.         -0.42541206]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 869 is [True, False, False, False, False, True]
State prediction error at timestep 869 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 869 of -1
Current timestep = 870. State = [[-0.16046096  0.3645761 ]]. Action = [[0.         0.         0.         0.22637284]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 870 is [True, False, False, False, False, True]
State prediction error at timestep 870 is tensor(1.5529e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 870 of -1
Current timestep = 871. State = [[-0.16046095  0.36457616]]. Action = [[ 0.          0.          0.         -0.21286416]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 871 is [True, False, False, False, False, True]
State prediction error at timestep 871 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 871 of -1
Current timestep = 872. State = [[-0.16046095  0.36457622]]. Action = [[ 0.         0.         0.        -0.5084921]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 872 is [True, False, False, False, False, True]
State prediction error at timestep 872 is tensor(9.2809e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 872 of -1
Current timestep = 873. State = [[-0.16046095  0.36457628]]. Action = [[ 0.          0.          0.         -0.41328442]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 873 is [True, False, False, False, False, True]
State prediction error at timestep 873 is tensor(8.5803e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 873 of -1
Current timestep = 874. State = [[-0.16046093  0.36457637]]. Action = [[ 0.         0.         0.        -0.2827584]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 874 is [True, False, False, False, False, True]
State prediction error at timestep 874 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 874 of -1
Current timestep = 875. State = [[-0.16046093  0.36457643]]. Action = [[ 0.          0.          0.         -0.19570369]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 875 is [True, False, False, False, False, True]
State prediction error at timestep 875 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 875 of -1
Current timestep = 876. State = [[-0.16046093  0.3645765 ]]. Action = [[0.         0.         0.         0.02242875]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 876 is [True, False, False, False, False, True]
State prediction error at timestep 876 is tensor(4.6187e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 876 of -1
Current timestep = 877. State = [[-0.16046093  0.36457655]]. Action = [[ 0.         0.         0.        -0.5805023]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 877 is [True, False, False, False, False, True]
State prediction error at timestep 877 is tensor(9.3717e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 877 of -1
Current timestep = 878. State = [[-0.16046092  0.3645766 ]]. Action = [[0.         0.         0.         0.03573513]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 878 is [True, False, False, False, False, True]
State prediction error at timestep 878 is tensor(3.9216e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 878 of -1
Current timestep = 879. State = [[-0.16046092  0.36457667]]. Action = [[0.         0.         0.         0.02648866]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 879 is [True, False, False, False, False, True]
State prediction error at timestep 879 is tensor(4.3354e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 879 of -1
Current timestep = 880. State = [[-0.16046092  0.36457676]]. Action = [[0.         0.         0.         0.72159624]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 880 is [True, False, False, False, False, True]
State prediction error at timestep 880 is tensor(5.4015e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 880 of -1
Current timestep = 881. State = [[-0.1604609   0.36457682]]. Action = [[0.         0.         0.         0.14296508]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 881 is [True, False, False, False, False, True]
State prediction error at timestep 881 is tensor(8.9530e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 881 of -1
Current timestep = 882. State = [[-0.1604609   0.36457688]]. Action = [[ 0.         0.         0.        -0.1048286]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 882 is [True, False, False, False, False, True]
State prediction error at timestep 882 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 882 of -1
Current timestep = 883. State = [[-0.1604609   0.36457694]]. Action = [[0.        0.        0.        0.5081457]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 883 is [True, False, False, False, False, True]
State prediction error at timestep 883 is tensor(5.6260e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 883 of -1
Current timestep = 884. State = [[-0.1604609  0.364577 ]]. Action = [[0.        0.        0.        0.8677263]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 884 is [True, False, False, False, False, True]
State prediction error at timestep 884 is tensor(5.4560e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 884 of -1
Current timestep = 885. State = [[-0.16046089  0.36457705]]. Action = [[ 0.          0.          0.         -0.68689483]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 885 is [True, False, False, False, False, True]
State prediction error at timestep 885 is tensor(6.7415e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 885 of -1
Current timestep = 886. State = [[-0.16046089  0.3645771 ]]. Action = [[ 0.         0.         0.        -0.5050736]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 886 is [True, False, False, False, False, True]
State prediction error at timestep 886 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 886 of -1
Current timestep = 887. State = [[-0.16046089  0.36457717]]. Action = [[ 0.          0.          0.         -0.15573907]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 887 is [True, False, False, False, False, True]
State prediction error at timestep 887 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 887 of -1
Current timestep = 888. State = [[-0.16046089  0.36457723]]. Action = [[ 0.         0.         0.        -0.8833219]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 888 is [True, False, False, False, False, True]
State prediction error at timestep 888 is tensor(3.9738e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 888 of -1
Current timestep = 889. State = [[-0.16046089  0.3645773 ]]. Action = [[0.        0.        0.        0.7877617]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 889 is [True, False, False, False, False, True]
State prediction error at timestep 889 is tensor(5.6023e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 889 of -1
Current timestep = 890. State = [[-0.16046087  0.36457735]]. Action = [[ 0.          0.          0.         -0.05438983]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 890 is [True, False, False, False, False, True]
State prediction error at timestep 890 is tensor(8.4314e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 890 of -1
Current timestep = 891. State = [[-0.16046087  0.3645774 ]]. Action = [[ 0.         0.         0.        -0.1686492]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 891 is [True, False, False, False, False, True]
State prediction error at timestep 891 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 891 of -1
Current timestep = 892. State = [[-0.16046087  0.36457747]]. Action = [[0.         0.         0.         0.35435092]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 892 is [True, False, False, False, False, True]
State prediction error at timestep 892 is tensor(1.0267e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 892 of -1
Current timestep = 893. State = [[-0.16046087  0.36457753]]. Action = [[0.         0.         0.         0.54720974]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 893 is [True, False, False, False, False, True]
State prediction error at timestep 893 is tensor(6.4881e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 893 of -1
Current timestep = 894. State = [[-0.16046087  0.3645776 ]]. Action = [[ 0.          0.          0.         -0.01698238]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 894 is [True, False, False, False, False, True]
State prediction error at timestep 894 is tensor(7.2090e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 894 of -1
Current timestep = 895. State = [[-0.16046086  0.36457765]]. Action = [[ 0.         0.         0.        -0.5383949]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 895 is [True, False, False, False, False, True]
State prediction error at timestep 895 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 895 of -1
Current timestep = 896. State = [[-0.16046086  0.3645777 ]]. Action = [[0.         0.         0.         0.22483325]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 896 is [True, False, False, False, False, True]
State prediction error at timestep 896 is tensor(5.2340e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 896 of -1
Current timestep = 897. State = [[-0.16046086  0.36457774]]. Action = [[ 0.          0.          0.         -0.00018322]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 897 is [True, False, False, False, False, True]
State prediction error at timestep 897 is tensor(4.9699e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 897 of -1
Current timestep = 898. State = [[-0.16046086  0.3645778 ]]. Action = [[ 0.         0.         0.        -0.4886287]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 898 is [True, False, False, False, False, True]
State prediction error at timestep 898 is tensor(8.9284e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 898 of -1
Current timestep = 899. State = [[-0.26736116 -0.05054824]]. Action = [[ 0.          0.          0.         -0.20382011]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 899 is [True, False, False, False, True, False]
State prediction error at timestep 899 is tensor(0.0936, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 899 of -1
Current timestep = 900. State = [[-0.2614896  -0.05417988]]. Action = [[ 0.04927874 -0.00131176  0.         -0.5113058 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 900 is [True, False, False, False, True, False]
State prediction error at timestep 900 is tensor(3.6800e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 900 of 0
Current timestep = 901. State = [[-0.25864318 -0.05204593]]. Action = [[ 0.00942717  0.06402447  0.         -0.72002405]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 901 is [True, False, False, False, True, False]
State prediction error at timestep 901 is tensor(1.1110e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 901 of 1
Current timestep = 902. State = [[-0.25953177 -0.05526098]]. Action = [[-0.04152162 -0.08476853  0.         -0.65364784]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 902 is [True, False, False, False, True, False]
State prediction error at timestep 902 is tensor(1.0240e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 902 of 1
Current timestep = 903. State = [[-0.26121566 -0.05789503]]. Action = [[-0.02977119  0.01788205  0.         -0.9485888 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 903 is [True, False, False, False, True, False]
State prediction error at timestep 903 is tensor(1.0700e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 903 of 1
Current timestep = 904. State = [[-0.26493853 -0.06151929]]. Action = [[-0.07324878 -0.05708913  0.         -0.5243423 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 904 is [True, False, False, False, True, False]
State prediction error at timestep 904 is tensor(8.0207e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 904 of -1
Current timestep = 905. State = [[-0.26815373 -0.06804787]]. Action = [[-0.0366462 -0.0725716  0.        -0.5385567]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 905 is [True, False, False, False, True, False]
State prediction error at timestep 905 is tensor(1.8074e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 905 of -1
Current timestep = 906. State = [[-0.26675218 -0.06857912]]. Action = [[0.04553666 0.05954065 0.         0.39648438]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 906 is [True, False, False, False, True, False]
State prediction error at timestep 906 is tensor(1.3407e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 906 of -1
Current timestep = 907. State = [[-0.26945502 -0.06548189]]. Action = [[-0.07898979  0.0468151   0.          0.27418363]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 907 is [True, False, False, False, True, False]
State prediction error at timestep 907 is tensor(1.4501e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 907 of -1
Current timestep = 908. State = [[-0.27155405 -0.06070749]]. Action = [[ 0.0135867   0.07474623  0.         -0.04030764]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 908 is [True, False, False, False, True, False]
State prediction error at timestep 908 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 908 of 1
Current timestep = 909. State = [[-0.27542162 -0.06170131]]. Action = [[-0.06632879 -0.0677828   0.          0.29935503]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 909 is [True, False, False, False, True, False]
State prediction error at timestep 909 is tensor(4.3110e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 909 of -1
Current timestep = 910. State = [[-0.2825264  -0.06045873]]. Action = [[-0.08990883  0.06396768  0.         -0.32751358]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 910 is [True, False, False, False, True, False]
State prediction error at timestep 910 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 910 of -1
Current timestep = 911. State = [[-0.28582382 -0.05796529]]. Action = [[0.0128388  0.01012649 0.         0.21309686]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 911 is [True, False, False, False, True, False]
State prediction error at timestep 911 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 911 of -1
Current timestep = 912. State = [[-0.29114673 -0.06036802]]. Action = [[-0.08701398 -0.06343755  0.         -0.12531948]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 912 is [True, False, False, False, True, False]
State prediction error at timestep 912 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 912 of -1
Current timestep = 913. State = [[-0.29165947 -0.0581173 ]]. Action = [[ 0.07094648  0.07958993  0.         -0.03309268]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 913 is [True, False, False, False, True, False]
State prediction error at timestep 913 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 913 of -1
Current timestep = 914. State = [[-0.29178274 -0.05419062]]. Action = [[-0.00823005  0.0194996   0.          0.31838965]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 914 is [True, False, False, False, True, False]
State prediction error at timestep 914 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 914 of -1
Current timestep = 915. State = [[-0.29516965 -0.04933583]]. Action = [[-0.03583066  0.06829483  0.         -0.16691875]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 915 is [True, False, False, False, True, False]
State prediction error at timestep 915 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 915 of 1
Current timestep = 916. State = [[-0.30210012 -0.04191344]]. Action = [[-0.08773423  0.09071932  0.         -0.62647927]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 916 is [True, False, False, False, True, False]
State prediction error at timestep 916 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 916 of -1
Current timestep = 917. State = [[-0.3046585  -0.04152887]]. Action = [[ 0.03812277 -0.07108883  0.          0.53253853]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 917 is [True, False, False, False, True, False]
State prediction error at timestep 917 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 917 of -1
Current timestep = 918. State = [[-0.30914265 -0.04479461]]. Action = [[-0.0915462  -0.04371179  0.          0.24441445]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 918 is [True, False, False, False, True, False]
State prediction error at timestep 918 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 918 of -1
Current timestep = 919. State = [[-0.31345317 -0.04926096]]. Action = [[-0.01815567 -0.07114361  0.          0.3883351 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 919 is [True, False, False, False, True, False]
State prediction error at timestep 919 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 919 of -1
Current timestep = 920. State = [[-0.3176675  -0.04695685]]. Action = [[-0.0532964   0.08631171  0.          0.50009465]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 920 is [True, False, False, False, True, False]
State prediction error at timestep 920 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 920 of -1
Current timestep = 921. State = [[-0.32526556 -0.04381874]]. Action = [[-0.09961843  0.00893835  0.         -0.03763485]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 921 is [True, False, False, False, True, False]
State prediction error at timestep 921 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 921 of -1
Current timestep = 922. State = [[-0.3290974  -0.03858962]]. Action = [[0.01182979 0.08805641 0.         0.7192277 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 922 is [True, False, False, False, True, False]
State prediction error at timestep 922 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 922 of -1
Current timestep = 923. State = [[-0.3322136  -0.03454594]]. Action = [[-0.02821489  0.01206747  0.         -0.5543637 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 923 is [True, False, False, False, True, False]
State prediction error at timestep 923 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 923 of -1
Current timestep = 924. State = [[-0.33032057 -0.03428489]]. Action = [[ 0.09745813 -0.02343587  0.         -0.7080637 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 924 is [True, False, False, False, True, False]
State prediction error at timestep 924 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 924 of -1
Current timestep = 925. State = [[-0.32568976 -0.02964758]]. Action = [[ 0.0781569   0.08718801  0.         -0.76180464]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 925 is [True, False, False, False, True, False]
State prediction error at timestep 925 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 925 of -1
Current timestep = 926. State = [[-0.3226161  -0.02262398]]. Action = [[0.05109801 0.0691966  0.         0.11464226]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 926 is [True, False, False, False, True, False]
State prediction error at timestep 926 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 926 of -1
Current timestep = 927. State = [[-0.3223467  -0.02061258]]. Action = [[ 0.00306971 -0.02395411  0.          0.24143338]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 927 is [True, False, False, False, True, False]
State prediction error at timestep 927 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 927 of -1
Current timestep = 928. State = [[-0.32501736 -0.02051429]]. Action = [[-0.04141333 -0.00353382  0.         -0.5651383 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 928 is [True, False, False, False, True, False]
State prediction error at timestep 928 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 928 of 1
Current timestep = 929. State = [[-0.32959896 -0.01770347]]. Action = [[-0.06180633  0.04442225  0.         -0.51839125]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 929 is [True, False, False, False, True, False]
State prediction error at timestep 929 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 929 of 1
Current timestep = 930. State = [[-0.3284943  -0.01949193]]. Action = [[ 0.0688607  -0.07791112  0.          0.4321699 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 930 is [True, False, False, False, True, False]
State prediction error at timestep 930 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 930 of -1
Current timestep = 931. State = [[-0.3241353  -0.02358531]]. Action = [[ 0.04310723 -0.04731232  0.         -0.04497725]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 931 is [True, False, False, False, True, False]
State prediction error at timestep 931 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 931 of -1
Current timestep = 932. State = [[-0.3182139  -0.02253265]]. Action = [[0.07984605 0.04766052 0.         0.5121987 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 932 is [True, False, False, False, True, False]
State prediction error at timestep 932 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 932 of -1
Current timestep = 933. State = [[-0.31293768 -0.01754719]]. Action = [[ 0.0490847   0.06931374  0.         -0.28437805]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 933 is [True, False, False, False, True, False]
State prediction error at timestep 933 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 933 of 1
Current timestep = 934. State = [[-0.31365454 -0.01893274]]. Action = [[-0.0625519  -0.07790042  0.          0.33720887]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 934 is [True, False, False, False, True, False]
State prediction error at timestep 934 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 934 of 1
Current timestep = 935. State = [[-0.31210777 -0.0175158 ]]. Action = [[ 0.04701143  0.073417    0.         -0.3290606 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 935 is [True, False, False, False, True, False]
State prediction error at timestep 935 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 935 of 1
Current timestep = 936. State = [[-0.31416836 -0.01950338]]. Action = [[-0.08810835 -0.08860649  0.         -0.79624444]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 936 is [True, False, False, False, True, False]
State prediction error at timestep 936 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 936 of 1
Current timestep = 937. State = [[-0.3157552  -0.01754525]]. Action = [[-1.0468811e-04  9.4325207e-02  0.0000000e+00  6.6618037e-01]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 937 is [True, False, False, False, True, False]
State prediction error at timestep 937 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 937 of 1
Current timestep = 938. State = [[-0.31751505 -0.01563018]]. Action = [[-0.04142402 -0.02056707  0.         -0.62650454]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 938 is [True, False, False, False, True, False]
State prediction error at timestep 938 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 938 of 1
Current timestep = 939. State = [[-0.31629682 -0.01298209]]. Action = [[ 0.0438601   0.05369554  0.         -0.4920324 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 939 is [True, False, False, False, True, False]
State prediction error at timestep 939 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 939 of 1
Current timestep = 940. State = [[-0.3191377  -0.01091997]]. Action = [[-0.08355546 -0.00105561  0.         -0.8931445 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 940 is [True, False, False, False, True, False]
State prediction error at timestep 940 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 940 of 1
Current timestep = 941. State = [[-0.31995553 -0.00541901]]. Action = [[ 0.03827722  0.09573675  0.         -0.13520736]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 941 is [True, False, False, False, True, False]
State prediction error at timestep 941 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 941 of 1
Current timestep = 942. State = [[-0.3158488   0.00052939]]. Action = [[0.08519537 0.04229511 0.         0.6864053 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 942 is [True, False, False, False, True, False]
State prediction error at timestep 942 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 942 of 1
Current timestep = 943. State = [[-0.3154364  -0.00042981]]. Action = [[-0.02680769 -0.0680711   0.          0.7812376 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 943 is [True, False, False, False, True, False]
State prediction error at timestep 943 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 943 of -1
Current timestep = 944. State = [[-0.31937906  0.00253507]]. Action = [[-0.06029539  0.08200946  0.         -0.66032547]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 944 is [True, False, False, False, True, False]
State prediction error at timestep 944 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 944 of -1
Current timestep = 945. State = [[-0.32149956  0.00680305]]. Action = [[0.00411745 0.02010731 0.         0.50344324]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 945 is [True, False, False, False, True, False]
State prediction error at timestep 945 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 945 of 1
Current timestep = 946. State = [[-0.32103267  0.01341943]]. Action = [[0.02671296 0.09593926 0.         0.5416484 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 946 is [True, False, False, False, True, False]
State prediction error at timestep 946 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 946 of -1
Current timestep = 947. State = [[-0.32418182  0.01814546]]. Action = [[-0.05932006  0.0124684   0.         -0.358953  ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 947 is [True, False, False, False, True, False]
State prediction error at timestep 947 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 947 of -1
Current timestep = 948. State = [[-0.32448757  0.01664409]]. Action = [[ 0.04101341 -0.06615947  0.         -0.50964344]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 948 is [True, False, False, False, True, False]
State prediction error at timestep 948 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 948 of -1
Current timestep = 949. State = [[-0.3248542  0.0187689]]. Action = [[-0.02048173  0.06118032  0.          0.318892  ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 949 is [True, False, False, False, True, False]
State prediction error at timestep 949 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 949 of -1
Current timestep = 950. State = [[-0.32530788  0.02632918]]. Action = [[0.01641307 0.09710338 0.         0.04460549]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 950 is [True, False, False, False, True, False]
State prediction error at timestep 950 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 950 of -1
Current timestep = 951. State = [[-0.33040905  0.03478754]]. Action = [[-0.09313594  0.08648001  0.          0.1671052 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 951 is [True, False, False, False, True, False]
State prediction error at timestep 951 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 951 of -1
Current timestep = 952. State = [[-0.3381641   0.03903415]]. Action = [[-0.08414631  0.00076912  0.         -0.00126958]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 952 is [True, False, False, False, True, False]
State prediction error at timestep 952 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 952 of -1
Current timestep = 953. State = [[-0.34012777  0.03729739]]. Action = [[ 0.03010524 -0.06994638  0.          0.36355782]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 953 is [True, False, False, False, True, False]
State prediction error at timestep 953 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 953 of -1
Current timestep = 954. State = [[-0.33964506  0.03817257]]. Action = [[ 0.01082443  0.03557759  0.         -0.33316106]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 954 is [True, False, False, False, True, False]
State prediction error at timestep 954 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 954 of -1
Current timestep = 955. State = [[-0.33801118  0.0375669 ]]. Action = [[ 0.03983981 -0.04950826  0.         -0.9236735 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 955 is [True, False, False, False, True, False]
State prediction error at timestep 955 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 955 of -1
Current timestep = 956. State = [[-0.3374531   0.03724191]]. Action = [[-0.00604045  0.01005118  0.         -0.6883433 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 956 is [True, False, False, False, True, False]
State prediction error at timestep 956 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 956 of -1
Current timestep = 957. State = [[-0.33327493  0.03950961]]. Action = [[ 0.09414702  0.03465842  0.         -0.6553006 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 957 is [True, False, False, False, True, False]
State prediction error at timestep 957 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 957 of -1
Current timestep = 958. State = [[-0.32960817  0.03997771]]. Action = [[ 0.02385775 -0.01385318  0.         -0.8698999 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 958 is [True, False, False, False, True, False]
State prediction error at timestep 958 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 958 of -1
Current timestep = 959. State = [[-0.33258507  0.03631946]]. Action = [[-0.091571   -0.07029508  0.         -0.21984589]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 959 is [True, False, False, False, True, False]
State prediction error at timestep 959 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 959 of -1
Current timestep = 960. State = [[-0.33770356  0.03034862]]. Action = [[-0.07141013 -0.08092395  0.          0.5035505 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 960 is [True, False, False, False, True, False]
State prediction error at timestep 960 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 960 of 1
Current timestep = 961. State = [[-0.33837143  0.02892439]]. Action = [[0.01933499 0.02712356 0.         0.43258548]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 961 is [True, False, False, False, True, False]
State prediction error at timestep 961 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 961 of -1
Current timestep = 962. State = [[-0.3414093   0.02885156]]. Action = [[-0.07605983 -0.00633682  0.          0.06633055]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 962 is [True, False, False, False, True, False]
State prediction error at timestep 962 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 962 of -1
Current timestep = 963. State = [[-0.33982933  0.03278723]]. Action = [[ 0.08885963  0.08962794  0.         -0.14041758]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 963 is [True, False, False, False, True, False]
State prediction error at timestep 963 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 963 of -1
Current timestep = 964. State = [[-0.33444142  0.03666367]]. Action = [[ 0.07259107  0.02962743  0.         -0.3204726 ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 964 is [True, False, False, False, True, False]
State prediction error at timestep 964 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 964 of 1
Current timestep = 965. State = [[-0.3327797   0.03765369]]. Action = [[-0.00539331  0.0016198   0.         -0.6990204 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 965 is [True, False, False, False, True, False]
State prediction error at timestep 965 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 965 of 1
Current timestep = 966. State = [[-0.3349911   0.03880456]]. Action = [[-0.04503633  0.01899924  0.         -0.4867277 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 966 is [True, False, False, False, True, False]
State prediction error at timestep 966 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 966 of 1
Current timestep = 967. State = [[-0.33389997  0.04175811]]. Action = [[ 0.05105484  0.04192951  0.         -0.8066254 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 967 is [True, False, False, False, True, False]
State prediction error at timestep 967 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 967 of 1
Current timestep = 968. State = [[-0.33596754  0.0443482 ]]. Action = [[-0.06750768  0.0172744   0.         -0.83291733]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 968 is [True, False, False, False, True, False]
State prediction error at timestep 968 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 968 of 1
Current timestep = 969. State = [[-0.34101525  0.04685187]]. Action = [[-0.0612519  0.0237671  0.        -0.3258536]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 969 is [True, False, False, False, True, False]
State prediction error at timestep 969 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 969 of 1
Current timestep = 970. State = [[-0.34292936  0.04522669]]. Action = [[ 0.00342943 -0.06438698  0.         -0.42509615]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 970 is [True, False, False, False, True, False]
State prediction error at timestep 970 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 970 of 1
Current timestep = 971. State = [[-0.34265032  0.04109669]]. Action = [[ 0.0053489  -0.05694969  0.         -0.16994429]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 971 is [True, False, False, False, True, False]
State prediction error at timestep 971 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 971 of -1
Current timestep = 972. State = [[-0.3404546   0.04339979]]. Action = [[0.04421545 0.0788567  0.         0.89899623]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 972 is [True, False, False, False, True, False]
State prediction error at timestep 972 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 972 of -1
Current timestep = 973. State = [[-0.33724764  0.04705732]]. Action = [[0.0511714  0.02556673 0.         0.99367094]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 973 is [True, False, False, False, True, False]
State prediction error at timestep 973 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 973 of -1
Current timestep = 974. State = [[-0.33360738  0.0451363 ]]. Action = [[ 0.04884649 -0.05809705  0.          0.05432618]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 974 is [True, False, False, False, True, False]
State prediction error at timestep 974 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 974 of -1
Current timestep = 975. State = [[-0.3273052   0.04666793]]. Action = [[ 0.09736238  0.06730812  0.         -0.46882546]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 975 is [True, False, False, False, True, False]
State prediction error at timestep 975 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 975 of 1
Current timestep = 976. State = [[-0.3236835   0.04931084]]. Action = [[0.01393954 0.01875218 0.         0.5297941 ]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 976 is [True, False, False, False, True, False]
State prediction error at timestep 976 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 976 of 1
Current timestep = 977. State = [[-0.3231411   0.04574804]]. Action = [[-0.01339574 -0.08557257  0.         -0.7348125 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 977 is [True, False, False, False, True, False]
State prediction error at timestep 977 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 977 of 1
Current timestep = 978. State = [[-0.31956327  0.04656607]]. Action = [[0.06105032 0.06764144 0.         0.16041017]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 978 is [True, False, False, False, True, False]
State prediction error at timestep 978 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 978 of 1
Current timestep = 979. State = [[-0.31242856  0.04480015]]. Action = [[ 0.09131471 -0.06987678  0.          0.81760037]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 979 is [True, False, False, False, True, False]
State prediction error at timestep 979 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 979 of 1
Current timestep = 980. State = [[-0.30455422  0.04349337]]. Action = [[ 0.07741793  0.02008365  0.         -0.90919036]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 980 is [True, False, False, False, True, False]
State prediction error at timestep 980 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 980 of 1
Current timestep = 981. State = [[-0.2973183   0.04652502]]. Action = [[0.07082594 0.06034368 0.         0.8968376 ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 981 is [True, False, False, False, True, False]
State prediction error at timestep 981 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 981 of 1
Current timestep = 982. State = [[-0.29548377  0.0451036 ]]. Action = [[-0.04191065 -0.06027008  0.         -0.79211426]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 982 is [True, False, False, False, True, False]
State prediction error at timestep 982 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 982 of 1
Current timestep = 983. State = [[-0.29381225  0.04716358]]. Action = [[0.02177954 0.07588106 0.         0.2208041 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 983 is [True, False, False, False, True, False]
State prediction error at timestep 983 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 983 of 1
Current timestep = 984. State = [[-0.29341108  0.04991499]]. Action = [[-0.02815789  0.00938698  0.          0.3543061 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 984 is [True, False, False, False, True, False]
State prediction error at timestep 984 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 984 of 1
Current timestep = 985. State = [[-0.29213402  0.05125015]]. Action = [[0.0173711  0.01091552 0.         0.04926825]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 985 is [True, False, False, False, True, False]
State prediction error at timestep 985 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 985 of 1
Current timestep = 986. State = [[-0.28755185  0.05105827]]. Action = [[ 0.06215207 -0.01867915  0.          0.30979824]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 986 is [True, False, False, False, True, False]
State prediction error at timestep 986 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 986 of 1
Current timestep = 987. State = [[-0.2844141   0.04814013]]. Action = [[ 0.00186404 -0.05376541  0.          0.16706645]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 987 is [True, False, False, False, True, False]
State prediction error at timestep 987 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 987 of 1
Current timestep = 988. State = [[-0.2834899   0.04539664]]. Action = [[-0.01532304 -0.02730916  0.         -0.05149043]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 988 is [True, False, False, False, True, False]
State prediction error at timestep 988 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 988 of 1
Current timestep = 989. State = [[-0.27835605  0.04324316]]. Action = [[ 0.08459883 -0.02487586  0.          0.6468673 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 989 is [True, False, False, False, True, False]
State prediction error at timestep 989 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 989 of 1
Current timestep = 990. State = [[-0.2784763   0.03814908]]. Action = [[-0.09112004 -0.08310709  0.         -0.21361125]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 990 is [True, False, False, False, True, False]
State prediction error at timestep 990 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 990 of 1
Current timestep = 991. State = [[-0.28350174  0.03117419]]. Action = [[-0.08492097 -0.08577778  0.          0.08047867]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 991 is [True, False, False, False, True, False]
State prediction error at timestep 991 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 991 of 1
Current timestep = 992. State = [[-0.28319523  0.02948765]]. Action = [[ 0.04095962  0.03221171  0.         -0.96585965]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 992 is [True, False, False, False, True, False]
State prediction error at timestep 992 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 992 of -1
Current timestep = 993. State = [[-0.28313673  0.0302442 ]]. Action = [[-0.03195719  0.01500962  0.          0.15476418]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 993 is [True, False, False, False, True, False]
State prediction error at timestep 993 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 993 of -1
Current timestep = 994. State = [[-0.27976108  0.03422336]]. Action = [[0.0875928  0.08378833 0.         0.07674968]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 994 is [True, False, False, False, True, False]
State prediction error at timestep 994 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 994 of -1
Current timestep = 995. State = [[-0.28132054  0.03663692]]. Action = [[-0.08199424  0.00686894  0.         -0.5366301 ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 995 is [True, False, False, False, True, False]
State prediction error at timestep 995 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 995 of -1
Current timestep = 996. State = [[-0.28013244  0.04080937]]. Action = [[ 0.09288179  0.08085372  0.         -0.1694482 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 996 is [True, False, False, False, True, False]
State prediction error at timestep 996 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 996 of 1
Current timestep = 997. State = [[-0.27423903  0.04670629]]. Action = [[ 0.09344859  0.07134206  0.         -0.03094751]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 997 is [True, False, False, False, True, False]
State prediction error at timestep 997 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 997 of 1
Current timestep = 998. State = [[-0.27366775  0.05184686]]. Action = [[-0.02733501  0.05422992  0.          0.18239856]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 998 is [True, False, False, False, True, False]
State prediction error at timestep 998 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 998 of 1
Current timestep = 999. State = [[-0.27945894  0.05781139]]. Action = [[-0.08871098  0.07098962  0.          0.7011545 ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 999 is [True, False, False, False, True, False]
State prediction error at timestep 999 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 999 of 1
Current timestep = 1000. State = [[-0.2842214   0.06462415]]. Action = [[-0.02494478  0.06813256  0.         -0.53735167]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 1000 is [True, False, False, False, True, False]
State prediction error at timestep 1000 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1000 of -1
Current timestep = 1001. State = [[-0.28317645  0.06635546]]. Action = [[ 0.06250227 -0.03763412  0.          0.03642988]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 1001 is [True, False, False, False, True, False]
State prediction error at timestep 1001 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1001 of -1
Current timestep = 1002. State = [[-0.28583834  0.06239468]]. Action = [[-0.08362453 -0.09093294  0.          0.42904758]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 1002 is [True, False, False, False, True, False]
State prediction error at timestep 1002 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1002 of -1
Current timestep = 1003. State = [[-0.28434178  0.06372632]]. Action = [[ 0.09626872  0.05950334  0.         -0.04455996]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 1003 is [True, False, False, False, True, False]
State prediction error at timestep 1003 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1003 of -1
Current timestep = 1004. State = [[-0.28552705  0.06630705]]. Action = [[-0.08455908 -0.00301911  0.          0.01801562]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 1004 is [True, False, False, False, True, False]
State prediction error at timestep 1004 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1004 of -1
Current timestep = 1005. State = [[-0.2916433   0.06792224]]. Action = [[-0.07929549  0.00840808  0.         -0.23542011]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 1005 is [True, False, False, False, True, False]
State prediction error at timestep 1005 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1005 of -1
Current timestep = 1006. State = [[-0.29074183  0.0652146 ]]. Action = [[ 0.07177674 -0.07817374  0.         -0.52086174]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 1006 is [True, False, False, False, True, False]
State prediction error at timestep 1006 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1006 of -1
Current timestep = 1007. State = [[-0.29264197  0.06280239]]. Action = [[-0.08398767 -0.01326595  0.         -0.5829605 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 1007 is [True, False, False, False, True, False]
State prediction error at timestep 1007 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1007 of -1
Current timestep = 1008. State = [[-0.29058003  0.06191372]]. Action = [[ 0.0931311  -0.0110705   0.          0.32375622]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 1008 is [True, False, False, False, True, False]
State prediction error at timestep 1008 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1008 of -1
Current timestep = 1009. State = [[-0.29141706  0.06639244]]. Action = [[-0.07296471  0.09797943  0.          0.48532236]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 1009 is [True, False, False, False, True, False]
State prediction error at timestep 1009 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1009 of 1
Current timestep = 1010. State = [[-0.29501536  0.0734648 ]]. Action = [[-0.02547541  0.07973505  0.          0.96836054]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 1010 is [True, False, False, False, True, False]
State prediction error at timestep 1010 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1010 of 1
Current timestep = 1011. State = [[-0.29747835  0.08050773]]. Action = [[-0.0136195   0.08072116  0.          0.13044691]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 1011 is [True, False, False, False, True, False]
State prediction error at timestep 1011 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1011 of -1
Current timestep = 1012. State = [[-0.30368006  0.08562973]]. Action = [[-0.09390807  0.03472514  0.          0.3300172 ]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 1012 is [True, False, False, False, True, False]
State prediction error at timestep 1012 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1012 of -1
Current timestep = 1013. State = [[-0.30745623  0.0868698 ]]. Action = [[ 0.00177975 -0.02296381  0.          0.729386  ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 1013 is [True, False, False, False, True, False]
State prediction error at timestep 1013 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1013 of -1
Current timestep = 1014. State = [[-0.30802137  0.08612801]]. Action = [[ 0.01241927 -0.0246955   0.         -0.5054402 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 1014 is [True, False, False, False, True, False]
State prediction error at timestep 1014 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1014 of -1
Current timestep = 1015. State = [[-0.31267458  0.08870506]]. Action = [[-0.08238242  0.04734514  0.         -0.74072903]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 1015 is [True, False, False, False, True, False]
State prediction error at timestep 1015 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1015 of -1
Current timestep = 1016. State = [[-0.31659168  0.09416831]]. Action = [[-0.00686626  0.06150299  0.         -0.751546  ]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 1016 is [True, False, False, False, True, False]
State prediction error at timestep 1016 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1016 of -1
Current timestep = 1017. State = [[-0.31909403  0.09749795]]. Action = [[-0.014603    0.0092338   0.         -0.89224344]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 1017 is [True, False, False, False, True, False]
State prediction error at timestep 1017 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1017 of -1
Current timestep = 1018. State = [[-0.3195728   0.09874455]]. Action = [[ 0.02534146 -0.00066356  0.          0.51985455]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 1018 is [True, False, False, False, True, False]
State prediction error at timestep 1018 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1018 of -1
Current timestep = 1019. State = [[-0.32021037  0.09594489]]. Action = [[-0.00897259 -0.07146704  0.         -0.9405016 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 1019 is [True, False, False, False, True, False]
State prediction error at timestep 1019 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1019 of -1
Current timestep = 1020. State = [[-0.3229188   0.09694902]]. Action = [[-0.039662    0.05027387  0.         -0.99246436]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 1020 is [True, False, False, False, True, False]
State prediction error at timestep 1020 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1020 of -1
Current timestep = 1021. State = [[-0.32894662  0.10208686]]. Action = [[-0.08251435  0.06255407  0.          0.19584572]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 1021 is [True, False, False, False, True, False]
State prediction error at timestep 1021 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1021 of -1
Current timestep = 1022. State = [[-0.3344849   0.10942861]]. Action = [[-0.0362371   0.09313541  0.         -0.29017234]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 1022 is [True, False, False, False, True, False]
State prediction error at timestep 1022 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1022 of -1
Current timestep = 1023. State = [[-0.337294    0.10924114]]. Action = [[-0.00360053 -0.08101942  0.         -0.9386161 ]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 1023 is [True, False, False, False, True, False]
State prediction error at timestep 1023 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1023 of -1
Current timestep = 1024. State = [[-0.33813825  0.1036778 ]]. Action = [[ 0.00231934 -0.08255223  0.          0.66857755]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 1024 is [True, False, False, False, True, False]
State prediction error at timestep 1024 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1024 of -1
Current timestep = 1025. State = [[-0.33880913  0.10401906]]. Action = [[-0.00234515  0.05253888  0.         -0.638631  ]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 1025 is [True, False, False, False, True, False]
State prediction error at timestep 1025 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1025 of -1
Current timestep = 1026. State = [[-0.3415621   0.10641295]]. Action = [[-0.03710233  0.01558413  0.          0.7949939 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 1026 is [True, False, False, False, True, False]
State prediction error at timestep 1026 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1026 of 1
Current timestep = 1027. State = [[-0.34298295  0.10812747]]. Action = [[ 0.01025621  0.01873181  0.         -0.5447395 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 1027 is [True, False, False, False, True, False]
State prediction error at timestep 1027 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1027 of -1
Current timestep = 1028. State = [[-0.3426781   0.11111711]]. Action = [[ 0.02032954  0.04715175  0.         -0.18208212]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 1028 is [True, False, False, False, True, False]
State prediction error at timestep 1028 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1028 of -1
Current timestep = 1029. State = [[-0.3450827   0.11715688]]. Action = [[-0.0378041   0.09170363  0.         -0.84207505]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 1029 is [True, False, False, False, True, False]
State prediction error at timestep 1029 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1029 of -1
Current timestep = 1030. State = [[-0.34468973  0.11788674]]. Action = [[ 0.05250616 -0.04750296  0.          0.8096514 ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 1030 is [True, False, False, False, True, False]
State prediction error at timestep 1030 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1030 of -1
Current timestep = 1031. State = [[-0.34822366  0.11666366]]. Action = [[-0.09104518 -0.0092339   0.          0.51063466]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 1031 is [True, False, False, False, True, False]
State prediction error at timestep 1031 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1031 of -1
Current timestep = 1032. State = [[-0.35121712  0.11950804]]. Action = [[0.00415292 0.05120593 0.         0.38383925]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 1032 is [True, False, False, False, True, False]
State prediction error at timestep 1032 is tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1032 of -1
Current timestep = 1033. State = [[-0.35537463  0.1186773 ]]. Action = [[-0.07111868 -0.06068818  0.         -0.89924973]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 1033 is [True, False, False, False, True, False]
State prediction error at timestep 1033 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1033 of -1
Current timestep = 1034. State = [[-0.3579835   0.12088612]]. Action = [[0.0037444  0.06534726 0.         0.52099967]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 1034 is [True, False, False, False, True, False]
State prediction error at timestep 1034 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1034 of -1
Current timestep = 1035. State = [[-0.35563764  0.12160814]]. Action = [[ 0.06526386 -0.0287113   0.         -0.85857916]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 1035 is [True, False, False, False, True, False]
State prediction error at timestep 1035 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1035 of -1
Current timestep = 1036. State = [[-0.3582244   0.12314755]]. Action = [[-0.07938038  0.04160009  0.         -0.71056044]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 1036 is [True, False, False, False, True, False]
State prediction error at timestep 1036 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1036 of -1
Current timestep = 1037. State = [[-0.35878873  0.12016766]]. Action = [[ 0.04117069 -0.09544248  0.         -0.7021    ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 1037 is [True, False, False, False, True, False]
State prediction error at timestep 1037 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1037 of -1
Current timestep = 1038. State = [[-0.35820407  0.11813156]]. Action = [[-0.00845586  0.01168598  0.          0.11233151]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 1038 is [True, False, False, False, True, False]
State prediction error at timestep 1038 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1038 of -1
Current timestep = 1039. State = [[-0.35359347  0.11579254]]. Action = [[ 0.09750425 -0.04690183  0.          0.9678422 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 1039 is [True, False, False, False, True, False]
State prediction error at timestep 1039 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1039 of -1
Current timestep = 1040. State = [[-0.34812027  0.11348997]]. Action = [[ 0.04803231 -0.00495696  0.          0.605369  ]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 1040 is [True, False, False, False, True, False]
State prediction error at timestep 1040 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1040 of -1
Current timestep = 1041. State = [[-0.34500596  0.1111028 ]]. Action = [[ 0.01885387 -0.02876265  0.          0.3063345 ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 1041 is [True, False, False, False, True, False]
State prediction error at timestep 1041 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1041 of -1
Current timestep = 1042. State = [[-0.34701902  0.11410791]]. Action = [[-0.06816672  0.08986201  0.          0.5609926 ]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 1042 is [True, False, False, False, True, False]
State prediction error at timestep 1042 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1042 of 1
Current timestep = 1043. State = [[-0.3451521   0.11329932]]. Action = [[ 0.06867387 -0.0654619   0.         -0.02488965]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 1043 is [True, False, False, False, True, False]
State prediction error at timestep 1043 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1043 of 1
Current timestep = 1044. State = [[-0.34487933  0.10964908]]. Action = [[-0.04674292 -0.02818871  0.         -0.12323755]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 1044 is [True, False, False, False, True, False]
State prediction error at timestep 1044 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1044 of 1
Current timestep = 1045. State = [[-0.3457267   0.10989293]]. Action = [[-0.00570326  0.02966242  0.         -0.49206555]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 1045 is [True, False, False, False, True, False]
State prediction error at timestep 1045 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1045 of 1
Current timestep = 1046. State = [[-0.34752357  0.11443438]]. Action = [[-0.0338449   0.08047212  0.         -0.07192934]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 1046 is [True, False, False, False, True, False]
State prediction error at timestep 1046 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1046 of 1
Current timestep = 1047. State = [[-0.3533196   0.11583896]]. Action = [[-0.09343626 -0.02353076  0.         -0.52139807]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 1047 is [True, False, False, False, True, False]
State prediction error at timestep 1047 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1047 of 1
Current timestep = 1048. State = [[-0.35771132  0.11846154]]. Action = [[-0.02346426  0.0533025   0.          0.1753813 ]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 1048 is [True, False, False, False, True, False]
State prediction error at timestep 1048 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1048 of 1
Current timestep = 1049. State = [[-0.3644963  0.1251485]]. Action = [[-0.09602811  0.09234486  0.          0.5062871 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 1049 is [True, False, False, False, False, True]
State prediction error at timestep 1049 is tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1049 of 1
Current timestep = 1050. State = [[-0.36741367  0.12475019]]. Action = [[ 0.02855597 -0.08930166  0.          0.1731267 ]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 1050 is [True, False, False, False, True, False]
State prediction error at timestep 1050 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1050 of -1
Current timestep = 1051. State = [[-0.36399242  0.11788341]]. Action = [[ 0.07483751 -0.09562352  0.          0.42852068]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 1051 is [True, False, False, False, True, False]
State prediction error at timestep 1051 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1051 of -1
Current timestep = 1052. State = [[-0.36044332  0.1138101 ]]. Action = [[ 0.03561001 -0.01690758  0.         -0.7508886 ]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 1052 is [True, False, False, False, True, False]
State prediction error at timestep 1052 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1052 of -1
Current timestep = 1053. State = [[-0.3569477   0.11053612]]. Action = [[ 0.04860344 -0.04192321  0.         -0.8987875 ]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 1053 is [True, False, False, False, True, False]
State prediction error at timestep 1053 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1053 of -1
Current timestep = 1054. State = [[-0.35455322  0.11258937]]. Action = [[ 0.01773043  0.08321417  0.         -0.45459306]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 1054 is [True, False, False, False, True, False]
State prediction error at timestep 1054 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1054 of -1
Current timestep = 1055. State = [[-0.35458755  0.11607035]]. Action = [[-0.00845366  0.03646123  0.         -0.06660557]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 1055 is [True, False, False, False, True, False]
State prediction error at timestep 1055 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1055 of 1
Current timestep = 1056. State = [[-0.3595091   0.11894163]]. Action = [[-0.09191071  0.03760342  0.         -0.20754766]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 1056 is [True, False, False, False, True, False]
State prediction error at timestep 1056 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1056 of 1
Current timestep = 1057. State = [[-0.35988295  0.11816862]]. Action = [[ 0.05199585 -0.0423285   0.          0.55694294]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 1057 is [True, False, False, False, True, False]
State prediction error at timestep 1057 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1057 of -1
Current timestep = 1058. State = [[-0.36126587  0.11683577]]. Action = [[-0.05291798 -0.00378602  0.         -0.12654221]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 1058 is [True, False, False, False, True, False]
State prediction error at timestep 1058 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1058 of -1
Current timestep = 1059. State = [[-0.3611504   0.11804146]]. Action = [[ 0.03577361  0.02567085  0.         -0.38613617]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 1059 is [True, False, False, False, True, False]
State prediction error at timestep 1059 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1059 of -1
Current timestep = 1060. State = [[-0.35657993  0.11896988]]. Action = [[ 0.08027884  0.00822143  0.         -0.51721704]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 1060 is [True, False, False, False, True, False]
State prediction error at timestep 1060 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1060 of -1
Current timestep = 1061. State = [[-0.35719562  0.11554427]]. Action = [[-0.06795084 -0.07468517  0.         -0.14499003]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 1061 is [True, False, False, False, True, False]
State prediction error at timestep 1061 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1061 of 1
Current timestep = 1062. State = [[-0.35593602  0.11287298]]. Action = [[ 0.06517727 -0.00664821  0.         -0.90929115]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 1062 is [True, False, False, False, True, False]
State prediction error at timestep 1062 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1062 of 1
Current timestep = 1063. State = [[-0.35664114  0.11655425]]. Action = [[-0.04868907  0.08904345  0.          0.6416279 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 1063 is [True, False, False, False, True, False]
State prediction error at timestep 1063 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1063 of 1
Current timestep = 1064. State = [[-0.35585284  0.12174082]]. Action = [[0.05247603 0.05631644 0.         0.32620418]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 1064 is [True, False, False, False, True, False]
State prediction error at timestep 1064 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1064 of 1
Current timestep = 1065. State = [[-0.35585013  0.12768954]]. Action = [[-0.01454496  0.08716307  0.          0.5044488 ]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 1065 is [True, False, False, False, False, True]
State prediction error at timestep 1065 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1065 of -1
Current timestep = 1066. State = [[-0.3571001   0.13429664]]. Action = [[ 2.7692318e-04  7.5956158e-02  0.0000000e+00 -8.8923150e-01]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 1066 is [True, False, False, False, False, True]
State prediction error at timestep 1066 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1066 of -1
Current timestep = 1067. State = [[-0.35529032  0.13577437]]. Action = [[ 0.05338974 -0.02739809  0.          0.8547753 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 1067 is [True, False, False, False, False, True]
State prediction error at timestep 1067 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1067 of -1
Current timestep = 1068. State = [[-0.35420737  0.1399966 ]]. Action = [[0.00070437 0.086729   0.         0.16650808]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 1068 is [True, False, False, False, False, True]
State prediction error at timestep 1068 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1068 of -1
Current timestep = 1069. State = [[-0.35392517  0.14106022]]. Action = [[ 0.01178374 -0.04727913  0.         -0.5371316 ]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 1069 is [True, False, False, False, False, True]
State prediction error at timestep 1069 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1069 of -1
Current timestep = 1070. State = [[-0.35035908  0.14560066]]. Action = [[0.06809006 0.09769601 0.         0.20157921]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 1070 is [True, False, False, False, False, True]
State prediction error at timestep 1070 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1070 of 1
Current timestep = 1071. State = [[-0.3451117   0.14999618]]. Action = [[0.06334291 0.01632784 0.         0.29317355]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 1071 is [True, False, False, False, False, True]
State prediction error at timestep 1071 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1071 of 1
Current timestep = 1072. State = [[-0.34348825  0.155519  ]]. Action = [[-0.01627309  0.07772031  0.         -0.46380436]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 1072 is [True, False, False, False, False, True]
State prediction error at timestep 1072 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1072 of 1
Current timestep = 1073. State = [[-0.3475813   0.16368544]]. Action = [[-0.08237547  0.08803008  0.          0.9278774 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 1073 is [True, False, False, False, False, True]
State prediction error at timestep 1073 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1073 of -1
Current timestep = 1074. State = [[-0.35083607  0.16966474]]. Action = [[-0.01730584  0.02676343  0.          0.98473763]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 1074 is [True, False, False, False, False, True]
State prediction error at timestep 1074 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1074 of -1
Current timestep = 1075. State = [[-0.34907925  0.17305054]]. Action = [[0.04898327 0.00962325 0.         0.8628975 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 1075 is [True, False, False, False, False, True]
State prediction error at timestep 1075 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1075 of -1
Current timestep = 1076. State = [[-0.34315866  0.17870888]]. Action = [[0.09119635 0.07658667 0.         0.5037079 ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 1076 is [True, False, False, False, False, True]
State prediction error at timestep 1076 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1076 of -1
Current timestep = 1077. State = [[-0.3446361   0.18461327]]. Action = [[-0.0921452   0.03917176  0.         -0.23075962]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 1077 is [True, False, False, False, False, True]
State prediction error at timestep 1077 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1077 of -1
Current timestep = 1078. State = [[-0.34891775  0.18448849]]. Action = [[-0.0348191  -0.07084827  0.         -0.19878441]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 1078 is [True, False, False, False, False, True]
State prediction error at timestep 1078 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1078 of 1
Current timestep = 1079. State = [[-0.35084432  0.18596   ]]. Action = [[-0.01576199  0.02698327  0.         -0.6072382 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 1079 is [True, False, False, False, False, True]
State prediction error at timestep 1079 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1079 of -1
Current timestep = 1080. State = [[-0.347805    0.18579729]]. Action = [[ 0.07258458 -0.04792922  0.         -0.10639739]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 1080 is [True, False, False, False, False, True]
State prediction error at timestep 1080 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1080 of -1
Current timestep = 1081. State = [[-0.34672207  0.18835013]]. Action = [[-0.02466597  0.06025376  0.         -0.81959265]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 1081 is [True, False, False, False, False, True]
State prediction error at timestep 1081 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1081 of -1
Current timestep = 1082. State = [[-0.34379217  0.18649063]]. Action = [[ 0.06557367 -0.09124499  0.         -0.81067216]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 1082 is [True, False, False, False, False, True]
State prediction error at timestep 1082 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1082 of -1
Current timestep = 1083. State = [[-0.34552583  0.1804366 ]]. Action = [[-0.09333538 -0.09177454  0.         -0.856336  ]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 1083 is [True, False, False, False, False, True]
State prediction error at timestep 1083 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1083 of -1
Current timestep = 1084. State = [[-0.35104308  0.17662112]]. Action = [[-0.07818161 -0.044213    0.         -0.7300948 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 1084 is [True, False, False, False, False, True]
State prediction error at timestep 1084 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1084 of -1
Current timestep = 1085. State = [[-0.35604548  0.1781851 ]]. Action = [[-0.05739737  0.04774917  0.         -0.6324887 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 1085 is [True, False, False, False, False, True]
State prediction error at timestep 1085 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1085 of 1
Current timestep = 1086. State = [[-0.35601372  0.1759019 ]]. Action = [[ 0.04337467 -0.07443652  0.          0.14613318]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 1086 is [True, False, False, False, False, True]
State prediction error at timestep 1086 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1086 of 1
Current timestep = 1087. State = [[-0.35094428  0.17540647]]. Action = [[ 0.0868515   0.04992367  0.         -0.4455803 ]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 1087 is [True, False, False, False, False, True]
State prediction error at timestep 1087 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1087 of 1
Current timestep = 1088. State = [[-0.35193014  0.17673141]]. Action = [[-0.06651745  0.02115299  0.          0.5717857 ]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 1088 is [True, False, False, False, False, True]
State prediction error at timestep 1088 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1088 of 1
Current timestep = 1089. State = [[-0.35609114  0.17920674]]. Action = [[-0.03283507  0.0504579   0.         -0.09196013]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 1089 is [True, False, False, False, False, True]
State prediction error at timestep 1089 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1089 of 1
Current timestep = 1090. State = [[-0.3539446   0.17834541]]. Action = [[ 0.08410539 -0.03203572  0.          0.4852388 ]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 1090 is [True, False, False, False, False, True]
State prediction error at timestep 1090 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1090 of 1
Current timestep = 1091. State = [[-0.34836257  0.17324641]]. Action = [[ 0.07510067 -0.06273597  0.         -0.83335596]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 1091 is [True, False, False, False, False, True]
State prediction error at timestep 1091 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1091 of 1
Current timestep = 1092. State = [[-0.3414942   0.17398879]]. Action = [[0.09414711 0.08179157 0.         0.98209167]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 1092 is [True, False, False, False, False, True]
State prediction error at timestep 1092 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1092 of 1
Current timestep = 1093. State = [[-0.3342978   0.17936967]]. Action = [[ 0.08766346  0.09739447  0.         -0.6829613 ]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 1093 is [True, False, False, False, False, True]
State prediction error at timestep 1093 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1093 of 1
Current timestep = 1094. State = [[-0.328517    0.18025264]]. Action = [[ 0.05333165 -0.0154634   0.          0.24820983]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 1094 is [True, False, False, False, False, True]
State prediction error at timestep 1094 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1094 of 1
Current timestep = 1095. State = [[-0.33034876  0.18300033]]. Action = [[-0.08806758  0.07133163  0.          0.6060729 ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 1095 is [True, False, False, False, False, True]
State prediction error at timestep 1095 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1095 of 1
Current timestep = 1096. State = [[-0.33591893  0.18218057]]. Action = [[-0.08064023 -0.07183146  0.         -0.12513953]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 1096 is [True, False, False, False, False, True]
State prediction error at timestep 1096 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1096 of 1
Current timestep = 1097. State = [[-0.3399887   0.18118599]]. Action = [[-0.04738054 -0.00543211  0.          0.25267863]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 1097 is [True, False, False, False, False, True]
State prediction error at timestep 1097 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1097 of 1
Current timestep = 1098. State = [[-0.34059995  0.18137245]]. Action = [[ 0.01257851 -0.00986761  0.         -0.50221986]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 1098 is [True, False, False, False, False, True]
State prediction error at timestep 1098 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1098 of 1
Current timestep = 1099. State = [[-0.33550093  0.18452431]]. Action = [[0.09825825 0.06476519 0.         0.7571604 ]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 1099 is [True, False, False, False, False, True]
State prediction error at timestep 1099 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1099 of 1
Current timestep = 1100. State = [[-0.33574334  0.18631525]]. Action = [[-0.07078286 -0.0086139   0.         -0.9552854 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 1100 is [True, False, False, False, False, True]
State prediction error at timestep 1100 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1100 of 1
Current timestep = 1101. State = [[-0.33362043  0.18230866]]. Action = [[ 0.08086879 -0.0851272   0.          0.6171615 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 1101 is [True, False, False, False, False, True]
State prediction error at timestep 1101 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1101 of 1
Current timestep = 1102. State = [[-0.33015236  0.17868572]]. Action = [[ 0.0179434  -0.02194027  0.         -0.47170997]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 1102 is [True, False, False, False, False, True]
State prediction error at timestep 1102 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1102 of 1
Current timestep = 1103. State = [[-0.327852    0.18159084]]. Action = [[ 0.02617712  0.08052609  0.         -0.8375871 ]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 1103 is [True, False, False, False, False, True]
State prediction error at timestep 1103 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1103 of 1
Current timestep = 1104. State = [[-0.3305743   0.18434975]]. Action = [[-0.07576706  0.01289121  0.          0.30164456]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 1104 is [True, False, False, False, False, True]
State prediction error at timestep 1104 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1104 of 1
Current timestep = 1105. State = [[-0.32910168  0.1889934 ]]. Action = [[0.08096982 0.08837397 0.         0.84119475]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 1105 is [True, False, False, False, False, True]
State prediction error at timestep 1105 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1105 of -1
Current timestep = 1106. State = [[-0.3228905   0.18844186]]. Action = [[ 0.07739333 -0.0581619   0.         -0.1426804 ]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 1106 is [True, False, False, False, False, True]
State prediction error at timestep 1106 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1106 of -1
Current timestep = 1107. State = [[-0.3150867  0.1847976]]. Action = [[ 0.09188602 -0.03860239  0.          0.7894572 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 1107 is [True, False, False, False, False, True]
State prediction error at timestep 1107 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1107 of -1
Current timestep = 1108. State = [[-0.30852598  0.18647254]]. Action = [[ 0.05128605  0.06581513  0.         -0.5705364 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 1108 is [True, False, False, False, False, True]
State prediction error at timestep 1108 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1108 of 1
Current timestep = 1109. State = [[-0.30506143  0.18435149]]. Action = [[ 0.00703689 -0.0777566   0.          0.01871085]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 1109 is [True, False, False, False, False, True]
State prediction error at timestep 1109 is tensor(9.2429e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1109 of 1
Current timestep = 1110. State = [[-0.30689204  0.18599987]]. Action = [[-0.07375075  0.07330563  0.         -0.9437735 ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 1110 is [True, False, False, False, False, True]
State prediction error at timestep 1110 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1110 of 1
Current timestep = 1111. State = [[-0.3071761   0.18506782]]. Action = [[ 0.01500432 -0.07050712  0.         -0.05386573]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 1111 is [True, False, False, False, False, True]
State prediction error at timestep 1111 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1111 of 1
Current timestep = 1112. State = [[-0.3083474   0.18527478]]. Action = [[-0.05152411  0.03314958  0.         -0.5594704 ]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 1112 is [True, False, False, False, False, True]
State prediction error at timestep 1112 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1112 of 1
Current timestep = 1113. State = [[-0.30899608  0.18763457]]. Action = [[0.00454687 0.02033329 0.         0.96839   ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 1113 is [True, False, False, False, False, True]
State prediction error at timestep 1113 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1113 of 1
Current timestep = 1114. State = [[-0.30531645  0.18756713]]. Action = [[ 0.06580659 -0.01884146  0.         -0.5643432 ]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 1114 is [True, False, False, False, False, True]
State prediction error at timestep 1114 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1114 of 1
Current timestep = 1115. State = [[-0.29956788  0.18688057]]. Action = [[ 0.06756326 -0.00030108  0.          0.23842442]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 1115 is [True, False, False, False, False, True]
State prediction error at timestep 1115 is tensor(8.1082e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1115 of 1
Current timestep = 1116. State = [[-0.29807806  0.18919261]]. Action = [[-0.02347575  0.05167843  0.          0.29203224]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 1116 is [True, False, False, False, False, True]
State prediction error at timestep 1116 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1116 of 1
Current timestep = 1117. State = [[-0.2942104   0.19313861]]. Action = [[0.08204813 0.05218997 0.         0.6164415 ]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 1117 is [True, False, False, False, False, True]
State prediction error at timestep 1117 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1117 of 1
Current timestep = 1118. State = [[-0.294271    0.19270813]]. Action = [[-0.06472588 -0.04515331  0.         -0.1174739 ]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 1118 is [True, False, False, False, False, True]
State prediction error at timestep 1118 is tensor(8.1444e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1118 of 1
Current timestep = 1119. State = [[-0.2974068   0.19592409]]. Action = [[-0.03092806  0.08313837  0.         -0.61892843]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 1119 is [True, False, False, False, False, True]
State prediction error at timestep 1119 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1119 of 1
Current timestep = 1120. State = [[-0.29966456  0.20224947]]. Action = [[-0.01423135  0.07578192  0.         -0.5336755 ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 1120 is [True, False, False, False, False, True]
State prediction error at timestep 1120 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1120 of 1
Current timestep = 1121. State = [[-0.29702652  0.20841086]]. Action = [[ 0.08040246  0.07448094  0.         -0.8368709 ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 1121 is [True, False, False, False, False, True]
State prediction error at timestep 1121 is tensor(9.3872e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1121 of -1
Current timestep = 1122. State = [[-0.29511446  0.20880146]]. Action = [[ 0.00200246 -0.04466206  0.         -0.16655165]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 1122 is [True, False, False, False, False, True]
State prediction error at timestep 1122 is tensor(5.4234e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1122 of -1
Current timestep = 1123. State = [[-0.29699892  0.2124516 ]]. Action = [[-0.03269245  0.08454745  0.         -0.00854874]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 1123 is [True, False, False, False, False, True]
State prediction error at timestep 1123 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1123 of -1
Current timestep = 1124. State = [[-0.29643348  0.21176276]]. Action = [[ 0.04003585 -0.07983979  0.         -0.68133366]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 1124 is [True, False, False, False, False, True]
State prediction error at timestep 1124 is tensor(2.9099e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1124 of -1
Current timestep = 1125. State = [[-0.29342166  0.2094639 ]]. Action = [[ 0.03602616 -0.02018242  0.          0.80133784]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 1125 is [True, False, False, False, False, True]
State prediction error at timestep 1125 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1125 of -1
Current timestep = 1126. State = [[-0.28855565  0.20882724]]. Action = [[ 0.06726571 -0.00920992  0.          0.71904504]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 1126 is [True, False, False, False, False, True]
State prediction error at timestep 1126 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1126 of -1
Current timestep = 1127. State = [[-0.2869697   0.20939866]]. Action = [[-0.02245858  0.01146499  0.          0.38394058]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 1127 is [True, False, False, False, False, True]
State prediction error at timestep 1127 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1127 of -1
Current timestep = 1128. State = [[-0.28440318  0.20778705]]. Action = [[ 0.04575291 -0.04721526  0.         -0.0926559 ]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 1128 is [True, False, False, False, False, True]
State prediction error at timestep 1128 is tensor(8.0604e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1128 of 1
Current timestep = 1129. State = [[-0.28437835  0.20604365]]. Action = [[-0.0479325  -0.01490886  0.          0.25269926]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 1129 is [True, False, False, False, False, True]
State prediction error at timestep 1129 is tensor(8.9587e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1129 of 1
Current timestep = 1130. State = [[-0.28776732  0.2055616 ]]. Action = [[-0.0636156 -0.0113628  0.         0.7115772]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 1130 is [True, False, False, False, False, True]
State prediction error at timestep 1130 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1130 of 1
Current timestep = 1131. State = [[-0.29040995  0.20630796]]. Action = [[-0.02860375  0.01023474  0.         -0.66434634]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 1131 is [True, False, False, False, False, True]
State prediction error at timestep 1131 is tensor(3.5139e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1131 of 1
Current timestep = 1132. State = [[-0.29486156  0.21008398]]. Action = [[-0.07329617  0.06132434  0.          0.9702389 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 1132 is [True, False, False, False, False, True]
State prediction error at timestep 1132 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1132 of 1
Current timestep = 1133. State = [[-0.30142748  0.21374403]]. Action = [[-0.07841681  0.02494027  0.          0.9451666 ]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 1133 is [True, False, False, False, False, True]
State prediction error at timestep 1133 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1133 of 1
Current timestep = 1134. State = [[-0.30754346  0.21234353]]. Action = [[-0.05892831 -0.06357607  0.         -0.18603659]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 1134 is [True, False, False, False, False, True]
State prediction error at timestep 1134 is tensor(8.8530e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1134 of -1
Current timestep = 1135. State = [[-0.31475797  0.21298872]]. Action = [[-0.0878264   0.02974541  0.          0.76776206]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 1135 is [True, False, False, False, False, True]
State prediction error at timestep 1135 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1135 of -1
Current timestep = 1136. State = [[-0.32196897  0.21392263]]. Action = [[-0.06066592 -0.01340693  0.          0.7230505 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 1136 is [True, False, False, False, False, True]
State prediction error at timestep 1136 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1136 of -1
Current timestep = 1137. State = [[-0.32578948  0.21075256]]. Action = [[-0.004645   -0.07025833  0.         -0.41451752]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 1137 is [True, False, False, False, False, True]
State prediction error at timestep 1137 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1137 of -1
Current timestep = 1138. State = [[-0.32749137  0.20614532]]. Action = [[ 0.00087271 -0.05619431  0.          0.11692142]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 1138 is [True, False, False, False, False, True]
State prediction error at timestep 1138 is tensor(7.6973e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1138 of -1
Current timestep = 1139. State = [[-0.32757905  0.20049037]]. Action = [[ 0.02313383 -0.07411907  0.          0.8239839 ]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 1139 is [True, False, False, False, False, True]
State prediction error at timestep 1139 is tensor(3.3495e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1139 of -1
Current timestep = 1140. State = [[-0.3324227   0.19550951]]. Action = [[-0.09145276 -0.04594575  0.          0.22370839]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 1140 is [True, False, False, False, False, True]
State prediction error at timestep 1140 is tensor(9.4241e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1140 of -1
Current timestep = 1141. State = [[-0.33902824  0.19607836]]. Action = [[-0.05581429  0.05126534  0.          0.41544938]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 1141 is [True, False, False, False, False, True]
State prediction error at timestep 1141 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1141 of -1
Current timestep = 1142. State = [[-0.33985323  0.19387013]]. Action = [[ 0.0514564  -0.05352847  0.         -0.9389991 ]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 1142 is [True, False, False, False, False, True]
State prediction error at timestep 1142 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1142 of -1
Current timestep = 1143. State = [[-0.33693513  0.19239876]]. Action = [[0.05929448 0.03227704 0.         0.15163791]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 1143 is [True, False, False, False, False, True]
State prediction error at timestep 1143 is tensor(4.3428e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1143 of -1
Current timestep = 1144. State = [[-0.33525944  0.19341326]]. Action = [[0.023332   0.04267981 0.         0.28940403]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 1144 is [True, False, False, False, False, True]
State prediction error at timestep 1144 is tensor(4.6353e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1144 of -1
Current timestep = 1145. State = [[-0.33076093  0.19165093]]. Action = [[ 0.09539369 -0.02368113  0.          0.47739244]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 1145 is [True, False, False, False, False, True]
State prediction error at timestep 1145 is tensor(1.4711e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1145 of -1
Current timestep = 1146. State = [[-0.3242172  0.192453 ]]. Action = [[0.08643558 0.06947353 0.         0.26219475]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 1146 is [True, False, False, False, False, True]
State prediction error at timestep 1146 is tensor(1.2480e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1146 of -1
Current timestep = 1147. State = [[-0.32001832  0.19297732]]. Action = [[ 0.03384759  0.00833534  0.         -0.10037386]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 1147 is [True, False, False, False, False, True]
State prediction error at timestep 1147 is tensor(3.6404e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1147 of 1
Current timestep = 1148. State = [[-0.31618136  0.19408652]]. Action = [[ 0.04925802  0.04231841  0.         -0.5724726 ]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 1148 is [True, False, False, False, False, True]
State prediction error at timestep 1148 is tensor(5.3432e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1148 of 1
Current timestep = 1149. State = [[-0.3177729   0.19927427]]. Action = [[-0.07049815  0.0973696   0.         -0.71594894]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 1149 is [True, False, False, False, False, True]
State prediction error at timestep 1149 is tensor(4.9277e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1149 of 1
Current timestep = 1150. State = [[-0.3190891   0.20260371]]. Action = [[ 0.00845647  0.01164025  0.         -0.30785346]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 1150 is [True, False, False, False, False, True]
State prediction error at timestep 1150 is tensor(7.3950e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1150 of 1
Current timestep = 1151. State = [[-0.3189645   0.20381588]]. Action = [[-0.00567133  0.00812499  0.         -0.7225553 ]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 1151 is [True, False, False, False, False, True]
State prediction error at timestep 1151 is tensor(5.0422e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1151 of 1
Current timestep = 1152. State = [[-0.32120544  0.20800883]]. Action = [[-0.04599041  0.06500522  0.         -0.06014115]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 1152 is [True, False, False, False, False, True]
State prediction error at timestep 1152 is tensor(3.5380e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1152 of 1
Current timestep = 1153. State = [[-0.31806365  0.20799111]]. Action = [[ 0.08845227 -0.05779263  0.          0.28578997]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 1153 is [True, False, False, False, False, True]
State prediction error at timestep 1153 is tensor(2.5106e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1153 of 1
Current timestep = 1154. State = [[-0.31911162  0.20938446]]. Action = [[-0.08010618  0.04322837  0.          0.74935937]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 1154 is [True, False, False, False, False, True]
State prediction error at timestep 1154 is tensor(7.9457e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1154 of -1
Current timestep = 1155. State = [[-0.32490957  0.20964666]]. Action = [[-0.07884413 -0.05172637  0.         -0.45965135]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 1155 is [True, False, False, False, False, True]
State prediction error at timestep 1155 is tensor(5.0328e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1155 of -1
Current timestep = 1156. State = [[-0.32873482  0.21324816]]. Action = [[-0.02720037  0.06657579  0.          0.10664403]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 1156 is [True, False, False, False, False, True]
State prediction error at timestep 1156 is tensor(3.6500e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1156 of -1
Current timestep = 1157. State = [[-0.32960626  0.21979086]]. Action = [[0.01269682 0.06867526 0.         0.38671458]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 1157 is [True, False, False, False, False, True]
State prediction error at timestep 1157 is tensor(8.4432e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1157 of -1
Current timestep = 1158. State = [[-0.32681736  0.22389372]]. Action = [[ 0.0642268   0.02285327  0.         -0.6850057 ]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 1158 is [True, False, False, False, False, True]
State prediction error at timestep 1158 is tensor(2.5144e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1158 of -1
Current timestep = 1159. State = [[-0.32313567  0.22464807]]. Action = [[ 0.04308035 -0.01522227  0.         -0.5407156 ]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 1159 is [True, False, False, False, False, True]
State prediction error at timestep 1159 is tensor(3.0116e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1159 of -1
Current timestep = 1160. State = [[-0.3259978  0.2272665]]. Action = [[-0.08427517  0.04207767  0.         -0.3830756 ]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 1160 is [True, False, False, False, False, True]
State prediction error at timestep 1160 is tensor(3.7012e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1160 of -1
Current timestep = 1161. State = [[-0.32707477  0.2331506 ]]. Action = [[0.03405466 0.07214596 0.         0.38981748]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 1161 is [True, False, False, False, False, True]
State prediction error at timestep 1161 is tensor(7.2564e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1161 of -1
Current timestep = 1162. State = [[-0.32654065  0.24063493]]. Action = [[ 0.00449856  0.09191842  0.         -0.8445914 ]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 1162 is [True, False, False, False, False, True]
State prediction error at timestep 1162 is tensor(3.1605e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1162 of -1
Current timestep = 1163. State = [[-0.32895216  0.24782781]]. Action = [[-0.03896139  0.07090097  0.          0.75651026]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 1163 is [True, False, False, False, False, True]
State prediction error at timestep 1163 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1163 of -1
Current timestep = 1164. State = [[-0.32807395  0.24847506]]. Action = [[ 0.05137589 -0.05811945  0.         -0.08234197]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 1164 is [True, False, False, False, False, True]
State prediction error at timestep 1164 is tensor(1.1256e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1164 of -1
Current timestep = 1165. State = [[-0.3222088   0.24546127]]. Action = [[ 0.08760189 -0.05617929  0.          0.68115973]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 1165 is [True, False, False, False, False, True]
State prediction error at timestep 1165 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1165 of -1
Current timestep = 1166. State = [[-0.3155445  0.2422215]]. Action = [[ 0.06667801 -0.05030269  0.          0.73389554]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 1166 is [True, False, False, False, False, True]
State prediction error at timestep 1166 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1166 of -1
Current timestep = 1167. State = [[-0.315539    0.24099891]]. Action = [[-0.06629199 -0.01161981  0.          0.01650488]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 1167 is [True, False, False, False, False, True]
State prediction error at timestep 1167 is tensor(1.7193e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1167 of 1
Current timestep = 1168. State = [[-0.3178258  0.2447445]]. Action = [[-0.02982139  0.06257535  0.          0.79305387]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 1168 is [True, False, False, False, False, True]
State prediction error at timestep 1168 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1168 of 1
Current timestep = 1169. State = [[-0.3177519  0.2480763]]. Action = [[0.01033738 0.01728301 0.         0.35976315]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 1169 is [True, False, False, False, False, True]
State prediction error at timestep 1169 is tensor(6.0627e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1169 of -1
Current timestep = 1170. State = [[-0.31920373  0.24781407]]. Action = [[-0.04448706 -0.0308282   0.          0.57458735]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 1170 is [True, False, False, False, False, True]
State prediction error at timestep 1170 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1170 of -1
Current timestep = 1171. State = [[-0.32212767  0.24422827]]. Action = [[-0.04409043 -0.07602833  0.          0.4645506 ]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 1171 is [True, False, False, False, False, True]
State prediction error at timestep 1171 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1171 of -1
Current timestep = 1172. State = [[-0.3212294  0.2435344]]. Action = [[0.03905783 0.01749821 0.         0.41656888]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 1172 is [True, False, False, False, False, True]
State prediction error at timestep 1172 is tensor(4.4332e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1172 of -1
Current timestep = 1173. State = [[-0.3215115  0.2427622]]. Action = [[-0.0341108  -0.03013967  0.         -0.0373922 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 1173 is [True, False, False, False, False, True]
State prediction error at timestep 1173 is tensor(7.5276e-07, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1173 of -1
Current timestep = 1174. State = [[-0.32014066  0.24663663]]. Action = [[0.0473037  0.096905   0.         0.29183495]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 1174 is [True, False, False, False, False, True]
State prediction error at timestep 1174 is tensor(3.7711e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1174 of -1
Current timestep = 1175. State = [[-0.31778213  0.24688266]]. Action = [[ 0.01872593 -0.04770466  0.         -0.3835681 ]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 1175 is [True, False, False, False, False, True]
State prediction error at timestep 1175 is tensor(1.2556e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1175 of -1
Current timestep = 1176. State = [[-0.32153267  0.24357866]]. Action = [[-0.09537118 -0.04869393  0.         -0.6693133 ]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 1176 is [True, False, False, False, False, True]
State prediction error at timestep 1176 is tensor(3.5500e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1176 of -1
Current timestep = 1177. State = [[-0.32607672  0.24098395]]. Action = [[-0.03952726 -0.03666344  0.         -0.23616904]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 1177 is [True, False, False, False, False, True]
State prediction error at timestep 1177 is tensor(1.9024e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1177 of -1
Current timestep = 1178. State = [[-0.33251116  0.24155992]]. Action = [[-0.09703917  0.02489106  0.         -0.30449414]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 1178 is [True, False, False, False, False, True]
State prediction error at timestep 1178 is tensor(2.6761e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1178 of -1
Current timestep = 1179. State = [[-0.3362647  0.2433715]]. Action = [[ 0.00081704  0.01782943  0.         -0.51703614]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 1179 is [True, False, False, False, False, True]
State prediction error at timestep 1179 is tensor(8.2495e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1179 of -1
Current timestep = 1180. State = [[-0.341508    0.24553086]]. Action = [[-0.07767533  0.03332951  0.         -0.8056381 ]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 1180 is [True, False, False, False, False, True]
State prediction error at timestep 1180 is tensor(6.4576e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1180 of -1
Current timestep = 1181. State = [[-0.3430096   0.24337268]]. Action = [[ 0.04421926 -0.06394865  0.         -0.8471699 ]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 1181 is [True, False, False, False, False, True]
State prediction error at timestep 1181 is tensor(5.6761e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1181 of -1
Current timestep = 1182. State = [[-0.3476321   0.24534826]]. Action = [[-0.09024016  0.08531354  0.         -0.86779094]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 1182 is [True, False, False, False, False, True]
State prediction error at timestep 1182 is tensor(7.5787e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1182 of -1
Current timestep = 1183. State = [[-0.35444817  0.24329782]]. Action = [[-0.05180583 -0.09279267  0.          0.25157762]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 1183 is [True, False, False, False, False, True]
State prediction error at timestep 1183 is tensor(5.6078e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1183 of -1
Current timestep = 1184. State = [[-0.3607491   0.24340881]]. Action = [[-0.05790928  0.04929791  0.          0.87185824]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 1184 is [True, False, False, False, False, True]
State prediction error at timestep 1184 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1184 of -1
Current timestep = 1185. State = [[-0.36440855  0.24842285]]. Action = [[ 0.00659702  0.08189972  0.         -0.9431887 ]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 1185 is [True, False, False, False, False, True]
State prediction error at timestep 1185 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1185 of -1
Current timestep = 1186. State = [[-0.36516201  0.25079513]]. Action = [[ 0.02745176  0.01293047  0.         -0.62094057]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 1186 is [True, False, False, False, False, True]
State prediction error at timestep 1186 is tensor(7.4013e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1186 of -1
Current timestep = 1187. State = [[-0.36895615  0.25167784]]. Action = [[-0.05572721  0.01598249  0.          0.58717895]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 1187 is [True, False, False, False, False, True]
State prediction error at timestep 1187 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1187 of -1
Current timestep = 1188. State = [[-0.36871767  0.25614598]]. Action = [[0.07411418 0.08989436 0.         0.15030372]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 1188 is [True, False, False, False, False, True]
State prediction error at timestep 1188 is tensor(9.8469e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1188 of -1
Current timestep = 1189. State = [[-0.37282473  0.26077935]]. Action = [[-0.09659242  0.04509979  0.         -0.61453164]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 1189 is [True, False, False, False, False, True]
State prediction error at timestep 1189 is tensor(5.3336e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1189 of -1
Current timestep = 1190. State = [[-0.37927124  0.262952  ]]. Action = [[-0.04264338  0.00763895  0.         -0.7528312 ]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 1190 is [True, False, False, False, False, True]
State prediction error at timestep 1190 is tensor(9.6208e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1190 of -1
Current timestep = 1191. State = [[-0.3822727  0.2638681]]. Action = [[ 0.          0.          0.         -0.40643364]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 1191 is [True, False, False, False, False, True]
State prediction error at timestep 1191 is tensor(9.9207e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1191 of -1
Current timestep = 1192. State = [[-0.38371822  0.26449758]]. Action = [[ 0.          0.          0.         -0.25744426]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 1192 is [True, False, False, False, False, True]
State prediction error at timestep 1192 is tensor(6.9684e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1192 of -1
Current timestep = 1193. State = [[-0.38484192  0.26512748]]. Action = [[0.        0.        0.        0.8581464]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 1193 is [True, False, False, False, False, True]
State prediction error at timestep 1193 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1193 of -1
Current timestep = 1194. State = [[-0.38572672  0.26575166]]. Action = [[0.        0.        0.        0.7355764]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 1194 is [True, False, False, False, False, True]
State prediction error at timestep 1194 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1194 of -1
Current timestep = 1195. State = [[-0.38638836  0.26633716]]. Action = [[0.        0.        0.        0.8447472]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 1195 is [True, False, False, False, False, True]
State prediction error at timestep 1195 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1195 of -1
Current timestep = 1196. State = [[-0.38684782  0.26685813]]. Action = [[0.        0.        0.        0.9551344]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 1196 is [True, False, False, False, False, True]
State prediction error at timestep 1196 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1196 of -1
Current timestep = 1197. State = [[-0.38712826  0.2672819 ]]. Action = [[ 0.          0.          0.         -0.51979184]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 1197 is [True, False, False, False, False, True]
State prediction error at timestep 1197 is tensor(5.9858e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1197 of -1
Current timestep = 1198. State = [[-0.387293    0.26762423]]. Action = [[0.         0.         0.         0.69822717]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 1198 is [True, False, False, False, False, True]
State prediction error at timestep 1198 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1198 of -1
Current timestep = 1199. State = [[-0.38739312  0.26789713]]. Action = [[0.         0.         0.         0.33050323]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 1199 is [True, False, False, False, False, True]
State prediction error at timestep 1199 is tensor(5.1932e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1199 of -1
Current timestep = 1200. State = [[-0.38745922  0.2681056 ]]. Action = [[ 0.         0.         0.        -0.0185979]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 1200 is [True, False, False, False, False, True]
State prediction error at timestep 1200 is tensor(1.7338e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1200 of -1
Current timestep = 1201. State = [[-0.38751662  0.26825806]]. Action = [[ 0.          0.          0.         -0.40754217]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 1201 is [True, False, False, False, False, True]
State prediction error at timestep 1201 is tensor(2.3248e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1201 of -1
Current timestep = 1202. State = [[-0.3875659   0.26835907]]. Action = [[ 0.          0.          0.         -0.83518213]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 1202 is [True, False, False, False, False, True]
State prediction error at timestep 1202 is tensor(1.8710e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1202 of -1
Current timestep = 1203. State = [[-0.38759375  0.2684399 ]]. Action = [[0.         0.         0.         0.12995875]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 1203 is [True, False, False, False, False, True]
State prediction error at timestep 1203 is tensor(3.1711e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1203 of -1
Current timestep = 1204. State = [[-0.38761255  0.26850885]]. Action = [[ 0.         0.         0.        -0.9706044]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 1204 is [True, False, False, False, False, True]
State prediction error at timestep 1204 is tensor(7.2507e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1204 of -1
Current timestep = 1205. State = [[-0.38762933  0.26856923]]. Action = [[0.         0.         0.         0.07967865]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 1205 is [True, False, False, False, False, True]
State prediction error at timestep 1205 is tensor(1.1157e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1205 of -1
Current timestep = 1206. State = [[-0.38764822  0.2686239 ]]. Action = [[ 0.         0.         0.        -0.5352595]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 1206 is [True, False, False, False, False, True]
State prediction error at timestep 1206 is tensor(3.2857e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1206 of -1
Current timestep = 1207. State = [[-0.38767013  0.26867434]]. Action = [[ 0.         0.         0.        -0.6168215]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 1207 is [True, False, False, False, False, True]
State prediction error at timestep 1207 is tensor(2.3531e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1207 of -1
Current timestep = 1208. State = [[-0.38769305  0.2687212 ]]. Action = [[0.         0.         0.         0.02330375]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 1208 is [True, False, False, False, False, True]
State prediction error at timestep 1208 is tensor(4.0814e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1208 of -1
Current timestep = 1209. State = [[-0.3877156   0.26876318]]. Action = [[ 0.         0.         0.        -0.8511894]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 1209 is [True, False, False, False, False, True]
State prediction error at timestep 1209 is tensor(2.1220e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1209 of -1
Current timestep = 1210. State = [[-0.38773766  0.26880026]]. Action = [[ 0.          0.          0.         -0.53169423]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 1210 is [True, False, False, False, False, True]
State prediction error at timestep 1210 is tensor(2.7502e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1210 of -1
Current timestep = 1211. State = [[-0.38775903  0.26883268]]. Action = [[ 0.          0.          0.         -0.10327423]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 1211 is [True, False, False, False, False, True]
State prediction error at timestep 1211 is tensor(9.9817e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1211 of -1
Current timestep = 1212. State = [[-0.38777772  0.26886025]]. Action = [[ 0.          0.          0.         -0.45649946]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 1212 is [True, False, False, False, False, True]
State prediction error at timestep 1212 is tensor(2.9622e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1212 of -1
Current timestep = 1213. State = [[-0.38779393  0.26888418]]. Action = [[ 0.          0.          0.         -0.48548573]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 1213 is [True, False, False, False, False, True]
State prediction error at timestep 1213 is tensor(2.2686e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1213 of -1
Current timestep = 1214. State = [[-0.38780817  0.26890513]]. Action = [[0.         0.         0.         0.20146644]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 1214 is [True, False, False, False, False, True]
State prediction error at timestep 1214 is tensor(3.8242e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1214 of -1
Current timestep = 1215. State = [[-0.3878207  0.2689235]]. Action = [[0.         0.         0.         0.43241143]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 1215 is [True, False, False, False, False, True]
State prediction error at timestep 1215 is tensor(7.7262e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1215 of -1
Current timestep = 1216. State = [[-0.38783172  0.2689396 ]]. Action = [[0.        0.        0.        0.6896448]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 1216 is [True, False, False, False, False, True]
State prediction error at timestep 1216 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1216 of -1
Current timestep = 1217. State = [[-0.38784143  0.26895374]]. Action = [[ 0.          0.          0.         -0.18857825]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 1217 is [True, False, False, False, False, True]
State prediction error at timestep 1217 is tensor(1.0761e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1217 of -1
Current timestep = 1218. State = [[-0.38785002  0.26896617]]. Action = [[ 0.          0.          0.         -0.65815866]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 1218 is [True, False, False, False, False, True]
State prediction error at timestep 1218 is tensor(2.3847e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1218 of -1
Current timestep = 1219. State = [[-0.3878576   0.26897708]]. Action = [[ 0.          0.          0.         -0.22257668]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 1219 is [True, False, False, False, False, True]
State prediction error at timestep 1219 is tensor(2.7203e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1219 of -1
Current timestep = 1220. State = [[-0.38786423  0.26898664]]. Action = [[ 0.         0.         0.        -0.6938398]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 1220 is [True, False, False, False, False, True]
State prediction error at timestep 1220 is tensor(2.5789e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1220 of -1
Current timestep = 1221. State = [[-0.3878701   0.26899502]]. Action = [[ 0.         0.         0.        -0.6783137]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 1221 is [True, False, False, False, False, True]
State prediction error at timestep 1221 is tensor(1.5689e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1221 of -1
Current timestep = 1222. State = [[-0.3878753   0.26900238]]. Action = [[ 0.          0.          0.         -0.96990603]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 1222 is [True, False, False, False, False, True]
State prediction error at timestep 1222 is tensor(3.9435e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1222 of -1
Current timestep = 1223. State = [[-0.38787988  0.26900882]]. Action = [[ 0.          0.          0.         -0.53402865]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 1223 is [True, False, False, False, False, True]
State prediction error at timestep 1223 is tensor(6.3254e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1223 of -1
Current timestep = 1224. State = [[-0.38788393  0.26901445]]. Action = [[0.         0.         0.         0.73051226]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 1224 is [True, False, False, False, False, True]
State prediction error at timestep 1224 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1224 of -1
Current timestep = 1225. State = [[-0.3878875   0.26901937]]. Action = [[ 0.          0.          0.         -0.03143257]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 1225 is [True, False, False, False, False, True]
State prediction error at timestep 1225 is tensor(1.9866e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1225 of -1
Current timestep = 1226. State = [[-0.38789067  0.2690237 ]]. Action = [[ 0.         0.         0.        -0.9077166]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 1226 is [True, False, False, False, False, True]
State prediction error at timestep 1226 is tensor(3.0486e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1226 of -1
Current timestep = 1227. State = [[-0.38789347  0.26902747]]. Action = [[0.         0.         0.         0.13905454]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 1227 is [True, False, False, False, False, True]
State prediction error at timestep 1227 is tensor(3.0194e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1227 of -1
Current timestep = 1228. State = [[-0.38789594  0.26903075]]. Action = [[ 0.          0.          0.         -0.41379833]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 1228 is [True, False, False, False, False, True]
State prediction error at timestep 1228 is tensor(1.3751e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1228 of -1
Current timestep = 1229. State = [[-0.38789815  0.2690336 ]]. Action = [[ 0.          0.          0.         -0.75118124]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 1229 is [True, False, False, False, False, True]
State prediction error at timestep 1229 is tensor(1.2260e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1229 of -1
Current timestep = 1230. State = [[-0.38790008  0.2690361 ]]. Action = [[0.         0.         0.         0.50398517]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 1230 is [True, False, False, False, False, True]
State prediction error at timestep 1230 is tensor(8.6173e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1230 of -1
Current timestep = 1231. State = [[-0.3879018   0.26903826]]. Action = [[0.         0.         0.         0.55994177]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 1231 is [True, False, False, False, False, True]
State prediction error at timestep 1231 is tensor(9.7967e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1231 of -1
Current timestep = 1232. State = [[-0.38790333  0.26904014]]. Action = [[ 0.          0.          0.         -0.11907494]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 1232 is [True, False, False, False, False, True]
State prediction error at timestep 1232 is tensor(4.6762e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1232 of -1
Current timestep = 1233. State = [[-0.3879047   0.26904178]]. Action = [[0.         0.         0.         0.34216857]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 1233 is [True, False, False, False, False, True]
State prediction error at timestep 1233 is tensor(2.4781e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1233 of -1
Current timestep = 1234. State = [[-0.387906    0.26904327]]. Action = [[ 0.        0.        0.       -0.790721]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 1234 is [True, False, False, False, False, True]
State prediction error at timestep 1234 is tensor(1.1588e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1234 of -1
Current timestep = 1235. State = [[-0.38790727  0.2690448 ]]. Action = [[ 0.         0.         0.        -0.3921795]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 1235 is [True, False, False, False, False, True]
State prediction error at timestep 1235 is tensor(5.1945e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1235 of -1
Current timestep = 1236. State = [[-0.38790852  0.26904625]]. Action = [[ 0.          0.          0.         -0.20607656]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 1236 is [True, False, False, False, False, True]
State prediction error at timestep 1236 is tensor(5.1872e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1236 of -1
Current timestep = 1237. State = [[-0.38790977  0.26904774]]. Action = [[0.         0.         0.         0.00284767]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 1237 is [True, False, False, False, False, True]
State prediction error at timestep 1237 is tensor(3.7633e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1237 of -1
Current timestep = 1238. State = [[-0.38791102  0.2690492 ]]. Action = [[0.        0.        0.        0.4971112]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 1238 is [True, False, False, False, False, True]
State prediction error at timestep 1238 is tensor(5.9345e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1238 of -1
Current timestep = 1239. State = [[-0.38791224  0.26905063]]. Action = [[ 0.         0.         0.        -0.2850411]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 1239 is [True, False, False, False, False, True]
State prediction error at timestep 1239 is tensor(6.7857e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1239 of -1
Current timestep = 1240. State = [[-0.3879135   0.26905206]]. Action = [[ 0.          0.          0.         -0.44809002]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 1240 is [True, False, False, False, False, True]
State prediction error at timestep 1240 is tensor(1.5292e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1240 of -1
Current timestep = 1241. State = [[-0.3879147  0.2690535]]. Action = [[0.        0.        0.        0.2516563]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 1241 is [True, False, False, False, False, True]
State prediction error at timestep 1241 is tensor(2.8771e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1241 of -1
Current timestep = 1242. State = [[-0.3879159   0.26905492]]. Action = [[ 0.        0.        0.       -0.839844]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 1242 is [True, False, False, False, False, True]
State prediction error at timestep 1242 is tensor(1.0299e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1242 of -1
Current timestep = 1243. State = [[-0.3879171   0.26905632]]. Action = [[ 0.         0.         0.        -0.6535914]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 1243 is [True, False, False, False, False, True]
State prediction error at timestep 1243 is tensor(5.6377e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1243 of -1
Current timestep = 1244. State = [[-0.3879183  0.2690577]]. Action = [[0.         0.         0.         0.16124487]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 1244 is [True, False, False, False, False, True]
State prediction error at timestep 1244 is tensor(5.9434e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1244 of -1
Current timestep = 1245. State = [[-0.3879195   0.26905906]]. Action = [[0.         0.         0.         0.06301749]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 1245 is [True, False, False, False, False, True]
State prediction error at timestep 1245 is tensor(5.0645e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1245 of -1
Current timestep = 1246. State = [[-0.38792065  0.26906043]]. Action = [[0.         0.         0.         0.29868853]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 1246 is [True, False, False, False, False, True]
State prediction error at timestep 1246 is tensor(2.7256e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1246 of -1
Current timestep = 1247. State = [[-0.3879218  0.2690618]]. Action = [[ 0.          0.          0.         -0.45593297]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 1247 is [True, False, False, False, False, True]
State prediction error at timestep 1247 is tensor(1.1960e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1247 of -1
