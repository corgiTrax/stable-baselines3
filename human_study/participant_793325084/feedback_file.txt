Current timestep = 0. State = [[-0.3270049  -0.09084156]]. Action = [[-0.02517132 -0.00313229  0.         -0.03610903]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [True, False, False, False, True, False]
State prediction error at timestep 0 is 0.012
Current timestep = 1. State = [[-0.3284511  -0.08900083]]. Action = [[ 0.01121883  0.03684529  0.         -0.24135602]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False]
State prediction error at timestep 1 is 0.012
Current timestep = 2. State = [[-0.3323186  -0.08544317]]. Action = [[-0.06113325  0.04126974  0.          0.97395396]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, True, False]
State prediction error at timestep 2 is 0.012
Current timestep = 3. State = [[-0.3383631  -0.08004148]]. Action = [[-0.06263261  0.07551753  0.         -0.21903908]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, True, False]
State prediction error at timestep 3 is 0.012
Current timestep = 4. State = [[-0.3429387  -0.08150396]]. Action = [[-0.02606332 -0.08540395  0.          0.91687274]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, True, False]
State prediction error at timestep 4 is 0.012
Current timestep = 5. State = [[-0.3490021  -0.07965203]]. Action = [[-0.07761858  0.08164795  0.         -0.8448607 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, True, False]
State prediction error at timestep 5 is 0.012
Current timestep = 6. State = [[-0.34893882 -0.07850175]]. Action = [[ 0.09810986 -0.04243719  0.         -0.2252906 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, True, False]
State prediction error at timestep 6 is 0.012
Current timestep = 7. State = [[-0.3492724  -0.07514054]]. Action = [[-0.05269296  0.07933923  0.          0.7123525 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, True, False]
State prediction error at timestep 7 is 0.012
Current timestep = 8. State = [[-0.34811005 -0.06969579]]. Action = [[ 0.0754961   0.04299169  0.         -0.08161724]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, True, False]
State prediction error at timestep 8 is 0.012
Current timestep = 9. State = [[-0.35013327 -0.07000023]]. Action = [[-0.07022719 -0.05783322  0.          0.24431825]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, True, False]
State prediction error at timestep 9 is 0.012
Current timestep = 10. State = [[-0.34971988 -0.0753062 ]]. Action = [[ 0.06681105 -0.08201386  0.         -0.67114556]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, True, False]
State prediction error at timestep 10 is 0.012
Current timestep = 11. State = [[-0.34873503 -0.08106681]]. Action = [[-0.00926805 -0.06453748  0.         -0.9684069 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, True, False]
State prediction error at timestep 11 is 0.012
Current timestep = 12. State = [[-0.34941414 -0.08864632]]. Action = [[-0.00988554 -0.09839112  0.         -0.614913  ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, True, False]
State prediction error at timestep 12 is 0.012
Current timestep = 13. State = [[-0.3451792  -0.09532307]]. Action = [[ 0.09057599 -0.05426887  0.          0.24568582]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, True, False]
State prediction error at timestep 13 is 0.012
Current timestep = 14. State = [[-0.33860153 -0.09723782]]. Action = [[ 0.07226252  0.01412418  0.         -0.4160719 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, True, False]
State prediction error at timestep 14 is 0.012
Current timestep = 15. State = [[-0.33855936 -0.10063896]]. Action = [[-0.05909092 -0.05171558  0.          0.7692232 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, True, False]
State prediction error at timestep 15 is 0.012
Current timestep = 16. State = [[-0.3438158 -0.1003454]]. Action = [[-0.08847439  0.07359082  0.          0.7894316 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, True, False]
State prediction error at timestep 16 is 0.012
Current timestep = 17. State = [[-0.3458716  -0.09542044]]. Action = [[ 0.00787131  0.08607116  0.         -0.33679414]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, True, False]
State prediction error at timestep 17 is 0.012
Current timestep = 18. State = [[-0.34760857 -0.08906771]]. Action = [[-0.03301679  0.08093991  0.         -0.731575  ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, True, False]
State prediction error at timestep 18 is 0.012
Current timestep = 19. State = [[-0.3488182  -0.08823722]]. Action = [[ 0.00312903 -0.03759826  0.         -0.25821555]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, True, False]
State prediction error at timestep 19 is 0.012
Current timestep = 20. State = [[-0.34626248 -0.08579159]]. Action = [[0.0632496  0.05764089 0.         0.49787724]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, True, False]
State prediction error at timestep 20 is 0.012
Current timestep = 21. State = [[-0.342236   -0.08267199]]. Action = [[0.05672931 0.00467298 0.         0.501621  ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, True, False]
State prediction error at timestep 21 is 0.012
Current timestep = 22. State = [[-0.33771208 -0.07604022]]. Action = [[ 0.06753404  0.09819474  0.         -0.9514527 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [True, False, False, False, True, False]
State prediction error at timestep 22 is 0.012
Current timestep = 23. State = [[-0.33737254 -0.06802481]]. Action = [[-0.02280841  0.06887992  0.          0.03624845]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [True, False, False, False, True, False]
State prediction error at timestep 23 is 0.012
Current timestep = 24. State = [[-0.33695143 -0.05916549]]. Action = [[ 0.03349089  0.09955809  0.         -0.682824  ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [True, False, False, False, True, False]
State prediction error at timestep 24 is 0.012
Current timestep = 25. State = [[-0.33869988 -0.05770453]]. Action = [[-0.0462237  -0.08078437  0.          0.63734305]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [True, False, False, False, True, False]
State prediction error at timestep 25 is 0.012
Current timestep = 26. State = [[-0.3381048  -0.05767744]]. Action = [[ 0.04534339  0.01859118  0.         -0.01341397]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [True, False, False, False, True, False]
State prediction error at timestep 26 is 0.012
Current timestep = 27. State = [[-0.33955047 -0.05927359]]. Action = [[-0.05272523 -0.06325215  0.         -0.01878482]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [True, False, False, False, True, False]
State prediction error at timestep 27 is 0.012
Current timestep = 28. State = [[-0.3442493  -0.05989646]]. Action = [[-0.07307081  0.01494579  0.         -0.91120285]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [True, False, False, False, True, False]
State prediction error at timestep 28 is 0.012
Current timestep = 29. State = [[-0.34387147 -0.05626411]]. Action = [[ 0.05071848  0.05536649  0.         -0.4208697 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [True, False, False, False, True, False]
State prediction error at timestep 29 is 0.012
Current timestep = 30. State = [[-0.34318334 -0.05048785]]. Action = [[-0.01370352  0.06336819  0.         -0.95380545]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [True, False, False, False, True, False]
State prediction error at timestep 30 is 0.012
Current timestep = 31. State = [[-0.3446865  -0.04688857]]. Action = [[-0.02395083  0.01285665  0.          0.84736323]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [True, False, False, False, True, False]
State prediction error at timestep 31 is 0.012
Current timestep = 32. State = [[-0.34537023 -0.04917354]]. Action = [[ 4.3716282e-04 -7.0835866e-02  0.0000000e+00 -4.9097490e-01]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [True, False, False, False, True, False]
State prediction error at timestep 32 is 0.012
Current timestep = 33. State = [[-0.3490955 -0.0550513]]. Action = [[-0.07968862 -0.07912775  0.         -0.9374181 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [True, False, False, False, True, False]
State prediction error at timestep 33 is 0.012
Current timestep = 34. State = [[-0.35011888 -0.0571089 ]]. Action = [[0.0229729  0.01553579 0.         0.09854746]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [True, False, False, False, True, False]
State prediction error at timestep 34 is 0.012
Current timestep = 35. State = [[-0.35075063 -0.05881244]]. Action = [[-0.02379552 -0.03595639  0.          0.6699455 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [True, False, False, False, True, False]
State prediction error at timestep 35 is 0.012
Current timestep = 36. State = [[-0.34704706 -0.06053897]]. Action = [[ 0.09312334 -0.00839349  0.          0.02484822]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [True, False, False, False, True, False]
State prediction error at timestep 36 is 0.012
Current timestep = 37. State = [[-0.34123677 -0.0633743 ]]. Action = [[ 0.0663007  -0.04746206  0.          0.314659  ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [True, False, False, False, True, False]
State prediction error at timestep 37 is 0.012
Current timestep = 38. State = [[-0.34045175 -0.06886414]]. Action = [[-0.03301517 -0.06903735  0.         -0.56067777]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [True, False, False, False, True, False]
State prediction error at timestep 38 is 0.012
Current timestep = 39. State = [[-0.3418825  -0.07414134]]. Action = [[-0.02143808 -0.03881108  0.          0.5556381 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [True, False, False, False, True, False]
State prediction error at timestep 39 is 0.012
Current timestep = 40. State = [[-0.34645125 -0.0722801 ]]. Action = [[-0.09060122  0.09276371  0.          0.32077074]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [True, False, False, False, True, False]
State prediction error at timestep 40 is 0.012
Current timestep = 41. State = [[-0.34738398 -0.07240871]]. Action = [[ 0.04349054 -0.03881253  0.         -0.17703742]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [True, False, False, False, True, False]
State prediction error at timestep 41 is 0.012
Current timestep = 42. State = [[-0.34785113 -0.07390076]]. Action = [[-0.03742965  0.00716915  0.          0.46081853]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [True, False, False, False, True, False]
State prediction error at timestep 42 is 0.012
Current timestep = 43. State = [[-0.34558818 -0.07153713]]. Action = [[ 0.06237604  0.05458137  0.         -0.7390872 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [True, False, False, False, True, False]
State prediction error at timestep 43 is 0.012
Current timestep = 44. State = [[-0.34431395 -0.06599911]]. Action = [[-0.00907054  0.07323664  0.         -0.0730992 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [True, False, False, False, True, False]
State prediction error at timestep 44 is 0.012
Current timestep = 45. State = [[-0.34240717 -0.06398208]]. Action = [[ 0.04537082 -0.01607694  0.         -0.51758724]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [True, False, False, False, True, False]
State prediction error at timestep 45 is 0.012
Current timestep = 46. State = [[-0.33944783 -0.06147002]]. Action = [[0.03811892 0.04228497 0.         0.02757192]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [True, False, False, False, True, False]
State prediction error at timestep 46 is 0.012
Current timestep = 47. State = [[-0.33906823 -0.06076062]]. Action = [[-0.01317835 -0.02618026  0.          0.755185  ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [True, False, False, False, True, False]
State prediction error at timestep 47 is 0.012
Current timestep = 48. State = [[-0.34161144 -0.0599232 ]]. Action = [[-0.04631549  0.02226819  0.          0.37288344]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [True, False, False, False, True, False]
State prediction error at timestep 48 is 0.012
Current timestep = 49. State = [[-0.34073713 -0.05722469]]. Action = [[0.04538212 0.03099369 0.         0.8847685 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [True, False, False, False, True, False]
State prediction error at timestep 49 is 0.012
Current timestep = 50. State = [[-0.3410031  -0.05961129]]. Action = [[-0.03130955 -0.08020533  0.         -0.02700591]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [True, False, False, False, True, False]
State prediction error at timestep 50 is 0.012
Current timestep = 51. State = [[-0.33802786 -0.05763282]]. Action = [[0.08275392 0.09060951 0.         0.1242373 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 51 is [True, False, False, False, True, False]
State prediction error at timestep 51 is 0.012
Current timestep = 52. State = [[-0.33209655 -0.05824121]]. Action = [[ 0.07275843 -0.08305749  0.          0.5712166 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 52 is [True, False, False, False, True, False]
State prediction error at timestep 52 is 0.012
Current timestep = 53. State = [[-0.33138907 -0.06134968]]. Action = [[-0.04576635 -0.02269816  0.         -0.8974389 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 53 is [True, False, False, False, True, False]
State prediction error at timestep 53 is 0.012
Current timestep = 54. State = [[-0.334476   -0.06685781]]. Action = [[-0.04895029 -0.08923292  0.          0.16367233]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 54 is [True, False, False, False, True, False]
State prediction error at timestep 54 is 0.012
Current timestep = 55. State = [[-0.3370901  -0.07392347]]. Action = [[-0.03475114 -0.07091607  0.          0.7207265 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 55 is [True, False, False, False, True, False]
State prediction error at timestep 55 is 0.012
Current timestep = 56. State = [[-0.33656964 -0.07507531]]. Action = [[0.02381404 0.04445919 0.         0.91396666]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 56 is [True, False, False, False, True, False]
State prediction error at timestep 56 is 0.012
Current timestep = 57. State = [[-0.33120745 -0.07767337]]. Action = [[ 0.09283268 -0.06270957  0.         -0.27012765]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 57 is [True, False, False, False, True, False]
State prediction error at timestep 57 is 0.012
Current timestep = 58. State = [[-0.32833883 -0.08389764]]. Action = [[-0.00675305 -0.07176851  0.          0.02913284]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 58 is [True, False, False, False, True, False]
State prediction error at timestep 58 is 0.012
Current timestep = 59. State = [[-0.3318823  -0.08305091]]. Action = [[-0.08985103  0.09186571  0.         -0.01006943]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 59 is [True, False, False, False, True, False]
State prediction error at timestep 59 is 0.012
Current timestep = 60. State = [[-0.33297646 -0.07838884]]. Action = [[0.03257651 0.06013202 0.         0.36233544]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 60 is [True, False, False, False, True, False]
State prediction error at timestep 60 is 0.012
Current timestep = 61. State = [[-0.32820085 -0.07664732]]. Action = [[ 0.08748408 -0.0035544   0.          0.6086904 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 61 is [True, False, False, False, True, False]
State prediction error at timestep 61 is 0.012
Current timestep = 62. State = [[-0.32613924 -0.07976142]]. Action = [[-0.0061772  -0.06493673  0.         -0.59949154]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 62 is [True, False, False, False, True, False]
State prediction error at timestep 62 is 0.012
Current timestep = 63. State = [[-0.3243946  -0.07876316]]. Action = [[ 0.03622233  0.06289604  0.         -0.9037737 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 63 is [True, False, False, False, True, False]
State prediction error at timestep 63 is 0.012
Current timestep = 64. State = [[-0.3255149  -0.07654376]]. Action = [[-0.0444268   0.00884514  0.         -0.55001134]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 64 is [True, False, False, False, True, False]
State prediction error at timestep 64 is 0.012
Current timestep = 65. State = [[-0.33025914 -0.07610568]]. Action = [[-0.07457881  0.00533535  0.         -0.73126566]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 65 is [True, False, False, False, True, False]
State prediction error at timestep 65 is 0.012
Current timestep = 66. State = [[-0.33115077 -0.07938772]]. Action = [[ 0.02870005 -0.06568596  0.         -0.78596085]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 66 is [True, False, False, False, True, False]
State prediction error at timestep 66 is 0.012
Current timestep = 67. State = [[-0.32550073 -0.08299406]]. Action = [[ 0.09941655 -0.03260429  0.          0.7270007 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 67 is [True, False, False, False, True, False]
State prediction error at timestep 67 is 0.012
Current timestep = 68. State = [[-0.3216882 -0.0795166]]. Action = [[0.0126427  0.08787294 0.         0.43771553]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 68 is [True, False, False, False, True, False]
State prediction error at timestep 68 is 0.012
Current timestep = 69. State = [[-0.324924 -0.079347]]. Action = [[-0.08297069 -0.05488757  0.          0.3013432 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 69 is [True, False, False, False, True, False]
State prediction error at timestep 69 is 0.012
Current timestep = 70. State = [[-0.32778  -0.082482]]. Action = [[-0.01454542 -0.02396128  0.          0.02888215]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 70 is [True, False, False, False, True, False]
State prediction error at timestep 70 is 0.012
Current timestep = 71. State = [[-0.3279824  -0.08397991]]. Action = [[ 0.00488553 -0.00518494  0.         -0.54344183]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 71 is [True, False, False, False, True, False]
State prediction error at timestep 71 is 0.012
Current timestep = 72. State = [[-0.33110738 -0.08600672]]. Action = [[-0.06774455 -0.02733359  0.          0.9019809 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 72 is [True, False, False, False, True, False]
State prediction error at timestep 72 is 0.012
Current timestep = 73. State = [[-0.33222526 -0.08249398]]. Action = [[ 0.01881512  0.09733189  0.         -0.14095664]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 73 is [True, False, False, False, True, False]
State prediction error at timestep 73 is 0.012
Current timestep = 74. State = [[-0.33280078 -0.08355485]]. Action = [[-0.01836509 -0.0853783   0.         -0.5593137 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 74 is [True, False, False, False, True, False]
State prediction error at timestep 74 is 0.012
Current timestep = 75. State = [[-0.33577377 -0.089941  ]]. Action = [[-0.04543436 -0.07269826  0.         -0.39439988]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 75 is [True, False, False, False, True, False]
State prediction error at timestep 75 is 0.012
Current timestep = 76. State = [[-0.3392199  -0.09303892]]. Action = [[-3.7618410e-02  1.8163025e-04  0.0000000e+00  7.1356511e-01]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 76 is [True, False, False, False, True, False]
State prediction error at timestep 76 is 0.012
Current timestep = 77. State = [[-0.3414189  -0.09785232]]. Action = [[-0.01348653 -0.07660855  0.         -0.311545  ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 77 is [True, False, False, False, True, False]
State prediction error at timestep 77 is 0.012
Current timestep = 78. State = [[-0.3419085  -0.10598537]]. Action = [[ 0.0088176  -0.09705828  0.          0.51455307]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 78 is [True, False, False, False, True, False]
State prediction error at timestep 78 is 0.012
Current timestep = 79. State = [[-0.34617656 -0.1131292 ]]. Action = [[-0.08410595 -0.05526781  0.         -0.64967614]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 79 is [True, False, False, False, True, False]
State prediction error at timestep 79 is 0.012
Current timestep = 80. State = [[-0.3493777  -0.11977927]]. Action = [[-0.00273821 -0.06441283  0.         -0.23225856]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 80 is [True, False, False, False, True, False]
State prediction error at timestep 80 is 0.012
Current timestep = 81. State = [[-0.34769306 -0.12471276]]. Action = [[ 0.0523889  -0.02938996  0.         -0.47577   ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 81 is [True, False, False, False, True, False]
State prediction error at timestep 81 is 0.012
Current timestep = 82. State = [[-0.3502639  -0.12274865]]. Action = [[-0.08084679  0.09289929  0.         -0.83660877]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 82 is [True, False, False, False, True, False]
State prediction error at timestep 82 is 0.012
Current timestep = 83. State = [[-0.3496516  -0.11991539]]. Action = [[ 0.09557936  0.0084514   0.         -0.7967107 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 83 is [True, False, False, False, True, False]
State prediction error at timestep 83 is 0.012
Current timestep = 84. State = [[-0.34718603 -0.11969393]]. Action = [[ 1.0477938e-02 -7.7143312e-04  0.0000000e+00 -9.0358460e-01]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 84 is [True, False, False, False, True, False]
State prediction error at timestep 84 is 0.012
Current timestep = 85. State = [[-0.34530267 -0.11827753]]. Action = [[ 0.03765007  0.03227519  0.         -0.30874026]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 85 is [True, False, False, False, True, False]
State prediction error at timestep 85 is 0.012
Current timestep = 86. State = [[-0.3454343 -0.120103 ]]. Action = [[-0.01675708 -0.05415622  0.         -0.28540534]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 86 is [True, False, False, False, True, False]
State prediction error at timestep 86 is 0.012
Current timestep = 87. State = [[-0.34890392 -0.12305215]]. Action = [[-0.05287606 -0.01641592  0.         -0.12867564]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 87 is [True, False, False, False, True, False]
State prediction error at timestep 87 is 0.012
Current timestep = 88. State = [[-0.35100242 -0.12475462]]. Action = [[-0.00321083 -0.00711001  0.          0.3568728 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 88 is [True, False, False, False, True, False]
State prediction error at timestep 88 is 0.012
Current timestep = 89. State = [[-0.35404032 -0.13023002]]. Action = [[-0.05046738 -0.09045341  0.          0.9829929 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 89 is [True, False, False, True, False, False]
State prediction error at timestep 89 is 0.012
Current timestep = 90. State = [[-0.35926694 -0.1299755 ]]. Action = [[-0.06923585  0.08169415  0.          0.30456305]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 90 is [True, False, False, True, False, False]
State prediction error at timestep 90 is 0.012
Current timestep = 91. State = [[-0.36676252 -0.12599865]]. Action = [[-0.0972987   0.05307455  0.         -0.79303753]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 91 is [True, False, False, True, False, False]
State prediction error at timestep 91 is 0.012
Current timestep = 92. State = [[-0.37007698 -0.1277802 ]]. Action = [[ 0.02130534 -0.06689826  0.         -0.19529057]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 92 is [True, False, False, True, False, False]
State prediction error at timestep 92 is 0.012
Current timestep = 93. State = [[-0.37006626 -0.12681435]]. Action = [[0.0036811  0.06034426 0.         0.37502968]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 93 is [True, False, False, True, False, False]
State prediction error at timestep 93 is 0.012
Current timestep = 94. State = [[-0.3686967 -0.1245316]]. Action = [[0.03166024 0.00575425 0.         0.10213578]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 94 is [True, False, False, False, True, False]
State prediction error at timestep 94 is 0.012
Current timestep = 95. State = [[-0.36961532 -0.12174302]]. Action = [[-0.02989867  0.04017638  0.         -0.81921107]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 95 is [True, False, False, False, True, False]
State prediction error at timestep 95 is 0.012
Current timestep = 96. State = [[-0.3714131  -0.11859533]]. Action = [[-0.00971439  0.0301424   0.         -0.04370892]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 96 is [True, False, False, False, True, False]
State prediction error at timestep 96 is 0.012
Current timestep = 97. State = [[-0.36826617 -0.11461917]]. Action = [[ 0.0807774   0.04114463  0.         -0.6593675 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 97 is [True, False, False, False, True, False]
State prediction error at timestep 97 is 0.012
Current timestep = 98. State = [[-0.3682648  -0.11114176]]. Action = [[-0.03965494  0.01769154  0.          0.92147255]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 98 is [True, False, False, False, True, False]
State prediction error at timestep 98 is 0.012
Current timestep = 99. State = [[-0.37182084 -0.10839062]]. Action = [[-0.03942654  0.02698264  0.         -0.16999316]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 99 is [True, False, False, False, True, False]
State prediction error at timestep 99 is 0.012
Current timestep = 100. State = [[-0.3737007  -0.10682634]]. Action = [[0.         0.         0.         0.11940181]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 100 is [True, False, False, False, True, False]
State prediction error at timestep 100 is 0.012
Current timestep = 101. State = [[-0.37439188 -0.10590777]]. Action = [[0.         0.         0.         0.28773856]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 101 is [True, False, False, False, True, False]
State prediction error at timestep 101 is 0.012
Current timestep = 102. State = [[-0.37305108 -0.10270731]]. Action = [[0.03710111 0.04353496 0.         0.2768674 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 102 is [True, False, False, False, True, False]
State prediction error at timestep 102 is 0.012
Current timestep = 103. State = [[-0.36794305 -0.10029064]]. Action = [[ 0.08918381 -0.00831923  0.         -0.28873467]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 103 is [True, False, False, False, True, False]
State prediction error at timestep 103 is 0.012
Current timestep = 104. State = [[-0.36748224 -0.10127585]]. Action = [[-0.04273349 -0.04148028  0.         -0.7239744 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 104 is [True, False, False, False, True, False]
State prediction error at timestep 104 is 0.012
Current timestep = 105. State = [[-0.36962137 -0.10389086]]. Action = [[-0.01482176 -0.03528193  0.         -0.9768368 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 105 is [True, False, False, False, True, False]
State prediction error at timestep 105 is 0.012
Current timestep = 106. State = [[-0.36617258 -0.10537354]]. Action = [[ 0.08357575 -0.01348406  0.         -0.11461991]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 106 is [True, False, False, False, True, False]
State prediction error at timestep 106 is 0.012
Current timestep = 107. State = [[-0.3641017  -0.10588992]]. Action = [[-0.01091077 -0.00968432  0.         -0.08456141]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 107 is [True, False, False, False, True, False]
State prediction error at timestep 107 is 0.012
Current timestep = 108. State = [[-0.3647807  -0.10744979]]. Action = [[-0.01592769 -0.02231164  0.         -0.52216256]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 108 is [True, False, False, False, True, False]
State prediction error at timestep 108 is 0.012
Current timestep = 109. State = [[-0.36200017 -0.10626697]]. Action = [[ 0.058874    0.04144724  0.         -0.8177222 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 109 is [True, False, False, False, True, False]
State prediction error at timestep 109 is 0.012
Current timestep = 110. State = [[-0.35580534 -0.10451893]]. Action = [[ 0.08087202  0.00300796  0.         -0.9461646 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 110 is [True, False, False, False, True, False]
State prediction error at timestep 110 is 0.012
Current timestep = 111. State = [[-0.34866193 -0.09961282]]. Action = [[0.08202185 0.07949492 0.         0.9906614 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 111 is [True, False, False, False, True, False]
State prediction error at timestep 111 is 0.012
Current timestep = 112. State = [[-0.34126097 -0.09682806]]. Action = [[ 0.08528724 -0.01235012  0.         -0.96350336]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 112 is [True, False, False, False, True, False]
State prediction error at timestep 112 is 0.012
Current timestep = 113. State = [[-0.34117305 -0.09506026]]. Action = [[-0.07417892  0.0336945   0.          0.84478045]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 113 is [True, False, False, False, True, False]
State prediction error at timestep 113 is 0.012
Current timestep = 114. State = [[-0.3397638  -0.08869367]]. Action = [[0.06916561 0.0973826  0.         0.2454791 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 114 is [True, False, False, False, True, False]
State prediction error at timestep 114 is 0.012
Current timestep = 115. State = [[-0.33869064 -0.08047839]]. Action = [[-0.01158882  0.08103619  0.         -0.38037252]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 115 is [True, False, False, False, True, False]
State prediction error at timestep 115 is 0.012
Current timestep = 116. State = [[-0.3376005  -0.07808656]]. Action = [[ 0.03212031 -0.03029605  0.          0.67524683]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 116 is [True, False, False, False, True, False]
State prediction error at timestep 116 is 0.012
Current timestep = 117. State = [[-0.33387274 -0.07311687]]. Action = [[0.05970105 0.08509628 0.         0.4118315 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 117 is [True, False, False, False, True, False]
State prediction error at timestep 117 is 0.012
Current timestep = 118. State = [[-0.33245522 -0.06742403]]. Action = [[-0.00548008  0.03136968  0.          0.8506783 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 118 is [True, False, False, False, True, False]
State prediction error at timestep 118 is 0.012
Current timestep = 119. State = [[-0.32883832 -0.06211849]]. Action = [[ 0.07496005  0.0512901   0.         -0.5467224 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 119 is [True, False, False, False, True, False]
State prediction error at timestep 119 is 0.012
Current timestep = 120. State = [[-0.32592055 -0.05939408]]. Action = [[ 0.01337998 -0.0130128   0.         -0.27900124]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 120 is [True, False, False, False, True, False]
State prediction error at timestep 120 is 0.012
Current timestep = 121. State = [[-0.3284565  -0.05521851]]. Action = [[-0.07190643  0.06262528  0.         -0.14114434]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 121 is [True, False, False, False, True, False]
State prediction error at timestep 121 is 0.012
Current timestep = 122. State = [[-0.32626262 -0.05257294]]. Action = [[ 0.08701735 -0.01347913  0.          0.5711534 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 122 is [True, False, False, False, True, False]
State prediction error at timestep 122 is 0.012
Current timestep = 123. State = [[-0.32382312 -0.0533673 ]]. Action = [[-0.01879687 -0.03573602  0.          0.10692334]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 123 is [True, False, False, False, True, False]
State prediction error at timestep 123 is 0.012
Current timestep = 124. State = [[-0.32203928 -0.05481014]]. Action = [[ 0.01601466 -0.02323282  0.          0.21763086]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 124 is [True, False, False, False, True, False]
State prediction error at timestep 124 is 0.012
Current timestep = 125. State = [[-0.32391578 -0.05462665]]. Action = [[-0.07914612  0.01010527  0.         -0.05132365]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 125 is [True, False, False, False, True, False]
State prediction error at timestep 125 is 0.012
Current timestep = 126. State = [[-0.32169768 -0.05438175]]. Action = [[ 0.06825583 -0.00703262  0.         -0.04624939]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 126 is [True, False, False, False, True, False]
State prediction error at timestep 126 is 0.012
Current timestep = 127. State = [[-0.32073015 -0.05401361]]. Action = [[-0.04754002  0.00680681  0.          0.01879144]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 127 is [True, False, False, False, True, False]
State prediction error at timestep 127 is 0.012
Current timestep = 128. State = [[-0.3252712  -0.05284323]]. Action = [[-0.09623236  0.02034541  0.          0.18736851]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 128 is [True, False, False, False, True, False]
State prediction error at timestep 128 is 0.012
Current timestep = 129. State = [[-0.33178008 -0.04842794]]. Action = [[-0.09710603  0.07774549  0.         -0.909334  ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 129 is [True, False, False, False, True, False]
State prediction error at timestep 129 is 0.012
Current timestep = 130. State = [[-0.33836505 -0.04988842]]. Action = [[-0.0848588  -0.08023626  0.          0.97973585]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 130 is [True, False, False, False, True, False]
State prediction error at timestep 130 is 0.012
Current timestep = 131. State = [[-0.34021637 -0.04807803]]. Action = [[ 0.02452739  0.08706162  0.         -0.33817333]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 131 is [True, False, False, False, True, False]
State prediction error at timestep 131 is 0.012
Current timestep = 132. State = [[-0.34046638 -0.04849353]]. Action = [[-1.5713274e-04 -7.2476134e-02  0.0000000e+00 -9.3395925e-01]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 132 is [True, False, False, False, True, False]
State prediction error at timestep 132 is 0.012
Current timestep = 133. State = [[-0.34036136 -0.05365004]]. Action = [[ 0.01759513 -0.06927857  0.          0.3322369 ]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 133 is [True, False, False, False, True, False]
State prediction error at timestep 133 is 0.012
Current timestep = 134. State = [[-0.33654827 -0.06037531]]. Action = [[ 0.08368777 -0.08932294  0.         -0.1830532 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 134 is [True, False, False, False, True, False]
State prediction error at timestep 134 is 0.012
Current timestep = 135. State = [[-0.3364084  -0.06236254]]. Action = [[-0.04159392  0.02638268  0.         -0.263579  ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 135 is [True, False, False, False, True, False]
State prediction error at timestep 135 is 0.012
Current timestep = 136. State = [[-0.33616808 -0.06324318]]. Action = [[ 0.04214465 -0.01857676  0.         -0.5455249 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 136 is [True, False, False, False, True, False]
State prediction error at timestep 136 is 0.012
Current timestep = 137. State = [[-0.33360782 -0.06221341]]. Action = [[ 0.04537598  0.04021681  0.         -0.8251441 ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 137 is [True, False, False, False, True, False]
State prediction error at timestep 137 is 0.012
Current timestep = 138. State = [[-0.3333504  -0.06577211]]. Action = [[-0.00896082 -0.08648797  0.         -0.6011182 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 138 is [True, False, False, False, True, False]
State prediction error at timestep 138 is 0.012
Current timestep = 139. State = [[-0.33381993 -0.074048  ]]. Action = [[ 0.00144257 -0.09740138  0.          0.4732709 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 139 is [True, False, False, False, True, False]
State prediction error at timestep 139 is 0.012
Current timestep = 140. State = [[-0.32989714 -0.07519073]]. Action = [[0.0879296  0.06759537 0.         0.75975275]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 140 is [True, False, False, False, True, False]
State prediction error at timestep 140 is 0.012
Current timestep = 141. State = [[-0.32558042 -0.06931984]]. Action = [[ 0.04135331  0.09023546  0.         -0.06988275]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 141 is [True, False, False, False, True, False]
State prediction error at timestep 141 is 0.012
Current timestep = 142. State = [[-0.3257608  -0.06314112]]. Action = [[-0.02416668  0.06962629  0.          0.17399645]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 142 is [True, False, False, False, True, False]
State prediction error at timestep 142 is 0.012
Current timestep = 143. State = [[-0.32485095 -0.05608462]]. Action = [[ 0.04110511  0.09079217  0.         -0.52428895]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 143 is [True, False, False, False, True, False]
State prediction error at timestep 143 is 0.012
Current timestep = 144. State = [[-0.3213053  -0.05278175]]. Action = [[ 0.06174278 -0.00877477  0.         -0.70893675]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 144 is [True, False, False, False, True, False]
State prediction error at timestep 144 is 0.012
Current timestep = 145. State = [[-0.31560606 -0.05307953]]. Action = [[ 0.08646726 -0.02543203  0.          0.4767716 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 145 is [True, False, False, False, True, False]
State prediction error at timestep 145 is 0.012
Current timestep = 146. State = [[-0.31273177 -0.05484474]]. Action = [[ 0.00307836 -0.03747223  0.          0.24625003]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 146 is [True, False, False, False, True, False]
State prediction error at timestep 146 is 0.012
Current timestep = 147. State = [[-0.31539    -0.05461533]]. Action = [[-0.07419313  0.01984207  0.         -0.9420088 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 147 is [True, False, False, False, True, False]
State prediction error at timestep 147 is 0.012
Current timestep = 148. State = [[-0.31789812 -0.05322681]]. Action = [[-0.02395105  0.01243401  0.         -0.21106172]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 148 is [True, False, False, False, True, False]
State prediction error at timestep 148 is 0.012
Current timestep = 149. State = [[-0.31916648 -0.0485487 ]]. Action = [[-0.01996619  0.07638253  0.         -0.31137848]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 149 is [True, False, False, False, True, False]
State prediction error at timestep 149 is 0.012
Current timestep = 150. State = [[-0.31912085 -0.04790635]]. Action = [[ 0.00639953 -0.04726395  0.         -0.23423773]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 150 is [True, False, False, False, True, False]
State prediction error at timestep 150 is 0.012
Current timestep = 151. State = [[-0.32033592 -0.04463446]]. Action = [[-0.03535977  0.077981    0.         -0.5698542 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 151 is [True, False, False, False, True, False]
State prediction error at timestep 151 is 0.012
Current timestep = 152. State = [[-0.3252392  -0.04382206]]. Action = [[-0.08546834 -0.04167936  0.         -0.30824268]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 152 is [True, False, False, False, True, False]
State prediction error at timestep 152 is 0.012
Current timestep = 153. State = [[-0.3283226 -0.0475811]]. Action = [[-0.01909339 -0.05993737  0.         -0.49667573]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 153 is [True, False, False, False, True, False]
State prediction error at timestep 153 is 0.012
Current timestep = 154. State = [[-0.32962275 -0.05398095]]. Action = [[-0.01765736 -0.09105944  0.          0.677847  ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 154 is [True, False, False, False, True, False]
State prediction error at timestep 154 is 0.012
Current timestep = 155. State = [[-0.333075   -0.05868926]]. Action = [[-0.06454287 -0.02857007  0.         -0.58711743]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 155 is [True, False, False, False, True, False]
State prediction error at timestep 155 is 0.012
Current timestep = 156. State = [[-0.3306322  -0.06359298]]. Action = [[ 0.09631538 -0.06606284  0.          0.2608112 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 156 is [True, False, False, False, True, False]
State prediction error at timestep 156 is 0.012
Current timestep = 157. State = [[-0.33016792 -0.07019156]]. Action = [[-0.05680401 -0.06990388  0.          0.16281736]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 157 is [True, False, False, False, True, False]
State prediction error at timestep 157 is 0.012
Current timestep = 158. State = [[-0.33218503 -0.0777284 ]]. Action = [[-0.01908929 -0.07745232  0.         -0.32034814]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 158 is [True, False, False, False, True, False]
State prediction error at timestep 158 is 0.012
Current timestep = 159. State = [[-0.32876542 -0.08545782]]. Action = [[ 0.08050441 -0.07333989  0.          0.94406533]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 159 is [True, False, False, False, True, False]
State prediction error at timestep 159 is 0.012
Current timestep = 160. State = [[-0.32507157 -0.08984529]]. Action = [[ 0.02443065 -0.00784156  0.         -0.8740796 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 160 is [True, False, False, False, True, False]
State prediction error at timestep 160 is 0.012
Current timestep = 161. State = [[-0.32011837 -0.09009524]]. Action = [[0.07942613 0.03452214 0.         0.36968005]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 161 is [True, False, False, False, True, False]
State prediction error at timestep 161 is 0.012
Current timestep = 162. State = [[-0.31815332 -0.09082493]]. Action = [[-0.00881167 -0.00804116  0.         -0.33206046]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 162 is [True, False, False, False, True, False]
State prediction error at timestep 162 is 0.012
Current timestep = 163. State = [[-0.31987438 -0.08945048]]. Action = [[-0.03323823  0.05922397  0.          0.6142738 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 163 is [True, False, False, False, True, False]
State prediction error at timestep 163 is 0.012
Current timestep = 164. State = [[-0.31934655 -0.08669081]]. Action = [[ 0.03466316  0.0387822   0.         -0.14046508]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 164 is [True, False, False, False, True, False]
State prediction error at timestep 164 is 0.012
Current timestep = 165. State = [[-0.31397054 -0.08246246]]. Action = [[ 0.09909924  0.05962933  0.         -0.28255308]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 165 is [True, False, False, False, True, False]
State prediction error at timestep 165 is 0.012
Current timestep = 166. State = [[-0.3098394  -0.07921509]]. Action = [[ 0.03544044  0.01555784  0.         -0.71008694]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 166 is [True, False, False, False, True, False]
State prediction error at timestep 166 is 0.012
Current timestep = 167. State = [[-0.30599573 -0.0788828 ]]. Action = [[ 0.06100287 -0.01755409  0.         -0.9477239 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 167 is [True, False, False, False, True, False]
State prediction error at timestep 167 is 0.012
Current timestep = 168. State = [[-0.30159238 -0.07522024]]. Action = [[0.05557228 0.06844025 0.         0.3619163 ]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 168 is [True, False, False, False, True, False]
State prediction error at timestep 168 is 0.012
Current timestep = 169. State = [[-0.29555747 -0.07706189]]. Action = [[ 0.08749374 -0.09507672  0.         -0.6846394 ]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 169 is [True, False, False, False, True, False]
State prediction error at timestep 169 is 0.012
Current timestep = 170. State = [[-0.292127   -0.07580077]]. Action = [[ 0.00155808  0.0683658   0.         -0.57995296]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 170 is [True, False, False, False, True, False]
State prediction error at timestep 170 is 0.012
Current timestep = 171. State = [[-0.2890537  -0.07224686]]. Action = [[ 0.04960083  0.02149124  0.         -0.50004685]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 171 is [True, False, False, False, True, False]
State prediction error at timestep 171 is 0.012
Current timestep = 172. State = [[-0.28927314 -0.06775602]]. Action = [[-0.04574952  0.06167934  0.         -0.32204366]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 172 is [True, False, False, False, True, False]
State prediction error at timestep 172 is 0.012
Current timestep = 173. State = [[-0.29184568 -0.07004771]]. Action = [[-0.0430637  -0.09628773  0.          0.6125511 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 173 is [True, False, False, False, True, False]
State prediction error at timestep 173 is 0.012
Current timestep = 174. State = [[-0.29551774 -0.07174634]]. Action = [[-0.07040967  0.01563574  0.          0.65946627]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 174 is [True, False, False, False, True, False]
State prediction error at timestep 174 is 0.012
Current timestep = 175. State = [[-0.2967067  -0.06941272]]. Action = [[-0.00135913  0.03624814  0.         -0.50893474]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 175 is [True, False, False, False, True, False]
State prediction error at timestep 175 is 0.012
Current timestep = 176. State = [[-0.2927901 -0.068423 ]]. Action = [[ 0.07167061 -0.01313334  0.         -0.30285203]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 176 is [True, False, False, False, True, False]
State prediction error at timestep 176 is 0.012
Current timestep = 177. State = [[-0.29026425 -0.06450999]]. Action = [[ 0.00078374  0.07220586  0.         -0.06658101]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 177 is [True, False, False, False, True, False]
State prediction error at timestep 177 is 0.012
Current timestep = 178. State = [[-0.288296   -0.05833368]]. Action = [[ 0.0339006   0.06569939  0.         -0.03266454]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 178 is [True, False, False, False, True, False]
State prediction error at timestep 178 is 0.012
Current timestep = 179. State = [[-0.28564802 -0.05962619]]. Action = [[ 0.0317174  -0.08609602  0.         -0.6378873 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 179 is [True, False, False, False, True, False]
State prediction error at timestep 179 is 0.012
Current timestep = 180. State = [[-0.28528652 -0.06387938]]. Action = [[-0.02266153 -0.04613214  0.          0.69155   ]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 180 is [True, False, False, False, True, False]
State prediction error at timestep 180 is 0.012
Current timestep = 181. State = [[-0.28766182 -0.06355577]]. Action = [[-0.05102316  0.03555208  0.          0.8183851 ]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 181 is [True, False, False, False, True, False]
State prediction error at timestep 181 is 0.012
Current timestep = 182. State = [[-0.28652522 -0.06697873]]. Action = [[ 0.04255792 -0.08809259  0.         -0.8239961 ]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 182 is [True, False, False, False, True, False]
State prediction error at timestep 182 is 0.012
Current timestep = 183. State = [[-0.28789344 -0.06554155]]. Action = [[-0.07077293  0.08616778  0.         -0.18445301]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 183 is [True, False, False, False, True, False]
State prediction error at timestep 183 is 0.012
Current timestep = 184. State = [[-0.2884342  -0.06188855]]. Action = [[0.02589329 0.02521404 0.         0.8529171 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 184 is [True, False, False, False, True, False]
State prediction error at timestep 184 is 0.012
Current timestep = 185. State = [[-0.2847512  -0.05975501]]. Action = [[ 0.06569769  0.01783788  0.         -0.38379776]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 185 is [True, False, False, False, True, False]
State prediction error at timestep 185 is 0.012
Current timestep = 186. State = [[-0.28575414 -0.06221387]]. Action = [[-0.05819391 -0.06710884  0.         -0.94576174]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 186 is [True, False, False, False, True, False]
State prediction error at timestep 186 is 0.012
Current timestep = 187. State = [[-0.28383714 -0.0596551 ]]. Action = [[0.07454874 0.09273987 0.         0.47669947]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 187 is [True, False, False, False, True, False]
State prediction error at timestep 187 is 0.012
Current timestep = 188. State = [[-0.27960598 -0.05633758]]. Action = [[ 0.05260085  0.0025412   0.         -0.57161003]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 188 is [True, False, False, False, True, False]
State prediction error at timestep 188 is 0.012
Current timestep = 189. State = [[-0.27406687 -0.05061303]]. Action = [[0.0878674  0.09567057 0.         0.1119225 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 189 is [True, False, False, False, True, False]
State prediction error at timestep 189 is 0.012
Current timestep = 190. State = [[-0.27421707 -0.05066198]]. Action = [[-0.05437192 -0.08486065  0.          0.78376555]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 190 is [True, False, False, False, True, False]
State prediction error at timestep 190 is 0.012
Current timestep = 191. State = [[-0.2756834  -0.05309411]]. Action = [[-0.00622382 -0.00950444  0.         -0.7951282 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 191 is [True, False, False, False, True, False]
State prediction error at timestep 191 is 0.012
Current timestep = 192. State = [[-0.2718516  -0.05126519]]. Action = [[0.07846951 0.03925348 0.         0.23868382]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 192 is [True, False, False, False, True, False]
State prediction error at timestep 192 is 0.012
Current timestep = 193. State = [[-0.26519394 -0.05462364]]. Action = [[ 0.08475376 -0.09730351  0.         -0.85029477]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 193 is [True, False, False, False, True, False]
State prediction error at timestep 193 is 0.012
Current timestep = 194. State = [[-0.26077172 -0.05266792]]. Action = [[ 0.02459947  0.09512203  0.         -0.0240348 ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 194 is [True, False, False, False, True, False]
State prediction error at timestep 194 is 0.012
Current timestep = 195. State = [[-0.2604729  -0.05332825]]. Action = [[-0.02676065 -0.06845657  0.          0.64145064]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 195 is [True, False, False, False, True, False]
State prediction error at timestep 195 is 0.012
Current timestep = 196. State = [[-0.26098123 -0.0586077 ]]. Action = [[-0.01997313 -0.0633789   0.         -0.46609902]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 196 is [True, False, False, False, True, False]
State prediction error at timestep 196 is 0.012
Current timestep = 197. State = [[-0.26182988 -0.05615171]]. Action = [[-0.02913294  0.09803899  0.         -0.04217392]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 197 is [True, False, False, False, True, False]
State prediction error at timestep 197 is 0.012
Current timestep = 198. State = [[-0.26216164 -0.05238132]]. Action = [[-0.00518145  0.02210631  0.         -0.13174242]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 198 is [True, False, False, False, True, False]
State prediction error at timestep 198 is 0.012
Current timestep = 199. State = [[-0.26115856 -0.04977397]]. Action = [[0.01377072 0.03175464 0.         0.46658075]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 199 is [True, False, False, False, True, False]
State prediction error at timestep 199 is 0.012
Current timestep = 200. State = [[-0.25613797 -0.05159242]]. Action = [[ 0.08866837 -0.06372884  0.          0.8047106 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 200 is [True, False, False, False, True, False]
State prediction error at timestep 200 is 0.012
Current timestep = 201. State = [[-0.25739935 -0.05110197]]. Action = [[-0.09963728  0.04562307  0.         -0.7303585 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 201 is [True, False, False, False, True, False]
State prediction error at timestep 201 is 0.012
Current timestep = 202. State = [[-0.25971475 -0.04583406]]. Action = [[ 0.01372969  0.07401478  0.         -0.37497103]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 202 is [True, False, False, False, True, False]
State prediction error at timestep 202 is 0.012
Current timestep = 203. State = [[-0.25881273 -0.04137978]]. Action = [[0.03079679 0.02936555 0.         0.88116693]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 203 is [True, False, False, False, True, False]
State prediction error at timestep 203 is 0.012
Current timestep = 204. State = [[-0.26325098 -0.03920305]]. Action = [[-0.09553662  0.0074361   0.          0.56615937]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 204 is [True, False, False, False, True, False]
State prediction error at timestep 204 is 0.012
Current timestep = 205. State = [[-0.26314884 -0.03863703]]. Action = [[ 0.07862469 -0.01221822  0.         -0.00350201]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 205 is [True, False, False, False, True, False]
State prediction error at timestep 205 is 0.012
Current timestep = 206. State = [[-0.2627846  -0.03968672]]. Action = [[-0.02758104 -0.02839027  0.          0.43885493]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 206 is [True, False, False, False, True, False]
State prediction error at timestep 206 is 0.012
Current timestep = 207. State = [[-0.26661077 -0.04249676]]. Action = [[-0.06656671 -0.04742297  0.          0.9427171 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 207 is [True, False, False, False, True, False]
State prediction error at timestep 207 is 0.012
Current timestep = 208. State = [[-0.26401705 -0.04649693]]. Action = [[ 0.09372016 -0.05449561  0.          0.99166226]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 208 is [True, False, False, False, True, False]
State prediction error at timestep 208 is 0.012
Current timestep = 209. State = [[-0.25998968 -0.05055672]]. Action = [[ 0.01848885 -0.04243303  0.          0.32107306]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 209 is [True, False, False, False, True, False]
State prediction error at timestep 209 is 0.012
Current timestep = 210. State = [[-0.25492895 -0.04856766]]. Action = [[0.07581138 0.07693285 0.         0.27240837]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 210 is [True, False, False, False, True, False]
State prediction error at timestep 210 is 0.012
Current timestep = 211. State = [[-0.25200364 -0.04738659]]. Action = [[ 0.00561909 -0.01224796  0.         -0.4178825 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 211 is [True, False, False, False, True, False]
State prediction error at timestep 211 is 0.012
Current timestep = 212. State = [[-0.25577775 -0.04380378]]. Action = [[-0.09821889  0.08508011  0.          0.60448813]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 212 is [True, False, False, False, True, False]
State prediction error at timestep 212 is 0.012
Current timestep = 213. State = [[-0.2601423  -0.03868705]]. Action = [[-0.03787294  0.05345585  0.         -0.6106347 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 213 is [True, False, False, False, True, False]
State prediction error at timestep 213 is 0.012
Current timestep = 214. State = [[-0.25788662 -0.03311647]]. Action = [[ 0.08194851  0.06537334  0.         -0.37116373]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 214 is [True, False, False, False, True, False]
State prediction error at timestep 214 is 0.012
Current timestep = 215. State = [[-0.25670663 -0.02896534]]. Action = [[-0.00999141  0.02379422  0.         -0.535717  ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 215 is [True, False, False, False, True, False]
State prediction error at timestep 215 is 0.012
Current timestep = 216. State = [[-0.25481623 -0.02400691]]. Action = [[ 0.05203732  0.06142607  0.         -0.7833507 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 216 is [True, False, False, False, True, False]
State prediction error at timestep 216 is 0.012
Current timestep = 217. State = [[-0.25826988 -0.02168971]]. Action = [[-0.09518235 -0.01473077  0.          0.03574967]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 217 is [True, False, False, False, True, False]
State prediction error at timestep 217 is 0.012
Current timestep = 218. State = [[-0.25813964 -0.0229524 ]]. Action = [[ 0.06755545 -0.04342345  0.         -0.55490094]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 218 is [True, False, False, False, True, False]
State prediction error at timestep 218 is 0.012
Current timestep = 219. State = [[-0.2574342 -0.0224337]]. Action = [[-0.02191421  0.01703962  0.          0.1606834 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 219 is [True, False, False, False, True, False]
State prediction error at timestep 219 is 0.012
Current timestep = 220. State = [[-0.25709668 -0.0217813 ]]. Action = [[ 0.01412831 -0.01183335  0.         -0.653043  ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 220 is [True, False, False, False, True, False]
State prediction error at timestep 220 is 0.012
Current timestep = 221. State = [[-0.2587634  -0.01735832]]. Action = [[-0.044709    0.08114203  0.          0.81247103]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 221 is [True, False, False, False, True, False]
State prediction error at timestep 221 is 0.012
Current timestep = 222. State = [[-0.2642933  -0.01002232]]. Action = [[-0.08587576  0.08262318  0.          0.8246758 ]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 222 is [True, False, False, False, True, False]
State prediction error at timestep 222 is 0.012
Current timestep = 223. State = [[-0.27144128 -0.0023442 ]]. Action = [[-0.08651321  0.07867614  0.          0.93394005]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 223 is [True, False, False, False, True, False]
State prediction error at timestep 223 is 0.012
Current timestep = 224. State = [[-0.27681163  0.00641493]]. Action = [[-0.0363778   0.09473156  0.         -0.4123146 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 224 is [True, False, False, False, True, False]
State prediction error at timestep 224 is 0.012
Current timestep = 225. State = [[-0.27504647  0.01119268]]. Action = [[ 9.7632639e-02 -2.2386014e-04  0.0000000e+00  5.1452816e-01]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 225 is [True, False, False, False, True, False]
State prediction error at timestep 225 is 0.012
Current timestep = 226. State = [[-0.2763855   0.01487385]]. Action = [[-0.05765215  0.03545868  0.          0.5289302 ]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 226 is [True, False, False, False, True, False]
State prediction error at timestep 226 is 0.012
Current timestep = 227. State = [[-0.27539372  0.01323935]]. Action = [[ 0.07703767 -0.08573862  0.          0.08602011]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 227 is [True, False, False, False, True, False]
State prediction error at timestep 227 is 0.012
Current timestep = 228. State = [[-0.27247435  0.00902725]]. Action = [[ 0.03076085 -0.05657064  0.         -0.70641214]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 228 is [True, False, False, False, True, False]
State prediction error at timestep 228 is 0.012
Current timestep = 229. State = [[-0.27556634  0.01188353]]. Action = [[-0.08112167  0.0805572   0.         -0.54819727]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 229 is [True, False, False, False, True, False]
State prediction error at timestep 229 is 0.012
Current timestep = 230. State = [[-0.2790564   0.01239125]]. Action = [[-0.02027931 -0.04841634  0.          0.9498532 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 230 is [True, False, False, False, True, False]
State prediction error at timestep 230 is 0.012
Current timestep = 231. State = [[-0.2758072   0.01329324]]. Action = [[ 0.08933201  0.03565674  0.         -0.5562528 ]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 231 is [True, False, False, False, True, False]
State prediction error at timestep 231 is 0.012
Current timestep = 232. State = [[-0.26957363  0.01020595]]. Action = [[ 0.08178236 -0.08400054  0.          0.75736856]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 232 is [True, False, False, False, True, False]
State prediction error at timestep 232 is 0.012
Current timestep = 233. State = [[-0.2706412   0.01248191]]. Action = [[-0.08310437  0.09771391  0.          0.25492954]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 233 is [True, False, False, False, True, False]
State prediction error at timestep 233 is 0.012
Current timestep = 234. State = [[-0.2687248   0.01269033]]. Action = [[ 0.09362882 -0.05004777  0.          0.01931775]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 234 is [True, False, False, False, True, False]
State prediction error at timestep 234 is 0.012
Current timestep = 235. State = [[-0.26842156  0.01305097]]. Action = [[-0.05275721  0.03627472  0.         -0.12875408]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 235 is [True, False, False, False, True, False]
State prediction error at timestep 235 is 0.012
Current timestep = 236. State = [[-0.26700947  0.00903605]]. Action = [[ 0.05046607 -0.09847365  0.         -0.9721306 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 236 is [True, False, False, False, True, False]
State prediction error at timestep 236 is 0.012
Current timestep = 237. State = [[-0.26222003  0.0089357 ]]. Action = [[0.06234524 0.0633396  0.         0.4381032 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 237 is [True, False, False, False, True, False]
State prediction error at timestep 237 is 0.012
Current timestep = 238. State = [[-0.25759855  0.01368046]]. Action = [[0.05353069 0.06746554 0.         0.43462968]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 238 is [True, False, False, False, True, False]
State prediction error at timestep 238 is 0.012
Current timestep = 239. State = [[-0.25383276  0.018617  ]]. Action = [[ 0.04239265  0.05968372  0.         -0.61793566]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 239 is [True, False, False, False, True, False]
State prediction error at timestep 239 is 0.012
Current timestep = 240. State = [[-0.25062674  0.01825021]]. Action = [[ 0.03337624 -0.046882    0.          0.7587408 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 240 is [True, False, False, False, True, False]
State prediction error at timestep 240 is 0.012
Current timestep = 241. State = [[-0.24862032  0.01666844]]. Action = [[ 0.00426346 -0.00932635  0.          0.20876658]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 241 is [True, False, False, False, True, False]
State prediction error at timestep 241 is 0.012
Current timestep = 242. State = [[-0.24908918  0.01319122]]. Action = [[-0.03706463 -0.06626555  0.          0.36524403]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 242 is [True, False, False, False, True, False]
State prediction error at timestep 242 is 0.012
Current timestep = 243. State = [[-0.25085416  0.01432383]]. Action = [[-0.04224936  0.05942445  0.         -0.5759227 ]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 243 is [True, False, False, False, True, False]
State prediction error at timestep 243 is 0.012
Current timestep = 244. State = [[-0.2525163   0.01844151]]. Action = [[-0.02609134  0.04302607  0.          0.02485895]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 244 is [True, False, False, False, True, False]
State prediction error at timestep 244 is 0.012
Current timestep = 245. State = [[-0.25435874  0.02449529]]. Action = [[-0.0294378   0.08185606  0.          0.70086753]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 245 is [True, False, False, False, True, False]
State prediction error at timestep 245 is 0.012
Current timestep = 246. State = [[-0.25216538  0.02802126]]. Action = [[0.06492827 0.00351547 0.         0.01838219]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 246 is [True, False, False, False, True, False]
State prediction error at timestep 246 is 0.012
Current timestep = 247. State = [[-0.2551543  0.0333625]]. Action = [[-0.09800553  0.08266083  0.          0.6473994 ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 247 is [True, False, False, False, True, False]
State prediction error at timestep 247 is 0.012
Current timestep = 248. State = [[-0.26174417  0.03918307]]. Action = [[-0.06673756  0.04162658  0.          0.14702559]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 248 is [True, False, False, False, True, False]
State prediction error at timestep 248 is 0.012
Current timestep = 249. State = [[-0.26613793  0.03717372]]. Action = [[-0.03351276 -0.09778798  0.         -0.7860285 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 249 is [True, False, False, False, True, False]
State prediction error at timestep 249 is 0.012
Current timestep = 250. State = [[-0.27069438  0.03117273]]. Action = [[-0.0643495  -0.08868106  0.          0.39860976]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 250 is [True, False, False, False, True, False]
State prediction error at timestep 250 is 0.012
Current timestep = 251. State = [[-0.26915696  0.03130565]]. Action = [[ 0.0872656   0.04713624  0.         -0.43543458]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 251 is [True, False, False, False, True, False]
State prediction error at timestep 251 is 0.012
Current timestep = 252. State = [[-0.27017647  0.03221026]]. Action = [[-0.06406257 -0.0146413   0.          0.7022412 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 252 is [True, False, False, False, True, False]
State prediction error at timestep 252 is 0.012
Current timestep = 253. State = [[-0.27701676  0.0315654 ]]. Action = [[-0.09831903 -0.01400302  0.          0.02466536]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 253 is [True, False, False, False, True, False]
State prediction error at timestep 253 is 0.012
Current timestep = 254. State = [[-0.2781004   0.03020198]]. Action = [[ 0.05219635 -0.02322022  0.         -0.7885103 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 254 is [True, False, False, False, True, False]
State prediction error at timestep 254 is 0.012
Current timestep = 255. State = [[-0.27875164  0.03391379]]. Action = [[-0.02651195  0.0892221   0.         -0.8168889 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 255 is [True, False, False, False, True, False]
State prediction error at timestep 255 is 0.012
Current timestep = 256. State = [[-0.2815601   0.03857125]]. Action = [[-0.02270103  0.03821061  0.         -0.8023792 ]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 256 is [True, False, False, False, True, False]
State prediction error at timestep 256 is 0.012
Current timestep = 257. State = [[-0.28168344  0.04469186]]. Action = [[ 0.03832378  0.09020045  0.         -0.8241176 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 257 is [True, False, False, False, True, False]
State prediction error at timestep 257 is 0.012
Current timestep = 258. State = [[-0.2823777   0.04927888]]. Action = [[-0.00296441  0.02705752  0.         -0.7659553 ]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 258 is [True, False, False, False, True, False]
State prediction error at timestep 258 is 0.012
Current timestep = 259. State = [[-0.2865812   0.05383103]]. Action = [[-0.05658524  0.05703773  0.          0.68668246]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 259 is [True, False, False, False, True, False]
State prediction error at timestep 259 is 0.012
Current timestep = 260. State = [[-0.2866701   0.06134447]]. Action = [[0.06697123 0.09690454 0.         0.94628024]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 260 is [True, False, False, False, True, False]
State prediction error at timestep 260 is 0.012
Current timestep = 261. State = [[-0.28345323  0.0611476 ]]. Action = [[ 0.05872671 -0.08565628  0.          0.53379023]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 261 is [True, False, False, False, True, False]
State prediction error at timestep 261 is 0.012
Current timestep = 262. State = [[-0.28473762  0.05876284]]. Action = [[-0.05382015 -0.02013361  0.          0.30620217]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 262 is [True, False, False, False, True, False]
State prediction error at timestep 262 is 0.012
Current timestep = 263. State = [[-0.29091272  0.06372131]]. Action = [[-0.09326884  0.0934334   0.         -0.0293349 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 263 is [True, False, False, False, True, False]
State prediction error at timestep 263 is 0.012
Current timestep = 264. State = [[-0.29716575  0.07052726]]. Action = [[-0.05873246  0.05696218  0.         -0.84896934]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 264 is [True, False, False, False, True, False]
State prediction error at timestep 264 is 0.012
Current timestep = 265. State = [[-0.30203298  0.06996173]]. Action = [[-0.04692098 -0.07746659  0.          0.10845613]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 265 is [True, False, False, False, True, False]
State prediction error at timestep 265 is 0.012
Current timestep = 266. State = [[-0.3044239   0.06447797]]. Action = [[-0.01355476 -0.09146859  0.          0.563499  ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 266 is [True, False, False, False, True, False]
State prediction error at timestep 266 is 0.012
Current timestep = 267. State = [[-0.30214015  0.05778148]]. Action = [[ 0.05679294 -0.08886103  0.         -0.20960104]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 267 is [True, False, False, False, True, False]
State prediction error at timestep 267 is 0.012
Current timestep = 268. State = [[-0.30423927  0.05585822]]. Action = [[-0.07766265  0.01920233  0.          0.76058364]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 268 is [True, False, False, False, True, False]
State prediction error at timestep 268 is 0.012
Current timestep = 269. State = [[-0.30645007  0.05713174]]. Action = [[0.00217776 0.0207987  0.         0.89136255]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 269 is [True, False, False, False, True, False]
State prediction error at timestep 269 is 0.012
Current timestep = 270. State = [[-0.3079255   0.05722017]]. Action = [[-0.01824551 -0.0042288   0.          0.37617683]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 270 is [True, False, False, False, True, False]
State prediction error at timestep 270 is 0.012
Current timestep = 271. State = [[-0.30721372  0.05628859]]. Action = [[ 0.03740668 -0.0081032   0.          0.11308277]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 271 is [True, False, False, False, True, False]
State prediction error at timestep 271 is 0.012
Current timestep = 272. State = [[-0.30902824  0.05947851]]. Action = [[-0.04190005  0.07939287  0.          0.3330425 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 272 is [True, False, False, False, True, False]
State prediction error at timestep 272 is 0.012
Current timestep = 273. State = [[-0.31043318  0.05918268]]. Action = [[ 0.01360656 -0.04711839  0.          0.6510427 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 273 is [True, False, False, False, True, False]
State prediction error at timestep 273 is 0.012
Current timestep = 274. State = [[-0.3116755   0.06218117]]. Action = [[-0.01387528  0.09124922  0.         -0.71032465]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 274 is [True, False, False, False, True, False]
State prediction error at timestep 274 is 0.012
Current timestep = 275. State = [[-0.31053293  0.06874306]]. Action = [[ 0.0596187   0.08101343  0.         -0.0348435 ]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 275 is [True, False, False, False, True, False]
State prediction error at timestep 275 is 0.012
Current timestep = 276. State = [[-0.3136971   0.06910733]]. Action = [[-0.07890238 -0.04928231  0.         -0.3679859 ]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 276 is [True, False, False, False, True, False]
State prediction error at timestep 276 is 0.012
Current timestep = 277. State = [[-0.3158841   0.06361549]]. Action = [[ 0.0207376  -0.09217788  0.          0.75566316]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 277 is [True, False, False, False, True, False]
State prediction error at timestep 277 is 0.012
Current timestep = 278. State = [[-0.31894943  0.06493405]]. Action = [[-0.05207764  0.08330765  0.          0.65749335]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 278 is [True, False, False, False, True, False]
State prediction error at timestep 278 is 0.012
Current timestep = 279. State = [[-0.32417113  0.06672224]]. Action = [[-0.05400294 -0.01759986  0.         -0.36770654]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 279 is [True, False, False, False, True, False]
State prediction error at timestep 279 is 0.012
Current timestep = 280. State = [[-0.32888597  0.06395723]]. Action = [[-0.04599093 -0.05814148  0.         -0.09917009]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 280 is [True, False, False, False, True, False]
State prediction error at timestep 280 is 0.012
Current timestep = 281. State = [[-0.32851973  0.06148602]]. Action = [[ 0.05087202 -0.01895991  0.          0.49590337]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 281 is [True, False, False, False, True, False]
State prediction error at timestep 281 is 0.012
Current timestep = 282. State = [[-0.32422566  0.05611213]]. Action = [[ 0.07080226 -0.08798846  0.          0.41281605]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 282 is [True, False, False, False, True, False]
State prediction error at timestep 282 is 0.012
Current timestep = 283. State = [[-0.32356784  0.05285986]]. Action = [[-2.8187126e-02  6.4696372e-04  0.0000000e+00  8.1139421e-01]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 283 is [True, False, False, False, True, False]
State prediction error at timestep 283 is 0.012
Current timestep = 284. State = [[-0.32891694  0.05210605]]. Action = [[-0.09890959 -0.00117623  0.         -0.0380137 ]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 284 is [True, False, False, False, True, False]
State prediction error at timestep 284 is 0.012
Current timestep = 285. State = [[-0.32962367  0.05153176]]. Action = [[ 0.04869366  0.00047702  0.         -0.27904463]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 285 is [True, False, False, False, True, False]
State prediction error at timestep 285 is 0.012
Current timestep = 286. State = [[-0.33184755  0.0470554 ]]. Action = [[-0.07356026 -0.07800369  0.         -0.07798249]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 286 is [True, False, False, False, True, False]
State prediction error at timestep 286 is 0.012
Current timestep = 287. State = [[-0.33565742  0.0490003 ]]. Action = [[-0.03127161  0.09989857  0.         -0.5866436 ]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 287 is [True, False, False, False, True, False]
State prediction error at timestep 287 is 0.012
Current timestep = 288. State = [[-0.3376639   0.05593571]]. Action = [[ 0.00411229  0.08926732  0.         -0.09009129]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 288 is [True, False, False, False, True, False]
State prediction error at timestep 288 is 0.012
Current timestep = 289. State = [[-0.34106845  0.05701596]]. Action = [[-0.04035716 -0.03542302  0.         -0.2635529 ]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 289 is [True, False, False, False, True, False]
State prediction error at timestep 289 is 0.012
Current timestep = 290. State = [[-0.33867323  0.05257513]]. Action = [[ 0.09734147 -0.07145954  0.         -0.02795124]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 290 is [True, False, False, False, True, False]
State prediction error at timestep 290 is 0.012
Current timestep = 291. State = [[-0.33934304  0.05070234]]. Action = [[-0.05713931  0.01066504  0.         -0.7663967 ]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 291 is [True, False, False, False, True, False]
State prediction error at timestep 291 is 0.012
Current timestep = 292. State = [[-0.3443329   0.04722777]]. Action = [[-0.0625463  -0.07223548  0.          0.49005258]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 292 is [True, False, False, False, True, False]
State prediction error at timestep 292 is 0.012
Current timestep = 293. State = [[-0.34409702  0.04107144]]. Action = [[ 0.04731906 -0.07586887  0.          0.20205629]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 293 is [True, False, False, False, True, False]
State prediction error at timestep 293 is 0.012
Current timestep = 294. State = [[-0.3407475   0.04014534]]. Action = [[0.04698782 0.04513011 0.         0.29335082]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 294 is [True, False, False, False, True, False]
State prediction error at timestep 294 is 0.012
Current timestep = 295. State = [[-0.34339014  0.04069804]]. Action = [[-0.079163    0.00162347  0.          0.7200632 ]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 295 is [True, False, False, False, True, False]
State prediction error at timestep 295 is 0.012
Current timestep = 296. State = [[-0.35042593  0.04081953]]. Action = [[-0.09001391  0.00916243  0.          0.8843081 ]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 296 is [True, False, False, False, True, False]
State prediction error at timestep 296 is 0.012
Current timestep = 297. State = [[-0.35025927  0.04505273]]. Action = [[ 0.09163158  0.08728083  0.         -0.98925376]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 297 is [True, False, False, False, True, False]
State prediction error at timestep 297 is 0.012
Current timestep = 298. State = [[-0.35206652  0.05168556]]. Action = [[-0.06739083  0.08127836  0.          0.87305737]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 298 is [True, False, False, False, True, False]
State prediction error at timestep 298 is 0.012
Current timestep = 299. State = [[-0.35217538  0.05353411]]. Action = [[ 0.05995821 -0.02107758  0.         -0.16872978]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 299 is [True, False, False, False, True, False]
State prediction error at timestep 299 is 0.012
Current timestep = 300. State = [[-0.35036096  0.05214578]]. Action = [[ 0.02406726 -0.02474345  0.          0.8243147 ]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 300 is [True, False, False, False, True, False]
State prediction error at timestep 300 is 0.012
Current timestep = 301. State = [[-0.35238832  0.05004519]]. Action = [[-0.04933728 -0.03398766  0.         -0.41738147]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 301 is [True, False, False, False, True, False]
State prediction error at timestep 301 is 0.012
Current timestep = 302. State = [[-0.35451567  0.04460435]]. Action = [[-0.01862063 -0.09534556  0.         -0.6467637 ]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 302 is [True, False, False, False, True, False]
State prediction error at timestep 302 is 0.012
Current timestep = 303. State = [[-0.35500893  0.04608322]]. Action = [[0.00112841 0.09300032 0.         0.01337445]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 303 is [True, False, False, False, True, False]
State prediction error at timestep 303 is 0.012
Current timestep = 304. State = [[-0.35112584  0.05064994]]. Action = [[ 0.09127598  0.03858715  0.         -0.5939901 ]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 304 is [True, False, False, False, True, False]
State prediction error at timestep 304 is 0.012
Current timestep = 305. State = [[-0.34843764  0.05144186]]. Action = [[ 0.01257388 -0.01067562  0.         -0.13458979]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 305 is [True, False, False, False, True, False]
State prediction error at timestep 305 is 0.012
Current timestep = 306. State = [[-0.3472422   0.05032225]]. Action = [[ 0.0142207  -0.01958447  0.          0.42453074]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 306 is [True, False, False, False, True, False]
State prediction error at timestep 306 is 0.012
Current timestep = 307. State = [[-0.347805    0.05295533]]. Action = [[-0.02269419  0.06272305  0.         -0.7118628 ]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 307 is [True, False, False, False, True, False]
State prediction error at timestep 307 is 0.012
Current timestep = 308. State = [[-0.35210845  0.05452526]]. Action = [[-0.07670791 -0.01200892  0.         -0.57948595]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 308 is [True, False, False, False, True, False]
State prediction error at timestep 308 is 0.012
Current timestep = 309. State = [[-0.35501692  0.05374131]]. Action = [[-0.01899513 -0.02193917  0.         -0.24825007]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 309 is [True, False, False, False, True, False]
State prediction error at timestep 309 is 0.012
Current timestep = 310. State = [[-0.3562144   0.05805962]]. Action = [[-0.00771308  0.09098392  0.          0.89527404]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 310 is [True, False, False, False, True, False]
State prediction error at timestep 310 is 0.012
Current timestep = 311. State = [[-0.35275817  0.06583799]]. Action = [[ 0.09839325  0.09345367  0.         -0.2632689 ]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 311 is [True, False, False, False, True, False]
State prediction error at timestep 311 is 0.012
Current timestep = 312. State = [[-0.34957457  0.07207994]]. Action = [[ 0.03474412  0.05695762  0.         -0.28462952]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 312 is [True, False, False, False, True, False]
State prediction error at timestep 312 is 0.012
Current timestep = 313. State = [[-0.35124895  0.07680634]]. Action = [[-0.03894487  0.04155552  0.         -0.3176986 ]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 313 is [True, False, False, False, True, False]
State prediction error at timestep 313 is 0.012
Current timestep = 314. State = [[-0.35027206  0.08374467]]. Action = [[0.0606556  0.09062483 0.         0.03274632]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 314 is [True, False, False, False, True, False]
State prediction error at timestep 314 is 0.012
Current timestep = 315. State = [[-0.34920782  0.09016749]]. Action = [[ 0.00686908  0.04994369  0.         -0.52691865]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 315 is [True, False, False, False, True, False]
State prediction error at timestep 315 is 0.012
Current timestep = 316. State = [[-0.34463894  0.08936868]]. Action = [[ 0.09516902 -0.07655267  0.          0.9859054 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 316 is [True, False, False, False, True, False]
State prediction error at timestep 316 is 0.012
Current timestep = 317. State = [[-0.3433256   0.09169412]]. Action = [[-0.03308152  0.06699195  0.         -0.44100857]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 317 is [True, False, False, False, True, False]
State prediction error at timestep 317 is 0.012
Current timestep = 318. State = [[-0.3437468   0.09097013]]. Action = [[-0.00384919 -0.08461466  0.          0.538484  ]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 318 is [True, False, False, False, True, False]
State prediction error at timestep 318 is 0.012
Current timestep = 319. State = [[-0.33905095  0.09152488]]. Action = [[ 0.07944661  0.03174534  0.         -0.489398  ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 319 is [True, False, False, False, True, False]
State prediction error at timestep 319 is 0.012
Current timestep = 320. State = [[-0.33598065  0.09129915]]. Action = [[-0.0113832  -0.04154754  0.         -0.07388496]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 320 is [True, False, False, False, True, False]
State prediction error at timestep 320 is 0.012
Current timestep = 321. State = [[-0.33642134  0.08987838]]. Action = [[-0.03960497 -0.02587609  0.          0.7758266 ]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 321 is [True, False, False, False, True, False]
State prediction error at timestep 321 is 0.012
Current timestep = 322. State = [[-0.33151627  0.09090852]]. Action = [[0.09529164 0.02536049 0.         0.23380637]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 322 is [True, False, False, False, True, False]
State prediction error at timestep 322 is 0.012
Current timestep = 323. State = [[-0.32888788  0.09023276]]. Action = [[-0.0380289  -0.03560158  0.          0.73209715]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 323 is [True, False, False, False, True, False]
State prediction error at timestep 323 is 0.012
Current timestep = 324. State = [[-0.33236066  0.09184307]]. Action = [[-0.08567055  0.0413663   0.         -0.65301824]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 324 is [True, False, False, False, True, False]
State prediction error at timestep 324 is 0.012
Current timestep = 325. State = [[-0.33325386  0.09027199]]. Action = [[ 0.00748942 -0.06792901  0.         -0.74373543]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 325 is [True, False, False, False, True, False]
State prediction error at timestep 325 is 0.012
Current timestep = 326. State = [[-0.33178052  0.09067179]]. Action = [[ 0.00927542  0.04223023  0.         -0.96729946]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 326 is [True, False, False, False, True, False]
State prediction error at timestep 326 is 0.012
Current timestep = 327. State = [[-0.33221158  0.0874107 ]]. Action = [[-0.027773   -0.09101842  0.          0.63733697]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 327 is [True, False, False, False, True, False]
State prediction error at timestep 327 is 0.012
Current timestep = 328. State = [[-0.336868    0.08209366]]. Action = [[-0.0977295  -0.05809113  0.         -0.22927636]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 328 is [True, False, False, False, True, False]
State prediction error at timestep 328 is 0.012
Current timestep = 329. State = [[-0.34319183  0.08371479]]. Action = [[-0.0802382   0.06772222  0.          0.21889639]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 329 is [True, False, False, False, True, False]
State prediction error at timestep 329 is 0.012
Current timestep = 330. State = [[-0.34222665  0.08231741]]. Action = [[ 0.0804474  -0.06525839  0.          0.34611845]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 330 is [True, False, False, False, True, False]
State prediction error at timestep 330 is 0.012
Current timestep = 331. State = [[-0.34543106  0.0833503 ]]. Action = [[-0.09573589  0.06936931  0.         -0.01418412]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 331 is [True, False, False, False, True, False]
State prediction error at timestep 331 is 0.012
Current timestep = 332. State = [[-0.34938562  0.08588295]]. Action = [[-0.00324064  0.01468589  0.         -0.9650372 ]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 332 is [True, False, False, False, True, False]
State prediction error at timestep 332 is 0.012
Current timestep = 333. State = [[-0.34885103  0.0907364 ]]. Action = [[ 0.05169832  0.09133273  0.         -0.9666131 ]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 333 is [True, False, False, False, True, False]
State prediction error at timestep 333 is 0.012
Current timestep = 334. State = [[-0.3497134   0.08933888]]. Action = [[-0.01224783 -0.07963748  0.         -0.23841894]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 334 is [True, False, False, False, True, False]
State prediction error at timestep 334 is 0.012
Current timestep = 335. State = [[-0.3522648   0.08694872]]. Action = [[-0.02042683 -0.00158922  0.         -0.24857134]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 335 is [True, False, False, False, True, False]
State prediction error at timestep 335 is 0.012
Current timestep = 336. State = [[-0.35594785  0.08834986]]. Action = [[-0.03708806  0.03426159  0.          0.544919  ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 336 is [True, False, False, False, True, False]
State prediction error at timestep 336 is 0.012
Current timestep = 337. State = [[-0.35911646  0.08506056]]. Action = [[-0.01980055 -0.08641309  0.         -0.21847332]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 337 is [True, False, False, False, True, False]
State prediction error at timestep 337 is 0.012
Current timestep = 338. State = [[-0.36401418  0.08692824]]. Action = [[-0.0661864   0.09364087  0.         -0.73228985]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 338 is [True, False, False, False, True, False]
State prediction error at timestep 338 is 0.012
Current timestep = 339. State = [[-0.369843    0.08562359]]. Action = [[-0.0546456  -0.08666154  0.         -0.43282878]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 339 is [True, False, False, False, True, False]
State prediction error at timestep 339 is 0.012
Current timestep = 340. State = [[-0.36995578  0.08485318]]. Action = [[ 0.056404    0.03266782  0.         -0.7109239 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 340 is [True, False, False, False, True, False]
State prediction error at timestep 340 is 0.012
Current timestep = 341. State = [[-0.36594865  0.08621364]]. Action = [[ 0.07224711  0.01855035  0.         -0.53498703]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 341 is [True, False, False, False, True, False]
State prediction error at timestep 341 is 0.012
Current timestep = 342. State = [[-0.36454836  0.08659533]]. Action = [[0.00119704 0.00516788 0.         0.68729067]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 342 is [True, False, False, False, True, False]
State prediction error at timestep 342 is 0.012
Current timestep = 343. State = [[-0.36236957  0.08481719]]. Action = [[ 0.04929963 -0.03291995  0.         -0.6164951 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 343 is [True, False, False, False, True, False]
State prediction error at timestep 343 is 0.012
Current timestep = 344. State = [[-0.35867095  0.08207807]]. Action = [[ 0.04546113 -0.02658944  0.          0.604738  ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 344 is [True, False, False, False, True, False]
State prediction error at timestep 344 is 0.012
Current timestep = 345. State = [[-0.35568255  0.07638498]]. Action = [[ 0.02121743 -0.08684698  0.         -0.15997213]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 345 is [True, False, False, False, True, False]
State prediction error at timestep 345 is 0.012
Current timestep = 346. State = [[-0.35558847  0.07719953]]. Action = [[-0.02774825  0.08443392  0.         -0.35764176]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 346 is [True, False, False, False, True, False]
State prediction error at timestep 346 is 0.012
Current timestep = 347. State = [[-0.35571668  0.07953908]]. Action = [[0.00513898 0.00777678 0.         0.38699365]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 347 is [True, False, False, False, True, False]
State prediction error at timestep 347 is 0.012
Current timestep = 348. State = [[-0.35266098  0.07883345]]. Action = [[ 0.05342049 -0.01493974  0.         -0.44285524]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 348 is [True, False, False, False, True, False]
State prediction error at timestep 348 is 0.012
Current timestep = 349. State = [[-0.3500662   0.07488667]]. Action = [[ 0.00927167 -0.06272862  0.         -0.64070034]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 349 is [True, False, False, False, True, False]
State prediction error at timestep 349 is 0.012
Current timestep = 350. State = [[-0.35054007  0.07253195]]. Action = [[-0.03582796 -0.00322063  0.         -0.32054746]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 350 is [True, False, False, False, True, False]
State prediction error at timestep 350 is 0.012
Current timestep = 351. State = [[-0.35141608  0.0720816 ]]. Action = [[-1.43888295e-02 -1.32910907e-04  0.00000000e+00  5.37557602e-01]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 351 is [True, False, False, False, True, False]
State prediction error at timestep 351 is 0.012
Current timestep = 352. State = [[-0.35278296  0.07340892]]. Action = [[-0.0290448   0.03100079  0.         -0.9101254 ]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 352 is [True, False, False, False, True, False]
State prediction error at timestep 352 is 0.012
Current timestep = 353. State = [[-0.3550756  0.0693954]]. Action = [[-0.03787947 -0.0984361   0.         -0.48478913]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 353 is [True, False, False, False, True, False]
State prediction error at timestep 353 is 0.012
Current timestep = 354. State = [[-0.35996768  0.06635852]]. Action = [[-0.08906347 -0.00326948  0.          0.7360873 ]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 354 is [True, False, False, False, True, False]
State prediction error at timestep 354 is 0.012
Current timestep = 355. State = [[-0.3640682   0.06679945]]. Action = [[-0.03239907  0.01451205  0.         -0.24832118]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 355 is [True, False, False, False, True, False]
State prediction error at timestep 355 is 0.012
Current timestep = 356. State = [[-0.36242822  0.07002239]]. Action = [[0.07307122 0.06122526 0.         0.0860337 ]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 356 is [True, False, False, False, True, False]
State prediction error at timestep 356 is 0.012
Current timestep = 357. State = [[-0.35857967  0.06719621]]. Action = [[ 0.05739697 -0.08531006  0.          0.9602027 ]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 357 is [True, False, False, False, True, False]
State prediction error at timestep 357 is 0.012
Current timestep = 358. State = [[-0.35422635  0.06110889]]. Action = [[ 0.05734735 -0.06000493  0.          0.6758517 ]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 358 is [True, False, False, False, True, False]
State prediction error at timestep 358 is 0.012
Current timestep = 359. State = [[-0.35141772  0.06028834]]. Action = [[0.02036209 0.04030734 0.         0.12570786]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 359 is [True, False, False, False, True, False]
State prediction error at timestep 359 is 0.012
Current timestep = 360. State = [[-0.34831643  0.06513827]]. Action = [[ 0.05384945  0.09314866  0.         -0.61892647]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 360 is [True, False, False, False, True, False]
State prediction error at timestep 360 is 0.012
Current timestep = 361. State = [[-0.3510981   0.07083277]]. Action = [[-0.08127633  0.06800442  0.          0.8156121 ]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 361 is [True, False, False, False, True, False]
State prediction error at timestep 361 is 0.012
Current timestep = 362. State = [[-0.35489887  0.07372958]]. Action = [[-0.01559198  0.01370113  0.         -0.35039037]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 362 is [True, False, False, False, True, False]
State prediction error at timestep 362 is 0.012
Current timestep = 363. State = [[-0.3526974   0.07196207]]. Action = [[ 0.07225939 -0.05020162  0.          0.3761872 ]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 363 is [True, False, False, False, True, False]
State prediction error at timestep 363 is 0.012
Current timestep = 364. State = [[-0.34882498  0.06874377]]. Action = [[ 0.04371256 -0.03554789  0.         -0.97263044]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 364 is [True, False, False, False, True, False]
State prediction error at timestep 364 is 0.012
Current timestep = 365. State = [[-0.34867492  0.06430349]]. Action = [[-0.03154184 -0.06682341  0.         -0.27600598]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 365 is [True, False, False, False, True, False]
State prediction error at timestep 365 is 0.012
Current timestep = 366. State = [[-0.34678882  0.06555623]]. Action = [[0.04600526 0.06810338 0.         0.84440506]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 366 is [True, False, False, False, True, False]
State prediction error at timestep 366 is 0.012
Current timestep = 367. State = [[-0.34644195  0.06345095]]. Action = [[-0.03018109 -0.07878159  0.          0.6478708 ]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 367 is [True, False, False, False, True, False]
State prediction error at timestep 367 is 0.012
Current timestep = 368. State = [[-0.34224492  0.06500922]]. Action = [[ 0.09539228  0.08254253  0.         -0.5728567 ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 368 is [True, False, False, False, True, False]
State prediction error at timestep 368 is 0.012
Current timestep = 369. State = [[-0.3367227  0.0635817]]. Action = [[ 0.04097544 -0.06924746  0.          0.02762902]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 369 is [True, False, False, False, True, False]
State prediction error at timestep 369 is 0.012
Current timestep = 370. State = [[-0.33178395  0.06447186]]. Action = [[ 0.0486482   0.06333358  0.         -0.6584465 ]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 370 is [True, False, False, False, True, False]
State prediction error at timestep 370 is 0.012
Current timestep = 371. State = [[-0.33353782  0.06670264]]. Action = [[-0.0922754   0.01031687  0.          0.10843635]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 371 is [True, False, False, False, True, False]
State prediction error at timestep 371 is 0.012
Current timestep = 372. State = [[-0.33714998  0.06441103]]. Action = [[-0.04205335 -0.0609902   0.         -0.32867497]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 372 is [True, False, False, False, True, False]
State prediction error at timestep 372 is 0.012
Current timestep = 373. State = [[-0.3365799   0.06372833]]. Action = [[0.02417841 0.01743629 0.         0.37088263]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 373 is [True, False, False, False, True, False]
State prediction error at timestep 373 is 0.012
Current timestep = 374. State = [[-0.33432278  0.06667418]]. Action = [[0.02849316 0.05033054 0.         0.45122695]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 374 is [True, False, False, False, True, False]
State prediction error at timestep 374 is 0.012
Current timestep = 375. State = [[-0.33417523  0.06961629]]. Action = [[-0.01295059  0.02658694  0.         -0.46888477]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 375 is [True, False, False, False, True, False]
State prediction error at timestep 375 is 0.012
Current timestep = 376. State = [[-0.33064598  0.06714275]]. Action = [[ 0.07793459 -0.07030288  0.         -0.7294052 ]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 376 is [True, False, False, False, True, False]
State prediction error at timestep 376 is 0.012
Current timestep = 377. State = [[-0.3274224   0.06780346]]. Action = [[ 0.01628248  0.05679289  0.         -0.41296673]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 377 is [True, False, False, False, True, False]
State prediction error at timestep 377 is 0.012
Current timestep = 378. State = [[-0.32521155  0.06506238]]. Action = [[ 0.02499916 -0.0865989   0.         -0.3394674 ]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 378 is [True, False, False, False, True, False]
State prediction error at timestep 378 is 0.012
Current timestep = 379. State = [[-0.32847795  0.06426197]]. Action = [[-0.09956655  0.03235096  0.         -0.5708886 ]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 379 is [True, False, False, False, True, False]
State prediction error at timestep 379 is 0.012
Current timestep = 380. State = [[-0.32631466  0.06185844]]. Action = [[ 0.09148902 -0.06600899  0.         -0.7401458 ]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 380 is [True, False, False, False, True, False]
State prediction error at timestep 380 is 0.012
Current timestep = 381. State = [[-0.32283393  0.06291752]]. Action = [[ 0.00433896  0.06511136  0.         -0.710396  ]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 381 is [True, False, False, False, True, False]
State prediction error at timestep 381 is 0.012
Current timestep = 382. State = [[-0.32337007  0.06148845]]. Action = [[-0.03280153 -0.06434791  0.          0.7218077 ]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 382 is [True, False, False, False, True, False]
State prediction error at timestep 382 is 0.012
Current timestep = 383. State = [[-0.32161453  0.05480698]]. Action = [[ 0.03060811 -0.09663288  0.         -0.47275913]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 383 is [True, False, False, False, True, False]
State prediction error at timestep 383 is 0.012
Current timestep = 384. State = [[-0.31505904  0.04685276]]. Action = [[ 0.09049081 -0.08724773  0.          0.09765232]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 384 is [True, False, False, False, True, False]
State prediction error at timestep 384 is 0.012
Current timestep = 385. State = [[-0.3140501   0.03831389]]. Action = [[-0.07005149 -0.09655289  0.          0.06793427]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 385 is [True, False, False, False, True, False]
State prediction error at timestep 385 is 0.012
Current timestep = 386. State = [[-0.314283    0.03753658]]. Action = [[ 0.00956962  0.07097002  0.         -0.30797338]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 386 is [True, False, False, False, True, False]
State prediction error at timestep 386 is 0.012
Current timestep = 387. State = [[-0.3182015   0.04182135]]. Action = [[-0.09130742  0.07073156  0.         -0.82999414]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 387 is [True, False, False, False, True, False]
State prediction error at timestep 387 is 0.012
Current timestep = 388. State = [[-0.3237246   0.04075077]]. Action = [[-0.05873357 -0.05307183  0.          0.54345584]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 388 is [True, False, False, False, True, False]
State prediction error at timestep 388 is 0.012
Current timestep = 389. State = [[-0.328817   0.0417504]]. Action = [[-0.0576416   0.05809379  0.          0.0535357 ]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 389 is [True, False, False, False, True, False]
State prediction error at timestep 389 is 0.012
Current timestep = 390. State = [[-0.33175582  0.04330745]]. Action = [[-0.0017455   0.0031541   0.          0.12712479]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 390 is [True, False, False, False, True, False]
State prediction error at timestep 390 is 0.012
Current timestep = 391. State = [[-0.33310986  0.04180969]]. Action = [[ 0.00272062 -0.03047898  0.         -0.9681096 ]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 391 is [True, False, False, False, True, False]
State prediction error at timestep 391 is 0.012
Current timestep = 392. State = [[-0.33693156  0.039821  ]]. Action = [[-0.05441289 -0.01840308  0.         -0.70569754]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 392 is [True, False, False, False, True, False]
State prediction error at timestep 392 is 0.012
Current timestep = 393. State = [[-0.33597323  0.03737993]]. Action = [[ 0.07764467 -0.03144535  0.         -0.9625329 ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 393 is [True, False, False, False, True, False]
State prediction error at timestep 393 is 0.012
Current timestep = 394. State = [[-0.33869225  0.03394147]]. Action = [[-0.08598656 -0.04167542  0.          0.9566463 ]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 394 is [True, False, False, False, True, False]
State prediction error at timestep 394 is 0.012
Current timestep = 395. State = [[-0.34262273  0.03099494]]. Action = [[-0.01231229 -0.02475339  0.          0.16604269]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 395 is [True, False, False, False, True, False]
State prediction error at timestep 395 is 0.012
Current timestep = 396. State = [[-0.34617206  0.02803189]]. Action = [[-0.04061718 -0.03182213  0.          0.74991536]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 396 is [True, False, False, False, True, False]
State prediction error at timestep 396 is 0.012
Current timestep = 397. State = [[-0.35088304  0.0233951 ]]. Action = [[-0.05308446 -0.06055566  0.          0.01375067]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 397 is [True, False, False, False, True, False]
State prediction error at timestep 397 is 0.012
Current timestep = 398. State = [[-0.35381696  0.02223618]]. Action = [[-0.00858318  0.02901501  0.          0.7597914 ]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 398 is [True, False, False, False, True, False]
State prediction error at timestep 398 is 0.012
Current timestep = 399. State = [[-0.35462976  0.02078272]]. Action = [[ 0.01578669 -0.02805732  0.          0.5673311 ]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 399 is [True, False, False, False, True, False]
State prediction error at timestep 399 is 0.012
Current timestep = 400. State = [[-0.35569826  0.01561108]]. Action = [[-0.00858404 -0.07072638  0.          0.90279615]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 400 is [True, False, False, False, True, False]
State prediction error at timestep 400 is 0.012
Current timestep = 401. State = [[-0.35734043  0.01271417]]. Action = [[-0.0122075   0.00387862  0.         -0.4020986 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 401 is [True, False, False, False, True, False]
State prediction error at timestep 401 is 0.012
Current timestep = 402. State = [[-0.36203384  0.01040665]]. Action = [[-0.07188563 -0.0272503   0.         -0.3986498 ]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 402 is [True, False, False, False, True, False]
State prediction error at timestep 402 is 0.012
Current timestep = 403. State = [[-0.36255676  0.00824282]]. Action = [[ 0.05077463 -0.00888107  0.         -0.8169536 ]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 403 is [True, False, False, False, True, False]
State prediction error at timestep 403 is 0.012
Current timestep = 404. State = [[-0.3590057   0.00248029]]. Action = [[ 0.06155103 -0.08891229  0.          0.85012555]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 404 is [True, False, False, False, True, False]
State prediction error at timestep 404 is 0.012
Current timestep = 405. State = [[-0.35463834  0.00099126]]. Action = [[ 0.06424963  0.04745797  0.         -0.4720571 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 405 is [True, False, False, False, True, False]
State prediction error at timestep 405 is 0.012
Current timestep = 406. State = [[-0.35239533  0.00047324]]. Action = [[ 0.01777609 -0.01467505  0.          0.31221056]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 406 is [True, False, False, False, True, False]
State prediction error at timestep 406 is 0.012
Current timestep = 407. State = [[-3.5536486e-01 -3.6958965e-05]]. Action = [[-0.07007273  0.01543732  0.         -0.5621452 ]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 407 is [True, False, False, False, True, False]
State prediction error at timestep 407 is 0.012
Current timestep = 408. State = [[-0.35799628 -0.00323069]]. Action = [[-0.01275649 -0.05715167  0.          0.22244465]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 408 is [True, False, False, False, True, False]
State prediction error at timestep 408 is 0.012
Current timestep = 409. State = [[-0.35645148 -0.01032165]]. Action = [[ 0.0399354  -0.09178049  0.         -0.21691102]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 409 is [True, False, False, False, True, False]
State prediction error at timestep 409 is 0.012
Current timestep = 410. State = [[-0.35806724 -0.01914417]]. Action = [[-0.06606541 -0.09912776  0.          0.8801396 ]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 410 is [True, False, False, False, True, False]
State prediction error at timestep 410 is 0.012
Current timestep = 411. State = [[-0.36122864 -0.02707244]]. Action = [[-0.04080061 -0.06969124  0.          0.9302002 ]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 411 is [True, False, False, False, True, False]
State prediction error at timestep 411 is 0.012
Current timestep = 412. State = [[-0.3615966  -0.02644732]]. Action = [[ 0.01623962  0.09420358  0.         -0.9161777 ]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 412 is [True, False, False, False, True, False]
State prediction error at timestep 412 is 0.012
Current timestep = 413. State = [[-0.36021832 -0.02690069]]. Action = [[ 0.02643705 -0.04100062  0.         -0.70916575]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 413 is [True, False, False, False, True, False]
State prediction error at timestep 413 is 0.012
Current timestep = 414. State = [[-0.36253068 -0.02762404]]. Action = [[-0.05646575  0.02577332  0.          0.9251492 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 414 is [True, False, False, False, True, False]
State prediction error at timestep 414 is 0.012
Current timestep = 415. State = [[-0.36239523 -0.02949958]]. Action = [[ 0.04680907 -0.03598819  0.          0.98881316]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 415 is [True, False, False, False, True, False]
State prediction error at timestep 415 is 0.012
Current timestep = 416. State = [[-0.36459813 -0.03142518]]. Action = [[-0.06226669 -0.0032639   0.         -0.4628172 ]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 416 is [True, False, False, False, True, False]
State prediction error at timestep 416 is 0.012
Current timestep = 417. State = [[-0.36317503 -0.03211408]]. Action = [[ 0.08013058  0.00036044  0.         -0.21147603]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 417 is [True, False, False, False, True, False]
State prediction error at timestep 417 is 0.012
Current timestep = 418. State = [[-0.36512107 -0.03454143]]. Action = [[-0.08166286 -0.03781302  0.         -0.70637006]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 418 is [True, False, False, False, True, False]
State prediction error at timestep 418 is 0.012
Current timestep = 419. State = [[-0.36783186 -0.03133922]]. Action = [[0.00485333 0.0982404  0.         0.3252722 ]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 419 is [True, False, False, False, True, False]
State prediction error at timestep 419 is 0.012
Current timestep = 420. State = [[-0.36706188 -0.02516878]]. Action = [[ 0.0420351   0.06197999  0.         -0.16977727]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 420 is [True, False, False, False, True, False]
State prediction error at timestep 420 is 0.012
Current timestep = 421. State = [[-0.36970407 -0.02368227]]. Action = [[-0.0509559  -0.02182326  0.          0.7509217 ]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 421 is [True, False, False, False, True, False]
State prediction error at timestep 421 is 0.012
Current timestep = 422. State = [[-0.36916333 -0.02340449]]. Action = [[ 0.06254528  0.0062324   0.         -0.98159015]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 422 is [True, False, False, False, True, False]
State prediction error at timestep 422 is 0.012
Current timestep = 423. State = [[-0.36864904 -0.02126272]]. Action = [[-0.00323447  0.02758669  0.          0.7456614 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 423 is [True, False, False, False, True, False]
State prediction error at timestep 423 is 0.012
Current timestep = 424. State = [[-0.36515877 -0.01594013]]. Action = [[0.09256329 0.07457607 0.         0.90157545]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 424 is [True, False, False, False, True, False]
State prediction error at timestep 424 is 0.012
Current timestep = 425. State = [[-0.36336344 -0.01652349]]. Action = [[-0.00097075 -0.08202976  0.         -0.8076555 ]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 425 is [True, False, False, False, True, False]
State prediction error at timestep 425 is 0.012
Current timestep = 426. State = [[-0.35994673 -0.01814227]]. Action = [[0.06958269 0.00295367 0.         0.488878  ]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 426 is [True, False, False, False, True, False]
State prediction error at timestep 426 is 0.012
Current timestep = 427. State = [[-0.3589651  -0.01513333]]. Action = [[-0.0228494   0.05357748  0.          0.5688182 ]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 427 is [True, False, False, False, True, False]
State prediction error at timestep 427 is 0.012
Current timestep = 428. State = [[-0.3622025 -0.0158025]]. Action = [[-0.06203667 -0.05185557  0.         -0.68762636]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 428 is [True, False, False, False, True, False]
State prediction error at timestep 428 is 0.012
Current timestep = 429. State = [[-0.36155105 -0.01249103]]. Action = [[ 0.04346477  0.09320938  0.         -0.13253349]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 429 is [True, False, False, False, True, False]
State prediction error at timestep 429 is 0.012
Current timestep = 430. State = [[-0.3608176  -0.00825816]]. Action = [[-0.00771398  0.01826577  0.         -0.68535745]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 430 is [True, False, False, False, True, False]
State prediction error at timestep 430 is 0.012
Current timestep = 431. State = [[-0.3580782  -0.00786435]]. Action = [[ 0.05677135 -0.02074119  0.         -0.34598404]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 431 is [True, False, False, False, True, False]
State prediction error at timestep 431 is 0.012
Current timestep = 432. State = [[-0.35403204 -0.00903219]]. Action = [[ 0.04193885 -0.02415978  0.         -0.7631167 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 432 is [True, False, False, False, True, False]
State prediction error at timestep 432 is 0.012
Current timestep = 433. State = [[-0.35318196 -0.01420515]]. Action = [[-0.02686401 -0.09515855  0.          0.866186  ]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 433 is [True, False, False, False, True, False]
State prediction error at timestep 433 is 0.012
Current timestep = 434. State = [[-0.35655364 -0.01782571]]. Action = [[-0.08449087 -0.01299673  0.          0.6640625 ]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 434 is [True, False, False, False, True, False]
State prediction error at timestep 434 is 0.012
Current timestep = 435. State = [[-0.3610512  -0.02307456]]. Action = [[-0.07287253 -0.08499196  0.         -0.01479512]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 435 is [True, False, False, False, True, False]
State prediction error at timestep 435 is 0.012
Current timestep = 436. State = [[-0.36509427 -0.02353628]]. Action = [[-0.05904313  0.05740508  0.         -0.5950826 ]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 436 is [True, False, False, False, True, False]
State prediction error at timestep 436 is 0.012
Current timestep = 437. State = [[-0.37120637 -0.02241217]]. Action = [[-0.09654173  0.00264307  0.          0.5140873 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 437 is [True, False, False, False, True, False]
State prediction error at timestep 437 is 0.012
Current timestep = 438. State = [[-0.37423962 -0.02261515]]. Action = [[0.        0.        0.        0.5001869]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 438 is [True, False, False, False, True, False]
State prediction error at timestep 438 is 0.012
Current timestep = 439. State = [[-0.37192369 -0.02613119]]. Action = [[ 0.06668853 -0.0651292   0.          0.8095763 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 439 is [True, False, False, False, True, False]
State prediction error at timestep 439 is 0.012
Current timestep = 440. State = [[-0.36927092 -0.02752718]]. Action = [[ 0.03342762  0.01814346  0.         -0.2590834 ]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 440 is [True, False, False, False, True, False]
State prediction error at timestep 440 is 0.012
Current timestep = 441. State = [[-0.36897564 -0.02744454]]. Action = [[0.        0.        0.        0.4045037]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 441 is [True, False, False, False, True, False]
State prediction error at timestep 441 is 0.012
Current timestep = 442. State = [[-0.37223345 -0.02733713]]. Action = [[-0.05332578  0.0090837   0.         -0.8108663 ]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 442 is [True, False, False, False, True, False]
State prediction error at timestep 442 is 0.012
Current timestep = 443. State = [[-0.37450752 -0.02740416]]. Action = [[ 0.         0.         0.        -0.4437071]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 443 is [True, False, False, False, True, False]
State prediction error at timestep 443 is 0.012
Current timestep = 444. State = [[-0.37596697 -0.02249447]]. Action = [[-0.00712611  0.0995298   0.         -0.62653923]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 444 is [True, False, False, False, True, False]
State prediction error at timestep 444 is 0.012
Current timestep = 445. State = [[-0.3730843  -0.01626904]]. Action = [[ 0.09703413  0.05453553  0.         -0.4946915 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 445 is [True, False, False, False, True, False]
State prediction error at timestep 445 is 0.012
Current timestep = 446. State = [[-0.3728101  -0.00989246]]. Action = [[-0.01821793  0.07413789  0.          0.66037965]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 446 is [True, False, False, False, True, False]
State prediction error at timestep 446 is 0.012
Current timestep = 447. State = [[-0.3747597  -0.00377869]]. Action = [[ 0.00247018  0.05641594  0.         -0.25697613]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 447 is [True, False, False, False, True, False]
State prediction error at timestep 447 is 0.012
Current timestep = 448. State = [[-0.37777096 -0.00477185]]. Action = [[-0.0342971  -0.08106737  0.         -0.5842132 ]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 448 is [True, False, False, False, True, False]
State prediction error at timestep 448 is 0.012
Current timestep = 449. State = [[-0.37614483 -0.00356767]]. Action = [[0.07372297 0.05353268 0.         0.09421408]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 449 is [True, False, False, False, True, False]
State prediction error at timestep 449 is 0.012
Current timestep = 450. State = [[-0.3738005  -0.00470065]]. Action = [[ 0.01921485 -0.07225363  0.         -0.8079358 ]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 450 is [True, False, False, False, True, False]
State prediction error at timestep 450 is 0.012
Current timestep = 451. State = [[-0.37301576 -0.00606337]]. Action = [[ 0.        0.        0.       -0.043814]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 451 is [True, False, False, False, True, False]
State prediction error at timestep 451 is 0.012
Current timestep = 452. State = [[-0.37262186 -0.00574346]]. Action = [[0.      0.      0.      0.09428]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 452 is [True, False, False, False, True, False]
State prediction error at timestep 452 is 0.012
Current timestep = 453. State = [[-0.36904517 -0.00410677]]. Action = [[0.0647961 0.0260021 0.        0.7845838]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 453 is [True, False, False, False, True, False]
State prediction error at timestep 453 is 0.012
Current timestep = 454. State = [[-0.36544704 -0.00520116]]. Action = [[ 0.02510985 -0.04274772  0.         -0.248559  ]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 454 is [True, False, False, False, True, False]
State prediction error at timestep 454 is 0.012
Current timestep = 455. State = [[-0.36046246 -0.0084879 ]]. Action = [[ 0.0651074  -0.04124139  0.         -0.12591517]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 455 is [True, False, False, False, True, False]
State prediction error at timestep 455 is 0.012
Current timestep = 456. State = [[-0.36166593 -0.01179615]]. Action = [[-0.097564   -0.03393858  0.         -0.76892203]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 456 is [True, False, False, False, True, False]
State prediction error at timestep 456 is 0.012
Current timestep = 457. State = [[-0.36400566 -0.01296987]]. Action = [[-0.01558197  0.00778686  0.          0.6488712 ]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 457 is [True, False, False, False, True, False]
State prediction error at timestep 457 is 0.012
Current timestep = 458. State = [[-0.36649442 -0.01502165]]. Action = [[-0.05210643 -0.03358372  0.         -0.6983514 ]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 458 is [True, False, False, False, True, False]
State prediction error at timestep 458 is 0.012
Current timestep = 459. State = [[-0.37181425 -0.01598896]]. Action = [[-0.08981835  0.01250692  0.         -0.62494725]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 459 is [True, False, False, False, True, False]
State prediction error at timestep 459 is 0.012
Current timestep = 460. State = [[-0.3711537  -0.01985288]]. Action = [[ 0.07024831 -0.07263957  0.          0.6815803 ]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 460 is [True, False, False, False, True, False]
State prediction error at timestep 460 is 0.012
Current timestep = 461. State = [[-0.36530036 -0.01899508]]. Action = [[0.08062708 0.07491467 0.         0.7849951 ]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 461 is [True, False, False, False, True, False]
State prediction error at timestep 461 is 0.012
Current timestep = 462. State = [[-0.36115003 -0.02009026]]. Action = [[ 0.03488613 -0.05896032  0.         -0.9389544 ]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 462 is [True, False, False, False, True, False]
State prediction error at timestep 462 is 0.012
Current timestep = 463. State = [[-0.3580634  -0.02014936]]. Action = [[0.03403526 0.03993172 0.         0.9115062 ]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 463 is [True, False, False, False, True, False]
State prediction error at timestep 463 is 0.012
Current timestep = 464. State = [[-0.35806975 -0.02201936]]. Action = [[-0.0270206  -0.05123943  0.         -0.50400436]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 464 is [True, False, False, False, True, False]
State prediction error at timestep 464 is 0.012
Current timestep = 465. State = [[-0.3561234 -0.0218802]]. Action = [[0.04615731 0.04132345 0.         0.290493  ]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 465 is [True, False, False, False, True, False]
State prediction error at timestep 465 is 0.012
Current timestep = 466. State = [[-0.3538775  -0.02124474]]. Action = [[ 0.01622567 -0.00485907  0.         -0.45286238]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 466 is [True, False, False, False, True, False]
State prediction error at timestep 466 is 0.012
Current timestep = 467. State = [[-0.35010576 -0.02434914]]. Action = [[ 0.05855576 -0.05541181  0.          0.9220178 ]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 467 is [True, False, False, False, True, False]
State prediction error at timestep 467 is 0.012
Current timestep = 468. State = [[-0.35172835 -0.02462105]]. Action = [[-8.5717276e-02  3.6575012e-02  0.0000000e+00  3.2782555e-05]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 468 is [True, False, False, False, True, False]
State prediction error at timestep 468 is 0.012
Current timestep = 469. State = [[-0.35857943 -0.02379132]]. Action = [[-0.09894673  0.00388857  0.         -0.03090715]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 469 is [True, False, False, False, True, False]
State prediction error at timestep 469 is 0.012
Current timestep = 470. State = [[-0.35896584 -0.02553253]]. Action = [[ 0.05917346 -0.03557009  0.          0.50279486]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 470 is [True, False, False, False, True, False]
State prediction error at timestep 470 is 0.012
Current timestep = 471. State = [[-0.35410348 -0.02522254]]. Action = [[0.06771555 0.0289024  0.         0.06915569]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 471 is [True, False, False, False, True, False]
State prediction error at timestep 471 is 0.012
Current timestep = 472. State = [[-0.34826264 -0.02655763]]. Action = [[ 0.07767337 -0.04328289  0.          0.86710835]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 472 is [True, False, False, False, True, False]
State prediction error at timestep 472 is 0.012
Current timestep = 473. State = [[-0.34902227 -0.03194844]]. Action = [[-0.08001698 -0.07751729  0.         -0.4200771 ]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 473 is [True, False, False, False, True, False]
State prediction error at timestep 473 is 0.012
Current timestep = 474. State = [[-0.35164714 -0.03510323]]. Action = [[-0.02025385 -0.00455423  0.          0.59956586]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 474 is [True, False, False, False, True, False]
State prediction error at timestep 474 is 0.012
Current timestep = 475. State = [[-0.35388842 -0.03994995]]. Action = [[-0.03874698 -0.0768189   0.          0.22140479]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 475 is [True, False, False, False, True, False]
State prediction error at timestep 475 is 0.012
Current timestep = 476. State = [[-0.3557677  -0.03897161]]. Action = [[-0.01856872  0.08578249  0.          0.17878878]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 476 is [True, False, False, False, True, False]
State prediction error at timestep 476 is 0.012
Current timestep = 477. State = [[-0.35947764 -0.03525948]]. Action = [[-0.05779477  0.03662264  0.          0.28349924]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 477 is [True, False, False, False, True, False]
State prediction error at timestep 477 is 0.012
Current timestep = 478. State = [[-0.36059168 -0.03911236]]. Action = [[ 0.02176622 -0.09590584  0.         -0.93396616]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 478 is [True, False, False, False, True, False]
State prediction error at timestep 478 is 0.012
Current timestep = 479. State = [[-0.3571765  -0.04035413]]. Action = [[ 0.07070523  0.03852307  0.         -0.90368253]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 479 is [True, False, False, False, True, False]
State prediction error at timestep 479 is 0.012
Current timestep = 480. State = [[-0.3539942  -0.03840404]]. Action = [[ 0.03695448  0.01963146  0.         -0.05145156]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 480 is [True, False, False, False, True, False]
State prediction error at timestep 480 is 0.012
Current timestep = 481. State = [[-0.35481778 -0.0380028 ]]. Action = [[-0.02984937 -0.00442631  0.         -0.39157444]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 481 is [True, False, False, False, True, False]
State prediction error at timestep 481 is 0.012
Current timestep = 482. State = [[-0.35992298 -0.04180792]]. Action = [[-0.08403208 -0.06928013  0.         -0.65935105]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 482 is [True, False, False, False, True, False]
State prediction error at timestep 482 is 0.012
Current timestep = 483. State = [[-0.3583227  -0.04082463]]. Action = [[ 0.0970461   0.07717503  0.         -0.646887  ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 483 is [True, False, False, False, True, False]
State prediction error at timestep 483 is 0.012
Current timestep = 484. State = [[-0.35792738 -0.03501464]]. Action = [[-0.03947439  0.06930763  0.         -0.07366562]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 484 is [True, False, False, False, True, False]
State prediction error at timestep 484 is 0.012
Current timestep = 485. State = [[-0.3634047  -0.02942301]]. Action = [[-0.08212     0.06020498  0.         -0.70521474]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 485 is [True, False, False, False, True, False]
State prediction error at timestep 485 is 0.012
Current timestep = 486. State = [[-0.36764738 -0.02792026]]. Action = [[-0.02526207 -0.02032774  0.         -0.6612668 ]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 486 is [True, False, False, False, True, False]
State prediction error at timestep 486 is 0.012
Current timestep = 487. State = [[-0.36533844 -0.02460698]]. Action = [[0.08378346 0.05852631 0.         0.6093693 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 487 is [True, False, False, False, True, False]
State prediction error at timestep 487 is 0.012
Current timestep = 488. State = [[-0.36352214 -0.01770848]]. Action = [[ 0.01520833  0.07900851  0.         -0.1810801 ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 488 is [True, False, False, False, True, False]
State prediction error at timestep 488 is 0.012
Current timestep = 489. State = [[-0.3603081  -0.01620639]]. Action = [[ 0.07807096 -0.04503169  0.         -0.40708613]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 489 is [True, False, False, False, True, False]
State prediction error at timestep 489 is 0.012
Current timestep = 490. State = [[-0.35593188 -0.01393763]]. Action = [[ 0.0590279   0.0456939   0.         -0.23237932]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 490 is [True, False, False, False, True, False]
State prediction error at timestep 490 is 0.012
Current timestep = 491. State = [[-0.35123056 -0.01221474]]. Action = [[ 0.06803065 -0.01247806  0.         -0.24252224]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 491 is [True, False, False, False, True, False]
State prediction error at timestep 491 is 0.012
Current timestep = 492. State = [[-0.3488468  -0.00911761]]. Action = [[ 0.0067096   0.04962393  0.         -0.35204238]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 492 is [True, False, False, False, True, False]
State prediction error at timestep 492 is 0.012
Current timestep = 493. State = [[-0.34804687 -0.00371094]]. Action = [[ 0.00767819  0.06155092  0.         -0.71714187]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 493 is [True, False, False, False, True, False]
State prediction error at timestep 493 is 0.012
Current timestep = 494. State = [[-0.34777334 -0.00467709]]. Action = [[-0.007531   -0.07783411  0.         -0.20175159]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 494 is [True, False, False, False, True, False]
State prediction error at timestep 494 is 0.012
Current timestep = 495. State = [[-0.34593    -0.00511225]]. Action = [[0.0216864  0.01927565 0.         0.06876302]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 495 is [True, False, False, False, True, False]
State prediction error at timestep 495 is 0.012
Current timestep = 496. State = [[-0.3411484  -0.00762919]]. Action = [[ 0.06128144 -0.07179403  0.         -0.14420271]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 496 is [True, False, False, False, True, False]
State prediction error at timestep 496 is 0.012
Current timestep = 497. State = [[-0.3335483  -0.01037903]]. Action = [[ 0.08788811 -0.01873811  0.         -0.15000159]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 497 is [True, False, False, False, True, False]
State prediction error at timestep 497 is 0.012
Current timestep = 498. State = [[-0.32442904 -0.01510521]]. Action = [[ 0.09660014 -0.07947445  0.         -0.6509905 ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 498 is [True, False, False, False, True, False]
State prediction error at timestep 498 is 0.012
Current timestep = 499. State = [[-0.3185898 -0.0138087]]. Action = [[ 0.01835684  0.08355958  0.         -0.0060041 ]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 499 is [True, False, False, False, True, False]
State prediction error at timestep 499 is 0.012
Current timestep = 500. State = [[-0.3155643 -0.0127812]]. Action = [[ 0.00889243 -0.01560266  0.         -0.44918495]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 500 is [True, False, False, False, True, False]
State prediction error at timestep 500 is 0.012
Current timestep = 501. State = [[-0.3117886  -0.01219181]]. Action = [[0.03274115 0.02789339 0.         0.17022693]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 501 is [True, False, False, False, True, False]
State prediction error at timestep 501 is 0.012
Current timestep = 502. State = [[-0.30433345 -0.01471975]]. Action = [[ 0.09677943 -0.05883095  0.          0.52146196]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 502 is [True, False, False, False, True, False]
State prediction error at timestep 502 is 0.012
Current timestep = 503. State = [[-0.29726344 -0.01346912]]. Action = [[ 0.05006734  0.0680356   0.         -0.11701512]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 503 is [True, False, False, False, True, False]
State prediction error at timestep 503 is 0.012
Current timestep = 504. State = [[-0.2968267  -0.00867416]]. Action = [[-0.05686605  0.06343009  0.          0.72881794]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 504 is [True, False, False, False, True, False]
State prediction error at timestep 504 is 0.012
Current timestep = 505. State = [[-0.29935804 -0.00833182]]. Action = [[-0.0522093  -0.03428001  0.          0.7778163 ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 505 is [True, False, False, False, True, False]
State prediction error at timestep 505 is 0.012
Current timestep = 506. State = [[-0.30065563 -0.01004042]]. Action = [[-0.02516241 -0.02094136  0.          0.774933  ]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 506 is [True, False, False, False, True, False]
State prediction error at timestep 506 is 0.012
Current timestep = 507. State = [[-0.3012351  -0.00662718]]. Action = [[-0.01832598  0.07522105  0.          0.9059336 ]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 507 is [True, False, False, False, True, False]
State prediction error at timestep 507 is 0.012
Current timestep = 508. State = [[-0.3022851  -0.00657017]]. Action = [[-0.02457923 -0.05363314  0.         -0.37792307]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 508 is [True, False, False, False, True, False]
State prediction error at timestep 508 is 0.012
Current timestep = 509. State = [[-0.298169   -0.00527446]]. Action = [[ 0.09021027  0.04537129  0.         -0.7929649 ]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 509 is [True, False, False, False, True, False]
State prediction error at timestep 509 is 0.012
Current timestep = 510. State = [[-0.29081568 -0.00804586]]. Action = [[ 0.09514385 -0.08907235  0.          0.21174324]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 510 is [True, False, False, False, True, False]
State prediction error at timestep 510 is 0.012
Current timestep = 511. State = [[-0.28375793 -0.01167461]]. Action = [[ 0.07141203 -0.02215929  0.         -0.3633207 ]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 511 is [True, False, False, False, True, False]
State prediction error at timestep 511 is 0.012
Current timestep = 512. State = [[-0.2768659  -0.01540359]]. Action = [[ 0.07312217 -0.05264485  0.          0.7472129 ]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 512 is [True, False, False, False, True, False]
State prediction error at timestep 512 is 0.012
Current timestep = 513. State = [[-0.27174598 -0.02098797]]. Action = [[ 0.02823288 -0.06740317  0.          0.34089684]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 513 is [True, False, False, False, True, False]
State prediction error at timestep 513 is 0.012
Current timestep = 514. State = [[-0.27271053 -0.02329177]]. Action = [[-0.07947282  0.01395305  0.         -0.17455852]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 514 is [True, False, False, False, True, False]
State prediction error at timestep 514 is 0.012
Current timestep = 515. State = [[-0.27561834 -0.02207148]]. Action = [[-0.05044181  0.03792246  0.         -0.8972438 ]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 515 is [True, False, False, False, True, False]
State prediction error at timestep 515 is 0.012
Current timestep = 516. State = [[-0.2777929  -0.02096176]]. Action = [[-0.03518949  0.01352175  0.         -0.97962   ]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 516 is [True, False, False, False, True, False]
State prediction error at timestep 516 is 0.012
Current timestep = 517. State = [[-0.27607745 -0.0182357 ]]. Action = [[ 0.04667943  0.05283295  0.         -0.28167975]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 517 is [True, False, False, False, True, False]
State prediction error at timestep 517 is 0.012
Current timestep = 518. State = [[-0.27860162 -0.02015806]]. Action = [[-0.08400543 -0.0681702   0.          0.69756424]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 518 is [True, False, False, False, True, False]
State prediction error at timestep 518 is 0.012
Current timestep = 519. State = [[-0.2847086  -0.01990137]]. Action = [[-0.08410473  0.0457414   0.         -0.5958358 ]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 519 is [True, False, False, False, True, False]
State prediction error at timestep 519 is 0.012
Current timestep = 520. State = [[-0.28436303 -0.01420439]]. Action = [[0.07279556 0.08518731 0.         0.5744257 ]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 520 is [True, False, False, False, True, False]
State prediction error at timestep 520 is 0.012
Current timestep = 521. State = [[-0.279889  -0.0130615]]. Action = [[ 0.06899785 -0.03888924  0.         -0.8461533 ]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 521 is [True, False, False, False, True, False]
State prediction error at timestep 521 is 0.012
Current timestep = 522. State = [[-0.27453417 -0.01222679]]. Action = [[0.07923584 0.02884784 0.         0.8008146 ]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 522 is [True, False, False, False, True, False]
State prediction error at timestep 522 is 0.012
Current timestep = 523. State = [[-0.2767679  -0.01078712]]. Action = [[-0.09534995  0.00646478  0.         -0.17469162]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 523 is [True, False, False, False, True, False]
State prediction error at timestep 523 is 0.012
Current timestep = 524. State = [[-0.27805558 -0.01344612]]. Action = [[ 0.03655665 -0.06649028  0.         -0.7645536 ]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 524 is [True, False, False, False, True, False]
State prediction error at timestep 524 is 0.012
Current timestep = 525. State = [[-0.27278507 -0.01849844]]. Action = [[ 0.09522197 -0.06534435  0.          0.04693067]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 525 is [True, False, False, False, True, False]
State prediction error at timestep 525 is 0.012
Current timestep = 526. State = [[-0.2716514  -0.02247132]]. Action = [[-0.03905302 -0.03439987  0.         -0.47537816]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 526 is [True, False, False, False, True, False]
State prediction error at timestep 526 is 0.012
Current timestep = 527. State = [[-0.2750944  -0.02159462]]. Action = [[-0.05733531  0.04862375  0.          0.57581973]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 527 is [True, False, False, False, True, False]
State prediction error at timestep 527 is 0.012
Current timestep = 528. State = [[-0.2758942  -0.02198901]]. Action = [[ 0.01642083 -0.02727268  0.          0.18196094]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 528 is [True, False, False, False, True, False]
State prediction error at timestep 528 is 0.012
Current timestep = 529. State = [[-0.27123109 -0.01981958]]. Action = [[0.09173387 0.06541219 0.         0.7012117 ]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 529 is [True, False, False, False, True, False]
State prediction error at timestep 529 is 0.012
Current timestep = 530. State = [[-0.27252817 -0.01326063]]. Action = [[-0.07461113  0.09856474  0.         -0.6181594 ]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 530 is [True, False, False, False, True, False]
State prediction error at timestep 530 is 0.012
Current timestep = 531. State = [[-0.2791811  -0.01300683]]. Action = [[-0.08068784 -0.05981946  0.         -0.479398  ]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 531 is [True, False, False, False, True, False]
State prediction error at timestep 531 is 0.012
Current timestep = 532. State = [[-0.28011525 -0.01224999]]. Action = [[0.04585969 0.04062837 0.         0.1331358 ]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 532 is [True, False, False, False, True, False]
State prediction error at timestep 532 is 0.012
Current timestep = 533. State = [[-0.280181  -0.0129002]]. Action = [[-0.00960327 -0.04289803  0.          0.34462285]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 533 is [True, False, False, False, True, False]
State prediction error at timestep 533 is 0.012
Current timestep = 534. State = [[-0.28509364 -0.01570145]]. Action = [[-0.09030557 -0.03809397  0.         -0.5598222 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 534 is [True, False, False, False, True, False]
State prediction error at timestep 534 is 0.012
Current timestep = 535. State = [[-0.28632888 -0.02116225]]. Action = [[ 0.02972492 -0.08811817  0.          0.572804  ]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 535 is [True, False, False, False, True, False]
State prediction error at timestep 535 is 0.012
Current timestep = 536. State = [[-0.28161168 -0.02445582]]. Action = [[ 0.08292889 -0.00729389  0.          0.77230334]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 536 is [True, False, False, False, True, False]
State prediction error at timestep 536 is 0.012
Current timestep = 537. State = [[-0.2759639  -0.02219441]]. Action = [[ 0.07094084  0.06247955  0.         -0.9806415 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 537 is [True, False, False, False, True, False]
State prediction error at timestep 537 is 0.012
Current timestep = 538. State = [[-0.27226794 -0.0257423 ]]. Action = [[ 0.03295118 -0.09910754  0.         -0.5560324 ]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 538 is [True, False, False, False, True, False]
State prediction error at timestep 538 is 0.012
Current timestep = 539. State = [[-0.27106643 -0.03291993]]. Action = [[-0.00840111 -0.07207593  0.         -0.2840904 ]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 539 is [True, False, False, False, True, False]
State prediction error at timestep 539 is 0.012
Current timestep = 540. State = [[-0.2671132  -0.03253854]]. Action = [[ 0.07145392  0.07542294  0.         -0.42179275]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 540 is [True, False, False, False, True, False]
State prediction error at timestep 540 is 0.012
Current timestep = 541. State = [[-0.2677481  -0.02890852]]. Action = [[-0.06320062  0.05031686  0.         -0.83937025]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 541 is [True, False, False, False, True, False]
State prediction error at timestep 541 is 0.012
Current timestep = 542. State = [[-0.268281   -0.03220133]]. Action = [[ 0.01695845 -0.0847486   0.          0.9404931 ]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 542 is [True, False, False, False, True, False]
State prediction error at timestep 542 is 0.012
Current timestep = 543. State = [[-0.26386905 -0.03617106]]. Action = [[ 0.07367922 -0.01790107  0.         -0.4721111 ]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 543 is [True, False, False, False, True, False]
State prediction error at timestep 543 is 0.012
Current timestep = 544. State = [[-0.26308757 -0.03378585]]. Action = [[-0.03570401  0.07485887  0.          0.67991495]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 544 is [True, False, False, False, True, False]
State prediction error at timestep 544 is 0.012
Current timestep = 545. State = [[-0.26428685 -0.03576398]]. Action = [[-0.01100727 -0.07426924  0.          0.47194982]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 545 is [True, False, False, False, True, False]
State prediction error at timestep 545 is 0.012
Current timestep = 546. State = [[-0.2663965  -0.03477238]]. Action = [[-0.04275542  0.06937578  0.         -0.33416986]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 546 is [True, False, False, False, True, False]
State prediction error at timestep 546 is 0.012
Current timestep = 547. State = [[-0.26972646 -0.0376833 ]]. Action = [[-0.04833544 -0.09379338  0.          0.6217084 ]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 547 is [True, False, False, False, True, False]
State prediction error at timestep 547 is 0.012
Current timestep = 548. State = [[-0.26706025 -0.03699269]]. Action = [[0.08352182 0.07422017 0.         0.40902376]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 548 is [True, False, False, False, True, False]
State prediction error at timestep 548 is 0.012
Current timestep = 549. State = [[-0.26641232 -0.03173151]]. Action = [[-0.02799673  0.06321978  0.         -0.9365571 ]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 549 is [True, False, False, False, True, False]
State prediction error at timestep 549 is 0.012
Current timestep = 550. State = [[-0.27009398 -0.02860031]]. Action = [[-0.05512981  0.01656814  0.         -0.13116324]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 550 is [True, False, False, False, True, False]
State prediction error at timestep 550 is 0.012
Current timestep = 551. State = [[-0.27364    -0.02457525]]. Action = [[-0.03146157  0.05766477  0.         -0.41768026]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 551 is [True, False, False, False, True, False]
State prediction error at timestep 551 is 0.012
Current timestep = 552. State = [[-0.2768945  -0.02016857]]. Action = [[-0.03157199  0.03697485  0.         -0.23048872]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 552 is [True, False, False, False, True, False]
State prediction error at timestep 552 is 0.012
Current timestep = 553. State = [[-0.27839223 -0.02001485]]. Action = [[ 0.00421421 -0.04098063  0.         -0.13289559]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 553 is [True, False, False, False, True, False]
State prediction error at timestep 553 is 0.012
Current timestep = 554. State = [[-0.27572387 -0.0154603 ]]. Action = [[ 0.0723364   0.09494751  0.         -0.6156328 ]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 554 is [True, False, False, False, True, False]
State prediction error at timestep 554 is 0.012
Current timestep = 555. State = [[-0.27531043 -0.01097677]]. Action = [[-0.00902926  0.01379089  0.          0.25241554]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 555 is [True, False, False, False, True, False]
State prediction error at timestep 555 is 0.012
Current timestep = 556. State = [[-0.27923396 -0.01376125]]. Action = [[-0.06451979 -0.08811558  0.         -0.21468842]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 556 is [True, False, False, False, True, False]
State prediction error at timestep 556 is 0.012
Current timestep = 557. State = [[-0.27983892 -0.01252169]]. Action = [[ 0.03168794  0.06054413  0.         -0.7844381 ]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 557 is [True, False, False, False, True, False]
State prediction error at timestep 557 is 0.012
Current timestep = 558. State = [[-0.27675503 -0.01283146]]. Action = [[ 0.05601392 -0.05366596  0.         -0.17573798]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 558 is [True, False, False, False, True, False]
State prediction error at timestep 558 is 0.012
Current timestep = 559. State = [[-0.27256146 -0.01841672]]. Action = [[ 0.05176198 -0.09039542  0.         -0.8369373 ]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 559 is [True, False, False, False, True, False]
State prediction error at timestep 559 is 0.012
Current timestep = 560. State = [[-0.272357   -0.01893458]]. Action = [[-0.03837786  0.04526607  0.          0.9375632 ]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 560 is [True, False, False, False, True, False]
State prediction error at timestep 560 is 0.012
Current timestep = 561. State = [[-0.27361596 -0.01735302]]. Action = [[-0.01419838  0.01155837  0.         -0.05836856]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 561 is [True, False, False, False, True, False]
State prediction error at timestep 561 is 0.012
Current timestep = 562. State = [[-0.27496618 -0.01729573]]. Action = [[-0.02549524 -0.00402541  0.         -0.59274405]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 562 is [True, False, False, False, True, False]
State prediction error at timestep 562 is 0.012
Current timestep = 563. State = [[-0.271025   -0.01745674]]. Action = [[ 0.09274534  0.00180402  0.         -0.06339782]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 563 is [True, False, False, False, True, False]
State prediction error at timestep 563 is 0.012
Current timestep = 564. State = [[-0.26469773 -0.0144986 ]]. Action = [[0.07493392 0.06214013 0.         0.3664478 ]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 564 is [True, False, False, False, True, False]
State prediction error at timestep 564 is 0.012
Current timestep = 565. State = [[-0.26128608 -0.00963916]]. Action = [[ 0.02352931  0.06240831  0.         -0.92032325]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 565 is [True, False, False, False, True, False]
State prediction error at timestep 565 is 0.012
Current timestep = 566. State = [[-0.2604174  -0.00797035]]. Action = [[-0.00052937 -0.00813042  0.         -0.08056515]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 566 is [True, False, False, False, True, False]
State prediction error at timestep 566 is 0.012
Current timestep = 567. State = [[-0.25766915 -0.00637053]]. Action = [[0.04875293 0.02897847 0.         0.5677208 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 567 is [True, False, False, False, True, False]
State prediction error at timestep 567 is 0.012
Current timestep = 568. State = [[-0.2568008  -0.00354476]]. Action = [[-0.01737469  0.03130656  0.         -0.34987712]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 568 is [True, False, False, False, True, False]
State prediction error at timestep 568 is 0.012
Current timestep = 569. State = [[-0.25288486  0.00210826]]. Action = [[0.08407217 0.08135977 0.         0.7516494 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 569 is [True, False, False, False, True, False]
State prediction error at timestep 569 is 0.012
Current timestep = 570. State = [[-0.2496395   0.00391504]]. Action = [[ 0.01385465 -0.02873067  0.         -0.23393238]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 570 is [True, False, False, False, True, False]
State prediction error at timestep 570 is 0.012
Current timestep = 571. State = [[-0.24736258  0.00353103]]. Action = [[ 0.02122394 -0.01085789  0.          0.7352762 ]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 571 is [True, False, False, False, True, False]
State prediction error at timestep 571 is 0.012
Current timestep = 572. State = [[-0.24394232  0.00872532]]. Action = [[0.0414579  0.09466485 0.         0.7069384 ]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 572 is [True, False, False, False, True, False]
State prediction error at timestep 572 is 0.012
Current timestep = 573. State = [[-0.24584277  0.01168407]]. Action = [[-0.07910393 -0.01579689  0.          0.6663703 ]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 573 is [True, False, False, False, True, False]
State prediction error at timestep 573 is 0.012
Current timestep = 574. State = [[-0.24677375  0.00948821]]. Action = [[ 0.00518954 -0.06085864  0.          0.27689946]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 574 is [True, False, False, False, True, False]
State prediction error at timestep 574 is 0.012
Current timestep = 575. State = [[-0.24625765  0.00982579]]. Action = [[-0.01019163  0.02436092  0.          0.74184394]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 575 is [True, False, False, False, True, False]
State prediction error at timestep 575 is 0.012
Current timestep = 576. State = [[-0.24884538  0.01496054]]. Action = [[-0.06154616  0.0736055   0.         -0.4359668 ]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 576 is [True, False, False, False, True, False]
State prediction error at timestep 576 is 0.012
Current timestep = 577. State = [[-0.25310922  0.01597123]]. Action = [[-0.06189437 -0.04429758  0.          0.48023248]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 577 is [True, False, False, False, True, False]
State prediction error at timestep 577 is 0.012
Current timestep = 578. State = [[-0.25508207  0.01772076]]. Action = [[-0.01082579  0.03918456  0.         -0.76718426]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 578 is [True, False, False, False, True, False]
State prediction error at timestep 578 is 0.012
Current timestep = 579. State = [[-0.2537238   0.02315344]]. Action = [[ 0.04097646  0.06950911  0.         -0.5215869 ]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 579 is [True, False, False, False, True, False]
State prediction error at timestep 579 is 0.012
Current timestep = 580. State = [[-0.25583217  0.0212787 ]]. Action = [[-0.06010491 -0.09955843  0.         -0.52445275]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 580 is [True, False, False, False, True, False]
State prediction error at timestep 580 is 0.012
Current timestep = 581. State = [[-0.25535375  0.02176954]]. Action = [[ 0.04876661  0.05430878  0.         -0.16657639]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 581 is [True, False, False, False, True, False]
State prediction error at timestep 581 is 0.012
Current timestep = 582. State = [[-0.2532035   0.02051496]]. Action = [[ 0.0254392  -0.06244842  0.          0.7543514 ]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 582 is [True, False, False, False, True, False]
State prediction error at timestep 582 is 0.012
Current timestep = 583. State = [[-0.2563798   0.02357755]]. Action = [[-0.07820434  0.0916147   0.         -0.16540015]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 583 is [True, False, False, False, True, False]
State prediction error at timestep 583 is 0.012
Current timestep = 584. State = [[-0.25695145  0.02873274]]. Action = [[0.04580378 0.04355856 0.         0.53009677]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 584 is [True, False, False, False, True, False]
State prediction error at timestep 584 is 0.012
Current timestep = 585. State = [[-0.2563031   0.02776927]]. Action = [[ 0.00155725 -0.05694128  0.         -0.6675591 ]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 585 is [True, False, False, False, True, False]
State prediction error at timestep 585 is 0.012
Current timestep = 586. State = [[-0.25615904  0.02635727]]. Action = [[ 0.00535686 -0.0031271   0.         -0.9825558 ]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 586 is [True, False, False, False, True, False]
State prediction error at timestep 586 is 0.012
Current timestep = 587. State = [[-0.2588669   0.02545676]]. Action = [[-0.05737407 -0.01963631  0.          0.19064772]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 587 is [True, False, False, False, True, False]
State prediction error at timestep 587 is 0.012
Current timestep = 588. State = [[-0.25999707  0.02131033]]. Action = [[ 0.00677641 -0.0752698   0.         -0.74670553]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 588 is [True, False, False, False, True, False]
State prediction error at timestep 588 is 0.012
Current timestep = 589. State = [[-0.2575609   0.02012744]]. Action = [[0.04468635 0.0248066  0.         0.48469043]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 589 is [True, False, False, False, True, False]
State prediction error at timestep 589 is 0.012
Current timestep = 590. State = [[-0.26077437  0.02523034]]. Action = [[-0.09052147  0.09564602  0.          0.5644152 ]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 590 is [True, False, False, False, True, False]
State prediction error at timestep 590 is 0.012
Current timestep = 591. State = [[-0.26703435  0.02892298]]. Action = [[-0.06523684  0.01513074  0.          0.4672519 ]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 591 is [True, False, False, False, True, False]
State prediction error at timestep 591 is 0.012
Current timestep = 592. State = [[-0.27085572  0.02838492]]. Action = [[-0.02196235 -0.03009898  0.         -0.02628273]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 592 is [True, False, False, False, True, False]
State prediction error at timestep 592 is 0.012
Current timestep = 593. State = [[-0.27327678  0.02652793]]. Action = [[-0.01901784 -0.02627609  0.          0.9892664 ]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 593 is [True, False, False, False, True, False]
State prediction error at timestep 593 is 0.012
Current timestep = 594. State = [[-0.27765986  0.02205031]]. Action = [[-0.06477769 -0.07747892  0.          0.07841158]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 594 is [True, False, False, False, True, False]
State prediction error at timestep 594 is 0.012
Current timestep = 595. State = [[-0.27889654  0.02221403]]. Action = [[ 0.02720527  0.05066619  0.         -0.49601126]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 595 is [True, False, False, False, True, False]
State prediction error at timestep 595 is 0.012
Current timestep = 596. State = [[-0.28080517  0.02793507]]. Action = [[-0.0278063   0.08954474  0.          0.9023584 ]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 596 is [True, False, False, False, True, False]
State prediction error at timestep 596 is 0.012
Current timestep = 597. State = [[-0.28768024  0.0328663 ]]. Action = [[-0.09457643  0.04094883  0.         -0.36075795]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 597 is [True, False, False, False, True, False]
State prediction error at timestep 597 is 0.012
Current timestep = 598. State = [[-0.2923779   0.03463099]]. Action = [[-0.00857156 -0.00180315  0.         -0.37717366]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 598 is [True, False, False, False, True, False]
State prediction error at timestep 598 is 0.012
Current timestep = 599. State = [[-0.29548323  0.03669645]]. Action = [[-0.02096254  0.03001337  0.         -0.4948995 ]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 599 is [True, False, False, False, True, False]
State prediction error at timestep 599 is 0.012
Current timestep = 600. State = [[-0.2994953   0.04153017]]. Action = [[-0.03135657  0.06714403  0.          0.8964596 ]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 600 is [True, False, False, False, True, False]
State prediction error at timestep 600 is 0.012
Current timestep = 601. State = [[-0.30363512  0.04334921]]. Action = [[-0.02650841 -0.01908581  0.         -0.8332626 ]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 601 is [True, False, False, False, True, False]
State prediction error at timestep 601 is 0.012
Current timestep = 602. State = [[-0.310675    0.03985796]]. Action = [[-0.09784143 -0.07845176  0.         -0.53988665]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 602 is [True, False, False, False, True, False]
State prediction error at timestep 602 is 0.012
Current timestep = 603. State = [[-0.31191745  0.03708103]]. Action = [[ 0.06057393 -0.02128365  0.          0.02834129]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 603 is [True, False, False, False, True, False]
State prediction error at timestep 603 is 0.012
Current timestep = 604. State = [[-0.30685377  0.03752916]]. Action = [[0.09332841 0.02251764 0.         0.6058736 ]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 604 is [True, False, False, False, True, False]
State prediction error at timestep 604 is 0.012
Current timestep = 605. State = [[-0.3069631   0.04168737]]. Action = [[-0.04041376  0.07312278  0.          0.3625015 ]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 605 is [True, False, False, False, True, False]
State prediction error at timestep 605 is 0.012
Current timestep = 606. State = [[-0.3092593  0.0434051]]. Action = [[-0.00737274 -0.01076124  0.          0.25468063]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 606 is [True, False, False, False, True, False]
State prediction error at timestep 606 is 0.012
Current timestep = 607. State = [[-0.30830842  0.04489248]]. Action = [[0.04117803 0.03161114 0.         0.14701807]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 607 is [True, False, False, False, True, False]
State prediction error at timestep 607 is 0.012
Current timestep = 608. State = [[-0.31256992  0.05093611]]. Action = [[-0.09439955  0.09989469  0.          0.16068304]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 608 is [True, False, False, False, True, False]
State prediction error at timestep 608 is 0.012
Current timestep = 609. State = [[-0.31322205  0.05249938]]. Action = [[ 0.06396099 -0.03718161  0.          0.05816877]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 609 is [True, False, False, False, True, False]
State prediction error at timestep 609 is 0.012
Current timestep = 610. State = [[-0.31602365  0.05671987]]. Action = [[-0.07346742  0.0928702   0.         -0.72642225]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 610 is [True, False, False, False, True, False]
State prediction error at timestep 610 is 0.012
Current timestep = 611. State = [[-0.31880125  0.0560474 ]]. Action = [[ 8.422509e-04 -8.657336e-02  0.000000e+00  8.458307e-01]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 611 is [True, False, False, False, True, False]
State prediction error at timestep 611 is 0.012
Current timestep = 612. State = [[-0.32035443  0.05879143]]. Action = [[-0.01633822  0.0903812   0.         -0.06595856]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 612 is [True, False, False, False, True, False]
State prediction error at timestep 612 is 0.012
Current timestep = 613. State = [[-0.32594004  0.06590664]]. Action = [[-0.08356193  0.07509466  0.         -0.32690245]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 613 is [True, False, False, False, True, False]
State prediction error at timestep 613 is 0.012
Current timestep = 614. State = [[-0.32855278  0.06892443]]. Action = [[ 0.01903339 -0.00937527  0.          0.22672677]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 614 is [True, False, False, False, True, False]
State prediction error at timestep 614 is 0.012
Current timestep = 615. State = [[-0.32675317  0.06700051]]. Action = [[ 0.04779836 -0.0562859   0.          0.3957746 ]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 615 is [True, False, False, False, True, False]
State prediction error at timestep 615 is 0.012
Current timestep = 616. State = [[-0.32326186  0.0627378 ]]. Action = [[ 0.05110728 -0.06561787  0.          0.7569829 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 616 is [True, False, False, False, True, False]
State prediction error at timestep 616 is 0.012
Current timestep = 617. State = [[-0.31771925  0.06577571]]. Action = [[ 0.0856423   0.09938668  0.         -0.47485673]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 617 is [True, False, False, False, True, False]
State prediction error at timestep 617 is 0.012
Current timestep = 618. State = [[-0.31088468  0.07001226]]. Action = [[ 0.09350535  0.03010996  0.         -0.97987205]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 618 is [True, False, False, False, True, False]
State prediction error at timestep 618 is 0.012
Current timestep = 619. State = [[-0.30608544  0.07288335]]. Action = [[0.03684215 0.03804659 0.         0.23448598]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 619 is [True, False, False, False, True, False]
State prediction error at timestep 619 is 0.012
Current timestep = 620. State = [[-0.29945707  0.07547291]]. Action = [[0.09896632 0.02823228 0.         0.98905706]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 620 is [True, False, False, False, True, False]
State prediction error at timestep 620 is 0.012
Current timestep = 621. State = [[-0.2919476   0.07665011]]. Action = [[ 0.07467472  0.00581938  0.         -0.9938354 ]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 621 is [True, False, False, False, True, False]
State prediction error at timestep 621 is 0.012
Current timestep = 622. State = [[-0.28833032  0.08182313]]. Action = [[0.00098898 0.0966697  0.         0.7894455 ]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 622 is [True, False, False, False, True, False]
State prediction error at timestep 622 is 0.012
Current timestep = 623. State = [[-0.28838745  0.08233249]]. Action = [[-0.03582539 -0.05948996  0.          0.44535136]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 623 is [True, False, False, False, True, False]
State prediction error at timestep 623 is 0.012
Current timestep = 624. State = [[-0.28790188  0.08504312]]. Action = [[-0.00566722  0.06642725  0.          0.6773325 ]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 624 is [True, False, False, False, True, False]
State prediction error at timestep 624 is 0.012
Current timestep = 625. State = [[-0.2887475   0.08585394]]. Action = [[-0.04299963 -0.04385731  0.         -0.15665197]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 625 is [True, False, False, False, True, False]
State prediction error at timestep 625 is 0.012
Current timestep = 626. State = [[-0.28472573  0.0867622 ]]. Action = [[0.0787892  0.01992594 0.         0.95648146]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 626 is [True, False, False, False, True, False]
State prediction error at timestep 626 is 0.012
Current timestep = 627. State = [[-0.27680382  0.08984698]]. Action = [[ 0.08844181  0.03697538  0.         -0.3434568 ]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 627 is [True, False, False, False, True, False]
State prediction error at timestep 627 is 0.012
Current timestep = 628. State = [[-0.27504358  0.08794054]]. Action = [[-0.05698236 -0.07727917  0.         -0.55647093]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 628 is [True, False, False, False, True, False]
State prediction error at timestep 628 is 0.012
Current timestep = 629. State = [[-0.27263018  0.08825719]]. Action = [[ 0.05094697  0.03670716  0.         -0.05748993]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 629 is [True, False, False, False, True, False]
State prediction error at timestep 629 is 0.012
Current timestep = 630. State = [[-0.27281475  0.09410542]]. Action = [[-0.05336151  0.08737039  0.         -0.03152585]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 630 is [True, False, False, False, True, False]
State prediction error at timestep 630 is 0.012
Current timestep = 631. State = [[-0.2722451   0.09800951]]. Action = [[0.02723116 0.01036346 0.         0.4979713 ]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 631 is [True, False, False, False, True, False]
State prediction error at timestep 631 is 0.012
Current timestep = 632. State = [[-0.27039927  0.10413948]]. Action = [[0.01595028 0.09896594 0.         0.42594278]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 632 is [True, False, False, False, True, False]
State prediction error at timestep 632 is 0.012
Current timestep = 633. State = [[-0.27242014  0.10602239]]. Action = [[-0.05523187 -0.04066811  0.         -0.12818384]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 633 is [True, False, False, False, True, False]
State prediction error at timestep 633 is 0.012
Current timestep = 634. State = [[-0.2740472   0.10401014]]. Action = [[-0.0094514  -0.04509208  0.         -0.60036016]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 634 is [True, False, False, False, True, False]
State prediction error at timestep 634 is 0.012
Current timestep = 635. State = [[-0.27055833  0.09964339]]. Action = [[ 0.06842463 -0.07816436  0.         -0.2783476 ]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 635 is [True, False, False, False, True, False]
State prediction error at timestep 635 is 0.012
Current timestep = 636. State = [[-0.2659543   0.09334982]]. Action = [[ 0.038228   -0.08503304  0.         -0.7730674 ]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 636 is [True, False, False, False, True, False]
State prediction error at timestep 636 is 0.012
Current timestep = 637. State = [[-0.2604184   0.09521596]]. Action = [[0.07154364 0.0973851  0.         0.05149865]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 637 is [True, False, False, False, True, False]
State prediction error at timestep 637 is 0.012
Current timestep = 638. State = [[-0.2611228   0.09357389]]. Action = [[-0.08196685 -0.08470008  0.         -0.17770249]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 638 is [True, False, False, False, True, False]
State prediction error at timestep 638 is 0.012
Current timestep = 639. State = [[-0.2631539   0.09223228]]. Action = [[-0.00391995  0.02402687  0.          0.28788435]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 639 is [True, False, False, False, True, False]
State prediction error at timestep 639 is 0.012
Current timestep = 640. State = [[-0.2607571   0.08871968]]. Action = [[ 0.05254122 -0.07084224  0.         -0.51357603]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 640 is [True, False, False, False, True, False]
State prediction error at timestep 640 is 0.012
Current timestep = 641. State = [[-0.25704128  0.08833849]]. Action = [[ 0.04348443  0.05216476  0.         -0.21810913]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 641 is [True, False, False, False, True, False]
State prediction error at timestep 641 is 0.012
Current timestep = 642. State = [[-0.25891688  0.0925745 ]]. Action = [[-0.06299232  0.07454646  0.         -0.2744394 ]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 642 is [True, False, False, False, True, False]
State prediction error at timestep 642 is 0.012
Current timestep = 643. State = [[-0.26331645  0.09129056]]. Action = [[-0.05120852 -0.06481425  0.          0.7658851 ]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 643 is [True, False, False, False, True, False]
State prediction error at timestep 643 is 0.012
Current timestep = 644. State = [[-0.26281318  0.09143457]]. Action = [[ 0.04742465  0.04352032  0.         -0.6083065 ]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 644 is [True, False, False, False, True, False]
State prediction error at timestep 644 is 0.012
Current timestep = 645. State = [[-0.25706184  0.0871828 ]]. Action = [[ 0.09619214 -0.09881356  0.         -0.95769733]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 645 is [True, False, False, False, True, False]
State prediction error at timestep 645 is 0.012
Current timestep = 646. State = [[-0.25165233  0.08806584]]. Action = [[ 0.05239103  0.09305919  0.         -0.35257006]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 646 is [True, False, False, False, True, False]
State prediction error at timestep 646 is 0.012
Current timestep = 647. State = [[-0.24576727  0.09277216]]. Action = [[0.08820438 0.05861523 0.         0.40050292]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 647 is [True, False, False, False, True, False]
State prediction error at timestep 647 is 0.012
Current timestep = 648. State = [[-0.24462378  0.09060344]]. Action = [[-0.04115284 -0.07373197  0.          0.2803011 ]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 648 is [True, False, False, False, True, False]
State prediction error at timestep 648 is 0.012
Current timestep = 649. State = [[-0.24567334  0.08753445]]. Action = [[-0.01053555 -0.01893614  0.         -0.72565717]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 649 is [True, False, False, False, True, False]
State prediction error at timestep 649 is 0.012
Current timestep = 650. State = [[-0.24877532  0.08908948]]. Action = [[-0.06525794  0.04484237  0.         -0.3789481 ]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 650 is [True, False, False, False, True, False]
State prediction error at timestep 650 is 0.012
Current timestep = 651. State = [[-0.24700186  0.09349289]]. Action = [[0.07618288 0.06207082 0.         0.34899652]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 651 is [True, False, False, False, True, False]
State prediction error at timestep 651 is 0.012
Current timestep = 652. State = [[-0.24806     0.09898926]]. Action = [[-0.06342683  0.06878347  0.         -0.76596206]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 652 is [True, False, False, False, True, False]
State prediction error at timestep 652 is 0.012
Current timestep = 653. State = [[-0.24974811  0.10532019]]. Action = [[ 0.00789462  0.07249831  0.         -0.37702894]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 653 is [True, False, False, False, True, False]
State prediction error at timestep 653 is 0.012
Current timestep = 654. State = [[-0.24797936  0.11014633]]. Action = [[0.0474469  0.03703807 0.         0.26188624]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 654 is [True, False, False, False, True, False]
State prediction error at timestep 654 is 0.012
Current timestep = 655. State = [[-0.24551524  0.10783964]]. Action = [[ 0.02976342 -0.08831351  0.          0.3069737 ]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 655 is [True, False, False, False, True, False]
State prediction error at timestep 655 is 0.012
Current timestep = 656. State = [[-0.24646415  0.10934399]]. Action = [[-0.04010884  0.06209569  0.         -0.20109618]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 656 is [True, False, False, False, True, False]
State prediction error at timestep 656 is 0.012
Current timestep = 657. State = [[-0.24571058  0.10749947]]. Action = [[ 0.03435377 -0.0926173   0.          0.18249917]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 657 is [True, False, False, False, True, False]
State prediction error at timestep 657 is 0.012
Current timestep = 658. State = [[-0.24577224  0.105302  ]]. Action = [[-0.03179321 -0.00979427  0.         -0.7875047 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 658 is [True, False, False, False, True, False]
State prediction error at timestep 658 is 0.012
Current timestep = 659. State = [[-0.24379751  0.10250576]]. Action = [[ 0.043309   -0.06060323  0.          0.5375166 ]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 659 is [True, False, False, False, True, False]
State prediction error at timestep 659 is 0.012
Current timestep = 660. State = [[-0.23715699  0.09987368]]. Action = [[ 0.09491216 -0.01704042  0.          0.4644935 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 660 is [True, False, False, False, True, False]
State prediction error at timestep 660 is 0.012
Current timestep = 661. State = [[-0.23449515  0.09584054]]. Action = [[-0.02479723 -0.06182852  0.          0.82555366]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 661 is [True, False, False, False, True, False]
State prediction error at timestep 661 is 0.012
Current timestep = 662. State = [[-0.23295912  0.09263118]]. Action = [[ 0.0182485  -0.01829763  0.         -0.8011281 ]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 662 is [True, False, False, False, True, False]
State prediction error at timestep 662 is 0.012
Current timestep = 663. State = [[-0.23117256  0.093535  ]]. Action = [[0.00739714 0.04684976 0.         0.51387954]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 663 is [True, False, False, False, True, False]
State prediction error at timestep 663 is 0.012
Current timestep = 664. State = [[-0.22556308  0.09443528]]. Action = [[0.09729623 0.01106997 0.         0.60273874]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 664 is [True, False, False, False, True, False]
State prediction error at timestep 664 is 0.012
Current timestep = 665. State = [[-0.21994032  0.09505337]]. Action = [[ 0.04698556  0.02762476  0.         -0.0470311 ]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 665 is [True, False, False, False, True, False]
State prediction error at timestep 665 is 0.012
Current timestep = 666. State = [[-0.21340021  0.09369275]]. Action = [[ 0.08840128 -0.02307506  0.         -0.3390838 ]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 666 is [True, False, False, False, True, False]
State prediction error at timestep 666 is 0.012
Current timestep = 667. State = [[-0.20576343  0.09674209]]. Action = [[ 0.08647694  0.09624893  0.         -0.69255114]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 667 is [True, False, False, False, True, False]
State prediction error at timestep 667 is 0.012
Current timestep = 668. State = [[-0.19758     0.10164344]]. Action = [[0.09992255 0.06365254 0.         0.5988679 ]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 668 is [True, False, False, False, True, False]
State prediction error at timestep 668 is 0.012
Current timestep = 669. State = [[-0.19187391  0.10357599]]. Action = [[0.03592481 0.01204173 0.         0.7943357 ]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 669 is [True, False, False, False, True, False]
State prediction error at timestep 669 is 0.012
Current timestep = 670. State = [[-0.19102436  0.10749085]]. Action = [[-0.03469252  0.07026207  0.         -0.45133263]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 670 is [True, False, False, False, True, False]
State prediction error at timestep 670 is 0.012
Current timestep = 671. State = [[-0.18935266  0.11396481]]. Action = [[ 0.02804438  0.07726803  0.         -0.16600358]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 671 is [True, False, False, False, True, False]
State prediction error at timestep 671 is 0.012
Current timestep = 672. State = [[-0.19079152  0.11959668]]. Action = [[-0.0650923   0.04410706  0.         -0.2180605 ]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 672 is [True, False, False, False, True, False]
State prediction error at timestep 672 is 0.012
Current timestep = 673. State = [[-0.18730105  0.1269579 ]]. Action = [[ 0.09875765  0.09084234  0.         -0.3289113 ]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 673 is [True, False, False, False, False, True]
State prediction error at timestep 673 is 0.012
Current timestep = 674. State = [[-0.18777372  0.12961939]]. Action = [[-0.09775459 -0.04352016  0.          0.19812512]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 674 is [True, False, False, False, False, True]
State prediction error at timestep 674 is 0.012
Current timestep = 675. State = [[-0.18536043  0.12583005]]. Action = [[ 0.0869179  -0.09575927  0.         -0.87877107]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 675 is [True, False, False, False, False, True]
State prediction error at timestep 675 is 0.012
Current timestep = 676. State = [[-0.1820669   0.12144004]]. Action = [[-0.00630052 -0.06255816  0.          0.4445219 ]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 676 is [True, False, False, False, True, False]
State prediction error at timestep 676 is 0.012
Current timestep = 677. State = [[-0.18065102  0.11586442]]. Action = [[-0.00451447 -0.09705857  0.         -0.04356968]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 677 is [True, False, False, False, True, False]
State prediction error at timestep 677 is 0.012
Current timestep = 678. State = [[-0.18206076  0.1121502 ]]. Action = [[-0.0660281  -0.03237283  0.          0.23532486]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 678 is [True, False, False, False, True, False]
State prediction error at timestep 678 is 0.012
Current timestep = 679. State = [[-0.18237664  0.11583854]]. Action = [[0.00185739 0.08714854 0.         0.56651926]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 679 is [True, False, False, False, True, False]
State prediction error at timestep 679 is 0.012
Current timestep = 680. State = [[-0.18474357  0.11710406]]. Action = [[-0.06586607 -0.03134788  0.         -0.2472384 ]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 680 is [True, False, False, False, True, False]
State prediction error at timestep 680 is 0.012
Current timestep = 681. State = [[-0.18582354  0.1202091 ]]. Action = [[ 0.00512733  0.07015779  0.         -0.14791906]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 681 is [True, False, False, False, True, False]
State prediction error at timestep 681 is 0.012
Current timestep = 682. State = [[-0.1868821   0.12410303]]. Action = [[-0.02109624  0.0317814   0.          0.44601274]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 682 is [True, False, False, False, True, False]
State prediction error at timestep 682 is 0.012
Current timestep = 683. State = [[-0.18426561  0.1243417 ]]. Action = [[ 0.07271525 -0.0215927   0.          0.024351  ]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 683 is [True, False, False, False, True, False]
State prediction error at timestep 683 is 0.012
Current timestep = 684. State = [[-0.17947799  0.12176627]]. Action = [[ 0.06322425 -0.03688561  0.         -0.15575051]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 684 is [True, False, False, False, True, False]
State prediction error at timestep 684 is 0.012
Current timestep = 685. State = [[-0.18022409  0.11684036]]. Action = [[-0.06083758 -0.07334603  0.          0.07509732]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 685 is [True, False, False, False, True, False]
State prediction error at timestep 685 is 0.012
Current timestep = 686. State = [[-0.17939207  0.11171016]]. Action = [[ 0.04273786 -0.05345914  0.         -0.43095022]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 686 is [True, False, False, False, True, False]
State prediction error at timestep 686 is 0.012
Current timestep = 687. State = [[-0.17319247  0.11058367]]. Action = [[ 0.09982011  0.03008839  0.         -0.7360014 ]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 687 is [True, False, False, False, True, False]
State prediction error at timestep 687 is 0.012
Current timestep = 688. State = [[-0.17070994  0.1123668 ]]. Action = [[-0.00995146  0.04514747  0.         -0.42158002]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 688 is [True, False, False, False, True, False]
State prediction error at timestep 688 is 0.012
Current timestep = 689. State = [[-0.16944581  0.11743219]]. Action = [[ 0.02968646  0.09393749  0.         -0.4237852 ]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 689 is [True, False, False, False, True, False]
State prediction error at timestep 689 is 0.012
Current timestep = 690. State = [[-0.16880776  0.11626065]]. Action = [[-0.00245116 -0.06742518  0.         -0.7228733 ]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 690 is [True, False, False, False, True, False]
State prediction error at timestep 690 is 0.012
Current timestep = 691. State = [[-0.17307004  0.11859465]]. Action = [[-0.09258889  0.08759674  0.         -0.78427863]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 691 is [True, False, False, False, True, False]
State prediction error at timestep 691 is 0.012
Current timestep = 692. State = [[-0.17551248  0.11894725]]. Action = [[ 0.00231936 -0.04925582  0.         -0.5128294 ]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 692 is [True, False, False, False, True, False]
State prediction error at timestep 692 is 0.012
Current timestep = 693. State = [[-0.17463455  0.11958039]]. Action = [[ 0.02040564  0.03244578  0.         -0.6444013 ]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 693 is [True, False, False, False, True, False]
State prediction error at timestep 693 is 0.012
Current timestep = 694. State = [[-0.17366284  0.11664777]]. Action = [[ 0.00908263 -0.08148886  0.         -0.7098818 ]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 694 is [True, False, False, False, True, False]
State prediction error at timestep 694 is 0.012
Current timestep = 695. State = [[-0.16896117  0.11691931]]. Action = [[0.08978231 0.05359105 0.         0.5158378 ]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 695 is [True, False, False, False, True, False]
State prediction error at timestep 695 is 0.012
Current timestep = 696. State = [[-0.16651814  0.12065038]]. Action = [[-0.00170132  0.05154433  0.         -0.12882173]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 696 is [True, False, False, False, True, False]
State prediction error at timestep 696 is 0.012
Current timestep = 697. State = [[-0.16720891  0.123301  ]]. Action = [[-0.01753282  0.01963051  0.          0.9793967 ]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 697 is [True, False, False, False, True, False]
State prediction error at timestep 697 is 0.012
Current timestep = 698. State = [[-0.1704893   0.12516762]]. Action = [[-0.06120741  0.01466836  0.          0.10217381]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 698 is [True, False, False, False, False, True]
State prediction error at timestep 698 is 0.012
Current timestep = 699. State = [[-0.17584065  0.1260045 ]]. Action = [[-0.07940488 -0.0107099   0.          0.60022473]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 699 is [True, False, False, False, False, True]
State prediction error at timestep 699 is 0.012
Current timestep = 700. State = [[-0.18276407  0.12669794]]. Action = [[-0.09785821 -0.00499603  0.         -0.9246324 ]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 700 is [True, False, False, False, False, True]
State prediction error at timestep 700 is 0.012
Current timestep = 701. State = [[-0.19013923  0.12442166]]. Action = [[-0.09209645 -0.07136656  0.         -0.1754458 ]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 701 is [True, False, False, False, True, False]
State prediction error at timestep 701 is 0.012
Current timestep = 702. State = [[-0.18994011  0.12679183]]. Action = [[0.08345472 0.07465472 0.         0.30291736]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 702 is [True, False, False, False, False, True]
State prediction error at timestep 702 is 0.012
Current timestep = 703. State = [[-0.18627542  0.12852132]]. Action = [[ 0.03723919 -0.0176481   0.         -0.7877661 ]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 703 is [True, False, False, False, False, True]
State prediction error at timestep 703 is 0.012
Current timestep = 704. State = [[-0.18812808  0.12691249]]. Action = [[-0.06697093 -0.03649393  0.         -0.1631676 ]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 704 is [True, False, False, False, False, True]
State prediction error at timestep 704 is 0.012
Current timestep = 705. State = [[-0.18750632  0.12321918]]. Action = [[ 0.04376713 -0.0624591   0.          0.67180943]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 705 is [True, False, False, False, True, False]
State prediction error at timestep 705 is 0.012
Current timestep = 706. State = [[-0.1827209   0.11766754]]. Action = [[ 0.06720173 -0.06997086  0.          0.08968353]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 706 is [True, False, False, False, True, False]
State prediction error at timestep 706 is 0.012
Current timestep = 707. State = [[-0.18444021  0.11260657]]. Action = [[-0.09227987 -0.04977893  0.          0.1369803 ]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 707 is [True, False, False, False, True, False]
State prediction error at timestep 707 is 0.012
Current timestep = 708. State = [[-0.18917446  0.11231239]]. Action = [[-0.05337816  0.03426244  0.         -0.5549263 ]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 708 is [True, False, False, False, True, False]
State prediction error at timestep 708 is 0.012
Current timestep = 709. State = [[-0.19076282  0.1080058 ]]. Action = [[ 0.00307916 -0.09325156  0.          0.81189466]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 709 is [True, False, False, False, True, False]
State prediction error at timestep 709 is 0.012
Current timestep = 710. State = [[-0.19287705  0.1008712 ]]. Action = [[-0.04367981 -0.07376806  0.         -0.3440084 ]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 710 is [True, False, False, False, True, False]
State prediction error at timestep 710 is 0.012
Current timestep = 711. State = [[-0.19333905  0.09351538]]. Action = [[ 0.01462279 -0.08083436  0.         -0.04511029]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 711 is [True, False, False, False, True, False]
State prediction error at timestep 711 is 0.012
Current timestep = 712. State = [[-0.18959354  0.09305903]]. Action = [[0.07666405 0.07467923 0.         0.33489728]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 712 is [True, False, False, False, True, False]
State prediction error at timestep 712 is 0.012
Current timestep = 713. State = [[-0.19150408  0.0946189 ]]. Action = [[-0.07389606  0.02351657  0.         -0.47716224]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 713 is [True, False, False, False, True, False]
State prediction error at timestep 713 is 0.012
Current timestep = 714. State = [[-0.19346015  0.09000015]]. Action = [[ 0.01956774 -0.08320484  0.         -0.07414454]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 714 is [True, False, False, False, True, False]
State prediction error at timestep 714 is 0.012
Current timestep = 715. State = [[-0.1960367   0.08547157]]. Action = [[-0.04545664 -0.01749237  0.          0.02751064]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 715 is [True, False, False, False, True, False]
State prediction error at timestep 715 is 0.012
Current timestep = 716. State = [[-0.1996096   0.08707456]]. Action = [[-0.0273395   0.06836902  0.          0.3334744 ]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 716 is [True, False, False, False, True, False]
State prediction error at timestep 716 is 0.012
Current timestep = 717. State = [[-0.20366172  0.08483332]]. Action = [[-0.04084251 -0.06687041  0.          0.08878958]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 717 is [True, False, False, False, True, False]
State prediction error at timestep 717 is 0.012
Current timestep = 718. State = [[-0.20417082  0.08061759]]. Action = [[ 0.03423097 -0.03215975  0.          0.04506803]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 718 is [True, False, False, False, True, False]
State prediction error at timestep 718 is 0.012
Current timestep = 719. State = [[-0.20259045  0.08086836]]. Action = [[0.03599738 0.04701794 0.         0.84846234]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 719 is [True, False, False, False, True, False]
State prediction error at timestep 719 is 0.012
Current timestep = 720. State = [[-0.20056604  0.08275278]]. Action = [[ 0.04528933  0.03282707  0.         -0.18432838]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 720 is [True, False, False, False, True, False]
State prediction error at timestep 720 is 0.012
Current timestep = 721. State = [[-0.19572209  0.0794566 ]]. Action = [[ 0.09344276 -0.0664374   0.         -0.3738433 ]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 721 is [True, False, False, False, True, False]
State prediction error at timestep 721 is 0.012
Current timestep = 722. State = [[-0.1907697   0.07325035]]. Action = [[ 0.05374724 -0.06422956  0.         -0.09684998]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 722 is [True, False, False, False, True, False]
State prediction error at timestep 722 is 0.012
Current timestep = 723. State = [[-0.18419892  0.06834429]]. Action = [[ 0.09589332 -0.03247714  0.         -0.9610952 ]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 723 is [True, False, False, False, True, False]
State prediction error at timestep 723 is 0.012
Current timestep = 724. State = [[-0.17955664  0.06899529]]. Action = [[0.02752351 0.06490695 0.         0.9721887 ]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 724 is [True, False, False, False, True, False]
State prediction error at timestep 724 is 0.012
Current timestep = 725. State = [[-0.18063587  0.06792412]]. Action = [[-0.05867473 -0.03510105  0.          0.3132459 ]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 725 is [True, False, False, False, True, False]
State prediction error at timestep 725 is 0.012
Current timestep = 726. State = [[-0.17822985  0.06995192]]. Action = [[ 0.06737638  0.07668816  0.         -0.7576656 ]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 726 is [True, False, False, False, True, False]
State prediction error at timestep 726 is 0.012
Current timestep = 727. State = [[-0.17223133  0.07356574]]. Action = [[0.07252797 0.04423074 0.         0.20903766]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 727 is [True, False, False, False, True, False]
State prediction error at timestep 727 is 0.012
Current timestep = 728. State = [[-0.17149235  0.07138065]]. Action = [[-0.05104155 -0.06515346  0.         -0.22109938]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 728 is [True, False, False, False, True, False]
State prediction error at timestep 728 is 0.012
Current timestep = 729. State = [[-0.17627284  0.06932003]]. Action = [[-0.09767909 -0.00771218  0.          0.26353765]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 729 is [True, False, False, False, True, False]
State prediction error at timestep 729 is 0.012
Current timestep = 730. State = [[-0.18051389  0.07278809]]. Action = [[-0.04933175  0.066714    0.          0.07376039]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 730 is [True, False, False, False, True, False]
State prediction error at timestep 730 is 0.012
Current timestep = 731. State = [[-0.18458526  0.07909339]]. Action = [[-0.05474791  0.07256094  0.         -0.6693413 ]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 731 is [True, False, False, False, True, False]
State prediction error at timestep 731 is 0.012
Current timestep = 732. State = [[-0.18884547  0.08012745]]. Action = [[-0.050009   -0.04691753  0.         -0.23385882]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 732 is [True, False, False, False, True, False]
State prediction error at timestep 732 is 0.012
Current timestep = 733. State = [[-0.18630403  0.08056929]]. Action = [[0.09495976 0.01469727 0.         0.0703851 ]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 733 is [True, False, False, False, True, False]
State prediction error at timestep 733 is 0.012
Current timestep = 734. State = [[-0.17946073  0.08306633]]. Action = [[0.09816854 0.03344583 0.         0.63652277]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 734 is [True, False, False, False, True, False]
State prediction error at timestep 734 is 0.012
Current timestep = 735. State = [[-0.177161    0.08106329]]. Action = [[-0.01384691 -0.0677177   0.         -0.25449574]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 735 is [True, False, False, False, True, False]
State prediction error at timestep 735 is 0.012
Current timestep = 736. State = [[-0.18126188  0.07989144]]. Action = [[-0.08786596  0.00540759  0.          0.66461205]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 736 is [True, False, False, False, True, False]
State prediction error at timestep 736 is 0.012
Current timestep = 737. State = [[-0.18126203  0.08000285]]. Action = [[ 0.04611503 -0.00867917  0.         -0.8090815 ]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 737 is [True, False, False, False, True, False]
State prediction error at timestep 737 is 0.012
Current timestep = 738. State = [[-0.18123813  0.0756508 ]]. Action = [[-0.03278945 -0.08802291  0.         -0.8233887 ]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 738 is [True, False, False, False, True, False]
State prediction error at timestep 738 is 0.012
Current timestep = 739. State = [[-0.17956439  0.07518743]]. Action = [[ 0.04054555  0.04270545  0.         -0.4175024 ]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 739 is [True, False, False, False, True, False]
State prediction error at timestep 739 is 0.012
Current timestep = 740. State = [[-0.17351003  0.07809369]]. Action = [[0.0997655  0.04433044 0.         0.7284478 ]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 740 is [True, False, False, False, True, False]
State prediction error at timestep 740 is 0.012
Current timestep = 741. State = [[-0.17198315  0.07572842]]. Action = [[-0.0362744  -0.0667589   0.         -0.42877495]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 741 is [True, False, False, False, True, False]
State prediction error at timestep 741 is 0.012
Current timestep = 742. State = [[-0.17179924  0.07672048]]. Action = [[ 0.01788559  0.06527161  0.         -0.30008316]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 742 is [True, False, False, False, True, False]
State prediction error at timestep 742 is 0.012
Current timestep = 743. State = [[-0.17584406  0.07684875]]. Action = [[-0.09505345 -0.03013795  0.         -0.3036222 ]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 743 is [True, False, False, False, True, False]
State prediction error at timestep 743 is 0.012
Current timestep = 744. State = [[-0.18128534  0.07507068]]. Action = [[-0.05945491 -0.02408413  0.          0.7404125 ]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 744 is [True, False, False, False, True, False]
State prediction error at timestep 744 is 0.012
Current timestep = 745. State = [[-0.18477263  0.07147457]]. Action = [[-0.03265084 -0.06120014  0.          0.08400738]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 745 is [True, False, False, False, True, False]
State prediction error at timestep 745 is 0.012
Current timestep = 746. State = [[-0.1871745   0.06495823]]. Action = [[-0.02743443 -0.09395974  0.          0.58146596]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 746 is [True, False, False, False, True, False]
State prediction error at timestep 746 is 0.012
Current timestep = 747. State = [[-0.18362461  0.06131987]]. Action = [[ 0.09577601 -0.00413854  0.         -0.2073139 ]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 747 is [True, False, False, False, True, False]
State prediction error at timestep 747 is 0.012
Current timestep = 748. State = [[-0.17942543  0.06349433]]. Action = [[0.03954966 0.07138895 0.         0.8553473 ]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 748 is [True, False, False, False, True, False]
State prediction error at timestep 748 is 0.012
Current timestep = 749. State = [[-0.18051766  0.06207605]]. Action = [[-0.04362353 -0.0516749   0.         -0.15699548]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 749 is [True, False, False, False, True, False]
State prediction error at timestep 749 is 0.012
Current timestep = 750. State = [[-0.1825422   0.05768132]]. Action = [[-0.01776645 -0.04611916  0.         -0.72059715]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 750 is [True, False, False, False, True, False]
State prediction error at timestep 750 is 0.012
Current timestep = 751. State = [[-0.18204308  0.05606703]]. Action = [[ 0.02259632  0.01253571  0.         -0.27660632]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 751 is [True, False, False, False, True, False]
State prediction error at timestep 751 is 0.012
Current timestep = 752. State = [[-0.18213625  0.05553325]]. Action = [[-0.00994236  0.0007353   0.          0.43566608]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 752 is [True, False, False, False, True, False]
State prediction error at timestep 752 is 0.012
Current timestep = 753. State = [[-0.18553376  0.05261574]]. Action = [[-0.06210102 -0.04646353  0.         -0.01682848]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 753 is [True, False, False, False, True, False]
State prediction error at timestep 753 is 0.012
Current timestep = 754. State = [[-0.18335044  0.05161461]]. Action = [[ 0.08916586  0.02082907  0.         -0.4560727 ]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 754 is [True, False, False, False, True, False]
State prediction error at timestep 754 is 0.012
Current timestep = 755. State = [[-0.17963775  0.05529509]]. Action = [[0.03245159 0.0794354  0.         0.46081185]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 755 is [True, False, False, False, True, False]
State prediction error at timestep 755 is 0.012
Current timestep = 756. State = [[-0.1809154   0.05789674]]. Action = [[-0.04210079  0.014102    0.         -0.8798099 ]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 756 is [True, False, False, False, True, False]
State prediction error at timestep 756 is 0.012
Current timestep = 757. State = [[-0.18078642  0.05794002]]. Action = [[ 0.02867126 -0.00846184  0.         -0.57500964]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 757 is [True, False, False, False, True, False]
State prediction error at timestep 757 is 0.012
Current timestep = 758. State = [[-0.17963074  0.06077139]]. Action = [[ 0.01301589  0.06184836  0.         -0.13088995]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 758 is [True, False, False, False, True, False]
State prediction error at timestep 758 is 0.012
Current timestep = 759. State = [[-0.18072519  0.05969456]]. Action = [[-0.02689406 -0.06171781  0.         -0.41441768]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 759 is [True, False, False, False, True, False]
State prediction error at timestep 759 is 0.012
Current timestep = 760. State = [[-0.18513742  0.05418836]]. Action = [[-0.08373877 -0.08482928  0.         -0.47703707]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 760 is [True, False, False, False, True, False]
State prediction error at timestep 760 is 0.012
Current timestep = 761. State = [[-0.18593797  0.05209634]]. Action = [[0.02319938 0.00378259 0.         0.40574253]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 761 is [True, False, False, False, True, False]
State prediction error at timestep 761 is 0.012
Current timestep = 762. State = [[-0.18103147  0.05138109]]. Action = [[ 0.08613863 -0.0111784   0.          0.0889492 ]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 762 is [True, False, False, False, True, False]
State prediction error at timestep 762 is 0.012
Current timestep = 763. State = [[-0.17422058  0.05465633]]. Action = [[0.09175815 0.08290429 0.         0.16887808]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 763 is [True, False, False, False, True, False]
State prediction error at timestep 763 is 0.012
Current timestep = 764. State = [[-0.16745742  0.05382213]]. Action = [[ 0.08441784 -0.05277661  0.          0.35092437]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 764 is [True, False, False, False, True, False]
State prediction error at timestep 764 is 0.012
Current timestep = 765. State = [[-0.15949644  0.04712795]]. Action = [[ 0.09889483 -0.09109934  0.         -0.9062925 ]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 765 is [True, False, False, False, True, False]
State prediction error at timestep 765 is 0.012
Current timestep = 766. State = [[-0.15673079  0.04307215]]. Action = [[-0.03031645 -0.00757559  0.         -0.3386684 ]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 766 is [True, False, False, False, True, False]
State prediction error at timestep 766 is 0.012
Current timestep = 767. State = [[-0.15189132  0.04234822]]. Action = [[0.08742791 0.01329206 0.         0.3423338 ]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 767 is [True, False, False, False, True, False]
State prediction error at timestep 767 is 0.012
Current timestep = 768. State = [[-0.15199317  0.04479174]]. Action = [[-0.08349542  0.06050854  0.         -0.71676725]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 768 is [True, False, False, False, True, False]
State prediction error at timestep 768 is 0.012
Current timestep = 769. State = [[-0.1576873   0.04856493]]. Action = [[-0.09485385  0.04565816  0.          0.00723088]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 769 is [True, False, False, False, True, False]
State prediction error at timestep 769 is 0.012
Current timestep = 770. State = [[-0.16428505  0.04959306]]. Action = [[-0.09464572 -0.01559724  0.          0.98291266]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 770 is [True, False, False, False, True, False]
State prediction error at timestep 770 is 0.012
Current timestep = 771. State = [[-0.16313452  0.0485387 ]]. Action = [[ 0.08209168 -0.02330686  0.         -0.04953921]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 771 is [True, False, False, False, True, False]
State prediction error at timestep 771 is 0.012
Current timestep = 772. State = [[-0.15780447  0.05163904]]. Action = [[ 0.06039479  0.07174834  0.         -0.8955244 ]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 772 is [True, False, False, False, True, False]
State prediction error at timestep 772 is 0.012
Current timestep = 773. State = [[-0.15710919  0.0502039 ]]. Action = [[-0.03073711 -0.07670204  0.         -0.0803296 ]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 773 is [True, False, False, False, True, False]
State prediction error at timestep 773 is 0.012
Current timestep = 774. State = [[-0.15366915  0.05091136]]. Action = [[0.07833286 0.05247349 0.         0.6510874 ]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 774 is [True, False, False, False, True, False]
State prediction error at timestep 774 is 0.012
Current timestep = 775. State = [[-0.15157542  0.05500583]]. Action = [[-0.0064294   0.05095788  0.          0.5468526 ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 775 is [True, False, False, False, True, False]
State prediction error at timestep 775 is 0.012
Current timestep = 776. State = [[-0.14918591  0.06061576]]. Action = [[ 0.04780822  0.07364369  0.         -0.09134418]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 776 is [True, False, False, False, True, False]
State prediction error at timestep 776 is 0.012
Current timestep = 777. State = [[-0.15038714  0.06510887]]. Action = [[-0.05271511  0.03255347  0.          0.31260288]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 777 is [True, False, False, False, True, False]
State prediction error at timestep 777 is 0.012
Current timestep = 778. State = [[-0.14731817  0.06415185]]. Action = [[ 0.09098675 -0.05786715  0.          0.64170885]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 778 is [True, False, False, False, True, False]
State prediction error at timestep 778 is 0.012
Current timestep = 779. State = [[-0.14615245  0.06128096]]. Action = [[-0.0404515 -0.0381982  0.        -0.8567645]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 779 is [True, False, False, False, True, False]
State prediction error at timestep 779 is 0.012
Current timestep = 780. State = [[-0.14487267  0.05664609]]. Action = [[ 0.02826687 -0.07978947  0.          0.29480922]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 780 is [True, False, False, False, True, False]
State prediction error at timestep 780 is 0.012
Current timestep = 781. State = [[-0.14594945  0.05510238]]. Action = [[-0.05909122  0.01270431  0.         -0.4156394 ]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 781 is [True, False, False, False, True, False]
State prediction error at timestep 781 is 0.012
Current timestep = 782. State = [[-0.148765   0.0565072]]. Action = [[-0.04438443  0.01810564  0.          0.1762631 ]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 782 is [True, False, False, False, True, False]
State prediction error at timestep 782 is 0.012
Current timestep = 783. State = [[-0.15161332  0.06226762]]. Action = [[-0.04042704  0.09732001  0.         -0.01336288]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 783 is [True, False, False, False, True, False]
State prediction error at timestep 783 is 0.012
Current timestep = 784. State = [[-0.15685958  0.07051188]]. Action = [[-0.07758362  0.09354185  0.         -0.8942189 ]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 784 is [True, False, False, False, True, False]
State prediction error at timestep 784 is 0.012
Current timestep = 785. State = [[-0.161463    0.07880908]]. Action = [[-0.03111388  0.08416905  0.         -0.22903812]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 785 is [True, False, False, False, True, False]
State prediction error at timestep 785 is 0.012
Current timestep = 786. State = [[-0.16318783  0.08607947]]. Action = [[ 0.01375966  0.0640104   0.         -0.55082744]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 786 is [True, False, False, False, True, False]
State prediction error at timestep 786 is 0.012
Current timestep = 787. State = [[-0.1642903   0.08769075]]. Action = [[ 0.00127302 -0.03892101  0.          0.04489005]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 787 is [True, False, False, False, True, False]
State prediction error at timestep 787 is 0.012
Current timestep = 788. State = [[-0.16321042  0.0848792 ]]. Action = [[ 0.0428882  -0.0631846   0.          0.23667431]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 788 is [True, False, False, False, True, False]
State prediction error at timestep 788 is 0.012
Current timestep = 789. State = [[-0.16107522  0.08337707]]. Action = [[ 0.03391647 -0.00922661  0.         -0.35315073]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 789 is [True, False, False, False, True, False]
State prediction error at timestep 789 is 0.012
Current timestep = 790. State = [[-0.15703218  0.08130748]]. Action = [[ 0.07092898 -0.0421159   0.         -0.5083091 ]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 790 is [True, False, False, False, True, False]
State prediction error at timestep 790 is 0.012
Current timestep = 791. State = [[-0.15865491  0.07870369]]. Action = [[-0.08103445 -0.03079488  0.         -0.17037821]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 791 is [True, False, False, False, True, False]
State prediction error at timestep 791 is 0.012
Current timestep = 792. State = [[-0.1641696   0.07964296]]. Action = [[-0.071275    0.03380396  0.         -0.2509128 ]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 792 is [True, False, False, False, True, False]
State prediction error at timestep 792 is 0.012
Current timestep = 793. State = [[-0.17016412  0.07721509]]. Action = [[-0.07818829 -0.07419064  0.         -0.45124555]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 793 is [True, False, False, False, True, False]
State prediction error at timestep 793 is 0.012
Current timestep = 794. State = [[-0.17520516  0.07793431]]. Action = [[-0.05157137  0.05190139  0.          0.83721507]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 794 is [True, False, False, False, True, False]
State prediction error at timestep 794 is 0.012
Current timestep = 795. State = [[-0.17828387  0.07772014]]. Action = [[-0.01654925 -0.03577612  0.          0.6436479 ]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 795 is [True, False, False, False, True, False]
State prediction error at timestep 795 is 0.012
Current timestep = 796. State = [[-0.17955622  0.08001536]]. Action = [[0.00435616 0.0657978  0.         0.34108114]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 796 is [True, False, False, False, True, False]
State prediction error at timestep 796 is 0.012
Current timestep = 797. State = [[-0.1816346   0.07980998]]. Action = [[-0.01961886 -0.04053861  0.          0.4180622 ]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 797 is [True, False, False, False, True, False]
State prediction error at timestep 797 is 0.012
Current timestep = 798. State = [[-0.18309064  0.07959151]]. Action = [[0.00348534 0.01959308 0.         0.9446156 ]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 798 is [True, False, False, False, True, False]
State prediction error at timestep 798 is 0.012
Current timestep = 799. State = [[-0.18875898  0.0829957 ]]. Action = [[-0.09237529  0.05989669  0.         -0.86301434]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 799 is [True, False, False, False, True, False]
State prediction error at timestep 799 is 0.012
Current timestep = 800. State = [[-0.19417757  0.08207397]]. Action = [[-0.0310057  -0.05955762  0.          0.42639923]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 800 is [True, False, False, False, True, False]
State prediction error at timestep 800 is 0.012
Current timestep = 801. State = [[-0.19500215  0.07683877]]. Action = [[ 0.02631459 -0.07459968  0.          0.64242697]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 801 is [True, False, False, False, True, False]
State prediction error at timestep 801 is 0.012
Current timestep = 802. State = [[-0.19479708  0.07806172]]. Action = [[ 0.01307043  0.07752425  0.         -0.45114148]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 802 is [True, False, False, False, True, False]
State prediction error at timestep 802 is 0.012
Current timestep = 803. State = [[-0.19663744  0.07832377]]. Action = [[-0.02002709 -0.03140248  0.         -0.79141146]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 803 is [True, False, False, False, True, False]
State prediction error at timestep 803 is 0.012
Current timestep = 804. State = [[-0.19426072  0.08153559]]. Action = [[ 0.08673374  0.08854715  0.         -0.23511785]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 804 is [True, False, False, False, True, False]
State prediction error at timestep 804 is 0.012
Current timestep = 805. State = [[-0.19008093  0.08758617]]. Action = [[ 0.06524015  0.08235817  0.         -0.8650296 ]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 805 is [True, False, False, False, True, False]
State prediction error at timestep 805 is 0.012
Current timestep = 806. State = [[-0.19103602  0.09284588]]. Action = [[-0.03645007  0.05970483  0.         -0.29706693]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 806 is [True, False, False, False, True, False]
State prediction error at timestep 806 is 0.012
Current timestep = 807. State = [[-0.1929501   0.09774405]]. Action = [[0.00191204 0.0552044  0.         0.85993576]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 807 is [True, False, False, False, True, False]
State prediction error at timestep 807 is 0.012
Current timestep = 808. State = [[-0.19422193  0.09811968]]. Action = [[-0.00838102 -0.04010493  0.         -0.8830146 ]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 808 is [True, False, False, False, True, False]
State prediction error at timestep 808 is 0.012
Current timestep = 809. State = [[-0.19254377  0.10066368]]. Action = [[0.04964977 0.05710419 0.         0.22307944]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 809 is [True, False, False, False, True, False]
State prediction error at timestep 809 is 0.012
Current timestep = 810. State = [[-0.19583257  0.10115054]]. Action = [[-0.0951198  -0.04268194  0.          0.1658225 ]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 810 is [True, False, False, False, True, False]
State prediction error at timestep 810 is 0.012
Current timestep = 811. State = [[-0.20336549  0.10088862]]. Action = [[-0.09847884 -0.00873587  0.         -0.58889747]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 811 is [True, False, False, False, True, False]
State prediction error at timestep 811 is 0.012
Current timestep = 812. State = [[-0.2039476  0.0995621]]. Action = [[ 0.05778228 -0.04292473  0.          0.5534167 ]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 812 is [True, False, False, False, True, False]
State prediction error at timestep 812 is 0.012
Current timestep = 813. State = [[-0.20562129  0.09979966]]. Action = [[-0.06169579  0.01521252  0.          0.14616466]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 813 is [True, False, False, False, True, False]
State prediction error at timestep 813 is 0.012
Current timestep = 814. State = [[-0.20465393  0.09773404]]. Action = [[ 0.05525187 -0.06137919  0.          0.6213716 ]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 814 is [True, False, False, False, True, False]
State prediction error at timestep 814 is 0.012
Current timestep = 815. State = [[-0.2069936   0.10008293]]. Action = [[-0.07648259  0.07835027  0.         -0.9107446 ]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 815 is [True, False, False, False, True, False]
State prediction error at timestep 815 is 0.012
Current timestep = 816. State = [[-0.20800653  0.10636403]]. Action = [[0.0331305  0.07516041 0.         0.3436234 ]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 816 is [True, False, False, False, True, False]
State prediction error at timestep 816 is 0.012
Current timestep = 817. State = [[-0.20856012  0.10939439]]. Action = [[-0.01224626  0.00717163  0.          0.6208749 ]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 817 is [True, False, False, False, True, False]
State prediction error at timestep 817 is 0.012
Current timestep = 818. State = [[-0.2125639  0.1134128]]. Action = [[-0.06181024  0.06185397  0.         -0.02620709]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 818 is [True, False, False, False, True, False]
State prediction error at timestep 818 is 0.012
Current timestep = 819. State = [[-0.2183306   0.11932239]]. Action = [[-0.06230352  0.06351162  0.         -0.5510592 ]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 819 is [True, False, False, False, True, False]
State prediction error at timestep 819 is 0.012
Current timestep = 820. State = [[-0.21929401  0.12034367]]. Action = [[ 0.0415346  -0.04034868  0.          0.20208788]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 820 is [True, False, False, False, True, False]
State prediction error at timestep 820 is 0.012
Current timestep = 821. State = [[-0.2179034   0.12326865]]. Action = [[ 0.02876069  0.06459723  0.         -0.1201269 ]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 821 is [True, False, False, False, True, False]
State prediction error at timestep 821 is 0.012
Current timestep = 822. State = [[-0.21820448  0.12510654]]. Action = [[-0.00275913 -0.01392561  0.          0.35883915]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 822 is [True, False, False, False, False, True]
State prediction error at timestep 822 is 0.012
Current timestep = 823. State = [[-0.21865156  0.12637298]]. Action = [[0.00610732 0.01621568 0.         0.2921095 ]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 823 is [True, False, False, False, False, True]
State prediction error at timestep 823 is 0.012
Current timestep = 824. State = [[-0.21462446  0.13149501]]. Action = [[ 0.09555947  0.08454406  0.         -0.63137627]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 824 is [True, False, False, False, False, True]
State prediction error at timestep 824 is 0.012
Current timestep = 825. State = [[-0.21649422  0.13596255]]. Action = [[-0.08850329  0.02734628  0.         -0.5202895 ]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 825 is [True, False, False, False, False, True]
State prediction error at timestep 825 is 0.012
Current timestep = 826. State = [[-0.21823683  0.139428  ]]. Action = [[ 0.03319474  0.03669318  0.         -0.20287979]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 826 is [True, False, False, False, False, True]
State prediction error at timestep 826 is 0.012
Current timestep = 827. State = [[-0.21854924  0.1394588 ]]. Action = [[-0.0043386  -0.03547197  0.          0.21912348]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 827 is [True, False, False, False, False, True]
State prediction error at timestep 827 is 0.012
Current timestep = 828. State = [[-0.21991146  0.14267166]]. Action = [[-0.0134307   0.06923728  0.          0.42798185]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 828 is [True, False, False, False, False, True]
State prediction error at timestep 828 is 0.012
Current timestep = 829. State = [[-0.21603203  0.14145297]]. Action = [[ 0.09789347 -0.07627241  0.         -0.56486595]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 829 is [True, False, False, False, False, True]
State prediction error at timestep 829 is 0.012
Current timestep = 830. State = [[-0.21013956  0.14024451]]. Action = [[0.06310018 0.01439534 0.         0.6298704 ]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 830 is [True, False, False, False, False, True]
State prediction error at timestep 830 is 0.012
Current timestep = 831. State = [[-0.20811184  0.14217871]]. Action = [[-0.00596305  0.03171647  0.         -0.93713677]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 831 is [True, False, False, False, False, True]
State prediction error at timestep 831 is 0.012
Current timestep = 832. State = [[-0.20445578  0.13923508]]. Action = [[ 0.06129994 -0.08188109  0.          0.6372268 ]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 832 is [True, False, False, False, False, True]
State prediction error at timestep 832 is 0.012
Current timestep = 833. State = [[-0.19967677  0.13521917]]. Action = [[ 0.03703453 -0.03269438  0.         -0.84256804]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 833 is [True, False, False, False, False, True]
State prediction error at timestep 833 is 0.012
Current timestep = 834. State = [[-0.19888987  0.13510029]]. Action = [[-0.0366334   0.02324779  0.          0.645414  ]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 834 is [True, False, False, False, False, True]
State prediction error at timestep 834 is 0.012
Current timestep = 835. State = [[-0.19640642  0.13832611]]. Action = [[0.0458475  0.05581217 0.         0.7376232 ]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 835 is [True, False, False, False, False, True]
State prediction error at timestep 835 is 0.012
Current timestep = 836. State = [[-0.19423212  0.14077163]]. Action = [[-1.2346357e-04  2.0283543e-02  0.0000000e+00  5.3654909e-01]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 836 is [True, False, False, False, False, True]
State prediction error at timestep 836 is 0.012
Current timestep = 837. State = [[-0.19011495  0.14372358]]. Action = [[ 0.06566533  0.04771147  0.         -0.13291478]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 837 is [True, False, False, False, False, True]
State prediction error at timestep 837 is 0.012
Current timestep = 838. State = [[-0.18376319  0.14496976]]. Action = [[0.07623284 0.00031461 0.         0.18038046]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 838 is [True, False, False, False, False, True]
State prediction error at timestep 838 is 0.012
Current timestep = 839. State = [[-0.1762521   0.14822833]]. Action = [[0.08962833 0.069745   0.         0.0684495 ]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 839 is [True, False, False, False, False, True]
State prediction error at timestep 839 is 0.012
Current timestep = 840. State = [[-0.17526314  0.14782295]]. Action = [[-0.06563804 -0.05295813  0.         -0.08991122]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 840 is [True, False, False, False, False, True]
State prediction error at timestep 840 is 0.012
Current timestep = 841. State = [[-0.17794883  0.14588255]]. Action = [[-0.04095739 -0.02058496  0.          0.6408386 ]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 841 is [True, False, False, False, False, True]
State prediction error at timestep 841 is 0.012
Current timestep = 842. State = [[-0.17976153  0.14270979]]. Action = [[-0.03072355 -0.06254348  0.          0.15673113]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 842 is [True, False, False, False, False, True]
State prediction error at timestep 842 is 0.012
Current timestep = 843. State = [[-0.17701517  0.1372196 ]]. Action = [[ 0.05418298 -0.08067755  0.         -0.43133378]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 843 is [True, False, False, False, False, True]
State prediction error at timestep 843 is 0.012
Current timestep = 844. State = [[-0.1696259   0.12946376]]. Action = [[ 0.09743606 -0.09903786  0.         -0.84396744]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 844 is [True, False, False, False, False, True]
State prediction error at timestep 844 is 0.012
Current timestep = 845. State = [[-0.16376995  0.12621154]]. Action = [[ 0.03497571  0.0171715   0.         -0.6419293 ]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 845 is [True, False, False, False, False, True]
State prediction error at timestep 845 is 0.012
Current timestep = 846. State = [[-0.15729406  0.12479022]]. Action = [[ 0.08368819 -0.00747488  0.          0.9522784 ]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 846 is [True, False, False, False, True, False]
State prediction error at timestep 846 is 0.012
Current timestep = 847. State = [[-0.15240999  0.12555364]]. Action = [[0.02626482 0.0515176  0.         0.37349308]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 847 is [True, False, False, False, False, True]
State prediction error at timestep 847 is 0.012
Current timestep = 848. State = [[-0.1521812   0.12523082]]. Action = [[-0.03699075 -0.01112098  0.         -0.90853995]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 848 is [True, False, False, False, False, True]
State prediction error at timestep 848 is 0.012
Current timestep = 849. State = [[-0.15569659  0.12194269]]. Action = [[-0.08058725 -0.04895262  0.          0.23734021]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 849 is [True, False, False, False, True, False]
State prediction error at timestep 849 is 0.012
Current timestep = 850. State = [[-0.15993218  0.12516326]]. Action = [[-0.06187503  0.09743608  0.         -0.9838493 ]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 850 is [True, False, False, False, False, True]
State prediction error at timestep 850 is 0.012
Current timestep = 851. State = [[-0.16490129  0.1295133 ]]. Action = [[-0.06701927  0.02729433  0.          0.50647426]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 851 is [True, False, False, False, False, True]
State prediction error at timestep 851 is 0.012
Current timestep = 852. State = [[-0.16543809  0.13134423]]. Action = [[ 0.03594214  0.00758737  0.         -0.568202  ]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 852 is [True, False, False, False, False, True]
State prediction error at timestep 852 is 0.012
Current timestep = 853. State = [[-0.16597705  0.13382858]]. Action = [[-0.01714475  0.03579705  0.          0.87571764]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 853 is [True, False, False, False, False, True]
State prediction error at timestep 853 is 0.012
Current timestep = 854. State = [[-0.16586861  0.13697544]]. Action = [[ 0.02747444  0.03136539  0.         -0.13461995]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 854 is [True, False, False, False, False, True]
State prediction error at timestep 854 is 0.012
Current timestep = 855. State = [[-0.1648092   0.13917446]]. Action = [[0.02528293 0.01547952 0.         0.35942578]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 855 is [True, False, False, False, False, True]
State prediction error at timestep 855 is 0.012
Current timestep = 856. State = [[-0.16325672  0.1424657 ]]. Action = [[0.03427506 0.04789763 0.         0.5365486 ]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 856 is [True, False, False, False, False, True]
State prediction error at timestep 856 is 0.012
Current timestep = 857. State = [[-0.15963937  0.1470746 ]]. Action = [[0.07210352 0.05834232 0.         0.21490633]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 857 is [True, False, False, False, False, True]
State prediction error at timestep 857 is 0.012
Current timestep = 858. State = [[-0.16045056  0.14794402]]. Action = [[-0.05137458 -0.02878148  0.          0.82392335]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 858 is [True, False, False, False, False, True]
State prediction error at timestep 858 is 0.012
Current timestep = 859. State = [[-0.16413382  0.14974687]]. Action = [[-0.03935675  0.03478643  0.          0.81637096]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 859 is [True, False, False, False, False, True]
State prediction error at timestep 859 is 0.012
Current timestep = 860. State = [[-0.16643615  0.15117411]]. Action = [[-0.01270922 -0.0092575   0.          0.23814678]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 860 is [True, False, False, False, False, True]
State prediction error at timestep 860 is 0.012
Current timestep = 861. State = [[-0.17042243  0.15215476]]. Action = [[-0.06593549  0.00363239  0.         -0.3307966 ]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 861 is [True, False, False, False, False, True]
State prediction error at timestep 861 is 0.012
Current timestep = 862. State = [[-0.17490295  0.15752056]]. Action = [[-0.04328059  0.08309162  0.          0.8063748 ]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 862 is [True, False, False, False, False, True]
State prediction error at timestep 862 is 0.012
Current timestep = 863. State = [[-0.18190952  0.16402644]]. Action = [[-0.09652586  0.05571672  0.         -0.71435916]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 863 is [True, False, False, False, False, True]
State prediction error at timestep 863 is 0.012
Current timestep = 864. State = [[-0.1832433   0.16461562]]. Action = [[ 0.05222832 -0.05329921  0.          0.85693955]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 864 is [True, False, False, False, False, True]
State prediction error at timestep 864 is 0.012
Current timestep = 865. State = [[-0.18627197  0.16649832]]. Action = [[-0.06917726  0.04367628  0.         -0.52012765]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 865 is [True, False, False, False, False, True]
State prediction error at timestep 865 is 0.012
Current timestep = 866. State = [[-0.1920562   0.17072059]]. Action = [[-0.05696666  0.03379955  0.          0.5667535 ]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 866 is [True, False, False, False, False, True]
State prediction error at timestep 866 is 0.012
Current timestep = 867. State = [[-0.19048871  0.17000401]]. Action = [[ 0.09219135 -0.05805593  0.          0.3958149 ]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 867 is [True, False, False, False, False, True]
State prediction error at timestep 867 is 0.012
Current timestep = 868. State = [[-0.19040047  0.17031999]]. Action = [[-0.03124291  0.0283972   0.         -0.32739675]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 868 is [True, False, False, False, False, True]
State prediction error at timestep 868 is 0.012
Current timestep = 869. State = [[-0.18895032  0.17596413]]. Action = [[0.06472602 0.09197838 0.         0.41242588]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 869 is [True, False, False, False, False, True]
State prediction error at timestep 869 is 0.012
Current timestep = 870. State = [[-0.18866874  0.17445192]]. Action = [[-0.02139685 -0.09331255  0.          0.21802056]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 870 is [True, False, False, False, False, True]
State prediction error at timestep 870 is 0.012
Current timestep = 871. State = [[-0.18953384  0.17207375]]. Action = [[ 1.8365681e-04 -3.1995103e-03  0.0000000e+00  6.5077376e-01]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 871 is [True, False, False, False, False, True]
State prediction error at timestep 871 is 0.012
Current timestep = 872. State = [[-0.1892055   0.17329831]]. Action = [[0.0156481  0.02888759 0.         0.6373844 ]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 872 is [True, False, False, False, False, True]
State prediction error at timestep 872 is 0.012
Current timestep = 873. State = [[-0.18811709  0.17743978]]. Action = [[ 0.02411852  0.07074206  0.         -0.96167463]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 873 is [True, False, False, False, False, True]
State prediction error at timestep 873 is 0.012
Current timestep = 874. State = [[-0.18358468  0.18142498]]. Action = [[0.09080487 0.04582456 0.         0.30074644]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 874 is [True, False, False, False, False, True]
State prediction error at timestep 874 is 0.012
Current timestep = 875. State = [[-0.1821253   0.17915712]]. Action = [[-0.02477155 -0.0719272   0.          0.6413734 ]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 875 is [True, False, False, False, False, True]
State prediction error at timestep 875 is 0.012
Current timestep = 876. State = [[-0.17845577  0.17707986]]. Action = [[ 0.08695766  0.00340705  0.         -0.9982169 ]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 876 is [True, False, False, False, False, True]
State prediction error at timestep 876 is 0.012
Current timestep = 877. State = [[-0.17963031  0.17882223]]. Action = [[-0.08156133  0.04030191  0.          0.81873894]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 877 is [True, False, False, False, False, True]
State prediction error at timestep 877 is 0.012
Current timestep = 878. State = [[-0.18340579  0.1793913 ]]. Action = [[-0.03815    -0.01683912  0.         -0.23263693]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 878 is [True, False, False, False, False, True]
State prediction error at timestep 878 is 0.012
Current timestep = 879. State = [[-0.18307748  0.17841175]]. Action = [[ 0.0270442  -0.01787385  0.          0.17300022]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 879 is [True, False, False, False, False, True]
State prediction error at timestep 879 is 0.012
Current timestep = 880. State = [[-0.17938475  0.17686002]]. Action = [[ 0.05652063 -0.0201425   0.         -0.38552034]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 880 is [True, False, False, False, False, True]
State prediction error at timestep 880 is 0.012
Current timestep = 881. State = [[-0.18150595  0.17682287]]. Action = [[-0.08591688  0.01171925  0.         -0.30482107]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 881 is [True, False, False, False, False, True]
State prediction error at timestep 881 is 0.012
Current timestep = 882. State = [[-0.18178438  0.17823668]]. Action = [[0.03914043 0.01896606 0.         0.07608569]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 882 is [True, False, False, False, False, True]
State prediction error at timestep 882 is 0.012
Current timestep = 883. State = [[-0.18532377  0.18247747]]. Action = [[-0.09166531  0.07043836  0.         -0.03199273]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 883 is [True, False, False, False, False, True]
State prediction error at timestep 883 is 0.012
Current timestep = 884. State = [[-0.18354307  0.18094127]]. Action = [[ 0.09288027 -0.08233316  0.          0.5820422 ]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 884 is [True, False, False, False, False, True]
State prediction error at timestep 884 is 0.012
Current timestep = 885. State = [[-0.17680241  0.17991683]]. Action = [[ 0.0878885   0.02983522  0.         -0.7006631 ]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 885 is [True, False, False, False, False, True]
State prediction error at timestep 885 is 0.012
Current timestep = 886. State = [[-0.17414635  0.17887416]]. Action = [[-0.00411619 -0.0275893   0.         -0.12688214]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 886 is [True, False, False, False, False, True]
State prediction error at timestep 886 is 0.012
Current timestep = 887. State = [[-0.1731754  0.1756025]]. Action = [[ 0.00847441 -0.04633982  0.          0.7721385 ]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 887 is [True, False, False, False, False, True]
State prediction error at timestep 887 is 0.012
Current timestep = 888. State = [[-0.17089848  0.17355154]]. Action = [[ 0.0268695  -0.00736762  0.          0.246279  ]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 888 is [True, False, False, False, False, True]
State prediction error at timestep 888 is 0.012
Current timestep = 889. State = [[-0.16557649  0.1725161 ]]. Action = [[ 0.07847475 -0.0023205   0.          0.06501865]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 889 is [True, False, False, False, False, True]
State prediction error at timestep 889 is 0.012
Current timestep = 890. State = [[-0.16561401  0.17293741]]. Action = [[-0.06440885  0.02336283  0.          0.20854795]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 890 is [True, False, False, False, False, True]
State prediction error at timestep 890 is 0.012
Current timestep = 891. State = [[-0.16341263  0.17569338]]. Action = [[0.07114594 0.05211455 0.         0.72177327]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 891 is [True, False, False, False, False, True]
State prediction error at timestep 891 is 0.012
Current timestep = 892. State = [[-0.15991712  0.17758298]]. Action = [[ 0.02346541  0.01724808  0.         -0.26254362]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 892 is [True, False, False, False, False, True]
State prediction error at timestep 892 is 0.012
Current timestep = 893. State = [[-0.15750515  0.17664383]]. Action = [[ 0.02072918 -0.02557365  0.          0.60408294]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 893 is [True, False, False, False, False, True]
State prediction error at timestep 893 is 0.012
Current timestep = 894. State = [[-0.15669438  0.17853315]]. Action = [[-0.01080244  0.05403348  0.          0.23601127]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 894 is [True, False, False, False, False, True]
State prediction error at timestep 894 is 0.012
Current timestep = 895. State = [[-0.15755762  0.18096864]]. Action = [[-0.02265695  0.01391633  0.         -0.7242096 ]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 895 is [True, False, False, False, False, True]
State prediction error at timestep 895 is 0.012
Current timestep = 896. State = [[-0.16078503  0.18029934]]. Action = [[-0.06514917 -0.03705639  0.         -0.66519666]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 896 is [True, False, False, False, False, True]
State prediction error at timestep 896 is 0.012
Current timestep = 897. State = [[-0.16593675  0.18308584]]. Action = [[-0.0784089   0.05580121  0.         -0.76408756]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 897 is [True, False, False, False, False, True]
State prediction error at timestep 897 is 0.012
Current timestep = 898. State = [[-0.16960336  0.182055  ]]. Action = [[-0.03089613 -0.07806367  0.          0.647159  ]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 898 is [True, False, False, False, False, True]
State prediction error at timestep 898 is 0.012
Current timestep = 899. State = [[-0.17463312  0.07921308]]. Action = [[-0.09301739 -0.08689797  0.         -0.5352886 ]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 899 is [True, False, False, False, True, False]
State prediction error at timestep 899 is 0.012
Current timestep = 900. State = [[-0.1755085   0.07512537]]. Action = [[-0.08341965 -0.08956175  0.          0.42098212]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 900 is [True, False, False, False, True, False]
State prediction error at timestep 900 is 0.012
Current timestep = 901. State = [[-0.17521428  0.06833483]]. Action = [[ 0.03159811 -0.09614088  0.          0.41597986]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 901 is [True, False, False, False, True, False]
State prediction error at timestep 901 is 0.012
Current timestep = 902. State = [[-0.16911833  0.06819914]]. Action = [[ 0.09385409  0.06346265  0.         -0.73376685]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 902 is [True, False, False, False, True, False]
State prediction error at timestep 902 is 0.012
Current timestep = 903. State = [[-0.16923805  0.07034738]]. Action = [[-0.07935603  0.0167402   0.          0.57125115]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 903 is [True, False, False, False, True, False]
State prediction error at timestep 903 is 0.012
Current timestep = 904. State = [[-0.16743234  0.06758997]]. Action = [[ 0.07537896 -0.05933464  0.         -0.34267306]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 904 is [True, False, False, False, True, False]
State prediction error at timestep 904 is 0.012
Current timestep = 905. State = [[-0.16778739  0.06886975]]. Action = [[-0.05565983  0.07289916  0.          0.40900445]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 905 is [True, False, False, False, True, False]
State prediction error at timestep 905 is 0.012
Current timestep = 906. State = [[-0.17229931  0.07127406]]. Action = [[-0.0662068   0.01069977  0.         -0.8688945 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 906 is [True, False, False, False, True, False]
State prediction error at timestep 906 is 0.012
Current timestep = 907. State = [[-0.17802583  0.06988173]]. Action = [[-0.08059959 -0.04108346  0.          0.7860532 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 907 is [True, False, False, False, True, False]
State prediction error at timestep 907 is 0.012
Current timestep = 908. State = [[-0.17971197  0.07119281]]. Action = [[0.01806863 0.04568339 0.         0.87451863]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 908 is [True, False, False, False, True, False]
State prediction error at timestep 908 is 0.012
Current timestep = 909. State = [[-0.17504737  0.0696516 ]]. Action = [[ 0.09899142 -0.05589607  0.          0.2814293 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 909 is [True, False, False, False, True, False]
State prediction error at timestep 909 is 0.012
Current timestep = 910. State = [[-0.17547342  0.06902354]]. Action = [[-0.06328503  0.02443359  0.          0.6967299 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 910 is [True, False, False, False, True, False]
State prediction error at timestep 910 is 0.012
Current timestep = 911. State = [[-0.17307092  0.0681084 ]]. Action = [[ 0.09653551 -0.02532632  0.          0.25446916]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 911 is [True, False, False, False, True, False]
State prediction error at timestep 911 is 0.012
Current timestep = 912. State = [[-0.16645057  0.06701157]]. Action = [[0.08972823 0.00527827 0.         0.0655055 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 912 is [True, False, False, False, True, False]
State prediction error at timestep 912 is 0.012
Current timestep = 913. State = [[-0.16066483  0.06936903]]. Action = [[ 0.0677987   0.06183898  0.         -0.93427217]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 913 is [True, False, False, False, True, False]
State prediction error at timestep 913 is 0.012
Current timestep = 914. State = [[-0.15798639  0.06651373]]. Action = [[ 0.00903265 -0.08073846  0.         -0.5293332 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 914 is [True, False, False, False, True, False]
State prediction error at timestep 914 is 0.012
Current timestep = 915. State = [[-0.1530934   0.06682885]]. Action = [[0.08118217 0.06520467 0.         0.6361582 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 915 is [True, False, False, False, True, False]
State prediction error at timestep 915 is 0.012
Current timestep = 916. State = [[-0.14844765  0.0676036 ]]. Action = [[ 0.03548845 -0.00778349  0.          0.35799026]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 916 is [True, False, False, False, True, False]
State prediction error at timestep 916 is 0.012
Current timestep = 917. State = [[-0.15066029  0.06472596]]. Action = [[-0.09790182 -0.05136839  0.          0.50291705]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 917 is [True, False, False, False, True, False]
State prediction error at timestep 917 is 0.012
Current timestep = 918. State = [[-0.15351132  0.06780492]]. Action = [[-0.02586622  0.0898725   0.          0.2557869 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 918 is [True, False, False, False, True, False]
State prediction error at timestep 918 is 0.012
Current timestep = 919. State = [[-0.15575577  0.0701191 ]]. Action = [[-0.03693535 -0.01333588  0.         -0.7058575 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 919 is [True, False, False, False, True, False]
State prediction error at timestep 919 is 0.012
Current timestep = 920. State = [[-0.1590824   0.07176466]]. Action = [[-0.05469064  0.02418448  0.          0.5819497 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 920 is [True, False, False, False, True, False]
State prediction error at timestep 920 is 0.012
Current timestep = 921. State = [[-0.15801008  0.0781119 ]]. Action = [[ 0.0597868   0.09788913  0.         -0.27533615]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 921 is [True, False, False, False, True, False]
State prediction error at timestep 921 is 0.012
Current timestep = 922. State = [[-0.15431795  0.07703201]]. Action = [[ 0.04750434 -0.09664341  0.         -0.7038536 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 922 is [True, False, False, False, True, False]
State prediction error at timestep 922 is 0.012
Current timestep = 923. State = [[-0.14947638  0.07079594]]. Action = [[ 0.06065626 -0.07862227  0.         -0.28851628]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 923 is [True, False, False, False, True, False]
State prediction error at timestep 923 is 0.012
Current timestep = 924. State = [[-0.14554588  0.07095708]]. Action = [[ 0.0300464   0.05586015  0.         -0.7354646 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 924 is [True, False, False, False, True, False]
State prediction error at timestep 924 is 0.012
Current timestep = 925. State = [[-0.14016731  0.07689079]]. Action = [[ 0.08316027  0.09315776  0.         -0.88165176]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 925 is [True, False, False, False, True, False]
State prediction error at timestep 925 is 0.012
Current timestep = 926. State = [[-0.1404821   0.08257522]]. Action = [[-0.06537471  0.05589854  0.          0.9782543 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 926 is [True, False, False, False, True, False]
State prediction error at timestep 926 is 0.012
Current timestep = 927. State = [[-0.14586617  0.08480962]]. Action = [[-0.07951075 -0.00536416  0.          0.484581  ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 927 is [True, False, False, False, True, False]
State prediction error at timestep 927 is 0.012
Current timestep = 928. State = [[-0.14959571  0.08630702]]. Action = [[-0.03264285  0.00968951  0.         -0.89557725]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 928 is [True, False, False, False, True, False]
State prediction error at timestep 928 is 0.012
Current timestep = 929. State = [[-0.15483503  0.08575725]]. Action = [[-0.08804687 -0.04126343  0.          0.3785901 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 929 is [True, False, False, False, True, False]
State prediction error at timestep 929 is 0.012
Current timestep = 930. State = [[-0.16078313  0.0871637 ]]. Action = [[-0.07188775  0.02567974  0.         -0.9348801 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 930 is [True, False, False, False, True, False]
State prediction error at timestep 930 is 0.012
Current timestep = 931. State = [[-0.16468245  0.09130588]]. Action = [[-0.02623191  0.04378626  0.          0.8469348 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 931 is [True, False, False, False, True, False]
State prediction error at timestep 931 is 0.012
Current timestep = 932. State = [[-0.16302246  0.08994165]]. Action = [[ 0.06884205 -0.07363455  0.         -0.48603934]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 932 is [True, False, False, False, True, False]
State prediction error at timestep 932 is 0.012
Current timestep = 933. State = [[-0.15988678  0.08771329]]. Action = [[ 0.04025096 -0.00834483  0.         -0.39977723]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 933 is [True, False, False, False, True, False]
State prediction error at timestep 933 is 0.012
Current timestep = 934. State = [[-0.1610446   0.08538701]]. Action = [[-0.04115825 -0.03977817  0.         -0.7556489 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 934 is [True, False, False, False, True, False]
State prediction error at timestep 934 is 0.012
Current timestep = 935. State = [[-0.16645798  0.08384369]]. Action = [[-0.08550342 -0.00930098  0.          0.51018786]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 935 is [True, False, False, False, True, False]
State prediction error at timestep 935 is 0.012
Current timestep = 936. State = [[-0.17150725  0.08701146]]. Action = [[-0.04422996  0.06685717  0.          0.68021655]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 936 is [True, False, False, False, True, False]
State prediction error at timestep 936 is 0.012
Current timestep = 937. State = [[-0.17429686  0.08859324]]. Action = [[-0.01000511 -0.01128369  0.          0.46054518]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 937 is [True, False, False, False, True, False]
State prediction error at timestep 937 is 0.012
Current timestep = 938. State = [[-0.17245503  0.08900879]]. Action = [[0.06727143 0.0131681  0.         0.906888  ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 938 is [True, False, False, False, True, False]
State prediction error at timestep 938 is 0.012
Current timestep = 939. State = [[-0.17228872  0.08799825]]. Action = [[-0.01332896 -0.02220585  0.         -0.11340064]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 939 is [True, False, False, False, True, False]
State prediction error at timestep 939 is 0.012
Current timestep = 940. State = [[-0.1741949   0.08816673]]. Action = [[-0.01680029  0.02067788  0.          0.80609727]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 940 is [True, False, False, False, True, False]
State prediction error at timestep 940 is 0.012
Current timestep = 941. State = [[-0.17809251  0.08426148]]. Action = [[-0.05739452 -0.08833259  0.         -0.46496332]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 941 is [True, False, False, False, True, False]
State prediction error at timestep 941 is 0.012
Current timestep = 942. State = [[-0.18147305  0.08578055]]. Action = [[-0.02508176  0.08452003  0.         -0.29688525]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 942 is [True, False, False, False, True, False]
State prediction error at timestep 942 is 0.012
Current timestep = 943. State = [[-0.1798922   0.09219639]]. Action = [[0.07462993 0.08427846 0.         0.7790005 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 943 is [True, False, False, False, True, False]
State prediction error at timestep 943 is 0.012
Current timestep = 944. State = [[-0.17631218  0.09521977]]. Action = [[0.06055851 0.01179151 0.         0.97877383]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 944 is [True, False, False, False, True, False]
State prediction error at timestep 944 is 0.012
Current timestep = 945. State = [[-0.17597193  0.09444095]]. Action = [[-0.01235661 -0.02439753  0.         -0.45056152]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 945 is [True, False, False, False, True, False]
State prediction error at timestep 945 is 0.012
Current timestep = 946. State = [[-0.17587997  0.09279161]]. Action = [[ 0.01561481 -0.02096728  0.          0.8735049 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 946 is [True, False, False, False, True, False]
State prediction error at timestep 946 is 0.012
Current timestep = 947. State = [[-0.17452836  0.0874605 ]]. Action = [[ 0.01918431 -0.09318873  0.         -0.3469535 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 947 is [True, False, False, False, True, False]
State prediction error at timestep 947 is 0.012
Current timestep = 948. State = [[-0.17141807  0.08528547]]. Action = [[ 0.04498086  0.01954328  0.         -0.02904272]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 948 is [True, False, False, False, True, False]
State prediction error at timestep 948 is 0.012
Current timestep = 949. State = [[-0.17215289  0.08681424]]. Action = [[-0.04869395  0.03177086  0.         -0.28634965]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 949 is [True, False, False, False, True, False]
State prediction error at timestep 949 is 0.012
Current timestep = 950. State = [[-0.171425   0.0880674]]. Action = [[ 0.03578683  0.01071352  0.         -0.7555905 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 950 is [True, False, False, False, True, False]
State prediction error at timestep 950 is 0.012
Current timestep = 951. State = [[-0.16642423  0.09077515]]. Action = [[0.08200314 0.05443198 0.         0.6757114 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 951 is [True, False, False, False, True, False]
State prediction error at timestep 951 is 0.012
Current timestep = 952. State = [[-0.16690296  0.08773336]]. Action = [[-0.07424372 -0.09158712  0.          0.6195617 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 952 is [True, False, False, False, True, False]
State prediction error at timestep 952 is 0.012
Current timestep = 953. State = [[-0.1720067   0.08537382]]. Action = [[-0.069371    0.00381778  0.         -0.21495974]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 953 is [True, False, False, False, True, False]
State prediction error at timestep 953 is 0.012
Current timestep = 954. State = [[-0.17387974  0.08970518]]. Action = [[0.01090918 0.08659453 0.         0.38285136]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 954 is [True, False, False, False, True, False]
State prediction error at timestep 954 is 0.012
Current timestep = 955. State = [[-0.17424396  0.09213205]]. Action = [[ 0.00254086 -0.00507199  0.         -0.7048568 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 955 is [True, False, False, False, True, False]
State prediction error at timestep 955 is 0.012
Current timestep = 956. State = [[-0.17316958  0.09220784]]. Action = [[ 0.03166268 -0.00197843  0.          0.51603174]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 956 is [True, False, False, False, True, False]
State prediction error at timestep 956 is 0.012
Current timestep = 957. State = [[-0.16933496  0.09699862]]. Action = [[0.07444104 0.09782951 0.         0.6951506 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 957 is [True, False, False, False, True, False]
State prediction error at timestep 957 is 0.012
Current timestep = 958. State = [[-0.16392775  0.09978405]]. Action = [[0.08405428 0.00096381 0.         0.50041604]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 958 is [True, False, False, False, True, False]
State prediction error at timestep 958 is 0.012
Current timestep = 959. State = [[-0.15863706  0.09871928]]. Action = [[ 0.06241379 -0.02273578  0.          0.04101753]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 959 is [True, False, False, False, True, False]
State prediction error at timestep 959 is 0.012
Current timestep = 960. State = [[-0.15244155  0.10190117]]. Action = [[ 0.08441157  0.0815258   0.         -0.523966  ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 960 is [True, False, False, False, True, False]
State prediction error at timestep 960 is 0.012
Current timestep = 961. State = [[-0.14875649  0.10804819]]. Action = [[ 0.0206154  0.079207   0.        -0.8064507]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 961 is [True, False, False, False, True, False]
State prediction error at timestep 961 is 0.012
Current timestep = 962. State = [[-0.14933148  0.10704244]]. Action = [[-0.04263875 -0.07917876  0.         -0.21784282]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 962 is [True, False, False, False, True, False]
State prediction error at timestep 962 is 0.012
Current timestep = 963. State = [[-0.1491846   0.10227298]]. Action = [[-0.00197476 -0.06882813  0.         -0.13169128]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 963 is [True, False, False, False, True, False]
State prediction error at timestep 963 is 0.012
Current timestep = 964. State = [[-0.14863567  0.10343456]]. Action = [[-0.01502205  0.05394488  0.          0.84701204]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 964 is [True, False, False, False, True, False]
State prediction error at timestep 964 is 0.012
Current timestep = 965. State = [[-0.14332382  0.10701504]]. Action = [[0.09899279 0.03348307 0.         0.96536326]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 965 is [True, False, False, False, True, False]
State prediction error at timestep 965 is 0.012
Current timestep = 966. State = [[-0.13617674  0.11010479]]. Action = [[0.07116457 0.03746688 0.         0.1969577 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 966 is [True, False, False, False, True, False]
State prediction error at timestep 966 is 0.012
Current timestep = 967. State = [[-0.13036115  0.10849258]]. Action = [[ 0.04990234 -0.05827497  0.          0.75828576]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 967 is [True, False, False, False, True, False]
State prediction error at timestep 967 is 0.012
Current timestep = 968. State = [[-0.1296086   0.11048762]]. Action = [[-0.04811747  0.06874769  0.          0.5653417 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 968 is [True, False, False, False, True, False]
State prediction error at timestep 968 is 0.012
Current timestep = 969. State = [[-0.12470498  0.11058345]]. Action = [[ 0.09725779 -0.04575193  0.         -0.12988919]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 969 is [True, False, False, False, True, False]
State prediction error at timestep 969 is 0.012
Current timestep = 970. State = [[-0.12318584  0.11053003]]. Action = [[-0.06089608  0.0163299   0.         -0.80751985]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 970 is [True, False, False, False, True, False]
State prediction error at timestep 970 is 0.012
Current timestep = 971. State = [[-0.12400652  0.11435236]]. Action = [[-0.01447992  0.05521802  0.          0.8585055 ]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 971 is [True, False, False, False, True, False]
State prediction error at timestep 971 is 0.012
Current timestep = 972. State = [[-0.12283225  0.1212726 ]]. Action = [[ 0.01719111  0.08940654  0.         -0.01785398]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 972 is [True, False, False, False, True, False]
State prediction error at timestep 972 is 0.012
Current timestep = 973. State = [[-0.11891706  0.12581326]]. Action = [[ 0.0634846   0.01896201  0.         -0.5259989 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 973 is [True, False, False, False, False, True]
State prediction error at timestep 973 is 0.012
Current timestep = 974. State = [[-0.11606409  0.12917513]]. Action = [[0.01359548 0.03608038 0.         0.20189917]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 974 is [True, False, False, False, False, True]
State prediction error at timestep 974 is 0.012
Current timestep = 975. State = [[-0.11638793  0.12991078]]. Action = [[-0.02777552 -0.02939115  0.         -0.28144813]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 975 is [True, False, False, False, False, True]
State prediction error at timestep 975 is 0.012
Current timestep = 976. State = [[-0.12093297  0.130407  ]]. Action = [[-0.09690737 -0.00301504  0.          0.55649614]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 976 is [True, False, False, False, False, True]
State prediction error at timestep 976 is 0.012
Current timestep = 977. State = [[-0.12312904  0.12729418]]. Action = [[-0.01011229 -0.09242389  0.         -0.50125897]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 977 is [True, False, False, False, False, True]
State prediction error at timestep 977 is 0.012
Current timestep = 978. State = [[-0.11832361  0.12657082]]. Action = [[ 0.09578169  0.02359129  0.         -0.3578788 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 978 is [True, False, False, False, False, True]
State prediction error at timestep 978 is 0.012
Current timestep = 979. State = [[-0.11040632  0.12930329]]. Action = [[ 0.09676328  0.0420832   0.         -0.45464778]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 979 is [True, False, False, False, False, True]
State prediction error at timestep 979 is 0.012
Current timestep = 980. State = [[-0.10711206  0.12734337]]. Action = [[-0.01192524 -0.06527869  0.          0.31549096]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 980 is [True, False, False, False, False, True]
State prediction error at timestep 980 is 0.012
Current timestep = 981. State = [[-0.10245047  0.12334814]]. Action = [[ 0.07798595 -0.03863639  0.         -0.6364405 ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 981 is [True, False, False, False, True, False]
State prediction error at timestep 981 is 0.012
Current timestep = 982. State = [[-0.1011211   0.12072139]]. Action = [[-0.0427819  -0.01712835  0.          0.89997673]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 982 is [True, False, False, False, True, False]
State prediction error at timestep 982 is 0.012
Current timestep = 983. State = [[-0.10036274  0.12351919]]. Action = [[ 0.01721631  0.0766285   0.         -0.6600516 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 983 is [True, False, False, False, True, False]
State prediction error at timestep 983 is 0.012
Current timestep = 984. State = [[-0.09577876  0.12503332]]. Action = [[ 0.07465675 -0.00395219  0.         -0.83267987]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 984 is [True, False, False, False, False, True]
State prediction error at timestep 984 is 0.012
Current timestep = 985. State = [[-0.09458878  0.12372053]]. Action = [[-0.03359612 -0.01797117  0.          0.8324299 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 985 is [True, False, False, False, True, False]
State prediction error at timestep 985 is 0.012
Current timestep = 986. State = [[-0.09445831  0.12215996]]. Action = [[ 0.0043617  -0.01707197  0.          0.7571852 ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 986 is [True, False, False, False, True, False]
State prediction error at timestep 986 is 0.012
Current timestep = 987. State = [[-0.09128989  0.12556267]]. Action = [[0.05393986 0.08451789 0.         0.91074586]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 987 is [True, False, False, False, False, True]
State prediction error at timestep 987 is 0.012
Current timestep = 988. State = [[-0.09342349  0.12440124]]. Action = [[-0.09513517 -0.07575029  0.          0.5027149 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 988 is [True, False, False, False, True, False]
State prediction error at timestep 988 is 0.012
Current timestep = 989. State = [[-0.09393582  0.12034896]]. Action = [[ 0.03991907 -0.04135776  0.          0.14787495]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 989 is [True, False, False, False, True, False]
State prediction error at timestep 989 is 0.012
Current timestep = 990. State = [[-0.09232879  0.11853708]]. Action = [[ 0.01049151 -0.00351747  0.         -0.08527881]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 990 is [True, False, False, False, True, False]
State prediction error at timestep 990 is 0.012
Current timestep = 991. State = [[-0.09308257  0.11486947]]. Action = [[-0.02764587 -0.06312492  0.          0.650923  ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 991 is [True, False, False, False, True, False]
State prediction error at timestep 991 is 0.012
Current timestep = 992. State = [[-0.09498535  0.113911  ]]. Action = [[-0.03136913  0.02429801  0.          0.6611495 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 992 is [True, False, False, False, True, False]
State prediction error at timestep 992 is 0.012
Current timestep = 993. State = [[-0.09146675  0.11277775]]. Action = [[ 0.09209859 -0.02520504  0.         -0.692278  ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 993 is [True, False, False, False, True, False]
State prediction error at timestep 993 is 0.012
Current timestep = 994. State = [[-0.09177025  0.11459894]]. Action = [[-0.06004525  0.06383594  0.          0.4478165 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 994 is [True, False, False, False, True, False]
State prediction error at timestep 994 is 0.012
Current timestep = 995. State = [[-0.09754324  0.1146182 ]]. Action = [[-0.08616318 -0.03452219  0.         -0.5358048 ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 995 is [True, False, False, False, True, False]
State prediction error at timestep 995 is 0.012
Current timestep = 996. State = [[-0.09978438  0.11398407]]. Action = [[ 0.00700314  0.00219162  0.         -0.5991376 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 996 is [True, False, False, False, True, False]
State prediction error at timestep 996 is 0.012
Current timestep = 997. State = [[-0.10394139  0.11108261]]. Action = [[-0.08489864 -0.06169039  0.          0.7437209 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 997 is [True, False, False, False, True, False]
State prediction error at timestep 997 is 0.012
Current timestep = 998. State = [[-0.11087722  0.10505649]]. Action = [[-0.09520837 -0.0915528   0.          0.5565076 ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 998 is [True, False, False, False, True, False]
State prediction error at timestep 998 is 0.012
Current timestep = 999. State = [[-0.11136221  0.0994935 ]]. Action = [[ 0.05635961 -0.05256925  0.          0.8191378 ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 999 is [True, False, False, False, True, False]
State prediction error at timestep 999 is 0.012
Current timestep = 1000. State = [[-0.11088982  0.09386621]]. Action = [[-0.02084371 -0.06486428  0.          0.36910772]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 1000 is [True, False, False, False, True, False]
State prediction error at timestep 1000 is 0.012
Current timestep = 1001. State = [[-0.11303467  0.08694663]]. Action = [[-0.03861452 -0.08106516  0.         -0.37766755]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 1001 is [True, False, False, False, True, False]
State prediction error at timestep 1001 is 0.012
Current timestep = 1002. State = [[-0.11255932  0.08228175]]. Action = [[ 0.02965219 -0.01920224  0.          0.7019793 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 1002 is [True, False, False, False, True, False]
State prediction error at timestep 1002 is 0.012
Current timestep = 1003. State = [[-0.11222149  0.07508282]]. Action = [[-0.00776701 -0.09812682  0.          0.9466896 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 1003 is [True, False, False, False, True, False]
State prediction error at timestep 1003 is 0.012
Current timestep = 1004. State = [[-0.11453635  0.06929614]]. Action = [[-0.0441862  -0.02287438  0.          0.22634363]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 1004 is [True, False, False, False, True, False]
State prediction error at timestep 1004 is 0.012
Current timestep = 1005. State = [[-0.1177784   0.06302957]]. Action = [[-0.03817734 -0.07460159  0.         -0.77004814]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 1005 is [True, False, False, False, True, False]
State prediction error at timestep 1005 is 0.012
Current timestep = 1006. State = [[-0.11727311  0.05694324]]. Action = [[ 0.03919714 -0.03906184  0.          0.87841535]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 1006 is [True, False, False, False, True, False]
State prediction error at timestep 1006 is 0.012
Current timestep = 1007. State = [[-0.11772471  0.05198858]]. Action = [[-0.02054184 -0.03128257  0.          0.90425086]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 1007 is [True, False, False, False, True, False]
State prediction error at timestep 1007 is 0.012
Current timestep = 1008. State = [[-0.11761151  0.05143966]]. Action = [[ 0.02725398  0.04996251  0.         -0.6225882 ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 1008 is [True, False, False, False, True, False]
State prediction error at timestep 1008 is 0.012
Current timestep = 1009. State = [[-0.11356198  0.05360307]]. Action = [[0.09491577 0.0544657  0.         0.76703167]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 1009 is [True, False, False, False, True, False]
State prediction error at timestep 1009 is 0.012
Current timestep = 1010. State = [[-0.11167067  0.05076107]]. Action = [[ 0.01019116 -0.05599188  0.         -0.68790007]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 1010 is [True, False, False, False, True, False]
State prediction error at timestep 1010 is 0.012
Current timestep = 1011. State = [[-0.10858008  0.04905679]]. Action = [[ 0.07431579  0.02838691  0.         -0.03772992]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 1011 is [True, False, False, False, True, False]
State prediction error at timestep 1011 is 0.012
Current timestep = 1012. State = [[-0.10608076  0.04888009]]. Action = [[0.0269706  0.01076402 0.         0.42734635]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 1012 is [True, False, False, False, True, False]
State prediction error at timestep 1012 is 0.012
Current timestep = 1013. State = [[-0.11011705  0.04931031]]. Action = [[-0.0946182   0.02043293  0.         -0.2018624 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 1013 is [True, False, False, False, True, False]
State prediction error at timestep 1013 is 0.012
Current timestep = 1014. State = [[-0.10989784  0.05092245]]. Action = [[ 0.0751218   0.02965959  0.         -0.86963993]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 1014 is [True, False, False, False, True, False]
State prediction error at timestep 1014 is 0.012
Current timestep = 1015. State = [[-0.10614147  0.05081174]]. Action = [[ 0.04310875 -0.01290338  0.          0.16432142]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 1015 is [True, False, False, False, True, False]
State prediction error at timestep 1015 is 0.012
Current timestep = 1016. State = [[-0.10575353  0.05460204]]. Action = [[-0.01784409  0.0863105   0.         -0.79304975]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 1016 is [True, False, False, False, True, False]
State prediction error at timestep 1016 is 0.012
Current timestep = 1017. State = [[-0.1032171   0.06169716]]. Action = [[ 0.06661092  0.08675348  0.         -0.05441201]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 1017 is [True, False, False, False, True, False]
State prediction error at timestep 1017 is 0.012
Current timestep = 1018. State = [[-0.10193689  0.06288766]]. Action = [[-0.00794149 -0.0415217   0.          0.12224686]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 1018 is [True, False, False, False, True, False]
State prediction error at timestep 1018 is 0.012
Current timestep = 1019. State = [[-0.10561437  0.06481283]]. Action = [[-0.08073373  0.04130784  0.         -0.6694067 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 1019 is [True, False, False, False, True, False]
State prediction error at timestep 1019 is 0.012
Current timestep = 1020. State = [[-0.11179961  0.07162617]]. Action = [[-0.08933624  0.08410076  0.         -0.6760888 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 1020 is [True, False, False, False, True, False]
State prediction error at timestep 1020 is 0.012
Current timestep = 1021. State = [[-0.11588252  0.07678837]]. Action = [[-0.030038    0.01414088  0.         -0.66972756]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 1021 is [True, False, False, False, True, False]
State prediction error at timestep 1021 is 0.012
Current timestep = 1022. State = [[-0.11748455  0.07789499]]. Action = [[-0.01067324 -0.02871726  0.          0.25382912]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 1022 is [True, False, False, False, True, False]
State prediction error at timestep 1022 is 0.012
Current timestep = 1023. State = [[-0.11876905  0.07660843]]. Action = [[-0.01955844 -0.04419378  0.         -0.51790446]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 1023 is [True, False, False, False, True, False]
State prediction error at timestep 1023 is 0.012
Current timestep = 1024. State = [[-0.12038306  0.07781783]]. Action = [[-0.0218103   0.02387957  0.         -0.04514879]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 1024 is [True, False, False, False, True, False]
State prediction error at timestep 1024 is 0.012
Current timestep = 1025. State = [[-0.11849897  0.08110186]]. Action = [[0.05867507 0.03275304 0.         0.53611016]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 1025 is [True, False, False, False, True, False]
State prediction error at timestep 1025 is 0.012
Current timestep = 1026. State = [[-0.11551243  0.0814309 ]]. Action = [[ 0.03775021 -0.02569739  0.         -0.7047712 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 1026 is [True, False, False, False, True, False]
State prediction error at timestep 1026 is 0.012
Current timestep = 1027. State = [[-0.11506626  0.08296356]]. Action = [[-0.00988653  0.03807948  0.         -0.07900125]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 1027 is [True, False, False, False, True, False]
State prediction error at timestep 1027 is 0.012
Current timestep = 1028. State = [[-0.1124602   0.08354037]]. Action = [[ 0.06175292 -0.01478218  0.          0.5770025 ]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 1028 is [True, False, False, False, True, False]
State prediction error at timestep 1028 is 0.012
Current timestep = 1029. State = [[-0.10816684  0.08455534]]. Action = [[ 0.05522948  0.02999835  0.         -0.56859726]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 1029 is [True, False, False, False, True, False]
State prediction error at timestep 1029 is 0.012
Current timestep = 1030. State = [[-0.1058265  0.0843266]]. Action = [[ 0.01319759 -0.01858497  0.          0.5714809 ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 1030 is [True, False, False, False, True, False]
State prediction error at timestep 1030 is 0.012
Current timestep = 1031. State = [[-0.10809428  0.0871883 ]]. Action = [[-0.06280432  0.06686681  0.         -0.02139705]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 1031 is [True, False, False, False, True, False]
State prediction error at timestep 1031 is 0.012
Current timestep = 1032. State = [[-0.10947809  0.09256072]]. Action = [[ 0.00418463  0.06028608  0.         -0.4935966 ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 1032 is [True, False, False, False, True, False]
State prediction error at timestep 1032 is 0.012
Current timestep = 1033. State = [[-0.113499    0.09049396]]. Action = [[-0.08997542 -0.09533142  0.         -0.24315941]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 1033 is [True, False, False, False, True, False]
State prediction error at timestep 1033 is 0.012
Current timestep = 1034. State = [[-0.11208943  0.08421322]]. Action = [[ 0.07782345 -0.08356238  0.          0.7948768 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 1034 is [True, False, False, False, True, False]
State prediction error at timestep 1034 is 0.012
Current timestep = 1035. State = [[-0.11315015  0.08270315]]. Action = [[-0.08291986  0.0194141   0.         -0.04008788]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 1035 is [True, False, False, False, True, False]
State prediction error at timestep 1035 is 0.012
Current timestep = 1036. State = [[-0.11368313  0.07968489]]. Action = [[ 0.01904037 -0.07277864  0.          0.34697163]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 1036 is [True, False, False, False, True, False]
State prediction error at timestep 1036 is 0.012
Current timestep = 1037. State = [[-0.11335889  0.08032586]]. Action = [[-0.0129336   0.05921068  0.         -0.33567202]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 1037 is [True, False, False, False, True, False]
State prediction error at timestep 1037 is 0.012
Current timestep = 1038. State = [[-0.11173155  0.08106302]]. Action = [[ 0.03766171 -0.01354218  0.          0.53323567]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 1038 is [True, False, False, False, True, False]
State prediction error at timestep 1038 is 0.012
Current timestep = 1039. State = [[-0.11091799  0.07703191]]. Action = [[-0.00844985 -0.06800191  0.         -0.6106459 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 1039 is [True, False, False, False, True, False]
State prediction error at timestep 1039 is 0.012
Current timestep = 1040. State = [[-0.10785332  0.07146518]]. Action = [[ 0.05811655 -0.05851182  0.         -0.12160766]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 1040 is [True, False, False, False, True, False]
State prediction error at timestep 1040 is 0.012
Current timestep = 1041. State = [[-0.10869945  0.06671739]]. Action = [[-0.06372258 -0.04003153  0.          0.56736994]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 1041 is [True, False, False, False, True, False]
State prediction error at timestep 1041 is 0.012
Current timestep = 1042. State = [[-0.11262862  0.06096492]]. Action = [[-0.05953641 -0.07325477  0.          0.3312087 ]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 1042 is [True, False, False, False, True, False]
State prediction error at timestep 1042 is 0.012
Current timestep = 1043. State = [[-0.1130095  0.0586995]]. Action = [[ 0.01984215  0.01912104  0.         -0.55158883]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 1043 is [True, False, False, False, True, False]
State prediction error at timestep 1043 is 0.012
Current timestep = 1044. State = [[-0.10808548  0.06274994]]. Action = [[ 0.09985802  0.09805235  0.         -0.29405463]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 1044 is [True, False, False, False, True, False]
State prediction error at timestep 1044 is 0.012
Current timestep = 1045. State = [[-0.10492366  0.06229347]]. Action = [[ 0.02067767 -0.04399825  0.          0.9547901 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 1045 is [True, False, False, False, True, False]
State prediction error at timestep 1045 is 0.012
Current timestep = 1046. State = [[-0.1072356   0.05963225]]. Action = [[-0.05967481 -0.01327957  0.          0.19046116]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 1046 is [True, False, False, False, True, False]
State prediction error at timestep 1046 is 0.012
Current timestep = 1047. State = [[-0.10731847  0.05500591]]. Action = [[ 0.03068823 -0.07041498  0.         -0.0634523 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 1047 is [True, False, False, False, True, False]
State prediction error at timestep 1047 is 0.012
Current timestep = 1048. State = [[-0.10536672  0.049998  ]]. Action = [[ 0.02183378 -0.03973609  0.         -0.45328498]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 1048 is [True, False, False, False, True, False]
State prediction error at timestep 1048 is 0.012
Current timestep = 1049. State = [[-0.10069636  0.05166095]]. Action = [[0.08375234 0.08233904 0.         0.5564741 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 1049 is [True, False, False, False, True, False]
State prediction error at timestep 1049 is 0.012
Current timestep = 1050. State = [[-0.10070105  0.05124347]]. Action = [[-0.05101869 -0.03691415  0.          0.22185814]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 1050 is [True, False, False, False, True, False]
State prediction error at timestep 1050 is 0.012
Current timestep = 1051. State = [[-0.1015928  0.0470547]]. Action = [[ 0.00898547 -0.05141078  0.          0.99601007]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 1051 is [True, False, False, False, True, False]
State prediction error at timestep 1051 is 0.012
Current timestep = 1052. State = [[-0.10272072  0.04806157]]. Action = [[-0.02541732  0.06571389  0.         -0.66212404]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 1052 is [True, False, False, False, True, False]
State prediction error at timestep 1052 is 0.012
Current timestep = 1053. State = [[-0.10735261  0.04781778]]. Action = [[-0.07836245 -0.03584678  0.          0.6744528 ]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 1053 is [True, False, False, False, True, False]
State prediction error at timestep 1053 is 0.012
Current timestep = 1054. State = [[-0.10976775  0.0504407 ]]. Action = [[-0.0005331   0.07210588  0.         -0.01992548]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 1054 is [True, False, False, False, True, False]
State prediction error at timestep 1054 is 0.012
Current timestep = 1055. State = [[-0.11074518  0.05121381]]. Action = [[-0.00695431 -0.02911751  0.          0.3158083 ]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 1055 is [True, False, False, False, True, False]
State prediction error at timestep 1055 is 0.012
Current timestep = 1056. State = [[-0.10958435  0.05257226]]. Action = [[ 0.03859293  0.0391767   0.         -0.9458256 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 1056 is [True, False, False, False, True, False]
State prediction error at timestep 1056 is 0.012
Current timestep = 1057. State = [[-0.10454451  0.05407992]]. Action = [[0.09889691 0.00837018 0.         0.3293903 ]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 1057 is [True, False, False, False, True, False]
State prediction error at timestep 1057 is 0.012
Current timestep = 1058. State = [[-0.10422716  0.05120014]]. Action = [[-0.04780402 -0.06218441  0.         -0.4087019 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 1058 is [True, False, False, False, True, False]
State prediction error at timestep 1058 is 0.012
Current timestep = 1059. State = [[-0.10791817  0.05088525]]. Action = [[-0.04498581  0.03062291  0.         -0.12226999]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 1059 is [True, False, False, False, True, False]
State prediction error at timestep 1059 is 0.012
Current timestep = 1060. State = [[-0.11448519  0.05490728]]. Action = [[-0.09922152  0.05984075  0.          0.93935084]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 1060 is [True, False, False, False, True, False]
State prediction error at timestep 1060 is 0.012
Current timestep = 1061. State = [[-0.12080501  0.05904512]]. Action = [[-0.05823983  0.03245046  0.         -0.31689984]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 1061 is [True, False, False, False, True, False]
State prediction error at timestep 1061 is 0.012
Current timestep = 1062. State = [[-0.12664811  0.0567809 ]]. Action = [[-0.06791382 -0.08552685  0.         -0.10924006]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 1062 is [True, False, False, False, True, False]
State prediction error at timestep 1062 is 0.012
Current timestep = 1063. State = [[-0.13116942  0.05548143]]. Action = [[-0.03835889  0.00760498  0.          0.1677171 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 1063 is [True, False, False, False, True, False]
State prediction error at timestep 1063 is 0.012
Current timestep = 1064. State = [[-0.13462283  0.06091525]]. Action = [[-0.02342618  0.09562253  0.          0.474051  ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 1064 is [True, False, False, False, True, False]
State prediction error at timestep 1064 is 0.012
Current timestep = 1065. State = [[-0.13797767  0.06884538]]. Action = [[-0.01774765  0.08813121  0.          0.06256223]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 1065 is [True, False, False, False, True, False]
State prediction error at timestep 1065 is 0.012
Current timestep = 1066. State = [[-0.14095189  0.0739653 ]]. Action = [[-0.00803383  0.02822735  0.          0.4917779 ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 1066 is [True, False, False, False, True, False]
State prediction error at timestep 1066 is 0.012
Current timestep = 1067. State = [[-0.14585027  0.0791458 ]]. Action = [[-0.0532483   0.06201915  0.          0.33800828]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 1067 is [True, False, False, False, True, False]
State prediction error at timestep 1067 is 0.012
Current timestep = 1068. State = [[-0.15326993  0.08538495]]. Action = [[-0.07800195  0.05984048  0.         -0.40752316]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 1068 is [True, False, False, False, True, False]
State prediction error at timestep 1068 is 0.012
Current timestep = 1069. State = [[-0.15869851  0.08406187]]. Action = [[-0.02515301 -0.09613751  0.          0.06707072]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 1069 is [True, False, False, False, True, False]
State prediction error at timestep 1069 is 0.012
Current timestep = 1070. State = [[-0.15948486  0.0854499 ]]. Action = [[0.03605817 0.05909397 0.         0.61523676]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 1070 is [True, False, False, False, True, False]
State prediction error at timestep 1070 is 0.012
Current timestep = 1071. State = [[-0.15606615  0.09039073]]. Action = [[ 0.0924653   0.05312584  0.         -0.9475179 ]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 1071 is [True, False, False, False, True, False]
State prediction error at timestep 1071 is 0.012
Current timestep = 1072. State = [[-0.15472922  0.0946752 ]]. Action = [[0.01154344 0.04442147 0.         0.25357187]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 1072 is [True, False, False, False, True, False]
State prediction error at timestep 1072 is 0.012
Current timestep = 1073. State = [[-0.1524961  0.1004238]]. Action = [[0.06736618 0.07872456 0.         0.2754593 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 1073 is [True, False, False, False, True, False]
State prediction error at timestep 1073 is 0.012
Current timestep = 1074. State = [[-0.15121138  0.10386549]]. Action = [[0.01259811 0.01269738 0.         0.1009233 ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 1074 is [True, False, False, False, True, False]
State prediction error at timestep 1074 is 0.012
Current timestep = 1075. State = [[-0.15108037  0.1095544 ]]. Action = [[ 0.0107735   0.09123055  0.         -0.13697726]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 1075 is [True, False, False, False, True, False]
State prediction error at timestep 1075 is 0.012
Current timestep = 1076. State = [[-0.14858644  0.11448152]]. Action = [[0.05938841 0.0291119  0.         0.77140117]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 1076 is [True, False, False, False, True, False]
State prediction error at timestep 1076 is 0.012
Current timestep = 1077. State = [[-0.15118788  0.11793067]]. Action = [[-0.08621898  0.02688188  0.         -0.8619108 ]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 1077 is [True, False, False, False, True, False]
State prediction error at timestep 1077 is 0.012
Current timestep = 1078. State = [[-0.15801547  0.12475893]]. Action = [[-0.08683252  0.08754387  0.          0.14542413]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 1078 is [True, False, False, False, True, False]
State prediction error at timestep 1078 is 0.012
Current timestep = 1079. State = [[-0.16218255  0.12459401]]. Action = [[-0.02500013 -0.09717063  0.         -0.745737  ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 1079 is [True, False, False, False, True, False]
State prediction error at timestep 1079 is 0.012
Current timestep = 1080. State = [[-0.15895768  0.12535745]]. Action = [[ 0.09249695  0.03867587  0.         -0.38111818]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 1080 is [True, False, False, False, False, True]
State prediction error at timestep 1080 is 0.012
Current timestep = 1081. State = [[-0.15935944  0.12388514]]. Action = [[-0.07693987 -0.07844938  0.          0.26834846]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 1081 is [True, False, False, False, True, False]
State prediction error at timestep 1081 is 0.012
Current timestep = 1082. State = [[-0.15826969  0.12299705]]. Action = [[0.06343985 0.0085208  0.         0.05565238]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 1082 is [True, False, False, False, True, False]
State prediction error at timestep 1082 is 0.012
Current timestep = 1083. State = [[-0.15267438  0.12446817]]. Action = [[ 0.07603764  0.02106241  0.         -0.5194232 ]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 1083 is [True, False, False, False, True, False]
State prediction error at timestep 1083 is 0.012
Current timestep = 1084. State = [[-0.15329175  0.12092644]]. Action = [[-0.08025346 -0.09109644  0.         -0.26710796]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 1084 is [True, False, False, False, True, False]
State prediction error at timestep 1084 is 0.012
Current timestep = 1085. State = [[-0.15432993  0.1210277 ]]. Action = [[ 0.01770906  0.05353705  0.         -0.7641356 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 1085 is [True, False, False, False, True, False]
State prediction error at timestep 1085 is 0.012
Current timestep = 1086. State = [[-0.15808707  0.11951865]]. Action = [[-0.09100384 -0.06055483  0.         -0.80686355]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 1086 is [True, False, False, False, True, False]
State prediction error at timestep 1086 is 0.012
Current timestep = 1087. State = [[-0.16377765  0.11646593]]. Action = [[-0.06864703 -0.03243514  0.          0.4985633 ]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 1087 is [True, False, False, False, True, False]
State prediction error at timestep 1087 is 0.012
Current timestep = 1088. State = [[-0.16458805  0.1149055 ]]. Action = [[ 0.02999561 -0.00999061  0.          0.92235494]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 1088 is [True, False, False, False, True, False]
State prediction error at timestep 1088 is 0.012
Current timestep = 1089. State = [[-0.16844682  0.1115182 ]]. Action = [[-0.09123151 -0.05709622  0.         -0.7561028 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 1089 is [True, False, False, False, True, False]
State prediction error at timestep 1089 is 0.012
Current timestep = 1090. State = [[-0.17603569  0.10678233]]. Action = [[-0.0976013  -0.06005704  0.         -0.22185141]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 1090 is [True, False, False, False, True, False]
State prediction error at timestep 1090 is 0.012
Current timestep = 1091. State = [[-0.17836939  0.10821842]]. Action = [[0.03577938 0.07468306 0.         0.04578471]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 1091 is [True, False, False, False, True, False]
State prediction error at timestep 1091 is 0.012
Current timestep = 1092. State = [[-0.17895706  0.10517787]]. Action = [[-0.01110975 -0.09286748  0.          0.9041778 ]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 1092 is [True, False, False, False, True, False]
State prediction error at timestep 1092 is 0.012
Current timestep = 1093. State = [[-0.17813696  0.10052825]]. Action = [[ 0.03349041 -0.02681028  0.          0.29017448]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 1093 is [True, False, False, False, True, False]
State prediction error at timestep 1093 is 0.012
Current timestep = 1094. State = [[-0.17938331  0.1013985 ]]. Action = [[-0.0291583   0.05612025  0.          0.1264646 ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 1094 is [True, False, False, False, True, False]
State prediction error at timestep 1094 is 0.012
Current timestep = 1095. State = [[-0.17763416  0.10081613]]. Action = [[ 0.07225894 -0.02463444  0.          0.1765126 ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 1095 is [True, False, False, False, True, False]
State prediction error at timestep 1095 is 0.012
Current timestep = 1096. State = [[-0.17536385  0.09449801]]. Action = [[ 0.02088772 -0.09108654  0.         -0.5975807 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 1096 is [True, False, False, False, True, False]
State prediction error at timestep 1096 is 0.012
Current timestep = 1097. State = [[-0.17320335  0.09435517]]. Action = [[0.03884349 0.0787148  0.         0.54652596]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 1097 is [True, False, False, False, True, False]
State prediction error at timestep 1097 is 0.012
Current timestep = 1098. State = [[-0.17535962  0.09750772]]. Action = [[-0.05422202  0.0421676   0.          0.96172357]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 1098 is [True, False, False, False, True, False]
State prediction error at timestep 1098 is 0.012
Current timestep = 1099. State = [[-0.18017532  0.09450909]]. Action = [[-0.05876496 -0.07798339  0.          0.8623661 ]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 1099 is [True, False, False, False, True, False]
State prediction error at timestep 1099 is 0.012
Current timestep = 1100. State = [[-0.1850338   0.09366511]]. Action = [[-0.05779624  0.03173969  0.          0.4973917 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 1100 is [True, False, False, False, True, False]
State prediction error at timestep 1100 is 0.012
Current timestep = 1101. State = [[-0.1832579   0.09426772]]. Action = [[ 0.09027206  0.00228415  0.         -0.15932077]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 1101 is [True, False, False, False, True, False]
State prediction error at timestep 1101 is 0.012
Current timestep = 1102. State = [[-0.17980026  0.09030682]]. Action = [[ 0.03074531 -0.07073151  0.          0.4543202 ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 1102 is [True, False, False, False, True, False]
State prediction error at timestep 1102 is 0.012
Current timestep = 1103. State = [[-0.17619053  0.08479626]]. Action = [[ 0.05133448 -0.05467787  0.          0.4729458 ]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 1103 is [True, False, False, False, True, False]
State prediction error at timestep 1103 is 0.012
Current timestep = 1104. State = [[-0.1699646   0.07858681]]. Action = [[ 0.0881355  -0.06759397  0.         -0.03466082]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 1104 is [True, False, False, False, True, False]
State prediction error at timestep 1104 is 0.012
Current timestep = 1105. State = [[-0.16253975  0.07717094]]. Action = [[0.08728664 0.04501427 0.         0.41396368]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 1105 is [True, False, False, False, True, False]
State prediction error at timestep 1105 is 0.012
Current timestep = 1106. State = [[-0.16098255  0.07365623]]. Action = [[-0.04353527 -0.06529231  0.          0.97683465]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 1106 is [True, False, False, False, True, False]
State prediction error at timestep 1106 is 0.012
Current timestep = 1107. State = [[-0.16118972  0.0682261 ]]. Action = [[-0.00163966 -0.04632018  0.          0.2010014 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 1107 is [True, False, False, False, True, False]
State prediction error at timestep 1107 is 0.012
Current timestep = 1108. State = [[-0.16255511  0.06381464]]. Action = [[-0.04595179 -0.03363369  0.          0.6286193 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 1108 is [True, False, False, False, True, False]
State prediction error at timestep 1108 is 0.012
Current timestep = 1109. State = [[-0.16125287  0.06579705]]. Action = [[ 0.04011657  0.08569717  0.         -0.29200697]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 1109 is [True, False, False, False, True, False]
State prediction error at timestep 1109 is 0.012
Current timestep = 1110. State = [[-0.15636295  0.06237661]]. Action = [[ 0.07105752 -0.09536091  0.          0.05505395]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 1110 is [True, False, False, False, True, False]
State prediction error at timestep 1110 is 0.012
Current timestep = 1111. State = [[-0.15595858  0.058737  ]]. Action = [[-0.04949622  0.00357267  0.         -0.8297745 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 1111 is [True, False, False, False, True, False]
State prediction error at timestep 1111 is 0.012
Current timestep = 1112. State = [[-0.1575089   0.05513385]]. Action = [[-0.02182097 -0.0537909   0.          0.39956987]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 1112 is [True, False, False, False, True, False]
State prediction error at timestep 1112 is 0.012
Current timestep = 1113. State = [[-0.1589548   0.05188253]]. Action = [[-0.03127693 -0.01770736  0.          0.28102612]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 1113 is [True, False, False, False, True, False]
State prediction error at timestep 1113 is 0.012
Current timestep = 1114. State = [[-0.15952013  0.05539149]]. Action = [[-3.3889711e-04  9.6017815e-02  0.0000000e+00 -7.2028416e-01]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 1114 is [True, False, False, False, True, False]
State prediction error at timestep 1114 is 0.012
Current timestep = 1115. State = [[-0.15628448  0.05452622]]. Action = [[ 0.0705403  -0.06371776  0.         -0.64322686]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 1115 is [True, False, False, False, True, False]
State prediction error at timestep 1115 is 0.012
Current timestep = 1116. State = [[-0.14970808  0.04722841]]. Action = [[ 0.09413608 -0.09612605  0.         -0.5761867 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 1116 is [True, False, False, False, True, False]
State prediction error at timestep 1116 is 0.012
Current timestep = 1117. State = [[-0.14403746  0.04406952]]. Action = [[ 0.05263519  0.01932272  0.         -0.8410431 ]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 1117 is [True, False, False, False, True, False]
State prediction error at timestep 1117 is 0.012
Current timestep = 1118. State = [[-0.14334558  0.04301149]]. Action = [[-0.03061829 -0.00665709  0.         -0.6764481 ]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 1118 is [True, False, False, False, True, False]
State prediction error at timestep 1118 is 0.012
Current timestep = 1119. State = [[-0.13965634  0.04142392]]. Action = [[ 0.07936322 -0.00867285  0.         -0.27094448]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 1119 is [True, False, False, False, True, False]
State prediction error at timestep 1119 is 0.012
Current timestep = 1120. State = [[-0.14011072  0.04313385]]. Action = [[-0.07138537  0.05758248  0.         -0.56213   ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 1120 is [True, False, False, False, True, False]
State prediction error at timestep 1120 is 0.012
Current timestep = 1121. State = [[-0.14541595  0.04845327]]. Action = [[-0.07923868  0.0784171   0.          0.7685051 ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 1121 is [True, False, False, False, True, False]
State prediction error at timestep 1121 is 0.012
Current timestep = 1122. State = [[-0.14867729  0.05219546]]. Action = [[-0.01872879  0.01940761  0.         -0.6331923 ]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 1122 is [True, False, False, False, True, False]
State prediction error at timestep 1122 is 0.012
Current timestep = 1123. State = [[-0.15068917  0.05280355]]. Action = [[-0.0235596  -0.01566777  0.          0.5209148 ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 1123 is [True, False, False, False, True, False]
State prediction error at timestep 1123 is 0.012
Current timestep = 1124. State = [[-0.15083243  0.04978044]]. Action = [[ 0.01431645 -0.06595671  0.         -0.64963424]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 1124 is [True, False, False, False, True, False]
State prediction error at timestep 1124 is 0.012
Current timestep = 1125. State = [[-0.1531801   0.05122465]]. Action = [[-0.05302828  0.05865135  0.          0.1919713 ]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 1125 is [True, False, False, False, True, False]
State prediction error at timestep 1125 is 0.012
Current timestep = 1126. State = [[-0.15238938  0.05455569]]. Action = [[ 0.05706917  0.02305482  0.         -0.6911782 ]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 1126 is [True, False, False, False, True, False]
State prediction error at timestep 1126 is 0.012
Current timestep = 1127. State = [[-0.15571839  0.05963759]]. Action = [[-0.08954783  0.07420962  0.         -0.946771  ]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 1127 is [True, False, False, False, True, False]
State prediction error at timestep 1127 is 0.012
Current timestep = 1128. State = [[-0.16243327  0.06206665]]. Action = [[-0.07140861 -0.0160872   0.          0.27415884]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 1128 is [True, False, False, False, True, False]
State prediction error at timestep 1128 is 0.012
Current timestep = 1129. State = [[-0.16183497  0.06251433]]. Action = [[ 0.08051687 -0.00306795  0.         -0.6425678 ]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 1129 is [True, False, False, False, True, False]
State prediction error at timestep 1129 is 0.012
Current timestep = 1130. State = [[-0.16095556  0.05807082]]. Action = [[-0.01558075 -0.0989446   0.          0.7079396 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 1130 is [True, False, False, False, True, False]
State prediction error at timestep 1130 is 0.012
Current timestep = 1131. State = [[-0.16238551  0.05463962]]. Action = [[-0.02313057 -0.01685525  0.          0.60168076]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 1131 is [True, False, False, False, True, False]
State prediction error at timestep 1131 is 0.012
Current timestep = 1132. State = [[-0.1676314   0.05202588]]. Action = [[-0.09658629 -0.04293556  0.         -0.6546779 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 1132 is [True, False, False, False, True, False]
State prediction error at timestep 1132 is 0.012
Current timestep = 1133. State = [[-0.16950816  0.04993692]]. Action = [[ 0.01797029 -0.01677885  0.          0.25757754]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 1133 is [True, False, False, False, True, False]
State prediction error at timestep 1133 is 0.012
Current timestep = 1134. State = [[-0.16612983  0.04948385]]. Action = [[ 0.06729489  0.01073712  0.         -0.4664569 ]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 1134 is [True, False, False, False, True, False]
State prediction error at timestep 1134 is 0.012
Current timestep = 1135. State = [[-0.16637443  0.0527865 ]]. Action = [[-0.03340343  0.07269412  0.         -0.6715493 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 1135 is [True, False, False, False, True, False]
State prediction error at timestep 1135 is 0.012
Current timestep = 1136. State = [[-0.16981246  0.05442827]]. Action = [[-0.04082282 -0.00509984  0.          0.7397363 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 1136 is [True, False, False, False, True, False]
State prediction error at timestep 1136 is 0.012
Current timestep = 1137. State = [[-0.17358051  0.05626208]]. Action = [[-0.03996485  0.03758051  0.         -0.04586554]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 1137 is [True, False, False, False, True, False]
State prediction error at timestep 1137 is 0.012
Current timestep = 1138. State = [[-0.17139748  0.05302951]]. Action = [[ 0.08587527 -0.08662061  0.         -0.7593437 ]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 1138 is [True, False, False, False, True, False]
State prediction error at timestep 1138 is 0.012
Current timestep = 1139. State = [[-0.17179143  0.04684042]]. Action = [[-0.05228643 -0.06798575  0.          0.5707611 ]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 1139 is [True, False, False, False, True, False]
State prediction error at timestep 1139 is 0.012
Current timestep = 1140. State = [[-0.17660749  0.04417193]]. Action = [[-0.06898434 -0.00360665  0.          0.8766681 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 1140 is [True, False, False, False, True, False]
State prediction error at timestep 1140 is 0.012
Current timestep = 1141. State = [[-0.17467785  0.0452201 ]]. Action = [[ 0.09820833  0.03642366  0.         -0.66993695]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 1141 is [True, False, False, False, True, False]
State prediction error at timestep 1141 is 0.012
Current timestep = 1142. State = [[-0.17248842  0.04853642]]. Action = [[-2.4718046e-04  5.7755463e-02  0.0000000e+00  7.6931596e-01]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 1142 is [True, False, False, False, True, False]
State prediction error at timestep 1142 is 0.012
Current timestep = 1143. State = [[-0.1770894   0.05153024]]. Action = [[-0.09248409  0.02866315  0.          0.97019506]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 1143 is [True, False, False, False, True, False]
State prediction error at timestep 1143 is 0.012
Current timestep = 1144. State = [[-0.18259844  0.05498809]]. Action = [[-0.05250495  0.04391243  0.         -0.14698052]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 1144 is [True, False, False, False, True, False]
State prediction error at timestep 1144 is 0.012
Current timestep = 1145. State = [[-0.18382475  0.05885841]]. Action = [[ 0.02464922  0.03905082  0.         -0.9870381 ]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 1145 is [True, False, False, False, True, False]
State prediction error at timestep 1145 is 0.012
Current timestep = 1146. State = [[-0.18792872  0.06021097]]. Action = [[-0.07858235 -0.01227967  0.          0.17743301]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 1146 is [True, False, False, False, True, False]
State prediction error at timestep 1146 is 0.012
Current timestep = 1147. State = [[-0.19292197  0.057639  ]]. Action = [[-0.04224129 -0.06401781  0.         -0.159145  ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 1147 is [True, False, False, False, True, False]
State prediction error at timestep 1147 is 0.012
Current timestep = 1148. State = [[-0.1917813   0.05945991]]. Action = [[0.07245492 0.06373066 0.         0.77017283]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 1148 is [True, False, False, False, True, False]
State prediction error at timestep 1148 is 0.012
Current timestep = 1149. State = [[-0.19288018  0.05747197]]. Action = [[-0.04964813 -0.08396882  0.         -0.8095371 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 1149 is [True, False, False, False, True, False]
State prediction error at timestep 1149 is 0.012
Current timestep = 1150. State = [[-0.19799654  0.05686916]]. Action = [[-0.06646751  0.02832193  0.          0.03666735]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 1150 is [True, False, False, False, True, False]
State prediction error at timestep 1150 is 0.012
Current timestep = 1151. State = [[-0.19947374  0.05358283]]. Action = [[ 0.02355964 -0.08496461  0.         -0.15142047]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 1151 is [True, False, False, False, True, False]
State prediction error at timestep 1151 is 0.012
Current timestep = 1152. State = [[-0.19872345  0.04855361]]. Action = [[ 0.01373357 -0.04712833  0.          0.20297682]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 1152 is [True, False, False, False, True, False]
State prediction error at timestep 1152 is 0.012
Current timestep = 1153. State = [[-0.19675809  0.05080612]]. Action = [[ 0.04309995  0.08856457  0.         -0.69664544]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 1153 is [True, False, False, False, True, False]
State prediction error at timestep 1153 is 0.012
Current timestep = 1154. State = [[-0.19696233  0.05339608]]. Action = [[-0.01187576  0.01327537  0.          0.10056651]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 1154 is [True, False, False, False, True, False]
State prediction error at timestep 1154 is 0.012
Current timestep = 1155. State = [[-0.20149094  0.05842364]]. Action = [[-0.07057953  0.09523118  0.         -0.1659224 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 1155 is [True, False, False, False, True, False]
State prediction error at timestep 1155 is 0.012
Current timestep = 1156. State = [[-0.20350271  0.05948249]]. Action = [[ 0.01913317 -0.03857095  0.         -0.38425738]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 1156 is [True, False, False, False, True, False]
State prediction error at timestep 1156 is 0.012
Current timestep = 1157. State = [[-0.20632552  0.06294917]]. Action = [[-0.04825215  0.08423954  0.          0.59904563]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 1157 is [True, False, False, False, True, False]
State prediction error at timestep 1157 is 0.012
Current timestep = 1158. State = [[-0.204143    0.06430913]]. Action = [[ 0.09689566 -0.02903032  0.         -0.42680848]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 1158 is [True, False, False, False, True, False]
State prediction error at timestep 1158 is 0.012
Current timestep = 1159. State = [[-0.20412824  0.06585049]]. Action = [[-0.03931854  0.03910338  0.         -0.1568563 ]]. Reward = [0.]
