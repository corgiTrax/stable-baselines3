Current timestep = 0. State = [[-0.2581058   0.00795366]]. Action = [[-0.02517132 -0.00313229  0.08415417 -0.03610903]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is None
Current timestep = 1. State = [[-0.25782904  0.0078603 ]]. Action = [[ 0.01121883  0.03684529 -0.07181501 -0.24135602]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False]
State prediction error at timestep 1 is 0.012
Human Feedback received at timestep 1 of 1
Current timestep = 2. State = [[-0.25765866  0.00889681]]. Action = [[-0.06113325  0.04126974  0.03300034  0.97395396]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, True, False]
Current timestep = 3. State = [[-0.25805703  0.00984475]]. Action = [[-0.06263261  0.07551753 -0.02271957 -0.21903908]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, True, False]
State prediction error at timestep 3 is 0.012
Human Feedback received at timestep 3 of -1
Current timestep = 4. State = [[-0.26065645  0.0171612 ]]. Action = [[-0.02606332 -0.08540395 -0.09080984  0.91687274]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, True, False]
Current timestep = 5. State = [[-0.2608053   0.01598012]]. Action = [[-0.07761858  0.08164795 -0.07904283 -0.8448607 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, True, False]
Current timestep = 6. State = [[-0.2617475   0.01662461]]. Action = [[ 0.09810986 -0.04243719 -0.07681088 -0.2252906 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, True, False]
Current timestep = 7. State = [[-0.2618115   0.01649901]]. Action = [[-0.05269296  0.07933923 -0.05097861  0.7123525 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, True, False]
State prediction error at timestep 7 is 0.012
Human Feedback received at timestep 7 of -1
Current timestep = 8. State = [[-0.26321492  0.02004419]]. Action = [[ 0.0754961   0.04299169 -0.08663189 -0.08161724]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, True, False]
Current timestep = 9. State = [[-0.26332864  0.02048077]]. Action = [[-0.07022719 -0.05783322  0.0835178   0.24431825]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, True, False]
State prediction error at timestep 9 is 0.012
Human Feedback received at timestep 9 of -1
Current timestep = 10. State = [[-0.26355824  0.01929832]]. Action = [[ 0.06681105 -0.08201386 -0.0795724  -0.67114556]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, True, False]
State prediction error at timestep 10 is 0.012
Human Feedback received at timestep 10 of 1
Current timestep = 11. State = [[-0.2638602   0.01366271]]. Action = [[-0.00926805 -0.06453748  0.05081462 -0.9684069 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, True, False]
Current timestep = 12. State = [[-0.26388174  0.01216758]]. Action = [[-0.00988554 -0.09839112  0.08039667 -0.614913  ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, True, False]
State prediction error at timestep 12 is 0.012
Human Feedback received at timestep 12 of 1
Current timestep = 13. State = [[-0.26463702  0.00260299]]. Action = [[ 0.09057599 -0.05426887  0.07797232  0.24568582]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, True, False]
State prediction error at timestep 13 is 0.012
Human Feedback received at timestep 13 of -1
Current timestep = 14. State = [[-0.26389995 -0.00100626]]. Action = [[ 0.07226252  0.01412418 -0.09395985 -0.4160719 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, True, False]
Current timestep = 15. State = [[-0.26280788 -0.00100086]]. Action = [[-0.05909092 -0.05171558 -0.0525969   0.7692232 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, True, False]
Current timestep = 16. State = [[-0.26286778 -0.00171479]]. Action = [[-0.08847439  0.07359082 -0.01290637  0.7894316 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, True, False]
State prediction error at timestep 16 is 0.012
Human Feedback received at timestep 16 of -1
Current timestep = 17. State = [[-0.26338008 -0.00092808]]. Action = [[ 0.00787131  0.08607116 -0.07212043 -0.33679414]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, True, False]
Current timestep = 18. State = [[-0.26402766  0.00099056]]. Action = [[-0.03301679  0.08093991 -0.04848113 -0.731575  ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, True, False]
Current timestep = 19. State = [[-0.2649166   0.00377952]]. Action = [[ 0.00312903 -0.03759826  0.05114145 -0.25821555]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, True, False]
State prediction error at timestep 19 is 0.012
Human Feedback received at timestep 19 of -1
Current timestep = 20. State = [[-0.26586732  0.00653371]]. Action = [[ 0.0632496   0.05764089 -0.0382315   0.49787724]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, True, False]
Current timestep = 21. State = [[-0.266234   0.0074882]]. Action = [[ 0.05672931  0.00467298 -0.07356826  0.501621  ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, True, False]
Current timestep = 22. State = [[-0.2659159   0.00827378]]. Action = [[ 0.06753404  0.09819474  0.039411   -0.9514527 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [True, False, False, False, True, False]
Current timestep = 23. State = [[-0.2650686   0.01090382]]. Action = [[-0.02280841  0.06887992  0.05683497  0.03624845]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [True, False, False, False, True, False]
State prediction error at timestep 23 is 0.012
Human Feedback received at timestep 23 of 1
Current timestep = 24. State = [[-0.26378274  0.02049451]]. Action = [[ 0.03349089  0.09955809  0.05350745 -0.682824  ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [True, False, False, False, True, False]
Current timestep = 25. State = [[-0.26366684  0.0229859 ]]. Action = [[-0.0462237  -0.08078437  0.09888066  0.63734305]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [True, False, False, False, True, False]
Current timestep = 26. State = [[-0.26381177  0.02321555]]. Action = [[ 0.04534339  0.01859118 -0.00705447 -0.01341397]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [True, False, False, False, True, False]
State prediction error at timestep 26 is 0.012
Human Feedback received at timestep 26 of 1
Current timestep = 27. State = [[-0.26231018  0.0236569 ]]. Action = [[-0.05272523 -0.06325215  0.00538734 -0.01878482]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [True, False, False, False, True, False]
State prediction error at timestep 27 is 0.012
Human Feedback received at timestep 27 of 1
Current timestep = 28. State = [[-0.2622924   0.02361124]]. Action = [[-7.3070809e-02  1.4945790e-02 -7.2551519e-04 -9.1120285e-01]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [True, False, False, False, True, False]
Current timestep = 29. State = [[-0.26233083  0.02364641]]. Action = [[ 0.05071848  0.05536649 -0.01994523 -0.4208697 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [True, False, False, False, True, False]
Current timestep = 30. State = [[-0.2625117   0.02409923]]. Action = [[-0.01370352  0.06336819 -0.09457915 -0.95380545]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [True, False, False, False, True, False]
Current timestep = 31. State = [[-0.26316825  0.02575057]]. Action = [[-0.02395083  0.01285665 -0.02076205  0.84736323]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [True, False, False, False, True, False]
Current timestep = 32. State = [[-0.263877    0.02757211]]. Action = [[ 4.3716282e-04 -7.0835866e-02 -7.5898826e-02 -4.9097490e-01]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [True, False, False, False, True, False]
Current timestep = 33. State = [[-0.26389533  0.02744021]]. Action = [[-0.07968862 -0.07912775  0.08637451 -0.9374181 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [True, False, False, False, True, False]
Current timestep = 34. State = [[-0.26377517  0.0266387 ]]. Action = [[ 0.0229729   0.01553579 -0.09458311  0.09854746]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [True, False, False, False, True, False]
Current timestep = 35. State = [[-0.26390293  0.02638958]]. Action = [[-0.02379552 -0.03595639  0.03375626  0.6699455 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [True, False, False, False, True, False]
Current timestep = 36. State = [[-0.26396692  0.02560393]]. Action = [[ 0.09312334 -0.00839349  0.06660537  0.02484822]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [True, False, False, False, True, False]
Current timestep = 37. State = [[-0.26388547  0.02476004]]. Action = [[ 0.0663007  -0.04746206  0.0988551   0.314659  ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [True, False, False, False, True, False]
Current timestep = 38. State = [[-0.26329866  0.02319738]]. Action = [[-0.03301517 -0.06903735 -0.06527947 -0.56067777]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [True, False, False, False, True, False]
Current timestep = 39. State = [[-0.2629423   0.02068032]]. Action = [[-0.02143808 -0.03881108 -0.03790156  0.5556381 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [True, False, False, False, True, False]
Current timestep = 40. State = [[-0.26306006  0.01844776]]. Action = [[-0.09060122  0.09276371 -0.07957199  0.32077074]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [True, False, False, False, True, False]
Current timestep = 41. State = [[-0.26333496  0.01830634]]. Action = [[ 0.04349054 -0.03881253  0.08305307 -0.17703742]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [True, False, False, False, True, False]
State prediction error at timestep 41 is 0.012
Human Feedback received at timestep 41 of -1
Current timestep = 42. State = [[-0.26351047  0.01548766]]. Action = [[-0.03742965  0.00716915  0.0617476   0.46081853]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [True, False, False, False, True, False]
State prediction error at timestep 42 is 0.012
Human Feedback received at timestep 42 of -1
Current timestep = 43. State = [[-0.26354453  0.01557916]]. Action = [[ 0.06237604  0.05458137  0.02491368 -0.7390872 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [True, False, False, False, True, False]
Current timestep = 44. State = [[-0.26374185  0.01619983]]. Action = [[-0.00907054  0.07323664  0.05582912 -0.0730992 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [True, False, False, False, True, False]
State prediction error at timestep 44 is 0.012
Human Feedback received at timestep 44 of -1
Current timestep = 45. State = [[-0.26503247  0.02026362]]. Action = [[ 0.04537082 -0.01607694  0.02252619 -0.51758724]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [True, False, False, False, True, False]
State prediction error at timestep 45 is 0.012
Human Feedback received at timestep 45 of -1
Current timestep = 46. State = [[-0.264965    0.02056025]]. Action = [[0.03811892 0.04228497 0.09190296 0.02757192]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [True, False, False, False, True, False]
State prediction error at timestep 46 is 0.012
Human Feedback received at timestep 46 of -1
Current timestep = 47. State = [[-0.26487964  0.02122455]]. Action = [[-0.01317835 -0.02618026  0.0384618   0.755185  ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [True, False, False, False, True, False]
Current timestep = 48. State = [[-0.2648764   0.02128066]]. Action = [[-0.04631549  0.02226819 -0.08048056  0.37288344]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [True, False, False, False, True, False]
Current timestep = 49. State = [[-0.26487318  0.02133678]]. Action = [[ 0.04538212  0.03099369 -0.08087294  0.8847685 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [True, False, False, False, True, False]
Current timestep = 50. State = [[-0.26500347  0.02166525]]. Action = [[-0.03130955 -0.08020533 -0.04806885 -0.02700591]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [True, False, False, False, True, False]
Current timestep = 51. State = [[-0.26499346  0.02171154]]. Action = [[ 0.08275392  0.09060951 -0.01434544  0.1242373 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 51 is [True, False, False, False, True, False]
State prediction error at timestep 51 is 0.012
Human Feedback received at timestep 51 of 1
Current timestep = 52. State = [[-0.26190302  0.02356149]]. Action = [[ 0.07275843 -0.08305749  0.07526415  0.5712166 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 52 is [True, False, False, False, True, False]
Current timestep = 53. State = [[-0.26051247  0.02338912]]. Action = [[-0.04576635 -0.02269816 -0.0494803  -0.8974389 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 53 is [True, False, False, False, True, False]
Current timestep = 54. State = [[-0.25970602  0.02304825]]. Action = [[-0.04895029 -0.08923292  0.08332331  0.16367233]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 54 is [True, False, False, False, True, False]
Current timestep = 55. State = [[-0.2592758   0.02073281]]. Action = [[-0.03475114 -0.07091607 -0.03284355  0.7207265 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 55 is [True, False, False, False, True, False]
Current timestep = 56. State = [[-0.25911918  0.01790845]]. Action = [[ 0.02381404  0.04445919 -0.05927184  0.91396666]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 56 is [True, False, False, False, True, False]
State prediction error at timestep 56 is 0.012
Human Feedback received at timestep 56 of -1
Current timestep = 57. State = [[-0.25938982  0.01429841]]. Action = [[ 0.09283268 -0.06270957  0.09320115 -0.27012765]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 57 is [True, False, False, False, True, False]
Current timestep = 58. State = [[-0.25844994  0.01304682]]. Action = [[-0.00675305 -0.07176851 -0.03619952  0.02913284]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 58 is [True, False, False, False, True, False]
State prediction error at timestep 58 is 0.012
Human Feedback received at timestep 58 of 1
Current timestep = 59. State = [[-0.25694534  0.00635275]]. Action = [[-0.08985103  0.09186571  0.01365498 -0.01006943]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 59 is [True, False, False, False, True, False]
Current timestep = 60. State = [[-0.25734794  0.0073823 ]]. Action = [[ 0.03257651  0.06013202 -0.01982924  0.36233544]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 60 is [True, False, False, False, True, False]
Current timestep = 61. State = [[-0.2576544   0.00860388]]. Action = [[ 0.08748408 -0.0035544   0.04789095  0.6086904 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 61 is [True, False, False, False, True, False]
Current timestep = 62. State = [[-0.25727132  0.00909249]]. Action = [[-0.0061772  -0.06493673 -0.0312747  -0.59949154]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 62 is [True, False, False, False, True, False]
Current timestep = 63. State = [[-0.25710988  0.00894443]]. Action = [[ 0.03622233  0.06289604  0.06601017 -0.9037737 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 63 is [True, False, False, False, True, False]
Current timestep = 64. State = [[-0.25647837  0.00935258]]. Action = [[-0.0444268   0.00884514 -0.09802714 -0.55001134]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 64 is [True, False, False, False, True, False]
Current timestep = 65. State = [[-0.2564516   0.00975486]]. Action = [[-0.07457881  0.00533535  0.06909239 -0.73126566]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 65 is [True, False, False, False, True, False]
Current timestep = 66. State = [[-0.25662997  0.01016981]]. Action = [[ 0.02870005 -0.06568596 -0.09837475 -0.78596085]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 66 is [True, False, False, False, True, False]
State prediction error at timestep 66 is 0.012
Human Feedback received at timestep 66 of 1
Current timestep = 67. State = [[-0.25654984  0.00988537]]. Action = [[ 0.09941655 -0.03260429  0.0816211   0.7270007 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 67 is [True, False, False, False, True, False]
State prediction error at timestep 67 is 0.012
Human Feedback received at timestep 67 of -1
Current timestep = 68. State = [[-0.252715    0.00929323]]. Action = [[0.0126427  0.08787294 0.07834474 0.43771553]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 68 is [True, False, False, False, True, False]
Current timestep = 69. State = [[-0.2522904   0.00982045]]. Action = [[-0.08297069 -0.05488757  0.05622382  0.3013432 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 69 is [True, False, False, False, True, False]
Current timestep = 70. State = [[-0.25232837  0.00974788]]. Action = [[-0.01454542 -0.02396128 -0.07411633  0.02888215]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 70 is [True, False, False, False, True, False]
State prediction error at timestep 70 is 0.012
Human Feedback received at timestep 70 of -1
Current timestep = 71. State = [[-0.2525895   0.00936025]]. Action = [[ 0.00488553 -0.00518494  0.036042   -0.54344183]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 71 is [True, False, False, False, True, False]
Current timestep = 72. State = [[-0.25257507  0.0092597 ]]. Action = [[-0.06774455 -0.02733359 -0.00795063  0.9019809 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 72 is [True, False, False, False, True, False]
Current timestep = 73. State = [[-0.25264055  0.00865634]]. Action = [[ 0.01881512  0.09733189  0.04219944 -0.14095664]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 73 is [True, False, False, False, True, False]
Current timestep = 74. State = [[-0.25292003  0.00952486]]. Action = [[-0.01836509 -0.0853783   0.02358713 -0.5593137 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 74 is [True, False, False, False, True, False]
Current timestep = 75. State = [[-0.25287682  0.00897776]]. Action = [[-0.04543436 -0.07269826  0.09658947 -0.39439988]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 75 is [True, False, False, False, True, False]
Current timestep = 76. State = [[-0.25289634  0.00713673]]. Action = [[-3.7618410e-02  1.8163025e-04 -4.0399708e-02  7.1356511e-01]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 76 is [True, False, False, False, True, False]
Current timestep = 77. State = [[-0.2532721   0.00611864]]. Action = [[-0.01348653 -0.07660855 -0.0293747  -0.311545  ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 77 is [True, False, False, False, True, False]
Current timestep = 78. State = [[-0.25392187  0.00343703]]. Action = [[ 0.0088176  -0.09705828  0.04007175  0.51455307]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 78 is [True, False, False, False, True, False]
Current timestep = 79. State = [[-0.25430158 -0.00084608]]. Action = [[-0.08410595 -0.05526781 -0.08487031 -0.64967614]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 79 is [True, False, False, False, True, False]
State prediction error at timestep 79 is 0.012
Human Feedback received at timestep 79 of -1
Current timestep = 80. State = [[-0.26051775 -0.01413022]]. Action = [[-0.00273821 -0.06441283 -0.0241676  -0.23225856]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 80 is [True, False, False, False, True, False]
Current timestep = 81. State = [[-0.26077253 -0.01558851]]. Action = [[ 0.0523889  -0.02938996 -0.06605877 -0.47577   ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 81 is [True, False, False, False, True, False]
Current timestep = 82. State = [[-0.26108095 -0.01672152]]. Action = [[-0.08084679  0.09289929 -0.05120718 -0.83660877]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 82 is [True, False, False, False, True, False]
Current timestep = 83. State = [[-0.26175883 -0.01615531]]. Action = [[ 0.09557936  0.0084514   0.03005014 -0.7967107 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 83 is [True, False, False, False, True, False]
Current timestep = 84. State = [[-0.261762   -0.01589509]]. Action = [[ 1.0477938e-02 -7.7143312e-04 -8.6157724e-02 -9.0358460e-01]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 84 is [True, False, False, False, True, False]
Current timestep = 85. State = [[-0.2616333  -0.01588614]]. Action = [[ 0.03765007  0.03227519 -0.03392147 -0.30874026]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 85 is [True, False, False, False, True, False]
State prediction error at timestep 85 is 0.012
Human Feedback received at timestep 85 of -1
Current timestep = 86. State = [[-0.261453   -0.01432521]]. Action = [[-0.01675708 -0.05415622  0.066994   -0.28540534]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 86 is [True, False, False, False, True, False]
Current timestep = 87. State = [[-0.26148692 -0.01471186]]. Action = [[-0.05287606 -0.01641592  0.01526015 -0.12867564]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 87 is [True, False, False, False, True, False]
Current timestep = 88. State = [[-0.26155302 -0.01532406]]. Action = [[-0.00321083 -0.00711001 -0.05035846  0.3568728 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 88 is [True, False, False, False, True, False]
State prediction error at timestep 88 is 0.012
Human Feedback received at timestep 88 of -1
Current timestep = 89. State = [[-0.26169798 -0.01657964]]. Action = [[-5.0467383e-02 -9.0453409e-02  3.1928718e-04  9.8299289e-01]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 89 is [True, False, False, False, True, False]
State prediction error at timestep 89 is 0.012
Human Feedback received at timestep 89 of -1
Current timestep = 90. State = [[-0.26280114 -0.02275156]]. Action = [[-0.06923585  0.08169415 -0.01754173  0.30456305]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 90 is [True, False, False, False, True, False]
State prediction error at timestep 90 is 0.012
Human Feedback received at timestep 90 of -1
Current timestep = 91. State = [[-0.2660903 -0.02015  ]]. Action = [[-0.0972987   0.05307455 -0.09755058 -0.79303753]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 91 is [True, False, False, False, True, False]
Current timestep = 92. State = [[-0.26725054 -0.01893418]]. Action = [[ 0.02130534 -0.06689826  0.01533963 -0.19529057]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 92 is [True, False, False, False, True, False]
Current timestep = 93. State = [[-0.2679993  -0.01918527]]. Action = [[ 0.0036811   0.06034426 -0.0312944   0.37502968]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 93 is [True, False, False, False, True, False]
Current timestep = 94. State = [[-0.26866177 -0.01850113]]. Action = [[0.03166024 0.00575425 0.01886453 0.10213578]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 94 is [True, False, False, False, True, False]
State prediction error at timestep 94 is 0.012
Human Feedback received at timestep 94 of -1
Current timestep = 95. State = [[-0.26910198 -0.01721153]]. Action = [[-0.02989867  0.04017638 -0.06231183 -0.81921107]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 95 is [True, False, False, False, True, False]
Current timestep = 96. State = [[-0.2694432  -0.01630688]]. Action = [[-0.00971439  0.0301424  -0.07408705 -0.04370892]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 96 is [True, False, False, False, True, False]
Current timestep = 97. State = [[-0.26993415 -0.01497491]]. Action = [[ 0.0807774   0.04114463  0.08333304 -0.6593675 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 97 is [True, False, False, False, True, False]
Current timestep = 98. State = [[-0.2704429  -0.01325368]]. Action = [[-0.03965494  0.01769154  0.01191881  0.92147255]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 98 is [True, False, False, False, True, False]
Current timestep = 99. State = [[-0.2709194  -0.01156569]]. Action = [[-0.03942654  0.02698264 -0.08467113 -0.16999316]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 99 is [True, False, False, False, True, False]
Current timestep = 100. State = [[-0.27157363 -0.00980769]]. Action = [[-0.06031826 -0.08776253 -0.00947938  0.11940181]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 100 is [True, False, False, False, True, False]
State prediction error at timestep 100 is 0.012
Human Feedback received at timestep 100 of -1
Current timestep = 101. State = [[-0.27375352 -0.01034378]]. Action = [[-0.09161872 -0.01099446  0.04641641  0.28773856]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 101 is [True, False, False, False, True, False]
Current timestep = 102. State = [[-0.27460805 -0.01035011]]. Action = [[0.03710111 0.04353496 0.02696779 0.2768674 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 102 is [True, False, False, False, True, False]
Current timestep = 103. State = [[-0.27520645 -0.00974652]]. Action = [[ 0.08918381 -0.00831923 -0.08352672 -0.28873467]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 103 is [True, False, False, False, True, False]
Current timestep = 104. State = [[-0.27504504 -0.0097032 ]]. Action = [[-0.04273349 -0.04148028  0.08754414 -0.7239744 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 104 is [True, False, False, False, True, False]
Current timestep = 105. State = [[-0.27514005 -0.01023513]]. Action = [[-0.01482176 -0.03528193 -0.02799021 -0.9768368 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 105 is [True, False, False, False, True, False]
Current timestep = 106. State = [[-0.27536434 -0.01129874]]. Action = [[ 0.08357575 -0.01348406  0.08208784 -0.11461991]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 106 is [True, False, False, False, True, False]
State prediction error at timestep 106 is 0.012
Human Feedback received at timestep 106 of -1
Current timestep = 107. State = [[-0.27572477 -0.01340173]]. Action = [[-0.01091077 -0.00968432  0.08984665 -0.08456141]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 107 is [True, False, False, False, True, False]
Current timestep = 108. State = [[-0.2757561  -0.01362328]]. Action = [[-0.01592769 -0.02231164 -0.00850479 -0.52216256]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 108 is [True, False, False, False, True, False]
Current timestep = 109. State = [[-0.2758064  -0.01395746]]. Action = [[ 0.058874    0.04144724 -0.0447047  -0.8177222 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 109 is [True, False, False, False, True, False]
Current timestep = 110. State = [[-0.27573565 -0.01378802]]. Action = [[ 0.08087202  0.00300796  0.06354868 -0.9461646 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 110 is [True, False, False, False, True, False]
Current timestep = 111. State = [[-0.27532098 -0.01353544]]. Action = [[ 0.08202185  0.07949492 -0.05382702  0.9906614 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 111 is [True, False, False, False, True, False]
Current timestep = 112. State = [[-0.274595   -0.01254986]]. Action = [[ 0.08528724 -0.01235012  0.06995175 -0.96350336]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 112 is [True, False, False, False, True, False]
Current timestep = 113. State = [[-0.27255434 -0.01198868]]. Action = [[-0.07417892  0.0336945   0.06228643  0.84478045]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 113 is [True, False, False, False, True, False]
State prediction error at timestep 113 is 0.012
Human Feedback received at timestep 113 of -1
Current timestep = 114. State = [[-0.27216366 -0.01016454]]. Action = [[ 0.06916561  0.0973826  -0.03375982  0.2454791 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 114 is [True, False, False, False, True, False]
Current timestep = 115. State = [[-0.27111614 -0.00820218]]. Action = [[-0.01158882  0.08103619  0.08105295 -0.38037252]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 115 is [True, False, False, False, True, False]
Current timestep = 116. State = [[-0.27063873 -0.00490135]]. Action = [[ 0.03212031 -0.03029605 -0.07179489  0.67524683]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 116 is [True, False, False, False, True, False]
Current timestep = 117. State = [[-0.26986536 -0.00367065]]. Action = [[0.05970105 0.08509628 0.01517849 0.4118315 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 117 is [True, False, False, False, True, False]
Current timestep = 118. State = [[-0.26778185 -0.00079343]]. Action = [[-0.00548008  0.03136968  0.09019355  0.8506783 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 118 is [True, False, False, False, True, False]
Current timestep = 119. State = [[-0.26599416  0.00191336]]. Action = [[ 0.07496005  0.0512901   0.06044472 -0.5467224 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 119 is [True, False, False, False, True, False]
State prediction error at timestep 119 is 0.012
Human Feedback received at timestep 119 of 1
Current timestep = 120. State = [[-0.25661877  0.00946517]]. Action = [[ 0.01337998 -0.0130128  -0.07320319 -0.27900124]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 120 is [True, False, False, False, True, False]
Current timestep = 121. State = [[-0.25654694  0.00956801]]. Action = [[-0.07190643  0.06262528  0.08503192 -0.14114434]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 121 is [True, False, False, False, True, False]
Current timestep = 122. State = [[-0.2569014   0.01118537]]. Action = [[ 0.08701735 -0.01347913 -0.01041719  0.5711534 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 122 is [True, False, False, False, True, False]
Current timestep = 123. State = [[-0.2561445   0.01193998]]. Action = [[-0.01879687 -0.03573602  0.01343177  0.10692334]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 123 is [True, False, False, False, True, False]
Current timestep = 124. State = [[-0.256078    0.01194184]]. Action = [[ 0.01601466 -0.02323282  0.05927012  0.21763086]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 124 is [True, False, False, False, True, False]
State prediction error at timestep 124 is 0.012
Human Feedback received at timestep 124 of 1
Current timestep = 125. State = [[-0.25557628  0.01214342]]. Action = [[-0.07914612  0.01010527 -0.01630551 -0.05132365]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 125 is [True, False, False, False, True, False]
Current timestep = 126. State = [[-0.25557184  0.01220152]]. Action = [[ 0.06825583 -0.00703262  0.04944303 -0.04624939]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 126 is [True, False, False, False, True, False]
State prediction error at timestep 126 is 0.012
Human Feedback received at timestep 126 of 1
Current timestep = 127. State = [[-0.25556746  0.01225922]]. Action = [[-0.04754002  0.00680681 -0.01599861  0.01879144]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 127 is [True, False, False, False, True, False]
Current timestep = 128. State = [[-0.25559708  0.01233649]]. Action = [[-0.09623236  0.02034541 -0.01810242  0.18736851]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 128 is [True, False, False, False, True, False]
Current timestep = 129. State = [[-0.25585383  0.01277369]]. Action = [[-0.09710603  0.07774549 -0.08365448 -0.909334  ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 129 is [True, False, False, False, True, False]
Current timestep = 130. State = [[-0.25728324  0.01502052]]. Action = [[-0.0848588  -0.08023626  0.01014981  0.97973585]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 130 is [True, False, False, False, True, False]
Current timestep = 131. State = [[-0.25885865  0.01544847]]. Action = [[ 0.02452739  0.08706162  0.05962651 -0.33817333]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 131 is [True, False, False, False, True, False]
State prediction error at timestep 131 is 0.012
Human Feedback received at timestep 131 of -1
Current timestep = 132. State = [[-0.261739    0.02089668]]. Action = [[-1.5713274e-04 -7.2476134e-02 -2.7982354e-02 -9.3395925e-01]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 132 is [True, False, False, False, True, False]
Current timestep = 133. State = [[-0.26200897  0.01972488]]. Action = [[ 0.01759513 -0.06927857  0.01507185  0.3322369 ]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 133 is [True, False, False, False, True, False]
Current timestep = 134. State = [[-0.26203305  0.01746541]]. Action = [[ 0.08368777 -0.08932294 -0.02894814 -0.1830532 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 134 is [True, False, False, False, True, False]
State prediction error at timestep 134 is 0.012
Human Feedback received at timestep 134 of -1
Current timestep = 135. State = [[-0.2618111   0.00958394]]. Action = [[-0.04159392  0.02638268 -0.0351847  -0.263579  ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 135 is [True, False, False, False, True, False]
Current timestep = 136. State = [[-0.2618227   0.00968698]]. Action = [[ 0.04214465 -0.01857676  0.0467592  -0.5455249 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 136 is [True, False, False, False, True, False]
State prediction error at timestep 136 is 0.012
Human Feedback received at timestep 136 of -1
Current timestep = 137. State = [[-0.26178998  0.0092816 ]]. Action = [[ 0.04537598  0.04021681 -0.09451013 -0.8251441 ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 137 is [True, False, False, False, True, False]
Current timestep = 138. State = [[-0.26177368  0.00923589]]. Action = [[-0.00896082 -0.08648797  0.0059223  -0.6011182 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 138 is [True, False, False, False, True, False]
Current timestep = 139. State = [[-0.26134533  0.0083147 ]]. Action = [[ 0.00144257 -0.09740138 -0.08489161  0.4732709 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 139 is [True, False, False, False, True, False]
State prediction error at timestep 139 is 0.012
Human Feedback received at timestep 139 of 1
Current timestep = 140. State = [[-0.2598423  0.0006426]]. Action = [[ 0.0879296   0.06759537 -0.04926252  0.75975275]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 140 is [True, False, False, False, True, False]
Current timestep = 141. State = [[-0.25958472  0.00125335]]. Action = [[ 0.04135331  0.09023546 -0.01241406 -0.06988275]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 141 is [True, False, False, False, True, False]
Current timestep = 142. State = [[-0.25918642  0.0029333 ]]. Action = [[-0.02416668  0.06962629  0.05774819  0.17399645]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 142 is [True, False, False, False, True, False]
Current timestep = 143. State = [[-0.2593      0.00543642]]. Action = [[ 0.04110511  0.09079217 -0.08798521 -0.52428895]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 143 is [True, False, False, False, True, False]
Current timestep = 144. State = [[-0.25854445  0.0086066 ]]. Action = [[ 0.06174278 -0.00877477 -0.0686432  -0.70893675]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 144 is [True, False, False, False, True, False]
Current timestep = 145. State = [[-0.2568906   0.01065413]]. Action = [[ 0.08646726 -0.02543203 -0.01597602  0.4767716 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 145 is [True, False, False, False, True, False]
State prediction error at timestep 145 is 0.012
Human Feedback received at timestep 145 of 1
Current timestep = 146. State = [[-0.24953544  0.01241663]]. Action = [[ 0.00307836 -0.03747223 -0.05400804  0.24625003]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 146 is [True, False, False, False, True, False]
Current timestep = 147. State = [[-0.24951118  0.01243018]]. Action = [[-0.07419313  0.01984207  0.0421484  -0.9420088 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 147 is [True, False, False, False, True, False]
Current timestep = 148. State = [[-0.24952456  0.01246173]]. Action = [[-0.02395105  0.01243401 -0.06443793 -0.21106172]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 148 is [True, False, False, False, True, False]
State prediction error at timestep 148 is 0.012
Human Feedback received at timestep 148 of 1
Current timestep = 149. State = [[-0.24979599  0.01310481]]. Action = [[-0.01996619  0.07638253  0.06264653 -0.31137848]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 149 is [True, False, False, False, True, False]
Current timestep = 150. State = [[-0.25024828  0.01471426]]. Action = [[ 0.00639953 -0.04726395 -0.02848524 -0.23423773]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 150 is [True, False, False, False, True, False]
Current timestep = 151. State = [[-0.25034404  0.01512134]]. Action = [[-0.03535977  0.077981    0.01392361 -0.5698542 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 151 is [True, False, False, False, True, False]
Current timestep = 152. State = [[-0.25088978  0.01669809]]. Action = [[-0.08546834 -0.04167936  0.08332638 -0.30824268]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 152 is [True, False, False, False, True, False]
Current timestep = 153. State = [[-0.2512204   0.01733898]]. Action = [[-0.01909339 -0.05993737 -0.02686805 -0.49667573]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 153 is [True, False, False, False, True, False]
Current timestep = 154. State = [[-0.2512168   0.01706611]]. Action = [[-0.01765736 -0.09105944  0.08477192  0.677847  ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 154 is [True, False, False, False, True, False]
State prediction error at timestep 154 is 0.012
Human Feedback received at timestep 154 of -1
Current timestep = 155. State = [[-0.2523749   0.01251765]]. Action = [[-0.06454287 -0.02857007 -0.08038177 -0.58711743]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 155 is [True, False, False, False, True, False]
State prediction error at timestep 155 is 0.012
Human Feedback received at timestep 155 of -1
Current timestep = 156. State = [[-0.2560611   0.00976148]]. Action = [[ 0.09631538 -0.06606284  0.08758994  0.2608112 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 156 is [True, False, False, False, True, False]
Current timestep = 157. State = [[-0.25592744  0.00870039]]. Action = [[-0.05680401 -0.06990388 -0.05040084  0.16281736]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 157 is [True, False, False, False, True, False]
Current timestep = 158. State = [[-0.25593632  0.00605068]]. Action = [[-0.01908929 -0.07745232  0.073628   -0.32034814]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 158 is [True, False, False, False, True, False]
State prediction error at timestep 158 is 0.012
Human Feedback received at timestep 158 of -1
Current timestep = 159. State = [[-0.25676584 -0.00350093]]. Action = [[ 0.08050441 -0.07333989 -0.03609399  0.94406533]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 159 is [True, False, False, False, True, False]
State prediction error at timestep 159 is 0.012
Human Feedback received at timestep 159 of 1
Current timestep = 160. State = [[-0.255971   -0.00770808]]. Action = [[ 0.02443065 -0.00784156  0.02658243 -0.8740796 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 160 is [True, False, False, False, True, False]
State prediction error at timestep 160 is 0.012
Human Feedback received at timestep 160 of 1
Current timestep = 161. State = [[-0.25550422 -0.00850072]]. Action = [[0.07942613 0.03452214 0.06676128 0.36968005]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 161 is [True, False, False, False, True, False]
Current timestep = 162. State = [[-0.25516313 -0.00836428]]. Action = [[-0.00881167 -0.00804116  0.04567108 -0.33206046]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 162 is [True, False, False, False, True, False]
State prediction error at timestep 162 is 0.012
Human Feedback received at timestep 162 of 1
Current timestep = 163. State = [[-0.25334743 -0.0074785 ]]. Action = [[-0.03323823  0.05922397 -0.0702532   0.6142738 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 163 is [True, False, False, False, True, False]
Current timestep = 164. State = [[-0.25343147 -0.00721069]]. Action = [[ 0.03466316  0.0387822  -0.08805623 -0.14046508]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 164 is [True, False, False, False, True, False]
Current timestep = 165. State = [[-0.25340578 -0.00661014]]. Action = [[ 0.09909924  0.05962933 -0.06600879 -0.28255308]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 165 is [True, False, False, False, True, False]
State prediction error at timestep 165 is 0.012
Human Feedback received at timestep 165 of 1
Current timestep = 166. State = [[-0.25176996 -0.00301712]]. Action = [[ 0.03544044  0.01555784  0.01475412 -0.71008694]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 166 is [True, False, False, False, True, False]
State prediction error at timestep 166 is 0.012
Human Feedback received at timestep 166 of 1
Current timestep = 167. State = [[-0.2504631  -0.00134253]]. Action = [[ 0.06100287 -0.01755409 -0.08310144 -0.9477239 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 167 is [True, False, False, False, True, False]
Current timestep = 168. State = [[-0.24922791 -0.00104427]]. Action = [[ 0.05557228  0.06844025 -0.06573057  0.3619163 ]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 168 is [True, False, False, False, True, False]
State prediction error at timestep 168 is 0.012
Human Feedback received at timestep 168 of 1
Current timestep = 169. State = [[-0.23826079  0.00086218]]. Action = [[ 0.08749374 -0.09507672  0.05334998 -0.6846394 ]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 169 is [True, False, False, False, True, False]
State prediction error at timestep 169 is 0.012
Human Feedback received at timestep 169 of 1
Current timestep = 170. State = [[-2.3030451e-01  1.9167799e-04]]. Action = [[ 0.00155808  0.0683658  -0.0212245  -0.57995296]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 170 is [True, False, False, False, True, False]
Current timestep = 171. State = [[-0.2303353   0.00046072]]. Action = [[ 0.04960083  0.02149124  0.04392467 -0.50004685]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 171 is [True, False, False, False, True, False]
Current timestep = 172. State = [[-0.2297397   0.00095555]]. Action = [[-0.04574952  0.06167934 -0.00382785 -0.32204366]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 172 is [True, False, False, False, True, False]
Current timestep = 173. State = [[-0.22991043  0.00223498]]. Action = [[-0.0430637  -0.09628773  0.04409655  0.6125511 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 173 is [True, False, False, False, True, False]
Current timestep = 174. State = [[-0.22992076  0.00205329]]. Action = [[-0.07040967  0.01563574  0.09173442  0.65946627]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 174 is [True, False, False, False, True, False]
Current timestep = 175. State = [[-0.22991058  0.00212342]]. Action = [[-0.00135913  0.03624814  0.07527515 -0.50893474]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 175 is [True, False, False, False, True, False]
State prediction error at timestep 175 is 0.012
Human Feedback received at timestep 175 of 1
Current timestep = 176. State = [[-0.23037905  0.00336581]]. Action = [[ 0.07167061 -0.01313334  0.09221774 -0.30285203]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 176 is [True, False, False, False, True, False]
State prediction error at timestep 176 is 0.012
Human Feedback received at timestep 176 of 1
Current timestep = 177. State = [[-0.23041584  0.00340287]]. Action = [[ 0.00078374  0.07220586 -0.00734807 -0.06658101]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 177 is [True, False, False, False, True, False]
Current timestep = 178. State = [[-0.23069535  0.00434789]]. Action = [[ 0.0339006   0.06569939  0.02012752 -0.03266454]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 178 is [True, False, False, False, True, False]
Current timestep = 179. State = [[-0.231122    0.00621523]]. Action = [[ 0.0317174  -0.08609602  0.02552479 -0.6378873 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 179 is [True, False, False, False, True, False]
Current timestep = 180. State = [[-0.23094621  0.00615719]]. Action = [[-0.02266153 -0.04613214 -0.05246865  0.69155   ]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 180 is [True, False, False, False, True, False]
Current timestep = 181. State = [[-0.23081483  0.00588561]]. Action = [[-0.05102316  0.03555208  0.05710242  0.8183851 ]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 181 is [True, False, False, False, True, False]
Current timestep = 182. State = [[-0.23088272  0.00605539]]. Action = [[ 0.04255792 -0.08809259  0.07322729 -0.8239961 ]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 182 is [True, False, False, False, True, False]
Current timestep = 183. State = [[-0.23079368  0.00535494]]. Action = [[-0.07077293  0.08616778  0.07944613 -0.18445301]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 183 is [True, False, False, False, True, False]
State prediction error at timestep 183 is 0.012
Human Feedback received at timestep 183 of -1
Current timestep = 184. State = [[-0.23112495  0.00580964]]. Action = [[0.02589329 0.02521404 0.04560284 0.8529171 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 184 is [True, False, False, False, True, False]
Current timestep = 185. State = [[-0.23119535  0.00617744]]. Action = [[ 0.06569769  0.01783788 -0.08351611 -0.38379776]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 185 is [True, False, False, False, True, False]
Current timestep = 186. State = [[-0.23119052  0.00623833]]. Action = [[-0.05819391 -0.06710884  0.01129653 -0.94576174]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 186 is [True, False, False, False, True, False]
Current timestep = 187. State = [[-0.23116578  0.00627697]]. Action = [[0.07454874 0.09273987 0.05538996 0.47669947]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 187 is [True, False, False, False, True, False]
State prediction error at timestep 187 is 0.012
Human Feedback received at timestep 187 of -1
Current timestep = 188. State = [[-0.23011477  0.00827699]]. Action = [[ 0.05260085  0.0025412   0.00820528 -0.57161003]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 188 is [True, False, False, False, True, False]
State prediction error at timestep 188 is 0.012
Human Feedback received at timestep 188 of 1
Current timestep = 189. State = [[-0.22785394  0.00914165]]. Action = [[0.0878674  0.09567057 0.06605928 0.1119225 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 189 is [True, False, False, False, True, False]
Current timestep = 190. State = [[-0.22648332  0.01050425]]. Action = [[-0.05437192 -0.08486065 -0.0335448   0.78376555]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 190 is [True, False, False, False, True, False]
Current timestep = 191. State = [[-0.22615248  0.01045887]]. Action = [[-0.00622382 -0.00950444  0.02845653 -0.7951282 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 191 is [True, False, False, False, True, False]
Current timestep = 192. State = [[-0.22582261  0.01053471]]. Action = [[0.07846951 0.03925348 0.06481846 0.23868382]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 192 is [True, False, False, False, True, False]
State prediction error at timestep 192 is 0.012
Human Feedback received at timestep 192 of 1
Current timestep = 193. State = [[-0.22190785  0.01101076]]. Action = [[ 0.08475376 -0.09730351  0.07400119 -0.85029477]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 193 is [True, False, False, False, True, False]
Current timestep = 194. State = [[-0.21991657  0.01030876]]. Action = [[ 0.02459947  0.09512203 -0.03304484 -0.0240348 ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 194 is [True, False, False, False, True, False]
Current timestep = 195. State = [[-0.21804354  0.01102356]]. Action = [[-0.02676065 -0.06845657  0.04891325  0.64145064]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 195 is [True, False, False, False, True, False]
Current timestep = 196. State = [[-0.2165512   0.01088364]]. Action = [[-0.01997313 -0.0633789   0.09127475 -0.46609902]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 196 is [True, False, False, False, True, False]
Current timestep = 197. State = [[-0.21590337  0.010028  ]]. Action = [[-0.02913294  0.09803899  0.099008   -0.04217392]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 197 is [True, False, False, False, True, False]
State prediction error at timestep 197 is 0.012
Human Feedback received at timestep 197 of 1
Current timestep = 198. State = [[-0.2159019   0.01098485]]. Action = [[-0.00518145  0.02210631 -0.09389158 -0.13174242]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 198 is [True, False, False, False, True, False]
Current timestep = 199. State = [[-0.21612206  0.01121348]]. Action = [[0.01377072 0.03175464 0.08283656 0.46658075]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 199 is [True, False, False, False, True, False]
Current timestep = 200. State = [[-0.21620096  0.01157381]]. Action = [[ 0.08866837 -0.06372884 -0.04892212  0.8047106 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 200 is [True, False, False, False, True, False]
Current timestep = 201. State = [[-0.2146339   0.01171929]]. Action = [[-0.09963728  0.04562307 -0.0738671  -0.7303585 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 201 is [True, False, False, False, True, False]
Current timestep = 202. State = [[-0.21457155  0.01214372]]. Action = [[ 0.01372969  0.07401478  0.02453931 -0.37497103]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 202 is [True, False, False, False, True, False]
Current timestep = 203. State = [[-0.21499838  0.01377912]]. Action = [[0.03079679 0.02936555 0.08133461 0.88116693]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 203 is [True, False, False, False, True, False]
State prediction error at timestep 203 is 0.012
Human Feedback received at timestep 203 of 1
Current timestep = 204. State = [[-0.21328254  0.01877606]]. Action = [[-0.09553662  0.0074361   0.07375055  0.56615937]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 204 is [True, False, False, False, True, False]
Current timestep = 205. State = [[-0.2137643   0.01927085]]. Action = [[ 0.07862469 -0.01221822  0.05229449 -0.00350201]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 205 is [True, False, False, False, True, False]
State prediction error at timestep 205 is 0.012
Human Feedback received at timestep 205 of 1
Current timestep = 206. State = [[-0.21337143  0.0210645 ]]. Action = [[-0.02758104 -0.02839027 -0.05051571  0.43885493]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 206 is [True, False, False, False, True, False]
Current timestep = 207. State = [[-0.21335658  0.02095002]]. Action = [[-0.06656671 -0.04742297 -0.0952935   0.9427171 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 207 is [True, False, False, False, True, False]
State prediction error at timestep 207 is 0.012
Human Feedback received at timestep 207 of 1
Current timestep = 208. State = [[-0.21326035  0.02053494]]. Action = [[ 0.09372016 -0.05449561 -0.08689364  0.99166226]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 208 is [True, False, False, False, True, False]
Current timestep = 209. State = [[-0.2127976   0.01882497]]. Action = [[ 0.01848885 -0.04243303 -0.00870301  0.32107306]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 209 is [True, False, False, False, True, False]
Current timestep = 210. State = [[-0.21219844  0.01715386]]. Action = [[ 0.07581138  0.07693285 -0.02460351  0.27240837]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 210 is [True, False, False, False, True, False]
Current timestep = 211. State = [[-0.21096876  0.01726199]]. Action = [[ 0.00561909 -0.01224796 -0.05688819 -0.4178825 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 211 is [True, False, False, False, True, False]
Current timestep = 212. State = [[-0.21025102  0.01747795]]. Action = [[-0.09821889  0.08508011  0.00868406  0.60448813]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 212 is [True, False, False, False, True, False]
Current timestep = 213. State = [[-0.21069527  0.01841891]]. Action = [[-0.03787294  0.05345585 -0.05274829 -0.6106347 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 213 is [True, False, False, False, True, False]
Current timestep = 214. State = [[-0.21136303  0.0204289 ]]. Action = [[ 0.08194851  0.06537334 -0.09670521 -0.37116373]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 214 is [True, False, False, False, True, False]
Current timestep = 215. State = [[-0.21128732  0.02283743]]. Action = [[-0.00999141  0.02379422 -0.09918956 -0.535717  ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 215 is [True, False, False, False, True, False]
Current timestep = 216. State = [[-0.21109466  0.0247368 ]]. Action = [[ 0.05203732  0.06142607 -0.01964322 -0.7833507 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 216 is [True, False, False, False, True, False]
Current timestep = 217. State = [[-0.21042919  0.02731327]]. Action = [[-0.09518235 -0.01473077  0.08672791  0.03574967]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 217 is [True, False, False, False, True, False]
Current timestep = 218. State = [[-0.21062087  0.02913189]]. Action = [[ 0.06755545 -0.04342345  0.049168   -0.55490094]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 218 is [True, False, False, False, True, False]
State prediction error at timestep 218 is 0.012
Human Feedback received at timestep 218 of 1
Current timestep = 219. State = [[-0.21056592  0.02979532]]. Action = [[-0.02191421  0.01703962  0.03256529  0.1606834 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 219 is [True, False, False, False, True, False]
Current timestep = 220. State = [[-0.21057229  0.03029145]]. Action = [[ 0.01412831 -0.01183335  0.07836091 -0.653043  ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 220 is [True, False, False, False, True, False]
Current timestep = 221. State = [[-0.21060574  0.03037776]]. Action = [[-0.044709    0.08114203  0.09841742  0.81247103]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 221 is [True, False, False, False, True, False]
Current timestep = 222. State = [[-0.21110003  0.0322026 ]]. Action = [[-0.08587576  0.08262318  0.07842646  0.8246758 ]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 222 is [True, False, False, False, True, False]
Current timestep = 223. State = [[-0.2121285   0.03541705]]. Action = [[-0.08651321  0.07867614  0.095258    0.93394005]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 223 is [True, False, False, False, True, False]
Current timestep = 224. State = [[-0.21411815  0.04034965]]. Action = [[-0.0363778   0.09473156  0.05874661 -0.4123146 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 224 is [True, False, False, False, True, False]
State prediction error at timestep 224 is 0.012
Human Feedback received at timestep 224 of -1
Current timestep = 225. State = [[-0.21977302  0.0542362 ]]. Action = [[ 9.7632639e-02 -2.2386014e-04 -3.1841606e-02  5.1452816e-01]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 225 is [True, False, False, False, True, False]
Current timestep = 226. State = [[-0.21979535  0.05434985]]. Action = [[-0.05765215  0.03545868 -0.05237228  0.5289302 ]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 226 is [True, False, False, False, True, False]
Current timestep = 227. State = [[-0.22001715  0.05496298]]. Action = [[ 0.07703767 -0.08573862 -0.0853665   0.08602011]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 227 is [True, False, False, False, True, False]
Current timestep = 228. State = [[-0.21975341  0.05442941]]. Action = [[ 0.03076085 -0.05657064 -0.0910904  -0.70641214]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 228 is [True, False, False, False, True, False]
State prediction error at timestep 228 is 0.012
Human Feedback received at timestep 228 of -1
Current timestep = 229. State = [[-0.21849075  0.05187294]]. Action = [[-0.08112167  0.0805572   0.05290886 -0.54819727]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 229 is [True, False, False, False, True, False]
Current timestep = 230. State = [[-0.2188764   0.05256371]]. Action = [[-0.02027931 -0.04841634  0.08463166  0.9498532 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 230 is [True, False, False, False, True, False]
State prediction error at timestep 230 is 0.012
Human Feedback received at timestep 230 of -1
Current timestep = 231. State = [[-0.21883261  0.05233612]]. Action = [[ 0.08933201  0.03565674 -0.02980313 -0.5562528 ]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 231 is [True, False, False, False, True, False]
State prediction error at timestep 231 is 0.012
Human Feedback received at timestep 231 of -1
Current timestep = 232. State = [[-0.21879077  0.05242764]]. Action = [[ 0.08178236 -0.08400054 -0.02627659  0.75736856]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 232 is [True, False, False, False, True, False]
Current timestep = 233. State = [[-0.21759169  0.05164715]]. Action = [[-0.08310437  0.09771391 -0.00102019  0.25492954]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 233 is [True, False, False, False, True, False]
Current timestep = 234. State = [[-0.21771571  0.05224118]]. Action = [[ 0.09362882 -0.05004777 -0.07013855  0.01931775]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 234 is [True, False, False, False, True, False]
State prediction error at timestep 234 is 0.012
Human Feedback received at timestep 234 of 1
Current timestep = 235. State = [[-0.21484831  0.05291798]]. Action = [[-0.05275721  0.03627472 -0.04388751 -0.12875408]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 235 is [True, False, False, False, True, False]
State prediction error at timestep 235 is 0.012
Human Feedback received at timestep 235 of 1
Current timestep = 236. State = [[-0.21477772  0.0532815 ]]. Action = [[ 0.05046607 -0.09847365  0.08645111 -0.9721306 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 236 is [True, False, False, False, True, False]
Current timestep = 237. State = [[-0.21412393  0.05198564]]. Action = [[ 0.06234524  0.0633396  -0.06657198  0.4381032 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 237 is [True, False, False, False, True, False]
State prediction error at timestep 237 is 0.012
Human Feedback received at timestep 237 of 1
Current timestep = 238. State = [[-0.21018785  0.05291521]]. Action = [[ 0.05353069  0.06746554 -0.08526461  0.43462968]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 238 is [True, False, False, False, True, False]
Current timestep = 239. State = [[-0.20907009  0.05358907]]. Action = [[ 0.04239265  0.05968372 -0.0695051  -0.61793566]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 239 is [True, False, False, False, True, False]
Current timestep = 240. State = [[-0.20734034  0.05475802]]. Action = [[ 0.03337624 -0.046882   -0.07955758  0.7587408 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 240 is [True, False, False, False, True, False]
Current timestep = 241. State = [[-0.20488669  0.05505479]]. Action = [[ 0.00426346 -0.00932635  0.04581194  0.20876658]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 241 is [True, False, False, False, True, False]
Current timestep = 242. State = [[-0.20277232  0.05510566]]. Action = [[-0.03706463 -0.06626555  0.09122283  0.36524403]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 242 is [True, False, False, False, True, False]
Current timestep = 243. State = [[-0.20208843  0.05485113]]. Action = [[-0.04224936  0.05942445 -0.06807353 -0.5759227 ]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 243 is [True, False, False, False, True, False]
Current timestep = 244. State = [[-0.20226017  0.05527836]]. Action = [[-0.02609134  0.04302607 -0.0366139   0.02485895]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 244 is [True, False, False, False, True, False]
State prediction error at timestep 244 is 0.012
Human Feedback received at timestep 244 of 1
Current timestep = 245. State = [[-0.20329843  0.05687428]]. Action = [[-0.0294378   0.08185606 -0.02560621  0.70086753]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 245 is [True, False, False, False, True, False]
Current timestep = 246. State = [[-0.20392387  0.05863354]]. Action = [[ 0.06492827  0.00351547 -0.06824426  0.01838219]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 246 is [True, False, False, False, True, False]
State prediction error at timestep 246 is 0.012
Human Feedback received at timestep 246 of 1
Current timestep = 247. State = [[-0.20304     0.06211572]]. Action = [[-0.09800553  0.08266083  0.05532997  0.6473994 ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 247 is [True, False, False, False, True, False]
Current timestep = 248. State = [[-0.20407672  0.06470439]]. Action = [[-0.06673756  0.04162658 -0.05961117  0.14702559]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 248 is [True, False, False, False, True, False]
Current timestep = 249. State = [[-0.20535932  0.06776717]]. Action = [[-0.03351276 -0.09778798 -0.06632639 -0.7860285 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 249 is [True, False, False, False, True, False]
Current timestep = 250. State = [[-0.20579274  0.06761805]]. Action = [[-0.0643495  -0.08868106  0.00343658  0.39860976]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 250 is [True, False, False, False, True, False]
Current timestep = 251. State = [[-0.20612685  0.06602948]]. Action = [[ 0.0872656   0.04713624 -0.00613047 -0.43543458]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 251 is [True, False, False, False, True, False]
Current timestep = 252. State = [[-0.2062159   0.06598897]]. Action = [[-0.06406257 -0.0146413  -0.01632836  0.7022412 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 252 is [True, False, False, False, True, False]
State prediction error at timestep 252 is 0.012
Human Feedback received at timestep 252 of -1
Current timestep = 253. State = [[-0.20670167  0.06507914]]. Action = [[-0.09831903 -0.01400302  0.0203767   0.02466536]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 253 is [True, False, False, False, True, False]
Current timestep = 254. State = [[-0.20782603  0.06480131]]. Action = [[ 0.05219635 -0.02322022  0.04425616 -0.7885103 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 254 is [True, False, False, False, True, False]
Current timestep = 255. State = [[-0.20794047  0.06433407]]. Action = [[-0.02651195  0.0892221   0.09250442 -0.8168889 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 255 is [True, False, False, False, True, False]
Current timestep = 256. State = [[-0.20854485  0.06580218]]. Action = [[-0.02270103  0.03821061  0.01738671 -0.8023792 ]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 256 is [True, False, False, False, True, False]
State prediction error at timestep 256 is 0.012
Human Feedback received at timestep 256 of -1
Current timestep = 257. State = [[-0.21090527  0.0708876 ]]. Action = [[ 0.03832378  0.09020045  0.09140072 -0.8241176 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 257 is [True, False, False, False, True, False]
State prediction error at timestep 257 is 0.012
Human Feedback received at timestep 257 of -1
Current timestep = 258. State = [[-0.21321575  0.07606652]]. Action = [[-0.00296441  0.02705752 -0.01717356 -0.7659553 ]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 258 is [True, False, False, False, True, False]
Current timestep = 259. State = [[-0.21353298  0.07676409]]. Action = [[-0.05658524  0.05703773  0.07106899  0.68668246]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 259 is [True, False, False, False, True, False]
Current timestep = 260. State = [[-0.2144597   0.07882437]]. Action = [[ 0.06697123  0.09690454 -0.00583932  0.94628024]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 260 is [True, False, False, False, True, False]
Current timestep = 261. State = [[-0.21560916  0.08174359]]. Action = [[ 0.05872671 -0.08565628  0.05935959  0.53379023]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 261 is [True, False, False, False, True, False]
Current timestep = 262. State = [[-0.21556346  0.08178367]]. Action = [[-0.05382015 -0.02013361  0.06054083  0.30620217]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 262 is [True, False, False, False, True, False]
Current timestep = 263. State = [[-0.21565676  0.08193684]]. Action = [[-0.09326884  0.0934334  -0.08988322 -0.0293349 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 263 is [True, False, False, False, True, False]
State prediction error at timestep 263 is 0.012
Human Feedback received at timestep 263 of -1
Current timestep = 264. State = [[-0.21891865  0.08839898]]. Action = [[-0.05873246  0.05696218  0.0220667  -0.84896934]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 264 is [True, False, False, False, True, False]
Current timestep = 265. State = [[-0.21972452  0.08995819]]. Action = [[-0.04692098 -0.07746659  0.06650382  0.10845613]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 265 is [True, False, False, False, True, False]
Current timestep = 266. State = [[-0.21991023  0.0897804 ]]. Action = [[-0.01355476 -0.09146859 -0.0607963   0.563499  ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 266 is [True, False, False, False, True, False]
Current timestep = 267. State = [[-0.2205675   0.08739739]]. Action = [[ 0.05679294 -0.08886103  0.06429335 -0.20960104]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 267 is [True, False, False, False, True, False]
Current timestep = 268. State = [[-0.22012372  0.08421396]]. Action = [[-0.07766265  0.01920233 -0.07250085  0.76058364]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 268 is [True, False, False, False, True, False]
Current timestep = 269. State = [[-0.22116245  0.08270428]]. Action = [[0.00217776 0.0207987  0.096298   0.89136255]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 269 is [True, False, False, False, True, False]
State prediction error at timestep 269 is 0.012
Human Feedback received at timestep 269 of -1
Current timestep = 270. State = [[-0.22299504  0.07973679]]. Action = [[-0.01824551 -0.0042288  -0.02237844  0.37617683]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 270 is [True, False, False, False, True, False]
Current timestep = 271. State = [[-0.2232244   0.07946377]]. Action = [[ 0.03740668 -0.0081032  -0.09759673  0.11308277]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 271 is [True, False, False, False, True, False]
Current timestep = 272. State = [[-0.22311988  0.07914274]]. Action = [[-0.04190005  0.07939287  0.0598923   0.3330425 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 272 is [True, False, False, False, True, False]
Current timestep = 273. State = [[-0.22391784  0.08065856]]. Action = [[ 0.01360656 -0.04711839 -0.059313    0.6510427 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 273 is [True, False, False, False, True, False]
Current timestep = 274. State = [[-0.22432078  0.08080126]]. Action = [[-0.01387528  0.09124922 -0.09462655 -0.71032465]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 274 is [True, False, False, False, True, False]
State prediction error at timestep 274 is 0.012
Human Feedback received at timestep 274 of -1
Current timestep = 275. State = [[-0.2269658   0.08580947]]. Action = [[ 0.0596187   0.08101343  0.05366347 -0.0348435 ]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 275 is [True, False, False, False, True, False]
State prediction error at timestep 275 is 0.012
Human Feedback received at timestep 275 of -1
Current timestep = 276. State = [[-0.22880189  0.08966637]]. Action = [[-0.07890238 -0.04928231 -0.00666558 -0.3679859 ]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 276 is [True, False, False, False, True, False]
State prediction error at timestep 276 is 0.012
Human Feedback received at timestep 276 of -1
Current timestep = 277. State = [[-0.22881562  0.08910079]]. Action = [[ 0.0207376  -0.09217788  0.09348451  0.75566316]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 277 is [True, False, False, False, True, False]
Current timestep = 278. State = [[-0.22860377  0.0874824 ]]. Action = [[-0.05207764  0.08330765 -0.02257383  0.65749335]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 278 is [True, False, False, False, True, False]
Current timestep = 279. State = [[-0.22909762  0.08817806]]. Action = [[-0.05400294 -0.01759986  0.02296461 -0.36770654]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 279 is [True, False, False, False, True, False]
Current timestep = 280. State = [[-0.22978157  0.0881279 ]]. Action = [[-0.04599093 -0.05814148 -0.02697864 -0.09917009]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 280 is [True, False, False, False, True, False]
Current timestep = 281. State = [[-0.23094468  0.0870202 ]]. Action = [[ 0.05087202 -0.01895991  0.00163712  0.49590337]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 281 is [True, False, False, False, True, False]
State prediction error at timestep 281 is 0.012
Human Feedback received at timestep 281 of -1
Current timestep = 282. State = [[-0.23104171  0.08475388]]. Action = [[ 0.07080226 -0.08798846 -0.0462607   0.41281605]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 282 is [True, False, False, False, True, False]
Current timestep = 283. State = [[-0.2304776   0.08254525]]. Action = [[-2.8187126e-02  6.4696372e-04 -6.3429624e-02  8.1139421e-01]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 283 is [True, False, False, False, True, False]
Current timestep = 284. State = [[-0.2305698   0.08116239]]. Action = [[-0.09890959 -0.00117623 -0.00801872 -0.0380137 ]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 284 is [True, False, False, False, True, False]
Current timestep = 285. State = [[-0.23179282  0.07982765]]. Action = [[ 0.04869366  0.00047702 -0.01336696 -0.27904463]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 285 is [True, False, False, False, True, False]
Current timestep = 286. State = [[-0.23213565  0.07881346]]. Action = [[-0.07356026 -0.07800369  0.02168324 -0.07798249]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 286 is [True, False, False, False, True, False]
Current timestep = 287. State = [[-0.2329754   0.07664845]]. Action = [[-0.03127161  0.09989857 -0.02154607 -0.5866436 ]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 287 is [True, False, False, False, True, False]
State prediction error at timestep 287 is 0.012
Human Feedback received at timestep 287 of -1
Current timestep = 288. State = [[-0.23808345  0.07793061]]. Action = [[ 0.00411229  0.08926732  0.04149271 -0.09009129]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 288 is [True, False, False, False, True, False]
Current timestep = 289. State = [[-0.23886645  0.0795818 ]]. Action = [[-0.04035716 -0.03542302 -0.0828861  -0.2635529 ]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 289 is [True, False, False, False, True, False]
Current timestep = 290. State = [[-0.23990846  0.08010726]]. Action = [[ 0.09734147 -0.07145954 -0.06648915 -0.02795124]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 290 is [True, False, False, False, True, False]
State prediction error at timestep 290 is 0.012
Human Feedback received at timestep 290 of -1
Current timestep = 291. State = [[-0.23925915  0.07830333]]. Action = [[-0.05713931  0.01066504  0.05723054 -0.7663967 ]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 291 is [True, False, False, False, True, False]
Current timestep = 292. State = [[-0.2395939  0.0782869]]. Action = [[-0.0625463  -0.07223548 -0.08415158  0.49005258]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 292 is [True, False, False, False, True, False]
Current timestep = 293. State = [[-0.2405496  0.0766925]]. Action = [[ 0.04731906 -0.07586887  0.00132948  0.20205629]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 293 is [True, False, False, False, True, False]
Current timestep = 294. State = [[-0.24050328  0.07415237]]. Action = [[0.04698782 0.04513011 0.05181111 0.29335082]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 294 is [True, False, False, False, True, False]
Current timestep = 295. State = [[-0.24042746  0.07324826]]. Action = [[-0.079163    0.00162347  0.01756128  0.7200632 ]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 295 is [True, False, False, False, True, False]
Current timestep = 296. State = [[-0.24086493  0.07276542]]. Action = [[-0.09001391  0.00916243  0.01656779  0.8843081 ]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 296 is [True, False, False, False, True, False]
Current timestep = 297. State = [[-0.24227943  0.07253093]]. Action = [[ 0.09163158  0.08728083  0.03535148 -0.98925376]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 297 is [True, False, False, False, True, False]
State prediction error at timestep 297 is 0.012
Human Feedback received at timestep 297 of -1
Current timestep = 298. State = [[-0.24348249  0.0753508 ]]. Action = [[-0.06739083  0.08127836  0.08096527  0.87305737]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 298 is [True, False, False, False, True, False]
State prediction error at timestep 298 is 0.012
Human Feedback received at timestep 298 of -1
Current timestep = 299. State = [[-0.24697109  0.08193503]]. Action = [[ 0.05995821 -0.02107758  0.01941912 -0.16872978]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 299 is [True, False, False, False, True, False]
Current timestep = 300. State = [[-0.24694288  0.08188841]]. Action = [[ 0.02406726 -0.02474345 -0.09443858  0.8243147 ]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 300 is [True, False, False, False, True, False]
Current timestep = 301. State = [[-0.24670832  0.08124749]]. Action = [[-0.04933728 -0.03398766 -0.01630395 -0.41738147]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 301 is [True, False, False, False, True, False]
Current timestep = 302. State = [[-0.24656585  0.07974885]]. Action = [[-0.01862063 -0.09534556  0.04536916 -0.6467637 ]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 302 is [True, False, False, False, True, False]
Current timestep = 303. State = [[-0.24643497  0.0770848 ]]. Action = [[0.00112841 0.09300032 0.08388915 0.01337445]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 303 is [True, False, False, False, True, False]
Current timestep = 304. State = [[-0.24672425  0.07701195]]. Action = [[ 0.09127598  0.03858715 -0.01237662 -0.5939901 ]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 304 is [True, False, False, False, True, False]
State prediction error at timestep 304 is 0.012
Human Feedback received at timestep 304 of -1
Current timestep = 305. State = [[-0.24651694  0.07742357]]. Action = [[ 0.01257388 -0.01067562 -0.05871306 -0.13458979]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 305 is [True, False, False, False, True, False]
State prediction error at timestep 305 is 0.012
Human Feedback received at timestep 305 of -1
Current timestep = 306. State = [[-0.2465447   0.07742411]]. Action = [[ 0.0142207  -0.01958447  0.02874389  0.42453074]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 306 is [True, False, False, False, True, False]
Current timestep = 307. State = [[-0.24623327  0.07739374]]. Action = [[-0.02269419  0.06272305  0.06134482 -0.7118628 ]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 307 is [True, False, False, False, True, False]
Current timestep = 308. State = [[-0.24647759  0.07770512]]. Action = [[-0.07670791 -0.01200892 -0.03664701 -0.57948595]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 308 is [True, False, False, False, True, False]
Current timestep = 309. State = [[-0.24682747  0.07834337]]. Action = [[-0.01899513 -0.02193917 -0.08300927 -0.24825007]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 309 is [True, False, False, False, True, False]
Current timestep = 310. State = [[-0.24688183  0.07856611]]. Action = [[-0.00771308  0.09098392  0.00701918  0.89527404]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 310 is [True, False, False, False, True, False]
Current timestep = 311. State = [[-0.24786289  0.08050368]]. Action = [[ 0.09839325  0.09345367  0.07996049 -0.2632689 ]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 311 is [True, False, False, False, True, False]
State prediction error at timestep 311 is 0.012
Human Feedback received at timestep 311 of -1
Current timestep = 312. State = [[-0.25006503  0.08761115]]. Action = [[ 0.03474412  0.05695762 -0.04820592 -0.28462952]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 312 is [True, False, False, False, True, False]
State prediction error at timestep 312 is 0.012
Human Feedback received at timestep 312 of 1
Current timestep = 313. State = [[-0.24967837  0.09161181]]. Action = [[-0.03894487  0.04155552  0.072271   -0.3176986 ]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 313 is [True, False, False, False, True, False]
State prediction error at timestep 313 is 0.012
Human Feedback received at timestep 313 of 1
Current timestep = 314. State = [[-0.2508881   0.09486584]]. Action = [[0.0606556  0.09062483 0.06980232 0.03274632]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 314 is [True, False, False, False, True, False]
Current timestep = 315. State = [[-0.25061676  0.09656575]]. Action = [[ 0.00686908  0.04994369 -0.03459104 -0.52691865]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 315 is [True, False, False, False, True, False]
Current timestep = 316. State = [[-0.25045443  0.09864076]]. Action = [[ 0.09516902 -0.07655267  0.02194508  0.9859054 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 316 is [True, False, False, False, True, False]
Current timestep = 317. State = [[-0.2487905   0.09915853]]. Action = [[-0.03308152  0.06699195 -0.02239869 -0.44100857]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 317 is [True, False, False, False, True, False]
Current timestep = 318. State = [[-0.24791329  0.10057946]]. Action = [[-0.00384919 -0.08461466  0.09463494  0.538484  ]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 318 is [True, False, False, False, True, False]
State prediction error at timestep 318 is 0.012
Human Feedback received at timestep 318 of 1
Current timestep = 319. State = [[-0.24747048  0.10067059]]. Action = [[ 0.07944661  0.03174534  0.03960378 -0.489398  ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 319 is [True, False, False, False, True, False]
Current timestep = 320. State = [[-0.24655582  0.10097159]]. Action = [[-0.0113832  -0.04154754 -0.04387505 -0.07388496]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 320 is [True, False, False, False, True, False]
Current timestep = 321. State = [[-0.24578115  0.10097055]]. Action = [[-0.03960497 -0.02587609  0.0463227   0.7758266 ]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 321 is [True, False, False, False, True, False]
Current timestep = 322. State = [[-0.24546327  0.10051183]]. Action = [[0.09529164 0.02536049 0.03677603 0.23380637]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 322 is [True, False, False, False, True, False]
Current timestep = 323. State = [[-0.24461874  0.10070523]]. Action = [[-0.0380289  -0.03560158  0.07986628  0.73209715]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 323 is [True, False, False, False, True, False]
Current timestep = 324. State = [[-0.24409305  0.10018392]]. Action = [[-0.08567055  0.0413663  -0.08813748 -0.65301824]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 324 is [True, False, False, False, True, False]
State prediction error at timestep 324 is 0.012
Human Feedback received at timestep 324 of 1
Current timestep = 325. State = [[-0.24411568  0.10018447]]. Action = [[ 0.00748942 -0.06792901 -0.06111893 -0.74373543]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 325 is [True, False, False, False, True, False]
Current timestep = 326. State = [[-0.24380818  0.09935427]]. Action = [[ 0.00927542  0.04223023 -0.08608825 -0.96729946]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 326 is [True, False, False, False, True, False]
Current timestep = 327. State = [[-0.24386135  0.09929077]]. Action = [[-0.027773   -0.09101842  0.08704553  0.63733697]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 327 is [True, False, False, False, True, False]
Current timestep = 328. State = [[-0.24342294  0.09786792]]. Action = [[-0.0977295  -0.05809113  0.0740791  -0.22927636]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 328 is [True, False, False, False, True, False]
Current timestep = 329. State = [[-0.24377388  0.09602216]]. Action = [[-0.0802382   0.06772222  0.07545846  0.21889639]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 329 is [True, False, False, False, True, False]
Current timestep = 330. State = [[-0.24541433  0.09633496]]. Action = [[ 0.0804474  -0.06525839  0.03197817  0.34611845]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 330 is [True, False, False, False, True, False]
Current timestep = 331. State = [[-0.24544767  0.09537969]]. Action = [[-0.09573589  0.06936931 -0.03920716 -0.01418412]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 331 is [True, False, False, False, True, False]
Current timestep = 332. State = [[-0.24650447  0.09558303]]. Action = [[-0.00324064  0.01468589  0.0723727  -0.9650372 ]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 332 is [True, False, False, False, True, False]
Current timestep = 333. State = [[-0.24727291  0.0962945 ]]. Action = [[ 0.05169832  0.09133273  0.05068345 -0.9666131 ]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 333 is [True, False, False, False, True, False]
State prediction error at timestep 333 is 0.012
Human Feedback received at timestep 333 of -1
Current timestep = 334. State = [[-0.24910259  0.09989286]]. Action = [[-0.01224783 -0.07963748 -0.0712843  -0.23841894]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 334 is [True, False, False, False, True, False]
Current timestep = 335. State = [[-0.24898179  0.09962385]]. Action = [[-0.02042683 -0.00158922 -0.05990985 -0.24857134]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 335 is [True, False, False, False, True, False]
Current timestep = 336. State = [[-0.24910682  0.09944802]]. Action = [[-0.03708806  0.03426159  0.04892348  0.544919  ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 336 is [True, False, False, False, True, False]
State prediction error at timestep 336 is 0.012
Human Feedback received at timestep 336 of -1
Current timestep = 337. State = [[-0.24958023  0.09980672]]. Action = [[-0.01980055 -0.08641309 -0.09766602 -0.21847332]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 337 is [True, False, False, False, True, False]
Current timestep = 338. State = [[-0.24995425  0.09894165]]. Action = [[-0.0661864   0.09364087  0.04409262 -0.73228985]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 338 is [True, False, False, False, True, False]
Current timestep = 339. State = [[-0.25142613  0.09976912]]. Action = [[-0.0546456  -0.08666154  0.04084399 -0.43282878]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 339 is [True, False, False, False, True, False]
Current timestep = 340. State = [[-0.25266382  0.09887973]]. Action = [[ 0.056404    0.03266782  0.04432254 -0.7109239 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 340 is [True, False, False, False, True, False]
Current timestep = 341. State = [[-0.25281015  0.09885367]]. Action = [[ 0.07224711  0.01855035  0.08853181 -0.53498703]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 341 is [True, False, False, False, True, False]
State prediction error at timestep 341 is 0.012
Human Feedback received at timestep 341 of -1
Current timestep = 342. State = [[-0.25269714  0.09888513]]. Action = [[0.00119704 0.00516788 0.09179064 0.68729067]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 342 is [True, False, False, False, True, False]
State prediction error at timestep 342 is 0.012
Human Feedback received at timestep 342 of -1
Current timestep = 343. State = [[-0.25270188  0.09890153]]. Action = [[ 0.04929963 -0.03291995 -0.05465809 -0.6164951 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 343 is [True, False, False, False, True, False]
State prediction error at timestep 343 is 0.012
Human Feedback received at timestep 343 of -1
Current timestep = 344. State = [[-0.25252485  0.09820454]]. Action = [[ 0.04546113 -0.02658944  0.01967163  0.604738  ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 344 is [True, False, False, False, True, False]
Current timestep = 345. State = [[-0.25200516  0.09738731]]. Action = [[ 0.02121743 -0.08684698  0.00435277 -0.15997213]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 345 is [True, False, False, False, True, False]
Current timestep = 346. State = [[-0.25089508  0.09513866]]. Action = [[-0.02774825  0.08443392 -0.06347967 -0.35764176]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 346 is [True, False, False, False, True, False]
Current timestep = 347. State = [[-0.25106925  0.09526069]]. Action = [[0.00513898 0.00777678 0.04727756 0.38699365]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 347 is [True, False, False, False, True, False]
Current timestep = 348. State = [[-0.25110787  0.09532052]]. Action = [[ 0.05342049 -0.01493974  0.07837936 -0.44285524]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 348 is [True, False, False, False, True, False]
Current timestep = 349. State = [[-0.25065887  0.0952241 ]]. Action = [[ 0.00927167 -0.06272862  0.08109813 -0.64070034]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 349 is [True, False, False, False, True, False]
Current timestep = 350. State = [[-0.24959077  0.09390568]]. Action = [[-0.03582796 -0.00322063 -0.05447743 -0.32054746]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 350 is [True, False, False, False, True, False]
Current timestep = 351. State = [[-0.24958333  0.09281135]]. Action = [[-1.43888295e-02 -1.32910907e-04  4.10227850e-02  5.37557602e-01]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 351 is [True, False, False, False, True, False]
Current timestep = 352. State = [[-0.24966119  0.09211416]]. Action = [[-0.0290448   0.03100079  0.01927687 -0.9101254 ]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 352 is [True, False, False, False, True, False]
Current timestep = 353. State = [[-0.24976592  0.09222218]]. Action = [[-3.7879474e-02 -9.8436102e-02 -2.9932708e-04 -4.8478913e-01]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 353 is [True, False, False, False, True, False]
State prediction error at timestep 353 is 0.012
Human Feedback received at timestep 353 of 1
Current timestep = 354. State = [[-0.2493038   0.08638215]]. Action = [[-0.08906347 -0.00326948 -0.09206425  0.7360873 ]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 354 is [True, False, False, False, True, False]
Current timestep = 355. State = [[-0.25020427  0.08623899]]. Action = [[-0.03239907  0.01451205 -0.02450632 -0.24832118]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 355 is [True, False, False, False, True, False]
State prediction error at timestep 355 is 0.012
Human Feedback received at timestep 355 of -1
Current timestep = 356. State = [[-0.25250623  0.08632802]]. Action = [[0.07307122 0.06122526 0.04459103 0.0860337 ]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 356 is [True, False, False, False, True, False]
Current timestep = 357. State = [[-0.25258476  0.08660906]]. Action = [[ 0.05739697 -0.08531006  0.04898866  0.9602027 ]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 357 is [True, False, False, False, True, False]
Current timestep = 358. State = [[-0.25231805  0.08593124]]. Action = [[ 0.05734735 -0.06000493  0.07621425  0.6758517 ]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 358 is [True, False, False, False, True, False]
State prediction error at timestep 358 is 0.012
Human Feedback received at timestep 358 of 1
Current timestep = 359. State = [[-0.250241    0.08012217]]. Action = [[0.02036209 0.04030734 0.01432393 0.12570786]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 359 is [True, False, False, False, True, False]
Current timestep = 360. State = [[-0.25026968  0.08055365]]. Action = [[ 0.05384945  0.09314866  0.00210229 -0.61892647]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 360 is [True, False, False, False, True, False]
Current timestep = 361. State = [[-0.24993053  0.08166964]]. Action = [[-0.08127633  0.06800442 -0.06586081  0.8156121 ]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 361 is [True, False, False, False, True, False]
Current timestep = 362. State = [[-0.25106493  0.08389799]]. Action = [[-0.01559198  0.01370113 -0.05577664 -0.35039037]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 362 is [True, False, False, False, True, False]
Current timestep = 363. State = [[-0.2519101   0.08563871]]. Action = [[ 0.07225939 -0.05020162 -0.02050369  0.3761872 ]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 363 is [True, False, False, False, True, False]
Current timestep = 364. State = [[-0.25138184  0.08564042]]. Action = [[ 0.04371256 -0.03554789  0.04747763 -0.97263044]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 364 is [True, False, False, False, True, False]
Current timestep = 365. State = [[-0.25056317  0.08559294]]. Action = [[-0.03154184 -0.06682341 -0.08810258 -0.27600598]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 365 is [True, False, False, False, True, False]
Current timestep = 366. State = [[-0.25009078  0.08494478]]. Action = [[ 0.04600526  0.06810338 -0.06712639  0.84440506]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 366 is [True, False, False, False, True, False]
Current timestep = 367. State = [[-0.24955612  0.08514552]]. Action = [[-0.03018109 -0.07878159 -0.06620476  0.6478708 ]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 367 is [True, False, False, False, True, False]
Current timestep = 368. State = [[-0.24944139  0.08434985]]. Action = [[ 0.09539228  0.08254253 -0.06559491 -0.5728567 ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 368 is [True, False, False, False, True, False]
State prediction error at timestep 368 is 0.012
Human Feedback received at timestep 368 of 1
Current timestep = 369. State = [[-0.24705184  0.08508753]]. Action = [[ 0.04097544 -0.06924746 -0.05909597  0.02762902]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 369 is [True, False, False, False, True, False]
Current timestep = 370. State = [[-0.24601834  0.08445313]]. Action = [[ 0.0486482   0.06333358  0.04071785 -0.6584465 ]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 370 is [True, False, False, False, True, False]
Current timestep = 371. State = [[-0.24487053  0.08506314]]. Action = [[-0.0922754   0.01031687  0.09861042  0.10843635]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 371 is [True, False, False, False, True, False]
Current timestep = 372. State = [[-0.24497113  0.08527057]]. Action = [[-0.04205335 -0.0609902  -0.069539   -0.32867497]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 372 is [True, False, False, False, True, False]
Current timestep = 373. State = [[-0.24463983  0.08478238]]. Action = [[ 0.02417841  0.01743629 -0.04976647  0.37088263]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 373 is [True, False, False, False, True, False]
Current timestep = 374. State = [[-0.24454524  0.08502462]]. Action = [[ 0.02849316  0.05033054 -0.01162867  0.45122695]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 374 is [True, False, False, False, True, False]
Current timestep = 375. State = [[-0.24467628  0.08528543]]. Action = [[-0.01295059  0.02658694 -0.07864308 -0.46888477]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 375 is [True, False, False, False, True, False]
State prediction error at timestep 375 is 0.012
Human Feedback received at timestep 375 of 1
Current timestep = 376. State = [[-0.2447796   0.08560105]]. Action = [[ 0.07793459 -0.07030288  0.07939845 -0.7294052 ]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 376 is [True, False, False, False, True, False]
Current timestep = 377. State = [[-0.24404946  0.08535383]]. Action = [[ 0.01628248  0.05679289  0.0016534  -0.41296673]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 377 is [True, False, False, False, True, False]
Current timestep = 378. State = [[-0.24339934  0.08566401]]. Action = [[ 0.02499916 -0.0865989  -0.09483472 -0.3394674 ]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 378 is [True, False, False, False, True, False]
Current timestep = 379. State = [[-0.24226935  0.08498676]]. Action = [[-0.09956655  0.03235096  0.04977038 -0.5708886 ]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 379 is [True, False, False, False, True, False]
Current timestep = 380. State = [[-0.24227089  0.08504013]]. Action = [[ 0.09148902 -0.06600899 -0.0709483  -0.7401458 ]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 380 is [True, False, False, False, True, False]
Current timestep = 381. State = [[-0.24135393  0.0840473 ]]. Action = [[ 0.00433896  0.06511136  0.08903451 -0.710396  ]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 381 is [True, False, False, False, True, False]
Current timestep = 382. State = [[-0.24104257  0.08418086]]. Action = [[-0.03280153 -0.06434791  0.02775667  0.7218077 ]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 382 is [True, False, False, False, True, False]
Current timestep = 383. State = [[-0.24063174  0.08285815]]. Action = [[ 0.03060811 -0.09663288 -0.06245511 -0.47275913]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 383 is [True, False, False, False, True, False]
Current timestep = 384. State = [[-0.23944207  0.08006199]]. Action = [[ 0.09049081 -0.08724773 -0.0335808   0.09765232]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 384 is [True, False, False, False, True, False]
Current timestep = 385. State = [[-0.23720123  0.07614022]]. Action = [[-0.07005149 -0.09655289 -0.02937255  0.06793427]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 385 is [True, False, False, False, True, False]
Current timestep = 386. State = [[-0.23592849  0.07216726]]. Action = [[ 0.00956962  0.07097002 -0.07294668 -0.30797338]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 386 is [True, False, False, False, True, False]
State prediction error at timestep 386 is 0.012
Human Feedback received at timestep 386 of 1
Current timestep = 387. State = [[-0.23491791  0.06901165]]. Action = [[-0.09130742  0.07073156 -0.0400863  -0.82999414]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 387 is [True, False, False, False, True, False]
Current timestep = 388. State = [[-0.23510726  0.06941997]]. Action = [[-0.05873357 -0.05307183 -0.04695589  0.54345584]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 388 is [True, False, False, False, True, False]
Current timestep = 389. State = [[-0.23514317  0.0694976 ]]. Action = [[-0.0576416   0.05809379  0.09238719  0.0535357 ]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 389 is [True, False, False, False, True, False]
Current timestep = 390. State = [[-0.235715   0.0706329]]. Action = [[-0.0017455   0.0031541  -0.01170313  0.12712479]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 390 is [True, False, False, False, True, False]
Current timestep = 391. State = [[-0.23598745  0.07121521]]. Action = [[ 0.00272062 -0.03047898  0.05550986 -0.9681096 ]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 391 is [True, False, False, False, True, False]
Current timestep = 392. State = [[-0.2359658   0.07103375]]. Action = [[-0.05441289 -0.01840308 -0.06605579 -0.70569754]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 392 is [True, False, False, False, True, False]
Current timestep = 393. State = [[-0.2369835   0.07059041]]. Action = [[ 0.07764467 -0.03144535 -0.02724692 -0.9625329 ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 393 is [True, False, False, False, True, False]
Current timestep = 394. State = [[-0.23695897  0.07010352]]. Action = [[-0.08598656 -0.04167542  0.03204217  0.9566463 ]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 394 is [True, False, False, False, True, False]
State prediction error at timestep 394 is 0.012
Human Feedback received at timestep 394 of -1
Current timestep = 395. State = [[-0.2389524   0.06596285]]. Action = [[-0.01231229 -0.02475339 -0.03665966  0.16604269]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 395 is [True, False, False, False, True, False]
Current timestep = 396. State = [[-0.23932777  0.06494349]]. Action = [[-0.04061718 -0.03182213  0.02073041  0.74991536]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 396 is [True, False, False, False, True, False]
Current timestep = 397. State = [[-0.23986243  0.06334978]]. Action = [[-0.05308446 -0.06055566  0.00107698  0.01375067]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 397 is [True, False, False, False, True, False]
Current timestep = 398. State = [[-0.24095334  0.06100366]]. Action = [[-0.00858318  0.02901501  0.0501371   0.7597914 ]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 398 is [True, False, False, False, True, False]
Current timestep = 399. State = [[-0.24165559  0.06000289]]. Action = [[ 0.01578669 -0.02805732  0.0659359   0.5673311 ]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 399 is [True, False, False, False, True, False]
Current timestep = 400. State = [[-0.24212612  0.05893352]]. Action = [[-0.00858404 -0.07072638 -0.00687102  0.90279615]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 400 is [True, False, False, False, True, False]
Current timestep = 401. State = [[-0.2425259  0.0568022]]. Action = [[-0.0122075   0.00387862 -0.07150917 -0.4020986 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 401 is [True, False, False, False, True, False]
State prediction error at timestep 401 is 0.012
Human Feedback received at timestep 401 of -1
Current timestep = 402. State = [[-0.24387173  0.05082731]]. Action = [[-0.07188563 -0.0272503   0.09475683 -0.3986498 ]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 402 is [True, False, False, False, True, False]
Current timestep = 403. State = [[-0.2447055   0.04959671]]. Action = [[ 0.05077463 -0.00888107 -0.05574118 -0.8169536 ]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 403 is [True, False, False, False, True, False]
Current timestep = 404. State = [[-0.24461131  0.04845368]]. Action = [[ 0.06155103 -0.08891229 -0.00839736  0.85012555]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 404 is [True, False, False, False, True, False]
Current timestep = 405. State = [[-0.24433662  0.04655385]]. Action = [[ 0.06424963  0.04745797 -0.05860872 -0.4720571 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 405 is [True, False, False, False, True, False]
State prediction error at timestep 405 is 0.012
Human Feedback received at timestep 405 of -1
Current timestep = 406. State = [[-0.24438865  0.0457407 ]]. Action = [[ 0.01777609 -0.01467505  0.06726482  0.31221056]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 406 is [True, False, False, False, True, False]
State prediction error at timestep 406 is 0.012
Human Feedback received at timestep 406 of -1
Current timestep = 407. State = [[-0.2443915   0.04548547]]. Action = [[-0.07007273  0.01543732  0.07536637 -0.5621452 ]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 407 is [True, False, False, False, True, False]
Current timestep = 408. State = [[-0.24440867  0.04540705]]. Action = [[-0.01275649 -0.05715167 -0.01544152  0.22244465]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 408 is [True, False, False, False, True, False]
Current timestep = 409. State = [[-0.24431273  0.04441645]]. Action = [[ 0.0399354  -0.09178049  0.00194242 -0.21691102]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 409 is [True, False, False, False, True, False]
Current timestep = 410. State = [[-0.24376854  0.04154376]]. Action = [[-0.06606541 -0.09912776 -0.01392005  0.8801396 ]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 410 is [True, False, False, False, True, False]
Current timestep = 411. State = [[-0.24377811  0.03759879]]. Action = [[-0.04080061 -0.06969124  0.09752505  0.9302002 ]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 411 is [True, False, False, False, True, False]
Current timestep = 412. State = [[-0.24440332  0.03279348]]. Action = [[ 0.01623962  0.09420358  0.09145891 -0.9161777 ]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 412 is [True, False, False, False, True, False]
Current timestep = 413. State = [[-0.24495655  0.03136115]]. Action = [[ 0.02643705 -0.04100062  0.06640377 -0.70916575]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 413 is [True, False, False, False, True, False]
State prediction error at timestep 413 is 0.012
Human Feedback received at timestep 413 of -1
Current timestep = 414. State = [[-0.24514227  0.0279591 ]]. Action = [[-0.05646575  0.02577332  0.02909692  0.9251492 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 414 is [True, False, False, False, True, False]
State prediction error at timestep 414 is 0.012
Human Feedback received at timestep 414 of -1
Current timestep = 415. State = [[-0.24649498  0.02778173]]. Action = [[ 0.04680907 -0.03598819  0.04907864  0.98881316]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 415 is [True, False, False, False, True, False]
State prediction error at timestep 415 is 0.012
Human Feedback received at timestep 415 of -1
Current timestep = 416. State = [[-0.24651307  0.02721468]]. Action = [[-0.06226669 -0.0032639   0.07468977 -0.4628172 ]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 416 is [True, False, False, False, True, False]
State prediction error at timestep 416 is 0.012
Human Feedback received at timestep 416 of -1
Current timestep = 417. State = [[-0.25045395  0.02608755]]. Action = [[ 0.08013058  0.00036044  0.01436602 -0.21147603]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 417 is [True, False, False, False, True, False]
Current timestep = 418. State = [[-0.2502149   0.02610099]]. Action = [[-0.08166286 -0.03781302 -0.00712233 -0.70637006]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 418 is [True, False, False, False, True, False]
Current timestep = 419. State = [[-0.25043783  0.0257171 ]]. Action = [[ 0.00485333  0.0982404  -0.02909616  0.3252722 ]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 419 is [True, False, False, False, True, False]
State prediction error at timestep 419 is 0.012
Human Feedback received at timestep 419 of -1
Current timestep = 420. State = [[-0.25107828  0.02669471]]. Action = [[ 0.0420351   0.06197999  0.06700534 -0.16977727]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 420 is [True, False, False, False, True, False]
Current timestep = 421. State = [[-0.2513388   0.02755964]]. Action = [[-0.0509559  -0.02182326 -0.02952897  0.7509217 ]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 421 is [True, False, False, False, True, False]
Current timestep = 422. State = [[-0.25146586  0.02795005]]. Action = [[ 0.06254528  0.0062324  -0.03606297 -0.98159015]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 422 is [True, False, False, False, True, False]
State prediction error at timestep 422 is 0.012
Human Feedback received at timestep 422 of -1
Current timestep = 423. State = [[-0.25147414  0.02816183]]. Action = [[-0.00323447  0.02758669  0.02984428  0.7456614 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 423 is [True, False, False, False, True, False]
Current timestep = 424. State = [[-0.25158125  0.02872246]]. Action = [[0.09256329 0.07457607 0.03510007 0.90157545]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 424 is [True, False, False, False, True, False]
Current timestep = 425. State = [[-0.2515002   0.03005885]]. Action = [[-0.00097075 -0.08202976  0.03807866 -0.8076555 ]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 425 is [True, False, False, False, True, False]
State prediction error at timestep 425 is 0.012
Human Feedback received at timestep 425 of -1
Current timestep = 426. State = [[-0.25074401  0.03011624]]. Action = [[ 0.06958269  0.00295367 -0.05823582  0.488878  ]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 426 is [True, False, False, False, True, False]
Current timestep = 427. State = [[-0.250119    0.03029722]]. Action = [[-0.0228494   0.05357748 -0.09173478  0.5688182 ]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 427 is [True, False, False, False, True, False]
State prediction error at timestep 427 is 0.012
Human Feedback received at timestep 427 of 1
Current timestep = 428. State = [[-0.24947801  0.03218273]]. Action = [[-0.06203667 -0.05185557  0.03793763 -0.68762636]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 428 is [True, False, False, False, True, False]
Current timestep = 429. State = [[-0.2494965   0.03229203]]. Action = [[ 0.04346477  0.09320938  0.04035216 -0.13253349]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 429 is [True, False, False, False, True, False]
Current timestep = 430. State = [[-0.24962728  0.0329957 ]]. Action = [[-0.00771398  0.01826577  0.07516175 -0.68535745]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 430 is [True, False, False, False, True, False]
State prediction error at timestep 430 is 0.012
Human Feedback received at timestep 430 of -1
Current timestep = 431. State = [[-0.24995267  0.03573108]]. Action = [[ 0.05677135 -0.02074119  0.07272732 -0.34598404]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 431 is [True, False, False, False, True, False]
Current timestep = 432. State = [[-0.24954899  0.03579683]]. Action = [[ 0.04193885 -0.02415978  0.04893904 -0.7631167 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 432 is [True, False, False, False, True, False]
State prediction error at timestep 432 is 0.012
Human Feedback received at timestep 432 of 1
Current timestep = 433. State = [[-0.24482352  0.03698034]]. Action = [[-0.02686401 -0.09515855  0.0173464   0.866186  ]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 433 is [True, False, False, False, True, False]
Current timestep = 434. State = [[-0.244192    0.03513339]]. Action = [[-0.08449087 -0.01299673 -0.01812258  0.6640625 ]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 434 is [True, False, False, False, True, False]
Current timestep = 435. State = [[-0.24413209  0.03362377]]. Action = [[-0.07287253 -0.08499196 -0.01178362 -0.01479512]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 435 is [True, False, False, False, True, False]
State prediction error at timestep 435 is 0.012
Human Feedback received at timestep 435 of -1
Current timestep = 436. State = [[-0.24739066  0.02612734]]. Action = [[-0.05904313  0.05740508  0.02857877 -0.5950826 ]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 436 is [True, False, False, False, True, False]
State prediction error at timestep 436 is 0.012
Human Feedback received at timestep 436 of -1
Current timestep = 437. State = [[-0.2498433   0.02667963]]. Action = [[-0.09654173  0.00264307  0.04716942  0.5140873 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 437 is [True, False, False, False, True, False]
Current timestep = 438. State = [[-0.2512052   0.02686653]]. Action = [[-0.09718434  0.01885413  0.05402618  0.5001869 ]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 438 is [True, False, False, False, True, False]
Current timestep = 439. State = [[-0.25359955  0.02739987]]. Action = [[ 0.06668853 -0.0651292   0.06416727  0.8095763 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 439 is [True, False, False, False, True, False]
Current timestep = 440. State = [[-0.25463447  0.02653866]]. Action = [[ 0.03342762  0.01814346 -0.01655057 -0.2590834 ]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 440 is [True, False, False, False, True, False]
Current timestep = 441. State = [[-0.2546419   0.02630704]]. Action = [[-0.09372902  0.09719586 -0.02911915  0.4045037 ]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 441 is [True, False, False, False, True, False]
Current timestep = 442. State = [[-0.25632378  0.02821204]]. Action = [[-0.05332578  0.0090837  -0.05706095 -0.8108663 ]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 442 is [True, False, False, False, True, False]
Current timestep = 443. State = [[-0.25849336  0.02994804]]. Action = [[-0.06812011  0.06725319  0.0805352  -0.4437071 ]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 443 is [True, False, False, False, True, False]
Current timestep = 444. State = [[-0.26185194  0.03280551]]. Action = [[-0.00712611  0.0995298  -0.06423876 -0.62653923]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 444 is [True, False, False, False, True, False]
Current timestep = 445. State = [[-0.26477742  0.03727124]]. Action = [[ 0.09703413  0.05453553  0.087294   -0.4946915 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 445 is [True, False, False, False, True, False]
Current timestep = 446. State = [[-0.26608115  0.04085813]]. Action = [[-0.01821793  0.07413789  0.00178708  0.66037965]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 446 is [True, False, False, False, True, False]
Current timestep = 447. State = [[-0.26753688  0.0449159 ]]. Action = [[ 0.00247018  0.05641594 -0.0191347  -0.25697613]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 447 is [True, False, False, False, True, False]
Current timestep = 448. State = [[-0.2692385   0.04870054]]. Action = [[-0.0342971  -0.08106737  0.06818109 -0.5842132 ]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 448 is [True, False, False, False, True, False]
Current timestep = 449. State = [[-0.26978385  0.04971647]]. Action = [[ 0.07372297  0.05353268 -0.07815239  0.09421408]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 449 is [True, False, False, False, True, False]
Current timestep = 450. State = [[-0.2701473   0.05053968]]. Action = [[ 0.01921485 -0.07225363  0.0655027  -0.8079358 ]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 450 is [True, False, False, False, True, False]
Current timestep = 451. State = [[-0.26990065  0.05040136]]. Action = [[-0.09678059  0.05455578 -0.03056832 -0.043814  ]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 451 is [True, False, False, False, True, False]
Current timestep = 452. State = [[-0.27041346  0.05146973]]. Action = [[-0.04726925 -0.01964069 -0.03964367  0.09428   ]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 452 is [True, False, False, False, True, False]
Current timestep = 453. State = [[-0.27087298  0.05191997]]. Action = [[ 0.0647961  0.0260021 -0.0145933  0.7845838]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 453 is [True, False, False, False, True, False]
Current timestep = 454. State = [[-0.27108085  0.05236938]]. Action = [[ 0.02510985 -0.04274772 -0.09315192 -0.248559  ]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 454 is [True, False, False, False, True, False]
State prediction error at timestep 454 is 0.012
Human Feedback received at timestep 454 of -1
Current timestep = 455. State = [[-0.27104217  0.05209205]]. Action = [[ 0.0651074  -0.04124139  0.02492224 -0.12591517]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 455 is [True, False, False, False, True, False]
Current timestep = 456. State = [[-0.27051762  0.05144397]]. Action = [[-0.097564   -0.03393858  0.00783952 -0.76892203]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 456 is [True, False, False, False, True, False]
Current timestep = 457. State = [[-0.27048877  0.0503296 ]]. Action = [[-0.01558197  0.00778686 -0.0825832   0.6488712 ]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 457 is [True, False, False, False, True, False]
Current timestep = 458. State = [[-0.27059984  0.04980111]]. Action = [[-0.05210643 -0.03358372  0.08211838 -0.6983514 ]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 458 is [True, False, False, False, True, False]
Current timestep = 459. State = [[-0.27160877  0.04886097]]. Action = [[-0.08981835  0.01250692  0.08632731 -0.62494725]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 459 is [True, False, False, False, True, False]
Current timestep = 460. State = [[-0.27299702  0.0484146 ]]. Action = [[ 0.07024831 -0.07263957 -0.08145192  0.6815803 ]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 460 is [True, False, False, False, True, False]
State prediction error at timestep 460 is 0.012
Human Feedback received at timestep 460 of -1
Current timestep = 461. State = [[-0.2735516   0.04439012]]. Action = [[0.08062708 0.07491467 0.04197269 0.7849951 ]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 461 is [True, False, False, False, True, False]
Current timestep = 462. State = [[-0.27352536  0.0444013 ]]. Action = [[ 0.03488613 -0.05896032  0.0873744  -0.9389544 ]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 462 is [True, False, False, False, True, False]
Current timestep = 463. State = [[-0.2734075  0.0443629]]. Action = [[ 0.03403526  0.03993172 -0.04122597  0.9115062 ]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 463 is [True, False, False, False, True, False]
Current timestep = 464. State = [[-0.27336305  0.04439056]]. Action = [[-0.0270206  -0.05123943 -0.08090671 -0.50400436]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 464 is [True, False, False, False, True, False]
Current timestep = 465. State = [[-0.27295768  0.04446881]]. Action = [[ 0.04615731  0.04132345 -0.09915034  0.290493  ]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 465 is [True, False, False, False, True, False]
State prediction error at timestep 465 is 0.012
Human Feedback received at timestep 465 of -1
Current timestep = 466. State = [[-0.27061749  0.04542587]]. Action = [[ 0.01622567 -0.00485907 -0.08736409 -0.45286238]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 466 is [True, False, False, False, True, False]
State prediction error at timestep 466 is 0.012
Human Feedback received at timestep 466 of -1
Current timestep = 467. State = [[-0.26926848  0.04578074]]. Action = [[ 0.05855576 -0.05541181 -0.05361391  0.9220178 ]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 467 is [True, False, False, False, True, False]
Current timestep = 468. State = [[-0.2683054   0.04484018]]. Action = [[-8.5717276e-02  3.6575012e-02 -9.7965226e-03  3.2782555e-05]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 468 is [True, False, False, False, True, False]
Current timestep = 469. State = [[-0.26844478  0.04498186]]. Action = [[-0.09894673  0.00388857 -0.03130484 -0.03090715]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 469 is [True, False, False, False, True, False]
State prediction error at timestep 469 is 0.012
Human Feedback received at timestep 469 of -1
Current timestep = 470. State = [[-0.26951426  0.04475617]]. Action = [[ 0.05917346 -0.03557009 -0.06295587  0.50279486]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 470 is [True, False, False, False, True, False]
Current timestep = 471. State = [[-0.26948756  0.04446644]]. Action = [[ 0.06771555  0.0289024  -0.03332519  0.06915569]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 471 is [True, False, False, False, True, False]
Current timestep = 472. State = [[-0.269435    0.04447094]]. Action = [[ 0.07767337 -0.04328289 -0.04388575  0.86710835]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 472 is [True, False, False, False, True, False]
Current timestep = 473. State = [[-0.26828748  0.04336077]]. Action = [[-0.08001698 -0.07751729 -0.00433614 -0.4200771 ]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 473 is [True, False, False, False, True, False]
State prediction error at timestep 473 is 0.012
Human Feedback received at timestep 473 of -1
Current timestep = 474. State = [[-0.26762164  0.03634669]]. Action = [[-0.02025385 -0.00455423 -0.09242383  0.59956586]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 474 is [True, False, False, False, True, False]
Current timestep = 475. State = [[-0.26764497  0.03598752]]. Action = [[-0.03874698 -0.0768189   0.07042017  0.22140479]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 475 is [True, False, False, False, True, False]
Current timestep = 476. State = [[-0.26761767  0.03433712]]. Action = [[-0.01856872  0.08578249  0.04202113  0.17878878]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 476 is [True, False, False, False, True, False]
Current timestep = 477. State = [[-0.26797146  0.03476612]]. Action = [[-0.05779477  0.03662264  0.00490193  0.28349924]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 477 is [True, False, False, False, True, False]
Current timestep = 478. State = [[-0.26875916  0.03527501]]. Action = [[ 0.02176622 -0.09590584  0.06685538 -0.93396616]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 478 is [True, False, False, False, True, False]
Current timestep = 479. State = [[-0.268938    0.03409562]]. Action = [[ 0.07070523  0.03852307  0.03735029 -0.90368253]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 479 is [True, False, False, False, True, False]
Current timestep = 480. State = [[-0.26882726  0.03380606]]. Action = [[ 0.03695448  0.01963146 -0.02643276 -0.05145156]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 480 is [True, False, False, False, True, False]
Current timestep = 481. State = [[-0.268938    0.03411308]]. Action = [[-0.02984937 -0.00442631 -0.06639883 -0.39157444]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 481 is [True, False, False, False, True, False]
State prediction error at timestep 481 is 0.012
Human Feedback received at timestep 481 of -1
Current timestep = 482. State = [[-0.26883867  0.03396704]]. Action = [[-0.08403208 -0.06928013  0.06939218 -0.65935105]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 482 is [True, False, False, False, True, False]
Current timestep = 483. State = [[-0.26929885  0.03314546]]. Action = [[ 0.0970461   0.07717503 -0.04928295 -0.646887  ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 483 is [True, False, False, False, True, False]
Current timestep = 484. State = [[-0.26948333  0.03341028]]. Action = [[-0.03947439  0.06930763 -0.01031894 -0.07366562]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 484 is [True, False, False, False, True, False]
Current timestep = 485. State = [[-0.26990813  0.03453032]]. Action = [[-0.08212     0.06020498 -0.02188978 -0.70521474]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 485 is [True, False, False, False, True, False]
Current timestep = 486. State = [[-0.27080154  0.03665923]]. Action = [[-0.02526207 -0.02032774 -0.08562513 -0.6612668 ]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 486 is [True, False, False, False, True, False]
Current timestep = 487. State = [[-0.2714807   0.03809916]]. Action = [[ 0.08378346  0.05852631 -0.0723224   0.6093693 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 487 is [True, False, False, False, True, False]
Current timestep = 488. State = [[-0.2719858   0.03977589]]. Action = [[ 0.01520833  0.07900851  0.09224354 -0.1810801 ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 488 is [True, False, False, False, True, False]
Current timestep = 489. State = [[-0.2726829   0.04220887]]. Action = [[ 0.07807096 -0.04503169 -0.09960822 -0.40708613]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 489 is [True, False, False, False, True, False]
Current timestep = 490. State = [[-0.2724125   0.04289231]]. Action = [[ 0.0590279   0.0456939   0.00695715 -0.23237932]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 490 is [True, False, False, False, True, False]
State prediction error at timestep 490 is 0.012
Human Feedback received at timestep 490 of -1
Current timestep = 491. State = [[-0.26963082  0.04635679]]. Action = [[ 0.06803065 -0.01247806 -0.06147787 -0.24252224]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 491 is [True, False, False, False, True, False]
State prediction error at timestep 491 is 0.012
Human Feedback received at timestep 491 of 1
Current timestep = 492. State = [[-0.2675183   0.04685514]]. Action = [[ 0.0067096   0.04962393  0.05131821 -0.35204238]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 492 is [True, False, False, False, True, False]
Current timestep = 493. State = [[-0.26722363  0.04770595]]. Action = [[ 0.00767819  0.06155092 -0.05887143 -0.71714187]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 493 is [True, False, False, False, True, False]
State prediction error at timestep 493 is 0.012
Human Feedback received at timestep 493 of 1
Current timestep = 494. State = [[-0.26635402  0.05334835]]. Action = [[-0.007531   -0.07783411  0.06684672 -0.20175159]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 494 is [True, False, False, False, True, False]
Current timestep = 495. State = [[-0.26609588  0.05320903]]. Action = [[0.0216864  0.01927565 0.08288755 0.06876302]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 495 is [True, False, False, False, True, False]
Current timestep = 496. State = [[-0.26574776  0.05296224]]. Action = [[ 0.06128144 -0.07179403 -0.0443458  -0.14420271]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 496 is [True, False, False, False, True, False]
Current timestep = 497. State = [[-0.26427236  0.05160646]]. Action = [[ 0.08788811 -0.01873811  0.00360207 -0.15000159]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 497 is [True, False, False, False, True, False]
State prediction error at timestep 497 is 0.012
Human Feedback received at timestep 497 of 1
Current timestep = 498. State = [[-0.25773212  0.0491731 ]]. Action = [[ 0.09660014 -0.07947445 -0.00461353 -0.6509905 ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 498 is [True, False, False, False, True, False]
Current timestep = 499. State = [[-0.2559645   0.04725837]]. Action = [[ 0.01835684  0.08355958  0.06597596 -0.0060041 ]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 499 is [True, False, False, False, True, False]
State prediction error at timestep 499 is 0.012
Human Feedback received at timestep 499 of 1
Current timestep = 500. State = [[-0.24758774  0.04869174]]. Action = [[ 0.00889243 -0.01560266  0.04214147 -0.44918495]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 500 is [True, False, False, False, True, False]
Current timestep = 501. State = [[-0.24752553  0.04870639]]. Action = [[ 0.03274115  0.02789339 -0.03956884  0.17022693]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 501 is [True, False, False, False, True, False]
State prediction error at timestep 501 is 0.012
Human Feedback received at timestep 501 of 1
Current timestep = 502. State = [[-0.24508613  0.04914029]]. Action = [[ 0.09677943 -0.05883095  0.09259539  0.52146196]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 502 is [True, False, False, False, True, False]
Current timestep = 503. State = [[-0.24350359  0.04793991]]. Action = [[ 0.05006734  0.0680356   0.03303082 -0.11701512]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 503 is [True, False, False, False, True, False]
Current timestep = 504. State = [[-0.24076872  0.04862145]]. Action = [[-0.05686605  0.06343009  0.04966799  0.72881794]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 504 is [True, False, False, False, True, False]
State prediction error at timestep 504 is 0.012
Human Feedback received at timestep 504 of 1
Current timestep = 505. State = [[-0.23601905  0.05146831]]. Action = [[-0.0522093  -0.03428001 -0.09793097  0.7778163 ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 505 is [True, False, False, False, True, False]
Current timestep = 506. State = [[-0.23601615  0.05140467]]. Action = [[-0.02516241 -0.02094136 -0.00922305  0.774933  ]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 506 is [True, False, False, False, True, False]
State prediction error at timestep 506 is 0.012
Human Feedback received at timestep 506 of 1
Current timestep = 507. State = [[-0.23602228  0.05150827]]. Action = [[-0.01832598  0.07522105 -0.08580784  0.9059336 ]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 507 is [True, False, False, False, True, False]
Current timestep = 508. State = [[-0.23638885  0.05213759]]. Action = [[-0.02457923 -0.05363314  0.06125312 -0.37792307]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 508 is [True, False, False, False, True, False]
State prediction error at timestep 508 is 0.012
Human Feedback received at timestep 508 of -1
Current timestep = 509. State = [[-0.23645727  0.05208728]]. Action = [[ 0.09021027  0.04537129 -0.02991519 -0.7929649 ]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 509 is [True, False, False, False, True, False]
Current timestep = 510. State = [[-0.23637363  0.05203131]]. Action = [[ 0.09514385 -0.08907235 -0.00159892  0.21174324]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 510 is [True, False, False, False, True, False]
State prediction error at timestep 510 is 0.012
Human Feedback received at timestep 510 of 1
Current timestep = 511. State = [[-0.23373505  0.05022435]]. Action = [[ 0.07141203 -0.02215929 -0.006641   -0.3633207 ]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 511 is [True, False, False, False, True, False]
Current timestep = 512. State = [[-0.23268634  0.04956387]]. Action = [[ 0.07312217 -0.05264485 -0.00724627  0.7472129 ]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 512 is [True, False, False, False, True, False]
Current timestep = 513. State = [[-0.23045167  0.04741088]]. Action = [[ 0.02823288 -0.06740317  0.07830252  0.34089684]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 513 is [True, False, False, False, True, False]
Current timestep = 514. State = [[-0.2282976   0.04465662]]. Action = [[-0.07947282  0.01395305 -0.02153907 -0.17455852]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 514 is [True, False, False, False, True, False]
Current timestep = 515. State = [[-0.2277137   0.04358361]]. Action = [[-0.05044181  0.03792246 -0.07002416 -0.8972438 ]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 515 is [True, False, False, False, True, False]
Current timestep = 516. State = [[-0.22776884  0.04393446]]. Action = [[-0.03518949  0.01352175  0.07416018 -0.97962   ]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 516 is [True, False, False, False, True, False]
Current timestep = 517. State = [[-0.22776704  0.04387046]]. Action = [[ 0.04667943  0.05283295 -0.01836594 -0.28167975]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 517 is [True, False, False, False, True, False]
State prediction error at timestep 517 is 0.012
Human Feedback received at timestep 517 of 1
Current timestep = 518. State = [[-0.22795324  0.04425746]]. Action = [[-0.08400543 -0.0681702  -0.07220963  0.69756424]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 518 is [True, False, False, False, True, False]
State prediction error at timestep 518 is 0.012
Human Feedback received at timestep 518 of -1
Current timestep = 519. State = [[-0.22803313  0.0442284 ]]. Action = [[-0.08410473  0.0457414   0.04229074 -0.5958358 ]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 519 is [True, False, False, False, True, False]
Current timestep = 520. State = [[-0.22833464  0.04480543]]. Action = [[ 0.07279556  0.08518731 -0.08691346  0.5744257 ]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 520 is [True, False, False, False, True, False]
Current timestep = 521. State = [[-0.228811    0.04615427]]. Action = [[ 0.06899785 -0.03888924  0.02637259 -0.8461533 ]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 521 is [True, False, False, False, True, False]
Current timestep = 522. State = [[-0.2287392   0.04608226]]. Action = [[ 0.07923584  0.02884784 -0.05105818  0.8008146 ]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 522 is [True, False, False, False, True, False]
Current timestep = 523. State = [[-0.22838314  0.04643999]]. Action = [[-0.09534995  0.00646478  0.03444055 -0.17469162]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 523 is [True, False, False, False, True, False]
Current timestep = 524. State = [[-0.22849663  0.04681057]]. Action = [[ 0.03655665 -0.06649028 -0.01030201 -0.7645536 ]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 524 is [True, False, False, False, True, False]
Current timestep = 525. State = [[-0.22841026  0.04655235]]. Action = [[ 0.09522197 -0.06534435  0.05730293  0.04693067]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 525 is [True, False, False, False, True, False]
Current timestep = 526. State = [[-0.22735655  0.04475729]]. Action = [[-0.03905302 -0.03439987 -0.07146388 -0.47537816]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 526 is [True, False, False, False, True, False]
Current timestep = 527. State = [[-0.22668438  0.04356368]]. Action = [[-0.05733531  0.04862375  0.05627527  0.57581973]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 527 is [True, False, False, False, True, False]
State prediction error at timestep 527 is 0.012
Human Feedback received at timestep 527 of -1
Current timestep = 528. State = [[-0.22685501  0.04368388]]. Action = [[ 0.01642083 -0.02727268  0.07146966  0.18196094]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 528 is [True, False, False, False, True, False]
State prediction error at timestep 528 is 0.012
Human Feedback received at timestep 528 of 1
Current timestep = 529. State = [[-0.22666721  0.04345887]]. Action = [[0.09173387 0.06541219 0.02426203 0.7012117 ]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 529 is [True, False, False, False, True, False]
State prediction error at timestep 529 is 0.012
Human Feedback received at timestep 529 of 1
Current timestep = 530. State = [[-0.22579393  0.04386858]]. Action = [[-0.07461113  0.09856474  0.06286829 -0.6181594 ]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 530 is [True, False, False, False, True, False]
State prediction error at timestep 530 is 0.012
Human Feedback received at timestep 530 of 1
Current timestep = 531. State = [[-0.2269907   0.04882189]]. Action = [[-0.08068784 -0.05981946  0.0556784  -0.479398  ]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 531 is [True, False, False, False, True, False]
Current timestep = 532. State = [[-0.2269907   0.04882189]]. Action = [[0.04585969 0.04062837 0.01532783 0.1331358 ]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 532 is [True, False, False, False, True, False]
Current timestep = 533. State = [[-0.2269907   0.04882189]]. Action = [[-0.00960327 -0.04289803 -0.02717405  0.34462285]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 533 is [True, False, False, False, True, False]
State prediction error at timestep 533 is 0.012
Human Feedback received at timestep 533 of -1
Current timestep = 534. State = [[-0.22698827  0.04875775]]. Action = [[-0.09030557 -0.03809397  0.04741592 -0.5598222 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 534 is [True, False, False, False, True, False]
Current timestep = 535. State = [[-0.22699586  0.04809058]]. Action = [[ 0.02972492 -0.08811817 -0.01607968  0.572804  ]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 535 is [True, False, False, False, True, False]
Current timestep = 536. State = [[-0.22644787  0.04578362]]. Action = [[ 0.08292889 -0.00729389  0.05762541  0.77230334]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 536 is [True, False, False, False, True, False]
State prediction error at timestep 536 is 0.012
Human Feedback received at timestep 536 of -1
Current timestep = 537. State = [[-0.22522964  0.04234314]]. Action = [[ 0.07094084  0.06247955 -0.04977294 -0.9806415 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 537 is [True, False, False, False, True, False]
Current timestep = 538. State = [[-0.22518317  0.04232932]]. Action = [[ 0.03295118 -0.09910754  0.09189408 -0.5560324 ]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 538 is [True, False, False, False, True, False]
Current timestep = 539. State = [[-0.22448526  0.04082531]]. Action = [[-0.00840111 -0.07207593 -0.05463451 -0.2840904 ]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 539 is [True, False, False, False, True, False]
State prediction error at timestep 539 is 0.012
Human Feedback received at timestep 539 of 1
Current timestep = 540. State = [[-0.22125944  0.03285762]]. Action = [[ 0.07145392  0.07542294 -0.04076539 -0.42179275]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 540 is [True, False, False, False, True, False]
Current timestep = 541. State = [[-0.22129758  0.03308566]]. Action = [[-0.06320062  0.05031686 -0.04580928 -0.83937025]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 541 is [True, False, False, False, True, False]
Current timestep = 542. State = [[-0.22153367  0.03403072]]. Action = [[ 0.01695845 -0.0847486  -0.09837933  0.9404931 ]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 542 is [True, False, False, False, True, False]
State prediction error at timestep 542 is 0.012
Human Feedback received at timestep 542 of 1
Current timestep = 543. State = [[-0.22140132  0.03368038]]. Action = [[ 0.07367922 -0.01790107  0.07488429 -0.4721111 ]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 543 is [True, False, False, False, True, False]
State prediction error at timestep 543 is 0.012
Human Feedback received at timestep 543 of 1
Current timestep = 544. State = [[-0.22038358  0.03246742]]. Action = [[-0.03570401  0.07485887 -0.05284622  0.67991495]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 544 is [True, False, False, False, True, False]
Current timestep = 545. State = [[-0.22035079  0.03329306]]. Action = [[-0.01100727 -0.07426924 -0.0918029   0.47194982]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 545 is [True, False, False, False, True, False]
Current timestep = 546. State = [[-0.22032583  0.0328435 ]]. Action = [[-0.04275542  0.06937578 -0.06442273 -0.33416986]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 546 is [True, False, False, False, True, False]
Current timestep = 547. State = [[-0.22049159  0.03321112]]. Action = [[-0.04833544 -0.09379338  0.07553323  0.6217084 ]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 547 is [True, False, False, False, True, False]
Current timestep = 548. State = [[-0.22026403  0.03285676]]. Action = [[ 0.08352182  0.07422017 -0.02134883  0.40902376]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 548 is [True, False, False, False, True, False]
Current timestep = 549. State = [[-0.22031371  0.03311196]]. Action = [[-0.02799673  0.06321978 -0.02256883 -0.9365571 ]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 549 is [True, False, False, False, True, False]
State prediction error at timestep 549 is 0.012
Human Feedback received at timestep 549 of 1
Current timestep = 550. State = [[-0.22094364  0.03647571]]. Action = [[-0.05512981  0.01656814 -0.0360012  -0.13116324]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 550 is [True, False, False, False, True, False]
Current timestep = 551. State = [[-0.22107358  0.03705898]]. Action = [[-0.03146157  0.05766477  0.01920881 -0.41768026]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 551 is [True, False, False, False, True, False]
Current timestep = 552. State = [[-0.22163756  0.03876715]]. Action = [[-0.03157199  0.03697485  0.0853573  -0.23048872]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 552 is [True, False, False, False, True, False]
State prediction error at timestep 552 is 0.012
Human Feedback received at timestep 552 of -1
Current timestep = 553. State = [[-0.22363698  0.0440278 ]]. Action = [[ 0.00421421 -0.04098063  0.06567769 -0.13289559]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 553 is [True, False, False, False, True, False]
Current timestep = 554. State = [[-0.22363874  0.04409205]]. Action = [[ 0.0723364   0.09494751 -0.03514596 -0.6156328 ]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 554 is [True, False, False, False, True, False]
Current timestep = 555. State = [[-0.22389421  0.04526436]]. Action = [[-0.00902926  0.01379089  0.03616071  0.25241554]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 555 is [True, False, False, False, True, False]
Current timestep = 556. State = [[-0.2240327   0.04590763]]. Action = [[-0.06451979 -0.08811558 -0.00583059 -0.21468842]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 556 is [True, False, False, False, True, False]
State prediction error at timestep 556 is 0.012
Human Feedback received at timestep 556 of -1
Current timestep = 557. State = [[-0.22400251  0.04576991]]. Action = [[ 0.03168794  0.06054413  0.0615019  -0.7844381 ]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 557 is [True, False, False, False, True, False]
Current timestep = 558. State = [[-0.22413145  0.0460922 ]]. Action = [[ 0.05601392 -0.05366596 -0.04696042 -0.17573798]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 558 is [True, False, False, False, True, False]
Current timestep = 559. State = [[-0.22399187  0.04582486]]. Action = [[ 0.05176198 -0.09039542  0.08955019 -0.8369373 ]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 559 is [True, False, False, False, True, False]
Current timestep = 560. State = [[-0.22332889  0.0441526 ]]. Action = [[-0.03837786  0.04526607  0.00646199  0.9375632 ]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 560 is [True, False, False, False, True, False]
Current timestep = 561. State = [[-0.22337724  0.04425941]]. Action = [[-0.01419838  0.01155837 -0.07180029 -0.05836856]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 561 is [True, False, False, False, True, False]
Current timestep = 562. State = [[-0.22337724  0.04425941]]. Action = [[-0.02549524 -0.00402541 -0.07355887 -0.59274405]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 562 is [True, False, False, False, True, False]
Current timestep = 563. State = [[-0.22335717  0.04420929]]. Action = [[ 0.09274534  0.00180402 -0.02253181 -0.06339782]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 563 is [True, False, False, False, True, False]
Current timestep = 564. State = [[-0.222896    0.04433151]]. Action = [[ 0.07493392  0.06214013 -0.05047372  0.3664478 ]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 564 is [True, False, False, False, True, False]
Current timestep = 565. State = [[-0.22096592  0.04503744]]. Action = [[ 0.02352931  0.06240831  0.07933437 -0.92032325]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 565 is [True, False, False, False, True, False]
Current timestep = 566. State = [[-0.21827284  0.04661959]]. Action = [[-0.00052937 -0.00813042  0.05502198 -0.08056515]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 566 is [True, False, False, False, True, False]
State prediction error at timestep 566 is 0.012
Human Feedback received at timestep 566 of -1
Current timestep = 567. State = [[-0.21010922  0.04950294]]. Action = [[ 0.04875293  0.02897847 -0.00341047  0.5677208 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 567 is [True, False, False, False, True, False]
Current timestep = 568. State = [[-0.20905378  0.04995446]]. Action = [[-0.01737469  0.03130656  0.09204312 -0.34987712]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 568 is [True, False, False, False, True, False]
Current timestep = 569. State = [[-0.20837297  0.05097979]]. Action = [[ 0.08407217  0.08135977 -0.09930187  0.7516494 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 569 is [True, False, False, False, True, False]
Current timestep = 570. State = [[-0.20654504  0.05344505]]. Action = [[ 0.01385465 -0.02873067  0.09676906 -0.23393238]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 570 is [True, False, False, False, True, False]
Current timestep = 571. State = [[-0.20468086  0.05465418]]. Action = [[ 0.02122394 -0.01085789  0.09860522  0.7352762 ]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 571 is [True, False, False, False, True, False]
Current timestep = 572. State = [[-0.20325767  0.05531225]]. Action = [[0.0414579  0.09466485 0.08982681 0.7069384 ]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 572 is [True, False, False, False, True, False]
Current timestep = 573. State = [[-0.20168251  0.05769505]]. Action = [[-0.07910393 -0.01579689 -0.03198915  0.6663703 ]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 573 is [True, False, False, False, True, False]
Current timestep = 574. State = [[-0.20168085  0.05897599]]. Action = [[ 0.00518954 -0.06085864  0.00677087  0.27689946]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 574 is [True, False, False, False, True, False]
Current timestep = 575. State = [[-0.20160234  0.05899526]]. Action = [[-0.01019163  0.02436092 -0.07960041  0.74184394]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 575 is [True, False, False, False, True, False]
Current timestep = 576. State = [[-0.20184945  0.05934519]]. Action = [[-0.06154616  0.0736055   0.08761289 -0.4359668 ]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 576 is [True, False, False, False, True, False]
Current timestep = 577. State = [[-0.20264144  0.06123528]]. Action = [[-0.06189437 -0.04429758 -0.03209163  0.48023248]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 577 is [True, False, False, False, True, False]
Current timestep = 578. State = [[-0.2031346   0.06213664]]. Action = [[-0.01082579  0.03918456 -0.07208042 -0.76718426]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 578 is [True, False, False, False, True, False]
Current timestep = 579. State = [[-0.20388387  0.06349906]]. Action = [[ 0.04097646  0.06950911 -0.0525694  -0.5215869 ]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 579 is [True, False, False, False, True, False]
Current timestep = 580. State = [[-0.20485884  0.06565551]]. Action = [[-0.06010491 -0.09955843  0.03621646 -0.52445275]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 580 is [True, False, False, False, True, False]
Current timestep = 581. State = [[-0.20504819  0.06585021]]. Action = [[ 0.04876661  0.05430878  0.07584111 -0.16657639]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 581 is [True, False, False, False, True, False]
Current timestep = 582. State = [[-0.20523146  0.06601127]]. Action = [[ 0.0254392  -0.06244842  0.03824455  0.7543514 ]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 582 is [True, False, False, False, True, False]
Current timestep = 583. State = [[-0.20522407  0.06609363]]. Action = [[-0.07820434  0.0916147   0.05186444 -0.16540015]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 583 is [True, False, False, False, True, False]
State prediction error at timestep 583 is 0.012
Human Feedback received at timestep 583 of 1
Current timestep = 584. State = [[-0.20695154  0.06986184]]. Action = [[0.04580378 0.04355856 0.03883372 0.53009677]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 584 is [True, False, False, False, True, False]
Current timestep = 585. State = [[-0.20716499  0.07035099]]. Action = [[ 0.00155725 -0.05694128  0.02662555 -0.6675591 ]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 585 is [True, False, False, False, True, False]
State prediction error at timestep 585 is 0.012
Human Feedback received at timestep 585 of -1
Current timestep = 586. State = [[-0.20713644  0.07022979]]. Action = [[ 0.00535686 -0.0031271   0.04153534 -0.9825558 ]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 586 is [True, False, False, False, True, False]
Current timestep = 587. State = [[-0.20713644  0.07022979]]. Action = [[-0.05737407 -0.01963631  0.08540165  0.19064772]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 587 is [True, False, False, False, True, False]
Current timestep = 588. State = [[-0.20711139  0.07004324]]. Action = [[ 0.00677641 -0.0752698   0.05090856 -0.74670553]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 588 is [True, False, False, False, True, False]
Current timestep = 589. State = [[-0.20676114  0.06841394]]. Action = [[0.04468635 0.0248066  0.05436348 0.48469043]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 589 is [True, False, False, False, True, False]
State prediction error at timestep 589 is 0.012
Human Feedback received at timestep 589 of 1
Current timestep = 590. State = [[-0.20670451  0.06768715]]. Action = [[-0.09052147  0.09564602  0.06476267  0.5644152 ]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 590 is [True, False, False, False, True, False]
Current timestep = 591. State = [[-0.20735511  0.06911136]]. Action = [[-0.06523684  0.01513074 -0.00348308  0.4672519 ]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 591 is [True, False, False, False, True, False]
State prediction error at timestep 591 is 0.012
Human Feedback received at timestep 591 of -1
Current timestep = 592. State = [[-0.20951314  0.07301702]]. Action = [[-0.02196235 -0.03009898 -0.05623062 -0.02628273]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 592 is [True, False, False, False, True, False]
State prediction error at timestep 592 is 0.012
Human Feedback received at timestep 592 of -1
Current timestep = 593. State = [[-0.20954955  0.07273689]]. Action = [[-0.01901784 -0.02627609  0.08311614  0.9892664 ]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 593 is [True, False, False, False, True, False]
Current timestep = 594. State = [[-0.20966238  0.0724201 ]]. Action = [[-0.06477769 -0.07747892 -0.08842966  0.07841158]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 594 is [True, False, False, False, True, False]
Current timestep = 595. State = [[-0.21051802  0.07057472]]. Action = [[ 0.02720527  0.05066619 -0.03894    -0.49601126]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 595 is [True, False, False, False, True, False]
Current timestep = 596. State = [[-0.21111217  0.07086343]]. Action = [[-0.0278063   0.08954474  0.02044933  0.9023584 ]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 596 is [True, False, False, False, True, False]
Current timestep = 597. State = [[-0.21222104  0.07244197]]. Action = [[-0.09457643  0.04094883 -0.06740455 -0.36075795]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 597 is [True, False, False, False, True, False]
Current timestep = 598. State = [[-0.21421297  0.07484915]]. Action = [[-0.00857156 -0.00180315 -0.02813222 -0.37717366]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 598 is [True, False, False, False, True, False]
State prediction error at timestep 598 is 0.012
Human Feedback received at timestep 598 of -1
Current timestep = 599. State = [[-0.22008863  0.07903543]]. Action = [[-0.02096254  0.03001337 -0.08340523 -0.4948995 ]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 599 is [True, False, False, False, True, False]
Current timestep = 600. State = [[-0.2204936   0.07967649]]. Action = [[-0.03135657  0.06714403 -0.09431948  0.8964596 ]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 600 is [True, False, False, False, True, False]
State prediction error at timestep 600 is 0.012
Human Feedback received at timestep 600 of -1
Current timestep = 601. State = [[-0.22377296  0.08581952]]. Action = [[-0.02650841 -0.01908581 -0.03501461 -0.8332626 ]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 601 is [True, False, False, False, True, False]
Current timestep = 602. State = [[-0.22412962  0.08562058]]. Action = [[-0.09784143 -0.07845176  0.02220396 -0.53988665]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 602 is [True, False, False, False, True, False]
Current timestep = 603. State = [[-0.22569576  0.08367578]]. Action = [[ 0.06057393 -0.02128365  0.00321659  0.02834129]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 603 is [True, False, False, False, True, False]
Current timestep = 604. State = [[-0.22611748  0.08253147]]. Action = [[ 0.09332841  0.02251764 -0.06423526  0.6058736 ]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 604 is [True, False, False, False, True, False]
Current timestep = 605. State = [[-0.22597834  0.08215467]]. Action = [[-0.04041376  0.07312278 -0.04011678  0.3625015 ]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 605 is [True, False, False, False, True, False]
Current timestep = 606. State = [[-0.22604734  0.08261304]]. Action = [[-0.00737274 -0.01076124  0.08106064  0.25468063]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 606 is [True, False, False, False, True, False]
Current timestep = 607. State = [[-0.22610256  0.08277672]]. Action = [[0.04117803 0.03161114 0.02179315 0.14701807]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 607 is [True, False, False, False, True, False]
Current timestep = 608. State = [[-0.22628292  0.08314168]]. Action = [[-0.09439955  0.09989469 -0.02642988  0.16068304]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 608 is [True, False, False, False, True, False]
State prediction error at timestep 608 is 0.012
Human Feedback received at timestep 608 of -1
Current timestep = 609. State = [[-0.23062013  0.09171195]]. Action = [[ 0.06396099 -0.03718161 -0.05049421  0.05816877]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 609 is [True, False, False, False, True, False]
State prediction error at timestep 609 is 0.012
Human Feedback received at timestep 609 of -1
Current timestep = 610. State = [[-0.23061179  0.09178757]]. Action = [[-0.07346742  0.0928702  -0.05703734 -0.72642225]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 610 is [True, False, False, False, True, False]
Current timestep = 611. State = [[-0.23120482  0.09295593]]. Action = [[ 8.422509e-04 -8.657336e-02  9.843544e-02  8.458307e-01]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 611 is [True, False, False, False, True, False]
Current timestep = 612. State = [[-0.23120117  0.09278061]]. Action = [[-0.01633822  0.0903812   0.04471775 -0.06595856]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 612 is [True, False, False, False, True, False]
Current timestep = 613. State = [[-0.23197484  0.09427249]]. Action = [[-0.08356193  0.07509466 -0.02065491 -0.32690245]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 613 is [True, False, False, False, True, False]
Current timestep = 614. State = [[-0.23351093  0.09729011]]. Action = [[ 0.01903339 -0.00937527 -0.05591431  0.22672677]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 614 is [True, False, False, False, True, False]
Current timestep = 615. State = [[-0.2345325  0.0991827]]. Action = [[ 0.04779836 -0.0562859   0.06919309  0.3957746 ]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 615 is [True, False, False, False, True, False]
Current timestep = 616. State = [[-0.23434734  0.09878069]]. Action = [[ 0.05110728 -0.06561787 -0.09437811  0.7569829 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 616 is [True, False, False, False, True, False]
Current timestep = 617. State = [[-0.23381947  0.09771555]]. Action = [[ 0.0856423   0.09938668 -0.0189276  -0.47485673]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 617 is [True, False, False, False, True, False]
Current timestep = 618. State = [[-0.23397939  0.09848158]]. Action = [[ 0.09350535  0.03010996 -0.02239557 -0.97987205]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 618 is [True, False, False, False, True, False]
Current timestep = 619. State = [[-0.2327898   0.09886715]]. Action = [[ 0.03684215  0.03804659 -0.02053562  0.23448598]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 619 is [True, False, False, False, True, False]
Current timestep = 620. State = [[-0.23149422  0.09922668]]. Action = [[0.09896632 0.02823228 0.06077533 0.98905706]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 620 is [True, False, False, False, True, False]
Current timestep = 621. State = [[-0.22942851  0.10018554]]. Action = [[ 0.07467472  0.00581938 -0.04764849 -0.9938354 ]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 621 is [True, False, False, False, True, False]
State prediction error at timestep 621 is 0.012
Human Feedback received at timestep 621 of 1
Current timestep = 622. State = [[-0.21910636  0.10435306]]. Action = [[ 0.00098898  0.0966697  -0.0557702   0.7894455 ]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 622 is [True, False, False, False, True, False]
State prediction error at timestep 622 is 0.012
Human Feedback received at timestep 622 of 1
Current timestep = 623. State = [[-0.21767195  0.10825741]]. Action = [[-0.03582539 -0.05948996 -0.06613323  0.44535136]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 623 is [True, False, False, False, True, False]
State prediction error at timestep 623 is 0.012
Human Feedback received at timestep 623 of -1
Current timestep = 624. State = [[-0.21767904  0.10830132]]. Action = [[-0.00566722  0.06642725  0.08053162  0.6773325 ]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 624 is [True, False, False, False, True, False]
Current timestep = 625. State = [[-0.21779631  0.10852364]]. Action = [[-0.04299963 -0.04385731  0.09550043 -0.15665197]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 625 is [True, False, False, False, True, False]
Current timestep = 626. State = [[-0.21779631  0.10852364]]. Action = [[0.0787892  0.01992594 0.01964937 0.95648146]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 626 is [True, False, False, False, True, False]
State prediction error at timestep 626 is 0.012
Human Feedback received at timestep 626 of -1
Current timestep = 627. State = [[-0.21762702  0.10861063]]. Action = [[ 0.08844181  0.03697538  0.02666213 -0.3434568 ]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 627 is [True, False, False, False, True, False]
State prediction error at timestep 627 is 0.012
Human Feedback received at timestep 627 of 1
Current timestep = 628. State = [[-0.2117523   0.11142559]]. Action = [[-0.05698236 -0.07727917  0.05102771 -0.55647093]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 628 is [True, False, False, False, True, False]
Current timestep = 629. State = [[-0.211465    0.11116286]]. Action = [[ 0.05094697  0.03670716  0.08759933 -0.05748993]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 629 is [True, False, False, False, True, False]
Current timestep = 630. State = [[-0.21120293  0.11157151]]. Action = [[-0.05336151  0.08737039 -0.0058944  -0.03152585]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 630 is [True, False, False, False, True, False]
Current timestep = 631. State = [[-0.21173453  0.11273373]]. Action = [[ 0.02723116  0.01036346 -0.03786927  0.4979713 ]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 631 is [True, False, False, False, True, False]
Current timestep = 632. State = [[-0.21219209  0.11370883]]. Action = [[ 0.01595028  0.09896594 -0.0797961   0.42594278]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 632 is [True, False, False, False, True, False]
Current timestep = 633. State = [[-0.21217705  0.11616567]]. Action = [[-0.05523187 -0.04066811  0.01401584 -0.12818384]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 633 is [True, False, False, False, True, False]
State prediction error at timestep 633 is 0.012
Human Feedback received at timestep 633 of 1
Current timestep = 634. State = [[-0.21382163  0.11937645]]. Action = [[-0.0094514  -0.04509208 -0.04450374 -0.60036016]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 634 is [True, False, False, False, True, False]
State prediction error at timestep 634 is 0.012
Human Feedback received at timestep 634 of 1
Current timestep = 635. State = [[-0.21368647  0.11919852]]. Action = [[ 0.06842463 -0.07816436  0.08083516 -0.2783476 ]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 635 is [True, False, False, False, True, False]
State prediction error at timestep 635 is 0.012
Human Feedback received at timestep 635 of 1
Current timestep = 636. State = [[-0.21165301  0.11707669]]. Action = [[ 0.038228   -0.08503304  0.0550678  -0.7730674 ]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 636 is [True, False, False, False, True, False]
State prediction error at timestep 636 is 0.012
Human Feedback received at timestep 636 of 1
Current timestep = 637. State = [[-0.20966087  0.11193424]]. Action = [[ 0.07154364  0.0973851  -0.0469716   0.05149865]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 637 is [True, False, False, False, True, False]
State prediction error at timestep 637 is 0.012
Human Feedback received at timestep 637 of 1
Current timestep = 638. State = [[-0.20772864  0.11304282]]. Action = [[-0.08196685 -0.08470008  0.05683481 -0.17770249]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 638 is [True, False, False, False, True, False]
Current timestep = 639. State = [[-0.20757604  0.11276773]]. Action = [[-0.00391995  0.02402687  0.00379225  0.28788435]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 639 is [True, False, False, False, True, False]
Current timestep = 640. State = [[-0.20750478  0.11245591]]. Action = [[ 0.05254122 -0.07084224 -0.02729597 -0.51357603]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 640 is [True, False, False, False, True, False]
Current timestep = 641. State = [[-0.20695445  0.11116754]]. Action = [[ 0.04348443  0.05216476  0.08028281 -0.21810913]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 641 is [True, False, False, False, True, False]
Current timestep = 642. State = [[-0.20685157  0.11118697]]. Action = [[-0.06299232  0.07454646  0.08416408 -0.2744394 ]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 642 is [True, False, False, False, True, False]
Current timestep = 643. State = [[-0.20737554  0.11220106]]. Action = [[-0.05120852 -0.06481425  0.09262701  0.7658851 ]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 643 is [True, False, False, False, True, False]
State prediction error at timestep 643 is 0.012
Human Feedback received at timestep 643 of 1
Current timestep = 644. State = [[-0.20737423  0.11164179]]. Action = [[ 0.04742465  0.04352032 -0.02543389 -0.6083065 ]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 644 is [True, False, False, False, True, False]
Current timestep = 645. State = [[-0.20738083  0.11154912]]. Action = [[ 0.09619214 -0.09881356  0.08611036 -0.95769733]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 645 is [True, False, False, False, True, False]
Current timestep = 646. State = [[-0.20627174  0.11030138]]. Action = [[ 0.05239103  0.09305919 -0.01061209 -0.35257006]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 646 is [True, False, False, False, True, False]
Current timestep = 647. State = [[-0.20529671  0.11077556]]. Action = [[0.08820438 0.05861523 0.03931918 0.40050292]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 647 is [True, False, False, False, True, False]
Current timestep = 648. State = [[-0.20298456  0.1124089 ]]. Action = [[-0.04115284 -0.07373197 -0.06915799  0.2803011 ]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 648 is [True, False, False, False, True, False]
Current timestep = 649. State = [[-0.2011174   0.11241172]]. Action = [[-0.01053555 -0.01893614 -0.03832964 -0.72565717]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 649 is [True, False, False, False, True, False]
Current timestep = 650. State = [[-0.19989079  0.11242296]]. Action = [[-0.06525794  0.04484237 -0.03308209 -0.3789481 ]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 650 is [True, False, False, False, True, False]
State prediction error at timestep 650 is 0.012
Human Feedback received at timestep 650 of 1
Current timestep = 651. State = [[-0.19990386  0.11340147]]. Action = [[0.07618288 0.06207082 0.08381095 0.34899652]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 651 is [True, False, False, False, True, False]
State prediction error at timestep 651 is 0.012
Human Feedback received at timestep 651 of 1
Current timestep = 652. State = [[-0.19672534  0.11603004]]. Action = [[-0.06342683  0.06878347  0.08198006 -0.76596206]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 652 is [True, False, False, False, True, False]
Current timestep = 653. State = [[-0.19719039  0.11772916]]. Action = [[ 0.00789462  0.07249831 -0.01483709 -0.37702894]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 653 is [True, False, False, False, True, False]
Current timestep = 654. State = [[-0.19783512  0.12008136]]. Action = [[0.0474469  0.03703807 0.07980754 0.26188624]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 654 is [True, False, False, False, True, False]
Current timestep = 655. State = [[-0.1975282  0.1222823]]. Action = [[ 0.02976342 -0.08831351 -0.06256473  0.3069737 ]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 655 is [True, False, False, False, True, False]
Current timestep = 656. State = [[-0.19650505  0.12236506]]. Action = [[-0.04010884  0.06209569  0.02865935 -0.20109618]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 656 is [True, False, False, False, True, False]
State prediction error at timestep 656 is 0.012
Human Feedback received at timestep 656 of -1
Current timestep = 657. State = [[-0.19537431  0.12480331]]. Action = [[ 0.03435377 -0.0926173  -0.09484588  0.18249917]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 657 is [True, False, False, False, True, False]
Current timestep = 658. State = [[-0.19498663  0.12405166]]. Action = [[-0.03179321 -0.00979427 -0.06736336 -0.7875047 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 658 is [True, False, False, False, True, False]
State prediction error at timestep 658 is 0.012
Human Feedback received at timestep 658 of -1
Current timestep = 659. State = [[-0.19458959  0.12331862]]. Action = [[ 0.043309   -0.06060323 -0.03849318  0.5375166 ]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 659 is [True, False, False, False, True, False]
State prediction error at timestep 659 is 0.012
Human Feedback received at timestep 659 of -1
Current timestep = 660. State = [[-0.19306621  0.12029991]]. Action = [[ 0.09491216 -0.01704042 -0.07378484  0.4644935 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 660 is [True, False, False, False, True, False]
Current timestep = 661. State = [[-0.19210745  0.11944504]]. Action = [[-0.02479723 -0.06182852 -0.08821286  0.82555366]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 661 is [True, False, False, False, True, False]
Current timestep = 662. State = [[-0.19132057  0.11782681]]. Action = [[ 0.0182485  -0.01829763  0.05740631 -0.8011281 ]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 662 is [True, False, False, False, True, False]
Current timestep = 663. State = [[-0.19045347  0.1165245 ]]. Action = [[0.00739714 0.04684976 0.0016966  0.51387954]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 663 is [True, False, False, False, True, False]
State prediction error at timestep 663 is 0.012
Human Feedback received at timestep 663 of -1
Current timestep = 664. State = [[-0.18749297  0.11643821]]. Action = [[0.09729623 0.01106997 0.01183365 0.60273874]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 664 is [True, False, False, False, True, False]
Current timestep = 665. State = [[-0.1859832   0.11679003]]. Action = [[ 0.04698556  0.02762476  0.05532999 -0.0470311 ]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 665 is [True, False, False, False, True, False]
Current timestep = 666. State = [[-0.1842107   0.11758811]]. Action = [[ 0.08840128 -0.02307506 -0.02132276 -0.3390838 ]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 666 is [True, False, False, False, True, False]
Current timestep = 667. State = [[-0.18128549  0.1175421 ]]. Action = [[ 0.08647694  0.09624893 -0.01919797 -0.69255114]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 667 is [True, False, False, False, True, False]
State prediction error at timestep 667 is 0.012
Human Feedback received at timestep 667 of 1
Current timestep = 668. State = [[-0.16628711  0.12496208]]. Action = [[0.09992255 0.06365254 0.05252413 0.5988679 ]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 668 is [True, False, False, False, True, False]
Current timestep = 669. State = [[-0.16454053  0.12608016]]. Action = [[ 0.03592481  0.01204173 -0.0634755   0.7943357 ]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 669 is [True, False, False, False, True, False]
Current timestep = 670. State = [[-0.16255376  0.12714285]]. Action = [[-0.03469252  0.07026207  0.06337183 -0.45133263]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 670 is [True, False, False, False, False, True]
Current timestep = 671. State = [[-0.16027805  0.1289828 ]]. Action = [[ 0.02804438  0.07726803  0.03216933 -0.16600358]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 671 is [True, False, False, False, False, True]
Current timestep = 672. State = [[-0.15789    0.1324612]]. Action = [[-0.0650923   0.04410706 -0.00138721 -0.2180605 ]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 672 is [True, False, False, False, False, True]
Current timestep = 673. State = [[-0.15715946  0.13527842]]. Action = [[ 0.09875765  0.09084234 -0.07068293 -0.3289113 ]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 673 is [True, False, False, False, False, True]
Current timestep = 674. State = [[-0.15529963  0.13827302]]. Action = [[-0.09775459 -0.04352016 -0.00555469  0.19812512]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 674 is [True, False, False, False, False, True]
Current timestep = 675. State = [[-0.15423895  0.13983944]]. Action = [[ 0.0869179  -0.09575927 -0.0435595  -0.87877107]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 675 is [True, False, False, False, False, True]
Current timestep = 676. State = [[-0.15257296  0.13929926]]. Action = [[-0.00630052 -0.06255816  0.0265154   0.4445219 ]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 676 is [True, False, False, False, False, True]
Current timestep = 677. State = [[-0.15173942  0.13772953]]. Action = [[-0.00451447 -0.09705857  0.04062777 -0.04356968]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 677 is [True, False, False, False, False, True]
Current timestep = 678. State = [[-0.1508      0.13509947]]. Action = [[-0.0660281  -0.03237283 -0.03149316  0.23532486]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 678 is [True, False, False, False, False, True]
State prediction error at timestep 678 is 0.012
Human Feedback received at timestep 678 of 1
Current timestep = 679. State = [[-0.14994936  0.1291562 ]]. Action = [[ 0.00185739  0.08714854 -0.04642076  0.56651926]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 679 is [True, False, False, False, False, True]
State prediction error at timestep 679 is 0.012
Human Feedback received at timestep 679 of 1
Current timestep = 680. State = [[-0.15093848  0.13066961]]. Action = [[-0.06586607 -0.03134788  0.06005945 -0.2472384 ]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 680 is [True, False, False, False, False, True]
Current timestep = 681. State = [[-0.15095879  0.13058975]]. Action = [[ 0.00512733  0.07015779  0.08807199 -0.14791906]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 681 is [True, False, False, False, False, True]
State prediction error at timestep 681 is 0.012
Human Feedback received at timestep 681 of 1
Current timestep = 682. State = [[-0.15252014  0.13270132]]. Action = [[-0.02109624  0.0317814  -0.01331442  0.44601274]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 682 is [True, False, False, False, False, True]
State prediction error at timestep 682 is 0.012
Human Feedback received at timestep 682 of 1
Current timestep = 683. State = [[-0.15374072  0.13467824]]. Action = [[ 0.07271525 -0.0215927  -0.09729511  0.024351  ]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 683 is [True, False, False, False, False, True]
State prediction error at timestep 683 is 0.012
Human Feedback received at timestep 683 of -1
Current timestep = 684. State = [[-0.15368794  0.13463524]]. Action = [[ 0.06322425 -0.03688561 -0.01438568 -0.15575051]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 684 is [True, False, False, False, False, True]
State prediction error at timestep 684 is 0.012
Human Feedback received at timestep 684 of -1
Current timestep = 685. State = [[-0.15279931  0.13307478]]. Action = [[-0.06083758 -0.07334603  0.05190866  0.07509732]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 685 is [True, False, False, False, False, True]
Current timestep = 686. State = [[-0.15228893  0.1314732 ]]. Action = [[ 0.04273786 -0.05345914  0.07498484 -0.43095022]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 686 is [True, False, False, False, False, True]
Current timestep = 687. State = [[-0.15162937  0.12966926]]. Action = [[ 0.09982011  0.03008839 -0.03191379 -0.7360014 ]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 687 is [True, False, False, False, False, True]
Current timestep = 688. State = [[-0.15094383  0.12880045]]. Action = [[-0.00995146  0.04514747  0.0669034  -0.42158002]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 688 is [True, False, False, False, False, True]
State prediction error at timestep 688 is 0.012
Human Feedback received at timestep 688 of 1
Current timestep = 689. State = [[-0.14956275  0.12933354]]. Action = [[ 0.02968646  0.09393749 -0.09386354 -0.4237852 ]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 689 is [True, False, False, False, False, True]
Current timestep = 690. State = [[-0.14915605  0.12995127]]. Action = [[-0.00245116 -0.06742518 -0.08322194 -0.7228733 ]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 690 is [True, False, False, False, False, True]
Current timestep = 691. State = [[-0.1490966   0.12973712]]. Action = [[-0.09258889  0.08759674 -0.05777127 -0.78427863]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 691 is [True, False, False, False, False, True]
Current timestep = 692. State = [[-0.14976099  0.13129033]]. Action = [[ 0.00231936 -0.04925582 -0.05496159 -0.5128294 ]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 692 is [True, False, False, False, False, True]
Current timestep = 693. State = [[-0.14968082  0.13119352]]. Action = [[ 0.02040564  0.03244578 -0.04137124 -0.6444013 ]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 693 is [True, False, False, False, False, True]
Current timestep = 694. State = [[-0.14976268  0.13129604]]. Action = [[ 0.00908263 -0.08148886 -0.00412056 -0.7098818 ]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 694 is [True, False, False, False, False, True]
Current timestep = 695. State = [[-0.14944322  0.13064976]]. Action = [[0.08978231 0.05359105 0.04672422 0.5158378 ]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 695 is [True, False, False, False, False, True]
Current timestep = 696. State = [[-0.14912276  0.13092905]]. Action = [[-0.00170132  0.05154433 -0.03282244 -0.12882173]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 696 is [True, False, False, False, False, True]
Current timestep = 697. State = [[-0.14879824  0.13208458]]. Action = [[-0.01753282  0.01963051  0.06203689  0.9793967 ]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 697 is [True, False, False, False, False, True]
Current timestep = 698. State = [[-0.14851807  0.13304451]]. Action = [[-0.06120741  0.01466836  0.06390638  0.10217381]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 698 is [True, False, False, False, False, True]
Current timestep = 699. State = [[-0.14883727  0.1336511 ]]. Action = [[-0.07940488 -0.0107099   0.04209953  0.60022473]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 699 is [True, False, False, False, False, True]
Current timestep = 700. State = [[-0.14936261  0.13440907]]. Action = [[-0.09785821 -0.00499603  0.01770946 -0.9246324 ]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 700 is [True, False, False, False, False, True]
Current timestep = 701. State = [[-0.15005302  0.1355172 ]]. Action = [[-0.09209645 -0.07136656  0.08478414 -0.1754458 ]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 701 is [True, False, False, False, False, True]
Current timestep = 702. State = [[-0.15087141  0.13526943]]. Action = [[ 0.08345472  0.07465472 -0.0421112   0.30291736]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 702 is [True, False, False, False, False, True]
Current timestep = 703. State = [[-0.15134166  0.13629888]]. Action = [[ 0.03723919 -0.0176481   0.01274909 -0.7877661 ]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 703 is [True, False, False, False, False, True]
State prediction error at timestep 703 is 0.012
Human Feedback received at timestep 703 of -1
Current timestep = 704. State = [[-0.15140909  0.13653564]]. Action = [[-0.06697093 -0.03649393 -0.09101032 -0.1631676 ]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 704 is [True, False, False, False, False, True]
State prediction error at timestep 704 is 0.012
Human Feedback received at timestep 704 of -1
Current timestep = 705. State = [[-0.15142295  0.13647735]]. Action = [[ 0.04376713 -0.0624591   0.01377448  0.67180943]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 705 is [True, False, False, False, False, True]
Current timestep = 706. State = [[-0.15096572  0.13541621]]. Action = [[ 0.06720173 -0.06997086  0.0919993   0.08968353]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 706 is [True, False, False, False, False, True]
Current timestep = 707. State = [[-0.15000592  0.13307041]]. Action = [[-0.09227987 -0.04977893  0.05314028  0.1369803 ]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 707 is [True, False, False, False, False, True]
Current timestep = 708. State = [[-0.15052348  0.13098511]]. Action = [[-0.05337816  0.03426244  0.05336595 -0.5549263 ]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 708 is [True, False, False, False, False, True]
Current timestep = 709. State = [[-0.15149918  0.1301208 ]]. Action = [[ 0.00307916 -0.09325156  0.01493709  0.81189466]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 709 is [True, False, False, False, False, True]
State prediction error at timestep 709 is 0.012
Human Feedback received at timestep 709 of 1
Current timestep = 710. State = [[-0.15269461  0.12325465]]. Action = [[-0.04367981 -0.07376806 -0.06773715 -0.3440084 ]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 710 is [True, False, False, False, False, True]
Current timestep = 711. State = [[-0.15312368  0.12081108]]. Action = [[ 0.01462279 -0.08083436  0.01638691 -0.04511029]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 711 is [True, False, False, False, True, False]
Current timestep = 712. State = [[-0.15303308  0.11717408]]. Action = [[ 0.07666405  0.07467923 -0.01725141  0.33489728]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 712 is [True, False, False, False, True, False]
Current timestep = 713. State = [[-0.15307625  0.11662398]]. Action = [[-0.07389606  0.02351657 -0.08609597 -0.47716224]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 713 is [True, False, False, False, True, False]
Current timestep = 714. State = [[-0.1534055   0.11665122]]. Action = [[ 0.01956774 -0.08320484 -0.09202017 -0.07414454]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 714 is [True, False, False, False, True, False]
Current timestep = 715. State = [[-0.15292753  0.11497167]]. Action = [[-0.04545664 -0.01749237  0.07727193  0.02751064]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 715 is [True, False, False, False, True, False]
State prediction error at timestep 715 is 0.012
Human Feedback received at timestep 715 of 1
Current timestep = 716. State = [[-0.15404975  0.11224528]]. Action = [[-0.0273395   0.06836902 -0.05026637  0.3334744 ]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 716 is [True, False, False, False, True, False]
State prediction error at timestep 716 is 0.012
Human Feedback received at timestep 716 of 1
Current timestep = 717. State = [[-0.15470493  0.11328503]]. Action = [[-0.04084251 -0.06687041 -0.026256    0.08878958]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 717 is [True, False, False, False, True, False]
Current timestep = 718. State = [[-0.15481798  0.11279963]]. Action = [[ 0.03423097 -0.03215975 -0.06543682  0.04506803]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 718 is [True, False, False, False, True, False]
Current timestep = 719. State = [[-0.15463474  0.11162731]]. Action = [[0.03599738 0.04701794 0.00882161 0.84846234]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 719 is [True, False, False, False, True, False]
Current timestep = 720. State = [[-0.1547416   0.11191717]]. Action = [[ 0.04528933  0.03282707  0.06746417 -0.18432838]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 720 is [True, False, False, False, True, False]
State prediction error at timestep 720 is 0.012
Human Feedback received at timestep 720 of -1
Current timestep = 721. State = [[-0.1547201   0.11195129]]. Action = [[ 0.09344276 -0.0664374  -0.04847099 -0.3738433 ]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 721 is [True, False, False, False, True, False]
Current timestep = 722. State = [[-0.1536305   0.11071157]]. Action = [[ 0.05374724 -0.06422956  0.02337199 -0.09684998]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 722 is [True, False, False, False, True, False]
Current timestep = 723. State = [[-0.15191513  0.10842399]]. Action = [[ 0.09589332 -0.03247714 -0.04759007 -0.9610952 ]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 723 is [True, False, False, False, True, False]
Current timestep = 724. State = [[-0.1502189   0.10580642]]. Action = [[0.02752351 0.06490695 0.01937412 0.9721887 ]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 724 is [True, False, False, False, True, False]
Current timestep = 725. State = [[-0.14920011  0.10520381]]. Action = [[-0.05867473 -0.03510105  0.09356207  0.3132459 ]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 725 is [True, False, False, False, True, False]
Current timestep = 726. State = [[-0.1487183   0.10445657]]. Action = [[ 0.06737638  0.07668816  0.0657989  -0.7576656 ]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 726 is [True, False, False, False, True, False]
Current timestep = 727. State = [[-0.14836286  0.10473945]]. Action = [[0.07252797 0.04423074 0.08064774 0.20903766]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 727 is [True, False, False, False, True, False]
Current timestep = 728. State = [[-0.14702684  0.10543758]]. Action = [[-0.05104155 -0.06515346  0.0189819  -0.22109938]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 728 is [True, False, False, False, True, False]
State prediction error at timestep 728 is 0.012
Human Feedback received at timestep 728 of 1
Current timestep = 729. State = [[-0.14604656  0.10524663]]. Action = [[-0.09767909 -0.00771218  0.03941382  0.26353765]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 729 is [True, False, False, False, True, False]
Current timestep = 730. State = [[-0.14618964  0.10538711]]. Action = [[-0.04933175  0.066714    0.08312836  0.07376039]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 730 is [True, False, False, False, True, False]
Current timestep = 731. State = [[-0.14668049  0.10648113]]. Action = [[-0.05474791  0.07256094  0.09222751 -0.6693413 ]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 731 is [True, False, False, False, True, False]
Current timestep = 732. State = [[-0.14768738  0.10897627]]. Action = [[-0.050009   -0.04691753 -0.02770389 -0.23385882]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 732 is [True, False, False, False, True, False]
Current timestep = 733. State = [[-0.14802976  0.10958954]]. Action = [[0.09495976 0.01469727 0.09350469 0.0703851 ]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 733 is [True, False, False, False, True, False]
State prediction error at timestep 733 is 0.012
Human Feedback received at timestep 733 of 1
Current timestep = 734. State = [[-0.14832178  0.1098659 ]]. Action = [[0.09816854 0.03344583 0.07041868 0.63652277]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 734 is [True, False, False, False, True, False]
Current timestep = 735. State = [[-0.14788751  0.11010122]]. Action = [[-0.01384691 -0.0677177   0.01077503 -0.25449574]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 735 is [True, False, False, False, True, False]
Current timestep = 736. State = [[-0.14782932  0.10977373]]. Action = [[-0.08786596  0.00540759  0.0758967   0.66461205]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 736 is [True, False, False, False, True, False]
Current timestep = 737. State = [[-0.14789337  0.1099529 ]]. Action = [[ 0.04611503 -0.00867917 -0.00897417 -0.8090815 ]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 737 is [True, False, False, False, True, False]
State prediction error at timestep 737 is 0.012
Human Feedback received at timestep 737 of 1
Current timestep = 738. State = [[-0.14783949  0.10978738]]. Action = [[-0.03278945 -0.08802291 -0.04096885 -0.8233887 ]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 738 is [True, False, False, False, True, False]
Current timestep = 739. State = [[-0.14721993  0.10831485]]. Action = [[ 0.04054555  0.04270545 -0.06906333 -0.4175024 ]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 739 is [True, False, False, False, True, False]
Current timestep = 740. State = [[-0.14725474  0.10836587]]. Action = [[0.0997655  0.04433044 0.08083566 0.7284478 ]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 740 is [True, False, False, False, True, False]
Current timestep = 741. State = [[-0.1469909   0.10850524]]. Action = [[-0.0362744  -0.0667589   0.00656798 -0.42877495]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 741 is [True, False, False, False, True, False]
Current timestep = 742. State = [[-0.14666806  0.10767896]]. Action = [[ 0.01788559  0.06527161 -0.05669249 -0.30008316]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 742 is [True, False, False, False, True, False]
Current timestep = 743. State = [[-0.14664216  0.10790301]]. Action = [[-0.09505345 -0.03013795 -0.03465802 -0.3036222 ]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 743 is [True, False, False, False, True, False]
Current timestep = 744. State = [[-0.14664216  0.10790301]]. Action = [[-0.05945491 -0.02408413  0.04087206  0.7404125 ]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 744 is [True, False, False, False, True, False]
Current timestep = 745. State = [[-0.14663063  0.10769498]]. Action = [[-0.03265084 -0.06120014 -0.07894612  0.08400738]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 745 is [True, False, False, False, True, False]
Current timestep = 746. State = [[-0.14673549  0.10667571]]. Action = [[-0.02743443 -0.09395974  0.01067108  0.58146596]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 746 is [True, False, False, False, True, False]
Current timestep = 747. State = [[-0.14699984  0.10372849]]. Action = [[ 0.09577601 -0.00413854  0.02530643 -0.2073139 ]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 747 is [True, False, False, False, True, False]
Current timestep = 748. State = [[-0.14640005  0.10177613]]. Action = [[0.03954966 0.07138895 0.08885372 0.8553473 ]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 748 is [True, False, False, False, True, False]
Current timestep = 749. State = [[-0.14639379  0.10174792]]. Action = [[-0.04362353 -0.0516749  -0.0759366  -0.15699548]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 749 is [True, False, False, False, True, False]
Current timestep = 750. State = [[-0.14605008  0.10081291]]. Action = [[-0.01776645 -0.04611916  0.05620628 -0.72059715]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 750 is [True, False, False, False, True, False]
Current timestep = 751. State = [[-0.14539115  0.09902383]]. Action = [[ 0.02259632  0.01253571 -0.06818925 -0.27660632]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 751 is [True, False, False, False, True, False]
Current timestep = 752. State = [[-0.14520845  0.09820463]]. Action = [[-0.00994236  0.0007353  -0.01336513  0.43566608]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 752 is [True, False, False, False, True, False]
Current timestep = 753. State = [[-0.14517452  0.0977359 ]]. Action = [[-0.06210102 -0.04646353  0.07779395 -0.01682848]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 753 is [True, False, False, False, True, False]
Current timestep = 754. State = [[-0.14543594  0.09617721]]. Action = [[ 0.08916586  0.02082907  0.0354222  -0.4560727 ]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 754 is [True, False, False, False, True, False]
Current timestep = 755. State = [[-0.1453206   0.09547926]]. Action = [[0.03245159 0.0794354  0.00798297 0.46081185]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 755 is [True, False, False, False, True, False]
Current timestep = 756. State = [[-0.14547247  0.09610284]]. Action = [[-0.04210079  0.014102   -0.05339179 -0.8798099 ]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 756 is [True, False, False, False, True, False]
Current timestep = 757. State = [[-0.14558253  0.09633318]]. Action = [[ 0.02867126 -0.00846184 -0.05522672 -0.57500964]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 757 is [True, False, False, False, True, False]
Current timestep = 758. State = [[-0.14560638  0.09632283]]. Action = [[ 0.01301589  0.06184836 -0.06178359 -0.13088995]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 758 is [True, False, False, False, True, False]
State prediction error at timestep 758 is 0.012
Human Feedback received at timestep 758 of 1
Current timestep = 759. State = [[-0.14634463  0.09816094]]. Action = [[-0.02689406 -0.06171781  0.09211075 -0.41441768]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 759 is [True, False, False, False, True, False]
Current timestep = 760. State = [[-0.14626037  0.09778119]]. Action = [[-0.08373877 -0.08482928  0.06434175 -0.47703707]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 760 is [True, False, False, False, True, False]
Current timestep = 761. State = [[-0.14592533  0.09660723]]. Action = [[ 0.02319938  0.00378259 -0.05191866  0.40574253]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 761 is [True, False, False, False, True, False]
Current timestep = 762. State = [[-0.1456609   0.09548044]]. Action = [[ 0.08613863 -0.0111784  -0.04891837  0.0889492 ]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 762 is [True, False, False, False, True, False]
Current timestep = 763. State = [[-0.1453065   0.09453227]]. Action = [[ 0.09175815  0.08290429 -0.0679123   0.16887808]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 763 is [True, False, False, False, True, False]
State prediction error at timestep 763 is 0.012
Human Feedback received at timestep 763 of 1
Current timestep = 764. State = [[-0.14454678  0.09488246]]. Action = [[ 0.08441784 -0.05277661 -0.04939286  0.35092437]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 764 is [True, False, False, False, True, False]
Current timestep = 765. State = [[-0.14325973  0.0936502 ]]. Action = [[ 0.09889483 -0.09109934  0.05198094 -0.9062925 ]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 765 is [True, False, False, False, True, False]
Current timestep = 766. State = [[-0.14092335  0.0907394 ]]. Action = [[-0.03031645 -0.00757559 -0.01813237 -0.3386684 ]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 766 is [True, False, False, False, True, False]
Current timestep = 767. State = [[-0.13970557  0.0888542 ]]. Action = [[0.08742791 0.01329206 0.09813964 0.3423338 ]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 767 is [True, False, False, False, True, False]
Current timestep = 768. State = [[-0.13786425  0.08771253]]. Action = [[-0.08349542  0.06050854  0.05592672 -0.71676725]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 768 is [True, False, False, False, True, False]
State prediction error at timestep 768 is 0.012
Human Feedback received at timestep 768 of 1
Current timestep = 769. State = [[-0.13712722  0.08853091]]. Action = [[-0.09485385  0.04565816  0.04238484  0.00723088]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 769 is [True, False, False, False, True, False]
Current timestep = 770. State = [[-0.1376396   0.08936983]]. Action = [[-0.09464572 -0.01559724  0.03760443  0.98291266]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 770 is [True, False, False, False, True, False]
Current timestep = 771. State = [[-0.13795145  0.08988865]]. Action = [[ 0.08209168 -0.02330686 -0.01268444 -0.04953921]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 771 is [True, False, False, False, True, False]
State prediction error at timestep 771 is 0.012
Human Feedback received at timestep 771 of 1
Current timestep = 772. State = [[-0.13791017  0.0897024 ]]. Action = [[ 0.06039479  0.07174834  0.05338157 -0.8955244 ]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 772 is [True, False, False, False, True, False]
State prediction error at timestep 772 is 0.012
Human Feedback received at timestep 772 of 1
Current timestep = 773. State = [[-0.13831635  0.09074048]]. Action = [[-0.03073711 -0.07670204  0.08517655 -0.0803296 ]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 773 is [True, False, False, False, True, False]
Current timestep = 774. State = [[-0.13824204  0.09049372]]. Action = [[ 0.07833286  0.05247349 -0.01338233  0.6510874 ]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 774 is [True, False, False, False, True, False]
Current timestep = 775. State = [[-0.13821042  0.09065528]]. Action = [[-0.0064294   0.05095788  0.07959337  0.5468526 ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 775 is [True, False, False, False, True, False]
State prediction error at timestep 775 is 0.012
Human Feedback received at timestep 775 of 1
Current timestep = 776. State = [[-0.13671131  0.09258845]]. Action = [[ 0.04780822  0.07364369  0.0883671  -0.09134418]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 776 is [True, False, False, False, True, False]
Current timestep = 777. State = [[-0.13609946  0.09454151]]. Action = [[-0.05271511  0.03255347 -0.08845709  0.31260288]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 777 is [True, False, False, False, True, False]
Current timestep = 778. State = [[-0.13552263  0.09626971]]. Action = [[ 0.09098675 -0.05786715  0.07080584  0.64170885]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 778 is [True, False, False, False, True, False]
Current timestep = 779. State = [[-0.1339827   0.09654225]]. Action = [[-0.0404515  -0.0381982  -0.02195472 -0.8567645 ]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 779 is [True, False, False, False, True, False]
State prediction error at timestep 779 is 0.012
Human Feedback received at timestep 779 of 1
Current timestep = 780. State = [[-0.13151011  0.09735212]]. Action = [[ 0.02826687 -0.07978947 -0.02654274  0.29480922]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 780 is [True, False, False, False, True, False]
Current timestep = 781. State = [[-0.13070452  0.09600341]]. Action = [[-0.05909122  0.01270431 -0.0010706  -0.4156394 ]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 781 is [True, False, False, False, True, False]
Current timestep = 782. State = [[-0.13062759  0.09575774]]. Action = [[-0.04438443  0.01810564 -0.05106967  0.1762631 ]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 782 is [True, False, False, False, True, False]
Current timestep = 783. State = [[-0.13079554  0.09593538]]. Action = [[-0.04042704  0.09732001 -0.04642818 -0.01336288]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 783 is [True, False, False, False, True, False]
Current timestep = 784. State = [[-0.13186589  0.09792016]]. Action = [[-0.07758362  0.09354185 -0.08910225 -0.8942189 ]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 784 is [True, False, False, False, True, False]
Current timestep = 785. State = [[-0.13331403  0.10129983]]. Action = [[-0.03111388  0.08416905  0.02982768 -0.22903812]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 785 is [True, False, False, False, True, False]
Current timestep = 786. State = [[-0.13503891  0.10543102]]. Action = [[ 0.01375966  0.0640104  -0.0265853  -0.55082744]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 786 is [True, False, False, False, True, False]
Current timestep = 787. State = [[-0.13699557  0.109434  ]]. Action = [[ 0.00127302 -0.03892101 -0.04701322  0.04489005]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 787 is [True, False, False, False, True, False]
State prediction error at timestep 787 is 0.012
Human Feedback received at timestep 787 of -1
Current timestep = 788. State = [[-0.13882466  0.11271819]]. Action = [[ 0.0428882  -0.0631846  -0.04951763  0.23667431]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 788 is [True, False, False, False, True, False]
Current timestep = 789. State = [[-0.13870613  0.11242126]]. Action = [[ 0.03391647 -0.00922661 -0.09557016 -0.35315073]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 789 is [True, False, False, False, True, False]
Current timestep = 790. State = [[-0.13848144  0.11195642]]. Action = [[ 0.07092898 -0.0421159  -0.05857671 -0.5083091 ]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 790 is [True, False, False, False, True, False]
Current timestep = 791. State = [[-0.13759254  0.11088617]]. Action = [[-0.08103445 -0.03079488  0.00734819 -0.17037821]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 791 is [True, False, False, False, True, False]
Current timestep = 792. State = [[-0.13733187  0.11024401]]. Action = [[-0.071275    0.03380396  0.01754638 -0.2509128 ]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 792 is [True, False, False, False, True, False]
Current timestep = 793. State = [[-0.13740762  0.11028915]]. Action = [[-0.07818829 -0.07419064 -0.09353018 -0.45124555]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 793 is [True, False, False, False, True, False]
Current timestep = 794. State = [[-0.13724771  0.10913116]]. Action = [[-0.05157137  0.05190139  0.01873665  0.83721507]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 794 is [True, False, False, False, True, False]
Current timestep = 795. State = [[-0.13765661  0.10936888]]. Action = [[-0.01654925 -0.03577612  0.05498432  0.6436479 ]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 795 is [True, False, False, False, True, False]
Current timestep = 796. State = [[-0.13822529  0.10869455]]. Action = [[ 0.00435616  0.0657978  -0.03997241  0.34108114]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 796 is [True, False, False, False, True, False]
Current timestep = 797. State = [[-0.13884577  0.10977226]]. Action = [[-0.01961886 -0.04053861  0.09982049  0.4180622 ]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 797 is [True, False, False, False, True, False]
Current timestep = 798. State = [[-0.13918012  0.10949808]]. Action = [[ 0.00348534  0.01959308 -0.02087668  0.9446156 ]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 798 is [True, False, False, False, True, False]
Current timestep = 799. State = [[-0.13951124  0.1097817 ]]. Action = [[-0.09237529  0.05989669  0.0442652  -0.86301434]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 799 is [True, False, False, False, True, False]
Current timestep = 800. State = [[-0.14083515  0.11123687]]. Action = [[-0.0310057  -0.05955762 -0.03305681  0.42639923]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 800 is [True, False, False, False, True, False]
Current timestep = 801. State = [[-0.14210165  0.11078861]]. Action = [[ 0.02631459 -0.07459968  0.04079994  0.64242697]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 801 is [True, False, False, False, True, False]
Current timestep = 802. State = [[-0.14286809  0.10929283]]. Action = [[ 0.01307043  0.07752425 -0.04506218 -0.45114148]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 802 is [True, False, False, False, True, False]
Current timestep = 803. State = [[-0.14353728  0.1100653 ]]. Action = [[-0.02002709 -0.03140248 -0.09238388 -0.79141146]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 803 is [True, False, False, False, True, False]
Current timestep = 804. State = [[-0.14395303  0.1101996 ]]. Action = [[ 0.08673374  0.08854715  0.01118996 -0.23511785]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 804 is [True, False, False, False, True, False]
Current timestep = 805. State = [[-0.14429797  0.11083593]]. Action = [[ 0.06524015  0.08235817  0.06048099 -0.8650296 ]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 805 is [True, False, False, False, True, False]
State prediction error at timestep 805 is 0.012
Human Feedback received at timestep 805 of -1
Current timestep = 806. State = [[-0.14561218  0.11394875]]. Action = [[-0.03645007  0.05970483  0.01501115 -0.29706693]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 806 is [True, False, False, False, True, False]
Current timestep = 807. State = [[-0.14655042  0.11593848]]. Action = [[ 0.00191204  0.0552044  -0.09157774  0.85993576]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 807 is [True, False, False, False, True, False]
Current timestep = 808. State = [[-0.14759406  0.11856689]]. Action = [[-0.00838102 -0.04010493 -0.06506404 -0.8830146 ]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 808 is [True, False, False, False, True, False]
Current timestep = 809. State = [[-0.14797343  0.11945629]]. Action = [[0.04964977 0.05710419 0.07301892 0.22307944]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 809 is [True, False, False, False, True, False]
Current timestep = 810. State = [[-0.14851613  0.12083831]]. Action = [[-0.0951198  -0.04268194  0.0818577   0.1658225 ]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 810 is [True, False, False, False, True, False]
Current timestep = 811. State = [[-0.14887983  0.12163581]]. Action = [[-0.09847884 -0.00873587 -0.06219068 -0.58889747]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 811 is [True, False, False, False, True, False]
Current timestep = 812. State = [[-0.14936641  0.12272348]]. Action = [[ 0.05778228 -0.04292473  0.09699094  0.5534167 ]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 812 is [True, False, False, False, True, False]
State prediction error at timestep 812 is 0.012
Human Feedback received at timestep 812 of -1
Current timestep = 813. State = [[-0.14938906  0.1225423 ]]. Action = [[-0.06169579  0.01521252  0.07104268  0.14616466]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 813 is [True, False, False, False, True, False]
Current timestep = 814. State = [[-0.14946172  0.12279488]]. Action = [[ 0.05525187 -0.06137919  0.0307646   0.6213716 ]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 814 is [True, False, False, False, True, False]
Current timestep = 815. State = [[-0.1493385   0.12240966]]. Action = [[-0.07648259  0.07835027 -0.07649315 -0.9107446 ]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 815 is [True, False, False, False, True, False]
State prediction error at timestep 815 is 0.012
Human Feedback received at timestep 815 of -1
Current timestep = 816. State = [[-0.15018737  0.12404869]]. Action = [[0.0331305  0.07516041 0.0758326  0.3436234 ]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 816 is [True, False, False, False, True, False]
Current timestep = 817. State = [[-0.15090194  0.1256417 ]]. Action = [[-0.01224626  0.00717163 -0.06398384  0.6208749 ]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 817 is [True, False, False, False, True, False]
State prediction error at timestep 817 is 0.012
Human Feedback received at timestep 817 of -1
Current timestep = 818. State = [[-0.1524414   0.12849084]]. Action = [[-0.06181024  0.06185397 -0.09163709 -0.02620709]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 818 is [True, False, False, False, False, True]
Current timestep = 819. State = [[-0.15355705  0.13073792]]. Action = [[-0.06230352  0.06351162 -0.00637991 -0.5510592 ]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 819 is [True, False, False, False, False, True]
Current timestep = 820. State = [[-0.15522978  0.13430332]]. Action = [[ 0.0415346  -0.04034868 -0.03588769  0.20208788]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 820 is [True, False, False, False, False, True]
Current timestep = 821. State = [[-0.15569246  0.13511336]]. Action = [[ 0.02876069  0.06459723  0.0982933  -0.1201269 ]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 821 is [True, False, False, False, False, True]
Current timestep = 822. State = [[-0.1566788   0.13676639]]. Action = [[-0.00275913 -0.01392561 -0.08058811  0.35883915]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 822 is [True, False, False, False, False, True]
Current timestep = 823. State = [[-0.15711462  0.13762192]]. Action = [[0.00610732 0.01621568 0.01296987 0.2921095 ]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 823 is [True, False, False, False, False, True]
Current timestep = 824. State = [[-0.15754218  0.13861005]]. Action = [[ 0.09555947  0.08454406  0.06883361 -0.63137627]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 824 is [True, False, False, False, False, True]
Current timestep = 825. State = [[-0.15826634  0.14002013]]. Action = [[-0.08850329  0.02734628  0.02368083 -0.5202895 ]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 825 is [True, False, False, False, False, True]
Current timestep = 826. State = [[-0.15933022  0.14236708]]. Action = [[ 0.03319474  0.03669318  0.04794113 -0.20287979]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 826 is [True, False, False, False, False, True]
State prediction error at timestep 826 is 0.012
Human Feedback received at timestep 826 of -1
Current timestep = 827. State = [[-0.16164628  0.14642765]]. Action = [[-0.0043386  -0.03547197 -0.0971041   0.21912348]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 827 is [True, False, False, False, False, True]
Current timestep = 828. State = [[-0.16173014  0.14680639]]. Action = [[-0.0134307   0.06923728 -0.07572687  0.42798185]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 828 is [True, False, False, False, False, True]
Current timestep = 829. State = [[-0.16226473  0.14801008]]. Action = [[ 0.09789347 -0.07627241 -0.04279349 -0.56486595]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 829 is [True, False, False, False, False, True]
Current timestep = 830. State = [[-0.16126336  0.14742799]]. Action = [[0.06310018 0.01439534 0.02555294 0.6298704 ]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 830 is [True, False, False, False, False, True]
Current timestep = 831. State = [[-0.16035777  0.14748318]]. Action = [[-0.00596305  0.03171647 -0.02472159 -0.93713677]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 831 is [True, False, False, False, False, True]
Current timestep = 832. State = [[-0.15987313  0.14820564]]. Action = [[ 0.06129994 -0.08188109 -0.09054743  0.6372268 ]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 832 is [True, False, False, False, False, True]
Current timestep = 833. State = [[-0.1583572  0.1469489]]. Action = [[ 0.03703453 -0.03269438 -0.02102495 -0.84256804]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 833 is [True, False, False, False, False, True]
Current timestep = 834. State = [[-0.15673251  0.14576635]]. Action = [[-0.0366334   0.02324779  0.06166469  0.645414  ]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 834 is [True, False, False, False, False, True]
Current timestep = 835. State = [[-0.15630405  0.1458873 ]]. Action = [[ 0.0458475   0.05581217 -0.06220392  0.7376232 ]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 835 is [True, False, False, False, False, True]
Current timestep = 836. State = [[-0.15559971  0.14652996]]. Action = [[-1.2346357e-04  2.0283543e-02 -2.0593025e-02  5.3654909e-01]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 836 is [True, False, False, False, False, True]
Current timestep = 837. State = [[-0.15470423  0.14720166]]. Action = [[ 0.06566533  0.04771147  0.09251698 -0.13291478]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 837 is [True, False, False, False, False, True]
State prediction error at timestep 837 is 0.012
Human Feedback received at timestep 837 of -1
Current timestep = 838. State = [[-0.1510204   0.14976345]]. Action = [[ 0.07623284  0.00031461 -0.03485184  0.18038046]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 838 is [True, False, False, False, False, True]
Current timestep = 839. State = [[-0.14949606  0.15067655]]. Action = [[ 0.08962833  0.069745   -0.02982546  0.0684495 ]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 839 is [True, False, False, False, False, True]
Current timestep = 840. State = [[-0.14587747  0.1533372 ]]. Action = [[-0.06563804 -0.05295813 -0.00681051 -0.08991122]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 840 is [True, False, False, False, False, True]
Current timestep = 841. State = [[-0.14391942  0.15422264]]. Action = [[-0.04095739 -0.02058496 -0.01373348  0.6408386 ]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 841 is [True, False, False, False, False, True]
Current timestep = 842. State = [[-0.1437676   0.15428406]]. Action = [[-0.03072355 -0.06254348  0.09715547  0.15673113]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 842 is [True, False, False, False, False, True]
Current timestep = 843. State = [[-0.1433352   0.15335831]]. Action = [[ 0.05418298 -0.08067755 -0.03330144 -0.43133378]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 843 is [True, False, False, False, False, True]
Current timestep = 844. State = [[-0.1417554   0.15059832]]. Action = [[ 0.09743606 -0.09903786  0.08823482 -0.84396744]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 844 is [True, False, False, False, False, True]
Current timestep = 845. State = [[-0.139301    0.14592801]]. Action = [[ 0.03497571  0.0171715   0.08525719 -0.6419293 ]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 845 is [True, False, False, False, False, True]
Current timestep = 846. State = [[-0.13743567  0.14249404]]. Action = [[ 0.08368819 -0.00747488  0.08865478  0.9522784 ]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 846 is [True, False, False, False, False, True]
Current timestep = 847. State = [[-0.13544057  0.14016233]]. Action = [[0.02626482 0.0515176  0.03883437 0.37349308]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 847 is [True, False, False, False, False, True]
Current timestep = 848. State = [[-0.1336906   0.13976067]]. Action = [[-0.03699075 -0.01112098  0.0150217  -0.90853995]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 848 is [True, False, False, False, False, True]
Current timestep = 849. State = [[-0.13284405  0.13942434]]. Action = [[-0.08058725 -0.04895262  0.09272122  0.23734021]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 849 is [True, False, False, False, False, True]
Current timestep = 850. State = [[-0.13275623  0.1390776 ]]. Action = [[-0.06187503  0.09743608  0.06816655 -0.9838493 ]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 850 is [True, False, False, False, False, True]
Current timestep = 851. State = [[-0.13338076  0.14001246]]. Action = [[-0.06701927  0.02729433 -0.03178024  0.50647426]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 851 is [True, False, False, False, False, True]
State prediction error at timestep 851 is 0.012
Human Feedback received at timestep 851 of 1
Current timestep = 852. State = [[-0.1347049  0.1424144]]. Action = [[ 0.03594214  0.00758737 -0.07646017 -0.568202  ]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 852 is [True, False, False, False, False, True]
State prediction error at timestep 852 is 0.012
Human Feedback received at timestep 852 of 1
Current timestep = 853. State = [[-0.13501605  0.14278257]]. Action = [[-0.01714475  0.03579705 -0.08230279  0.87571764]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 853 is [True, False, False, False, False, True]
Current timestep = 854. State = [[-0.13531752  0.14337176]]. Action = [[ 0.02747444  0.03136539 -0.07021043 -0.13461995]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 854 is [True, False, False, False, False, True]
Current timestep = 855. State = [[-0.13559957  0.14411712]]. Action = [[ 0.02528293  0.01547952 -0.03603738  0.35942578]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 855 is [True, False, False, False, False, True]
Current timestep = 856. State = [[-0.13589428  0.14483857]]. Action = [[0.03427506 0.04789763 0.02263607 0.5365486 ]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 856 is [True, False, False, False, False, True]
Current timestep = 857. State = [[-0.13532606  0.14669093]]. Action = [[0.07210352 0.05834232 0.06235597 0.21490633]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 857 is [True, False, False, False, False, True]
Current timestep = 858. State = [[-0.13389772  0.14895941]]. Action = [[-0.05137458 -0.02878148  0.09468909  0.82392335]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 858 is [True, False, False, False, False, True]
State prediction error at timestep 858 is 0.012
Human Feedback received at timestep 858 of 1
Current timestep = 859. State = [[-0.1311452   0.15283577]]. Action = [[-0.03935675  0.03478643  0.02669158  0.81637096]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 859 is [True, False, False, False, False, True]
Current timestep = 860. State = [[-0.13168018  0.15361379]]. Action = [[-0.01270922 -0.0092575  -0.05036385  0.23814678]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 860 is [True, False, False, False, False, True]
Current timestep = 861. State = [[-0.13199304  0.15420403]]. Action = [[-0.06593549  0.00363239  0.05747517 -0.3307966 ]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 861 is [True, False, False, False, False, True]
Current timestep = 862. State = [[-0.13267113  0.15521353]]. Action = [[-0.04328059  0.08309162 -0.04536742  0.8063748 ]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 862 is [True, False, False, False, False, True]
Current timestep = 863. State = [[-0.13420704  0.1580408 ]]. Action = [[-0.09652586  0.05571672 -0.0776618  -0.71435916]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 863 is [True, False, False, False, False, True]
Current timestep = 864. State = [[-0.13634406  0.16197412]]. Action = [[ 0.05222832 -0.05329921  0.01665686  0.85693955]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 864 is [True, False, False, False, False, True]
State prediction error at timestep 864 is 0.012
Human Feedback received at timestep 864 of -1
Current timestep = 865. State = [[-0.13799585  0.16409697]]. Action = [[-0.06917726  0.04367628  0.01813357 -0.52012765]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 865 is [True, False, False, False, False, True]
Current timestep = 866. State = [[-0.13883507  0.1657221 ]]. Action = [[-0.05696666  0.03379955  0.01097181  0.5667535 ]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 866 is [True, False, False, False, False, True]
Current timestep = 867. State = [[-0.14015014  0.16791923]]. Action = [[ 0.09219135 -0.05805593 -0.03271112  0.3958149 ]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 867 is [True, False, False, False, False, True]
Current timestep = 868. State = [[-0.1400096   0.16761126]]. Action = [[-0.03124291  0.0283972  -0.07521993 -0.32739675]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 868 is [True, False, False, False, False, True]
State prediction error at timestep 868 is 0.012
Human Feedback received at timestep 868 of -1
Current timestep = 869. State = [[-0.14050724  0.16842073]]. Action = [[0.06472602 0.09197838 0.0641252  0.41242588]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 869 is [True, False, False, False, False, True]
Current timestep = 870. State = [[-0.1411017   0.16948265]]. Action = [[-0.02139685 -0.09331255  0.09150799  0.21802056]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 870 is [True, False, False, False, False, True]
Current timestep = 871. State = [[-0.14079481  0.16888244]]. Action = [[ 1.8365681e-04 -3.1995103e-03 -3.8447697e-02  6.5077376e-01]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 871 is [True, False, False, False, False, True]
Current timestep = 872. State = [[-0.140934    0.16917737]]. Action = [[0.0156481  0.02888759 0.02448751 0.6373844 ]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 872 is [True, False, False, False, False, True]
State prediction error at timestep 872 is 0.012
Human Feedback received at timestep 872 of -1
Current timestep = 873. State = [[-0.14100602  0.16922122]]. Action = [[ 0.02411852  0.07074206 -0.00392079 -0.96167463]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 873 is [True, False, False, False, False, True]
State prediction error at timestep 873 is 0.012
Human Feedback received at timestep 873 of -1
Current timestep = 874. State = [[-0.14175619  0.17083175]]. Action = [[ 0.09080487  0.04582456 -0.0877212   0.30074644]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 874 is [True, False, False, False, False, True]
Current timestep = 875. State = [[-0.1410574   0.17189002]]. Action = [[-0.02477155 -0.0719272  -0.00107453  0.6413734 ]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 875 is [True, False, False, False, False, True]
Current timestep = 876. State = [[-0.14044276  0.17118524]]. Action = [[ 0.08695766  0.00340705 -0.05911535 -0.9982169 ]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 876 is [True, False, False, False, False, True]
State prediction error at timestep 876 is 0.012
Human Feedback received at timestep 876 of 1
Current timestep = 877. State = [[-0.1353929   0.17349367]]. Action = [[-0.08156133  0.04030191  0.04143881  0.81873894]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 877 is [True, False, False, False, False, True]
Current timestep = 878. State = [[-0.1358403   0.17428228]]. Action = [[-0.03815    -0.01683912  0.0480257  -0.23263693]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 878 is [True, False, False, False, False, True]
State prediction error at timestep 878 is 0.012
Human Feedback received at timestep 878 of 1
Current timestep = 879. State = [[-0.13632098  0.17463623]]. Action = [[ 0.0270442  -0.01787385  0.06983516  0.17300022]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 879 is [True, False, False, False, False, True]
Current timestep = 880. State = [[-0.13632098  0.17463623]]. Action = [[ 0.05652063 -0.0201425   0.07256692 -0.38552034]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 880 is [True, False, False, False, False, True]
Current timestep = 881. State = [[-0.1361145   0.17423004]]. Action = [[-0.08591688  0.01171925  0.06132428 -0.30482107]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 881 is [True, False, False, False, False, True]
Current timestep = 882. State = [[-0.13623603  0.1743    ]]. Action = [[ 0.03914043  0.01896606 -0.07152376  0.07608569]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 882 is [True, False, False, False, False, True]
State prediction error at timestep 882 is 0.012
Human Feedback received at timestep 882 of -1
Current timestep = 883. State = [[-0.13636722  0.1742762 ]]. Action = [[-0.09166531  0.07043836 -0.08278611 -0.03199273]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 883 is [True, False, False, False, False, True]
Current timestep = 884. State = [[-0.13737859  0.17620492]]. Action = [[ 0.09288027 -0.08233316  0.0251113   0.5820422 ]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 884 is [True, False, False, False, False, True]
Current timestep = 885. State = [[-0.1368795   0.17527607]]. Action = [[ 0.0878885   0.02983522  0.0266408  -0.7006631 ]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 885 is [True, False, False, False, False, True]
Current timestep = 886. State = [[-0.1362571   0.17480546]]. Action = [[-0.00411619 -0.0275893   0.0013525  -0.12688214]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 886 is [True, False, False, False, False, True]
State prediction error at timestep 886 is 0.012
Human Feedback received at timestep 886 of -1
Current timestep = 887. State = [[-0.1354116  0.1741288]]. Action = [[ 0.00847441 -0.04633982 -0.0735062   0.7721385 ]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 887 is [True, False, False, False, False, True]
Current timestep = 888. State = [[-0.13499585  0.17336203]]. Action = [[ 0.0268695  -0.00736762  0.03452194  0.246279  ]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 888 is [True, False, False, False, False, True]
Current timestep = 889. State = [[-0.13463014  0.17271319]]. Action = [[ 0.07847475 -0.0023205  -0.05571717  0.06501865]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 889 is [True, False, False, False, False, True]
Current timestep = 890. State = [[-0.13360372  0.17180389]]. Action = [[-0.06440885  0.02336283  0.09939712  0.20854795]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 890 is [True, False, False, False, False, True]
Current timestep = 891. State = [[-0.13340485  0.17181613]]. Action = [[ 0.07114594  0.05211455 -0.05754867  0.72177327]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 891 is [True, False, False, False, False, True]
Current timestep = 892. State = [[-0.13220894  0.17277706]]. Action = [[ 0.02346541  0.01724808 -0.097071   -0.26254362]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 892 is [True, False, False, False, False, True]
Current timestep = 893. State = [[-0.13102692  0.17340933]]. Action = [[ 0.02072918 -0.02557365  0.02855726  0.60408294]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 893 is [True, False, False, False, False, True]
Current timestep = 894. State = [[-0.13025159  0.17388707]]. Action = [[-0.01080244  0.05403348 -0.01041983  0.23601127]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 894 is [True, False, False, False, False, True]
State prediction error at timestep 894 is 0.012
Human Feedback received at timestep 894 of 1
Current timestep = 895. State = [[-0.12428369  0.17959389]]. Action = [[-0.02265695  0.01391633  0.07119263 -0.7242096 ]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 895 is [True, False, False, False, False, True]
Current timestep = 896. State = [[-0.12422395  0.1796726 ]]. Action = [[-0.06514917 -0.03705639 -0.08764727 -0.66519666]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 896 is [True, False, False, False, False, True]
Current timestep = 897. State = [[-0.12427498  0.1797328 ]]. Action = [[-0.0784089   0.05580121  0.03054302 -0.76408756]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 897 is [True, False, False, False, False, True]
State prediction error at timestep 897 is 0.012
Human Feedback received at timestep 897 of -1
Current timestep = 898. State = [[-0.12591971  0.18206644]]. Action = [[-0.03089613 -0.07806367  0.02903099  0.647159  ]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 898 is [True, False, False, False, False, True]
Current timestep = 899. State = [[-0.12567042  0.18123661]]. Action = [[-0.09301739 -0.08689797 -0.05041949 -0.5352886 ]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 899 is [True, False, False, False, False, True]
Current timestep = 900. State = [[-0.12609388  0.17903192]]. Action = [[-0.08341965 -0.08956175 -0.04226464  0.42098212]]. Reward = [0.]
Curr episode timestep = 900
Scene graph at timestep 900 is [True, False, False, False, False, True]
Current timestep = 901. State = [[-0.12723634  0.17550407]]. Action = [[ 0.03159811 -0.09614088 -0.07445858  0.41597986]]. Reward = [0.]
Curr episode timestep = 901
Scene graph at timestep 901 is [True, False, False, False, False, True]
Current timestep = 902. State = [[-0.12753662  0.17114075]]. Action = [[ 0.09385409  0.06346265  0.0027549  -0.73376685]]. Reward = [0.]
Curr episode timestep = 902
Scene graph at timestep 902 is [True, False, False, False, False, True]
Current timestep = 903. State = [[-0.12718676  0.16967005]]. Action = [[-0.07935603  0.0167402   0.02910904  0.57125115]]. Reward = [0.]
Curr episode timestep = 903
Scene graph at timestep 903 is [True, False, False, False, False, True]
Current timestep = 904. State = [[-0.12775978  0.16922161]]. Action = [[ 0.07537896 -0.05933464 -0.0300904  -0.34267306]]. Reward = [0.]
Curr episode timestep = 904
Scene graph at timestep 904 is [True, False, False, False, False, True]
Current timestep = 905. State = [[-0.1270346   0.16700074]]. Action = [[-0.05565983  0.07289916  0.06205503  0.40900445]]. Reward = [0.]
Curr episode timestep = 905
Scene graph at timestep 905 is [True, False, False, False, False, True]
Current timestep = 906. State = [[-0.12739067  0.16755527]]. Action = [[-0.0662068   0.01069977 -0.01846278 -0.8688945 ]]. Reward = [0.]
Curr episode timestep = 906
Scene graph at timestep 906 is [True, False, False, False, False, True]
Current timestep = 907. State = [[-0.12826976  0.16791946]]. Action = [[-0.08059959 -0.04108346  0.05988631  0.7860532 ]]. Reward = [0.]
Curr episode timestep = 907
Scene graph at timestep 907 is [True, False, False, False, False, True]
Current timestep = 908. State = [[-0.1294994   0.16737987]]. Action = [[ 0.01806863  0.04568339 -0.09589341  0.87451863]]. Reward = [0.]
Curr episode timestep = 908
Scene graph at timestep 908 is [True, False, False, False, False, True]
State prediction error at timestep 908 is 0.012
Human Feedback received at timestep 908 of -1
Current timestep = 909. State = [[-0.1346004   0.16770129]]. Action = [[ 0.09899142 -0.05589607 -0.08134917  0.2814293 ]]. Reward = [0.]
Curr episode timestep = 909
Scene graph at timestep 909 is [True, False, False, False, False, True]
Current timestep = 910. State = [[-0.13382065  0.16678126]]. Action = [[-0.06328503  0.02443359  0.06295427  0.6967299 ]]. Reward = [0.]
Curr episode timestep = 910
Scene graph at timestep 910 is [True, False, False, False, False, True]
Current timestep = 911. State = [[-0.13407966  0.16738509]]. Action = [[ 0.09653551 -0.02532632  0.09450188  0.25446916]]. Reward = [0.]
Curr episode timestep = 911
Scene graph at timestep 911 is [True, False, False, False, False, True]
Current timestep = 912. State = [[-0.1333327   0.16623001]]. Action = [[ 0.08972823  0.00527827 -0.00380697  0.0655055 ]]. Reward = [0.]
Curr episode timestep = 912
Scene graph at timestep 912 is [True, False, False, False, False, True]
Current timestep = 913. State = [[-0.132521    0.16560757]]. Action = [[ 0.0677987   0.06183898 -0.01500729 -0.93427217]]. Reward = [0.]
Curr episode timestep = 913
Scene graph at timestep 913 is [True, False, False, False, False, True]
Current timestep = 914. State = [[-0.13219477  0.16574799]]. Action = [[ 0.00903265 -0.08073846 -0.07088149 -0.5293332 ]]. Reward = [0.]
Curr episode timestep = 914
Scene graph at timestep 914 is [True, False, False, False, False, True]
Current timestep = 915. State = [[-0.131001    0.16440837]]. Action = [[0.08118217 0.06520467 0.0263078  0.6361582 ]]. Reward = [0.]
Curr episode timestep = 915
Scene graph at timestep 915 is [True, False, False, False, False, True]
Current timestep = 916. State = [[-0.13013966  0.16439675]]. Action = [[ 0.03548845 -0.00778349 -0.07430907  0.35799026]]. Reward = [0.]
Curr episode timestep = 916
Scene graph at timestep 916 is [True, False, False, False, False, True]
Current timestep = 917. State = [[-0.12917148  0.16429476]]. Action = [[-0.09790182 -0.05136839  0.01648949  0.50291705]]. Reward = [0.]
Curr episode timestep = 917
Scene graph at timestep 917 is [True, False, False, False, False, True]
Current timestep = 918. State = [[-0.12896992  0.16375944]]. Action = [[-0.02586622  0.0898725  -0.05072693  0.2557869 ]]. Reward = [0.]
Curr episode timestep = 918
Scene graph at timestep 918 is [True, False, False, False, False, True]
Current timestep = 919. State = [[-0.12924382  0.16429518]]. Action = [[-0.03693535 -0.01333588  0.01647316 -0.7058575 ]]. Reward = [0.]
Curr episode timestep = 919
Scene graph at timestep 919 is [True, False, False, False, False, True]
Current timestep = 920. State = [[-0.12945472  0.16465244]]. Action = [[-0.05469064  0.02418448 -0.08127294  0.5819497 ]]. Reward = [0.]
Curr episode timestep = 920
Scene graph at timestep 920 is [True, False, False, False, False, True]
Current timestep = 921. State = [[-0.1300097   0.16581908]]. Action = [[ 0.0597868   0.09788913  0.0692981  -0.27533615]]. Reward = [0.]
Curr episode timestep = 921
Scene graph at timestep 921 is [True, False, False, False, False, True]
Current timestep = 922. State = [[-0.13078015  0.1676961 ]]. Action = [[ 0.04750434 -0.09664341 -0.04256422 -0.7038536 ]]. Reward = [0.]
Curr episode timestep = 922
Scene graph at timestep 922 is [True, False, False, False, False, True]
Current timestep = 923. State = [[-0.13017441  0.16641527]]. Action = [[ 0.06065626 -0.07862227 -0.05663332 -0.28851628]]. Reward = [0.]
Curr episode timestep = 923
Scene graph at timestep 923 is [True, False, False, False, False, True]
Current timestep = 924. State = [[-0.12925811  0.16451302]]. Action = [[ 0.0300464   0.05586015 -0.06560711 -0.7354646 ]]. Reward = [0.]
Curr episode timestep = 924
Scene graph at timestep 924 is [True, False, False, False, False, True]
Current timestep = 925. State = [[-0.12903747  0.16476612]]. Action = [[ 0.08316027  0.09315776  0.01035939 -0.88165176]]. Reward = [0.]
Curr episode timestep = 925
Scene graph at timestep 925 is [True, False, False, False, False, True]
Current timestep = 926. State = [[-0.12764873  0.16690882]]. Action = [[-0.06537471  0.05589854  0.00852372  0.9782543 ]]. Reward = [0.]
Curr episode timestep = 926
Scene graph at timestep 926 is [True, False, False, False, False, True]
Current timestep = 927. State = [[-0.12708408  0.16905387]]. Action = [[-0.07951075 -0.00536416  0.01788787  0.484581  ]]. Reward = [0.]
Curr episode timestep = 927
Scene graph at timestep 927 is [True, False, False, False, False, True]
Current timestep = 928. State = [[-0.1272817   0.16981058]]. Action = [[-0.03264285  0.00968951  0.07066978 -0.89557725]]. Reward = [0.]
Curr episode timestep = 928
Scene graph at timestep 928 is [True, False, False, False, False, True]
Current timestep = 929. State = [[-0.12805524  0.1708389 ]]. Action = [[-0.08804687 -0.04126343 -0.01817167  0.3785901 ]]. Reward = [0.]
Curr episode timestep = 929
Scene graph at timestep 929 is [True, False, False, False, False, True]
State prediction error at timestep 929 is 0.012
Human Feedback received at timestep 929 of -1
Current timestep = 930. State = [[-0.12893009  0.17244893]]. Action = [[-0.07188775  0.02567974  0.09164681 -0.9348801 ]]. Reward = [0.]
Curr episode timestep = 930
Scene graph at timestep 930 is [True, False, False, False, False, True]
Current timestep = 931. State = [[-0.12976596  0.17379169]]. Action = [[-0.02623191  0.04378626  0.04621988  0.8469348 ]]. Reward = [0.]
Curr episode timestep = 931
Scene graph at timestep 931 is [True, False, False, False, False, True]
Current timestep = 932. State = [[-0.13081086  0.17569804]]. Action = [[ 0.06884205 -0.07363455 -0.07456936 -0.48603934]]. Reward = [0.]
Curr episode timestep = 932
Scene graph at timestep 932 is [True, False, False, False, False, True]
State prediction error at timestep 932 is 0.012
Human Feedback received at timestep 932 of -1
Current timestep = 933. State = [[-0.13070498  0.17543362]]. Action = [[ 0.04025096 -0.00834483  0.021734   -0.39977723]]. Reward = [0.]
Curr episode timestep = 933
Scene graph at timestep 933 is [True, False, False, False, False, True]
State prediction error at timestep 933 is 0.012
Human Feedback received at timestep 933 of -1
Current timestep = 934. State = [[-0.13070498  0.17543362]]. Action = [[-0.04115825 -0.03977817  0.00133522 -0.7556489 ]]. Reward = [0.]
Curr episode timestep = 934
Scene graph at timestep 934 is [True, False, False, False, False, True]
Current timestep = 935. State = [[-0.13050194  0.17500265]]. Action = [[-0.08550342 -0.00930098 -0.05288993  0.51018786]]. Reward = [0.]
Curr episode timestep = 935
Scene graph at timestep 935 is [True, False, False, False, False, True]
Current timestep = 936. State = [[-0.13104604  0.17497884]]. Action = [[-0.04422996  0.06685717  0.05667823  0.68021655]]. Reward = [0.]
Curr episode timestep = 936
Scene graph at timestep 936 is [True, False, False, False, False, True]
Current timestep = 937. State = [[-0.13144208  0.17563744]]. Action = [[-0.01000511 -0.01128369  0.04246902  0.46054518]]. Reward = [0.]
Curr episode timestep = 937
Scene graph at timestep 937 is [True, False, False, False, False, True]
Current timestep = 938. State = [[-0.13175541  0.17602785]]. Action = [[0.06727143 0.0131681  0.02000137 0.906888  ]]. Reward = [0.]
Curr episode timestep = 938
Scene graph at timestep 938 is [True, False, False, False, False, True]
Current timestep = 939. State = [[-0.13177252  0.17602836]]. Action = [[-0.01332896 -0.02220585 -0.075366   -0.11340064]]. Reward = [0.]
Curr episode timestep = 939
Scene graph at timestep 939 is [True, False, False, False, False, True]
Current timestep = 940. State = [[-0.13182256  0.1761465 ]]. Action = [[-0.01680029  0.02067788  0.04494875  0.80609727]]. Reward = [0.]
Curr episode timestep = 940
Scene graph at timestep 940 is [True, False, False, False, False, True]
Current timestep = 941. State = [[-0.13193566  0.17597507]]. Action = [[-0.05739452 -0.08833259  0.04035407 -0.46496332]]. Reward = [0.]
Curr episode timestep = 941
Scene graph at timestep 941 is [True, False, False, False, False, True]
Current timestep = 942. State = [[-0.13279001  0.17500016]]. Action = [[-0.02508176  0.08452003  0.06170066 -0.29688525]]. Reward = [0.]
Curr episode timestep = 942
Scene graph at timestep 942 is [True, False, False, False, False, True]
Current timestep = 943. State = [[-0.13393469  0.17571561]]. Action = [[ 0.07462993  0.08427846 -0.06863949  0.7790005 ]]. Reward = [0.]
Curr episode timestep = 943
Scene graph at timestep 943 is [True, False, False, False, False, True]
Current timestep = 944. State = [[-0.13474995  0.1773639 ]]. Action = [[0.06055851 0.01179151 0.06802126 0.97877383]]. Reward = [0.]
Curr episode timestep = 944
Scene graph at timestep 944 is [True, False, False, False, False, True]
Current timestep = 945. State = [[-0.13513753  0.1780711 ]]. Action = [[-0.01235661 -0.02439753  0.0480834  -0.45056152]]. Reward = [0.]
Curr episode timestep = 945
Scene graph at timestep 945 is [True, False, False, False, False, True]
State prediction error at timestep 945 is 0.012
Human Feedback received at timestep 945 of -1
Current timestep = 946. State = [[-0.13542433  0.17854188]]. Action = [[ 0.01561481 -0.02096728 -0.03962373  0.8735049 ]]. Reward = [0.]
Curr episode timestep = 946
Scene graph at timestep 946 is [True, False, False, False, False, True]
Current timestep = 947. State = [[-0.13536699  0.17843021]]. Action = [[ 0.01918431 -0.09318873 -0.05782218 -0.3469535 ]]. Reward = [0.]
Curr episode timestep = 947
Scene graph at timestep 947 is [True, False, False, False, False, True]
State prediction error at timestep 947 is 0.012
Human Feedback received at timestep 947 of -1
Current timestep = 948. State = [[-0.13406886  0.17610697]]. Action = [[ 0.04498086  0.01954328  0.09798677 -0.02904272]]. Reward = [0.]
Curr episode timestep = 948
Scene graph at timestep 948 is [True, False, False, False, False, True]
Current timestep = 949. State = [[-0.13406886  0.17610697]]. Action = [[-0.04869395  0.03177086 -0.07267751 -0.28634965]]. Reward = [0.]
Curr episode timestep = 949
Scene graph at timestep 949 is [True, False, False, False, False, True]
Current timestep = 950. State = [[-0.13422368  0.17632754]]. Action = [[ 0.03578683  0.01071352  0.02693928 -0.7555905 ]]. Reward = [0.]
Curr episode timestep = 950
Scene graph at timestep 950 is [True, False, False, False, False, True]
Current timestep = 951. State = [[-0.13413744  0.17624134]]. Action = [[ 0.08200314  0.05443198 -0.01779336  0.6757114 ]]. Reward = [0.]
Curr episode timestep = 951
Scene graph at timestep 951 is [True, False, False, False, False, True]
Current timestep = 952. State = [[-0.13440938  0.17672305]]. Action = [[-0.07424372 -0.09158712 -0.07694933  0.6195617 ]]. Reward = [0.]
Curr episode timestep = 952
Scene graph at timestep 952 is [True, False, False, False, False, True]
Current timestep = 953. State = [[-0.13416478  0.17647108]]. Action = [[-0.069371    0.00381778  0.06619629 -0.21495974]]. Reward = [0.]
Curr episode timestep = 953
Scene graph at timestep 953 is [True, False, False, False, False, True]
Current timestep = 954. State = [[-0.13436626  0.17682493]]. Action = [[ 0.01090918  0.08659453 -0.07451959  0.38285136]]. Reward = [0.]
Curr episode timestep = 954
Scene graph at timestep 954 is [True, False, False, False, False, True]
Current timestep = 955. State = [[-0.13477504  0.17768435]]. Action = [[ 0.00254086 -0.00507199 -0.05153171 -0.7048568 ]]. Reward = [0.]
Curr episode timestep = 955
Scene graph at timestep 955 is [True, False, False, False, False, True]
Current timestep = 956. State = [[-0.13492155  0.17799535]]. Action = [[ 0.03166268 -0.00197843 -0.07150361  0.51603174]]. Reward = [0.]
Curr episode timestep = 956
Scene graph at timestep 956 is [True, False, False, False, False, True]
State prediction error at timestep 956 is 0.012
Human Feedback received at timestep 956 of -1
Current timestep = 957. State = [[-0.13499428  0.17803806]]. Action = [[0.07444104 0.09782951 0.09005044 0.6951506 ]]. Reward = [0.]
Curr episode timestep = 957
Scene graph at timestep 957 is [True, False, False, False, False, True]
Current timestep = 958. State = [[-0.13479084  0.1792061 ]]. Action = [[0.08405428 0.00096381 0.06356253 0.50041604]]. Reward = [0.]
Curr episode timestep = 958
Scene graph at timestep 958 is [True, False, False, False, False, True]
Current timestep = 959. State = [[-0.13374273  0.17993766]]. Action = [[ 0.06241379 -0.02273578  0.06957509  0.04101753]]. Reward = [0.]
Curr episode timestep = 959
Scene graph at timestep 959 is [True, False, False, False, False, True]
Current timestep = 960. State = [[-0.13207516  0.1799395 ]]. Action = [[ 0.08441157  0.0815258  -0.06698299 -0.523966  ]]. Reward = [0.]
Curr episode timestep = 960
Scene graph at timestep 960 is [True, False, False, False, False, True]
Current timestep = 961. State = [[-0.12983085  0.18245792]]. Action = [[ 0.0206154   0.079207    0.03728435 -0.8064507 ]]. Reward = [0.]
Curr episode timestep = 961
Scene graph at timestep 961 is [True, False, False, False, False, True]
Current timestep = 962. State = [[-0.12731533  0.18567258]]. Action = [[-0.04263875 -0.07917876  0.06046348 -0.21784282]]. Reward = [0.]
Curr episode timestep = 962
Scene graph at timestep 962 is [True, False, False, False, False, True]
Current timestep = 963. State = [[-0.12567626  0.18614307]]. Action = [[-0.00197476 -0.06882813  0.09341245 -0.13169128]]. Reward = [0.]
Curr episode timestep = 963
Scene graph at timestep 963 is [True, False, False, False, False, True]
Current timestep = 964. State = [[-0.12478025  0.18522978]]. Action = [[-0.01502205  0.05394488  0.08252098  0.84701204]]. Reward = [0.]
Curr episode timestep = 964
Scene graph at timestep 964 is [True, False, False, False, False, True]
State prediction error at timestep 964 is 0.012
Human Feedback received at timestep 964 of -1
Current timestep = 965. State = [[-0.12415572  0.18722326]]. Action = [[0.09899279 0.03348307 0.07657876 0.96536326]]. Reward = [0.]
Curr episode timestep = 965
Scene graph at timestep 965 is [True, False, False, False, False, True]
State prediction error at timestep 965 is 0.012
Human Feedback received at timestep 965 of -1
Current timestep = 966. State = [[-0.11987048  0.19097903]]. Action = [[0.07116457 0.03746688 0.09430509 0.1969577 ]]. Reward = [0.]
Curr episode timestep = 966
Scene graph at timestep 966 is [True, False, False, False, False, True]
State prediction error at timestep 966 is 0.012
Human Feedback received at timestep 966 of 1
Current timestep = 967. State = [[-0.1159526   0.19388932]]. Action = [[ 0.04990234 -0.05827497  0.01456747  0.75828576]]. Reward = [0.]
Curr episode timestep = 967
Scene graph at timestep 967 is [True, False, False, False, False, True]
Current timestep = 968. State = [[-0.11417485  0.19290148]]. Action = [[-0.04811747  0.06874769 -0.09766384  0.5653417 ]]. Reward = [0.]
Curr episode timestep = 968
Scene graph at timestep 968 is [True, False, False, False, False, True]
Current timestep = 969. State = [[-0.1136714   0.19380422]]. Action = [[ 0.09725779 -0.04575193  0.09416205 -0.12988919]]. Reward = [0.]
Curr episode timestep = 969
Scene graph at timestep 969 is [True, False, False, False, False, True]
Current timestep = 970. State = [[-0.11178067  0.19337997]]. Action = [[-6.0896076e-02  1.6329899e-02  6.6139549e-04 -8.0751985e-01]]. Reward = [0.]
Curr episode timestep = 970
Scene graph at timestep 970 is [True, False, False, False, False, True]
State prediction error at timestep 970 is 0.012
Human Feedback received at timestep 970 of 1
Current timestep = 971. State = [[-0.11035039  0.19403893]]. Action = [[-0.01447992  0.05521802 -0.01586162  0.8585055 ]]. Reward = [0.]
Curr episode timestep = 971
Scene graph at timestep 971 is [True, False, False, False, False, True]
State prediction error at timestep 971 is 0.012
Human Feedback received at timestep 971 of 1
Current timestep = 972. State = [[-0.11029019  0.19516478]]. Action = [[ 0.01719111  0.08940654  0.0395174  -0.01785398]]. Reward = [0.]
Curr episode timestep = 972
Scene graph at timestep 972 is [True, False, False, False, False, True]
Current timestep = 973. State = [[-0.11009309  0.19726117]]. Action = [[ 0.0634846   0.01896201  0.09452837 -0.5259989 ]]. Reward = [0.]
Curr episode timestep = 973
Scene graph at timestep 973 is [True, False, False, False, False, True]
Current timestep = 974. State = [[-0.10866802  0.19882059]]. Action = [[ 0.01359548  0.03608038 -0.0562992   0.20189917]]. Reward = [0.]
Curr episode timestep = 974
Scene graph at timestep 974 is [True, False, False, False, False, True]
Current timestep = 975. State = [[-0.10654823  0.201509  ]]. Action = [[-0.02777552 -0.02939115 -0.06359877 -0.28144813]]. Reward = [0.]
Curr episode timestep = 975
Scene graph at timestep 975 is [True, False, False, False, False, True]
Current timestep = 976. State = [[-0.10531122  0.20303656]]. Action = [[-0.09690737 -0.00301504  0.04762272  0.55649614]]. Reward = [0.]
Curr episode timestep = 976
Scene graph at timestep 976 is [True, False, False, False, False, True]
State prediction error at timestep 976 is 0.012
Human Feedback received at timestep 976 of -1
Current timestep = 977. State = [[-0.10606859  0.2039224 ]]. Action = [[-0.01011229 -0.09242389  0.09397715 -0.50125897]]. Reward = [0.]
Curr episode timestep = 977
Scene graph at timestep 977 is [True, False, False, False, False, True]
Current timestep = 978. State = [[-0.10568438  0.20332125]]. Action = [[ 0.09578169  0.02359129  0.01079711 -0.3578788 ]]. Reward = [0.]
Curr episode timestep = 978
Scene graph at timestep 978 is [True, False, False, False, False, True]
Current timestep = 979. State = [[-0.10528659  0.20259613]]. Action = [[ 0.09676328  0.0420832  -0.00397911 -0.45464778]]. Reward = [0.]
Curr episode timestep = 979
Scene graph at timestep 979 is [True, False, False, False, False, True]
Current timestep = 980. State = [[-0.10431038  0.20269656]]. Action = [[-0.01192524 -0.06527869  0.08555084  0.31549096]]. Reward = [0.]
Curr episode timestep = 980
Scene graph at timestep 980 is [True, False, False, False, False, True]
State prediction error at timestep 980 is 0.012
Human Feedback received at timestep 980 of -1
Current timestep = 981. State = [[-0.10222337  0.19943509]]. Action = [[ 0.07798595 -0.03863639 -0.0384877  -0.6364405 ]]. Reward = [0.]
Curr episode timestep = 981
Scene graph at timestep 981 is [True, False, False, False, False, True]
Current timestep = 982. State = [[-0.10117907  0.19799234]]. Action = [[-0.0427819  -0.01712835  0.05040497  0.89997673]]. Reward = [0.]
Curr episode timestep = 982
Scene graph at timestep 982 is [True, False, False, False, False, True]
State prediction error at timestep 982 is 0.012
Human Feedback received at timestep 982 of -1
Current timestep = 983. State = [[-0.09925129  0.19535998]]. Action = [[ 0.01721631  0.0766285   0.07251649 -0.6600516 ]]. Reward = [0.]
Curr episode timestep = 983
Scene graph at timestep 983 is [True, False, False, False, False, True]
Current timestep = 984. State = [[-0.09900669  0.19640414]]. Action = [[ 0.07465675 -0.00395219  0.06290405 -0.83267987]]. Reward = [0.]
Curr episode timestep = 984
Scene graph at timestep 984 is [True, False, False, False, False, True]
Current timestep = 985. State = [[-0.09795666  0.19678552]]. Action = [[-0.03359612 -0.01797117  0.07402737  0.8324299 ]]. Reward = [0.]
Curr episode timestep = 985
Scene graph at timestep 985 is [True, False, False, False, False, True]
Current timestep = 986. State = [[-0.0975916   0.19714199]]. Action = [[ 0.0043617  -0.01707197 -0.09512517  0.7571852 ]]. Reward = [0.]
Curr episode timestep = 986
Scene graph at timestep 986 is [True, False, False, False, False, True]
Current timestep = 987. State = [[-0.09734845  0.1973705 ]]. Action = [[0.05393986 0.08451789 0.06035089 0.91074586]]. Reward = [0.]
Curr episode timestep = 987
Scene graph at timestep 987 is [True, False, False, False, False, True]
Current timestep = 988. State = [[-0.09597617  0.19905475]]. Action = [[-0.09513517 -0.07575029 -0.09776043  0.5027149 ]]. Reward = [0.]
Curr episode timestep = 988
Scene graph at timestep 988 is [True, False, False, False, False, True]
Current timestep = 989. State = [[-0.0950158  0.1990128]]. Action = [[ 0.03991907 -0.04135776  0.06147832  0.14787495]]. Reward = [0.]
Curr episode timestep = 989
Scene graph at timestep 989 is [True, False, False, False, False, True]
State prediction error at timestep 989 is 0.012
Human Feedback received at timestep 989 of -1
Current timestep = 990. State = [[-0.09199385  0.1955087 ]]. Action = [[ 0.01049151 -0.00351747  0.07600265 -0.08527881]]. Reward = [0.]
Curr episode timestep = 990
Scene graph at timestep 990 is [True, False, False, False, False, True]
Current timestep = 991. State = [[-0.09195811  0.19544497]]. Action = [[-0.02764587 -0.06312492 -0.00900898  0.650923  ]]. Reward = [0.]
Curr episode timestep = 991
Scene graph at timestep 991 is [True, False, False, False, False, True]
State prediction error at timestep 991 is 0.012
Human Feedback received at timestep 991 of 1
Current timestep = 992. State = [[-0.09147294  0.19231443]]. Action = [[-0.03136913  0.02429801  0.02039461  0.6611495 ]]. Reward = [0.]
Curr episode timestep = 992
Scene graph at timestep 992 is [True, False, False, False, False, True]
Current timestep = 993. State = [[-0.09155909  0.1923542 ]]. Action = [[ 0.09209859 -0.02520504 -0.04470358 -0.692278  ]]. Reward = [0.]
Curr episode timestep = 993
Scene graph at timestep 993 is [True, False, False, False, False, True]
Current timestep = 994. State = [[-0.09133121  0.19191845]]. Action = [[-0.06004525  0.06383594  0.00353722  0.4478165 ]]. Reward = [0.]
Curr episode timestep = 994
Scene graph at timestep 994 is [True, False, False, False, False, True]
Current timestep = 995. State = [[-0.09185214  0.19269049]]. Action = [[-0.08616318 -0.03452219 -0.07548784 -0.5358048 ]]. Reward = [0.]
Curr episode timestep = 995
Scene graph at timestep 995 is [True, False, False, False, False, True]
State prediction error at timestep 995 is 0.012
Human Feedback received at timestep 995 of 1
Current timestep = 996. State = [[-0.09213109  0.19286412]]. Action = [[ 0.00700314  0.00219162 -0.02411757 -0.5991376 ]]. Reward = [0.]
Curr episode timestep = 996
Scene graph at timestep 996 is [True, False, False, False, False, True]
Current timestep = 997. State = [[-0.09216844  0.19288087]]. Action = [[-0.08489864 -0.06169039 -0.00760527  0.7437209 ]]. Reward = [0.]
Curr episode timestep = 997
Scene graph at timestep 997 is [True, False, False, False, False, True]
Current timestep = 998. State = [[-0.09217504  0.19229527]]. Action = [[-0.09520837 -0.0915528  -0.07435171  0.5565076 ]]. Reward = [0.]
Curr episode timestep = 998
Scene graph at timestep 998 is [True, False, False, False, False, True]
Current timestep = 999. State = [[-0.0924751   0.18994026]]. Action = [[ 0.05635961 -0.05256925 -0.01603507  0.8191378 ]]. Reward = [0.]
Curr episode timestep = 999
Scene graph at timestep 999 is [True, False, False, False, False, True]
Current timestep = 1000. State = [[-0.09250953  0.18761048]]. Action = [[-0.02084371 -0.06486428 -0.0530897   0.36910772]]. Reward = [0.]
Curr episode timestep = 1000
Scene graph at timestep 1000 is [True, False, False, False, False, True]
State prediction error at timestep 1000 is 0.012
Human Feedback received at timestep 1000 of 1
Current timestep = 1001. State = [[-0.09242826  0.18056628]]. Action = [[-0.03861452 -0.08106516  0.05596922 -0.37766755]]. Reward = [0.]
Curr episode timestep = 1001
Scene graph at timestep 1001 is [True, False, False, False, False, True]
Current timestep = 1002. State = [[-0.09252774  0.1782219 ]]. Action = [[ 0.02965219 -0.01920224 -0.07871969  0.7019793 ]]. Reward = [0.]
Curr episode timestep = 1002
Scene graph at timestep 1002 is [True, False, False, False, False, True]
Current timestep = 1003. State = [[-0.09250157  0.17566662]]. Action = [[-0.00776701 -0.09812682  0.07960107  0.9466896 ]]. Reward = [0.]
Curr episode timestep = 1003
Scene graph at timestep 1003 is [True, False, False, False, False, True]
Current timestep = 1004. State = [[-0.09239586  0.1720048 ]]. Action = [[-0.0441862  -0.02287438  0.02140515  0.22634363]]. Reward = [0.]
Curr episode timestep = 1004
Scene graph at timestep 1004 is [True, False, False, False, False, True]
Current timestep = 1005. State = [[-0.09347584  0.16906759]]. Action = [[-0.03817734 -0.07460159 -0.04011443 -0.77004814]]. Reward = [0.]
Curr episode timestep = 1005
Scene graph at timestep 1005 is [True, False, False, False, False, True]
Current timestep = 1006. State = [[-0.09493148  0.1653192 ]]. Action = [[ 0.03919714 -0.03906184 -0.03916722  0.87841535]]. Reward = [0.]
Curr episode timestep = 1006
Scene graph at timestep 1006 is [True, False, False, False, False, True]
State prediction error at timestep 1006 is 0.012
Human Feedback received at timestep 1006 of -1
Current timestep = 1007. State = [[-0.09588043  0.15652472]]. Action = [[-0.02054184 -0.03128257  0.06392481  0.90425086]]. Reward = [0.]
Curr episode timestep = 1007
Scene graph at timestep 1007 is [True, False, False, False, False, True]
State prediction error at timestep 1007 is 0.012
Human Feedback received at timestep 1007 of 1
Current timestep = 1008. State = [[-0.0961025   0.15438397]]. Action = [[ 0.02725398  0.04996251 -0.06594665 -0.6225882 ]]. Reward = [0.]
Curr episode timestep = 1008
Scene graph at timestep 1008 is [True, False, False, False, False, True]
Current timestep = 1009. State = [[-0.0961025   0.15438397]]. Action = [[ 0.09491577  0.0544657  -0.00205831  0.76703167]]. Reward = [0.]
Curr episode timestep = 1009
Scene graph at timestep 1009 is [True, False, False, False, False, True]
Current timestep = 1010. State = [[-0.09606621  0.15442145]]. Action = [[ 0.01019116 -0.05599188  0.01059698 -0.68790007]]. Reward = [0.]
Curr episode timestep = 1010
Scene graph at timestep 1010 is [True, False, False, False, False, True]
Current timestep = 1011. State = [[-0.09577271  0.15457211]]. Action = [[ 0.07431579  0.02838691 -0.0165839  -0.03772992]]. Reward = [0.]
Curr episode timestep = 1011
Scene graph at timestep 1011 is [True, False, False, False, False, True]
Current timestep = 1012. State = [[-0.09547789  0.15464193]]. Action = [[0.0269706  0.01076402 0.008858   0.42734635]]. Reward = [0.]
Curr episode timestep = 1012
Scene graph at timestep 1012 is [True, False, False, False, False, True]
Current timestep = 1013. State = [[-0.09509187  0.15495233]]. Action = [[-0.0946182   0.02043293  0.04330993 -0.2018624 ]]. Reward = [0.]
Curr episode timestep = 1013
Scene graph at timestep 1013 is [True, False, False, False, False, True]
State prediction error at timestep 1013 is 0.012
Human Feedback received at timestep 1013 of 1
Current timestep = 1014. State = [[-0.09516396  0.15515885]]. Action = [[ 0.0751218   0.02965959 -0.01354971 -0.86963993]]. Reward = [0.]
Curr episode timestep = 1014
Scene graph at timestep 1014 is [True, False, False, False, False, True]
Current timestep = 1015. State = [[-0.09496024  0.1553619 ]]. Action = [[ 0.04310875 -0.01290338  0.09669652  0.16432142]]. Reward = [0.]
Curr episode timestep = 1015
Scene graph at timestep 1015 is [True, False, False, False, False, True]
State prediction error at timestep 1015 is 0.012
Human Feedback received at timestep 1015 of -1
Current timestep = 1016. State = [[-0.09256405  0.15719241]]. Action = [[-0.01784409  0.0863105  -0.0194243  -0.79304975]]. Reward = [0.]
Curr episode timestep = 1016
Scene graph at timestep 1016 is [True, False, False, False, False, True]
State prediction error at timestep 1016 is 0.012
Human Feedback received at timestep 1016 of -1
Current timestep = 1017. State = [[-0.09266772  0.15951498]]. Action = [[ 0.06661092  0.08675348  0.09495401 -0.05441201]]. Reward = [0.]
Curr episode timestep = 1017
Scene graph at timestep 1017 is [True, False, False, False, False, True]
Current timestep = 1018. State = [[-0.09207461  0.16138501]]. Action = [[-0.00794149 -0.0415217   0.02281437  0.12224686]]. Reward = [0.]
Curr episode timestep = 1018
Scene graph at timestep 1018 is [True, False, False, False, False, True]
State prediction error at timestep 1018 is 0.012
