Current timestep = 0. State = [[-0.01003599  1.4279668  -0.5073682   0.37816858  0.00948947  0.07379487
   0.          0.        ]]. Action = [[0.21324694 0.9795289 ]]. Reward = [-1.4340123]
Curr episode timestep = 0
Scene graph at timestep 0 is None
Current timestep = 1. State = [[-0.01507254  1.4358772  -0.50738     0.35153988  0.0131768   0.07375313
   0.          0.        ]]. Action = [[-0.8392989  -0.09151709]]. Reward = [0.38931507]
Curr episode timestep = 1
Scene graph at timestep 1 is [False, True, True, True, True, True, True, True, False, False]
State prediction error at timestep 1 is 0.012
Human Feedback received at timestep 1 of -1
Current timestep = 2. State = [[-0.01999855  1.4436843  -0.4968818   0.346942    0.01741469  0.08476544
   0.          0.        ]]. Action = [[ 0.5411637 -0.3711567]]. Reward = [-0.31723234]
Curr episode timestep = 2
Scene graph at timestep 2 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 3. State = [[-0.02506218  1.4514271  -0.5100101   0.3440797   0.02102274  0.07216763
   0.          0.        ]]. Action = [[0.69996643 0.39171696]]. Reward = [-2.31831]
Curr episode timestep = 3
Scene graph at timestep 3 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 4. State = [[-0.03018713  1.4595295  -0.51590526  0.36005607  0.02440257  0.06760245
   0.          0.        ]]. Action = [[ 0.22983932 -0.36949283]]. Reward = [-2.7323573]
Curr episode timestep = 4
Scene graph at timestep 4 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 5. State = [[-0.03531218  1.467032   -0.515915    0.3333813   0.02778182  0.06759097
   0.          0.        ]]. Action = [[-0.44545293  0.3546927 ]]. Reward = [0.3874061]
Curr episode timestep = 5
Scene graph at timestep 5 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 6. State = [[-0.0404933   1.4739267  -0.522958    0.30633292  0.03257414  0.09585513
   0.          0.        ]]. Action = [[-0.8416494 -0.8901052]]. Reward = [-0.39018008]
Curr episode timestep = 6
Scene graph at timestep 6 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 7. State = [[-0.0456747   1.4802216  -0.5229732   0.2796628   0.03736512  0.09582804
   0.          0.        ]]. Action = [[-0.6771529   0.12509131]]. Reward = [0.17857356]
Curr episode timestep = 7
Scene graph at timestep 7 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 8. State = [[-0.05086193  1.4872078  -0.52500606  0.31032455  0.04357943  0.12429772
   0.          0.        ]]. Action = [[ 0.7784449 -0.6182288]]. Reward = [-3.3028145]
Curr episode timestep = 8
Scene graph at timestep 8 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 9. State = [[-0.05607691  1.4941015  -0.5277147   0.30619946  0.04973137  0.12304971
   0.          0.        ]]. Action = [[ 0.71183515 -0.43866527]]. Reward = [-1.6048645]
Curr episode timestep = 9
Scene graph at timestep 9 is [False, True, True, True, True, True, True, True, False, True]
State prediction error at timestep 9 is 0.012
Human Feedback received at timestep 9 of -1
Current timestep = 10. State = [[-0.06122694  1.5003924  -0.5195607   0.2794355   0.05424857  0.09035259
   0.          0.        ]]. Action = [[-0.85825366  0.964123  ]]. Reward = [0.8882962]
Curr episode timestep = 10
Scene graph at timestep 10 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 11. State = [[-0.06630497  1.5060982  -0.5105189   0.25348526  0.05693866  0.05380654
   0.          0.        ]]. Action = [[-0.40060323  0.86709154]]. Reward = [1.1086274]
Curr episode timestep = 11
Scene graph at timestep 11 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 12. State = [[-0.07156935  1.511986   -0.53056973  0.26152423  0.06103126  0.08185986
   0.          0.        ]]. Action = [[ 0.13032615 -0.7540799 ]]. Reward = [-3.3672788]
Curr episode timestep = 12
Scene graph at timestep 12 is [False, True, True, True, True, True, True, False, False, False]
State prediction error at timestep 12 is 0.012
Human Feedback received at timestep 12 of -1
Current timestep = 13. State = [[-0.07704058  1.5178194  -0.5525931   0.25903252  0.06644952  0.10837488
   0.          0.        ]]. Action = [[ 0.80835104 -0.796832  ]]. Reward = [-3.32341]
Curr episode timestep = 13
Scene graph at timestep 13 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 14. State = [[-0.0826993   1.5238163  -0.5724548   0.26622334  0.07297345  0.13049097
   0.          0.        ]]. Action = [[ 0.56134987 -0.66732985]]. Reward = [-3.6390445]
Curr episode timestep = 14
Scene graph at timestep 14 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 15. State = [[-0.08849669  1.5299586  -0.5858367   0.272683    0.07901753  0.12089263
   0.          0.        ]]. Action = [[ 0.1529994 -0.2076577]]. Reward = [-2.9088643]
Curr episode timestep = 15
Scene graph at timestep 15 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 16. State = [[-0.09438477  1.5354897  -0.5972057   0.24535912  0.08734837  0.16663174
   0.          0.        ]]. Action = [[-0.11930978 -0.9231334 ]]. Reward = [-1.3934005]
Curr episode timestep = 16
Scene graph at timestep 16 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 17. State = [[-0.10038767  1.5416757  -0.6068282   0.27453703  0.09384403  0.12992464
   0.          0.        ]]. Action = [[0.7090889  0.82021916]]. Reward = [-3.6255827]
Curr episode timestep = 17
Scene graph at timestep 17 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 18. State = [[-0.10634308  1.5472764  -0.6008505   0.24857679  0.09911898  0.10550819
   0.          0.        ]]. Action = [[-0.63038015  0.7082974 ]]. Reward = [0.43281946]
Curr episode timestep = 18
Scene graph at timestep 18 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 19. State = [[-0.11229868  1.5522774  -0.60086465  0.2219098   0.10439315  0.10549277
   0.          0.        ]]. Action = [[-0.01082945  0.3346014 ]]. Reward = [-0.09749264]
Curr episode timestep = 19
Scene graph at timestep 19 is [False, True, True, True, True, True, True, False, True, False]
State prediction error at timestep 19 is 0.012
Human Feedback received at timestep 19 of -1
Current timestep = 20. State = [[-0.11832313  1.5580087  -0.60786146  0.25433034  0.10977759  0.10769852
   0.          0.        ]]. Action = [[0.86779296 0.41064763]]. Reward = [-3.273728]
Curr episode timestep = 20
Scene graph at timestep 20 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 21. State = [[-0.12434778  1.5631399  -0.6078744   0.2276477   0.11516117  0.10768107
   0.          0.        ]]. Action = [[-0.9089347  0.2793306]]. Reward = [-0.11464372]
Curr episode timestep = 21
Scene graph at timestep 21 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 22. State = [[-0.13057737  1.5682647  -0.62995607  0.2272148   0.12212834  0.13935603
   0.          0.        ]]. Action = [[ 0.70696855 -0.8682131 ]]. Reward = [-3.5978343]
Curr episode timestep = 22
Scene graph at timestep 22 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 23. State = [[-0.13678741  1.5735247  -0.6299703   0.23302247  0.13105676  0.17858429
   0.          0.        ]]. Action = [[ 0.8910785 -0.835037 ]]. Reward = [-1.978922]
Curr episode timestep = 23
Scene graph at timestep 23 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 24. State = [[-0.14297123  1.5786765  -0.62911403  0.22798486  0.14174594  0.21378386
   0.          0.        ]]. Action = [[ 0.7459488  -0.74625194]]. Reward = [-1.6674086]
Curr episode timestep = 24
Scene graph at timestep 24 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 25. State = [[-0.14914942  1.5840198  -0.62993324  0.23628817  0.15383688  0.24181867
   0.          0.        ]]. Action = [[ 0.5938306  -0.54309493]]. Reward = [-2.4174883]
Curr episode timestep = 25
Scene graph at timestep 25 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 26. State = [[-0.15530233  1.5894114  -0.6278166   0.23828374  0.16634864  0.25023487
   0.          0.        ]]. Action = [[ 0.1610241  -0.41295707]]. Reward = [-1.8931974]
Curr episode timestep = 26
Scene graph at timestep 26 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 27. State = [[-0.16157217  1.5947647  -0.6392231   0.23650245  0.17861393  0.24530593
   0.          0.        ]]. Action = [[ 0.73252416 -0.4068712 ]]. Reward = [-3.0867956]
Curr episode timestep = 27
Scene graph at timestep 27 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 28. State = [[-0.16776934  1.5995363  -0.6300688   0.21078505  0.18901111  0.2079434
   0.          0.        ]]. Action = [[-0.82281065  0.77564776]]. Reward = [0.11673076]
Curr episode timestep = 28
Scene graph at timestep 28 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 29. State = [[-0.17412558  1.604362   -0.64440167  0.21333313  0.19782503  0.17627858
   0.          0.        ]]. Action = [[0.73702824 0.6399895 ]]. Reward = [-3.1488512]
Curr episode timestep = 29
Scene graph at timestep 29 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 30. State = [[-0.1806159   1.6092517  -0.6575828   0.21615963  0.20643325  0.17216446
   0.          0.        ]]. Action = [[0.29509866 0.4884287 ]]. Reward = [-2.952636]
Curr episode timestep = 30
Scene graph at timestep 30 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 31. State = [[-0.18706302  1.6135598  -0.6521009   0.19042301  0.21389471  0.1492291
   0.          0.        ]]. Action = [[-0.1673336   0.60823846]]. Reward = [0.02090326]
Curr episode timestep = 31
Scene graph at timestep 31 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 32. State = [[-0.19364604  1.6185685  -0.66734844  0.22126359  0.22304274  0.18296036
   0.          0.        ]]. Action = [[ 0.89475346 -0.7147583 ]]. Reward = [-4.168644]
Curr episode timestep = 32
Scene graph at timestep 32 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 33. State = [[-0.20016909  1.6229951  -0.6598005   0.1955861   0.23063381  0.15182176
   0.          0.        ]]. Action = [[-0.38237667  0.6884769 ]]. Reward = [0.19151041]
Curr episode timestep = 33
Scene graph at timestep 33 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 34. State = [[-0.2066462   1.6268427  -0.65399396  0.1700115   0.23699829  0.12728986
   0.          0.        ]]. Action = [[-0.42346227  0.59976184]]. Reward = [0.12817049]
Curr episode timestep = 34
Scene graph at timestep 34 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 35. State = [[-0.2131339   1.6305635  -0.65532386  0.16429636  0.2436579   0.13319236
   0.          0.        ]]. Action = [[ 0.39687824 -0.21060163]]. Reward = [-1.3149003]
Curr episode timestep = 35
Scene graph at timestep 35 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 36. State = [[-0.2196217   1.6336849  -0.6553225   0.1376261   0.25031748  0.13319193
   0.          0.        ]]. Action = [[-0.7712213 -0.4225014]]. Reward = [-0.46193483]
Curr episode timestep = 36
Scene graph at timestep 36 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 37. State = [[-0.2261908   1.6361803  -0.6655208   0.10940311  0.25910127  0.17567594
   0.          0.        ]]. Action = [[-0.31240654 -0.850606  ]]. Reward = [-1.7233757]
Curr episode timestep = 37
Scene graph at timestep 37 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 38. State = [[-0.23278208  1.6386337  -0.6680523   0.1074393   0.26822674  0.18250959
   0.          0.        ]]. Action = [[0.17786074 0.3367436 ]]. Reward = [-1.6420395]
Curr episode timestep = 38
Scene graph at timestep 38 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 39. State = [[-0.23931427  1.6405183  -0.6605489   0.08238953  0.27574104  0.15028621
   0.          0.        ]]. Action = [[-0.89332384  0.78584146]]. Reward = [0.04231549]
Curr episode timestep = 39
Scene graph at timestep 39 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 40. State = [[-0.24592939  1.6427714  -0.67063415  0.09838912  0.28510886  0.18735662
   0.          0.        ]]. Action = [[ 0.5713482 -0.7864103]]. Reward = [-2.7302556]
Curr episode timestep = 40
Scene graph at timestep 40 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 41. State = [[-0.25290713  1.645628   -0.70632213  0.12525903  0.29390994  0.17602143
   0.          0.        ]]. Action = [[ 0.96615565 -0.33570695]]. Reward = [-5.515091]
Curr episode timestep = 41
Scene graph at timestep 41 is [False, True, True, True, True, True, True, True, False, True]
State prediction error at timestep 41 is 0.012
Human Feedback received at timestep 41 of -1
Current timestep = 42. State = [[-0.26001492  1.648359   -0.7173543   0.12003572  0.3006995   0.13579133
   0.          0.        ]]. Action = [[0.27828693 0.9748335 ]]. Reward = [-2.2776465]
Curr episode timestep = 42
Scene graph at timestep 42 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 43. State = [[-0.26712283  1.6504905  -0.7173526   0.09336536  0.30748904  0.1357909
   0.          0.        ]]. Action = [[-0.23120546 -0.36389607]]. Reward = [-0.60911745]
Curr episode timestep = 43
Scene graph at timestep 43 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 44. State = [[-0.27438602  1.6528703  -0.73297167  0.10434546  0.3143851   0.13792102
   0.          0.        ]]. Action = [[0.365587   0.12147331]]. Reward = [-2.942653]
Curr episode timestep = 44
Scene graph at timestep 44 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 45. State = [[-0.28180808  1.6553742  -0.74883604  0.109826    0.32127216  0.13774171
   0.          0.        ]]. Action = [[ 0.5055556  -0.45808458]]. Reward = [-2.9330292]
Curr episode timestep = 45
Scene graph at timestep 45 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 46. State = [[-0.2893309   1.6576455  -0.7576052   0.09975802  0.32681203  0.11079735
   0.          0.        ]]. Action = [[0.03596604 0.6256845 ]]. Reward = [-1.8095815]
Curr episode timestep = 46
Scene graph at timestep 46 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 47. State = [[-0.2967859   1.6593523  -0.7490213   0.07505668  0.33048537  0.07346676
   0.          0.        ]]. Action = [[-0.3957833  0.9177263]]. Reward = [0.4445746]
Curr episode timestep = 47
Scene graph at timestep 47 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 48. State = [[-0.30437985  1.6609867  -0.7640383   0.0715725   0.33533084  0.0969096
   0.          0.        ]]. Action = [[ 0.716779  -0.5382301]]. Reward = [-2.5154107]
Curr episode timestep = 48
Scene graph at timestep 48 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 49. State = [[-0.3122467   1.6627824  -0.7895929   0.07913623  0.3383757   0.06089685
   0.          0.        ]]. Action = [[0.63384414 0.7423909 ]]. Reward = [-3.5084398]
Curr episode timestep = 49
Scene graph at timestep 49 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 50. State = [[-0.32017955  1.6648923  -0.79470694  0.09343266  0.33986443  0.02977484
   0.          0.        ]]. Action = [[0.35403478 0.80097306]]. Reward = [-1.3945715]
Curr episode timestep = 50
Scene graph at timestep 50 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 51. State = [[-0.32811242  1.6664021  -0.7947069   0.06676582  0.34135318  0.02977482
   0.          0.        ]]. Action = [[-0.95460314  0.13271987]]. Reward = [-0.18121514]
Curr episode timestep = 51
Scene graph at timestep 51 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 52. State = [[-0.33609653  1.6672832  -0.80119514  0.03849742  0.34426895  0.05831552
   0.          0.        ]]. Action = [[-0.4269026 -0.8272656]]. Reward = [-1.0201086]
Curr episode timestep = 52
Scene graph at timestep 52 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 53. State = [[-0.3440807   1.6675644  -0.80119467  0.01183009  0.34718472  0.05831545
   0.          0.        ]]. Action = [[-0.77404714 -0.23371887]]. Reward = [-0.39494237]
Curr episode timestep = 53
Scene graph at timestep 53 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 54. State = [[-0.35224676  1.6677916  -0.8210025   0.00902911  0.35180724  0.09245054
   0.          0.        ]]. Action = [[ 0.31832933 -0.823202  ]]. Reward = [-2.8508332]
Curr episode timestep = 54
Scene graph at timestep 54 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 55. State = [[-0.3604533   1.667395   -0.8261283  -0.01897755  0.35756794  0.11521323
   0.          0.        ]]. Action = [[-0.5941741 -0.7027859]]. Reward = [-1.2592804]
Curr episode timestep = 55
Scene graph at timestep 55 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 56. State = [[-0.36871114  1.6663702  -0.8325947  -0.04725653  0.3647548   0.14373717
   0.          0.        ]]. Action = [[-0.27570397 -0.59020865]]. Reward = [-1.5715678]
Curr episode timestep = 56
Scene graph at timestep 56 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 57. State = [[-0.37692675  1.664764   -0.8272827  -0.07285293  0.37080362  0.12097672
   0.          0.        ]]. Action = [[-0.7310774   0.63501835]]. Reward = [-0.30161506]
Curr episode timestep = 57
Scene graph at timestep 57 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 58. State = [[-0.38533694  1.6629959  -0.8451411  -0.07966561  0.3751753   0.08743428
   0.          0.        ]]. Action = [[0.64906096 0.6875495 ]]. Reward = [-2.5609112]
Curr episode timestep = 58
Scene graph at timestep 58 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 59. State = [[-0.39371124  1.6606566  -0.84053296 -0.10478707  0.37847418  0.06597756
   0.          0.        ]]. Action = [[-0.19898784  0.6749482 ]]. Reward = [-0.12868495]
Curr episode timestep = 59
Scene graph at timestep 59 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 60. State = [[-0.402281    1.6585405  -0.8601699  -0.09489463  0.38187042  0.06792441
   0.          0.        ]]. Action = [[ 0.49387717 -0.25341547]]. Reward = [-2.392667]
Curr episode timestep = 60
Scene graph at timestep 60 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 61. State = [[-0.41085076  1.6558247  -0.8601693  -0.1215622   0.38526666  0.06792433
   0.          0.        ]]. Action = [[-0.8922652  -0.13563138]]. Reward = [-0.612872]
Curr episode timestep = 61
Scene graph at timestep 61 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 62. State = [[-0.41959915  1.6530095  -0.8778474  -0.12593724  0.38847733  0.06421325
   0.          0.        ]]. Action = [[ 0.22198367 -0.3994754 ]]. Reward = [-2.2561133]
Curr episode timestep = 62
Scene graph at timestep 62 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 63. State = [[-0.42848483  1.6504357  -0.8919498  -0.1153172   0.39208227  0.07209894
   0.          0.        ]]. Action = [[0.39780712 0.11004281]]. Reward = [-1.7956665]
Curr episode timestep = 63
Scene graph at timestep 63 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 64. State = [[-0.4373706   1.6472621  -0.891949   -0.14198487  0.39568722  0.07209881
   0.          0.        ]]. Action = [[-0.53886217 -0.11918247]]. Reward = [-0.65978676]
Curr episode timestep = 64
Scene graph at timestep 64 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 65. State = [[-0.4462564   1.6434886  -0.8919484  -0.1686525   0.39929217  0.07209878
   0.          0.        ]]. Action = [[-0.39904165 -0.0020411 ]]. Reward = [-0.6838739]
Curr episode timestep = 65
Scene graph at timestep 65 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 66. State = [[-0.45514226  1.6391153  -0.89194775 -0.19532016  0.40289712  0.07209869
   0.          0.        ]]. Action = [[-0.9294127  -0.44491255]]. Reward = [-0.7070819]
Curr episode timestep = 66
Scene graph at timestep 66 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 67. State = [[-0.46409267  1.6341131  -0.9000324  -0.22375055  0.4082524   0.10710529
   0.          0.        ]]. Action = [[-0.5351183  -0.92563033]]. Reward = [-1.758178]
Curr episode timestep = 67
Scene graph at timestep 67 is [True, True, True, True, True, True, True, False, True, False]
State prediction error at timestep 67 is 0.012
Human Feedback received at timestep 67 of -1
Current timestep = 68. State = [[-0.4732862   1.6290208  -0.92394435 -0.2276531   0.41320005  0.09895347
   0.          0.        ]]. Action = [[ 0.3992796  -0.34423006]]. Reward = [-2.8839846]
Curr episode timestep = 68
Scene graph at timestep 68 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 69. State = [[-0.4826867   1.6237576  -0.9443205  -0.23517768  0.4178013   0.09202457
   0.          0.        ]]. Action = [[0.4644872  0.13070083]]. Reward = [-2.5986526]
Curr episode timestep = 69
Scene graph at timestep 69 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 70. State = [[-0.49237102  1.6186197  -0.9724189  -0.2295342   0.42211002  0.08617467
   0.          0.        ]]. Action = [[ 0.7848352  -0.48417634]]. Reward = [-3.08318]
Curr episode timestep = 70
Scene graph at timestep 70 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 71. State = [[-0.50205547  1.6128821  -0.972418   -0.25620228  0.42641878  0.08617456
   0.          0.        ]]. Action = [[-0.8017256  -0.29621756]]. Reward = [-0.8133943]
Curr episode timestep = 71
Scene graph at timestep 71 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 72. State = [[-0.51173997  1.6065446  -0.97241706 -0.28287032  0.43072754  0.08617445
   0.          0.        ]]. Action = [[-0.6050756  -0.18726987]]. Reward = [-0.8294605]
Curr episode timestep = 72
Scene graph at timestep 72 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 73. State = [[-0.52151     1.6000333  -0.9811424  -0.29067314  0.43522462  0.08994164
   0.          0.        ]]. Action = [[ 0.39480472 -0.1917556 ]]. Reward = [-1.395818]
Curr episode timestep = 73
Scene graph at timestep 73 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 74. State = [[-0.5313481   1.5928797  -0.9897257  -0.31978184  0.44166914  0.12889008
   0.          0.        ]]. Action = [[-0.27696198 -0.8553481 ]]. Reward = [-1.9798487]
Curr episode timestep = 74
Scene graph at timestep 74 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 75. State = [[-0.5415542   1.5862014  -1.0263952  -0.29864788  0.4479915   0.1264473
   0.          0.        ]]. Action = [[ 0.62727284 -0.21738207]]. Reward = [-3.455585]
Curr episode timestep = 75
Scene graph at timestep 75 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 76. State = [[-0.55196637  1.5796063  -1.0470327  -0.2950018   0.4543665   0.12750082
   0.          0.        ]]. Action = [[ 0.7572018 -0.3175453]]. Reward = [-2.501301]
Curr episode timestep = 76
Scene graph at timestep 76 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 77. State = [[-0.5623787   1.5724113  -1.0470306  -0.32167152  0.46074152  0.12750047
   0.          0.        ]]. Action = [[-0.6203332  -0.22935307]]. Reward = [-1.059354]
Curr episode timestep = 77
Scene graph at timestep 77 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 78. State = [[-0.57301176  1.5658517  -1.0675464  -0.29294732  0.46542457  0.09366111
   0.          0.        ]]. Action = [[0.81231654 0.88252926]]. Reward = [-1.6797476]
Curr episode timestep = 78
Scene graph at timestep 78 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 79. State = [[-0.5836448   1.5586925  -1.0675452  -0.31961563  0.47010761  0.09366103
   0.          0.        ]]. Action = [[-0.20027429  0.174101  ]]. Reward = [-0.9013353]
Curr episode timestep = 79
Scene graph at timestep 79 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 80. State = [[-0.5944742   1.5517948  -1.088517   -0.30846608  0.47628784  0.12360438
   0.          0.        ]]. Action = [[ 0.80149674 -0.5492166 ]]. Reward = [-2.3448615]
Curr episode timestep = 80
Scene graph at timestep 80 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 81. State = [[-0.60524356  1.544351   -1.0807998  -0.33217415  0.48058176  0.08587883
   0.          0.        ]]. Action = [[-0.87619525  0.91091835]]. Reward = [-0.08309212]
Curr episode timestep = 81
Scene graph at timestep 81 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 82. State = [[-0.6162811   1.5370182  -1.1075255  -0.32722095  0.48478928  0.08415022
   0.          0.        ]]. Action = [[0.26889384 0.48166454]]. Reward = [-2.7521532]
Curr episode timestep = 82
Scene graph at timestep 82 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 83. State = [[-0.62764424  1.5297911  -1.1397992  -0.32242954  0.48867768  0.07776795
   0.          0.        ]]. Action = [[ 0.46029615 -0.36663163]]. Reward = [-3.3325956]
Curr episode timestep = 83
Scene graph at timestep 83 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 84. State = [[-0.63894093  1.522022   -1.1312845  -0.3458726   0.49048853  0.03621753
   0.          0.        ]]. Action = [[-0.5109658  0.8901615]]. Reward = [0.23179078]
Curr episode timestep = 84
Scene graph at timestep 84 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 85. State = [[-0.65023756  1.5136528  -1.1312842  -0.37253955  0.4922994   0.03621768
   0.          0.        ]]. Action = [[-0.9493812  -0.19270277]]. Reward = [-0.65928996]
Curr episode timestep = 85
Scene graph at timestep 85 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 86. State = [[-0.66153425  1.5046837  -1.1312841  -0.3992065   0.4941103   0.03621712
   0.          0.        ]]. Action = [[-0.6186522  0.4958551]]. Reward = [-0.669616]
Curr episode timestep = 86
Scene graph at timestep 86 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 87. State = [[-0.67283094  1.4951147  -1.131284   -0.4258734   0.49592116  0.03621768
   0.          0.        ]]. Action = [[-0.8050232   0.24884593]]. Reward = [-0.67944103]
Curr episode timestep = 87
Scene graph at timestep 87 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 88. State = [[-0.6842182   1.4854255  -1.139297   -0.43082896  0.49655876  0.01275185
   0.          0.        ]]. Action = [[0.21646285 0.5807506 ]]. Reward = [-0.7783451]
Curr episode timestep = 88
Scene graph at timestep 88 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 89. State = [[-0.6956272   1.4755524  -1.1399473  -0.43845975  0.49549407 -0.02129381
   0.          0.        ]]. Action = [[0.24245048 0.8286866 ]]. Reward = [-0.02445325]
Curr episode timestep = 89
Scene graph at timestep 89 is [True, True, True, True, True, True, True, True, False, False]
State prediction error at timestep 89 is 0.012
Human Feedback received at timestep 89 of -1
Current timestep = 90. State = [[-0.70726436  1.4658263  -1.1629138  -0.43198717  0.4945954  -0.01797295
   0.          0.        ]]. Action = [[ 0.27433395 -0.2885903 ]]. Reward = [-1.6437978]
Curr episode timestep = 90
Scene graph at timestep 90 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 91. State = [[-0.7189511   1.455449   -1.169327   -0.46144688  0.4953284   0.01465951
   0.          0.        ]]. Action = [[-0.32549715 -0.9854029 ]]. Reward = [-1.3357329]
Curr episode timestep = 91
Scene graph at timestep 91 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 92. State = [[-0.73069084  1.4444261  -1.1760972  -0.490677    0.49771464  0.04772478
   0.          0.        ]]. Action = [[-0.5615394  -0.65199935]]. Reward = [-1.5238286]
Curr episode timestep = 92
Scene graph at timestep 92 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 93. State = [[-0.7425511   1.433322   -1.1866447  -0.4937391   0.4984046   0.01379903
   0.          0.        ]]. Action = [[0.3730836  0.80578864]]. Reward = [-0.9425831]
Curr episode timestep = 93
Scene graph at timestep 93 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 94. State = [[-0.7544114   1.4216179  -1.1866447  -0.5204058   0.49909458  0.0137994
   0.          0.        ]]. Action = [[-0.34018588 -0.43593824]]. Reward = [-0.63100857]
Curr episode timestep = 94
Scene graph at timestep 94 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 95. State = [[-0.7662152   1.4093584  -1.1794622  -0.5445317   0.49806222 -0.02064724
   0.          0.        ]]. Action = [[-0.01998383  0.79299426]]. Reward = [0.26569048]
Curr episode timestep = 95
Scene graph at timestep 95 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 96. State = [[-0.7780644   1.3964672  -1.1851977  -0.57304204  0.4983715   0.00618562
   0.          0.        ]]. Action = [[-0.35126126 -0.5296636 ]]. Reward = [-1.2255329]
Curr episode timestep = 96
Scene graph at timestep 96 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 97. State = [[-0.79020566  1.3840396  -1.2147338  -0.5525592   0.4990618   0.01380576
   0.          0.        ]]. Action = [[ 0.58476007 -0.03954494]]. Reward = [-1.6249684]
Curr episode timestep = 97
Scene graph at timestep 97 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 98. State = [[-0.8023468   1.3710121  -1.2147337  -0.5792259   0.49975204  0.01380497
   0.          0.        ]]. Action = [[-0.11214316  0.23351645]]. Reward = [-0.6748008]
Curr episode timestep = 98
Scene graph at timestep 98 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 99. State = [[-0.8144428   1.357416   -1.209028   -0.60406417  0.49910858 -0.01286901
   0.          0.        ]]. Action = [[-0.00656015  0.81975937]]. Reward = [0.01583757]
Curr episode timestep = 99
Scene graph at timestep 99 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 100. State = [[-0.82683647  1.3436552  -1.2382861  -0.61119694  0.49789864 -0.02419862
   0.          0.        ]]. Action = [[0.50500035 0.38534594]]. Reward = [-2.510094]
Curr episode timestep = 100
Scene graph at timestep 100 is [True, True, True, True, True, True, True, False, False, False]
State prediction error at timestep 100 is 0.012
Human Feedback received at timestep 100 of -1
Current timestep = 101. State = [[-0.8395907   1.3305825  -1.2728764  -0.58008903  0.49503326 -0.05730758
   0.          0.        ]]. Action = [[0.86033666 0.80675757]]. Reward = [-1.3734146]
Curr episode timestep = 101
Scene graph at timestep 101 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 102. State = [[-0.85234505  1.3169098  -1.2728759  -0.6067563   0.4921679  -0.05730734
   0.          0.        ]]. Action = [[-0.23869735  0.32920825]]. Reward = [-0.3749129]
Curr episode timestep = 102
Scene graph at timestep 102 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 103. State = [[-0.8652604   1.3032377  -1.2905743  -0.6073032   0.49109325 -0.02149287
   0.          0.        ]]. Action = [[ 0.47529793 -0.7750701 ]]. Reward = [-1.3246621]
Curr episode timestep = 103
Scene graph at timestep 103 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 104. State = [[-0.8784014   1.2897941  -1.3133936  -0.5972421   0.4903024  -0.01581648
   0.          0.        ]]. Action = [[0.51708055 0.04616284]]. Reward = [-1.4148073]
Curr episode timestep = 104
Scene graph at timestep 104 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 105. State = [[-0.8916487   1.2763143  -1.3257068  -0.59945375  0.49139908  0.0219331
   0.          0.        ]]. Action = [[ 0.56677675 -0.7854153 ]]. Reward = [-1.2235777]
Curr episode timestep = 105
Scene graph at timestep 105 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 106. State = [[-0.9051363   1.2629275  -1.3479543  -0.59468055  0.49049827 -0.01801598
   0.          0.        ]]. Action = [[0.00342071 0.96612024]]. Reward = [-1.6124029]
Curr episode timestep = 106
Scene graph at timestep 106 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 107. State = [[-0.9189986   1.2498816  -1.3852794  -0.57948023  0.48943472 -0.02127135
   0.          0.        ]]. Action = [[ 0.42417502 -0.38219976]]. Reward = [-2.695265]
Curr episode timestep = 107
Scene graph at timestep 107 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 108. State = [[-0.933212    1.2368861  -1.419949   -0.5770894   0.48788008 -0.03109292
   0.          0.        ]]. Action = [[ 0.6216202  -0.06040049]]. Reward = [-3.0086446]
Curr episode timestep = 108
Scene graph at timestep 108 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 109. State = [[-0.94742537  1.2232904  -1.4199489  -0.6037562   0.48632544 -0.03109283
   0.          0.        ]]. Action = [[-0.30394173  0.10425365]]. Reward = [-0.6514056]
Curr episode timestep = 109
Scene graph at timestep 109 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 110. State = [[-0.961566    1.2091427  -1.4107674  -0.62763697  0.4826537  -0.07343466
   0.          0.        ]]. Action = [[-0.2960744   0.82368946]]. Reward = [0.47173205]
Curr episode timestep = 110
Scene graph at timestep 110 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 111. State = [[-0.9756595   1.1944333  -1.4047524  -0.65214646  0.47753668 -0.10234082
   0.          0.        ]]. Action = [[-0.3209778   0.68856263]]. Reward = [0.28529608]
Curr episode timestep = 111
Scene graph at timestep 111 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 112. State = [[-0.9899495   1.1796854  -1.4260652  -0.6544561   0.47426745 -0.06538425
   0.          0.        ]]. Action = [[ 0.0335902  -0.89200896]]. Reward = [-1.6621046]
Curr episode timestep = 112
Scene graph at timestep 112 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 113. State = [[-0.00354633  1.4113905  -0.35921702  0.02089847  0.00411606  0.081368
   0.          0.        ]]. Action = [[ 0.73219883 -0.77928245]]. Reward = [-100.]
Curr episode timestep = 113
Scene graph at timestep 113 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 114. State = [[-0.00709305  1.4112833  -0.35873118 -0.00477798  0.0081368   0.08042271
   0.          0.        ]]. Action = [[-0.7357452   0.09901953]]. Reward = [-0.28653923]
Curr episode timestep = 0
Scene graph at timestep 114 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 115. State = [[-0.0106842   1.4116228  -0.36119822  0.01507406  0.01018149  0.0408976
   0.          0.        ]]. Action = [[0.47267127 0.9283025 ]]. Reward = [-0.7643883]
Curr episode timestep = 1
Scene graph at timestep 115 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 116. State = [[-0.01448116  1.41254    -0.3832092   0.04073563  0.01366254  0.06962769
   0.          0.        ]]. Action = [[ 0.9645846  -0.86915636]]. Reward = [-3.149534]
Curr episode timestep = 2
Scene graph at timestep 116 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 117. State = [[-0.01827812  1.412857   -0.38321954  0.01406102  0.01714213  0.06959815
   0.          0.        ]]. Action = [[-0.11669517 -0.30724174]]. Reward = [-0.19499128]
Curr episode timestep = 3
Scene graph at timestep 117 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 118. State = [[-0.02200766  1.4125876  -0.37475604 -0.01200564  0.01891855  0.03553181
   0.          0.        ]]. Action = [[-0.04091865  0.9363177 ]]. Reward = [0.6688136]
Curr episode timestep = 4
Scene graph at timestep 118 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 119. State = [[-2.5669003e-02  1.4117272e+00 -3.6618483e-01 -3.8242839e-02
   1.8973073e-02  1.0905151e-03  0.0000000e+00  0.0000000e+00]]. Action = [[-0.6201239  0.7359884]]. Reward = [0.72951204]
Curr episode timestep = 5
Scene graph at timestep 119 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 120. State = [[-0.02923365  1.4110051  -0.35703444 -0.03209367  0.01953248  0.01118919
   0.          0.        ]]. Action = [[ 0.31955254 -0.35069895]]. Reward = [0.7816175]
Curr episode timestep = 6
Scene graph at timestep 120 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 121. State = [[-0.03279953  1.4110672  -0.35900375  0.00272697  0.02192077  0.04777021
   0.          0.        ]]. Action = [[ 0.8856002 -0.8345125]]. Reward = [-0.6147603]
Curr episode timestep = 7
Scene graph at timestep 121 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 122. State = [[-0.03642588  1.4108669  -0.36478743 -0.00893762  0.02404439  0.0424761
   0.          0.        ]]. Action = [[0.10681725 0.2334404 ]]. Reward = [-0.9555216]
Curr episode timestep = 8
Scene graph at timestep 122 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 123. State = [[-0.04009809  1.4100692  -0.37051824 -0.03550621  0.02731468  0.06541175
   0.          0.        ]]. Action = [[-0.8334087 -0.6257614]]. Reward = [-1.0078927]
Curr episode timestep = 9
Scene graph at timestep 123 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 124. State = [[-0.04375191  1.4093555  -0.36698633 -0.0317486   0.02889057  0.03152116
   0.          0.        ]]. Action = [[0.40743804 0.83034205]]. Reward = [0.05271143]
Curr episode timestep = 10
Scene graph at timestep 124 is [False, True, True, True, True, True, True, False, True, False]
State prediction error at timestep 124 is 0.012
Human Feedback received at timestep 124 of -1
Current timestep = 125. State = [[-0.04736099  1.4085702  -0.36122626 -0.03491108  0.02920967  0.0063825
   0.          0.        ]]. Action = [[0.61202574 0.63996446]]. Reward = [0.31869265]
Curr episode timestep = 11
Scene graph at timestep 125 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 126. State = [[-0.05099363  1.4080216  -0.36356005 -0.02438588  0.02949374  0.00568206
   0.          0.        ]]. Action = [[ 0.5592141  -0.37508678]]. Reward = [-0.3669051]
Curr episode timestep = 12
Scene graph at timestep 126 is [False, True, True, True, True, True, True, True, False, True]
State prediction error at timestep 126 is 0.012
Human Feedback received at timestep 126 of -1
Current timestep = 127. State = [[-0.05464621  1.4075861  -0.36397123 -0.01932795  0.02822252 -0.02542689
   0.          0.        ]]. Action = [[0.14816809 0.7502487 ]]. Reward = [-0.04849843]
Curr episode timestep = 13
Scene graph at timestep 127 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 128. State = [[-0.05829878  1.4065505  -0.36396694 -0.04599893  0.02695225 -0.02540773
   0.          0.        ]]. Action = [[-0.49213707 -0.07740319]]. Reward = [-0.02195831]
Curr episode timestep = 14
Scene graph at timestep 128 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 129. State = [[-0.06186781  1.4054927  -0.35606167 -0.04700127  0.02612215 -0.01660373
   0.          0.        ]]. Action = [[ 0.14004207 -0.4408338 ]]. Reward = [0.7736274]
Curr episode timestep = 15
Scene graph at timestep 129 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 130. State = [[-0.06543694  1.4038347  -0.35605922 -0.07367446  0.0252918  -0.01660859
   0.          0.        ]]. Action = [[-0.22263712 -0.26819712]]. Reward = [-0.21260843]
Curr episode timestep = 16
Scene graph at timestep 130 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 131. State = [[-0.06903591  1.4023848  -0.35898024 -0.06442656  0.02438481 -0.0181417
   0.          0.        ]]. Action = [[0.27390683 0.11106443]]. Reward = [-0.08420276]
Curr episode timestep = 17
Scene graph at timestep 131 is [False, True, True, True, True, True, True, False, False, False]
State prediction error at timestep 131 is 0.012
Human Feedback received at timestep 131 of -1
Current timestep = 132. State = [[-0.07263489  1.4003347  -0.35897732 -0.09110168  0.02347804 -0.01813714
   0.          0.        ]]. Action = [[-0.9144245  -0.22345603]]. Reward = [-0.28686047]
Curr episode timestep = 18
Scene graph at timestep 132 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 133. State = [[-0.07631616  1.3984846  -0.36688322 -0.08220651  0.02224522 -0.02465828
   0.          0.        ]]. Action = [[0.36930382 0.11862564]]. Reward = [-0.4792729]
Curr episode timestep = 19
Scene graph at timestep 133 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 134. State = [[-0.07993879  1.3960314  -0.35953015 -0.10899367  0.01954195 -0.05407033
   0.          0.        ]]. Action = [[-0.21972561  0.9049363 ]]. Reward = [0.4971127]
Curr episode timestep = 20
Scene graph at timestep 134 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 135. State = [[-0.08357954  1.3941112  -0.3598635  -0.08529694  0.01537607 -0.08332516
   0.          0.        ]]. Action = [[0.446882  0.6812904]]. Reward = [0.9349127]
Curr episode timestep = 21
Scene graph at timestep 135 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 136. State = [[-0.0872777   1.3915861  -0.36705607 -0.11219692  0.01265567 -0.05441273
   0.          0.        ]]. Action = [[-0.3610748  -0.72684073]]. Reward = [-0.9190293]
Curr episode timestep = 22
Scene graph at timestep 136 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 137. State = [[-0.09097576  1.3884614  -0.3670493  -0.1388621   0.00993471 -0.05442408
   0.          0.        ]]. Action = [[-0.32438552  0.14874327]]. Reward = [-0.30149832]
Curr episode timestep = 23
Scene graph at timestep 137 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 138. State = [[-0.09483452  1.3853972  -0.38416344 -0.1361747   0.00823456 -0.03400297
   0.          0.        ]]. Action = [[ 0.40201688 -0.62179404]]. Reward = [-1.2936097]
Curr episode timestep = 24
Scene graph at timestep 138 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 139. State = [[-0.0988244   1.3825498  -0.3989131  -0.12655221  0.00816191 -0.00145297
   0.          0.        ]]. Action = [[ 0.83635235 -0.87191665]]. Reward = [-1.13028]
Curr episode timestep = 25
Scene graph at timestep 139 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 140. State = [[-0.10294513  1.3798842  -0.41140285 -0.11846773  0.00750345 -0.01316937
   0.          0.        ]]. Action = [[0.43106413 0.187325  ]]. Reward = [-0.874431]
Curr episode timestep = 26
Scene graph at timestep 140 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 141. State = [[-0.10699139  1.3766235  -0.40205526 -0.14490776  0.00497237 -0.05062152
   0.          0.        ]]. Action = [[-0.8025267  0.8343184]]. Reward = [0.5973148]
Curr episode timestep = 27
Scene graph at timestep 141 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 142. State = [[-0.11103763  1.372763   -0.40205532 -0.17157498  0.00244129 -0.05062158
   0.          0.        ]]. Action = [[-0.11177462  0.41162813]]. Reward = [-0.37028638]
Curr episode timestep = 28
Scene graph at timestep 142 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 143. State = [[-0.11517038  1.3682926  -0.4129215  -0.19868973  0.00208676 -0.00709069
   0.          0.        ]]. Action = [[-0.48020822 -0.9415815 ]]. Reward = [-1.6915807]
Curr episode timestep = 29
Scene graph at timestep 143 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 144. State = [[-1.19365975e-01  1.36417627e+00 -4.17494148e-01 -1.82945579e-01
   5.15325773e-05 -4.07043584e-02  0.00000000e+00  0.00000000e+00]]. Action = [[0.84597945 0.70676327]]. Reward = [0.5215853]
Curr episode timestep = 30
Scene graph at timestep 144 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 145. State = [[-1.2361212e-01  1.3594581e+00 -4.2385358e-01 -2.0969157e-01
  -7.1010465e-04 -1.5232576e-02  0.0000000e+00  0.0000000e+00]]. Action = [[-0.91321415 -0.6053252 ]]. Reward = [-1.3586906]
Curr episode timestep = 31
Scene graph at timestep 145 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 146. State = [[-0.12779942  1.354145   -0.41644987 -0.23613499 -0.00295437 -0.04488539
   0.          0.        ]]. Action = [[-0.7890564  0.8047378]]. Reward = [-0.3432432]
Curr episode timestep = 32
Scene graph at timestep 146 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 147. State = [[-0.13212872  1.3487835  -0.43223843 -0.23828913 -0.00364779 -0.01386844
   0.          0.        ]]. Action = [[ 0.587875 -0.840255]]. Reward = [-1.3237065]
Curr episode timestep = 33
Scene graph at timestep 147 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 148. State = [[-0.1363471   1.3432274  -0.42165256 -0.24693745 -0.00383236 -0.00369111
   0.          0.        ]]. Action = [[0.2997259  0.14871311]]. Reward = [0.7906399]
Curr episode timestep = 34
Scene graph at timestep 148 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 149. State = [[-0.14074306  1.3375791  -0.44095272 -0.251033   -0.00249835  0.02668028
   0.          0.        ]]. Action = [[ 0.31219316 -0.8241525 ]]. Reward = [-1.4477354]
Curr episode timestep = 35
Scene graph at timestep 149 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 150. State = [[-0.14505748  1.3328116  -0.43121767 -0.21189258 -0.00271807 -0.00439443
   0.          0.        ]]. Action = [[0.89938164 0.7983017 ]]. Reward = [2.7909653]
Curr episode timestep = 36
Scene graph at timestep 150 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 151. State = [[-0.14947033  1.3282747  -0.4405949  -0.2016367  -0.00340055 -0.01364972
   0.          0.        ]]. Action = [[ 0.37686408 -0.16116184]]. Reward = [-0.2800646]
Curr episode timestep = 37
Scene graph at timestep 151 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 152. State = [[-0.15394744  1.3231393  -0.4486421  -0.22823969 -0.00247137  0.01858356
   0.          0.        ]]. Action = [[-0.5487659  -0.80891603]]. Reward = [-1.3539926]
Curr episode timestep = 38
Scene graph at timestep 152 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 153. State = [[-0.1583641   1.3173933  -0.4410781  -0.25537482 -0.00305747 -0.01172183
   0.          0.        ]]. Action = [[-0.01070029  0.98431075]]. Reward = [-0.20048313]
Curr episode timestep = 39
Scene graph at timestep 153 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 154. State = [[-0.16278076  1.3110474  -0.44107804 -0.28204152 -0.00364358 -0.01172194
   0.          0.        ]]. Action = [[-0.5086728  0.4954921]]. Reward = [-0.86930877]
Curr episode timestep = 40
Scene graph at timestep 154 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 155. State = [[-0.16726771  1.3040986  -0.44989032 -0.30883723 -0.00246508  0.02357027
   0.          0.        ]]. Action = [[-0.47030973 -0.8238375 ]]. Reward = [-1.488715]
Curr episode timestep = 41
Scene graph at timestep 155 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 156. State = [[-1.7175464e-01  1.2965498e+00 -4.4989032e-01 -3.3550400e-01
  -1.2865714e-03  2.3570143e-02  0.0000000e+00  0.0000000e+00]]. Action = [[-0.20634091  0.4664309 ]]. Reward = [-0.7438982]
Curr episode timestep = 42
Scene graph at timestep 156 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 157. State = [[-1.7627087e-01  1.2892094e+00 -4.5268422e-01 -3.2623616e-01
  -2.4735133e-04  2.0784676e-02  0.0000000e+00  0.0000000e+00]]. Action = [[0.15506518 0.4005394 ]]. Reward = [0.92055553]
Curr episode timestep = 43
Scene graph at timestep 157 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 158. State = [[-1.8078718e-01  1.2812691e+00 -4.5268422e-01 -3.5290292e-01
   7.9187611e-04  2.0784616e-02  0.0000000e+00  0.0000000e+00]]. Action = [[-0.24514496  0.13403678]]. Reward = [-0.93000174]
Curr episode timestep = 44
Scene graph at timestep 158 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 159. State = [[-1.8523017e-01  1.2727306e+00 -4.4348735e-01 -3.7948611e-01
  -1.0727555e-05 -1.6052205e-02  0.0000000e+00  0.0000000e+00]]. Action = [[-0.11139649  0.95702326]]. Reward = [-0.13823023]
Curr episode timestep = 45
Scene graph at timestep 159 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 160. State = [[-1.8967314e-01  1.2635922e+00 -4.4348735e-01 -4.0615284e-01
  -8.1333867e-04 -1.6052194e-02  0.0000000e+00  0.0000000e+00]]. Action = [[-0.15423    -0.09584635]]. Reward = [-1.0091028]
Curr episode timestep = 46
Scene graph at timestep 160 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 161. State = [[-0.19408235  1.2542593  -0.44026113 -0.41479814 -0.00146059 -0.01294488
   0.          0.        ]]. Action = [[0.03372133 0.41867542]]. Reward = [0.2844047]
Curr episode timestep = 47
Scene graph at timestep 161 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 162. State = [[-0.19860134  1.2448512  -0.45072493 -0.41813633 -0.00261838 -0.02315575
   0.          0.        ]]. Action = [[0.33839226 0.10145533]]. Reward = [-0.4496317]
Curr episode timestep = 48
Scene graph at timestep 162 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 163. State = [[-0.20312032  1.2348433  -0.450725   -0.44480312 -0.00377615 -0.02315575
   0.          0.        ]]. Action = [[-0.13354361 -0.16907394]]. Reward = [-1.0439411]
Curr episode timestep = 49
Scene graph at timestep 163 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 164. State = [[-0.2076393   1.2242353  -0.45072502 -0.4714699  -0.00493394 -0.02315583
   0.          0.        ]]. Action = [[-0.8766354   0.46923745]]. Reward = [-1.0446783]
Curr episode timestep = 50
Scene graph at timestep 164 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 165. State = [[-0.21215829  1.2130274  -0.45072508 -0.49813667 -0.00609175 -0.02315597
   0.          0.        ]]. Action = [[-0.5374657  -0.46034598]]. Reward = [-1.0407995]
Curr episode timestep = 51
Scene graph at timestep 165 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 166. State = [[-0.21667819  1.2014889  -0.4523758  -0.51281893 -0.00571125  0.00761004
   0.          0.        ]]. Action = [[ 0.03411365 -0.7579496 ]]. Reward = [-0.28768167]
Curr episode timestep = 52
Scene graph at timestep 166 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 167. State = [[-0.22115521  1.1893421  -0.44699273 -0.53986096 -0.00640957 -0.01396647
   0.          0.        ]]. Action = [[-0.5407963  0.6765902]]. Reward = [-0.6821057]
Curr episode timestep = 53
Scene graph at timestep 167 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 168. State = [[-0.22583218  1.1777337  -0.46861157 -0.51592386 -0.0055073   0.01804527
   0.          0.        ]]. Action = [[ 0.9547837 -0.9272445]]. Reward = [1.2149805]
Curr episode timestep = 54
Scene graph at timestep 168 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 169. State = [[-0.23053947  1.1666142  -0.47148257 -0.4941984  -0.00476418  0.01486244
   0.          0.        ]]. Action = [[ 0.9282944  -0.21409512]]. Reward = [2.1812403]
Curr episode timestep = 55
Scene graph at timestep 169 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 170. State = [[-0.23521033  1.1557766  -0.4697194  -0.4816658  -0.00216503  0.0519831
   0.          0.        ]]. Action = [[ 0.6512897  -0.85061616]]. Reward = [1.9819015]
Curr episode timestep = 56
Scene graph at timestep 170 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 171. State = [[-2.3983368e-01  1.1443368e+00 -4.6376047e-01 -5.0843388e-01
  -7.5932918e-04  2.8113913e-02  0.0000000e+00  0.0000000e+00]]. Action = [[-0.91236323  0.5487224 ]]. Reward = [-0.3877373]
Curr episode timestep = 57
Scene graph at timestep 171 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 172. State = [[-0.24449548  1.1333332  -0.46885768 -0.4890493   0.00188898  0.05296607
   0.          0.        ]]. Action = [[ 0.7021816  -0.61313653]]. Reward = [1.6604125]
Curr episode timestep = 58
Scene graph at timestep 172 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 173. State = [[-0.24920721  1.1217312  -0.4751286  -0.5156588   0.00579309  0.07808222
   0.          0.        ]]. Action = [[-0.49628127 -0.648087  ]]. Reward = [-1.7458138]
Curr episode timestep = 59
Scene graph at timestep 173 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 174. State = [[-0.2539652   1.1095264  -0.48092738 -0.54245365  0.01085876  0.10131337
   0.          0.        ]]. Action = [[-0.2847206 -0.649324 ]]. Reward = [-1.8169339]
Curr episode timestep = 60
Scene graph at timestep 174 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 175. State = [[-0.2586628   1.0967159  -0.4733569  -0.56938857  0.01440951  0.0710151
   0.          0.        ]]. Action = [[-0.32329667  0.9581909 ]]. Reward = [-0.79297286]
Curr episode timestep = 61
Scene graph at timestep 175 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 176. State = [[-0.26333514  1.0838616  -0.47097522 -0.5713396   0.01810157  0.07384098
   0.          0.        ]]. Action = [[0.11368132 0.01122618]]. Reward = [0.6066581]
Curr episode timestep = 62
Scene graph at timestep 176 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 177. State = [[-0.2680161   1.0707649  -0.47181734 -0.582132    0.02177352  0.07343921
   0.          0.        ]]. Action = [[0.08264363 0.04288578]]. Reward = [-0.2590065]
Curr episode timestep = 63
Scene graph at timestep 177 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 178. State = [[-0.27273482  1.0570723  -0.47655195 -0.60863787  0.02639208  0.09237131
   0.          0.        ]]. Action = [[-0.9374519 -0.5307873]]. Reward = [-1.635182]
Curr episode timestep = 64
Scene graph at timestep 178 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 179. State = [[-0.2774536   1.0427799  -0.47655186 -0.6353063   0.03101064  0.09237117
   0.          0.        ]]. Action = [[-0.0314523  -0.35042506]]. Reward = [-1.3156831]
Curr episode timestep = 65
Scene graph at timestep 179 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 180. State = [[-0.282096    1.0284016  -0.46730256 -0.6391016   0.03403201  0.06042758
   0.          0.        ]]. Action = [[0.2227683  0.81300664]]. Reward = [1.0025339]
Curr episode timestep = 66
Scene graph at timestep 180 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 181. State = [[-0.28661603  1.0143837  -0.45573777 -0.6231073   0.03771968  0.07375349
   0.          0.        ]]. Action = [[ 0.71616864 -0.25875866]]. Reward = [2.5767007]
Curr episode timestep = 67
Scene graph at timestep 181 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 182. State = [[-0.2910816   0.99976605 -0.44890904 -0.6497399   0.04004029  0.04641218
   0.          0.        ]]. Action = [[-0.0498479  0.6439965]]. Reward = [-0.74446315]
Curr episode timestep = 68
Scene graph at timestep 182 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 183. State = [[-0.29547414  0.9845428  -0.43974423 -0.6766004   0.04052995  0.00979329
   0.          0.        ]]. Action = [[-0.7382101   0.96197534]]. Reward = [-0.46365875]
Curr episode timestep = 69
Scene graph at timestep 183 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 184. State = [[-0.29986662  0.96871966 -0.43974423 -0.70326704  0.04101963  0.00979349
   0.          0.        ]]. Action = [[-0.9247786  -0.11033404]]. Reward = [-0.9121181]
Curr episode timestep = 70
Scene graph at timestep 184 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 185. State = [[-0.30432543  0.9522915  -0.44806862 -0.7302058   0.04317921  0.04319174
   0.          0.        ]]. Action = [[-0.96623105 -0.8651601 ]]. Reward = [-1.5370653]
Curr episode timestep = 71
Scene graph at timestep 185 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 186. State = [[-0.30881682  0.9357705  -0.4512425  -0.7343204   0.04525558  0.04152744
   0.          0.        ]]. Action = [[ 0.7914945  -0.15467292]]. Reward = [0.4395047]
Curr episode timestep = 72
Scene graph at timestep 186 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 187. State = [[-0.3132585   0.91865647 -0.4449965  -0.76065177  0.04607664  0.01642105
   0.          0.        ]]. Action = [[-0.8029024   0.58835185]]. Reward = [-0.5556116]
Curr episode timestep = 73
Scene graph at timestep 187 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 188. State = [[-0.317623    0.90095174 -0.43530947 -0.78684443  0.04495149 -0.02250281
   0.          0.        ]]. Action = [[-0.10128152  0.88185775]]. Reward = [-0.18171984]
Curr episode timestep = 74
Scene graph at timestep 188 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 189. State = [[-0.3219418   0.88265175 -0.42957944 -0.8132608   0.0426757  -0.04551577
   0.          0.        ]]. Action = [[-0.5493451  0.5407587]]. Reward = [-0.26316592]
Curr episode timestep = 75
Scene graph at timestep 189 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 190. State = [[-0.3263339   0.863757   -0.43876156 -0.8397555   0.04223427 -0.00882857
   0.          0.        ]]. Action = [[-0.7552639 -0.9039987]]. Reward = [-1.1370227]
Curr episode timestep = 76
Scene graph at timestep 190 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 191. State = [[-0.33071262  0.84466124 -0.43574142 -0.8486437   0.04013392 -0.0420072
   0.          0.        ]]. Action = [[0.3294797  0.81166315]]. Reward = [0.96102655]
Curr episode timestep = 77
Scene graph at timestep 191 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 192. State = [[-0.33514333  0.82540256 -0.4407575  -0.8558845   0.03784688 -0.04574087
   0.          0.        ]]. Action = [[0.06664217 0.39483857]]. Reward = [0.82019514]
Curr episode timestep = 78
Scene graph at timestep 192 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 193. State = [[-0.339513    0.80555737 -0.4330871  -0.8819117   0.03401563 -0.07662499
   0.          0.        ]]. Action = [[-0.18892854  0.9469745 ]]. Reward = [0.04085699]
Curr episode timestep = 79
Scene graph at timestep 193 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 194. State = [[-0.34394017  0.78575695 -0.438636   -0.879932    0.0299859  -0.08059475
   0.          0.        ]]. Action = [[ 0.3328309  -0.34400928]]. Reward = [1.7790112]
Curr episode timestep = 80
Scene graph at timestep 194 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 195. State = [[-0.34836736  0.7653567  -0.43863598 -0.90660006  0.02595617 -0.08059464
   0.          0.        ]]. Action = [[-0.41816002  0.4974904 ]]. Reward = [-0.30835596]
Curr episode timestep = 81
Scene graph at timestep 195 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 196. State = [[-0.3528967   0.7453626  -0.45050487 -0.8885901   0.02356103 -0.04790282
   0.          0.        ]]. Action = [[ 0.34665322 -0.832875  ]]. Reward = [2.7223866]
Curr episode timestep = 82
Scene graph at timestep 196 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 197. State = [[-0.35742602  0.7247685  -0.45050484 -0.9152573   0.02116589 -0.0479028
   0.          0.        ]]. Action = [[-0.2373954  -0.09878922]]. Reward = [-0.48890495]
Curr episode timestep = 83
Scene graph at timestep 197 is [True, True, True, True, True, True, True, True, False, False]
State prediction error at timestep 197 is 0.012
Human Feedback received at timestep 197 of -1
Current timestep = 198. State = [[-0.3619553   0.70357436 -0.45050484 -0.9419244   0.01877076 -0.04790275
   0.          0.        ]]. Action = [[-0.1160174  -0.38372076]]. Reward = [-0.4706146]
Curr episode timestep = 84
Scene graph at timestep 198 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 199. State = [[-0.36648464  0.6817805  -0.45050484 -0.9685915   0.01637563 -0.04790274
   0.          0.        ]]. Action = [[-0.73442274  0.41408682]]. Reward = [-0.45428407]
Curr episode timestep = 85
Scene graph at timestep 199 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 200. State = [[-0.37105483  0.6601562  -0.45443955 -0.9610539   0.01383003 -0.05091213
   0.          0.        ]]. Action = [[0.5966406  0.37673151]]. Reward = [2.2053058]
Curr episode timestep = 86
Scene graph at timestep 200 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 201. State = [[-0.3756376   0.6385185  -0.45419636 -0.9616408   0.00980681 -0.08046457
   0.          0.        ]]. Action = [[0.17013061 0.7055259 ]]. Reward = [1.8102678]
Curr episode timestep = 87
Scene graph at timestep 201 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 202. State = [[-0.38016462  0.61741465 -0.44892922 -0.9379346   0.00607474 -0.07464122
   0.          0.        ]]. Action = [[ 0.6688831  -0.24122787]]. Reward = [4.064712]
Curr episode timestep = 88
Scene graph at timestep 202 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 203. State = [[-3.8477451e-01  5.9638190e-01 -4.5551246e-01 -9.3477410e-01
   6.7460118e-04 -1.0800283e-01  0.0000000e+00  0.0000000e+00]]. Action = [[0.6591567 0.6927781]]. Reward = [1.802182]
Curr episode timestep = 89
Scene graph at timestep 203 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 204. State = [[-0.38938433  0.57474965 -0.45551243 -0.9614432  -0.00472552 -0.1080026
   0.          0.        ]]. Action = [[-0.6171248  0.3821187]]. Reward = [-1.2586342]
Curr episode timestep = 90
Scene graph at timestep 204 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 205. State = [[-0.39399415  0.5525177  -0.45551243 -0.9881123  -0.01012564 -0.10800239
   0.          0.        ]]. Action = [[-0.22252661 -0.13914502]]. Reward = [-1.3936346]
Curr episode timestep = 91
Scene graph at timestep 205 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 206. State = [[-0.39854902  0.5296912  -0.44862142 -1.0145725  -0.01690492 -0.13558555
   0.          0.        ]]. Action = [[-0.9295716   0.57865405]]. Reward = [-1.2509592]
Curr episode timestep = 92
Scene graph at timestep 206 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 207. State = [[-0.40310392  0.50626534 -0.44862145 -1.041243   -0.02368417 -0.1355851
   0.          0.        ]]. Action = [[-0.7271669  -0.37264365]]. Reward = [-1.5485165]
Curr episode timestep = 93
Scene graph at timestep 207 is [True, True, True, True, True, True, True, False, True, False]
State prediction error at timestep 207 is 0.012
Human Feedback received at timestep 207 of -1
Current timestep = 208. State = [[-0.4075891   0.48224717 -0.43988094 -1.0676353  -0.03221083 -0.17053339
   0.          0.        ]]. Action = [[-0.9166961  0.9070463]]. Reward = [-1.4000862]
Curr episode timestep = 94
Scene graph at timestep 208 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 209. State = [[-0.4122614   0.458575   -0.46039852 -1.0522592  -0.03895224 -0.13482806
   0.          0.        ]]. Action = [[ 0.310956  -0.9387935]]. Reward = [1.1918182]
Curr episode timestep = 95
Scene graph at timestep 209 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 210. State = [[-0.41693363  0.43430337 -0.46039873 -1.07893    -0.04569371 -0.1348296
   0.          0.        ]]. Action = [[-0.03101671  0.3599769 ]]. Reward = [-1.662081]
Curr episode timestep = 96
Scene graph at timestep 210 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 211. State = [[-0.42148414  0.41067803 -0.45030528 -1.050167   -0.05038406 -0.09380689
   0.          0.        ]]. Action = [[ 0.8122816  -0.89529467]]. Reward = [3.6301064]
Curr episode timestep = 97
Scene graph at timestep 211 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 212. State = [[-0.42603463  0.38645303 -0.4503054  -1.0768355  -0.0550743  -0.09380485
   0.          0.        ]]. Action = [[-0.13966703  0.4664898 ]]. Reward = [-1.5967613]
Curr episode timestep = 98
Scene graph at timestep 212 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 213. State = [[-0.43053666  0.36217642 -0.4455893  -1.0791379  -0.05963383 -0.09119058
   0.          0.        ]]. Action = [[0.26501048 0.37100577]]. Reward = [0.58102494]
Curr episode timestep = 99
Scene graph at timestep 213 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 214. State = [[-0.43503866  0.3373001  -0.44558948 -1.1058061  -0.06419335 -0.09119043
   0.          0.        ]]. Action = [[-0.6459122 -0.2682541]]. Reward = [-1.7120992]
Curr episode timestep = 100
Scene graph at timestep 214 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 215. State = [[-0.43954557  0.3130093  -0.44582382 -1.0798072  -0.06901073 -0.09634747
   0.          0.        ]]. Action = [[ 0.6047145  -0.06345987]]. Reward = [2.7635634]
Curr episode timestep = 101
Scene graph at timestep 215 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 216. State = [[-0.4440518   0.2891177  -0.4455418  -1.0620921  -0.07403762 -0.10053776
   0.          0.        ]]. Action = [[ 0.63766813 -0.2523178 ]]. Reward = [1.8708379]
Curr episode timestep = 102
Scene graph at timestep 216 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 217. State = [[-0.4484951   0.2646136  -0.43764162 -1.0894165  -0.0806607  -0.13246183
   0.          0.        ]]. Action = [[-0.9189362   0.68510723]]. Reward = [-1.9965317]
Curr episode timestep = 103
Scene graph at timestep 217 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 218. State = [[-0.45287448  0.23950733 -0.42963067 -1.1163042  -0.08888955 -0.16457693
   0.          0.        ]]. Action = [[-0.4580772  0.6653061]]. Reward = [-2.2088745]
Curr episode timestep = 104
Scene graph at timestep 218 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 219. State = [[-0.4571208   0.21484846 -0.41666204 -1.0964452  -0.09679259 -0.15806076
   0.          0.        ]]. Action = [[0.8792429  0.44784784]]. Reward = [1.9673606]
Curr episode timestep = 105
Scene graph at timestep 219 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 220. State = [[-0.461311    0.19054177 -0.41279656 -1.0807122  -0.10296156 -0.12337937
   0.          0.        ]]. Action = [[ 0.8742969 -0.8092662]]. Reward = [1.283521]
Curr episode timestep = 106
Scene graph at timestep 220 is [True, True, True, False, False, True, True, True, False, True]
Current timestep = 221. State = [[-0.46555203  0.16565245 -0.4192043  -1.1065352  -0.10782117 -0.09719235
   0.          0.        ]]. Action = [[-0.07315838 -0.8318346 ]]. Reward = [-2.6555011]
Curr episode timestep = 107
Scene graph at timestep 221 is [True, True, True, False, False, True, True, True, False, True]
Current timestep = 222. State = [[-0.46962124  0.14140421 -0.4024065  -1.0780331  -0.11230285 -0.08963362
   0.          0.        ]]. Action = [[0.74974024 0.07456148]]. Reward = [2.9181738]
Curr episode timestep = 108
Scene graph at timestep 222 is [True, True, True, False, False, True, True, False, False, False]
Current timestep = 223. State = [[-0.4736271   0.11729366 -0.39426422 -1.0720668  -0.11858374 -0.12561789
   0.          0.        ]]. Action = [[0.07905567 0.9016378 ]]. Reward = [0.2766765]
Curr episode timestep = 109
Scene graph at timestep 223 is [True, True, True, False, False, True, True, True, False, True]
Current timestep = 224. State = [[-0.4775074   0.0934619  -0.3797452  -1.0598722  -0.12682584 -0.16484194
   0.          0.        ]]. Action = [[0.5955038  0.97052574]]. Reward = [0.68575054]
Curr episode timestep = 110
Scene graph at timestep 224 is [True, True, True, False, False, True, True, True, False, False]
State prediction error at timestep 224 is 0.012
Human Feedback received at timestep 224 of -1
Current timestep = 225. State = [[-0.48122406  0.07024649 -0.3840149  -1.0305077  -0.11626455  0.2089893
   1.          0.        ]]. Action = [[ 0.72582626 -0.39231324]]. Reward = [13.433179]
Curr episode timestep = 111
Scene graph at timestep 225 is [True, True, True, False, False, True, True, True, False, True]
Current timestep = 226. State = [[-0.48458466  0.04707435 -0.35615382 -1.0284324  -0.09631183  0.39906996
   1.          1.        ]]. Action = [[0.20131516 0.7889762 ]]. Reward = [12.874979]
Curr episode timestep = 112
Scene graph at timestep 226 is [True, True, True, False, False, True, True, True, False, True]
Current timestep = 227. State = [[-0.0063179   1.4115431  -0.6399437   0.02767497  0.00732759  0.1449568
   0.          0.        ]]. Action = [[0.6774399 0.9550383]]. Reward = [-100.]
Curr episode timestep = 113
Scene graph at timestep 227 is [True, True, True, False, False, True, True, True, False, False]
Current timestep = 228. State = [[-0.01269884  1.4115951  -0.64694196  0.00224419  0.0160668   0.17480104
   0.          0.        ]]. Action = [[-0.43719363 -0.7835866 ]]. Reward = [-1.5473212]
Curr episode timestep = 0
Scene graph at timestep 228 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 229. State = [[-0.01910124  1.412269   -0.6490282   0.02982963  0.02476231  0.17392662
   0.          0.        ]]. Action = [[ 0.8668287  -0.23758072]]. Reward = [-1.5009208]
Curr episode timestep = 1
Scene graph at timestep 229 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 230. State = [[-0.02555809  1.4123375  -0.6558491   0.00285133  0.03482223  0.20121694
   0.          0.        ]]. Action = [[-0.42280996 -0.7017966 ]]. Reward = [-1.6583031]
Curr episode timestep = 2
Scene graph at timestep 230 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 231. State = [[-0.03197498  1.4118087  -0.6508473  -0.02374569  0.04387042  0.18098041
   0.          0.        ]]. Action = [[-0.3297273   0.50772274]]. Reward = [-0.42274535]
Curr episode timestep = 3
Scene graph at timestep 231 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 232. State = [[-0.03844013  1.410973   -0.6572842  -0.03749243  0.05452959  0.21320347
   0.          0.        ]]. Action = [[ 0.11803198 -0.8040074 ]]. Reward = [-1.8975539]
Curr episode timestep = 4
Scene graph at timestep 232 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 233. State = [[-0.04496946  1.4095318  -0.66531104 -0.06454572  0.06679456  0.24532203
   0.          0.        ]]. Action = [[-0.60748935 -0.85160303]]. Reward = [-2.135503]
Curr episode timestep = 5
Scene graph at timestep 233 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 234. State = [[-0.05149927  1.4074929  -0.6653474  -0.09122432  0.07905717  0.24527486
   0.          0.        ]]. Action = [[-0.83750784  0.08712983]]. Reward = [-1.3585597]
Curr episode timestep = 6
Scene graph at timestep 234 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 235. State = [[-0.05816765  1.4052666  -0.67864025 -0.09960023  0.09076571  0.23419237
   0.          0.        ]]. Action = [[0.3974352 0.448959 ]]. Reward = [-2.6178184]
Curr episode timestep = 7
Scene graph at timestep 235 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 236. State = [[-0.0650342   1.4027823  -0.70017624 -0.11129557  0.104199    0.26869026
   0.          0.        ]]. Action = [[ 0.24011469 -0.9040699 ]]. Reward = [-3.6439953]
Curr episode timestep = 8
Scene graph at timestep 236 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 237. State = [[-0.07174473  1.4004171  -0.682709   -0.10597137  0.11579195  0.23188019
   0.          0.        ]]. Action = [[0.24835432 0.95638895]]. Reward = [0.63648677]
Curr episode timestep = 9
Scene graph at timestep 237 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 238. State = [[-0.07845573  1.3974535  -0.68274003 -0.13265567  0.12738387  0.23185983
   0.          0.        ]]. Action = [[-0.19487071  0.07925797]]. Reward = [-1.3615856]
Curr episode timestep = 10
Scene graph at timestep 238 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 239. State = [[-0.08529691  1.3948748  -0.69552183 -0.11562566  0.13875875  0.22751844
   0.          0.        ]]. Action = [[0.4687469  0.45527363]]. Reward = [-2.096354]
Curr episode timestep = 11
Scene graph at timestep 239 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 240. State = [[-0.09229155  1.392376   -0.71041816 -0.11212172  0.1497124   0.21909268
   0.          0.        ]]. Action = [[0.34297442 0.09685254]]. Reward = [-2.5063221]
Curr episode timestep = 12
Scene graph at timestep 240 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 241. State = [[-0.0994997   1.389983   -0.7311011  -0.10741751  0.16000123  0.20579584
   0.          0.        ]]. Action = [[ 0.65079236 -0.34607548]]. Reward = [-3.0612154]
Curr episode timestep = 13
Scene graph at timestep 241 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 242. State = [[-0.10666685  1.3870026  -0.72591937 -0.13347752  0.16922091  0.18441038
   0.          0.        ]]. Action = [[-0.8447566  0.6462257]]. Reward = [-0.6110645]
Curr episode timestep = 14
Scene graph at timestep 242 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 243. State = [[-0.11389418  1.3834097  -0.73344666 -0.16093835  0.17997143  0.21502967
   0.          0.        ]]. Action = [[-0.4250785  -0.83621013]]. Reward = [-2.0800757]
Curr episode timestep = 15
Scene graph at timestep 243 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 244. State = [[-0.12112208  1.3792183  -0.73347557 -0.1876194   0.19071937  0.21497802
   0.          0.        ]]. Action = [[-0.66956687  0.18503702]]. Reward = [-1.3379539]
Curr episode timestep = 16
Scene graph at timestep 244 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 245. State = [[-0.12843676  1.3749424  -0.74203813 -0.19143143  0.20137331  0.213098
   0.          0.        ]]. Action = [[ 0.18069959 -0.14548737]]. Reward = [-1.8068367]
Curr episode timestep = 17
Scene graph at timestep 245 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 246. State = [[-0.13569164  1.3700824  -0.7345142  -0.21725462  0.21047838  0.18211791
   0.          0.        ]]. Action = [[-0.51814747  0.7244785 ]]. Reward = [-0.48167965]
Curr episode timestep = 18
Scene graph at timestep 246 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 247. State = [[-0.14288083  1.3646402  -0.72622883 -0.24292392  0.21787506  0.14794673
   0.          0.        ]]. Action = [[-0.54673094  0.9113183 ]]. Reward = [-0.27950627]
Curr episode timestep = 19
Scene graph at timestep 247 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 248. State = [[-0.15019187  1.3592904  -0.7383176  -0.23885486  0.22518173  0.1461462
   0.          0.        ]]. Action = [[0.12553525 0.02929461]]. Reward = [-1.4669505]
Curr episode timestep = 20
Scene graph at timestep 248 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 249. State = [[-0.15754957  1.353328   -0.7441562  -0.26629004  0.23368737  0.17012843
   0.          0.        ]]. Action = [[-0.12499332 -0.5256198 ]]. Reward = [-1.7942029]
Curr episode timestep = 21
Scene graph at timestep 249 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 250. State = [[-0.16490774  1.3467665  -0.7441792  -0.29296574  0.2421912   0.17009208
   0.          0.        ]]. Action = [[-0.58241725 -0.47223663]]. Reward = [-1.2264699]
Curr episode timestep = 22
Scene graph at timestep 250 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 251. State = [[-0.1724803   1.3400465  -0.76496845 -0.2999569   0.25005752  0.15733996
   0.          0.        ]]. Action = [[ 0.82500076 -0.05997324]]. Reward = [-2.6785655]
Curr episode timestep = 23
Scene graph at timestep 251 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 252. State = [[-0.1802847   1.3335557  -0.7860998  -0.28945306  0.2558339   0.11552697
   0.          0.        ]]. Action = [[0.8198167 0.9007598]]. Reward = [-1.9383373]
Curr episode timestep = 24
Scene graph at timestep 252 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 253. State = [[-0.18802814  1.3264899  -0.77841735 -0.31475174  0.25999093  0.08314049
   0.          0.        ]]. Action = [[-0.5282699  0.9420357]]. Reward = [-0.04500766]
Curr episode timestep = 25
Scene graph at timestep 253 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 254. State = [[-0.1957716   1.3188243  -0.7784168  -0.34141982  0.26414794  0.08314036
   0.          0.        ]]. Action = [[-0.3341387   0.04450798]]. Reward = [-0.80386543]
Curr episode timestep = 26
Scene graph at timestep 254 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 255. State = [[-0.20353684  1.3111727  -0.7809741  -0.34087926  0.26870185  0.09107832
   0.          0.        ]]. Action = [[ 0.99156106 -0.4663489 ]]. Reward = [-0.32682347]
Curr episode timestep = 27
Scene graph at timestep 255 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 256. State = [[-0.2112411   1.3029542  -0.7732421  -0.36578372  0.2715859   0.05768093
   0.          0.        ]]. Action = [[-0.78786516  0.7022761 ]]. Reward = [0.05459138]
Curr episode timestep = 28
Scene graph at timestep 256 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 257. State = [[-0.21894541  1.2941359  -0.7732419  -0.39245108  0.27446994  0.05768079
   0.          0.        ]]. Action = [[-0.60566926  0.15397024]]. Reward = [-0.7181728]
Curr episode timestep = 29
Scene graph at timestep 257 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 258. State = [[-0.22664976  1.2847176  -0.77324164 -0.4191184   0.27735397  0.05768071
   0.          0.        ]]. Action = [[-0.7639073  0.1408863]]. Reward = [-0.7305579]
Curr episode timestep = 30
Scene graph at timestep 258 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 259. State = [[-0.23445745  1.2752067  -0.7835507  -0.42323777  0.28020585  0.05703757
   0.          0.        ]]. Action = [[ 0.07832277 -0.4402451 ]]. Reward = [-0.75204813]
Curr episode timestep = 31
Scene graph at timestep 259 is [False, True, True, True, True, True, True, False, True, False]
Current timestep = 260. State = [[-0.24230413  1.2650771  -0.7884642  -0.4509328   0.28411084  0.07809968
   0.          0.        ]]. Action = [[-0.47741175 -0.62743247]]. Reward = [-1.333748]
Curr episode timestep = 32
Scene graph at timestep 260 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 261. State = [[-0.2501959   1.2543327  -0.7941176  -0.47850382  0.28919828  0.10174836
   0.          0.        ]]. Action = [[-0.30390203 -0.6111608 ]]. Reward = [-1.5076118]
Curr episode timestep = 33
Scene graph at timestep 261 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 262. State = [[-0.25813523  1.2437345  -0.7993036  -0.4721059   0.2947304   0.11064234
   0.          0.        ]]. Action = [[ 0.16331124 -0.4484824 ]]. Reward = [0.03494276]
Curr episode timestep = 34
Scene graph at timestep 262 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 263. State = [[-0.26622516  1.2330625  -0.81264466 -0.4750536   0.29850268  0.07544602
   0.          0.        ]]. Action = [[0.96450365 0.75480163]]. Reward = [-1.117633]
Curr episode timestep = 35
Scene graph at timestep 263 is [False, True, True, True, True, True, True, True, False, False]
Current timestep = 264. State = [[-0.27425963  1.2218223  -0.8056138  -0.500012    0.30073923  0.04473066
   0.          0.        ]]. Action = [[-0.27975774  0.7690251 ]]. Reward = [-0.00756539]
Curr episode timestep = 36
Scene graph at timestep 264 is [False, True, True, True, True, True, True, True, False, True]
Current timestep = 265. State = [[-0.2822423   1.2099991  -0.79912215 -0.5256514   0.30161926  0.01760059
   0.          0.        ]]. Action = [[-0.27282476  0.81445265]]. Reward = [0.02826674]
Curr episode timestep = 37
Scene graph at timestep 265 is [False, True, True, True, True, True, True, False, False, False]
Current timestep = 266. State = [[-0.2904068   1.1983279  -0.8171894  -0.51887643  0.30238467  0.01530847
   0.          0.        ]]. Action = [[0.06389916 0.2715745 ]]. Reward = [-0.43921593]
Curr episode timestep = 38
Scene graph at timestep 266 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 267. State = [[-0.2985713   1.1860566  -0.8171894  -0.54554325  0.3031501   0.01530827
   0.          0.        ]]. Action = [[-0.43635887  0.34627986]]. Reward = [-0.53623146]
Curr episode timestep = 39
Scene graph at timestep 267 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 268. State = [[-0.306961    1.1736643  -0.8416476  -0.5513308   0.30591786  0.05535551
   0.          0.        ]]. Action = [[ 0.04722655 -0.9741551 ]]. Reward = [-1.8306304]
Curr episode timestep = 40
Scene graph at timestep 268 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 269. State = [[-0.31539574  1.1606463  -0.8473501  -0.5793972   0.309934    0.0803227
   0.          0.        ]]. Action = [[-0.8356093  -0.65096426]]. Reward = [-1.4157124]
Curr episode timestep = 41
Scene graph at timestep 269 is [True, True, True, True, True, True, True, True, False, False]
State prediction error at timestep 269 is 0.012
Human Feedback received at timestep 269 of -1
Current timestep = 270. State = [[-0.3238663   1.1475883  -0.8498446  -0.5809577   0.31282216  0.05776348
   0.          0.        ]]. Action = [[0.68205905 0.5956801 ]]. Reward = [0.17936158]
Curr episode timestep = 42
Scene graph at timestep 270 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 271. State = [[-0.33229145  1.1339566  -0.8440835  -0.60618997  0.31444573  0.03247135
   0.          0.        ]]. Action = [[-0.53414965  0.80873346]]. Reward = [-0.08570666]
Curr episode timestep = 43
Scene graph at timestep 271 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 272. State = [[-0.34071666  1.119725   -0.8440834  -0.6328568   0.31606925  0.03247111
   0.          0.        ]]. Action = [[-0.28136754 -0.41661394]]. Reward = [-0.6175555]
Curr episode timestep = 44
Scene graph at timestep 272 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 273. State = [[-0.34931254  1.1052926  -0.86240256 -0.6420572   0.31899258  0.05846685
   0.          0.        ]]. Action = [[ 0.30582452 -0.65711564]]. Reward = [-1.4022968]
Curr episode timestep = 45
Scene graph at timestep 273 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 274. State = [[-0.35795778  1.090988   -0.86780137 -0.63648415  0.32240263  0.06820145
   0.          0.        ]]. Action = [[ 0.51326156 -0.07651472]]. Reward = [0.42558852]
Curr episode timestep = 46
Scene graph at timestep 274 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 275. State = [[-0.36668143  1.0760522  -0.87764645 -0.66500574  0.3279046   0.11003946
   0.          0.        ]]. Action = [[-0.05233896 -0.9543415 ]]. Reward = [-1.9331099]
Curr episode timestep = 47
Scene graph at timestep 275 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 276. State = [[-0.37564245  1.0612597  -0.901086   -0.6585852   0.33310476  0.10400305
   0.          0.        ]]. Action = [[0.5119326  0.13693345]]. Reward = [-1.1405643]
Curr episode timestep = 48
Scene graph at timestep 276 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 277. State = [[-0.38453975  1.0458971  -0.89305145 -0.6835468   0.3365737   0.06937872
   0.          0.        ]]. Action = [[-0.24631572  0.90112174]]. Reward = [-0.08259919]
Curr episode timestep = 49
Scene graph at timestep 277 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 278. State = [[-0.39335117  1.0299755  -0.8822255  -0.70788187  0.33770537  0.02263354
   0.          0.        ]]. Action = [[-0.87566745  0.9579127 ]]. Reward = [0.39071435]
Curr episode timestep = 50
Scene graph at timestep 278 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 279. State = [[-0.40255517  1.0143698  -0.92278403 -0.69414675  0.34020448  0.04998227
   0.          0.        ]]. Action = [[ 0.88647366 -0.77972823]]. Reward = [-1.7962223]
Curr episode timestep = 51
Scene graph at timestep 279 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 280. State = [[-0.4117996   0.99813724 -0.92793244 -0.7222771   0.34386024  0.07311501
   0.          0.        ]]. Action = [[-0.19684774 -0.509038  ]]. Reward = [-1.3413433]
Curr episode timestep = 52
Scene graph at timestep 280 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 281. State = [[-0.4210027   0.98133373 -0.9226507  -0.747385    0.3463214   0.04922308
   0.          0.        ]]. Action = [[-0.72856355  0.62805176]]. Reward = [-0.22082782]
Curr episode timestep = 53
Scene graph at timestep 281 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 282. State = [[-0.43020573  0.9639303  -0.92265046 -0.7740522   0.34878254  0.04922294
   0.          0.        ]]. Action = [[-0.08612645  0.2713784 ]]. Reward = [-0.71703994]
Curr episode timestep = 54
Scene graph at timestep 282 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 283. State = [[-0.4393583   0.94595176 -0.9162806  -0.79929364  0.34986088  0.02156655
   0.          0.        ]]. Action = [[-0.40687752  0.7718053 ]]. Reward = [-0.03093917]
Curr episode timestep = 55
Scene graph at timestep 283 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 284. State = [[-0.44851083  0.9273733  -0.91628057 -0.8259603   0.3509392   0.02156647
   0.          0.        ]]. Action = [[-0.79280233 -0.22678375]]. Reward = [-0.5903554]
Curr episode timestep = 56
Scene graph at timestep 284 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 285. State = [[-0.4579267   0.909572   -0.9443402  -0.7918397   0.35383376  0.05789115
   0.          0.        ]]. Action = [[ 0.90387833 -0.7528698 ]]. Reward = [0.70336115]
Curr episode timestep = 57
Scene graph at timestep 285 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 286. State = [[-0.46728116  0.8911976  -0.9366285  -0.81693083  0.35507354  0.02479526
   0.          0.        ]]. Action = [[-0.86046326  0.8728062 ]]. Reward = [0.0118778]
Curr episode timestep = 58
Scene graph at timestep 286 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 287. State = [[-0.47659975  0.8722376  -0.9321226  -0.8427378   0.35535446  0.00561858
   0.          0.        ]]. Action = [[-0.79182005  0.55124116]]. Reward = [-0.18954043]
Curr episode timestep = 59
Scene graph at timestep 287 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 288. State = [[-0.48624223  0.85377645 -0.96302015 -0.820194    0.35405925 -0.0259042
   0.          0.        ]]. Action = [[0.5339116 0.6648017]]. Reward = [0.18647414]
Curr episode timestep = 60
Scene graph at timestep 288 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 289. State = [[-0.49617124  0.8357608  -0.9933608  -0.80081135  0.3545428   0.0096709
   0.          0.        ]]. Action = [[ 0.48641098 -0.84815204]]. Reward = [-0.33802426]
Curr episode timestep = 61
Scene graph at timestep 289 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 290. State = [[-0.5061003   0.81714493 -0.9933607  -0.82747805  0.35502633  0.00967063
   0.          0.        ]]. Action = [[-0.7948168  -0.11248255]]. Reward = [-0.6617234]
Curr episode timestep = 62
Scene graph at timestep 290 is [True, True, True, True, True, True, True, True, False, False]
State prediction error at timestep 290 is 0.012
Human Feedback received at timestep 290 of -1
Current timestep = 291. State = [[-0.5160668   0.79790497 -0.99812305 -0.85547835  0.35657936  0.03106081
   0.          0.        ]]. Action = [[-0.64024913 -0.54129636]]. Reward = [-1.2498579]
Curr episode timestep = 63
Scene graph at timestep 291 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 292. State = [[-0.5260333   0.7780651  -0.9981229  -0.8821452   0.35813242  0.03106097
   0.          0.        ]]. Action = [[-0.23596728  0.14481533]]. Reward = [-0.800936]
Curr episode timestep = 64
Scene graph at timestep 292 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 293. State = [[-0.53605217  0.7576019  -1.0047054  -0.9101835   0.36110154  0.05938205
   0.          0.        ]]. Action = [[-0.28057295 -0.64162004]]. Reward = [-1.5633442]
Curr episode timestep = 65
Scene graph at timestep 293 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 294. State = [[-0.54657465  0.7377368  -1.0560658  -0.8838597   0.3651356   0.08068134
   0.          0.        ]]. Action = [[ 0.87795794 -0.6806154 ]]. Reward = [-1.8584898]
Curr episode timestep = 66
Scene graph at timestep 294 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 295. State = [[-0.5570406   0.71730137 -1.0489392  -0.9088393   0.36760905  0.04946874
   0.          0.        ]]. Action = [[-0.25708163  0.61551833]]. Reward = [-0.3471692]
Curr episode timestep = 67
Scene graph at timestep 295 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 296. State = [[-0.5678338   0.6971897  -1.0833579  -0.894899    0.37188908  0.08560111
   0.          0.        ]]. Action = [[ 0.7600508  -0.89124006]]. Reward = [-1.543855]
Curr episode timestep = 68
Scene graph at timestep 296 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 297. State = [[-0.5785769   0.6765105  -1.0770035  -0.9197786   0.37473807  0.05697994
   0.          0.        ]]. Action = [[-0.19331986  0.8876226 ]]. Reward = [-0.5258871]
Curr episode timestep = 69
Scene graph at timestep 297 is [True, True, True, True, True, True, True, True, False, True]
State prediction error at timestep 297 is 0.012
Human Feedback received at timestep 297 of -1
Current timestep = 298. State = [[-0.58947027  0.6562652  -1.0905241  -0.9001058   0.37599808  0.02520015
   0.          0.        ]]. Action = [[0.4154451 0.7979374]]. Reward = [0.6717686]
Curr episode timestep = 70
Scene graph at timestep 298 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 299. State = [[-0.6005529   0.63608336 -1.1107836  -0.8976307   0.37867063  0.05345088
   0.          0.        ]]. Action = [[ 0.02388525 -0.6742272 ]]. Reward = [-1.1197926]
Curr episode timestep = 71
Scene graph at timestep 299 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 300. State = [[-0.6115842   0.61533153 -1.1042765  -0.9226084   0.37989643  0.02451623
   0.          0.        ]]. Action = [[-0.8838539   0.71702456]]. Reward = [-0.50409764]
Curr episode timestep = 72
Scene graph at timestep 300 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 301. State = [[-0.6229362   0.5949754  -1.136132   -0.9049686   0.3808817   0.01970527
   0.          0.        ]]. Action = [[ 0.71264327 -0.44065887]]. Reward = [-1.0943557]
Curr episode timestep = 73
Scene graph at timestep 301 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 302. State = [[-0.63428825  0.5740192  -1.136132   -0.9316353   0.38186696  0.01970515
   0.          0.        ]]. Action = [[-0.80986106  0.46349025]]. Reward = [-1.1791875]
Curr episode timestep = 74
Scene graph at timestep 302 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 303. State = [[-0.6456808   0.55289465 -1.1404856  -0.9391983   0.3831741   0.02614261
   0.          0.        ]]. Action = [[0.24423492 0.44950712]]. Reward = [-0.5930814]
Curr episode timestep = 75
Scene graph at timestep 303 is [True, True, True, True, True, True, True, False, True, False]
Current timestep = 304. State = [[-0.6570734   0.53117007 -1.1404855  -0.96586496  0.3844812   0.02614197
   0.          0.        ]]. Action = [[-0.24120075 -0.22332883]]. Reward = [-1.3262527]
Curr episode timestep = 76
Scene graph at timestep 304 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 305. State = [[-0.66839635  0.50887686 -1.1317543  -0.9906635   0.38390297 -0.01156475
   0.          0.        ]]. Action = [[-0.23748165  0.9537897 ]]. Reward = [-0.441889]
Curr episode timestep = 77
Scene graph at timestep 305 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 306. State = [[-0.67992026  0.48703045 -1.1521719  -0.97089523  0.38367128 -0.00463379
   0.          0.        ]]. Action = [[ 0.38176167 -0.15190482]]. Reward = [-0.0740351]
Curr episode timestep = 78
Scene graph at timestep 306 is [True, True, True, True, True, True, True, False, False, False]
Current timestep = 307. State = [[-0.69162786  0.46521664 -1.169382   -0.96913034  0.3822017  -0.02939174
   0.          0.        ]]. Action = [[0.9757986 0.5256033]]. Reward = [-1.0902746]
Curr episode timestep = 79
Scene graph at timestep 307 is [True, True, True, True, True, True, True, True, False, False]
Current timestep = 308. State = [[-0.70338595  0.4427758  -1.175747   -0.99735725  0.38213462 -0.00134176
   0.          0.        ]]. Action = [[-0.3747942  -0.70970345]]. Reward = [-2.0772586]
Curr episode timestep = 80
Scene graph at timestep 308 is [True, True, True, True, True, True, True, True, False, True]
Current timestep = 309. State = [[-0.71514404  0.41973484 -1.1757469  -1.0240239   0.38206753 -0.00134158
   0.          0.        ]]. Action = [[-0.76554376 -0.11109304]]. Reward = [-1.5392108]
Curr episode timestep = 81
Scene graph at timestep 309 is [True, True, True, True, True, True, True, False, False, False]
