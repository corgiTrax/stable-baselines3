Current timestep = 0. State = [[-0.32604954 -0.08628346]]. Action = [[0.00435984 0.09830839 0.         0.7271644 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [True, False, False, False, True, False]
State prediction error at timestep 0 is tensor(0.0668, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 0 of 0
Current timestep = 1. State = [[-0.33171427 -0.08338372]]. Action = [[-0.08950704 -0.00990598  0.          0.9261991 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False]
State prediction error at timestep 1 is tensor(0.0582, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 1 of -1
Current timestep = 2. State = [[-0.33283383 -0.08530016]]. Action = [[ 0.05919486 -0.05022838  0.          0.01757967]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, True, False]
State prediction error at timestep 2 is tensor(0.0498, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 2 of -1
Current timestep = 3. State = [[-0.32827213 -0.08361222]]. Action = [[ 0.07941776  0.04839816  0.         -0.50814736]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, True, False]
State prediction error at timestep 3 is tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 3 of -1
Current timestep = 4. State = [[-0.32541126 -0.08398188]]. Action = [[ 0.02240409 -0.05186519  0.          0.06079757]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, True, False]
State prediction error at timestep 4 is tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 4 of 1
Current timestep = 5. State = [[-0.3279662  -0.08312573]]. Action = [[-0.06502679  0.04306696  0.         -0.71754336]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, True, False]
State prediction error at timestep 5 is tensor(0.0098, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 5 of 1
Current timestep = 6. State = [[-0.33477807 -0.08681148]]. Action = [[-0.09400448 -0.09524496  0.         -0.55266786]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, True, False]
State prediction error at timestep 6 is tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 6 of 1
Current timestep = 7. State = [[-0.34229863 -0.08950668]]. Action = [[-0.08571869  0.01574626  0.          0.7504549 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, True, False]
State prediction error at timestep 7 is tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 7 of -1
Current timestep = 8. State = [[-0.3429938  -0.09305697]]. Action = [[ 0.06539506 -0.0697781   0.          0.35995412]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, True, False]
State prediction error at timestep 8 is tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 8 of -1
Current timestep = 9. State = [[-0.33896464 -0.09809606]]. Action = [[ 0.05115844 -0.04866862  0.          0.9661391 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, True, False]
State prediction error at timestep 9 is tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 9 of -1
Current timestep = 10. State = [[-0.34125766 -0.0959148 ]]. Action = [[-0.09368906  0.09748144  0.          0.9563508 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, True, False]
State prediction error at timestep 10 is tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 10 of -1
Current timestep = 11. State = [[-0.34793982 -0.0893025 ]]. Action = [[-0.06639187  0.08793294  0.         -0.7742076 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, True, False]
State prediction error at timestep 11 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 11 of -1
Current timestep = 12. State = [[-0.35246354 -0.0905406 ]]. Action = [[-0.02063891 -0.07997255  0.         -0.95368123]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, True, False]
State prediction error at timestep 12 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 12 of -1
Current timestep = 13. State = [[-0.35143134 -0.09692683]]. Action = [[ 0.06857524 -0.08357626  0.          0.79949784]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, True, False]
State prediction error at timestep 13 is tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 13 of -1
Current timestep = 14. State = [[-0.34906232 -0.1031656 ]]. Action = [[ 0.03607979 -0.07323649  0.          0.9914714 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, True, False]
State prediction error at timestep 14 is tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 14 of -1
Current timestep = 15. State = [[-0.34915978 -0.10752635]]. Action = [[-0.00920279 -0.03296737  0.         -0.212901  ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, True, False]
State prediction error at timestep 15 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 15 of -1
Current timestep = 16. State = [[-0.3515993 -0.1142972]]. Action = [[-0.03364602 -0.09512369  0.         -0.46627086]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, True, False]
State prediction error at timestep 16 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 16 of -1
Current timestep = 17. State = [[-0.35041395 -0.11492392]]. Action = [[ 0.0631833   0.078958    0.         -0.04599631]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, True, False]
State prediction error at timestep 17 is tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 17 of -1
Current timestep = 18. State = [[-0.35247564 -0.11036146]]. Action = [[-0.0743435   0.06373584  0.         -0.79923385]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, True, False]
State prediction error at timestep 18 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 18 of -1
Current timestep = 19. State = [[-0.3557668  -0.10817446]]. Action = [[-0.0147164   0.01580398  0.         -0.61370265]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, True, False]
State prediction error at timestep 19 is tensor(8.2450e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 19 of -1
Current timestep = 20. State = [[-0.3527888  -0.10625481]]. Action = [[0.0859893  0.02442236 0.         0.30674028]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, True, False]
State prediction error at timestep 20 is tensor(0.0074, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 20 of -1
Current timestep = 21. State = [[-0.35509413 -0.10489058]]. Action = [[-0.09340572  0.00903406  0.          0.02963233]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, True, False]
State prediction error at timestep 21 is tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 21 of -1
Current timestep = 22. State = [[-0.3558339  -0.10878154]]. Action = [[ 0.06779792 -0.09275456  0.         -0.54073656]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [True, False, False, False, True, False]
State prediction error at timestep 22 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 22 of -1
Current timestep = 23. State = [[-0.3501848  -0.11582592]]. Action = [[ 0.08790816 -0.09015904  0.          0.19786131]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [True, False, False, False, True, False]
State prediction error at timestep 23 is tensor(0.0071, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 23 of -1
Current timestep = 24. State = [[-0.34371805 -0.12279028]]. Action = [[ 0.07267658 -0.08339598  0.         -0.6289266 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [True, False, False, False, True, False]
State prediction error at timestep 24 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 24 of -1
Current timestep = 25. State = [[-0.33777672 -0.12917803]]. Action = [[ 0.05813199 -0.06662576  0.         -0.70856094]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [True, False, False, True, False, False]
State prediction error at timestep 25 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 25 of -1
Current timestep = 26. State = [[-0.33398366 -0.1349801 ]]. Action = [[ 0.01710353 -0.05333377  0.         -0.49725258]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [True, False, False, True, False, False]
State prediction error at timestep 26 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 26 of -1
Current timestep = 27. State = [[-0.32845178 -0.14066252]]. Action = [[ 0.07397484 -0.04998511  0.         -0.83825654]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [True, False, False, True, False, False]
State prediction error at timestep 27 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 27 of -1
Current timestep = 28. State = [[-0.32833174 -0.14097202]]. Action = [[-0.07978643  0.07155377  0.          0.70632434]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [True, False, False, True, False, False]
State prediction error at timestep 28 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 28 of -1
Current timestep = 29. State = [[-0.32638088 -0.13758485]]. Action = [[ 0.07643072  0.05659097  0.         -0.20878553]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [True, False, False, True, False, False]
State prediction error at timestep 29 is tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 29 of -1
Current timestep = 30. State = [[-0.32206243 -0.13426696]]. Action = [[0.03655075 0.04116782 0.         0.9097792 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [True, False, False, True, False, False]
State prediction error at timestep 30 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 30 of -1
Current timestep = 31. State = [[-0.32094046 -0.13048552]]. Action = [[-0.00839311  0.05425092  0.         -0.6915011 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [True, False, False, True, False, False]
State prediction error at timestep 31 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 31 of -1
Current timestep = 32. State = [[-0.31661135 -0.13219668]]. Action = [[ 0.09111435 -0.07279836  0.         -0.02515697]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [True, False, False, True, False, False]
State prediction error at timestep 32 is tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 32 of -1
Current timestep = 33. State = [[-0.31448805 -0.13134903]]. Action = [[-0.03157179  0.06367806  0.         -0.4428445 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [True, False, False, True, False, False]
State prediction error at timestep 33 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 33 of -1
Current timestep = 34. State = [[-0.3167867  -0.12686466]]. Action = [[-0.03639818  0.05399626  0.         -0.98353004]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [True, False, False, True, False, False]
State prediction error at timestep 34 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 34 of -1
Current timestep = 35. State = [[-0.31564876 -0.12613358]]. Action = [[ 0.04568673 -0.02825644  0.          0.72240937]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [True, False, False, True, False, False]
State prediction error at timestep 35 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 35 of -1
Current timestep = 36. State = [[-0.31780753 -0.12896705]]. Action = [[-0.07439803 -0.04893605  0.         -0.93899006]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [True, False, False, True, False, False]
State prediction error at timestep 36 is tensor(9.5293e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 36 of -1
Current timestep = 37. State = [[-0.32095695 -0.13504726]]. Action = [[-0.02559195 -0.08706646  0.         -0.67708194]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [True, False, False, True, False, False]
State prediction error at timestep 37 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 37 of -1
Current timestep = 38. State = [[-0.32042405 -0.13681045]]. Action = [[ 0.02305707  0.02523672  0.         -0.69167334]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [True, False, False, True, False, False]
State prediction error at timestep 38 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 38 of -1
Current timestep = 39. State = [[-0.3236325  -0.13289377]]. Action = [[-0.08637901  0.07388005  0.         -0.517688  ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [True, False, False, True, False, False]
State prediction error at timestep 39 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 39 of -1
Current timestep = 40. State = [[-0.3237299  -0.13436355]]. Action = [[ 0.06007446 -0.07989652  0.         -0.49592167]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [True, False, False, True, False, False]
State prediction error at timestep 40 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 40 of -1
Current timestep = 41. State = [[-0.31675074 -0.13849932]]. Action = [[ 0.09654539 -0.03722852  0.         -0.44516897]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [True, False, False, True, False, False]
State prediction error at timestep 41 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 41 of -1
Current timestep = 42. State = [[-0.31111586 -0.13490997]]. Action = [[ 0.03333474  0.09628118  0.         -0.69466555]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [True, False, False, True, False, False]
State prediction error at timestep 42 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 42 of -1
Current timestep = 43. State = [[-0.31004885 -0.1338145 ]]. Action = [[-0.01587927 -0.03592645  0.          0.88195944]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [True, False, False, True, False, False]
State prediction error at timestep 43 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 43 of -1
Current timestep = 44. State = [[-0.30792013 -0.1342662 ]]. Action = [[ 0.04028092  0.01130275  0.         -0.30264962]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [True, False, False, True, False, False]
State prediction error at timestep 44 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 44 of -1
Current timestep = 45. State = [[-0.3035888  -0.13600132]]. Action = [[ 0.05309267 -0.04195397  0.          0.5218322 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [True, False, False, True, False, False]
State prediction error at timestep 45 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 45 of -1
Current timestep = 46. State = [[-0.30081308 -0.13419917]]. Action = [[0.00991942 0.06003953 0.         0.5824646 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [True, False, False, True, False, False]
State prediction error at timestep 46 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 46 of -1
Current timestep = 47. State = [[-0.30148235 -0.12796357]]. Action = [[-0.0323048   0.09017807  0.         -0.21992636]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [True, False, False, True, False, False]
State prediction error at timestep 47 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 47 of -1
Current timestep = 48. State = [[-0.29865944 -0.12718096]]. Action = [[ 0.07403915 -0.05109023  0.         -0.7260029 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [True, False, False, True, False, False]
State prediction error at timestep 48 is tensor(4.7817e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 48 of -1
Current timestep = 49. State = [[-0.29240063 -0.12437077]]. Action = [[ 0.06747351  0.07111067  0.         -0.45134294]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [True, False, False, False, True, False]
State prediction error at timestep 49 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 49 of -1
Current timestep = 50. State = [[-0.2873597  -0.11758821]]. Action = [[ 0.0426737   0.07641727  0.         -0.8412951 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [True, False, False, False, True, False]
State prediction error at timestep 50 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 50 of -1
Current timestep = 51. State = [[-0.28989175 -0.11397099]]. Action = [[-0.09475566  0.00767674  0.          0.39351213]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 51 is [True, False, False, False, True, False]
State prediction error at timestep 51 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 51 of -1
Current timestep = 52. State = [[-0.29360366 -0.11731965]]. Action = [[-0.03532665 -0.08242221  0.         -0.47736776]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 52 is [True, False, False, False, True, False]
State prediction error at timestep 52 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 52 of 1
Current timestep = 53. State = [[-0.297761   -0.12102858]]. Action = [[-0.0741969  -0.02738796  0.         -0.2999456 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 53 is [True, False, False, False, True, False]
State prediction error at timestep 53 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 53 of 1
Current timestep = 54. State = [[-0.29746738 -0.1261046 ]]. Action = [[ 0.04062577 -0.08185817  0.         -0.01309502]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 54 is [True, False, False, True, False, False]
State prediction error at timestep 54 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 54 of 1
Current timestep = 55. State = [[-0.29828846 -0.13244039]]. Action = [[-0.05400257 -0.06966211  0.          0.31021953]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 55 is [True, False, False, True, False, False]
State prediction error at timestep 55 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 55 of 1
Current timestep = 56. State = [[-0.29994875 -0.1385231 ]]. Action = [[-0.01880425 -0.05825498  0.         -0.22547954]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 56 is [True, False, False, True, False, False]
State prediction error at timestep 56 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 56 of -1
Current timestep = 57. State = [[-0.3033272  -0.13875943]]. Action = [[-0.06867609  0.05859322  0.          0.8621203 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 57 is [True, False, False, True, False, False]
State prediction error at timestep 57 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 57 of -1
Current timestep = 58. State = [[-0.3018463  -0.13480145]]. Action = [[0.06934046 0.064358   0.         0.25226486]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 58 is [True, False, False, True, False, False]
State prediction error at timestep 58 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 58 of -1
Current timestep = 59. State = [[-0.3005138 -0.1297992]]. Action = [[-0.0119206   0.06309188  0.         -0.5618697 ]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 59 is [True, False, False, True, False, False]
State prediction error at timestep 59 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 59 of -1
Current timestep = 60. State = [[-0.29837203 -0.12882684]]. Action = [[ 0.0530125  -0.02404566  0.          0.42915523]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 60 is [True, False, False, True, False, False]
State prediction error at timestep 60 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 60 of -1
Current timestep = 61. State = [[-0.30126682 -0.13011974]]. Action = [[-0.08711399 -0.01381721  0.         -0.5927022 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 61 is [True, False, False, True, False, False]
State prediction error at timestep 61 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 61 of -1
Current timestep = 62. State = [[-0.30309132 -0.13264874]]. Action = [[ 0.02382757 -0.03864987  0.          0.7844385 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 62 is [True, False, False, True, False, False]
State prediction error at timestep 62 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 62 of -1
Current timestep = 63. State = [[-0.3011085  -0.13336343]]. Action = [[ 0.03917716  0.00732145  0.         -0.48086935]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 63 is [True, False, False, True, False, False]
State prediction error at timestep 63 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 63 of -1
Current timestep = 64. State = [[-0.30289683 -0.13385497]]. Action = [[-0.05165159 -0.01490119  0.          0.2093097 ]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 64 is [True, False, False, True, False, False]
State prediction error at timestep 64 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 64 of -1
Current timestep = 65. State = [[-0.30667022 -0.13479449]]. Action = [[-0.03899502 -0.00429736  0.          0.6146164 ]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 65 is [True, False, False, True, False, False]
State prediction error at timestep 65 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 65 of -1
Current timestep = 66. State = [[-0.312936   -0.13783138]]. Action = [[-0.09198519 -0.04717354  0.          0.82629013]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 66 is [True, False, False, True, False, False]
State prediction error at timestep 66 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 66 of -1
Current timestep = 67. State = [[-0.3189431  -0.14469229]]. Action = [[-0.0520874  -0.09253145  0.         -0.87864006]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 67 is [True, False, False, True, False, False]
State prediction error at timestep 67 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 67 of -1
Current timestep = 68. State = [[-0.31940407 -0.15039471]]. Action = [[ 0.03996348 -0.0408619   0.          0.03650677]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 68 is [True, False, False, True, False, False]
State prediction error at timestep 68 is tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 68 of -1
Current timestep = 69. State = [[-0.316411   -0.15217534]]. Action = [[ 0.04944784  0.00298771  0.         -0.01521105]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 69 is [True, False, False, True, False, False]
State prediction error at timestep 69 is tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 69 of -1
Current timestep = 70. State = [[-0.3112326  -0.15520707]]. Action = [[ 0.08163003 -0.05487268  0.         -0.6778405 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 70 is [True, False, False, True, False, False]
State prediction error at timestep 70 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 70 of -1
Current timestep = 71. State = [[-0.31267658 -0.15951128]]. Action = [[-0.07899408 -0.03732152  0.          0.55941606]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 71 is [True, False, False, True, False, False]
State prediction error at timestep 71 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 71 of -1
Current timestep = 72. State = [[-0.31841636 -0.16323152]]. Action = [[-0.0575058  -0.02650692  0.         -0.5912264 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 72 is [True, False, False, True, False, False]
State prediction error at timestep 72 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 72 of -1
Current timestep = 73. State = [[-0.31874874 -0.16662139]]. Action = [[ 0.0473351  -0.02731906  0.          0.8286966 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 73 is [True, False, False, True, False, False]
State prediction error at timestep 73 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 73 of -1
Current timestep = 74. State = [[-0.31908968 -0.17280023]]. Action = [[-0.02040728 -0.08708278  0.          0.6586659 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 74 is [True, False, False, True, False, False]
State prediction error at timestep 74 is tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 74 of -1
Current timestep = 75. State = [[-0.3167285  -0.17812848]]. Action = [[ 0.06728294 -0.03206332  0.          0.12121272]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 75 is [True, False, False, True, False, False]
State prediction error at timestep 75 is tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 75 of -1
Current timestep = 76. State = [[-0.31103393 -0.18221962]]. Action = [[ 0.07733931 -0.0424742   0.          0.18912232]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 76 is [True, False, False, True, False, False]
State prediction error at timestep 76 is tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 76 of -1
Current timestep = 77. State = [[-0.3113161  -0.18649356]]. Action = [[-0.05609271 -0.03603822  0.          0.7141768 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 77 is [True, False, False, True, False, False]
State prediction error at timestep 77 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 77 of -1
Current timestep = 78. State = [[-0.3090727  -0.18502514]]. Action = [[ 0.0795706   0.08357627  0.         -0.8826926 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 78 is [True, False, False, True, False, False]
State prediction error at timestep 78 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 78 of -1
Current timestep = 79. State = [[-0.30772704 -0.18352477]]. Action = [[-1.7066412e-02 -3.2340735e-04  0.0000000e+00  4.5572495e-01]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 79 is [True, False, False, True, False, False]
State prediction error at timestep 79 is tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 79 of -1
Current timestep = 80. State = [[-0.3043308  -0.18728124]]. Action = [[ 0.07951228 -0.06625366  0.         -0.7040123 ]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 80 is [True, False, False, True, False, False]
State prediction error at timestep 80 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 80 of -1
Current timestep = 81. State = [[-0.30558687 -0.18632162]]. Action = [[-0.08670907  0.08715541  0.         -0.3614971 ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 81 is [True, False, False, True, False, False]
State prediction error at timestep 81 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 81 of -1
Current timestep = 82. State = [[-0.30724618 -0.18244877]]. Action = [[ 0.03122889  0.03313921  0.         -0.34880316]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 82 is [True, False, False, True, False, False]
State prediction error at timestep 82 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 82 of -1
Current timestep = 83. State = [[-0.30467907 -0.18327615]]. Action = [[ 0.05247863 -0.0510861   0.          0.68012345]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 83 is [True, False, False, True, False, False]
State prediction error at timestep 83 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 83 of -1
Current timestep = 84. State = [[-0.30567467 -0.18018784]]. Action = [[-0.04537087  0.08580937  0.          0.38239872]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 84 is [True, False, False, True, False, False]
State prediction error at timestep 84 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 84 of -1
Current timestep = 85. State = [[-0.3127563  -0.17889684]]. Action = [[-0.09409975 -0.03260952  0.         -0.2224639 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 85 is [True, False, False, True, False, False]
State prediction error at timestep 85 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 85 of -1
Current timestep = 86. State = [[-0.31967977 -0.17744003]]. Action = [[-0.05393067  0.04078455  0.         -0.06477231]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 86 is [True, False, False, True, False, False]
State prediction error at timestep 86 is tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 86 of -1
Current timestep = 87. State = [[-0.3265731 -0.1751805]]. Action = [[-0.07528329  0.01632114  0.         -0.8962233 ]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 87 is [True, False, False, True, False, False]
State prediction error at timestep 87 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 87 of -1
Current timestep = 88. State = [[-0.32882464 -0.17138253]]. Action = [[0.02876434 0.05396575 0.         0.12518573]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 88 is [True, False, False, True, False, False]
State prediction error at timestep 88 is tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 88 of -1
Current timestep = 89. State = [[-0.32784802 -0.16447096]]. Action = [[0.02811862 0.08110727 0.         0.8301985 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 89 is [True, False, False, True, False, False]
State prediction error at timestep 89 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 89 of -1
Current timestep = 90. State = [[-0.32663667 -0.16188787]]. Action = [[ 0.02764512 -0.03111738  0.         -0.3389212 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 90 is [True, False, False, True, False, False]
State prediction error at timestep 90 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 90 of -1
Current timestep = 91. State = [[-0.32838178 -0.16609855]]. Action = [[-0.03117431 -0.09856004  0.          0.7877226 ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 91 is [True, False, False, True, False, False]
State prediction error at timestep 91 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 91 of -1
Current timestep = 92. State = [[-0.33299813 -0.1717657 ]]. Action = [[-0.0548743  -0.06779662  0.          0.08862233]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 92 is [True, False, False, True, False, False]
State prediction error at timestep 92 is tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 92 of -1
Current timestep = 93. State = [[-0.33373272 -0.17009573]]. Action = [[ 0.03616745  0.07713332  0.         -0.8160514 ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 93 is [True, False, False, True, False, False]
State prediction error at timestep 93 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 93 of -1
Current timestep = 94. State = [[-0.33490464 -0.17022948]]. Action = [[-0.03369085 -0.05145237  0.         -0.6307522 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 94 is [True, False, False, True, False, False]
State prediction error at timestep 94 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 94 of -1
Current timestep = 95. State = [[-0.33626157 -0.16792989]]. Action = [[ 4.0988624e-04  7.3963292e-02  0.0000000e+00 -9.0623170e-01]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 95 is [True, False, False, True, False, False]
State prediction error at timestep 95 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 95 of -1
Current timestep = 96. State = [[-0.3383543  -0.16894801]]. Action = [[-0.032543   -0.06333105  0.         -0.6240001 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 96 is [True, False, False, True, False, False]
State prediction error at timestep 96 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 96 of -1
Current timestep = 97. State = [[-0.33645442 -0.17164521]]. Action = [[ 0.06554677 -0.01963414  0.         -0.07814467]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 97 is [True, False, False, True, False, False]
State prediction error at timestep 97 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 97 of -1
Current timestep = 98. State = [[-0.33493134 -0.17173046]]. Action = [[-0.00569645  0.00839043  0.         -0.6207758 ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 98 is [True, False, False, True, False, False]
State prediction error at timestep 98 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 98 of -1
Current timestep = 99. State = [[-0.33478495 -0.16771987]]. Action = [[0.005075   0.07755845 0.         0.12932181]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 99 is [True, False, False, True, False, False]
State prediction error at timestep 99 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 99 of -1
Current timestep = 100. State = [[-0.33195487 -0.16358614]]. Action = [[ 0.0554784   0.03086536  0.         -0.5979209 ]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 100 is [True, False, False, True, False, False]
State prediction error at timestep 100 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 100 of -1
Current timestep = 101. State = [[-0.3259113 -0.1575963]]. Action = [[ 0.08806627  0.07974107  0.         -0.89002883]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 101 is [True, False, False, True, False, False]
State prediction error at timestep 101 is tensor(6.3687e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 101 of -1
Current timestep = 102. State = [[-0.32422832 -0.15235357]]. Action = [[-0.01982336  0.0319952   0.         -0.5211054 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 102 is [True, False, False, True, False, False]
State prediction error at timestep 102 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 102 of -1
Current timestep = 103. State = [[-0.32237506 -0.15396304]]. Action = [[ 0.05183411 -0.07674875  0.          0.44297218]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 103 is [True, False, False, True, False, False]
State prediction error at timestep 103 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 103 of -1
Current timestep = 104. State = [[-0.3179678  -0.15471736]]. Action = [[ 0.05621021  0.009363    0.         -0.30662042]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 104 is [True, False, False, True, False, False]
State prediction error at timestep 104 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 104 of -1
Current timestep = 105. State = [[-0.31266147 -0.15752357]]. Action = [[ 0.06183686 -0.07699135  0.         -0.24751478]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 105 is [True, False, False, True, False, False]
State prediction error at timestep 105 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 105 of -1
Current timestep = 106. State = [[-0.30939814 -0.15462449]]. Action = [[ 0.00765549  0.09716385  0.         -0.13519955]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 106 is [True, False, False, True, False, False]
State prediction error at timestep 106 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 106 of -1
Current timestep = 107. State = [[-0.30639926 -0.15298903]]. Action = [[ 0.04683668 -0.03538974  0.          0.5356014 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 107 is [True, False, False, True, False, False]
State prediction error at timestep 107 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 107 of -1
Current timestep = 108. State = [[-0.30116463 -0.15336524]]. Action = [[ 0.0646385  -0.00259555  0.          0.56476223]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 108 is [True, False, False, True, False, False]
State prediction error at timestep 108 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 108 of -1
Current timestep = 109. State = [[-0.29992998 -0.15254007]]. Action = [[-0.03121166  0.01134771  0.          0.5031743 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 109 is [True, False, False, True, False, False]
State prediction error at timestep 109 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 109 of -1
Current timestep = 110. State = [[-0.30168316 -0.14815144]]. Action = [[-0.03419773  0.08279517  0.          0.47749007]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 110 is [True, False, False, True, False, False]
State prediction error at timestep 110 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 110 of -1
Current timestep = 111. State = [[-0.30413058 -0.14230143]]. Action = [[-0.04029074  0.06785857  0.          0.12423003]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 111 is [True, False, False, True, False, False]
State prediction error at timestep 111 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 111 of -1
Current timestep = 112. State = [[-0.30536562 -0.14434005]]. Action = [[-0.00712172 -0.09146224  0.         -0.811299  ]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 112 is [True, False, False, True, False, False]
State prediction error at timestep 112 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 112 of -1
Current timestep = 113. State = [[-0.30150804 -0.15079068]]. Action = [[ 0.07085104 -0.08380727  0.          0.73642373]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 113 is [True, False, False, True, False, False]
State prediction error at timestep 113 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 113 of -1
Current timestep = 114. State = [[-0.3020066  -0.15423091]]. Action = [[-0.07565559 -0.01159684  0.         -0.14848685]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 114 is [True, False, False, True, False, False]
State prediction error at timestep 114 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 114 of -1
Current timestep = 115. State = [[-0.3013885  -0.15059872]]. Action = [[0.04420681 0.08780003 0.         0.48999035]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 115 is [True, False, False, True, False, False]
State prediction error at timestep 115 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 115 of -1
Current timestep = 116. State = [[-0.2953632  -0.15194416]]. Action = [[ 0.09623731 -0.09048355  0.          0.41194165]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 116 is [True, False, False, True, False, False]
State prediction error at timestep 116 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 116 of -1
Current timestep = 117. State = [[-0.29227534 -0.1568417 ]]. Action = [[-0.01304837 -0.04813527  0.          0.8463316 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 117 is [True, False, False, True, False, False]
State prediction error at timestep 117 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 117 of -1
Current timestep = 118. State = [[-0.29181108 -0.15453126]]. Action = [[-0.00327689  0.08893738  0.         -0.6406165 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 118 is [True, False, False, True, False, False]
State prediction error at timestep 118 is tensor(9.5053e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 118 of -1
Current timestep = 119. State = [[-0.29425254 -0.14956908]]. Action = [[-0.05964547  0.05978853  0.         -0.19560373]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 119 is [True, False, False, True, False, False]
State prediction error at timestep 119 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 119 of -1
Current timestep = 120. State = [[-0.29407445 -0.15025252]]. Action = [[ 0.03472849 -0.0491585   0.          0.17859054]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 120 is [True, False, False, True, False, False]
State prediction error at timestep 120 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 120 of -1
Current timestep = 121. State = [[-0.28821975 -0.15588546]]. Action = [[ 0.0889168  -0.08618559  0.          0.22403121]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 121 is [True, False, False, True, False, False]
State prediction error at timestep 121 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 121 of -1
Current timestep = 122. State = [[-0.2839718  -0.15844414]]. Action = [[0.01510014 0.0038114  0.         0.6464145 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 122 is [True, False, False, True, False, False]
State prediction error at timestep 122 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 122 of -1
Current timestep = 123. State = [[-0.2865731 -0.1625377]]. Action = [[-0.08064979 -0.06940288  0.         -0.39065862]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 123 is [True, False, False, True, False, False]
State prediction error at timestep 123 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 123 of -1
Current timestep = 124. State = [[-0.2861326  -0.16198516]]. Action = [[0.04382842 0.07383902 0.         0.06805134]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 124 is [True, False, False, True, False, False]
State prediction error at timestep 124 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 124 of -1
Current timestep = 125. State = [[-0.28132108 -0.1576945 ]]. Action = [[ 0.06289401  0.05043254  0.         -0.7577491 ]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 125 is [True, False, False, True, False, False]
State prediction error at timestep 125 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 125 of -1
Current timestep = 126. State = [[-0.27607843 -0.15831427]]. Action = [[ 0.05785734 -0.04961744  0.         -0.08927184]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 126 is [True, False, False, True, False, False]
State prediction error at timestep 126 is tensor(8.9288e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 126 of -1
Current timestep = 127. State = [[-0.27278277 -0.15619521]]. Action = [[0.01981305 0.06659973 0.         0.6500671 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 127 is [True, False, False, True, False, False]
State prediction error at timestep 127 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 127 of -1
Current timestep = 128. State = [[-0.2738683  -0.15535627]]. Action = [[-0.04259109 -0.02315343  0.         -0.74240613]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 128 is [True, False, False, True, False, False]
State prediction error at timestep 128 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 128 of -1
Current timestep = 129. State = [[-0.27372232 -0.15884914]]. Action = [[ 0.02030528 -0.05659573  0.         -0.9196338 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 129 is [True, False, False, True, False, False]
State prediction error at timestep 129 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 129 of -1
Current timestep = 130. State = [[-0.2734024  -0.16287266]]. Action = [[-0.01399262 -0.04224411  0.          0.89215815]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 130 is [True, False, False, True, False, False]
State prediction error at timestep 130 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 130 of -1
Current timestep = 131. State = [[-0.27148145 -0.16490704]]. Action = [[ 0.0346809 -0.0059201  0.        -0.8783987]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 131 is [True, False, False, True, False, False]
State prediction error at timestep 131 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 131 of -1
Current timestep = 132. State = [[-0.27429542 -0.16770154]]. Action = [[-0.08944511 -0.03962005  0.          0.82464826]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 132 is [True, False, False, True, False, False]
State prediction error at timestep 132 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 132 of -1
Current timestep = 133. State = [[-0.27409002 -0.17012419]]. Action = [[ 0.04507902 -0.00727633  0.         -0.44655377]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 133 is [True, False, False, True, False, False]
State prediction error at timestep 133 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 133 of -1
Current timestep = 134. State = [[-0.27312955 -0.16668636]]. Action = [[-0.01365688  0.08684585  0.          0.1362735 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 134 is [True, False, False, True, False, False]
State prediction error at timestep 134 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 134 of -1
Current timestep = 135. State = [[-0.27069423 -0.16148043]]. Action = [[ 0.05159185  0.05642688  0.         -0.07521057]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 135 is [True, False, False, True, False, False]
State prediction error at timestep 135 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 135 of -1
Current timestep = 136. State = [[-0.27070028 -0.16334079]]. Action = [[-0.03198107 -0.08106593  0.         -0.8780274 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 136 is [True, False, False, True, False, False]
State prediction error at timestep 136 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 136 of -1
Current timestep = 137. State = [[-0.27295542 -0.16605319]]. Action = [[-0.0298181  -0.00540338  0.         -0.01075763]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 137 is [True, False, False, True, False, False]
State prediction error at timestep 137 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 137 of -1
Current timestep = 138. State = [[-0.2717086  -0.17020817]]. Action = [[ 0.04300847 -0.07337372  0.          0.80183744]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 138 is [True, False, False, True, False, False]
State prediction error at timestep 138 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 138 of -1
Current timestep = 139. State = [[-0.2661275  -0.17705496]]. Action = [[ 0.08422921 -0.09136201  0.         -0.03957283]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 139 is [True, False, False, True, False, False]
State prediction error at timestep 139 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 139 of -1
Current timestep = 140. State = [[-0.26094756 -0.18028821]]. Action = [[ 0.04336891 -0.00159456  0.         -0.43417966]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 140 is [True, False, False, True, False, False]
State prediction error at timestep 140 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 140 of -1
Current timestep = 141. State = [[-0.2627152 -0.1777701]]. Action = [[-0.07885902  0.07565314  0.         -0.6503109 ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 141 is [True, False, False, True, False, False]
State prediction error at timestep 141 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 141 of -1
Current timestep = 142. State = [[-0.26528782 -0.17531896]]. Action = [[-0.00797065  0.02278499  0.          0.04501534]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 142 is [True, False, False, True, False, False]
State prediction error at timestep 142 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 142 of -1
Current timestep = 143. State = [[-0.26792482 -0.17984053]]. Action = [[-0.04296118 -0.0956293   0.          0.623302  ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 143 is [True, False, False, True, False, False]
State prediction error at timestep 143 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 143 of -1
Current timestep = 144. State = [[-0.26519305 -0.18038398]]. Action = [[0.08529175 0.0576352  0.         0.23395419]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 144 is [True, False, False, True, False, False]
State prediction error at timestep 144 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 144 of -1
Current timestep = 145. State = [[-0.26689982 -0.18215486]]. Action = [[-0.08907054 -0.07067439  0.          0.38881755]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 145 is [True, False, False, True, False, False]
State prediction error at timestep 145 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 145 of -1
Current timestep = 146. State = [[-0.2729728  -0.18142584]]. Action = [[-0.07399897  0.07051451  0.          0.6487466 ]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 146 is [True, False, False, True, False, False]
State prediction error at timestep 146 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 146 of -1
Current timestep = 147. State = [[-0.27282736 -0.18390016]]. Action = [[ 0.06447896 -0.08753949  0.          0.08768797]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 147 is [True, False, False, True, False, False]
State prediction error at timestep 147 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 147 of -1
Current timestep = 148. State = [[-0.26864514 -0.18712088]]. Action = [[ 0.04001405 -0.00381901  0.         -0.75799304]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 148 is [True, False, False, True, False, False]
State prediction error at timestep 148 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 148 of -1
Current timestep = 149. State = [[-0.26457825 -0.1922391 ]]. Action = [[ 0.0419615  -0.08497103  0.         -0.9359287 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 149 is [True, False, False, True, False, False]
State prediction error at timestep 149 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 149 of -1
Current timestep = 150. State = [[-0.25793803 -0.19191703]]. Action = [[0.09236444 0.06901351 0.         0.3878739 ]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 150 is [True, False, False, True, False, False]
State prediction error at timestep 150 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 150 of -1
Current timestep = 151. State = [[-0.25209978 -0.19177729]]. Action = [[ 0.04805083 -0.02915369  0.         -0.58043057]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 151 is [True, False, False, True, False, False]
State prediction error at timestep 151 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 151 of -1
Current timestep = 152. State = [[-0.2522312  -0.19725364]]. Action = [[-0.04835875 -0.08264565  0.          0.21133327]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 152 is [True, False, False, True, False, False]
State prediction error at timestep 152 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 152 of -1
Current timestep = 153. State = [[-0.252443   -0.19598556]]. Action = [[0.00893726 0.0970545  0.         0.7230027 ]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 153 is [True, False, False, True, False, False]
State prediction error at timestep 153 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 153 of -1
Current timestep = 154. State = [[-0.2539461  -0.19235411]]. Action = [[-0.04548479  0.03522118  0.         -0.8547854 ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 154 is [True, False, False, True, False, False]
State prediction error at timestep 154 is tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 154 of -1
Current timestep = 155. State = [[-0.25691694 -0.19604495]]. Action = [[-0.04221708 -0.08478069  0.         -0.3236035 ]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 155 is [True, False, False, True, False, False]
State prediction error at timestep 155 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 155 of -1
Current timestep = 156. State = [[-0.2585797  -0.19757435]]. Action = [[-0.01567105  0.03186446  0.         -0.24348408]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 156 is [True, False, False, True, False, False]
State prediction error at timestep 156 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 156 of -1
Current timestep = 157. State = [[-0.25776497 -0.19595602]]. Action = [[0.01961496 0.02467529 0.         0.56316674]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 157 is [True, False, False, True, False, False]
State prediction error at timestep 157 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 157 of -1
Current timestep = 158. State = [[-0.2579775  -0.19543268]]. Action = [[-0.02117822 -0.0033922   0.         -0.5852606 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 158 is [True, False, False, True, False, False]
State prediction error at timestep 158 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 158 of -1
Current timestep = 159. State = [[-0.25879052 -0.19086689]]. Action = [[-0.00780116  0.09380382  0.         -0.47430527]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 159 is [True, False, False, True, False, False]
State prediction error at timestep 159 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 159 of -1
Current timestep = 160. State = [[-0.25966316 -0.18916225]]. Action = [[-0.01190465 -0.02695926  0.          0.2796564 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 160 is [True, False, False, True, False, False]
State prediction error at timestep 160 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 160 of -1
Current timestep = 161. State = [[-0.259779   -0.18804772]]. Action = [[ 0.00669712  0.02625527  0.         -0.7439804 ]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 161 is [True, False, False, True, False, False]
State prediction error at timestep 161 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 161 of -1
Current timestep = 162. State = [[-0.2579677  -0.18698552]]. Action = [[ 0.03599436 -0.00687519  0.          0.12070179]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 162 is [True, False, False, True, False, False]
State prediction error at timestep 162 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 162 of -1
Current timestep = 163. State = [[-0.25750777 -0.18804939]]. Action = [[-0.00919966 -0.03263689  0.          0.61822176]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 163 is [True, False, False, True, False, False]
State prediction error at timestep 163 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 163 of -1
Current timestep = 164. State = [[-0.2620473  -0.18720746]]. Action = [[-0.08592363  0.03240167  0.         -0.13750696]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 164 is [True, False, False, True, False, False]
State prediction error at timestep 164 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 164 of -1
Current timestep = 165. State = [[-0.26735806 -0.18917492]]. Action = [[-0.04951499 -0.05663366  0.          0.8825033 ]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 165 is [True, False, False, True, False, False]
State prediction error at timestep 165 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 165 of -1
Current timestep = 166. State = [[-0.26886356 -0.19488202]]. Action = [[ 0.00945316 -0.08034644  0.          0.4945792 ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 166 is [True, False, False, True, False, False]
State prediction error at timestep 166 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 166 of -1
Current timestep = 167. State = [[-0.27126592 -0.19493   ]]. Action = [[-0.04874979  0.05608524  0.          0.39609742]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 167 is [True, False, False, True, False, False]
State prediction error at timestep 167 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 167 of -1
Current timestep = 168. State = [[-0.26891726 -0.19771272]]. Action = [[ 0.09595466 -0.09358536  0.          0.53707063]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 168 is [True, False, False, True, False, False]
State prediction error at timestep 168 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 168 of -1
Current timestep = 169. State = [[-0.26137254 -0.20223401]]. Action = [[ 0.09374359 -0.03369288  0.         -0.9213636 ]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 169 is [True, False, False, True, False, False]
State prediction error at timestep 169 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 169 of -1
Current timestep = 170. State = [[-0.25444567 -0.20816104]]. Action = [[ 0.07007799 -0.0872883   0.         -0.75450486]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 170 is [True, False, False, True, False, False]
State prediction error at timestep 170 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 170 of -1
Current timestep = 171. State = [[-0.25552624 -0.21038039]]. Action = [[-0.08953412  0.04116408  0.         -0.8811142 ]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 171 is [True, False, False, True, False, False]
State prediction error at timestep 171 is tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 171 of -1
Current timestep = 172. State = [[-0.25475362 -0.21347582]]. Action = [[ 0.07573324 -0.06902848  0.          0.8960886 ]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 172 is [True, False, False, True, False, False]
State prediction error at timestep 172 is tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 172 of -1
Current timestep = 173. State = [[-0.25459066 -0.22014745]]. Action = [[-0.04095184 -0.07172103  0.          0.8752949 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 173 is [True, False, False, True, False, False]
State prediction error at timestep 173 is tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 173 of -1
Current timestep = 174. State = [[-0.2563089  -0.22761947]]. Action = [[-0.01790889 -0.07191597  0.         -0.89394623]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 174 is [True, False, False, True, False, False]
State prediction error at timestep 174 is tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 174 of -1
Current timestep = 175. State = [[-0.2576561  -0.22723319]]. Action = [[-0.02195679  0.09404739  0.         -0.76458776]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 175 is [True, False, False, True, False, False]
State prediction error at timestep 175 is tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 175 of -1
Current timestep = 176. State = [[-0.25725555 -0.22683647]]. Action = [[ 0.0217375  -0.01342737  0.         -0.3096946 ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 176 is [True, False, False, True, False, False]
State prediction error at timestep 176 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 176 of -1
Current timestep = 177. State = [[-0.25566667 -0.22870696]]. Action = [[ 0.01878963 -0.0105807   0.          0.26303935]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 177 is [True, False, False, True, False, False]
State prediction error at timestep 177 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 177 of -1
Current timestep = 178. State = [[-0.25954545 -0.23333211]]. Action = [[-0.09155571 -0.06362627  0.          0.33886147]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 178 is [True, False, False, True, False, False]
State prediction error at timestep 178 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 178 of -1
Current timestep = 179. State = [[-0.2618798  -0.23901705]]. Action = [[ 0.00750606 -0.04880141  0.          0.94298327]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 179 is [True, False, False, True, False, False]
State prediction error at timestep 179 is tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 179 of -1
Current timestep = 180. State = [[-0.26024607 -0.23792984]]. Action = [[ 0.03113007  0.07537211  0.         -0.7761148 ]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 180 is [True, False, False, True, False, False]
State prediction error at timestep 180 is tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 180 of -1
Current timestep = 181. State = [[-0.25561246 -0.23832014]]. Action = [[ 0.07504969 -0.04198488  0.         -0.79109377]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 181 is [True, False, False, True, False, False]
State prediction error at timestep 181 is tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 181 of -1
Current timestep = 182. State = [[-0.25292534 -0.2371412 ]]. Action = [[0.00386105 0.05285048 0.         0.33823848]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 182 is [True, False, False, True, False, False]
State prediction error at timestep 182 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 182 of -1
Current timestep = 183. State = [[-0.25613028 -0.231394  ]]. Action = [[-0.0693486   0.0946136   0.          0.33548653]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 183 is [True, False, False, True, False, False]
State prediction error at timestep 183 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 183 of -1
Current timestep = 184. State = [[-0.26299396 -0.23040463]]. Action = [[-0.09116436 -0.02901931  0.          0.73392344]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 184 is [True, False, False, True, False, False]
State prediction error at timestep 184 is tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 184 of -1
Current timestep = 185. State = [[-0.27111208 -0.23593351]]. Action = [[-0.09616254 -0.09020197  0.          0.22922838]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 185 is [True, False, False, True, False, False]
State prediction error at timestep 185 is tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 185 of -1
Current timestep = 186. State = [[-0.27067673 -0.24048004]]. Action = [[ 0.08137336 -0.03377534  0.         -0.1228646 ]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 186 is [True, False, False, True, False, False]
State prediction error at timestep 186 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 186 of -1
Current timestep = 187. State = [[-0.27240208 -0.23972537]]. Action = [[-0.07847561  0.04258464  0.          0.18812776]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 187 is [True, False, False, True, False, False]
State prediction error at timestep 187 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 187 of -1
Current timestep = 188. State = [[-0.27554795 -0.23448105]]. Action = [[-0.00501361  0.08134145  0.          0.90702486]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 188 is [True, False, False, True, False, False]
State prediction error at timestep 188 is tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 188 of -1
Current timestep = 189. State = [[-0.27935967 -0.22984366]]. Action = [[-0.0512919   0.03580376  0.          0.75103545]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 189 is [True, False, False, True, False, False]
State prediction error at timestep 189 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 189 of -1
Current timestep = 190. State = [[-0.28569636 -0.23284222]]. Action = [[-0.07321425 -0.09349865  0.          0.6941507 ]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 190 is [True, False, False, True, False, False]
State prediction error at timestep 190 is tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 190 of -1
Current timestep = 191. State = [[-0.28718635 -0.23163323]]. Action = [[ 0.04075714  0.07157426  0.         -0.61772054]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 191 is [True, False, False, True, False, False]
State prediction error at timestep 191 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 191 of -1
Current timestep = 192. State = [[-0.28628388 -0.22795151]]. Action = [[0.01613346 0.01858294 0.         0.72729015]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 192 is [True, False, False, True, False, False]
State prediction error at timestep 192 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 192 of -1
Current timestep = 193. State = [[-0.28715092 -0.22176309]]. Action = [[-0.00884396  0.09220021  0.          0.13626134]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 193 is [True, False, False, True, False, False]
State prediction error at timestep 193 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 193 of -1
Current timestep = 194. State = [[-0.28635225 -0.22035614]]. Action = [[ 0.04397594 -0.0536644   0.          0.78261113]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 194 is [True, False, False, True, False, False]
State prediction error at timestep 194 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 194 of -1
Current timestep = 195. State = [[-0.28732914 -0.21917981]]. Action = [[-0.03171685  0.03258897  0.         -0.6598672 ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 195 is [True, False, False, True, False, False]
State prediction error at timestep 195 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 195 of -1
Current timestep = 196. State = [[-0.28674826 -0.22174092]]. Action = [[ 0.04628719 -0.09024464  0.          0.7658862 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 196 is [True, False, False, True, False, False]
State prediction error at timestep 196 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 196 of -1
Current timestep = 197. State = [[-0.28636542 -0.2252285 ]]. Action = [[-0.01147102 -0.03087336  0.          0.0080719 ]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 197 is [True, False, False, True, False, False]
State prediction error at timestep 197 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 197 of -1
Current timestep = 198. State = [[-0.28675643 -0.22896232]]. Action = [[ 0.00145972 -0.05605188  0.          0.4015522 ]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 198 is [True, False, False, True, False, False]
State prediction error at timestep 198 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 198 of -1
Current timestep = 199. State = [[-0.29020086 -0.22983141]]. Action = [[-0.06853322  0.02635355  0.         -0.8003572 ]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 199 is [True, False, False, True, False, False]
State prediction error at timestep 199 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 199 of -1
Current timestep = 200. State = [[-0.28913414 -0.22859113]]. Action = [[0.06689634 0.02155688 0.         0.7918761 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 200 is [True, False, False, True, False, False]
State prediction error at timestep 200 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 200 of -1
Current timestep = 201. State = [[-0.2860418  -0.22476871]]. Action = [[ 0.02567109  0.06279821  0.         -0.7528262 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 201 is [True, False, False, True, False, False]
State prediction error at timestep 201 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 201 of -1
Current timestep = 202. State = [[-0.28168574 -0.2245134 ]]. Action = [[ 0.07102007 -0.04075133  0.          0.46641886]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 202 is [True, False, False, True, False, False]
State prediction error at timestep 202 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 202 of -1
Current timestep = 203. State = [[-0.27588537 -0.22202808]]. Action = [[ 0.06939188  0.06030447  0.         -0.33550394]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 203 is [True, False, False, True, False, False]
State prediction error at timestep 203 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 203 of -1
Current timestep = 204. State = [[-0.27639046 -0.21876441]]. Action = [[-0.0566479   0.02226212  0.          0.16216803]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 204 is [True, False, False, True, False, False]
State prediction error at timestep 204 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 204 of -1
Current timestep = 205. State = [[-0.27877605 -0.21952215]]. Action = [[-0.01565324 -0.03204368  0.          0.53037834]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 205 is [True, False, False, True, False, False]
State prediction error at timestep 205 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 205 of -1
Current timestep = 206. State = [[-0.2838777  -0.21841007]]. Action = [[-0.09119126  0.04368546  0.          0.34444237]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 206 is [True, False, False, True, False, False]
State prediction error at timestep 206 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 206 of -1
Current timestep = 207. State = [[-0.29018247 -0.22021772]]. Action = [[-0.06734253 -0.05508336  0.          0.4195814 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 207 is [True, False, False, True, False, False]
State prediction error at timestep 207 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 207 of -1
Current timestep = 208. State = [[-0.29699823 -0.21796602]]. Action = [[-0.0890642   0.08583302  0.         -0.37549973]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 208 is [True, False, False, True, False, False]
State prediction error at timestep 208 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 208 of -1
Current timestep = 209. State = [[-0.298938   -0.21966273]]. Action = [[ 0.03666621 -0.09653719  0.          0.2797035 ]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 209 is [True, False, False, True, False, False]
State prediction error at timestep 209 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 209 of -1
Current timestep = 210. State = [[-0.29752535 -0.22196884]]. Action = [[ 0.00490651  0.01123055  0.         -0.9103955 ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 210 is [True, False, False, True, False, False]
State prediction error at timestep 210 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 210 of -1
Current timestep = 211. State = [[-0.29284036 -0.22657081]]. Action = [[ 0.08156342 -0.09490185  0.         -0.4303825 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 211 is [True, False, False, True, False, False]
State prediction error at timestep 211 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 211 of -1
Current timestep = 212. State = [[-0.2898246  -0.22869526]]. Action = [[-0.00628629  0.02306469  0.          0.3547498 ]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 212 is [True, False, False, True, False, False]
State prediction error at timestep 212 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 212 of -1
Current timestep = 213. State = [[-0.28794554 -0.22803713]]. Action = [[0.02971566 0.01178275 0.         0.46670222]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 213 is [True, False, False, True, False, False]
State prediction error at timestep 213 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 213 of -1
Current timestep = 214. State = [[-0.28971583 -0.23080344]]. Action = [[-0.0579894  -0.05334746  0.         -0.7138312 ]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 214 is [True, False, False, True, False, False]
State prediction error at timestep 214 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 214 of -1
Current timestep = 215. State = [[-0.28843746 -0.23479116]]. Action = [[ 0.05708904 -0.03529884  0.         -0.6833244 ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 215 is [True, False, False, True, False, False]
State prediction error at timestep 215 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 215 of -1
Current timestep = 216. State = [[-0.28358027 -0.23890157]]. Action = [[ 0.05883113 -0.05176144  0.          0.0055325 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 216 is [True, False, False, True, False, False]
State prediction error at timestep 216 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 216 of -1
Current timestep = 217. State = [[-0.2855579  -0.23885994]]. Action = [[-0.08955026  0.05602539  0.          0.86010826]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 217 is [True, False, False, True, False, False]
State prediction error at timestep 217 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 217 of -1
Current timestep = 218. State = [[-0.29080167 -0.23551354]]. Action = [[-0.04555212  0.05325586  0.         -0.09989715]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 218 is [True, False, False, True, False, False]
State prediction error at timestep 218 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 218 of -1
Current timestep = 219. State = [[-0.2888291 -0.2328086]]. Action = [[ 0.08319078  0.02344231  0.         -0.47244585]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 219 is [True, False, False, True, False, False]
State prediction error at timestep 219 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 219 of -1
Current timestep = 220. State = [[-0.28260443 -0.23576304]]. Action = [[ 0.08302743 -0.09076862  0.         -0.6981343 ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 220 is [True, False, False, True, False, False]
State prediction error at timestep 220 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 220 of -1
Current timestep = 221. State = [[-0.28070933 -0.24239443]]. Action = [[-0.01478843 -0.09198242  0.         -0.754435  ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 221 is [True, False, False, True, False, False]
State prediction error at timestep 221 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 221 of -1
Current timestep = 222. State = [[-0.2773417  -0.24643916]]. Action = [[ 0.0702315  -0.02127215  0.          0.02709961]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 222 is [True, False, False, True, False, False]
State prediction error at timestep 222 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 222 of -1
Current timestep = 223. State = [[-0.27497217 -0.24343327]]. Action = [[-9.2905760e-04  8.6526774e-02  0.0000000e+00 -9.6320391e-01]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 223 is [True, False, False, True, False, False]
State prediction error at timestep 223 is tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 223 of -1
Current timestep = 224. State = [[-0.27217257 -0.23643635]]. Action = [[ 0.05488262  0.09627821  0.         -0.9490412 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 224 is [True, False, False, True, False, False]
State prediction error at timestep 224 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 224 of -1
Current timestep = 225. State = [[-0.2671856  -0.23591195]]. Action = [[ 0.07012156 -0.06209151  0.         -0.76365095]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 225 is [True, False, False, True, False, False]
State prediction error at timestep 225 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 225 of -1
Current timestep = 226. State = [[-0.26407596 -0.2337807 ]]. Action = [[ 0.01006987  0.0695437   0.         -0.3237158 ]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 226 is [True, False, False, True, False, False]
State prediction error at timestep 226 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 226 of -1
Current timestep = 227. State = [[-0.26036733 -0.22649336]]. Action = [[ 0.06361816  0.09457744  0.         -0.6844522 ]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 227 is [True, False, False, True, False, False]
State prediction error at timestep 227 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 227 of -1
Current timestep = 228. State = [[-0.2604752  -0.22621614]]. Action = [[-0.0463529  -0.07936563  0.         -0.7897289 ]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 228 is [True, False, False, True, False, False]
State prediction error at timestep 228 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 228 of -1
Current timestep = 229. State = [[-0.2572117  -0.22888124]]. Action = [[ 0.08660049 -0.02785836  0.         -0.25020325]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 229 is [True, False, False, True, False, False]
State prediction error at timestep 229 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 229 of -1
Current timestep = 230. State = [[-0.25649855 -0.23263063]]. Action = [[-0.04621073 -0.07084272  0.          0.8768599 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 230 is [True, False, False, True, False, False]
State prediction error at timestep 230 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 230 of -1
Current timestep = 231. State = [[-0.25893828 -0.23251098]]. Action = [[-0.03726237  0.04707535  0.          0.22905517]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 231 is [True, False, False, True, False, False]
State prediction error at timestep 231 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 231 of -1
Current timestep = 232. State = [[-0.25919876 -0.23540364]]. Action = [[ 0.00810705 -0.07992639  0.         -0.31359553]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 232 is [True, False, False, True, False, False]
State prediction error at timestep 232 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 232 of -1
Current timestep = 233. State = [[-0.26135498 -0.24245566]]. Action = [[-0.06299166 -0.08456488  0.         -0.15888971]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 233 is [True, False, False, True, False, False]
State prediction error at timestep 233 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 233 of -1
Current timestep = 234. State = [[-0.26659384 -0.24606264]]. Action = [[-0.08447453  0.00581396  0.          0.29945278]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 234 is [True, False, False, True, False, False]
State prediction error at timestep 234 is tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 234 of -1
Current timestep = 235. State = [[-0.26666299 -0.24548398]]. Action = [[ 0.03920946  0.04052334  0.         -0.8856344 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 235 is [True, False, False, True, False, False]
State prediction error at timestep 235 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 235 of -1
Current timestep = 236. State = [[-0.2639471  -0.24960352]]. Action = [[ 0.02490322 -0.09032321  0.          0.92484915]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 236 is [True, False, False, True, False, False]
State prediction error at timestep 236 is tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 236 of -1
Current timestep = 237. State = [[-0.26116073 -0.24847332]]. Action = [[0.02703685 0.09451645 0.         0.08015168]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 237 is [True, False, False, True, False, False]
State prediction error at timestep 237 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 237 of -1
Current timestep = 238. State = [[-0.26090235 -0.2464595 ]]. Action = [[-0.01567711 -0.00076099  0.          0.5539007 ]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 238 is [True, False, False, True, False, False]
State prediction error at timestep 238 is tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 238 of -1
Current timestep = 239. State = [[-0.2587831  -0.24474846]]. Action = [[0.05107722 0.03664584 0.         0.13826191]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 239 is [True, False, False, True, False, False]
State prediction error at timestep 239 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 239 of -1
Current timestep = 240. State = [[-0.25529826 -0.24351586]]. Action = [[ 0.04059059 -0.00186084  0.          0.3563738 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 240 is [True, False, False, True, False, False]
State prediction error at timestep 240 is tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 240 of -1
Current timestep = 241. State = [[-0.25049594 -0.24524033]]. Action = [[ 0.07028092 -0.04510395  0.          0.5948309 ]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 241 is [True, False, False, True, False, False]
State prediction error at timestep 241 is tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 241 of -1
Current timestep = 242. State = [[-0.25210536 -0.2438797 ]]. Action = [[-0.08268137  0.05585868  0.         -0.4150616 ]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 242 is [True, False, False, True, False, False]
State prediction error at timestep 242 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 242 of 1
Current timestep = 243. State = [[-0.25669    -0.24642383]]. Action = [[-0.03484283 -0.0874579   0.         -0.07904607]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 243 is [True, False, False, True, False, False]
State prediction error at timestep 243 is tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 243 of 1
Current timestep = 244. State = [[-0.26135018 -0.24883626]]. Action = [[-0.06229147  0.00329701  0.         -0.7678861 ]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 244 is [True, False, False, True, False, False]
State prediction error at timestep 244 is tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 244 of 1
Current timestep = 245. State = [[-0.26212576 -0.25056982]]. Action = [[ 0.02954132 -0.02929093  0.         -0.70567447]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 245 is [True, False, False, True, False, False]
State prediction error at timestep 245 is tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 245 of 1
Current timestep = 246. State = [[-0.2637893  -0.24850178]]. Action = [[-0.04493972  0.06411887  0.         -0.03626889]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 246 is [True, False, False, True, False, False]
State prediction error at timestep 246 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 246 of 1
Current timestep = 247. State = [[-0.2679613 -0.2425612]]. Action = [[-0.04838457  0.08821882  0.         -0.13291192]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 247 is [True, False, False, True, False, False]
State prediction error at timestep 247 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 247 of 1
Current timestep = 248. State = [[-0.2690732  -0.24013169]]. Action = [[ 0.02229676 -0.01038672  0.          0.3818406 ]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 248 is [True, False, False, True, False, False]
State prediction error at timestep 248 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 248 of 1
Current timestep = 249. State = [[-0.26917353 -0.24279624]]. Action = [[-0.00446908 -0.06069851  0.         -0.76948667]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 249 is [True, False, False, True, False, False]
State prediction error at timestep 249 is tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 249 of 1
Current timestep = 250. State = [[-0.2723977  -0.24707298]]. Action = [[-0.0548619  -0.05488222  0.          0.09272456]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 250 is [True, False, False, True, False, False]
State prediction error at timestep 250 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 250 of 1
Current timestep = 251. State = [[-0.27021223 -0.24949543]]. Action = [[ 0.0837611  -0.01460786  0.          0.9341707 ]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 251 is [True, False, False, True, False, False]
State prediction error at timestep 251 is tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 251 of 1
Current timestep = 252. State = [[-0.2638672  -0.24517077]]. Action = [[ 0.08282239  0.08910083  0.         -0.5855757 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 252 is [True, False, False, True, False, False]
State prediction error at timestep 252 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 252 of -1
Current timestep = 253. State = [[-0.26414004 -0.23754452]]. Action = [[-0.05244691  0.09381623  0.         -0.84115326]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 253 is [True, False, False, True, False, False]
State prediction error at timestep 253 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 253 of -1
Current timestep = 254. State = [[-0.26780134 -0.2344281 ]]. Action = [[-0.03379025 -0.00176296  0.         -0.6843915 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 254 is [True, False, False, True, False, False]
State prediction error at timestep 254 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 254 of -1
Current timestep = 255. State = [[-0.26458314 -0.2360023 ]]. Action = [[ 0.09921285 -0.05203736  0.         -0.88595295]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 255 is [True, False, False, True, False, False]
State prediction error at timestep 255 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 255 of -1
Current timestep = 256. State = [[-0.26546648 -0.23386604]]. Action = [[-0.07988124  0.0680733   0.          0.4296193 ]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 256 is [True, False, False, True, False, False]
State prediction error at timestep 256 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 256 of -1
Current timestep = 257. State = [[-0.27159822 -0.23077203]]. Action = [[-0.06248206  0.00891569  0.         -0.29527336]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 257 is [True, False, False, True, False, False]
State prediction error at timestep 257 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 257 of -1
Current timestep = 258. State = [[-0.27853584 -0.22936912]]. Action = [[-0.07825266  0.0066694   0.          0.43613112]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 258 is [True, False, False, True, False, False]
State prediction error at timestep 258 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 258 of -1
Current timestep = 259. State = [[-0.28168133 -0.23100789]]. Action = [[ 0.00642605 -0.05162696  0.          0.08806455]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 259 is [True, False, False, True, False, False]
State prediction error at timestep 259 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 259 of -1
Current timestep = 260. State = [[-0.2849043  -0.23528892]]. Action = [[-0.05029897 -0.06890403  0.          0.7596712 ]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 260 is [True, False, False, True, False, False]
State prediction error at timestep 260 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 260 of -1
Current timestep = 261. State = [[-0.28866315 -0.24062108]]. Action = [[-0.0328006  -0.06775482  0.          0.7431741 ]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 261 is [True, False, False, True, False, False]
State prediction error at timestep 261 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 261 of -1
Current timestep = 262. State = [[-0.2894067  -0.24561843]]. Action = [[ 0.01577573 -0.05362196  0.          0.69451857]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 262 is [True, False, False, True, False, False]
State prediction error at timestep 262 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 262 of -1
Current timestep = 263. State = [[-0.28445873 -0.24411798]]. Action = [[ 0.09700299  0.06978066  0.         -0.57109946]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 263 is [True, False, False, True, False, False]
State prediction error at timestep 263 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 263 of -1
Current timestep = 264. State = [[-0.28325984 -0.23884831]]. Action = [[-0.02762187  0.07051399  0.          0.4473927 ]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 264 is [True, False, False, True, False, False]
State prediction error at timestep 264 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 264 of -1
Current timestep = 265. State = [[-0.2859332  -0.23319672]]. Action = [[-0.02673134  0.07586589  0.          0.5214888 ]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 265 is [True, False, False, True, False, False]
State prediction error at timestep 265 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 265 of -1
Current timestep = 266. State = [[-0.28724635 -0.2300713 ]]. Action = [[0.0080112  0.01386662 0.         0.6668863 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 266 is [True, False, False, True, False, False]
State prediction error at timestep 266 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 266 of -1
Current timestep = 267. State = [[-0.29003316 -0.22802845]]. Action = [[-0.04289551  0.02177904  0.         -0.16493475]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 267 is [True, False, False, True, False, False]
State prediction error at timestep 267 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 267 of -1
Current timestep = 268. State = [[-0.29191342 -0.23165129]]. Action = [[ 0.00585081 -0.09787392  0.          0.36710763]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 268 is [True, False, False, True, False, False]
State prediction error at timestep 268 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 268 of -1
Current timestep = 269. State = [[-0.29658192 -0.23781802]]. Action = [[-0.08356297 -0.07159613  0.          0.52031684]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 269 is [True, False, False, True, False, False]
State prediction error at timestep 269 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 269 of -1
Current timestep = 270. State = [[-0.2962208  -0.23793401]]. Action = [[ 0.06769925  0.05080538  0.         -0.52465487]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 270 is [True, False, False, True, False, False]
State prediction error at timestep 270 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 270 of -1
Current timestep = 271. State = [[-0.2973142  -0.23288004]]. Action = [[-0.05406824  0.07637095  0.          0.22476923]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 271 is [True, False, False, True, False, False]
State prediction error at timestep 271 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 271 of -1
Current timestep = 272. State = [[-0.30085102 -0.2332263 ]]. Action = [[-0.03009145 -0.05235046  0.          0.64002085]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 272 is [True, False, False, True, False, False]
State prediction error at timestep 272 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 272 of -1
Current timestep = 273. State = [[-0.3008863 -0.2383006]]. Action = [[ 0.02745635 -0.07354251  0.          0.9499655 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 273 is [True, False, False, True, False, False]
State prediction error at timestep 273 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 273 of -1
Current timestep = 274. State = [[-0.2978037  -0.24148224]]. Action = [[ 0.04833489 -0.02034691  0.         -0.19648659]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 274 is [True, False, False, True, False, False]
State prediction error at timestep 274 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 274 of -1
Current timestep = 275. State = [[-0.29664725 -0.24712528]]. Action = [[-0.00886939 -0.09699611  0.         -0.2231754 ]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 275 is [True, False, False, True, False, False]
State prediction error at timestep 275 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 275 of -1
Current timestep = 276. State = [[-0.29423016 -0.25042024]]. Action = [[0.04855085 0.0019262  0.         0.71639335]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 276 is [True, False, False, True, False, False]
State prediction error at timestep 276 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 276 of -1
Current timestep = 277. State = [[-0.29396108 -0.24697518]]. Action = [[-0.02709479  0.0891363   0.          0.46803594]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 277 is [True, False, False, True, False, False]
State prediction error at timestep 277 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 277 of -1
Current timestep = 278. State = [[-0.29938963 -0.24064052]]. Action = [[-0.08861171  0.09558088  0.         -0.5833    ]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 278 is [True, False, False, True, False, False]
State prediction error at timestep 278 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 278 of -1
Current timestep = 279. State = [[-0.29872853 -0.24127302]]. Action = [[ 0.08950668 -0.084232    0.         -0.7995552 ]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 279 is [True, False, False, True, False, False]
State prediction error at timestep 279 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 279 of -1
Current timestep = 280. State = [[-0.29662663 -0.24721423]]. Action = [[-0.01860963 -0.06171352  0.          0.16629398]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 280 is [True, False, False, True, False, False]
State prediction error at timestep 280 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 280 of -1
Current timestep = 281. State = [[-0.29991964 -0.24785659]]. Action = [[-0.07387672  0.0567074   0.         -0.54894567]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 281 is [True, False, False, True, False, False]
State prediction error at timestep 281 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 281 of -1
Current timestep = 282. State = [[-0.30209327 -0.2467849 ]]. Action = [[-0.00543328  0.01576804  0.          0.6119566 ]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 282 is [True, False, False, True, False, False]
State prediction error at timestep 282 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 282 of -1
Current timestep = 283. State = [[-0.3041219  -0.24340531]]. Action = [[-0.03967131  0.07250991  0.         -0.9139813 ]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 283 is [True, False, False, True, False, False]
State prediction error at timestep 283 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 283 of -1
Current timestep = 284. State = [[-0.3093919  -0.24365035]]. Action = [[-0.08076064 -0.03653576  0.         -0.7030614 ]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 284 is [True, False, False, True, False, False]
State prediction error at timestep 284 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 284 of -1
Current timestep = 285. State = [[-0.30754498 -0.24858765]]. Action = [[ 0.09279764 -0.08164428  0.          0.8977052 ]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 285 is [True, False, False, True, False, False]
State prediction error at timestep 285 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 285 of -1
Current timestep = 286. State = [[-0.30859035 -0.2477665 ]]. Action = [[-0.08744355  0.0827884   0.          0.8984225 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 286 is [True, False, False, True, False, False]
State prediction error at timestep 286 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 286 of -1
Current timestep = 287. State = [[-0.31589654 -0.24323319]]. Action = [[-0.08119825  0.04225601  0.          0.1802392 ]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 287 is [True, False, False, True, False, False]
State prediction error at timestep 287 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 287 of -1
Current timestep = 288. State = [[-0.31687227 -0.2383871 ]]. Action = [[ 0.05671286  0.05583138  0.         -0.40731966]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 288 is [True, False, False, True, False, False]
State prediction error at timestep 288 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 288 of -1
Current timestep = 289. State = [[-0.31370407 -0.2393802 ]]. Action = [[ 0.05258345 -0.08856793  0.          0.56107426]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 289 is [True, False, False, True, False, False]
State prediction error at timestep 289 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 289 of -1
Current timestep = 290. State = [[-0.3167332  -0.24218607]]. Action = [[-0.08130437 -0.02881818  0.         -0.2254433 ]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 290 is [True, False, False, True, False, False]
State prediction error at timestep 290 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 290 of -1
Current timestep = 291. State = [[-0.32344392 -0.2458891 ]]. Action = [[-0.06627921 -0.06522432  0.         -0.15051699]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 291 is [True, False, False, True, False, False]
State prediction error at timestep 291 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 291 of -1
Current timestep = 292. State = [[-0.3279038  -0.24799342]]. Action = [[-0.02483512 -0.00495783  0.          0.35414827]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 292 is [True, False, False, True, False, False]
State prediction error at timestep 292 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 292 of -1
Current timestep = 293. State = [[-0.3312357 -0.251987 ]]. Action = [[-0.03062747 -0.07309157  0.         -0.7821916 ]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 293 is [True, False, False, True, False, False]
State prediction error at timestep 293 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 293 of -1
Current timestep = 294. State = [[-0.3282845  -0.25802457]]. Action = [[ 0.08964405 -0.07586049  0.          0.5900605 ]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 294 is [True, False, False, True, False, False]
State prediction error at timestep 294 is tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 294 of -1
Current timestep = 295. State = [[-0.327065   -0.25874972]]. Action = [[-0.02893973  0.04611859  0.         -0.8940985 ]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 295 is [True, False, False, True, False, False]
State prediction error at timestep 295 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 295 of -1
Current timestep = 296. State = [[-0.32455826 -0.26200008]]. Action = [[ 0.07838351 -0.09198535  0.          0.8252398 ]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 296 is [True, False, False, True, False, False]
State prediction error at timestep 296 is tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 296 of -1
Current timestep = 297. State = [[-0.32347205 -0.26165888]]. Action = [[-0.02510731  0.08308021  0.          0.62954617]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 297 is [True, False, False, True, False, False]
State prediction error at timestep 297 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 297 of -1
Current timestep = 298. State = [[-0.32296982 -0.2561976 ]]. Action = [[0.04036517 0.07152856 0.         0.4174919 ]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 298 is [True, False, False, True, False, False]
State prediction error at timestep 298 is tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 298 of -1
Current timestep = 299. State = [[-0.32304668 -0.2574166 ]]. Action = [[-0.00452329 -0.07681523  0.         -0.88316154]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 299 is [True, False, False, True, False, False]
State prediction error at timestep 299 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 299 of -1
Current timestep = 300. State = [[-0.3286568  -0.25682974]]. Action = [[-0.09319546  0.06280393  0.         -0.6523901 ]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 300 is [True, False, False, True, False, False]
State prediction error at timestep 300 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 300 of -1
Current timestep = 301. State = [[-0.3293588  -0.25731435]]. Action = [[ 0.07260168 -0.05805734  0.          0.5057845 ]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 301 is [True, False, False, True, False, False]
State prediction error at timestep 301 is tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 301 of -1
Current timestep = 302. State = [[-0.3324179 -0.2573072]]. Action = [[-0.08884194  0.03353057  0.         -0.24497342]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 302 is [True, False, False, True, False, False]
State prediction error at timestep 302 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 302 of -1
Current timestep = 303. State = [[-0.33515424 -0.254758  ]]. Action = [[0.01716892 0.03334815 0.         0.5678637 ]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 303 is [True, False, False, True, False, False]
State prediction error at timestep 303 is tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 303 of -1
Current timestep = 304. State = [[-0.33756155 -0.2553538 ]]. Action = [[-0.03793274 -0.03864125  0.         -0.6443791 ]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 304 is [True, False, False, True, False, False]
State prediction error at timestep 304 is tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 304 of -1
Current timestep = 305. State = [[-0.34135848 -0.25170168]]. Action = [[-0.03669088  0.09542065  0.          0.38774812]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 305 is [True, False, False, True, False, False]
State prediction error at timestep 305 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 305 of -1
Current timestep = 306. State = [[-0.34185785 -0.24982715]]. Action = [[ 0.03448338 -0.0310946   0.          0.6818048 ]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 306 is [True, False, False, True, False, False]
State prediction error at timestep 306 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 306 of -1
Current timestep = 307. State = [[-0.33624887 -0.24752203]]. Action = [[ 0.09836502  0.04428389  0.         -0.19639182]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 307 is [True, False, False, True, False, False]
State prediction error at timestep 307 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 307 of -1
Current timestep = 308. State = [[-0.3351502  -0.24894264]]. Action = [[-0.04415764 -0.08166672  0.         -0.6397207 ]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 308 is [True, False, False, True, False, False]
State prediction error at timestep 308 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 308 of -1
Current timestep = 309. State = [[-0.34080803 -0.2520482 ]]. Action = [[-0.08056803 -0.02670107  0.          0.9847958 ]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 309 is [True, False, False, True, False, False]
State prediction error at timestep 309 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 309 of -1
Current timestep = 310. State = [[-0.3413111  -0.24932295]]. Action = [[0.0542037  0.07379324 0.         0.25311732]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 310 is [True, False, False, True, False, False]
State prediction error at timestep 310 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 310 of -1
Current timestep = 311. State = [[-0.34142372 -0.24717984]]. Action = [[-0.02523804 -0.00383779  0.          0.83044577]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 311 is [True, False, False, True, False, False]
State prediction error at timestep 311 is tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 311 of -1
Current timestep = 312. State = [[-0.33994105 -0.24860571]]. Action = [[ 0.04788034 -0.03605001  0.         -0.9857635 ]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 312 is [True, False, False, True, False, False]
State prediction error at timestep 312 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 312 of -1
Current timestep = 313. State = [[-0.33941108 -0.24731426]]. Action = [[-0.01720522  0.04060692  0.         -0.9548494 ]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 313 is [True, False, False, True, False, False]
State prediction error at timestep 313 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 313 of -1
Current timestep = 314. State = [[-0.3355525  -0.24276535]]. Action = [[0.08777822 0.0611238  0.         0.79398394]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 314 is [True, False, False, True, False, False]
State prediction error at timestep 314 is tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 314 of -1
Current timestep = 315. State = [[-0.32845846 -0.23828295]]. Action = [[ 0.08523423  0.03245718  0.         -0.81842446]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 315 is [True, False, False, True, False, False]
State prediction error at timestep 315 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 315 of -1
Current timestep = 316. State = [[-0.3258471  -0.23166145]]. Action = [[-0.00587521  0.08872607  0.          0.7877555 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 316 is [True, False, False, True, False, False]
State prediction error at timestep 316 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 316 of -1
Current timestep = 317. State = [[-0.3302328  -0.22672664]]. Action = [[-0.07856336  0.02642191  0.          0.8516824 ]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 317 is [True, False, False, True, False, False]
State prediction error at timestep 317 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 317 of 1
Current timestep = 318. State = [[-0.33046368 -0.22023518]]. Action = [[ 0.05748024  0.09126332  0.         -0.47731352]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 318 is [True, False, False, True, False, False]
State prediction error at timestep 318 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 318 of 1
Current timestep = 319. State = [[-0.32832953 -0.2203714 ]]. Action = [[ 0.02083325 -0.09660409  0.         -0.5359838 ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 319 is [True, False, False, True, False, False]
State prediction error at timestep 319 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 319 of 1
Current timestep = 320. State = [[-0.32856154 -0.22526576]]. Action = [[-0.01825113 -0.07457851  0.         -0.56074834]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 320 is [True, False, False, True, False, False]
State prediction error at timestep 320 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 320 of 1
Current timestep = 321. State = [[-0.32642606 -0.22583483]]. Action = [[ 0.04781155  0.0196558   0.         -0.32388437]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 321 is [True, False, False, True, False, False]
State prediction error at timestep 321 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 321 of 1
Current timestep = 322. State = [[-0.32797867 -0.22079837]]. Action = [[-0.06744546  0.08613176  0.          0.46538806]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 322 is [True, False, False, True, False, False]
State prediction error at timestep 322 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 322 of 1
Current timestep = 323. State = [[-0.33225802 -0.21351752]]. Action = [[-0.04457944  0.09319108  0.         -0.23735249]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 323 is [True, False, False, True, False, False]
State prediction error at timestep 323 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 323 of 1
Current timestep = 324. State = [[-0.32968077 -0.21187896]]. Action = [[ 0.09020274 -0.05114913  0.          0.15932965]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 324 is [True, False, False, True, False, False]
State prediction error at timestep 324 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 324 of 1
Current timestep = 325. State = [[-0.32736662 -0.20817278]]. Action = [[-0.02303324  0.09332413  0.          0.09927487]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 325 is [True, False, False, True, False, False]
State prediction error at timestep 325 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 325 of 1
Current timestep = 326. State = [[-0.33028293 -0.20851506]]. Action = [[-0.05189694 -0.07500865  0.         -0.70373446]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 326 is [True, False, False, True, False, False]
State prediction error at timestep 326 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 326 of 1
Current timestep = 327. State = [[-0.334559   -0.20730054]]. Action = [[-0.0543658   0.06167055  0.          0.74466276]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 327 is [True, False, False, True, False, False]
State prediction error at timestep 327 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 327 of 1
Current timestep = 328. State = [[-0.33608526 -0.20649086]]. Action = [[ 0.00718838 -0.02572999  0.         -0.8230425 ]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 328 is [True, False, False, True, False, False]
State prediction error at timestep 328 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 328 of 1
Current timestep = 329. State = [[-0.3325127  -0.20680964]]. Action = [[ 0.06633497 -0.00765049  0.          0.28695476]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 329 is [True, False, False, True, False, False]
State prediction error at timestep 329 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 329 of 1
Current timestep = 330. State = [[-0.3347703  -0.20569173]]. Action = [[-0.09111533  0.01676384  0.         -0.93166804]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 330 is [True, False, False, True, False, False]
State prediction error at timestep 330 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 330 of 1
Current timestep = 331. State = [[-0.34019673 -0.20488793]]. Action = [[-0.05057986  0.00494772  0.          0.6832509 ]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 331 is [True, False, False, True, False, False]
State prediction error at timestep 331 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 331 of 1
Current timestep = 332. State = [[-0.341313   -0.19982311]]. Action = [[0.01914927 0.09539831 0.         0.00762451]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 332 is [True, False, False, True, False, False]
State prediction error at timestep 332 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 332 of 1
Current timestep = 333. State = [[-0.34110078 -0.19426407]]. Action = [[ 8.1521273e-04  4.2509682e-02  0.0000000e+00 -9.5718712e-01]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 333 is [True, False, False, True, False, False]
State prediction error at timestep 333 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 333 of 1
Current timestep = 334. State = [[-0.34367064 -0.19021112]]. Action = [[-0.04325316  0.03584849  0.         -0.57805413]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 334 is [True, False, False, True, False, False]
State prediction error at timestep 334 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 334 of 1
Current timestep = 335. State = [[-0.34895876 -0.18714091]]. Action = [[-0.06368564  0.02367096  0.         -0.6699873 ]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 335 is [True, False, False, True, False, False]
State prediction error at timestep 335 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 335 of 1
Current timestep = 336. State = [[-0.35051808 -0.18636042]]. Action = [[ 0.02759597 -0.01722068  0.          0.04013395]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 336 is [True, False, False, True, False, False]
State prediction error at timestep 336 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 336 of 1
Current timestep = 337. State = [[-0.35513622 -0.18179679]]. Action = [[-0.09319238  0.08770149  0.         -0.3528273 ]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 337 is [True, False, False, True, False, False]
State prediction error at timestep 337 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 337 of 1
Current timestep = 338. State = [[-0.35984424 -0.17415556]]. Action = [[-0.00978045  0.08067212  0.         -0.5749042 ]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 338 is [True, False, False, True, False, False]
State prediction error at timestep 338 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 338 of 1
Current timestep = 339. State = [[-0.36616036 -0.17136551]]. Action = [[-0.08393236 -0.02407994  0.         -0.86312217]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 339 is [True, False, False, True, False, False]
State prediction error at timestep 339 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 339 of 1
Current timestep = 340. State = [[-0.37497148 -0.16924174]]. Action = [[-0.08422594  0.02941901  0.         -0.5667447 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 340 is [True, False, False, True, False, False]
State prediction error at timestep 340 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 340 of 1
Current timestep = 341. State = [[-0.37567937 -0.17108153]]. Action = [[ 0.08818717 -0.09593554  0.         -0.6887468 ]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 341 is [True, False, False, True, False, False]
State prediction error at timestep 341 is tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 341 of -1
Current timestep = 342. State = [[-0.37388453 -0.17266311]]. Action = [[ 0.         0.         0.        -0.3052504]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 342 is [True, False, False, True, False, False]
State prediction error at timestep 342 is tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 342 of -1
Current timestep = 343. State = [[-0.3693309  -0.17205927]]. Action = [[ 0.09242316 -0.00474837  0.         -0.49818105]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 343 is [True, False, False, True, False, False]
State prediction error at timestep 343 is tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 343 of -1
Current timestep = 344. State = [[-0.3674376  -0.16857958]]. Action = [[-0.02060948  0.05479652  0.         -0.770513  ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 344 is [True, False, False, True, False, False]
State prediction error at timestep 344 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 344 of -1
Current timestep = 345. State = [[-0.36421785 -0.16209912]]. Action = [[ 0.07751177  0.08062012  0.         -0.65240544]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 345 is [True, False, False, True, False, False]
State prediction error at timestep 345 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 345 of -1
Current timestep = 346. State = [[-0.36067522 -0.15917744]]. Action = [[ 0.0282963  -0.01719715  0.         -0.9760148 ]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 346 is [True, False, False, True, False, False]
State prediction error at timestep 346 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 346 of -1
Current timestep = 347. State = [[-0.35580915 -0.15963368]]. Action = [[ 0.0813188  -0.02883878  0.         -0.8389589 ]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 347 is [True, False, False, True, False, False]
State prediction error at timestep 347 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 347 of 1
Current timestep = 348. State = [[-0.35340306 -0.15530759]]. Action = [[-0.00423596  0.08451242  0.          0.03115726]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 348 is [True, False, False, True, False, False]
State prediction error at timestep 348 is tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 348 of 1
Current timestep = 349. State = [[-0.3518426  -0.15638494]]. Action = [[ 0.04316873 -0.09877482  0.         -0.17810899]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 349 is [True, False, False, True, False, False]
State prediction error at timestep 349 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 349 of 1
Current timestep = 350. State = [[-0.3523307  -0.16106173]]. Action = [[-0.03467719 -0.04915036  0.          0.55769265]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 350 is [True, False, False, True, False, False]
State prediction error at timestep 350 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 350 of 1
Current timestep = 351. State = [[-0.34911844 -0.15851687]]. Action = [[ 0.0852141   0.09235182  0.         -0.5206354 ]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 351 is [True, False, False, True, False, False]
State prediction error at timestep 351 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 351 of 1
Current timestep = 352. State = [[-0.34362954 -0.15353504]]. Action = [[ 0.0478613   0.03816398  0.         -0.05015159]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 352 is [True, False, False, True, False, False]
State prediction error at timestep 352 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 352 of 1
Current timestep = 353. State = [[-0.34592968 -0.14766423]]. Action = [[-0.09086522  0.08681954  0.          0.152542  ]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 353 is [True, False, False, True, False, False]
State prediction error at timestep 353 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 353 of 1
Current timestep = 354. State = [[-0.35055074 -0.146794  ]]. Action = [[-0.03749446 -0.03966061  0.         -0.33203328]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 354 is [True, False, False, True, False, False]
State prediction error at timestep 354 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 354 of 1
Current timestep = 355. State = [[-0.3476249  -0.14364652]]. Action = [[0.09069941 0.08198034 0.         0.53764176]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 355 is [True, False, False, True, False, False]
State prediction error at timestep 355 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 355 of 1
Current timestep = 356. State = [[-0.3477681 -0.139469 ]]. Action = [[-0.05976681  0.01620601  0.          0.32378054]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 356 is [True, False, False, True, False, False]
State prediction error at timestep 356 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 356 of 1
Current timestep = 357. State = [[-0.34824258 -0.13628577]]. Action = [[ 0.02208979  0.03495116  0.         -0.9070938 ]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 357 is [True, False, False, True, False, False]
State prediction error at timestep 357 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 357 of 1
Current timestep = 358. State = [[-0.34414867 -0.13127531]]. Action = [[ 0.06997127  0.05285118  0.         -0.86334   ]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 358 is [True, False, False, True, False, False]
State prediction error at timestep 358 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 358 of 1
Current timestep = 359. State = [[-0.3394347  -0.12899393]]. Action = [[ 0.05006259 -0.02122183  0.          0.7864944 ]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 359 is [True, False, False, True, False, False]
State prediction error at timestep 359 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 359 of 1
Current timestep = 360. State = [[-0.33705673 -0.12468012]]. Action = [[0.01282112 0.06645858 0.         0.42394733]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 360 is [True, False, False, False, True, False]
State prediction error at timestep 360 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 360 of 1
Current timestep = 361. State = [[-0.3326338  -0.11981328]]. Action = [[0.07948741 0.02731062 0.         0.8745794 ]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 361 is [True, False, False, False, True, False]
State prediction error at timestep 361 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 361 of 1
Current timestep = 362. State = [[-0.32925364 -0.11563563]]. Action = [[ 0.01946503  0.03110195  0.         -0.40827954]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 362 is [True, False, False, False, True, False]
State prediction error at timestep 362 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 362 of 1
Current timestep = 363. State = [[-0.3330361  -0.10867912]]. Action = [[-0.09357686  0.09752811  0.          0.87224674]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 363 is [True, False, False, False, True, False]
State prediction error at timestep 363 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 363 of 1
Current timestep = 364. State = [[-0.33211988 -0.10742404]]. Action = [[ 0.09349801 -0.06911832  0.         -0.6725181 ]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 364 is [True, False, False, False, True, False]
State prediction error at timestep 364 is tensor(1.9748e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 364 of 1
Current timestep = 365. State = [[-0.3266948  -0.10944816]]. Action = [[ 0.04101951 -0.02542837  0.          0.46559894]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 365 is [True, False, False, False, True, False]
State prediction error at timestep 365 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 365 of 1
Current timestep = 366. State = [[-0.32625225 -0.1097336 ]]. Action = [[-4.6843290e-02  4.6785176e-04  0.0000000e+00 -7.0419776e-01]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 366 is [True, False, False, False, True, False]
State prediction error at timestep 366 is tensor(4.6573e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 366 of 1
Current timestep = 367. State = [[-0.3230333  -0.10625532]]. Action = [[ 0.06352762  0.06305612  0.         -0.10898799]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 367 is [True, False, False, False, True, False]
State prediction error at timestep 367 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 367 of 1
Current timestep = 368. State = [[-0.3235779  -0.10114732]]. Action = [[-0.07160128  0.05324031  0.         -0.522967  ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 368 is [True, False, False, False, True, False]
State prediction error at timestep 368 is tensor(4.2477e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 368 of 1
Current timestep = 369. State = [[-0.32559082 -0.09590805]]. Action = [[-0.01973613  0.06104209  0.         -0.5245439 ]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 369 is [True, False, False, False, True, False]
State prediction error at timestep 369 is tensor(3.6375e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 369 of 1
Current timestep = 370. State = [[-0.32112804 -0.08876736]]. Action = [[ 0.09519783  0.08152831  0.         -0.44177294]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 370 is [True, False, False, False, True, False]
State prediction error at timestep 370 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 370 of 1
Current timestep = 371. State = [[-0.31869638 -0.08133771]]. Action = [[-0.00942379  0.06406327  0.          0.236714  ]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 371 is [True, False, False, False, True, False]
State prediction error at timestep 371 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 371 of 1
Current timestep = 372. State = [[-0.31530774 -0.08139057]]. Action = [[ 0.07035952 -0.07621284  0.          0.57324433]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 372 is [True, False, False, False, True, False]
State prediction error at timestep 372 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 372 of 1
Current timestep = 373. State = [[-0.31547332 -0.08489083]]. Action = [[-0.05778911 -0.05080187  0.         -0.84466916]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 373 is [True, False, False, False, True, False]
State prediction error at timestep 373 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 373 of 1
Current timestep = 374. State = [[-0.31252092 -0.08609883]]. Action = [[ 0.07799614 -0.00652297  0.          0.5209677 ]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 374 is [True, False, False, False, True, False]
State prediction error at timestep 374 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 374 of 1
Current timestep = 375. State = [[-0.31194577 -0.08898249]]. Action = [[-0.04954008 -0.06305639  0.         -0.81894654]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 375 is [True, False, False, False, True, False]
State prediction error at timestep 375 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 375 of 1
Current timestep = 376. State = [[-0.31551448 -0.08830158]]. Action = [[-0.06805245  0.05330712  0.          0.4462446 ]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 376 is [True, False, False, False, True, False]
State prediction error at timestep 376 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 376 of 1
Current timestep = 377. State = [[-0.31507862 -0.08273599]]. Action = [[ 0.03604276  0.08266408  0.         -0.10400516]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 377 is [True, False, False, False, True, False]
State prediction error at timestep 377 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 377 of 1
Current timestep = 378. State = [[-0.3133179 -0.0765224]]. Action = [[0.01398145 0.06158305 0.         0.12974727]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 378 is [True, False, False, False, True, False]
State prediction error at timestep 378 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 378 of 1
Current timestep = 379. State = [[-0.31622747 -0.07068202]]. Action = [[-0.06695512  0.06182719  0.          0.5742948 ]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 379 is [True, False, False, False, True, False]
State prediction error at timestep 379 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 379 of 1
Current timestep = 380. State = [[-0.32285413 -0.06879848]]. Action = [[-0.09288567 -0.0153203   0.         -0.04454982]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 380 is [True, False, False, False, True, False]
State prediction error at timestep 380 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 380 of 1
Current timestep = 381. State = [[-0.32831845 -0.07046299]]. Action = [[-0.04991574 -0.03814845  0.         -0.74164045]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 381 is [True, False, False, False, True, False]
State prediction error at timestep 381 is tensor(7.1721e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 381 of 1
Current timestep = 382. State = [[-0.33058798 -0.07604808]]. Action = [[-0.0068716  -0.09730854  0.          0.46444273]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 382 is [True, False, False, False, True, False]
State prediction error at timestep 382 is tensor(8.3824e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 382 of 1
Current timestep = 383. State = [[-0.33274156 -0.07421114]]. Action = [[-0.02740809  0.09516377  0.         -0.86625004]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 383 is [True, False, False, False, True, False]
State prediction error at timestep 383 is tensor(1.6730e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 383 of -1
Current timestep = 384. State = [[-0.33785692 -0.07117264]]. Action = [[-0.07351677  0.00107513  0.          0.6269305 ]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 384 is [True, False, False, False, True, False]
State prediction error at timestep 384 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 384 of -1
Current timestep = 385. State = [[-0.34162262 -0.07415923]]. Action = [[-0.01636714 -0.06845174  0.         -0.33061993]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 385 is [True, False, False, False, True, False]
State prediction error at timestep 385 is tensor(4.0869e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 385 of -1
Current timestep = 386. State = [[-0.3459845  -0.08014416]]. Action = [[-0.06009216 -0.0783395   0.         -0.49138713]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 386 is [True, False, False, False, True, False]
State prediction error at timestep 386 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 386 of -1
Current timestep = 387. State = [[-0.35227814 -0.0826839 ]]. Action = [[-0.0761219   0.00766591  0.         -0.762545  ]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 387 is [True, False, False, False, True, False]
State prediction error at timestep 387 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 387 of -1
Current timestep = 388. State = [[-0.3571254  -0.08090865]]. Action = [[-0.03015788  0.044712    0.          0.06328571]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 388 is [True, False, False, False, True, False]
State prediction error at timestep 388 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 388 of -1
Current timestep = 389. State = [[-0.35669893 -0.08267765]]. Action = [[ 0.06074924 -0.060386    0.          0.59624565]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 389 is [True, False, False, False, True, False]
State prediction error at timestep 389 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 389 of -1
Current timestep = 390. State = [[-0.35778764 -0.08322734]]. Action = [[-0.03359918  0.02702064  0.         -0.02687019]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 390 is [True, False, False, False, True, False]
State prediction error at timestep 390 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 390 of -1
Current timestep = 391. State = [[-0.35723957 -0.08366305]]. Action = [[ 0.05541819 -0.02073785  0.          0.63588846]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 391 is [True, False, False, False, True, False]
State prediction error at timestep 391 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 391 of -1
Current timestep = 392. State = [[-0.3602455  -0.08061332]]. Action = [[-0.07257573  0.07625592  0.         -0.65980315]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 392 is [True, False, False, False, True, False]
State prediction error at timestep 392 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 392 of -1
Current timestep = 393. State = [[-0.36067316 -0.07559773]]. Action = [[ 0.07229107  0.04717826  0.         -0.3784846 ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 393 is [True, False, False, False, True, False]
State prediction error at timestep 393 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 393 of -1
Current timestep = 394. State = [[-0.36021057 -0.07050848]]. Action = [[0.00358919 0.05374046 0.         0.31748796]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 394 is [True, False, False, False, True, False]
State prediction error at timestep 394 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 394 of -1
Current timestep = 395. State = [[-0.361047   -0.06785045]]. Action = [[0.01111697 0.00140007 0.         0.1361767 ]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 395 is [True, False, False, False, True, False]
State prediction error at timestep 395 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 395 of -1
Current timestep = 396. State = [[-0.35770324 -0.06931544]]. Action = [[ 0.09047156 -0.05165396  0.         -0.60222423]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 396 is [True, False, False, False, True, False]
State prediction error at timestep 396 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 396 of -1
Current timestep = 397. State = [[-0.35704473 -0.06750291]]. Action = [[-0.02464108  0.05222548  0.         -0.22866684]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 397 is [True, False, False, False, True, False]
State prediction error at timestep 397 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 397 of -1
Current timestep = 398. State = [[-0.36345878 -0.06679197]]. Action = [[-0.09820788 -0.02489801  0.         -0.0237906 ]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 398 is [True, False, False, False, True, False]
State prediction error at timestep 398 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 398 of -1
Current timestep = 399. State = [[-0.36839202 -0.06762917]]. Action = [[-0.02464859 -0.00643272  0.         -0.15042043]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 399 is [True, False, False, False, True, False]
State prediction error at timestep 399 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 399 of -1
Current timestep = 400. State = [[-0.3715103  -0.07231236]]. Action = [[-0.03110863 -0.09053553  0.         -0.1752963 ]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 400 is [True, False, False, False, True, False]
State prediction error at timestep 400 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 400 of -1
Current timestep = 401. State = [[-0.3711502  -0.07740065]]. Action = [[ 0.03543661 -0.04430705  0.         -0.978929  ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 401 is [True, False, False, False, True, False]
State prediction error at timestep 401 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 401 of -1
Current timestep = 402. State = [[-0.3742754  -0.07843508]]. Action = [[-0.08281453  0.01840851  0.          0.7753285 ]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 402 is [True, False, False, False, True, False]
State prediction error at timestep 402 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 402 of -1
Current timestep = 403. State = [[-0.37561014 -0.08268636]]. Action = [[ 0.03220373 -0.08453704  0.         -0.633093  ]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 403 is [True, False, False, False, True, False]
State prediction error at timestep 403 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 403 of -1
Current timestep = 404. State = [[-0.37195942 -0.08528043]]. Action = [[ 0.06050149  0.00982449  0.         -0.4336295 ]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 404 is [True, False, False, False, True, False]
State prediction error at timestep 404 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 404 of -1
Current timestep = 405. State = [[-0.37076864 -0.08260424]]. Action = [[-0.01341359  0.05971631  0.         -0.5144539 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 405 is [True, False, False, False, True, False]
State prediction error at timestep 405 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 405 of -1
Current timestep = 406. State = [[-0.37028584 -0.08318984]]. Action = [[ 0.01820645 -0.03934888  0.         -0.6038654 ]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 406 is [True, False, False, False, True, False]
State prediction error at timestep 406 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 406 of -1
Current timestep = 407. State = [[-0.37293282 -0.0817536 ]]. Action = [[-0.06210691  0.06156745  0.         -0.41344577]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 407 is [True, False, False, False, True, False]
State prediction error at timestep 407 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 407 of -1
Current timestep = 408. State = [[-0.3713191  -0.07500954]]. Action = [[0.08166911 0.09965379 0.         0.6240219 ]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 408 is [True, False, False, False, True, False]
State prediction error at timestep 408 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 408 of -1
Current timestep = 409. State = [[-0.37224293 -0.06759054]]. Action = [[-0.04954879  0.07238539  0.         -0.494201  ]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 409 is [True, False, False, False, True, False]
State prediction error at timestep 409 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 409 of -1
Current timestep = 410. State = [[-0.37427437 -0.06626212]]. Action = [[ 0.00511734 -0.03570984  0.         -0.4895352 ]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 410 is [True, False, False, False, True, False]
State prediction error at timestep 410 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 410 of -1
Current timestep = 411. State = [[-0.37592044 -0.06693225]]. Action = [[-0.0163701  -0.00868346  0.          0.72711253]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 411 is [True, False, False, False, True, False]
State prediction error at timestep 411 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 411 of -1
Current timestep = 412. State = [[-0.3752883  -0.07124913]]. Action = [[ 0.03647319 -0.090629    0.          0.40493643]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 412 is [True, False, False, False, True, False]
State prediction error at timestep 412 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 412 of -1
Current timestep = 413. State = [[-0.37185335 -0.07655916]]. Action = [[ 0.05418732 -0.05800742  0.         -0.59176034]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 413 is [True, False, False, False, True, False]
State prediction error at timestep 413 is tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 413 of -1
Current timestep = 414. State = [[-0.3687354  -0.08213862]]. Action = [[ 0.02414469 -0.07338323  0.          0.8482313 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 414 is [True, False, False, False, True, False]
State prediction error at timestep 414 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 414 of -1
Current timestep = 415. State = [[-0.36615258 -0.08093187]]. Action = [[ 0.02422067  0.07927722  0.         -0.8952517 ]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 415 is [True, False, False, False, True, False]
State prediction error at timestep 415 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 415 of -1
Current timestep = 416. State = [[-0.36704516 -0.07746512]]. Action = [[-0.04434341  0.0324539   0.         -0.39339733]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 416 is [True, False, False, False, True, False]
State prediction error at timestep 416 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 416 of -1
Current timestep = 417. State = [[-0.36501518 -0.07783304]]. Action = [[ 0.0606854  -0.02421994  0.          0.58192885]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 417 is [True, False, False, False, True, False]
State prediction error at timestep 417 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 417 of -1
Current timestep = 418. State = [[-0.3636302  -0.08325421]]. Action = [[-0.01796015 -0.08833417  0.          0.17360532]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 418 is [True, False, False, False, True, False]
State prediction error at timestep 418 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 418 of -1
Current timestep = 419. State = [[-0.36469734 -0.08346951]]. Action = [[-0.02809156  0.06487196  0.          0.28410518]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 419 is [True, False, False, False, True, False]
State prediction error at timestep 419 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 419 of -1
Current timestep = 420. State = [[-0.3610776  -0.08514349]]. Action = [[ 0.08343749 -0.06149879  0.         -0.03326392]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 420 is [True, False, False, False, True, False]
State prediction error at timestep 420 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 420 of -1
Current timestep = 421. State = [[-0.35335094 -0.08335476]]. Action = [[0.08828472 0.07553151 0.         0.4424677 ]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 421 is [True, False, False, False, True, False]
State prediction error at timestep 421 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 421 of -1
Current timestep = 422. State = [[-0.34916678 -0.08531331]]. Action = [[ 0.00424719 -0.09410384  0.         -0.23222119]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 422 is [True, False, False, False, True, False]
State prediction error at timestep 422 is tensor(5.8355e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 422 of -1
Current timestep = 423. State = [[-0.34300286 -0.09066224]]. Action = [[ 0.09548659 -0.04431401  0.          0.5793493 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 423 is [True, False, False, False, True, False]
State prediction error at timestep 423 is tensor(3.2962e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 423 of -1
Current timestep = 424. State = [[-0.3430855  -0.09435311]]. Action = [[-0.09286474 -0.0236211   0.         -0.58947635]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 424 is [True, False, False, False, True, False]
State prediction error at timestep 424 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 424 of 1
Current timestep = 425. State = [[-0.34127176 -0.09345325]]. Action = [[ 0.07257561  0.05231967  0.         -0.6621266 ]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 425 is [True, False, False, False, True, False]
State prediction error at timestep 425 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 425 of 1
Current timestep = 426. State = [[-0.33471018 -0.08738515]]. Action = [[0.08573415 0.09249999 0.         0.77439904]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 426 is [True, False, False, False, True, False]
State prediction error at timestep 426 is tensor(4.9042e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 426 of 1
Current timestep = 427. State = [[-0.33500454 -0.08057088]]. Action = [[-0.06133439  0.07375558  0.          0.46814716]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 427 is [True, False, False, False, True, False]
State prediction error at timestep 427 is tensor(2.3531e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 427 of 1
Current timestep = 428. State = [[-0.33801728 -0.07472578]]. Action = [[-0.02267341  0.062258    0.          0.33298886]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 428 is [True, False, False, False, True, False]
State prediction error at timestep 428 is tensor(5.7776e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 428 of 1
Current timestep = 429. State = [[-0.3348801  -0.06981069]]. Action = [[0.09328122 0.03758918 0.         0.8471737 ]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 429 is [True, False, False, False, True, False]
State prediction error at timestep 429 is tensor(8.5004e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 429 of 1
Current timestep = 430. State = [[-0.3332966  -0.06807525]]. Action = [[-0.01066098 -0.01776531  0.          0.7357695 ]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 430 is [True, False, False, False, True, False]
State prediction error at timestep 430 is tensor(6.1142e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 430 of 1
Current timestep = 431. State = [[-0.33619854 -0.06838299]]. Action = [[-0.05220335 -0.01765047  0.         -0.8424474 ]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 431 is [True, False, False, False, True, False]
State prediction error at timestep 431 is tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 431 of 1
Current timestep = 432. State = [[-0.33312872 -0.06351533]]. Action = [[0.09818102 0.09185078 0.         0.29223382]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 432 is [True, False, False, False, True, False]
State prediction error at timestep 432 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 432 of 1
Current timestep = 433. State = [[-0.33446822 -0.06299283]]. Action = [[-0.08967    -0.0953453   0.         -0.26143277]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 433 is [True, False, False, False, True, False]
State prediction error at timestep 433 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 433 of 1
Current timestep = 434. State = [[-0.33421534 -0.06190466]]. Action = [[ 0.053504    0.0628456   0.         -0.26803315]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 434 is [True, False, False, False, True, False]
State prediction error at timestep 434 is tensor(2.1405e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 434 of 1
Current timestep = 435. State = [[-0.3287528  -0.06149152]]. Action = [[ 0.08265144 -0.04493952  0.          0.5394932 ]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 435 is [True, False, False, False, True, False]
State prediction error at timestep 435 is tensor(5.9535e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 435 of 1
Current timestep = 436. State = [[-0.3298709  -0.05918123]]. Action = [[-0.08852535  0.0594661   0.          0.37107468]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 436 is [True, False, False, False, True, False]
State prediction error at timestep 436 is tensor(2.0617e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 436 of 1
Current timestep = 437. State = [[-0.33363256 -0.05535156]]. Action = [[-0.0210565   0.02986706  0.          0.8800726 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 437 is [True, False, False, False, True, False]
State prediction error at timestep 437 is tensor(7.2053e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 437 of 1
Current timestep = 438. State = [[-0.33458713 -0.05011649]]. Action = [[ 0.00970642  0.06793606  0.         -0.8843953 ]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 438 is [True, False, False, False, True, False]
State prediction error at timestep 438 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 438 of 1
Current timestep = 439. State = [[-0.3384069  -0.04385557]]. Action = [[-0.06462158  0.06367119  0.         -0.71291256]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 439 is [True, False, False, False, True, False]
State prediction error at timestep 439 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 439 of 1
Current timestep = 440. State = [[-0.33885288 -0.04566438]]. Action = [[ 0.04755376 -0.09910499  0.          0.92139626]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 440 is [True, False, False, False, True, False]
State prediction error at timestep 440 is tensor(3.5788e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 440 of 1
Current timestep = 441. State = [[-0.3358073  -0.04359841]]. Action = [[ 0.0468219   0.08423776  0.         -0.7827602 ]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 441 is [True, False, False, False, True, False]
State prediction error at timestep 441 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 441 of 1
Current timestep = 442. State = [[-0.3379698  -0.04320439]]. Action = [[-0.06895987 -0.06067714  0.         -0.5489817 ]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 442 is [True, False, False, False, True, False]
State prediction error at timestep 442 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 442 of 1
Current timestep = 443. State = [[-0.34073552 -0.04281869]]. Action = [[-0.0211812   0.02996335  0.          0.5385746 ]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 443 is [True, False, False, False, True, False]
State prediction error at timestep 443 is tensor(1.1103e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 443 of 1
Current timestep = 444. State = [[-0.3389464  -0.04347347]]. Action = [[ 0.05055072 -0.03887789  0.         -0.6576834 ]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 444 is [True, False, False, False, True, False]
State prediction error at timestep 444 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 444 of 1
Current timestep = 445. State = [[-0.34028322 -0.04593284]]. Action = [[-0.06236258 -0.03248449  0.         -0.6130425 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 445 is [True, False, False, False, True, False]
State prediction error at timestep 445 is tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 445 of 1
Current timestep = 446. State = [[-0.34610066 -0.04401492]]. Action = [[-0.09107473  0.06017027  0.         -0.0768792 ]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 446 is [True, False, False, False, True, False]
State prediction error at timestep 446 is tensor(9.9006e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 446 of 1
Current timestep = 447. State = [[-0.3480879  -0.04540695]]. Action = [[ 0.0167621  -0.06260465  0.         -0.43878102]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 447 is [True, False, False, False, True, False]
State prediction error at timestep 447 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 447 of 1
Current timestep = 448. State = [[-0.3447123  -0.05037772]]. Action = [[ 0.06074681 -0.06211101  0.          0.17896211]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 448 is [True, False, False, False, True, False]
State prediction error at timestep 448 is tensor(1.4461e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 448 of 1
Current timestep = 449. State = [[-0.34711376 -0.05190881]]. Action = [[-0.09575676  0.0176211   0.         -0.5004212 ]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 449 is [True, False, False, False, True, False]
State prediction error at timestep 449 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 449 of 1
Current timestep = 450. State = [[-0.3492127 -0.0507977]]. Action = [[0.01908363 0.02215566 0.         0.8399682 ]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 450 is [True, False, False, False, True, False]
State prediction error at timestep 450 is tensor(3.1706e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 450 of 1
Current timestep = 451. State = [[-0.34772623 -0.05250043]]. Action = [[ 0.0362437  -0.04323096  0.         -0.2712747 ]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 451 is [True, False, False, False, True, False]
State prediction error at timestep 451 is tensor(4.4974e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 451 of 1
Current timestep = 452. State = [[-0.3497611  -0.05763308]]. Action = [[-0.05379926 -0.06998867  0.         -0.3114015 ]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 452 is [True, False, False, False, True, False]
State prediction error at timestep 452 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 452 of 1
Current timestep = 453. State = [[-0.35192192 -0.06475958]]. Action = [[-0.01015978 -0.08465683  0.          0.56559443]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 453 is [True, False, False, False, True, False]
State prediction error at timestep 453 is tensor(6.3360e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 453 of 1
Current timestep = 454. State = [[-0.35032558 -0.06978922]]. Action = [[ 0.04059298 -0.0276638   0.          0.82170033]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 454 is [True, False, False, False, True, False]
State prediction error at timestep 454 is tensor(2.1185e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 454 of 1
Current timestep = 455. State = [[-0.3519702  -0.06820331]]. Action = [[-0.05726288  0.07464296  0.          0.6697918 ]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 455 is [True, False, False, False, True, False]
State prediction error at timestep 455 is tensor(1.2141e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 455 of 1
Current timestep = 456. State = [[-0.35212836 -0.06786359]]. Action = [[ 0.04208685 -0.01928491  0.          0.13718176]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 456 is [True, False, False, False, True, False]
State prediction error at timestep 456 is tensor(3.8155e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 456 of 1
Current timestep = 457. State = [[-0.3506036  -0.06707719]]. Action = [[ 0.01978737  0.03651657  0.         -0.98650044]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 457 is [True, False, False, False, True, False]
State prediction error at timestep 457 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 457 of 1
Current timestep = 458. State = [[-0.3509502  -0.06255631]]. Action = [[-0.00407169  0.07499705  0.          0.81799483]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 458 is [True, False, False, False, True, False]
State prediction error at timestep 458 is tensor(2.6371e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 458 of 1
Current timestep = 459. State = [[-0.35602424 -0.05771558]]. Action = [[-0.08093302  0.05173285  0.         -0.19562256]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 459 is [True, False, False, False, True, False]
State prediction error at timestep 459 is tensor(4.1661e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 459 of 1
Current timestep = 460. State = [[-0.35918796 -0.05945051]]. Action = [[ 0.00593746 -0.07124396  0.          0.87568986]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 460 is [True, False, False, False, True, False]
State prediction error at timestep 460 is tensor(7.8182e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 460 of 1
Current timestep = 461. State = [[-0.35881212 -0.06159326]]. Action = [[ 0.02299535 -0.00572252  0.         -0.9440286 ]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 461 is [True, False, False, False, True, False]
State prediction error at timestep 461 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 461 of 1
Current timestep = 462. State = [[-0.36017552 -0.06232072]]. Action = [[-0.02919327 -0.01189407  0.          0.6138197 ]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 462 is [True, False, False, False, True, False]
State prediction error at timestep 462 is tensor(4.3835e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 462 of 1
Current timestep = 463. State = [[-0.36480176 -0.06541677]]. Action = [[-0.0701987  -0.05279093  0.          0.74394894]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 463 is [True, False, False, False, True, False]
State prediction error at timestep 463 is tensor(5.3785e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 463 of 1
Current timestep = 464. State = [[-0.36278626 -0.06644163]]. Action = [[0.09277356 0.01380739 0.         0.6194763 ]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 464 is [True, False, False, False, True, False]
State prediction error at timestep 464 is tensor(3.1197e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 464 of 1
Current timestep = 465. State = [[-0.36249587 -0.06316521]]. Action = [[-0.04306851  0.05796074  0.          0.88289034]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 465 is [True, False, False, False, True, False]
State prediction error at timestep 465 is tensor(3.0429e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 465 of 1
Current timestep = 466. State = [[-0.3596392  -0.05715142]]. Action = [[0.09539027 0.07687963 0.         0.5649636 ]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 466 is [True, False, False, False, True, False]
State prediction error at timestep 466 is tensor(8.1809e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 466 of 1
Current timestep = 467. State = [[-0.3608799  -0.05008982]]. Action = [[-0.06452931  0.07923052  0.          0.45405507]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 467 is [True, False, False, False, True, False]
State prediction error at timestep 467 is tensor(8.9037e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 467 of 1
Current timestep = 468. State = [[-0.36709756 -0.04922966]]. Action = [[-0.06963916 -0.04830101  0.         -0.4313501 ]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 468 is [True, False, False, False, True, False]
State prediction error at timestep 468 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 468 of -1
Current timestep = 469. State = [[-0.37075844 -0.05028458]]. Action = [[-0.01270101 -0.00704209  0.          0.9055071 ]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 469 is [True, False, False, False, True, False]
State prediction error at timestep 469 is tensor(5.3748e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 469 of -1
Current timestep = 470. State = [[-0.37448752 -0.05397449]]. Action = [[-0.05121572 -0.07734756  0.         -0.8451885 ]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 470 is [True, False, False, False, True, False]
State prediction error at timestep 470 is tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 470 of -1
Current timestep = 471. State = [[-0.37992436 -0.0545903 ]]. Action = [[-0.07054339  0.03158893  0.         -0.46379066]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 471 is [True, False, False, False, True, False]
State prediction error at timestep 471 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 471 of -1
Current timestep = 472. State = [[-0.38267836 -0.05367252]]. Action = [[ 0.          0.          0.         -0.28242242]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 472 is [True, False, False, False, True, False]
State prediction error at timestep 472 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 472 of -1
Current timestep = 473. State = [[-0.38357148 -0.05337537]]. Action = [[0.        0.        0.        0.8484459]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 473 is [True, False, False, False, True, False]
State prediction error at timestep 473 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 473 of -1
Current timestep = 474. State = [[-0.38436556 -0.05312146]]. Action = [[ 0.         0.         0.        -0.4921195]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 474 is [True, False, False, False, True, False]
State prediction error at timestep 474 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 474 of -1
Current timestep = 475. State = [[-0.38513297 -0.05291117]]. Action = [[ 0.          0.          0.         -0.81432533]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 475 is [True, False, False, False, True, False]
State prediction error at timestep 475 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 475 of -1
Current timestep = 476. State = [[-0.38585418 -0.05274604]]. Action = [[ 0.         0.         0.        -0.4401306]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 476 is [True, False, False, False, True, False]
State prediction error at timestep 476 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 476 of -1
Current timestep = 477. State = [[-0.3865079  -0.05261452]]. Action = [[ 0.          0.          0.         -0.46802294]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 477 is [True, False, False, False, True, False]
State prediction error at timestep 477 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 477 of -1
Current timestep = 478. State = [[-0.38708097 -0.05251304]]. Action = [[0.        0.        0.        0.4120927]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 478 is [True, False, False, False, True, False]
State prediction error at timestep 478 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 478 of -1
Current timestep = 479. State = [[-0.38756537 -0.05243751]]. Action = [[ 0.          0.          0.         -0.37900615]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 479 is [True, False, False, False, True, False]
State prediction error at timestep 479 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 479 of -1
Current timestep = 480. State = [[-0.38795707 -0.05238288]]. Action = [[0.        0.        0.        0.3800757]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 480 is [True, False, False, False, True, False]
State prediction error at timestep 480 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 480 of -1
Current timestep = 481. State = [[-0.3882534  -0.05234456]]. Action = [[ 0.         0.         0.        -0.9230174]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 481 is [True, False, False, False, True, False]
State prediction error at timestep 481 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 481 of -1
Current timestep = 482. State = [[-0.38844094 -0.05232546]]. Action = [[ 0.         0.         0.        -0.8872874]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 482 is [True, False, False, False, True, False]
State prediction error at timestep 482 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 482 of -1
Current timestep = 483. State = [[-0.38857007 -0.05230615]]. Action = [[0.        0.        0.        0.7449068]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 483 is [True, False, False, False, True, False]
State prediction error at timestep 483 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 483 of -1
Current timestep = 484. State = [[-0.38866395 -0.05228337]]. Action = [[0.        0.        0.        0.8700433]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 484 is [True, False, False, False, True, False]
State prediction error at timestep 484 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 484 of -1
Current timestep = 485. State = [[-0.38873187 -0.05226551]]. Action = [[0.         0.         0.         0.06517899]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 485 is [True, False, False, False, True, False]
State prediction error at timestep 485 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 485 of -1
Current timestep = 486. State = [[-0.38879052 -0.0522497 ]]. Action = [[0.         0.         0.         0.46729517]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 486 is [True, False, False, False, True, False]
State prediction error at timestep 486 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 486 of -1
Current timestep = 487. State = [[-0.3888418  -0.05223599]]. Action = [[0.         0.         0.         0.65333235]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 487 is [True, False, False, False, True, False]
State prediction error at timestep 487 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 487 of -1
Current timestep = 488. State = [[-0.38888356 -0.05222497]]. Action = [[ 0.          0.          0.         -0.21039438]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 488 is [True, False, False, False, True, False]
State prediction error at timestep 488 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 488 of -1
Current timestep = 489. State = [[-0.38891667 -0.05221638]]. Action = [[ 0.          0.          0.         -0.63839847]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 489 is [True, False, False, False, True, False]
State prediction error at timestep 489 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 489 of -1
Current timestep = 490. State = [[-0.38894272 -0.05220976]]. Action = [[0.        0.        0.        0.9391186]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 490 is [True, False, False, False, True, False]
State prediction error at timestep 490 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 490 of -1
Current timestep = 491. State = [[-0.38896313 -0.0522047 ]]. Action = [[ 0.          0.          0.         -0.64867973]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 491 is [True, False, False, False, True, False]
State prediction error at timestep 491 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 491 of -1
Current timestep = 492. State = [[-0.3889792  -0.05220084]]. Action = [[ 0.         0.         0.        -0.4886474]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 492 is [True, False, False, False, True, False]
State prediction error at timestep 492 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 492 of -1
Current timestep = 493. State = [[-0.38899186 -0.05219791]]. Action = [[0.        0.        0.        0.7330153]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 493 is [True, False, False, False, True, False]
State prediction error at timestep 493 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 493 of -1
Current timestep = 494. State = [[-0.38900197 -0.05219568]]. Action = [[0.        0.        0.        0.5535165]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 494 is [True, False, False, False, True, False]
State prediction error at timestep 494 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 494 of -1
Current timestep = 495. State = [[-0.38901  -0.052194]]. Action = [[ 0.          0.          0.         -0.61176157]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 495 is [True, False, False, False, True, False]
State prediction error at timestep 495 is tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 495 of -1
Current timestep = 496. State = [[-0.38901657 -0.05219271]]. Action = [[0.        0.        0.        0.7388406]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 496 is [True, False, False, False, True, False]
State prediction error at timestep 496 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 496 of -1
Current timestep = 497. State = [[-0.3890224  -0.05219156]]. Action = [[0.         0.         0.         0.37010074]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 497 is [True, False, False, False, True, False]
State prediction error at timestep 497 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 497 of -1
Current timestep = 498. State = [[-0.38902792 -0.05219045]]. Action = [[ 0.         0.         0.        -0.7195555]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 498 is [True, False, False, False, True, False]
State prediction error at timestep 498 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 498 of -1
Current timestep = 499. State = [[-0.38903314 -0.05218937]]. Action = [[0.         0.         0.         0.06703687]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 499 is [True, False, False, False, True, False]
State prediction error at timestep 499 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 499 of -1
Current timestep = 500. State = [[-0.3890381  -0.05218831]]. Action = [[0.         0.         0.         0.49631822]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 500 is [True, False, False, False, True, False]
State prediction error at timestep 500 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 500 of -1
Current timestep = 501. State = [[-0.3890428  -0.05218727]]. Action = [[0.        0.        0.        0.3264674]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 501 is [True, False, False, False, True, False]
State prediction error at timestep 501 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 501 of -1
Current timestep = 502. State = [[-0.38904727 -0.05218626]]. Action = [[ 0.         0.         0.        -0.7787515]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 502 is [True, False, False, False, True, False]
State prediction error at timestep 502 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 502 of -1
Current timestep = 503. State = [[-0.38905153 -0.05218527]]. Action = [[0.         0.         0.         0.48255038]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 503 is [True, False, False, False, True, False]
State prediction error at timestep 503 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 503 of -1
Current timestep = 504. State = [[-0.3890556  -0.05218429]]. Action = [[ 0.         0.         0.        -0.6287121]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 504 is [True, False, False, False, True, False]
State prediction error at timestep 504 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 504 of -1
Current timestep = 505. State = [[-0.3890595  -0.05218334]]. Action = [[0.         0.         0.         0.81046367]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 505 is [True, False, False, False, True, False]
State prediction error at timestep 505 is tensor(4.6679e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 505 of -1
Current timestep = 506. State = [[-0.38906327 -0.05218241]]. Action = [[ 0.          0.          0.         -0.08709496]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 506 is [True, False, False, False, True, False]
State prediction error at timestep 506 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 506 of -1
Current timestep = 507. State = [[-0.38906687 -0.05218149]]. Action = [[ 0.          0.          0.         -0.13145977]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 507 is [True, False, False, False, True, False]
State prediction error at timestep 507 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 507 of -1
Current timestep = 508. State = [[-0.38907033 -0.05218059]]. Action = [[0.         0.         0.         0.88199985]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 508 is [True, False, False, False, True, False]
State prediction error at timestep 508 is tensor(3.8227e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 508 of -1
Current timestep = 509. State = [[-0.38907367 -0.0521797 ]]. Action = [[ 0.          0.          0.         -0.96922094]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 509 is [True, False, False, False, True, False]
State prediction error at timestep 509 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 509 of -1
Current timestep = 510. State = [[-0.389077   -0.05217882]]. Action = [[ 0.         0.         0.        -0.1881873]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 510 is [True, False, False, False, True, False]
State prediction error at timestep 510 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 510 of -1
Current timestep = 511. State = [[-0.38908032 -0.05217795]]. Action = [[ 0.         0.         0.        -0.4318844]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 511 is [True, False, False, False, True, False]
State prediction error at timestep 511 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 511 of -1
Current timestep = 512. State = [[-0.3890836  -0.05217708]]. Action = [[ 0.         0.         0.        -0.9581754]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 512 is [True, False, False, False, True, False]
State prediction error at timestep 512 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 512 of -1
Current timestep = 513. State = [[-0.38908684 -0.05217622]]. Action = [[0.         0.         0.         0.56705546]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 513 is [True, False, False, False, True, False]
State prediction error at timestep 513 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 513 of -1
Current timestep = 514. State = [[-0.38909003 -0.05217537]]. Action = [[0.        0.        0.        0.9063659]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 514 is [True, False, False, False, True, False]
State prediction error at timestep 514 is tensor(5.7551e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 514 of -1
Current timestep = 515. State = [[-0.38909325 -0.05217453]]. Action = [[ 0.          0.          0.         -0.91807103]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 515 is [True, False, False, False, True, False]
State prediction error at timestep 515 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 515 of -1
Current timestep = 516. State = [[-0.3890964  -0.05217369]]. Action = [[ 0.         0.         0.        -0.6465322]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 516 is [True, False, False, False, True, False]
State prediction error at timestep 516 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 516 of -1
Current timestep = 517. State = [[-0.38909954 -0.05217287]]. Action = [[0.        0.        0.        0.2915039]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 517 is [True, False, False, False, True, False]
State prediction error at timestep 517 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 517 of -1
Current timestep = 518. State = [[-0.38910264 -0.05217205]]. Action = [[0.        0.        0.        0.1672734]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 518 is [True, False, False, False, True, False]
State prediction error at timestep 518 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 518 of -1
Current timestep = 519. State = [[-0.38910574 -0.05217123]]. Action = [[ 0.         0.         0.        -0.7709487]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 519 is [True, False, False, False, True, False]
State prediction error at timestep 519 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 519 of -1
Current timestep = 520. State = [[-0.3891088  -0.05217042]]. Action = [[ 0.         0.         0.        -0.5741886]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 520 is [True, False, False, False, True, False]
State prediction error at timestep 520 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 520 of -1
Current timestep = 521. State = [[-0.38911182 -0.05216962]]. Action = [[0.         0.         0.         0.19225025]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 521 is [True, False, False, False, True, False]
State prediction error at timestep 521 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 521 of -1
Current timestep = 522. State = [[-0.38911483 -0.05216883]]. Action = [[0.        0.        0.        0.9223919]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 522 is [True, False, False, False, True, False]
State prediction error at timestep 522 is tensor(3.2632e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 522 of -1
Current timestep = 523. State = [[-0.38911784 -0.05216805]]. Action = [[0.        0.        0.        0.7887757]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 523 is [True, False, False, False, True, False]
State prediction error at timestep 523 is tensor(3.3306e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 523 of -1
Current timestep = 524. State = [[-0.3891208  -0.05216727]]. Action = [[0.         0.         0.         0.37889886]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 524 is [True, False, False, False, True, False]
State prediction error at timestep 524 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 524 of -1
Current timestep = 525. State = [[-0.3891237  -0.05216649]]. Action = [[ 0.          0.          0.         -0.10322422]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 525 is [True, False, False, False, True, False]
State prediction error at timestep 525 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 525 of -1
Current timestep = 526. State = [[-0.38912663 -0.05216573]]. Action = [[ 0.         0.         0.        -0.9662482]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 526 is [True, False, False, False, True, False]
State prediction error at timestep 526 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 526 of -1
Current timestep = 527. State = [[-0.38912952 -0.05216497]]. Action = [[0.         0.         0.         0.13007545]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 527 is [True, False, False, False, True, False]
State prediction error at timestep 527 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 527 of -1
Current timestep = 528. State = [[-0.38913238 -0.05216422]]. Action = [[ 0.         0.         0.        -0.7181956]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 528 is [True, False, False, False, True, False]
State prediction error at timestep 528 is tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 528 of -1
Current timestep = 529. State = [[-0.3891352  -0.05216347]]. Action = [[0.         0.         0.         0.56300545]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 529 is [True, False, False, False, True, False]
State prediction error at timestep 529 is tensor(6.2877e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 529 of -1
Current timestep = 530. State = [[-0.38913804 -0.05216273]]. Action = [[0.        0.        0.        0.7310393]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 530 is [True, False, False, False, True, False]
State prediction error at timestep 530 is tensor(2.5096e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 530 of -1
Current timestep = 531. State = [[-0.3891408 -0.052162 ]]. Action = [[0.         0.         0.         0.87497044]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 531 is [True, False, False, False, True, False]
State prediction error at timestep 531 is tensor(1.2538e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 531 of -1
Current timestep = 532. State = [[-0.3891436  -0.05216127]]. Action = [[0.         0.         0.         0.08808422]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 532 is [True, False, False, False, True, False]
State prediction error at timestep 532 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 532 of -1
Current timestep = 533. State = [[-0.38914633 -0.05216055]]. Action = [[ 0.          0.          0.         -0.23936725]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 533 is [True, False, False, False, True, False]
State prediction error at timestep 533 is tensor(8.9759e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 533 of -1
Current timestep = 534. State = [[-0.38914904 -0.05215984]]. Action = [[ 0.          0.          0.         -0.17619193]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 534 is [True, False, False, False, True, False]
State prediction error at timestep 534 is tensor(9.7899e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 534 of -1
Current timestep = 535. State = [[-0.38915175 -0.05215913]]. Action = [[0.        0.        0.        0.8296895]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 535 is [True, False, False, False, True, False]
State prediction error at timestep 535 is tensor(1.3308e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 535 of -1
Current timestep = 536. State = [[-0.38915443 -0.05215843]]. Action = [[0.         0.         0.         0.82634294]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 536 is [True, False, False, False, True, False]
State prediction error at timestep 536 is tensor(1.2177e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 536 of -1
Current timestep = 537. State = [[-0.3891571  -0.05215773]]. Action = [[ 0.         0.         0.        -0.7167638]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 537 is [True, False, False, False, True, False]
State prediction error at timestep 537 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 537 of -1
Current timestep = 538. State = [[-0.3891597  -0.05215704]]. Action = [[0.         0.         0.         0.37513113]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 538 is [True, False, False, False, True, False]
State prediction error at timestep 538 is tensor(6.7034e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 538 of -1
Current timestep = 539. State = [[-0.38916233 -0.05215636]]. Action = [[ 0.         0.         0.        -0.9696792]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 539 is [True, False, False, False, True, False]
State prediction error at timestep 539 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 539 of -1
Current timestep = 540. State = [[-0.38916492 -0.05215568]]. Action = [[ 0.          0.          0.         -0.61609256]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 540 is [True, False, False, False, True, False]
State prediction error at timestep 540 is tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 540 of -1
Current timestep = 541. State = [[-0.3891675  -0.05215501]]. Action = [[ 0.          0.          0.         -0.47779638]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 541 is [True, False, False, False, True, False]
State prediction error at timestep 541 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 541 of -1
Current timestep = 542. State = [[-0.38917002 -0.05215435]]. Action = [[ 0.         0.         0.        -0.9434708]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 542 is [True, False, False, False, True, False]
State prediction error at timestep 542 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 542 of -1
Current timestep = 543. State = [[-0.38917255 -0.05215369]]. Action = [[0.         0.         0.         0.72626686]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 543 is [True, False, False, False, True, False]
State prediction error at timestep 543 is tensor(2.9229e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 543 of -1
Current timestep = 544. State = [[-0.38917506 -0.05215303]]. Action = [[ 0.         0.         0.        -0.7614921]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 544 is [True, False, False, False, True, False]
State prediction error at timestep 544 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 544 of -1
Current timestep = 545. State = [[-0.38917753 -0.05215238]]. Action = [[0.         0.         0.         0.78372705]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 545 is [True, False, False, False, True, False]
State prediction error at timestep 545 is tensor(9.1757e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 545 of -1
Current timestep = 546. State = [[-0.38918    -0.05215174]]. Action = [[ 0.         0.         0.        -0.3016318]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 546 is [True, False, False, False, True, False]
State prediction error at timestep 546 is tensor(6.2685e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 546 of -1
Current timestep = 547. State = [[-0.38918245 -0.05215111]]. Action = [[0.         0.         0.         0.16938066]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 547 is [True, False, False, False, True, False]
State prediction error at timestep 547 is tensor(9.3039e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 547 of -1
Current timestep = 548. State = [[-0.38918486 -0.05215047]]. Action = [[0.         0.         0.         0.51443315]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 548 is [True, False, False, False, True, False]
State prediction error at timestep 548 is tensor(4.5781e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 548 of -1
Current timestep = 549. State = [[-0.38918728 -0.05214985]]. Action = [[0.        0.        0.        0.0335927]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 549 is [True, False, False, False, True, False]
State prediction error at timestep 549 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 549 of -1
Current timestep = 550. State = [[-0.38918963 -0.05214923]]. Action = [[ 0.          0.          0.         -0.06891453]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 550 is [True, False, False, False, True, False]
State prediction error at timestep 550 is tensor(9.0081e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 550 of -1
Current timestep = 551. State = [[-0.38919201 -0.05214861]]. Action = [[ 0.          0.          0.         -0.01792085]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 551 is [True, False, False, False, True, False]
State prediction error at timestep 551 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 551 of -1
Current timestep = 552. State = [[-0.38919434 -0.052148  ]]. Action = [[ 0.       0.       0.      -0.90056]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 552 is [True, False, False, False, True, False]
State prediction error at timestep 552 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 552 of -1
Current timestep = 553. State = [[-0.38919666 -0.0521474 ]]. Action = [[ 0.          0.          0.         -0.10712904]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 553 is [True, False, False, False, True, False]
State prediction error at timestep 553 is tensor(7.0213e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 553 of -1
Current timestep = 554. State = [[-0.38919896 -0.0521468 ]]. Action = [[ 0.          0.          0.         -0.17861414]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 554 is [True, False, False, False, True, False]
State prediction error at timestep 554 is tensor(5.4898e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 554 of -1
Current timestep = 555. State = [[-0.38920125 -0.05214621]]. Action = [[ 0.         0.         0.        -0.8931452]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 555 is [True, False, False, False, True, False]
State prediction error at timestep 555 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 555 of -1
Current timestep = 556. State = [[-0.38920352 -0.05214562]]. Action = [[ 0.        0.        0.       -0.476413]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 556 is [True, False, False, False, True, False]
State prediction error at timestep 556 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 556 of -1
Current timestep = 557. State = [[-0.38920575 -0.05214503]]. Action = [[0.         0.         0.         0.14991939]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 557 is [True, False, False, False, True, False]
State prediction error at timestep 557 is tensor(9.0622e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 557 of -1
Current timestep = 558. State = [[-0.389208   -0.05214446]]. Action = [[ 0.          0.          0.         -0.24024034]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 558 is [True, False, False, False, True, False]
State prediction error at timestep 558 is tensor(5.1970e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 558 of -1
Current timestep = 559. State = [[-0.3892102  -0.05214388]]. Action = [[0.         0.         0.         0.79085875]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 559 is [True, False, False, False, True, False]
State prediction error at timestep 559 is tensor(2.7310e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 559 of -1
Current timestep = 560. State = [[-0.3892124  -0.05214332]]. Action = [[0.         0.         0.         0.67061543]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 560 is [True, False, False, False, True, False]
State prediction error at timestep 560 is tensor(3.0855e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 560 of -1
Current timestep = 561. State = [[-0.38921455 -0.05214275]]. Action = [[ 0.          0.          0.         -0.93929195]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 561 is [True, False, False, False, True, False]
State prediction error at timestep 561 is tensor(9.4674e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 561 of -1
Current timestep = 562. State = [[-0.38921672 -0.0521422 ]]. Action = [[0.         0.         0.         0.72943175]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 562 is [True, False, False, False, True, False]
State prediction error at timestep 562 is tensor(1.5978e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 562 of -1
Current timestep = 563. State = [[-0.38921884 -0.05214164]]. Action = [[ 0.          0.          0.         -0.25578916]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 563 is [True, False, False, False, True, False]
State prediction error at timestep 563 is tensor(3.4997e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 563 of -1
Current timestep = 564. State = [[-0.38922095 -0.05214109]]. Action = [[0.         0.         0.         0.01251054]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 564 is [True, False, False, False, True, False]
State prediction error at timestep 564 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 564 of -1
Current timestep = 565. State = [[-0.38922307 -0.05214055]]. Action = [[0.         0.         0.         0.54747474]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 565 is [True, False, False, False, True, False]
State prediction error at timestep 565 is tensor(3.7511e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 565 of -1
Current timestep = 566. State = [[-0.38922516 -0.05214001]]. Action = [[0.         0.         0.         0.49187732]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 566 is [True, False, False, False, True, False]
State prediction error at timestep 566 is tensor(3.5620e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 566 of -1
Current timestep = 567. State = [[-0.3892272  -0.05213948]]. Action = [[ 0.          0.          0.         -0.43333817]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 567 is [True, False, False, False, True, False]
State prediction error at timestep 567 is tensor(9.1433e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 567 of -1
Current timestep = 568. State = [[-0.38922927 -0.05213895]]. Action = [[0.        0.        0.        0.2920134]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 568 is [True, False, False, False, True, False]
State prediction error at timestep 568 is tensor(3.0450e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 568 of -1
Current timestep = 569. State = [[-0.3892313  -0.05213842]]. Action = [[0.         0.         0.         0.60541236]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 569 is [True, False, False, False, True, False]
State prediction error at timestep 569 is tensor(2.4555e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 569 of -1
Current timestep = 570. State = [[-0.3892333 -0.0521379]]. Action = [[0.         0.         0.         0.63943446]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 570 is [True, False, False, False, True, False]
State prediction error at timestep 570 is tensor(2.2717e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 570 of -1
Current timestep = 571. State = [[-0.3892353  -0.05213739]]. Action = [[ 0.          0.          0.         -0.11278123]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 571 is [True, False, False, False, True, False]
State prediction error at timestep 571 is tensor(5.7674e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 571 of -1
Current timestep = 572. State = [[-0.38923728 -0.05213688]]. Action = [[ 0.          0.          0.         -0.23680454]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 572 is [True, False, False, False, True, False]
State prediction error at timestep 572 is tensor(3.0402e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 572 of -1
Current timestep = 573. State = [[-0.38923925 -0.05213637]]. Action = [[ 0.         0.         0.        -0.8673116]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 573 is [True, False, False, False, True, False]
State prediction error at timestep 573 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 573 of -1
Current timestep = 574. State = [[-0.3892412  -0.05213587]]. Action = [[0.         0.         0.         0.35301042]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 574 is [True, False, False, False, True, False]
State prediction error at timestep 574 is tensor(2.6739e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 574 of -1
Current timestep = 575. State = [[-0.38924313 -0.05213537]]. Action = [[ 0.          0.          0.         -0.59226054]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 575 is [True, False, False, False, True, False]
State prediction error at timestep 575 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 575 of -1
Current timestep = 576. State = [[-0.38924503 -0.05213488]]. Action = [[0.        0.        0.        0.4325763]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 576 is [True, False, False, False, True, False]
State prediction error at timestep 576 is tensor(2.9350e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 576 of -1
Current timestep = 577. State = [[-0.38924694 -0.05213439]]. Action = [[ 0.         0.         0.        -0.5579814]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 577 is [True, False, False, False, True, False]
State prediction error at timestep 577 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 577 of -1
Current timestep = 578. State = [[-0.38924882 -0.05213391]]. Action = [[0.         0.         0.         0.59977067]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 578 is [True, False, False, False, True, False]
State prediction error at timestep 578 is tensor(2.1469e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 578 of -1
Current timestep = 579. State = [[-0.3892507  -0.05213343]]. Action = [[0.         0.         0.         0.07407427]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 579 is [True, False, False, False, True, False]
State prediction error at timestep 579 is tensor(7.6108e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 579 of -1
Current timestep = 580. State = [[-0.38925254 -0.05213295]]. Action = [[ 0.          0.          0.         -0.35524762]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 580 is [True, False, False, False, True, False]
State prediction error at timestep 580 is tensor(4.7076e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 580 of -1
Current timestep = 581. State = [[-0.3892544  -0.05213248]]. Action = [[0.         0.         0.         0.73163915]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 581 is [True, False, False, False, True, False]
State prediction error at timestep 581 is tensor(2.4177e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 581 of -1
Current timestep = 582. State = [[-0.3892562  -0.05213201]]. Action = [[ 0.          0.          0.         -0.74412143]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 582 is [True, False, False, False, True, False]
State prediction error at timestep 582 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 582 of -1
Current timestep = 583. State = [[-0.389258   -0.05213155]]. Action = [[ 0.          0.          0.         -0.43347728]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 583 is [True, False, False, False, True, False]
State prediction error at timestep 583 is tensor(9.1209e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 583 of -1
Current timestep = 584. State = [[-0.38925982 -0.05213109]]. Action = [[0.         0.         0.         0.18588161]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 584 is [True, False, False, False, True, False]
State prediction error at timestep 584 is tensor(4.5227e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 584 of -1
Current timestep = 585. State = [[-0.38926157 -0.05213064]]. Action = [[ 0.          0.          0.         -0.06934792]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 585 is [True, False, False, False, True, False]
State prediction error at timestep 585 is tensor(6.2825e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 585 of -1
Current timestep = 586. State = [[-0.38926333 -0.05213018]]. Action = [[0.         0.         0.         0.24460793]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 586 is [True, False, False, False, True, False]
State prediction error at timestep 586 is tensor(3.2384e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 586 of -1
Current timestep = 587. State = [[-0.3892651  -0.05212973]]. Action = [[0.         0.         0.         0.28968847]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 587 is [True, False, False, False, True, False]
State prediction error at timestep 587 is tensor(2.5441e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 587 of -1
Current timestep = 588. State = [[-0.38926682 -0.05212929]]. Action = [[0.         0.         0.         0.69554615]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 588 is [True, False, False, False, True, False]
State prediction error at timestep 588 is tensor(2.0574e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 588 of -1
Current timestep = 589. State = [[-0.38926855 -0.05212886]]. Action = [[0.        0.        0.        0.8604729]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 589 is [True, False, False, False, True, False]
State prediction error at timestep 589 is tensor(1.2829e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 589 of -1
Current timestep = 590. State = [[-0.38927025 -0.05212842]]. Action = [[ 0.        0.        0.       -0.610421]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 590 is [True, False, False, False, True, False]
State prediction error at timestep 590 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 590 of -1
Current timestep = 591. State = [[-0.38927194 -0.05212799]]. Action = [[ 0.         0.         0.        -0.1779834]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 591 is [True, False, False, False, True, False]
State prediction error at timestep 591 is tensor(2.3208e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 591 of -1
Current timestep = 592. State = [[-0.3892736  -0.05212756]]. Action = [[0.         0.         0.         0.14349353]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 592 is [True, False, False, False, True, False]
State prediction error at timestep 592 is tensor(5.2612e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 592 of -1
Current timestep = 593. State = [[-0.38927528 -0.05212714]]. Action = [[ 0.         0.         0.        -0.9949857]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 593 is [True, False, False, False, True, False]
State prediction error at timestep 593 is tensor(4.4857e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 593 of -1
Current timestep = 594. State = [[-0.38927692 -0.05212672]]. Action = [[ 0.          0.          0.         -0.27413273]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 594 is [True, False, False, False, True, False]
State prediction error at timestep 594 is tensor(1.8180e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 594 of -1
Current timestep = 595. State = [[-0.38927856 -0.0521263 ]]. Action = [[ 0.         0.         0.        -0.7007248]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 595 is [True, False, False, False, True, False]
State prediction error at timestep 595 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 595 of -1
Current timestep = 596. State = [[-0.38928017 -0.05212589]]. Action = [[ 0.          0.          0.         -0.48277944]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 596 is [True, False, False, False, True, False]
State prediction error at timestep 596 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 596 of -1
Current timestep = 597. State = [[-0.38928178 -0.05212548]]. Action = [[ 0.         0.         0.        -0.6536072]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 597 is [True, False, False, False, True, False]
State prediction error at timestep 597 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 597 of -1
Current timestep = 598. State = [[-0.38928336 -0.05212507]]. Action = [[ 0.         0.         0.        -0.4541887]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 598 is [True, False, False, False, True, False]
State prediction error at timestep 598 is tensor(8.5278e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 598 of -1
Current timestep = 599. State = [[-0.38928497 -0.05212467]]. Action = [[ 0.          0.          0.         -0.93498087]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 599 is [True, False, False, False, True, False]
State prediction error at timestep 599 is tensor(6.6947e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 599 of -1
Current timestep = 600. State = [[-0.38928652 -0.05212427]]. Action = [[ 0.          0.          0.         -0.78927875]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 600 is [True, False, False, False, True, False]
State prediction error at timestep 600 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 600 of -1
Current timestep = 601. State = [[-0.38928807 -0.05212388]]. Action = [[ 0.          0.          0.         -0.81839347]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 601 is [True, False, False, False, True, False]
State prediction error at timestep 601 is tensor(9.3076e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 601 of -1
Current timestep = 602. State = [[-0.38928962 -0.05212349]]. Action = [[ 0.          0.          0.         -0.56788135]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 602 is [True, False, False, False, True, False]
State prediction error at timestep 602 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 602 of -1
Current timestep = 603. State = [[-0.38929114 -0.0521231 ]]. Action = [[ 0.         0.         0.        -0.8693914]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 603 is [True, False, False, False, True, False]
State prediction error at timestep 603 is tensor(8.8457e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 603 of -1
Current timestep = 604. State = [[-0.38929266 -0.05212272]]. Action = [[0.         0.         0.         0.38396358]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 604 is [True, False, False, False, True, False]
State prediction error at timestep 604 is tensor(2.5620e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 604 of -1
Current timestep = 605. State = [[-0.38929418 -0.05212234]]. Action = [[ 0.          0.          0.         -0.00623423]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 605 is [True, False, False, False, True, False]
State prediction error at timestep 605 is tensor(7.8099e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 605 of -1
Current timestep = 606. State = [[-0.38929567 -0.05212196]]. Action = [[0.         0.         0.         0.70910096]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 606 is [True, False, False, False, True, False]
State prediction error at timestep 606 is tensor(3.1742e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 606 of -1
Current timestep = 607. State = [[-0.38929713 -0.05212159]]. Action = [[ 0.         0.         0.        -0.6142436]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 607 is [True, False, False, False, True, False]
State prediction error at timestep 607 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 607 of -1
Current timestep = 608. State = [[-0.3892986  -0.05212121]]. Action = [[ 0.         0.         0.        -0.7513881]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 608 is [True, False, False, False, True, False]
State prediction error at timestep 608 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 608 of -1
Current timestep = 609. State = [[-0.38930005 -0.05212085]]. Action = [[0.         0.         0.         0.07903862]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 609 is [True, False, False, False, True, False]
State prediction error at timestep 609 is tensor(5.3958e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 609 of -1
Current timestep = 610. State = [[-0.3893015  -0.05212048]]. Action = [[0.         0.         0.         0.46019316]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 610 is [True, False, False, False, True, False]
State prediction error at timestep 610 is tensor(1.5932e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 610 of -1
Current timestep = 611. State = [[-0.38930294 -0.05212012]]. Action = [[0.         0.         0.         0.11414289]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 611 is [True, False, False, False, True, False]
State prediction error at timestep 611 is tensor(4.8624e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 611 of -1
Current timestep = 612. State = [[-0.38930434 -0.05211977]]. Action = [[ 0.          0.          0.         -0.45347595]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 612 is [True, False, False, False, True, False]
State prediction error at timestep 612 is tensor(7.3505e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 612 of -1
Current timestep = 613. State = [[-0.38930574 -0.05211942]]. Action = [[ 0.         0.         0.        -0.3321153]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 613 is [True, False, False, False, True, False]
State prediction error at timestep 613 is tensor(2.8484e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 613 of -1
Current timestep = 614. State = [[-0.38930714 -0.05211906]]. Action = [[ 0.        0.        0.       -0.783569]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 614 is [True, False, False, False, True, False]
State prediction error at timestep 614 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 614 of -1
Current timestep = 615. State = [[-0.38930854 -0.05211871]]. Action = [[0.         0.         0.         0.86862457]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 615 is [True, False, False, False, True, False]
State prediction error at timestep 615 is tensor(2.6468e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 615 of -1
Current timestep = 616. State = [[-0.3893099  -0.05211837]]. Action = [[ 0.         0.         0.        -0.5855341]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 616 is [True, False, False, False, True, False]
State prediction error at timestep 616 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 616 of -1
Current timestep = 617. State = [[-0.38931125 -0.05211803]]. Action = [[ 0.         0.         0.        -0.7418796]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 617 is [True, False, False, False, True, False]
State prediction error at timestep 617 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 617 of -1
Current timestep = 618. State = [[-0.3893126  -0.05211769]]. Action = [[0.         0.         0.         0.75149393]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 618 is [True, False, False, False, True, False]
State prediction error at timestep 618 is tensor(3.6996e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 618 of -1
Current timestep = 619. State = [[-0.38931394 -0.05211736]]. Action = [[ 0.         0.         0.        -0.9504648]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 619 is [True, False, False, False, True, False]
State prediction error at timestep 619 is tensor(5.0141e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 619 of -1
Current timestep = 620. State = [[-0.38931528 -0.05211702]]. Action = [[0.         0.         0.         0.40193737]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 620 is [True, False, False, False, True, False]
State prediction error at timestep 620 is tensor(2.5872e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 620 of -1
Current timestep = 621. State = [[-0.3893166  -0.05211669]]. Action = [[ 0.         0.         0.        -0.5353731]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 621 is [True, False, False, False, True, False]
State prediction error at timestep 621 is tensor(9.7147e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 621 of -1
Current timestep = 622. State = [[-0.3893179  -0.05211637]]. Action = [[ 0.          0.          0.         -0.53922164]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 622 is [True, False, False, False, True, False]
State prediction error at timestep 622 is tensor(8.4000e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 622 of -1
Current timestep = 623. State = [[-0.38931918 -0.05211604]]. Action = [[0.        0.        0.        0.3067757]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 623 is [True, False, False, False, True, False]
State prediction error at timestep 623 is tensor(6.4121e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 623 of -1
Current timestep = 624. State = [[-0.38932046 -0.05211572]]. Action = [[0.        0.        0.        0.7235646]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 624 is [True, False, False, False, True, False]
State prediction error at timestep 624 is tensor(2.7226e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 624 of -1
Current timestep = 625. State = [[-0.38932174 -0.05211541]]. Action = [[ 0.          0.          0.         -0.23002958]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 625 is [True, False, False, False, True, False]
State prediction error at timestep 625 is tensor(1.8939e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 625 of -1
Current timestep = 626. State = [[-0.389323   -0.05211509]]. Action = [[0.         0.         0.         0.64202166]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 626 is [True, False, False, False, True, False]
State prediction error at timestep 626 is tensor(3.6074e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 626 of -1
Current timestep = 627. State = [[-0.38932425 -0.05211478]]. Action = [[ 0.          0.          0.         -0.91745317]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 627 is [True, False, False, False, True, False]
State prediction error at timestep 627 is tensor(3.8243e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 627 of -1
Current timestep = 628. State = [[-0.3893255  -0.05211447]]. Action = [[ 0.         0.         0.        -0.3438388]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 628 is [True, False, False, False, True, False]
State prediction error at timestep 628 is tensor(1.3541e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 628 of -1
Current timestep = 629. State = [[-0.38932672 -0.05211416]]. Action = [[0.         0.         0.         0.09190464]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 629 is [True, False, False, False, True, False]
State prediction error at timestep 629 is tensor(4.6905e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 629 of 1
Current timestep = 630. State = [[-0.38932794 -0.05211386]]. Action = [[0.        0.        0.        0.5356076]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 630 is [True, False, False, False, True, False]
State prediction error at timestep 630 is tensor(3.3469e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 630 of -1
Current timestep = 631. State = [[-0.38932917 -0.05211356]]. Action = [[0.        0.        0.        0.8678174]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 631 is [True, False, False, False, True, False]
State prediction error at timestep 631 is tensor(3.0484e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 631 of -1
Current timestep = 632. State = [[-0.38933036 -0.05211326]]. Action = [[ 0.         0.         0.        -0.9764035]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 632 is [True, False, False, False, True, False]
State prediction error at timestep 632 is tensor(5.1656e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 632 of -1
Current timestep = 633. State = [[-0.38933155 -0.05211297]]. Action = [[ 0.          0.          0.         -0.50174505]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 633 is [True, False, False, False, True, False]
State prediction error at timestep 633 is tensor(6.4999e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 633 of -1
Current timestep = 634. State = [[-0.3893327  -0.05211267]]. Action = [[ 0.          0.          0.         -0.31293577]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 634 is [True, False, False, False, True, False]
State prediction error at timestep 634 is tensor(1.6064e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 634 of -1
Current timestep = 635. State = [[-0.3893339  -0.05211239]]. Action = [[ 0.          0.          0.         -0.90967876]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 635 is [True, False, False, False, True, False]
State prediction error at timestep 635 is tensor(3.9570e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 635 of -1
Current timestep = 636. State = [[-0.38933507 -0.0521121 ]]. Action = [[0.         0.         0.         0.44829977]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 636 is [True, False, False, False, True, False]
State prediction error at timestep 636 is tensor(3.1561e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 636 of -1
Current timestep = 637. State = [[-0.3893362  -0.05211181]]. Action = [[0.         0.         0.         0.52280474]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 637 is [True, False, False, False, True, False]
State prediction error at timestep 637 is tensor(4.0023e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 637 of -1
Current timestep = 638. State = [[-0.38933736 -0.05211153]]. Action = [[ 0.         0.         0.        -0.6323602]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 638 is [True, False, False, False, True, False]
State prediction error at timestep 638 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 638 of 0
Current timestep = 639. State = [[-0.3893385  -0.05211125]]. Action = [[0.         0.         0.         0.00166678]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 639 is [True, False, False, False, True, False]
State prediction error at timestep 639 is tensor(6.3147e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 639 of 0
Current timestep = 640. State = [[-0.3893396  -0.05211097]]. Action = [[0.         0.         0.         0.88452816]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 640 is [True, False, False, False, True, False]
State prediction error at timestep 640 is tensor(2.8365e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 640 of -1
Current timestep = 641. State = [[-0.38934073 -0.0521107 ]]. Action = [[ 0.         0.         0.        -0.8113998]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 641 is [True, False, False, False, True, False]
State prediction error at timestep 641 is tensor(6.8344e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 641 of -1
Current timestep = 642. State = [[-0.38934183 -0.05211043]]. Action = [[ 0.         0.         0.        -0.6284721]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 642 is [True, False, False, False, True, False]
State prediction error at timestep 642 is tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 642 of -1
Current timestep = 643. State = [[-0.3893429  -0.05211016]]. Action = [[0.         0.         0.         0.04270077]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 643 is [True, False, False, False, True, False]
State prediction error at timestep 643 is tensor(5.7673e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 643 of -1
Current timestep = 644. State = [[-0.389344   -0.05210989]]. Action = [[ 0.          0.          0.         -0.14080924]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 644 is [True, False, False, False, True, False]
State prediction error at timestep 644 is tensor(3.1009e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 644 of -1
Current timestep = 645. State = [[-0.38934508 -0.05210963]]. Action = [[ 0.         0.         0.        -0.9302082]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 645 is [True, False, False, False, True, False]
State prediction error at timestep 645 is tensor(3.2610e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 645 of -1
Current timestep = 646. State = [[-0.38934615 -0.05210936]]. Action = [[0.         0.         0.         0.75163484]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 646 is [True, False, False, False, True, False]
State prediction error at timestep 646 is tensor(3.1327e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 646 of -1
Current timestep = 647. State = [[-0.3893472 -0.0521091]]. Action = [[ 0.          0.          0.         -0.37485725]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 647 is [True, False, False, False, True, False]
State prediction error at timestep 647 is tensor(2.6961e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 647 of -1
Current timestep = 648. State = [[-0.38934827 -0.05210885]]. Action = [[ 0.          0.          0.         -0.93526256]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 648 is [True, False, False, False, True, False]
State prediction error at timestep 648 is tensor(3.3560e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 648 of -1
Current timestep = 649. State = [[-0.3893493  -0.05210859]]. Action = [[ 0.         0.         0.        -0.8392186]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 649 is [True, False, False, False, True, False]
State prediction error at timestep 649 is tensor(6.3599e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 649 of -1
Current timestep = 650. State = [[-0.38935032 -0.05210834]]. Action = [[0.        0.        0.        0.6340101]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 650 is [True, False, False, False, True, False]
State prediction error at timestep 650 is tensor(3.3021e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 650 of -1
Current timestep = 651. State = [[-0.38935137 -0.05210809]]. Action = [[0.        0.        0.        0.6768776]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 651 is [True, False, False, False, True, False]
State prediction error at timestep 651 is tensor(3.2369e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 651 of -1
Current timestep = 652. State = [[-0.38935238 -0.05210784]]. Action = [[ 0.         0.         0.        -0.8926676]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 652 is [True, False, False, False, True, False]
State prediction error at timestep 652 is tensor(3.5142e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 652 of -1
Current timestep = 653. State = [[-0.38935336 -0.05210759]]. Action = [[ 0.         0.         0.        -0.8775447]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 653 is [True, False, False, False, True, False]
State prediction error at timestep 653 is tensor(4.2685e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 653 of -1
Current timestep = 654. State = [[-0.38935438 -0.05210735]]. Action = [[0.        0.        0.        0.4943899]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 654 is [True, False, False, False, True, False]
State prediction error at timestep 654 is tensor(2.5868e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 654 of -1
Current timestep = 655. State = [[-0.38935536 -0.05210711]]. Action = [[0.        0.        0.        0.1412251]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 655 is [True, False, False, False, True, False]
State prediction error at timestep 655 is tensor(2.6101e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 655 of -1
Current timestep = 656. State = [[-0.38935634 -0.05210687]]. Action = [[ 0.          0.          0.         -0.26612324]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 656 is [True, False, False, False, True, False]
State prediction error at timestep 656 is tensor(6.8131e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 656 of -1
Current timestep = 657. State = [[-0.38935733 -0.05210664]]. Action = [[ 0.          0.          0.         -0.63089204]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 657 is [True, False, False, False, True, False]
State prediction error at timestep 657 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 657 of -1
Current timestep = 658. State = [[-0.38935828 -0.0521064 ]]. Action = [[ 0.          0.          0.         -0.35412902]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 658 is [True, False, False, False, True, False]
State prediction error at timestep 658 is tensor(2.1297e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 658 of -1
Current timestep = 659. State = [[-0.38935924 -0.05210617]]. Action = [[ 0.          0.          0.         -0.20798528]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 659 is [True, False, False, False, True, False]
State prediction error at timestep 659 is tensor(1.0446e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 659 of -1
Current timestep = 660. State = [[-0.3893602  -0.05210594]]. Action = [[0.        0.        0.        0.3609494]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 660 is [True, False, False, False, True, False]
State prediction error at timestep 660 is tensor(8.7877e-06, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 660 of -1
Current timestep = 661. State = [[-0.38936114 -0.05210571]]. Action = [[0.         0.         0.         0.13983238]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 661 is [True, False, False, False, True, False]
State prediction error at timestep 661 is tensor(2.7690e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 661 of -1
Current timestep = 662. State = [[-0.38936207 -0.05210548]]. Action = [[0.       0.       0.       0.876418]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 662 is [True, False, False, False, True, False]
State prediction error at timestep 662 is tensor(3.3035e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 662 of -1
Current timestep = 663. State = [[-0.389363   -0.05210526]]. Action = [[ 0.          0.          0.         -0.49644345]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 663 is [True, False, False, False, True, False]
State prediction error at timestep 663 is tensor(5.4870e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 663 of -1
Current timestep = 664. State = [[-0.3893639  -0.05210504]]. Action = [[0.         0.         0.         0.92851114]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 664 is [True, False, False, False, True, False]
State prediction error at timestep 664 is tensor(2.5503e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 664 of -1
Current timestep = 665. State = [[-0.38936484 -0.05210482]]. Action = [[ 0.          0.          0.         -0.12972319]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 665 is [True, False, False, False, True, False]
State prediction error at timestep 665 is tensor(3.5646e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 665 of -1
Current timestep = 666. State = [[-0.38936573 -0.0521046 ]]. Action = [[ 0.          0.          0.         -0.95915246]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 666 is [True, False, False, False, True, False]
State prediction error at timestep 666 is tensor(2.4460e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 666 of -1
Current timestep = 667. State = [[-0.38936663 -0.05210439]]. Action = [[ 0.          0.          0.         -0.94708633]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 667 is [True, False, False, False, True, False]
State prediction error at timestep 667 is tensor(1.8078e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 667 of -1
Current timestep = 668. State = [[-0.38936752 -0.05210417]]. Action = [[0.        0.        0.        0.0974071]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 668 is [True, False, False, False, True, False]
State prediction error at timestep 668 is tensor(2.8089e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 668 of -1
Current timestep = 669. State = [[-0.3893684  -0.05210396]]. Action = [[0.         0.         0.         0.15656257]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 669 is [True, False, False, False, True, False]
State prediction error at timestep 669 is tensor(1.3268e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 669 of -1
Current timestep = 670. State = [[-0.38936928 -0.05210375]]. Action = [[ 0.         0.         0.        -0.7819731]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 670 is [True, False, False, False, True, False]
State prediction error at timestep 670 is tensor(8.4849e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 670 of -1
Current timestep = 671. State = [[-0.38937014 -0.05210354]]. Action = [[ 0.         0.         0.        -0.6709024]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 671 is [True, False, False, False, True, False]
State prediction error at timestep 671 is tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 671 of -1
Current timestep = 672. State = [[-0.389371   -0.05210334]]. Action = [[ 0.          0.          0.         -0.07002205]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 672 is [True, False, False, False, True, False]
State prediction error at timestep 672 is tensor(5.6111e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 672 of -1
Current timestep = 673. State = [[-0.38937187 -0.05210313]]. Action = [[0.        0.        0.        0.4257815]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 673 is [True, False, False, False, True, False]
State prediction error at timestep 673 is tensor(1.1687e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 673 of -1
Current timestep = 674. State = [[-0.3893727  -0.05210293]]. Action = [[0.         0.         0.         0.61713636]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 674 is [True, False, False, False, True, False]
State prediction error at timestep 674 is tensor(2.0651e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 674 of -1
Current timestep = 675. State = [[-0.38937354 -0.05210273]]. Action = [[ 0.          0.          0.         -0.49167866]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 675 is [True, False, False, False, True, False]
State prediction error at timestep 675 is tensor(3.9221e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 675 of -1
Current timestep = 676. State = [[-0.38937438 -0.05210253]]. Action = [[0.         0.         0.         0.68138814]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 676 is [True, False, False, False, True, False]
State prediction error at timestep 676 is tensor(4.7500e-05, device='cuda:0', grad_fn=<MseLossBackward>)
Human Feedback received at timestep 676 of -1
Current timestep = 677. State = [[-0.3893752  -0.05210234]]. Action = [[ 0.          0.          0.         -0.58681345]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 677 is [True, False, False, False, True, False]
State prediction error at timestep 677 is tensor(8.1355e-05, device='cuda:0', grad_fn=<MseLossBackward>)
