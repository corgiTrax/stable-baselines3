Current timestep = 0. State = [[-0.3360049   0.06815844]]. Action = [[-0.02517132 -0.00313229  0.         -0.03610903]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [True, False, False, False, True, False]
State prediction error at timestep 0 is 0.012
Current timestep = 1. State = [[-0.3374511   0.06999917]]. Action = [[ 0.01121883  0.03684529  0.         -0.24135602]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False]
State prediction error at timestep 1 is 0.012
Current timestep = 2. State = [[-0.34131858  0.07355683]]. Action = [[-0.06113325  0.04126974  0.          0.97395396]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [True, False, False, False, True, False]
State prediction error at timestep 2 is 0.012
Current timestep = 3. State = [[-0.3473631   0.07895852]]. Action = [[-0.06263261  0.07551753  0.         -0.21903908]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [True, False, False, False, True, False]
State prediction error at timestep 3 is 0.012
Current timestep = 4. State = [[-0.3519387   0.07749604]]. Action = [[-0.02606332 -0.08540395  0.          0.91687274]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [True, False, False, False, True, False]
State prediction error at timestep 4 is 0.012
Current timestep = 5. State = [[-0.3580021   0.07934797]]. Action = [[-0.07761858  0.08164795  0.         -0.8448607 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [True, False, False, False, True, False]
State prediction error at timestep 5 is 0.012
Current timestep = 6. State = [[-0.35793883  0.08049826]]. Action = [[ 0.09810986 -0.04243719  0.         -0.2252906 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [True, False, False, False, True, False]
State prediction error at timestep 6 is 0.012
Current timestep = 7. State = [[-0.3582724   0.08385947]]. Action = [[-0.05269296  0.07933923  0.          0.7123525 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [True, False, False, False, True, False]
State prediction error at timestep 7 is 0.012
Current timestep = 8. State = [[-0.35711005  0.08930421]]. Action = [[ 0.0754961   0.04299169  0.         -0.08161724]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [True, False, False, False, True, False]
State prediction error at timestep 8 is 0.012
Current timestep = 9. State = [[-0.35913327  0.08899977]]. Action = [[-0.07022719 -0.05783322  0.          0.24431825]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [True, False, False, False, True, False]
State prediction error at timestep 9 is 0.012
Current timestep = 10. State = [[-0.3587199  0.0836938]]. Action = [[ 0.06681105 -0.08201386  0.         -0.67114556]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [True, False, False, False, True, False]
State prediction error at timestep 10 is 0.012
Current timestep = 11. State = [[-0.35773504  0.07793319]]. Action = [[-0.00926805 -0.06453748  0.         -0.9684069 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [True, False, False, False, True, False]
State prediction error at timestep 11 is 0.012
Current timestep = 12. State = [[-0.3584141   0.07035369]]. Action = [[-0.00988554 -0.09839112  0.         -0.614913  ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [True, False, False, False, True, False]
State prediction error at timestep 12 is 0.012
Current timestep = 13. State = [[-0.3541792   0.06367693]]. Action = [[ 0.09057599 -0.05426887  0.          0.24568582]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [True, False, False, False, True, False]
State prediction error at timestep 13 is 0.012
Current timestep = 14. State = [[-0.34760153  0.06176218]]. Action = [[ 0.07226252  0.01412418  0.         -0.4160719 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [True, False, False, False, True, False]
State prediction error at timestep 14 is 0.012
Current timestep = 15. State = [[-0.34755936  0.05836104]]. Action = [[-0.05909092 -0.05171558  0.          0.7692232 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [True, False, False, False, True, False]
State prediction error at timestep 15 is 0.012
Current timestep = 16. State = [[-0.3528158  0.0586546]]. Action = [[-0.08847439  0.07359082  0.          0.7894316 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [True, False, False, False, True, False]
State prediction error at timestep 16 is 0.012
Current timestep = 17. State = [[-0.3548716   0.06357956]]. Action = [[ 0.00787131  0.08607116  0.         -0.33679414]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [True, False, False, False, True, False]
State prediction error at timestep 17 is 0.012
Current timestep = 18. State = [[-0.35660857  0.06993229]]. Action = [[-0.03301679  0.08093991  0.         -0.731575  ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [True, False, False, False, True, False]
State prediction error at timestep 18 is 0.012
Current timestep = 19. State = [[-0.35781822  0.07076278]]. Action = [[ 0.00312903 -0.03759826  0.         -0.25821555]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [True, False, False, False, True, False]
State prediction error at timestep 19 is 0.012
Current timestep = 20. State = [[-0.3552625   0.07320841]]. Action = [[0.0632496  0.05764089 0.         0.49787724]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [True, False, False, False, True, False]
State prediction error at timestep 20 is 0.012
Current timestep = 21. State = [[-0.35123602  0.076328  ]]. Action = [[0.05672931 0.00467298 0.         0.501621  ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [True, False, False, False, True, False]
State prediction error at timestep 21 is 0.012
Current timestep = 22. State = [[-0.34671208  0.08295979]]. Action = [[ 0.06753404  0.09819474  0.         -0.9514527 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [True, False, False, False, True, False]
State prediction error at timestep 22 is 0.012
Current timestep = 23. State = [[-0.34637254  0.09097518]]. Action = [[-0.02280841  0.06887992  0.          0.03624845]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [True, False, False, False, True, False]
State prediction error at timestep 23 is 0.012
Current timestep = 24. State = [[-0.34595144  0.09983452]]. Action = [[ 0.03349089  0.09955809  0.         -0.682824  ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [True, False, False, False, True, False]
State prediction error at timestep 24 is 0.012
Current timestep = 25. State = [[-0.34769988  0.10129546]]. Action = [[-0.0462237  -0.08078437  0.          0.63734305]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [True, False, False, False, True, False]
State prediction error at timestep 25 is 0.012
Current timestep = 26. State = [[-0.3471048   0.10132255]]. Action = [[ 0.04534339  0.01859118  0.         -0.01341397]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [True, False, False, False, True, False]
State prediction error at timestep 26 is 0.012
Current timestep = 27. State = [[-0.34855047  0.09972642]]. Action = [[-0.05272523 -0.06325215  0.         -0.01878482]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [True, False, False, False, True, False]
State prediction error at timestep 27 is 0.012
Current timestep = 28. State = [[-0.3532493   0.09910354]]. Action = [[-0.07307081  0.01494579  0.         -0.91120285]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [True, False, False, False, True, False]
State prediction error at timestep 28 is 0.012
Current timestep = 29. State = [[-0.35287148  0.10273589]]. Action = [[ 0.05071848  0.05536649  0.         -0.4208697 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [True, False, False, False, True, False]
State prediction error at timestep 29 is 0.012
Current timestep = 30. State = [[-0.35218334  0.10851215]]. Action = [[-0.01370352  0.06336819  0.         -0.95380545]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [True, False, False, False, True, False]
State prediction error at timestep 30 is 0.012
Current timestep = 31. State = [[-0.3536865   0.11211143]]. Action = [[-0.02395083  0.01285665  0.          0.84736323]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [True, False, False, False, True, False]
State prediction error at timestep 31 is 0.012
Current timestep = 32. State = [[-0.35437024  0.10982646]]. Action = [[ 4.3716282e-04 -7.0835866e-02  0.0000000e+00 -4.9097490e-01]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [True, False, False, False, True, False]
State prediction error at timestep 32 is 0.012
Current timestep = 33. State = [[-0.3580955  0.1039487]]. Action = [[-0.07968862 -0.07912775  0.         -0.9374181 ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [True, False, False, False, True, False]
State prediction error at timestep 33 is 0.012
Current timestep = 34. State = [[-0.35911888  0.1018911 ]]. Action = [[0.0229729  0.01553579 0.         0.09854746]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [True, False, False, False, True, False]
State prediction error at timestep 34 is 0.012
Current timestep = 35. State = [[-0.35975063  0.10018756]]. Action = [[-0.02379552 -0.03595639  0.          0.6699455 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [True, False, False, False, True, False]
State prediction error at timestep 35 is 0.012
Current timestep = 36. State = [[-0.35604706  0.09846102]]. Action = [[ 0.09312334 -0.00839349  0.          0.02484822]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [True, False, False, False, True, False]
State prediction error at timestep 36 is 0.012
Current timestep = 37. State = [[-0.35023677  0.09562571]]. Action = [[ 0.0663007  -0.04746206  0.          0.314659  ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [True, False, False, False, True, False]
State prediction error at timestep 37 is 0.012
Current timestep = 38. State = [[-0.34945175  0.09013586]]. Action = [[-0.03301517 -0.06903735  0.         -0.56067777]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [True, False, False, False, True, False]
State prediction error at timestep 38 is 0.012
Current timestep = 39. State = [[-0.3508825   0.08485866]]. Action = [[-0.02143808 -0.03881108  0.          0.5556381 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [True, False, False, False, True, False]
State prediction error at timestep 39 is 0.012
Current timestep = 40. State = [[-0.35545126  0.0867199 ]]. Action = [[-0.09060122  0.09276371  0.          0.32077074]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [True, False, False, False, True, False]
State prediction error at timestep 40 is 0.012
Current timestep = 41. State = [[-0.35638398  0.08659129]]. Action = [[ 0.04349054 -0.03881253  0.         -0.17703742]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [True, False, False, False, True, False]
State prediction error at timestep 41 is 0.012
Current timestep = 42. State = [[-0.35685113  0.08509924]]. Action = [[-0.03742965  0.00716915  0.          0.46081853]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [True, False, False, False, True, False]
State prediction error at timestep 42 is 0.012
Current timestep = 43. State = [[-0.35458818  0.08746287]]. Action = [[ 0.06237604  0.05458137  0.         -0.7390872 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [True, False, False, False, True, False]
State prediction error at timestep 43 is 0.012
Current timestep = 44. State = [[-0.35331395  0.0930009 ]]. Action = [[-0.00907054  0.07323664  0.         -0.0730992 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [True, False, False, False, True, False]
State prediction error at timestep 44 is 0.012
Current timestep = 45. State = [[-0.35140714  0.09501792]]. Action = [[ 0.04537082 -0.01607694  0.         -0.51758724]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [True, False, False, False, True, False]
State prediction error at timestep 45 is 0.012
Current timestep = 46. State = [[-0.34844783  0.09752999]]. Action = [[0.03811892 0.04228497 0.         0.02757192]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [True, False, False, False, True, False]
State prediction error at timestep 46 is 0.012
Current timestep = 47. State = [[-0.34806824  0.09823938]]. Action = [[-0.01317835 -0.02618026  0.          0.755185  ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [True, False, False, False, True, False]
State prediction error at timestep 47 is 0.012
Current timestep = 48. State = [[-0.35061145  0.0990768 ]]. Action = [[-0.04631549  0.02226819  0.          0.37288344]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [True, False, False, False, True, False]
State prediction error at timestep 48 is 0.012
Current timestep = 49. State = [[-0.34973714  0.10177531]]. Action = [[0.04538212 0.03099369 0.         0.8847685 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [True, False, False, False, True, False]
State prediction error at timestep 49 is 0.012
Current timestep = 50. State = [[-0.3500031  0.0993887]]. Action = [[-0.03130955 -0.08020533  0.         -0.02700591]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [True, False, False, False, True, False]
State prediction error at timestep 50 is 0.012
Current timestep = 51. State = [[-0.34702787  0.10136718]]. Action = [[0.08275392 0.09060951 0.         0.1242373 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 51 is [True, False, False, False, True, False]
State prediction error at timestep 51 is 0.012
Current timestep = 52. State = [[-0.34109655  0.10075879]]. Action = [[ 0.07275843 -0.08305749  0.          0.5712166 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 52 is [True, False, False, False, True, False]
State prediction error at timestep 52 is 0.012
Current timestep = 53. State = [[-0.34038907  0.09765032]]. Action = [[-0.04576635 -0.02269816  0.         -0.8974389 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 53 is [True, False, False, False, True, False]
State prediction error at timestep 53 is 0.012
Current timestep = 54. State = [[-0.343476    0.09214219]]. Action = [[-0.04895029 -0.08923292  0.          0.16367233]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 54 is [True, False, False, False, True, False]
State prediction error at timestep 54 is 0.012
Current timestep = 55. State = [[-0.34609008  0.08507653]]. Action = [[-0.03475114 -0.07091607  0.          0.7207265 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 55 is [True, False, False, False, True, False]
State prediction error at timestep 55 is 0.012
Current timestep = 56. State = [[-0.34556964  0.0839247 ]]. Action = [[0.02381404 0.04445919 0.         0.91396666]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 56 is [True, False, False, False, True, False]
State prediction error at timestep 56 is 0.012
Current timestep = 57. State = [[-0.34020746  0.08132663]]. Action = [[ 0.09283268 -0.06270957  0.         -0.27012765]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 57 is [True, False, False, False, True, False]
State prediction error at timestep 57 is 0.012
Current timestep = 58. State = [[-0.3373388   0.07510237]]. Action = [[-0.00675305 -0.07176851  0.          0.02913284]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 58 is [True, False, False, False, True, False]
State prediction error at timestep 58 is 0.012
Current timestep = 59. State = [[-0.3408823   0.07594908]]. Action = [[-0.08985103  0.09186571  0.         -0.01006943]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 59 is [True, False, False, False, True, False]
State prediction error at timestep 59 is 0.012
Current timestep = 60. State = [[-0.34197646  0.08061116]]. Action = [[0.03257651 0.06013202 0.         0.36233544]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 60 is [True, False, False, False, True, False]
State prediction error at timestep 60 is 0.012
Current timestep = 61. State = [[-0.33720085  0.08235268]]. Action = [[ 0.08748408 -0.0035544   0.          0.6086904 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 61 is [True, False, False, False, True, False]
State prediction error at timestep 61 is 0.012
Current timestep = 62. State = [[-0.33513924  0.07923858]]. Action = [[-0.0061772  -0.06493673  0.         -0.59949154]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 62 is [True, False, False, False, True, False]
State prediction error at timestep 62 is 0.012
Current timestep = 63. State = [[-0.33339462  0.08023684]]. Action = [[ 0.03622233  0.06289604  0.         -0.9037737 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 63 is [True, False, False, False, True, False]
State prediction error at timestep 63 is 0.012
Current timestep = 64. State = [[-0.33451492  0.08245625]]. Action = [[-0.0444268   0.00884514  0.         -0.55001134]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 64 is [True, False, False, False, True, False]
State prediction error at timestep 64 is 0.012
Current timestep = 65. State = [[-0.33925915  0.08289431]]. Action = [[-0.07457881  0.00533535  0.         -0.73126566]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 65 is [True, False, False, False, True, False]
State prediction error at timestep 65 is 0.012
Current timestep = 66. State = [[-0.34015077  0.07961228]]. Action = [[ 0.02870005 -0.06568596  0.         -0.78596085]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 66 is [True, False, False, False, True, False]
State prediction error at timestep 66 is 0.012
Current timestep = 67. State = [[-0.3345007   0.07600594]]. Action = [[ 0.09941655 -0.03260429  0.          0.7270007 ]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 67 is [True, False, False, False, True, False]
State prediction error at timestep 67 is 0.012
Current timestep = 68. State = [[-0.3306882  0.0794834]]. Action = [[0.0126427  0.08787294 0.         0.43771553]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 68 is [True, False, False, False, True, False]
State prediction error at timestep 68 is 0.012
Current timestep = 69. State = [[-0.333924    0.07965299]]. Action = [[-0.08297069 -0.05488757  0.          0.3013432 ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 69 is [True, False, False, False, True, False]
State prediction error at timestep 69 is 0.012
Current timestep = 70. State = [[-0.33678     0.07651801]]. Action = [[-0.01454542 -0.02396128  0.          0.02888215]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 70 is [True, False, False, False, True, False]
State prediction error at timestep 70 is 0.012
Current timestep = 71. State = [[-0.3369824   0.07502009]]. Action = [[ 0.00488553 -0.00518494  0.         -0.54344183]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 71 is [True, False, False, False, True, False]
State prediction error at timestep 71 is 0.012
Current timestep = 72. State = [[-0.34010738  0.07299328]]. Action = [[-0.06774455 -0.02733359  0.          0.9019809 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 72 is [True, False, False, False, True, False]
State prediction error at timestep 72 is 0.012
Current timestep = 73. State = [[-0.34122527  0.07650602]]. Action = [[ 0.01881512  0.09733189  0.         -0.14095664]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 73 is [True, False, False, False, True, False]
State prediction error at timestep 73 is 0.012
Current timestep = 74. State = [[-0.34180078  0.07544515]]. Action = [[-0.01836509 -0.0853783   0.         -0.5593137 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 74 is [True, False, False, False, True, False]
State prediction error at timestep 74 is 0.012
Current timestep = 75. State = [[-0.34477377  0.06905899]]. Action = [[-0.04543436 -0.07269826  0.         -0.39439988]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 75 is [True, False, False, False, True, False]
State prediction error at timestep 75 is 0.012
Current timestep = 76. State = [[-0.34821987  0.06596109]]. Action = [[-3.7618410e-02  1.8163025e-04  0.0000000e+00  7.1356511e-01]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 76 is [True, False, False, False, True, False]
State prediction error at timestep 76 is 0.012
Current timestep = 77. State = [[-0.3504189   0.06114768]]. Action = [[-0.01348653 -0.07660855  0.         -0.311545  ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 77 is [True, False, False, False, True, False]
State prediction error at timestep 77 is 0.012
Current timestep = 78. State = [[-0.35090852  0.05301463]]. Action = [[ 0.0088176  -0.09705828  0.          0.51455307]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 78 is [True, False, False, False, True, False]
State prediction error at timestep 78 is 0.012
Current timestep = 79. State = [[-0.35517657  0.0458708 ]]. Action = [[-0.08410595 -0.05526781  0.         -0.64967614]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 79 is [True, False, False, False, True, False]
State prediction error at timestep 79 is 0.012
Current timestep = 80. State = [[-0.3583777   0.03922074]]. Action = [[-0.00273821 -0.06441283  0.         -0.23225856]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 80 is [True, False, False, False, True, False]
State prediction error at timestep 80 is 0.012
Current timestep = 81. State = [[-0.35669306  0.03428724]]. Action = [[ 0.0523889  -0.02938996  0.         -0.47577   ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 81 is [True, False, False, False, True, False]
State prediction error at timestep 81 is 0.012
Current timestep = 82. State = [[-0.3592639   0.03625135]]. Action = [[-0.08084679  0.09289929  0.         -0.83660877]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 82 is [True, False, False, False, True, False]
State prediction error at timestep 82 is 0.012
Current timestep = 83. State = [[-0.3586516   0.03908461]]. Action = [[ 0.09557936  0.0084514   0.         -0.7967107 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 83 is [True, False, False, False, True, False]
State prediction error at timestep 83 is 0.012
Current timestep = 84. State = [[-0.356186    0.03930607]]. Action = [[ 1.0477938e-02 -7.7143312e-04  0.0000000e+00 -9.0358460e-01]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 84 is [True, False, False, False, True, False]
State prediction error at timestep 84 is 0.012
Current timestep = 85. State = [[-0.35430267  0.04072246]]. Action = [[ 0.03765007  0.03227519  0.         -0.30874026]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 85 is [True, False, False, False, True, False]
State prediction error at timestep 85 is 0.012
Current timestep = 86. State = [[-0.3544343  0.038897 ]]. Action = [[-0.01675708 -0.05415622  0.         -0.28540534]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 86 is [True, False, False, False, True, False]
State prediction error at timestep 86 is 0.012
Current timestep = 87. State = [[-0.35790393  0.03594785]]. Action = [[-0.05287606 -0.01641592  0.         -0.12867564]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 87 is [True, False, False, False, True, False]
State prediction error at timestep 87 is 0.012
Current timestep = 88. State = [[-0.36000243  0.03424538]]. Action = [[-0.00321083 -0.00711001  0.          0.3568728 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 88 is [True, False, False, False, True, False]
State prediction error at timestep 88 is 0.012
Current timestep = 89. State = [[-0.36304033  0.02876998]]. Action = [[-0.05046738 -0.09045341  0.          0.9829929 ]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 89 is [True, False, False, False, True, False]
State prediction error at timestep 89 is 0.012
Current timestep = 90. State = [[-0.36826694  0.0290245 ]]. Action = [[-0.06923585  0.08169415  0.          0.30456305]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 90 is [True, False, False, False, True, False]
State prediction error at timestep 90 is 0.012
Current timestep = 91. State = [[-0.37576252  0.03300135]]. Action = [[-0.0972987   0.05307455  0.         -0.79303753]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 91 is [True, False, False, False, True, False]
State prediction error at timestep 91 is 0.012
Current timestep = 92. State = [[-0.379077   0.0312198]]. Action = [[ 0.02130534 -0.06689826  0.         -0.19529057]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 92 is [True, False, False, False, True, False]
State prediction error at timestep 92 is 0.012
Current timestep = 93. State = [[-0.37906626  0.03218566]]. Action = [[0.0036811  0.06034426 0.         0.37502968]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 93 is [True, False, False, False, True, False]
State prediction error at timestep 93 is 0.012
Current timestep = 94. State = [[-0.3776967   0.03446839]]. Action = [[0.03166024 0.00575425 0.         0.10213578]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 94 is [True, False, False, False, True, False]
State prediction error at timestep 94 is 0.012
Current timestep = 95. State = [[-0.37861532  0.03725697]]. Action = [[-0.02989867  0.04017638  0.         -0.81921107]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 95 is [True, False, False, False, True, False]
State prediction error at timestep 95 is 0.012
Current timestep = 96. State = [[-0.38041312  0.04040467]]. Action = [[-0.00971439  0.0301424   0.         -0.04370892]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 96 is [True, False, False, False, True, False]
State prediction error at timestep 96 is 0.012
Current timestep = 97. State = [[-0.37726617  0.04438083]]. Action = [[ 0.0807774   0.04114463  0.         -0.6593675 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 97 is [True, False, False, False, True, False]
State prediction error at timestep 97 is 0.012
Current timestep = 98. State = [[-0.3772648   0.04785824]]. Action = [[-0.03965494  0.01769154  0.          0.92147255]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 98 is [True, False, False, False, True, False]
State prediction error at timestep 98 is 0.012
Current timestep = 99. State = [[-0.38082084  0.05060938]]. Action = [[-0.03942654  0.02698264  0.         -0.16999316]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 99 is [True, False, False, False, True, False]
State prediction error at timestep 99 is 0.012
Current timestep = 100. State = [[-0.3827007   0.05217366]]. Action = [[0.         0.         0.         0.11940181]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 100 is [True, False, False, False, True, False]
State prediction error at timestep 100 is 0.012
Current timestep = 101. State = [[-0.3833919   0.05309223]]. Action = [[0.         0.         0.         0.28773856]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 101 is [True, False, False, False, True, False]
State prediction error at timestep 101 is 0.012
Current timestep = 102. State = [[-0.3839231   0.05392424]]. Action = [[0.        0.        0.        0.2768674]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 102 is [True, False, False, False, True, False]
State prediction error at timestep 102 is 0.012
Current timestep = 103. State = [[-0.37997082  0.05457202]]. Action = [[ 0.08918381 -0.00831923  0.         -0.28873467]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 103 is [True, False, False, False, True, False]
State prediction error at timestep 103 is 0.012
Current timestep = 104. State = [[-0.3775215   0.05552169]]. Action = [[ 0.         0.         0.        -0.7239744]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 104 is [True, False, False, False, True, False]
State prediction error at timestep 104 is 0.012
Current timestep = 105. State = [[-0.37814355  0.05430682]]. Action = [[-0.01482176 -0.03528193  0.         -0.9768368 ]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 105 is [True, False, False, False, True, False]
State prediction error at timestep 105 is 0.012
Current timestep = 106. State = [[-0.3743875   0.05292644]]. Action = [[ 0.08357575 -0.01348406  0.         -0.11461991]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 106 is [True, False, False, False, True, False]
State prediction error at timestep 106 is 0.012
Current timestep = 107. State = [[-0.37214398  0.05239976]]. Action = [[-0.01091077 -0.00968432  0.         -0.08456141]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 107 is [True, False, False, False, True, False]
State prediction error at timestep 107 is 0.012
Current timestep = 108. State = [[-0.37268028  0.05082266]]. Action = [[-0.01592769 -0.02231164  0.         -0.52216256]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 108 is [True, False, False, False, True, False]
State prediction error at timestep 108 is 0.012
Current timestep = 109. State = [[-0.3697625   0.05199992]]. Action = [[ 0.058874    0.04144724  0.         -0.8177222 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 109 is [True, False, False, False, True, False]
State prediction error at timestep 109 is 0.012
Current timestep = 110. State = [[-0.3634467   0.05375563]]. Action = [[ 0.08087202  0.00300796  0.         -0.9461646 ]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 110 is [True, False, False, False, True, False]
State prediction error at timestep 110 is 0.012
Current timestep = 111. State = [[-0.35619587  0.05867688]]. Action = [[0.08202185 0.07949492 0.         0.9906614 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 111 is [True, False, False, False, True, False]
State prediction error at timestep 111 is 0.012
Current timestep = 112. State = [[-0.34869844  0.06148092]]. Action = [[ 0.08528724 -0.01235012  0.         -0.96350336]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 112 is [True, False, False, False, True, False]
State prediction error at timestep 112 is 0.012
Current timestep = 113. State = [[-0.34852085  0.06327067]]. Action = [[-0.07417892  0.0336945   0.          0.84478045]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 113 is [True, False, False, False, True, False]
State prediction error at timestep 113 is 0.012
Current timestep = 114. State = [[-0.34702304  0.06965945]]. Action = [[0.06916561 0.0973826  0.         0.2454791 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 114 is [True, False, False, False, True, False]
State prediction error at timestep 114 is 0.012
Current timestep = 115. State = [[-0.34587213  0.07789532]]. Action = [[-0.01158882  0.08103619  0.         -0.38037252]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 115 is [True, False, False, False, True, False]
State prediction error at timestep 115 is 0.012
Current timestep = 116. State = [[-0.34470934  0.08030502]]. Action = [[ 0.03212031 -0.03029605  0.          0.67524683]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 116 is [True, False, False, False, True, False]
State prediction error at timestep 116 is 0.012
Current timestep = 117. State = [[-0.34092122  0.08529112]]. Action = [[0.05970105 0.08509628 0.         0.4118315 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 117 is [True, False, False, False, True, False]
State prediction error at timestep 117 is 0.012
Current timestep = 118. State = [[-0.3394518   0.09099957]]. Action = [[-0.00548008  0.03136968  0.          0.8506783 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 118 is [True, False, False, False, True, False]
State prediction error at timestep 118 is 0.012
Current timestep = 119. State = [[-0.33578995  0.09631811]]. Action = [[ 0.07496005  0.0512901   0.         -0.5467224 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 119 is [True, False, False, False, True, False]
State prediction error at timestep 119 is 0.012
Current timestep = 120. State = [[-0.332836    0.09905261]]. Action = [[ 0.01337998 -0.0130128   0.         -0.27900124]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 120 is [True, False, False, False, True, False]
State prediction error at timestep 120 is 0.012
Current timestep = 121. State = [[-0.33534127  0.10323596]]. Action = [[-0.07190643  0.06262528  0.         -0.14114434]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 121 is [True, False, False, False, True, False]
State prediction error at timestep 121 is 0.012
Current timestep = 122. State = [[-0.33312473  0.10588741]]. Action = [[ 0.08701735 -0.01347913  0.          0.5711534 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 122 is [True, False, False, False, True, False]
State prediction error at timestep 122 is 0.012
Current timestep = 123. State = [[-0.3306692   0.10509402]]. Action = [[-0.01879687 -0.03573602  0.          0.10692334]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 123 is [True, False, False, False, True, False]
State prediction error at timestep 123 is 0.012
Current timestep = 124. State = [[-0.32887653  0.10364962]]. Action = [[ 0.01601466 -0.02323282  0.          0.21763086]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 124 is [True, False, False, False, True, False]
State prediction error at timestep 124 is 0.012
Current timestep = 125. State = [[-0.33075103  0.10383083]]. Action = [[-0.07914612  0.01010527  0.         -0.05132365]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 125 is [True, False, False, False, True, False]
State prediction error at timestep 125 is 0.012
Current timestep = 126. State = [[-0.32853726  0.1040743 ]]. Action = [[ 0.06825583 -0.00703262  0.         -0.04624939]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 126 is [True, False, False, False, True, False]
State prediction error at timestep 126 is 0.012
Current timestep = 127. State = [[-0.32757473  0.10443934]]. Action = [[-0.04754002  0.00680681  0.          0.01879144]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 127 is [True, False, False, False, True, False]
State prediction error at timestep 127 is 0.012
Current timestep = 128. State = [[-0.3321207   0.10560819]]. Action = [[-0.09623236  0.02034541  0.          0.18736851]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 128 is [True, False, False, False, True, False]
State prediction error at timestep 128 is 0.012
Current timestep = 129. State = [[-0.33863485  0.11002279]]. Action = [[-0.09710603  0.07774549  0.         -0.909334  ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 129 is [True, False, False, False, True, False]
State prediction error at timestep 129 is 0.012
Current timestep = 130. State = [[-0.3452259   0.10855813]]. Action = [[-0.0848588  -0.08023626  0.          0.97973585]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 130 is [True, False, False, False, True, False]
State prediction error at timestep 130 is 0.012
Current timestep = 131. State = [[-0.3470789  0.1103767]]. Action = [[ 0.02452739  0.08706162  0.         -0.33817333]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 131 is [True, False, False, False, True, False]
State prediction error at timestep 131 is 0.012
Current timestep = 132. State = [[-0.34733322  0.10996041]]. Action = [[-1.5713274e-04 -7.2476134e-02  0.0000000e+00 -9.3395925e-01]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 132 is [True, False, False, False, True, False]
State prediction error at timestep 132 is 0.012
Current timestep = 133. State = [[-0.34723446  0.10480531]]. Action = [[ 0.01759513 -0.06927857  0.          0.3322369 ]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 133 is [True, False, False, False, True, False]
State prediction error at timestep 133 is 0.012
Current timestep = 134. State = [[-0.34342983  0.09808065]]. Action = [[ 0.08368777 -0.08932294  0.         -0.1830532 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 134 is [True, False, False, False, True, False]
State prediction error at timestep 134 is 0.012
Current timestep = 135. State = [[-0.3432975   0.09609204]]. Action = [[-0.04159392  0.02638268  0.         -0.263579  ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 135 is [True, False, False, False, True, False]
State prediction error at timestep 135 is 0.012
Current timestep = 136. State = [[-0.343066   0.0952104]]. Action = [[ 0.04214465 -0.01857676  0.         -0.5455249 ]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 136 is [True, False, False, False, True, False]
State prediction error at timestep 136 is 0.012
Current timestep = 137. State = [[-0.34051394  0.09623879]]. Action = [[ 0.04537598  0.04021681  0.         -0.8251441 ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 137 is [True, False, False, False, True, False]
State prediction error at timestep 137 is 0.012
Current timestep = 138. State = [[-0.34026352  0.09267601]]. Action = [[-0.00896082 -0.08648797  0.         -0.6011182 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 138 is [True, False, False, False, True, False]
State prediction error at timestep 138 is 0.012
Current timestep = 139. State = [[-0.34073898  0.0843986 ]]. Action = [[ 0.00144257 -0.09740138  0.          0.4732709 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 139 is [True, False, False, False, True, False]
State prediction error at timestep 139 is 0.012
Current timestep = 140. State = [[-0.33681765  0.08326391]]. Action = [[0.0879296  0.06759537 0.         0.75975275]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 140 is [True, False, False, False, True, False]
State prediction error at timestep 140 is 0.012
Current timestep = 141. State = [[-0.3325039   0.08913265]]. Action = [[ 0.04135331  0.09023546  0.         -0.06988275]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 141 is [True, False, False, False, True, False]
State prediction error at timestep 141 is 0.012
Current timestep = 142. State = [[-0.3326811   0.09530831]]. Action = [[-0.02416668  0.06962629  0.          0.17399645]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 142 is [True, False, False, False, True, False]
State prediction error at timestep 142 is 0.012
Current timestep = 143. State = [[-0.33176142  0.10236397]]. Action = [[ 0.04110511  0.09079217  0.         -0.52428895]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 143 is [True, False, False, False, True, False]
State prediction error at timestep 143 is 0.012
Current timestep = 144. State = [[-0.32820258  0.10566758]]. Action = [[ 0.06174278 -0.00877477  0.         -0.70893675]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 144 is [True, False, False, False, True, False]
State prediction error at timestep 144 is 0.012
Current timestep = 145. State = [[-0.32248968  0.10537123]]. Action = [[ 0.08646726 -0.02543203  0.          0.4767716 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 145 is [True, False, False, False, True, False]
State prediction error at timestep 145 is 0.012
Current timestep = 146. State = [[-0.31960392  0.10360742]]. Action = [[ 0.00307836 -0.03747223  0.          0.24625003]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 146 is [True, False, False, False, True, False]
State prediction error at timestep 146 is 0.012
Current timestep = 147. State = [[-0.32225153  0.10383776]]. Action = [[-0.07419313  0.01984207  0.         -0.9420088 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 147 is [True, False, False, False, True, False]
State prediction error at timestep 147 is 0.012
Current timestep = 148. State = [[-0.3247496   0.10522699]]. Action = [[-0.02395105  0.01243401  0.         -0.21106172]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 148 is [True, False, False, False, True, False]
State prediction error at timestep 148 is 0.012
Current timestep = 149. State = [[-0.32600904  0.10990574]]. Action = [[-0.01996619  0.07638253  0.         -0.31137848]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 149 is [True, False, False, False, True, False]
State prediction error at timestep 149 is 0.012
Current timestep = 150. State = [[-0.3259553   0.11054876]]. Action = [[ 0.00639953 -0.04726395  0.         -0.23423773]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 150 is [True, False, False, False, True, False]
State prediction error at timestep 150 is 0.012
Current timestep = 151. State = [[-0.32716498  0.11382077]]. Action = [[-0.03535977  0.077981    0.         -0.5698542 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 151 is [True, False, False, False, True, False]
State prediction error at timestep 151 is 0.012
Current timestep = 152. State = [[-0.33206296  0.11463366]]. Action = [[-0.08546834 -0.04167936  0.         -0.30824268]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 152 is [True, False, False, False, True, False]
State prediction error at timestep 152 is 0.012
Current timestep = 153. State = [[-0.33514437  0.11087489]]. Action = [[-0.01909339 -0.05993737  0.         -0.49667573]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 153 is [True, False, False, False, True, False]
State prediction error at timestep 153 is 0.012
Current timestep = 154. State = [[-0.3364462   0.10447466]]. Action = [[-0.01765736 -0.09105944  0.          0.677847  ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 154 is [True, False, False, False, True, False]
State prediction error at timestep 154 is 0.012
Current timestep = 155. State = [[-0.33990282  0.09976471]]. Action = [[-0.06454287 -0.02857007  0.         -0.58711743]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 155 is [True, False, False, False, True, False]
State prediction error at timestep 155 is 0.012
Current timestep = 156. State = [[-0.33746687  0.09485999]]. Action = [[ 0.09631538 -0.06606284  0.          0.2608112 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 156 is [True, False, False, False, True, False]
State prediction error at timestep 156 is 0.012
Current timestep = 157. State = [[-0.33700913  0.08825887]]. Action = [[-0.05680401 -0.06990388  0.          0.16281736]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 157 is [True, False, False, False, True, False]
State prediction error at timestep 157 is 0.012
Current timestep = 158. State = [[-0.33903313  0.08071859]]. Action = [[-0.01908929 -0.07745232  0.         -0.32034814]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 158 is [True, False, False, False, True, False]
State prediction error at timestep 158 is 0.012
Current timestep = 159. State = [[-0.33562073  0.07298562]]. Action = [[ 0.08050441 -0.07333989  0.          0.94406533]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 159 is [True, False, False, False, True, False]
State prediction error at timestep 159 is 0.012
Current timestep = 160. State = [[-0.33193564  0.0685949 ]]. Action = [[ 0.02443065 -0.00784156  0.         -0.8740796 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 160 is [True, False, False, False, True, False]
State prediction error at timestep 160 is 0.012
Current timestep = 161. State = [[-0.32698962  0.06834152]]. Action = [[0.07942613 0.03452214 0.         0.36968005]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 161 is [True, False, False, False, True, False]
State prediction error at timestep 161 is 0.012
Current timestep = 162. State = [[-0.32503     0.06760879]]. Action = [[-0.00881167 -0.00804116  0.         -0.33206046]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 162 is [True, False, False, False, True, False]
State prediction error at timestep 162 is 0.012
Current timestep = 163. State = [[-0.32675076  0.06898116]]. Action = [[-0.03323823  0.05922397  0.          0.6142738 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 163 is [True, False, False, False, True, False]
State prediction error at timestep 163 is 0.012
Current timestep = 164. State = [[-0.3262176   0.07173918]]. Action = [[ 0.03466316  0.0387822   0.         -0.14046508]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 164 is [True, False, False, False, True, False]
State prediction error at timestep 164 is 0.012
Current timestep = 165. State = [[-0.32083398  0.07596582]]. Action = [[ 0.09909924  0.05962933  0.         -0.28255308]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 165 is [True, False, False, False, True, False]
State prediction error at timestep 165 is 0.012
Current timestep = 166. State = [[-0.3166917   0.07921208]]. Action = [[ 0.03544044  0.01555784  0.         -0.71008694]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 166 is [True, False, False, False, True, False]
State prediction error at timestep 166 is 0.012
Current timestep = 167. State = [[-0.31283346  0.07954431]]. Action = [[ 0.06100287 -0.01755409  0.         -0.9477239 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 167 is [True, False, False, False, True, False]
State prediction error at timestep 167 is 0.012
Current timestep = 168. State = [[-0.30841452  0.08320753]]. Action = [[0.05557228 0.06844025 0.         0.3619163 ]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 168 is [True, False, False, False, True, False]
State prediction error at timestep 168 is 0.012
Current timestep = 169. State = [[-0.30236387  0.08136532]]. Action = [[ 0.08749374 -0.09507672  0.         -0.6846394 ]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 169 is [True, False, False, False, True, False]
State prediction error at timestep 169 is 0.012
Current timestep = 170. State = [[-0.29891998  0.08262692]]. Action = [[ 0.00155808  0.0683658   0.         -0.57995296]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 170 is [True, False, False, False, True, False]
State prediction error at timestep 170 is 0.012
Current timestep = 171. State = [[-0.29583132  0.08618171]]. Action = [[ 0.04960083  0.02149124  0.         -0.50004685]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 171 is [True, False, False, False, True, False]
State prediction error at timestep 171 is 0.012
Current timestep = 172. State = [[-0.296035    0.09067347]]. Action = [[-0.04574952  0.06167934  0.         -0.32204366]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 172 is [True, False, False, False, True, False]
State prediction error at timestep 172 is 0.012
Current timestep = 173. State = [[-0.2985937  0.088379 ]]. Action = [[-0.0430637  -0.09628773  0.          0.6125511 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 173 is [True, False, False, False, True, False]
State prediction error at timestep 173 is 0.012
Current timestep = 174. State = [[-0.30225655  0.08667937]]. Action = [[-0.07040967  0.01563574  0.          0.65946627]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 174 is [True, False, False, False, True, False]
State prediction error at timestep 174 is 0.012
Current timestep = 175. State = [[-0.30343843  0.08901253]]. Action = [[-0.00135913  0.03624814  0.         -0.50893474]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 175 is [True, False, False, False, True, False]
State prediction error at timestep 175 is 0.012
Current timestep = 176. State = [[-0.2995179   0.09000118]]. Action = [[ 0.07167061 -0.01313334  0.         -0.30285203]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 176 is [True, False, False, False, True, False]
State prediction error at timestep 176 is 0.012
Current timestep = 177. State = [[-0.29698944  0.0939125 ]]. Action = [[ 0.00078374  0.07220586  0.         -0.06658101]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 177 is [True, False, False, False, True, False]
State prediction error at timestep 177 is 0.012
Current timestep = 178. State = [[-0.2950161   0.10008883]]. Action = [[ 0.0339006   0.06569939  0.         -0.03266454]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 178 is [True, False, False, False, True, False]
State prediction error at timestep 178 is 0.012
Current timestep = 179. State = [[-0.29236433  0.09879413]]. Action = [[ 0.0317174  -0.08609602  0.         -0.6378873 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 179 is [True, False, False, False, True, False]
State prediction error at timestep 179 is 0.012
Current timestep = 180. State = [[-0.2920032  0.0945394]]. Action = [[-0.02266153 -0.04613214  0.          0.69155   ]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 180 is [True, False, False, False, True, False]
State prediction error at timestep 180 is 0.012
Current timestep = 181. State = [[-0.29438066  0.09486125]]. Action = [[-0.05102316  0.03555208  0.          0.8183851 ]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 181 is [True, False, False, False, True, False]
State prediction error at timestep 181 is 0.012
Current timestep = 182. State = [[-0.2932475   0.09143731]]. Action = [[ 0.04255792 -0.08809259  0.         -0.8239961 ]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 182 is [True, False, False, False, True, False]
State prediction error at timestep 182 is 0.012
Current timestep = 183. State = [[-0.2946188   0.09287234]]. Action = [[-0.07077293  0.08616778  0.         -0.18445301]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 183 is [True, False, False, False, True, False]
State prediction error at timestep 183 is 0.012
Current timestep = 184. State = [[-0.29516032  0.09652515]]. Action = [[0.02589329 0.02521404 0.         0.8529171 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 184 is [True, False, False, False, True, False]
State prediction error at timestep 184 is 0.012
Current timestep = 185. State = [[-0.2914773   0.09865861]]. Action = [[ 0.06569769  0.01783788  0.         -0.38379776]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 185 is [True, False, False, False, True, False]
State prediction error at timestep 185 is 0.012
Current timestep = 186. State = [[-0.29248026  0.09619938]]. Action = [[-0.05819391 -0.06710884  0.         -0.94576174]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 186 is [True, False, False, False, True, False]
State prediction error at timestep 186 is 0.012
Current timestep = 187. State = [[-0.29056403  0.09876313]]. Action = [[0.07454874 0.09273987 0.         0.47669947]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 187 is [True, False, False, False, True, False]
State prediction error at timestep 187 is 0.012
Current timestep = 188. State = [[-0.2863319   0.10208242]]. Action = [[ 0.05260085  0.0025412   0.         -0.57161003]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 188 is [True, False, False, False, True, False]
State prediction error at timestep 188 is 0.012
Current timestep = 189. State = [[-0.28079045  0.10780864]]. Action = [[0.0878674  0.09567057 0.         0.1119225 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 189 is [True, False, False, False, True, False]
State prediction error at timestep 189 is 0.012
Current timestep = 190. State = [[-0.28093636  0.10775322]]. Action = [[-0.05437192 -0.08486065  0.          0.78376555]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 190 is [True, False, False, False, True, False]
State prediction error at timestep 190 is 0.012
Current timestep = 191. State = [[-0.28240052  0.1053206 ]]. Action = [[-0.00622382 -0.00950444  0.         -0.7951282 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 191 is [True, False, False, False, True, False]
State prediction error at timestep 191 is 0.012
Current timestep = 192. State = [[-0.2785674   0.10715013]]. Action = [[0.07846951 0.03925348 0.         0.23868382]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 192 is [True, False, False, False, True, False]
State prediction error at timestep 192 is 0.012
Current timestep = 193. State = [[-0.27190977  0.1037918 ]]. Action = [[ 0.08475376 -0.09730351  0.         -0.85029477]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 193 is [True, False, False, False, True, False]
State prediction error at timestep 193 is 0.012
Current timestep = 194. State = [[-0.26748955  0.10574751]]. Action = [[ 0.02459947  0.09512203  0.         -0.0240348 ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 194 is [True, False, False, False, True, False]
State prediction error at timestep 194 is 0.012
Current timestep = 195. State = [[-0.2671903   0.10508426]]. Action = [[-0.02676065 -0.06845657  0.          0.64145064]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 195 is [True, False, False, False, True, False]
State prediction error at timestep 195 is 0.012
Current timestep = 196. State = [[-0.26769987  0.09980233]]. Action = [[-0.01997313 -0.0633789   0.         -0.46609902]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 196 is [True, False, False, False, True, False]
State prediction error at timestep 196 is 0.012
Current timestep = 197. State = [[-0.2685497   0.10225616]]. Action = [[-0.02913294  0.09803899  0.         -0.04217392]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 197 is [True, False, False, False, True, False]
State prediction error at timestep 197 is 0.012
Current timestep = 198. State = [[-0.26887852  0.10602737]]. Action = [[-0.00518145  0.02210631  0.         -0.13174242]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 198 is [True, False, False, False, True, False]
State prediction error at timestep 198 is 0.012
Current timestep = 199. State = [[-0.26787165  0.10863589]]. Action = [[0.01377072 0.03175464 0.         0.46658075]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 199 is [True, False, False, False, True, False]
State prediction error at timestep 199 is 0.012
Current timestep = 200. State = [[-0.26284865  0.10681867]]. Action = [[ 0.08866837 -0.06372884  0.          0.8047106 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 200 is [True, False, False, False, True, False]
State prediction error at timestep 200 is 0.012
Current timestep = 201. State = [[-0.26410484  0.10730748]]. Action = [[-0.09963728  0.04562307  0.         -0.7303585 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 201 is [True, False, False, False, True, False]
State prediction error at timestep 201 is 0.012
Current timestep = 202. State = [[-0.26641768  0.11257698]]. Action = [[ 0.01372969  0.07401478  0.         -0.37497103]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 202 is [True, False, False, False, True, False]
State prediction error at timestep 202 is 0.012
Current timestep = 203. State = [[-0.26551214  0.11703464]]. Action = [[0.03079679 0.02936555 0.         0.88116693]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 203 is [True, False, False, False, True, False]
State prediction error at timestep 203 is 0.012
Current timestep = 204. State = [[-0.26994583  0.11921392]]. Action = [[-0.09553662  0.0074361   0.          0.56615937]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 204 is [True, False, False, False, True, False]
State prediction error at timestep 204 is 0.012
Current timestep = 205. State = [[-0.26984438  0.119782  ]]. Action = [[ 0.07862469 -0.01221822  0.         -0.00350201]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 205 is [True, False, False, False, True, False]
State prediction error at timestep 205 is 0.012
Current timestep = 206. State = [[-0.26947886  0.11873224]]. Action = [[-0.02758104 -0.02839027  0.          0.43885493]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 206 is [True, False, False, False, True, False]
State prediction error at timestep 206 is 0.012
Current timestep = 207. State = [[-0.27330548  0.11592019]]. Action = [[-0.06656671 -0.04742297  0.          0.9427171 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 207 is [True, False, False, False, True, False]
State prediction error at timestep 207 is 0.012
Current timestep = 208. State = [[-0.27071702  0.11191738]]. Action = [[ 0.09372016 -0.05449561  0.          0.99166226]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 208 is [True, False, False, False, True, False]
State prediction error at timestep 208 is 0.012
Current timestep = 209. State = [[-0.26669395  0.10785339]]. Action = [[ 0.01848885 -0.04243303  0.          0.32107306]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 209 is [True, False, False, False, True, False]
State prediction error at timestep 209 is 0.012
Current timestep = 210. State = [[-0.2616367   0.10983894]]. Action = [[0.07581138 0.07693285 0.         0.27240837]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 210 is [True, False, False, False, True, False]
State prediction error at timestep 210 is 0.012
Current timestep = 211. State = [[-0.25871217  0.11101931]]. Action = [[ 0.00561909 -0.01224796  0.         -0.4178825 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 211 is [True, False, False, False, True, False]
State prediction error at timestep 211 is 0.012
Current timestep = 212. State = [[-0.26248375  0.11460198]]. Action = [[-0.09821889  0.08508011  0.          0.60448813]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 212 is [True, False, False, False, True, False]
State prediction error at timestep 212 is 0.012
Current timestep = 213. State = [[-0.26684335  0.1197215 ]]. Action = [[-0.03787294  0.05345585  0.         -0.6106347 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 213 is [True, False, False, False, True, False]
State prediction error at timestep 213 is 0.012
Current timestep = 214. State = [[-0.2645822   0.12529673]]. Action = [[ 0.08194851  0.06537334  0.         -0.37116373]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 214 is [True, False, False, False, False, True]
State prediction error at timestep 214 is 0.012
Current timestep = 215. State = [[-0.26339397  0.12945312]]. Action = [[-0.00999141  0.02379422  0.         -0.535717  ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 215 is [True, False, False, False, False, True]
State prediction error at timestep 215 is 0.012
Current timestep = 216. State = [[-0.26149517  0.13441665]]. Action = [[ 0.05203732  0.06142607  0.         -0.7833507 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 216 is [True, False, False, False, False, True]
State prediction error at timestep 216 is 0.012
Current timestep = 217. State = [[-0.26493913  0.13673759]]. Action = [[-0.09518235 -0.01473077  0.          0.03574967]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 217 is [True, False, False, False, False, True]
State prediction error at timestep 217 is 0.012
Current timestep = 218. State = [[-0.26480547  0.1354769 ]]. Action = [[ 0.06755545 -0.04342345  0.         -0.55490094]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 218 is [True, False, False, False, False, True]
State prediction error at timestep 218 is 0.012
Current timestep = 219. State = [[-0.26409614  0.135995  ]]. Action = [[-0.02191421  0.01703962  0.          0.1606834 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 219 is [True, False, False, False, False, True]
State prediction error at timestep 219 is 0.012
Current timestep = 220. State = [[-0.26375553  0.13664596]]. Action = [[ 0.01412831 -0.01183335  0.         -0.653043  ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 220 is [True, False, False, False, False, True]
State prediction error at timestep 220 is 0.012
Current timestep = 221. State = [[-0.26541948  0.1410678 ]]. Action = [[-0.044709    0.08114203  0.          0.81247103]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 221 is [True, False, False, False, False, True]
State prediction error at timestep 221 is 0.012
Current timestep = 222. State = [[-0.27094373  0.14840573]]. Action = [[-0.08587576  0.08262318  0.          0.8246758 ]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 222 is [True, False, False, False, False, True]
State prediction error at timestep 222 is 0.012
Current timestep = 223. State = [[-0.27808383  0.15608789]]. Action = [[-0.08651321  0.07867614  0.          0.93394005]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 223 is [True, False, False, False, False, True]
State prediction error at timestep 223 is 0.012
Current timestep = 224. State = [[-0.28344494  0.16485314]]. Action = [[-0.0363778   0.09473156  0.         -0.4123146 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 224 is [True, False, False, False, False, True]
State prediction error at timestep 224 is 0.012
Current timestep = 225. State = [[-0.2816733  0.169639 ]]. Action = [[ 9.7632639e-02 -2.2386014e-04  0.0000000e+00  5.1452816e-01]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 225 is [True, False, False, False, False, True]
State prediction error at timestep 225 is 0.012
Current timestep = 226. State = [[-0.2830023   0.17332572]]. Action = [[-0.05765215  0.03545868  0.          0.5289302 ]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 226 is [True, False, False, False, False, True]
State prediction error at timestep 226 is 0.012
Current timestep = 227. State = [[-0.2820074   0.17169431]]. Action = [[ 0.07703767 -0.08573862  0.          0.08602011]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 227 is [True, False, False, False, False, True]
State prediction error at timestep 227 is 0.012
Current timestep = 228. State = [[-0.27908793  0.16747965]]. Action = [[ 0.03076085 -0.05657064  0.         -0.70641214]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 228 is [True, False, False, False, False, True]
State prediction error at timestep 228 is 0.012
Current timestep = 229. State = [[-0.2821789   0.17033157]]. Action = [[-0.08112167  0.0805572   0.         -0.54819727]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 229 is [True, False, False, False, False, True]
State prediction error at timestep 229 is 0.012
Current timestep = 230. State = [[-0.28567037  0.17083667]]. Action = [[-0.02027931 -0.04841634  0.          0.9498532 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 230 is [True, False, False, False, False, True]
State prediction error at timestep 230 is 0.012
Current timestep = 231. State = [[-0.28242588  0.17173602]]. Action = [[ 0.08933201  0.03565674  0.         -0.5562528 ]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 231 is [True, False, False, False, False, True]
State prediction error at timestep 231 is 0.012
Current timestep = 232. State = [[-0.2761989   0.16864717]]. Action = [[ 0.08178236 -0.08400054  0.          0.75736856]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 232 is [True, False, False, False, False, True]
State prediction error at timestep 232 is 0.012
Current timestep = 233. State = [[-0.27726907  0.17092098]]. Action = [[-0.08310437  0.09771391  0.          0.25492954]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 233 is [True, False, False, False, False, True]
State prediction error at timestep 233 is 0.012
Current timestep = 234. State = [[-0.27536342  0.17112958]]. Action = [[ 0.09362882 -0.05004777  0.          0.01931775]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 234 is [True, False, False, False, False, True]
State prediction error at timestep 234 is 0.012
Current timestep = 235. State = [[-0.27506372  0.17148817]]. Action = [[-0.05275721  0.03627472  0.         -0.12875408]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 235 is [True, False, False, False, False, True]
State prediction error at timestep 235 is 0.012
Current timestep = 236. State = [[-0.27365845  0.16747104]]. Action = [[ 0.05046607 -0.09847365  0.         -0.9721306 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 236 is [True, False, False, False, False, True]
State prediction error at timestep 236 is 0.012
Current timestep = 237. State = [[-0.26887566  0.16736762]]. Action = [[0.06234524 0.0633396  0.         0.4381032 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 237 is [True, False, False, False, False, True]
State prediction error at timestep 237 is 0.012
Current timestep = 238. State = [[-0.26425833  0.17211387]]. Action = [[0.05353069 0.06746554 0.         0.43462968]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 238 is [True, False, False, False, False, True]
State prediction error at timestep 238 is 0.012
Current timestep = 239. State = [[-0.26049453  0.1770547 ]]. Action = [[ 0.04239265  0.05968372  0.         -0.61793566]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 239 is [True, False, False, False, False, True]
State prediction error at timestep 239 is 0.012
Current timestep = 240. State = [[-0.2572899   0.17669185]]. Action = [[ 0.03337624 -0.046882    0.          0.7587408 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 240 is [True, False, False, False, False, True]
State prediction error at timestep 240 is 0.012
Current timestep = 241. State = [[-0.2552856   0.17511052]]. Action = [[ 0.00426346 -0.00932635  0.          0.20876658]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 241 is [True, False, False, False, False, True]
State prediction error at timestep 241 is 0.012
Current timestep = 242. State = [[-0.25575605  0.17163141]]. Action = [[-0.03706463 -0.06626555  0.          0.36524403]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 242 is [True, False, False, False, False, True]
State prediction error at timestep 242 is 0.012
Current timestep = 243. State = [[-0.2575212   0.17276089]]. Action = [[-0.04224936  0.05942445  0.         -0.5759227 ]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 243 is [True, False, False, False, False, True]
State prediction error at timestep 243 is 0.012
Current timestep = 244. State = [[-0.25918075  0.17687912]]. Action = [[-0.02609134  0.04302607  0.          0.02485895]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 244 is [True, False, False, False, False, True]
State prediction error at timestep 244 is 0.012
Current timestep = 245. State = [[-0.26101857  0.18293607]]. Action = [[-0.0294378   0.08185606  0.          0.70086753]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 245 is [True, False, False, False, False, True]
State prediction error at timestep 245 is 0.012
Current timestep = 246. State = [[-0.25881988  0.18646738]]. Action = [[0.06492827 0.00351547 0.         0.01838219]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 246 is [True, False, False, False, False, True]
State prediction error at timestep 246 is 0.012
Current timestep = 247. State = [[-0.2617996   0.19181353]]. Action = [[-0.09800553  0.08266083  0.          0.6473994 ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 247 is [True, False, False, False, False, True]
State prediction error at timestep 247 is 0.012
Current timestep = 248. State = [[-0.26838303  0.19764061]]. Action = [[-0.06673756  0.04162658  0.          0.14702559]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 248 is [True, False, False, False, False, True]
State prediction error at timestep 248 is 0.012
Current timestep = 249. State = [[-0.27277204  0.19563474]]. Action = [[-0.03351276 -0.09778798  0.         -0.7860285 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 249 is [True, False, False, False, False, True]
State prediction error at timestep 249 is 0.012
Current timestep = 250. State = [[-0.27732617  0.18963112]]. Action = [[-0.0643495  -0.08868106  0.          0.39860976]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 250 is [True, False, False, False, False, True]
State prediction error at timestep 250 is 0.012
Current timestep = 251. State = [[-0.27578926  0.18976107]]. Action = [[ 0.0872656   0.04713624  0.         -0.43543458]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 251 is [True, False, False, False, False, True]
State prediction error at timestep 251 is 0.012
Current timestep = 252. State = [[-0.27680779  0.19066405]]. Action = [[-0.06406257 -0.0146413   0.          0.7022412 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 252 is [True, False, False, False, False, True]
State prediction error at timestep 252 is 0.012
Current timestep = 253. State = [[-0.2836478   0.19001627]]. Action = [[-0.09831903 -0.01400302  0.          0.02466536]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 253 is [True, False, False, False, False, True]
State prediction error at timestep 253 is 0.012
Current timestep = 254. State = [[-0.284734    0.18865031]]. Action = [[ 0.05219635 -0.02322022  0.         -0.7885103 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 254 is [True, False, False, False, False, True]
State prediction error at timestep 254 is 0.012
Current timestep = 255. State = [[-0.28538412  0.1923617 ]]. Action = [[-0.02651195  0.0892221   0.         -0.8168889 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 255 is [True, False, False, False, False, True]
State prediction error at timestep 255 is 0.012
Current timestep = 256. State = [[-0.28818893  0.19702232]]. Action = [[-0.02270103  0.03821061  0.         -0.8023792 ]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 256 is [True, False, False, False, False, True]
State prediction error at timestep 256 is 0.012
Current timestep = 257. State = [[-0.28830817  0.20314848]]. Action = [[ 0.03832378  0.09020045  0.         -0.8241176 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 257 is [True, False, False, False, False, True]
State prediction error at timestep 257 is 0.012
Current timestep = 258. State = [[-0.28899857  0.20774399]]. Action = [[-0.00296441  0.02705752  0.         -0.7659553 ]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 258 is [True, False, False, False, False, True]
State prediction error at timestep 258 is 0.012
Current timestep = 259. State = [[-0.29319838  0.21230334]]. Action = [[-0.05658524  0.05703773  0.          0.68668246]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 259 is [True, False, False, False, False, True]
State prediction error at timestep 259 is 0.012
Current timestep = 260. State = [[-0.29328442  0.21982592]]. Action = [[0.06697123 0.09690454 0.         0.94628024]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 260 is [True, False, False, False, False, True]
State prediction error at timestep 260 is 0.012
Current timestep = 261. State = [[-0.29006547  0.21963476]]. Action = [[ 0.05872671 -0.08565628  0.          0.53379023]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 261 is [True, False, False, False, False, True]
State prediction error at timestep 261 is 0.012
Current timestep = 262. State = [[-0.29134813  0.2172499 ]]. Action = [[-0.05382015 -0.02013361  0.          0.30620217]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 262 is [True, False, False, False, False, True]
State prediction error at timestep 262 is 0.012
Current timestep = 263. State = [[-0.29752186  0.22220649]]. Action = [[-0.09326884  0.0934334   0.         -0.0293349 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 263 is [True, False, False, False, False, True]
State prediction error at timestep 263 is 0.012
Current timestep = 264. State = [[-0.3037711   0.22901486]]. Action = [[-0.05873246  0.05696218  0.         -0.84896934]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 264 is [True, False, False, False, False, True]
State prediction error at timestep 264 is 0.012
Current timestep = 265. State = [[-0.30863523  0.22845048]]. Action = [[-0.04692098 -0.07746659  0.          0.10845613]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 265 is [True, False, False, False, False, True]
State prediction error at timestep 265 is 0.012
Current timestep = 266. State = [[-0.31102487  0.22296225]]. Action = [[-0.01355476 -0.09146859  0.          0.563499  ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 266 is [True, False, False, False, False, True]
State prediction error at timestep 266 is 0.012
Current timestep = 267. State = [[-0.30874258  0.21625799]]. Action = [[ 0.05679294 -0.08886103  0.         -0.20960104]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 267 is [True, False, False, False, False, True]
State prediction error at timestep 267 is 0.012
Current timestep = 268. State = [[-0.31084216  0.21432711]]. Action = [[-0.07766265  0.01920233  0.          0.76058364]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 268 is [True, False, False, False, False, True]
State prediction error at timestep 268 is 0.012
Current timestep = 269. State = [[-0.3130562  0.2155939]]. Action = [[0.00217776 0.0207987  0.         0.89136255]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 269 is [True, False, False, False, False, True]
State prediction error at timestep 269 is 0.012
Current timestep = 270. State = [[-0.31453523  0.2156789 ]]. Action = [[-0.01824551 -0.0042288   0.          0.37617683]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 270 is [True, False, False, False, False, True]
State prediction error at timestep 270 is 0.012
Current timestep = 271. State = [[-0.31382737  0.21474493]]. Action = [[ 0.03740668 -0.0081032   0.          0.11308277]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 271 is [True, False, False, False, False, True]
State prediction error at timestep 271 is 0.012
Current timestep = 272. State = [[-0.31564534  0.21793497]]. Action = [[-0.04190005  0.07939287  0.          0.3330425 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 272 is [True, False, False, False, False, True]
State prediction error at timestep 272 is 0.012
Current timestep = 273. State = [[-0.31705195  0.21764098]]. Action = [[ 0.01360656 -0.04711839  0.          0.6510427 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 273 is [True, False, False, False, False, True]
State prediction error at timestep 273 is 0.012
Current timestep = 274. State = [[-0.3182959   0.22064161]]. Action = [[-0.01387528  0.09124922  0.         -0.71032465]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 274 is [True, False, False, False, False, True]
State prediction error at timestep 274 is 0.012
Current timestep = 275. State = [[-0.31715328  0.22721134]]. Action = [[ 0.0596187   0.08101343  0.         -0.0348435 ]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 275 is [True, False, False, False, False, True]
State prediction error at timestep 275 is 0.012
Current timestep = 276. State = [[-0.32031432  0.22758286]]. Action = [[-0.07890238 -0.04928231  0.         -0.3679859 ]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 276 is [True, False, False, False, False, True]
State prediction error at timestep 276 is 0.012
Current timestep = 277. State = [[-0.32249922  0.22209273]]. Action = [[ 0.0207376  -0.09217788  0.          0.75566316]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 277 is [True, False, False, False, False, True]
State prediction error at timestep 277 is 0.012
Current timestep = 278. State = [[-0.32556263  0.22341461]]. Action = [[-0.05207764  0.08330765  0.          0.65749335]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 278 is [True, False, False, False, False, True]
State prediction error at timestep 278 is 0.012
Current timestep = 279. State = [[-0.3307803  0.2252056]]. Action = [[-0.05400294 -0.01759986  0.         -0.36770654]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 279 is [True, False, False, False, False, True]
State prediction error at timestep 279 is 0.012
Current timestep = 280. State = [[-0.33549127  0.22243966]]. Action = [[-0.04599093 -0.05814148  0.         -0.09917009]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 280 is [True, False, False, False, False, True]
State prediction error at timestep 280 is 0.012
Current timestep = 281. State = [[-0.3351236   0.21996574]]. Action = [[ 0.05087202 -0.01895991  0.          0.49590337]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 281 is [True, False, False, False, False, True]
State prediction error at timestep 281 is 0.012
Current timestep = 282. State = [[-0.330831    0.21458913]]. Action = [[ 0.07080226 -0.08798846  0.          0.41281605]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 282 is [True, False, False, False, False, True]
State prediction error at timestep 282 is 0.012
Current timestep = 283. State = [[-0.33017537  0.21133178]]. Action = [[-2.8187126e-02  6.4696372e-04  0.0000000e+00  8.1139421e-01]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 283 is [True, False, False, False, False, True]
State prediction error at timestep 283 is 0.012
Current timestep = 284. State = [[-0.33552492  0.21057236]]. Action = [[-0.09890959 -0.00117623  0.         -0.0380137 ]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 284 is [True, False, False, False, False, True]
State prediction error at timestep 284 is 0.012
Current timestep = 285. State = [[-0.33623397  0.20999418]]. Action = [[ 0.04869366  0.00047702  0.         -0.27904463]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 285 is [True, False, False, False, False, True]
State prediction error at timestep 285 is 0.012
Current timestep = 286. State = [[-0.3384562   0.20551443]]. Action = [[-0.07356026 -0.07800369  0.         -0.07798249]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 286 is [True, False, False, False, False, True]
State prediction error at timestep 286 is 0.012
Current timestep = 287. State = [[-0.3422621   0.20745854]]. Action = [[-0.03127161  0.09989857  0.         -0.5866436 ]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 287 is [True, False, False, False, False, True]
State prediction error at timestep 287 is 0.012
Current timestep = 288. State = [[-0.34426078  0.21440054]]. Action = [[ 0.00411229  0.08926732  0.         -0.09009129]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 288 is [True, False, False, False, False, True]
State prediction error at timestep 288 is 0.012
Current timestep = 289. State = [[-0.3476573   0.21548937]]. Action = [[-0.04035716 -0.03542302  0.         -0.2635529 ]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 289 is [True, False, False, False, False, True]
State prediction error at timestep 289 is 0.012
Current timestep = 290. State = [[-0.34525916  0.21105312]]. Action = [[ 0.09734147 -0.07145954  0.         -0.02795124]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 290 is [True, False, False, False, False, True]
State prediction error at timestep 290 is 0.012
Current timestep = 291. State = [[-0.34592155  0.2091835 ]]. Action = [[-0.05713931  0.01066504  0.         -0.7663967 ]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 291 is [True, False, False, False, False, True]
State prediction error at timestep 291 is 0.012
Current timestep = 292. State = [[-0.35090947  0.20570725]]. Action = [[-0.0625463  -0.07223548  0.          0.49005258]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 292 is [True, False, False, False, False, True]
State prediction error at timestep 292 is 0.012
Current timestep = 293. State = [[-0.35067526  0.19954517]]. Action = [[ 0.04731906 -0.07586887  0.          0.20205629]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 293 is [True, False, False, False, False, True]
State prediction error at timestep 293 is 0.012
Current timestep = 294. State = [[-0.34732783  0.19861574]]. Action = [[0.04698782 0.04513011 0.         0.29335082]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 294 is [True, False, False, False, False, True]
State prediction error at timestep 294 is 0.012
Current timestep = 295. State = [[-0.34996983  0.19916767]]. Action = [[-0.079163    0.00162347  0.          0.7200632 ]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 295 is [True, False, False, False, False, True]
State prediction error at timestep 295 is 0.012
Current timestep = 296. State = [[-0.35700396  0.19928767]]. Action = [[-0.09001391  0.00916243  0.          0.8843081 ]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 296 is [True, False, False, False, False, True]
State prediction error at timestep 296 is 0.012
Current timestep = 297. State = [[-0.35683805  0.20352517]]. Action = [[ 0.09163158  0.08728083  0.         -0.98925376]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 297 is [True, False, False, False, False, True]
State prediction error at timestep 297 is 0.012
Current timestep = 298. State = [[-0.35863623  0.21016659]]. Action = [[-0.06739083  0.08127836  0.          0.87305737]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 298 is [True, False, False, False, False, True]
State prediction error at timestep 298 is 0.012
Current timestep = 299. State = [[-0.35873818  0.21202397]]. Action = [[ 0.05995821 -0.02107758  0.         -0.16872978]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 299 is [True, False, False, False, False, True]
State prediction error at timestep 299 is 0.012
Current timestep = 300. State = [[-0.35691845  0.21064271]]. Action = [[ 0.02406726 -0.02474345  0.          0.8243147 ]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 300 is [True, False, False, False, False, True]
State prediction error at timestep 300 is 0.012
Current timestep = 301. State = [[-0.3589418  0.2085439]]. Action = [[-0.04933728 -0.03398766  0.         -0.41738147]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 301 is [True, False, False, False, False, True]
State prediction error at timestep 301 is 0.012
Current timestep = 302. State = [[-0.3610668   0.20309855]]. Action = [[-0.01862063 -0.09534556  0.         -0.6467637 ]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 302 is [True, False, False, False, False, True]
State prediction error at timestep 302 is 0.012
Current timestep = 303. State = [[-0.36155814  0.2045774 ]]. Action = [[0.00112841 0.09300032 0.         0.01337445]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 303 is [True, False, False, False, False, True]
State prediction error at timestep 303 is 0.012
Current timestep = 304. State = [[-0.35767224  0.2091481 ]]. Action = [[ 0.09127598  0.03858715  0.         -0.5939901 ]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 304 is [True, False, False, False, False, True]
State prediction error at timestep 304 is 0.012
Current timestep = 305. State = [[-0.35498244  0.2099451 ]]. Action = [[ 0.01257388 -0.01067562  0.         -0.13458979]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 305 is [True, False, False, False, False, True]
State prediction error at timestep 305 is 0.012
Current timestep = 306. State = [[-0.35378614  0.20882656]]. Action = [[ 0.0142207  -0.01958447  0.          0.42453074]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 306 is [True, False, False, False, False, True]
State prediction error at timestep 306 is 0.012
Current timestep = 307. State = [[-0.35434783  0.2114596 ]]. Action = [[-0.02269419  0.06272305  0.         -0.7118628 ]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 307 is [True, False, False, False, False, True]
State prediction error at timestep 307 is 0.012
Current timestep = 308. State = [[-0.35864764  0.21303034]]. Action = [[-0.07670791 -0.01200892  0.         -0.57948595]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 308 is [True, False, False, False, False, True]
State prediction error at timestep 308 is 0.012
Current timestep = 309. State = [[-0.36155194  0.21224506]]. Action = [[-0.01899513 -0.02193917  0.         -0.24825007]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 309 is [True, False, False, False, False, True]
State prediction error at timestep 309 is 0.012
Current timestep = 310. State = [[-0.3627452   0.21656409]]. Action = [[-0.00771308  0.09098392  0.          0.89527404]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 310 is [True, False, False, False, False, True]
State prediction error at timestep 310 is 0.012
Current timestep = 311. State = [[-0.35928538  0.22435114]]. Action = [[ 0.09839325  0.09345367  0.         -0.2632689 ]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 311 is [True, False, False, False, False, True]
State prediction error at timestep 311 is 0.012
Current timestep = 312. State = [[-0.35609788  0.23060676]]. Action = [[ 0.03474412  0.05695762  0.         -0.28462952]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 312 is [True, False, False, False, False, True]
State prediction error at timestep 312 is 0.012
Current timestep = 313. State = [[-0.35776812  0.23534396]]. Action = [[-0.03894487  0.04155552  0.         -0.3176986 ]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 313 is [True, False, False, False, False, True]
State prediction error at timestep 313 is 0.012
Current timestep = 314. State = [[-0.35678822  0.24229172]]. Action = [[0.0606556  0.09062483 0.         0.03274632]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 314 is [True, False, False, False, False, True]
State prediction error at timestep 314 is 0.012
Current timestep = 315. State = [[-0.3557224   0.24872488]]. Action = [[ 0.00686908  0.04994369  0.         -0.52691865]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 315 is [True, False, False, False, False, True]
State prediction error at timestep 315 is 0.012
Current timestep = 316. State = [[-0.35115334  0.2479292 ]]. Action = [[ 0.09516902 -0.07655267  0.          0.9859054 ]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 316 is [True, False, False, False, False, True]
State prediction error at timestep 316 is 0.012
Current timestep = 317. State = [[-0.34984    0.2502561]]. Action = [[-0.03308152  0.06699195  0.         -0.44100857]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 317 is [True, False, False, False, False, True]
State prediction error at timestep 317 is 0.012
Current timestep = 318. State = [[-0.35025826  0.2495267 ]]. Action = [[-0.00384919 -0.08461466  0.          0.538484  ]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 318 is [True, False, False, False, False, True]
State prediction error at timestep 318 is 0.012
Current timestep = 319. State = [[-0.34556106  0.25007242]]. Action = [[ 0.07944661  0.03174534  0.         -0.489398  ]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 319 is [True, False, False, False, False, True]
State prediction error at timestep 319 is 0.012
Current timestep = 320. State = [[-0.34249198  0.24983709]]. Action = [[-0.0113832  -0.04154754  0.         -0.07388496]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 320 is [True, False, False, False, False, True]
State prediction error at timestep 320 is 0.012
Current timestep = 321. State = [[-0.3429318   0.24840434]]. Action = [[-0.03960497 -0.02587609  0.          0.7758266 ]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 321 is [True, False, False, False, False, True]
State prediction error at timestep 321 is 0.012
Current timestep = 322. State = [[-0.33802903  0.2494249 ]]. Action = [[0.09529164 0.02536049 0.         0.23380637]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 322 is [True, False, False, False, False, True]
State prediction error at timestep 322 is 0.012
Current timestep = 323. State = [[-0.33539918  0.248742  ]]. Action = [[-0.0380289  -0.03560158  0.          0.73209715]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 323 is [True, False, False, False, False, True]
State prediction error at timestep 323 is 0.012
Current timestep = 324. State = [[-0.3388685   0.25034553]]. Action = [[-0.08567055  0.0413663   0.         -0.65301824]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 324 is [True, False, False, False, False, True]
State prediction error at timestep 324 is 0.012
Current timestep = 325. State = [[-0.33975688  0.24876988]]. Action = [[ 0.00748942 -0.06792901  0.         -0.74373543]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 325 is [True, False, False, False, False, True]
State prediction error at timestep 325 is 0.012
Current timestep = 326. State = [[-0.33828154  0.2491675 ]]. Action = [[ 0.00927542  0.04223023  0.         -0.96729946]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 326 is [True, False, False, False, False, True]
State prediction error at timestep 326 is 0.012
Current timestep = 327. State = [[-0.33871245  0.245905  ]]. Action = [[-0.027773   -0.09101842  0.          0.63733697]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 327 is [True, False, False, False, False, True]
State prediction error at timestep 327 is 0.012
Current timestep = 328. State = [[-0.3433644  0.2405825]]. Action = [[-0.0977295  -0.05809113  0.         -0.22927636]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 328 is [True, False, False, False, False, True]
State prediction error at timestep 328 is 0.012
Current timestep = 329. State = [[-0.34968036  0.24220021]]. Action = [[-0.0802382   0.06772222  0.          0.21889639]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 329 is [True, False, False, False, False, True]
State prediction error at timestep 329 is 0.012
Current timestep = 330. State = [[-0.3487122   0.24080029]]. Action = [[ 0.0804474  -0.06525839  0.          0.34611845]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 330 is [True, False, False, False, False, True]
State prediction error at timestep 330 is 0.012
Current timestep = 331. State = [[-0.35190448  0.24184053]]. Action = [[-0.09573589  0.06936931  0.         -0.01418412]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 331 is [True, False, False, False, False, True]
State prediction error at timestep 331 is 0.012
Current timestep = 332. State = [[-0.35585132  0.24438007]]. Action = [[-0.00324064  0.01468589  0.         -0.9650372 ]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 332 is [True, False, False, False, False, True]
State prediction error at timestep 332 is 0.012
Current timestep = 333. State = [[-0.35531208  0.24924386]]. Action = [[ 0.05169832  0.09133273  0.         -0.9666131 ]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 333 is [True, False, False, False, False, True]
State prediction error at timestep 333 is 0.012
Current timestep = 334. State = [[-0.35617337  0.24785629]]. Action = [[-0.01224783 -0.07963748  0.         -0.23841894]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 334 is [True, False, False, False, False, True]
State prediction error at timestep 334 is 0.012
Current timestep = 335. State = [[-0.3587199   0.24547091]]. Action = [[-0.02042683 -0.00158922  0.         -0.24857134]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 335 is [True, False, False, False, False, True]
State prediction error at timestep 335 is 0.012
Current timestep = 336. State = [[-0.36239833  0.24687609]]. Action = [[-0.03708806  0.03426159  0.          0.544919  ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 336 is [True, False, False, False, False, True]
State prediction error at timestep 336 is 0.012
Current timestep = 337. State = [[-0.36556277  0.24358892]]. Action = [[-0.01980055 -0.08641309  0.         -0.21847332]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 337 is [True, False, False, False, False, True]
State prediction error at timestep 337 is 0.012
Current timestep = 338. State = [[-0.37045616  0.2454613 ]]. Action = [[-0.0661864   0.09364087  0.         -0.73228985]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 338 is [True, False, False, False, False, True]
State prediction error at timestep 338 is 0.012
Current timestep = 339. State = [[-0.3762794  0.244157 ]]. Action = [[-0.0546456  -0.08666154  0.         -0.43282878]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 339 is [True, False, False, False, False, True]
State prediction error at timestep 339 is 0.012
Current timestep = 340. State = [[-0.37639087  0.24338697]]. Action = [[ 0.056404    0.03266782  0.         -0.7109239 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 340 is [True, False, False, False, False, True]
State prediction error at timestep 340 is 0.012
Current timestep = 341. State = [[-0.37238753  0.24475041]]. Action = [[ 0.07224711  0.01855035  0.         -0.53498703]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 341 is [True, False, False, False, False, True]
State prediction error at timestep 341 is 0.012
Current timestep = 342. State = [[-0.3709928  0.2451348]]. Action = [[0.00119704 0.00516788 0.         0.68729067]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 342 is [True, False, False, False, False, True]
State prediction error at timestep 342 is 0.012
Current timestep = 343. State = [[-0.36881894  0.24335703]]. Action = [[ 0.04929963 -0.03291995  0.         -0.6164951 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 343 is [True, False, False, False, False, True]
State prediction error at timestep 343 is 0.012
Current timestep = 344. State = [[-0.36512664  0.24061532]]. Action = [[ 0.04546113 -0.02658944  0.          0.604738  ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 344 is [True, False, False, False, False, True]
State prediction error at timestep 344 is 0.012
Current timestep = 345. State = [[-0.3621448   0.23491567]]. Action = [[ 0.02121743 -0.08684698  0.         -0.15997213]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 345 is [True, False, False, False, False, True]
State prediction error at timestep 345 is 0.012
Current timestep = 346. State = [[-0.3620546  0.2357261]]. Action = [[-0.02774825  0.08443392  0.         -0.35764176]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 346 is [True, False, False, False, False, True]
State prediction error at timestep 346 is 0.012
Current timestep = 347. State = [[-0.362184    0.23806418]]. Action = [[0.00513898 0.00777678 0.         0.38699365]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 347 is [True, False, False, False, False, True]
State prediction error at timestep 347 is 0.012
Current timestep = 348. State = [[-0.35913014  0.23735881]]. Action = [[ 0.05342049 -0.01493974  0.         -0.44285524]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 348 is [True, False, False, False, False, True]
State prediction error at timestep 348 is 0.012
Current timestep = 349. State = [[-0.3565379   0.23341097]]. Action = [[ 0.00927167 -0.06272862  0.         -0.64070034]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 349 is [True, False, False, False, False, True]
State prediction error at timestep 349 is 0.012
Current timestep = 350. State = [[-0.35701242  0.23105213]]. Action = [[-0.03582796 -0.00322063  0.         -0.32054746]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 350 is [True, False, False, False, False, True]
State prediction error at timestep 350 is 0.012
Current timestep = 351. State = [[-0.3578873   0.23060198]]. Action = [[-1.43888295e-02 -1.32910907e-04  0.00000000e+00  5.37557602e-01]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 351 is [True, False, False, False, False, True]
State prediction error at timestep 351 is 0.012
Current timestep = 352. State = [[-0.3592515   0.23193057]]. Action = [[-0.0290448   0.03100079  0.         -0.9101254 ]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 352 is [True, False, False, False, False, True]
State prediction error at timestep 352 is 0.012
Current timestep = 353. State = [[-0.36153987  0.22791664]]. Action = [[-0.03787947 -0.0984361   0.         -0.48478913]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 353 is [True, False, False, False, False, True]
State prediction error at timestep 353 is 0.012
Current timestep = 354. State = [[-0.366426    0.22487612]]. Action = [[-0.08906347 -0.00326948  0.          0.7360873 ]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 354 is [True, False, False, False, False, True]
State prediction error at timestep 354 is 0.012
Current timestep = 355. State = [[-0.37051797  0.22531584]]. Action = [[-0.03239907  0.01451205  0.         -0.24832118]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 355 is [True, False, False, False, False, True]
State prediction error at timestep 355 is 0.012
Current timestep = 356. State = [[-0.36887285  0.22854355]]. Action = [[0.07307122 0.06122526 0.         0.0860337 ]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 356 is [True, False, False, False, False, True]
State prediction error at timestep 356 is 0.012
Current timestep = 357. State = [[-0.36502087  0.22572362]]. Action = [[ 0.05739697 -0.08531006  0.          0.9602027 ]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 357 is [True, False, False, False, False, True]
State prediction error at timestep 357 is 0.012
Current timestep = 358. State = [[-0.3606674   0.21963654]]. Action = [[ 0.05734735 -0.06000493  0.          0.6758517 ]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 358 is [True, False, False, False, False, True]
State prediction error at timestep 358 is 0.012
Current timestep = 359. State = [[-0.35785934  0.21881527]]. Action = [[0.02036209 0.04030734 0.         0.12570786]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 359 is [True, False, False, False, False, True]
State prediction error at timestep 359 is 0.012
Current timestep = 360. State = [[-0.35475862  0.22366878]]. Action = [[ 0.05384945  0.09314866  0.         -0.61892647]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 360 is [True, False, False, False, False, True]
State prediction error at timestep 360 is 0.012
Current timestep = 361. State = [[-0.35753667  0.22937189]]. Action = [[-0.08127633  0.06800442  0.          0.8156121 ]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 361 is [True, False, False, False, False, True]
State prediction error at timestep 361 is 0.012
Current timestep = 362. State = [[-0.36133355  0.23227835]]. Action = [[-0.01559198  0.01370113  0.         -0.35039037]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 362 is [True, False, False, False, False, True]
State prediction error at timestep 362 is 0.012
Current timestep = 363. State = [[-0.35913     0.23051876]]. Action = [[ 0.07225939 -0.05020162  0.          0.3761872 ]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 363 is [True, False, False, False, False, True]
State prediction error at timestep 363 is 0.012
Current timestep = 364. State = [[-0.35525954  0.22730403]]. Action = [[ 0.04371256 -0.03554789  0.         -0.97263044]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 364 is [True, False, False, False, False, True]
State prediction error at timestep 364 is 0.012
Current timestep = 365. State = [[-0.35511065  0.22286141]]. Action = [[-0.03154184 -0.06682341  0.         -0.27600598]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 365 is [True, False, False, False, False, True]
State prediction error at timestep 365 is 0.012
Current timestep = 366. State = [[-0.35322478  0.22411019]]. Action = [[0.04600526 0.06810338 0.         0.84440506]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 366 is [True, False, False, False, False, True]
State prediction error at timestep 366 is 0.012
Current timestep = 367. State = [[-0.35288072  0.22200215]]. Action = [[-0.03018109 -0.07878159  0.          0.6478708 ]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 367 is [True, False, False, False, False, True]
State prediction error at timestep 367 is 0.012
Current timestep = 368. State = [[-0.34868553  0.2235585 ]]. Action = [[ 0.09539228  0.08254253  0.         -0.5728567 ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 368 is [True, False, False, False, False, True]
State prediction error at timestep 368 is 0.012
Current timestep = 369. State = [[-0.34316793  0.22213098]]. Action = [[ 0.04097544 -0.06924746  0.          0.02762902]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 369 is [True, False, False, False, False, True]
State prediction error at timestep 369 is 0.012
Current timestep = 370. State = [[-0.33823293  0.22301918]]. Action = [[ 0.0486482   0.06333358  0.         -0.6584465 ]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 370 is [True, False, False, False, False, True]
State prediction error at timestep 370 is 0.012
Current timestep = 371. State = [[-0.33998564  0.22525029]]. Action = [[-0.0922754   0.01031687  0.          0.10843635]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 371 is [True, False, False, False, False, True]
State prediction error at timestep 371 is 0.012
Current timestep = 372. State = [[-0.34359637  0.22295725]]. Action = [[-0.04205335 -0.0609902   0.         -0.32867497]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 372 is [True, False, False, False, False, True]
State prediction error at timestep 372 is 0.012
Current timestep = 373. State = [[-0.34302524  0.22227277]]. Action = [[0.02417841 0.01743629 0.         0.37088263]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 373 is [True, False, False, False, False, True]
State prediction error at timestep 373 is 0.012
Current timestep = 374. State = [[-0.34076777  0.22522083]]. Action = [[0.02849316 0.05033054 0.         0.45122695]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 374 is [True, False, False, False, False, True]
State prediction error at timestep 374 is 0.012
Current timestep = 375. State = [[-0.34061927  0.22816764]]. Action = [[-0.01295059  0.02658694  0.         -0.46888477]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 375 is [True, False, False, False, False, True]
State prediction error at timestep 375 is 0.012
Current timestep = 376. State = [[-0.3370896   0.22569716]]. Action = [[ 0.07793459 -0.07030288  0.         -0.7294052 ]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 376 is [True, False, False, False, False, True]
State prediction error at timestep 376 is 0.012
Current timestep = 377. State = [[-0.33386713  0.22635882]]. Action = [[ 0.01628248  0.05679289  0.         -0.41296673]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 377 is [True, False, False, False, False, True]
State prediction error at timestep 377 is 0.012
Current timestep = 378. State = [[-0.33165702  0.22361732]]. Action = [[ 0.02499916 -0.0865989   0.         -0.3394674 ]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 378 is [True, False, False, False, False, True]
State prediction error at timestep 378 is 0.012
Current timestep = 379. State = [[-0.33492112  0.22281304]]. Action = [[-0.09956655  0.03235096  0.         -0.5708886 ]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 379 is [True, False, False, False, False, True]
State prediction error at timestep 379 is 0.012
Current timestep = 380. State = [[-0.33276302  0.220405  ]]. Action = [[ 0.09148902 -0.06600899  0.         -0.7401458 ]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 380 is [True, False, False, False, False, True]
State prediction error at timestep 380 is 0.012
Current timestep = 381. State = [[-0.32927793  0.22146273]]. Action = [[ 0.00433896  0.06511136  0.         -0.710396  ]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 381 is [True, False, False, False, False, True]
State prediction error at timestep 381 is 0.012
Current timestep = 382. State = [[-0.3298083   0.22003299]]. Action = [[-0.03280153 -0.06434791  0.          0.7218077 ]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 382 is [True, False, False, False, False, True]
State prediction error at timestep 382 is 0.012
Current timestep = 383. State = [[-0.32804796  0.2133462 ]]. Action = [[ 0.03060811 -0.09663288  0.         -0.47275913]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 383 is [True, False, False, False, False, True]
State prediction error at timestep 383 is 0.012
Current timestep = 384. State = [[-0.32149115  0.20538379]]. Action = [[ 0.09049081 -0.08724773  0.          0.09765232]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 384 is [True, False, False, False, False, True]
State prediction error at timestep 384 is 0.012
Current timestep = 385. State = [[-0.32047918  0.19683328]]. Action = [[-0.07005149 -0.09655289  0.          0.06793427]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 385 is [True, False, False, False, False, True]
State prediction error at timestep 385 is 0.012
Current timestep = 386. State = [[-0.32071275  0.19604754]]. Action = [[ 0.00956962  0.07097002  0.         -0.30797338]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 386 is [True, False, False, False, False, True]
State prediction error at timestep 386 is 0.012
Current timestep = 387. State = [[-0.32463032  0.20033179]]. Action = [[-0.09130742  0.07073156  0.         -0.82999414]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 387 is [True, False, False, False, False, True]
State prediction error at timestep 387 is 0.012
Current timestep = 388. State = [[-0.3301498   0.19926299]]. Action = [[-0.05873357 -0.05307183  0.          0.54345584]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 388 is [True, False, False, False, False, True]
State prediction error at timestep 388 is 0.012
Current timestep = 389. State = [[-0.33523712  0.2002648 ]]. Action = [[-0.0576416   0.05809379  0.          0.0535357 ]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 389 is [True, False, False, False, False, True]
State prediction error at timestep 389 is 0.012
Current timestep = 390. State = [[-0.3381686   0.20182802]]. Action = [[-0.0017455   0.0031541   0.          0.12712479]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 390 is [True, False, False, False, False, True]
State prediction error at timestep 390 is 0.012
Current timestep = 391. State = [[-0.3395164   0.20033634]]. Action = [[ 0.00272062 -0.03047898  0.         -0.9681096 ]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 391 is [True, False, False, False, False, True]
State prediction error at timestep 391 is 0.012
Current timestep = 392. State = [[-0.34333342  0.19835113]]. Action = [[-0.05441289 -0.01840308  0.         -0.70569754]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 392 is [True, False, False, False, False, True]
State prediction error at timestep 392 is 0.012
Current timestep = 393. State = [[-0.342374    0.19591257]]. Action = [[ 0.07764467 -0.03144535  0.         -0.9625329 ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 393 is [True, False, False, False, False, True]
State prediction error at timestep 393 is 0.012
Current timestep = 394. State = [[-0.34508723  0.19247416]]. Action = [[-0.08598656 -0.04167542  0.          0.9566463 ]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 394 is [True, False, False, False, False, True]
State prediction error at timestep 394 is 0.012
Current timestep = 395. State = [[-0.34901673  0.18952577]]. Action = [[-0.01231229 -0.02475339  0.          0.16604269]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 395 is [True, False, False, False, False, True]
State prediction error at timestep 395 is 0.012
Current timestep = 396. State = [[-0.3525668   0.18656087]]. Action = [[-0.04061718 -0.03182213  0.          0.74991536]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 396 is [True, False, False, False, False, True]
State prediction error at timestep 396 is 0.012
Current timestep = 397. State = [[-0.3572795   0.18192038]]. Action = [[-0.05308446 -0.06055566  0.          0.01375067]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 397 is [True, False, False, False, False, True]
State prediction error at timestep 397 is 0.012
Current timestep = 398. State = [[-0.3602154   0.18075806]]. Action = [[-0.00858318  0.02901501  0.          0.7597914 ]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 398 is [True, False, False, False, False, True]
State prediction error at timestep 398 is 0.012
Current timestep = 399. State = [[-0.3610292   0.17930472]]. Action = [[ 0.01578669 -0.02805732  0.          0.5673311 ]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 399 is [True, False, False, False, False, True]
State prediction error at timestep 399 is 0.012
Current timestep = 400. State = [[-0.36210084  0.17413129]]. Action = [[-0.00858404 -0.07072638  0.          0.90279615]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 400 is [True, False, False, False, False, True]
State prediction error at timestep 400 is 0.012
Current timestep = 401. State = [[-0.3637474   0.17123078]]. Action = [[-0.0122075   0.00387862  0.         -0.4020986 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 401 is [True, False, False, False, False, True]
State prediction error at timestep 401 is 0.012
Current timestep = 402. State = [[-0.3684437  0.1689209]]. Action = [[-0.07188563 -0.0272503   0.         -0.3986498 ]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 402 is [True, False, False, False, False, True]
State prediction error at timestep 402 is 0.012
Current timestep = 403. State = [[-0.36897004  0.16675535]]. Action = [[ 0.05077463 -0.00888107  0.         -0.8169536 ]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 403 is [True, False, False, False, False, True]
State prediction error at timestep 403 is 0.012
Current timestep = 404. State = [[-0.36542192  0.16099203]]. Action = [[ 0.06155103 -0.08891229  0.          0.85012555]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 404 is [True, False, False, False, False, True]
State prediction error at timestep 404 is 0.012
Current timestep = 405. State = [[-0.36105844  0.15950194]]. Action = [[ 0.06424963  0.04745797  0.         -0.4720571 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 405 is [True, False, False, False, False, True]
State prediction error at timestep 405 is 0.012
Current timestep = 406. State = [[-0.35881665  0.15898609]]. Action = [[ 0.01777609 -0.01467505  0.          0.31221056]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 406 is [True, False, False, False, False, True]
State prediction error at timestep 406 is 0.012
Current timestep = 407. State = [[-0.3617845   0.15847641]]. Action = [[-0.07007273  0.01543732  0.         -0.5621452 ]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 407 is [True, False, False, False, False, True]
State prediction error at timestep 407 is 0.012
Current timestep = 408. State = [[-0.36441368  0.15528278]]. Action = [[-0.01275649 -0.05715167  0.          0.22244465]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 408 is [True, False, False, False, False, True]
State prediction error at timestep 408 is 0.012
Current timestep = 409. State = [[-0.3628704   0.14818895]]. Action = [[ 0.0399354  -0.09178049  0.         -0.21691102]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 409 is [True, False, False, False, False, True]
State prediction error at timestep 409 is 0.012
Current timestep = 410. State = [[-0.3644909   0.13935967]]. Action = [[-0.06606541 -0.09912776  0.          0.8801396 ]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 410 is [True, False, False, False, False, True]
State prediction error at timestep 410 is 0.012
Current timestep = 411. State = [[-0.36765933  0.13142224]]. Action = [[-0.04080061 -0.06969124  0.          0.9302002 ]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 411 is [True, False, False, False, False, True]
State prediction error at timestep 411 is 0.012
Current timestep = 412. State = [[-0.36802897  0.13205138]]. Action = [[ 0.01623962  0.09420358  0.         -0.9161777 ]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 412 is [True, False, False, False, False, True]
State prediction error at timestep 412 is 0.012
Current timestep = 413. State = [[-0.366649    0.13159771]]. Action = [[ 0.02643705 -0.04100062  0.         -0.70916575]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 413 is [True, False, False, False, False, True]
State prediction error at timestep 413 is 0.012
Current timestep = 414. State = [[-0.36895785  0.13087328]]. Action = [[-0.05646575  0.02577332  0.          0.9251492 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 414 is [True, False, False, False, False, True]
State prediction error at timestep 414 is 0.012
Current timestep = 415. State = [[-0.3688179   0.12899771]]. Action = [[ 0.04680907 -0.03598819  0.          0.98881316]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 415 is [True, False, False, False, False, True]
State prediction error at timestep 415 is 0.012
Current timestep = 416. State = [[-0.3710154   0.12707146]]. Action = [[-0.06226669 -0.0032639   0.         -0.4628172 ]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 416 is [True, False, False, False, False, True]
State prediction error at timestep 416 is 0.012
Current timestep = 417. State = [[-0.36958867  0.12638304]]. Action = [[ 0.08013058  0.00036044  0.         -0.21147603]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 417 is [True, False, False, False, False, True]
State prediction error at timestep 417 is 0.012
Current timestep = 418. State = [[-0.37152645  0.12395527]]. Action = [[-0.08166286 -0.03781302  0.         -0.70637006]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 418 is [True, False, False, False, True, False]
State prediction error at timestep 418 is 0.012
Current timestep = 419. State = [[-0.37422925  0.12716284]]. Action = [[0.00485333 0.0982404  0.         0.3252722 ]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 419 is [True, False, False, False, False, True]
State prediction error at timestep 419 is 0.012
Current timestep = 420. State = [[-0.3734462   0.13333623]]. Action = [[ 0.0420351   0.06197999  0.         -0.16977727]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 420 is [True, False, False, False, False, True]
State prediction error at timestep 420 is 0.012
Current timestep = 421. State = [[-0.3760717   0.13482527]]. Action = [[-0.0509559  -0.02182326  0.          0.7509217 ]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 421 is [True, False, False, False, False, True]
State prediction error at timestep 421 is 0.012
Current timestep = 422. State = [[-0.37551865  0.13510564]]. Action = [[ 0.06254528  0.0062324   0.         -0.98159015]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 422 is [True, False, False, False, False, True]
State prediction error at timestep 422 is 0.012
Current timestep = 423. State = [[-0.37499157  0.13725035]]. Action = [[-0.00323447  0.02758669  0.          0.7456614 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 423 is [True, False, False, False, False, True]
State prediction error at timestep 423 is 0.012
Current timestep = 424. State = [[-0.37148747  0.142577  ]]. Action = [[0.09256329 0.07457607 0.         0.90157545]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 424 is [True, False, False, False, False, True]
State prediction error at timestep 424 is 0.012
Current timestep = 425. State = [[-0.3696782   0.14198755]]. Action = [[-0.00097075 -0.08202976  0.         -0.8076555 ]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 425 is [True, False, False, False, False, True]
State prediction error at timestep 425 is 0.012
Current timestep = 426. State = [[-0.36625257  0.14036816]]. Action = [[0.06958269 0.00295367 0.         0.488878  ]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 426 is [True, False, False, False, False, True]
State prediction error at timestep 426 is 0.012
Current timestep = 427. State = [[-0.36526266  0.1433785 ]]. Action = [[-0.0228494   0.05357748  0.          0.5688182 ]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 427 is [True, False, False, False, False, True]
State prediction error at timestep 427 is 0.012
Current timestep = 428. State = [[-0.36849177  0.14270958]]. Action = [[-0.06203667 -0.05185557  0.         -0.68762636]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 428 is [True, False, False, False, False, True]
State prediction error at timestep 428 is 0.012
Current timestep = 429. State = [[-0.36783418  0.14602657]]. Action = [[ 0.04346477  0.09320938  0.         -0.13253349]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 429 is [True, False, False, False, False, True]
State prediction error at timestep 429 is 0.012
Current timestep = 430. State = [[-0.36709097  0.1502627 ]]. Action = [[-0.00771398  0.01826577  0.         -0.68535745]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 430 is [True, False, False, False, False, True]
State prediction error at timestep 430 is 0.012
Current timestep = 431. State = [[-0.36434415  0.15065777]]. Action = [[ 0.05677135 -0.02074119  0.         -0.34598404]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 431 is [True, False, False, False, False, True]
State prediction error at timestep 431 is 0.012
Current timestep = 432. State = [[-0.3602967   0.14949003]]. Action = [[ 0.04193885 -0.02415978  0.         -0.7631167 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 432 is [True, False, False, False, False, True]
State prediction error at timestep 432 is 0.012
Current timestep = 433. State = [[-0.3594495   0.14431298]]. Action = [[-0.02686401 -0.09515855  0.          0.866186  ]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 433 is [True, False, False, False, False, True]
State prediction error at timestep 433 is 0.012
Current timestep = 434. State = [[-0.36282745  0.14068395]]. Action = [[-0.08449087 -0.01299673  0.          0.6640625 ]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 434 is [True, False, False, False, False, True]
State prediction error at timestep 434 is 0.012
Current timestep = 435. State = [[-0.36733183  0.13542724]]. Action = [[-0.07287253 -0.08499196  0.         -0.01479512]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 435 is [True, False, False, False, False, True]
State prediction error at timestep 435 is 0.012
Current timestep = 436. State = [[-0.37138098  0.13496082]]. Action = [[-0.05904313  0.05740508  0.         -0.5950826 ]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 436 is [True, False, False, False, False, True]
State prediction error at timestep 436 is 0.012
Current timestep = 437. State = [[-0.37749517  0.13608265]]. Action = [[-0.09654173  0.00264307  0.          0.5140873 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 437 is [True, False, False, False, False, True]
State prediction error at timestep 437 is 0.012
Current timestep = 438. State = [[-0.38052955  0.13587807]]. Action = [[0.        0.        0.        0.5001869]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 438 is [True, False, False, False, False, True]
State prediction error at timestep 438 is 0.012
Current timestep = 439. State = [[-0.37821487  0.13236226]]. Action = [[ 0.06668853 -0.0651292   0.          0.8095763 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 439 is [True, False, False, False, False, True]
State prediction error at timestep 439 is 0.012
Current timestep = 440. State = [[-0.37556544  0.13096674]]. Action = [[ 0.03342762  0.01814346  0.         -0.2590834 ]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 440 is [True, False, False, False, False, True]
State prediction error at timestep 440 is 0.012
Current timestep = 441. State = [[-0.37527147  0.13104995]]. Action = [[0.        0.        0.        0.4045037]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 441 is [True, False, False, False, False, True]
State prediction error at timestep 441 is 0.012
Current timestep = 442. State = [[-0.37852857  0.13115732]]. Action = [[-0.05332578  0.0090837   0.         -0.8108663 ]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 442 is [True, False, False, False, False, True]
State prediction error at timestep 442 is 0.012
Current timestep = 443. State = [[-0.38079977  0.13109027]]. Action = [[ 0.         0.         0.        -0.4437071]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 443 is [True, False, False, False, False, True]
State prediction error at timestep 443 is 0.012
Current timestep = 444. State = [[-0.38171634  0.13090546]]. Action = [[ 0.          0.          0.         -0.62653923]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 444 is [True, False, False, False, False, True]
State prediction error at timestep 444 is 0.012
Current timestep = 445. State = [[-0.3780111   0.13370451]]. Action = [[ 0.09703413  0.05453553  0.         -0.4946915 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 445 is [True, False, False, False, False, True]
State prediction error at timestep 445 is 0.012
Current timestep = 446. State = [[-0.37731117  0.13943875]]. Action = [[-0.01821793  0.07413789  0.          0.66037965]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 446 is [True, False, False, False, False, True]
State prediction error at timestep 446 is 0.012
Current timestep = 447. State = [[-0.37892196  0.14513558]]. Action = [[ 0.00247018  0.05641594  0.         -0.25697613]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 447 is [True, False, False, False, False, True]
State prediction error at timestep 447 is 0.012
Current timestep = 448. State = [[-0.38020664  0.14774577]]. Action = [[ 0.         0.         0.        -0.5842132]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 448 is [True, False, False, False, False, True]
State prediction error at timestep 448 is 0.012
Current timestep = 449. State = [[-0.3777384  0.151481 ]]. Action = [[0.07372297 0.05353268 0.         0.09421408]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 449 is [True, False, False, False, False, True]
State prediction error at timestep 449 is 0.012
Current timestep = 450. State = [[-0.3755869   0.15054752]]. Action = [[ 0.01921485 -0.07225363  0.         -0.8079358 ]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 450 is [True, False, False, False, False, True]
State prediction error at timestep 450 is 0.012
Current timestep = 451. State = [[-0.3750188   0.14924201]]. Action = [[ 0.        0.        0.       -0.043814]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 451 is [True, False, False, False, False, True]
State prediction error at timestep 451 is 0.012
Current timestep = 452. State = [[-0.3769987   0.14865565]]. Action = [[-0.04726925 -0.01964069  0.          0.09428   ]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 452 is [True, False, False, False, False, True]
State prediction error at timestep 452 is 0.012
Current timestep = 453. State = [[-0.37476417  0.14974795]]. Action = [[0.0647961 0.0260021 0.        0.7845838]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 453 is [True, False, False, False, False, True]
State prediction error at timestep 453 is 0.012
Current timestep = 454. State = [[-0.37120524  0.14868736]]. Action = [[ 0.02510985 -0.04274772  0.         -0.248559  ]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 454 is [True, False, False, False, False, True]
State prediction error at timestep 454 is 0.012
Current timestep = 455. State = [[-0.3662442   0.14546593]]. Action = [[ 0.0651074  -0.04124139  0.         -0.12591517]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 455 is [True, False, False, False, False, True]
State prediction error at timestep 455 is 0.012
Current timestep = 456. State = [[-0.3674873   0.14219399]]. Action = [[-0.097564   -0.03393858  0.         -0.76892203]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 456 is [True, False, False, False, False, True]
State prediction error at timestep 456 is 0.012
Current timestep = 457. State = [[-0.36987355  0.1410392 ]]. Action = [[-0.01558197  0.00778686  0.          0.6488712 ]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 457 is [True, False, False, False, False, True]
State prediction error at timestep 457 is 0.012
Current timestep = 458. State = [[-0.3724016   0.13900504]]. Action = [[-0.05210643 -0.03358372  0.         -0.6983514 ]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 458 is [True, False, False, False, False, True]
State prediction error at timestep 458 is 0.012
Current timestep = 459. State = [[-0.37776858  0.13803352]]. Action = [[-0.08981835  0.01250692  0.         -0.62494725]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 459 is [True, False, False, False, False, True]
State prediction error at timestep 459 is 0.012
Current timestep = 460. State = [[-0.37717006  0.13417564]]. Action = [[ 0.07024831 -0.07263957  0.          0.6815803 ]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 460 is [True, False, False, False, False, True]
State prediction error at timestep 460 is 0.012
Current timestep = 461. State = [[-0.37133864  0.13505565]]. Action = [[0.08062708 0.07491467 0.         0.7849951 ]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 461 is [True, False, False, False, False, True]
State prediction error at timestep 461 is 0.012
Current timestep = 462. State = [[-0.36719298  0.13399236]]. Action = [[ 0.03488613 -0.05896032  0.         -0.9389544 ]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 462 is [True, False, False, False, False, True]
State prediction error at timestep 462 is 0.012
Current timestep = 463. State = [[-0.3641266   0.13395292]]. Action = [[0.03403526 0.03993172 0.         0.9115062 ]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 463 is [True, False, False, False, False, True]
State prediction error at timestep 463 is 0.012
Current timestep = 464. State = [[-0.3641512   0.13209546]]. Action = [[-0.0270206  -0.05123943  0.         -0.50400436]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 464 is [True, False, False, False, False, True]
State prediction error at timestep 464 is 0.012
Current timestep = 465. State = [[-0.36222914  0.13223518]]. Action = [[0.04615731 0.04132345 0.         0.290493  ]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 465 is [True, False, False, False, False, True]
State prediction error at timestep 465 is 0.012
Current timestep = 466. State = [[-0.35999614  0.1328849 ]]. Action = [[ 0.01622567 -0.00485907  0.         -0.45286238]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 466 is [True, False, False, False, False, True]
State prediction error at timestep 466 is 0.012
Current timestep = 467. State = [[-0.3562419   0.12978938]]. Action = [[ 0.05855576 -0.05541181  0.          0.9220178 ]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 467 is [True, False, False, False, False, True]
State prediction error at timestep 467 is 0.012
Current timestep = 468. State = [[-0.35787386  0.12950622]]. Action = [[-8.5717276e-02  3.6575012e-02  0.0000000e+00  3.2782555e-05]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 468 is [True, False, False, False, False, True]
State prediction error at timestep 468 is 0.012
Current timestep = 469. State = [[-0.3647604   0.13031353]]. Action = [[-0.09894673  0.00388857  0.         -0.03090715]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 469 is [True, False, False, False, False, True]
State prediction error at timestep 469 is 0.012
Current timestep = 470. State = [[-0.36518663  0.12856075]]. Action = [[ 0.05917346 -0.03557009  0.          0.50279486]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 470 is [True, False, False, False, False, True]
State prediction error at timestep 470 is 0.012
Current timestep = 471. State = [[-0.3603351   0.12887797]]. Action = [[0.06771555 0.0289024  0.         0.06915569]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 471 is [True, False, False, False, False, True]
State prediction error at timestep 471 is 0.012
Current timestep = 472. State = [[-0.35449994  0.12756516]]. Action = [[ 0.07767337 -0.04328289  0.          0.86710835]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 472 is [True, False, False, False, False, True]
State prediction error at timestep 472 is 0.012
Current timestep = 473. State = [[-0.35528216  0.1221735 ]]. Action = [[-0.08001698 -0.07751729  0.         -0.4200771 ]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 473 is [True, False, False, False, True, False]
State prediction error at timestep 473 is 0.012
Current timestep = 474. State = [[-0.35793275  0.11899973]]. Action = [[-0.02025385 -0.00455423  0.          0.59956586]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 474 is [True, False, False, False, True, False]
State prediction error at timestep 474 is 0.012
Current timestep = 475. State = [[-0.36019182  0.11413641]]. Action = [[-0.03874698 -0.0768189   0.          0.22140479]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 475 is [True, False, False, False, True, False]
State prediction error at timestep 475 is 0.012
Current timestep = 476. State = [[-0.3620794   0.11510639]]. Action = [[-0.01856872  0.08578249  0.          0.17878878]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 476 is [True, False, False, False, True, False]
State prediction error at timestep 476 is 0.012
Current timestep = 477. State = [[-0.36576992  0.11880814]]. Action = [[-0.05779477  0.03662264  0.          0.28349924]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 477 is [True, False, False, False, True, False]
State prediction error at timestep 477 is 0.012
Current timestep = 478. State = [[-0.36687857  0.11494205]]. Action = [[ 0.02176622 -0.09590584  0.         -0.93396616]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 478 is [True, False, False, False, True, False]
State prediction error at timestep 478 is 0.012
Current timestep = 479. State = [[-0.36344436  0.11370454]]. Action = [[ 0.07070523  0.03852307  0.         -0.90368253]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 479 is [True, False, False, False, True, False]
State prediction error at timestep 479 is 0.012
Current timestep = 480. State = [[-0.36022168  0.11568216]]. Action = [[ 0.03695448  0.01963146  0.         -0.05145156]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 480 is [True, False, False, False, True, False]
State prediction error at timestep 480 is 0.012
Current timestep = 481. State = [[-0.3610145   0.11610237]]. Action = [[-0.02984937 -0.00442631  0.         -0.39157444]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 481 is [True, False, False, False, True, False]
State prediction error at timestep 481 is 0.012
Current timestep = 482. State = [[-0.3661143   0.11228634]]. Action = [[-0.08403208 -0.06928013  0.         -0.65935105]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 482 is [True, False, False, False, True, False]
State prediction error at timestep 482 is 0.012
Current timestep = 483. State = [[-0.36451307  0.11322936]]. Action = [[ 0.0970461   0.07717503  0.         -0.646887  ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 483 is [True, False, False, False, True, False]
State prediction error at timestep 483 is 0.012
Current timestep = 484. State = [[-0.3641053   0.11905653]]. Action = [[-0.03947439  0.06930763  0.         -0.07366562]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 484 is [True, False, False, False, True, False]
State prediction error at timestep 484 is 0.012
Current timestep = 485. State = [[-0.36956978  0.12465429]]. Action = [[-0.08212     0.06020498  0.         -0.70521474]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 485 is [True, False, False, False, True, False]
State prediction error at timestep 485 is 0.012
Current timestep = 486. State = [[-0.3738067  0.1261466]]. Action = [[-0.02526207 -0.02032774  0.         -0.6612668 ]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 486 is [True, False, False, False, False, True]
State prediction error at timestep 486 is 0.012
Current timestep = 487. State = [[-0.37148774  0.12946497]]. Action = [[0.08378346 0.05852631 0.         0.6093693 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 487 is [True, False, False, False, False, True]
State prediction error at timestep 487 is 0.012
Current timestep = 488. State = [[-0.36965024  0.13640223]]. Action = [[ 0.01520833  0.07900851  0.         -0.1810801 ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 488 is [True, False, False, False, False, True]
State prediction error at timestep 488 is 0.012
Current timestep = 489. State = [[-0.36642322  0.13794574]]. Action = [[ 0.07807096 -0.04503169  0.         -0.40708613]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 489 is [True, False, False, False, False, True]
State prediction error at timestep 489 is 0.012
Current timestep = 490. State = [[-0.36204964  0.14025503]]. Action = [[ 0.0590279   0.0456939   0.         -0.23237932]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 490 is [True, False, False, False, False, True]
State prediction error at timestep 490 is 0.012
Current timestep = 491. State = [[-0.35735694  0.14201653]]. Action = [[ 0.06803065 -0.01247806  0.         -0.24252224]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 491 is [True, False, False, False, False, True]
State prediction error at timestep 491 is 0.012
Current timestep = 492. State = [[-0.35499305  0.14513884]]. Action = [[ 0.0067096   0.04962393  0.         -0.35204238]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 492 is [True, False, False, False, False, True]
State prediction error at timestep 492 is 0.012
Current timestep = 493. State = [[-0.354208    0.15055902]]. Action = [[ 0.00767819  0.06155092  0.         -0.71714187]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 493 is [True, False, False, False, False, True]
State prediction error at timestep 493 is 0.012
Current timestep = 494. State = [[-0.35395324  0.14959241]]. Action = [[-0.007531   -0.07783411  0.         -0.20175159]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 494 is [True, False, False, False, False, True]
State prediction error at timestep 494 is 0.012
Current timestep = 495. State = [[-0.3521368   0.14913912]]. Action = [[0.0216864  0.01927565 0.         0.06876302]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 495 is [True, False, False, False, False, True]
State prediction error at timestep 495 is 0.012
Current timestep = 496. State = [[-0.34737873  0.1466115 ]]. Action = [[ 0.06128144 -0.07179403  0.         -0.14420271]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 496 is [True, False, False, False, False, True]
State prediction error at timestep 496 is 0.012
Current timestep = 497. State = [[-0.33980677  0.14385562]]. Action = [[ 0.08788811 -0.01873811  0.         -0.15000159]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 497 is [True, False, False, False, False, True]
State prediction error at timestep 497 is 0.012
Current timestep = 498. State = [[-0.33071396  0.13913281]]. Action = [[ 0.09660014 -0.07947445  0.         -0.6509905 ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 498 is [True, False, False, False, False, True]
State prediction error at timestep 498 is 0.012
Current timestep = 499. State = [[-0.32489038  0.14043538]]. Action = [[ 0.01835684  0.08355958  0.         -0.0060041 ]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 499 is [True, False, False, False, False, True]
State prediction error at timestep 499 is 0.012
Current timestep = 500. State = [[-0.32188797  0.14145975]]. Action = [[ 0.00889243 -0.01560266  0.         -0.44918495]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 500 is [True, False, False, False, False, True]
State prediction error at timestep 500 is 0.012
Current timestep = 501. State = [[-0.31813335  0.14204328]]. Action = [[0.03274115 0.02789339 0.         0.17022693]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 501 is [True, False, False, False, False, True]
State prediction error at timestep 501 is 0.012
Current timestep = 502. State = [[-0.31069413  0.13951923]]. Action = [[ 0.09677943 -0.05883095  0.          0.52146196]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 502 is [True, False, False, False, False, True]
State prediction error at timestep 502 is 0.012
Current timestep = 503. State = [[-0.30363566  0.14078121]]. Action = [[ 0.05006734  0.0680356   0.         -0.11701512]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 503 is [True, False, False, False, False, True]
State prediction error at timestep 503 is 0.012
Current timestep = 504. State = [[-0.30319858  0.14558163]]. Action = [[-0.05686605  0.06343009  0.          0.72881794]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 504 is [True, False, False, False, False, True]
State prediction error at timestep 504 is 0.012
Current timestep = 505. State = [[-0.30572423  0.14591263]]. Action = [[-0.0522093  -0.03428001  0.          0.7778163 ]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 505 is [True, False, False, False, False, True]
State prediction error at timestep 505 is 0.012
Current timestep = 506. State = [[-0.30701694  0.14418112]]. Action = [[-0.02516241 -0.02094136  0.          0.774933  ]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 506 is [True, False, False, False, False, True]
State prediction error at timestep 506 is 0.012
Current timestep = 507. State = [[-0.3075822   0.14757814]]. Action = [[-0.01832598  0.07522105  0.          0.9059336 ]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 507 is [True, False, False, False, False, True]
State prediction error at timestep 507 is 0.012
Current timestep = 508. State = [[-0.30861577  0.14762466]]. Action = [[-0.02457923 -0.05363314  0.         -0.37792307]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 508 is [True, False, False, False, False, True]
State prediction error at timestep 508 is 0.012
Current timestep = 509. State = [[-0.30448347  0.1489166 ]]. Action = [[ 0.09021027  0.04537129  0.         -0.7929649 ]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 509 is [True, False, False, False, False, True]
State prediction error at timestep 509 is 0.012
Current timestep = 510. State = [[-0.29712787  0.14616595]]. Action = [[ 0.09514385 -0.08907235  0.          0.21174324]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 510 is [True, False, False, False, False, True]
State prediction error at timestep 510 is 0.012
Current timestep = 511. State = [[-0.29008195  0.14255188]]. Action = [[ 0.07141203 -0.02215929  0.         -0.3633207 ]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 511 is [True, False, False, False, False, True]
State prediction error at timestep 511 is 0.012
Current timestep = 512. State = [[-0.28320515  0.13883214]]. Action = [[ 0.07312217 -0.05264485  0.          0.7472129 ]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 512 is [True, False, False, False, False, True]
State prediction error at timestep 512 is 0.012
Current timestep = 513. State = [[-0.2781044   0.13324746]]. Action = [[ 0.02823288 -0.06740317  0.          0.34089684]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 513 is [True, False, False, False, False, True]
State prediction error at timestep 513 is 0.012
Current timestep = 514. State = [[-0.2790843  0.130927 ]]. Action = [[-0.07947282  0.01395305  0.         -0.17455852]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 514 is [True, False, False, False, False, True]
State prediction error at timestep 514 is 0.012
Current timestep = 515. State = [[-0.28200886  0.13212363]]. Action = [[-0.05044181  0.03792246  0.         -0.8972438 ]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 515 is [True, False, False, False, False, True]
State prediction error at timestep 515 is 0.012
Current timestep = 516. State = [[-0.28418782  0.13321574]]. Action = [[-0.03518949  0.01352175  0.         -0.97962   ]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 516 is [True, False, False, False, False, True]
State prediction error at timestep 516 is 0.012
Current timestep = 517. State = [[-0.28246617  0.1359378 ]]. Action = [[ 0.04667943  0.05283295  0.         -0.28167975]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 517 is [True, False, False, False, False, True]
State prediction error at timestep 517 is 0.012
Current timestep = 518. State = [[-0.28498647  0.13401867]]. Action = [[-0.08400543 -0.0681702   0.          0.69756424]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 518 is [True, False, False, False, False, True]
State prediction error at timestep 518 is 0.012
Current timestep = 519. State = [[-0.29107693  0.13425629]]. Action = [[-0.08410473  0.0457414   0.         -0.5958358 ]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 519 is [True, False, False, False, False, True]
State prediction error at timestep 519 is 0.012
Current timestep = 520. State = [[-0.29069954  0.13995375]]. Action = [[0.07279556 0.08518731 0.         0.5744257 ]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 520 is [True, False, False, False, False, True]
State prediction error at timestep 520 is 0.012
Current timestep = 521. State = [[-0.28619814  0.14111838]]. Action = [[ 0.06899785 -0.03888924  0.         -0.8461533 ]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 521 is [True, False, False, False, False, True]
State prediction error at timestep 521 is 0.012
Current timestep = 522. State = [[-0.28083134  0.14198002]]. Action = [[0.07923584 0.02884784 0.         0.8008146 ]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 522 is [True, False, False, False, False, True]
State prediction error at timestep 522 is 0.012
Current timestep = 523. State = [[-0.2830568   0.14343078]]. Action = [[-0.09534995  0.00646478  0.         -0.17469162]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 523 is [True, False, False, False, False, True]
State prediction error at timestep 523 is 0.012
Current timestep = 524. State = [[-0.28434458  0.14077625]]. Action = [[ 0.03655665 -0.06649028  0.         -0.7645536 ]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 524 is [True, False, False, False, False, True]
State prediction error at timestep 524 is 0.012
Current timestep = 525. State = [[-0.27907377  0.13573192]]. Action = [[ 0.09522197 -0.06534435  0.          0.04693067]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 525 is [True, False, False, False, False, True]
State prediction error at timestep 525 is 0.012
Current timestep = 526. State = [[-0.2779417   0.13176143]]. Action = [[-0.03905302 -0.03439987  0.         -0.47537816]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 526 is [True, False, False, False, False, True]
State prediction error at timestep 526 is 0.012
Current timestep = 527. State = [[-0.2813917   0.13263083]]. Action = [[-0.05733531  0.04862375  0.          0.57581973]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 527 is [True, False, False, False, False, True]
State prediction error at timestep 527 is 0.012
Current timestep = 528. State = [[-0.2821938   0.13223083]]. Action = [[ 0.01642083 -0.02727268  0.          0.18196094]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 528 is [True, False, False, False, False, True]
State prediction error at timestep 528 is 0.012
Current timestep = 529. State = [[-0.27752972  0.13441113]]. Action = [[0.09173387 0.06541219 0.         0.7012117 ]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 529 is [True, False, False, False, False, True]
State prediction error at timestep 529 is 0.012
Current timestep = 530. State = [[-0.27881455  0.14098765]]. Action = [[-0.07461113  0.09856474  0.         -0.6181594 ]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 530 is [True, False, False, False, False, True]
State prediction error at timestep 530 is 0.012
Current timestep = 531. State = [[-0.2854626   0.14125037]]. Action = [[-0.08068784 -0.05981946  0.         -0.479398  ]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 531 is [True, False, False, False, False, True]
State prediction error at timestep 531 is 0.012
Current timestep = 532. State = [[-0.28639272  0.14200966]]. Action = [[0.04585969 0.04062837 0.         0.1331358 ]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 532 is [True, False, False, False, False, True]
State prediction error at timestep 532 is 0.012
Current timestep = 533. State = [[-0.28646344  0.14137334]]. Action = [[-0.00960327 -0.04289803  0.          0.34462285]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 533 is [True, False, False, False, False, True]
State prediction error at timestep 533 is 0.012
Current timestep = 534. State = [[-0.2913867   0.13856749]]. Action = [[-0.09030557 -0.03809397  0.         -0.5598222 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 534 is [True, False, False, False, False, True]
State prediction error at timestep 534 is 0.012
Current timestep = 535. State = [[-0.2926395   0.13309167]]. Action = [[ 0.02972492 -0.08811817  0.          0.572804  ]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 535 is [True, False, False, False, False, True]
State prediction error at timestep 535 is 0.012
Current timestep = 536. State = [[-0.28793472  0.12979291]]. Action = [[ 0.08292889 -0.00729389  0.          0.77230334]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 536 is [True, False, False, False, False, True]
State prediction error at timestep 536 is 0.012
Current timestep = 537. State = [[-0.28229278  0.13206883]]. Action = [[ 0.07094084  0.06247955  0.         -0.9806415 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 537 is [True, False, False, False, False, True]
State prediction error at timestep 537 is 0.012
Current timestep = 538. State = [[-0.27860597  0.12853645]]. Action = [[ 0.03295118 -0.09910754  0.         -0.5560324 ]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 538 is [True, False, False, False, False, True]
State prediction error at timestep 538 is 0.012
Current timestep = 539. State = [[-0.27742472  0.12135574]]. Action = [[-0.00840111 -0.07207593  0.         -0.2840904 ]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 539 is [True, False, False, False, True, False]
State prediction error at timestep 539 is 0.012
Current timestep = 540. State = [[-0.2734875   0.12173403]]. Action = [[ 0.07145392  0.07542294  0.         -0.42179275]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 540 is [True, False, False, False, True, False]
State prediction error at timestep 540 is 0.012
Current timestep = 541. State = [[-0.2741295   0.12537095]]. Action = [[-0.06320062  0.05031686  0.         -0.83937025]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 541 is [True, False, False, False, False, True]
State prediction error at timestep 541 is 0.012
Current timestep = 542. State = [[-0.2746675   0.12207701]]. Action = [[ 0.01695845 -0.0847486   0.          0.9404931 ]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 542 is [True, False, False, False, True, False]
State prediction error at timestep 542 is 0.012
Current timestep = 543. State = [[-0.2702571   0.11810817]]. Action = [[ 0.07367922 -0.01790107  0.         -0.4721111 ]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 543 is [True, False, False, False, True, False]
State prediction error at timestep 543 is 0.012
Current timestep = 544. State = [[-0.26946607  0.12049973]]. Action = [[-0.03570401  0.07485887  0.          0.67991495]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 544 is [True, False, False, False, True, False]
State prediction error at timestep 544 is 0.012
Current timestep = 545. State = [[-0.27066445  0.11852281]]. Action = [[-0.01100727 -0.07426924  0.          0.47194982]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 545 is [True, False, False, False, True, False]
State prediction error at timestep 545 is 0.012
Current timestep = 546. State = [[-0.2727741  0.1195101]]. Action = [[-0.04275542  0.06937578  0.         -0.33416986]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 546 is [True, False, False, False, True, False]
State prediction error at timestep 546 is 0.012
Current timestep = 547. State = [[-0.2760995   0.11658846]]. Action = [[-0.04833544 -0.09379338  0.          0.6217084 ]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 547 is [True, False, False, False, True, False]
State prediction error at timestep 547 is 0.012
Current timestep = 548. State = [[-0.27342892  0.11726971]]. Action = [[0.08352182 0.07422017 0.         0.40902376]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 548 is [True, False, False, False, True, False]
State prediction error at timestep 548 is 0.012
Current timestep = 549. State = [[-0.27277562  0.12254684]]. Action = [[-0.02799673  0.06321978  0.         -0.9365571 ]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 549 is [True, False, False, False, True, False]
State prediction error at timestep 549 is 0.012
Current timestep = 550. State = [[-0.27645046  0.12568575]]. Action = [[-0.05512981  0.01656814  0.         -0.13116324]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 550 is [True, False, False, False, False, True]
State prediction error at timestep 550 is 0.012
Current timestep = 551. State = [[-0.27998784  0.12971117]]. Action = [[-0.03146157  0.05766477  0.         -0.41768026]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 551 is [True, False, False, False, False, True]
State prediction error at timestep 551 is 0.012
Current timestep = 552. State = [[-0.28322875  0.13412179]]. Action = [[-0.03157199  0.03697485  0.         -0.23048872]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 552 is [True, False, False, False, False, True]
State prediction error at timestep 552 is 0.012
Current timestep = 553. State = [[-0.28471556  0.13427864]]. Action = [[ 0.00421421 -0.04098063  0.         -0.13289559]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 553 is [True, False, False, False, False, True]
State prediction error at timestep 553 is 0.012
Current timestep = 554. State = [[-0.28203896  0.13884494]]. Action = [[ 0.0723364   0.09494751  0.         -0.6156328 ]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 554 is [True, False, False, False, False, True]
State prediction error at timestep 554 is 0.012
Current timestep = 555. State = [[-0.28161576  0.14335296]]. Action = [[-0.00902926  0.01379089  0.          0.25241554]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 555 is [True, False, False, False, False, True]
State prediction error at timestep 555 is 0.012
Current timestep = 556. State = [[-0.28554067  0.14057148]]. Action = [[-0.06451979 -0.08811558  0.         -0.21468842]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 556 is [True, False, False, False, False, True]
State prediction error at timestep 556 is 0.012
Current timestep = 557. State = [[-0.28615072  0.14179969]]. Action = [[ 0.03168794  0.06054413  0.         -0.7844381 ]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 557 is [True, False, False, False, False, True]
State prediction error at timestep 557 is 0.012
Current timestep = 558. State = [[-0.28307092  0.14149548]]. Action = [[ 0.05601392 -0.05366596  0.         -0.17573798]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 558 is [True, False, False, False, False, True]
State prediction error at timestep 558 is 0.012
Current timestep = 559. State = [[-0.27889183  0.13591303]]. Action = [[ 0.05176198 -0.09039542  0.         -0.8369373 ]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 559 is [True, False, False, False, False, True]
State prediction error at timestep 559 is 0.012
Current timestep = 560. State = [[-0.27869847  0.13538723]]. Action = [[-0.03837786  0.04526607  0.          0.9375632 ]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 560 is [True, False, False, False, False, True]
State prediction error at timestep 560 is 0.012
Current timestep = 561. State = [[-0.27998003  0.13695799]]. Action = [[-0.01419838  0.01155837  0.         -0.05836856]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 561 is [True, False, False, False, False, True]
State prediction error at timestep 561 is 0.012
Current timestep = 562. State = [[-0.28134984  0.13700563]]. Action = [[-0.02549524 -0.00402541  0.         -0.59274405]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 562 is [True, False, False, False, False, True]
State prediction error at timestep 562 is 0.012
Current timestep = 563. State = [[-0.27742502  0.13684395]]. Action = [[ 0.09274534  0.00180402  0.         -0.06339782]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 563 is [True, False, False, False, False, True]
State prediction error at timestep 563 is 0.012
Current timestep = 564. State = [[-0.27111053  0.1398186 ]]. Action = [[0.07493392 0.06214013 0.         0.3664478 ]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 564 is [True, False, False, False, False, True]
State prediction error at timestep 564 is 0.012
Current timestep = 565. State = [[-0.2677105   0.14469995]]. Action = [[ 0.02352931  0.06240831  0.         -0.92032325]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 565 is [True, False, False, False, False, True]
State prediction error at timestep 565 is 0.012
Current timestep = 566. State = [[-0.2668536   0.14638337]]. Action = [[-0.00052937 -0.00813042  0.         -0.08056515]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 566 is [True, False, False, False, False, True]
State prediction error at timestep 566 is 0.012
Current timestep = 567. State = [[-0.2641178   0.14799213]]. Action = [[0.04875293 0.02897847 0.         0.5677208 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 567 is [True, False, False, False, False, True]
State prediction error at timestep 567 is 0.012
Current timestep = 568. State = [[-0.26325977  0.15082869]]. Action = [[-0.01737469  0.03130656  0.         -0.34987712]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 568 is [True, False, False, False, False, True]
State prediction error at timestep 568 is 0.012
Current timestep = 569. State = [[-0.25934932  0.15649483]]. Action = [[0.08407217 0.08135977 0.         0.7516494 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 569 is [True, False, False, False, False, True]
State prediction error at timestep 569 is 0.012
Current timestep = 570. State = [[-0.25611362  0.15832128]]. Action = [[ 0.01385465 -0.02873067  0.         -0.23393238]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 570 is [True, False, False, False, False, True]
State prediction error at timestep 570 is 0.012
Current timestep = 571. State = [[-0.25384948  0.15794249]]. Action = [[ 0.02122394 -0.01085789  0.          0.7352762 ]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 571 is [True, False, False, False, False, True]
State prediction error at timestep 571 is 0.012
Current timestep = 572. State = [[-0.25043938  0.16314271]]. Action = [[0.0414579  0.09466485 0.         0.7069384 ]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 572 is [True, False, False, False, False, True]
State prediction error at timestep 572 is 0.012
Current timestep = 573. State = [[-0.25234908  0.16610378]]. Action = [[-0.07910393 -0.01579689  0.          0.6663703 ]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 573 is [True, False, False, False, False, True]
State prediction error at timestep 573 is 0.012
Current timestep = 574. State = [[-0.2532777   0.16389382]]. Action = [[ 0.00518954 -0.06085864  0.          0.27689946]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 574 is [True, False, False, False, False, True]
State prediction error at timestep 574 is 0.012
Current timestep = 575. State = [[-0.2527582  0.1642174]]. Action = [[-0.01019163  0.02436092  0.          0.74184394]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 575 is [True, False, False, False, False, True]
State prediction error at timestep 575 is 0.012
Current timestep = 576. State = [[-0.25533587  0.16934095]]. Action = [[-0.06154616  0.0736055   0.         -0.4359668 ]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 576 is [True, False, False, False, False, True]
State prediction error at timestep 576 is 0.012
Current timestep = 577. State = [[-0.25958475  0.17033795]]. Action = [[-0.06189437 -0.04429758  0.          0.48023248]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 577 is [True, False, False, False, False, True]
State prediction error at timestep 577 is 0.012
Current timestep = 578. State = [[-0.26154447  0.17206907]]. Action = [[-0.01082579  0.03918456  0.         -0.76718426]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 578 is [True, False, False, False, False, True]
State prediction error at timestep 578 is 0.012
Current timestep = 579. State = [[-0.2601692   0.17750028]]. Action = [[ 0.04097646  0.06950911  0.         -0.5215869 ]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 579 is [True, False, False, False, False, True]
State prediction error at timestep 579 is 0.012
Current timestep = 580. State = [[-0.26226997  0.17563428]]. Action = [[-0.06010491 -0.09955843  0.         -0.52445275]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 580 is [True, False, False, False, False, True]
State prediction error at timestep 580 is 0.012
Current timestep = 581. State = [[-0.26177043  0.17611867]]. Action = [[ 0.04876661  0.05430878  0.         -0.16657639]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 581 is [True, False, False, False, False, True]
State prediction error at timestep 581 is 0.012
Current timestep = 582. State = [[-0.2596133   0.17486975]]. Action = [[ 0.0254392  -0.06244842  0.          0.7543514 ]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 582 is [True, False, False, False, False, True]
State prediction error at timestep 582 is 0.012
Current timestep = 583. State = [[-0.26277983  0.1779322 ]]. Action = [[-0.07820434  0.0916147   0.         -0.16540015]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 583 is [True, False, False, False, False, True]
State prediction error at timestep 583 is 0.012
Current timestep = 584. State = [[-0.26335272  0.1830908 ]]. Action = [[0.04580378 0.04355856 0.         0.53009677]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 584 is [True, False, False, False, False, True]
State prediction error at timestep 584 is 0.012
Current timestep = 585. State = [[-0.2627046   0.18213603]]. Action = [[ 0.00155725 -0.05694128  0.         -0.6675591 ]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 585 is [True, False, False, False, False, True]
State prediction error at timestep 585 is 0.012
Current timestep = 586. State = [[-0.26256442  0.18072304]]. Action = [[ 0.00535686 -0.0031271   0.         -0.9825558 ]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 586 is [True, False, False, False, False, True]
State prediction error at timestep 586 is 0.012
Current timestep = 587. State = [[-0.26527607  0.17981602]]. Action = [[-0.05737407 -0.01963631  0.          0.19064772]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 587 is [True, False, False, False, False, True]
State prediction error at timestep 587 is 0.012
Current timestep = 588. State = [[-0.26640958  0.17565471]]. Action = [[ 0.00677641 -0.0752698   0.         -0.74670553]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 588 is [True, False, False, False, False, True]
State prediction error at timestep 588 is 0.012
Current timestep = 589. State = [[-0.26398015  0.1744624 ]]. Action = [[0.04468635 0.0248066  0.         0.48469043]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 589 is [True, False, False, False, False, True]
State prediction error at timestep 589 is 0.012
Current timestep = 590. State = [[-0.26718852  0.17956331]]. Action = [[-0.09052147  0.09564602  0.          0.5644152 ]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 590 is [True, False, False, False, False, True]
State prediction error at timestep 590 is 0.012
Current timestep = 591. State = [[-0.27344984  0.18325408]]. Action = [[-0.06523684  0.01513074  0.          0.4672519 ]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 591 is [True, False, False, False, False, True]
State prediction error at timestep 591 is 0.012
Current timestep = 592. State = [[-0.27727354  0.18271165]]. Action = [[-0.02196235 -0.03009898  0.         -0.02628273]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 592 is [True, False, False, False, False, True]
State prediction error at timestep 592 is 0.012
Current timestep = 593. State = [[-0.2796988   0.18084975]]. Action = [[-0.01901784 -0.02627609  0.          0.9892664 ]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 593 is [True, False, False, False, False, True]
State prediction error at timestep 593 is 0.012
Current timestep = 594. State = [[-0.28408703  0.17636155]]. Action = [[-0.06477769 -0.07747892  0.          0.07841158]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 594 is [True, False, False, False, False, True]
State prediction error at timestep 594 is 0.012
Current timestep = 595. State = [[-0.2853232   0.17651492]]. Action = [[ 0.02720527  0.05066619  0.         -0.49601126]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 595 is [True, False, False, False, False, True]
State prediction error at timestep 595 is 0.012
Current timestep = 596. State = [[-0.28723523  0.18224397]]. Action = [[-0.0278063   0.08954474  0.          0.9023584 ]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 596 is [True, False, False, False, False, True]
State prediction error at timestep 596 is 0.012
Current timestep = 597. State = [[-0.29410827  0.18718511]]. Action = [[-0.09457643  0.04094883  0.         -0.36075795]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 597 is [True, False, False, False, False, True]
State prediction error at timestep 597 is 0.012
Current timestep = 598. State = [[-0.2988011   0.18895456]]. Action = [[-0.00857156 -0.00180315  0.         -0.37717366]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 598 is [True, False, False, False, False, True]
State prediction error at timestep 598 is 0.012
Current timestep = 599. State = [[-0.3019046   0.19102937]]. Action = [[-0.02096254  0.03001337  0.         -0.4948995 ]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 599 is [True, False, False, False, False, True]
State prediction error at timestep 599 is 0.012
Current timestep = 600. State = [[-0.30591404  0.19587682]]. Action = [[-0.03135657  0.06714403  0.          0.8964596 ]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 600 is [True, False, False, False, False, True]
State prediction error at timestep 600 is 0.012
Current timestep = 601. State = [[-0.31005144  0.19771013]]. Action = [[-0.02650841 -0.01908581  0.         -0.8332626 ]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 601 is [True, False, False, False, False, True]
State prediction error at timestep 601 is 0.012
Current timestep = 602. State = [[-0.3170925   0.19421504]]. Action = [[-0.09784143 -0.07845176  0.         -0.53988665]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 602 is [True, False, False, False, False, True]
State prediction error at timestep 602 is 0.012
Current timestep = 603. State = [[-0.3183358  0.1914303]]. Action = [[ 0.06057393 -0.02128365  0.          0.02834129]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 603 is [True, False, False, False, False, True]
State prediction error at timestep 603 is 0.012
Current timestep = 604. State = [[-0.31328508  0.19188385]]. Action = [[0.09332841 0.02251764 0.         0.6058736 ]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 604 is [True, False, False, False, False, True]
State prediction error at timestep 604 is 0.012
Current timestep = 605. State = [[-0.31340417  0.19605538]]. Action = [[-0.04041376  0.07312278  0.          0.3625015 ]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 605 is [True, False, False, False, False, True]
State prediction error at timestep 605 is 0.012
Current timestep = 606. State = [[-0.31572235  0.19777885]]. Action = [[-0.00737274 -0.01076124  0.          0.25468063]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 606 is [True, False, False, False, False, True]
State prediction error at timestep 606 is 0.012
Current timestep = 607. State = [[-0.31479642  0.19927181]]. Action = [[0.04117803 0.03161114 0.         0.14701807]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 607 is [True, False, False, False, False, True]
State prediction error at timestep 607 is 0.012
Current timestep = 608. State = [[-0.31907302  0.20532386]]. Action = [[-0.09439955  0.09989469  0.          0.16068304]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 608 is [True, False, False, False, False, True]
State prediction error at timestep 608 is 0.012
Current timestep = 609. State = [[-0.3197632   0.20689413]]. Action = [[ 0.06396099 -0.03718161  0.          0.05816877]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 609 is [True, False, False, False, False, True]
State prediction error at timestep 609 is 0.012
Current timestep = 610. State = [[-0.3225662   0.21113043]]. Action = [[-0.07346742  0.0928702   0.         -0.72642225]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 610 is [True, False, False, False, False, True]
State prediction error at timestep 610 is 0.012
Current timestep = 611. State = [[-0.32535368  0.21045497]]. Action = [[ 8.422509e-04 -8.657336e-02  0.000000e+00  8.458307e-01]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 611 is [True, False, False, False, False, True]
State prediction error at timestep 611 is 0.012
Current timestep = 612. State = [[-0.32692102  0.21319743]]. Action = [[-0.01633822  0.0903812   0.         -0.06595856]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 612 is [True, False, False, False, False, True]
State prediction error at timestep 612 is 0.012
Current timestep = 613. State = [[-0.3325108   0.22031711]]. Action = [[-0.08356193  0.07509466  0.         -0.32690245]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 613 is [True, False, False, False, False, True]
State prediction error at timestep 613 is 0.012
Current timestep = 614. State = [[-0.33512092  0.22333896]]. Action = [[ 0.01903339 -0.00937527  0.          0.22672677]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 614 is [True, False, False, False, False, True]
State prediction error at timestep 614 is 0.012
Current timestep = 615. State = [[-0.3333278   0.22142024]]. Action = [[ 0.04779836 -0.0562859   0.          0.3957746 ]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 615 is [True, False, False, False, False, True]
State prediction error at timestep 615 is 0.012
Current timestep = 616. State = [[-0.32984734  0.217156  ]]. Action = [[ 0.05110728 -0.06561787  0.          0.7569829 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 616 is [True, False, False, False, False, True]
State prediction error at timestep 616 is 0.012
Current timestep = 617. State = [[-0.3243186   0.22019404]]. Action = [[ 0.0856423   0.09938668  0.         -0.47485673]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 617 is [True, False, False, False, False, True]
State prediction error at timestep 617 is 0.012
Current timestep = 618. State = [[-0.31750804  0.22444753]]. Action = [[ 0.09350535  0.03010996  0.         -0.97987205]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 618 is [True, False, False, False, False, True]
State prediction error at timestep 618 is 0.012
Current timestep = 619. State = [[-0.31274003  0.22733206]]. Action = [[0.03684215 0.03804659 0.         0.23448598]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 619 is [True, False, False, False, False, True]
State prediction error at timestep 619 is 0.012
Current timestep = 620. State = [[-0.3061438   0.22993156]]. Action = [[0.09896632 0.02823228 0.         0.98905706]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 620 is [True, False, False, False, False, True]
State prediction error at timestep 620 is 0.012
Current timestep = 621. State = [[-0.29866946  0.2311153 ]]. Action = [[ 0.07467472  0.00581938  0.         -0.9938354 ]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 621 is [True, False, False, False, False, True]
State prediction error at timestep 621 is 0.012
Current timestep = 622. State = [[-0.2950854   0.23629329]]. Action = [[0.00098898 0.0966697  0.         0.7894455 ]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 622 is [True, False, False, False, False, True]
State prediction error at timestep 622 is 0.012
Current timestep = 623. State = [[-0.29516804  0.2367995 ]]. Action = [[-0.03582539 -0.05948996  0.          0.44535136]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 623 is [True, False, False, False, False, True]
State prediction error at timestep 623 is 0.012
Current timestep = 624. State = [[-0.2946929   0.23950244]]. Action = [[-0.00566722  0.06642725  0.          0.6773325 ]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 624 is [True, False, False, False, False, True]
State prediction error at timestep 624 is 0.012
Current timestep = 625. State = [[-0.29554012  0.24030876]]. Action = [[-0.04299963 -0.04385731  0.         -0.15665197]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 625 is [True, False, False, False, False, True]
State prediction error at timestep 625 is 0.012
Current timestep = 626. State = [[-0.29151696  0.24120922]]. Action = [[0.0787892  0.01992594 0.         0.95648146]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 626 is [True, False, False, False, False, True]
State prediction error at timestep 626 is 0.012
Current timestep = 627. State = [[-0.28360182  0.24429566]]. Action = [[ 0.08844181  0.03697538  0.         -0.3434568 ]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 627 is [True, False, False, False, False, True]
State prediction error at timestep 627 is 0.012
Current timestep = 628. State = [[-0.28184807  0.2423787 ]]. Action = [[-0.05698236 -0.07727917  0.         -0.55647093]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 628 is [True, False, False, False, False, True]
State prediction error at timestep 628 is 0.012
Current timestep = 629. State = [[-0.27942437  0.2426865 ]]. Action = [[ 0.05094697  0.03670716  0.         -0.05748993]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 629 is [True, False, False, False, False, True]
State prediction error at timestep 629 is 0.012
Current timestep = 630. State = [[-0.27960485  0.24853234]]. Action = [[-0.05336151  0.08737039  0.         -0.03152585]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 630 is [True, False, False, False, False, True]
State prediction error at timestep 630 is 0.012
Current timestep = 631. State = [[-0.27902845  0.252438  ]]. Action = [[0.02723116 0.01036346 0.         0.4979713 ]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 631 is [True, False, False, False, False, True]
State prediction error at timestep 631 is 0.012
Current timestep = 632. State = [[-0.27718037  0.25857678]]. Action = [[0.01595028 0.09896594 0.         0.42594278]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 632 is [True, False, False, False, False, True]
State prediction error at timestep 632 is 0.012
Current timestep = 633. State = [[-0.2792014   0.26046675]]. Action = [[-0.05523187 -0.04066811  0.         -0.12818384]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 633 is [True, False, False, False, False, True]
State prediction error at timestep 633 is 0.012
Current timestep = 634. State = [[-0.28081304  0.25845072]]. Action = [[-0.0094514  -0.04509208  0.         -0.60036016]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 634 is [True, False, False, False, False, True]
State prediction error at timestep 634 is 0.012
Current timestep = 635. State = [[-0.277312    0.25407684]]. Action = [[ 0.06842463 -0.07816436  0.         -0.2783476 ]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 635 is [True, False, False, False, False, True]
State prediction error at timestep 635 is 0.012
Current timestep = 636. State = [[-0.27270377  0.24777266]]. Action = [[ 0.038228   -0.08503304  0.         -0.7730674 ]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 636 is [True, False, False, False, False, True]
State prediction error at timestep 636 is 0.012
Current timestep = 637. State = [[-0.26716506  0.24963321]]. Action = [[0.07154364 0.0973851  0.         0.05149865]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 637 is [True, False, False, False, False, True]
State prediction error at timestep 637 is 0.012
Current timestep = 638. State = [[-0.2678766   0.24798015]]. Action = [[-0.08196685 -0.08470008  0.         -0.17770249]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 638 is [True, False, False, False, False, True]
State prediction error at timestep 638 is 0.012
Current timestep = 639. State = [[-0.26989254  0.24663429]]. Action = [[-0.00391995  0.02402687  0.          0.28788435]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 639 is [True, False, False, False, False, True]
State prediction error at timestep 639 is 0.012
Current timestep = 640. State = [[-0.2674886   0.24312435]]. Action = [[ 0.05254122 -0.07084224  0.         -0.51357603]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 640 is [True, False, False, False, False, True]
State prediction error at timestep 640 is 0.012
Current timestep = 641. State = [[-0.2637716   0.24274975]]. Action = [[ 0.04348443  0.05216476  0.         -0.21810913]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 641 is [True, False, False, False, False, True]
State prediction error at timestep 641 is 0.012
Current timestep = 642. State = [[-0.2656424   0.24700041]]. Action = [[-0.06299232  0.07454646  0.         -0.2744394 ]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 642 is [True, False, False, False, False, True]
State prediction error at timestep 642 is 0.012
Current timestep = 643. State = [[-0.27003708  0.24572296]]. Action = [[-0.05120852 -0.06481425  0.          0.7658851 ]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 643 is [True, False, False, False, False, True]
State prediction error at timestep 643 is 0.012
Current timestep = 644. State = [[-0.269529   0.2458727]]. Action = [[ 0.04742465  0.04352032  0.         -0.6083065 ]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 644 is [True, False, False, False, False, True]
State prediction error at timestep 644 is 0.012
Current timestep = 645. State = [[-0.26379013  0.24163128]]. Action = [[ 0.09619214 -0.09881356  0.         -0.95769733]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 645 is [True, False, False, False, False, True]
State prediction error at timestep 645 is 0.012
Current timestep = 646. State = [[-0.25839916  0.24252568]]. Action = [[ 0.05239103  0.09305919  0.         -0.35257006]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 646 is [True, False, False, False, False, True]
State prediction error at timestep 646 is 0.012
Current timestep = 647. State = [[-0.25253093  0.24725239]]. Action = [[0.08820438 0.05861523 0.         0.40050292]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 647 is [True, False, False, False, False, True]
State prediction error at timestep 647 is 0.012
Current timestep = 648. State = [[-0.2514091   0.24508978]]. Action = [[-0.04115284 -0.07373197  0.          0.2803011 ]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 648 is [True, False, False, False, False, True]
State prediction error at timestep 648 is 0.012
Current timestep = 649. State = [[-0.25245774  0.24202219]]. Action = [[-0.01053555 -0.01893614  0.         -0.72565717]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 649 is [True, False, False, False, False, True]
State prediction error at timestep 649 is 0.012
Current timestep = 650. State = [[-0.2555532   0.24357758]]. Action = [[-0.06525794  0.04484237  0.         -0.3789481 ]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 650 is [True, False, False, False, False, True]
State prediction error at timestep 650 is 0.012
Current timestep = 651. State = [[-0.2537763   0.24799114]]. Action = [[0.07618288 0.06207082 0.         0.34899652]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 651 is [True, False, False, False, False, True]
State prediction error at timestep 651 is 0.012
Current timestep = 652. State = [[-0.25482482  0.25350478]]. Action = [[-0.06342683  0.06878347  0.         -0.76596206]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 652 is [True, False, False, False, False, True]
State prediction error at timestep 652 is 0.012
Current timestep = 653. State = [[-0.25650463  0.25985262]]. Action = [[ 0.00789462  0.07249831  0.         -0.37702894]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 653 is [True, False, False, False, False, True]
State prediction error at timestep 653 is 0.012
Current timestep = 654. State = [[-0.2547343   0.26470143]]. Action = [[0.0474469  0.03703807 0.         0.26188624]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 654 is [True, False, False, False, False, True]
State prediction error at timestep 654 is 0.012
Current timestep = 655. State = [[-0.2522735   0.26240978]]. Action = [[ 0.02976342 -0.08831351  0.          0.3069737 ]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 655 is [True, False, False, False, False, True]
State prediction error at timestep 655 is 0.012
Current timestep = 656. State = [[-0.25322264  0.2639173 ]]. Action = [[-0.04010884  0.06209569  0.         -0.20109618]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 656 is [True, False, False, False, False, True]
State prediction error at timestep 656 is 0.012
Current timestep = 657. State = [[-0.2524649   0.26207012]]. Action = [[ 0.03435377 -0.0926173   0.          0.18249917]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 657 is [True, False, False, False, False, True]
State prediction error at timestep 657 is 0.012
Current timestep = 658. State = [[-0.25252402  0.25986096]]. Action = [[-0.03179321 -0.00979427  0.         -0.7875047 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 658 is [True, False, False, False, False, True]
State prediction error at timestep 658 is 0.012
Current timestep = 659. State = [[-0.25054622  0.2570507 ]]. Action = [[ 0.043309   -0.06060323  0.          0.5375166 ]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 659 is [True, False, False, False, False, True]
State prediction error at timestep 659 is 0.012
Current timestep = 660. State = [[-0.24390967  0.25440764]]. Action = [[ 0.09491216 -0.01704042  0.          0.4644935 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 660 is [True, False, False, False, False, True]
State prediction error at timestep 660 is 0.012
Current timestep = 661. State = [[-0.24125467  0.25036225]]. Action = [[-0.02479723 -0.06182852  0.          0.82555366]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 661 is [True, False, False, False, False, True]
State prediction error at timestep 661 is 0.012
Current timestep = 662. State = [[-0.23972276  0.24713568]]. Action = [[ 0.0182485  -0.01829763  0.         -0.8011281 ]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 662 is [True, False, False, False, False, True]
State prediction error at timestep 662 is 0.012
Current timestep = 663. State = [[-0.23794024  0.24802983]]. Action = [[0.00739714 0.04684976 0.         0.51387954]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 663 is [True, False, False, False, False, True]
State prediction error at timestep 663 is 0.012
Current timestep = 664. State = [[-0.2323375   0.24893127]]. Action = [[0.09729623 0.01106997 0.         0.60273874]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 664 is [True, False, False, False, False, True]
State prediction error at timestep 664 is 0.012
Current timestep = 665. State = [[-0.22672592  0.24955954]]. Action = [[ 0.04698556  0.02762476  0.         -0.0470311 ]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 665 is [True, False, False, False, False, True]
State prediction error at timestep 665 is 0.012
Current timestep = 666. State = [[-0.2201986   0.24820977]]. Action = [[ 0.08840128 -0.02307506  0.         -0.3390838 ]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 666 is [True, False, False, False, False, True]
State prediction error at timestep 666 is 0.012
Current timestep = 667. State = [[-0.21257822  0.25127435]]. Action = [[ 0.08647694  0.09624893  0.         -0.69255114]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 667 is [True, False, False, False, False, True]
State prediction error at timestep 667 is 0.012
Current timestep = 668. State = [[-0.20441392  0.25619984]]. Action = [[0.09992255 0.06365254 0.         0.5988679 ]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 668 is [True, False, False, False, False, True]
State prediction error at timestep 668 is 0.012
Current timestep = 669. State = [[-0.19873057  0.25815234]]. Action = [[0.03592481 0.01204173 0.         0.7943357 ]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 669 is [True, False, False, False, False, True]
State prediction error at timestep 669 is 0.012
Current timestep = 670. State = [[-0.19789712  0.26207927]]. Action = [[-0.03469252  0.07026207  0.         -0.45133263]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 670 is [True, False, False, False, False, True]
State prediction error at timestep 670 is 0.012
Current timestep = 671. State = [[-0.19623515  0.26856726]]. Action = [[ 0.02804438  0.07726803  0.         -0.16600358]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 671 is [True, False, False, False, False, True]
State prediction error at timestep 671 is 0.012
Current timestep = 672. State = [[-0.19767967  0.27421454]]. Action = [[-0.0650923   0.04410706  0.         -0.2180605 ]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 672 is [True, False, False, False, False, True]
State prediction error at timestep 672 is 0.012
Current timestep = 673. State = [[-0.1941941  0.2815948]]. Action = [[ 0.09875765  0.09084234  0.         -0.3289113 ]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 673 is [True, False, False, False, False, True]
State prediction error at timestep 673 is 0.012
Current timestep = 674. State = [[-0.19466724  0.2842578 ]]. Action = [[-0.09775459 -0.04352016  0.          0.19812512]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 674 is [True, False, False, False, False, True]
State prediction error at timestep 674 is 0.012
Current timestep = 675. State = [[-0.19225156  0.2804689 ]]. Action = [[ 0.0869179  -0.09575927  0.         -0.87877107]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 675 is [True, False, False, False, False, True]
State prediction error at timestep 675 is 0.012
Current timestep = 676. State = [[-0.1889429   0.27607477]]. Action = [[-0.00630052 -0.06255816  0.          0.4445219 ]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 676 is [True, False, False, False, False, True]
State prediction error at timestep 676 is 0.012
Current timestep = 677. State = [[-0.18750933  0.27048552]]. Action = [[-0.00451447 -0.09705857  0.         -0.04356968]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 677 is [True, False, False, False, False, True]
State prediction error at timestep 677 is 0.012
Current timestep = 678. State = [[-0.18890001  0.26674986]]. Action = [[-0.0660281  -0.03237283  0.          0.23532486]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 678 is [True, False, False, False, False, True]
State prediction error at timestep 678 is 0.012
Current timestep = 679. State = [[-0.18919119  0.27042302]]. Action = [[0.00185739 0.08714854 0.         0.56651926]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 679 is [True, False, False, False, False, True]
State prediction error at timestep 679 is 0.012
Current timestep = 680. State = [[-0.19154046  0.2716808 ]]. Action = [[-0.06586607 -0.03134788  0.         -0.2472384 ]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 680 is [True, False, False, False, False, True]
State prediction error at timestep 680 is 0.012
Current timestep = 681. State = [[-0.19260035  0.27477953]]. Action = [[ 0.00512733  0.07015779  0.         -0.14791906]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 681 is [True, False, False, False, False, True]
State prediction error at timestep 681 is 0.012
Current timestep = 682. State = [[-0.19364484  0.2786757 ]]. Action = [[-0.02109624  0.0317814   0.          0.44601274]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 682 is [True, False, False, False, False, True]
State prediction error at timestep 682 is 0.012
Current timestep = 683. State = [[-0.19102089  0.27891836]]. Action = [[ 0.07271525 -0.0215927   0.          0.024351  ]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 683 is [True, False, False, False, False, True]
State prediction error at timestep 683 is 0.012
Current timestep = 684. State = [[-0.18623719  0.27634814]]. Action = [[ 0.06322425 -0.03688561  0.         -0.15575051]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 684 is [True, False, False, False, False, True]
State prediction error at timestep 684 is 0.012
Current timestep = 685. State = [[-0.18698506  0.27141738]]. Action = [[-0.06083758 -0.07334603  0.          0.07509732]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 685 is [True, False, False, False, False, True]
State prediction error at timestep 685 is 0.012
Current timestep = 686. State = [[-0.1861577   0.26627615]]. Action = [[ 0.04273786 -0.05345914  0.         -0.43095022]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 686 is [True, False, False, False, False, True]
State prediction error at timestep 686 is 0.012
Current timestep = 687. State = [[-0.17996809  0.2651472 ]]. Action = [[ 0.09982011  0.03008839  0.         -0.7360014 ]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 687 is [True, False, False, False, False, True]
State prediction error at timestep 687 is 0.012
Current timestep = 688. State = [[-0.17749819  0.2669364 ]]. Action = [[-0.00995146  0.04514747  0.         -0.42158002]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 688 is [True, False, False, False, False, True]
State prediction error at timestep 688 is 0.012
Current timestep = 689. State = [[-0.17624667  0.27201045]]. Action = [[ 0.02968646  0.09393749  0.         -0.4237852 ]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 689 is [True, False, False, False, False, True]
State prediction error at timestep 689 is 0.012
Current timestep = 690. State = [[-0.17562196  0.27084905]]. Action = [[-0.00245116 -0.06742518  0.         -0.7228733 ]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 690 is [True, False, False, False, False, True]
State prediction error at timestep 690 is 0.012
Current timestep = 691. State = [[-0.17988849  0.27318487]]. Action = [[-0.09258889  0.08759674  0.         -0.78427863]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 691 is [True, False, False, False, False, True]
State prediction error at timestep 691 is 0.012
Current timestep = 692. State = [[-0.18232669  0.27353808]]. Action = [[ 0.00231936 -0.04925582  0.         -0.5128294 ]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 692 is [True, False, False, False, False, True]
State prediction error at timestep 692 is 0.012
Current timestep = 693. State = [[-0.18144847  0.27417234]]. Action = [[ 0.02040564  0.03244578  0.         -0.6444013 ]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 693 is [True, False, False, False, False, True]
State prediction error at timestep 693 is 0.012
Current timestep = 694. State = [[-0.18047808  0.27124137]]. Action = [[ 0.00908263 -0.08148886  0.         -0.7098818 ]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 694 is [True, False, False, False, False, True]
State prediction error at timestep 694 is 0.012
Current timestep = 695. State = [[-0.17577957  0.271514  ]]. Action = [[0.08978231 0.05359105 0.         0.5158378 ]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 695 is [True, False, False, False, False, True]
State prediction error at timestep 695 is 0.012
Current timestep = 696. State = [[-0.17334923  0.27525198]]. Action = [[-0.00170132  0.05154433  0.         -0.12882173]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 696 is [True, False, False, False, False, True]
State prediction error at timestep 696 is 0.012
Current timestep = 697. State = [[-0.17404962  0.2779067 ]]. Action = [[-0.01753282  0.01963051  0.          0.9793967 ]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 697 is [True, False, False, False, False, True]
State prediction error at timestep 697 is 0.012
Current timestep = 698. State = [[-0.1773324   0.27977267]]. Action = [[-0.06120741  0.01466836  0.          0.10217381]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 698 is [True, False, False, False, False, True]
State prediction error at timestep 698 is 0.012
Current timestep = 699. State = [[-0.18267983  0.28060338]]. Action = [[-0.07940488 -0.0107099   0.          0.60022473]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 699 is [True, False, False, False, False, True]
State prediction error at timestep 699 is 0.012
Current timestep = 700. State = [[-0.189593    0.28128597]]. Action = [[-0.09785821 -0.00499603  0.         -0.9246324 ]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 700 is [True, False, False, False, False, True]
State prediction error at timestep 700 is 0.012
Current timestep = 701. State = [[-0.19695352  0.27899393]]. Action = [[-0.09209645 -0.07136656  0.         -0.1754458 ]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 701 is [True, False, False, False, False, True]
State prediction error at timestep 701 is 0.012
Current timestep = 702. State = [[-0.19674256  0.28136143]]. Action = [[0.08345472 0.07465472 0.         0.30291736]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 702 is [True, False, False, False, False, True]
State prediction error at timestep 702 is 0.012
Current timestep = 703. State = [[-0.19308196  0.2830843 ]]. Action = [[ 0.03723919 -0.0176481   0.         -0.7877661 ]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 703 is [True, False, False, False, False, True]
State prediction error at timestep 703 is 0.012
Current timestep = 704. State = [[-0.1949396   0.28146312]]. Action = [[-0.06697093 -0.03649393  0.         -0.1631676 ]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 704 is [True, False, False, False, False, True]
State prediction error at timestep 704 is 0.012
Current timestep = 705. State = [[-0.19432601  0.27775502]]. Action = [[ 0.04376713 -0.0624591   0.          0.67180943]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 705 is [True, False, False, False, False, True]
State prediction error at timestep 705 is 0.012
Current timestep = 706. State = [[-0.18955393  0.27218923]]. Action = [[ 0.06720173 -0.06997086  0.          0.08968353]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 706 is [True, False, False, False, False, True]
State prediction error at timestep 706 is 0.012
Current timestep = 707. State = [[-0.1912781   0.26711085]]. Action = [[-0.09227987 -0.04977893  0.          0.1369803 ]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 707 is [True, False, False, False, False, True]
State prediction error at timestep 707 is 0.012
Current timestep = 708. State = [[-0.1960203   0.26679838]]. Action = [[-0.05337816  0.03426244  0.         -0.5549263 ]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 708 is [True, False, False, False, False, True]
State prediction error at timestep 708 is 0.012
Current timestep = 709. State = [[-0.19761682  0.26247838]]. Action = [[ 0.00307916 -0.09325156  0.          0.81189466]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 709 is [True, False, False, False, False, True]
State prediction error at timestep 709 is 0.012
Current timestep = 710. State = [[-0.19973978  0.2553269 ]]. Action = [[-0.04367981 -0.07376806  0.         -0.3440084 ]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 710 is [True, False, False, False, False, True]
State prediction error at timestep 710 is 0.012
Current timestep = 711. State = [[-0.20020795  0.24795279]]. Action = [[ 0.01462279 -0.08083436  0.         -0.04511029]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 711 is [True, False, False, False, False, True]
State prediction error at timestep 711 is 0.012
Current timestep = 712. State = [[-0.19646733  0.2474911 ]]. Action = [[0.07666405 0.07467923 0.         0.33489728]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 712 is [True, False, False, False, False, True]
State prediction error at timestep 712 is 0.012
Current timestep = 713. State = [[-0.19838732  0.24905427]]. Action = [[-0.07389606  0.02351657  0.         -0.47716224]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 713 is [True, False, False, False, False, True]
State prediction error at timestep 713 is 0.012
Current timestep = 714. State = [[-0.20035237  0.24443921]]. Action = [[ 0.01956774 -0.08320484  0.         -0.07414454]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 714 is [True, False, False, False, False, True]
State prediction error at timestep 714 is 0.012
Current timestep = 715. State = [[-0.20293804  0.23991075]]. Action = [[-0.04545664 -0.01749237  0.          0.02751064]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 715 is [True, False, False, False, False, True]
State prediction error at timestep 715 is 0.012
Current timestep = 716. State = [[-0.20651396  0.2415171 ]]. Action = [[-0.0273395   0.06836902  0.          0.3334744 ]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 716 is [True, False, False, False, False, True]
State prediction error at timestep 716 is 0.012
Current timestep = 717. State = [[-0.21056533  0.2392832 ]]. Action = [[-0.04084251 -0.06687041  0.          0.08878958]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 717 is [True, False, False, False, False, True]
State prediction error at timestep 717 is 0.012
Current timestep = 718. State = [[-0.21107389  0.23506904]]. Action = [[ 0.03423097 -0.03215975  0.          0.04506803]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 718 is [True, False, False, False, False, True]
State prediction error at timestep 718 is 0.012
Current timestep = 719. State = [[-0.20949607  0.23533008]]. Action = [[0.03599738 0.04701794 0.         0.84846234]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 719 is [True, False, False, False, False, True]
State prediction error at timestep 719 is 0.012
Current timestep = 720. State = [[-0.20747596  0.2372345 ]]. Action = [[ 0.04528933  0.03282707  0.         -0.18432838]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 720 is [True, False, False, False, False, True]
State prediction error at timestep 720 is 0.012
Current timestep = 721. State = [[-0.2026415   0.23395745]]. Action = [[ 0.09344276 -0.0664374   0.         -0.3738433 ]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 721 is [True, False, False, False, False, True]
State prediction error at timestep 721 is 0.012
Current timestep = 722. State = [[-0.19770403  0.22776195]]. Action = [[ 0.05374724 -0.06422956  0.         -0.09684998]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 722 is [True, False, False, False, False, True]
State prediction error at timestep 722 is 0.012
Current timestep = 723. State = [[-0.19114842  0.22286172]]. Action = [[ 0.09589332 -0.03247714  0.         -0.9610952 ]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 723 is [True, False, False, False, False, True]
State prediction error at timestep 723 is 0.012
Current timestep = 724. State = [[-0.18652208  0.22352107]]. Action = [[0.02752351 0.06490695 0.         0.9721887 ]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 724 is [True, False, False, False, False, True]
State prediction error at timestep 724 is 0.012
Current timestep = 725. State = [[-0.18761274  0.22245334]]. Action = [[-0.05867473 -0.03510105  0.          0.3132459 ]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 725 is [True, False, False, False, False, True]
State prediction error at timestep 725 is 0.012
Current timestep = 726. State = [[-0.18520524  0.22448692]]. Action = [[ 0.06737638  0.07668816  0.         -0.7576656 ]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 726 is [True, False, False, False, False, True]
State prediction error at timestep 726 is 0.012
Current timestep = 727. State = [[-0.17921546  0.2281151 ]]. Action = [[0.07252797 0.04423074 0.         0.20903766]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 727 is [True, False, False, False, False, True]
State prediction error at timestep 727 is 0.012
Current timestep = 728. State = [[-0.17848873  0.22593564]]. Action = [[-0.05104155 -0.06515346  0.         -0.22109938]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 728 is [True, False, False, False, False, True]
State prediction error at timestep 728 is 0.012
Current timestep = 729. State = [[-0.18326248  0.22386923]]. Action = [[-0.09767909 -0.00771218  0.          0.26353765]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 729 is [True, False, False, False, False, True]
State prediction error at timestep 729 is 0.012
Current timestep = 730. State = [[-0.18748587  0.2273309 ]]. Action = [[-0.04933175  0.066714    0.          0.07376039]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 730 is [True, False, False, False, False, True]
State prediction error at timestep 730 is 0.012
Current timestep = 731. State = [[-0.1915352   0.23364007]]. Action = [[-0.05474791  0.07256094  0.         -0.6693413 ]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 731 is [True, False, False, False, False, True]
State prediction error at timestep 731 is 0.012
Current timestep = 732. State = [[-0.19577207  0.23467796]]. Action = [[-0.050009   -0.04691753  0.         -0.23385882]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 732 is [True, False, False, False, False, True]
State prediction error at timestep 732 is 0.012
Current timestep = 733. State = [[-0.19321439  0.23512478]]. Action = [[0.09495976 0.01469727 0.         0.0703851 ]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 733 is [True, False, False, False, False, True]
State prediction error at timestep 733 is 0.012
Current timestep = 734. State = [[-0.18636756  0.23763415]]. Action = [[0.09816854 0.03344583 0.         0.63652277]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 734 is [True, False, False, False, False, True]
State prediction error at timestep 734 is 0.012
Current timestep = 735. State = [[-0.18407166  0.2356362 ]]. Action = [[-0.01384691 -0.0677177   0.         -0.25449574]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 735 is [True, False, False, False, False, True]
State prediction error at timestep 735 is 0.012
Current timestep = 736. State = [[-0.188165    0.23445846]]. Action = [[-0.08786596  0.00540759  0.          0.66461205]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 736 is [True, False, False, False, False, True]
State prediction error at timestep 736 is 0.012
Current timestep = 737. State = [[-0.18815675  0.23456341]]. Action = [[ 0.04611503 -0.00867917  0.         -0.8090815 ]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 737 is [True, False, False, False, False, True]
State prediction error at timestep 737 is 0.012
Current timestep = 738. State = [[-0.18812437  0.23020415]]. Action = [[-0.03278945 -0.08802291  0.         -0.8233887 ]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 738 is [True, False, False, False, False, True]
State prediction error at timestep 738 is 0.012
Current timestep = 739. State = [[-0.18644203  0.22973095]]. Action = [[ 0.04054555  0.04270545  0.         -0.4175024 ]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 739 is [True, False, False, False, False, True]
State prediction error at timestep 739 is 0.012
Current timestep = 740. State = [[-0.18038893  0.232643  ]]. Action = [[0.0997655  0.04433044 0.         0.7284478 ]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 740 is [True, False, False, False, False, True]
State prediction error at timestep 740 is 0.012
Current timestep = 741. State = [[-0.17887324  0.23028012]]. Action = [[-0.0362744  -0.0667589   0.         -0.42877495]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 741 is [True, False, False, False, False, True]
State prediction error at timestep 741 is 0.012
Current timestep = 742. State = [[-0.17868826  0.23127468]]. Action = [[ 0.01788559  0.06527161  0.         -0.30008316]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 742 is [True, False, False, False, False, True]
State prediction error at timestep 742 is 0.012
Current timestep = 743. State = [[-0.18272917  0.23140833]]. Action = [[-0.09505345 -0.03013795  0.         -0.3036222 ]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 743 is [True, False, False, False, False, True]
State prediction error at timestep 743 is 0.012
Current timestep = 744. State = [[-0.18815456  0.22962704]]. Action = [[-0.05945491 -0.02408413  0.          0.7404125 ]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 744 is [True, False, False, False, False, True]
State prediction error at timestep 744 is 0.012
Current timestep = 745. State = [[-0.1916256   0.22602534]]. Action = [[-0.03265084 -0.06120014  0.          0.08400738]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 745 is [True, False, False, False, False, True]
State prediction error at timestep 745 is 0.012
Current timestep = 746. State = [[-0.19401364  0.21949914]]. Action = [[-0.02743443 -0.09395974  0.          0.58146596]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 746 is [True, False, False, False, False, True]
State prediction error at timestep 746 is 0.012
Current timestep = 747. State = [[-0.19045429  0.21585645]]. Action = [[ 0.09577601 -0.00413854  0.         -0.2073139 ]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 747 is [True, False, False, False, False, True]
State prediction error at timestep 747 is 0.012
Current timestep = 748. State = [[-0.18625721  0.21803702]]. Action = [[0.03954966 0.07138895 0.         0.8553473 ]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 748 is [True, False, False, False, False, True]
State prediction error at timestep 748 is 0.012
Current timestep = 749. State = [[-0.18735477  0.21662267]]. Action = [[-0.04362353 -0.0516749   0.         -0.15699548]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 749 is [True, False, False, False, False, True]
State prediction error at timestep 749 is 0.012
Current timestep = 750. State = [[-0.18937466  0.21222305]]. Action = [[-0.01776645 -0.04611916  0.         -0.72059715]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 750 is [True, False, False, False, False, True]
State prediction error at timestep 750 is 0.012
Current timestep = 751. State = [[-0.18887085  0.21060573]]. Action = [[ 0.02259632  0.01253571  0.         -0.27660632]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 751 is [True, False, False, False, False, True]
State prediction error at timestep 751 is 0.012
Current timestep = 752. State = [[-0.18896085  0.21007489]]. Action = [[-0.00994236  0.0007353   0.          0.43566608]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 752 is [True, False, False, False, False, True]
State prediction error at timestep 752 is 0.012
Current timestep = 753. State = [[-0.19235358  0.20715596]]. Action = [[-0.06210102 -0.04646353  0.         -0.01682848]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 753 is [True, False, False, False, False, True]
State prediction error at timestep 753 is 0.012
Current timestep = 754. State = [[-0.19016562  0.20615746]]. Action = [[ 0.08916586  0.02082907  0.         -0.4560727 ]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 754 is [True, False, False, False, False, True]
State prediction error at timestep 754 is 0.012
Current timestep = 755. State = [[-0.1864551   0.20984909]]. Action = [[0.03245159 0.0794354  0.         0.46081185]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 755 is [True, False, False, False, False, True]
State prediction error at timestep 755 is 0.012
Current timestep = 756. State = [[-0.1877345  0.2124624]]. Action = [[-0.04210079  0.014102    0.         -0.8798099 ]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 756 is [True, False, False, False, False, True]
State prediction error at timestep 756 is 0.012
Current timestep = 757. State = [[-0.18760426  0.21251214]]. Action = [[ 0.02867126 -0.00846184  0.         -0.57500964]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 757 is [True, False, False, False, False, True]
State prediction error at timestep 757 is 0.012
Current timestep = 758. State = [[-0.18644871  0.21535377]]. Action = [[ 0.01301589  0.06184836  0.         -0.13088995]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 758 is [True, False, False, False, False, True]
State prediction error at timestep 758 is 0.012
Current timestep = 759. State = [[-0.18754342  0.21428536]]. Action = [[-0.02689406 -0.06171781  0.         -0.41441768]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 759 is [True, False, False, False, False, True]
State prediction error at timestep 759 is 0.012
Current timestep = 760. State = [[-0.19195673  0.20877059]]. Action = [[-0.08373877 -0.08482928  0.         -0.47703707]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 760 is [True, False, False, False, False, True]
State prediction error at timestep 760 is 0.012
Current timestep = 761. State = [[-0.19275212  0.20666519]]. Action = [[0.02319938 0.00378259 0.         0.40574253]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 761 is [True, False, False, False, False, True]
State prediction error at timestep 761 is 0.012
Current timestep = 762. State = [[-0.1878498   0.20594664]]. Action = [[ 0.08613863 -0.0111784   0.          0.0889492 ]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 762 is [True, False, False, False, False, True]
State prediction error at timestep 762 is 0.012
Current timestep = 763. State = [[-0.18104817  0.20923148]]. Action = [[0.09175815 0.08290429 0.         0.16887808]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 763 is [True, False, False, False, False, True]
State prediction error at timestep 763 is 0.012
Current timestep = 764. State = [[-0.17429799  0.20841086]]. Action = [[ 0.08441784 -0.05277661  0.          0.35092437]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 764 is [True, False, False, False, False, True]
State prediction error at timestep 764 is 0.012
Current timestep = 765. State = [[-0.16635738  0.2017206 ]]. Action = [[ 0.09889483 -0.09109934  0.         -0.9062925 ]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 765 is [True, False, False, False, False, True]
State prediction error at timestep 765 is 0.012
Current timestep = 766. State = [[-0.16360603  0.19765958]]. Action = [[-0.03031645 -0.00757559  0.         -0.3386684 ]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 766 is [True, False, False, False, False, True]
State prediction error at timestep 766 is 0.012
Current timestep = 767. State = [[-0.15878822  0.19693168]]. Action = [[0.08742791 0.01329206 0.         0.3423338 ]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 767 is [True, False, False, False, False, True]
State prediction error at timestep 767 is 0.012
Current timestep = 768. State = [[-0.15890259  0.19937173]]. Action = [[-0.08349542  0.06050854  0.         -0.71676725]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 768 is [True, False, False, False, False, True]
State prediction error at timestep 768 is 0.012
Current timestep = 769. State = [[-0.16460735  0.20314023]]. Action = [[-0.09485385  0.04565816  0.          0.00723088]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 769 is [True, False, False, False, False, True]
State prediction error at timestep 769 is 0.012
Current timestep = 770. State = [[-0.17120658  0.20416152]]. Action = [[-0.09464572 -0.01559724  0.          0.98291266]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 770 is [True, False, False, False, False, True]
State prediction error at timestep 770 is 0.012
Current timestep = 771. State = [[-0.17006153  0.20310573]]. Action = [[ 0.08209168 -0.02330686  0.         -0.04953921]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 771 is [True, False, False, False, False, True]
State prediction error at timestep 771 is 0.012
Current timestep = 772. State = [[-0.16473056  0.20620924]]. Action = [[ 0.06039479  0.07174834  0.         -0.8955244 ]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 772 is [True, False, False, False, False, True]
State prediction error at timestep 772 is 0.012
Current timestep = 773. State = [[-0.16403748  0.20477608]]. Action = [[-0.03073711 -0.07670204  0.         -0.0803296 ]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 773 is [True, False, False, False, False, True]
State prediction error at timestep 773 is 0.012
Current timestep = 774. State = [[-0.16058895  0.20548297]]. Action = [[0.07833286 0.05247349 0.         0.6510874 ]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 774 is [True, False, False, False, False, True]
State prediction error at timestep 774 is 0.012
Current timestep = 775. State = [[-0.15849473  0.20958474]]. Action = [[-0.0064294   0.05095788  0.          0.5468526 ]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 775 is [True, False, False, False, False, True]
State prediction error at timestep 775 is 0.012
Current timestep = 776. State = [[-0.15610325  0.21520437]]. Action = [[ 0.04780822  0.07364369  0.         -0.09134418]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 776 is [True, False, False, False, False, True]
State prediction error at timestep 776 is 0.012
Current timestep = 777. State = [[-0.1573033   0.21970811]]. Action = [[-0.05271511  0.03255347  0.          0.31260288]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 777 is [True, False, False, False, False, True]
State prediction error at timestep 777 is 0.012
Current timestep = 778. State = [[-0.15423827  0.21875802]]. Action = [[ 0.09098675 -0.05786715  0.          0.64170885]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 778 is [True, False, False, False, False, True]
State prediction error at timestep 778 is 0.012
Current timestep = 779. State = [[-0.15306748  0.21588784]]. Action = [[-0.0404515 -0.0381982  0.        -0.8567645]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 779 is [True, False, False, False, False, True]
State prediction error at timestep 779 is 0.012
Current timestep = 780. State = [[-0.15178584  0.2112455 ]]. Action = [[ 0.02826687 -0.07978947  0.          0.29480922]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 780 is [True, False, False, False, False, True]
State prediction error at timestep 780 is 0.012
Current timestep = 781. State = [[-0.15286146  0.20969102]]. Action = [[-0.05909122  0.01270431  0.         -0.4156394 ]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 781 is [True, False, False, False, False, True]
State prediction error at timestep 781 is 0.012
Current timestep = 782. State = [[-0.1556699   0.21108419]]. Action = [[-0.04438443  0.01810564  0.          0.1762631 ]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 782 is [True, False, False, False, False, True]
State prediction error at timestep 782 is 0.012
Current timestep = 783. State = [[-0.15850547  0.21683843]]. Action = [[-0.04042704  0.09732001  0.         -0.01336288]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 783 is [True, False, False, False, False, True]
State prediction error at timestep 783 is 0.012
Current timestep = 784. State = [[-0.16373369  0.2250853 ]]. Action = [[-0.07758362  0.09354185  0.         -0.8942189 ]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 784 is [True, False, False, False, False, True]
State prediction error at timestep 784 is 0.012
Current timestep = 785. State = [[-0.16831614  0.23339064]]. Action = [[-0.03111388  0.08416905  0.         -0.22903812]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 785 is [True, False, False, False, False, True]
State prediction error at timestep 785 is 0.012
Current timestep = 786. State = [[-0.17002232  0.2406769 ]]. Action = [[ 0.01375966  0.0640104   0.         -0.55082744]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 786 is [True, False, False, False, False, True]
State prediction error at timestep 786 is 0.012
Current timestep = 787. State = [[-0.17111367  0.24230427]]. Action = [[ 0.00127302 -0.03892101  0.          0.04489005]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 787 is [True, False, False, False, False, True]
State prediction error at timestep 787 is 0.012
Current timestep = 788. State = [[-0.17003141  0.23949826]]. Action = [[ 0.0428882  -0.0631846   0.          0.23667431]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 788 is [True, False, False, False, False, True]
State prediction error at timestep 788 is 0.012
Current timestep = 789. State = [[-0.1679006   0.23799682]]. Action = [[ 0.03391647 -0.00922661  0.         -0.35315073]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 789 is [True, False, False, False, False, True]
State prediction error at timestep 789 is 0.012
Current timestep = 790. State = [[-0.16386658  0.2359271 ]]. Action = [[ 0.07092898 -0.0421159   0.         -0.5083091 ]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 790 is [True, False, False, False, False, True]
State prediction error at timestep 790 is 0.012
Current timestep = 791. State = [[-0.16549537  0.2333144 ]]. Action = [[-0.08103445 -0.03079488  0.         -0.17037821]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 791 is [True, False, False, False, False, True]
State prediction error at timestep 791 is 0.012
Current timestep = 792. State = [[-0.17101859  0.23424071]]. Action = [[-0.071275    0.03380396  0.         -0.2509128 ]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 792 is [True, False, False, False, False, True]
State prediction error at timestep 792 is 0.012
Current timestep = 793. State = [[-0.17701723  0.23179908]]. Action = [[-0.07818829 -0.07419064  0.         -0.45124555]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 793 is [True, False, False, False, False, True]
State prediction error at timestep 793 is 0.012
Current timestep = 794. State = [[-0.18205963  0.2325039 ]]. Action = [[-0.05157137  0.05190139  0.          0.83721507]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 794 is [True, False, False, False, False, True]
State prediction error at timestep 794 is 0.012
Current timestep = 795. State = [[-0.1851365   0.23228128]]. Action = [[-0.01654925 -0.03577612  0.          0.6436479 ]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 795 is [True, False, False, False, False, True]
State prediction error at timestep 795 is 0.012
Current timestep = 796. State = [[-0.18640776  0.23457381]]. Action = [[0.00435616 0.0657978  0.         0.34108114]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 796 is [True, False, False, False, False, True]
State prediction error at timestep 796 is 0.012
Current timestep = 797. State = [[-0.18848574  0.2343722 ]]. Action = [[-0.01961886 -0.04053861  0.          0.4180622 ]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 797 is [True, False, False, False, False, True]
State prediction error at timestep 797 is 0.012
Current timestep = 798. State = [[-0.18994437  0.23415649]]. Action = [[0.00348534 0.01959308 0.         0.9446156 ]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 798 is [True, False, False, False, False, True]
State prediction error at timestep 798 is 0.012
Current timestep = 799. State = [[-0.19561204  0.23756818]]. Action = [[-0.09237529  0.05989669  0.         -0.86301434]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 799 is [True, False, False, False, False, True]
State prediction error at timestep 799 is 0.012
Current timestep = 800. State = [[-0.2010294   0.23664999]]. Action = [[-0.0310057  -0.05955762  0.          0.42639923]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 800 is [True, False, False, False, False, True]
State prediction error at timestep 800 is 0.012
Current timestep = 801. State = [[-0.20185797  0.23141325]]. Action = [[ 0.02631459 -0.07459968  0.          0.64242697]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 801 is [True, False, False, False, False, True]
State prediction error at timestep 801 is 0.012
Current timestep = 802. State = [[-0.20165992  0.23263901]]. Action = [[ 0.01307043  0.07752425  0.         -0.45114148]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 802 is [True, False, False, False, False, True]
State prediction error at timestep 802 is 0.012
Current timestep = 803. State = [[-0.20350498  0.23290999]]. Action = [[-0.02002709 -0.03140248  0.         -0.79141146]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 803 is [True, False, False, False, False, True]
State prediction error at timestep 803 is 0.012
Current timestep = 804. State = [[-0.20113301  0.23613515]]. Action = [[ 0.08673374  0.08854715  0.         -0.23511785]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 804 is [True, False, False, False, False, True]
State prediction error at timestep 804 is 0.012
Current timestep = 805. State = [[-0.19697185  0.24221006]]. Action = [[ 0.06524015  0.08235817  0.         -0.8650296 ]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 805 is [True, False, False, False, False, True]
State prediction error at timestep 805 is 0.012
Current timestep = 806. State = [[-0.19794682  0.24749157]]. Action = [[-0.03645007  0.05970483  0.         -0.29706693]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 806 is [True, False, False, False, False, True]
State prediction error at timestep 806 is 0.012
Current timestep = 807. State = [[-0.1998765   0.25240692]]. Action = [[0.00191204 0.0552044  0.         0.85993576]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 807 is [True, False, False, False, False, True]
State prediction error at timestep 807 is 0.012
Current timestep = 808. State = [[-0.20116277  0.2527953 ]]. Action = [[-0.00838102 -0.04010493  0.         -0.8830146 ]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 808 is [True, False, False, False, False, True]
State prediction error at timestep 808 is 0.012
Current timestep = 809. State = [[-0.19949856  0.25534672]]. Action = [[0.04964977 0.05710419 0.         0.22307944]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 809 is [True, False, False, False, False, True]
State prediction error at timestep 809 is 0.012
Current timestep = 810. State = [[-0.2027992   0.25583375]]. Action = [[-0.0951198  -0.04268194  0.          0.1658225 ]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 810 is [True, False, False, False, False, True]
State prediction error at timestep 810 is 0.012
Current timestep = 811. State = [[-0.21032938  0.25556678]]. Action = [[-0.09847884 -0.00873587  0.         -0.58889747]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 811 is [True, False, False, False, False, True]
State prediction error at timestep 811 is 0.012
Current timestep = 812. State = [[-0.2109113   0.25423494]]. Action = [[ 0.05778228 -0.04292473  0.          0.5534167 ]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 812 is [True, False, False, False, False, True]
State prediction error at timestep 812 is 0.012
Current timestep = 813. State = [[-0.21257523  0.2544676 ]]. Action = [[-0.06169579  0.01521252  0.          0.14616466]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 813 is [True, False, False, False, False, True]
State prediction error at timestep 813 is 0.012
Current timestep = 814. State = [[-0.21160042  0.25239462]]. Action = [[ 0.05525187 -0.06137919  0.          0.6213716 ]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 814 is [True, False, False, False, False, True]
State prediction error at timestep 814 is 0.012
Current timestep = 815. State = [[-0.21392992  0.25474104]]. Action = [[-0.07648259  0.07835027  0.         -0.9107446 ]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 815 is [True, False, False, False, False, True]
State prediction error at timestep 815 is 0.012
Current timestep = 816. State = [[-0.21493411  0.26102304]]. Action = [[0.0331305  0.07516041 0.         0.3436234 ]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 816 is [True, False, False, False, False, True]
State prediction error at timestep 816 is 0.012
Current timestep = 817. State = [[-0.21547961  0.26406205]]. Action = [[-0.01224626  0.00717163  0.          0.6208749 ]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 817 is [True, False, False, False, False, True]
State prediction error at timestep 817 is 0.012
Current timestep = 818. State = [[-0.21947591  0.26808497]]. Action = [[-0.06181024  0.06185397  0.         -0.02620709]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 818 is [True, False, False, False, False, True]
State prediction error at timestep 818 is 0.012
Current timestep = 819. State = [[-0.2252309  0.2740009]]. Action = [[-0.06230352  0.06351162  0.         -0.5510592 ]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 819 is [True, False, False, False, False, True]
State prediction error at timestep 819 is 0.012
Current timestep = 820. State = [[-0.22618577  0.27503008]]. Action = [[ 0.0415346  -0.04034868  0.          0.20208788]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 820 is [True, False, False, False, False, True]
State prediction error at timestep 820 is 0.012
Current timestep = 821. State = [[-0.2247956   0.27796367]]. Action = [[ 0.02876069  0.06459723  0.         -0.1201269 ]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 821 is [True, False, False, False, False, True]
State prediction error at timestep 821 is 0.012
Current timestep = 822. State = [[-0.2250992   0.27981147]]. Action = [[-0.00275913 -0.01392561  0.          0.35883915]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 822 is [True, False, False, False, False, True]
State prediction error at timestep 822 is 0.012
Current timestep = 823. State = [[-0.22554919  0.28108102]]. Action = [[0.00610732 0.01621568 0.         0.2921095 ]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 823 is [True, False, False, False, False, True]
State prediction error at timestep 823 is 0.012
Current timestep = 824. State = [[-0.22153063  0.28621244]]. Action = [[ 0.09555947  0.08454406  0.         -0.63137627]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 824 is [True, False, False, False, False, True]
State prediction error at timestep 824 is 0.012
Current timestep = 825. State = [[-0.22340915  0.29068518]]. Action = [[-0.08850329  0.02734628  0.         -0.5202895 ]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 825 is [True, False, False, False, False, True]
State prediction error at timestep 825 is 0.012
Current timestep = 826. State = [[-0.22516498  0.29415917]]. Action = [[ 0.03319474  0.03669318  0.         -0.20287979]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 826 is [True, False, False, False, False, True]
State prediction error at timestep 826 is 0.012
Current timestep = 827. State = [[-0.22549248  0.2941978 ]]. Action = [[-0.0043386  -0.03547197  0.          0.21912348]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 827 is [True, False, False, False, False, True]
State prediction error at timestep 827 is 0.012
Current timestep = 828. State = [[-0.22686729  0.2974133 ]]. Action = [[-0.0134307   0.06923728  0.          0.42798185]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 828 is [True, False, False, False, False, True]
State prediction error at timestep 828 is 0.012
Current timestep = 829. State = [[-0.22300217  0.2961978 ]]. Action = [[ 0.09789347 -0.07627241  0.         -0.56486595]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 829 is [True, False, False, False, False, True]
State prediction error at timestep 829 is 0.012
Current timestep = 830. State = [[-0.21712881  0.29498813]]. Action = [[0.06310018 0.01439534 0.         0.6298704 ]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 830 is [True, False, False, False, False, True]
State prediction error at timestep 830 is 0.012
Current timestep = 831. State = [[-0.21511701  0.29691994]]. Action = [[-0.00596305  0.03171647  0.         -0.93713677]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 831 is [True, False, False, False, False, True]
State prediction error at timestep 831 is 0.012
Current timestep = 832. State = [[-0.21147326  0.29397124]]. Action = [[ 0.06129994 -0.08188109  0.          0.6372268 ]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 832 is [True, False, False, False, False, True]
State prediction error at timestep 832 is 0.012
Current timestep = 833. State = [[-0.20670709  0.28994504]]. Action = [[ 0.03703453 -0.03269438  0.         -0.84256804]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 833 is [True, False, False, False, False, True]
State prediction error at timestep 833 is 0.012
Current timestep = 834. State = [[-0.20592846  0.2898159 ]]. Action = [[-0.0366334   0.02324779  0.          0.645414  ]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 834 is [True, False, False, False, False, True]
State prediction error at timestep 834 is 0.012
Current timestep = 835. State = [[-0.203448    0.29303724]]. Action = [[0.0458475  0.05581217 0.         0.7376232 ]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 835 is [True, False, False, False, False, True]
State prediction error at timestep 835 is 0.012
Current timestep = 836. State = [[-0.20127906  0.295484  ]]. Action = [[-1.2346357e-04  2.0283543e-02  0.0000000e+00  5.3654909e-01]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 836 is [True, False, False, False, False, True]
State prediction error at timestep 836 is 0.012
Current timestep = 837. State = [[-0.19716668  0.29843882]]. Action = [[ 0.06566533  0.04771147  0.         -0.13291478]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 837 is [True, False, False, False, False, True]
State prediction error at timestep 837 is 0.012
Current timestep = 838. State = [[-0.19082339  0.29969186]]. Action = [[0.07623284 0.00031461 0.         0.18038046]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 838 is [True, False, False, False, False, True]
State prediction error at timestep 838 is 0.012
Current timestep = 839. State = [[-0.18332313  0.3029597 ]]. Action = [[0.08962833 0.069745   0.         0.0684495 ]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 839 is [True, False, False, False, False, True]
State prediction error at timestep 839 is 0.012
Current timestep = 840. State = [[-0.18234363  0.30255422]]. Action = [[-0.06563804 -0.05295813  0.         -0.08991122]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 840 is [True, False, False, False, False, True]
State prediction error at timestep 840 is 0.012
Current timestep = 841. State = [[-0.18502645  0.3006153 ]]. Action = [[-0.04095739 -0.02058496  0.          0.6408386 ]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 841 is [True, False, False, False, False, True]
State prediction error at timestep 841 is 0.012
Current timestep = 842. State = [[-0.18683377  0.29744044]]. Action = [[-0.03072355 -0.06254348  0.          0.15673113]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 842 is [True, False, False, False, False, True]
State prediction error at timestep 842 is 0.012
Current timestep = 843. State = [[-0.18408144  0.29194388]]. Action = [[ 0.05418298 -0.08067755  0.         -0.43133378]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 843 is [True, False, False, False, False, True]
State prediction error at timestep 843 is 0.012
Current timestep = 844. State = [[-0.1766925   0.28418052]]. Action = [[ 0.09743606 -0.09903786  0.         -0.84396744]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 844 is [True, False, False, False, False, True]
State prediction error at timestep 844 is 0.012
Current timestep = 845. State = [[-0.17084086  0.28092265]]. Action = [[ 0.03497571  0.0171715   0.         -0.6419293 ]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 845 is [True, False, False, False, False, True]
State prediction error at timestep 845 is 0.012
Current timestep = 846. State = [[-0.16436848  0.27950048]]. Action = [[ 0.08368819 -0.00747488  0.          0.9522784 ]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 846 is [True, False, False, False, False, True]
State prediction error at timestep 846 is 0.012
Current timestep = 847. State = [[-0.15948921  0.28026718]]. Action = [[0.02626482 0.0515176  0.         0.37349308]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 847 is [True, False, False, False, False, True]
State prediction error at timestep 847 is 0.012
Current timestep = 848. State = [[-0.15926234  0.27994815]]. Action = [[-0.03699075 -0.01112098  0.         -0.90853995]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 848 is [True, False, False, False, False, True]
State prediction error at timestep 848 is 0.012
Current timestep = 849. State = [[-0.16277152  0.27665538]]. Action = [[-0.08058725 -0.04895262  0.          0.23734021]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 849 is [True, False, False, False, False, True]
State prediction error at timestep 849 is 0.012
Current timestep = 850. State = [[-0.16699366  0.2798704 ]]. Action = [[-0.06187503  0.09743608  0.         -0.9838493 ]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 850 is [True, False, False, False, False, True]
State prediction error at timestep 850 is 0.012
Current timestep = 851. State = [[-0.17194405  0.2842259 ]]. Action = [[-0.06701927  0.02729433  0.          0.50647426]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 851 is [True, False, False, False, False, True]
State prediction error at timestep 851 is 0.012
Current timestep = 852. State = [[-0.17246465  0.28606436]]. Action = [[ 0.03594214  0.00758737  0.         -0.568202  ]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 852 is [True, False, False, False, False, True]
State prediction error at timestep 852 is 0.012
Current timestep = 853. State = [[-0.17298958  0.28855938]]. Action = [[-0.01714475  0.03579705  0.          0.87571764]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 853 is [True, False, False, False, False, True]
State prediction error at timestep 853 is 0.012
Current timestep = 854. State = [[-0.17286807  0.2917198 ]]. Action = [[ 0.02747444  0.03136539  0.         -0.13461995]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 854 is [True, False, False, False, False, True]
State prediction error at timestep 854 is 0.012
Current timestep = 855. State = [[-0.17180152  0.2939337 ]]. Action = [[0.02528293 0.01547952 0.         0.35942578]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 855 is [True, False, False, False, False, True]
State prediction error at timestep 855 is 0.012
Current timestep = 856. State = [[-0.17024636  0.29723936]]. Action = [[0.03427506 0.04789763 0.         0.5365486 ]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 856 is [True, False, False, False, False, True]
State prediction error at timestep 856 is 0.012
Current timestep = 857. State = [[-0.16663212  0.30186567]]. Action = [[0.07210352 0.05834232 0.         0.21490633]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 857 is [True, False, False, False, False, True]
State prediction error at timestep 857 is 0.012
Current timestep = 858. State = [[-0.16744918  0.30274487]]. Action = [[-0.05137458 -0.02878148  0.          0.82392335]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 858 is [True, False, False, False, False, True]
State prediction error at timestep 858 is 0.012
Current timestep = 859. State = [[-0.17113131  0.30455387]]. Action = [[-0.03935675  0.03478643  0.          0.81637096]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 859 is [True, False, False, False, False, True]
State prediction error at timestep 859 is 0.012
Current timestep = 860. State = [[-0.17342913  0.30598778]]. Action = [[-0.01270922 -0.0092575   0.          0.23814678]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 860 is [True, False, False, False, False, True]
State prediction error at timestep 860 is 0.012
Current timestep = 861. State = [[-0.1774112   0.30697033]]. Action = [[-0.06593549  0.00363239  0.         -0.3307966 ]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 861 is [True, False, False, False, False, True]
State prediction error at timestep 861 is 0.012
Current timestep = 862. State = [[-0.18188381  0.31233764]]. Action = [[-0.04328059  0.08309162  0.          0.8063748 ]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 862 is [True, False, False, False, False, True]
State prediction error at timestep 862 is 0.012
Current timestep = 863. State = [[-0.18888003  0.3188498 ]]. Action = [[-0.09652586  0.05571672  0.         -0.71435916]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 863 is [True, False, False, False, False, True]
State prediction error at timestep 863 is 0.012
Current timestep = 864. State = [[-0.19020738  0.3194419 ]]. Action = [[ 0.05222832 -0.05329921  0.          0.85693955]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 864 is [True, False, False, False, False, True]
State prediction error at timestep 864 is 0.012
Current timestep = 865. State = [[-0.1932292   0.32132703]]. Action = [[-0.06917726  0.04367628  0.         -0.52012765]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 865 is [True, False, False, False, False, True]
State prediction error at timestep 865 is 0.012
Current timestep = 866. State = [[-0.199001    0.32555026]]. Action = [[-0.05696666  0.03379955  0.          0.5667535 ]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 866 is [True, False, False, False, False, True]
State prediction error at timestep 866 is 0.012
Current timestep = 867. State = [[-0.19742939  0.32483312]]. Action = [[ 0.09219135 -0.05805593  0.          0.3958149 ]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 867 is [True, False, False, False, False, True]
State prediction error at timestep 867 is 0.012
Current timestep = 868. State = [[-0.19733794  0.32514974]]. Action = [[-0.03124291  0.0283972   0.         -0.32739675]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 868 is [True, False, False, False, False, True]
State prediction error at timestep 868 is 0.012
Current timestep = 869. State = [[-0.19588405  0.33079818]]. Action = [[0.06472602 0.09197838 0.         0.41242588]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 869 is [True, False, False, False, False, True]
State prediction error at timestep 869 is 0.012
Current timestep = 870. State = [[-0.19561031  0.32928273]]. Action = [[-0.02139685 -0.09331255  0.          0.21802056]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 870 is [True, False, False, False, False, True]
State prediction error at timestep 870 is 0.012
Current timestep = 871. State = [[-0.19646852  0.326904  ]]. Action = [[ 1.8365681e-04 -3.1995103e-03  0.0000000e+00  6.5077376e-01]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 871 is [True, False, False, False, False, True]
State prediction error at timestep 871 is 0.012
Current timestep = 872. State = [[-0.19613363  0.32813272]]. Action = [[0.0156481  0.02888759 0.         0.6373844 ]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 872 is [True, False, False, False, False, True]
State prediction error at timestep 872 is 0.012
Current timestep = 873. State = [[-0.1950432   0.33228394]]. Action = [[ 0.02411852  0.07074206  0.         -0.96167463]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 873 is [True, False, False, False, False, True]
State prediction error at timestep 873 is 0.012
Current timestep = 874. State = [[-0.19051546  0.33628467]]. Action = [[0.09080487 0.04582456 0.         0.30074644]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 874 is [True, False, False, False, False, True]
State prediction error at timestep 874 is 0.012
Current timestep = 875. State = [[-0.18906572  0.33402154]]. Action = [[-0.02477155 -0.0719272   0.          0.6413734 ]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 875 is [True, False, False, False, False, True]
State prediction error at timestep 875 is 0.012
Current timestep = 876. State = [[-0.18540125  0.33194977]]. Action = [[ 0.08695766  0.00340705  0.         -0.9982169 ]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 876 is [True, False, False, False, False, True]
State prediction error at timestep 876 is 0.012
Current timestep = 877. State = [[-0.18657337  0.3336992 ]]. Action = [[-0.08156133  0.04030191  0.          0.81873894]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 877 is [True, False, False, False, False, True]
State prediction error at timestep 877 is 0.012
Current timestep = 878. State = [[-0.19035165  0.33427075]]. Action = [[-0.03815    -0.01683912  0.         -0.23263693]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 878 is [True, False, False, False, False, True]
State prediction error at timestep 878 is 0.012
Current timestep = 879. State = [[-0.19002698  0.33329   ]]. Action = [[ 0.0270442  -0.01787385  0.          0.17300022]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 879 is [True, False, False, False, False, True]
State prediction error at timestep 879 is 0.012
Current timestep = 880. State = [[-0.18634142  0.3317367 ]]. Action = [[ 0.05652063 -0.0201425   0.         -0.38552034]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 880 is [True, False, False, False, False, True]
State prediction error at timestep 880 is 0.012
Current timestep = 881. State = [[-0.18846343  0.3316975 ]]. Action = [[-0.08591688  0.01171925  0.         -0.30482107]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 881 is [True, False, False, False, False, True]
State prediction error at timestep 881 is 0.012
Current timestep = 882. State = [[-0.18874714  0.33310714]]. Action = [[0.03914043 0.01896606 0.         0.07608569]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 882 is [True, False, False, False, False, True]
State prediction error at timestep 882 is 0.012
Current timestep = 883. State = [[-0.19228695  0.33734897]]. Action = [[-0.09166531  0.07043836  0.         -0.03199273]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 883 is [True, False, False, False, False, True]
State prediction error at timestep 883 is 0.012
Current timestep = 884. State = [[-0.1905108   0.33580637]]. Action = [[ 0.09288027 -0.08233316  0.          0.5820422 ]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 884 is [True, False, False, False, False, True]
State prediction error at timestep 884 is 0.012
Current timestep = 885. State = [[-0.18377815  0.3347826 ]]. Action = [[ 0.0878885   0.02983522  0.         -0.7006631 ]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 885 is [True, False, False, False, False, True]
State prediction error at timestep 885 is 0.012
Current timestep = 886. State = [[-0.18112977  0.3337413 ]]. Action = [[-0.00411619 -0.0275893   0.         -0.12688214]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 886 is [True, False, False, False, False, True]
State prediction error at timestep 886 is 0.012
Current timestep = 887. State = [[-0.18016325  0.33046743]]. Action = [[ 0.00847441 -0.04633982  0.          0.7721385 ]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 887 is [True, False, False, False, False, True]
State prediction error at timestep 887 is 0.012
Current timestep = 888. State = [[-0.17788988  0.32841223]]. Action = [[ 0.0268695  -0.00736762  0.          0.246279  ]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 888 is [True, False, False, False, False, True]
State prediction error at timestep 888 is 0.012
Current timestep = 889. State = [[-0.1725736  0.3273761]]. Action = [[ 0.07847475 -0.0023205   0.          0.06501865]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 889 is [True, False, False, False, False, True]
State prediction error at timestep 889 is 0.012
Current timestep = 890. State = [[-0.1726125   0.32779855]]. Action = [[-0.06440885  0.02336283  0.          0.20854795]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 890 is [True, False, False, False, False, True]
State prediction error at timestep 890 is 0.012
Current timestep = 891. State = [[-0.170418    0.33055735]]. Action = [[0.07114594 0.05211455 0.         0.72177327]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 891 is [True, False, False, False, False, True]
State prediction error at timestep 891 is 0.012
Current timestep = 892. State = [[-0.16692844  0.332453  ]]. Action = [[ 0.02346541  0.01724808  0.         -0.26254362]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 892 is [True, False, False, False, False, True]
State prediction error at timestep 892 is 0.012
Current timestep = 893. State = [[-0.16452062  0.3315153 ]]. Action = [[ 0.02072918 -0.02557365  0.          0.60408294]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 893 is [True, False, False, False, False, True]
State prediction error at timestep 893 is 0.012
Current timestep = 894. State = [[-0.16371188  0.333404  ]]. Action = [[-0.01080244  0.05403348  0.          0.23601127]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 894 is [True, False, False, False, False, True]
State prediction error at timestep 894 is 0.012
Current timestep = 895. State = [[-0.1645736   0.33584192]]. Action = [[-0.02265695  0.01391633  0.         -0.7242096 ]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 895 is [True, False, False, False, False, True]
State prediction error at timestep 895 is 0.012
Current timestep = 896. State = [[-0.16779539  0.3351704 ]]. Action = [[-0.06514917 -0.03705639  0.         -0.66519666]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 896 is [True, False, False, False, False, True]
State prediction error at timestep 896 is 0.012
Current timestep = 897. State = [[-0.17293566  0.3379517 ]]. Action = [[-0.0784089   0.05580121  0.         -0.76408756]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 897 is [True, False, False, False, False, True]
State prediction error at timestep 897 is 0.012
Current timestep = 898. State = [[-0.1765883  0.3369169]]. Action = [[-0.03089613 -0.07806367  0.          0.647159  ]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 898 is [True, False, False, False, False, True]
State prediction error at timestep 898 is 0.012
Current timestep = 899. State = [[-0.18363312  0.23821309]]. Action = [[-0.09301739 -0.08689797  0.         -0.5352886 ]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 899 is [True, False, False, False, False, True]
State prediction error at timestep 899 is 0.012
Current timestep = 900. State = [[-0.1845085   0.23412536]]. Action = [[-0.08341965 -0.08956175  0.          0.42098212]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 900 is [True, False, False, False, False, True]
State prediction error at timestep 900 is 0.012
Current timestep = 901. State = [[-0.18421428  0.22733483]]. Action = [[ 0.03159811 -0.09614088  0.          0.41597986]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 901 is [True, False, False, False, False, True]
State prediction error at timestep 901 is 0.012
Current timestep = 902. State = [[-0.17811832  0.22719914]]. Action = [[ 0.09385409  0.06346265  0.         -0.73376685]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 902 is [True, False, False, False, False, True]
State prediction error at timestep 902 is 0.012
Current timestep = 903. State = [[-0.17823803  0.22934738]]. Action = [[-0.07935603  0.0167402   0.          0.57125115]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 903 is [True, False, False, False, False, True]
State prediction error at timestep 903 is 0.012
Current timestep = 904. State = [[-0.17643234  0.22658996]]. Action = [[ 0.07537896 -0.05933464  0.         -0.34267306]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 904 is [True, False, False, False, False, True]
State prediction error at timestep 904 is 0.012
Current timestep = 905. State = [[-0.17678738  0.22786975]]. Action = [[-0.05565983  0.07289916  0.          0.40900445]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 905 is [True, False, False, False, False, True]
State prediction error at timestep 905 is 0.012
Current timestep = 906. State = [[-0.18129931  0.23027407]]. Action = [[-0.0662068   0.01069977  0.         -0.8688945 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 906 is [True, False, False, False, False, True]
State prediction error at timestep 906 is 0.012
Current timestep = 907. State = [[-0.18702583  0.22888173]]. Action = [[-0.08059959 -0.04108346  0.          0.7860532 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 907 is [True, False, False, False, False, True]
State prediction error at timestep 907 is 0.012
Current timestep = 908. State = [[-0.18871197  0.23019281]]. Action = [[0.01806863 0.04568339 0.         0.87451863]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 908 is [True, False, False, False, False, True]
State prediction error at timestep 908 is 0.012
Current timestep = 909. State = [[-0.18404737  0.2286516 ]]. Action = [[ 0.09899142 -0.05589607  0.          0.2814293 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 909 is [True, False, False, False, False, True]
State prediction error at timestep 909 is 0.012
Current timestep = 910. State = [[-0.18447343  0.22802354]]. Action = [[-0.06328503  0.02443359  0.          0.6967299 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 910 is [True, False, False, False, False, True]
State prediction error at timestep 910 is 0.012
Current timestep = 911. State = [[-0.18207093  0.2271084 ]]. Action = [[ 0.09653551 -0.02532632  0.          0.25446916]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 911 is [True, False, False, False, False, True]
State prediction error at timestep 911 is 0.012
Current timestep = 912. State = [[-0.17545058  0.22601157]]. Action = [[0.08972823 0.00527827 0.         0.0655055 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 912 is [True, False, False, False, False, True]
State prediction error at timestep 912 is 0.012
Current timestep = 913. State = [[-0.16966483  0.22836903]]. Action = [[ 0.0677987   0.06183898  0.         -0.93427217]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 913 is [True, False, False, False, False, True]
State prediction error at timestep 913 is 0.012
Current timestep = 914. State = [[-0.16698639  0.22551373]]. Action = [[ 0.00903265 -0.08073846  0.         -0.5293332 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 914 is [True, False, False, False, False, True]
State prediction error at timestep 914 is 0.012
Current timestep = 915. State = [[-0.1620934   0.22582884]]. Action = [[0.08118217 0.06520467 0.         0.6361582 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 915 is [True, False, False, False, False, True]
State prediction error at timestep 915 is 0.012
Current timestep = 916. State = [[-0.15744765  0.22660361]]. Action = [[ 0.03548845 -0.00778349  0.          0.35799026]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 916 is [True, False, False, False, False, True]
State prediction error at timestep 916 is 0.012
Current timestep = 917. State = [[-0.1596603   0.22372596]]. Action = [[-0.09790182 -0.05136839  0.          0.50291705]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 917 is [True, False, False, False, False, True]
State prediction error at timestep 917 is 0.012
Current timestep = 918. State = [[-0.1625113   0.22680493]]. Action = [[-0.02586622  0.0898725   0.          0.2557869 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 918 is [True, False, False, False, False, True]
State prediction error at timestep 918 is 0.012
Current timestep = 919. State = [[-0.16475578  0.22911909]]. Action = [[-0.03693535 -0.01333588  0.         -0.7058575 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 919 is [True, False, False, False, False, True]
State prediction error at timestep 919 is 0.012
Current timestep = 920. State = [[-0.1680824   0.23076467]]. Action = [[-0.05469064  0.02418448  0.          0.5819497 ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 920 is [True, False, False, False, False, True]
State prediction error at timestep 920 is 0.012
Current timestep = 921. State = [[-0.16701008  0.2371119 ]]. Action = [[ 0.0597868   0.09788913  0.         -0.27533615]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 921 is [True, False, False, False, False, True]
State prediction error at timestep 921 is 0.012
Current timestep = 922. State = [[-0.16331793  0.23603201]]. Action = [[ 0.04750434 -0.09664341  0.         -0.7038536 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 922 is [True, False, False, False, False, True]
State prediction error at timestep 922 is 0.012
Current timestep = 923. State = [[-0.15847637  0.22979593]]. Action = [[ 0.06065626 -0.07862227  0.         -0.28851628]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 923 is [True, False, False, False, False, True]
State prediction error at timestep 923 is 0.012
Current timestep = 924. State = [[-0.15454589  0.22995709]]. Action = [[ 0.0300464   0.05586015  0.         -0.7354646 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 924 is [True, False, False, False, False, True]
State prediction error at timestep 924 is 0.012
Current timestep = 925. State = [[-0.1491673   0.23589079]]. Action = [[ 0.08316027  0.09315776  0.         -0.88165176]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 925 is [True, False, False, False, False, True]
State prediction error at timestep 925 is 0.012
Current timestep = 926. State = [[-0.1494821   0.24157523]]. Action = [[-0.06537471  0.05589854  0.          0.9782543 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 926 is [True, False, False, False, False, True]
State prediction error at timestep 926 is 0.012
Current timestep = 927. State = [[-0.15486617  0.24380963]]. Action = [[-0.07951075 -0.00536416  0.          0.484581  ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 927 is [True, False, False, False, False, True]
State prediction error at timestep 927 is 0.012
Current timestep = 928. State = [[-0.1585957   0.24530703]]. Action = [[-0.03264285  0.00968951  0.         -0.89557725]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 928 is [True, False, False, False, False, True]
State prediction error at timestep 928 is 0.012
Current timestep = 929. State = [[-0.16383503  0.24475725]]. Action = [[-0.08804687 -0.04126343  0.          0.3785901 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 929 is [True, False, False, False, False, True]
State prediction error at timestep 929 is 0.012
Current timestep = 930. State = [[-0.16978313  0.2461637 ]]. Action = [[-0.07188775  0.02567974  0.         -0.9348801 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 930 is [True, False, False, False, False, True]
State prediction error at timestep 930 is 0.012
Current timestep = 931. State = [[-0.17368244  0.2503059 ]]. Action = [[-0.02623191  0.04378626  0.          0.8469348 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 931 is [True, False, False, False, False, True]
State prediction error at timestep 931 is 0.012
Current timestep = 932. State = [[-0.17202245  0.24894165]]. Action = [[ 0.06884205 -0.07363455  0.         -0.48603934]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 932 is [True, False, False, False, False, True]
State prediction error at timestep 932 is 0.012
Current timestep = 933. State = [[-0.16888677  0.24671328]]. Action = [[ 0.04025096 -0.00834483  0.         -0.39977723]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 933 is [True, False, False, False, False, True]
State prediction error at timestep 933 is 0.012
Current timestep = 934. State = [[-0.1700446   0.24438702]]. Action = [[-0.04115825 -0.03977817  0.         -0.7556489 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 934 is [True, False, False, False, False, True]
State prediction error at timestep 934 is 0.012
Current timestep = 935. State = [[-0.17545798  0.2428437 ]]. Action = [[-0.08550342 -0.00930098  0.          0.51018786]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 935 is [True, False, False, False, False, True]
State prediction error at timestep 935 is 0.012
Current timestep = 936. State = [[-0.18050726  0.24601145]]. Action = [[-0.04422996  0.06685717  0.          0.68021655]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 936 is [True, False, False, False, False, True]
State prediction error at timestep 936 is 0.012
Current timestep = 937. State = [[-0.18329686  0.24759325]]. Action = [[-0.01000511 -0.01128369  0.          0.46054518]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 937 is [True, False, False, False, False, True]
State prediction error at timestep 937 is 0.012
Current timestep = 938. State = [[-0.18145503  0.24800879]]. Action = [[0.06727143 0.0131681  0.         0.906888  ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 938 is [True, False, False, False, False, True]
State prediction error at timestep 938 is 0.012
Current timestep = 939. State = [[-0.18128872  0.24699825]]. Action = [[-0.01332896 -0.02220585  0.         -0.11340064]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 939 is [True, False, False, False, False, True]
State prediction error at timestep 939 is 0.012
Current timestep = 940. State = [[-0.1831949   0.24716672]]. Action = [[-0.01680029  0.02067788  0.          0.80609727]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 940 is [True, False, False, False, False, True]
State prediction error at timestep 940 is 0.012
Current timestep = 941. State = [[-0.18709251  0.24326147]]. Action = [[-0.05739452 -0.08833259  0.         -0.46496332]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 941 is [True, False, False, False, False, True]
State prediction error at timestep 941 is 0.012
Current timestep = 942. State = [[-0.19047305  0.24478054]]. Action = [[-0.02508176  0.08452003  0.         -0.29688525]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 942 is [True, False, False, False, False, True]
State prediction error at timestep 942 is 0.012
Current timestep = 943. State = [[-0.1888922   0.25119638]]. Action = [[0.07462993 0.08427846 0.         0.7790005 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 943 is [True, False, False, False, False, True]
State prediction error at timestep 943 is 0.012
Current timestep = 944. State = [[-0.18531218  0.25421977]]. Action = [[0.06055851 0.01179151 0.         0.97877383]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 944 is [True, False, False, False, False, True]
State prediction error at timestep 944 is 0.012
Current timestep = 945. State = [[-0.18497193  0.25344095]]. Action = [[-0.01235661 -0.02439753  0.         -0.45056152]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 945 is [True, False, False, False, False, True]
State prediction error at timestep 945 is 0.012
Current timestep = 946. State = [[-0.18487996  0.2517916 ]]. Action = [[ 0.01561481 -0.02096728  0.          0.8735049 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 946 is [True, False, False, False, False, True]
State prediction error at timestep 946 is 0.012
Current timestep = 947. State = [[-0.18352836  0.2464605 ]]. Action = [[ 0.01918431 -0.09318873  0.         -0.3469535 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 947 is [True, False, False, False, False, True]
State prediction error at timestep 947 is 0.012
Current timestep = 948. State = [[-0.18041807  0.24428546]]. Action = [[ 0.04498086  0.01954328  0.         -0.02904272]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 948 is [True, False, False, False, False, True]
State prediction error at timestep 948 is 0.012
Current timestep = 949. State = [[-0.1811529   0.24581423]]. Action = [[-0.04869395  0.03177086  0.         -0.28634965]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 949 is [True, False, False, False, False, True]
State prediction error at timestep 949 is 0.012
Current timestep = 950. State = [[-0.180425    0.24706739]]. Action = [[ 0.03578683  0.01071352  0.         -0.7555905 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 950 is [True, False, False, False, False, True]
State prediction error at timestep 950 is 0.012
Current timestep = 951. State = [[-0.17542423  0.24977516]]. Action = [[0.08200314 0.05443198 0.         0.6757114 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 951 is [True, False, False, False, False, True]
State prediction error at timestep 951 is 0.012
Current timestep = 952. State = [[-0.17590296  0.24673335]]. Action = [[-0.07424372 -0.09158712  0.          0.6195617 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 952 is [True, False, False, False, False, True]
State prediction error at timestep 952 is 0.012
Current timestep = 953. State = [[-0.1810067   0.24437383]]. Action = [[-0.069371    0.00381778  0.         -0.21495974]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 953 is [True, False, False, False, False, True]
State prediction error at timestep 953 is 0.012
Current timestep = 954. State = [[-0.18287975  0.24870518]]. Action = [[0.01090918 0.08659453 0.         0.38285136]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 954 is [True, False, False, False, False, True]
State prediction error at timestep 954 is 0.012
Current timestep = 955. State = [[-0.18324396  0.25113204]]. Action = [[ 0.00254086 -0.00507199  0.         -0.7048568 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 955 is [True, False, False, False, False, True]
State prediction error at timestep 955 is 0.012
Current timestep = 956. State = [[-0.18216959  0.25120783]]. Action = [[ 0.03166268 -0.00197843  0.          0.51603174]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 956 is [True, False, False, False, False, True]
State prediction error at timestep 956 is 0.012
Current timestep = 957. State = [[-0.17833497  0.2559986 ]]. Action = [[0.07444104 0.09782951 0.         0.6951506 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 957 is [True, False, False, False, False, True]
State prediction error at timestep 957 is 0.012
Current timestep = 958. State = [[-0.17292775  0.25878406]]. Action = [[0.08405428 0.00096381 0.         0.50041604]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 958 is [True, False, False, False, False, True]
State prediction error at timestep 958 is 0.012
Current timestep = 959. State = [[-0.16763705  0.25771928]]. Action = [[ 0.06241379 -0.02273578  0.          0.04101753]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 959 is [True, False, False, False, False, True]
State prediction error at timestep 959 is 0.012
Current timestep = 960. State = [[-0.16144155  0.26090115]]. Action = [[ 0.08441157  0.0815258   0.         -0.523966  ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 960 is [True, False, False, False, False, True]
State prediction error at timestep 960 is 0.012
Current timestep = 961. State = [[-0.15775649  0.2670482 ]]. Action = [[ 0.0206154  0.079207   0.        -0.8064507]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 961 is [True, False, False, False, False, True]
State prediction error at timestep 961 is 0.012
Current timestep = 962. State = [[-0.15833148  0.26604244]]. Action = [[-0.04263875 -0.07917876  0.         -0.21784282]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 962 is [True, False, False, False, False, True]
State prediction error at timestep 962 is 0.012
Current timestep = 963. State = [[-0.1581846   0.26127297]]. Action = [[-0.00197476 -0.06882813  0.         -0.13169128]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 963 is [True, False, False, False, False, True]
State prediction error at timestep 963 is 0.012
Current timestep = 964. State = [[-0.15763566  0.26243454]]. Action = [[-0.01502205  0.05394488  0.          0.84701204]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 964 is [True, False, False, False, False, True]
State prediction error at timestep 964 is 0.012
Current timestep = 965. State = [[-0.15232381  0.26601505]]. Action = [[0.09899279 0.03348307 0.         0.96536326]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 965 is [True, False, False, False, False, True]
State prediction error at timestep 965 is 0.012
Current timestep = 966. State = [[-0.14517674  0.26910478]]. Action = [[0.07116457 0.03746688 0.         0.1969577 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 966 is [True, False, False, False, False, True]
State prediction error at timestep 966 is 0.012
Current timestep = 967. State = [[-0.13936116  0.26749256]]. Action = [[ 0.04990234 -0.05827497  0.          0.75828576]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 967 is [True, False, False, False, False, True]
State prediction error at timestep 967 is 0.012
Current timestep = 968. State = [[-0.1386086   0.26948762]]. Action = [[-0.04811747  0.06874769  0.          0.5653417 ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 968 is [True, False, False, False, False, True]
State prediction error at timestep 968 is 0.012
Current timestep = 969. State = [[-0.13370498  0.26958343]]. Action = [[ 0.09725779 -0.04575193  0.         -0.12988919]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 969 is [True, False, False, False, False, True]
State prediction error at timestep 969 is 0.012
Current timestep = 970. State = [[-0.13218583  0.26953003]]. Action = [[-0.06089608  0.0163299   0.         -0.80751985]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 970 is [True, False, False, False, False, True]
State prediction error at timestep 970 is 0.012
Current timestep = 971. State = [[-0.13300651  0.27335235]]. Action = [[-0.01447992  0.05521802  0.          0.8585055 ]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 971 is [True, False, False, False, False, True]
State prediction error at timestep 971 is 0.012
Current timestep = 972. State = [[-0.13183226  0.2802726 ]]. Action = [[ 0.01719111  0.08940654  0.         -0.01785398]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 972 is [True, False, False, False, False, True]
State prediction error at timestep 972 is 0.012
Current timestep = 973. State = [[-0.12791707  0.28481326]]. Action = [[ 0.0634846   0.01896201  0.         -0.5259989 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 973 is [True, False, False, False, False, True]
State prediction error at timestep 973 is 0.012
Current timestep = 974. State = [[-0.12506409  0.28817514]]. Action = [[0.01359548 0.03608038 0.         0.20189917]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 974 is [True, False, False, False, False, True]
State prediction error at timestep 974 is 0.012
Current timestep = 975. State = [[-0.12538792  0.28891078]]. Action = [[-0.02777552 -0.02939115  0.         -0.28144813]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 975 is [True, False, False, False, False, True]
State prediction error at timestep 975 is 0.012
Current timestep = 976. State = [[-0.12993297  0.289407  ]]. Action = [[-0.09690737 -0.00301504  0.          0.55649614]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 976 is [True, False, False, False, False, True]
State prediction error at timestep 976 is 0.012
Current timestep = 977. State = [[-0.13212904  0.2862942 ]]. Action = [[-0.01011229 -0.09242389  0.         -0.50125897]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 977 is [True, False, False, False, False, True]
State prediction error at timestep 977 is 0.012
Current timestep = 978. State = [[-0.12732361  0.28557083]]. Action = [[ 0.09578169  0.02359129  0.         -0.3578788 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 978 is [True, False, False, False, False, True]
State prediction error at timestep 978 is 0.012
Current timestep = 979. State = [[-0.11940631  0.2883033 ]]. Action = [[ 0.09676328  0.0420832   0.         -0.45464778]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 979 is [True, False, False, False, False, True]
State prediction error at timestep 979 is 0.012
Current timestep = 980. State = [[-0.11611207  0.28634337]]. Action = [[-0.01192524 -0.06527869  0.          0.31549096]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 980 is [True, False, False, False, False, True]
State prediction error at timestep 980 is 0.012
Current timestep = 981. State = [[-0.11145046  0.28234813]]. Action = [[ 0.07798595 -0.03863639  0.         -0.6364405 ]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 981 is [True, False, False, False, False, True]
State prediction error at timestep 981 is 0.012
Current timestep = 982. State = [[-0.11012109  0.27972138]]. Action = [[-0.0427819  -0.01712835  0.          0.89997673]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 982 is [True, False, False, False, False, True]
State prediction error at timestep 982 is 0.012
Current timestep = 983. State = [[-0.10936274  0.2825192 ]]. Action = [[ 0.01721631  0.0766285   0.         -0.6600516 ]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 983 is [True, False, False, False, False, True]
State prediction error at timestep 983 is 0.012
Current timestep = 984. State = [[-0.10477875  0.28403333]]. Action = [[ 0.07465675 -0.00395219  0.         -0.83267987]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 984 is [True, False, False, False, False, True]
State prediction error at timestep 984 is 0.012
Current timestep = 985. State = [[-0.10358878  0.28272054]]. Action = [[-0.03359612 -0.01797117  0.          0.8324299 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 985 is [True, False, False, False, False, True]
State prediction error at timestep 985 is 0.012
Current timestep = 986. State = [[-0.10345831  0.28115997]]. Action = [[ 0.0043617  -0.01707197  0.          0.7571852 ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 986 is [True, False, False, False, False, True]
State prediction error at timestep 986 is 0.012
Current timestep = 987. State = [[-0.10028989  0.28456268]]. Action = [[0.05393986 0.08451789 0.         0.91074586]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 987 is [True, False, False, False, False, True]
State prediction error at timestep 987 is 0.012
Current timestep = 988. State = [[-0.10242349  0.28340125]]. Action = [[-0.09513517 -0.07575029  0.          0.5027149 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 988 is [True, False, False, False, False, True]
State prediction error at timestep 988 is 0.012
Current timestep = 989. State = [[-0.10293582  0.27934897]]. Action = [[ 0.03991907 -0.04135776  0.          0.14787495]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 989 is [True, False, False, False, False, True]
State prediction error at timestep 989 is 0.012
Current timestep = 990. State = [[-0.10132878  0.27753708]]. Action = [[ 0.01049151 -0.00351747  0.         -0.08527881]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 990 is [True, False, False, False, False, True]
State prediction error at timestep 990 is 0.012
Current timestep = 991. State = [[-0.10208257  0.27386945]]. Action = [[-0.02764587 -0.06312492  0.          0.650923  ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 991 is [True, False, False, False, False, True]
State prediction error at timestep 991 is 0.012
Current timestep = 992. State = [[-0.10398535  0.272911  ]]. Action = [[-0.03136913  0.02429801  0.          0.6611495 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 992 is [True, False, False, False, False, True]
State prediction error at timestep 992 is 0.012
Current timestep = 993. State = [[-0.10046675  0.27177775]]. Action = [[ 0.09209859 -0.02520504  0.         -0.692278  ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 993 is [True, False, False, False, False, True]
State prediction error at timestep 993 is 0.012
Current timestep = 994. State = [[-0.10077024  0.27359894]]. Action = [[-0.06004525  0.06383594  0.          0.4478165 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 994 is [True, False, False, False, False, True]
State prediction error at timestep 994 is 0.012
Current timestep = 995. State = [[-0.10654324  0.2736182 ]]. Action = [[-0.08616318 -0.03452219  0.         -0.5358048 ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 995 is [True, False, False, False, False, True]
State prediction error at timestep 995 is 0.012
Current timestep = 996. State = [[-0.10878439  0.2729841 ]]. Action = [[ 0.00700314  0.00219162  0.         -0.5991376 ]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 996 is [True, False, False, False, False, True]
State prediction error at timestep 996 is 0.012
Current timestep = 997. State = [[-0.11294139  0.27008262]]. Action = [[-0.08489864 -0.06169039  0.          0.7437209 ]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 997 is [True, False, False, False, False, True]
State prediction error at timestep 997 is 0.012
Current timestep = 998. State = [[-0.11987723  0.2640565 ]]. Action = [[-0.09520837 -0.0915528   0.          0.5565076 ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 998 is [True, False, False, False, False, True]
State prediction error at timestep 998 is 0.012
Current timestep = 999. State = [[-0.12036221  0.2584935 ]]. Action = [[ 0.05635961 -0.05256925  0.          0.8191378 ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 999 is [True, False, False, False, False, True]
State prediction error at timestep 999 is 0.012
Current timestep = 1000. State = [[-0.11988983  0.2528662 ]]. Action = [[-0.02084371 -0.06486428  0.          0.36910772]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 1000 is [True, False, False, False, False, True]
State prediction error at timestep 1000 is 0.012
Current timestep = 1001. State = [[-0.12203467  0.24594663]]. Action = [[-0.03861452 -0.08106516  0.         -0.37766755]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 1001 is [True, False, False, False, False, True]
State prediction error at timestep 1001 is 0.012
Current timestep = 1002. State = [[-0.12155932  0.24128175]]. Action = [[ 0.02965219 -0.01920224  0.          0.7019793 ]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 1002 is [True, False, False, False, False, True]
State prediction error at timestep 1002 is 0.012
Current timestep = 1003. State = [[-0.12122149  0.23408282]]. Action = [[-0.00776701 -0.09812682  0.          0.9466896 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 1003 is [True, False, False, False, False, True]
State prediction error at timestep 1003 is 0.012
Current timestep = 1004. State = [[-0.12353636  0.22829613]]. Action = [[-0.0441862  -0.02287438  0.          0.22634363]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 1004 is [True, False, False, False, False, True]
State prediction error at timestep 1004 is 0.012
Current timestep = 1005. State = [[-0.1267784   0.22202957]]. Action = [[-0.03817734 -0.07460159  0.         -0.77004814]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 1005 is [True, False, False, False, False, True]
State prediction error at timestep 1005 is 0.012
Current timestep = 1006. State = [[-0.12627311  0.21594325]]. Action = [[ 0.03919714 -0.03906184  0.          0.87841535]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 1006 is [True, False, False, False, False, True]
State prediction error at timestep 1006 is 0.012
Current timestep = 1007. State = [[-0.1267247   0.21098858]]. Action = [[-0.02054184 -0.03128257  0.          0.90425086]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 1007 is [True, False, False, False, False, True]
State prediction error at timestep 1007 is 0.012
Current timestep = 1008. State = [[-0.12661152  0.21043965]]. Action = [[ 0.02725398  0.04996251  0.         -0.6225882 ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 1008 is [True, False, False, False, False, True]
State prediction error at timestep 1008 is 0.012
Current timestep = 1009. State = [[-0.12256198  0.21260306]]. Action = [[0.09491577 0.0544657  0.         0.76703167]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 1009 is [True, False, False, False, False, True]
State prediction error at timestep 1009 is 0.012
Current timestep = 1010. State = [[-0.12067068  0.20976107]]. Action = [[ 0.01019116 -0.05599188  0.         -0.68790007]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 1010 is [True, False, False, False, False, True]
State prediction error at timestep 1010 is 0.012
Current timestep = 1011. State = [[-0.11758008  0.2080568 ]]. Action = [[ 0.07431579  0.02838691  0.         -0.03772992]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 1011 is [True, False, False, False, False, True]
State prediction error at timestep 1011 is 0.012
Current timestep = 1012. State = [[-0.11508076  0.2078801 ]]. Action = [[0.0269706  0.01076402 0.         0.42734635]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 1012 is [True, False, False, False, False, True]
State prediction error at timestep 1012 is 0.012
Current timestep = 1013. State = [[-0.11911705  0.2083103 ]]. Action = [[-0.0946182   0.02043293  0.         -0.2018624 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 1013 is [True, False, False, False, False, True]
State prediction error at timestep 1013 is 0.012
Current timestep = 1014. State = [[-0.11889783  0.20992245]]. Action = [[ 0.0751218   0.02965959  0.         -0.86963993]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 1014 is [True, False, False, False, False, True]
State prediction error at timestep 1014 is 0.012
Current timestep = 1015. State = [[-0.11514147  0.20981173]]. Action = [[ 0.04310875 -0.01290338  0.          0.16432142]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 1015 is [True, False, False, False, False, True]
State prediction error at timestep 1015 is 0.012
Current timestep = 1016. State = [[-0.11475352  0.21360204]]. Action = [[-0.01784409  0.0863105   0.         -0.79304975]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 1016 is [True, False, False, False, False, True]
State prediction error at timestep 1016 is 0.012
Current timestep = 1017. State = [[-0.11221711  0.22069715]]. Action = [[ 0.06661092  0.08675348  0.         -0.05441201]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 1017 is [True, False, False, False, False, True]
State prediction error at timestep 1017 is 0.012
Current timestep = 1018. State = [[-0.11093689  0.22188766]]. Action = [[-0.00794149 -0.0415217   0.          0.12224686]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 1018 is [True, False, False, False, False, True]
State prediction error at timestep 1018 is 0.012
Current timestep = 1019. State = [[-0.11461437  0.22381283]]. Action = [[-0.08073373  0.04130784  0.         -0.6694067 ]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 1019 is [True, False, False, False, False, True]
State prediction error at timestep 1019 is 0.012
Current timestep = 1020. State = [[-0.12079962  0.23062617]]. Action = [[-0.08933624  0.08410076  0.         -0.6760888 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 1020 is [True, False, False, False, False, True]
State prediction error at timestep 1020 is 0.012
Current timestep = 1021. State = [[-0.12488252  0.23578838]]. Action = [[-0.030038    0.01414088  0.         -0.66972756]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 1021 is [True, False, False, False, False, True]
State prediction error at timestep 1021 is 0.012
Current timestep = 1022. State = [[-0.12648454  0.236895  ]]. Action = [[-0.01067324 -0.02871726  0.          0.25382912]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 1022 is [True, False, False, False, False, True]
State prediction error at timestep 1022 is 0.012
Current timestep = 1023. State = [[-0.12776905  0.23560843]]. Action = [[-0.01955844 -0.04419378  0.         -0.51790446]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 1023 is [True, False, False, False, False, True]
State prediction error at timestep 1023 is 0.012
Current timestep = 1024. State = [[-0.12938306  0.23681782]]. Action = [[-0.0218103   0.02387957  0.         -0.04514879]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 1024 is [True, False, False, False, False, True]
State prediction error at timestep 1024 is 0.012
Current timestep = 1025. State = [[-0.12749897  0.24010186]]. Action = [[0.05867507 0.03275304 0.         0.53611016]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 1025 is [True, False, False, False, False, True]
State prediction error at timestep 1025 is 0.012
Current timestep = 1026. State = [[-0.12451243  0.24043089]]. Action = [[ 0.03775021 -0.02569739  0.         -0.7047712 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 1026 is [True, False, False, False, False, True]
State prediction error at timestep 1026 is 0.012
Current timestep = 1027. State = [[-0.12406626  0.24196357]]. Action = [[-0.00988653  0.03807948  0.         -0.07900125]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 1027 is [True, False, False, False, False, True]
State prediction error at timestep 1027 is 0.012
Current timestep = 1028. State = [[-0.12146021  0.24254037]]. Action = [[ 0.06175292 -0.01478218  0.          0.5770025 ]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 1028 is [True, False, False, False, False, True]
State prediction error at timestep 1028 is 0.012
Current timestep = 1029. State = [[-0.11716683  0.24355535]]. Action = [[ 0.05522948  0.02999835  0.         -0.56859726]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 1029 is [True, False, False, False, False, True]
State prediction error at timestep 1029 is 0.012
Current timestep = 1030. State = [[-0.11482649  0.2433266 ]]. Action = [[ 0.01319759 -0.01858497  0.          0.5714809 ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 1030 is [True, False, False, False, False, True]
State prediction error at timestep 1030 is 0.012
Current timestep = 1031. State = [[-0.11709429  0.2461883 ]]. Action = [[-0.06280432  0.06686681  0.         -0.02139705]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 1031 is [True, False, False, False, False, True]
State prediction error at timestep 1031 is 0.012
Current timestep = 1032. State = [[-0.11847809  0.25156072]]. Action = [[ 0.00418463  0.06028608  0.         -0.4935966 ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 1032 is [True, False, False, False, False, True]
State prediction error at timestep 1032 is 0.012
Current timestep = 1033. State = [[-0.122499    0.24949397]]. Action = [[-0.08997542 -0.09533142  0.         -0.24315941]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 1033 is [True, False, False, False, False, True]
State prediction error at timestep 1033 is 0.012
Current timestep = 1034. State = [[-0.12108944  0.24321322]]. Action = [[ 0.07782345 -0.08356238  0.          0.7948768 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 1034 is [True, False, False, False, False, True]
State prediction error at timestep 1034 is 0.012
Current timestep = 1035. State = [[-0.12215015  0.24170315]]. Action = [[-0.08291986  0.0194141   0.         -0.04008788]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 1035 is [True, False, False, False, False, True]
State prediction error at timestep 1035 is 0.012
Current timestep = 1036. State = [[-0.12268314  0.2386849 ]]. Action = [[ 0.01904037 -0.07277864  0.          0.34697163]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 1036 is [True, False, False, False, False, True]
State prediction error at timestep 1036 is 0.012
Current timestep = 1037. State = [[-0.12235889  0.23932587]]. Action = [[-0.0129336   0.05921068  0.         -0.33567202]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 1037 is [True, False, False, False, False, True]
State prediction error at timestep 1037 is 0.012
Current timestep = 1038. State = [[-0.12073155  0.24006303]]. Action = [[ 0.03766171 -0.01354218  0.          0.53323567]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 1038 is [True, False, False, False, False, True]
State prediction error at timestep 1038 is 0.012
Current timestep = 1039. State = [[-0.119918   0.2360319]]. Action = [[-0.00844985 -0.06800191  0.         -0.6106459 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 1039 is [True, False, False, False, False, True]
State prediction error at timestep 1039 is 0.012
Current timestep = 1040. State = [[-0.11685333  0.23046517]]. Action = [[ 0.05811655 -0.05851182  0.         -0.12160766]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 1040 is [True, False, False, False, False, True]
State prediction error at timestep 1040 is 0.012
Current timestep = 1041. State = [[-0.11769944  0.22571738]]. Action = [[-0.06372258 -0.04003153  0.          0.56736994]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 1041 is [True, False, False, False, False, True]
State prediction error at timestep 1041 is 0.012
Current timestep = 1042. State = [[-0.12162862  0.21996492]]. Action = [[-0.05953641 -0.07325477  0.          0.3312087 ]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 1042 is [True, False, False, False, False, True]
State prediction error at timestep 1042 is 0.012
Current timestep = 1043. State = [[-0.12200949  0.2176995 ]]. Action = [[ 0.01984215  0.01912104  0.         -0.55158883]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 1043 is [True, False, False, False, False, True]
State prediction error at timestep 1043 is 0.012
Current timestep = 1044. State = [[-0.11708548  0.22174995]]. Action = [[ 0.09985802  0.09805235  0.         -0.29405463]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 1044 is [True, False, False, False, False, True]
State prediction error at timestep 1044 is 0.012
Current timestep = 1045. State = [[-0.11392365  0.22129346]]. Action = [[ 0.02067767 -0.04399825  0.          0.9547901 ]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 1045 is [True, False, False, False, False, True]
State prediction error at timestep 1045 is 0.012
Current timestep = 1046. State = [[-0.1162356   0.21863225]]. Action = [[-0.05967481 -0.01327957  0.          0.19046116]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 1046 is [True, False, False, False, False, True]
State prediction error at timestep 1046 is 0.012
Current timestep = 1047. State = [[-0.11631847  0.21400592]]. Action = [[ 0.03068823 -0.07041498  0.         -0.0634523 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 1047 is [True, False, False, False, False, True]
State prediction error at timestep 1047 is 0.012
Current timestep = 1048. State = [[-0.11436672  0.208998  ]]. Action = [[ 0.02183378 -0.03973609  0.         -0.45328498]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 1048 is [True, False, False, False, False, True]
State prediction error at timestep 1048 is 0.012
Current timestep = 1049. State = [[-0.10969636  0.21066095]]. Action = [[0.08375234 0.08233904 0.         0.5564741 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 1049 is [True, False, False, False, False, True]
State prediction error at timestep 1049 is 0.012
Current timestep = 1050. State = [[-0.10970104  0.21024346]]. Action = [[-0.05101869 -0.03691415  0.          0.22185814]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 1050 is [True, False, False, False, False, True]
State prediction error at timestep 1050 is 0.012
Current timestep = 1051. State = [[-0.1105928  0.2060547]]. Action = [[ 0.00898547 -0.05141078  0.          0.99601007]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 1051 is [True, False, False, False, False, True]
State prediction error at timestep 1051 is 0.012
Current timestep = 1052. State = [[-0.11172073  0.20706157]]. Action = [[-0.02541732  0.06571389  0.         -0.66212404]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 1052 is [True, False, False, False, False, True]
State prediction error at timestep 1052 is 0.012
Current timestep = 1053. State = [[-0.11635261  0.20681778]]. Action = [[-0.07836245 -0.03584678  0.          0.6744528 ]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 1053 is [True, False, False, False, False, True]
State prediction error at timestep 1053 is 0.012
Current timestep = 1054. State = [[-0.11876775  0.2094407 ]]. Action = [[-0.0005331   0.07210588  0.         -0.01992548]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 1054 is [True, False, False, False, False, True]
State prediction error at timestep 1054 is 0.012
Current timestep = 1055. State = [[-0.11974518  0.21021381]]. Action = [[-0.00695431 -0.02911751  0.          0.3158083 ]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 1055 is [True, False, False, False, False, True]
State prediction error at timestep 1055 is 0.012
Current timestep = 1056. State = [[-0.11858435  0.21157226]]. Action = [[ 0.03859293  0.0391767   0.         -0.9458256 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 1056 is [True, False, False, False, False, True]
State prediction error at timestep 1056 is 0.012
Current timestep = 1057. State = [[-0.11354451  0.21307991]]. Action = [[0.09889691 0.00837018 0.         0.3293903 ]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 1057 is [True, False, False, False, False, True]
State prediction error at timestep 1057 is 0.012
Current timestep = 1058. State = [[-0.11322715  0.21020013]]. Action = [[-0.04780402 -0.06218441  0.         -0.4087019 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 1058 is [True, False, False, False, False, True]
State prediction error at timestep 1058 is 0.012
Current timestep = 1059. State = [[-0.11691817  0.20988525]]. Action = [[-0.04498581  0.03062291  0.         -0.12226999]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 1059 is [True, False, False, False, False, True]
State prediction error at timestep 1059 is 0.012
Current timestep = 1060. State = [[-0.12348519  0.21390729]]. Action = [[-0.09922152  0.05984075  0.          0.93935084]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 1060 is [True, False, False, False, False, True]
State prediction error at timestep 1060 is 0.012
Current timestep = 1061. State = [[-0.12980501  0.21804513]]. Action = [[-0.05823983  0.03245046  0.         -0.31689984]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 1061 is [True, False, False, False, False, True]
State prediction error at timestep 1061 is 0.012
Current timestep = 1062. State = [[-0.13564812  0.2157809 ]]. Action = [[-0.06791382 -0.08552685  0.         -0.10924006]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 1062 is [True, False, False, False, False, True]
State prediction error at timestep 1062 is 0.012
Current timestep = 1063. State = [[-0.14016943  0.21448143]]. Action = [[-0.03835889  0.00760498  0.          0.1677171 ]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 1063 is [True, False, False, False, False, True]
State prediction error at timestep 1063 is 0.012
Current timestep = 1064. State = [[-0.14362283  0.21991526]]. Action = [[-0.02342618  0.09562253  0.          0.474051  ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 1064 is [True, False, False, False, False, True]
State prediction error at timestep 1064 is 0.012
Current timestep = 1065. State = [[-0.14697768  0.22784539]]. Action = [[-0.01774765  0.08813121  0.          0.06256223]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 1065 is [True, False, False, False, False, True]
State prediction error at timestep 1065 is 0.012
Current timestep = 1066. State = [[-0.14995189  0.2329653 ]]. Action = [[-0.00803383  0.02822735  0.          0.4917779 ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 1066 is [True, False, False, False, False, True]
State prediction error at timestep 1066 is 0.012
Current timestep = 1067. State = [[-0.15485027  0.2381458 ]]. Action = [[-0.0532483   0.06201915  0.          0.33800828]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 1067 is [True, False, False, False, False, True]
State prediction error at timestep 1067 is 0.012
Current timestep = 1068. State = [[-0.16226994  0.24438494]]. Action = [[-0.07800195  0.05984048  0.         -0.40752316]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 1068 is [True, False, False, False, False, True]
State prediction error at timestep 1068 is 0.012
Current timestep = 1069. State = [[-0.16769852  0.24306187]]. Action = [[-0.02515301 -0.09613751  0.          0.06707072]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 1069 is [True, False, False, False, False, True]
State prediction error at timestep 1069 is 0.012
Current timestep = 1070. State = [[-0.16848487  0.2444499 ]]. Action = [[0.03605817 0.05909397 0.         0.61523676]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 1070 is [True, False, False, False, False, True]
State prediction error at timestep 1070 is 0.012
Current timestep = 1071. State = [[-0.16506615  0.24939074]]. Action = [[ 0.0924653   0.05312584  0.         -0.9475179 ]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 1071 is [True, False, False, False, False, True]
State prediction error at timestep 1071 is 0.012
Current timestep = 1072. State = [[-0.1637292  0.2536752]]. Action = [[0.01154344 0.04442147 0.         0.25357187]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 1072 is [True, False, False, False, False, True]
State prediction error at timestep 1072 is 0.012
Current timestep = 1073. State = [[-0.16149609  0.2594238 ]]. Action = [[0.06736618 0.07872456 0.         0.2754593 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 1073 is [True, False, False, False, False, True]
State prediction error at timestep 1073 is 0.012
Current timestep = 1074. State = [[-0.16021138  0.26286548]]. Action = [[0.01259811 0.01269738 0.         0.1009233 ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 1074 is [True, False, False, False, False, True]
State prediction error at timestep 1074 is 0.012
Current timestep = 1075. State = [[-0.16008037  0.2685544 ]]. Action = [[ 0.0107735   0.09123055  0.         -0.13697726]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 1075 is [True, False, False, False, False, True]
State prediction error at timestep 1075 is 0.012
Current timestep = 1076. State = [[-0.15758643  0.27348152]]. Action = [[0.05938841 0.0291119  0.         0.77140117]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 1076 is [True, False, False, False, False, True]
State prediction error at timestep 1076 is 0.012
Current timestep = 1077. State = [[-0.16018787  0.2769307 ]]. Action = [[-0.08621898  0.02688188  0.         -0.8619108 ]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 1077 is [True, False, False, False, False, True]
State prediction error at timestep 1077 is 0.012
Current timestep = 1078. State = [[-0.16701548  0.28375894]]. Action = [[-0.08683252  0.08754387  0.          0.14542413]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 1078 is [True, False, False, False, False, True]
State prediction error at timestep 1078 is 0.012
Current timestep = 1079. State = [[-0.17118256  0.283594  ]]. Action = [[-0.02500013 -0.09717063  0.         -0.745737  ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 1079 is [True, False, False, False, False, True]
State prediction error at timestep 1079 is 0.012
Current timestep = 1080. State = [[-0.16795768  0.28435746]]. Action = [[ 0.09249695  0.03867587  0.         -0.38111818]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 1080 is [True, False, False, False, False, True]
State prediction error at timestep 1080 is 0.012
Current timestep = 1081. State = [[-0.16835944  0.28288513]]. Action = [[-0.07693987 -0.07844938  0.          0.26834846]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 1081 is [True, False, False, False, False, True]
State prediction error at timestep 1081 is 0.012
Current timestep = 1082. State = [[-0.16726969  0.28199705]]. Action = [[0.06343985 0.0085208  0.         0.05565238]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 1082 is [True, False, False, False, False, True]
State prediction error at timestep 1082 is 0.012
Current timestep = 1083. State = [[-0.16167438  0.2834682 ]]. Action = [[ 0.07603764  0.02106241  0.         -0.5194232 ]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 1083 is [True, False, False, False, False, True]
State prediction error at timestep 1083 is 0.012
Current timestep = 1084. State = [[-0.16229174  0.27992645]]. Action = [[-0.08025346 -0.09109644  0.         -0.26710796]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 1084 is [True, False, False, False, False, True]
State prediction error at timestep 1084 is 0.012
Current timestep = 1085. State = [[-0.16332991  0.2800277 ]]. Action = [[ 0.01770906  0.05353705  0.         -0.7641356 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 1085 is [True, False, False, False, False, True]
State prediction error at timestep 1085 is 0.012
Current timestep = 1086. State = [[-0.16708708  0.27851865]]. Action = [[-0.09100384 -0.06055483  0.         -0.80686355]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 1086 is [True, False, False, False, False, True]
State prediction error at timestep 1086 is 0.012
Current timestep = 1087. State = [[-0.17277764  0.27546594]]. Action = [[-0.06864703 -0.03243514  0.          0.4985633 ]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 1087 is [True, False, False, False, False, True]
State prediction error at timestep 1087 is 0.012
Current timestep = 1088. State = [[-0.17358805  0.2739055 ]]. Action = [[ 0.02999561 -0.00999061  0.          0.92235494]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 1088 is [True, False, False, False, False, True]
State prediction error at timestep 1088 is 0.012
Current timestep = 1089. State = [[-0.17744683  0.2705182 ]]. Action = [[-0.09123151 -0.05709622  0.         -0.7561028 ]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 1089 is [True, False, False, False, False, True]
State prediction error at timestep 1089 is 0.012
Current timestep = 1090. State = [[-0.18503569  0.26578233]]. Action = [[-0.0976013  -0.06005704  0.         -0.22185141]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 1090 is [True, False, False, False, False, True]
State prediction error at timestep 1090 is 0.012
Current timestep = 1091. State = [[-0.18736938  0.2672184 ]]. Action = [[0.03577938 0.07468306 0.         0.04578471]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 1091 is [True, False, False, False, False, True]
State prediction error at timestep 1091 is 0.012
Current timestep = 1092. State = [[-0.18795706  0.2641779 ]]. Action = [[-0.01110975 -0.09286748  0.          0.9041778 ]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 1092 is [True, False, False, False, False, True]
State prediction error at timestep 1092 is 0.012
Current timestep = 1093. State = [[-0.18713696  0.25952825]]. Action = [[ 0.03349041 -0.02681028  0.          0.29017448]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 1093 is [True, False, False, False, False, True]
State prediction error at timestep 1093 is 0.012
Current timestep = 1094. State = [[-0.18838331  0.2603985 ]]. Action = [[-0.0291583   0.05612025  0.          0.1264646 ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 1094 is [True, False, False, False, False, True]
State prediction error at timestep 1094 is 0.012
Current timestep = 1095. State = [[-0.18663417  0.25981614]]. Action = [[ 0.07225894 -0.02463444  0.          0.1765126 ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 1095 is [True, False, False, False, False, True]
State prediction error at timestep 1095 is 0.012
Current timestep = 1096. State = [[-0.18436384  0.25349802]]. Action = [[ 0.02088772 -0.09108654  0.         -0.5975807 ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 1096 is [True, False, False, False, False, True]
State prediction error at timestep 1096 is 0.012
Current timestep = 1097. State = [[-0.18220334  0.25335518]]. Action = [[0.03884349 0.0787148  0.         0.54652596]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 1097 is [True, False, False, False, False, True]
State prediction error at timestep 1097 is 0.012
Current timestep = 1098. State = [[-0.18435962  0.25650772]]. Action = [[-0.05422202  0.0421676   0.          0.96172357]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 1098 is [True, False, False, False, False, True]
State prediction error at timestep 1098 is 0.012
Current timestep = 1099. State = [[-0.18917532  0.25350907]]. Action = [[-0.05876496 -0.07798339  0.          0.8623661 ]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 1099 is [True, False, False, False, False, True]
State prediction error at timestep 1099 is 0.012
Current timestep = 1100. State = [[-0.19403379  0.2526651 ]]. Action = [[-0.05779624  0.03173969  0.          0.4973917 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 1100 is [True, False, False, False, False, True]
State prediction error at timestep 1100 is 0.012
Current timestep = 1101. State = [[-0.1922579  0.2532677]]. Action = [[ 0.09027206  0.00228415  0.         -0.15932077]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 1101 is [True, False, False, False, False, True]
State prediction error at timestep 1101 is 0.012
Current timestep = 1102. State = [[-0.18880026  0.24930681]]. Action = [[ 0.03074531 -0.07073151  0.          0.4543202 ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 1102 is [True, False, False, False, False, True]
State prediction error at timestep 1102 is 0.012
Current timestep = 1103. State = [[-0.18519053  0.24379626]]. Action = [[ 0.05133448 -0.05467787  0.          0.4729458 ]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 1103 is [True, False, False, False, False, True]
State prediction error at timestep 1103 is 0.012
Current timestep = 1104. State = [[-0.1789646   0.23758681]]. Action = [[ 0.0881355  -0.06759397  0.         -0.03466082]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 1104 is [True, False, False, False, False, True]
State prediction error at timestep 1104 is 0.012
Current timestep = 1105. State = [[-0.17153975  0.23617093]]. Action = [[0.08728664 0.04501427 0.         0.41396368]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 1105 is [True, False, False, False, False, True]
State prediction error at timestep 1105 is 0.012
Current timestep = 1106. State = [[-0.16998254  0.23265623]]. Action = [[-0.04353527 -0.06529231  0.          0.97683465]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 1106 is [True, False, False, False, False, True]
State prediction error at timestep 1106 is 0.012
Current timestep = 1107. State = [[-0.17018972  0.2272261 ]]. Action = [[-0.00163966 -0.04632018  0.          0.2010014 ]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 1107 is [True, False, False, False, False, True]
State prediction error at timestep 1107 is 0.012
Current timestep = 1108. State = [[-0.1715551   0.22281463]]. Action = [[-0.04595179 -0.03363369  0.          0.6286193 ]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 1108 is [True, False, False, False, False, True]
State prediction error at timestep 1108 is 0.012
Current timestep = 1109. State = [[-0.17025287  0.22479706]]. Action = [[ 0.04011657  0.08569717  0.         -0.29200697]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 1109 is [True, False, False, False, False, True]
State prediction error at timestep 1109 is 0.012
Current timestep = 1110. State = [[-0.16536295  0.22137661]]. Action = [[ 0.07105752 -0.09536091  0.          0.05505395]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 1110 is [True, False, False, False, False, True]
State prediction error at timestep 1110 is 0.012
Current timestep = 1111. State = [[-0.16495858  0.217737  ]]. Action = [[-0.04949622  0.00357267  0.         -0.8297745 ]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 1111 is [True, False, False, False, False, True]
State prediction error at timestep 1111 is 0.012
Current timestep = 1112. State = [[-0.16650888  0.21413386]]. Action = [[-0.02182097 -0.0537909   0.          0.39956987]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 1112 is [True, False, False, False, False, True]
State prediction error at timestep 1112 is 0.012
Current timestep = 1113. State = [[-0.1679548   0.21088253]]. Action = [[-0.03127693 -0.01770736  0.          0.28102612]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 1113 is [True, False, False, False, False, True]
State prediction error at timestep 1113 is 0.012
Current timestep = 1114. State = [[-0.16852014  0.21439148]]. Action = [[-3.3889711e-04  9.6017815e-02  0.0000000e+00 -7.2028416e-01]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 1114 is [True, False, False, False, False, True]
State prediction error at timestep 1114 is 0.012
Current timestep = 1115. State = [[-0.16528448  0.21352622]]. Action = [[ 0.0705403  -0.06371776  0.         -0.64322686]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 1115 is [True, False, False, False, False, True]
State prediction error at timestep 1115 is 0.012
Current timestep = 1116. State = [[-0.15870808  0.2062284 ]]. Action = [[ 0.09413608 -0.09612605  0.         -0.5761867 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 1116 is [True, False, False, False, False, True]
State prediction error at timestep 1116 is 0.012
Current timestep = 1117. State = [[-0.15303746  0.20306952]]. Action = [[ 0.05263519  0.01932272  0.         -0.8410431 ]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 1117 is [True, False, False, False, False, True]
State prediction error at timestep 1117 is 0.012
Current timestep = 1118. State = [[-0.15234558  0.2020115 ]]. Action = [[-0.03061829 -0.00665709  0.         -0.6764481 ]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 1118 is [True, False, False, False, False, True]
State prediction error at timestep 1118 is 0.012
Current timestep = 1119. State = [[-0.14865634  0.20042393]]. Action = [[ 0.07936322 -0.00867285  0.         -0.27094448]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 1119 is [True, False, False, False, False, True]
State prediction error at timestep 1119 is 0.012
Current timestep = 1120. State = [[-0.1491107   0.20213385]]. Action = [[-0.07138537  0.05758248  0.         -0.56213   ]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 1120 is [True, False, False, False, False, True]
State prediction error at timestep 1120 is 0.012
Current timestep = 1121. State = [[-0.15441595  0.20745327]]. Action = [[-0.07923868  0.0784171   0.          0.7685051 ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 1121 is [True, False, False, False, False, True]
State prediction error at timestep 1121 is 0.012
Current timestep = 1122. State = [[-0.1576773   0.21119545]]. Action = [[-0.01872879  0.01940761  0.         -0.6331923 ]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 1122 is [True, False, False, False, False, True]
State prediction error at timestep 1122 is 0.012
Current timestep = 1123. State = [[-0.15968917  0.21180356]]. Action = [[-0.0235596  -0.01566777  0.          0.5209148 ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 1123 is [True, False, False, False, False, True]
State prediction error at timestep 1123 is 0.012
Current timestep = 1124. State = [[-0.15983242  0.20878044]]. Action = [[ 0.01431645 -0.06595671  0.         -0.64963424]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 1124 is [True, False, False, False, False, True]
State prediction error at timestep 1124 is 0.012
Current timestep = 1125. State = [[-0.1621801   0.21022464]]. Action = [[-0.05302828  0.05865135  0.          0.1919713 ]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 1125 is [True, False, False, False, False, True]
State prediction error at timestep 1125 is 0.012
Current timestep = 1126. State = [[-0.16138938  0.2135557 ]]. Action = [[ 0.05706917  0.02305482  0.         -0.6911782 ]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 1126 is [True, False, False, False, False, True]
State prediction error at timestep 1126 is 0.012
Current timestep = 1127. State = [[-0.16471837  0.21863759]]. Action = [[-0.08954783  0.07420962  0.         -0.946771  ]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 1127 is [True, False, False, False, False, True]
State prediction error at timestep 1127 is 0.012
Current timestep = 1128. State = [[-0.17143327  0.22106665]]. Action = [[-0.07140861 -0.0160872   0.          0.27415884]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 1128 is [True, False, False, False, False, True]
State prediction error at timestep 1128 is 0.012
Current timestep = 1129. State = [[-0.17083497  0.22151434]]. Action = [[ 0.08051687 -0.00306795  0.         -0.6425678 ]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 1129 is [True, False, False, False, False, True]
State prediction error at timestep 1129 is 0.012
Current timestep = 1130. State = [[-0.16995557  0.21707082]]. Action = [[-0.01558075 -0.0989446   0.          0.7079396 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 1130 is [True, False, False, False, False, True]
State prediction error at timestep 1130 is 0.012
Current timestep = 1131. State = [[-0.1713855   0.21363962]]. Action = [[-0.02313057 -0.01685525  0.          0.60168076]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 1131 is [True, False, False, False, False, True]
State prediction error at timestep 1131 is 0.012
Current timestep = 1132. State = [[-0.1766314   0.21102588]]. Action = [[-0.09658629 -0.04293556  0.         -0.6546779 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 1132 is [True, False, False, False, False, True]
State prediction error at timestep 1132 is 0.012
Current timestep = 1133. State = [[-0.17850815  0.20893691]]. Action = [[ 0.01797029 -0.01677885  0.          0.25757754]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 1133 is [True, False, False, False, False, True]
State prediction error at timestep 1133 is 0.012
Current timestep = 1134. State = [[-0.17512982  0.20848386]]. Action = [[ 0.06729489  0.01073712  0.         -0.4664569 ]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 1134 is [True, False, False, False, False, True]
State prediction error at timestep 1134 is 0.012
Current timestep = 1135. State = [[-0.17537442  0.2117865 ]]. Action = [[-0.03340343  0.07269412  0.         -0.6715493 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 1135 is [True, False, False, False, False, True]
State prediction error at timestep 1135 is 0.012
Current timestep = 1136. State = [[-0.17881246  0.21342827]]. Action = [[-0.04082282 -0.00509984  0.          0.7397363 ]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 1136 is [True, False, False, False, False, True]
State prediction error at timestep 1136 is 0.012
Current timestep = 1137. State = [[-0.18258052  0.21526209]]. Action = [[-0.03996485  0.03758051  0.         -0.04586554]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 1137 is [True, False, False, False, False, True]
State prediction error at timestep 1137 is 0.012
Current timestep = 1138. State = [[-0.18039748  0.2120295 ]]. Action = [[ 0.08587527 -0.08662061  0.         -0.7593437 ]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 1138 is [True, False, False, False, False, True]
State prediction error at timestep 1138 is 0.012
Current timestep = 1139. State = [[-0.18079144  0.20584042]]. Action = [[-0.05228643 -0.06798575  0.          0.5707611 ]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 1139 is [True, False, False, False, False, True]
State prediction error at timestep 1139 is 0.012
Current timestep = 1140. State = [[-0.1856075   0.20317192]]. Action = [[-0.06898434 -0.00360665  0.          0.8766681 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 1140 is [True, False, False, False, False, True]
State prediction error at timestep 1140 is 0.012
Current timestep = 1141. State = [[-0.18367784  0.2042201 ]]. Action = [[ 0.09820833  0.03642366  0.         -0.66993695]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 1141 is [True, False, False, False, False, True]
State prediction error at timestep 1141 is 0.012
Current timestep = 1142. State = [[-0.18148842  0.20753641]]. Action = [[-2.4718046e-04  5.7755463e-02  0.0000000e+00  7.6931596e-01]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 1142 is [True, False, False, False, False, True]
State prediction error at timestep 1142 is 0.012
Current timestep = 1143. State = [[-0.1860894   0.21053024]]. Action = [[-0.09248409  0.02866315  0.          0.97019506]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 1143 is [True, False, False, False, False, True]
State prediction error at timestep 1143 is 0.012
Current timestep = 1144. State = [[-0.19159845  0.2139881 ]]. Action = [[-0.05250495  0.04391243  0.         -0.14698052]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 1144 is [True, False, False, False, False, True]
State prediction error at timestep 1144 is 0.012
Current timestep = 1145. State = [[-0.19282475  0.2178584 ]]. Action = [[ 0.02464922  0.03905082  0.         -0.9870381 ]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 1145 is [True, False, False, False, False, True]
State prediction error at timestep 1145 is 0.012
Current timestep = 1146. State = [[-0.19692872  0.21921097]]. Action = [[-0.07858235 -0.01227967  0.          0.17743301]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 1146 is [True, False, False, False, False, True]
State prediction error at timestep 1146 is 0.012
Current timestep = 1147. State = [[-0.20192197  0.216639  ]]. Action = [[-0.04224129 -0.06401781  0.         -0.159145  ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 1147 is [True, False, False, False, False, True]
State prediction error at timestep 1147 is 0.012
Current timestep = 1148. State = [[-0.2007813  0.2184599]]. Action = [[0.07245492 0.06373066 0.         0.77017283]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 1148 is [True, False, False, False, False, True]
State prediction error at timestep 1148 is 0.012
Current timestep = 1149. State = [[-0.20188019  0.21647197]]. Action = [[-0.04964813 -0.08396882  0.         -0.8095371 ]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 1149 is [True, False, False, False, False, True]
State prediction error at timestep 1149 is 0.012
Current timestep = 1150. State = [[-0.20699655  0.21586916]]. Action = [[-0.06646751  0.02832193  0.          0.03666735]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 1150 is [True, False, False, False, False, True]
State prediction error at timestep 1150 is 0.012
Current timestep = 1151. State = [[-0.20847374  0.21258283]]. Action = [[ 0.02355964 -0.08496461  0.         -0.15142047]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 1151 is [True, False, False, False, False, True]
State prediction error at timestep 1151 is 0.012
Current timestep = 1152. State = [[-0.20772345  0.20755361]]. Action = [[ 0.01373357 -0.04712833  0.          0.20297682]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 1152 is [True, False, False, False, False, True]
State prediction error at timestep 1152 is 0.012
Current timestep = 1153. State = [[-0.2057581   0.20980611]]. Action = [[ 0.04309995  0.08856457  0.         -0.69664544]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 1153 is [True, False, False, False, False, True]
State prediction error at timestep 1153 is 0.012
Current timestep = 1154. State = [[-0.20596232  0.21239609]]. Action = [[-0.01187576  0.01327537  0.          0.10056651]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 1154 is [True, False, False, False, False, True]
State prediction error at timestep 1154 is 0.012
Current timestep = 1155. State = [[-0.21049093  0.21742363]]. Action = [[-0.07057953  0.09523118  0.         -0.1659224 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 1155 is [True, False, False, False, False, True]
State prediction error at timestep 1155 is 0.012
Current timestep = 1156. State = [[-0.21250272  0.21848248]]. Action = [[ 0.01913317 -0.03857095  0.         -0.38425738]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 1156 is [True, False, False, False, False, True]
State prediction error at timestep 1156 is 0.012
Current timestep = 1157. State = [[-0.2153255   0.22194916]]. Action = [[-0.04825215  0.08423954  0.          0.59904563]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 1157 is [True, False, False, False, False, True]
State prediction error at timestep 1157 is 0.012
Current timestep = 1158. State = [[-0.213143    0.22330913]]. Action = [[ 0.09689566 -0.02903032  0.         -0.42680848]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 1158 is [True, False, False, False, False, True]
State prediction error at timestep 1158 is 0.012
Current timestep = 1159. State = [[-0.21312824  0.22485049]]. Action = [[-0.03931854  0.03910338  0.         -0.1568563 ]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 1159 is [True, False, False, False, False, True]
State prediction error at timestep 1159 is 0.012
Current timestep = 1160. State = [[-0.21629211  0.22269443]]. Action = [[-0.03535128 -0.07635286  0.         -0.17043209]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 1160 is [True, False, False, False, False, True]
State prediction error at timestep 1160 is 0.012
Current timestep = 1161. State = [[-0.22040495  0.22349766]]. Action = [[-0.0589258   0.04904784  0.         -0.07255864]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 1161 is [True, False, False, False, False, True]
State prediction error at timestep 1161 is 0.012
Current timestep = 1162. State = [[-0.21788459  0.22188264]]. Action = [[ 0.0975137  -0.06678614  0.         -0.78244394]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 1162 is [True, False, False, False, False, True]
State prediction error at timestep 1162 is 0.012
Current timestep = 1163. State = [[-0.21655752  0.2244589 ]]. Action = [[-0.02318844  0.08981019  0.          0.5769861 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 1163 is [True, False, False, False, False, True]
State prediction error at timestep 1163 is 0.012
Current timestep = 1164. State = [[-0.21915714  0.22536977]]. Action = [[-0.04056261 -0.03936648  0.         -0.36371022]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 1164 is [True, False, False, False, False, True]
State prediction error at timestep 1164 is 0.012
Current timestep = 1165. State = [[-0.22399746  0.22577243]]. Action = [[-0.07800238  0.0181192   0.         -0.6232807 ]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 1165 is [True, False, False, False, False, True]
State prediction error at timestep 1165 is 0.012
Current timestep = 1166. State = [[-0.22848205  0.222445  ]]. Action = [[-0.04785875 -0.08873288  0.         -0.41338772]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 1166 is [True, False, False, False, False, True]
State prediction error at timestep 1166 is 0.012
Current timestep = 1167. State = [[-0.22884436  0.2211291 ]]. Action = [[ 0.02232809  0.01917198  0.         -0.9816757 ]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 1167 is [True, False, False, False, False, True]
State prediction error at timestep 1167 is 0.012
Current timestep = 1168. State = [[-0.22611144  0.21991481]]. Action = [[ 0.05065755 -0.03103263  0.          0.138242  ]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 1168 is [True, False, False, False, False, True]
State prediction error at timestep 1168 is 0.012
Current timestep = 1169. State = [[-0.22794461  0.22283669]]. Action = [[-0.05977918  0.08142114  0.         -0.4279381 ]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 1169 is [True, False, False, False, False, True]
State prediction error at timestep 1169 is 0.012
Current timestep = 1170. State = [[-0.22859582  0.22660363]]. Action = [[ 0.03369343  0.02858546  0.         -0.35255313]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 1170 is [True, False, False, False, False, True]
State prediction error at timestep 1170 is 0.012
Current timestep = 1171. State = [[-0.22821082  0.22381215]]. Action = [[ 0.00316359 -0.07560721  0.         -0.39458627]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 1171 is [True, False, False, False, False, True]
State prediction error at timestep 1171 is 0.012
Current timestep = 1172. State = [[-0.22967432  0.22219078]]. Action = [[-0.02772601  0.01237582  0.          0.20669138]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 1172 is [True, False, False, False, False, True]
State prediction error at timestep 1172 is 0.012
Current timestep = 1173. State = [[-0.22683059  0.22434184]]. Action = [[ 0.08514186  0.04224726  0.         -0.1713056 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 1173 is [True, False, False, False, False, True]
State prediction error at timestep 1173 is 0.012
Current timestep = 1174. State = [[-0.22757964  0.2213791 ]]. Action = [[-0.06505192 -0.0820803   0.         -0.14446902]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 1174 is [True, False, False, False, False, True]
State prediction error at timestep 1174 is 0.012
Current timestep = 1175. State = [[-0.23009732  0.22025213]]. Action = [[-0.01051116  0.02723496  0.          0.5638639 ]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 1175 is [True, False, False, False, False, True]
State prediction error at timestep 1175 is 0.012
Current timestep = 1176. State = [[-0.22845666  0.21920584]]. Action = [[ 0.05259062 -0.02832459  0.         -0.05899054]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 1176 is [True, False, False, False, False, True]
State prediction error at timestep 1176 is 0.012
Current timestep = 1177. State = [[-0.2237505  0.2215398]]. Action = [[ 0.07895314  0.07446537  0.         -0.6552356 ]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 1177 is [True, False, False, False, False, True]
State prediction error at timestep 1177 is 0.012
Current timestep = 1178. State = [[-0.21887623  0.22218543]]. Action = [[ 0.06520637 -0.01699839  0.          0.7008686 ]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 1178 is [True, False, False, False, False, True]
State prediction error at timestep 1178 is 0.012
Current timestep = 1179. State = [[-0.21826527  0.22450016]]. Action = [[-0.02348668  0.06426274  0.         -0.7174393 ]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 1179 is [True, False, False, False, False, True]
State prediction error at timestep 1179 is 0.012
Current timestep = 1180. State = [[-0.21430981  0.22160976]]. Action = [[ 0.09113055 -0.08996395  0.         -0.80435956]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 1180 is [True, False, False, False, False, True]
State prediction error at timestep 1180 is 0.012
Current timestep = 1181. State = [[-0.20928869  0.21888298]]. Action = [[0.03924585 0.00578091 0.         0.383466  ]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 1181 is [True, False, False, False, False, True]
State prediction error at timestep 1181 is 0.012
Current timestep = 1182. State = [[-0.20284659  0.21333522]]. Action = [[ 0.08679216 -0.09958331  0.         -0.0943827 ]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 1182 is [True, False, False, False, False, True]
State prediction error at timestep 1182 is 0.012
Current timestep = 1183. State = [[-0.19717692  0.21250701]]. Action = [[ 0.03790414  0.06055564  0.         -0.11962163]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 1183 is [True, False, False, False, False, True]
State prediction error at timestep 1183 is 0.012
Current timestep = 1184. State = [[-0.19675878  0.21236426]]. Action = [[-0.04611162 -0.02117857  0.          0.46590507]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 1184 is [True, False, False, False, False, True]
State prediction error at timestep 1184 is 0.012
Current timestep = 1185. State = [[-0.19757752  0.21359053]]. Action = [[-0.02340569  0.04222097  0.         -0.14011174]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 1185 is [True, False, False, False, False, True]
State prediction error at timestep 1185 is 0.012
Current timestep = 1186. State = [[-0.19831769  0.21044973]]. Action = [[-0.02768666 -0.08546297  0.         -0.8443073 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 1186 is [True, False, False, False, False, True]
State prediction error at timestep 1186 is 0.012
Current timestep = 1187. State = [[-0.20009653  0.2060247 ]]. Action = [[-0.05102943 -0.03864586  0.         -0.61022174]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 1187 is [True, False, False, False, False, True]
State prediction error at timestep 1187 is 0.012
Current timestep = 1188. State = [[-0.19720747  0.20560908]]. Action = [[ 0.06776821  0.02213746  0.         -0.6257579 ]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 1188 is [True, False, False, False, False, True]
State prediction error at timestep 1188 is 0.012
Current timestep = 1189. State = [[-0.19101429  0.20823543]]. Action = [[ 0.07395162  0.04953984  0.         -0.11819547]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 1189 is [True, False, False, False, False, True]
State prediction error at timestep 1189 is 0.012
Current timestep = 1190. State = [[-0.18534152  0.20778643]]. Action = [[ 0.05872279 -0.03060351  0.         -0.9161533 ]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 1190 is [True, False, False, False, False, True]
State prediction error at timestep 1190 is 0.012
Current timestep = 1191. State = [[-0.18673019  0.20524968]]. Action = [[-0.09103979 -0.0294226   0.         -0.12942147]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 1191 is [True, False, False, False, False, True]
State prediction error at timestep 1191 is 0.012
Current timestep = 1192. State = [[-0.18822473  0.20440999]]. Action = [[ 0.00266577  0.00296424  0.         -0.46104348]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 1192 is [True, False, False, False, False, True]
State prediction error at timestep 1192 is 0.012
Current timestep = 1193. State = [[-0.19242746  0.2049693 ]]. Action = [[-0.09557049  0.01050104  0.         -0.47393084]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 1193 is [True, False, False, False, False, True]
State prediction error at timestep 1193 is 0.012
Current timestep = 1194. State = [[-0.19178459  0.20340902]]. Action = [[ 0.06762504 -0.03966258  0.          0.91911435]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 1194 is [True, False, False, False, False, True]
State prediction error at timestep 1194 is 0.012
Current timestep = 1195. State = [[-0.18555544  0.20007627]]. Action = [[ 0.08577811 -0.03811693  0.         -0.07189494]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 1195 is [True, False, False, False, False, True]
State prediction error at timestep 1195 is 0.012
Current timestep = 1196. State = [[-0.17811659  0.1979018 ]]. Action = [[ 0.09374674 -0.00563174  0.          0.63893235]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 1196 is [True, False, False, False, False, True]
State prediction error at timestep 1196 is 0.012
Current timestep = 1197. State = [[-0.17549941  0.19387928]]. Action = [[-0.01914985 -0.05912358  0.         -0.75572693]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 1197 is [True, False, False, False, False, True]
State prediction error at timestep 1197 is 0.012
Current timestep = 1198. State = [[-0.17300272  0.19473338]]. Action = [[ 0.04386733  0.06972534  0.         -0.2935878 ]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 1198 is [True, False, False, False, False, True]
State prediction error at timestep 1198 is 0.012
Current timestep = 1199. State = [[-0.17205118  0.19210984]]. Action = [[-0.01766267 -0.07638313  0.          0.57641435]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 1199 is [True, False, False, False, False, True]
State prediction error at timestep 1199 is 0.012
Current timestep = 1200. State = [[-0.17609693  0.18478842]]. Action = [[-0.09959625 -0.09183607  0.         -0.16662353]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 1200 is [True, False, False, False, False, True]
State prediction error at timestep 1200 is 0.012
Current timestep = 1201. State = [[-0.1741605   0.18176773]]. Action = [[ 0.08456298  0.01229987  0.         -0.8888753 ]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 1201 is [True, False, False, False, False, True]
State prediction error at timestep 1201 is 0.012
Current timestep = 1202. State = [[-0.17117225  0.18179782]]. Action = [[-0.00895485  0.01618524  0.          0.8810878 ]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 1202 is [True, False, False, False, False, True]
State prediction error at timestep 1202 is 0.012
Current timestep = 1203. State = [[-0.16831794  0.18562528]]. Action = [[ 0.04097611  0.08161896  0.         -0.28707886]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 1203 is [True, False, False, False, False, True]
State prediction error at timestep 1203 is 0.012
Current timestep = 1204. State = [[-0.16528918  0.19224326]]. Action = [[0.03083581 0.09143276 0.         0.10653341]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 1204 is [True, False, False, False, False, True]
State prediction error at timestep 1204 is 0.012
Current timestep = 1205. State = [[-0.16427141  0.19109769]]. Action = [[-0.00451723 -0.08156063  0.         -0.19108975]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 1205 is [True, False, False, False, False, True]
State prediction error at timestep 1205 is 0.012
Current timestep = 1206. State = [[-0.1605446   0.19013326]]. Action = [[0.06623238 0.02428977 0.         0.00244927]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 1206 is [True, False, False, False, False, True]
State prediction error at timestep 1206 is 0.012
Current timestep = 1207. State = [[-0.16110474  0.19185087]]. Action = [[-0.06203815  0.02042093  0.          0.8999798 ]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 1207 is [True, False, False, False, False, True]
State prediction error at timestep 1207 is 0.012
Current timestep = 1208. State = [[-0.16115609  0.19581403]]. Action = [[0.02685527 0.05834585 0.         0.02318394]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 1208 is [True, False, False, False, False, True]
State prediction error at timestep 1208 is 0.012
Current timestep = 1209. State = [[-0.15856722  0.19809288]]. Action = [[ 3.9757229e-02  2.3392588e-04  0.0000000e+00 -6.0654938e-01]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 1209 is [True, False, False, False, False, True]
State prediction error at timestep 1209 is 0.012
Current timestep = 1210. State = [[-0.16103716  0.201695  ]]. Action = [[-0.07771649  0.05678143  0.         -0.15295988]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 1210 is [True, False, False, False, False, True]
State prediction error at timestep 1210 is 0.012
Current timestep = 1211. State = [[-0.15912436  0.20680042]]. Action = [[0.09314633 0.05073106 0.         0.34403944]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 1211 is [True, False, False, False, False, True]
State prediction error at timestep 1211 is 0.012
Current timestep = 1212. State = [[-0.15919033  0.20938256]]. Action = [[-5.805701e-02 -5.090833e-04  0.000000e+00  6.297126e-01]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 1212 is [True, False, False, False, False, True]
State prediction error at timestep 1212 is 0.012
Current timestep = 1213. State = [[-0.1620235   0.21334422]]. Action = [[-0.02869364  0.05297277  0.          0.21037054]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 1213 is [True, False, False, False, False, True]
State prediction error at timestep 1213 is 0.012
Current timestep = 1214. State = [[-0.16442928  0.21972057]]. Action = [[-0.02567997  0.0677413   0.         -0.20250857]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 1214 is [True, False, False, False, False, True]
State prediction error at timestep 1214 is 0.012
Current timestep = 1215. State = [[-0.16314816  0.22554745]]. Action = [[ 0.05398668  0.04424935  0.         -0.3380177 ]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 1215 is [True, False, False, False, False, True]
State prediction error at timestep 1215 is 0.012
Current timestep = 1216. State = [[-0.15946326  0.22808781]]. Action = [[ 0.05903711 -0.00469751  0.         -0.28513652]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 1216 is [True, False, False, False, False, True]
State prediction error at timestep 1216 is 0.012
Current timestep = 1217. State = [[-0.16051577  0.23185849]]. Action = [[-0.05082498  0.05093341  0.         -0.47061217]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 1217 is [True, False, False, False, False, True]
State prediction error at timestep 1217 is 0.012
Current timestep = 1218. State = [[-0.16636664  0.2375387 ]]. Action = [[-0.08785949  0.05191519  0.         -0.91436535]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 1218 is [True, False, False, False, False, True]
State prediction error at timestep 1218 is 0.012
Current timestep = 1219. State = [[-0.16943291  0.23773654]]. Action = [[-0.00755008 -0.06515042  0.          0.35332608]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 1219 is [True, False, False, False, False, True]
State prediction error at timestep 1219 is 0.012
Current timestep = 1220. State = [[-0.16831563  0.2330899 ]]. Action = [[ 0.02832993 -0.08521143  0.          0.27900898]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 1220 is [True, False, False, False, False, True]
State prediction error at timestep 1220 is 0.012
Current timestep = 1221. State = [[-0.1643652   0.23074567]]. Action = [[ 0.06028869 -0.00800046  0.         -0.21834117]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 1221 is [True, False, False, False, False, True]
State prediction error at timestep 1221 is 0.012
Current timestep = 1222. State = [[-0.1658045  0.22704  ]]. Action = [[-0.07910683 -0.07261886  0.          0.13514662]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 1222 is [True, False, False, False, False, True]
State prediction error at timestep 1222 is 0.012
Current timestep = 1223. State = [[-0.16566537  0.22738257]]. Action = [[0.04408183 0.0508813  0.         0.12459254]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 1223 is [True, False, False, False, False, True]
State prediction error at timestep 1223 is 0.012
Current timestep = 1224. State = [[-0.16868755  0.22875515]]. Action = [[-0.0901975   0.00275391  0.         -0.6626741 ]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 1224 is [True, False, False, False, False, True]
State prediction error at timestep 1224 is 0.012
Current timestep = 1225. State = [[-0.16742559  0.23284025]]. Action = [[0.09334148 0.08266575 0.         0.18930972]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 1225 is [True, False, False, False, False, True]
State prediction error at timestep 1225 is 0.012
Current timestep = 1226. State = [[-0.16227321  0.23267895]]. Action = [[ 0.05846379 -0.04723733  0.          0.7570331 ]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 1226 is [True, False, False, False, False, True]
State prediction error at timestep 1226 is 0.012
Current timestep = 1227. State = [[-0.1577677   0.23301677]]. Action = [[0.05035827 0.03937294 0.         0.4539112 ]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 1227 is [True, False, False, False, False, True]
State prediction error at timestep 1227 is 0.012
Current timestep = 1228. State = [[-0.15747479  0.23183095]]. Action = [[-0.03471596 -0.04092092  0.         -0.4642864 ]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 1228 is [True, False, False, False, False, True]
State prediction error at timestep 1228 is 0.012
Current timestep = 1229. State = [[-0.15333976  0.22924891]]. Action = [[ 0.09199015 -0.02424978  0.         -0.3305667 ]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 1229 is [True, False, False, False, False, True]
State prediction error at timestep 1229 is 0.012
Current timestep = 1230. State = [[-0.14543827  0.22657296]]. Action = [[ 0.09354141 -0.02519792  0.          0.4106437 ]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 1230 is [True, False, False, False, False, True]
State prediction error at timestep 1230 is 0.012
Current timestep = 1231. State = [[-0.13767323  0.22590801]]. Action = [[ 0.08174067  0.021322    0.         -0.08690995]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 1231 is [True, False, False, False, False, True]
State prediction error at timestep 1231 is 0.012
Current timestep = 1232. State = [[-0.13711159  0.22626242]]. Action = [[-0.07076295  0.00997458  0.         -0.00348252]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 1232 is [True, False, False, False, False, True]
State prediction error at timestep 1232 is 0.012
Current timestep = 1233. State = [[-0.13829075  0.2259285 ]]. Action = [[-0.0100954 -0.0073192  0.        -0.6261109]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 1233 is [True, False, False, False, False, True]
State prediction error at timestep 1233 is 0.012
Current timestep = 1234. State = [[-0.13898438  0.22687684]]. Action = [[-0.02455227  0.02524509  0.          0.28205538]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 1234 is [True, False, False, False, False, True]
State prediction error at timestep 1234 is 0.012
Current timestep = 1235. State = [[-0.14238426  0.22879153]]. Action = [[-0.0709611   0.01935426  0.         -0.91200346]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 1235 is [True, False, False, False, False, True]
State prediction error at timestep 1235 is 0.012
Current timestep = 1236. State = [[-0.1398282   0.22523385]]. Action = [[ 0.08370306 -0.09014303  0.          0.2991233 ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 1236 is [True, False, False, False, False, True]
State prediction error at timestep 1236 is 0.012
Current timestep = 1237. State = [[-0.13890994  0.22744301]]. Action = [[-0.04094183  0.09802067  0.          0.69071627]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 1237 is [True, False, False, False, False, True]
State prediction error at timestep 1237 is 0.012
Current timestep = 1238. State = [[-0.14045592  0.23335734]]. Action = [[-0.01663379  0.0536755   0.         -0.42238128]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 1238 is [True, False, False, False, False, True]
State prediction error at timestep 1238 is 0.012
Current timestep = 1239. State = [[-0.14020011  0.23699778]]. Action = [[ 0.01612483  0.022464    0.         -0.9162301 ]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 1239 is [True, False, False, False, False, True]
State prediction error at timestep 1239 is 0.012
Current timestep = 1240. State = [[-0.14159524  0.23514192]]. Action = [[-0.03925073 -0.06965421  0.          0.7603221 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 1240 is [True, False, False, False, False, True]
State prediction error at timestep 1240 is 0.012
Current timestep = 1241. State = [[-0.1423986   0.23630673]]. Action = [[1.06073916e-04 4.79347333e-02 0.00000000e+00 2.44963169e-01]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 1241 is [True, False, False, False, False, True]
State prediction error at timestep 1241 is 0.012
Current timestep = 1242. State = [[-0.14406878  0.23434052]]. Action = [[-0.03576937 -0.0799831   0.          0.5712428 ]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 1242 is [True, False, False, False, False, True]
State prediction error at timestep 1242 is 0.012
Current timestep = 1243. State = [[-0.1404659   0.23462103]]. Action = [[0.09778795 0.04488686 0.         0.07393587]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 1243 is [True, False, False, False, False, True]
State prediction error at timestep 1243 is 0.012
Current timestep = 1244. State = [[-0.13705611  0.23933315]]. Action = [[ 0.0144956   0.06945687  0.         -0.4620999 ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 1244 is [True, False, False, False, False, True]
State prediction error at timestep 1244 is 0.012
Current timestep = 1245. State = [[-0.13658524  0.24440967]]. Action = [[-0.00182009  0.05339917  0.          0.10577023]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 1245 is [True, False, False, False, False, True]
State prediction error at timestep 1245 is 0.012
Current timestep = 1246. State = [[-0.1334253   0.24273145]]. Action = [[ 0.06283981 -0.07637893  0.         -0.01481837]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 1246 is [True, False, False, False, False, True]
State prediction error at timestep 1246 is 0.012
Current timestep = 1247. State = [[-0.13272046  0.2383326 ]]. Action = [[-0.03445781 -0.04990863  0.          0.04348361]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 1247 is [True, False, False, False, False, True]
State prediction error at timestep 1247 is 0.012
Current timestep = 1248. State = [[-0.13547076  0.24115486]]. Action = [[-0.05420442  0.08303329  0.         -0.2788546 ]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 1248 is [True, False, False, False, False, True]
State prediction error at timestep 1248 is 0.012
Current timestep = 1249. State = [[-0.13631238  0.24262986]]. Action = [[ 0.00663068 -0.02776474  0.          0.586884  ]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 1249 is [True, False, False, False, False, True]
State prediction error at timestep 1249 is 0.012
Current timestep = 1250. State = [[-0.13724248  0.2430866 ]]. Action = [[-0.02880976  0.01401726  0.          0.2156806 ]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 1250 is [True, False, False, False, False, True]
State prediction error at timestep 1250 is 0.012
Current timestep = 1251. State = [[-0.1366386   0.24421789]]. Action = [[ 0.02490727  0.007198    0.         -0.7663365 ]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 1251 is [True, False, False, False, False, True]
State prediction error at timestep 1251 is 0.012
Current timestep = 1252. State = [[-0.13439287  0.24098104]]. Action = [[ 0.029343   -0.07320846  0.          0.817893  ]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 1252 is [True, False, False, False, False, True]
State prediction error at timestep 1252 is 0.012
Current timestep = 1253. State = [[-0.13644657  0.23473611]]. Action = [[-0.07319859 -0.08267252  0.          0.10832012]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 1253 is [True, False, False, False, False, True]
State prediction error at timestep 1253 is 0.012
Current timestep = 1254. State = [[-0.13742346  0.2282944 ]]. Action = [[ 0.00463655 -0.07427482  0.         -0.38514292]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 1254 is [True, False, False, False, False, True]
State prediction error at timestep 1254 is 0.012
Current timestep = 1255. State = [[-0.14042488  0.22897571]]. Action = [[-0.07282946  0.07198533  0.         -0.30292296]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 1255 is [True, False, False, False, False, True]
State prediction error at timestep 1255 is 0.012
Current timestep = 1256. State = [[-0.14233947  0.22705261]]. Action = [[ 3.8280338e-04 -7.0898637e-02  0.0000000e+00 -5.2204114e-01]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 1256 is [True, False, False, False, False, True]
State prediction error at timestep 1256 is 0.012
Current timestep = 1257. State = [[-0.14474659  0.2205805 ]]. Action = [[-0.05022077 -0.07926138  0.          0.06362092]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 1257 is [True, False, False, False, False, True]
State prediction error at timestep 1257 is 0.012
Current timestep = 1258. State = [[-0.14283131  0.21539992]]. Action = [[ 0.06914913 -0.03651958  0.          0.85710466]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 1258 is [True, False, False, False, False, True]
State prediction error at timestep 1258 is 0.012
Current timestep = 1259. State = [[-0.14278993  0.21220373]]. Action = [[-0.03840571 -0.01443715  0.         -0.77575076]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 1259 is [True, False, False, False, False, True]
State prediction error at timestep 1259 is 0.012
Current timestep = 1260. State = [[-0.14318873  0.21406582]]. Action = [[ 0.01580974  0.07111905  0.         -0.24379146]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 1260 is [True, False, False, False, False, True]
State prediction error at timestep 1260 is 0.012
Current timestep = 1261. State = [[-0.1436311   0.21336141]]. Action = [[-0.00546849 -0.03499616  0.          0.60538375]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 1261 is [True, False, False, False, False, True]
State prediction error at timestep 1261 is 0.012
Current timestep = 1262. State = [[-0.14887585  0.2115972 ]]. Action = [[-0.09687138 -0.00242212  0.          0.18789506]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 1262 is [True, False, False, False, False, True]
State prediction error at timestep 1262 is 0.012
Current timestep = 1263. State = [[-0.15695289  0.21612702]]. Action = [[-0.09684726  0.09870514  0.         -0.07440323]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 1263 is [True, False, False, False, False, True]
State prediction error at timestep 1263 is 0.012
Current timestep = 1264. State = [[-0.16152066  0.21973224]]. Action = [[-0.00762248  0.01003029  0.          0.13596094]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 1264 is [True, False, False, False, False, True]
State prediction error at timestep 1264 is 0.012
Current timestep = 1265. State = [[-0.16525282  0.22535636]]. Action = [[-0.03276556  0.09510132  0.         -0.8772502 ]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 1265 is [True, False, False, False, False, True]
State prediction error at timestep 1265 is 0.012
Current timestep = 1266. State = [[-0.17069998  0.23212576]]. Action = [[-0.04753257  0.06360576  0.          0.7481885 ]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 1266 is [True, False, False, False, False, True]
State prediction error at timestep 1266 is 0.012
Current timestep = 1267. State = [[-0.17407122  0.23647568]]. Action = [[0.00724217 0.0251739  0.         0.6456461 ]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 1267 is [True, False, False, False, False, True]
State prediction error at timestep 1267 is 0.012
Current timestep = 1268. State = [[-0.17369804  0.23418848]]. Action = [[ 0.0498211  -0.08246744  0.         -0.7300975 ]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 1268 is [True, False, False, False, False, True]
State prediction error at timestep 1268 is 0.012
Current timestep = 1269. State = [[-0.1760556   0.23349798]]. Action = [[-0.04378406  0.02083113  0.          0.63020027]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 1269 is [True, False, False, False, False, True]
State prediction error at timestep 1269 is 0.012
Current timestep = 1270. State = [[-0.17922439  0.23788713]]. Action = [[-0.01027548  0.06558628  0.         -0.5775497 ]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 1270 is [True, False, False, False, False, True]
State prediction error at timestep 1270 is 0.012
Current timestep = 1271. State = [[-0.17710496  0.24491967]]. Action = [[0.08828371 0.09105628 0.         0.57314944]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 1271 is [True, False, False, False, False, True]
State prediction error at timestep 1271 is 0.012
Current timestep = 1272. State = [[-0.17346442  0.24651538]]. Action = [[ 0.05755972 -0.03159457  0.         -0.2901944 ]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 1272 is [True, False, False, False, False, True]
State prediction error at timestep 1272 is 0.012
Current timestep = 1273. State = [[-0.17181279  0.24765646]]. Action = [[0.01544635 0.03124531 0.         0.08981562]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 1273 is [True, False, False, False, False, True]
State prediction error at timestep 1273 is 0.012
Current timestep = 1274. State = [[-0.17014919  0.25342113]]. Action = [[0.03650864 0.09022399 0.         0.6758778 ]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 1274 is [True, False, False, False, False, True]
State prediction error at timestep 1274 is 0.012
Current timestep = 1275. State = [[-0.17380416  0.2549749 ]]. Action = [[-0.09608255 -0.0393926   0.         -0.08942634]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 1275 is [True, False, False, False, False, True]
State prediction error at timestep 1275 is 0.012
Current timestep = 1276. State = [[-0.17680906  0.25570658]]. Action = [[-0.00229061  0.01370634  0.         -0.69039005]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 1276 is [True, False, False, False, False, True]
State prediction error at timestep 1276 is 0.012
Current timestep = 1277. State = [[-0.17923957  0.25270864]]. Action = [[-0.04168146 -0.08636077  0.         -0.38025975]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 1277 is [True, False, False, False, False, True]
State prediction error at timestep 1277 is 0.012
Current timestep = 1278. State = [[-0.1784711  0.2548038]]. Action = [[0.04249727 0.07971825 0.         0.16778636]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 1278 is [True, False, False, False, False, True]
State prediction error at timestep 1278 is 0.012
Current timestep = 1279. State = [[-0.17685452  0.25975642]]. Action = [[0.01503237 0.04534595 0.         0.07079756]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 1279 is [True, False, False, False, False, True]
State prediction error at timestep 1279 is 0.012
Current timestep = 1280. State = [[-0.17968872  0.2646307 ]]. Action = [[-0.06345694  0.054404    0.          0.36385715]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 1280 is [True, False, False, False, False, True]
State prediction error at timestep 1280 is 0.012
Current timestep = 1281. State = [[-0.17861375  0.2627984 ]]. Action = [[ 0.05955534 -0.0890491   0.         -0.0775497 ]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 1281 is [True, False, False, False, False, True]
State prediction error at timestep 1281 is 0.012
Current timestep = 1282. State = [[-0.17486471  0.25735605]]. Action = [[ 0.03682124 -0.06761397  0.         -0.0549354 ]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 1282 is [True, False, False, False, False, True]
State prediction error at timestep 1282 is 0.012
Current timestep = 1283. State = [[-0.17373264  0.25792554]]. Action = [[-0.01118229  0.05323967  0.         -0.0306347 ]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 1283 is [True, False, False, False, False, True]
State prediction error at timestep 1283 is 0.012
Current timestep = 1284. State = [[-0.17797814  0.2548131 ]]. Action = [[-0.09789691 -0.09768339  0.         -0.636119  ]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 1284 is [True, False, False, False, False, True]
State prediction error at timestep 1284 is 0.012
Current timestep = 1285. State = [[-0.18062207  0.2500489 ]]. Action = [[-0.01374605 -0.04554693  0.         -0.97320706]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 1285 is [True, False, False, False, False, True]
State prediction error at timestep 1285 is 0.012
Current timestep = 1286. State = [[-0.1814383   0.24763472]]. Action = [[-0.01542749 -0.01510416  0.         -0.42325926]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 1286 is [True, False, False, False, False, True]
State prediction error at timestep 1286 is 0.012
Current timestep = 1287. State = [[-0.18048225  0.24389924]]. Action = [[ 0.02258272 -0.05481132  0.         -0.27124524]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 1287 is [True, False, False, False, False, True]
State prediction error at timestep 1287 is 0.012
Current timestep = 1288. State = [[-0.17799203  0.24224368]]. Action = [[0.03432531 0.01719667 0.         0.37160897]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 1288 is [True, False, False, False, False, True]
State prediction error at timestep 1288 is 0.012
Current timestep = 1289. State = [[-0.17815845  0.24384941]]. Action = [[-0.02166849  0.04372635  0.         -0.24219596]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 1289 is [True, False, False, False, False, True]
State prediction error at timestep 1289 is 0.012
Current timestep = 1290. State = [[-0.18277445  0.2422686 ]]. Action = [[-0.07992344 -0.04617151  0.         -0.6550987 ]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 1290 is [True, False, False, False, False, True]
State prediction error at timestep 1290 is 0.012
Current timestep = 1291. State = [[-0.18567124  0.23698889]]. Action = [[-0.01195684 -0.07301186  0.         -0.3404389 ]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 1291 is [True, False, False, False, False, True]
State prediction error at timestep 1291 is 0.012
Current timestep = 1292. State = [[-0.18707876  0.23732282]]. Action = [[-0.01387769  0.06345024  0.         -0.9780128 ]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 1292 is [True, False, False, False, False, True]
State prediction error at timestep 1292 is 0.012
Current timestep = 1293. State = [[-0.1877999   0.23448962]]. Action = [[ 0.00583273 -0.08065763  0.         -0.5320191 ]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 1293 is [True, False, False, False, False, True]
State prediction error at timestep 1293 is 0.012
Current timestep = 1294. State = [[-0.18842486  0.23189332]]. Action = [[-0.00652527  0.00688358  0.          0.7329016 ]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 1294 is [True, False, False, False, False, True]
State prediction error at timestep 1294 is 0.012
Current timestep = 1295. State = [[-0.18733454  0.23343123]]. Action = [[0.04015943 0.04472802 0.         0.9179089 ]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 1295 is [True, False, False, False, False, True]
State prediction error at timestep 1295 is 0.012
Current timestep = 1296. State = [[-0.1823413   0.23347336]]. Action = [[ 0.09997737 -0.00802752  0.         -0.48044074]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 1296 is [True, False, False, False, False, True]
State prediction error at timestep 1296 is 0.012
Current timestep = 1297. State = [[-0.17762995  0.2280247 ]]. Action = [[ 0.05091124 -0.08490042  0.         -0.8003256 ]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 1297 is [True, False, False, False, False, True]
State prediction error at timestep 1297 is 0.012
Current timestep = 1298. State = [[-0.17123827  0.22110255]]. Action = [[ 0.0967493  -0.06305755  0.         -0.78788316]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 1298 is [True, False, False, False, False, True]
State prediction error at timestep 1298 is 0.012
Current timestep = 1299. State = [[-0.16655853  0.21636344]]. Action = [[ 0.02763606 -0.0231946   0.          0.00145566]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 1299 is [True, False, False, False, False, True]
State prediction error at timestep 1299 is 0.012
Current timestep = 1300. State = [[-0.16608344  0.21388872]]. Action = [[-0.02770929 -0.00337014  0.          0.48922706]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 1300 is [True, False, False, False, False, True]
State prediction error at timestep 1300 is 0.012
Current timestep = 1301. State = [[-0.1619948   0.21153548]]. Action = [[ 0.0797228  -0.01532812  0.         -0.7819587 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 1301 is [True, False, False, False, False, True]
State prediction error at timestep 1301 is 0.012
Current timestep = 1302. State = [[-0.16284922  0.2121155 ]]. Action = [[-0.08861167  0.04729845  0.         -0.2699204 ]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 1302 is [True, False, False, False, False, True]
State prediction error at timestep 1302 is 0.012
Current timestep = 1303. State = [[-0.16512966  0.21267803]]. Action = [[-0.01274838 -0.00063702  0.         -0.6238828 ]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 1303 is [True, False, False, False, False, True]
State prediction error at timestep 1303 is 0.012
Current timestep = 1304. State = [[-0.1643406   0.21084616]]. Action = [[ 0.01821826 -0.02753288  0.          0.1119504 ]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 1304 is [True, False, False, False, False, True]
State prediction error at timestep 1304 is 0.012
Current timestep = 1305. State = [[-0.15995225  0.20939854]]. Action = [[ 0.07443871 -0.00161     0.         -0.6155399 ]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 1305 is [True, False, False, False, False, True]
State prediction error at timestep 1305 is 0.012
Current timestep = 1306. State = [[-0.16112265  0.20874974]]. Action = [[-0.07887197 -0.00196435  0.          0.7709186 ]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 1306 is [True, False, False, False, False, True]
State prediction error at timestep 1306 is 0.012
Current timestep = 1307. State = [[-0.16284324  0.21345928]]. Action = [[0.00939882 0.09845873 0.         0.48650444]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 1307 is [True, False, False, False, False, True]
State prediction error at timestep 1307 is 0.012
Current timestep = 1308. State = [[-0.16547322  0.21826054]]. Action = [[-0.045295    0.03380703  0.         -0.09096175]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 1308 is [True, False, False, False, False, True]
State prediction error at timestep 1308 is 0.012
Current timestep = 1309. State = [[-0.16932611  0.21591586]]. Action = [[-0.04565299 -0.08308155  0.         -0.5611831 ]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 1309 is [True, False, False, False, False, True]
State prediction error at timestep 1309 is 0.012
Current timestep = 1310. State = [[-0.1741706   0.21326572]]. Action = [[-0.0706913  -0.01900997  0.          0.5172626 ]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 1310 is [True, False, False, False, False, True]
State prediction error at timestep 1310 is 0.012
Current timestep = 1311. State = [[-0.17377272  0.21463162]]. Action = [[ 0.06097292  0.03252973  0.         -0.91039985]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 1311 is [True, False, False, False, False, True]
State prediction error at timestep 1311 is 0.012
Current timestep = 1312. State = [[-0.17419067  0.21880218]]. Action = [[-0.03092336  0.0588269   0.          0.7023779 ]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 1312 is [True, False, False, False, False, True]
State prediction error at timestep 1312 is 0.012
Current timestep = 1313. State = [[-0.17365915  0.2248312 ]]. Action = [[0.04191097 0.0749472  0.         0.00772476]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 1313 is [True, False, False, False, False, True]
State prediction error at timestep 1313 is 0.012
Current timestep = 1314. State = [[-0.1760899  0.228916 ]]. Action = [[-0.05562146  0.02166436  0.          0.8825166 ]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 1314 is [True, False, False, False, False, True]
State prediction error at timestep 1314 is 0.012
Current timestep = 1315. State = [[-0.17501383  0.2329717 ]]. Action = [[0.0749382  0.04915487 0.         0.60208917]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 1315 is [True, False, False, False, False, True]
State prediction error at timestep 1315 is 0.012
Current timestep = 1316. State = [[-0.17738096  0.23269688]]. Action = [[-0.08369975 -0.05499716  0.         -0.21673805]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 1316 is [True, False, False, False, False, True]
State prediction error at timestep 1316 is 0.012
Current timestep = 1317. State = [[-0.17646332  0.22737202]]. Action = [[ 0.07942948 -0.09177212  0.          0.18080604]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 1317 is [True, False, False, False, False, True]
State prediction error at timestep 1317 is 0.012
Current timestep = 1318. State = [[-0.1747026   0.22754493]]. Action = [[-0.00081383  0.05638101  0.          0.48095524]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 1318 is [True, False, False, False, False, True]
State prediction error at timestep 1318 is 0.012
Current timestep = 1319. State = [[-0.17026837  0.23262829]]. Action = [[ 0.09910097  0.07120479  0.         -0.7963705 ]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 1319 is [True, False, False, False, False, True]
State prediction error at timestep 1319 is 0.012
Current timestep = 1320. State = [[-0.16820312  0.23298408]]. Action = [[-0.01120223 -0.03655887  0.         -0.808341  ]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 1320 is [True, False, False, False, False, True]
State prediction error at timestep 1320 is 0.012
Current timestep = 1321. State = [[-0.16707386  0.23331317]]. Action = [[0.02612198 0.02503137 0.         0.93912196]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 1321 is [True, False, False, False, False, True]
State prediction error at timestep 1321 is 0.012
Current timestep = 1322. State = [[-0.16966748  0.23404598]]. Action = [[-0.07283255 -0.00131695  0.         -0.53354377]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 1322 is [True, False, False, False, False, True]
State prediction error at timestep 1322 is 0.012
Current timestep = 1323. State = [[-0.16894585  0.23222618]]. Action = [[ 0.04957988 -0.04208168  0.         -0.6401779 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 1323 is [True, False, False, False, False, True]
State prediction error at timestep 1323 is 0.012
Current timestep = 1324. State = [[-0.16585813  0.23220028]]. Action = [[ 0.02919588  0.02487036  0.         -0.59076774]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 1324 is [True, False, False, False, False, True]
State prediction error at timestep 1324 is 0.012
Current timestep = 1325. State = [[-0.16884847  0.23722836]]. Action = [[-0.08679947  0.0853573   0.          0.06811118]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 1325 is [True, False, False, False, False, True]
State prediction error at timestep 1325 is 0.012
Current timestep = 1326. State = [[-0.17441007  0.23571572]]. Action = [[-0.07224891 -0.09578875  0.         -0.30648577]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 1326 is [True, False, False, False, False, True]
State prediction error at timestep 1326 is 0.012
Current timestep = 1327. State = [[-0.17447367  0.23527691]]. Action = [[ 0.0399142   0.03360719  0.         -0.58971083]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 1327 is [True, False, False, False, False, True]
State prediction error at timestep 1327 is 0.012
Current timestep = 1328. State = [[-0.17309298  0.23560715]]. Action = [[ 0.00411783 -0.01662638  0.         -0.2322911 ]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 1328 is [True, False, False, False, False, True]
State prediction error at timestep 1328 is 0.012
Current timestep = 1329. State = [[-0.16890912  0.2369728 ]]. Action = [[0.08053821 0.03413849 0.         0.01439953]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 1329 is [True, False, False, False, False, True]
State prediction error at timestep 1329 is 0.012
Current timestep = 1330. State = [[-0.16548882  0.23423932]]. Action = [[ 0.02113191 -0.07174744  0.         -0.5074935 ]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 1330 is [True, False, False, False, False, True]
State prediction error at timestep 1330 is 0.012
Current timestep = 1331. State = [[-0.16506557  0.23476446]]. Action = [[-0.01524437  0.05579355  0.          0.6388998 ]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 1331 is [True, False, False, False, False, True]
State prediction error at timestep 1331 is 0.012
Current timestep = 1332. State = [[-0.16740905  0.232685  ]]. Action = [[-0.04965917 -0.07290787  0.         -0.8999266 ]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 1332 is [True, False, False, False, False, True]
State prediction error at timestep 1332 is 0.012
Current timestep = 1333. State = [[-0.16502433  0.23393688]]. Action = [[ 0.07300488  0.06838811  0.         -0.33931935]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 1333 is [True, False, False, False, False, True]
State prediction error at timestep 1333 is 0.012
Current timestep = 1334. State = [[-0.1647231  0.2365944]]. Action = [[-0.0434983   0.01641588  0.          0.97703195]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 1334 is [True, False, False, False, False, True]
State prediction error at timestep 1334 is 0.012
Current timestep = 1335. State = [[-0.16710094  0.23464993]]. Action = [[-0.03678199 -0.05641267  0.          0.09468031]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 1335 is [True, False, False, False, False, True]
State prediction error at timestep 1335 is 0.012
Current timestep = 1336. State = [[-0.16435371  0.23074664]]. Action = [[ 0.06735697 -0.04780806  0.          0.24956536]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 1336 is [True, False, False, False, False, True]
State prediction error at timestep 1336 is 0.012
Current timestep = 1337. State = [[-0.15757206  0.22788993]]. Action = [[ 0.0907458  -0.01774871  0.          0.2416246 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 1337 is [True, False, False, False, False, True]
State prediction error at timestep 1337 is 0.012
Current timestep = 1338. State = [[-0.15456033  0.22991186]]. Action = [[-0.00278609  0.06738143  0.         -0.78855395]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 1338 is [True, False, False, False, False, True]
State prediction error at timestep 1338 is 0.012
Current timestep = 1339. State = [[-0.15140706  0.23373857]]. Action = [[ 0.05631056  0.0480931   0.         -0.2902434 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 1339 is [True, False, False, False, False, True]
State prediction error at timestep 1339 is 0.012
Current timestep = 1340. State = [[-0.14612536  0.2364202 ]]. Action = [[ 0.0711038   0.03206705  0.         -0.8651988 ]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 1340 is [True, False, False, False, False, True]
State prediction error at timestep 1340 is 0.012
Current timestep = 1341. State = [[-0.14470135  0.23602514]]. Action = [[-0.02430455 -0.02380019  0.          0.04775751]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 1341 is [True, False, False, False, False, True]
State prediction error at timestep 1341 is 0.012
Current timestep = 1342. State = [[-0.14619428  0.2372761 ]]. Action = [[-0.03380743  0.03583657  0.         -0.08299869]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 1342 is [True, False, False, False, False, True]
State prediction error at timestep 1342 is 0.012
Current timestep = 1343. State = [[-0.14569636  0.23979001]]. Action = [[0.01879345 0.02275255 0.         0.6145762 ]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 1343 is [True, False, False, False, False, True]
State prediction error at timestep 1343 is 0.012
Current timestep = 1344. State = [[-0.14280473  0.23920064]]. Action = [[ 0.03887411 -0.03411108  0.         -0.538831  ]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 1344 is [True, False, False, False, False, True]
State prediction error at timestep 1344 is 0.012
Current timestep = 1345. State = [[-0.1364532  0.2400793]]. Action = [[ 0.09658834  0.03425591  0.         -0.01301718]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 1345 is [True, False, False, False, False, True]
State prediction error at timestep 1345 is 0.012
Current timestep = 1346. State = [[-0.13542911  0.24415678]]. Action = [[-0.04868164  0.06049215  0.          0.08457184]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 1346 is [True, False, False, False, False, True]
State prediction error at timestep 1346 is 0.012
Current timestep = 1347. State = [[-0.13341682  0.24934308]]. Action = [[ 0.06280153  0.05865633  0.         -0.12578547]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 1347 is [True, False, False, False, False, True]
State prediction error at timestep 1347 is 0.012
Current timestep = 1348. State = [[-0.13353032  0.25332665]]. Action = [[-0.04076494  0.03063308  0.          0.29916036]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 1348 is [True, False, False, False, False, True]
State prediction error at timestep 1348 is 0.012
Current timestep = 1349. State = [[-0.1379788  0.2509957]]. Action = [[-0.08174161 -0.09009288  0.         -0.87684935]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 1349 is [True, False, False, False, False, True]
State prediction error at timestep 1349 is 0.012
Current timestep = 1350. State = [[-0.13877757  0.25114444]]. Action = [[0.01785628 0.03133153 0.         0.8024553 ]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 1350 is [True, False, False, False, False, True]
State prediction error at timestep 1350 is 0.012
Current timestep = 1351. State = [[-0.13750531  0.25247875]]. Action = [[ 0.00665189 -0.00713105  0.         -0.84877074]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 1351 is [True, False, False, False, False, True]
State prediction error at timestep 1351 is 0.012
Current timestep = 1352. State = [[-0.13925561  0.24903278]]. Action = [[-0.05530647 -0.08262116  0.         -0.2042833 ]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 1352 is [True, False, False, False, False, True]
State prediction error at timestep 1352 is 0.012
Current timestep = 1353. State = [[-0.13959448  0.24926892]]. Action = [[ 0.00835256  0.04096492  0.         -0.4116683 ]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 1353 is [True, False, False, False, False, True]
State prediction error at timestep 1353 is 0.012
Current timestep = 1354. State = [[-0.13942708  0.24651334]]. Action = [[-0.011365   -0.08476003  0.          0.97967863]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 1354 is [True, False, False, False, False, True]
State prediction error at timestep 1354 is 0.012
Current timestep = 1355. State = [[-0.14300711  0.242577  ]]. Action = [[-0.08344683 -0.0352092   0.         -0.98970044]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 1355 is [True, False, False, False, False, True]
State prediction error at timestep 1355 is 0.012
Current timestep = 1356. State = [[-0.14722542  0.24515985]]. Action = [[-0.04790625  0.07091843  0.          0.39780867]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 1356 is [True, False, False, False, False, True]
State prediction error at timestep 1356 is 0.012
Current timestep = 1357. State = [[-0.15185076  0.24397983]]. Action = [[-0.06255282 -0.07034178  0.         -0.75059944]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 1357 is [True, False, False, False, False, True]
State prediction error at timestep 1357 is 0.012
Current timestep = 1358. State = [[-0.15510777  0.24635752]]. Action = [[-0.02210721  0.08252635  0.          0.51232433]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 1358 is [True, False, False, False, False, True]
State prediction error at timestep 1358 is 0.012
Current timestep = 1359. State = [[-0.1531831  0.2526882]]. Action = [[0.08325567 0.07909279 0.         0.81603694]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 1359 is [True, False, False, False, False, True]
State prediction error at timestep 1359 is 0.012
Current timestep = 1360. State = [[-0.15490976  0.25421408]]. Action = [[-0.05720695 -0.02242444  0.          0.9793464 ]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 1360 is [True, False, False, False, False, True]
State prediction error at timestep 1360 is 0.012
Current timestep = 1361. State = [[-0.1596527   0.25739658]]. Action = [[-0.03438852  0.06808115  0.          0.55365014]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 1361 is [True, False, False, False, False, True]
State prediction error at timestep 1361 is 0.012
Current timestep = 1362. State = [[-0.16139805  0.25639418]]. Action = [[ 0.02037891 -0.06727406  0.         -0.6228031 ]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 1362 is [True, False, False, False, False, True]
State prediction error at timestep 1362 is 0.012
Current timestep = 1363. State = [[-0.16572279  0.2539598 ]]. Action = [[-0.07310649 -0.01718231  0.          0.94984305]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 1363 is [True, False, False, False, False, True]
State prediction error at timestep 1363 is 0.012
Current timestep = 1364. State = [[-0.16977482  0.2491312 ]]. Action = [[-0.02082989 -0.09030687  0.         -0.8478613 ]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 1364 is [True, False, False, False, False, True]
State prediction error at timestep 1364 is 0.012
Current timestep = 1365. State = [[-0.16981511  0.24513954]]. Action = [[ 0.02976107 -0.02290957  0.         -0.8185639 ]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 1365 is [True, False, False, False, False, True]
State prediction error at timestep 1365 is 0.012
Current timestep = 1366. State = [[-0.17279986  0.24815525]]. Action = [[-0.05737656  0.08766691  0.          0.61541736]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 1366 is [True, False, False, False, False, True]
State prediction error at timestep 1366 is 0.012
Current timestep = 1367. State = [[-0.17637499  0.24918593]]. Action = [[-0.01633304 -0.02455796  0.         -0.2381354 ]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 1367 is [True, False, False, False, False, True]
State prediction error at timestep 1367 is 0.012
Current timestep = 1368. State = [[-0.17830147  0.24353573]]. Action = [[-0.00964285 -0.09709199  0.          0.8624433 ]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 1368 is [True, False, False, False, False, True]
State prediction error at timestep 1368 is 0.012
Current timestep = 1369. State = [[-0.18362364  0.24194998]]. Action = [[-0.08953457  0.03362932  0.         -0.7963303 ]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 1369 is [True, False, False, False, False, True]
State prediction error at timestep 1369 is 0.012
Current timestep = 1370. State = [[-0.18411759  0.24372464]]. Action = [[ 0.06735205  0.02731404  0.         -0.9273777 ]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 1370 is [True, False, False, False, False, True]
State prediction error at timestep 1370 is 0.012
Current timestep = 1371. State = [[-0.1818712   0.24098645]]. Action = [[ 0.02799638 -0.06080486  0.          0.4061731 ]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 1371 is [True, False, False, False, False, True]
State prediction error at timestep 1371 is 0.012
Current timestep = 1372. State = [[-0.17714816  0.23538387]]. Action = [[ 0.0873739  -0.06073068  0.         -0.3770007 ]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 1372 is [True, False, False, False, False, True]
State prediction error at timestep 1372 is 0.012
Current timestep = 1373. State = [[-0.17682582  0.23112044]]. Action = [[-0.04606115 -0.02598111  0.         -0.1553638 ]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 1373 is [True, False, False, False, False, True]
State prediction error at timestep 1373 is 0.012
Current timestep = 1374. State = [[-0.18207376  0.22566082]]. Action = [[-0.08933879 -0.07483695  0.          0.52405   ]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 1374 is [True, False, False, False, False, True]
State prediction error at timestep 1374 is 0.012
Current timestep = 1375. State = [[-0.1841934   0.22094667]]. Action = [[ 0.00362815 -0.03203637  0.         -0.4788034 ]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 1375 is [True, False, False, False, False, True]
State prediction error at timestep 1375 is 0.012
Current timestep = 1376. State = [[-0.18520065  0.21423863]]. Action = [[-0.02286934 -0.08983714  0.          0.28832114]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 1376 is [True, False, False, False, False, True]
State prediction error at timestep 1376 is 0.012
Current timestep = 1377. State = [[-0.18760452  0.21131784]]. Action = [[-0.03891463  0.02126281  0.         -0.5160359 ]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 1377 is [True, False, False, False, False, True]
State prediction error at timestep 1377 is 0.012
Current timestep = 1378. State = [[-0.1925153   0.21382575]]. Action = [[-0.07092306  0.06357951  0.          0.75354576]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 1378 is [True, False, False, False, False, True]
State prediction error at timestep 1378 is 0.012
Current timestep = 1379. State = [[-0.19972835  0.2119204 ]]. Action = [[-0.09270854 -0.06346292  0.         -0.05879569]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 1379 is [True, False, False, False, False, True]
State prediction error at timestep 1379 is 0.012
Current timestep = 1380. State = [[-0.20338723  0.20783022]]. Action = [[-0.00398587 -0.03687873  0.         -0.8868394 ]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 1380 is [True, False, False, False, False, True]
State prediction error at timestep 1380 is 0.012
Current timestep = 1381. State = [[-0.20724745  0.20540014]]. Action = [[-0.05233305 -0.01223671  0.         -0.87840056]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 1381 is [True, False, False, False, False, True]
State prediction error at timestep 1381 is 0.012
Current timestep = 1382. State = [[-0.21109293  0.2083503 ]]. Action = [[-0.01906404  0.07875984  0.          0.9819441 ]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 1382 is [True, False, False, False, False, True]
State prediction error at timestep 1382 is 0.012
Current timestep = 1383. State = [[-0.21628997  0.21151647]]. Action = [[-0.0536954   0.02373918  0.          0.9408665 ]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 1383 is [True, False, False, False, False, True]
State prediction error at timestep 1383 is 0.012
Current timestep = 1384. State = [[-0.22000873  0.21200211]]. Action = [[-0.00243955 -0.0058137   0.          0.5666753 ]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 1384 is [True, False, False, False, False, True]
State prediction error at timestep 1384 is 0.012
Current timestep = 1385. State = [[-0.22155285  0.20784864]]. Action = [[ 0.01184162 -0.07826535  0.          0.20017159]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 1385 is [True, False, False, False, False, True]
State prediction error at timestep 1385 is 0.012
Current timestep = 1386. State = [[-0.22659154  0.20112027]]. Action = [[-0.08022024 -0.08339234  0.         -0.8977506 ]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 1386 is [True, False, False, False, False, True]
State prediction error at timestep 1386 is 0.012
Current timestep = 1387. State = [[-0.23423092  0.19429386]]. Action = [[-0.08799522 -0.07842645  0.         -0.9963842 ]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 1387 is [True, False, False, False, False, True]
State prediction error at timestep 1387 is 0.012
Current timestep = 1388. State = [[-0.2340231  0.1908163]]. Action = [[ 0.09249536 -0.0043783   0.          0.9168606 ]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 1388 is [True, False, False, False, False, True]
State prediction error at timestep 1388 is 0.012
Current timestep = 1389. State = [[-0.2316154   0.18967272]]. Action = [[0.01715549 0.00634722 0.         0.79766417]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 1389 is [True, False, False, False, False, True]
State prediction error at timestep 1389 is 0.012
Current timestep = 1390. State = [[-0.23589762  0.18795949]]. Action = [[-0.09060555 -0.01647343  0.          0.5601361 ]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 1390 is [True, False, False, False, False, True]
State prediction error at timestep 1390 is 0.012
Current timestep = 1391. State = [[-0.23579025  0.1844442 ]]. Action = [[ 0.07214504 -0.04087989  0.          0.16784978]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 1391 is [True, False, False, False, False, True]
State prediction error at timestep 1391 is 0.012
Current timestep = 1392. State = [[-0.23366524  0.17792685]]. Action = [[ 0.01139067 -0.08105387  0.          0.42559135]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 1392 is [True, False, False, False, False, True]
State prediction error at timestep 1392 is 0.012
Current timestep = 1393. State = [[-0.23465158  0.1755569 ]]. Action = [[-0.02857415  0.02817435  0.         -0.32955217]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 1393 is [True, False, False, False, False, True]
State prediction error at timestep 1393 is 0.012
Current timestep = 1394. State = [[-0.23560163  0.17941612]]. Action = [[0.00376779 0.08668541 0.         0.6636691 ]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 1394 is [True, False, False, False, False, True]
State prediction error at timestep 1394 is 0.012
Current timestep = 1395. State = [[-0.23684743  0.18589877]]. Action = [[-0.00889074  0.09204846  0.         -0.04044628]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 1395 is [True, False, False, False, False, True]
State prediction error at timestep 1395 is 0.012
Current timestep = 1396. State = [[-0.23595195  0.18848464]]. Action = [[ 0.04577649 -0.00168366  0.         -0.87016034]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 1396 is [True, False, False, False, False, True]
State prediction error at timestep 1396 is 0.012
Current timestep = 1397. State = [[-0.23260263  0.18771942]]. Action = [[ 0.06131121 -0.0169672   0.          0.4939363 ]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 1397 is [True, False, False, False, False, True]
State prediction error at timestep 1397 is 0.012
Current timestep = 1398. State = [[-0.22904871  0.18864506]]. Action = [[ 0.04881533  0.02942049  0.         -0.2559666 ]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 1398 is [True, False, False, False, False, True]
State prediction error at timestep 1398 is 0.012
Current timestep = 1399. State = [[-0.22708645  0.18557987]]. Action = [[ 0.01431741 -0.07884362  0.         -0.7817924 ]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 1399 is [True, False, False, False, False, True]
State prediction error at timestep 1399 is 0.012
Current timestep = 1400. State = [[-0.22511524  0.17992495]]. Action = [[ 0.02107056 -0.06649355  0.          0.8758739 ]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 1400 is [True, False, False, False, False, True]
State prediction error at timestep 1400 is 0.012
Current timestep = 1401. State = [[-0.22699894  0.17887868]]. Action = [[-0.06924935  0.02562476  0.          0.4894439 ]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 1401 is [True, False, False, False, False, True]
State prediction error at timestep 1401 is 0.012
Current timestep = 1402. State = [[-0.22822362  0.18295234]]. Action = [[-3.7550926e-06  7.0956908e-02  0.0000000e+00 -4.0403998e-01]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 1402 is [True, False, False, False, False, True]
State prediction error at timestep 1402 is 0.012
Current timestep = 1403. State = [[-0.23008372  0.18514599]]. Action = [[-0.04146097 -0.0014528   0.         -0.1231547 ]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 1403 is [True, False, False, False, False, True]
State prediction error at timestep 1403 is 0.012
Current timestep = 1404. State = [[-0.23015381  0.19005588]]. Action = [[0.02110978 0.08991127 0.         0.6396694 ]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 1404 is [True, False, False, False, False, True]
State prediction error at timestep 1404 is 0.012
Current timestep = 1405. State = [[-0.2284021   0.19049951]]. Action = [[ 0.02993507 -0.05450974  0.          0.43707693]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 1405 is [True, False, False, False, False, True]
State prediction error at timestep 1405 is 0.012
Current timestep = 1406. State = [[-0.22353914  0.18452333]]. Action = [[ 0.07886945 -0.09638596  0.         -0.06264794]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 1406 is [True, False, False, False, False, True]
State prediction error at timestep 1406 is 0.012
Current timestep = 1407. State = [[-0.21618709  0.18571794]]. Action = [[0.09957605 0.08852243 0.         0.6311238 ]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 1407 is [True, False, False, False, False, True]
State prediction error at timestep 1407 is 0.012
Current timestep = 1408. State = [[-0.21727589  0.19162837]]. Action = [[-0.0977416   0.06955356  0.         -0.17276174]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 1408 is [True, False, False, False, False, True]
State prediction error at timestep 1408 is 0.012
Current timestep = 1409. State = [[-0.21588457  0.1957026 ]]. Action = [[0.0980657 0.0315988 0.        0.7311609]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 1409 is [True, False, False, False, False, True]
State prediction error at timestep 1409 is 0.012
Current timestep = 1410. State = [[-0.20877638  0.19543232]]. Action = [[ 0.09621989 -0.03177637  0.          0.8985534 ]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 1410 is [True, False, False, False, False, True]
State prediction error at timestep 1410 is 0.012
Current timestep = 1411. State = [[-0.2064312   0.19128883]]. Action = [[-0.0245947  -0.06921425  0.          0.2721405 ]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 1411 is [True, False, False, False, False, True]
State prediction error at timestep 1411 is 0.012
Current timestep = 1412. State = [[-0.20899305  0.18867382]]. Action = [[-0.06413773 -0.01465354  0.         -0.7957171 ]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 1412 is [True, False, False, False, False, True]
State prediction error at timestep 1412 is 0.012
Current timestep = 1413. State = [[-0.21186854  0.19299036]]. Action = [[-0.04227979  0.09212511  0.         -0.14720547]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 1413 is [True, False, False, False, False, True]
State prediction error at timestep 1413 is 0.012
Current timestep = 1414. State = [[-0.20896143  0.19534795]]. Action = [[ 0.0794687  -0.01427175  0.         -0.3311345 ]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 1414 is [True, False, False, False, False, True]
State prediction error at timestep 1414 is 0.012
Current timestep = 1415. State = [[-0.20696695  0.19390489]]. Action = [[-0.01525698 -0.02930223  0.          0.76297355]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 1415 is [True, False, False, False, False, True]
State prediction error at timestep 1415 is 0.012
Current timestep = 1416. State = [[-0.21026643  0.19295312]]. Action = [[-0.07946975 -0.00814732  0.          0.8974395 ]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 1416 is [True, False, False, False, False, True]
State prediction error at timestep 1416 is 0.012
Current timestep = 1417. State = [[-0.21003152  0.19144866]]. Action = [[ 0.03533287 -0.03138001  0.          0.6889317 ]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 1417 is [True, False, False, False, False, True]
State prediction error at timestep 1417 is 0.012
Current timestep = 1418. State = [[-0.2058558  0.1873082]]. Action = [[ 0.05290314 -0.06385575  0.          0.6466768 ]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 1418 is [True, False, False, False, False, True]
State prediction error at timestep 1418 is 0.012
Current timestep = 1419. State = [[-0.2019096   0.18457793]]. Action = [[ 0.03326698 -0.00746664  0.          0.02020347]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 1419 is [True, False, False, False, False, True]
State prediction error at timestep 1419 is 0.012
Current timestep = 1420. State = [[-0.19641323  0.17952085]]. Action = [[ 0.07454645 -0.08024703  0.          0.52121985]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 1420 is [True, False, False, False, False, True]
State prediction error at timestep 1420 is 0.012
Current timestep = 1421. State = [[-0.1921692   0.17620882]]. Action = [[ 0.02202912  0.00287689  0.         -0.7209237 ]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 1421 is [True, False, False, False, False, True]
State prediction error at timestep 1421 is 0.012
Current timestep = 1422. State = [[-0.19404246  0.17618373]]. Action = [[-0.07699214  0.02174349  0.          0.87397575]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 1422 is [True, False, False, False, False, True]
State prediction error at timestep 1422 is 0.012
Current timestep = 1423. State = [[-0.19219245  0.17720625]]. Action = [[ 0.06867474  0.02447222  0.         -0.6579847 ]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 1423 is [True, False, False, False, False, True]
State prediction error at timestep 1423 is 0.012
Current timestep = 1424. State = [[-0.19394013  0.18154371]]. Action = [[-0.08992452  0.0835314   0.         -0.50027955]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 1424 is [True, False, False, False, False, True]
State prediction error at timestep 1424 is 0.012
Current timestep = 1425. State = [[-0.19658387  0.18153375]]. Action = [[-0.01047666 -0.04972516  0.          0.03747094]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 1425 is [True, False, False, False, False, True]
State prediction error at timestep 1425 is 0.012
Current timestep = 1426. State = [[-0.1983388   0.18237418]]. Action = [[-0.03007703  0.04126173  0.          0.5605725 ]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 1426 is [True, False, False, False, False, True]
State prediction error at timestep 1426 is 0.012
Current timestep = 1427. State = [[-0.20428891  0.18820181]]. Action = [[-0.09888311  0.08562218  0.          0.26623762]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 1427 is [True, False, False, False, False, True]
State prediction error at timestep 1427 is 0.012
Current timestep = 1428. State = [[-0.20585679  0.19654816]]. Action = [[0.04920072 0.09759351 0.         0.28033924]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 1428 is [True, False, False, False, False, True]
State prediction error at timestep 1428 is 0.012
Current timestep = 1429. State = [[-0.2013861   0.20202379]]. Action = [[ 0.09525596  0.02716585  0.         -0.5006823 ]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 1429 is [True, False, False, False, False, True]
State prediction error at timestep 1429 is 0.012
Current timestep = 1430. State = [[-0.19775525  0.20775698]]. Action = [[ 0.04515011  0.07436245  0.         -0.4256335 ]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 1430 is [True, False, False, False, False, True]
State prediction error at timestep 1430 is 0.012
Current timestep = 1431. State = [[-0.19257165  0.2071082 ]]. Action = [[ 0.09504066 -0.07940916  0.         -0.43949127]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 1431 is [True, False, False, False, False, True]
State prediction error at timestep 1431 is 0.012
Current timestep = 1432. State = [[-0.19198436  0.20445772]]. Action = [[-0.04779181 -0.0276552   0.         -0.988659  ]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 1432 is [True, False, False, False, False, True]
State prediction error at timestep 1432 is 0.012
Current timestep = 1433. State = [[-0.19118136  0.20368196]]. Action = [[ 0.03558128 -0.01287808  0.         -0.5083436 ]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 1433 is [True, False, False, False, False, True]
State prediction error at timestep 1433 is 0.012
Current timestep = 1434. State = [[-0.19434933  0.20497677]]. Action = [[-0.09551231  0.02159266  0.         -0.6639996 ]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 1434 is [True, False, False, False, False, True]
State prediction error at timestep 1434 is 0.012
Current timestep = 1435. State = [[-0.19898863  0.20496327]]. Action = [[-0.05192648 -0.02867284  0.          0.01325774]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 1435 is [True, False, False, False, False, True]
State prediction error at timestep 1435 is 0.012
Current timestep = 1436. State = [[-0.20261726  0.20851746]]. Action = [[-0.04601244  0.07258233  0.          0.7110313 ]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 1436 is [True, False, False, False, False, True]
State prediction error at timestep 1436 is 0.012
Current timestep = 1437. State = [[-0.20022033  0.21513863]]. Action = [[0.09199657 0.07723535 0.         0.8989066 ]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 1437 is [True, False, False, False, False, True]
State prediction error at timestep 1437 is 0.012
Current timestep = 1438. State = [[-0.1949924  0.2186163]]. Action = [[ 0.069328    0.01023887  0.         -0.28548503]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 1438 is [True, False, False, False, False, True]
State prediction error at timestep 1438 is 0.012
Current timestep = 1439. State = [[-0.19031312  0.21850549]]. Action = [[ 0.0569798  -0.02015522  0.         -0.78481257]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 1439 is [True, False, False, False, False, True]
State prediction error at timestep 1439 is 0.012
Current timestep = 1440. State = [[-0.18671608  0.2231849 ]]. Action = [[0.03654256 0.09824716 0.         0.94787943]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 1440 is [True, False, False, False, False, True]
State prediction error at timestep 1440 is 0.012
Current timestep = 1441. State = [[-0.18114622  0.2307517 ]]. Action = [[0.09415235 0.08618986 0.         0.99782217]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 1441 is [True, False, False, False, False, True]
State prediction error at timestep 1441 is 0.012
Current timestep = 1442. State = [[-0.17832445  0.23766416]]. Action = [[0.00466397 0.07283901 0.         0.7400501 ]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 1442 is [True, False, False, False, False, True]
State prediction error at timestep 1442 is 0.012
Current timestep = 1443. State = [[-0.17320903  0.24043527]]. Action = [[ 0.09495779 -0.0086472   0.          0.06040668]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 1443 is [True, False, False, False, False, True]
State prediction error at timestep 1443 is 0.012
Current timestep = 1444. State = [[-0.17442855  0.24647307]]. Action = [[-0.09802181  0.09958883  0.         -0.41195744]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 1444 is [True, False, False, False, False, True]
State prediction error at timestep 1444 is 0.012
Current timestep = 1445. State = [[-0.17728989  0.25287342]]. Action = [[-0.00877435  0.03620287  0.         -0.8476604 ]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 1445 is [True, False, False, False, False, True]
State prediction error at timestep 1445 is 0.012
Current timestep = 1446. State = [[-0.17973107  0.25795844]]. Action = [[-0.04140748  0.03807371  0.          0.22029376]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 1446 is [True, False, False, False, False, True]
State prediction error at timestep 1446 is 0.012
Current timestep = 1447. State = [[-0.17682506  0.26459742]]. Action = [[0.09093412 0.0702224  0.         0.21291411]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 1447 is [True, False, False, False, False, True]
State prediction error at timestep 1447 is 0.012
Current timestep = 1448. State = [[-0.1711786   0.26632386]]. Action = [[ 0.06243824 -0.04317779  0.         -0.15279043]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 1448 is [True, False, False, False, False, True]
State prediction error at timestep 1448 is 0.012
Current timestep = 1449. State = [[-0.16762665  0.26246312]]. Action = [[ 0.01452906 -0.08672799  0.         -0.06629378]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 1449 is [True, False, False, False, False, True]
State prediction error at timestep 1449 is 0.012
Current timestep = 1450. State = [[-0.1670118   0.25865465]]. Action = [[-0.03145377 -0.05201534  0.          0.79719496]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 1450 is [True, False, False, False, False, True]
State prediction error at timestep 1450 is 0.012
Current timestep = 1451. State = [[-0.16855717  0.25930306]]. Action = [[-0.05115435  0.02370457  0.          0.02246761]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 1451 is [True, False, False, False, False, True]
State prediction error at timestep 1451 is 0.012
Current timestep = 1452. State = [[-0.16387409  0.25866777]]. Action = [[ 0.09946845 -0.03949891  0.         -0.9870909 ]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 1452 is [True, False, False, False, False, True]
State prediction error at timestep 1452 is 0.012
Current timestep = 1453. State = [[-0.15570004  0.2537287 ]]. Action = [[ 0.07786062 -0.0765634   0.         -0.44438338]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 1453 is [True, False, False, False, False, True]
State prediction error at timestep 1453 is 0.012
Current timestep = 1454. State = [[-0.15383159  0.24895647]]. Action = [[-0.05443884 -0.04240147  0.         -0.072501  ]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 1454 is [True, False, False, False, False, True]
State prediction error at timestep 1454 is 0.012
Current timestep = 1455. State = [[-0.15250322  0.24403292]]. Action = [[ 0.01284233 -0.06171844  0.         -0.00874412]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 1455 is [True, False, False, False, False, True]
State prediction error at timestep 1455 is 0.012
Current timestep = 1456. State = [[-0.15012017  0.23917748]]. Action = [[ 0.00434891 -0.04173073  0.         -0.7072774 ]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 1456 is [True, False, False, False, False, True]
State prediction error at timestep 1456 is 0.012
Current timestep = 1457. State = [[-0.14981595  0.23340899]]. Action = [[-0.03299508 -0.06707994  0.         -0.67370635]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 1457 is [True, False, False, False, False, True]
State prediction error at timestep 1457 is 0.012
Current timestep = 1458. State = [[-0.14558764  0.22501309]]. Action = [[ 0.07250696 -0.09917022  0.         -0.91014206]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 1458 is [True, False, False, False, False, True]
State prediction error at timestep 1458 is 0.012
Current timestep = 1459. State = [[-0.14135747  0.21593933]]. Action = [[ 0.01373346 -0.08210485  0.          0.16473722]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 1459 is [True, False, False, False, False, True]
State prediction error at timestep 1459 is 0.012
Current timestep = 1460. State = [[-0.13709034  0.21470286]]. Action = [[ 0.05054506  0.07258459  0.         -0.3128065 ]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 1460 is [True, False, False, False, False, True]
State prediction error at timestep 1460 is 0.012
Current timestep = 1461. State = [[-0.13523148  0.21417274]]. Action = [[-0.00653112 -0.00821     0.         -0.5485547 ]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 1461 is [True, False, False, False, False, True]
State prediction error at timestep 1461 is 0.012
Current timestep = 1462. State = [[-0.13672908  0.21075588]]. Action = [[-0.04407373 -0.0329038   0.         -0.7705038 ]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 1462 is [True, False, False, False, False, True]
State prediction error at timestep 1462 is 0.012
Current timestep = 1463. State = [[-0.13415144  0.20417741]]. Action = [[ 0.06510916 -0.08172795  0.          0.20010865]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 1463 is [True, False, False, False, False, True]
State prediction error at timestep 1463 is 0.012
Current timestep = 1464. State = [[-0.12898391  0.20193349]]. Action = [[ 0.06047433  0.04030026  0.         -0.32192743]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 1464 is [True, False, False, False, False, True]
State prediction error at timestep 1464 is 0.012
Current timestep = 1465. State = [[-0.12248596  0.19972482]]. Action = [[ 0.09293183 -0.02970576  0.         -0.2254268 ]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 1465 is [True, False, False, False, False, True]
State prediction error at timestep 1465 is 0.012
Current timestep = 1466. State = [[-0.11880206  0.19888577]]. Action = [[ 0.01461755  0.03365671  0.         -0.4078287 ]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 1466 is [True, False, False, False, False, True]
State prediction error at timestep 1466 is 0.012
Current timestep = 1467. State = [[-0.11644274  0.19504882]]. Action = [[ 0.02725735 -0.06842694  0.         -0.9357827 ]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 1467 is [True, False, False, False, False, True]
State prediction error at timestep 1467 is 0.012
Current timestep = 1468. State = [[-0.11687765  0.19279502]]. Action = [[-0.04094739  0.01792912  0.         -0.59644294]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 1468 is [True, False, False, False, False, True]
State prediction error at timestep 1468 is 0.012
Current timestep = 1469. State = [[-0.1157449   0.18958414]]. Action = [[ 0.02921923 -0.05446581  0.         -0.8247469 ]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 1469 is [True, False, False, False, False, True]
State prediction error at timestep 1469 is 0.012
Current timestep = 1470. State = [[-0.11798873  0.19175759]]. Action = [[-0.07754637  0.09048424  0.         -0.7957287 ]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 1470 is [True, False, False, False, False, True]
State prediction error at timestep 1470 is 0.012
Current timestep = 1471. State = [[-0.11946654  0.1928999 ]]. Action = [[ 0.00339459 -0.02517307  0.          0.7863995 ]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 1471 is [True, False, False, False, False, True]
State prediction error at timestep 1471 is 0.012
Current timestep = 1472. State = [[-0.11733862  0.19567522]]. Action = [[ 0.04135879  0.06855657  0.         -0.75910056]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 1472 is [True, False, False, False, False, True]
State prediction error at timestep 1472 is 0.012
Current timestep = 1473. State = [[-0.11543984  0.19853699]]. Action = [[0.02003442 0.0149953  0.         0.8815112 ]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 1473 is [True, False, False, False, False, True]
State prediction error at timestep 1473 is 0.012
Current timestep = 1474. State = [[-0.11620586  0.20102215]]. Action = [[-0.02483636  0.0315308   0.         -0.64845496]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 1474 is [True, False, False, False, False, True]
State prediction error at timestep 1474 is 0.012
Current timestep = 1475. State = [[-0.11964489  0.20724005]]. Action = [[-0.0520349   0.09056451  0.          0.86356854]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 1475 is [True, False, False, False, False, True]
State prediction error at timestep 1475 is 0.012
Current timestep = 1476. State = [[-0.12078767  0.20630501]]. Action = [[ 0.01294918 -0.09588278  0.         -0.629161  ]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 1476 is [True, False, False, False, False, True]
State prediction error at timestep 1476 is 0.012
Current timestep = 1477. State = [[-0.12385704  0.20240489]]. Action = [[-0.07163114 -0.04327599  0.          0.87127304]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 1477 is [True, False, False, False, False, True]
State prediction error at timestep 1477 is 0.012
Current timestep = 1478. State = [[-0.12754214  0.20571853]]. Action = [[-0.03714044  0.07902806  0.         -0.59886295]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 1478 is [True, False, False, False, False, True]
State prediction error at timestep 1478 is 0.012
Current timestep = 1479. State = [[-0.13366847  0.21081568]]. Action = [[-0.09472588  0.03701889  0.          0.6064873 ]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 1479 is [True, False, False, False, False, True]
State prediction error at timestep 1479 is 0.012
Current timestep = 1480. State = [[-0.13598293  0.21715495]]. Action = [[ 0.02638624  0.07811161  0.         -0.9119801 ]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 1480 is [True, False, False, False, False, True]
State prediction error at timestep 1480 is 0.012
Current timestep = 1481. State = [[-0.1355064   0.22299573]]. Action = [[0.02192883 0.04511494 0.         0.20268762]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 1481 is [True, False, False, False, False, True]
State prediction error at timestep 1481 is 0.012
Current timestep = 1482. State = [[-0.1379497   0.22491035]]. Action = [[-0.04109452 -0.01608104  0.          0.6220615 ]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 1482 is [True, False, False, False, False, True]
State prediction error at timestep 1482 is 0.012
Current timestep = 1483. State = [[-0.13981561  0.22602265]]. Action = [[ 0.00178875  0.00552988  0.         -0.32596886]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 1483 is [True, False, False, False, False, True]
State prediction error at timestep 1483 is 0.012
Current timestep = 1484. State = [[-0.13790317  0.2228184 ]]. Action = [[ 0.05477067 -0.08488029  0.          0.79768944]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 1484 is [True, False, False, False, False, True]
State prediction error at timestep 1484 is 0.012
Current timestep = 1485. State = [[-0.1327729   0.21961214]]. Action = [[ 0.08368694 -0.01843051  0.          0.14830208]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 1485 is [True, False, False, False, False, True]
State prediction error at timestep 1485 is 0.012
Current timestep = 1486. State = [[-0.12906447  0.21992129]]. Action = [[ 0.0323313   0.02650739  0.         -0.30198348]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 1486 is [True, False, False, False, False, True]
State prediction error at timestep 1486 is 0.012
Current timestep = 1487. State = [[-0.13054794  0.22366145]]. Action = [[-0.04983088  0.06572866  0.          0.977036  ]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 1487 is [True, False, False, False, False, True]
State prediction error at timestep 1487 is 0.012
Current timestep = 1488. State = [[-0.13211216  0.22211197]]. Action = [[-0.00635284 -0.07184473  0.          0.7691494 ]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 1488 is [True, False, False, False, False, True]
State prediction error at timestep 1488 is 0.012
Current timestep = 1489. State = [[-0.12828057  0.21548206]]. Action = [[ 0.07561516 -0.08884475  0.          0.31140244]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 1489 is [True, False, False, False, False, True]
State prediction error at timestep 1489 is 0.012
Current timestep = 1490. State = [[-0.12355052  0.20937721]]. Action = [[ 0.04000457 -0.05141348  0.         -0.08418   ]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 1490 is [True, False, False, False, False, True]
State prediction error at timestep 1490 is 0.012
Current timestep = 1491. State = [[-0.12025299  0.21001357]]. Action = [[ 0.02677006  0.06888027  0.         -0.33323383]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 1491 is [True, False, False, False, False, True]
State prediction error at timestep 1491 is 0.012
Current timestep = 1492. State = [[-0.12290027  0.20710568]]. Action = [[-0.09256151 -0.07975104  0.         -0.3563043 ]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 1492 is [True, False, False, False, False, True]
State prediction error at timestep 1492 is 0.012
Current timestep = 1493. State = [[-0.12077479  0.20466019]]. Action = [[ 0.09076568  0.01330201  0.         -0.31479347]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 1493 is [True, False, False, False, False, True]
State prediction error at timestep 1493 is 0.012
Current timestep = 1494. State = [[-0.11835225  0.20717193]]. Action = [[-0.01608587  0.06358313  0.         -0.04412127]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 1494 is [True, False, False, False, False, True]
State prediction error at timestep 1494 is 0.012
Current timestep = 1495. State = [[-0.11555511  0.2040598 ]]. Action = [[ 0.04592397 -0.08855481  0.         -0.5517558 ]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 1495 is [True, False, False, False, False, True]
State prediction error at timestep 1495 is 0.012
Current timestep = 1496. State = [[-0.11511495  0.19698666]]. Action = [[-0.0417276  -0.07831103  0.         -0.32500124]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 1496 is [True, False, False, False, False, True]
State prediction error at timestep 1496 is 0.012
Current timestep = 1497. State = [[-0.11066321  0.1923669 ]]. Action = [[ 0.09240686 -0.02480613  0.         -0.8970027 ]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 1497 is [True, False, False, False, False, True]
State prediction error at timestep 1497 is 0.012
Current timestep = 1498. State = [[-0.10782216  0.1861227 ]]. Action = [[-0.0231591  -0.08315104  0.         -0.36174238]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 1498 is [True, False, False, False, False, True]
State prediction error at timestep 1498 is 0.012
Current timestep = 1499. State = [[-0.10719435  0.18414411]]. Action = [[-0.00619667  0.03559572  0.          0.8975308 ]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 1499 is [True, False, False, False, False, True]
State prediction error at timestep 1499 is 0.012
Current timestep = 1500. State = [[-0.10902338  0.18367425]]. Action = [[-0.05689107 -0.00674983  0.          0.90320766]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 1500 is [True, False, False, False, False, True]
State prediction error at timestep 1500 is 0.012
Current timestep = 1501. State = [[-0.10946701  0.18511307]]. Action = [[0.00575855 0.04613181 0.         0.9310291 ]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 1501 is [True, False, False, False, False, True]
State prediction error at timestep 1501 is 0.012
Current timestep = 1502. State = [[-0.10753391  0.18855667]]. Action = [[0.03296951 0.05112977 0.         0.8240664 ]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 1502 is [True, False, False, False, False, True]
State prediction error at timestep 1502 is 0.012
Current timestep = 1503. State = [[-0.10704847  0.1916796 ]]. Action = [[-0.00648826  0.03357963  0.         -0.9310339 ]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 1503 is [True, False, False, False, False, True]
State prediction error at timestep 1503 is 0.012
Current timestep = 1504. State = [[-0.10390404  0.18859088]]. Action = [[ 0.06991971 -0.08408426  0.          0.00847363]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 1504 is [True, False, False, False, False, True]
State prediction error at timestep 1504 is 0.012
Current timestep = 1505. State = [[-0.10417762  0.18466665]]. Action = [[-0.05099543 -0.02657112  0.         -0.9698017 ]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 1505 is [True, False, False, False, False, True]
State prediction error at timestep 1505 is 0.012
Current timestep = 1506. State = [[-0.10251885  0.18254036]]. Action = [[ 0.05796783 -0.01895523  0.          0.83143306]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 1506 is [True, False, False, False, False, True]
State prediction error at timestep 1506 is 0.012
Current timestep = 1507. State = [[-0.0998396   0.18509935]]. Action = [[ 0.02275302  0.07198184  0.         -0.70894635]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 1507 is [True, False, False, False, False, True]
State prediction error at timestep 1507 is 0.012
Current timestep = 1508. State = [[-0.10283741  0.18487485]]. Action = [[-0.08079199 -0.0437201   0.         -0.83088493]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 1508 is [True, False, False, False, False, True]
State prediction error at timestep 1508 is 0.012
Current timestep = 1509. State = [[-0.10182511  0.17941657]]. Action = [[ 0.06355228 -0.08394178  0.          0.7132865 ]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 1509 is [True, False, False, False, False, True]
State prediction error at timestep 1509 is 0.012
Current timestep = 1510. State = [[-0.09660945  0.1742715 ]]. Action = [[ 0.06391043 -0.03911279  0.         -0.46859086]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 1510 is [True, False, False, False, False, True]
State prediction error at timestep 1510 is 0.012
Current timestep = 1511. State = [[-0.09148718  0.16925961]]. Action = [[ 0.05488581 -0.05302021  0.         -0.14648324]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 1511 is [True, False, False, False, False, True]
State prediction error at timestep 1511 is 0.012
Current timestep = 1512. State = [[-0.09332354  0.16572967]]. Action = [[-0.09725835 -0.01462736  0.          0.59059656]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 1512 is [True, False, False, False, False, True]
State prediction error at timestep 1512 is 0.012
Current timestep = 1513. State = [[-0.09454632  0.16592118]]. Action = [[0.01550321 0.0340425  0.         0.8842988 ]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 1513 is [True, False, False, False, False, True]
State prediction error at timestep 1513 is 0.012
Current timestep = 1514. State = [[-0.09518649  0.16411343]]. Action = [[-0.02550063 -0.03828431  0.         -0.6723196 ]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 1514 is [True, False, False, False, False, True]
State prediction error at timestep 1514 is 0.012
Current timestep = 1515. State = [[-0.09243391  0.16140671]]. Action = [[ 0.06626055 -0.01523694  0.          0.12458003]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 1515 is [True, False, False, False, False, True]
State prediction error at timestep 1515 is 0.012
Current timestep = 1516. State = [[-0.08897486  0.1570753 ]]. Action = [[ 0.0308539  -0.05551709  0.         -0.6315275 ]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 1516 is [True, False, False, False, False, True]
State prediction error at timestep 1516 is 0.012
Current timestep = 1517. State = [[-0.08750986  0.14968705]]. Action = [[ 0.00135176 -0.09047297  0.          0.99288607]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 1517 is [True, False, False, False, False, True]
State prediction error at timestep 1517 is 0.012
Current timestep = 1518. State = [[-0.08340283  0.14770114]]. Action = [[0.07262554 0.04486326 0.         0.03558469]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 1518 is [True, False, False, False, False, True]
State prediction error at timestep 1518 is 0.012
Current timestep = 1519. State = [[-0.07845739  0.15081316]]. Action = [[ 0.05801701  0.06714135  0.         -0.85930544]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 1519 is [True, False, False, False, False, True]
State prediction error at timestep 1519 is 0.012
Current timestep = 1520. State = [[-0.07673046  0.15384866]]. Action = [[-1.1099875e-04  3.9760880e-02  0.0000000e+00  4.3665123e-01]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 1520 is [True, False, False, False, False, True]
State prediction error at timestep 1520 is 0.012
Current timestep = 1521. State = [[-0.08091582  0.15511484]]. Action = [[-0.09704787  0.00801373  0.         -0.8554255 ]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 1521 is [True, False, False, False, False, True]
State prediction error at timestep 1521 is 0.012
Current timestep = 1522. State = [[-0.08083337  0.15582757]]. Action = [[ 0.05390195  0.00747881  0.         -0.05900693]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 1522 is [True, False, False, False, False, True]
State prediction error at timestep 1522 is 0.012
Current timestep = 1523. State = [[-0.07523056  0.15345068]]. Action = [[ 0.08014847 -0.0522943   0.         -0.34181857]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 1523 is [True, False, False, False, False, True]
State prediction error at timestep 1523 is 0.012
Current timestep = 1524. State = [[-0.07114005  0.14915262]]. Action = [[ 0.0242388  -0.05047288  0.          0.65645385]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 1524 is [True, False, False, False, False, True]
State prediction error at timestep 1524 is 0.012
Current timestep = 1525. State = [[-0.06976724  0.15060441]]. Action = [[-0.00498878  0.0677257   0.         -0.73916453]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 1525 is [True, False, False, False, False, True]
State prediction error at timestep 1525 is 0.012
Current timestep = 1526. State = [[-0.06547671  0.15463649]]. Action = [[ 0.07861339  0.04501147  0.         -0.8942284 ]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 1526 is [True, False, False, False, False, True]
State prediction error at timestep 1526 is 0.012
Current timestep = 1527. State = [[-0.06488734  0.15858541]]. Action = [[-0.04565468  0.04785227  0.          0.31896913]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 1527 is [True, False, False, False, False, True]
State prediction error at timestep 1527 is 0.012
Current timestep = 1528. State = [[-0.06595724  0.16505982]]. Action = [[-0.00661106  0.08727213  0.         -0.36756432]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 1528 is [True, False, False, False, False, True]
State prediction error at timestep 1528 is 0.012
Current timestep = 1529. State = [[-0.06904931  0.16449507]]. Action = [[-0.06700736 -0.08603155  0.         -0.6453821 ]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 1529 is [True, False, False, False, False, True]
State prediction error at timestep 1529 is 0.012
Current timestep = 1530. State = [[-0.07335624  0.16369234]]. Action = [[-0.06848673  0.00927445  0.          0.21219873]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 1530 is [True, False, False, False, False, True]
State prediction error at timestep 1530 is 0.012
Current timestep = 1531. State = [[-0.07937575  0.16391504]]. Action = [[-0.09998731 -0.0217493   0.          0.85832524]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 1531 is [True, False, False, False, False, True]
State prediction error at timestep 1531 is 0.012
Current timestep = 1532. State = [[-0.08250141  0.16674544]]. Action = [[-0.01543546  0.04617348  0.          0.5494752 ]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 1532 is [True, False, False, False, False, True]
State prediction error at timestep 1532 is 0.012
Current timestep = 1533. State = [[-0.08503161  0.16567966]]. Action = [[-0.04192669 -0.06941541  0.          0.48358107]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 1533 is [True, False, False, False, False, True]
State prediction error at timestep 1533 is 0.012
Current timestep = 1534. State = [[-0.08403168  0.16400589]]. Action = [[ 0.04704539 -0.00739501  0.         -0.45726693]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 1534 is [True, False, False, False, False, True]
State prediction error at timestep 1534 is 0.012
Current timestep = 1535. State = [[-0.08715625  0.15946217]]. Action = [[-0.0907034  -0.08987199  0.          0.8673451 ]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 1535 is [True, False, False, False, False, True]
State prediction error at timestep 1535 is 0.012
Current timestep = 1536. State = [[-0.08619457  0.1556588 ]]. Action = [[ 0.08615773 -0.01955017  0.         -0.17868888]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 1536 is [True, False, False, False, False, True]
State prediction error at timestep 1536 is 0.012
Current timestep = 1537. State = [[-0.08562533  0.15902378]]. Action = [[-0.02736311  0.09398948  0.          0.90798736]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 1537 is [True, False, False, False, False, True]
State prediction error at timestep 1537 is 0.012
Current timestep = 1538. State = [[-0.08716051  0.1570256 ]]. Action = [[-0.01009677 -0.08747928  0.         -0.56074566]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 1538 is [True, False, False, False, False, True]
State prediction error at timestep 1538 is 0.012
Current timestep = 1539. State = [[-0.0912172   0.15370996]]. Action = [[-0.07407103 -0.00835108  0.         -0.55325544]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 1539 is [True, False, False, False, False, True]
State prediction error at timestep 1539 is 0.012
Current timestep = 1540. State = [[-0.09709656  0.15082566]]. Action = [[-0.07607559 -0.04183691  0.          0.6811545 ]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 1540 is [True, False, False, False, False, True]
State prediction error at timestep 1540 is 0.012
Current timestep = 1541. State = [[-0.09806022  0.14692344]]. Action = [[ 0.03438669 -0.04238901  0.          0.3542813 ]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 1541 is [True, False, False, False, False, True]
State prediction error at timestep 1541 is 0.012
Current timestep = 1542. State = [[-0.09800621  0.14408748]]. Action = [[-0.00581502 -0.01383828  0.          0.469761  ]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 1542 is [True, False, False, False, False, True]
State prediction error at timestep 1542 is 0.012
Current timestep = 1543. State = [[-0.098556    0.14208014]]. Action = [[ 0.00285075 -0.01273906  0.         -0.3305968 ]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 1543 is [True, False, False, False, False, True]
State prediction error at timestep 1543 is 0.012
Current timestep = 1544. State = [[-0.10195473  0.14259419]]. Action = [[-0.05688209  0.03529751  0.         -0.63738257]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 1544 is [True, False, False, False, False, True]
State prediction error at timestep 1544 is 0.012
Current timestep = 1545. State = [[-0.10614841  0.14490402]]. Action = [[-0.03573651  0.03651395  0.         -0.66707754]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 1545 is [True, False, False, False, False, True]
State prediction error at timestep 1545 is 0.012
Current timestep = 1546. State = [[-0.11154328  0.14304854]]. Action = [[-0.06900895 -0.05552404  0.          0.64923024]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 1546 is [True, False, False, False, False, True]
State prediction error at timestep 1546 is 0.012
Current timestep = 1547. State = [[-0.11823957  0.1395922 ]]. Action = [[-0.08047295 -0.03462649  0.         -0.6899819 ]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 1547 is [True, False, False, False, False, True]
State prediction error at timestep 1547 is 0.012
Current timestep = 1548. State = [[-0.1203969   0.14138502]]. Action = [[ 0.0274075   0.06178281  0.         -0.9139861 ]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 1548 is [True, False, False, False, False, True]
State prediction error at timestep 1548 is 0.012
Current timestep = 1549. State = [[-0.12230857  0.13968256]]. Action = [[-0.02410155 -0.06740824  0.          0.4761808 ]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 1549 is [True, False, False, False, False, True]
State prediction error at timestep 1549 is 0.012
Current timestep = 1550. State = [[-0.12161163  0.13691464]]. Action = [[ 0.05350747 -0.01165059  0.         -0.1555996 ]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 1550 is [True, False, False, False, False, True]
State prediction error at timestep 1550 is 0.012
Current timestep = 1551. State = [[-0.12370158  0.13820942]]. Action = [[-0.04562667  0.04379549  0.         -0.84251654]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 1551 is [True, False, False, False, False, True]
State prediction error at timestep 1551 is 0.012
Current timestep = 1552. State = [[-0.12208633  0.14108056]]. Action = [[ 0.09252688  0.0374304   0.         -0.7901166 ]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 1552 is [True, False, False, False, False, True]
State prediction error at timestep 1552 is 0.012
Current timestep = 1553. State = [[-0.12112907  0.14218053]]. Action = [[-0.00364823  0.00331391  0.         -0.70551646]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 1553 is [True, False, False, False, False, True]
State prediction error at timestep 1553 is 0.012
Current timestep = 1554. State = [[-0.11864549  0.1456336 ]]. Action = [[0.07420974 0.068991   0.         0.22089267]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 1554 is [True, False, False, False, False, True]
State prediction error at timestep 1554 is 0.012
Current timestep = 1555. State = [[-0.12140052  0.14817181]]. Action = [[-0.08527251  0.00873367  0.         -0.5131773 ]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 1555 is [True, False, False, False, False, True]
State prediction error at timestep 1555 is 0.012
Current timestep = 1556. State = [[-0.12603293  0.14976084]]. Action = [[-0.02867537  0.01585113  0.         -0.15783286]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 1556 is [True, False, False, False, False, True]
State prediction error at timestep 1556 is 0.012
Current timestep = 1557. State = [[-0.12451588  0.15445073]]. Action = [[ 0.07630657  0.07257321  0.         -0.21380079]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 1557 is [True, False, False, False, False, True]
State prediction error at timestep 1557 is 0.012
Current timestep = 1558. State = [[-0.12209228  0.15978374]]. Action = [[0.03429561 0.04962646 0.         0.5663972 ]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 1558 is [True, False, False, False, False, True]
State prediction error at timestep 1558 is 0.012
Current timestep = 1559. State = [[-0.11800265  0.16368088]]. Action = [[0.08484896 0.0307012  0.         0.35557103]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 1559 is [True, False, False, False, False, True]
State prediction error at timestep 1559 is 0.012
Current timestep = 1560. State = [[-0.11734517  0.16748731]]. Action = [[-0.0214313   0.03997283  0.          0.3447293 ]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 1560 is [True, False, False, False, False, True]
State prediction error at timestep 1560 is 0.012
Current timestep = 1561. State = [[-0.11385594  0.1690866 ]]. Action = [[ 0.09222563 -0.01151257  0.          0.34785795]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 1561 is [True, False, False, False, False, True]
State prediction error at timestep 1561 is 0.012
Current timestep = 1562. State = [[-0.10871861  0.1646106 ]]. Action = [[ 0.05148353 -0.09874784  0.         -0.47278446]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 1562 is [True, False, False, False, False, True]
State prediction error at timestep 1562 is 0.012
Current timestep = 1563. State = [[-0.10472543  0.16043966]]. Action = [[ 0.03281083 -0.03119799  0.          0.75536084]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 1563 is [True, False, False, False, False, True]
State prediction error at timestep 1563 is 0.012
Current timestep = 1564. State = [[-0.10329532  0.16286694]]. Action = [[-0.01499406  0.06981295  0.         -0.48162043]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 1564 is [True, False, False, False, False, True]
State prediction error at timestep 1564 is 0.012
Current timestep = 1565. State = [[-0.10430583  0.16278154]]. Action = [[-0.04153795 -0.04592663  0.         -0.65664047]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 1565 is [True, False, False, False, False, True]
State prediction error at timestep 1565 is 0.012
Current timestep = 1566. State = [[-0.10579535  0.16224405]]. Action = [[-0.03916536  0.00861093  0.         -0.7373053 ]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 1566 is [True, False, False, False, False, True]
State prediction error at timestep 1566 is 0.012
Current timestep = 1567. State = [[-0.10205543  0.16422577]]. Action = [[ 0.0776385   0.03117692  0.         -0.20144552]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 1567 is [True, False, False, False, False, True]
State prediction error at timestep 1567 is 0.012
Current timestep = 1568. State = [[-0.095879    0.16859087]]. Action = [[0.06479464 0.0654342  0.         0.4732356 ]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 1568 is [True, False, False, False, False, True]
State prediction error at timestep 1568 is 0.012
Current timestep = 1569. State = [[-0.09343847  0.17357974]]. Action = [[-0.00549515  0.05282726  0.          0.37834978]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 1569 is [True, False, False, False, False, True]
State prediction error at timestep 1569 is 0.012
Current timestep = 1570. State = [[-0.09270684  0.17691514]]. Action = [[-0.00103794  0.01925635  0.         -0.08321935]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 1570 is [True, False, False, False, False, True]
State prediction error at timestep 1570 is 0.012
Current timestep = 1571. State = [[-0.09232216  0.17835972]]. Action = [[-0.00963905 -0.00203442  0.          0.39519787]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 1571 is [True, False, False, False, False, True]
State prediction error at timestep 1571 is 0.012
Current timestep = 1572. State = [[-0.0902402   0.18107373]]. Action = [[ 0.03063687  0.03583518  0.         -0.9918606 ]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 1572 is [True, False, False, False, False, True]
State prediction error at timestep 1572 is 0.012
Current timestep = 1573. State = [[-0.09150625  0.18484312]]. Action = [[-0.05789649  0.03299067  0.          0.5921525 ]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 1573 is [True, False, False, False, False, True]
State prediction error at timestep 1573 is 0.012
Current timestep = 1574. State = [[-0.09648711  0.1897006 ]]. Action = [[-0.08549201  0.04824985  0.         -0.3042485 ]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 1574 is [True, False, False, False, False, True]
State prediction error at timestep 1574 is 0.012
Current timestep = 1575. State = [[-0.10083196  0.18936342]]. Action = [[-0.05274595 -0.07027635  0.         -0.23156142]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 1575 is [True, False, False, False, False, True]
State prediction error at timestep 1575 is 0.012
Current timestep = 1576. State = [[-0.1018573   0.19110458]]. Action = [[ 0.00123967  0.04571851  0.         -0.57090026]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 1576 is [True, False, False, False, False, True]
State prediction error at timestep 1576 is 0.012
Current timestep = 1577. State = [[-0.10349097  0.19674541]]. Action = [[-0.03154106  0.06151026  0.          0.13780665]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 1577 is [True, False, False, False, False, True]
State prediction error at timestep 1577 is 0.012
Current timestep = 1578. State = [[-0.10590482  0.20449969]]. Action = [[-0.02149134  0.08806904  0.          0.51169   ]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 1578 is [True, False, False, False, False, True]
State prediction error at timestep 1578 is 0.012
Current timestep = 1579. State = [[-0.10452209  0.212368  ]]. Action = [[0.06419582 0.07201009 0.         0.62212944]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 1579 is [True, False, False, False, False, True]
State prediction error at timestep 1579 is 0.012
Current timestep = 1580. State = [[-0.10782758  0.21895914]]. Action = [[-0.08332518  0.05322655  0.         -0.44816828]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 1580 is [True, False, False, False, False, True]
State prediction error at timestep 1580 is 0.012
Current timestep = 1581. State = [[-0.1156977   0.22638373]]. Action = [[-0.08701854  0.07539187  0.          0.21832812]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 1581 is [True, False, False, False, False, True]
State prediction error at timestep 1581 is 0.012
Current timestep = 1582. State = [[-0.1199372   0.23415284]]. Action = [[ 0.00139146  0.06540807  0.         -0.511785  ]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 1582 is [True, False, False, False, False, True]
State prediction error at timestep 1582 is 0.012
Current timestep = 1583. State = [[-0.12321295  0.24199069]]. Action = [[-0.02337611  0.0720438   0.          0.7690635 ]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 1583 is [True, False, False, False, False, True]
State prediction error at timestep 1583 is 0.012
Current timestep = 1584. State = [[-0.12508893  0.2435382 ]]. Action = [[ 0.01359774 -0.05711904  0.          0.5771655 ]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 1584 is [True, False, False, False, False, True]
State prediction error at timestep 1584 is 0.012
Current timestep = 1585. State = [[-0.12668474  0.24835284]]. Action = [[-0.00737277  0.09191979  0.         -0.5194509 ]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 1585 is [True, False, False, False, False, True]
State prediction error at timestep 1585 is 0.012
Current timestep = 1586. State = [[-0.12609598  0.25395843]]. Action = [[ 0.05148017  0.02715588  0.         -0.9118658 ]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 1586 is [True, False, False, False, False, True]
State prediction error at timestep 1586 is 0.012
Current timestep = 1587. State = [[-0.12374754  0.25531554]]. Action = [[ 0.04822493 -0.01776174  0.         -0.19896579]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 1587 is [True, False, False, False, False, True]
State prediction error at timestep 1587 is 0.012
Current timestep = 1588. State = [[-0.12108417  0.26071936]]. Action = [[ 0.04716688  0.09942881  0.         -0.7517694 ]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 1588 is [True, False, False, False, False, True]
State prediction error at timestep 1588 is 0.012
Current timestep = 1589. State = [[-0.11698876  0.2667258 ]]. Action = [[0.07636086 0.048103   0.         0.84044373]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 1589 is [True, False, False, False, False, True]
State prediction error at timestep 1589 is 0.012
Current timestep = 1590. State = [[-0.11400472  0.26551357]]. Action = [[ 0.0240189  -0.06965724  0.         -0.900024  ]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 1590 is [True, False, False, False, False, True]
State prediction error at timestep 1590 is 0.012
Current timestep = 1591. State = [[-0.11037158  0.2679392 ]]. Action = [[ 0.05344509  0.07738144  0.         -0.8863841 ]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 1591 is [True, False, False, False, False, True]
State prediction error at timestep 1591 is 0.012
Current timestep = 1592. State = [[-0.10478858  0.27081317]]. Action = [[ 0.07609994  0.00758734  0.         -0.02844095]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 1592 is [True, False, False, False, False, True]
State prediction error at timestep 1592 is 0.012
Current timestep = 1593. State = [[-0.10248545  0.2669615 ]]. Action = [[-0.02114937 -0.09244832  0.         -0.5875644 ]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 1593 is [True, False, False, False, False, True]
State prediction error at timestep 1593 is 0.012
Current timestep = 1594. State = [[-0.1010708  0.2668982]]. Action = [[ 0.00912396  0.04535068  0.         -0.30819112]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 1594 is [True, False, False, False, False, True]
State prediction error at timestep 1594 is 0.012
Current timestep = 1595. State = [[-0.09588708  0.264653  ]]. Action = [[ 0.07382973 -0.07218885  0.         -0.17006117]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 1595 is [True, False, False, False, False, True]
State prediction error at timestep 1595 is 0.012
Current timestep = 1596. State = [[-0.09532789  0.26432085]]. Action = [[-0.06656659  0.03479893  0.          0.9758394 ]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 1596 is [True, False, False, False, False, True]
State prediction error at timestep 1596 is 0.012
Current timestep = 1597. State = [[-0.09143545  0.26870415]]. Action = [[ 0.09600129  0.06935512  0.         -0.32911998]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 1597 is [True, False, False, False, False, True]
State prediction error at timestep 1597 is 0.012
Current timestep = 1598. State = [[-0.08819762  0.26979968]]. Action = [[-0.0182647  -0.02355801  0.         -0.11012316]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 1598 is [True, False, False, False, False, True]
State prediction error at timestep 1598 is 0.012
Current timestep = 1599. State = [[-0.08307188  0.27221757]]. Action = [[0.0851488  0.05547728 0.         0.23487604]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 1599 is [True, False, False, False, False, True]
State prediction error at timestep 1599 is 0.012
Current timestep = 1600. State = [[-0.08198071  0.26944095]]. Action = [[-0.07022019 -0.0973137   0.         -0.99581367]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 1600 is [True, False, False, False, False, True]
State prediction error at timestep 1600 is 0.012
Current timestep = 1601. State = [[-0.08619309  0.26816434]]. Action = [[-0.08316027  0.01786487  0.          0.17488277]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 1601 is [True, False, False, False, False, True]
State prediction error at timestep 1601 is 0.012
Current timestep = 1602. State = [[-0.08523128  0.26566598]]. Action = [[ 0.04660726 -0.06900749  0.          0.33055115]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 1602 is [True, False, False, False, False, True]
State prediction error at timestep 1602 is 0.012
Current timestep = 1603. State = [[-0.08392275  0.26020104]]. Action = [[-0.02208587 -0.07231178  0.         -0.6190214 ]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 1603 is [True, False, False, False, False, True]
State prediction error at timestep 1603 is 0.012
Current timestep = 1604. State = [[-0.08624098  0.2566121 ]]. Action = [[-0.06397487 -0.02682237  0.          0.33128715]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 1604 is [True, False, False, False, False, True]
State prediction error at timestep 1604 is 0.012
Current timestep = 1605. State = [[-0.08973336  0.2520284 ]]. Action = [[-0.06012436 -0.0733377   0.         -0.03627282]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 1605 is [True, False, False, False, False, True]
State prediction error at timestep 1605 is 0.012
Current timestep = 1606. State = [[-0.08937976  0.24765559]]. Action = [[ 0.02415691 -0.03650582  0.         -0.14097309]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 1606 is [True, False, False, False, False, True]
State prediction error at timestep 1606 is 0.012
Current timestep = 1607. State = [[-0.09253301  0.24435359]]. Action = [[-0.09194881 -0.02990126  0.          0.29803514]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 1607 is [True, False, False, False, False, True]
State prediction error at timestep 1607 is 0.012
Current timestep = 1608. State = [[-0.09197447  0.24045034]]. Action = [[ 0.06317379 -0.04353961  0.         -0.3538506 ]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 1608 is [True, False, False, False, False, True]
State prediction error at timestep 1608 is 0.012
Current timestep = 1609. State = [[-0.08776673  0.24251002]]. Action = [[0.05675899 0.09392119 0.         0.44186306]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 1609 is [True, False, False, False, False, True]
State prediction error at timestep 1609 is 0.012
Current timestep = 1610. State = [[-0.09046163  0.24158219]]. Action = [[-0.09185355 -0.05443493  0.         -0.53730845]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 1610 is [True, False, False, False, False, True]
State prediction error at timestep 1610 is 0.012
Current timestep = 1611. State = [[-0.09128121  0.24154688]]. Action = [[0.05767635 0.04496387 0.         0.0437175 ]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 1611 is [True, False, False, False, False, True]
State prediction error at timestep 1611 is 0.012
Current timestep = 1612. State = [[-0.09170806  0.23929109]]. Action = [[-0.02004377 -0.05413809  0.         -0.47565675]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 1612 is [True, False, False, False, False, True]
State prediction error at timestep 1612 is 0.012
Current timestep = 1613. State = [[-0.09644449  0.237999  ]]. Action = [[-0.07432035  0.01630358  0.         -0.69911927]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 1613 is [True, False, False, False, False, True]
State prediction error at timestep 1613 is 0.012
Current timestep = 1614. State = [[-0.09873835  0.2378704 ]]. Action = [[ 0.01182995 -0.00352377  0.         -0.7524718 ]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 1614 is [True, False, False, False, False, True]
State prediction error at timestep 1614 is 0.012
Current timestep = 1615. State = [[-0.09508849  0.23228961]]. Action = [[ 0.08961155 -0.09830888  0.          0.93678665]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 1615 is [True, False, False, False, False, True]
State prediction error at timestep 1615 is 0.012
Current timestep = 1616. State = [[-0.09530738  0.2313474 ]]. Action = [[-0.04115922  0.06040014  0.         -0.6951791 ]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 1616 is [True, False, False, False, False, True]
State prediction error at timestep 1616 is 0.012
Current timestep = 1617. State = [[-0.09615894  0.22990717]]. Action = [[ 0.01773216 -0.04698221  0.          0.7812964 ]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 1617 is [True, False, False, False, False, True]
State prediction error at timestep 1617 is 0.012
Current timestep = 1618. State = [[-0.09274929  0.22800505]]. Action = [[ 0.07312848  0.00536193  0.         -0.37286294]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 1618 is [True, False, False, False, False, True]
State prediction error at timestep 1618 is 0.012
Current timestep = 1619. State = [[-0.08889289  0.22339454]]. Action = [[ 0.04690848 -0.07110648  0.         -0.7875025 ]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 1619 is [True, False, False, False, False, True]
State prediction error at timestep 1619 is 0.012
Current timestep = 1620. State = [[-0.08992949  0.21855883]]. Action = [[-0.05349733 -0.03136443  0.         -0.23892117]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 1620 is [True, False, False, False, False, True]
State prediction error at timestep 1620 is 0.012
Current timestep = 1621. State = [[-0.09135468  0.21951628]]. Action = [[-0.00479132  0.06034371  0.         -0.38310277]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 1621 is [True, False, False, False, False, True]
State prediction error at timestep 1621 is 0.012
Current timestep = 1622. State = [[-0.09006609  0.21734047]]. Action = [[ 0.03202135 -0.06055382  0.         -0.28399217]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 1622 is [True, False, False, False, False, True]
State prediction error at timestep 1622 is 0.012
Current timestep = 1623. State = [[-0.08644366  0.21099786]]. Action = [[ 0.05256284 -0.07232735  0.         -0.84352326]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 1623 is [True, False, False, False, False, True]
State prediction error at timestep 1623 is 0.012
Current timestep = 1624. State = [[-0.08059034  0.20571391]]. Action = [[ 0.08191251 -0.03223746  0.          0.9050915 ]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 1624 is [True, False, False, False, False, True]
State prediction error at timestep 1624 is 0.012
Current timestep = 1625. State = [[-0.0776411   0.20784217]]. Action = [[ 0.00572066  0.09661039  0.         -0.01303387]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 1625 is [True, False, False, False, False, True]
State prediction error at timestep 1625 is 0.012
Current timestep = 1626. State = [[-0.07382189  0.20875101]]. Action = [[ 0.06891333 -0.01283159  0.          0.07748735]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 1626 is [True, False, False, False, False, True]
State prediction error at timestep 1626 is 0.012
Current timestep = 1627. State = [[-0.07436696  0.2075102 ]]. Action = [[-0.06462065 -0.00251338  0.          0.11960971]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 1627 is [True, False, False, False, False, True]
State prediction error at timestep 1627 is 0.012
Current timestep = 1628. State = [[-0.07374095  0.20952927]]. Action = [[0.04028495 0.0524487  0.         0.35668898]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 1628 is [True, False, False, False, False, True]
State prediction error at timestep 1628 is 0.012
Current timestep = 1629. State = [[-0.06866263  0.20768802]]. Action = [[ 0.0790096  -0.05968311  0.         -0.58716345]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 1629 is [True, False, False, False, False, True]
State prediction error at timestep 1629 is 0.012
Current timestep = 1630. State = [[-0.06322605  0.20877713]]. Action = [[0.05860112 0.0667732  0.         0.46743882]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 1630 is [True, False, False, False, False, True]
State prediction error at timestep 1630 is 0.012
Current timestep = 1631. State = [[-0.06396029  0.21240246]]. Action = [[-0.06300756  0.039465    0.         -0.33273357]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 1631 is [True, False, False, False, False, True]
State prediction error at timestep 1631 is 0.012
Current timestep = 1632. State = [[-0.06196477  0.21341789]]. Action = [[ 0.0688987  -0.00955579  0.          0.9536979 ]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 1632 is [True, False, False, False, False, True]
State prediction error at timestep 1632 is 0.012
Current timestep = 1633. State = [[-0.06345429  0.21379432]]. Action = [[-0.08740619  0.00385324  0.          0.03225243]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 1633 is [True, False, False, False, False, True]
State prediction error at timestep 1633 is 0.012
Current timestep = 1634. State = [[-0.06925498  0.21229342]]. Action = [[-0.0898143  -0.04817659  0.          0.42465246]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 1634 is [True, False, False, False, False, True]
State prediction error at timestep 1634 is 0.012
Current timestep = 1635. State = [[-0.06937512  0.21180864]]. Action = [[ 0.04229348  0.00367234  0.         -0.04878718]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 1635 is [True, False, False, False, False, True]
State prediction error at timestep 1635 is 0.012
Current timestep = 1636. State = [[-0.06347243  0.21396665]]. Action = [[ 0.09413358  0.03615323  0.         -0.17432445]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 1636 is [True, False, False, False, False, True]
State prediction error at timestep 1636 is 0.012
Current timestep = 1637. State = [[-0.05963654  0.21497086]]. Action = [[ 0.02102898 -0.00280128  0.         -0.00671107]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 1637 is [True, False, False, False, False, True]
State prediction error at timestep 1637 is 0.012
Current timestep = 1638. State = [[-0.06061207  0.21203496]]. Action = [[-0.04814641 -0.06143905  0.         -0.9111524 ]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 1638 is [True, False, False, False, False, True]
State prediction error at timestep 1638 is 0.012
Current timestep = 1639. State = [[-0.06163964  0.2126153 ]]. Action = [[-0.01166666  0.04453904  0.         -0.05539638]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 1639 is [True, False, False, False, False, True]
State prediction error at timestep 1639 is 0.012
Current timestep = 1640. State = [[-0.05849233  0.2163415 ]]. Action = [[ 0.06623768  0.04785422  0.         -0.71716523]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 1640 is [True, False, False, False, False, True]
State prediction error at timestep 1640 is 0.012
Current timestep = 1641. State = [[-0.05415872  0.2146054 ]]. Action = [[ 0.04846614 -0.06452547  0.         -0.34355152]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 1641 is [True, False, False, False, False, True]
State prediction error at timestep 1641 is 0.012
Current timestep = 1642. State = [[-0.0528858   0.20939237]]. Action = [[-0.0166992  -0.06409699  0.         -0.74286115]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 1642 is [True, False, False, False, False, True]
State prediction error at timestep 1642 is 0.012
Current timestep = 1643. State = [[-0.05639251  0.20522794]]. Action = [[-0.088772   -0.03894525  0.          0.6640246 ]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 1643 is [True, False, False, False, False, True]
State prediction error at timestep 1643 is 0.012
Current timestep = 1644. State = [[-0.05981506  0.20669498]]. Action = [[-0.04390135  0.05618494  0.          0.11461151]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 1644 is [True, False, False, False, False, True]
State prediction error at timestep 1644 is 0.012
Current timestep = 1645. State = [[-0.05657947  0.20330165]]. Action = [[ 0.08576285 -0.09707598  0.          0.567889  ]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 1645 is [True, False, False, False, False, True]
State prediction error at timestep 1645 is 0.012
Current timestep = 1646. State = [[-0.05647309  0.19762698]]. Action = [[-0.06492718 -0.04707873  0.         -0.840912  ]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 1646 is [True, False, False, False, False, True]
State prediction error at timestep 1646 is 0.012
Current timestep = 1647. State = [[-0.05793264  0.19931185]]. Action = [[-0.00622446  0.07656641  0.          0.7214942 ]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 1647 is [True, False, False, False, False, True]
State prediction error at timestep 1647 is 0.012
Current timestep = 1648. State = [[-0.05677824  0.19660738]]. Action = [[ 0.02748735 -0.08763855  0.         -0.28674734]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 1648 is [True, False, False, False, False, True]
State prediction error at timestep 1648 is 0.012
Current timestep = 1649. State = [[-0.05818892  0.1965252 ]]. Action = [[-0.04625107  0.06089827  0.          0.03275394]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 1649 is [True, False, False, False, False, True]
State prediction error at timestep 1649 is 0.012
Current timestep = 1650. State = [[-0.05789829  0.19920152]]. Action = [[0.03655168 0.02793505 0.         0.31728196]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 1650 is [True, False, False, False, False, True]
State prediction error at timestep 1650 is 0.012
Current timestep = 1651. State = [[-0.05406812  0.19670184]]. Action = [[ 0.07021508 -0.06008403  0.         -0.25170743]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 1651 is [True, False, False, False, False, True]
State prediction error at timestep 1651 is 0.012
Current timestep = 1652. State = [[-0.05683123  0.19875272]]. Action = [[-0.09786566  0.08521651  0.         -0.64890885]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 1652 is [True, False, False, False, False, True]
State prediction error at timestep 1652 is 0.012
Current timestep = 1653. State = [[-0.05971847  0.19895561]]. Action = [[ 0.00766774 -0.04443889  0.          0.6883905 ]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 1653 is [True, False, False, False, False, True]
State prediction error at timestep 1653 is 0.012
Current timestep = 1654. State = [[-0.05981744  0.20121375]]. Action = [[ 0.01305105  0.06965374  0.         -0.6443768 ]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 1654 is [True, False, False, False, False, True]
State prediction error at timestep 1654 is 0.012
Current timestep = 1655. State = [[-0.05964709  0.20356117]]. Action = [[0.0166273  0.00574385 0.         0.30843842]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 1655 is [True, False, False, False, False, True]
State prediction error at timestep 1655 is 0.012
Current timestep = 1656. State = [[-0.0585846   0.19909756]]. Action = [[ 0.02768887 -0.09596533  0.         -0.10255241]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 1656 is [True, False, False, False, False, True]
State prediction error at timestep 1656 is 0.012
Current timestep = 1657. State = [[-0.05569689  0.1934694 ]]. Action = [[ 0.05013534 -0.04887119  0.         -0.21528304]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 1657 is [True, False, False, False, False, True]
State prediction error at timestep 1657 is 0.012
Current timestep = 1658. State = [[-0.05159194  0.19528197]]. Action = [[0.06194665 0.08499632 0.         0.23487806]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 1658 is [True, False, False, False, False, True]
State prediction error at timestep 1658 is 0.012
Current timestep = 1659. State = [[-0.05429781  0.20070352]]. Action = [[-0.09254691  0.07057177  0.         -0.14825642]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 1659 is [True, False, False, False, False, True]
State prediction error at timestep 1659 is 0.012
Current timestep = 1660. State = [[-0.06064138  0.19892439]]. Action = [[-0.07481259 -0.08373065  0.         -0.5912913 ]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 1660 is [True, False, False, False, False, True]
State prediction error at timestep 1660 is 0.012
Current timestep = 1661. State = [[-0.06239675  0.19946449]]. Action = [[0.01557746 0.05321633 0.         0.01676667]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 1661 is [True, False, False, False, False, True]
State prediction error at timestep 1661 is 0.012
Current timestep = 1662. State = [[-0.06125526  0.20033441]]. Action = [[ 0.02828187 -0.01480464  0.          0.49417293]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 1662 is [True, False, False, False, False, True]
State prediction error at timestep 1662 is 0.012
Current timestep = 1663. State = [[-0.05785178  0.2024608 ]]. Action = [[ 0.06692731  0.04968681  0.         -0.9387069 ]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 1663 is [True, False, False, False, False, True]
State prediction error at timestep 1663 is 0.012
Current timestep = 1664. State = [[-0.0599237   0.20211925]]. Action = [[-0.07902201 -0.03776725  0.         -0.04167175]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 1664 is [True, False, False, False, False, True]
State prediction error at timestep 1664 is 0.012
Current timestep = 1665. State = [[-0.0666308   0.19704208]]. Action = [[-0.09246209 -0.08746035  0.          0.40793037]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 1665 is [True, False, False, False, False, True]
State prediction error at timestep 1665 is 0.012
Current timestep = 1666. State = [[-0.06826704  0.18968606]]. Action = [[ 0.02223419 -0.09601351  0.         -0.37350094]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 1666 is [True, False, False, False, False, True]
State prediction error at timestep 1666 is 0.012
Current timestep = 1667. State = [[-0.06948909  0.1909067 ]]. Action = [[-0.03197093  0.0955553   0.         -0.61297256]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 1667 is [True, False, False, False, False, True]
State prediction error at timestep 1667 is 0.012
Current timestep = 1668. State = [[-0.072625    0.19123134]]. Action = [[-0.03780412 -0.04209345  0.         -0.9659543 ]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 1668 is [True, False, False, False, False, True]
State prediction error at timestep 1668 is 0.012
Current timestep = 1669. State = [[-0.07277264  0.18529779]]. Action = [[ 0.02451309 -0.09147425  0.         -0.59013903]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 1669 is [True, False, False, False, False, True]
State prediction error at timestep 1669 is 0.012
Current timestep = 1670. State = [[-0.07203269  0.17754158]]. Action = [[ 0.00409816 -0.08389035  0.          0.40107584]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 1670 is [True, False, False, False, False, True]
State prediction error at timestep 1670 is 0.012
Current timestep = 1671. State = [[-0.0690273   0.16951202]]. Action = [[ 0.05794273 -0.08121129  0.         -0.48994422]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 1671 is [True, False, False, False, False, True]
State prediction error at timestep 1671 is 0.012
Current timestep = 1672. State = [[-0.06972582  0.16292147]]. Action = [[-0.0521296  -0.04570774  0.          0.35711658]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 1672 is [True, False, False, False, False, True]
State prediction error at timestep 1672 is 0.012
Current timestep = 1673. State = [[-0.0731836   0.15744789]]. Action = [[-0.04837132 -0.04415559  0.          0.9682554 ]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 1673 is [True, False, False, False, False, True]
State prediction error at timestep 1673 is 0.012
Current timestep = 1674. State = [[-0.07891471  0.15141249]]. Action = [[-0.09441381 -0.05841422  0.          0.5385126 ]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 1674 is [True, False, False, False, False, True]
State prediction error at timestep 1674 is 0.012
Current timestep = 1675. State = [[-0.07812547  0.143057  ]]. Action = [[ 0.0807459  -0.09412576  0.          0.48030353]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 1675 is [True, False, False, False, False, True]
State prediction error at timestep 1675 is 0.012
Current timestep = 1676. State = [[-0.07461219  0.13301249]]. Action = [[ 0.02449362 -0.09568343  0.          0.49652314]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 1676 is [True, False, False, False, False, True]
State prediction error at timestep 1676 is 0.012
Current timestep = 1677. State = [[-0.07573389  0.13124758]]. Action = [[-0.04619167  0.07526233  0.         -0.78129387]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 1677 is [True, False, False, False, False, True]
State prediction error at timestep 1677 is 0.012
Current timestep = 1678. State = [[-0.07774606  0.12795362]]. Action = [[-0.01699464 -0.06571168  0.          0.5153916 ]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 1678 is [True, False, False, False, False, True]
State prediction error at timestep 1678 is 0.012
Current timestep = 1679. State = [[-0.07545941  0.12464886]]. Action = [[ 0.06109185  0.00880975  0.         -0.56542057]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 1679 is [True, False, False, False, True, False]
State prediction error at timestep 1679 is 0.012
Current timestep = 1680. State = [[-0.07092003  0.11826946]]. Action = [[ 0.06956065 -0.09238352  0.         -0.64511365]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 1680 is [True, False, False, False, True, False]
State prediction error at timestep 1680 is 0.012
Current timestep = 1681. State = [[-0.06597937  0.11688663]]. Action = [[0.07091781 0.06744381 0.         0.27184558]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 1681 is [True, False, False, False, True, False]
State prediction error at timestep 1681 is 0.012
Current timestep = 1682. State = [[-0.0601305   0.12136955]]. Action = [[ 0.09347703  0.08679914  0.         -0.74899167]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 1682 is [True, False, False, False, True, False]
State prediction error at timestep 1682 is 0.012
Current timestep = 1683. State = [[-0.06018927  0.11863457]]. Action = [[-0.05056575 -0.08653894  0.         -0.76011175]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 1683 is [True, False, False, False, True, False]
State prediction error at timestep 1683 is 0.012
Current timestep = 1684. State = [[-0.06481929  0.11188136]]. Action = [[-0.07184376 -0.06866738  0.          0.5597789 ]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 1684 is [True, False, False, False, True, False]
State prediction error at timestep 1684 is 0.012
Current timestep = 1685. State = [[-0.0670229   0.11318907]]. Action = [[-0.00770409  0.08641093  0.          0.59883976]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 1685 is [True, False, False, False, True, False]
State prediction error at timestep 1685 is 0.012
Current timestep = 1686. State = [[-0.06966747  0.12001079]]. Action = [[-0.04352471  0.09324879  0.         -0.19850779]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 1686 is [True, False, False, False, True, False]
State prediction error at timestep 1686 is 0.012
Current timestep = 1687. State = [[-0.07460423  0.1270322 ]]. Action = [[-0.06893685  0.07252338  0.         -0.09769779]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 1687 is [True, False, False, False, False, True]
State prediction error at timestep 1687 is 0.012
Current timestep = 1688. State = [[-0.08132619  0.13074337]]. Action = [[-0.08991312  0.00510506  0.          0.3802408 ]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 1688 is [True, False, False, False, False, True]
State prediction error at timestep 1688 is 0.012
Current timestep = 1689. State = [[-0.08075394  0.13213676]]. Action = [[ 0.08817083 -0.00606167  0.         -0.35611665]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 1689 is [True, False, False, False, False, True]
State prediction error at timestep 1689 is 0.012
Current timestep = 1690. State = [[-0.0748091   0.12888986]]. Action = [[ 0.08695786 -0.08182957  0.          0.8354368 ]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 1690 is [True, False, False, False, False, True]
State prediction error at timestep 1690 is 0.012
Current timestep = 1691. State = [[-0.07589845  0.12197255]]. Action = [[-0.08785827 -0.09833588  0.         -0.0291959 ]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 1691 is [True, False, False, False, True, False]
State prediction error at timestep 1691 is 0.012
Current timestep = 1692. State = [[-0.07962319  0.12399874]]. Action = [[-0.02952545  0.09985384  0.          0.03841424]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 1692 is [True, False, False, False, True, False]
State prediction error at timestep 1692 is 0.012
Current timestep = 1693. State = [[-0.07710799  0.12622602]]. Action = [[ 0.08581822 -0.01669133  0.          0.72429824]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 1693 is [True, False, False, False, False, True]
State prediction error at timestep 1693 is 0.012
Current timestep = 1694. State = [[-0.07254448  0.12366479]]. Action = [[ 0.05687662 -0.04478177  0.         -0.84171414]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 1694 is [True, False, False, False, True, False]
State prediction error at timestep 1694 is 0.012
Current timestep = 1695. State = [[-0.07229356  0.11727177]]. Action = [[-0.02959806 -0.09374854  0.          0.00583839]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 1695 is [True, False, False, False, True, False]
State prediction error at timestep 1695 is 0.012
Current timestep = 1696. State = [[-0.07271425  0.11458366]]. Action = [[-0.00048345  0.01728419  0.         -0.34769374]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 1696 is [True, False, False, False, True, False]
State prediction error at timestep 1696 is 0.012
Current timestep = 1697. State = [[-0.07349582  0.11464759]]. Action = [[-0.02053362  0.01029809  0.          0.31329632]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 1697 is [True, False, False, False, True, False]
State prediction error at timestep 1697 is 0.012
Current timestep = 1698. State = [[-0.07691724  0.11904095]]. Action = [[-0.06322087  0.09290879  0.          0.82626224]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 1698 is [True, False, False, False, True, False]
State prediction error at timestep 1698 is 0.012
Current timestep = 1699. State = [[-0.07941532  0.12255082]]. Action = [[-0.01433234  0.01579387  0.          0.6211436 ]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 1699 is [True, False, False, False, True, False]
State prediction error at timestep 1699 is 0.012
Current timestep = 1700. State = [[-0.08225997  0.12409768]]. Action = [[-0.04488403  0.01286776  0.          0.27077866]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 1700 is [True, False, False, False, True, False]
State prediction error at timestep 1700 is 0.012
Current timestep = 1701. State = [[-0.08169232  0.12498184]]. Action = [[ 0.04513345  0.00089148  0.         -0.60245746]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 1701 is [True, False, False, False, True, False]
State prediction error at timestep 1701 is 0.012
Current timestep = 1702. State = [[-0.0797305   0.13036458]]. Action = [[0.03068585 0.09776481 0.         0.8291602 ]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 1702 is [True, False, False, False, False, True]
State prediction error at timestep 1702 is 0.012
Current timestep = 1703. State = [[-0.08189096  0.13252884]]. Action = [[-0.04785303 -0.02908176  0.         -0.6445944 ]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 1703 is [True, False, False, False, False, True]
State prediction error at timestep 1703 is 0.012
Current timestep = 1704. State = [[-0.08584633  0.12923776]]. Action = [[-0.04889363 -0.06726149  0.         -0.9417914 ]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 1704 is [True, False, False, False, False, True]
State prediction error at timestep 1704 is 0.012
Current timestep = 1705. State = [[-0.08690951  0.13270493]]. Action = [[ 0.01425348  0.09952035  0.         -0.17685163]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 1705 is [True, False, False, False, False, True]
State prediction error at timestep 1705 is 0.012
Current timestep = 1706. State = [[-0.08658598  0.13621348]]. Action = [[ 0.01356339 -0.00108007  0.          0.28601158]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 1706 is [True, False, False, False, False, True]
State prediction error at timestep 1706 is 0.012
Current timestep = 1707. State = [[-0.08310959  0.13485318]]. Action = [[ 0.07682256 -0.042303    0.         -0.7853192 ]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 1707 is [True, False, False, False, False, True]
State prediction error at timestep 1707 is 0.012
Current timestep = 1708. State = [[-0.08461247  0.13001962]]. Action = [[-0.07520475 -0.07658683  0.          0.3841014 ]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 1708 is [True, False, False, False, False, True]
State prediction error at timestep 1708 is 0.012
Current timestep = 1709. State = [[-0.08755383  0.12691866]]. Action = [[-0.01694203 -0.01561052  0.          0.6972134 ]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 1709 is [True, False, False, False, False, True]
State prediction error at timestep 1709 is 0.012
Current timestep = 1710. State = [[-0.08486249  0.12213814]]. Action = [[ 0.07416108 -0.07650431  0.          0.1637541 ]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 1710 is [True, False, False, False, True, False]
State prediction error at timestep 1710 is 0.012
Current timestep = 1711. State = [[-0.07986598  0.12065363]]. Action = [[0.06822898 0.03408932 0.         0.86223197]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 1711 is [True, False, False, False, True, False]
State prediction error at timestep 1711 is 0.012
Current timestep = 1712. State = [[-0.07393175  0.11838979]]. Action = [[ 0.08816113 -0.04046193  0.         -0.34440064]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 1712 is [True, False, False, False, True, False]
State prediction error at timestep 1712 is 0.012
Current timestep = 1713. State = [[-0.07217368  0.11924932]]. Action = [[-0.01591974  0.06523462  0.         -0.5635049 ]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 1713 is [True, False, False, False, True, False]
State prediction error at timestep 1713 is 0.012
Current timestep = 1714. State = [[-0.07690994  0.1210502 ]]. Action = [[-0.09597376  0.01608057  0.         -0.3203107 ]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 1714 is [True, False, False, False, True, False]
State prediction error at timestep 1714 is 0.012
Current timestep = 1715. State = [[-0.08141663  0.11869252]]. Action = [[-0.04781587 -0.05116152  0.          0.25613427]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 1715 is [True, False, False, False, True, False]
State prediction error at timestep 1715 is 0.012
Current timestep = 1716. State = [[-0.08338375  0.11339899]]. Action = [[-0.01863081 -0.0695814   0.         -0.94918835]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 1716 is [True, False, False, False, True, False]
State prediction error at timestep 1716 is 0.012
Current timestep = 1717. State = [[-0.08333873  0.11294947]]. Action = [[ 0.00757823  0.04367711  0.         -0.54741305]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 1717 is [True, False, False, False, True, False]
State prediction error at timestep 1717 is 0.012
Current timestep = 1718. State = [[-0.08345098  0.11716516]]. Action = [[-0.00419597  0.06701968  0.         -0.20560122]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 1718 is [True, False, False, False, True, False]
State prediction error at timestep 1718 is 0.012
Current timestep = 1719. State = [[-0.08334503  0.12284872]]. Action = [[0.012239   0.0708173  0.         0.31010675]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 1719 is [True, False, False, False, True, False]
State prediction error at timestep 1719 is 0.012
Current timestep = 1720. State = [[-0.08322144  0.12887254]]. Action = [[ 0.00825711  0.06564101  0.         -0.88126695]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 1720 is [True, False, False, False, False, True]
State prediction error at timestep 1720 is 0.012
Current timestep = 1721. State = [[-0.07926533  0.13568108]]. Action = [[0.09659236 0.07721693 0.         0.07327771]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 1721 is [True, False, False, False, False, True]
State prediction error at timestep 1721 is 0.012
Current timestep = 1722. State = [[-0.08042616  0.13596036]]. Action = [[-0.06912447 -0.06336971  0.         -0.4700048 ]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 1722 is [True, False, False, False, False, True]
State prediction error at timestep 1722 is 0.012
Current timestep = 1723. State = [[-0.07910528  0.1386648 ]]. Action = [[0.08338755 0.06777977 0.         0.97097135]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 1723 is [True, False, False, False, False, True]
State prediction error at timestep 1723 is 0.012
Current timestep = 1724. State = [[-0.07646729  0.13782705]]. Action = [[ 0.022967   -0.0739797   0.          0.06477261]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 1724 is [True, False, False, False, False, True]
State prediction error at timestep 1724 is 0.012
Current timestep = 1725. State = [[-0.0713568   0.13890758]]. Action = [[0.0951932  0.05121479 0.         0.14591539]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 1725 is [True, False, False, False, False, True]
State prediction error at timestep 1725 is 0.012
Current timestep = 1726. State = [[-0.07114494  0.1359557 ]]. Action = [[-0.05743906 -0.09508307  0.         -0.62459326]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 1726 is [True, False, False, False, False, True]
State prediction error at timestep 1726 is 0.012
Current timestep = 1727. State = [[-0.06848674  0.12849987]]. Action = [[ 0.07843759 -0.09731264  0.          0.31924355]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 1727 is [True, False, False, False, False, True]
State prediction error at timestep 1727 is 0.012
Current timestep = 1728. State = [[-0.06299186  0.12760967]]. Action = [[ 0.05797043  0.05520499  0.         -0.9450787 ]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 1728 is [True, False, False, False, False, True]
State prediction error at timestep 1728 is 0.012
Current timestep = 1729. State = [[-0.05972553  0.12865753]]. Action = [[ 0.01991578  0.00630568  0.         -0.12440169]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 1729 is [True, False, False, False, False, True]
State prediction error at timestep 1729 is 0.012
Current timestep = 1730. State = [[-0.06172847  0.12572458]]. Action = [[-0.07705384 -0.05208069  0.         -0.7694782 ]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 1730 is [True, False, False, False, False, True]
State prediction error at timestep 1730 is 0.012
Current timestep = 1731. State = [[-0.06682109  0.11908417]]. Action = [[-0.09703176 -0.09209523  0.         -0.41083002]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 1731 is [True, False, False, False, True, False]
State prediction error at timestep 1731 is 0.012
Current timestep = 1732. State = [[-0.06416219  0.1147713 ]]. Action = [[ 0.09572191 -0.0156287   0.          0.374992  ]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 1732 is [True, False, False, False, True, False]
State prediction error at timestep 1732 is 0.012
Current timestep = 1733. State = [[-0.06113013  0.11789168]]. Action = [[-0.01819371  0.09549988  0.         -0.44009387]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 1733 is [True, False, False, False, True, False]
State prediction error at timestep 1733 is 0.012
Current timestep = 1734. State = [[-0.06329714  0.11758271]]. Action = [[-0.06557462 -0.05127078  0.         -0.57514924]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 1734 is [True, False, False, False, True, False]
State prediction error at timestep 1734 is 0.012
Current timestep = 1735. State = [[-0.06361926  0.11808591]]. Action = [[0.00366352 0.0434216  0.         0.46660173]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 1735 is [True, False, False, False, True, False]
State prediction error at timestep 1735 is 0.012
Current timestep = 1736. State = [[-0.06062249  0.11599948]]. Action = [[ 0.04496995 -0.06272867  0.          0.11957169]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 1736 is [True, False, False, False, True, False]
State prediction error at timestep 1736 is 0.012
Current timestep = 1737. State = [[-0.06010969  0.11625759]]. Action = [[-0.02830257  0.04640221  0.          0.00282085]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 1737 is [True, False, False, False, True, False]
State prediction error at timestep 1737 is 0.012
Current timestep = 1738. State = [[-0.0595084   0.11272211]]. Action = [[ 0.01577685 -0.09320761  0.          0.07816386]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 1738 is [True, False, False, False, True, False]
State prediction error at timestep 1738 is 0.012
Current timestep = 1739. State = [[-0.05900056  0.11391364]]. Action = [[-0.00692618  0.084742    0.          0.652194  ]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 1739 is [True, False, False, False, True, False]
State prediction error at timestep 1739 is 0.012
Current timestep = 1740. State = [[-0.05462208  0.1136177 ]]. Action = [[ 0.09410789 -0.05037607  0.         -0.496516  ]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 1740 is [True, False, False, False, True, False]
State prediction error at timestep 1740 is 0.012
Current timestep = 1741. State = [[-0.05319047  0.10933882]]. Action = [[-0.03035649 -0.05097604  0.          0.29891956]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 1741 is [True, False, False, False, True, False]
State prediction error at timestep 1741 is 0.012
Current timestep = 1742. State = [[-0.05387476  0.10222086]]. Action = [[-0.00950383 -0.09902347  0.          0.8790505 ]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 1742 is [True, False, False, False, True, False]
State prediction error at timestep 1742 is 0.012
Current timestep = 1743. State = [[-0.05567899  0.09979701]]. Action = [[-0.04349864  0.02992711  0.         -0.06202251]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 1743 is [True, False, False, False, True, False]
State prediction error at timestep 1743 is 0.012
Current timestep = 1744. State = [[-0.0591559   0.10285385]]. Action = [[-0.05628148  0.06182446  0.         -0.73516315]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 1744 is [True, False, False, False, True, False]
State prediction error at timestep 1744 is 0.012
Current timestep = 1745. State = [[-0.0633184   0.10455682]]. Action = [[-0.0569757  0.0023407  0.         0.7308707]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 1745 is [True, False, False, False, True, False]
State prediction error at timestep 1745 is 0.012
Current timestep = 1746. State = [[-0.06619491  0.10268863]]. Action = [[-0.02603827 -0.04022497  0.          0.9874319 ]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 1746 is [True, False, False, False, True, False]
State prediction error at timestep 1746 is 0.012
Current timestep = 1747. State = [[-0.06377776  0.10249709]]. Action = [[0.07425658 0.02194657 0.         0.3338132 ]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 1747 is [True, False, False, False, True, False]
State prediction error at timestep 1747 is 0.012
Current timestep = 1748. State = [[-0.06235972  0.10082079]]. Action = [[ 5.8822334e-04 -4.1980308e-02  0.0000000e+00  6.8858624e-01]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 1748 is [True, False, False, False, True, False]
State prediction error at timestep 1748 is 0.012
Current timestep = 1749. State = [[-0.06346804  0.10333604]]. Action = [[-0.01574305  0.0788353   0.         -0.36030018]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 1749 is [True, False, False, False, True, False]
State prediction error at timestep 1749 is 0.012
Current timestep = 1750. State = [[-0.0652922   0.10557802]]. Action = [[-0.01670779 -0.00161984  0.         -0.69173867]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 1750 is [True, False, False, False, True, False]
State prediction error at timestep 1750 is 0.012
Current timestep = 1751. State = [[-0.07048354  0.10199182]]. Action = [[-0.09031782 -0.07660237  0.          0.8682227 ]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 1751 is [True, False, False, False, True, False]
State prediction error at timestep 1751 is 0.012
Current timestep = 1752. State = [[-0.07389797  0.09853968]]. Action = [[-0.01614137 -0.02381063  0.         -0.4346351 ]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 1752 is [True, False, False, False, True, False]
State prediction error at timestep 1752 is 0.012
Current timestep = 1753. State = [[-0.07899652  0.09635393]]. Action = [[-0.08825959 -0.02412829  0.          0.63212514]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 1753 is [True, False, False, False, True, False]
State prediction error at timestep 1753 is 0.012
Current timestep = 1754. State = [[-0.08411945  0.09939429]]. Action = [[-0.04636723  0.07786018  0.          0.5513848 ]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 1754 is [True, False, False, False, True, False]
State prediction error at timestep 1754 is 0.012
Current timestep = 1755. State = [[-0.08429347  0.10125934]]. Action = [[ 0.04648348 -0.01095081  0.         -0.08765185]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 1755 is [True, False, False, False, True, False]
State prediction error at timestep 1755 is 0.012
Current timestep = 1756. State = [[-0.08676488  0.1008665 ]]. Action = [[-0.05477068 -0.00665688  0.         -0.38110363]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 1756 is [True, False, False, False, True, False]
State prediction error at timestep 1756 is 0.012
Current timestep = 1757. State = [[-0.08937626  0.09997779]]. Action = [[-0.00301284 -0.01590932  0.          0.19212437]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 1757 is [True, False, False, False, True, False]
State prediction error at timestep 1757 is 0.012
Current timestep = 1758. State = [[-0.0883789   0.10001668]]. Action = [[ 0.04838067  0.01017908  0.         -0.03108406]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 1758 is [True, False, False, False, True, False]
State prediction error at timestep 1758 is 0.012
Current timestep = 1759. State = [[-0.08400533  0.10183616]]. Action = [[0.09399762 0.0319856  0.         0.6351199 ]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 1759 is [True, False, False, False, True, False]
State prediction error at timestep 1759 is 0.012
Current timestep = 1760. State = [[-0.08088043  0.10296952]]. Action = [[0.04042246 0.00591005 0.         0.51727974]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 1760 is [True, False, False, False, True, False]
State prediction error at timestep 1760 is 0.012
Current timestep = 1761. State = [[-0.08303708  0.10596813]]. Action = [[-0.05003921  0.05780723  0.          0.9466145 ]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 1761 is [True, False, False, False, True, False]
State prediction error at timestep 1761 is 0.012
Current timestep = 1762. State = [[-0.08895476  0.10368143]]. Action = [[-0.08233993 -0.08326821  0.          0.9887048 ]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 1762 is [True, False, False, False, True, False]
State prediction error at timestep 1762 is 0.012
Current timestep = 1763. State = [[-0.08760779  0.09964993]]. Action = [[ 0.09124406 -0.03500307  0.          0.22977698]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 1763 is [True, False, False, False, True, False]
State prediction error at timestep 1763 is 0.012
Current timestep = 1764. State = [[-0.08382386  0.10154355]]. Action = [[0.03163054 0.06741779 0.         0.5547309 ]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 1764 is [True, False, False, False, True, False]
State prediction error at timestep 1764 is 0.012
Current timestep = 1765. State = [[-0.08625438  0.10345337]]. Action = [[-0.07374009  0.00240584  0.          0.38589776]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 1765 is [True, False, False, False, True, False]
State prediction error at timestep 1765 is 0.012
Current timestep = 1766. State = [[-0.08911619  0.10077416]]. Action = [[-0.0259169  -0.0578509   0.         -0.72889966]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 1766 is [True, False, False, False, True, False]
State prediction error at timestep 1766 is 0.012
Current timestep = 1767. State = [[-0.08776002  0.10006087]]. Action = [[ 0.03922526  0.02155519  0.         -0.37455046]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 1767 is [True, False, False, False, True, False]
State prediction error at timestep 1767 is 0.012
Current timestep = 1768. State = [[-0.09012415  0.10425497]]. Action = [[-0.07398352  0.07328402  0.          0.2144723 ]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 1768 is [True, False, False, False, True, False]
State prediction error at timestep 1768 is 0.012
Current timestep = 1769. State = [[-0.08812048  0.10378316]]. Action = [[ 0.09438575 -0.06065816  0.          0.41742063]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 1769 is [True, False, False, False, True, False]
State prediction error at timestep 1769 is 0.012
Current timestep = 1770. State = [[-0.08305362  0.10493527]]. Action = [[ 0.05007961  0.05579611  0.         -0.07271636]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 1770 is [True, False, False, False, True, False]
State prediction error at timestep 1770 is 0.012
Current timestep = 1771. State = [[-0.07851292  0.10485986]]. Action = [[ 0.05697889 -0.03317353  0.         -0.6158722 ]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 1771 is [True, False, False, False, True, False]
State prediction error at timestep 1771 is 0.012
Current timestep = 1772. State = [[-0.07913651  0.10746824]]. Action = [[-0.06037867  0.07066952  0.         -0.5504531 ]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 1772 is [True, False, False, False, True, False]
State prediction error at timestep 1772 is 0.012
Current timestep = 1773. State = [[-0.0826982   0.11302851]]. Action = [[-0.04958912  0.06238439  0.         -0.42973542]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 1773 is [True, False, False, False, True, False]
State prediction error at timestep 1773 is 0.012
Current timestep = 1774. State = [[-0.08009473  0.11510438]]. Action = [[ 0.08599373 -0.01364989  0.         -0.36483973]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 1774 is [True, False, False, False, True, False]
State prediction error at timestep 1774 is 0.012
Current timestep = 1775. State = [[-0.07650235  0.12014066]]. Action = [[ 0.02278195  0.09153824  0.         -0.9625704 ]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 1775 is [True, False, False, False, True, False]
State prediction error at timestep 1775 is 0.012
Current timestep = 1776. State = [[-0.07727491  0.12086002]]. Action = [[-0.03795169 -0.05873302  0.         -0.6483165 ]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 1776 is [True, False, False, False, True, False]
State prediction error at timestep 1776 is 0.012
Current timestep = 1777. State = [[-0.07632902  0.12504585]]. Action = [[0.03018337 0.09653267 0.         0.18843246]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 1777 is [True, False, False, False, False, True]
State prediction error at timestep 1777 is 0.012
Current timestep = 1778. State = [[-0.07179843  0.12925784]]. Action = [[0.07478749 0.00643063 0.         0.8803129 ]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 1778 is [True, False, False, False, False, True]
State prediction error at timestep 1778 is 0.012
Current timestep = 1779. State = [[-0.06586631  0.13435362]]. Action = [[0.07919938 0.07393175 0.         0.2367853 ]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 1779 is [True, False, False, False, False, True]
State prediction error at timestep 1779 is 0.012
Current timestep = 1780. State = [[-0.06435272  0.13957386]]. Action = [[-0.01819468  0.03808714  0.         -0.8032513 ]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 1780 is [True, False, False, False, False, True]
State prediction error at timestep 1780 is 0.012
Current timestep = 1781. State = [[-0.06454688  0.14297181]]. Action = [[-0.00301035  0.01667675  0.         -0.49801904]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 1781 is [True, False, False, False, False, True]
State prediction error at timestep 1781 is 0.012
Current timestep = 1782. State = [[-0.06708641  0.14635135]]. Action = [[-0.0619335   0.02738775  0.          0.37807095]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 1782 is [True, False, False, False, False, True]
State prediction error at timestep 1782 is 0.012
Current timestep = 1783. State = [[-0.06847622  0.15322717]]. Action = [[-0.00487617  0.08729549  0.          0.06356204]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 1783 is [True, False, False, False, False, True]
State prediction error at timestep 1783 is 0.012
Current timestep = 1784. State = [[-0.06979728  0.15545413]]. Action = [[-0.02977648 -0.04496662  0.         -0.6610155 ]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 1784 is [True, False, False, False, False, True]
State prediction error at timestep 1784 is 0.012
Current timestep = 1785. State = [[-0.06986238  0.15911482]]. Action = [[ 0.00668412  0.06245621  0.         -0.21841449]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 1785 is [True, False, False, False, False, True]
State prediction error at timestep 1785 is 0.012
Current timestep = 1786. State = [[-0.07058901  0.16288936]]. Action = [[-0.02185344  0.00674478  0.         -0.26141226]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 1786 is [True, False, False, False, False, True]
State prediction error at timestep 1786 is 0.012
Current timestep = 1787. State = [[-0.06780677  0.16395971]]. Action = [[ 0.06717952 -0.01355167  0.          0.56604433]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 1787 is [True, False, False, False, False, True]
State prediction error at timestep 1787 is 0.012
Current timestep = 1788. State = [[-0.06471212  0.1660019 ]]. Action = [[0.02509514 0.02810099 0.         0.05232263]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 1788 is [True, False, False, False, False, True]
State prediction error at timestep 1788 is 0.012
Current timestep = 1789. State = [[-0.06157473  0.16750196]]. Action = [[ 0.04576727 -0.00190106  0.         -0.9704472 ]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 1789 is [True, False, False, False, False, True]
State prediction error at timestep 1789 is 0.012
Current timestep = 1790. State = [[-0.06425972  0.1655345 ]]. Action = [[-0.09881818 -0.05167935  0.         -0.99042743]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 1790 is [True, False, False, False, False, True]
State prediction error at timestep 1790 is 0.012
Current timestep = 1791. State = [[-0.06865226  0.15959564]]. Action = [[-0.05149957 -0.09926713  0.         -0.05182064]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 1791 is [True, False, False, False, False, True]
State prediction error at timestep 1791 is 0.012
Current timestep = 1792. State = [[-0.07399336  0.15854898]]. Action = [[-0.0926981   0.03564657  0.         -0.9041183 ]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 1792 is [True, False, False, False, False, True]
State prediction error at timestep 1792 is 0.012
Current timestep = 1793. State = [[-0.07627025  0.15993251]]. Action = [[0.00241686 0.00663383 0.         0.4343866 ]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 1793 is [True, False, False, False, False, True]
State prediction error at timestep 1793 is 0.012
Current timestep = 1794. State = [[-0.07871193  0.16101268]]. Action = [[-0.04634059  0.01442592  0.          0.03533292]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 1794 is [True, False, False, False, False, True]
State prediction error at timestep 1794 is 0.012
Current timestep = 1795. State = [[-0.08164515  0.16143577]]. Action = [[-0.02703237 -0.00389381  0.          0.52578735]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 1795 is [True, False, False, False, False, True]
State prediction error at timestep 1795 is 0.012
Current timestep = 1796. State = [[-0.08216015  0.16556658]]. Action = [[0.02072515 0.08080316 0.         0.6454046 ]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 1796 is [True, False, False, False, False, True]
State prediction error at timestep 1796 is 0.012
Current timestep = 1797. State = [[-0.08111045  0.17151546]]. Action = [[ 0.03750982  0.06529029  0.         -0.8316934 ]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 1797 is [True, False, False, False, False, True]
State prediction error at timestep 1797 is 0.012
Current timestep = 1798. State = [[-0.08481687  0.17895776]]. Action = [[-0.06884582  0.09540395  0.         -0.6814844 ]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 1798 is [True, False, False, False, False, True]
State prediction error at timestep 1798 is 0.012
Current timestep = 1799. State = [[-0.33661634  0.2628328 ]]. Action = [[-0.01489967  0.06196361  0.         -0.4528246 ]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 1799 is [True, False, False, False, False, True]
State prediction error at timestep 1799 is 0.012
Current timestep = 1800. State = [[-0.34172928  0.25838697]]. Action = [[ 0.01349102 -0.05437597  0.          0.3949399 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1800 is [True, False, False, False, False, True]
State prediction error at timestep 1800 is 0.012
Current timestep = 1801. State = [[-0.34882876  0.2527931 ]]. Action = [[-0.08765553 -0.05404235  0.         -0.9843183 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1801 is [True, False, False, False, False, True]
State prediction error at timestep 1801 is 0.012
Current timestep = 1802. State = [[-0.35022688  0.24769983]]. Action = [[ 0.08128881 -0.03983359  0.          0.15434706]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 1802 is [True, False, False, False, False, True]
State prediction error at timestep 1802 is 0.012
Current timestep = 1803. State = [[-0.3537064   0.24721947]]. Action = [[-0.0746993   0.04762148  0.          0.7184806 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 1803 is [True, False, False, False, False, True]
State prediction error at timestep 1803 is 0.012
Current timestep = 1804. State = [[-0.3534127   0.24700993]]. Action = [[ 0.0906306  -0.00247186  0.         -0.991932  ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 1804 is [True, False, False, False, False, True]
State prediction error at timestep 1804 is 0.012
Current timestep = 1805. State = [[-0.35265002  0.24251117]]. Action = [[-0.00744805 -0.0629541   0.          0.43417978]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 1805 is [True, False, False, False, False, True]
State prediction error at timestep 1805 is 0.012
Current timestep = 1806. State = [[-0.3507872   0.24333872]]. Action = [[0.0625787  0.08107973 0.         0.20502663]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1806 is [True, False, False, False, False, True]
State prediction error at timestep 1806 is 0.012
Current timestep = 1807. State = [[-0.35300052  0.24659643]]. Action = [[-0.06206784  0.04076868  0.         -0.3216324 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 1807 is [True, False, False, False, False, True]
State prediction error at timestep 1807 is 0.012
Current timestep = 1808. State = [[-0.35754967  0.24758983]]. Action = [[-0.0366398   0.00258908  0.         -0.14769137]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 1808 is [True, False, False, False, False, True]
State prediction error at timestep 1808 is 0.012
Current timestep = 1809. State = [[-0.36258167  0.2500505 ]]. Action = [[-0.05759055  0.04749426  0.         -0.39111662]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 1809 is [True, False, False, False, False, True]
State prediction error at timestep 1809 is 0.012
Current timestep = 1810. State = [[-0.3637697   0.24982919]]. Action = [[ 0.03354054 -0.03658297  0.         -0.18492502]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1810 is [True, False, False, False, False, True]
State prediction error at timestep 1810 is 0.012
Current timestep = 1811. State = [[-0.3591313   0.24991837]]. Action = [[ 0.09644672  0.02342035  0.         -0.58817244]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 1811 is [True, False, False, False, False, True]
State prediction error at timestep 1811 is 0.012
Current timestep = 1812. State = [[-0.35644606  0.2518076 ]]. Action = [[0.01213177 0.03015963 0.         0.02520061]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 1812 is [True, False, False, False, False, True]
State prediction error at timestep 1812 is 0.012
Current timestep = 1813. State = [[-0.35996056  0.25755227]]. Action = [[-0.07138712  0.09323476  0.         -0.86854815]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 1813 is [True, False, False, False, False, True]
State prediction error at timestep 1813 is 0.012
Current timestep = 1814. State = [[-0.3646111   0.26082984]]. Action = [[-0.04104346 -0.00541902  0.         -0.7207546 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 1814 is [True, False, False, False, False, True]
State prediction error at timestep 1814 is 0.012
Current timestep = 1815. State = [[-0.36820593  0.2664236 ]]. Action = [[-0.03157756  0.09147208  0.         -0.43759048]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 1815 is [True, False, False, False, False, True]
State prediction error at timestep 1815 is 0.012
Current timestep = 1816. State = [[-0.3657426   0.27107942]]. Action = [[0.09462284 0.02075914 0.         0.2780068 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 1816 is [True, False, False, False, False, True]
State prediction error at timestep 1816 is 0.012
Current timestep = 1817. State = [[-0.3657952   0.26888755]]. Action = [[-0.04903604 -0.08053245  0.          0.9070289 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 1817 is [True, False, False, False, False, True]
State prediction error at timestep 1817 is 0.012
Current timestep = 1818. State = [[-0.36758348  0.26642695]]. Action = [[-0.00387849 -0.02268862  0.         -0.90705144]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 1818 is [True, False, False, False, False, True]
State prediction error at timestep 1818 is 0.012
Current timestep = 1819. State = [[-0.3664575   0.26665658]]. Action = [[0.03291658 0.00855271 0.         0.08360457]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 1819 is [True, False, False, False, False, True]
State prediction error at timestep 1819 is 0.012
Current timestep = 1820. State = [[-0.36349112  0.26984257]]. Action = [[ 0.04818665  0.0563921   0.         -0.47734702]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 1820 is [True, False, False, False, False, True]
State prediction error at timestep 1820 is 0.012
Current timestep = 1821. State = [[-0.36602238  0.27387074]]. Action = [[-0.07530857  0.04211379  0.         -0.9671959 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 1821 is [True, False, False, False, False, True]
State prediction error at timestep 1821 is 0.012
Current timestep = 1822. State = [[-0.3661408   0.27279392]]. Action = [[ 0.04602899 -0.05911312  0.          0.5169382 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 1822 is [True, False, False, False, False, True]
State prediction error at timestep 1822 is 0.012
Current timestep = 1823. State = [[-0.36212826  0.2726506 ]]. Action = [[0.05768945 0.02828353 0.         0.04053569]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 1823 is [True, False, False, False, False, True]
State prediction error at timestep 1823 is 0.012
Current timestep = 1824. State = [[-0.36171684  0.2781078 ]]. Action = [[-0.02322806  0.09609439  0.          0.03250098]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 1824 is [True, False, False, False, False, True]
State prediction error at timestep 1824 is 0.012
Current timestep = 1825. State = [[-0.3612325   0.28075287]]. Action = [[ 0.02740896 -0.00915197  0.          0.33181524]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 1825 is [True, False, False, False, False, True]
State prediction error at timestep 1825 is 0.012
Current timestep = 1826. State = [[-0.35597205  0.27751932]]. Action = [[ 0.08712388 -0.0669388   0.          0.8758216 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 1826 is [True, False, False, False, False, True]
State prediction error at timestep 1826 is 0.012
Current timestep = 1827. State = [[-0.34887296  0.2770628 ]]. Action = [[0.07874876 0.03414897 0.         0.5709851 ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 1827 is [True, False, False, False, False, True]
State prediction error at timestep 1827 is 0.012
Current timestep = 1828. State = [[-0.3436461   0.27589288]]. Action = [[ 0.03739572 -0.03644697  0.          0.19752872]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 1828 is [True, False, False, False, False, True]
State prediction error at timestep 1828 is 0.012
Current timestep = 1829. State = [[-0.3382073   0.27707362]]. Action = [[0.05866232 0.04822411 0.         0.23586345]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 1829 is [True, False, False, False, False, True]
State prediction error at timestep 1829 is 0.012
Current timestep = 1830. State = [[-0.33274364  0.27709556]]. Action = [[ 0.04641841 -0.02160809  0.          0.45841348]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 1830 is [True, False, False, False, False, True]
State prediction error at timestep 1830 is 0.012
Current timestep = 1831. State = [[-0.32523617  0.2800713 ]]. Action = [[ 0.09130531  0.07746329  0.         -0.41867483]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 1831 is [True, False, False, False, False, True]
State prediction error at timestep 1831 is 0.012
Current timestep = 1832. State = [[-0.32014248  0.28274027]]. Action = [[ 0.01671152  0.0141819   0.         -0.7452286 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 1832 is [True, False, False, False, False, True]
State prediction error at timestep 1832 is 0.012
Current timestep = 1833. State = [[-0.31488004  0.28706786]]. Action = [[ 0.06063879  0.07488015  0.         -0.15598786]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 1833 is [True, False, False, False, False, True]
State prediction error at timestep 1833 is 0.012
Current timestep = 1834. State = [[-0.3148682  0.2924716]]. Action = [[-0.06709722  0.05512915  0.          0.53340125]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 1834 is [True, False, False, False, False, True]
State prediction error at timestep 1834 is 0.012
Current timestep = 1835. State = [[-0.3115723  0.2981695]]. Action = [[ 0.08443912  0.06302353  0.         -0.69487464]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 1835 is [True, False, False, False, False, True]
State prediction error at timestep 1835 is 0.012
Current timestep = 1836. State = [[-0.3074968   0.30504242]]. Action = [[0.01559015 0.08017962 0.         0.33564138]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 1836 is [True, False, False, False, False, True]
State prediction error at timestep 1836 is 0.012
Current timestep = 1837. State = [[-0.30598834  0.31341597]]. Action = [[0.00383469 0.09248757 0.         0.2138387 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 1837 is [True, False, False, False, False, True]
State prediction error at timestep 1837 is 0.012
Current timestep = 1838. State = [[-0.3021758   0.32121408]]. Action = [[0.06436353 0.06778566 0.         0.04114521]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 1838 is [True, False, False, False, False, True]
State prediction error at timestep 1838 is 0.012
Current timestep = 1839. State = [[-0.3033704   0.32363117]]. Action = [[-0.08271053 -0.03912226  0.         -0.32096112]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 1839 is [True, False, False, False, False, True]
State prediction error at timestep 1839 is 0.012
Current timestep = 1840. State = [[-0.30211496  0.3240455 ]]. Action = [[ 0.06186118 -0.01740701  0.         -0.90056103]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 1840 is [True, False, False, False, False, True]
State prediction error at timestep 1840 is 0.012
Current timestep = 1841. State = [[-0.29817015  0.32121962]]. Action = [[ 0.02795469 -0.08490829  0.          0.34604418]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 1841 is [True, False, False, False, False, True]
State prediction error at timestep 1841 is 0.012
Current timestep = 1842. State = [[-0.2944621  0.320998 ]]. Action = [[0.02964889 0.01356101 0.         0.4591936 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 1842 is [True, False, False, False, False, True]
State prediction error at timestep 1842 is 0.012
Current timestep = 1843. State = [[-0.2902396  0.319123 ]]. Action = [[ 0.03787532 -0.06632574  0.         -0.7867352 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 1843 is [True, False, False, False, False, True]
State prediction error at timestep 1843 is 0.012
Current timestep = 1844. State = [[-0.285613   0.3173315]]. Action = [[ 0.03527138 -0.01205804  0.         -0.6131673 ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 1844 is [True, False, False, False, False, True]
State prediction error at timestep 1844 is 0.012
Current timestep = 1845. State = [[-0.28185835  0.31541806]]. Action = [[ 0.01771478 -0.03559149  0.         -0.87961894]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 1845 is [True, False, False, False, False, True]
State prediction error at timestep 1845 is 0.012
Current timestep = 1846. State = [[-0.27975672  0.31207222]]. Action = [[-7.4027330e-03 -4.8104268e-02  0.0000000e+00 -7.9751015e-05]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 1846 is [True, False, False, False, False, True]
State prediction error at timestep 1846 is 0.012
Current timestep = 1847. State = [[-0.27680552  0.31158346]]. Action = [[ 0.02784371  0.02328558  0.         -0.42326075]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 1847 is [True, False, False, False, False, True]
State prediction error at timestep 1847 is 0.012
Current timestep = 1848. State = [[-0.2789829   0.31329387]]. Action = [[-0.08879887  0.0276167   0.         -0.20932436]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 1848 is [True, False, False, False, False, True]
State prediction error at timestep 1848 is 0.012
Current timestep = 1849. State = [[-0.2770273   0.31091762]]. Action = [[ 0.07037305 -0.06292213  0.          0.05258882]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 1849 is [True, False, False, False, False, True]
State prediction error at timestep 1849 is 0.012
Current timestep = 1850. State = [[-0.27192554  0.30384555]]. Action = [[ 0.04369881 -0.09386579  0.         -0.48414242]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 1850 is [True, False, False, False, False, True]
State prediction error at timestep 1850 is 0.012
Current timestep = 1851. State = [[-0.26733217  0.29615885]]. Action = [[ 0.03758117 -0.07887987  0.         -0.14457983]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 1851 is [True, False, False, False, False, True]
State prediction error at timestep 1851 is 0.012
Current timestep = 1852. State = [[-0.26804727  0.2905017 ]]. Action = [[-0.06953683 -0.04428416  0.          0.29021597]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 1852 is [True, False, False, False, False, True]
State prediction error at timestep 1852 is 0.012
Current timestep = 1853. State = [[-0.27238616  0.28744143]]. Action = [[-0.07619123 -0.01757538  0.         -0.73973894]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 1853 is [True, False, False, False, False, True]
State prediction error at timestep 1853 is 0.012
Current timestep = 1854. State = [[-0.27242383  0.286374  ]]. Action = [[0.0345505  0.00962595 0.         0.5664904 ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 1854 is [True, False, False, False, False, True]
State prediction error at timestep 1854 is 0.012
Current timestep = 1855. State = [[-0.274992    0.28631315]]. Action = [[-0.07242259  0.01536945  0.         -0.3604843 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 1855 is [True, False, False, False, False, True]
State prediction error at timestep 1855 is 0.012
Current timestep = 1856. State = [[-0.27516744  0.29012185]]. Action = [[ 0.05119494  0.08642676  0.         -0.4434569 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 1856 is [True, False, False, False, False, True]
State prediction error at timestep 1856 is 0.012
Current timestep = 1857. State = [[-0.2731776  0.29466  ]]. Action = [[0.03477768 0.05856278 0.         0.3772328 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 1857 is [True, False, False, False, False, True]
State prediction error at timestep 1857 is 0.012
Current timestep = 1858. State = [[-0.27308303  0.29354694]]. Action = [[-0.00184292 -0.04806064  0.         -0.07136655]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 1858 is [True, False, False, False, False, True]
State prediction error at timestep 1858 is 0.012
Current timestep = 1859. State = [[-0.2736697   0.29111657]]. Action = [[-0.00298283 -0.01793899  0.         -0.44386387]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 1859 is [True, False, False, False, False, True]
State prediction error at timestep 1859 is 0.012
Current timestep = 1860. State = [[-0.27607846  0.29300812]]. Action = [[-0.03766451  0.05245527  0.         -0.8171003 ]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 1860 is [True, False, False, False, False, True]
State prediction error at timestep 1860 is 0.012
Current timestep = 1861. State = [[-0.28001246  0.2901069 ]]. Action = [[-0.04816995 -0.09297175  0.         -0.02103025]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 1861 is [True, False, False, False, False, True]
State prediction error at timestep 1861 is 0.012
Current timestep = 1862. State = [[-0.2824121  0.2903627]]. Action = [[-0.01249328  0.0531626   0.          0.2358551 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 1862 is [True, False, False, False, False, True]
State prediction error at timestep 1862 is 0.012
Current timestep = 1863. State = [[-0.28015542  0.29140037]]. Action = [[ 0.06920462 -0.00684841  0.         -0.60320383]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 1863 is [True, False, False, False, False, True]
State prediction error at timestep 1863 is 0.012
Current timestep = 1864. State = [[-0.27433997  0.28913143]]. Action = [[ 0.08988979 -0.03345097  0.         -0.98405915]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 1864 is [True, False, False, False, False, True]
State prediction error at timestep 1864 is 0.012
Current timestep = 1865. State = [[-0.26782674  0.28520513]]. Action = [[ 0.07804721 -0.04306026  0.         -0.65278006]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 1865 is [True, False, False, False, False, True]
State prediction error at timestep 1865 is 0.012
Current timestep = 1866. State = [[-0.2647044   0.28125602]]. Action = [[ 0.00298209 -0.03608073  0.          0.68155754]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 1866 is [True, False, False, False, False, True]
State prediction error at timestep 1866 is 0.012
Current timestep = 1867. State = [[-0.26114276  0.2811464 ]]. Action = [[ 0.0511562   0.03738513  0.         -0.21137404]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 1867 is [True, False, False, False, False, True]
State prediction error at timestep 1867 is 0.012
Current timestep = 1868. State = [[-0.26223147  0.28430146]]. Action = [[-0.06762303  0.05812337  0.         -0.960811  ]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 1868 is [True, False, False, False, False, True]
State prediction error at timestep 1868 is 0.012
Current timestep = 1869. State = [[-0.26731092  0.285351  ]]. Action = [[-0.07957749 -0.01261324  0.          0.67751694]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 1869 is [True, False, False, False, False, True]
State prediction error at timestep 1869 is 0.012
Current timestep = 1870. State = [[-0.2737354  0.2892691]]. Action = [[-0.08893022  0.07562464  0.         -0.7391579 ]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 1870 is [True, False, False, False, False, True]
State prediction error at timestep 1870 is 0.012
Current timestep = 1871. State = [[-0.2774568  0.2953554]]. Action = [[-0.00970067  0.06441664  0.         -0.14355516]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 1871 is [True, False, False, False, False, True]
State prediction error at timestep 1871 is 0.012
Current timestep = 1872. State = [[-0.27706823  0.29607734]]. Action = [[ 0.03619605 -0.03966311  0.         -0.8220624 ]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 1872 is [True, False, False, False, False, True]
State prediction error at timestep 1872 is 0.012
Current timestep = 1873. State = [[-0.27965686  0.29879886]]. Action = [[-0.05657351  0.06244377  0.          0.4753623 ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 1873 is [True, False, False, False, False, True]
State prediction error at timestep 1873 is 0.012
Current timestep = 1874. State = [[-0.27973434  0.30110684]]. Action = [[ 0.05077363 -0.00577509  0.          0.8824527 ]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 1874 is [True, False, False, False, False, True]
State prediction error at timestep 1874 is 0.012
Current timestep = 1875. State = [[-0.27824736  0.29708004]]. Action = [[ 0.01580151 -0.09228227  0.          0.6442177 ]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 1875 is [True, False, False, False, False, True]
State prediction error at timestep 1875 is 0.012
Current timestep = 1876. State = [[-0.27573287  0.29010534]]. Action = [[ 0.03877131 -0.09492137  0.         -0.89780515]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 1876 is [True, False, False, False, False, True]
State prediction error at timestep 1876 is 0.012
Current timestep = 1877. State = [[-0.27292138  0.2874003 ]]. Action = [[0.02559369 0.00660658 0.         0.13359904]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 1877 is [True, False, False, False, False, True]
State prediction error at timestep 1877 is 0.012
Current timestep = 1878. State = [[-0.27280876  0.2876341 ]]. Action = [[-0.02240995  0.01165972  0.         -0.2776661 ]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 1878 is [True, False, False, False, False, True]
State prediction error at timestep 1878 is 0.012
Current timestep = 1879. State = [[-0.2683672  0.2885583]]. Action = [[ 0.09767585  0.02392018  0.         -0.18599921]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 1879 is [True, False, False, False, False, True]
State prediction error at timestep 1879 is 0.012
Current timestep = 1880. State = [[-0.2680126   0.28757966]]. Action = [[-0.06369312 -0.02273779  0.         -0.40484488]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 1880 is [True, False, False, False, False, True]
State prediction error at timestep 1880 is 0.012
Current timestep = 1881. State = [[-0.273298   0.2861057]]. Action = [[-0.08065238 -0.01205684  0.          0.64593077]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 1881 is [True, False, False, False, False, True]
State prediction error at timestep 1881 is 0.012
Current timestep = 1882. State = [[-0.27543256  0.28344116]]. Action = [[ 0.0034339  -0.04350882  0.         -0.736842  ]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 1882 is [True, False, False, False, False, True]
State prediction error at timestep 1882 is 0.012
Current timestep = 1883. State = [[-0.27790016  0.2840622 ]]. Action = [[-0.04608045  0.04458355  0.         -0.74979585]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 1883 is [True, False, False, False, False, True]
State prediction error at timestep 1883 is 0.012
Current timestep = 1884. State = [[-0.27902535  0.28418604]]. Action = [[ 0.01400308 -0.01732937  0.         -0.43846136]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 1884 is [True, False, False, False, False, True]
State prediction error at timestep 1884 is 0.012
Current timestep = 1885. State = [[-0.27888632  0.2801087 ]]. Action = [[ 0.00386808 -0.06650314  0.         -0.6245581 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 1885 is [True, False, False, False, False, True]
State prediction error at timestep 1885 is 0.012
Current timestep = 1886. State = [[-0.2772753  0.280862 ]]. Action = [[0.03701647 0.06609941 0.         0.5057864 ]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 1886 is [True, False, False, False, False, True]
State prediction error at timestep 1886 is 0.012
Current timestep = 1887. State = [[-0.27376962  0.27928478]]. Action = [[ 0.0606866 -0.0532154  0.         0.5510063]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 1887 is [True, False, False, False, False, True]
State prediction error at timestep 1887 is 0.012
Current timestep = 1888. State = [[-0.27210763  0.27915183]]. Action = [[0.00203433 0.04286683 0.         0.3914591 ]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 1888 is [True, False, False, False, False, True]
State prediction error at timestep 1888 is 0.012
Current timestep = 1889. State = [[-0.27537856  0.2838173 ]]. Action = [[-0.06286196  0.08027258  0.         -0.16862947]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 1889 is [True, False, False, False, False, True]
State prediction error at timestep 1889 is 0.012
Current timestep = 1890. State = [[-0.27329674  0.28978637]]. Action = [[0.09779207 0.07766003 0.         0.7569704 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 1890 is [True, False, False, False, False, True]
State prediction error at timestep 1890 is 0.012
Current timestep = 1891. State = [[-0.27118883  0.29448828]]. Action = [[0.00089165 0.04925784 0.         0.6255307 ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 1891 is [True, False, False, False, False, True]
State prediction error at timestep 1891 is 0.012
Current timestep = 1892. State = [[-0.27053547  0.292377  ]]. Action = [[ 0.01304398 -0.0819002   0.          0.2858565 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 1892 is [True, False, False, False, False, True]
State prediction error at timestep 1892 is 0.012
Current timestep = 1893. State = [[-0.2710461  0.2911408]]. Action = [[-0.02587685  0.00798619  0.          0.52175903]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 1893 is [True, False, False, False, False, True]
State prediction error at timestep 1893 is 0.012
Current timestep = 1894. State = [[-0.26674458  0.2913954 ]]. Action = [[ 0.09489652 -0.00722487  0.         -0.3664754 ]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 1894 is [True, False, False, False, False, True]
State prediction error at timestep 1894 is 0.012
Current timestep = 1895. State = [[-0.26192623  0.28710097]]. Action = [[ 0.02675354 -0.0862484   0.          0.9247385 ]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 1895 is [True, False, False, False, False, True]
State prediction error at timestep 1895 is 0.012
Current timestep = 1896. State = [[-0.25905675  0.28801528]]. Action = [[ 0.01605217  0.06849795  0.         -0.91669804]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 1896 is [True, False, False, False, False, True]
State prediction error at timestep 1896 is 0.012
Current timestep = 1897. State = [[-0.25394276  0.2940967 ]]. Action = [[ 0.07841241  0.08684806  0.         -0.11962384]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 1897 is [True, False, False, False, False, True]
State prediction error at timestep 1897 is 0.012
Current timestep = 1898. State = [[-0.25005847  0.30107015]]. Action = [[0.02268483 0.09008726 0.         0.9265833 ]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 1898 is [True, False, False, False, False, True]
State prediction error at timestep 1898 is 0.012
Current timestep = 1899. State = [[-0.24745035  0.3021468 ]]. Action = [[ 0.02407628 -0.04015079  0.          0.0570097 ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 1899 is [True, False, False, False, False, True]
State prediction error at timestep 1899 is 0.012
Current timestep = 1900. State = [[-0.24119495  0.30359006]]. Action = [[ 0.09174635  0.0409212   0.         -0.5168421 ]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 1900 is [True, False, False, False, False, True]
State prediction error at timestep 1900 is 0.012
Current timestep = 1901. State = [[-0.24066749  0.3087702 ]]. Action = [[-0.06696109  0.07042407  0.         -0.23200667]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 1901 is [True, False, False, False, False, True]
State prediction error at timestep 1901 is 0.012
Current timestep = 1902. State = [[-0.2455815   0.30777138]]. Action = [[-0.08808067 -0.09017112  0.         -0.61228156]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 1902 is [True, False, False, False, False, True]
State prediction error at timestep 1902 is 0.012
Current timestep = 1903. State = [[-0.24296644  0.30561092]]. Action = [[ 0.09093788 -0.01757411  0.          0.10127807]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 1903 is [True, False, False, False, False, True]
State prediction error at timestep 1903 is 0.012
Current timestep = 1904. State = [[-0.24228151  0.30590436]]. Action = [[-0.07061414 -0.00418192  0.         -0.63273686]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 1904 is [True, False, False, False, False, True]
State prediction error at timestep 1904 is 0.012
Current timestep = 1905. State = [[-0.24276061  0.30418688]]. Action = [[-0.00463334 -0.05751845  0.          0.80519223]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 1905 is [True, False, False, False, False, True]
State prediction error at timestep 1905 is 0.012
Current timestep = 1906. State = [[-0.24621177  0.3055404 ]]. Action = [[-0.09408499  0.03864474  0.          0.01888502]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 1906 is [True, False, False, False, False, True]
State prediction error at timestep 1906 is 0.012
Current timestep = 1907. State = [[-0.2513965  0.3127825]]. Action = [[-0.06185544  0.09969909  0.         -0.29132795]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 1907 is [True, False, False, False, False, True]
State prediction error at timestep 1907 is 0.012
Current timestep = 1908. State = [[-0.25280505  0.31538075]]. Action = [[ 0.01525334 -0.03195626  0.          0.6241839 ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 1908 is [True, False, False, False, False, True]
State prediction error at timestep 1908 is 0.012
Current timestep = 1909. State = [[-0.24810234  0.31111392]]. Action = [[ 0.09366953 -0.08412383  0.          0.79502475]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 1909 is [True, False, False, False, False, True]
State prediction error at timestep 1909 is 0.012
Current timestep = 1910. State = [[-0.24859953  0.30996528]]. Action = [[-0.06623951  0.02556237  0.          0.16498303]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 1910 is [True, False, False, False, False, True]
State prediction error at timestep 1910 is 0.012
Current timestep = 1911. State = [[-0.24722394  0.30887347]]. Action = [[ 0.06385676 -0.04012777  0.         -0.7955507 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 1911 is [True, False, False, False, False, True]
State prediction error at timestep 1911 is 0.012
Current timestep = 1912. State = [[-0.24441792  0.30747136]]. Action = [[ 0.02132257 -0.00102261  0.         -0.0360083 ]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 1912 is [True, False, False, False, False, True]
State prediction error at timestep 1912 is 0.012
Current timestep = 1913. State = [[-0.24029067  0.3071772 ]]. Action = [[0.0682792  0.00648465 0.         0.8329289 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 1913 is [True, False, False, False, False, True]
State prediction error at timestep 1913 is 0.012
Current timestep = 1914. State = [[-0.24207772  0.30862075]]. Action = [[-0.08153851  0.03538593  0.         -0.43288934]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 1914 is [True, False, False, False, False, True]
State prediction error at timestep 1914 is 0.012
Current timestep = 1915. State = [[-0.23970617  0.3089811 ]]. Action = [[ 0.09907917 -0.00498179  0.          0.62182903]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 1915 is [True, False, False, False, False, True]
State prediction error at timestep 1915 is 0.012
Current timestep = 1916. State = [[-0.2370465   0.31137496]]. Action = [[-4.3962896e-04  6.2528215e-02  0.0000000e+00  8.3572268e-01]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 1916 is [True, False, False, False, False, True]
State prediction error at timestep 1916 is 0.012
Current timestep = 1917. State = [[-0.23877968  0.3166587 ]]. Action = [[-0.03505417  0.07484364  0.         -0.53706956]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 1917 is [True, False, False, False, False, True]
State prediction error at timestep 1917 is 0.012
Current timestep = 1918. State = [[-0.24148144  0.31714046]]. Action = [[-0.03060722 -0.04244706  0.          0.01519597]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 1918 is [True, False, False, False, False, True]
State prediction error at timestep 1918 is 0.012
Current timestep = 1919. State = [[-0.23900175  0.3158954 ]]. Action = [[ 0.06920875 -0.01114453  0.         -0.44941175]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 1919 is [True, False, False, False, False, True]
State prediction error at timestep 1919 is 0.012
Current timestep = 1920. State = [[-0.23251066  0.3110076 ]]. Action = [[ 0.08613317 -0.09012108  0.          0.7015209 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 1920 is [True, False, False, False, False, True]
State prediction error at timestep 1920 is 0.012
Current timestep = 1921. State = [[-0.23365428  0.3084451 ]]. Action = [[-0.09654821  0.00291371  0.         -0.44221234]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 1921 is [True, False, False, False, False, True]
State prediction error at timestep 1921 is 0.012
Current timestep = 1922. State = [[-0.23338123  0.31035018]]. Action = [[0.04927138 0.03770844 0.         0.025563  ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 1922 is [True, False, False, False, False, True]
State prediction error at timestep 1922 is 0.012
Current timestep = 1923. State = [[-0.22693655  0.30715343]]. Action = [[ 0.09267478 -0.08202213  0.         -0.8494651 ]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 1923 is [True, False, False, False, False, True]
State prediction error at timestep 1923 is 0.012
Current timestep = 1924. State = [[-0.22149584  0.30125296]]. Action = [[ 0.0311018 -0.0605124  0.        -0.7527748]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 1924 is [True, False, False, False, False, True]
State prediction error at timestep 1924 is 0.012
Current timestep = 1925. State = [[-0.22255763  0.29464605]]. Action = [[-0.07933925 -0.08674709  0.          0.30174935]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 1925 is [True, False, False, False, False, True]
State prediction error at timestep 1925 is 0.012
Current timestep = 1926. State = [[-0.21973932  0.28988045]]. Action = [[ 0.07382228 -0.02905688  0.         -0.9945331 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 1926 is [True, False, False, False, False, True]
State prediction error at timestep 1926 is 0.012
Current timestep = 1927. State = [[-0.2166284   0.28902292]]. Action = [[-0.00975899  0.02412752  0.         -0.71156275]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 1927 is [True, False, False, False, False, True]
State prediction error at timestep 1927 is 0.012
Current timestep = 1928. State = [[-0.21534845  0.28928986]]. Action = [[0.00307681 0.01195272 0.         0.13226604]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 1928 is [True, False, False, False, False, True]
State prediction error at timestep 1928 is 0.012
Current timestep = 1929. State = [[-0.21399263  0.28813797]]. Action = [[ 0.00539738 -0.01365712  0.         -0.3632689 ]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 1929 is [True, False, False, False, False, True]
State prediction error at timestep 1929 is 0.012
Current timestep = 1930. State = [[-0.20931134  0.28225327]]. Action = [[ 0.07193943 -0.09239832  0.         -0.40194207]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 1930 is [True, False, False, False, False, True]
State prediction error at timestep 1930 is 0.012
Current timestep = 1931. State = [[-0.20765668  0.27911794]]. Action = [[-0.03093929  0.01418126  0.          0.9570453 ]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 1931 is [True, False, False, False, False, True]
State prediction error at timestep 1931 is 0.012
Current timestep = 1932. State = [[-0.20317294  0.28248367]]. Action = [[0.0978502  0.08563157 0.         0.35764384]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 1932 is [True, False, False, False, False, True]
State prediction error at timestep 1932 is 0.012
Current timestep = 1933. State = [[-0.19781534  0.28555748]]. Action = [[0.04541676 0.03324903 0.         0.18296921]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 1933 is [True, False, False, False, False, True]
State prediction error at timestep 1933 is 0.012
Current timestep = 1934. State = [[-0.19487385  0.2840652 ]]. Action = [[ 0.01652548 -0.03880318  0.          0.10014617]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 1934 is [True, False, False, False, False, True]
State prediction error at timestep 1934 is 0.012
Current timestep = 1935. State = [[-0.19723466  0.27920327]]. Action = [[-0.08557072 -0.07341452  0.         -0.71858597]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 1935 is [True, False, False, False, False, True]
State prediction error at timestep 1935 is 0.012
Current timestep = 1936. State = [[-0.1960801   0.27329504]]. Action = [[ 0.04710235 -0.07379484  0.          0.07728112]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 1936 is [True, False, False, False, False, True]
State prediction error at timestep 1936 is 0.012
Current timestep = 1937. State = [[-0.19708999  0.266585  ]]. Action = [[-0.07658699 -0.0832084   0.          0.06608105]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 1937 is [True, False, False, False, False, True]
State prediction error at timestep 1937 is 0.012
Current timestep = 1938. State = [[-0.19830881  0.26733896]]. Action = [[-0.00472566  0.0745702   0.         -0.2111175 ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 1938 is [True, False, False, False, False, True]
State prediction error at timestep 1938 is 0.012
Current timestep = 1939. State = [[-0.20094015  0.2697722 ]]. Action = [[-0.05895936  0.0134149   0.         -0.04310924]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 1939 is [True, False, False, False, False, True]
State prediction error at timestep 1939 is 0.012
Current timestep = 1940. State = [[-0.20579115  0.27313647]]. Action = [[-0.0662351   0.05515347  0.         -0.81402886]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 1940 is [True, False, False, False, False, True]
State prediction error at timestep 1940 is 0.012
Current timestep = 1941. State = [[-0.20909615  0.2743649 ]]. Action = [[-0.01855498 -0.01604833  0.          0.6030483 ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 1941 is [True, False, False, False, False, True]
State prediction error at timestep 1941 is 0.012
Current timestep = 1942. State = [[-0.2134164   0.27715927]]. Action = [[-0.0602942   0.0547451   0.         -0.16989905]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 1942 is [True, False, False, False, False, True]
State prediction error at timestep 1942 is 0.012
Current timestep = 1943. State = [[-0.21767594  0.281324  ]]. Action = [[-0.02618461  0.03893939  0.          0.76405525]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 1943 is [True, False, False, False, False, True]
State prediction error at timestep 1943 is 0.012
Current timestep = 1944. State = [[-0.21767525  0.27982247]]. Action = [[ 0.04616652 -0.06641525  0.         -0.32693553]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 1944 is [True, False, False, False, False, True]
State prediction error at timestep 1944 is 0.012
Current timestep = 1945. State = [[-0.22042003  0.282332  ]]. Action = [[-0.05458986  0.08401682  0.          0.69868803]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 1945 is [True, False, False, False, False, True]
State prediction error at timestep 1945 is 0.012
Current timestep = 1946. State = [[-0.22615297  0.28193453]]. Action = [[-0.05897544 -0.06853777  0.         -0.17874587]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 1946 is [True, False, False, False, False, True]
State prediction error at timestep 1946 is 0.012
Current timestep = 1947. State = [[-0.23003228  0.28290507]]. Action = [[-0.01922828  0.04356519  0.          0.8976617 ]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 1947 is [True, False, False, False, False, True]
State prediction error at timestep 1947 is 0.012
Current timestep = 1948. State = [[-0.22813392  0.2798859 ]]. Action = [[ 0.07862969 -0.08964047  0.         -0.43865162]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 1948 is [True, False, False, False, False, True]
State prediction error at timestep 1948 is 0.012
Current timestep = 1949. State = [[-0.22536714  0.27967307]]. Action = [[0.03259947 0.05554215 0.         0.49738586]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 1949 is [True, False, False, False, False, True]
State prediction error at timestep 1949 is 0.012
Current timestep = 1950. State = [[-0.22371432  0.2841314 ]]. Action = [[0.03464486 0.06982946 0.         0.06436622]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 1950 is [True, False, False, False, False, True]
State prediction error at timestep 1950 is 0.012
Current timestep = 1951. State = [[-0.21944772  0.28342462]]. Action = [[ 0.08411709 -0.046608    0.         -0.9476278 ]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 1951 is [True, False, False, False, False, True]
State prediction error at timestep 1951 is 0.012
Current timestep = 1952. State = [[-0.22128348  0.2776754 ]]. Action = [[-0.09589706 -0.08741461  0.          0.7396283 ]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 1952 is [True, False, False, False, False, True]
State prediction error at timestep 1952 is 0.012
Current timestep = 1953. State = [[-0.22673447  0.2744057 ]]. Action = [[-0.05662218 -0.01103112  0.          0.02065635]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 1953 is [True, False, False, False, False, True]
State prediction error at timestep 1953 is 0.012
Current timestep = 1954. State = [[-0.2270745   0.27812782]]. Action = [[0.04607844 0.09383021 0.         0.6761241 ]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 1954 is [True, False, False, False, False, True]
State prediction error at timestep 1954 is 0.012
Current timestep = 1955. State = [[-0.2309752   0.27760458]]. Action = [[-0.09892078 -0.06180264  0.         -0.62611085]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 1955 is [True, False, False, False, False, True]
State prediction error at timestep 1955 is 0.012
Current timestep = 1956. State = [[-0.23519742  0.27636915]]. Action = [[-0.01088499  0.01100235  0.          0.5186994 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 1956 is [True, False, False, False, False, True]
State prediction error at timestep 1956 is 0.012
Current timestep = 1957. State = [[-0.23824681  0.27627912]]. Action = [[-0.02811911 -0.00056319  0.         -0.3329451 ]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 1957 is [True, False, False, False, False, True]
State prediction error at timestep 1957 is 0.012
Current timestep = 1958. State = [[-0.2437532   0.27414605]]. Action = [[-0.07295015 -0.0404799   0.         -0.9995785 ]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 1958 is [True, False, False, False, False, True]
State prediction error at timestep 1958 is 0.012
Current timestep = 1959. State = [[-0.24373922  0.27390793]]. Action = [[ 0.07151241  0.02501645  0.         -0.08228993]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 1959 is [True, False, False, False, False, True]
State prediction error at timestep 1959 is 0.012
Current timestep = 1960. State = [[-0.24009259  0.27834824]]. Action = [[ 0.06021162  0.08834418  0.         -0.7281508 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 1960 is [True, False, False, False, False, True]
State prediction error at timestep 1960 is 0.012
Current timestep = 1961. State = [[-0.24079181  0.2818782 ]]. Action = [[-0.02883109  0.027193    0.          0.9162741 ]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 1961 is [True, False, False, False, False, True]
State prediction error at timestep 1961 is 0.012
Current timestep = 1962. State = [[-0.23812352  0.27957654]]. Action = [[ 0.08623254 -0.06153245  0.         -0.92893785]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 1962 is [True, False, False, False, False, True]
State prediction error at timestep 1962 is 0.012
Current timestep = 1963. State = [[-0.2320268   0.27817312]]. Action = [[ 0.0832713   0.01728003  0.         -0.14213955]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 1963 is [True, False, False, False, False, True]
State prediction error at timestep 1963 is 0.012
Current timestep = 1964. State = [[-0.2306707   0.27604032]]. Action = [[-0.02734977 -0.04223218  0.         -0.9941507 ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 1964 is [True, False, False, False, False, True]
State prediction error at timestep 1964 is 0.012
Current timestep = 1965. State = [[-0.23521018  0.27886578]]. Action = [[-0.08573943  0.0831519   0.         -0.3595277 ]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 1965 is [True, False, False, False, False, True]
State prediction error at timestep 1965 is 0.012
Current timestep = 1966. State = [[-0.24143182  0.28007823]]. Action = [[-0.07858781 -0.03216399  0.          0.6325824 ]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 1966 is [True, False, False, False, False, True]
State prediction error at timestep 1966 is 0.012
Current timestep = 1967. State = [[-0.24635756  0.2758699 ]]. Action = [[-0.05571621 -0.08401032  0.          0.289719  ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 1967 is [True, False, False, False, False, True]
State prediction error at timestep 1967 is 0.012
Current timestep = 1968. State = [[-0.2448858   0.26971507]]. Action = [[ 0.06179097 -0.08074284  0.          0.96263146]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 1968 is [True, False, False, False, False, True]
State prediction error at timestep 1968 is 0.012
Current timestep = 1969. State = [[-0.24678753  0.26565555]]. Action = [[-0.08177754 -0.02898242  0.          0.05190408]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 1969 is [True, False, False, False, False, True]
State prediction error at timestep 1969 is 0.012
Current timestep = 1970. State = [[-0.24993116  0.2596304 ]]. Action = [[-0.02630445 -0.09852359  0.         -0.2865715 ]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 1970 is [True, False, False, False, False, True]
State prediction error at timestep 1970 is 0.012
Current timestep = 1971. State = [[-0.2509577   0.25777784]]. Action = [[-0.00678828  0.03349038  0.          0.25545692]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 1971 is [True, False, False, False, False, True]
State prediction error at timestep 1971 is 0.012
Current timestep = 1972. State = [[-0.24852857  0.2566754 ]]. Action = [[ 0.06171777 -0.01913396  0.         -0.9253608 ]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 1972 is [True, False, False, False, False, True]
State prediction error at timestep 1972 is 0.012
Current timestep = 1973. State = [[-0.24471164  0.2580621 ]]. Action = [[ 0.05530608  0.06522115  0.         -0.815568  ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 1973 is [True, False, False, False, False, True]
State prediction error at timestep 1973 is 0.012
Current timestep = 1974. State = [[-0.24499482  0.25759557]]. Action = [[-0.02676042 -0.02309196  0.          0.83225536]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 1974 is [True, False, False, False, False, True]
State prediction error at timestep 1974 is 0.012
Current timestep = 1975. State = [[-0.24751748  0.26055798]]. Action = [[-0.02317013  0.08794304  0.         -0.9756312 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 1975 is [True, False, False, False, False, True]
State prediction error at timestep 1975 is 0.012
Current timestep = 1976. State = [[-0.25115573  0.26144284]]. Action = [[-0.04107112 -0.02426734  0.         -0.7285663 ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 1976 is [True, False, False, False, False, True]
State prediction error at timestep 1976 is 0.012
Current timestep = 1977. State = [[-0.25615516  0.26220506]]. Action = [[-0.06131309  0.02776629  0.         -0.168688  ]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 1977 is [True, False, False, False, False, True]
State prediction error at timestep 1977 is 0.012
Current timestep = 1978. State = [[-0.25861156  0.2582752 ]]. Action = [[ 0.00266335 -0.09756752  0.          0.39189458]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 1978 is [True, False, False, False, False, True]
State prediction error at timestep 1978 is 0.012
Current timestep = 1979. State = [[-0.26315767  0.25839025]]. Action = [[-0.07858495  0.05939128  0.         -0.33743644]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 1979 is [True, False, False, False, False, True]
State prediction error at timestep 1979 is 0.012
Current timestep = 1980. State = [[-0.26718456  0.2574795 ]]. Action = [[-0.01755559 -0.05536267  0.          0.18342328]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 1980 is [True, False, False, False, False, True]
State prediction error at timestep 1980 is 0.012
Current timestep = 1981. State = [[-0.269937    0.25356525]]. Action = [[-0.02782281 -0.05092774  0.         -0.4492985 ]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 1981 is [True, False, False, False, False, True]
State prediction error at timestep 1981 is 0.012
Current timestep = 1982. State = [[-0.27122852  0.2531172 ]]. Action = [[0.00643326 0.02504162 0.         0.45152557]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 1982 is [True, False, False, False, False, True]
State prediction error at timestep 1982 is 0.012
Current timestep = 1983. State = [[-0.26952776  0.2582038 ]]. Action = [[0.05797102 0.09795932 0.         0.46332192]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 1983 is [True, False, False, False, False, True]
State prediction error at timestep 1983 is 0.012
Current timestep = 1984. State = [[-0.2655804  0.265289 ]]. Action = [[ 0.0843234   0.09696906  0.         -0.05535614]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 1984 is [True, False, False, False, False, True]
State prediction error at timestep 1984 is 0.012
Current timestep = 1985. State = [[-0.26699746  0.27061552]]. Action = [[-0.04989315  0.05250897  0.         -0.8506044 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 1985 is [True, False, False, False, False, True]
State prediction error at timestep 1985 is 0.012
Current timestep = 1986. State = [[-0.27315432  0.2759262 ]]. Action = [[-0.06515317  0.06683152  0.         -0.6935396 ]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 1986 is [True, False, False, False, False, True]
State prediction error at timestep 1986 is 0.012
Current timestep = 1987. State = [[-0.28126803  0.28286943]]. Action = [[-0.08932364  0.08121385  0.         -0.4415728 ]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 1987 is [True, False, False, False, False, True]
State prediction error at timestep 1987 is 0.012
Current timestep = 1988. State = [[-0.28185946  0.28825393]]. Action = [[0.08779804 0.0373615  0.         0.9890914 ]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 1988 is [True, False, False, False, False, True]
State prediction error at timestep 1988 is 0.012
Current timestep = 1989. State = [[-0.2842533   0.29399478]]. Action = [[-0.06300542  0.06627289  0.          0.09720099]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 1989 is [True, False, False, False, False, True]
State prediction error at timestep 1989 is 0.012
Current timestep = 1990. State = [[-0.28600055  0.29393983]]. Action = [[ 0.02671432 -0.07325352  0.          0.42938566]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 1990 is [True, False, False, False, False, True]
State prediction error at timestep 1990 is 0.012
Current timestep = 1991. State = [[-0.28624487  0.29638582]]. Action = [[-2.2873282e-05  6.1109401e-02  0.0000000e+00 -3.3126646e-01]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 1991 is [True, False, False, False, False, True]
State prediction error at timestep 1991 is 0.012
Current timestep = 1992. State = [[-0.28877634  0.29716215]]. Action = [[-0.03624842 -0.04762504  0.          0.6087055 ]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 1992 is [True, False, False, False, False, True]
State prediction error at timestep 1992 is 0.012
Current timestep = 1993. State = [[-0.28887028  0.2961297 ]]. Action = [[ 0.02517047 -0.0239355   0.         -0.5766648 ]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 1993 is [True, False, False, False, False, True]
State prediction error at timestep 1993 is 0.012
Current timestep = 1994. State = [[-0.28391802  0.29295972]]. Action = [[ 0.08633845 -0.06458947  0.         -0.7368869 ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 1994 is [True, False, False, False, False, True]
State prediction error at timestep 1994 is 0.012
Current timestep = 1995. State = [[-0.28150964  0.29482037]]. Action = [[-0.0090774   0.07336681  0.         -0.9911474 ]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 1995 is [True, False, False, False, False, True]
State prediction error at timestep 1995 is 0.012
Current timestep = 1996. State = [[-0.28066468  0.29671472]]. Action = [[ 0.01354609 -0.00864475  0.         -0.617622  ]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 1996 is [True, False, False, False, False, True]
State prediction error at timestep 1996 is 0.012
Current timestep = 1997. State = [[-0.28260237  0.29778397]]. Action = [[-0.0570342   0.01608775  0.          0.42634094]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 1997 is [True, False, False, False, False, True]
State prediction error at timestep 1997 is 0.012
Current timestep = 1998. State = [[-0.27950114  0.2984554 ]]. Action = [[ 0.08889634 -0.00260265  0.          0.78637934]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 1998 is [True, False, False, False, False, True]
State prediction error at timestep 1998 is 0.012
Current timestep = 1999. State = [[-0.27772555  0.3032157 ]]. Action = [[-0.02187308  0.09617173  0.          0.33612144]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 1999 is [True, False, False, False, False, True]
State prediction error at timestep 1999 is 0.012
Current timestep = 2000. State = [[-0.2787519   0.30253726]]. Action = [[-0.01839863 -0.07891796  0.         -0.75423366]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 2000 is [True, False, False, False, False, True]
State prediction error at timestep 2000 is 0.012
Current timestep = 2001. State = [[-0.27654177  0.29783902]]. Action = [[ 0.03930049 -0.06141946  0.          0.57055974]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 2001 is [True, False, False, False, False, True]
State prediction error at timestep 2001 is 0.012
Current timestep = 2002. State = [[-0.27635628  0.29987663]]. Action = [[-0.03391091  0.07792436  0.         -0.6323316 ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 2002 is [True, False, False, False, False, True]
State prediction error at timestep 2002 is 0.012
Current timestep = 2003. State = [[-0.2757196  0.3014707]]. Action = [[ 0.02462687 -0.01616882  0.         -0.05576843]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 2003 is [True, False, False, False, False, True]
State prediction error at timestep 2003 is 0.012
Current timestep = 2004. State = [[-0.2753146  0.2989288]]. Action = [[-0.01502129 -0.04849185  0.         -0.99177885]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 2004 is [True, False, False, False, False, True]
State prediction error at timestep 2004 is 0.012
Current timestep = 2005. State = [[-0.27616832  0.30023053]]. Action = [[-0.01979528  0.05082167  0.         -0.30226696]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 2005 is [True, False, False, False, False, True]
State prediction error at timestep 2005 is 0.012
Current timestep = 2006. State = [[-0.27392572  0.30469555]]. Action = [[ 0.0578438   0.06097554  0.         -0.549524  ]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 2006 is [True, False, False, False, False, True]
State prediction error at timestep 2006 is 0.012
Current timestep = 2007. State = [[-0.27320772  0.3070805 ]]. Action = [[-0.01463958  0.01136246  0.         -0.37278426]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 2007 is [True, False, False, False, False, True]
State prediction error at timestep 2007 is 0.012
Current timestep = 2008. State = [[-0.27019137  0.3110726 ]]. Action = [[ 0.0728705   0.07040425  0.         -0.23616749]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 2008 is [True, False, False, False, False, True]
State prediction error at timestep 2008 is 0.012
Current timestep = 2009. State = [[-0.2727255   0.31812415]]. Action = [[-0.08746175  0.09568875  0.         -0.56235707]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 2009 is [True, False, False, False, False, True]
State prediction error at timestep 2009 is 0.012
Current timestep = 2010. State = [[-0.27265075  0.325429  ]]. Action = [[0.06977964 0.07762892 0.         0.83541965]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 2010 is [True, False, False, False, False, True]
State prediction error at timestep 2010 is 0.012
Current timestep = 2011. State = [[-0.2760737   0.33119527]]. Action = [[-0.09369901  0.04744057  0.          0.77844644]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 2011 is [True, False, False, False, False, True]
State prediction error at timestep 2011 is 0.012
Current timestep = 2012. State = [[-0.27737942  0.33716387]]. Action = [[ 0.05221251  0.06545901  0.         -0.3842436 ]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 2012 is [True, False, False, False, False, True]
State prediction error at timestep 2012 is 0.012
Current timestep = 2013. State = [[-0.2728553   0.34038082]]. Action = [[0.08648413 0.00299581 0.         0.43281794]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 2013 is [True, False, False, False, False, True]
State prediction error at timestep 2013 is 0.012
Current timestep = 2014. State = [[-0.26813337  0.3378099 ]]. Action = [[ 0.04945626 -0.07804394  0.          0.75924635]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 2014 is [True, False, False, False, False, True]
State prediction error at timestep 2014 is 0.012
Current timestep = 2015. State = [[-0.26965624  0.33434594]]. Action = [[-0.07688682 -0.05477712  0.         -0.13536572]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 2015 is [True, False, False, False, False, True]
State prediction error at timestep 2015 is 0.012
Current timestep = 2016. State = [[-0.2663035   0.33222649]]. Action = [[ 0.09607419 -0.03323033  0.          0.6485381 ]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 2016 is [True, False, False, False, False, True]
State prediction error at timestep 2016 is 0.012
Current timestep = 2017. State = [[-0.2630188   0.33330303]]. Action = [[-0.01414069  0.02801777  0.         -0.31246215]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 2017 is [True, False, False, False, False, True]
State prediction error at timestep 2017 is 0.012
Current timestep = 2018. State = [[-0.26193702  0.3298974 ]]. Action = [[-0.0040292  -0.09966716  0.         -0.91786206]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 2018 is [True, False, False, False, False, True]
State prediction error at timestep 2018 is 0.012
Current timestep = 2019. State = [[-0.2603057   0.32329622]]. Action = [[-0.00383644 -0.08834316  0.         -0.00244194]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 2019 is [True, False, False, False, False, True]
State prediction error at timestep 2019 is 0.012
Current timestep = 2020. State = [[-0.2552496   0.32252726]]. Action = [[0.07071521 0.04239567 0.         0.76328635]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 2020 is [True, False, False, False, False, True]
State prediction error at timestep 2020 is 0.012
Current timestep = 2021. State = [[-0.2555384   0.32598302]]. Action = [[-0.07921267  0.05485348  0.         -0.26100504]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 2021 is [True, False, False, False, False, True]
State prediction error at timestep 2021 is 0.012
Current timestep = 2022. State = [[-0.26150528  0.3306088 ]]. Action = [[-0.0970863   0.05533222  0.          0.53768444]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 2022 is [True, False, False, False, False, True]
State prediction error at timestep 2022 is 0.012
Current timestep = 2023. State = [[-0.2621333  0.3314286]]. Action = [[ 0.04063847 -0.02677722  0.         -0.7612077 ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 2023 is [True, False, False, False, False, True]
State prediction error at timestep 2023 is 0.012
Current timestep = 2024. State = [[-0.25961185  0.33394596]]. Action = [[0.03314336 0.06433737 0.         0.0473088 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 2024 is [True, False, False, False, False, True]
State prediction error at timestep 2024 is 0.012
Current timestep = 2025. State = [[-0.25732306  0.33973536]]. Action = [[ 0.03793526  0.08403831  0.         -0.49733347]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 2025 is [True, False, False, False, False, True]
State prediction error at timestep 2025 is 0.012
Current timestep = 2026. State = [[-0.252511   0.3444153]]. Action = [[ 0.09053963  0.04913909  0.         -0.63170516]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 2026 is [True, False, False, False, False, True]
State prediction error at timestep 2026 is 0.012
Current timestep = 2027. State = [[-0.24572164  0.34724194]]. Action = [[ 0.09469592  0.03325505  0.         -0.94050926]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 2027 is [True, False, False, False, False, True]
State prediction error at timestep 2027 is 0.012
Current timestep = 2028. State = [[-0.24242431  0.34590864]]. Action = [[ 0.00404576 -0.04816343  0.          0.4992628 ]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 2028 is [True, False, False, False, False, True]
State prediction error at timestep 2028 is 0.012
Current timestep = 2029. State = [[-0.24378882  0.34612802]]. Action = [[-0.04438782  0.02204137  0.          0.87175775]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 2029 is [True, False, False, False, False, True]
State prediction error at timestep 2029 is 0.012
Current timestep = 2030. State = [[-0.24039495  0.34810802]]. Action = [[0.0850222  0.01840235 0.         0.6358783 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 2030 is [True, False, False, False, False, True]
State prediction error at timestep 2030 is 0.012
Current timestep = 2031. State = [[-0.23727785  0.34901285]]. Action = [[ 0.          0.          0.         -0.28732598]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 2031 is [True, False, False, False, False, True]
State prediction error at timestep 2031 is 0.012
Current timestep = 2032. State = [[-0.23614529  0.34961414]]. Action = [[ 0.          0.          0.         -0.38781798]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 2032 is [True, False, False, False, False, True]
State prediction error at timestep 2032 is 0.012
Current timestep = 2033. State = [[-0.23345576  0.3455937 ]]. Action = [[ 0.02909092 -0.09468784  0.          0.93039596]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 2033 is [True, False, False, False, False, True]
State prediction error at timestep 2033 is 0.012
Current timestep = 2034. State = [[-0.23051187  0.339734  ]]. Action = [[ 0.00828792 -0.07334447  0.          0.294708  ]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 2034 is [True, False, False, False, False, True]
State prediction error at timestep 2034 is 0.012
Current timestep = 2035. State = [[-0.22676362  0.33779275]]. Action = [[0.03438329 0.00464197 0.         0.6922443 ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 2035 is [True, False, False, False, False, True]
State prediction error at timestep 2035 is 0.012
Current timestep = 2036. State = [[-0.2240893   0.33716568]]. Action = [[ 0.00246741 -0.0077998   0.          0.07935989]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 2036 is [True, False, False, False, False, True]
State prediction error at timestep 2036 is 0.012
Current timestep = 2037. State = [[-0.22364834  0.33198172]]. Action = [[-0.02647235 -0.09619043  0.          0.99141645]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 2037 is [True, False, False, False, False, True]
State prediction error at timestep 2037 is 0.012
Current timestep = 2038. State = [[-0.22075905  0.3239742 ]]. Action = [[ 0.03620896 -0.09908145  0.          0.8792069 ]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 2038 is [True, False, False, False, False, True]
State prediction error at timestep 2038 is 0.012
Current timestep = 2039. State = [[-0.21388187  0.31990644]]. Action = [[ 0.08604353  0.00109012  0.         -0.45563734]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 2039 is [True, False, False, False, False, True]
State prediction error at timestep 2039 is 0.012
Current timestep = 2040. State = [[-0.20872469  0.3222695 ]]. Action = [[ 0.02912187  0.08428704  0.         -0.2897681 ]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 2040 is [True, False, False, False, False, True]
State prediction error at timestep 2040 is 0.012
Current timestep = 2041. State = [[-0.2072279  0.3216039]]. Action = [[-0.00850163 -0.03436638  0.         -0.46610296]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 2041 is [True, False, False, False, False, True]
State prediction error at timestep 2041 is 0.012
Current timestep = 2042. State = [[-0.20622072  0.32061803]]. Action = [[0.00536253 0.01823213 0.         0.86702156]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 2042 is [True, False, False, False, False, True]
State prediction error at timestep 2042 is 0.012
Current timestep = 2043. State = [[-0.20291735  0.320237  ]]. Action = [[ 0.05132765  0.00251262  0.         -0.9757382 ]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 2043 is [True, False, False, False, False, True]
State prediction error at timestep 2043 is 0.012
Current timestep = 2044. State = [[-0.20035568  0.3155507 ]]. Action = [[ 0.00770285 -0.07801752  0.          0.18623102]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 2044 is [True, False, False, False, False, True]
State prediction error at timestep 2044 is 0.012
Current timestep = 2045. State = [[-0.20063156  0.31168777]]. Action = [[-0.03197693 -0.01840714  0.          0.784688  ]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 2045 is [True, False, False, False, False, True]
State prediction error at timestep 2045 is 0.012
Current timestep = 2046. State = [[-0.20281778  0.30734044]]. Action = [[-0.04635211 -0.06516702  0.         -0.9895856 ]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 2046 is [True, False, False, False, False, True]
State prediction error at timestep 2046 is 0.012
Current timestep = 2047. State = [[-0.19899656  0.3035373 ]]. Action = [[ 0.09330683 -0.02256862  0.          0.29008365]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 2047 is [True, False, False, False, False, True]
State prediction error at timestep 2047 is 0.012
Current timestep = 2048. State = [[-0.19568898  0.29751784]]. Action = [[-0.00760085 -0.08560653  0.          0.8167281 ]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 2048 is [True, False, False, False, False, True]
State prediction error at timestep 2048 is 0.012
Current timestep = 2049. State = [[-0.19609354  0.29885224]]. Action = [[-0.02709346  0.09850334  0.          0.42490292]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 2049 is [True, False, False, False, False, True]
State prediction error at timestep 2049 is 0.012
Current timestep = 2050. State = [[-0.19556613  0.29870844]]. Action = [[ 0.01797979 -0.04370094  0.          0.38122118]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 2050 is [True, False, False, False, False, True]
State prediction error at timestep 2050 is 0.012
Current timestep = 2051. State = [[-0.19815585  0.29989168]]. Action = [[-0.06998047  0.05629007  0.         -0.5972911 ]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 2051 is [True, False, False, False, False, True]
State prediction error at timestep 2051 is 0.012
Current timestep = 2052. State = [[-0.20270993  0.30576295]]. Action = [[-0.04796627  0.0870749   0.          0.2823969 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 2052 is [True, False, False, False, False, True]
State prediction error at timestep 2052 is 0.012
Current timestep = 2053. State = [[-0.204731    0.30731088]]. Action = [[ 0.00329479 -0.02795465  0.         -0.25975764]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 2053 is [True, False, False, False, False, True]
State prediction error at timestep 2053 is 0.012
Current timestep = 2054. State = [[-0.20841476  0.30240715]]. Action = [[-0.0674829  -0.09609795  0.         -0.2942068 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 2054 is [True, False, False, False, False, True]
State prediction error at timestep 2054 is 0.012
Current timestep = 2055. State = [[-0.21455662  0.29538155]]. Action = [[-0.08491066 -0.09889652  0.         -0.06949967]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 2055 is [True, False, False, False, False, True]
State prediction error at timestep 2055 is 0.012
Current timestep = 2056. State = [[-0.21752751  0.29410797]]. Action = [[-0.00055161  0.02956853  0.          0.3672341 ]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 2056 is [True, False, False, False, False, True]
State prediction error at timestep 2056 is 0.012
Current timestep = 2057. State = [[-0.21909526  0.29721   ]]. Action = [[-0.01247631  0.05019089  0.          0.8339248 ]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 2057 is [True, False, False, False, False, True]
State prediction error at timestep 2057 is 0.012
Current timestep = 2058. State = [[-0.22055018  0.30167398]]. Action = [[ 0.00381799  0.06327616  0.         -0.7627143 ]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 2058 is [True, False, False, False, False, True]
State prediction error at timestep 2058 is 0.012
Current timestep = 2059. State = [[-0.21838798  0.29867762]]. Action = [[ 0.06952218 -0.09345634  0.         -0.20010078]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 2059 is [True, False, False, False, False, True]
State prediction error at timestep 2059 is 0.012
Current timestep = 2060. State = [[-0.21667692  0.2957052 ]]. Action = [[ 0.01081772  0.00519021  0.         -0.69107825]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 2060 is [True, False, False, False, False, True]
State prediction error at timestep 2060 is 0.012
Current timestep = 2061. State = [[-0.21639107  0.2991187 ]]. Action = [[ 0.01327219  0.08197238  0.         -0.00707263]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 2061 is [True, False, False, False, False, True]
State prediction error at timestep 2061 is 0.012
Current timestep = 2062. State = [[-0.22107823  0.30070636]]. Action = [[-0.08925298 -0.01020826  0.         -0.42405927]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 2062 is [True, False, False, False, False, True]
State prediction error at timestep 2062 is 0.012
Current timestep = 2063. State = [[-0.22920866  0.30151033]]. Action = [[-0.09712283  0.01500343  0.          0.7074919 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 2063 is [True, False, False, False, False, True]
State prediction error at timestep 2063 is 0.012
Current timestep = 2064. State = [[-0.23348007  0.30232605]]. Action = [[-4.2845309e-03 -6.8267435e-04  0.0000000e+00 -7.5204700e-01]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 2064 is [True, False, False, False, False, True]
State prediction error at timestep 2064 is 0.012
Current timestep = 2065. State = [[-0.23146746  0.30593207]]. Action = [[0.07942521 0.07214466 0.         0.09679008]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 2065 is [True, False, False, False, False, True]
State prediction error at timestep 2065 is 0.012
Current timestep = 2066. State = [[-0.2321199   0.31183046]]. Action = [[-0.0249116   0.07947754  0.         -0.79732025]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 2066 is [True, False, False, False, False, True]
State prediction error at timestep 2066 is 0.012
Current timestep = 2067. State = [[-0.23821415  0.3139685 ]]. Action = [[-0.08479999 -0.01567537  0.         -0.6002094 ]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 2067 is [True, False, False, False, False, True]
State prediction error at timestep 2067 is 0.012
Current timestep = 2068. State = [[-0.24392281  0.3102907 ]]. Action = [[-0.04612873 -0.08841201  0.          0.58801365]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 2068 is [True, False, False, False, False, True]
State prediction error at timestep 2068 is 0.012
Current timestep = 2069. State = [[-0.24782327  0.3083922 ]]. Action = [[-0.03387976 -0.00485943  0.          0.26109397]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 2069 is [True, False, False, False, False, True]
State prediction error at timestep 2069 is 0.012
Current timestep = 2070. State = [[-0.25026694  0.30552113]]. Action = [[-0.01207107 -0.06386082  0.          0.17806613]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 2070 is [True, False, False, False, False, True]
State prediction error at timestep 2070 is 0.012
Current timestep = 2071. State = [[-0.25205964  0.30707258]]. Action = [[-0.01264837  0.06477889  0.          0.54064584]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 2071 is [True, False, False, False, False, True]
State prediction error at timestep 2071 is 0.012
Current timestep = 2072. State = [[-0.24995853  0.30757537]]. Action = [[ 0.07198595 -0.02315186  0.          0.90249157]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 2072 is [True, False, False, False, False, True]
State prediction error at timestep 2072 is 0.012
Current timestep = 2073. State = [[-0.24471994  0.31071463]]. Action = [[ 0.08642692  0.08919137  0.         -0.6403414 ]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 2073 is [True, False, False, False, False, True]
State prediction error at timestep 2073 is 0.012
Current timestep = 2074. State = [[-0.24581558  0.31341365]]. Action = [[-0.06364126  0.0129263   0.          0.4911661 ]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 2074 is [True, False, False, False, False, True]
State prediction error at timestep 2074 is 0.012
Current timestep = 2075. State = [[-0.2516126   0.30969304]]. Action = [[-0.06753663 -0.08476651  0.          0.04979265]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 2075 is [True, False, False, False, False, True]
State prediction error at timestep 2075 is 0.012
Current timestep = 2076. State = [[-0.25502148  0.30615303]]. Action = [[-0.01688158 -0.02573127  0.          0.12862206]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 2076 is [True, False, False, False, False, True]
State prediction error at timestep 2076 is 0.012
Current timestep = 2077. State = [[-0.25553936  0.30955216]]. Action = [[ 0.01884495  0.09113257  0.         -0.7956827 ]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 2077 is [True, False, False, False, False, True]
State prediction error at timestep 2077 is 0.012
Current timestep = 2078. State = [[-0.25785914  0.31172833]]. Action = [[-0.03569451 -0.00298496  0.         -0.23409432]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 2078 is [True, False, False, False, False, True]
State prediction error at timestep 2078 is 0.012
Current timestep = 2079. State = [[-0.25758252  0.31534666]]. Action = [[ 0.04828318  0.07491278  0.         -0.75553083]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 2079 is [True, False, False, False, False, True]
State prediction error at timestep 2079 is 0.012
Current timestep = 2080. State = [[-0.25657752  0.32134536]]. Action = [[0.01908378 0.08235524 0.         0.14143789]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 2080 is [True, False, False, False, False, True]
State prediction error at timestep 2080 is 0.012
Current timestep = 2081. State = [[-0.2553208  0.3243085]]. Action = [[0.03548425 0.00995559 0.         0.46577454]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 2081 is [True, False, False, False, False, True]
State prediction error at timestep 2081 is 0.012
Current timestep = 2082. State = [[-0.2539947   0.32503545]]. Action = [[ 0.01909287  0.0013235   0.         -0.7810366 ]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 2082 is [True, False, False, False, False, True]
State prediction error at timestep 2082 is 0.012
Current timestep = 2083. State = [[-0.25349292  0.32940868]]. Action = [[0.00714795 0.0786142  0.         0.58581245]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 2083 is [True, False, False, False, False, True]
State prediction error at timestep 2083 is 0.012
Current timestep = 2084. State = [[-0.25007457  0.33329162]]. Action = [[ 0.07302672  0.02319044  0.         -0.231027  ]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 2084 is [True, False, False, False, False, True]
State prediction error at timestep 2084 is 0.012
Current timestep = 2085. State = [[-0.24509196  0.33902097]]. Action = [[0.06189742 0.09252348 0.         0.13015485]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 2085 is [True, False, False, False, False, True]
State prediction error at timestep 2085 is 0.012
Current timestep = 2086. State = [[-0.24739328  0.34652168]]. Action = [[-0.08600914  0.08094046  0.          0.5229237 ]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 2086 is [True, False, False, False, False, True]
State prediction error at timestep 2086 is 0.012
Current timestep = 2087. State = [[-0.2542836   0.34834614]]. Action = [[-0.09133911 -0.04702509  0.         -0.6615395 ]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 2087 is [True, False, False, False, False, True]
State prediction error at timestep 2087 is 0.012
Current timestep = 2088. State = [[-0.25704938  0.3492245 ]]. Action = [[0.         0.         0.         0.21774268]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 2088 is [True, False, False, False, False, True]
State prediction error at timestep 2088 is 0.012
Current timestep = 2089. State = [[-0.25598764  0.35133296]]. Action = [[0.02719059 0.00930081 0.         0.43241477]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 2089 is [True, False, False, False, False, True]
State prediction error at timestep 2089 is 0.012
Current timestep = 2090. State = [[-0.25525603  0.35301006]]. Action = [[ 0.         0.         0.        -0.6041136]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 2090 is [True, False, False, False, False, True]
State prediction error at timestep 2090 is 0.012
Current timestep = 2091. State = [[-0.2551245  0.3543216]]. Action = [[0.        0.        0.        0.8060503]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 2091 is [True, False, False, False, False, True]
State prediction error at timestep 2091 is 0.012
Current timestep = 2092. State = [[-0.25494078  0.3554519 ]]. Action = [[0.         0.         0.         0.23205304]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 2092 is [True, False, False, False, False, True]
State prediction error at timestep 2092 is 0.012
Current timestep = 2093. State = [[-0.25469285  0.35638836]]. Action = [[0.        0.        0.        0.6872227]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 2093 is [True, False, False, False, False, True]
State prediction error at timestep 2093 is 0.012
Current timestep = 2094. State = [[-0.2544058   0.35711432]]. Action = [[0.         0.         0.         0.02512085]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 2094 is [True, False, False, False, False, True]
State prediction error at timestep 2094 is 0.012
Current timestep = 2095. State = [[-0.25412446  0.35766992]]. Action = [[ 0.          0.          0.         -0.89398676]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 2095 is [True, False, False, False, False, True]
State prediction error at timestep 2095 is 0.012
Current timestep = 2096. State = [[-0.2538941   0.35810983]]. Action = [[0.         0.         0.         0.63767314]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 2096 is [True, False, False, False, False, True]
State prediction error at timestep 2096 is 0.012
Current timestep = 2097. State = [[-0.2537355   0.35843986]]. Action = [[0.       0.       0.       0.557729]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 2097 is [True, False, False, False, False, True]
State prediction error at timestep 2097 is 0.012
Current timestep = 2098. State = [[-0.25364226  0.3586794 ]]. Action = [[ 0.         0.         0.        -0.8784566]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 2098 is [True, False, False, False, False, True]
State prediction error at timestep 2098 is 0.012
Current timestep = 2099. State = [[-0.25356576  0.35886672]]. Action = [[0.        0.        0.        0.8979167]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 2099 is [True, False, False, False, False, True]
State prediction error at timestep 2099 is 0.012
Current timestep = 2100. State = [[-0.2534829   0.35902384]]. Action = [[0.        0.        0.        0.6047181]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 2100 is [True, False, False, False, False, True]
State prediction error at timestep 2100 is 0.012
Current timestep = 2101. State = [[-0.25340712  0.35915485]]. Action = [[0.         0.         0.         0.81614864]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 2101 is [True, False, False, False, False, True]
State prediction error at timestep 2101 is 0.012
Current timestep = 2102. State = [[-0.25334173  0.35926574]]. Action = [[0.         0.         0.         0.46291196]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 2102 is [True, False, False, False, False, True]
State prediction error at timestep 2102 is 0.012
Current timestep = 2103. State = [[-0.25328603  0.35935855]]. Action = [[ 0.          0.          0.         -0.26625884]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 2103 is [True, False, False, False, False, True]
State prediction error at timestep 2103 is 0.012
Current timestep = 2104. State = [[-0.253239    0.35943574]]. Action = [[ 0.          0.          0.         -0.11340195]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 2104 is [True, False, False, False, False, True]
State prediction error at timestep 2104 is 0.012
Current timestep = 2105. State = [[-0.25319964  0.35950014]]. Action = [[ 0.         0.         0.        -0.1266011]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 2105 is [True, False, False, False, False, True]
State prediction error at timestep 2105 is 0.012
Current timestep = 2106. State = [[-0.25316697  0.35955402]]. Action = [[ 0.         0.         0.        -0.2645594]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 2106 is [True, False, False, False, False, True]
State prediction error at timestep 2106 is 0.012
Current timestep = 2107. State = [[-0.25314024  0.35959938]]. Action = [[0.         0.         0.         0.06064236]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 2107 is [True, False, False, False, False, True]
State prediction error at timestep 2107 is 0.012
Current timestep = 2108. State = [[-0.25311872  0.35963792]]. Action = [[0.        0.        0.        0.5913948]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 2108 is [True, False, False, False, False, True]
State prediction error at timestep 2108 is 0.012
Current timestep = 2109. State = [[-0.2531017   0.35967085]]. Action = [[ 0.         0.         0.        -0.8339719]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 2109 is [True, False, False, False, False, True]
State prediction error at timestep 2109 is 0.012
Current timestep = 2110. State = [[-0.25308853  0.3596993 ]]. Action = [[0.        0.        0.        0.5150596]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 2110 is [True, False, False, False, False, True]
State prediction error at timestep 2110 is 0.012
Current timestep = 2111. State = [[-0.2530784   0.35972425]]. Action = [[0.        0.        0.        0.5630684]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 2111 is [True, False, False, False, False, True]
State prediction error at timestep 2111 is 0.012
Current timestep = 2112. State = [[-0.25307095  0.35974634]]. Action = [[0.         0.         0.         0.42746723]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 2112 is [True, False, False, False, False, True]
State prediction error at timestep 2112 is 0.012
Current timestep = 2113. State = [[-0.25306576  0.35976616]]. Action = [[ 0.         0.         0.        -0.2682743]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 2113 is [True, False, False, False, False, True]
State prediction error at timestep 2113 is 0.012
Current timestep = 2114. State = [[-0.2530622   0.35978368]]. Action = [[ 0.          0.          0.         -0.03155702]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 2114 is [True, False, False, False, False, True]
State prediction error at timestep 2114 is 0.012
Current timestep = 2115. State = [[-0.25305882  0.3597984 ]]. Action = [[ 0.          0.          0.         -0.20085979]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 2115 is [True, False, False, False, False, True]
State prediction error at timestep 2115 is 0.012
Current timestep = 2116. State = [[-0.2530559   0.35981107]]. Action = [[0.         0.         0.         0.11386538]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 2116 is [True, False, False, False, False, True]
State prediction error at timestep 2116 is 0.012
Current timestep = 2117. State = [[-0.2530535   0.35982206]]. Action = [[0.         0.         0.         0.79923844]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 2117 is [True, False, False, False, False, True]
State prediction error at timestep 2117 is 0.012
Current timestep = 2118. State = [[-0.2530515  0.3598317]]. Action = [[ 0.          0.          0.         -0.02850908]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 2118 is [True, False, False, False, False, True]
State prediction error at timestep 2118 is 0.012
Current timestep = 2119. State = [[-0.25304982  0.3598401 ]]. Action = [[ 0.          0.          0.         -0.06442159]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 2119 is [True, False, False, False, False, True]
State prediction error at timestep 2119 is 0.012
Current timestep = 2120. State = [[-0.25304848  0.35984746]]. Action = [[ 0.          0.          0.         -0.53980607]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 2120 is [True, False, False, False, False, True]
State prediction error at timestep 2120 is 0.012
Current timestep = 2121. State = [[-0.25304723  0.35985398]]. Action = [[0.        0.        0.        0.8640981]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 2121 is [True, False, False, False, False, True]
State prediction error at timestep 2121 is 0.012
Current timestep = 2122. State = [[-0.2530458   0.35985988]]. Action = [[ 0.         0.         0.        -0.9144186]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 2122 is [True, False, False, False, False, True]
State prediction error at timestep 2122 is 0.012
Current timestep = 2123. State = [[-0.25304422  0.3598652 ]]. Action = [[ 0.         0.         0.        -0.9582584]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 2123 is [True, False, False, False, False, True]
State prediction error at timestep 2123 is 0.012
Current timestep = 2124. State = [[-0.2530425   0.35987002]]. Action = [[ 0.          0.          0.         -0.28582716]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 2124 is [True, False, False, False, False, True]
State prediction error at timestep 2124 is 0.012
Current timestep = 2125. State = [[-0.2530406   0.35987434]]. Action = [[ 0.         0.         0.        -0.9045368]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 2125 is [True, False, False, False, False, True]
State prediction error at timestep 2125 is 0.012
Current timestep = 2126. State = [[-0.25303861  0.3598783 ]]. Action = [[ 0.          0.          0.         -0.72759354]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 2126 is [True, False, False, False, False, True]
State prediction error at timestep 2126 is 0.012
Current timestep = 2127. State = [[-0.25303656  0.35988188]]. Action = [[0.         0.         0.         0.04487443]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 2127 is [True, False, False, False, False, True]
State prediction error at timestep 2127 is 0.012
Current timestep = 2128. State = [[-0.25303438  0.35988516]]. Action = [[0.        0.        0.        0.6937523]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 2128 is [True, False, False, False, False, True]
State prediction error at timestep 2128 is 0.012
Current timestep = 2129. State = [[-0.25303218  0.35988817]]. Action = [[0.         0.         0.         0.56379175]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 2129 is [True, False, False, False, False, True]
State prediction error at timestep 2129 is 0.012
Current timestep = 2130. State = [[-0.2530299  0.359891 ]]. Action = [[0.         0.         0.         0.43078148]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 2130 is [True, False, False, False, False, True]
State prediction error at timestep 2130 is 0.012
Current timestep = 2131. State = [[-0.25302768  0.3598938 ]]. Action = [[ 0.          0.          0.         -0.22877592]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 2131 is [True, False, False, False, False, True]
State prediction error at timestep 2131 is 0.012
Current timestep = 2132. State = [[-0.25302547  0.35989657]]. Action = [[0.        0.        0.        0.5451169]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 2132 is [True, False, False, False, False, True]
State prediction error at timestep 2132 is 0.012
Current timestep = 2133. State = [[-0.25302327  0.35989934]]. Action = [[0.         0.         0.         0.42210066]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 2133 is [True, False, False, False, False, True]
State prediction error at timestep 2133 is 0.012
Current timestep = 2134. State = [[-0.2530211   0.35990205]]. Action = [[ 0.          0.          0.         -0.02676791]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 2134 is [True, False, False, False, False, True]
State prediction error at timestep 2134 is 0.012
Current timestep = 2135. State = [[-0.25301892  0.35990477]]. Action = [[ 0.          0.          0.         -0.83360785]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 2135 is [True, False, False, False, False, True]
State prediction error at timestep 2135 is 0.012
Current timestep = 2136. State = [[-0.25301677  0.35990745]]. Action = [[ 0.          0.          0.         -0.66757333]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 2136 is [True, False, False, False, False, True]
State prediction error at timestep 2136 is 0.012
Current timestep = 2137. State = [[-0.25301465  0.3599101 ]]. Action = [[ 0.         0.         0.        -0.5978467]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 2137 is [True, False, False, False, False, True]
State prediction error at timestep 2137 is 0.012
Current timestep = 2138. State = [[-0.25301257  0.35991272]]. Action = [[0.         0.         0.         0.25242615]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 2138 is [True, False, False, False, False, True]
State prediction error at timestep 2138 is 0.012
Current timestep = 2139. State = [[-0.25301048  0.35991535]]. Action = [[ 0.         0.         0.        -0.6237473]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 2139 is [True, False, False, False, False, True]
State prediction error at timestep 2139 is 0.012
Current timestep = 2140. State = [[-0.2530084   0.35991794]]. Action = [[0.         0.         0.         0.41017556]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 2140 is [True, False, False, False, False, True]
State prediction error at timestep 2140 is 0.012
Current timestep = 2141. State = [[-0.25300637  0.3599205 ]]. Action = [[0.         0.         0.         0.39526093]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 2141 is [True, False, False, False, False, True]
State prediction error at timestep 2141 is 0.012
Current timestep = 2142. State = [[-0.2530043   0.35992306]]. Action = [[0.        0.        0.        0.3278165]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 2142 is [True, False, False, False, False, True]
State prediction error at timestep 2142 is 0.012
Current timestep = 2143. State = [[-0.25300232  0.35992557]]. Action = [[0.         0.         0.         0.25669396]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 2143 is [True, False, False, False, False, True]
State prediction error at timestep 2143 is 0.012
Current timestep = 2144. State = [[-0.25300032  0.35992807]]. Action = [[ 0.         0.         0.        -0.4864266]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 2144 is [True, False, False, False, False, True]
State prediction error at timestep 2144 is 0.012
Current timestep = 2145. State = [[-0.25299835  0.35993057]]. Action = [[ 0.         0.         0.        -0.2483105]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 2145 is [True, False, False, False, False, True]
State prediction error at timestep 2145 is 0.012
Current timestep = 2146. State = [[-0.25299639  0.35993302]]. Action = [[ 0.         0.         0.        -0.5657355]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 2146 is [True, False, False, False, False, True]
State prediction error at timestep 2146 is 0.012
Current timestep = 2147. State = [[-0.25299445  0.35993546]]. Action = [[0.        0.        0.        0.5297451]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 2147 is [True, False, False, False, False, True]
State prediction error at timestep 2147 is 0.012
Current timestep = 2148. State = [[-0.2529925   0.35993788]]. Action = [[0.         0.         0.         0.08125448]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 2148 is [True, False, False, False, False, True]
State prediction error at timestep 2148 is 0.012
Current timestep = 2149. State = [[-0.2529906  0.3599403]]. Action = [[ 0.          0.          0.         -0.05551994]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 2149 is [True, False, False, False, False, True]
State prediction error at timestep 2149 is 0.012
Current timestep = 2150. State = [[-0.2529887   0.35994267]]. Action = [[0.        0.        0.        0.4897406]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 2150 is [True, False, False, False, False, True]
State prediction error at timestep 2150 is 0.012
Current timestep = 2151. State = [[-0.25298685  0.35994503]]. Action = [[0.        0.        0.        0.5895183]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 2151 is [True, False, False, False, False, True]
State prediction error at timestep 2151 is 0.012
Current timestep = 2152. State = [[-0.25298497  0.35994735]]. Action = [[0.         0.         0.         0.45355403]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 2152 is [True, False, False, False, False, True]
State prediction error at timestep 2152 is 0.012
Current timestep = 2153. State = [[-0.25298312  0.35994968]]. Action = [[0.        0.        0.        0.2850517]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 2153 is [True, False, False, False, False, True]
State prediction error at timestep 2153 is 0.012
Current timestep = 2154. State = [[-0.2529813   0.35995197]]. Action = [[0.         0.         0.         0.76049757]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 2154 is [True, False, False, False, False, True]
State prediction error at timestep 2154 is 0.012
Current timestep = 2155. State = [[-0.2529795   0.35995424]]. Action = [[ 0.         0.         0.        -0.9814966]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 2155 is [True, False, False, False, False, True]
State prediction error at timestep 2155 is 0.012
Current timestep = 2156. State = [[-0.2529777  0.3599565]]. Action = [[0.       0.       0.       0.331236]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 2156 is [True, False, False, False, False, True]
State prediction error at timestep 2156 is 0.012
Current timestep = 2157. State = [[-0.2529759   0.35995874]]. Action = [[0.        0.        0.        0.6159346]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 2157 is [True, False, False, False, False, True]
State prediction error at timestep 2157 is 0.012
Current timestep = 2158. State = [[-0.25297415  0.35996097]]. Action = [[ 0.          0.          0.         -0.59012383]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 2158 is [True, False, False, False, False, True]
State prediction error at timestep 2158 is 0.012
Current timestep = 2159. State = [[-0.25297242  0.35996318]]. Action = [[0.         0.         0.         0.24703228]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 2159 is [True, False, False, False, False, True]
State prediction error at timestep 2159 is 0.012
Current timestep = 2160. State = [[-0.2529707   0.35996535]]. Action = [[0.        0.        0.        0.6456208]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 2160 is [True, False, False, False, False, True]
State prediction error at timestep 2160 is 0.012
Current timestep = 2161. State = [[-0.25296897  0.3599675 ]]. Action = [[0.        0.        0.        0.9785106]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 2161 is [True, False, False, False, False, True]
State prediction error at timestep 2161 is 0.012
Current timestep = 2162. State = [[-0.25296727  0.35996965]]. Action = [[0.       0.       0.       0.361583]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 2162 is [True, False, False, False, False, True]
State prediction error at timestep 2162 is 0.012
Current timestep = 2163. State = [[-0.25296557  0.3599718 ]]. Action = [[ 0.          0.          0.         -0.03141552]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 2163 is [True, False, False, False, False, True]
State prediction error at timestep 2163 is 0.012
Current timestep = 2164. State = [[-0.2529639   0.35997388]]. Action = [[ 0.          0.          0.         -0.47294277]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 2164 is [True, False, False, False, False, True]
State prediction error at timestep 2164 is 0.012
Current timestep = 2165. State = [[-0.25296226  0.359976  ]]. Action = [[ 0.          0.          0.         -0.28896034]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 2165 is [True, False, False, False, False, True]
State prediction error at timestep 2165 is 0.012
Current timestep = 2166. State = [[-0.2529606   0.35997805]]. Action = [[ 0.          0.          0.         -0.54068977]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 2166 is [True, False, False, False, False, True]
State prediction error at timestep 2166 is 0.012
Current timestep = 2167. State = [[-0.25295898  0.3599801 ]]. Action = [[0.         0.         0.         0.10304976]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 2167 is [True, False, False, False, False, True]
State prediction error at timestep 2167 is 0.012
Current timestep = 2168. State = [[-0.25295737  0.35998216]]. Action = [[0.         0.         0.         0.54353046]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 2168 is [True, False, False, False, False, True]
State prediction error at timestep 2168 is 0.012
Current timestep = 2169. State = [[-0.25295576  0.35998416]]. Action = [[ 0.          0.          0.         -0.45153636]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 2169 is [True, False, False, False, False, True]
State prediction error at timestep 2169 is 0.012
Current timestep = 2170. State = [[-0.25295419  0.3599862 ]]. Action = [[ 0.         0.         0.        -0.2613684]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 2170 is [True, False, False, False, False, True]
State prediction error at timestep 2170 is 0.012
Current timestep = 2171. State = [[-0.2529526   0.35998815]]. Action = [[ 0.          0.          0.         -0.02302194]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 2171 is [True, False, False, False, False, True]
State prediction error at timestep 2171 is 0.012
Current timestep = 2172. State = [[-0.25295106  0.35999012]]. Action = [[0.        0.        0.        0.3693819]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 2172 is [True, False, False, False, False, True]
State prediction error at timestep 2172 is 0.012
Current timestep = 2173. State = [[-0.2529495  0.3599921]]. Action = [[ 0.          0.          0.         -0.60837436]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 2173 is [True, False, False, False, False, True]
State prediction error at timestep 2173 is 0.012
Current timestep = 2174. State = [[-0.252948    0.35999402]]. Action = [[0.         0.         0.         0.40819025]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 2174 is [True, False, False, False, False, True]
State prediction error at timestep 2174 is 0.012
Current timestep = 2175. State = [[-0.25294647  0.35999593]]. Action = [[ 0.          0.          0.         -0.48320496]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 2175 is [True, False, False, False, False, True]
State prediction error at timestep 2175 is 0.012
Current timestep = 2176. State = [[-0.25294498  0.35999784]]. Action = [[0.         0.         0.         0.05744565]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 2176 is [True, False, False, False, False, True]
State prediction error at timestep 2176 is 0.012
Current timestep = 2177. State = [[-0.2529435   0.35999972]]. Action = [[0.        0.        0.        0.6093099]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 2177 is [True, False, False, False, False, True]
State prediction error at timestep 2177 is 0.012
Current timestep = 2178. State = [[-0.252942   0.3600016]]. Action = [[ 0.          0.          0.         -0.92634344]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 2178 is [True, False, False, False, False, True]
State prediction error at timestep 2178 is 0.012
Current timestep = 2179. State = [[-0.25294054  0.36000344]]. Action = [[0.        0.        0.        0.7559736]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 2179 is [True, False, False, False, False, True]
State prediction error at timestep 2179 is 0.012
Current timestep = 2180. State = [[-0.25293908  0.3600053 ]]. Action = [[0.        0.        0.        0.7883053]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 2180 is [True, False, False, False, False, True]
State prediction error at timestep 2180 is 0.012
Current timestep = 2181. State = [[-0.25293764  0.3600071 ]]. Action = [[0.        0.        0.        0.3796159]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 2181 is [True, False, False, False, False, True]
State prediction error at timestep 2181 is 0.012
Current timestep = 2182. State = [[-0.2529362   0.36000893]]. Action = [[ 0.         0.         0.        -0.9516715]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 2182 is [True, False, False, False, False, True]
State prediction error at timestep 2182 is 0.012
Current timestep = 2183. State = [[-0.2529348  0.3600107]]. Action = [[0.         0.         0.         0.43006313]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 2183 is [True, False, False, False, False, True]
State prediction error at timestep 2183 is 0.012
Current timestep = 2184. State = [[-0.2529334  0.3600125]]. Action = [[0.         0.         0.         0.35201216]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 2184 is [True, False, False, False, False, True]
State prediction error at timestep 2184 is 0.012
Current timestep = 2185. State = [[-0.252932    0.36001426]]. Action = [[ 0.          0.          0.         -0.07982153]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 2185 is [True, False, False, False, False, True]
State prediction error at timestep 2185 is 0.012
Current timestep = 2186. State = [[-0.25293064  0.36001602]]. Action = [[ 0.         0.         0.        -0.5629725]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 2186 is [True, False, False, False, False, True]
State prediction error at timestep 2186 is 0.012
Current timestep = 2187. State = [[-0.2529293   0.36001775]]. Action = [[ 0.          0.          0.         -0.20655668]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 2187 is [True, False, False, False, False, True]
State prediction error at timestep 2187 is 0.012
Current timestep = 2188. State = [[-0.25292793  0.36001945]]. Action = [[0.        0.        0.        0.6086421]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 2188 is [True, False, False, False, False, True]
State prediction error at timestep 2188 is 0.012
Current timestep = 2189. State = [[-0.2529266   0.36002117]]. Action = [[ 0.          0.          0.         -0.75148433]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 2189 is [True, False, False, False, False, True]
State prediction error at timestep 2189 is 0.012
Current timestep = 2190. State = [[-0.25292528  0.36002284]]. Action = [[ 0.          0.          0.         -0.47878927]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 2190 is [True, False, False, False, False, True]
State prediction error at timestep 2190 is 0.012
Current timestep = 2191. State = [[-0.25292397  0.3600245 ]]. Action = [[0.         0.         0.         0.18427753]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 2191 is [True, False, False, False, False, True]
State prediction error at timestep 2191 is 0.012
Current timestep = 2192. State = [[-0.25292265  0.36002618]]. Action = [[ 0.          0.          0.         -0.16125149]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 2192 is [True, False, False, False, False, True]
State prediction error at timestep 2192 is 0.012
Current timestep = 2193. State = [[-0.25292137  0.36002782]]. Action = [[0.         0.         0.         0.14739466]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 2193 is [True, False, False, False, False, True]
State prediction error at timestep 2193 is 0.012
Current timestep = 2194. State = [[-0.2529201   0.36002946]]. Action = [[0.        0.        0.        0.6419735]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 2194 is [True, False, False, False, False, True]
State prediction error at timestep 2194 is 0.012
Current timestep = 2195. State = [[-0.2529188  0.3600311]]. Action = [[0.         0.         0.         0.53708935]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 2195 is [True, False, False, False, False, True]
State prediction error at timestep 2195 is 0.012
Current timestep = 2196. State = [[-0.25291756  0.36003268]]. Action = [[0.         0.         0.         0.85433865]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 2196 is [True, False, False, False, False, True]
State prediction error at timestep 2196 is 0.012
Current timestep = 2197. State = [[-0.2529163  0.3600343]]. Action = [[0.         0.         0.         0.53582335]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 2197 is [True, False, False, False, False, True]
State prediction error at timestep 2197 is 0.012
Current timestep = 2198. State = [[-0.25291508  0.36003587]]. Action = [[0.         0.         0.         0.24095166]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 2198 is [True, False, False, False, False, True]
State prediction error at timestep 2198 is 0.012
Current timestep = 2199. State = [[-0.25291386  0.36003742]]. Action = [[0.         0.         0.         0.84162426]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 2199 is [True, False, False, False, False, True]
State prediction error at timestep 2199 is 0.012
Current timestep = 2200. State = [[-0.25291264  0.36003897]]. Action = [[0.         0.         0.         0.01620352]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 2200 is [True, False, False, False, False, True]
State prediction error at timestep 2200 is 0.012
Current timestep = 2201. State = [[-0.25291142  0.36004052]]. Action = [[0.         0.         0.         0.24134636]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 2201 is [True, False, False, False, False, True]
State prediction error at timestep 2201 is 0.012
Current timestep = 2202. State = [[-0.25291023  0.36004204]]. Action = [[0.         0.         0.         0.35098505]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 2202 is [True, False, False, False, False, True]
State prediction error at timestep 2202 is 0.012
Current timestep = 2203. State = [[-0.25290906  0.36004356]]. Action = [[0.        0.        0.        0.8220775]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 2203 is [True, False, False, False, False, True]
State prediction error at timestep 2203 is 0.012
Current timestep = 2204. State = [[-0.2529079   0.36004505]]. Action = [[0.         0.         0.         0.11855435]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 2204 is [True, False, False, False, False, True]
State prediction error at timestep 2204 is 0.012
Current timestep = 2205. State = [[-0.25290674  0.36004654]]. Action = [[0.         0.         0.         0.61165476]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 2205 is [True, False, False, False, False, True]
State prediction error at timestep 2205 is 0.012
Current timestep = 2206. State = [[-0.25290558  0.36004803]]. Action = [[0.         0.         0.         0.26886892]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 2206 is [True, False, False, False, False, True]
State prediction error at timestep 2206 is 0.012
Current timestep = 2207. State = [[-0.25290444  0.3600495 ]]. Action = [[ 0.          0.          0.         -0.55322117]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 2207 is [True, False, False, False, False, True]
State prediction error at timestep 2207 is 0.012
Current timestep = 2208. State = [[-0.2529033   0.36005095]]. Action = [[ 0.        0.        0.       -0.689134]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 2208 is [True, False, False, False, False, True]
State prediction error at timestep 2208 is 0.012
Current timestep = 2209. State = [[-0.25290218  0.36005238]]. Action = [[ 0.        0.        0.       -0.519642]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 2209 is [True, False, False, False, False, True]
State prediction error at timestep 2209 is 0.012
Current timestep = 2210. State = [[-0.25290108  0.3600538 ]]. Action = [[0.        0.        0.        0.6644423]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 2210 is [True, False, False, False, False, True]
State prediction error at timestep 2210 is 0.012
Current timestep = 2211. State = [[-0.25289997  0.3600552 ]]. Action = [[0.         0.         0.         0.98345995]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 2211 is [True, False, False, False, False, True]
State prediction error at timestep 2211 is 0.012
Current timestep = 2212. State = [[-0.2528989  0.3600566]]. Action = [[ 0.          0.          0.         -0.46247208]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 2212 is [True, False, False, False, False, True]
State prediction error at timestep 2212 is 0.012
Current timestep = 2213. State = [[-0.2528978  0.360058 ]]. Action = [[0.         0.         0.         0.19846761]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 2213 is [True, False, False, False, False, True]
State prediction error at timestep 2213 is 0.012
Current timestep = 2214. State = [[-0.25289673  0.36005938]]. Action = [[ 0.          0.          0.         -0.93090284]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 2214 is [True, False, False, False, False, True]
State prediction error at timestep 2214 is 0.012
Current timestep = 2215. State = [[-0.25289568  0.36006075]]. Action = [[0.        0.        0.        0.7906537]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 2215 is [True, False, False, False, False, True]
State prediction error at timestep 2215 is 0.012
Current timestep = 2216. State = [[-0.25289464  0.36006212]]. Action = [[ 0.          0.          0.         -0.15008253]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 2216 is [True, False, False, False, False, True]
State prediction error at timestep 2216 is 0.012
Current timestep = 2217. State = [[-0.2528936   0.36006346]]. Action = [[0.        0.        0.        0.6247692]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 2217 is [True, False, False, False, False, True]
State prediction error at timestep 2217 is 0.012
Current timestep = 2218. State = [[-0.25289255  0.3600648 ]]. Action = [[ 0.          0.          0.         -0.98727816]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 2218 is [True, False, False, False, False, True]
State prediction error at timestep 2218 is 0.012
Current timestep = 2219. State = [[-0.25289154  0.36006612]]. Action = [[0.         0.         0.         0.13791227]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 2219 is [True, False, False, False, False, True]
State prediction error at timestep 2219 is 0.012
Current timestep = 2220. State = [[-0.2528905   0.36006743]]. Action = [[0.        0.        0.        0.5096328]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 2220 is [True, False, False, False, False, True]
State prediction error at timestep 2220 is 0.012
Current timestep = 2221. State = [[-0.2528895   0.36006874]]. Action = [[ 0.         0.         0.        -0.7856792]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 2221 is [True, False, False, False, False, True]
State prediction error at timestep 2221 is 0.012
Current timestep = 2222. State = [[-0.2528885   0.36007002]]. Action = [[ 0.         0.         0.        -0.6143121]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 2222 is [True, False, False, False, False, True]
State prediction error at timestep 2222 is 0.012
Current timestep = 2223. State = [[-0.25288752  0.3600713 ]]. Action = [[0.         0.         0.         0.13148558]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 2223 is [True, False, False, False, False, True]
State prediction error at timestep 2223 is 0.012
Current timestep = 2224. State = [[-0.25288653  0.36007255]]. Action = [[0.        0.        0.        0.2870977]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 2224 is [True, False, False, False, False, True]
State prediction error at timestep 2224 is 0.012
Current timestep = 2225. State = [[-0.25288558  0.36007383]]. Action = [[ 0.          0.          0.         -0.58858305]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 2225 is [True, False, False, False, False, True]
State prediction error at timestep 2225 is 0.012
Current timestep = 2226. State = [[-0.25288463  0.36007506]]. Action = [[0.        0.        0.        0.7671554]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 2226 is [True, False, False, False, False, True]
State prediction error at timestep 2226 is 0.012
Current timestep = 2227. State = [[-0.25288367  0.3600763 ]]. Action = [[0.         0.         0.         0.11976123]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 2227 is [True, False, False, False, False, True]
State prediction error at timestep 2227 is 0.012
Current timestep = 2228. State = [[-0.25288272  0.36007753]]. Action = [[0.        0.        0.        0.3307836]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 2228 is [True, False, False, False, False, True]
State prediction error at timestep 2228 is 0.012
Current timestep = 2229. State = [[-0.25288177  0.36007875]]. Action = [[0.         0.         0.         0.22956169]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 2229 is [True, False, False, False, False, True]
State prediction error at timestep 2229 is 0.012
Current timestep = 2230. State = [[-0.25288084  0.36007994]]. Action = [[ 0.          0.          0.         -0.10525775]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 2230 is [True, False, False, False, False, True]
State prediction error at timestep 2230 is 0.012
Current timestep = 2231. State = [[-0.25287995  0.36008117]]. Action = [[0.         0.         0.         0.34746027]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 2231 is [True, False, False, False, False, True]
State prediction error at timestep 2231 is 0.012
Current timestep = 2232. State = [[-0.25287902  0.36008233]]. Action = [[0.         0.         0.         0.11576641]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 2232 is [True, False, False, False, False, True]
State prediction error at timestep 2232 is 0.012
Current timestep = 2233. State = [[-0.25287813  0.36008352]]. Action = [[0.        0.        0.        0.8135123]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 2233 is [True, False, False, False, False, True]
State prediction error at timestep 2233 is 0.012
Current timestep = 2234. State = [[-0.25287724  0.36008468]]. Action = [[ 0.          0.          0.         -0.01213801]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 2234 is [True, False, False, False, False, True]
State prediction error at timestep 2234 is 0.012
Current timestep = 2235. State = [[-0.25287634  0.36008584]]. Action = [[0.       0.       0.       0.544976]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 2235 is [True, False, False, False, False, True]
State prediction error at timestep 2235 is 0.012
Current timestep = 2236. State = [[-0.25287545  0.36008698]]. Action = [[ 0.          0.          0.         -0.22006178]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 2236 is [True, False, False, False, False, True]
State prediction error at timestep 2236 is 0.012
Current timestep = 2237. State = [[-0.25287458  0.3600881 ]]. Action = [[ 0.         0.         0.        -0.9450005]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 2237 is [True, False, False, False, False, True]
State prediction error at timestep 2237 is 0.012
Current timestep = 2238. State = [[-0.25287372  0.36008924]]. Action = [[0.         0.         0.         0.94519615]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 2238 is [True, False, False, False, False, True]
State prediction error at timestep 2238 is 0.012
Current timestep = 2239. State = [[-0.25287288  0.36009037]]. Action = [[0.         0.         0.         0.44433236]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 2239 is [True, False, False, False, False, True]
State prediction error at timestep 2239 is 0.012
Current timestep = 2240. State = [[-0.25287202  0.36009148]]. Action = [[0.        0.        0.        0.9868734]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 2240 is [True, False, False, False, False, True]
State prediction error at timestep 2240 is 0.012
Current timestep = 2241. State = [[-0.2528712   0.36009258]]. Action = [[ 0.          0.          0.         -0.33000588]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 2241 is [True, False, False, False, False, True]
State prediction error at timestep 2241 is 0.012
Current timestep = 2242. State = [[-0.25287035  0.36009368]]. Action = [[ 0.          0.          0.         -0.00138092]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 2242 is [True, False, False, False, False, True]
State prediction error at timestep 2242 is 0.012
Current timestep = 2243. State = [[-0.25286952  0.36009476]]. Action = [[ 0.          0.          0.         -0.05976117]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 2243 is [True, False, False, False, False, True]
State prediction error at timestep 2243 is 0.012
Current timestep = 2244. State = [[-0.2528687   0.36009583]]. Action = [[0.         0.         0.         0.17915154]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 2244 is [True, False, False, False, False, True]
State prediction error at timestep 2244 is 0.012
Current timestep = 2245. State = [[-0.2528679  0.3600969]]. Action = [[ 0.          0.          0.         -0.20072961]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 2245 is [True, False, False, False, False, True]
State prediction error at timestep 2245 is 0.012
Current timestep = 2246. State = [[-0.2528671   0.36009794]]. Action = [[0.         0.         0.         0.12186801]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 2246 is [True, False, False, False, False, True]
State prediction error at timestep 2246 is 0.012
Current timestep = 2247. State = [[-0.2528663  0.360099 ]]. Action = [[ 0.          0.          0.         -0.15935159]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 2247 is [True, False, False, False, False, True]
State prediction error at timestep 2247 is 0.012
Current timestep = 2248. State = [[-0.25286552  0.36010003]]. Action = [[0.         0.         0.         0.13776469]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 2248 is [True, False, False, False, False, True]
State prediction error at timestep 2248 is 0.012
Current timestep = 2249. State = [[-0.25286475  0.36010107]]. Action = [[0.         0.         0.         0.69018304]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 2249 is [True, False, False, False, False, True]
State prediction error at timestep 2249 is 0.012
Current timestep = 2250. State = [[-0.25286397  0.3601021 ]]. Action = [[0.        0.        0.        0.3256961]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 2250 is [True, False, False, False, False, True]
State prediction error at timestep 2250 is 0.012
Current timestep = 2251. State = [[-0.2528632  0.3601031]]. Action = [[ 0.          0.          0.         -0.96771663]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 2251 is [True, False, False, False, False, True]
State prediction error at timestep 2251 is 0.012
Current timestep = 2252. State = [[-0.25286242  0.3601041 ]]. Action = [[ 0.          0.          0.         -0.42129135]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 2252 is [True, False, False, False, False, True]
State prediction error at timestep 2252 is 0.012
Current timestep = 2253. State = [[-0.25286168  0.3601051 ]]. Action = [[ 0.         0.         0.        -0.6103716]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 2253 is [True, False, False, False, False, True]
State prediction error at timestep 2253 is 0.012
Current timestep = 2254. State = [[-0.25286093  0.36010608]]. Action = [[ 0.         0.         0.        -0.7831228]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 2254 is [True, False, False, False, False, True]
State prediction error at timestep 2254 is 0.012
Current timestep = 2255. State = [[-0.2528602   0.36010706]]. Action = [[ 0.         0.         0.        -0.5419403]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 2255 is [True, False, False, False, False, True]
State prediction error at timestep 2255 is 0.012
Current timestep = 2256. State = [[-0.25285947  0.36010805]]. Action = [[0.        0.        0.        0.4746908]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 2256 is [True, False, False, False, False, True]
State prediction error at timestep 2256 is 0.012
Current timestep = 2257. State = [[-0.25285873  0.360109  ]]. Action = [[0.        0.        0.        0.8252821]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 2257 is [True, False, False, False, False, True]
State prediction error at timestep 2257 is 0.012
Current timestep = 2258. State = [[-0.252858    0.36010996]]. Action = [[ 0.          0.          0.         -0.40211797]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 2258 is [True, False, False, False, False, True]
State prediction error at timestep 2258 is 0.012
Current timestep = 2259. State = [[-0.2528573  0.3601109]]. Action = [[0.         0.         0.         0.53453565]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 2259 is [True, False, False, False, False, True]
State prediction error at timestep 2259 is 0.012
Current timestep = 2260. State = [[-0.25285658  0.36011186]]. Action = [[ 0.          0.          0.         -0.94425863]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 2260 is [True, False, False, False, False, True]
State prediction error at timestep 2260 is 0.012
Current timestep = 2261. State = [[-0.2528559  0.3601128]]. Action = [[ 0.          0.          0.         -0.29513443]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 2261 is [True, False, False, False, False, True]
State prediction error at timestep 2261 is 0.012
Current timestep = 2262. State = [[-0.2528552  0.3601137]]. Action = [[ 0.          0.          0.         -0.39516294]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 2262 is [True, False, False, False, False, True]
State prediction error at timestep 2262 is 0.012
Current timestep = 2263. State = [[-0.25285453  0.36011463]]. Action = [[0.         0.         0.         0.15763283]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 2263 is [True, False, False, False, False, True]
State prediction error at timestep 2263 is 0.012
Current timestep = 2264. State = [[-0.25285384  0.36011553]]. Action = [[ 0.          0.          0.         -0.84402925]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 2264 is [True, False, False, False, False, True]
State prediction error at timestep 2264 is 0.012
Current timestep = 2265. State = [[-0.25285316  0.36011642]]. Action = [[0.         0.         0.         0.35346377]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 2265 is [True, False, False, False, False, True]
State prediction error at timestep 2265 is 0.012
Current timestep = 2266. State = [[-0.2528525   0.36011735]]. Action = [[0.         0.         0.         0.22105277]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 2266 is [True, False, False, False, False, True]
State prediction error at timestep 2266 is 0.012
Current timestep = 2267. State = [[-0.2528518  0.3601182]]. Action = [[ 0.          0.          0.         -0.44499582]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 2267 is [True, False, False, False, False, True]
State prediction error at timestep 2267 is 0.012
Current timestep = 2268. State = [[-0.25285116  0.3601191 ]]. Action = [[0.         0.         0.         0.48855495]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 2268 is [True, False, False, False, False, True]
State prediction error at timestep 2268 is 0.012
Current timestep = 2269. State = [[-0.2528505   0.36011997]]. Action = [[ 0.          0.          0.         -0.88927567]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 2269 is [True, False, False, False, False, True]
State prediction error at timestep 2269 is 0.012
Current timestep = 2270. State = [[-0.25284988  0.36012083]]. Action = [[ 0.          0.          0.         -0.42840934]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 2270 is [True, False, False, False, False, True]
State prediction error at timestep 2270 is 0.012
Current timestep = 2271. State = [[-0.25284922  0.3601217 ]]. Action = [[ 0.        0.        0.       -0.330163]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 2271 is [True, False, False, False, False, True]
State prediction error at timestep 2271 is 0.012
Current timestep = 2272. State = [[-0.2528486   0.36012256]]. Action = [[ 0.          0.          0.         -0.80526674]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 2272 is [True, False, False, False, False, True]
State prediction error at timestep 2272 is 0.012
Current timestep = 2273. State = [[-0.25284797  0.3601234 ]]. Action = [[0.        0.        0.        0.8087342]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 2273 is [True, False, False, False, False, True]
State prediction error at timestep 2273 is 0.012
Current timestep = 2274. State = [[-0.25284734  0.36012423]]. Action = [[0.         0.         0.         0.43930912]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 2274 is [True, False, False, False, False, True]
State prediction error at timestep 2274 is 0.012
Current timestep = 2275. State = [[-0.25284672  0.36012506]]. Action = [[ 0.          0.          0.         -0.24899554]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 2275 is [True, False, False, False, False, True]
State prediction error at timestep 2275 is 0.012
Current timestep = 2276. State = [[-0.25284612  0.3601259 ]]. Action = [[0.        0.        0.        0.4388218]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 2276 is [True, False, False, False, False, True]
State prediction error at timestep 2276 is 0.012
Current timestep = 2277. State = [[-0.25284553  0.3601267 ]]. Action = [[ 0.          0.          0.         -0.53306276]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 2277 is [True, False, False, False, False, True]
State prediction error at timestep 2277 is 0.012
Current timestep = 2278. State = [[-0.2528449   0.36012754]]. Action = [[0.         0.         0.         0.59412384]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 2278 is [True, False, False, False, False, True]
State prediction error at timestep 2278 is 0.012
Current timestep = 2279. State = [[-0.2528443   0.36012834]]. Action = [[ 0.          0.          0.         -0.96148276]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 2279 is [True, False, False, False, False, True]
State prediction error at timestep 2279 is 0.012
Current timestep = 2280. State = [[-0.25284374  0.36012912]]. Action = [[ 0.         0.         0.        -0.3502559]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 2280 is [True, False, False, False, False, True]
State prediction error at timestep 2280 is 0.012
Current timestep = 2281. State = [[-0.25284314  0.36012992]]. Action = [[0.        0.        0.        0.7176914]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 2281 is [True, False, False, False, False, True]
State prediction error at timestep 2281 is 0.012
Current timestep = 2282. State = [[-0.25284258  0.3601307 ]]. Action = [[0.        0.        0.        0.5207255]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 2282 is [True, False, False, False, False, True]
State prediction error at timestep 2282 is 0.012
Current timestep = 2283. State = [[-0.252842    0.36013147]]. Action = [[0.         0.         0.         0.24723577]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 2283 is [True, False, False, False, False, True]
State prediction error at timestep 2283 is 0.012
Current timestep = 2284. State = [[-0.2528414   0.36013225]]. Action = [[0.         0.         0.         0.85972583]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 2284 is [True, False, False, False, False, True]
State prediction error at timestep 2284 is 0.012
Current timestep = 2285. State = [[-0.25284088  0.36013302]]. Action = [[ 0.         0.         0.        -0.8586029]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 2285 is [True, False, False, False, False, True]
State prediction error at timestep 2285 is 0.012
Current timestep = 2286. State = [[-0.2528403  0.3601338]]. Action = [[ 0.          0.          0.         -0.29282844]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 2286 is [True, False, False, False, False, True]
State prediction error at timestep 2286 is 0.012
Current timestep = 2287. State = [[-0.25283974  0.36013454]]. Action = [[ 0.          0.          0.         -0.04683822]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 2287 is [True, False, False, False, False, True]
State prediction error at timestep 2287 is 0.012
Current timestep = 2288. State = [[-0.2528392  0.3601353]]. Action = [[ 0.         0.         0.        -0.3032838]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 2288 is [True, False, False, False, False, True]
State prediction error at timestep 2288 is 0.012
Current timestep = 2289. State = [[-0.25283867  0.36013603]]. Action = [[ 0.          0.          0.         -0.22781527]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 2289 is [True, False, False, False, False, True]
State prediction error at timestep 2289 is 0.012
Current timestep = 2290. State = [[-0.25283813  0.36013678]]. Action = [[0.         0.         0.         0.02441168]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 2290 is [True, False, False, False, False, True]
State prediction error at timestep 2290 is 0.012
Current timestep = 2291. State = [[-0.2528376  0.3601375]]. Action = [[0.        0.        0.        0.6703582]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 2291 is [True, False, False, False, False, True]
State prediction error at timestep 2291 is 0.012
Current timestep = 2292. State = [[-0.25283706  0.36013824]]. Action = [[0.        0.        0.        0.5641866]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 2292 is [True, False, False, False, False, True]
State prediction error at timestep 2292 is 0.012
Current timestep = 2293. State = [[-0.25283656  0.36013895]]. Action = [[0.         0.         0.         0.09123755]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 2293 is [True, False, False, False, False, True]
State prediction error at timestep 2293 is 0.012
Current timestep = 2294. State = [[-0.25283602  0.36013967]]. Action = [[0.         0.         0.         0.30464077]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 2294 is [True, False, False, False, False, True]
State prediction error at timestep 2294 is 0.012
Current timestep = 2295. State = [[-0.2528355   0.36014035]]. Action = [[0.       0.       0.       0.880244]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 2295 is [True, False, False, False, False, True]
State prediction error at timestep 2295 is 0.012
Current timestep = 2296. State = [[-0.252835    0.36014107]]. Action = [[0.         0.         0.         0.54886305]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 2296 is [True, False, False, False, False, True]
State prediction error at timestep 2296 is 0.012
Current timestep = 2297. State = [[-0.2528345   0.36014175]]. Action = [[0.        0.        0.        0.6565075]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 2297 is [True, False, False, False, False, True]
State prediction error at timestep 2297 is 0.012
Current timestep = 2298. State = [[-0.252834    0.36014244]]. Action = [[ 0.          0.          0.         -0.20612621]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 2298 is [True, False, False, False, False, True]
State prediction error at timestep 2298 is 0.012
Current timestep = 2299. State = [[-0.25283352  0.36014313]]. Action = [[0.        0.        0.        0.7254354]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 2299 is [True, False, False, False, False, True]
State prediction error at timestep 2299 is 0.012
Current timestep = 2300. State = [[-0.252833   0.3601438]]. Action = [[ 0.          0.          0.         -0.56343734]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 2300 is [True, False, False, False, False, True]
State prediction error at timestep 2300 is 0.012
Current timestep = 2301. State = [[-0.25283253  0.3601445 ]]. Action = [[ 0.          0.          0.         -0.94860715]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 2301 is [True, False, False, False, False, True]
State prediction error at timestep 2301 is 0.012
Current timestep = 2302. State = [[-0.25283206  0.36014515]]. Action = [[0.         0.         0.         0.76327515]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 2302 is [True, False, False, False, False, True]
State prediction error at timestep 2302 is 0.012
Current timestep = 2303. State = [[-0.25283158  0.36014584]]. Action = [[ 0.          0.          0.         -0.08575213]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 2303 is [True, False, False, False, False, True]
State prediction error at timestep 2303 is 0.012
Current timestep = 2304. State = [[-0.2528311  0.3601465]]. Action = [[ 0.          0.          0.         -0.25550914]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 2304 is [True, False, False, False, False, True]
State prediction error at timestep 2304 is 0.012
Current timestep = 2305. State = [[-0.25283065  0.36014715]]. Action = [[0.         0.         0.         0.82549095]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 2305 is [True, False, False, False, False, True]
State prediction error at timestep 2305 is 0.012
Current timestep = 2306. State = [[-0.25283018  0.36014777]]. Action = [[ 0.         0.         0.        -0.7340076]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 2306 is [True, False, False, False, False, True]
State prediction error at timestep 2306 is 0.012
Current timestep = 2307. State = [[-0.25282973  0.36014843]]. Action = [[0.         0.         0.         0.90922093]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 2307 is [True, False, False, False, False, True]
State prediction error at timestep 2307 is 0.012
Current timestep = 2308. State = [[-0.25282925  0.36014906]]. Action = [[0.         0.         0.         0.59108233]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 2308 is [True, False, False, False, False, True]
State prediction error at timestep 2308 is 0.012
Current timestep = 2309. State = [[-0.2528288  0.3601497]]. Action = [[0.         0.         0.         0.43234515]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 2309 is [True, False, False, False, False, True]
State prediction error at timestep 2309 is 0.012
Current timestep = 2310. State = [[-0.25282836  0.36015034]]. Action = [[ 0.         0.         0.        -0.4018578]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 2310 is [True, False, False, False, False, True]
State prediction error at timestep 2310 is 0.012
Current timestep = 2311. State = [[-0.2528279   0.36015093]]. Action = [[0.        0.        0.        0.9175018]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 2311 is [True, False, False, False, False, True]
State prediction error at timestep 2311 is 0.012
Current timestep = 2312. State = [[-0.2528275   0.36015156]]. Action = [[0.        0.        0.        0.5775633]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 2312 is [True, False, False, False, False, True]
State prediction error at timestep 2312 is 0.012
Current timestep = 2313. State = [[-0.25282705  0.36015218]]. Action = [[0.         0.         0.         0.25181973]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 2313 is [True, False, False, False, False, True]
State prediction error at timestep 2313 is 0.012
Current timestep = 2314. State = [[-0.25282663  0.36015278]]. Action = [[0.        0.        0.        0.9624667]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 2314 is [True, False, False, False, False, True]
State prediction error at timestep 2314 is 0.012
Current timestep = 2315. State = [[-0.25282618  0.36015338]]. Action = [[0.         0.         0.         0.31357586]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 2315 is [True, False, False, False, False, True]
State prediction error at timestep 2315 is 0.012
Current timestep = 2316. State = [[-0.25282577  0.360154  ]]. Action = [[0.         0.         0.         0.27028203]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 2316 is [True, False, False, False, False, True]
State prediction error at timestep 2316 is 0.012
Current timestep = 2317. State = [[-0.25282535  0.36015457]]. Action = [[0.        0.        0.        0.7093508]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 2317 is [True, False, False, False, False, True]
State prediction error at timestep 2317 is 0.012
Current timestep = 2318. State = [[-0.25282493  0.36015517]]. Action = [[ 0.          0.          0.         -0.54597336]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 2318 is [True, False, False, False, False, True]
State prediction error at timestep 2318 is 0.012
Current timestep = 2319. State = [[-0.25282454  0.36015576]]. Action = [[0.         0.         0.         0.40857887]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 2319 is [True, False, False, False, False, True]
State prediction error at timestep 2319 is 0.012
Current timestep = 2320. State = [[-0.25282413  0.36015633]]. Action = [[ 0.         0.         0.        -0.0902909]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 2320 is [True, False, False, False, False, True]
State prediction error at timestep 2320 is 0.012
Current timestep = 2321. State = [[-0.2528237   0.36015692]]. Action = [[ 0.        0.        0.       -0.956288]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 2321 is [True, False, False, False, False, True]
State prediction error at timestep 2321 is 0.012
Current timestep = 2322. State = [[-0.25282332  0.3601575 ]]. Action = [[ 0.          0.          0.         -0.31073022]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 2322 is [True, False, False, False, False, True]
State prediction error at timestep 2322 is 0.012
Current timestep = 2323. State = [[-0.25282294  0.36015806]]. Action = [[ 0.         0.         0.        -0.5636757]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 2323 is [True, False, False, False, False, True]
State prediction error at timestep 2323 is 0.012
Current timestep = 2324. State = [[-0.25282255  0.36015862]]. Action = [[ 0.         0.         0.        -0.7332104]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 2324 is [True, False, False, False, False, True]
State prediction error at timestep 2324 is 0.012
Current timestep = 2325. State = [[-0.25282216  0.36015916]]. Action = [[0.         0.         0.         0.85945606]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 2325 is [True, False, False, False, False, True]
State prediction error at timestep 2325 is 0.012
Current timestep = 2326. State = [[-0.25282177  0.36015972]]. Action = [[0.        0.        0.        0.9154525]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 2326 is [True, False, False, False, False, True]
State prediction error at timestep 2326 is 0.012
Current timestep = 2327. State = [[-0.2528214   0.36016026]]. Action = [[ 0.          0.          0.         -0.02405816]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 2327 is [True, False, False, False, False, True]
State prediction error at timestep 2327 is 0.012
Current timestep = 2328. State = [[-0.252821    0.36016083]]. Action = [[0.         0.         0.         0.36813188]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 2328 is [True, False, False, False, False, True]
State prediction error at timestep 2328 is 0.012
Current timestep = 2329. State = [[-0.25282064  0.36016136]]. Action = [[0.        0.        0.        0.8946967]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 2329 is [True, False, False, False, False, True]
State prediction error at timestep 2329 is 0.012
Current timestep = 2330. State = [[-0.25282025  0.3601619 ]]. Action = [[0.         0.         0.         0.01557839]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 2330 is [True, False, False, False, False, True]
State prediction error at timestep 2330 is 0.012
Current timestep = 2331. State = [[-0.2528199   0.36016244]]. Action = [[ 0.          0.          0.         -0.47708952]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 2331 is [True, False, False, False, False, True]
State prediction error at timestep 2331 is 0.012
Current timestep = 2332. State = [[-0.25281954  0.36016294]]. Action = [[ 0.         0.         0.        -0.5783481]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 2332 is [True, False, False, False, False, True]
State prediction error at timestep 2332 is 0.012
Current timestep = 2333. State = [[-0.25281918  0.36016348]]. Action = [[ 0.         0.         0.        -0.8676255]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 2333 is [True, False, False, False, False, True]
State prediction error at timestep 2333 is 0.012
Current timestep = 2334. State = [[-0.25281882  0.360164  ]]. Action = [[ 0.         0.         0.        -0.4082569]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 2334 is [True, False, False, False, False, True]
State prediction error at timestep 2334 is 0.012
Current timestep = 2335. State = [[-0.25281847  0.36016452]]. Action = [[ 0.          0.          0.         -0.22705168]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 2335 is [True, False, False, False, False, True]
State prediction error at timestep 2335 is 0.012
Current timestep = 2336. State = [[-0.2528181   0.36016503]]. Action = [[ 0.          0.          0.         -0.51416993]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 2336 is [True, False, False, False, False, True]
State prediction error at timestep 2336 is 0.012
Current timestep = 2337. State = [[-0.25281778  0.36016554]]. Action = [[ 0.         0.         0.        -0.9002783]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 2337 is [True, False, False, False, False, True]
State prediction error at timestep 2337 is 0.012
Current timestep = 2338. State = [[-0.25281742  0.36016604]]. Action = [[ 0.         0.         0.        -0.4977548]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 2338 is [True, False, False, False, False, True]
State prediction error at timestep 2338 is 0.012
Current timestep = 2339. State = [[-0.2528171   0.36016655]]. Action = [[ 0.          0.          0.         -0.92426467]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 2339 is [True, False, False, False, False, True]
State prediction error at timestep 2339 is 0.012
Current timestep = 2340. State = [[-0.25281677  0.36016703]]. Action = [[ 0.          0.          0.         -0.43981493]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 2340 is [True, False, False, False, False, True]
State prediction error at timestep 2340 is 0.012
Current timestep = 2341. State = [[-0.2528164   0.36016753]]. Action = [[0.         0.         0.         0.70138836]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 2341 is [True, False, False, False, False, True]
State prediction error at timestep 2341 is 0.012
Current timestep = 2342. State = [[-0.25281608  0.360168  ]]. Action = [[ 0.          0.          0.         -0.80607766]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 2342 is [True, False, False, False, False, True]
State prediction error at timestep 2342 is 0.012
Current timestep = 2343. State = [[-0.25281575  0.36016852]]. Action = [[ 0.         0.         0.        -0.8053168]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 2343 is [True, False, False, False, False, True]
State prediction error at timestep 2343 is 0.012
Current timestep = 2344. State = [[-0.25281543  0.360169  ]]. Action = [[ 0.          0.          0.         -0.79864454]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 2344 is [True, False, False, False, False, True]
State prediction error at timestep 2344 is 0.012
Current timestep = 2345. State = [[-0.25281513  0.36016947]]. Action = [[0.         0.         0.         0.36159086]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 2345 is [True, False, False, False, False, True]
State prediction error at timestep 2345 is 0.012
Current timestep = 2346. State = [[-0.2528148   0.36016995]]. Action = [[ 0.         0.         0.        -0.4256835]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 2346 is [True, False, False, False, False, True]
State prediction error at timestep 2346 is 0.012
Current timestep = 2347. State = [[-0.25281447  0.3601704 ]]. Action = [[0.         0.         0.         0.22681534]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 2347 is [True, False, False, False, False, True]
State prediction error at timestep 2347 is 0.012
Current timestep = 2348. State = [[-0.25281417  0.36017087]]. Action = [[ 0.         0.         0.        -0.1072644]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 2348 is [True, False, False, False, False, True]
State prediction error at timestep 2348 is 0.012
Current timestep = 2349. State = [[-0.25281388  0.36017135]]. Action = [[0.        0.        0.        0.9980638]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 2349 is [True, False, False, False, False, True]
State prediction error at timestep 2349 is 0.012
Current timestep = 2350. State = [[-0.25281355  0.3601718 ]]. Action = [[0.       0.       0.       0.826308]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 2350 is [True, False, False, False, False, True]
State prediction error at timestep 2350 is 0.012
Current timestep = 2351. State = [[-0.25281325  0.36017224]]. Action = [[ 0.         0.         0.        -0.9647839]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 2351 is [True, False, False, False, False, True]
State prediction error at timestep 2351 is 0.012
Current timestep = 2352. State = [[-0.25281295  0.36017272]]. Action = [[0.         0.         0.         0.21247113]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 2352 is [True, False, False, False, False, True]
State prediction error at timestep 2352 is 0.012
Current timestep = 2353. State = [[-0.25281265  0.36017317]]. Action = [[ 0.          0.          0.         -0.11832917]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 2353 is [True, False, False, False, False, True]
State prediction error at timestep 2353 is 0.012
Current timestep = 2354. State = [[-0.25281236  0.3601736 ]]. Action = [[0.        0.        0.        0.6701782]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 2354 is [True, False, False, False, False, True]
State prediction error at timestep 2354 is 0.012
Current timestep = 2355. State = [[-0.2528121   0.36017403]]. Action = [[0.       0.       0.       0.806762]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 2355 is [True, False, False, False, False, True]
State prediction error at timestep 2355 is 0.012
Current timestep = 2356. State = [[-0.2528118   0.36017448]]. Action = [[0.        0.        0.        0.4747938]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 2356 is [True, False, False, False, False, True]
State prediction error at timestep 2356 is 0.012
Current timestep = 2357. State = [[-0.2528115   0.36017492]]. Action = [[0.        0.        0.        0.9730718]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 2357 is [True, False, False, False, False, True]
State prediction error at timestep 2357 is 0.012
Current timestep = 2358. State = [[-0.25281122  0.36017534]]. Action = [[0.        0.        0.        0.8115201]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 2358 is [True, False, False, False, False, True]
State prediction error at timestep 2358 is 0.012
Current timestep = 2359. State = [[-0.25281093  0.3601758 ]]. Action = [[ 0.          0.          0.         -0.34305614]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 2359 is [True, False, False, False, False, True]
State prediction error at timestep 2359 is 0.012
Current timestep = 2360. State = [[-0.25281066  0.3601762 ]]. Action = [[0.        0.        0.        0.5247146]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 2360 is [True, False, False, False, False, True]
State prediction error at timestep 2360 is 0.012
Current timestep = 2361. State = [[-0.2528104   0.36017662]]. Action = [[0.        0.        0.        0.8307245]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 2361 is [True, False, False, False, False, True]
State prediction error at timestep 2361 is 0.012
Current timestep = 2362. State = [[-0.25281012  0.36017704]]. Action = [[ 0.         0.         0.        -0.4493041]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 2362 is [True, False, False, False, False, True]
State prediction error at timestep 2362 is 0.012
Current timestep = 2363. State = [[-0.25280985  0.36017746]]. Action = [[ 0.          0.          0.         -0.18475449]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 2363 is [True, False, False, False, False, True]
State prediction error at timestep 2363 is 0.012
Current timestep = 2364. State = [[-0.25280958  0.36017787]]. Action = [[ 0.         0.         0.        -0.5570759]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 2364 is [True, False, False, False, False, True]
State prediction error at timestep 2364 is 0.012
Current timestep = 2365. State = [[-0.25280932  0.3601783 ]]. Action = [[0.         0.         0.         0.69322205]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 2365 is [True, False, False, False, False, True]
State prediction error at timestep 2365 is 0.012
Current timestep = 2366. State = [[-0.25280905  0.3601787 ]]. Action = [[ 0.        0.        0.       -0.844432]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 2366 is [True, False, False, False, False, True]
State prediction error at timestep 2366 is 0.012
Current timestep = 2367. State = [[-0.25280878  0.3601791 ]]. Action = [[ 0.         0.         0.        -0.8611882]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 2367 is [True, False, False, False, False, True]
State prediction error at timestep 2367 is 0.012
Current timestep = 2368. State = [[-0.25280854  0.3601795 ]]. Action = [[0.        0.        0.        0.6071397]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 2368 is [True, False, False, False, False, True]
State prediction error at timestep 2368 is 0.012
Current timestep = 2369. State = [[-0.25280827  0.3601799 ]]. Action = [[ 0.          0.          0.         -0.94164586]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 2369 is [True, False, False, False, False, True]
State prediction error at timestep 2369 is 0.012
Current timestep = 2370. State = [[-0.25280803  0.3601803 ]]. Action = [[0.        0.        0.        0.9962249]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 2370 is [True, False, False, False, False, True]
State prediction error at timestep 2370 is 0.012
Current timestep = 2371. State = [[-0.25280777  0.3601807 ]]. Action = [[ 0.         0.         0.        -0.6632991]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 2371 is [True, False, False, False, False, True]
State prediction error at timestep 2371 is 0.012
Current timestep = 2372. State = [[-0.25280753  0.3601811 ]]. Action = [[ 0.         0.         0.        -0.5220115]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 2372 is [True, False, False, False, False, True]
State prediction error at timestep 2372 is 0.012
Current timestep = 2373. State = [[-0.2528073   0.36018148]]. Action = [[ 0.         0.         0.        -0.7863721]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 2373 is [True, False, False, False, False, True]
State prediction error at timestep 2373 is 0.012
Current timestep = 2374. State = [[-0.25280705  0.36018184]]. Action = [[0.        0.        0.        0.3908074]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 2374 is [True, False, False, False, False, True]
State prediction error at timestep 2374 is 0.012
Current timestep = 2375. State = [[-0.2528068   0.36018223]]. Action = [[ 0.          0.          0.         -0.31398165]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 2375 is [True, False, False, False, False, True]
State prediction error at timestep 2375 is 0.012
Current timestep = 2376. State = [[-0.25280657  0.3601826 ]]. Action = [[0.         0.         0.         0.25026262]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 2376 is [True, False, False, False, False, True]
State prediction error at timestep 2376 is 0.012
Current timestep = 2377. State = [[-0.25280634  0.360183  ]]. Action = [[0.         0.         0.         0.46287155]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 2377 is [True, False, False, False, False, True]
State prediction error at timestep 2377 is 0.012
Current timestep = 2378. State = [[-0.2528061   0.36018336]]. Action = [[ 0.          0.          0.         -0.14438248]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 2378 is [True, False, False, False, False, True]
State prediction error at timestep 2378 is 0.012
Current timestep = 2379. State = [[-0.25280586  0.36018375]]. Action = [[0.        0.        0.        0.8158958]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 2379 is [True, False, False, False, False, True]
State prediction error at timestep 2379 is 0.012
Current timestep = 2380. State = [[-0.25280565  0.3601841 ]]. Action = [[0.        0.        0.        0.6683686]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 2380 is [True, False, False, False, False, True]
State prediction error at timestep 2380 is 0.012
Current timestep = 2381. State = [[-0.2528054   0.36018446]]. Action = [[ 0.         0.         0.        -0.8518116]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 2381 is [True, False, False, False, False, True]
State prediction error at timestep 2381 is 0.012
Current timestep = 2382. State = [[-0.25280517  0.36018482]]. Action = [[ 0.          0.          0.         -0.24271488]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 2382 is [True, False, False, False, False, True]
State prediction error at timestep 2382 is 0.012
Current timestep = 2383. State = [[-0.25280496  0.36018518]]. Action = [[0.         0.         0.         0.46485102]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 2383 is [True, False, False, False, False, True]
State prediction error at timestep 2383 is 0.012
Current timestep = 2384. State = [[-0.25280476  0.36018553]]. Action = [[0.         0.         0.         0.93056357]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 2384 is [True, False, False, False, False, True]
State prediction error at timestep 2384 is 0.012
Current timestep = 2385. State = [[-0.25280452  0.3601859 ]]. Action = [[0.         0.         0.         0.55188465]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 2385 is [True, False, False, False, False, True]
State prediction error at timestep 2385 is 0.012
Current timestep = 2386. State = [[-0.2528043   0.36018625]]. Action = [[ 0.          0.          0.         -0.33770943]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 2386 is [True, False, False, False, False, True]
State prediction error at timestep 2386 is 0.012
Current timestep = 2387. State = [[-0.2528041  0.3601866]]. Action = [[0.         0.         0.         0.64115834]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 2387 is [True, False, False, False, False, True]
State prediction error at timestep 2387 is 0.012
Current timestep = 2388. State = [[-0.2528039   0.36018693]]. Action = [[0.         0.         0.         0.60220385]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 2388 is [True, False, False, False, False, True]
State prediction error at timestep 2388 is 0.012
Current timestep = 2389. State = [[-0.25280368  0.3601873 ]]. Action = [[ 0.         0.         0.        -0.5176612]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 2389 is [True, False, False, False, False, True]
State prediction error at timestep 2389 is 0.012
Current timestep = 2390. State = [[-0.25280347  0.36018762]]. Action = [[ 0.          0.          0.         -0.09305209]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 2390 is [True, False, False, False, False, True]
State prediction error at timestep 2390 is 0.012
Current timestep = 2391. State = [[-0.25280327  0.36018798]]. Action = [[0.        0.        0.        0.5170171]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 2391 is [True, False, False, False, False, True]
State prediction error at timestep 2391 is 0.012
Current timestep = 2392. State = [[-0.25280306  0.3601883 ]]. Action = [[ 0.          0.          0.         -0.48815215]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 2392 is [True, False, False, False, False, True]
State prediction error at timestep 2392 is 0.012
Current timestep = 2393. State = [[-0.25280288  0.36018863]]. Action = [[0.         0.         0.         0.05336082]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 2393 is [True, False, False, False, False, True]
State prediction error at timestep 2393 is 0.012
Current timestep = 2394. State = [[-0.25280267  0.36018896]]. Action = [[0.        0.        0.        0.5789099]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 2394 is [True, False, False, False, False, True]
State prediction error at timestep 2394 is 0.012
Current timestep = 2395. State = [[-0.25280246  0.3601893 ]]. Action = [[0.         0.         0.         0.64217937]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 2395 is [True, False, False, False, False, True]
State prediction error at timestep 2395 is 0.012
Current timestep = 2396. State = [[-0.25280228  0.36018962]]. Action = [[ 0.          0.          0.         -0.09744024]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 2396 is [True, False, False, False, False, True]
State prediction error at timestep 2396 is 0.012
Current timestep = 2397. State = [[-0.25280207  0.36018994]]. Action = [[0.         0.         0.         0.91097915]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 2397 is [True, False, False, False, False, True]
State prediction error at timestep 2397 is 0.012
Current timestep = 2398. State = [[-0.2528019   0.36019027]]. Action = [[0.         0.         0.         0.93664956]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 2398 is [True, False, False, False, False, True]
State prediction error at timestep 2398 is 0.012
Current timestep = 2399. State = [[-0.25280172  0.3601906 ]]. Action = [[ 0.         0.         0.        -0.5151357]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 2399 is [True, False, False, False, False, True]
State prediction error at timestep 2399 is 0.012
Current timestep = 2400. State = [[-0.2528015   0.36019093]]. Action = [[ 0.         0.         0.        -0.9280269]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 2400 is [True, False, False, False, False, True]
State prediction error at timestep 2400 is 0.012
Current timestep = 2401. State = [[-0.25280133  0.36019123]]. Action = [[0.         0.         0.         0.84771323]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 2401 is [True, False, False, False, False, True]
State prediction error at timestep 2401 is 0.012
Current timestep = 2402. State = [[-0.25280115  0.36019155]]. Action = [[ 0.         0.         0.        -0.5855863]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 2402 is [True, False, False, False, False, True]
State prediction error at timestep 2402 is 0.012
Current timestep = 2403. State = [[-0.25280097  0.36019185]]. Action = [[0.         0.         0.         0.25223148]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 2403 is [True, False, False, False, False, True]
State prediction error at timestep 2403 is 0.012
Current timestep = 2404. State = [[-0.2528008   0.36019215]]. Action = [[ 0.          0.          0.         -0.68146443]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 2404 is [True, False, False, False, False, True]
State prediction error at timestep 2404 is 0.012
Current timestep = 2405. State = [[-0.2528006   0.36019248]]. Action = [[0.         0.         0.         0.01447785]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 2405 is [True, False, False, False, False, True]
State prediction error at timestep 2405 is 0.012
Current timestep = 2406. State = [[-0.25280043  0.36019278]]. Action = [[0.       0.       0.       0.726493]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 2406 is [True, False, False, False, False, True]
State prediction error at timestep 2406 is 0.012
Current timestep = 2407. State = [[-0.25280026  0.36019307]]. Action = [[0.         0.         0.         0.21035254]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 2407 is [True, False, False, False, False, True]
State prediction error at timestep 2407 is 0.012
Current timestep = 2408. State = [[-0.25280008  0.36019337]]. Action = [[0.        0.        0.        0.8668808]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 2408 is [True, False, False, False, False, True]
State prediction error at timestep 2408 is 0.012
Current timestep = 2409. State = [[-0.25279993  0.36019367]]. Action = [[0.        0.        0.        0.9897475]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 2409 is [True, False, False, False, False, True]
State prediction error at timestep 2409 is 0.012
Current timestep = 2410. State = [[-0.25279975  0.36019397]]. Action = [[ 0.         0.         0.        -0.5279586]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 2410 is [True, False, False, False, False, True]
State prediction error at timestep 2410 is 0.012
Current timestep = 2411. State = [[-0.25279957  0.36019427]]. Action = [[0.         0.         0.         0.72778773]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 2411 is [True, False, False, False, False, True]
State prediction error at timestep 2411 is 0.012
Current timestep = 2412. State = [[-0.25279942  0.36019456]]. Action = [[0.         0.         0.         0.17423868]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 2412 is [True, False, False, False, False, True]
State prediction error at timestep 2412 is 0.012
Current timestep = 2413. State = [[-0.25279924  0.36019486]]. Action = [[ 0.          0.          0.         -0.72144675]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 2413 is [True, False, False, False, False, True]
State prediction error at timestep 2413 is 0.012
Current timestep = 2414. State = [[-0.2527991   0.36019513]]. Action = [[ 0.          0.          0.         -0.25697386]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 2414 is [True, False, False, False, False, True]
State prediction error at timestep 2414 is 0.012
Current timestep = 2415. State = [[-0.25279894  0.36019543]]. Action = [[ 0.          0.          0.         -0.60349345]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 2415 is [True, False, False, False, False, True]
State prediction error at timestep 2415 is 0.012
Current timestep = 2416. State = [[-0.25279877  0.3601957 ]]. Action = [[ 0.         0.         0.        -0.9196693]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 2416 is [True, False, False, False, False, True]
State prediction error at timestep 2416 is 0.012
Current timestep = 2417. State = [[-0.25279862  0.360196  ]]. Action = [[ 0.          0.          0.         -0.02761453]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 2417 is [True, False, False, False, False, True]
State prediction error at timestep 2417 is 0.012
Current timestep = 2418. State = [[-0.25279847  0.36019626]]. Action = [[ 0.          0.          0.         -0.17537403]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 2418 is [True, False, False, False, False, True]
State prediction error at timestep 2418 is 0.012
Current timestep = 2419. State = [[-0.25279832  0.36019656]]. Action = [[ 0.          0.          0.         -0.97794604]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 2419 is [True, False, False, False, False, True]
State prediction error at timestep 2419 is 0.012
Current timestep = 2420. State = [[-0.25279817  0.36019683]]. Action = [[0.        0.        0.        0.6896211]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 2420 is [True, False, False, False, False, True]
State prediction error at timestep 2420 is 0.012
Current timestep = 2421. State = [[-0.25279802  0.3601971 ]]. Action = [[0.        0.        0.        0.5412648]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 2421 is [True, False, False, False, False, True]
State prediction error at timestep 2421 is 0.012
Current timestep = 2422. State = [[-0.25279787  0.36019737]]. Action = [[ 0.         0.         0.        -0.6353849]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 2422 is [True, False, False, False, False, True]
State prediction error at timestep 2422 is 0.012
Current timestep = 2423. State = [[-0.25279772  0.36019763]]. Action = [[0.        0.        0.        0.8649193]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 2423 is [True, False, False, False, False, True]
State prediction error at timestep 2423 is 0.012
Current timestep = 2424. State = [[-0.25279757  0.3601979 ]]. Action = [[ 0.          0.          0.         -0.84886336]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 2424 is [True, False, False, False, False, True]
State prediction error at timestep 2424 is 0.012
Current timestep = 2425. State = [[-0.25279742  0.36019817]]. Action = [[ 0.          0.          0.         -0.11141467]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 2425 is [True, False, False, False, False, True]
State prediction error at timestep 2425 is 0.012
Current timestep = 2426. State = [[-0.25279728  0.36019844]]. Action = [[ 0.          0.          0.         -0.26961815]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 2426 is [True, False, False, False, False, True]
State prediction error at timestep 2426 is 0.012
Current timestep = 2427. State = [[-0.25279713  0.3601987 ]]. Action = [[0.         0.         0.         0.56721187]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 2427 is [True, False, False, False, False, True]
State prediction error at timestep 2427 is 0.012
Current timestep = 2428. State = [[-0.252797    0.36019897]]. Action = [[0.        0.        0.        0.7181016]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 2428 is [True, False, False, False, False, True]
State prediction error at timestep 2428 is 0.012
Current timestep = 2429. State = [[-0.25279686  0.36019924]]. Action = [[ 0.          0.          0.         -0.12211442]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 2429 is [True, False, False, False, False, True]
State prediction error at timestep 2429 is 0.012
Current timestep = 2430. State = [[-0.2527967   0.36019948]]. Action = [[ 0.        0.        0.       -0.407161]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 2430 is [True, False, False, False, False, True]
State prediction error at timestep 2430 is 0.012
Current timestep = 2431. State = [[-0.2527966   0.36019975]]. Action = [[ 0.          0.          0.         -0.65003383]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 2431 is [True, False, False, False, False, True]
State prediction error at timestep 2431 is 0.012
Current timestep = 2432. State = [[-0.25279644  0.36020002]]. Action = [[0.         0.         0.         0.12915635]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 2432 is [True, False, False, False, False, True]
State prediction error at timestep 2432 is 0.012
Current timestep = 2433. State = [[-0.25279632  0.36020026]]. Action = [[ 0.          0.          0.         -0.01466256]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 2433 is [True, False, False, False, False, True]
State prediction error at timestep 2433 is 0.012
Current timestep = 2434. State = [[-0.2527962  0.3602005]]. Action = [[ 0.         0.         0.        -0.8985079]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 2434 is [True, False, False, False, False, True]
State prediction error at timestep 2434 is 0.012
Current timestep = 2435. State = [[-0.25279605  0.36020076]]. Action = [[ 0.          0.          0.         -0.98121554]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 2435 is [True, False, False, False, False, True]
State prediction error at timestep 2435 is 0.012
Current timestep = 2436. State = [[-0.25279593  0.360201  ]]. Action = [[ 0.          0.          0.         -0.40803063]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 2436 is [True, False, False, False, False, True]
State prediction error at timestep 2436 is 0.012
Current timestep = 2437. State = [[-0.25279582  0.36020124]]. Action = [[ 0.          0.          0.         -0.21383548]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 2437 is [True, False, False, False, False, True]
State prediction error at timestep 2437 is 0.012
Current timestep = 2438. State = [[-0.25279567  0.3602015 ]]. Action = [[0.         0.         0.         0.23667109]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 2438 is [True, False, False, False, False, True]
State prediction error at timestep 2438 is 0.012
Current timestep = 2439. State = [[-0.25279555  0.36020175]]. Action = [[ 0.          0.          0.         -0.09240472]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 2439 is [True, False, False, False, False, True]
State prediction error at timestep 2439 is 0.012
Current timestep = 2440. State = [[-0.25279543  0.36020198]]. Action = [[0.        0.        0.        0.6562693]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 2440 is [True, False, False, False, False, True]
State prediction error at timestep 2440 is 0.012
Current timestep = 2441. State = [[-0.2527953   0.36020222]]. Action = [[ 0.          0.          0.         -0.19696194]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 2441 is [True, False, False, False, False, True]
State prediction error at timestep 2441 is 0.012
Current timestep = 2442. State = [[-0.2527952   0.36020246]]. Action = [[ 0.         0.         0.        -0.7522435]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 2442 is [True, False, False, False, False, True]
State prediction error at timestep 2442 is 0.012
Current timestep = 2443. State = [[-0.25279507  0.3602027 ]]. Action = [[ 0.          0.          0.         -0.12690389]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 2443 is [True, False, False, False, False, True]
State prediction error at timestep 2443 is 0.012
Current timestep = 2444. State = [[-0.25279495  0.36020294]]. Action = [[ 0.          0.          0.         -0.75348806]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 2444 is [True, False, False, False, False, True]
State prediction error at timestep 2444 is 0.012
Current timestep = 2445. State = [[-0.25279483  0.36020318]]. Action = [[ 0.          0.          0.         -0.53446203]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 2445 is [True, False, False, False, False, True]
State prediction error at timestep 2445 is 0.012
Current timestep = 2446. State = [[-0.2527947   0.36020342]]. Action = [[0.         0.         0.         0.22086906]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 2446 is [True, False, False, False, False, True]
State prediction error at timestep 2446 is 0.012
Current timestep = 2447. State = [[-0.25279462  0.36020362]]. Action = [[0.        0.        0.        0.4907186]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 2447 is [True, False, False, False, False, True]
State prediction error at timestep 2447 is 0.012
Current timestep = 2448. State = [[-0.2527945   0.36020386]]. Action = [[0.         0.         0.         0.15181231]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 2448 is [True, False, False, False, False, True]
State prediction error at timestep 2448 is 0.012
Current timestep = 2449. State = [[-0.25279438  0.3602041 ]]. Action = [[0.       0.       0.       0.200647]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 2449 is [True, False, False, False, False, True]
State prediction error at timestep 2449 is 0.012
Current timestep = 2450. State = [[-0.25279427  0.3602043 ]]. Action = [[0.         0.         0.         0.54398346]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 2450 is [True, False, False, False, False, True]
State prediction error at timestep 2450 is 0.012
Current timestep = 2451. State = [[-0.25279418  0.36020455]]. Action = [[ 0.         0.         0.        -0.6032784]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 2451 is [True, False, False, False, False, True]
State prediction error at timestep 2451 is 0.012
Current timestep = 2452. State = [[-0.25279406  0.36020476]]. Action = [[ 0.          0.          0.         -0.45633996]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 2452 is [True, False, False, False, False, True]
State prediction error at timestep 2452 is 0.012
Current timestep = 2453. State = [[-0.25279397  0.360205  ]]. Action = [[ 0.         0.         0.        -0.9109053]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 2453 is [True, False, False, False, False, True]
State prediction error at timestep 2453 is 0.012
Current timestep = 2454. State = [[-0.25279385  0.3602052 ]]. Action = [[0.         0.         0.         0.60763645]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 2454 is [True, False, False, False, False, True]
State prediction error at timestep 2454 is 0.012
Current timestep = 2455. State = [[-0.25279373  0.3602054 ]]. Action = [[ 0.         0.         0.        -0.4428718]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 2455 is [True, False, False, False, False, True]
State prediction error at timestep 2455 is 0.012
Current timestep = 2456. State = [[-0.25279364  0.36020565]]. Action = [[0.        0.        0.        0.7422123]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 2456 is [True, False, False, False, False, True]
State prediction error at timestep 2456 is 0.012
Current timestep = 2457. State = [[-0.25279355  0.36020586]]. Action = [[0.         0.         0.         0.21503532]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 2457 is [True, False, False, False, False, True]
State prediction error at timestep 2457 is 0.012
Current timestep = 2458. State = [[-0.25279343  0.36020607]]. Action = [[0.        0.        0.        0.9315195]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 2458 is [True, False, False, False, False, True]
State prediction error at timestep 2458 is 0.012
Current timestep = 2459. State = [[-0.25279334  0.36020628]]. Action = [[0.         0.         0.         0.11611247]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 2459 is [True, False, False, False, False, True]
State prediction error at timestep 2459 is 0.012
Current timestep = 2460. State = [[-0.25279325  0.3602065 ]]. Action = [[0.        0.        0.        0.1907047]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 2460 is [True, False, False, False, False, True]
State prediction error at timestep 2460 is 0.012
Current timestep = 2461. State = [[-0.25279313  0.36020672]]. Action = [[ 0.          0.          0.         -0.51455176]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 2461 is [True, False, False, False, False, True]
State prediction error at timestep 2461 is 0.012
Current timestep = 2462. State = [[-0.25279304  0.36020693]]. Action = [[0.         0.         0.         0.34980893]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 2462 is [True, False, False, False, False, True]
State prediction error at timestep 2462 is 0.012
Current timestep = 2463. State = [[-0.25279295  0.36020714]]. Action = [[0.         0.         0.         0.01640713]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 2463 is [True, False, False, False, False, True]
State prediction error at timestep 2463 is 0.012
Current timestep = 2464. State = [[-0.25279287  0.36020735]]. Action = [[0.         0.         0.         0.69222116]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 2464 is [True, False, False, False, False, True]
State prediction error at timestep 2464 is 0.012
Current timestep = 2465. State = [[-0.25279278  0.36020756]]. Action = [[0.        0.        0.        0.2591853]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 2465 is [True, False, False, False, False, True]
State prediction error at timestep 2465 is 0.012
Current timestep = 2466. State = [[-0.2527927   0.36020774]]. Action = [[0.         0.         0.         0.85855854]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 2466 is [True, False, False, False, False, True]
State prediction error at timestep 2466 is 0.012
Current timestep = 2467. State = [[-0.2527926   0.36020795]]. Action = [[ 0.        0.        0.       -0.491754]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 2467 is [True, False, False, False, False, True]
State prediction error at timestep 2467 is 0.012
Current timestep = 2468. State = [[-0.2527925   0.36020815]]. Action = [[ 0.          0.          0.         -0.57937807]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 2468 is [True, False, False, False, False, True]
State prediction error at timestep 2468 is 0.012
Current timestep = 2469. State = [[-0.25279242  0.36020836]]. Action = [[ 0.        0.        0.       -0.810282]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 2469 is [True, False, False, False, False, True]
State prediction error at timestep 2469 is 0.012
Current timestep = 2470. State = [[-0.25279233  0.36020854]]. Action = [[0.        0.        0.        0.8029479]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 2470 is [True, False, False, False, False, True]
State prediction error at timestep 2470 is 0.012
Current timestep = 2471. State = [[-0.25279224  0.36020875]]. Action = [[0.         0.         0.         0.76806307]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 2471 is [True, False, False, False, False, True]
State prediction error at timestep 2471 is 0.012
Current timestep = 2472. State = [[-0.25279215  0.36020896]]. Action = [[ 0.          0.          0.         -0.12055641]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 2472 is [True, False, False, False, False, True]
State prediction error at timestep 2472 is 0.012
Current timestep = 2473. State = [[-0.25279206  0.36020914]]. Action = [[ 0.         0.         0.        -0.4527114]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 2473 is [True, False, False, False, False, True]
State prediction error at timestep 2473 is 0.012
Current timestep = 2474. State = [[-0.25279197  0.36020935]]. Action = [[ 0.         0.         0.        -0.2919948]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 2474 is [True, False, False, False, False, True]
State prediction error at timestep 2474 is 0.012
Current timestep = 2475. State = [[-0.25279188  0.36020952]]. Action = [[0.        0.        0.        0.5029223]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 2475 is [True, False, False, False, False, True]
State prediction error at timestep 2475 is 0.012
Current timestep = 2476. State = [[-0.25279182  0.36020973]]. Action = [[ 0.        0.        0.       -0.958554]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 2476 is [True, False, False, False, False, True]
State prediction error at timestep 2476 is 0.012
Current timestep = 2477. State = [[-0.25279173  0.3602099 ]]. Action = [[0.         0.         0.         0.55005765]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 2477 is [True, False, False, False, False, True]
State prediction error at timestep 2477 is 0.012
Current timestep = 2478. State = [[-0.25279164  0.36021012]]. Action = [[0.         0.         0.         0.09132564]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 2478 is [True, False, False, False, False, True]
State prediction error at timestep 2478 is 0.012
Current timestep = 2479. State = [[-0.25279158  0.3602103 ]]. Action = [[0.         0.         0.         0.82477355]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 2479 is [True, False, False, False, False, True]
State prediction error at timestep 2479 is 0.012
Current timestep = 2480. State = [[-0.2527915   0.36021048]]. Action = [[0.         0.         0.         0.81440556]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 2480 is [True, False, False, False, False, True]
State prediction error at timestep 2480 is 0.012
Current timestep = 2481. State = [[-0.25279143  0.36021066]]. Action = [[0.        0.        0.        0.5779135]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 2481 is [True, False, False, False, False, True]
State prediction error at timestep 2481 is 0.012
Current timestep = 2482. State = [[-0.25279135  0.36021087]]. Action = [[0.         0.         0.         0.12937653]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 2482 is [True, False, False, False, False, True]
State prediction error at timestep 2482 is 0.012
Current timestep = 2483. State = [[-0.25279126  0.36021104]]. Action = [[0.        0.        0.        0.6552421]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 2483 is [True, False, False, False, False, True]
State prediction error at timestep 2483 is 0.012
Current timestep = 2484. State = [[-0.2527912   0.36021122]]. Action = [[ 0.          0.          0.         -0.51828533]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 2484 is [True, False, False, False, False, True]
State prediction error at timestep 2484 is 0.012
Current timestep = 2485. State = [[-0.25279114  0.3602114 ]]. Action = [[ 0.          0.          0.         -0.00424856]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 2485 is [True, False, False, False, False, True]
State prediction error at timestep 2485 is 0.012
Current timestep = 2486. State = [[-0.25279105  0.36021158]]. Action = [[0.         0.         0.         0.61279464]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 2486 is [True, False, False, False, False, True]
State prediction error at timestep 2486 is 0.012
Current timestep = 2487. State = [[-0.252791    0.36021176]]. Action = [[ 0.         0.         0.        -0.8316215]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 2487 is [True, False, False, False, False, True]
State prediction error at timestep 2487 is 0.012
Current timestep = 2488. State = [[-0.2527909   0.36021194]]. Action = [[ 0.          0.          0.         -0.15047985]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 2488 is [True, False, False, False, False, True]
State prediction error at timestep 2488 is 0.012
Current timestep = 2489. State = [[-0.25279084  0.36021212]]. Action = [[ 0.          0.          0.         -0.02655429]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 2489 is [True, False, False, False, False, True]
State prediction error at timestep 2489 is 0.012
Current timestep = 2490. State = [[-0.25279078  0.3602123 ]]. Action = [[0.        0.        0.        0.6685997]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 2490 is [True, False, False, False, False, True]
State prediction error at timestep 2490 is 0.012
Current timestep = 2491. State = [[-0.2527907   0.36021248]]. Action = [[ 0.          0.          0.         -0.79400724]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 2491 is [True, False, False, False, False, True]
State prediction error at timestep 2491 is 0.012
Current timestep = 2492. State = [[-0.25279063  0.36021265]]. Action = [[0.         0.         0.         0.27245915]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 2492 is [True, False, False, False, False, True]
State prediction error at timestep 2492 is 0.012
Current timestep = 2493. State = [[-0.25279057  0.36021283]]. Action = [[0.         0.         0.         0.41795206]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 2493 is [True, False, False, False, False, True]
State prediction error at timestep 2493 is 0.012
Current timestep = 2494. State = [[-0.2527905  0.360213 ]]. Action = [[0.        0.        0.        0.5495231]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 2494 is [True, False, False, False, False, True]
State prediction error at timestep 2494 is 0.012
Current timestep = 2495. State = [[-0.25279045  0.36021316]]. Action = [[0.         0.         0.         0.40560603]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 2495 is [True, False, False, False, False, True]
State prediction error at timestep 2495 is 0.012
Current timestep = 2496. State = [[-0.25279036  0.36021334]]. Action = [[0.         0.         0.         0.06957185]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 2496 is [True, False, False, False, False, True]
State prediction error at timestep 2496 is 0.012
Current timestep = 2497. State = [[-0.2527903   0.36021352]]. Action = [[ 0.          0.          0.         -0.53409684]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 2497 is [True, False, False, False, False, True]
State prediction error at timestep 2497 is 0.012
Current timestep = 2498. State = [[-0.25279024  0.3602137 ]]. Action = [[0.         0.         0.         0.37210405]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 2498 is [True, False, False, False, False, True]
State prediction error at timestep 2498 is 0.012
Current timestep = 2499. State = [[-0.25279018  0.36021385]]. Action = [[ 0.         0.         0.        -0.5771678]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 2499 is [True, False, False, False, False, True]
State prediction error at timestep 2499 is 0.012
Current timestep = 2500. State = [[-0.25279012  0.36021402]]. Action = [[ 0.          0.          0.         -0.26800203]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 2500 is [True, False, False, False, False, True]
State prediction error at timestep 2500 is 0.012
Current timestep = 2501. State = [[-0.25279006  0.36021417]]. Action = [[ 0.         0.         0.        -0.5362177]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 2501 is [True, False, False, False, False, True]
State prediction error at timestep 2501 is 0.012
Current timestep = 2502. State = [[-0.25279     0.36021435]]. Action = [[0.        0.        0.        0.7064636]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 2502 is [True, False, False, False, False, True]
State prediction error at timestep 2502 is 0.012
Current timestep = 2503. State = [[-0.25278994  0.3602145 ]]. Action = [[0.         0.         0.         0.72235894]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 2503 is [True, False, False, False, False, True]
State prediction error at timestep 2503 is 0.012
Current timestep = 2504. State = [[-0.25278988  0.36021468]]. Action = [[ 0.          0.          0.         -0.02136475]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 2504 is [True, False, False, False, False, True]
State prediction error at timestep 2504 is 0.012
Current timestep = 2505. State = [[-0.25278983  0.36021483]]. Action = [[0.         0.         0.         0.55881953]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 2505 is [True, False, False, False, False, True]
State prediction error at timestep 2505 is 0.012
Current timestep = 2506. State = [[-0.2527898  0.360215 ]]. Action = [[0.         0.         0.         0.94584346]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 2506 is [True, False, False, False, False, True]
State prediction error at timestep 2506 is 0.012
Current timestep = 2507. State = [[-0.25278974  0.36021516]]. Action = [[ 0.         0.         0.        -0.7322469]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 2507 is [True, False, False, False, False, True]
State prediction error at timestep 2507 is 0.012
Current timestep = 2508. State = [[-0.25278968  0.36021534]]. Action = [[0.         0.         0.         0.08922732]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 2508 is [True, False, False, False, False, True]
State prediction error at timestep 2508 is 0.012
Current timestep = 2509. State = [[-0.25278962  0.36021549]]. Action = [[ 0.         0.         0.        -0.5005284]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 2509 is [True, False, False, False, False, True]
State prediction error at timestep 2509 is 0.012
Current timestep = 2510. State = [[-0.25278956  0.36021563]]. Action = [[0.         0.         0.         0.11264396]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 2510 is [True, False, False, False, False, True]
State prediction error at timestep 2510 is 0.012
Current timestep = 2511. State = [[-0.25278953  0.36021578]]. Action = [[ 0.          0.          0.         -0.26627207]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 2511 is [True, False, False, False, False, True]
State prediction error at timestep 2511 is 0.012
Current timestep = 2512. State = [[-0.25278947  0.36021596]]. Action = [[0.        0.        0.        0.6473894]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 2512 is [True, False, False, False, False, True]
State prediction error at timestep 2512 is 0.012
Current timestep = 2513. State = [[-0.2527894  0.3602161]]. Action = [[ 0.          0.          0.         -0.27137804]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 2513 is [True, False, False, False, False, True]
State prediction error at timestep 2513 is 0.012
Current timestep = 2514. State = [[-0.25278935  0.36021626]]. Action = [[ 0.          0.          0.         -0.65067637]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 2514 is [True, False, False, False, False, True]
State prediction error at timestep 2514 is 0.012
Current timestep = 2515. State = [[-0.25278932  0.3602164 ]]. Action = [[ 0.          0.          0.         -0.90296096]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 2515 is [True, False, False, False, False, True]
State prediction error at timestep 2515 is 0.012
Current timestep = 2516. State = [[-0.25278926  0.36021656]]. Action = [[0.         0.         0.         0.26077783]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 2516 is [True, False, False, False, False, True]
State prediction error at timestep 2516 is 0.012
Current timestep = 2517. State = [[-0.25278923  0.36021674]]. Action = [[0.         0.         0.         0.00019622]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 2517 is [True, False, False, False, False, True]
State prediction error at timestep 2517 is 0.012
Current timestep = 2518. State = [[-0.25278917  0.3602169 ]]. Action = [[ 0.         0.         0.        -0.6565775]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 2518 is [True, False, False, False, False, True]
State prediction error at timestep 2518 is 0.012
Current timestep = 2519. State = [[-0.2527891   0.36021703]]. Action = [[0.        0.        0.        0.9515178]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 2519 is [True, False, False, False, False, True]
State prediction error at timestep 2519 is 0.012
Current timestep = 2520. State = [[-0.25278908  0.36021718]]. Action = [[ 0.         0.         0.        -0.6092942]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 2520 is [True, False, False, False, False, True]
State prediction error at timestep 2520 is 0.012
Current timestep = 2521. State = [[-0.25278902  0.36021733]]. Action = [[ 0.         0.         0.        -0.6941138]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 2521 is [True, False, False, False, False, True]
State prediction error at timestep 2521 is 0.012
Current timestep = 2522. State = [[-0.252789    0.36021748]]. Action = [[ 0.         0.         0.        -0.2172162]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 2522 is [True, False, False, False, False, True]
State prediction error at timestep 2522 is 0.012
Current timestep = 2523. State = [[-0.25278893  0.36021763]]. Action = [[ 0.          0.          0.         -0.03076357]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 2523 is [True, False, False, False, False, True]
State prediction error at timestep 2523 is 0.012
Current timestep = 2524. State = [[-0.2527889   0.36021775]]. Action = [[0.         0.         0.         0.37601972]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 2524 is [True, False, False, False, False, True]
State prediction error at timestep 2524 is 0.012
Current timestep = 2525. State = [[-0.25278884  0.3602179 ]]. Action = [[0.        0.        0.        0.6577717]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 2525 is [True, False, False, False, False, True]
State prediction error at timestep 2525 is 0.012
Current timestep = 2526. State = [[-0.2527888   0.36021805]]. Action = [[0.         0.         0.         0.19644606]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 2526 is [True, False, False, False, False, True]
State prediction error at timestep 2526 is 0.012
Current timestep = 2527. State = [[-0.25278878  0.3602182 ]]. Action = [[0.         0.         0.         0.40642428]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 2527 is [True, False, False, False, False, True]
State prediction error at timestep 2527 is 0.012
Current timestep = 2528. State = [[-0.25278872  0.36021835]]. Action = [[0.         0.         0.         0.15026045]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 2528 is [True, False, False, False, False, True]
State prediction error at timestep 2528 is 0.012
Current timestep = 2529. State = [[-0.2527887  0.3602185]]. Action = [[ 0.          0.          0.         -0.02858669]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 2529 is [True, False, False, False, False, True]
State prediction error at timestep 2529 is 0.012
Current timestep = 2530. State = [[-0.25278866  0.3602186 ]]. Action = [[0.         0.         0.         0.03777456]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 2530 is [True, False, False, False, False, True]
State prediction error at timestep 2530 is 0.012
Current timestep = 2531. State = [[-0.2527886   0.36021876]]. Action = [[ 0.         0.         0.        -0.4335091]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 2531 is [True, False, False, False, False, True]
State prediction error at timestep 2531 is 0.012
Current timestep = 2532. State = [[-0.25278857  0.3602189 ]]. Action = [[0.        0.        0.        0.7084638]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 2532 is [True, False, False, False, False, True]
State prediction error at timestep 2532 is 0.012
Current timestep = 2533. State = [[-0.25278854  0.36021906]]. Action = [[ 0.         0.         0.        -0.5575656]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 2533 is [True, False, False, False, False, True]
State prediction error at timestep 2533 is 0.012
Current timestep = 2534. State = [[-0.25278848  0.36021918]]. Action = [[ 0.         0.         0.        -0.7527542]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 2534 is [True, False, False, False, False, True]
State prediction error at timestep 2534 is 0.012
Current timestep = 2535. State = [[-0.25278845  0.36021933]]. Action = [[ 0.        0.        0.       -0.802934]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 2535 is [True, False, False, False, False, True]
State prediction error at timestep 2535 is 0.012
Current timestep = 2536. State = [[-0.25278842  0.36021948]]. Action = [[0.        0.        0.        0.6036782]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 2536 is [True, False, False, False, False, True]
State prediction error at timestep 2536 is 0.012
Current timestep = 2537. State = [[-0.2527884  0.3602196]]. Action = [[0.        0.        0.        0.7198541]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 2537 is [True, False, False, False, False, True]
State prediction error at timestep 2537 is 0.012
Current timestep = 2538. State = [[-0.25278836  0.36021975]]. Action = [[ 0.         0.         0.        -0.9550939]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 2538 is [True, False, False, False, False, True]
State prediction error at timestep 2538 is 0.012
Current timestep = 2539. State = [[-0.2527883   0.36021987]]. Action = [[ 0.        0.        0.       -0.915445]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 2539 is [True, False, False, False, False, True]
State prediction error at timestep 2539 is 0.012
Current timestep = 2540. State = [[-0.25278828  0.36022002]]. Action = [[0.       0.       0.       0.435076]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 2540 is [True, False, False, False, False, True]
State prediction error at timestep 2540 is 0.012
Current timestep = 2541. State = [[-0.25278825  0.36022013]]. Action = [[ 0.000000e+00  0.000000e+00  0.000000e+00 -8.934736e-05]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 2541 is [True, False, False, False, False, True]
State prediction error at timestep 2541 is 0.012
Current timestep = 2542. State = [[-0.25278822  0.36022028]]. Action = [[ 0.          0.          0.         -0.15835506]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 2542 is [True, False, False, False, False, True]
State prediction error at timestep 2542 is 0.012
Current timestep = 2543. State = [[-0.2527882  0.3602204]]. Action = [[ 0.         0.         0.        -0.6326416]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 2543 is [True, False, False, False, False, True]
State prediction error at timestep 2543 is 0.012
Current timestep = 2544. State = [[-0.25278816  0.36022055]]. Action = [[ 0.          0.          0.         -0.79091513]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 2544 is [True, False, False, False, False, True]
State prediction error at timestep 2544 is 0.012
Current timestep = 2545. State = [[-0.25278813  0.36022067]]. Action = [[ 0.         0.         0.        -0.6379385]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 2545 is [True, False, False, False, False, True]
State prediction error at timestep 2545 is 0.012
Current timestep = 2546. State = [[-0.2527881   0.36022082]]. Action = [[ 0.          0.          0.         -0.56745934]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 2546 is [True, False, False, False, False, True]
State prediction error at timestep 2546 is 0.012
Current timestep = 2547. State = [[-0.25278807  0.36022094]]. Action = [[ 0.         0.         0.        -0.9918813]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 2547 is [True, False, False, False, False, True]
State prediction error at timestep 2547 is 0.012
Current timestep = 2548. State = [[-0.25278804  0.36022106]]. Action = [[0.        0.        0.        0.5664115]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 2548 is [True, False, False, False, False, True]
State prediction error at timestep 2548 is 0.012
Current timestep = 2549. State = [[-0.252788   0.3602212]]. Action = [[ 0.         0.         0.        -0.7973538]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 2549 is [True, False, False, False, False, True]
State prediction error at timestep 2549 is 0.012
Current timestep = 2550. State = [[-0.25278798  0.36022133]]. Action = [[0.         0.         0.         0.03378201]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 2550 is [True, False, False, False, False, True]
State prediction error at timestep 2550 is 0.012
Current timestep = 2551. State = [[-0.25278795  0.36022145]]. Action = [[ 0.          0.          0.         -0.07224518]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 2551 is [True, False, False, False, False, True]
State prediction error at timestep 2551 is 0.012
Current timestep = 2552. State = [[-0.25278792  0.36022156]]. Action = [[ 0.         0.         0.        -0.6918456]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 2552 is [True, False, False, False, False, True]
State prediction error at timestep 2552 is 0.012
Current timestep = 2553. State = [[-0.2527879  0.3602217]]. Action = [[0.         0.         0.         0.53416157]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 2553 is [True, False, False, False, False, True]
State prediction error at timestep 2553 is 0.012
Current timestep = 2554. State = [[-0.25278786  0.36022183]]. Action = [[0.        0.        0.        0.6995411]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 2554 is [True, False, False, False, False, True]
State prediction error at timestep 2554 is 0.012
Current timestep = 2555. State = [[-0.25278783  0.36022195]]. Action = [[0.         0.         0.         0.75725126]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 2555 is [True, False, False, False, False, True]
State prediction error at timestep 2555 is 0.012
Current timestep = 2556. State = [[-0.2527878   0.36022207]]. Action = [[0.         0.         0.         0.97829413]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 2556 is [True, False, False, False, False, True]
State prediction error at timestep 2556 is 0.012
Current timestep = 2557. State = [[-0.2527878   0.36022222]]. Action = [[ 0.         0.         0.        -0.5595941]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 2557 is [True, False, False, False, False, True]
State prediction error at timestep 2557 is 0.012
Current timestep = 2558. State = [[-0.25278777  0.36022234]]. Action = [[ 0.          0.          0.         -0.51650596]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 2558 is [True, False, False, False, False, True]
State prediction error at timestep 2558 is 0.012
Current timestep = 2559. State = [[-0.25278774  0.36022246]]. Action = [[0.         0.         0.         0.28436637]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 2559 is [True, False, False, False, False, True]
State prediction error at timestep 2559 is 0.012
Current timestep = 2560. State = [[-0.2527877   0.36022258]]. Action = [[ 0.          0.          0.         -0.60807735]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 2560 is [True, False, False, False, False, True]
State prediction error at timestep 2560 is 0.012
Current timestep = 2561. State = [[-0.25278768  0.3602227 ]]. Action = [[0.        0.        0.        0.5240011]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 2561 is [True, False, False, False, False, True]
State prediction error at timestep 2561 is 0.012
Current timestep = 2562. State = [[-0.25278768  0.36022282]]. Action = [[ 0.         0.         0.        -0.9671297]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 2562 is [True, False, False, False, False, True]
State prediction error at timestep 2562 is 0.012
Current timestep = 2563. State = [[-0.25278765  0.36022294]]. Action = [[ 0.          0.          0.         -0.39905018]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 2563 is [True, False, False, False, False, True]
State prediction error at timestep 2563 is 0.012
Current timestep = 2564. State = [[-0.25278762  0.36022305]]. Action = [[ 0.         0.         0.        -0.7971611]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 2564 is [True, False, False, False, False, True]
State prediction error at timestep 2564 is 0.012
Current timestep = 2565. State = [[-0.2527876   0.36022317]]. Action = [[ 0.        0.        0.       -0.657499]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 2565 is [True, False, False, False, False, True]
State prediction error at timestep 2565 is 0.012
Current timestep = 2566. State = [[-0.2527876  0.3602233]]. Action = [[ 0.         0.         0.        -0.5861041]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 2566 is [True, False, False, False, False, True]
State prediction error at timestep 2566 is 0.012
Current timestep = 2567. State = [[-0.25278756  0.3602234 ]]. Action = [[0.        0.        0.        0.7787981]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 2567 is [True, False, False, False, False, True]
State prediction error at timestep 2567 is 0.012
Current timestep = 2568. State = [[-0.25278753  0.36022353]]. Action = [[0.         0.         0.         0.02482343]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 2568 is [True, False, False, False, False, True]
State prediction error at timestep 2568 is 0.012
Current timestep = 2569. State = [[-0.25278753  0.36022365]]. Action = [[ 0.          0.          0.         -0.44352007]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 2569 is [True, False, False, False, False, True]
State prediction error at timestep 2569 is 0.012
Current timestep = 2570. State = [[-0.2527875   0.36022377]]. Action = [[0.        0.        0.        0.8275516]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 2570 is [True, False, False, False, False, True]
State prediction error at timestep 2570 is 0.012
Current timestep = 2571. State = [[-0.25278747  0.3602239 ]]. Action = [[0.         0.         0.         0.84840536]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 2571 is [True, False, False, False, False, True]
State prediction error at timestep 2571 is 0.012
Current timestep = 2572. State = [[-0.25278747  0.360224  ]]. Action = [[ 0.          0.          0.         -0.99972737]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 2572 is [True, False, False, False, False, True]
State prediction error at timestep 2572 is 0.012
Current timestep = 2573. State = [[-0.25278744  0.36022413]]. Action = [[ 0.          0.          0.         -0.73716635]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 2573 is [True, False, False, False, False, True]
State prediction error at timestep 2573 is 0.012
Current timestep = 2574. State = [[-0.25278744  0.36022425]]. Action = [[0.         0.         0.         0.85959077]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 2574 is [True, False, False, False, False, True]
State prediction error at timestep 2574 is 0.012
Current timestep = 2575. State = [[-0.2527874   0.36022434]]. Action = [[0.       0.       0.       0.459795]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 2575 is [True, False, False, False, False, True]
State prediction error at timestep 2575 is 0.012
Current timestep = 2576. State = [[-0.25278738  0.36022446]]. Action = [[0.         0.         0.         0.77468705]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 2576 is [True, False, False, False, False, True]
State prediction error at timestep 2576 is 0.012
Current timestep = 2577. State = [[-0.25278738  0.36022457]]. Action = [[ 0.         0.         0.        -0.8999358]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 2577 is [True, False, False, False, False, True]
State prediction error at timestep 2577 is 0.012
Current timestep = 2578. State = [[-0.25278735  0.3602247 ]]. Action = [[ 0.         0.         0.        -0.8047031]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 2578 is [True, False, False, False, False, True]
State prediction error at timestep 2578 is 0.012
Current timestep = 2579. State = [[-0.25278735  0.3602248 ]]. Action = [[0.       0.       0.       0.867067]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 2579 is [True, False, False, False, False, True]
State prediction error at timestep 2579 is 0.012
Current timestep = 2580. State = [[-0.25278732  0.3602249 ]]. Action = [[ 0.          0.          0.         -0.05585432]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 2580 is [True, False, False, False, False, True]
State prediction error at timestep 2580 is 0.012
Current timestep = 2581. State = [[-0.25278732  0.36022502]]. Action = [[ 0.          0.          0.         -0.07857317]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 2581 is [True, False, False, False, False, True]
State prediction error at timestep 2581 is 0.012
Current timestep = 2582. State = [[-0.2527873   0.36022514]]. Action = [[0.         0.         0.         0.85501313]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 2582 is [True, False, False, False, False, True]
State prediction error at timestep 2582 is 0.012
Current timestep = 2583. State = [[-0.2527873   0.36022526]]. Action = [[ 0.         0.         0.        -0.8750507]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 2583 is [True, False, False, False, False, True]
State prediction error at timestep 2583 is 0.012
Current timestep = 2584. State = [[-0.25278726  0.36022535]]. Action = [[ 0.         0.         0.        -0.0878284]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 2584 is [True, False, False, False, False, True]
State prediction error at timestep 2584 is 0.012
Current timestep = 2585. State = [[-0.25278726  0.36022547]]. Action = [[0.         0.         0.         0.34365392]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 2585 is [True, False, False, False, False, True]
State prediction error at timestep 2585 is 0.012
Current timestep = 2586. State = [[-0.25278723  0.3602256 ]]. Action = [[0.        0.        0.        0.7800448]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 2586 is [True, False, False, False, False, True]
State prediction error at timestep 2586 is 0.012
Current timestep = 2587. State = [[-0.25278723  0.36022568]]. Action = [[ 0.          0.          0.         -0.97149146]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 2587 is [True, False, False, False, False, True]
State prediction error at timestep 2587 is 0.012
Current timestep = 2588. State = [[-0.25278723  0.3602258 ]]. Action = [[0.        0.        0.        0.7661772]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 2588 is [True, False, False, False, False, True]
State prediction error at timestep 2588 is 0.012
Current timestep = 2589. State = [[-0.2527872   0.36022592]]. Action = [[0.        0.        0.        0.6900823]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 2589 is [True, False, False, False, False, True]
State prediction error at timestep 2589 is 0.012
Current timestep = 2590. State = [[-0.2527872  0.360226 ]]. Action = [[0.         0.         0.         0.72432876]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 2590 is [True, False, False, False, False, True]
State prediction error at timestep 2590 is 0.012
Current timestep = 2591. State = [[-0.25278717  0.36022612]]. Action = [[0.         0.         0.         0.25117922]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 2591 is [True, False, False, False, False, True]
State prediction error at timestep 2591 is 0.012
Current timestep = 2592. State = [[-0.25278717  0.3602262 ]]. Action = [[ 0.         0.         0.        -0.8848199]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 2592 is [True, False, False, False, False, True]
State prediction error at timestep 2592 is 0.012
Current timestep = 2593. State = [[-0.25278717  0.36022633]]. Action = [[ 0.         0.         0.        -0.3386742]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 2593 is [True, False, False, False, False, True]
State prediction error at timestep 2593 is 0.012
Current timestep = 2594. State = [[-0.25278714  0.36022645]]. Action = [[0.         0.         0.         0.41449797]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 2594 is [True, False, False, False, False, True]
State prediction error at timestep 2594 is 0.012
Current timestep = 2595. State = [[-0.25278714  0.36022654]]. Action = [[ 0.         0.         0.        -0.7950017]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 2595 is [True, False, False, False, False, True]
State prediction error at timestep 2595 is 0.012
Current timestep = 2596. State = [[-0.25278714  0.36022666]]. Action = [[0.        0.        0.        0.6627672]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 2596 is [True, False, False, False, False, True]
State prediction error at timestep 2596 is 0.012
Current timestep = 2597. State = [[-0.2527871   0.36022675]]. Action = [[0.        0.        0.        0.1107111]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 2597 is [True, False, False, False, False, True]
State prediction error at timestep 2597 is 0.012
Current timestep = 2598. State = [[-0.2527871   0.36022687]]. Action = [[0.         0.         0.         0.15228307]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 2598 is [True, False, False, False, False, True]
State prediction error at timestep 2598 is 0.012
Current timestep = 2599. State = [[-0.2527871   0.36022696]]. Action = [[0.        0.        0.        0.9462832]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 2599 is [True, False, False, False, False, True]
State prediction error at timestep 2599 is 0.012
Current timestep = 2600. State = [[-0.2527871   0.36022708]]. Action = [[ 0.          0.          0.         -0.37767065]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 2600 is [True, False, False, False, False, True]
State prediction error at timestep 2600 is 0.012
Current timestep = 2601. State = [[-0.25278708  0.36022717]]. Action = [[0.       0.       0.       0.268713]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 2601 is [True, False, False, False, False, True]
State prediction error at timestep 2601 is 0.012
Current timestep = 2602. State = [[-0.25278708  0.36022726]]. Action = [[0.         0.         0.         0.30444694]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 2602 is [True, False, False, False, False, True]
State prediction error at timestep 2602 is 0.012
Current timestep = 2603. State = [[-0.25278708  0.36022738]]. Action = [[ 0.         0.         0.        -0.9674787]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 2603 is [True, False, False, False, False, True]
State prediction error at timestep 2603 is 0.012
Current timestep = 2604. State = [[-0.25278708  0.36022747]]. Action = [[0.         0.         0.         0.43475735]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 2604 is [True, False, False, False, False, True]
State prediction error at timestep 2604 is 0.012
Current timestep = 2605. State = [[-0.25278705  0.36022758]]. Action = [[ 0.          0.          0.         -0.13779122]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 2605 is [True, False, False, False, False, True]
State prediction error at timestep 2605 is 0.012
Current timestep = 2606. State = [[-0.25278705  0.36022767]]. Action = [[ 0.          0.          0.         -0.10884106]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 2606 is [True, False, False, False, False, True]
State prediction error at timestep 2606 is 0.012
Current timestep = 2607. State = [[-0.25278705  0.36022776]]. Action = [[ 0.          0.          0.         -0.41356897]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 2607 is [True, False, False, False, False, True]
State prediction error at timestep 2607 is 0.012
Current timestep = 2608. State = [[-0.25278705  0.36022788]]. Action = [[0.         0.         0.         0.73309517]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 2608 is [True, False, False, False, False, True]
State prediction error at timestep 2608 is 0.012
Current timestep = 2609. State = [[-0.25278705  0.36022797]]. Action = [[0.        0.        0.        0.4541328]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 2609 is [True, False, False, False, False, True]
State prediction error at timestep 2609 is 0.012
Current timestep = 2610. State = [[-0.25278702  0.36022806]]. Action = [[0.        0.        0.        0.7684703]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 2610 is [True, False, False, False, False, True]
State prediction error at timestep 2610 is 0.012
Current timestep = 2611. State = [[-0.25278702  0.36022818]]. Action = [[0.        0.        0.        0.7693281]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 2611 is [True, False, False, False, False, True]
State prediction error at timestep 2611 is 0.012
Current timestep = 2612. State = [[-0.25278702  0.36022827]]. Action = [[0.         0.         0.         0.06071043]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 2612 is [True, False, False, False, False, True]
State prediction error at timestep 2612 is 0.012
Current timestep = 2613. State = [[-0.25278702  0.36022836]]. Action = [[0.         0.         0.         0.90855813]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 2613 is [True, False, False, False, False, True]
State prediction error at timestep 2613 is 0.012
Current timestep = 2614. State = [[-0.25278702  0.36022848]]. Action = [[ 0.          0.          0.         -0.12485981]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 2614 is [True, False, False, False, False, True]
State prediction error at timestep 2614 is 0.012
Current timestep = 2615. State = [[-0.25278702  0.36022857]]. Action = [[0.         0.         0.         0.26100945]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 2615 is [True, False, False, False, False, True]
State prediction error at timestep 2615 is 0.012
Current timestep = 2616. State = [[-0.25278702  0.36022866]]. Action = [[ 0.          0.          0.         -0.26843584]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 2616 is [True, False, False, False, False, True]
State prediction error at timestep 2616 is 0.012
Current timestep = 2617. State = [[-0.252787    0.36022875]]. Action = [[0.         0.         0.         0.68371224]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 2617 is [True, False, False, False, False, True]
State prediction error at timestep 2617 is 0.012
Current timestep = 2618. State = [[-0.252787    0.36022887]]. Action = [[ 0.          0.          0.         -0.22385496]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 2618 is [True, False, False, False, False, True]
State prediction error at timestep 2618 is 0.012
Current timestep = 2619. State = [[-0.252787    0.36022896]]. Action = [[ 0.         0.         0.        -0.1860627]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 2619 is [True, False, False, False, False, True]
State prediction error at timestep 2619 is 0.012
Current timestep = 2620. State = [[-0.252787    0.36022905]]. Action = [[0.         0.         0.         0.91513085]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 2620 is [True, False, False, False, False, True]
State prediction error at timestep 2620 is 0.012
Current timestep = 2621. State = [[-0.252787    0.36022913]]. Action = [[ 0.          0.          0.         -0.65554297]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 2621 is [True, False, False, False, False, True]
State prediction error at timestep 2621 is 0.012
Current timestep = 2622. State = [[-0.252787    0.36022925]]. Action = [[0.         0.         0.         0.10221803]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 2622 is [True, False, False, False, False, True]
State prediction error at timestep 2622 is 0.012
Current timestep = 2623. State = [[-0.252787    0.36022934]]. Action = [[ 0.          0.          0.         -0.00683254]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 2623 is [True, False, False, False, False, True]
State prediction error at timestep 2623 is 0.012
Current timestep = 2624. State = [[-0.252787    0.36022943]]. Action = [[ 0.          0.          0.         -0.47296858]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 2624 is [True, False, False, False, False, True]
State prediction error at timestep 2624 is 0.012
Current timestep = 2625. State = [[-0.252787    0.36022952]]. Action = [[0.         0.         0.         0.12349665]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 2625 is [True, False, False, False, False, True]
State prediction error at timestep 2625 is 0.012
Current timestep = 2626. State = [[-0.252787   0.3602296]]. Action = [[0.         0.         0.         0.94088364]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 2626 is [True, False, False, False, False, True]
State prediction error at timestep 2626 is 0.012
Current timestep = 2627. State = [[-0.252787   0.3602297]]. Action = [[ 0.          0.          0.         -0.68911844]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 2627 is [True, False, False, False, False, True]
State prediction error at timestep 2627 is 0.012
Current timestep = 2628. State = [[-0.252787   0.3602298]]. Action = [[0.         0.         0.         0.62243915]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 2628 is [True, False, False, False, False, True]
State prediction error at timestep 2628 is 0.012
Current timestep = 2629. State = [[-0.252787   0.3602299]]. Action = [[ 0.          0.          0.         -0.21321326]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 2629 is [True, False, False, False, False, True]
State prediction error at timestep 2629 is 0.012
Current timestep = 2630. State = [[-0.252787  0.36023 ]]. Action = [[ 0.          0.          0.         -0.07420415]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 2630 is [True, False, False, False, False, True]
State prediction error at timestep 2630 is 0.012
Current timestep = 2631. State = [[-0.252787   0.3602301]]. Action = [[0.         0.         0.         0.65735245]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 2631 is [True, False, False, False, False, True]
State prediction error at timestep 2631 is 0.012
Current timestep = 2632. State = [[-0.252787    0.36023018]]. Action = [[0.         0.         0.         0.34012926]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 2632 is [True, False, False, False, False, True]
State prediction error at timestep 2632 is 0.012
Current timestep = 2633. State = [[-0.252787    0.36023027]]. Action = [[0.         0.         0.         0.28261745]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 2633 is [True, False, False, False, False, True]
State prediction error at timestep 2633 is 0.012
Current timestep = 2634. State = [[-0.252787    0.36023036]]. Action = [[0.         0.         0.         0.80982256]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 2634 is [True, False, False, False, False, True]
State prediction error at timestep 2634 is 0.012
Current timestep = 2635. State = [[-0.252787    0.36023045]]. Action = [[0.        0.        0.        0.3760054]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 2635 is [True, False, False, False, False, True]
State prediction error at timestep 2635 is 0.012
Current timestep = 2636. State = [[-0.252787    0.36023054]]. Action = [[ 0.          0.          0.         -0.24417591]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 2636 is [True, False, False, False, False, True]
State prediction error at timestep 2636 is 0.012
Current timestep = 2637. State = [[-0.252787    0.36023062]]. Action = [[ 0.          0.          0.         -0.06922531]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 2637 is [True, False, False, False, False, True]
State prediction error at timestep 2637 is 0.012
Current timestep = 2638. State = [[-0.252787   0.3602307]]. Action = [[0.         0.         0.         0.06523848]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 2638 is [True, False, False, False, False, True]
State prediction error at timestep 2638 is 0.012
Current timestep = 2639. State = [[-0.252787   0.3602308]]. Action = [[0.         0.         0.         0.66792893]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 2639 is [True, False, False, False, False, True]
State prediction error at timestep 2639 is 0.012
Current timestep = 2640. State = [[-0.252787   0.3602309]]. Action = [[0.         0.         0.         0.05681074]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 2640 is [True, False, False, False, False, True]
State prediction error at timestep 2640 is 0.012
Current timestep = 2641. State = [[-0.25278702  0.36023098]]. Action = [[ 0.          0.          0.         -0.61440694]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 2641 is [True, False, False, False, False, True]
State prediction error at timestep 2641 is 0.012
Current timestep = 2642. State = [[-0.25278702  0.36023107]]. Action = [[ 0.          0.          0.         -0.17053127]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 2642 is [True, False, False, False, False, True]
State prediction error at timestep 2642 is 0.012
Current timestep = 2643. State = [[-0.25278702  0.36023116]]. Action = [[0.         0.         0.         0.12731218]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 2643 is [True, False, False, False, False, True]
State prediction error at timestep 2643 is 0.012
Current timestep = 2644. State = [[-0.25278702  0.36023125]]. Action = [[0.        0.        0.        0.7677164]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 2644 is [True, False, False, False, False, True]
State prediction error at timestep 2644 is 0.012
Current timestep = 2645. State = [[-0.25278702  0.36023134]]. Action = [[ 0.         0.         0.        -0.5150837]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 2645 is [True, False, False, False, False, True]
State prediction error at timestep 2645 is 0.012
Current timestep = 2646. State = [[-0.25278702  0.36023143]]. Action = [[ 0.          0.          0.         -0.82983935]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 2646 is [True, False, False, False, False, True]
State prediction error at timestep 2646 is 0.012
Current timestep = 2647. State = [[-0.25278702  0.36023152]]. Action = [[0.         0.         0.         0.34248316]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 2647 is [True, False, False, False, False, True]
State prediction error at timestep 2647 is 0.012
Current timestep = 2648. State = [[-0.25278702  0.3602316 ]]. Action = [[ 0.         0.         0.        -0.5800099]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 2648 is [True, False, False, False, False, True]
State prediction error at timestep 2648 is 0.012
Current timestep = 2649. State = [[-0.25278705  0.3602317 ]]. Action = [[ 0.          0.          0.         -0.66368353]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 2649 is [True, False, False, False, False, True]
State prediction error at timestep 2649 is 0.012
Current timestep = 2650. State = [[-0.25278705  0.3602318 ]]. Action = [[ 0.         0.         0.        -0.4256171]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 2650 is [True, False, False, False, False, True]
State prediction error at timestep 2650 is 0.012
Current timestep = 2651. State = [[-0.25278705  0.36023188]]. Action = [[0.        0.        0.        0.8003371]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 2651 is [True, False, False, False, False, True]
State prediction error at timestep 2651 is 0.012
Current timestep = 2652. State = [[-0.25278705  0.36023194]]. Action = [[0.        0.        0.        0.5887494]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 2652 is [True, False, False, False, False, True]
State prediction error at timestep 2652 is 0.012
Current timestep = 2653. State = [[-0.25278705  0.36023203]]. Action = [[0.         0.         0.         0.65414584]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 2653 is [True, False, False, False, False, True]
State prediction error at timestep 2653 is 0.012
Current timestep = 2654. State = [[-0.25278705  0.3602321 ]]. Action = [[ 0.          0.          0.         -0.80800843]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 2654 is [True, False, False, False, False, True]
State prediction error at timestep 2654 is 0.012
Current timestep = 2655. State = [[-0.25278708  0.3602322 ]]. Action = [[ 0.          0.          0.         -0.38134873]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 2655 is [True, False, False, False, False, True]
State prediction error at timestep 2655 is 0.012
Current timestep = 2656. State = [[-0.25278708  0.3602323 ]]. Action = [[0.         0.         0.         0.18052149]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 2656 is [True, False, False, False, False, True]
State prediction error at timestep 2656 is 0.012
Current timestep = 2657. State = [[-0.25278708  0.36023238]]. Action = [[0.         0.         0.         0.47679985]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 2657 is [True, False, False, False, False, True]
State prediction error at timestep 2657 is 0.012
Current timestep = 2658. State = [[-0.25278708  0.36023247]]. Action = [[ 0.          0.          0.         -0.30824643]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 2658 is [True, False, False, False, False, True]
State prediction error at timestep 2658 is 0.012
Current timestep = 2659. State = [[-0.2527871   0.36023253]]. Action = [[ 0.          0.          0.         -0.71907306]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 2659 is [True, False, False, False, False, True]
State prediction error at timestep 2659 is 0.012
Current timestep = 2660. State = [[-0.2527871   0.36023262]]. Action = [[0.        0.        0.        0.8243017]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 2660 is [True, False, False, False, False, True]
State prediction error at timestep 2660 is 0.012
Current timestep = 2661. State = [[-0.2527871  0.3602327]]. Action = [[ 0.          0.          0.         -0.42757303]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 2661 is [True, False, False, False, False, True]
State prediction error at timestep 2661 is 0.012
Current timestep = 2662. State = [[-0.2527871  0.3602328]]. Action = [[0.         0.         0.         0.87010264]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 2662 is [True, False, False, False, False, True]
State prediction error at timestep 2662 is 0.012
Current timestep = 2663. State = [[-0.2527871  0.3602329]]. Action = [[0.         0.         0.         0.79797506]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 2663 is [True, False, False, False, False, True]
State prediction error at timestep 2663 is 0.012
Current timestep = 2664. State = [[-0.25278714  0.36023295]]. Action = [[ 0.         0.         0.        -0.7418033]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 2664 is [True, False, False, False, False, True]
State prediction error at timestep 2664 is 0.012
Current timestep = 2665. State = [[-0.25278714  0.36023304]]. Action = [[ 0.          0.          0.         -0.12293863]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 2665 is [True, False, False, False, False, True]
State prediction error at timestep 2665 is 0.012
Current timestep = 2666. State = [[-0.25278714  0.36023313]]. Action = [[0.         0.         0.         0.44548154]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 2666 is [True, False, False, False, False, True]
State prediction error at timestep 2666 is 0.012
Current timestep = 2667. State = [[-0.25278717  0.36023322]]. Action = [[ 0.          0.          0.         -0.79280114]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 2667 is [True, False, False, False, False, True]
State prediction error at timestep 2667 is 0.012
Current timestep = 2668. State = [[-0.25278717  0.3602333 ]]. Action = [[0.        0.        0.        0.2848308]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 2668 is [True, False, False, False, False, True]
State prediction error at timestep 2668 is 0.012
Current timestep = 2669. State = [[-0.25278717  0.36023337]]. Action = [[0.        0.        0.        0.9223201]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 2669 is [True, False, False, False, False, True]
State prediction error at timestep 2669 is 0.012
Current timestep = 2670. State = [[-0.25278717  0.36023346]]. Action = [[ 0.          0.          0.         -0.09119451]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 2670 is [True, False, False, False, False, True]
State prediction error at timestep 2670 is 0.012
Current timestep = 2671. State = [[-0.2527872   0.36023355]]. Action = [[0.         0.         0.         0.28771257]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 2671 is [True, False, False, False, False, True]
State prediction error at timestep 2671 is 0.012
Current timestep = 2672. State = [[-0.2527872   0.36023363]]. Action = [[0.       0.       0.       0.598976]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 2672 is [True, False, False, False, False, True]
State prediction error at timestep 2672 is 0.012
Current timestep = 2673. State = [[-0.2527872  0.3602337]]. Action = [[ 0.         0.         0.        -0.5013866]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 2673 is [True, False, False, False, False, True]
State prediction error at timestep 2673 is 0.012
Current timestep = 2674. State = [[-0.25278723  0.36023378]]. Action = [[ 0.          0.          0.         -0.05578923]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 2674 is [True, False, False, False, False, True]
State prediction error at timestep 2674 is 0.012
Current timestep = 2675. State = [[-0.25278723  0.36023387]]. Action = [[0.         0.         0.         0.06199205]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 2675 is [True, False, False, False, False, True]
State prediction error at timestep 2675 is 0.012
Current timestep = 2676. State = [[-0.25278723  0.36023393]]. Action = [[ 0.         0.         0.        -0.6067143]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 2676 is [True, False, False, False, False, True]
State prediction error at timestep 2676 is 0.012
Current timestep = 2677. State = [[-0.25278726  0.36023402]]. Action = [[0.        0.        0.        0.9811382]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 2677 is [True, False, False, False, False, True]
State prediction error at timestep 2677 is 0.012
Current timestep = 2678. State = [[-0.25278726  0.3602341 ]]. Action = [[ 0.          0.          0.         -0.57310766]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 2678 is [True, False, False, False, False, True]
State prediction error at timestep 2678 is 0.012
Current timestep = 2679. State = [[-0.25278726  0.36023417]]. Action = [[0.         0.         0.         0.35741305]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 2679 is [True, False, False, False, False, True]
State prediction error at timestep 2679 is 0.012
Current timestep = 2680. State = [[-0.2527873   0.36023426]]. Action = [[ 0.         0.         0.        -0.3678316]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 2680 is [True, False, False, False, False, True]
State prediction error at timestep 2680 is 0.012
Current timestep = 2681. State = [[-0.2527873   0.36023435]]. Action = [[0.       0.       0.       0.276438]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 2681 is [True, False, False, False, False, True]
State prediction error at timestep 2681 is 0.012
Current timestep = 2682. State = [[-0.2527873  0.3602344]]. Action = [[0.         0.         0.         0.96364665]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 2682 is [True, False, False, False, False, True]
State prediction error at timestep 2682 is 0.012
Current timestep = 2683. State = [[-0.25278732  0.3602345 ]]. Action = [[ 0.         0.         0.        -0.8542386]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 2683 is [True, False, False, False, False, True]
State prediction error at timestep 2683 is 0.012
Current timestep = 2684. State = [[-0.25278732  0.3602346 ]]. Action = [[0.       0.       0.       0.540535]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 2684 is [True, False, False, False, False, True]
State prediction error at timestep 2684 is 0.012
Current timestep = 2685. State = [[-0.25278732  0.36023465]]. Action = [[0.         0.         0.         0.13374424]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 2685 is [True, False, False, False, False, True]
State prediction error at timestep 2685 is 0.012
Current timestep = 2686. State = [[-0.25278735  0.36023474]]. Action = [[ 0.         0.         0.        -0.7955977]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 2686 is [True, False, False, False, False, True]
State prediction error at timestep 2686 is 0.012
Current timestep = 2687. State = [[-0.25278735  0.36023483]]. Action = [[0.        0.        0.        0.4318732]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 2687 is [True, False, False, False, False, True]
State prediction error at timestep 2687 is 0.012
Current timestep = 2688. State = [[-0.25278735  0.3602349 ]]. Action = [[0.         0.         0.         0.21275723]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 2688 is [True, False, False, False, False, True]
State prediction error at timestep 2688 is 0.012
Current timestep = 2689. State = [[-0.25278738  0.36023498]]. Action = [[0.       0.       0.       0.702803]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 2689 is [True, False, False, False, False, True]
State prediction error at timestep 2689 is 0.012
Current timestep = 2690. State = [[-0.25278738  0.36023504]]. Action = [[ 0.         0.         0.        -0.4407581]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 2690 is [True, False, False, False, False, True]
State prediction error at timestep 2690 is 0.012
Current timestep = 2691. State = [[-0.2527874   0.36023512]]. Action = [[ 0.          0.          0.         -0.56361985]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 2691 is [True, False, False, False, False, True]
State prediction error at timestep 2691 is 0.012
Current timestep = 2692. State = [[-0.2527874  0.3602352]]. Action = [[ 0.          0.          0.         -0.35360658]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 2692 is [True, False, False, False, False, True]
State prediction error at timestep 2692 is 0.012
Current timestep = 2693. State = [[-0.2527874   0.36023527]]. Action = [[ 0.         0.         0.        -0.7129658]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 2693 is [True, False, False, False, False, True]
State prediction error at timestep 2693 is 0.012
Current timestep = 2694. State = [[-0.25278744  0.36023536]]. Action = [[0.         0.         0.         0.78860104]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 2694 is [True, False, False, False, False, True]
State prediction error at timestep 2694 is 0.012
Current timestep = 2695. State = [[-0.25278744  0.36023542]]. Action = [[ 0.        0.        0.       -0.810299]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 2695 is [True, False, False, False, False, True]
State prediction error at timestep 2695 is 0.012
Current timestep = 2696. State = [[-0.25278747  0.3602355 ]]. Action = [[0.         0.         0.         0.70144486]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 2696 is [True, False, False, False, False, True]
State prediction error at timestep 2696 is 0.012
Current timestep = 2697. State = [[-0.25278747  0.36023557]]. Action = [[0.         0.         0.         0.63283205]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 2697 is [True, False, False, False, False, True]
State prediction error at timestep 2697 is 0.012
Current timestep = 2698. State = [[-0.2527875   0.36023566]]. Action = [[0.         0.         0.         0.53180194]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 2698 is [True, False, False, False, False, True]
State prediction error at timestep 2698 is 0.012
Current timestep = 2699. State = [[-0.32721138  0.22708629]]. Action = [[ 0.          0.          0.         -0.92509604]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 2699 is [True, False, False, False, False, True]
State prediction error at timestep 2699 is 0.012
Current timestep = 2700. State = [[-0.33298513  0.22575007]]. Action = [[-0.08649355 -0.01063247  0.          0.01087904]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 2700 is [True, False, False, False, False, True]
State prediction error at timestep 2700 is 0.012
Current timestep = 2701. State = [[-0.33240807  0.2257775 ]]. Action = [[0.06374484 0.01398732 0.         0.75572133]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 2701 is [True, False, False, False, False, True]
State prediction error at timestep 2701 is 0.012
Current timestep = 2702. State = [[-0.33282202  0.22409193]]. Action = [[-0.04630033 -0.03339317  0.          0.93778324]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2702 is [True, False, False, False, False, True]
State prediction error at timestep 2702 is 0.012
Current timestep = 2703. State = [[-0.33514774  0.22676374]]. Action = [[-0.02044272  0.07900562  0.         -0.3019727 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 2703 is [True, False, False, False, False, True]
State prediction error at timestep 2703 is 0.012
Current timestep = 2704. State = [[-0.33381516  0.22968093]]. Action = [[0.05802291 0.01748355 0.         0.7820828 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 2704 is [True, False, False, False, False, True]
State prediction error at timestep 2704 is 0.012
Current timestep = 2705. State = [[-0.33672422  0.23291603]]. Action = [[-0.07132298  0.05472117  0.          0.16383386]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 2705 is [True, False, False, False, False, True]
State prediction error at timestep 2705 is 0.012
Current timestep = 2706. State = [[-0.3442449   0.23668052]]. Action = [[-0.08736702  0.03627693  0.         -0.92897356]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 2706 is [True, False, False, False, False, True]
State prediction error at timestep 2706 is 0.012
Current timestep = 2707. State = [[-0.34781814  0.23806965]]. Action = [[ 0.01085661 -0.00709767  0.         -0.6352171 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2707 is [True, False, False, False, False, True]
State prediction error at timestep 2707 is 0.012
Current timestep = 2708. State = [[-0.34968102  0.23715627]]. Action = [[-0.01095378 -0.02526438  0.         -0.679761  ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 2708 is [True, False, False, False, False, True]
State prediction error at timestep 2708 is 0.012
Current timestep = 2709. State = [[-0.34926865  0.2400298 ]]. Action = [[0.0443883  0.0662962  0.         0.41012943]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 2709 is [True, False, False, False, False, True]
State prediction error at timestep 2709 is 0.012
Current timestep = 2710. State = [[-0.3454515   0.24315165]]. Action = [[ 0.08762088  0.02345296  0.         -0.11763901]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 2710 is [True, False, False, False, False, True]
State prediction error at timestep 2710 is 0.012
Current timestep = 2711. State = [[-0.34582683  0.24185883]]. Action = [[-0.0410904  -0.04470474  0.          0.8657315 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 2711 is [True, False, False, False, False, True]
State prediction error at timestep 2711 is 0.012
Current timestep = 2712. State = [[-0.35070765  0.24420376]]. Action = [[-0.05890632  0.06708232  0.          0.62803364]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 2712 is [True, False, False, False, False, True]
State prediction error at timestep 2712 is 0.012
Current timestep = 2713. State = [[-0.3560314  0.2503366]]. Action = [[-0.04619068  0.07561233  0.          0.16204894]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 2713 is [True, False, False, False, False, True]
State prediction error at timestep 2713 is 0.012
Current timestep = 2714. State = [[-0.35917476  0.25218165]]. Action = [[-0.00619543 -0.02345888  0.          0.96322906]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 2714 is [True, False, False, False, False, True]
State prediction error at timestep 2714 is 0.012
Current timestep = 2715. State = [[-0.3558554   0.24875756]]. Action = [[ 0.09357958 -0.06816004  0.          0.056301  ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 2715 is [True, False, False, False, False, True]
State prediction error at timestep 2715 is 0.012
Current timestep = 2716. State = [[-0.35084477  0.24924561]]. Action = [[0.0611015 0.0520793 0.        0.3213141]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 2716 is [True, False, False, False, False, True]
State prediction error at timestep 2716 is 0.012
Current timestep = 2717. State = [[-0.35145196  0.2549245 ]]. Action = [[-0.04003083  0.0851186   0.         -0.588984  ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 2717 is [True, False, False, False, False, True]
State prediction error at timestep 2717 is 0.012
Current timestep = 2718. State = [[-0.3553428   0.25326186]]. Action = [[-0.05466161 -0.09994055  0.          0.82860947]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 2718 is [True, False, False, False, False, True]
State prediction error at timestep 2718 is 0.012
Current timestep = 2719. State = [[-0.36071682  0.25040555]]. Action = [[-0.08511171 -0.01848625  0.         -0.8036489 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 2719 is [True, False, False, False, False, True]
State prediction error at timestep 2719 is 0.012
Current timestep = 2720. State = [[-0.3666861  0.2514296]]. Action = [[-0.07315074  0.01911249  0.         -0.05546844]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 2720 is [True, False, False, False, False, True]
State prediction error at timestep 2720 is 0.012
Current timestep = 2721. State = [[-0.36926708  0.24975453]]. Action = [[-0.0018387  -0.05622892  0.          0.1951487 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 2721 is [True, False, False, False, False, True]
State prediction error at timestep 2721 is 0.012
Current timestep = 2722. State = [[-0.368979   0.2495406]]. Action = [[0.0169505  0.02518994 0.         0.66831446]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 2722 is [True, False, False, False, False, True]
State prediction error at timestep 2722 is 0.012
Current timestep = 2723. State = [[-0.3665336   0.25052506]]. Action = [[ 0.05449351  0.01130066  0.         -0.02923751]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 2723 is [True, False, False, False, False, True]
State prediction error at timestep 2723 is 0.012
Current timestep = 2724. State = [[-0.3699815   0.25235075]]. Action = [[-0.08996402  0.03267353  0.         -0.03341711]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 2724 is [True, False, False, False, False, True]
State prediction error at timestep 2724 is 0.012
Current timestep = 2725. State = [[-0.371666    0.25229174]]. Action = [[ 0.0351439  -0.02107851  0.          0.692173  ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 2725 is [True, False, False, False, False, True]
State prediction error at timestep 2725 is 0.012
Current timestep = 2726. State = [[-0.36843923  0.2471721 ]]. Action = [[ 0.06279782 -0.08462653  0.          0.8399378 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 2726 is [True, False, False, False, False, True]
State prediction error at timestep 2726 is 0.012
Current timestep = 2727. State = [[-0.36511767  0.24453138]]. Action = [[ 0.03573257  0.01184007  0.         -0.481462  ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 2727 is [True, False, False, False, False, True]
State prediction error at timestep 2727 is 0.012
Current timestep = 2728. State = [[-0.3623568   0.24792647]]. Action = [[ 0.03990399  0.08079735  0.         -0.6240837 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 2728 is [True, False, False, False, False, True]
State prediction error at timestep 2728 is 0.012
Current timestep = 2729. State = [[-0.36123317  0.25101545]]. Action = [[ 0.00825392  0.0287485   0.         -0.81028014]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 2729 is [True, False, False, False, False, True]
State prediction error at timestep 2729 is 0.012
Current timestep = 2730. State = [[-0.36029676  0.25254807]]. Action = [[ 0.01884545  0.01956664  0.         -0.123294  ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 2730 is [True, False, False, False, False, True]
State prediction error at timestep 2730 is 0.012
Current timestep = 2731. State = [[-0.35757053  0.2501549 ]]. Action = [[ 0.04345996 -0.0554686   0.         -0.27159083]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 2731 is [True, False, False, False, False, True]
State prediction error at timestep 2731 is 0.012
Current timestep = 2732. State = [[-0.3578881   0.24692859]]. Action = [[-0.04388141 -0.03055923  0.          0.46640635]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 2732 is [True, False, False, False, False, True]
State prediction error at timestep 2732 is 0.012
Current timestep = 2733. State = [[-0.3540178   0.24389006]]. Action = [[ 0.08794599 -0.03835739  0.         -0.771493  ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 2733 is [True, False, False, False, False, True]
State prediction error at timestep 2733 is 0.012
Current timestep = 2734. State = [[-0.3473795   0.23750895]]. Action = [[ 0.06071142 -0.09365758  0.         -0.61388224]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 2734 is [True, False, False, False, False, True]
State prediction error at timestep 2734 is 0.012
Current timestep = 2735. State = [[-0.34577468  0.23184387]]. Action = [[-0.04116434 -0.04479733  0.          0.13192165]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 2735 is [True, False, False, False, False, True]
State prediction error at timestep 2735 is 0.012
Current timestep = 2736. State = [[-0.34286094  0.22681652]]. Action = [[ 0.04327024 -0.05628767  0.          0.83427334]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 2736 is [True, False, False, False, False, True]
State prediction error at timestep 2736 is 0.012
Current timestep = 2737. State = [[-0.3425773   0.22468899]]. Action = [[-0.05289738  0.01298714  0.         -0.8728494 ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 2737 is [True, False, False, False, False, True]
State prediction error at timestep 2737 is 0.012
Current timestep = 2738. State = [[-0.3448653   0.22005989]]. Action = [[-0.04866627 -0.08083374  0.          0.84891343]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 2738 is [True, False, False, False, False, True]
State prediction error at timestep 2738 is 0.012
Current timestep = 2739. State = [[-0.3492936   0.21236983]]. Action = [[-0.09132522 -0.09065353  0.          0.30952   ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 2739 is [True, False, False, False, False, True]
State prediction error at timestep 2739 is 0.012
Current timestep = 2740. State = [[-0.3513455   0.21202949]]. Action = [[-0.00255706  0.0711382   0.         -0.89631915]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 2740 is [True, False, False, False, False, True]
State prediction error at timestep 2740 is 0.012
Current timestep = 2741. State = [[-0.35337323  0.21734375]]. Action = [[-0.03322322  0.08439327  0.         -0.52309   ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 2741 is [True, False, False, False, False, True]
State prediction error at timestep 2741 is 0.012
Current timestep = 2742. State = [[-0.35921472  0.22123164]]. Action = [[-0.07995929  0.03235682  0.          0.3300705 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 2742 is [True, False, False, False, False, True]
State prediction error at timestep 2742 is 0.012
Current timestep = 2743. State = [[-0.35859177  0.21772693]]. Action = [[ 0.08692684 -0.09046286  0.          0.809443  ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 2743 is [True, False, False, False, False, True]
State prediction error at timestep 2743 is 0.012
Current timestep = 2744. State = [[-0.35821372  0.21115318]]. Action = [[-0.02477759 -0.07008799  0.          0.38511384]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 2744 is [True, False, False, False, False, True]
State prediction error at timestep 2744 is 0.012
Current timestep = 2745. State = [[-0.35942867  0.20604695]]. Action = [[-0.00754303 -0.04672647  0.          0.79781616]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 2745 is [True, False, False, False, False, True]
State prediction error at timestep 2745 is 0.012
Current timestep = 2746. State = [[-0.36394373  0.20363961]]. Action = [[-0.0822862  -0.00530951  0.          0.4932841 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 2746 is [True, False, False, False, False, True]
State prediction error at timestep 2746 is 0.012
Current timestep = 2747. State = [[-0.36451602  0.20441812]]. Action = [[0.05233785 0.03425481 0.         0.2912644 ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 2747 is [True, False, False, False, False, True]
State prediction error at timestep 2747 is 0.012
Current timestep = 2748. State = [[-0.36558214  0.20854263]]. Action = [[-0.02918882  0.07527824  0.          0.7836579 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 2748 is [True, False, False, False, False, True]
State prediction error at timestep 2748 is 0.012
Current timestep = 2749. State = [[-0.36513233  0.20666413]]. Action = [[ 0.04527139 -0.07858258  0.         -0.39988542]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 2749 is [True, False, False, False, False, True]
State prediction error at timestep 2749 is 0.012
Current timestep = 2750. State = [[-0.3661154   0.20435452]]. Action = [[-0.03239698  0.00727025  0.          0.9710295 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 2750 is [True, False, False, False, False, True]
State prediction error at timestep 2750 is 0.012
Current timestep = 2751. State = [[-0.36462882  0.20442063]]. Action = [[ 0.06146463  0.00850042  0.         -0.5641043 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 2751 is [True, False, False, False, False, True]
State prediction error at timestep 2751 is 0.012
Current timestep = 2752. State = [[-0.3665294   0.20078123]]. Action = [[-0.06814504 -0.07064238  0.          0.1178894 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 2752 is [True, False, False, False, False, True]
State prediction error at timestep 2752 is 0.012
Current timestep = 2753. State = [[-0.36996126  0.20086485]]. Action = [[-0.02229362  0.05068263  0.          0.27799237]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 2753 is [True, False, False, False, False, True]
State prediction error at timestep 2753 is 0.012
Current timestep = 2754. State = [[-0.37227067  0.19917022]]. Action = [[-0.01628052 -0.05589363  0.         -0.40494668]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 2754 is [True, False, False, False, False, True]
State prediction error at timestep 2754 is 0.012
Current timestep = 2755. State = [[-0.3730024   0.20042746]]. Action = [[0.00988247 0.06372558 0.         0.603421  ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 2755 is [True, False, False, False, False, True]
State prediction error at timestep 2755 is 0.012
Current timestep = 2756. State = [[-0.3724415   0.20616344]]. Action = [[ 0.0314443   0.08288597  0.         -0.64952296]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 2756 is [True, False, False, False, False, True]
State prediction error at timestep 2756 is 0.012
Current timestep = 2757. State = [[-0.37144282  0.20654586]]. Action = [[ 0.02908426 -0.04383078  0.          0.2390753 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 2757 is [True, False, False, False, False, True]
State prediction error at timestep 2757 is 0.012
Current timestep = 2758. State = [[-0.3684404   0.20265801]]. Action = [[ 0.05705773 -0.0537163   0.         -0.03368843]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 2758 is [True, False, False, False, False, True]
State prediction error at timestep 2758 is 0.012
Current timestep = 2759. State = [[-0.37047723  0.20519856]]. Action = [[-0.06915023  0.08818876  0.         -0.82009655]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 2759 is [True, False, False, False, False, True]
State prediction error at timestep 2759 is 0.012
Current timestep = 2760. State = [[-0.37680864  0.20919396]]. Action = [[-0.08180982  0.02359945  0.         -0.68190455]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 2760 is [True, False, False, False, False, True]
State prediction error at timestep 2760 is 0.012
Current timestep = 2761. State = [[-0.38181844  0.20600241]]. Action = [[-0.04642468 -0.09389655  0.         -0.7378843 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 2761 is [True, False, False, False, False, True]
State prediction error at timestep 2761 is 0.012
Current timestep = 2762. State = [[-0.3833955   0.20367616]]. Action = [[ 0.          0.          0.         -0.04620987]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 2762 is [True, False, False, False, False, True]
State prediction error at timestep 2762 is 0.012
Current timestep = 2763. State = [[-0.38383487  0.20367305]]. Action = [[ 0.          0.          0.         -0.36245006]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 2763 is [True, False, False, False, False, True]
State prediction error at timestep 2763 is 0.012
Current timestep = 2764. State = [[-0.3842826   0.20372163]]. Action = [[ 0.         0.         0.        -0.6063938]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 2764 is [True, False, False, False, False, True]
State prediction error at timestep 2764 is 0.012
Current timestep = 2765. State = [[-0.384735    0.20371434]]. Action = [[ 0.          0.          0.         -0.95038116]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 2765 is [True, False, False, False, False, True]
State prediction error at timestep 2765 is 0.012
Current timestep = 2766. State = [[-0.3851662  0.203669 ]]. Action = [[ 0.          0.          0.         -0.87822706]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 2766 is [True, False, False, False, False, True]
State prediction error at timestep 2766 is 0.012
Current timestep = 2767. State = [[-0.38555822  0.20360595]]. Action = [[ 0.         0.         0.        -0.6255229]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 2767 is [True, False, False, False, False, True]
State prediction error at timestep 2767 is 0.012
Current timestep = 2768. State = [[-0.38589874  0.20354106]]. Action = [[ 0.          0.          0.         -0.22105908]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 2768 is [True, False, False, False, False, True]
State prediction error at timestep 2768 is 0.012
Current timestep = 2769. State = [[-0.38618     0.20348603]]. Action = [[0.        0.        0.        0.6342242]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 2769 is [True, False, False, False, False, True]
State prediction error at timestep 2769 is 0.012
Current timestep = 2770. State = [[-0.38639808  0.20344895]]. Action = [[ 0.         0.         0.        -0.8909727]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 2770 is [True, False, False, False, False, True]
State prediction error at timestep 2770 is 0.012
Current timestep = 2771. State = [[-0.38654512  0.20343421]]. Action = [[ 0.         0.         0.        -0.7761109]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 2771 is [True, False, False, False, False, True]
State prediction error at timestep 2771 is 0.012
Current timestep = 2772. State = [[-0.3866113   0.20342775]]. Action = [[0.         0.         0.         0.13627315]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 2772 is [True, False, False, False, False, True]
State prediction error at timestep 2772 is 0.012
Current timestep = 2773. State = [[-0.38664615  0.20342453]]. Action = [[0.         0.         0.         0.81789136]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 2773 is [True, False, False, False, False, True]
State prediction error at timestep 2773 is 0.012
Current timestep = 2774. State = [[-0.38666996  0.20342416]]. Action = [[ 0.         0.         0.        -0.6613146]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 2774 is [True, False, False, False, False, True]
State prediction error at timestep 2774 is 0.012
Current timestep = 2775. State = [[-0.38669035  0.20342496]]. Action = [[ 0.          0.          0.         -0.91825944]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 2775 is [True, False, False, False, False, True]
State prediction error at timestep 2775 is 0.012
Current timestep = 2776. State = [[-0.38670948  0.20342614]]. Action = [[ 0.         0.         0.        -0.7407212]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 2776 is [True, False, False, False, False, True]
State prediction error at timestep 2776 is 0.012
Current timestep = 2777. State = [[-0.3867258   0.20342779]]. Action = [[ 0.         0.         0.        -0.9968195]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 2777 is [True, False, False, False, False, True]
State prediction error at timestep 2777 is 0.012
Current timestep = 2778. State = [[-0.3867393   0.20342985]]. Action = [[ 0.          0.          0.         -0.24254602]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 2778 is [True, False, False, False, False, True]
State prediction error at timestep 2778 is 0.012
Current timestep = 2779. State = [[-0.38675046  0.20343223]]. Action = [[0.         0.         0.         0.97712564]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 2779 is [True, False, False, False, False, True]
State prediction error at timestep 2779 is 0.012
Current timestep = 2780. State = [[-0.38675976  0.20343482]]. Action = [[0.         0.         0.         0.10792255]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 2780 is [True, False, False, False, False, True]
State prediction error at timestep 2780 is 0.012
Current timestep = 2781. State = [[-0.38676825  0.20343739]]. Action = [[0.         0.         0.         0.02683735]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 2781 is [True, False, False, False, False, True]
State prediction error at timestep 2781 is 0.012
Current timestep = 2782. State = [[-0.3867763   0.20343982]]. Action = [[0.        0.        0.        0.3562752]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 2782 is [True, False, False, False, False, True]
State prediction error at timestep 2782 is 0.012
Current timestep = 2783. State = [[-0.38678387  0.2034421 ]]. Action = [[ 0.          0.          0.         -0.06932986]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 2783 is [True, False, False, False, False, True]
State prediction error at timestep 2783 is 0.012
Current timestep = 2784. State = [[-0.38679102  0.20344421]]. Action = [[ 0.        0.        0.       -0.329854]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 2784 is [True, False, False, False, False, True]
State prediction error at timestep 2784 is 0.012
Current timestep = 2785. State = [[-0.38679776  0.20344616]]. Action = [[0.        0.        0.        0.5013808]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 2785 is [True, False, False, False, False, True]
State prediction error at timestep 2785 is 0.012
Current timestep = 2786. State = [[-0.38680407  0.20344797]]. Action = [[ 0.          0.          0.         -0.90174854]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 2786 is [True, False, False, False, False, True]
State prediction error at timestep 2786 is 0.012
Current timestep = 2787. State = [[-0.38681006  0.20344962]]. Action = [[ 0.          0.          0.         -0.04746723]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 2787 is [True, False, False, False, False, True]
State prediction error at timestep 2787 is 0.012
Current timestep = 2788. State = [[-0.3868157   0.20345114]]. Action = [[0.        0.        0.        0.5159576]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 2788 is [True, False, False, False, False, True]
State prediction error at timestep 2788 is 0.012
Current timestep = 2789. State = [[-0.386821    0.20345253]]. Action = [[0.         0.         0.         0.36519408]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 2789 is [True, False, False, False, False, True]
State prediction error at timestep 2789 is 0.012
Current timestep = 2790. State = [[-0.38682598  0.2034538 ]]. Action = [[ 0.         0.         0.        -0.5453553]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 2790 is [True, False, False, False, False, True]
State prediction error at timestep 2790 is 0.012
Current timestep = 2791. State = [[-0.38683072  0.20345496]]. Action = [[ 0.         0.         0.        -0.8190418]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 2791 is [True, False, False, False, False, True]
State prediction error at timestep 2791 is 0.012
Current timestep = 2792. State = [[-0.38683516  0.20345601]]. Action = [[ 0.         0.         0.        -0.3836245]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 2792 is [True, False, False, False, False, True]
State prediction error at timestep 2792 is 0.012
Current timestep = 2793. State = [[-0.38683936  0.20345698]]. Action = [[0.        0.        0.        0.7454214]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 2793 is [True, False, False, False, False, True]
State prediction error at timestep 2793 is 0.012
Current timestep = 2794. State = [[-0.38684335  0.20345786]]. Action = [[ 0.          0.          0.         -0.51389384]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 2794 is [True, False, False, False, False, True]
State prediction error at timestep 2794 is 0.012
Current timestep = 2795. State = [[-0.3868471   0.20345867]]. Action = [[ 0.          0.          0.         -0.25842887]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 2795 is [True, False, False, False, False, True]
State prediction error at timestep 2795 is 0.012
Current timestep = 2796. State = [[-0.38685066  0.2034594 ]]. Action = [[0.        0.        0.        0.8152212]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 2796 is [True, False, False, False, False, True]
State prediction error at timestep 2796 is 0.012
Current timestep = 2797. State = [[-0.38685402  0.20346007]]. Action = [[0.         0.         0.         0.80981326]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 2797 is [True, False, False, False, False, True]
State prediction error at timestep 2797 is 0.012
Current timestep = 2798. State = [[-0.3868572   0.20346066]]. Action = [[ 0.          0.          0.         -0.03186578]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 2798 is [True, False, False, False, False, True]
State prediction error at timestep 2798 is 0.012
Current timestep = 2799. State = [[-0.38686022  0.20346121]]. Action = [[ 0.          0.          0.         -0.42569113]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 2799 is [True, False, False, False, False, True]
State prediction error at timestep 2799 is 0.012
Current timestep = 2800. State = [[-0.38686314  0.2034617 ]]. Action = [[0.         0.         0.         0.21886504]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 2800 is [True, False, False, False, False, True]
State prediction error at timestep 2800 is 0.012
Current timestep = 2801. State = [[-0.386866    0.20346214]]. Action = [[ 0.          0.          0.         -0.46651077]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 2801 is [True, False, False, False, False, True]
State prediction error at timestep 2801 is 0.012
Current timestep = 2802. State = [[-0.38686883  0.20346253]]. Action = [[ 0.          0.          0.         -0.24548435]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 2802 is [True, False, False, False, False, True]
State prediction error at timestep 2802 is 0.012
Current timestep = 2803. State = [[-0.38687158  0.20346287]]. Action = [[ 0.          0.          0.         -0.02381325]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 2803 is [True, False, False, False, False, True]
State prediction error at timestep 2803 is 0.012
Current timestep = 2804. State = [[-0.3868743   0.20346315]]. Action = [[ 0.          0.          0.         -0.57898825]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 2804 is [True, False, False, False, False, True]
State prediction error at timestep 2804 is 0.012
Current timestep = 2805. State = [[-0.38687694  0.2034634 ]]. Action = [[0.         0.         0.         0.68384635]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 2805 is [True, False, False, False, False, True]
State prediction error at timestep 2805 is 0.012
Current timestep = 2806. State = [[-0.38687956  0.20346361]]. Action = [[ 0.         0.         0.        -0.5495646]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 2806 is [True, False, False, False, False, True]
State prediction error at timestep 2806 is 0.012
Current timestep = 2807. State = [[-0.38688213  0.20346378]]. Action = [[ 0.         0.         0.        -0.9779847]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 2807 is [True, False, False, False, False, True]
State prediction error at timestep 2807 is 0.012
Current timestep = 2808. State = [[-0.38688463  0.20346391]]. Action = [[0.         0.         0.         0.17088938]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 2808 is [True, False, False, False, False, True]
State prediction error at timestep 2808 is 0.012
Current timestep = 2809. State = [[-0.3868871   0.20346403]]. Action = [[ 0.         0.         0.        -0.6442592]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 2809 is [True, False, False, False, False, True]
State prediction error at timestep 2809 is 0.012
Current timestep = 2810. State = [[-0.38688958  0.20346414]]. Action = [[ 0.          0.          0.         -0.77026814]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 2810 is [True, False, False, False, False, True]
State prediction error at timestep 2810 is 0.012
Current timestep = 2811. State = [[-0.38689202  0.20346425]]. Action = [[0.        0.        0.        0.6380911]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 2811 is [True, False, False, False, False, True]
State prediction error at timestep 2811 is 0.012
Current timestep = 2812. State = [[-0.38689443  0.20346436]]. Action = [[ 0.          0.          0.         -0.75298506]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 2812 is [True, False, False, False, False, True]
State prediction error at timestep 2812 is 0.012
Current timestep = 2813. State = [[-0.38689685  0.20346448]]. Action = [[ 0.         0.         0.        -0.9448709]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 2813 is [True, False, False, False, False, True]
State prediction error at timestep 2813 is 0.012
Current timestep = 2814. State = [[-0.38689923  0.20346458]]. Action = [[ 0.         0.         0.        -0.5459041]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 2814 is [True, False, False, False, False, True]
State prediction error at timestep 2814 is 0.012
Current timestep = 2815. State = [[-0.3869016   0.20346469]]. Action = [[0.         0.         0.         0.01396871]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 2815 is [True, False, False, False, False, True]
State prediction error at timestep 2815 is 0.012
Current timestep = 2816. State = [[-0.38690394  0.20346479]]. Action = [[ 0.          0.          0.         -0.91794205]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 2816 is [True, False, False, False, False, True]
State prediction error at timestep 2816 is 0.012
Current timestep = 2817. State = [[-0.38690624  0.2034649 ]]. Action = [[0.         0.         0.         0.85704255]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 2817 is [True, False, False, False, False, True]
State prediction error at timestep 2817 is 0.012
Current timestep = 2818. State = [[-0.38690856  0.203465  ]]. Action = [[0.         0.         0.         0.13874137]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 2818 is [True, False, False, False, False, True]
State prediction error at timestep 2818 is 0.012
Current timestep = 2819. State = [[-0.38691083  0.2034651 ]]. Action = [[0.         0.         0.         0.91784596]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 2819 is [True, False, False, False, False, True]
State prediction error at timestep 2819 is 0.012
Current timestep = 2820. State = [[-0.3869131   0.20346521]]. Action = [[ 0.          0.          0.         -0.16651613]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 2820 is [True, False, False, False, False, True]
State prediction error at timestep 2820 is 0.012
Current timestep = 2821. State = [[-0.38691536  0.20346531]]. Action = [[0.         0.         0.         0.49380958]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 2821 is [True, False, False, False, False, True]
State prediction error at timestep 2821 is 0.012
Current timestep = 2822. State = [[-0.3869176   0.20346542]]. Action = [[0.         0.         0.         0.13592744]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 2822 is [True, False, False, False, False, True]
State prediction error at timestep 2822 is 0.012
Current timestep = 2823. State = [[-0.3869198   0.20346552]]. Action = [[ 0.         0.         0.        -0.8956546]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 2823 is [True, False, False, False, False, True]
State prediction error at timestep 2823 is 0.012
Current timestep = 2824. State = [[-0.38692197  0.20346561]]. Action = [[0.         0.         0.         0.37162423]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 2824 is [True, False, False, False, False, True]
State prediction error at timestep 2824 is 0.012
Current timestep = 2825. State = [[-0.38692415  0.20346572]]. Action = [[0.         0.         0.         0.72220325]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 2825 is [True, False, False, False, False, True]
State prediction error at timestep 2825 is 0.012
Current timestep = 2826. State = [[-0.3869263  0.2034658]]. Action = [[0.         0.         0.         0.20413482]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 2826 is [True, False, False, False, False, True]
State prediction error at timestep 2826 is 0.012
Current timestep = 2827. State = [[-0.38692844  0.20346591]]. Action = [[ 0.          0.          0.         -0.01943666]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 2827 is [True, False, False, False, False, True]
State prediction error at timestep 2827 is 0.012
Current timestep = 2828. State = [[-0.38693056  0.203466  ]]. Action = [[ 0.         0.         0.        -0.5196221]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 2828 is [True, False, False, False, False, True]
State prediction error at timestep 2828 is 0.012
Current timestep = 2829. State = [[-0.38693267  0.2034661 ]]. Action = [[ 0.         0.         0.        -0.3931111]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 2829 is [True, False, False, False, False, True]
State prediction error at timestep 2829 is 0.012
Current timestep = 2830. State = [[-0.38693476  0.20346619]]. Action = [[ 0.          0.          0.         -0.34591103]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 2830 is [True, False, False, False, False, True]
State prediction error at timestep 2830 is 0.012
Current timestep = 2831. State = [[-0.3869368   0.20346628]]. Action = [[0.         0.         0.         0.30898094]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 2831 is [True, False, False, False, False, True]
State prediction error at timestep 2831 is 0.012
Current timestep = 2832. State = [[-0.38693887  0.20346639]]. Action = [[ 0.          0.          0.         -0.22500867]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 2832 is [True, False, False, False, False, True]
State prediction error at timestep 2832 is 0.012
Current timestep = 2833. State = [[-0.3869409   0.20346648]]. Action = [[0.         0.         0.         0.59583163]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 2833 is [True, False, False, False, False, True]
State prediction error at timestep 2833 is 0.012
Current timestep = 2834. State = [[-0.3869429   0.20346656]]. Action = [[ 0.         0.         0.        -0.9319833]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 2834 is [True, False, False, False, False, True]
State prediction error at timestep 2834 is 0.012
Current timestep = 2835. State = [[-0.38694492  0.20346665]]. Action = [[0.         0.         0.         0.18760419]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 2835 is [True, False, False, False, False, True]
State prediction error at timestep 2835 is 0.012
Current timestep = 2836. State = [[-0.3869469   0.20346674]]. Action = [[0.         0.         0.         0.20820463]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 2836 is [True, False, False, False, False, True]
State prediction error at timestep 2836 is 0.012
Current timestep = 2837. State = [[-0.38694885  0.20346683]]. Action = [[0.         0.         0.         0.42645943]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 2837 is [True, False, False, False, False, True]
State prediction error at timestep 2837 is 0.012
Current timestep = 2838. State = [[-0.3869508   0.20346692]]. Action = [[ 0.          0.          0.         -0.06846267]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 2838 is [True, False, False, False, False, True]
State prediction error at timestep 2838 is 0.012
Current timestep = 2839. State = [[-0.38695273  0.20346701]]. Action = [[0.        0.        0.        0.4592842]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 2839 is [True, False, False, False, False, True]
State prediction error at timestep 2839 is 0.012
Current timestep = 2840. State = [[-0.38695467  0.20346709]]. Action = [[0.        0.        0.        0.8641069]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 2840 is [True, False, False, False, False, True]
State prediction error at timestep 2840 is 0.012
Current timestep = 2841. State = [[-0.38695654  0.20346718]]. Action = [[0.       0.       0.       0.773139]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 2841 is [True, False, False, False, False, True]
State prediction error at timestep 2841 is 0.012
Current timestep = 2842. State = [[-0.38695845  0.20346726]]. Action = [[0.         0.         0.         0.11019707]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 2842 is [True, False, False, False, False, True]
State prediction error at timestep 2842 is 0.012
Current timestep = 2843. State = [[-0.3869603   0.20346734]]. Action = [[0.         0.         0.         0.73834395]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 2843 is [True, False, False, False, False, True]
State prediction error at timestep 2843 is 0.012
Current timestep = 2844. State = [[-0.38696218  0.20346743]]. Action = [[0.        0.        0.        0.6420597]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 2844 is [True, False, False, False, False, True]
State prediction error at timestep 2844 is 0.012
Current timestep = 2845. State = [[-0.386964   0.2034675]]. Action = [[ 0.          0.          0.         -0.38445473]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 2845 is [True, False, False, False, False, True]
State prediction error at timestep 2845 is 0.012
Current timestep = 2846. State = [[-0.3869658  0.2034676]]. Action = [[ 0.          0.          0.         -0.92470443]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 2846 is [True, False, False, False, False, True]
State prediction error at timestep 2846 is 0.012
Current timestep = 2847. State = [[-0.38696763  0.20346767]]. Action = [[0.        0.        0.        0.8435991]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 2847 is [True, False, False, False, False, True]
State prediction error at timestep 2847 is 0.012
Current timestep = 2848. State = [[-0.38696942  0.20346776]]. Action = [[0.         0.         0.         0.77986765]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 2848 is [True, False, False, False, False, True]
State prediction error at timestep 2848 is 0.012
Current timestep = 2849. State = [[-0.3869712   0.20346783]]. Action = [[0.        0.        0.        0.5928004]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 2849 is [True, False, False, False, False, True]
State prediction error at timestep 2849 is 0.012
Current timestep = 2850. State = [[-0.38697296  0.2034679 ]]. Action = [[0.         0.         0.         0.87916005]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 2850 is [True, False, False, False, False, True]
State prediction error at timestep 2850 is 0.012
Current timestep = 2851. State = [[-0.38697472  0.20346798]]. Action = [[ 0.          0.          0.         -0.09306729]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 2851 is [True, False, False, False, False, True]
State prediction error at timestep 2851 is 0.012
Current timestep = 2852. State = [[-0.38697645  0.20346807]]. Action = [[ 0.          0.          0.         -0.61180717]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 2852 is [True, False, False, False, False, True]
State prediction error at timestep 2852 is 0.012
Current timestep = 2853. State = [[-0.38697818  0.20346814]]. Action = [[0.         0.         0.         0.12460256]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 2853 is [True, False, False, False, False, True]
State prediction error at timestep 2853 is 0.012
Current timestep = 2854. State = [[-0.38697988  0.20346822]]. Action = [[ 0.          0.          0.         -0.29176986]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 2854 is [True, False, False, False, False, True]
State prediction error at timestep 2854 is 0.012
Current timestep = 2855. State = [[-0.38698158  0.2034683 ]]. Action = [[ 0.          0.          0.         -0.20380038]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 2855 is [True, False, False, False, False, True]
State prediction error at timestep 2855 is 0.012
Current timestep = 2856. State = [[-0.38698325  0.20346837]]. Action = [[0.         0.         0.         0.19127882]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 2856 is [True, False, False, False, False, True]
State prediction error at timestep 2856 is 0.012
Current timestep = 2857. State = [[-0.3869849   0.20346843]]. Action = [[ 0.         0.         0.        -0.8625185]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 2857 is [True, False, False, False, False, True]
State prediction error at timestep 2857 is 0.012
Current timestep = 2858. State = [[-0.38698655  0.2034685 ]]. Action = [[0.         0.         0.         0.24378991]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 2858 is [True, False, False, False, False, True]
State prediction error at timestep 2858 is 0.012
Current timestep = 2859. State = [[-0.3869882   0.20346858]]. Action = [[0.         0.         0.         0.93224645]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 2859 is [True, False, False, False, False, True]
State prediction error at timestep 2859 is 0.012
Current timestep = 2860. State = [[-0.3869898   0.20346865]]. Action = [[ 0.          0.          0.         -0.22272646]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 2860 is [True, False, False, False, False, True]
State prediction error at timestep 2860 is 0.012
Current timestep = 2861. State = [[-0.3869914   0.20346871]]. Action = [[0.        0.        0.        0.2989323]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 2861 is [True, False, False, False, False, True]
State prediction error at timestep 2861 is 0.012
Current timestep = 2862. State = [[-0.38699302  0.20346878]]. Action = [[0.         0.         0.         0.94303286]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 2862 is [True, False, False, False, False, True]
State prediction error at timestep 2862 is 0.012
Current timestep = 2863. State = [[-0.3869946   0.20346886]]. Action = [[ 0.          0.          0.         -0.20011157]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 2863 is [True, False, False, False, False, True]
State prediction error at timestep 2863 is 0.012
Current timestep = 2864. State = [[-0.38699618  0.20346892]]. Action = [[ 0.          0.          0.         -0.91688293]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 2864 is [True, False, False, False, False, True]
State prediction error at timestep 2864 is 0.012
Current timestep = 2865. State = [[-0.38699773  0.203469  ]]. Action = [[ 0.          0.          0.         -0.54981667]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 2865 is [True, False, False, False, False, True]
State prediction error at timestep 2865 is 0.012
Current timestep = 2866. State = [[-0.38699928  0.20346905]]. Action = [[0.        0.        0.        0.6344043]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 2866 is [True, False, False, False, False, True]
State prediction error at timestep 2866 is 0.012
Current timestep = 2867. State = [[-0.3870008   0.20346913]]. Action = [[0.        0.        0.        0.7860851]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 2867 is [True, False, False, False, False, True]
State prediction error at timestep 2867 is 0.012
Current timestep = 2868. State = [[-0.38700232  0.20346919]]. Action = [[0.        0.        0.        0.9575908]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 2868 is [True, False, False, False, False, True]
State prediction error at timestep 2868 is 0.012
Current timestep = 2869. State = [[-0.3870038   0.20346925]]. Action = [[0.         0.         0.         0.21001291]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 2869 is [True, False, False, False, False, True]
State prediction error at timestep 2869 is 0.012
Current timestep = 2870. State = [[-0.3870053  0.2034693]]. Action = [[0.         0.         0.         0.32948828]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 2870 is [True, False, False, False, False, True]
State prediction error at timestep 2870 is 0.012
Current timestep = 2871. State = [[-0.3870068   0.20346938]]. Action = [[0.       0.       0.       0.281039]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 2871 is [True, False, False, False, False, True]
State prediction error at timestep 2871 is 0.012
Current timestep = 2872. State = [[-0.38700825  0.20346944]]. Action = [[0.         0.         0.         0.21258307]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 2872 is [True, False, False, False, False, True]
State prediction error at timestep 2872 is 0.012
Current timestep = 2873. State = [[-0.3870097  0.2034695]]. Action = [[ 0.          0.          0.         -0.08714581]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 2873 is [True, False, False, False, False, True]
State prediction error at timestep 2873 is 0.012
Current timestep = 2874. State = [[-0.38701117  0.20346956]]. Action = [[0.         0.         0.         0.96487486]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 2874 is [True, False, False, False, False, True]
State prediction error at timestep 2874 is 0.012
Current timestep = 2875. State = [[-0.3870126   0.20346962]]. Action = [[ 0.          0.          0.         -0.52888167]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 2875 is [True, False, False, False, False, True]
State prediction error at timestep 2875 is 0.012
Current timestep = 2876. State = [[-0.387014    0.20346968]]. Action = [[0.         0.         0.         0.37047863]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 2876 is [True, False, False, False, False, True]
State prediction error at timestep 2876 is 0.012
Current timestep = 2877. State = [[-0.3870154   0.20346974]]. Action = [[0.         0.         0.         0.26148772]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 2877 is [True, False, False, False, False, True]
State prediction error at timestep 2877 is 0.012
Current timestep = 2878. State = [[-0.3870168  0.2034698]]. Action = [[ 0.          0.          0.         -0.97788966]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 2878 is [True, False, False, False, False, True]
State prediction error at timestep 2878 is 0.012
Current timestep = 2879. State = [[-0.3870182   0.20346986]]. Action = [[0.        0.        0.        0.4836607]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 2879 is [True, False, False, False, False, True]
State prediction error at timestep 2879 is 0.012
Current timestep = 2880. State = [[-0.38701957  0.2034699 ]]. Action = [[0.         0.         0.         0.24985349]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 2880 is [True, False, False, False, False, True]
State prediction error at timestep 2880 is 0.012
Current timestep = 2881. State = [[-0.38702095  0.20346996]]. Action = [[0.        0.        0.        0.5365522]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 2881 is [True, False, False, False, False, True]
State prediction error at timestep 2881 is 0.012
Current timestep = 2882. State = [[-0.3870223   0.20347002]]. Action = [[ 0.          0.          0.         -0.07083112]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 2882 is [True, False, False, False, False, True]
State prediction error at timestep 2882 is 0.012
Current timestep = 2883. State = [[-0.38702363  0.20347007]]. Action = [[0.         0.         0.         0.63222504]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 2883 is [True, False, False, False, False, True]
State prediction error at timestep 2883 is 0.012
Current timestep = 2884. State = [[-0.38702494  0.20347013]]. Action = [[0.        0.        0.        0.4422102]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 2884 is [True, False, False, False, False, True]
State prediction error at timestep 2884 is 0.012
Current timestep = 2885. State = [[-0.38702625  0.20347019]]. Action = [[ 0.          0.          0.         -0.80817634]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 2885 is [True, False, False, False, False, True]
State prediction error at timestep 2885 is 0.012
Current timestep = 2886. State = [[-0.38702756  0.20347023]]. Action = [[ 0.          0.          0.         -0.25132918]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 2886 is [True, False, False, False, False, True]
State prediction error at timestep 2886 is 0.012
Current timestep = 2887. State = [[-0.38702887  0.20347029]]. Action = [[0.         0.         0.         0.22889733]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 2887 is [True, False, False, False, False, True]
State prediction error at timestep 2887 is 0.012
Current timestep = 2888. State = [[-0.38703015  0.20347033]]. Action = [[ 0.         0.         0.        -0.6700587]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 2888 is [True, False, False, False, False, True]
State prediction error at timestep 2888 is 0.012
Current timestep = 2889. State = [[-0.3870314   0.20347038]]. Action = [[0.         0.         0.         0.78193355]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 2889 is [True, False, False, False, False, True]
State prediction error at timestep 2889 is 0.012
Current timestep = 2890. State = [[-0.3870327   0.20347044]]. Action = [[ 0.         0.         0.        -0.9514756]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 2890 is [True, False, False, False, False, True]
State prediction error at timestep 2890 is 0.012
Current timestep = 2891. State = [[-0.38703394  0.20347048]]. Action = [[0.         0.         0.         0.01348615]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 2891 is [True, False, False, False, False, True]
State prediction error at timestep 2891 is 0.012
Current timestep = 2892. State = [[-0.3870352   0.20347053]]. Action = [[ 0.          0.          0.         -0.20295483]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 2892 is [True, False, False, False, False, True]
State prediction error at timestep 2892 is 0.012
Current timestep = 2893. State = [[-0.3870364   0.20347057]]. Action = [[0.         0.         0.         0.13839614]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 2893 is [True, False, False, False, False, True]
State prediction error at timestep 2893 is 0.012
Current timestep = 2894. State = [[-0.38703763  0.20347063]]. Action = [[0.         0.         0.         0.00148177]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 2894 is [True, False, False, False, False, True]
State prediction error at timestep 2894 is 0.012
Current timestep = 2895. State = [[-0.38703883  0.20347068]]. Action = [[0.         0.         0.         0.67748475]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 2895 is [True, False, False, False, False, True]
State prediction error at timestep 2895 is 0.012
Current timestep = 2896. State = [[-0.38704005  0.20347072]]. Action = [[ 0.         0.         0.        -0.8301707]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 2896 is [True, False, False, False, False, True]
State prediction error at timestep 2896 is 0.012
Current timestep = 2897. State = [[-0.38704124  0.20347077]]. Action = [[0.      0.      0.      0.57252]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 2897 is [True, False, False, False, False, True]
State prediction error at timestep 2897 is 0.012
Current timestep = 2898. State = [[-0.3870424   0.20347081]]. Action = [[0.         0.         0.         0.00902581]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 2898 is [True, False, False, False, False, True]
State prediction error at timestep 2898 is 0.012
Current timestep = 2899. State = [[-0.3870436   0.20347086]]. Action = [[ 0.          0.          0.         -0.46203536]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 2899 is [True, False, False, False, False, True]
State prediction error at timestep 2899 is 0.012
Current timestep = 2900. State = [[-0.38704476  0.2034709 ]]. Action = [[0.        0.        0.        0.8341582]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 2900 is [True, False, False, False, False, True]
State prediction error at timestep 2900 is 0.012
Current timestep = 2901. State = [[-0.3870459   0.20347095]]. Action = [[ 0.          0.          0.         -0.06780511]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 2901 is [True, False, False, False, False, True]
State prediction error at timestep 2901 is 0.012
Current timestep = 2902. State = [[-0.38704705  0.20347099]]. Action = [[ 0.          0.          0.         -0.42991185]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 2902 is [True, False, False, False, False, True]
State prediction error at timestep 2902 is 0.012
Current timestep = 2903. State = [[-0.38704818  0.20347102]]. Action = [[0.        0.        0.        0.3905486]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 2903 is [True, False, False, False, False, True]
State prediction error at timestep 2903 is 0.012
Current timestep = 2904. State = [[-0.3870493   0.20347106]]. Action = [[0.        0.        0.        0.6280632]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 2904 is [True, False, False, False, False, True]
State prediction error at timestep 2904 is 0.012
Current timestep = 2905. State = [[-0.38705042  0.20347111]]. Action = [[0.         0.         0.         0.87490225]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 2905 is [True, False, False, False, False, True]
State prediction error at timestep 2905 is 0.012
Current timestep = 2906. State = [[-0.38705152  0.20347115]]. Action = [[ 0.         0.         0.        -0.7616906]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 2906 is [True, False, False, False, False, True]
State prediction error at timestep 2906 is 0.012
Current timestep = 2907. State = [[-0.3870526   0.20347118]]. Action = [[0.         0.         0.         0.94102097]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 2907 is [True, False, False, False, False, True]
State prediction error at timestep 2907 is 0.012
Current timestep = 2908. State = [[-0.3870537   0.20347123]]. Action = [[0.         0.         0.         0.06265306]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 2908 is [True, False, False, False, False, True]
State prediction error at timestep 2908 is 0.012
Current timestep = 2909. State = [[-0.38705477  0.20347126]]. Action = [[ 0.         0.         0.        -0.6391844]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 2909 is [True, False, False, False, False, True]
State prediction error at timestep 2909 is 0.012
Current timestep = 2910. State = [[-0.38705584  0.2034713 ]]. Action = [[0.         0.         0.         0.21206689]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 2910 is [True, False, False, False, False, True]
State prediction error at timestep 2910 is 0.012
Current timestep = 2911. State = [[-0.3870569   0.20347133]]. Action = [[0.         0.         0.         0.61577296]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 2911 is [True, False, False, False, False, True]
State prediction error at timestep 2911 is 0.012
Current timestep = 2912. State = [[-0.38705796  0.20347138]]. Action = [[0.         0.         0.         0.14187169]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 2912 is [True, False, False, False, False, True]
State prediction error at timestep 2912 is 0.012
Current timestep = 2913. State = [[-0.387059   0.2034714]]. Action = [[0.         0.         0.         0.50870335]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 2913 is [True, False, False, False, False, True]
State prediction error at timestep 2913 is 0.012
Current timestep = 2914. State = [[-0.38706002  0.20347145]]. Action = [[0.        0.        0.        0.9172714]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 2914 is [True, False, False, False, False, True]
State prediction error at timestep 2914 is 0.012
Current timestep = 2915. State = [[-0.38706106  0.20347148]]. Action = [[ 0.          0.          0.         -0.11869466]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 2915 is [True, False, False, False, False, True]
State prediction error at timestep 2915 is 0.012
Current timestep = 2916. State = [[-0.38706207  0.20347151]]. Action = [[0.        0.        0.        0.7838421]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 2916 is [True, False, False, False, False, True]
State prediction error at timestep 2916 is 0.012
Current timestep = 2917. State = [[-0.38706306  0.20347154]]. Action = [[ 0.         0.         0.        -0.5215442]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 2917 is [True, False, False, False, False, True]
State prediction error at timestep 2917 is 0.012
Current timestep = 2918. State = [[-0.38706407  0.20347159]]. Action = [[ 0.         0.         0.        -0.9396186]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 2918 is [True, False, False, False, False, True]
State prediction error at timestep 2918 is 0.012
Current timestep = 2919. State = [[-0.38706505  0.20347162]]. Action = [[0.         0.         0.         0.45267546]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 2919 is [True, False, False, False, False, True]
State prediction error at timestep 2919 is 0.012
Current timestep = 2920. State = [[-0.38706604  0.20347165]]. Action = [[ 0.          0.          0.         -0.38589346]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 2920 is [True, False, False, False, False, True]
State prediction error at timestep 2920 is 0.012
Current timestep = 2921. State = [[-0.38706702  0.20347168]]. Action = [[0.         0.         0.         0.23995161]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 2921 is [True, False, False, False, False, True]
State prediction error at timestep 2921 is 0.012
Current timestep = 2922. State = [[-0.38706797  0.2034717 ]]. Action = [[0.         0.         0.         0.08633482]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 2922 is [True, False, False, False, False, True]
State prediction error at timestep 2922 is 0.012
Current timestep = 2923. State = [[-0.38706893  0.20347174]]. Action = [[ 0.          0.          0.         -0.07669169]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 2923 is [True, False, False, False, False, True]
State prediction error at timestep 2923 is 0.012
Current timestep = 2924. State = [[-0.38706988  0.20347176]]. Action = [[0.         0.         0.         0.43243086]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 2924 is [True, False, False, False, False, True]
State prediction error at timestep 2924 is 0.012
Current timestep = 2925. State = [[-0.38707083  0.2034718 ]]. Action = [[ 0.          0.          0.         -0.21815461]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 2925 is [True, False, False, False, False, True]
State prediction error at timestep 2925 is 0.012
Current timestep = 2926. State = [[-0.38707176  0.20347182]]. Action = [[ 0.         0.         0.        -0.3129617]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 2926 is [True, False, False, False, False, True]
State prediction error at timestep 2926 is 0.012
Current timestep = 2927. State = [[-0.38707268  0.20347185]]. Action = [[0.        0.        0.        0.5843452]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 2927 is [True, False, False, False, False, True]
State prediction error at timestep 2927 is 0.012
Current timestep = 2928. State = [[-0.3870736   0.20347188]]. Action = [[ 0.          0.          0.         -0.83958703]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 2928 is [True, False, False, False, False, True]
State prediction error at timestep 2928 is 0.012
Current timestep = 2929. State = [[-0.38707453  0.20347191]]. Action = [[ 0.          0.          0.         -0.32616526]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 2929 is [True, False, False, False, False, True]
State prediction error at timestep 2929 is 0.012
Current timestep = 2930. State = [[-0.38707542  0.20347194]]. Action = [[ 0.         0.         0.        -0.2953936]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 2930 is [True, False, False, False, False, True]
State prediction error at timestep 2930 is 0.012
Current timestep = 2931. State = [[-0.38707632  0.20347196]]. Action = [[0.         0.         0.         0.68931043]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 2931 is [True, False, False, False, False, True]
State prediction error at timestep 2931 is 0.012
Current timestep = 2932. State = [[-0.3870772   0.20347199]]. Action = [[0.         0.         0.         0.06934333]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 2932 is [True, False, False, False, False, True]
State prediction error at timestep 2932 is 0.012
Current timestep = 2933. State = [[-0.38707808  0.20347202]]. Action = [[0.         0.         0.         0.71248364]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 2933 is [True, False, False, False, False, True]
State prediction error at timestep 2933 is 0.012
Current timestep = 2934. State = [[-0.38707897  0.20347203]]. Action = [[0.       0.       0.       0.573755]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 2934 is [True, False, False, False, False, True]
State prediction error at timestep 2934 is 0.012
Current timestep = 2935. State = [[-0.38707983  0.20347206]]. Action = [[0.        0.        0.        0.6337433]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 2935 is [True, False, False, False, False, True]
State prediction error at timestep 2935 is 0.012
Current timestep = 2936. State = [[-0.3870807  0.2034721]]. Action = [[ 0.          0.          0.         -0.02064693]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 2936 is [True, False, False, False, False, True]
State prediction error at timestep 2936 is 0.012
Current timestep = 2937. State = [[-0.38708153  0.20347211]]. Action = [[0.        0.        0.        0.6810894]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 2937 is [True, False, False, False, False, True]
State prediction error at timestep 2937 is 0.012
Current timestep = 2938. State = [[-0.3870824   0.20347214]]. Action = [[0.         0.         0.         0.35941637]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 2938 is [True, False, False, False, False, True]
State prediction error at timestep 2938 is 0.012
Current timestep = 2939. State = [[-0.38708323  0.20347215]]. Action = [[0.         0.         0.         0.48990297]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 2939 is [True, False, False, False, False, True]
State prediction error at timestep 2939 is 0.012
Current timestep = 2940. State = [[-0.38708407  0.20347218]]. Action = [[0.         0.         0.         0.61806214]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 2940 is [True, False, False, False, False, True]
State prediction error at timestep 2940 is 0.012
Current timestep = 2941. State = [[-0.38708487  0.2034722 ]]. Action = [[ 0.          0.          0.         -0.85291415]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 2941 is [True, False, False, False, False, True]
State prediction error at timestep 2941 is 0.012
Current timestep = 2942. State = [[-0.3870857   0.20347221]]. Action = [[ 0.          0.          0.         -0.70926946]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 2942 is [True, False, False, False, False, True]
State prediction error at timestep 2942 is 0.012
Current timestep = 2943. State = [[-0.3870865   0.20347224]]. Action = [[0.         0.         0.         0.52074456]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 2943 is [True, False, False, False, False, True]
State prediction error at timestep 2943 is 0.012
Current timestep = 2944. State = [[-0.38708732  0.20347226]]. Action = [[0.        0.        0.        0.4470278]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 2944 is [True, False, False, False, False, True]
State prediction error at timestep 2944 is 0.012
Current timestep = 2945. State = [[-0.38708812  0.20347227]]. Action = [[ 0.         0.         0.        -0.6174039]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 2945 is [True, False, False, False, False, True]
State prediction error at timestep 2945 is 0.012
Current timestep = 2946. State = [[-0.3870889  0.2034723]]. Action = [[ 0.          0.          0.         -0.64484537]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 2946 is [True, False, False, False, False, True]
State prediction error at timestep 2946 is 0.012
Current timestep = 2947. State = [[-0.38708967  0.20347232]]. Action = [[0.         0.         0.         0.65410995]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 2947 is [True, False, False, False, False, True]
State prediction error at timestep 2947 is 0.012
Current timestep = 2948. State = [[-0.38709044  0.20347233]]. Action = [[ 0.          0.          0.         -0.64861923]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 2948 is [True, False, False, False, False, True]
State prediction error at timestep 2948 is 0.012
Current timestep = 2949. State = [[-0.38709122  0.20347235]]. Action = [[ 0.          0.          0.         -0.06579494]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 2949 is [True, False, False, False, False, True]
State prediction error at timestep 2949 is 0.012
Current timestep = 2950. State = [[-0.387092    0.20347236]]. Action = [[0.        0.        0.        0.7055924]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 2950 is [True, False, False, False, False, True]
State prediction error at timestep 2950 is 0.012
Current timestep = 2951. State = [[-0.38709274  0.20347238]]. Action = [[ 0.         0.         0.        -0.8508439]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 2951 is [True, False, False, False, False, True]
State prediction error at timestep 2951 is 0.012
Current timestep = 2952. State = [[-0.38709348  0.2034724 ]]. Action = [[ 0.          0.          0.         -0.53620857]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 2952 is [True, False, False, False, False, True]
State prediction error at timestep 2952 is 0.012
Current timestep = 2953. State = [[-0.38709423  0.20347242]]. Action = [[ 0.          0.          0.         -0.82877386]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 2953 is [True, False, False, False, False, True]
State prediction error at timestep 2953 is 0.012
Current timestep = 2954. State = [[-0.38709497  0.20347244]]. Action = [[0.        0.        0.        0.6923971]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 2954 is [True, False, False, False, False, True]
State prediction error at timestep 2954 is 0.012
Current timestep = 2955. State = [[-0.38709572  0.20347245]]. Action = [[0.         0.         0.         0.65110373]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 2955 is [True, False, False, False, False, True]
State prediction error at timestep 2955 is 0.012
Current timestep = 2956. State = [[-0.38709643  0.20347247]]. Action = [[ 0.          0.          0.         -0.59904724]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 2956 is [True, False, False, False, False, True]
State prediction error at timestep 2956 is 0.012
Current timestep = 2957. State = [[-0.38709715  0.20347247]]. Action = [[0.         0.         0.         0.11678922]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 2957 is [True, False, False, False, False, True]
State prediction error at timestep 2957 is 0.012
Current timestep = 2958. State = [[-0.38709787  0.20347248]]. Action = [[ 0.         0.         0.        -0.7666258]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 2958 is [True, False, False, False, False, True]
State prediction error at timestep 2958 is 0.012
Current timestep = 2959. State = [[-0.38709858  0.2034725 ]]. Action = [[0.        0.        0.        0.6150453]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 2959 is [True, False, False, False, False, True]
State prediction error at timestep 2959 is 0.012
Current timestep = 2960. State = [[-0.3870993   0.20347251]]. Action = [[ 0.          0.          0.         -0.21102965]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 2960 is [True, False, False, False, False, True]
State prediction error at timestep 2960 is 0.012
Current timestep = 2961. State = [[-0.38709998  0.20347252]]. Action = [[0.         0.         0.         0.52601457]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 2961 is [True, False, False, False, False, True]
State prediction error at timestep 2961 is 0.012
Current timestep = 2962. State = [[-0.38710067  0.20347254]]. Action = [[ 0.         0.         0.        -0.5022703]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 2962 is [True, False, False, False, False, True]
State prediction error at timestep 2962 is 0.012
Current timestep = 2963. State = [[-0.38710135  0.20347254]]. Action = [[0.        0.        0.        0.6273129]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 2963 is [True, False, False, False, False, True]
State prediction error at timestep 2963 is 0.012
Current timestep = 2964. State = [[-0.38710204  0.20347255]]. Action = [[ 0.         0.         0.        -0.6407362]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 2964 is [True, False, False, False, False, True]
State prediction error at timestep 2964 is 0.012
Current timestep = 2965. State = [[-0.38710272  0.20347257]]. Action = [[ 0.          0.          0.         -0.39816093]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 2965 is [True, False, False, False, False, True]
State prediction error at timestep 2965 is 0.012
Current timestep = 2966. State = [[-0.38710338  0.20347257]]. Action = [[ 0.         0.         0.        -0.5599484]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 2966 is [True, False, False, False, False, True]
State prediction error at timestep 2966 is 0.012
Current timestep = 2967. State = [[-0.38710403  0.20347258]]. Action = [[ 0.         0.         0.        -0.3744129]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 2967 is [True, False, False, False, False, True]
State prediction error at timestep 2967 is 0.012
Current timestep = 2968. State = [[-0.3871047  0.2034726]]. Action = [[0.        0.        0.        0.1300149]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 2968 is [True, False, False, False, False, True]
State prediction error at timestep 2968 is 0.012
Current timestep = 2969. State = [[-0.38710535  0.2034726 ]]. Action = [[0.         0.         0.         0.30649757]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 2969 is [True, False, False, False, False, True]
State prediction error at timestep 2969 is 0.012
Current timestep = 2970. State = [[-0.387106    0.20347261]]. Action = [[0.         0.         0.         0.23939729]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 2970 is [True, False, False, False, False, True]
State prediction error at timestep 2970 is 0.012
Current timestep = 2971. State = [[-0.38710663  0.20347261]]. Action = [[ 0.         0.         0.        -0.4736793]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 2971 is [True, False, False, False, False, True]
State prediction error at timestep 2971 is 0.012
Current timestep = 2972. State = [[-0.38710728  0.20347263]]. Action = [[ 0.          0.          0.         -0.00286871]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 2972 is [True, False, False, False, False, True]
State prediction error at timestep 2972 is 0.012
Current timestep = 2973. State = [[-0.3871079   0.20347263]]. Action = [[0.         0.         0.         0.56413054]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 2973 is [True, False, False, False, False, True]
State prediction error at timestep 2973 is 0.012
Current timestep = 2974. State = [[-0.38710853  0.20347264]]. Action = [[ 0.          0.          0.         -0.45826864]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 2974 is [True, False, False, False, False, True]
State prediction error at timestep 2974 is 0.012
Current timestep = 2975. State = [[-0.38710913  0.20347264]]. Action = [[0.         0.         0.         0.00772071]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 2975 is [True, False, False, False, False, True]
State prediction error at timestep 2975 is 0.012
Current timestep = 2976. State = [[-0.38710976  0.20347266]]. Action = [[ 0.          0.          0.         -0.32237792]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 2976 is [True, False, False, False, False, True]
State prediction error at timestep 2976 is 0.012
Current timestep = 2977. State = [[-0.38711038  0.20347266]]. Action = [[ 0.        0.        0.       -0.796281]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 2977 is [True, False, False, False, False, True]
State prediction error at timestep 2977 is 0.012
Current timestep = 2978. State = [[-0.38711098  0.20347266]]. Action = [[ 0.        0.        0.       -0.842971]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 2978 is [True, False, False, False, False, True]
State prediction error at timestep 2978 is 0.012
Current timestep = 2979. State = [[-0.38711157  0.20347267]]. Action = [[0.         0.         0.         0.89448917]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 2979 is [True, False, False, False, False, True]
State prediction error at timestep 2979 is 0.012
Current timestep = 2980. State = [[-0.38711217  0.20347267]]. Action = [[ 0.          0.          0.         -0.04064888]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 2980 is [True, False, False, False, False, True]
State prediction error at timestep 2980 is 0.012
Current timestep = 2981. State = [[-0.38711277  0.20347267]]. Action = [[0.         0.         0.         0.90323555]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 2981 is [True, False, False, False, False, True]
State prediction error at timestep 2981 is 0.012
Current timestep = 2982. State = [[-0.38711333  0.20347267]]. Action = [[0.        0.        0.        0.3738817]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 2982 is [True, False, False, False, False, True]
State prediction error at timestep 2982 is 0.012
Current timestep = 2983. State = [[-0.38711393  0.20347267]]. Action = [[ 0.          0.          0.         -0.53049433]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 2983 is [True, False, False, False, False, True]
State prediction error at timestep 2983 is 0.012
Current timestep = 2984. State = [[-0.3871145   0.20347269]]. Action = [[ 0.         0.         0.        -0.9788873]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 2984 is [True, False, False, False, False, True]
State prediction error at timestep 2984 is 0.012
Current timestep = 2985. State = [[-0.38711506  0.20347269]]. Action = [[ 0.         0.         0.        -0.8850242]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 2985 is [True, False, False, False, False, True]
State prediction error at timestep 2985 is 0.012
Current timestep = 2986. State = [[-0.38711563  0.20347269]]. Action = [[0.         0.         0.         0.68752146]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 2986 is [True, False, False, False, False, True]
State prediction error at timestep 2986 is 0.012
Current timestep = 2987. State = [[-0.3871162   0.20347269]]. Action = [[ 0.          0.          0.         -0.72854906]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 2987 is [True, False, False, False, False, True]
State prediction error at timestep 2987 is 0.012
Current timestep = 2988. State = [[-0.38711673  0.20347269]]. Action = [[ 0.          0.          0.         -0.33557057]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 2988 is [True, False, False, False, False, True]
State prediction error at timestep 2988 is 0.012
Current timestep = 2989. State = [[-0.3871173   0.20347269]]. Action = [[0.         0.         0.         0.78585315]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 2989 is [True, False, False, False, False, True]
State prediction error at timestep 2989 is 0.012
Current timestep = 2990. State = [[-0.38711783  0.20347269]]. Action = [[ 0.          0.          0.         -0.65224767]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 2990 is [True, False, False, False, False, True]
State prediction error at timestep 2990 is 0.012
Current timestep = 2991. State = [[-0.38711837  0.20347269]]. Action = [[0.         0.         0.         0.60543704]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 2991 is [True, False, False, False, False, True]
State prediction error at timestep 2991 is 0.012
Current timestep = 2992. State = [[-0.3871189   0.20347269]]. Action = [[ 0.          0.          0.         -0.53654855]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 2992 is [True, False, False, False, False, True]
State prediction error at timestep 2992 is 0.012
Current timestep = 2993. State = [[-0.38711944  0.20347269]]. Action = [[ 0.          0.          0.         -0.22693217]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 2993 is [True, False, False, False, False, True]
State prediction error at timestep 2993 is 0.012
Current timestep = 2994. State = [[-0.38711998  0.20347269]]. Action = [[ 0.          0.          0.         -0.43575144]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 2994 is [True, False, False, False, False, True]
State prediction error at timestep 2994 is 0.012
Current timestep = 2995. State = [[-0.3871205   0.20347269]]. Action = [[0.        0.        0.        0.9433844]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 2995 is [True, False, False, False, False, True]
State prediction error at timestep 2995 is 0.012
Current timestep = 2996. State = [[-0.38712102  0.20347269]]. Action = [[0.         0.         0.         0.90343714]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 2996 is [True, False, False, False, False, True]
State prediction error at timestep 2996 is 0.012
Current timestep = 2997. State = [[-0.38712153  0.20347269]]. Action = [[0.         0.         0.         0.88315773]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 2997 is [True, False, False, False, False, True]
State prediction error at timestep 2997 is 0.012
Current timestep = 2998. State = [[-0.38712204  0.20347269]]. Action = [[0.         0.         0.         0.11141753]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 2998 is [True, False, False, False, False, True]
State prediction error at timestep 2998 is 0.012
Current timestep = 2999. State = [[-0.38712254  0.20347267]]. Action = [[0.        0.        0.        0.2868383]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 2999 is [True, False, False, False, False, True]
State prediction error at timestep 2999 is 0.012
Current timestep = 3000. State = [[-0.38712305  0.20347267]]. Action = [[ 0.         0.         0.        -0.1612637]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 3000 is [True, False, False, False, False, True]
State prediction error at timestep 3000 is 0.012
Current timestep = 3001. State = [[-0.38712355  0.20347267]]. Action = [[0.         0.         0.         0.12372327]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 3001 is [True, False, False, False, False, True]
State prediction error at timestep 3001 is 0.012
Current timestep = 3002. State = [[-0.38712403  0.20347267]]. Action = [[0.         0.         0.         0.01855946]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 3002 is [True, False, False, False, False, True]
State prediction error at timestep 3002 is 0.012
Current timestep = 3003. State = [[-0.38712454  0.20347266]]. Action = [[ 0.          0.          0.         -0.10993016]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 3003 is [True, False, False, False, False, True]
State prediction error at timestep 3003 is 0.012
Current timestep = 3004. State = [[-0.38712502  0.20347266]]. Action = [[0.        0.        0.        0.2685076]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 3004 is [True, False, False, False, False, True]
State prediction error at timestep 3004 is 0.012
Current timestep = 3005. State = [[-0.3871255   0.20347266]]. Action = [[0.         0.         0.         0.44162273]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 3005 is [True, False, False, False, False, True]
State prediction error at timestep 3005 is 0.012
Current timestep = 3006. State = [[-0.38712597  0.20347264]]. Action = [[ 0.          0.          0.         -0.55772704]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 3006 is [True, False, False, False, False, True]
State prediction error at timestep 3006 is 0.012
Current timestep = 3007. State = [[-0.38712645  0.20347264]]. Action = [[ 0.        0.        0.       -0.883029]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 3007 is [True, False, False, False, False, True]
State prediction error at timestep 3007 is 0.012
Current timestep = 3008. State = [[-0.38712692  0.20347264]]. Action = [[0.         0.         0.         0.29067743]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 3008 is [True, False, False, False, False, True]
State prediction error at timestep 3008 is 0.012
Current timestep = 3009. State = [[-0.38712737  0.20347263]]. Action = [[ 0.          0.          0.         -0.00214571]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 3009 is [True, False, False, False, False, True]
State prediction error at timestep 3009 is 0.012
Current timestep = 3010. State = [[-0.38712785  0.20347263]]. Action = [[0.         0.         0.         0.61070275]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 3010 is [True, False, False, False, False, True]
State prediction error at timestep 3010 is 0.012
Current timestep = 3011. State = [[-0.3871283   0.20347261]]. Action = [[0.         0.         0.         0.49877048]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 3011 is [True, False, False, False, False, True]
State prediction error at timestep 3011 is 0.012
Current timestep = 3012. State = [[-0.38712874  0.20347261]]. Action = [[0.        0.        0.        0.9637008]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 3012 is [True, False, False, False, False, True]
State prediction error at timestep 3012 is 0.012
Current timestep = 3013. State = [[-0.3871292  0.2034726]]. Action = [[0.         0.         0.         0.28332508]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 3013 is [True, False, False, False, False, True]
State prediction error at timestep 3013 is 0.012
Current timestep = 3014. State = [[-0.38712963  0.2034726 ]]. Action = [[ 0.          0.          0.         -0.92711425]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 3014 is [True, False, False, False, False, True]
State prediction error at timestep 3014 is 0.012
Current timestep = 3015. State = [[-0.38713008  0.20347258]]. Action = [[ 0.          0.          0.         -0.10440511]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 3015 is [True, False, False, False, False, True]
State prediction error at timestep 3015 is 0.012
Current timestep = 3016. State = [[-0.38713053  0.20347258]]. Action = [[0.         0.         0.         0.67327714]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 3016 is [True, False, False, False, False, True]
State prediction error at timestep 3016 is 0.012
Current timestep = 3017. State = [[-0.38713095  0.20347257]]. Action = [[ 0.         0.         0.        -0.6064128]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 3017 is [True, False, False, False, False, True]
State prediction error at timestep 3017 is 0.012
Current timestep = 3018. State = [[-0.3871314   0.20347255]]. Action = [[0.        0.        0.        0.5006182]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 3018 is [True, False, False, False, False, True]
State prediction error at timestep 3018 is 0.012
Current timestep = 3019. State = [[-0.3871318   0.20347255]]. Action = [[ 0.          0.          0.         -0.67540467]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 3019 is [True, False, False, False, False, True]
State prediction error at timestep 3019 is 0.012
Current timestep = 3020. State = [[-0.38713223  0.20347254]]. Action = [[0.        0.        0.        0.7929783]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 3020 is [True, False, False, False, False, True]
State prediction error at timestep 3020 is 0.012
Current timestep = 3021. State = [[-0.38713264  0.20347252]]. Action = [[0.         0.         0.         0.24706912]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 3021 is [True, False, False, False, False, True]
State prediction error at timestep 3021 is 0.012
Current timestep = 3022. State = [[-0.38713306  0.20347252]]. Action = [[0.         0.         0.         0.34534526]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 3022 is [True, False, False, False, False, True]
State prediction error at timestep 3022 is 0.012
Current timestep = 3023. State = [[-0.38713348  0.20347251]]. Action = [[ 0.          0.          0.         -0.30612946]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 3023 is [True, False, False, False, False, True]
State prediction error at timestep 3023 is 0.012
Current timestep = 3024. State = [[-0.3871339  0.2034725]]. Action = [[ 0.         0.         0.        -0.8069214]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 3024 is [True, False, False, False, False, True]
State prediction error at timestep 3024 is 0.012
Current timestep = 3025. State = [[-0.3871343  0.2034725]]. Action = [[0.         0.         0.         0.12079024]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 3025 is [True, False, False, False, False, True]
State prediction error at timestep 3025 is 0.012
Current timestep = 3026. State = [[-0.3871347   0.20347248]]. Action = [[ 0.          0.          0.         -0.18824422]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 3026 is [True, False, False, False, False, True]
State prediction error at timestep 3026 is 0.012
Current timestep = 3027. State = [[-0.38713512  0.20347247]]. Action = [[ 0.          0.          0.         -0.13668585]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 3027 is [True, False, False, False, False, True]
State prediction error at timestep 3027 is 0.012
Current timestep = 3028. State = [[-0.3871355   0.20347245]]. Action = [[0.        0.        0.        0.8888705]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 3028 is [True, False, False, False, False, True]
State prediction error at timestep 3028 is 0.012
Current timestep = 3029. State = [[-0.3871359   0.20347244]]. Action = [[0.        0.        0.        0.4844358]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 3029 is [True, False, False, False, False, True]
State prediction error at timestep 3029 is 0.012
Current timestep = 3030. State = [[-0.38713628  0.20347244]]. Action = [[ 0.          0.          0.         -0.47395617]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 3030 is [True, False, False, False, False, True]
State prediction error at timestep 3030 is 0.012
Current timestep = 3031. State = [[-0.38713667  0.20347242]]. Action = [[0.         0.         0.         0.62059474]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 3031 is [True, False, False, False, False, True]
State prediction error at timestep 3031 is 0.012
Current timestep = 3032. State = [[-0.38713706  0.2034724 ]]. Action = [[0.        0.        0.        0.5449245]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 3032 is [True, False, False, False, False, True]
State prediction error at timestep 3032 is 0.012
Current timestep = 3033. State = [[-0.38713744  0.20347239]]. Action = [[0.         0.         0.         0.75128114]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 3033 is [True, False, False, False, False, True]
State prediction error at timestep 3033 is 0.012
Current timestep = 3034. State = [[-0.3871378   0.20347238]]. Action = [[0.        0.        0.        0.9034884]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 3034 is [True, False, False, False, False, True]
State prediction error at timestep 3034 is 0.012
Current timestep = 3035. State = [[-0.3871382   0.20347236]]. Action = [[ 0.          0.          0.         -0.08312005]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 3035 is [True, False, False, False, False, True]
State prediction error at timestep 3035 is 0.012
Current timestep = 3036. State = [[-0.38713855  0.20347235]]. Action = [[0.         0.         0.         0.46257043]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 3036 is [True, False, False, False, False, True]
State prediction error at timestep 3036 is 0.012
Current timestep = 3037. State = [[-0.3871389   0.20347233]]. Action = [[ 0.          0.          0.         -0.27562672]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 3037 is [True, False, False, False, False, True]
State prediction error at timestep 3037 is 0.012
Current timestep = 3038. State = [[-0.3871393   0.20347232]]. Action = [[0.        0.        0.        0.9358301]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 3038 is [True, False, False, False, False, True]
State prediction error at timestep 3038 is 0.012
Current timestep = 3039. State = [[-0.38713965  0.2034723 ]]. Action = [[0.         0.         0.         0.45098186]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 3039 is [True, False, False, False, False, True]
State prediction error at timestep 3039 is 0.012
Current timestep = 3040. State = [[-0.38714     0.20347229]]. Action = [[ 0.         0.         0.        -0.7048223]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 3040 is [True, False, False, False, False, True]
State prediction error at timestep 3040 is 0.012
Current timestep = 3041. State = [[-0.38714036  0.20347227]]. Action = [[ 0.          0.          0.         -0.05266768]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 3041 is [True, False, False, False, False, True]
State prediction error at timestep 3041 is 0.012
Current timestep = 3042. State = [[-0.3871407   0.20347226]]. Action = [[0.         0.         0.         0.91018105]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 3042 is [True, False, False, False, False, True]
State prediction error at timestep 3042 is 0.012
Current timestep = 3043. State = [[-0.38714105  0.20347224]]. Action = [[ 0.          0.          0.         -0.02972215]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 3043 is [True, False, False, False, False, True]
State prediction error at timestep 3043 is 0.012
Current timestep = 3044. State = [[-0.3871414   0.20347223]]. Action = [[ 0.         0.         0.        -0.6326675]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 3044 is [True, False, False, False, False, True]
State prediction error at timestep 3044 is 0.012
Current timestep = 3045. State = [[-0.38714173  0.20347221]]. Action = [[0.        0.        0.        0.5968399]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 3045 is [True, False, False, False, False, True]
State prediction error at timestep 3045 is 0.012
Current timestep = 3046. State = [[-0.3871421   0.20347218]]. Action = [[ 0.         0.         0.        -0.5727654]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 3046 is [True, False, False, False, False, True]
State prediction error at timestep 3046 is 0.012
Current timestep = 3047. State = [[-0.38714242  0.20347217]]. Action = [[0.         0.         0.         0.08184135]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 3047 is [True, False, False, False, False, True]
State prediction error at timestep 3047 is 0.012
Current timestep = 3048. State = [[-0.38714275  0.20347215]]. Action = [[ 0.          0.          0.         -0.78586334]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 3048 is [True, False, False, False, False, True]
State prediction error at timestep 3048 is 0.012
Current timestep = 3049. State = [[-0.38714308  0.20347214]]. Action = [[ 0.          0.          0.         -0.06553704]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 3049 is [True, False, False, False, False, True]
State prediction error at timestep 3049 is 0.012
Current timestep = 3050. State = [[-0.3871434   0.20347212]]. Action = [[ 0.          0.          0.         -0.95160025]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 3050 is [True, False, False, False, False, True]
State prediction error at timestep 3050 is 0.012
Current timestep = 3051. State = [[-0.38714373  0.2034721 ]]. Action = [[ 0.          0.          0.         -0.07664555]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 3051 is [True, False, False, False, False, True]
State prediction error at timestep 3051 is 0.012
Current timestep = 3052. State = [[-0.38714406  0.20347208]]. Action = [[ 0.          0.          0.         -0.23227036]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 3052 is [True, False, False, False, False, True]
State prediction error at timestep 3052 is 0.012
Current timestep = 3053. State = [[-0.3871444   0.20347206]]. Action = [[ 0.         0.         0.        -0.3531705]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 3053 is [True, False, False, False, False, True]
State prediction error at timestep 3053 is 0.012
Current timestep = 3054. State = [[-0.38714468  0.20347205]]. Action = [[0.         0.         0.         0.07048833]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 3054 is [True, False, False, False, False, True]
State prediction error at timestep 3054 is 0.012
Current timestep = 3055. State = [[-0.387145    0.20347202]]. Action = [[0.         0.         0.         0.49505663]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 3055 is [True, False, False, False, False, True]
State prediction error at timestep 3055 is 0.012
Current timestep = 3056. State = [[-0.3871453  0.203472 ]]. Action = [[ 0.          0.          0.         -0.34401727]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 3056 is [True, False, False, False, False, True]
State prediction error at timestep 3056 is 0.012
Current timestep = 3057. State = [[-0.38714564  0.20347199]]. Action = [[ 0.         0.         0.        -0.5598531]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 3057 is [True, False, False, False, False, True]
State prediction error at timestep 3057 is 0.012
Current timestep = 3058. State = [[-0.38714594  0.20347196]]. Action = [[0.         0.         0.         0.52341294]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 3058 is [True, False, False, False, False, True]
State prediction error at timestep 3058 is 0.012
Current timestep = 3059. State = [[-0.38714623  0.20347194]]. Action = [[ 0.          0.          0.         -0.28153813]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 3059 is [True, False, False, False, False, True]
State prediction error at timestep 3059 is 0.012
Current timestep = 3060. State = [[-0.38714653  0.20347193]]. Action = [[ 0.         0.         0.        -0.9115642]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 3060 is [True, False, False, False, False, True]
State prediction error at timestep 3060 is 0.012
Current timestep = 3061. State = [[-0.38714683  0.2034719 ]]. Action = [[ 0.          0.          0.         -0.58210486]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 3061 is [True, False, False, False, False, True]
State prediction error at timestep 3061 is 0.012
Current timestep = 3062. State = [[-0.38714713  0.20347188]]. Action = [[ 0.         0.         0.        -0.3419789]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 3062 is [True, False, False, False, False, True]
State prediction error at timestep 3062 is 0.012
Current timestep = 3063. State = [[-0.38714743  0.20347185]]. Action = [[ 0.          0.          0.         -0.95264125]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 3063 is [True, False, False, False, False, True]
State prediction error at timestep 3063 is 0.012
Current timestep = 3064. State = [[-0.38714772  0.20347184]]. Action = [[0.         0.         0.         0.45762098]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 3064 is [True, False, False, False, False, True]
State prediction error at timestep 3064 is 0.012
Current timestep = 3065. State = [[-0.38714802  0.20347181]]. Action = [[ 0.         0.         0.        -0.6755893]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 3065 is [True, False, False, False, False, True]
State prediction error at timestep 3065 is 0.012
Current timestep = 3066. State = [[-0.3871483  0.2034718]]. Action = [[0.         0.         0.         0.07737243]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 3066 is [True, False, False, False, False, True]
State prediction error at timestep 3066 is 0.012
Current timestep = 3067. State = [[-0.3871486   0.20347178]]. Action = [[ 0.          0.          0.         -0.14180195]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 3067 is [True, False, False, False, False, True]
State prediction error at timestep 3067 is 0.012
Current timestep = 3068. State = [[-0.38714886  0.20347175]]. Action = [[ 0.         0.         0.        -0.6567737]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 3068 is [True, False, False, False, False, True]
State prediction error at timestep 3068 is 0.012
Current timestep = 3069. State = [[-0.38714916  0.20347172]]. Action = [[0.         0.         0.         0.96020854]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 3069 is [True, False, False, False, False, True]
State prediction error at timestep 3069 is 0.012
Current timestep = 3070. State = [[-0.38714942  0.2034717 ]]. Action = [[0.         0.         0.         0.27133417]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 3070 is [True, False, False, False, False, True]
State prediction error at timestep 3070 is 0.012
Current timestep = 3071. State = [[-0.3871497   0.20347168]]. Action = [[0.         0.         0.         0.41072154]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 3071 is [True, False, False, False, False, True]
State prediction error at timestep 3071 is 0.012
Current timestep = 3072. State = [[-0.38714996  0.20347166]]. Action = [[ 0.          0.          0.         -0.39239675]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 3072 is [True, False, False, False, False, True]
State prediction error at timestep 3072 is 0.012
Current timestep = 3073. State = [[-0.38715023  0.20347163]]. Action = [[0.        0.        0.        0.6759033]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 3073 is [True, False, False, False, False, True]
State prediction error at timestep 3073 is 0.012
Current timestep = 3074. State = [[-0.3871505   0.20347162]]. Action = [[0.        0.        0.        0.7546712]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 3074 is [True, False, False, False, False, True]
State prediction error at timestep 3074 is 0.012
Current timestep = 3075. State = [[-0.38715076  0.20347159]]. Action = [[ 0.         0.         0.        -0.7972009]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 3075 is [True, False, False, False, False, True]
State prediction error at timestep 3075 is 0.012
Current timestep = 3076. State = [[-0.38715103  0.20347156]]. Action = [[ 0.          0.          0.         -0.98557454]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 3076 is [True, False, False, False, False, True]
State prediction error at timestep 3076 is 0.012
Current timestep = 3077. State = [[-0.3871513   0.20347154]]. Action = [[ 0.          0.          0.         -0.99504375]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 3077 is [True, False, False, False, False, True]
State prediction error at timestep 3077 is 0.012
Current timestep = 3078. State = [[-0.38715154  0.20347151]]. Action = [[0.        0.        0.        0.6451957]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 3078 is [True, False, False, False, False, True]
State prediction error at timestep 3078 is 0.012
Current timestep = 3079. State = [[-0.3871518  0.2034715]]. Action = [[ 0.         0.         0.        -0.6074826]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 3079 is [True, False, False, False, False, True]
State prediction error at timestep 3079 is 0.012
Current timestep = 3080. State = [[-0.38715208  0.20347147]]. Action = [[ 0.         0.         0.        -0.9651902]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 3080 is [True, False, False, False, False, True]
State prediction error at timestep 3080 is 0.012
Current timestep = 3081. State = [[-0.3871523   0.20347144]]. Action = [[0.        0.        0.        0.2280916]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 3081 is [True, False, False, False, False, True]
State prediction error at timestep 3081 is 0.012
Current timestep = 3082. State = [[-0.38715255  0.2034714 ]]. Action = [[ 0.          0.          0.         -0.01878327]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 3082 is [True, False, False, False, False, True]
State prediction error at timestep 3082 is 0.012
Current timestep = 3083. State = [[-0.38715282  0.20347139]]. Action = [[ 0.         0.         0.        -0.9493933]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 3083 is [True, False, False, False, False, True]
State prediction error at timestep 3083 is 0.012
Current timestep = 3084. State = [[-0.38715306  0.20347136]]. Action = [[ 0.          0.          0.         -0.40119278]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 3084 is [True, False, False, False, False, True]
State prediction error at timestep 3084 is 0.012
Current timestep = 3085. State = [[-0.3871533   0.20347133]]. Action = [[0.         0.         0.         0.65533483]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 3085 is [True, False, False, False, False, True]
State prediction error at timestep 3085 is 0.012
Current timestep = 3086. State = [[-0.38715354  0.20347132]]. Action = [[0.         0.         0.         0.24552739]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 3086 is [True, False, False, False, False, True]
State prediction error at timestep 3086 is 0.012
Current timestep = 3087. State = [[-0.38715377  0.20347129]]. Action = [[0.        0.        0.        0.9036751]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 3087 is [True, False, False, False, False, True]
State prediction error at timestep 3087 is 0.012
Current timestep = 3088. State = [[-0.387154    0.20347126]]. Action = [[ 0.          0.          0.         -0.64698994]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 3088 is [True, False, False, False, False, True]
State prediction error at timestep 3088 is 0.012
Current timestep = 3089. State = [[-0.38715425  0.20347123]]. Action = [[0.        0.        0.        0.6241245]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 3089 is [True, False, False, False, False, True]
State prediction error at timestep 3089 is 0.012
Current timestep = 3090. State = [[-0.3871545  0.2034712]]. Action = [[ 0.          0.          0.         -0.02315265]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 3090 is [True, False, False, False, False, True]
State prediction error at timestep 3090 is 0.012
Current timestep = 3091. State = [[-0.38715473  0.20347118]]. Action = [[0.         0.         0.         0.72509146]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 3091 is [True, False, False, False, False, True]
State prediction error at timestep 3091 is 0.012
Current timestep = 3092. State = [[-0.38715494  0.20347115]]. Action = [[0.        0.        0.        0.3516581]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 3092 is [True, False, False, False, False, True]
State prediction error at timestep 3092 is 0.012
Current timestep = 3093. State = [[-0.38715518  0.20347112]]. Action = [[ 0.          0.          0.         -0.45142925]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 3093 is [True, False, False, False, False, True]
State prediction error at timestep 3093 is 0.012
Current timestep = 3094. State = [[-0.3871554  0.2034711]]. Action = [[0.       0.       0.       0.479208]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 3094 is [True, False, False, False, False, True]
State prediction error at timestep 3094 is 0.012
Current timestep = 3095. State = [[-0.38715562  0.20347106]]. Action = [[ 0.          0.          0.         -0.87134117]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 3095 is [True, False, False, False, False, True]
State prediction error at timestep 3095 is 0.012
Current timestep = 3096. State = [[-0.38715586  0.20347103]]. Action = [[0.        0.        0.        0.4553306]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 3096 is [True, False, False, False, False, True]
State prediction error at timestep 3096 is 0.012
Current timestep = 3097. State = [[-0.38715607  0.203471  ]]. Action = [[ 0.          0.          0.         -0.81074315]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 3097 is [True, False, False, False, False, True]
State prediction error at timestep 3097 is 0.012
Current timestep = 3098. State = [[-0.38715628  0.20347098]]. Action = [[ 0.          0.          0.         -0.12414968]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 3098 is [True, False, False, False, False, True]
State prediction error at timestep 3098 is 0.012
Current timestep = 3099. State = [[-0.3871565   0.20347095]]. Action = [[0.         0.         0.         0.14407527]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 3099 is [True, False, False, False, False, True]
State prediction error at timestep 3099 is 0.012
Current timestep = 3100. State = [[-0.38715672  0.20347093]]. Action = [[0.         0.         0.         0.62120366]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 3100 is [True, False, False, False, False, True]
State prediction error at timestep 3100 is 0.012
Current timestep = 3101. State = [[-0.38715693  0.2034709 ]]. Action = [[0.        0.        0.        0.7386234]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 3101 is [True, False, False, False, False, True]
State prediction error at timestep 3101 is 0.012
Current timestep = 3102. State = [[-0.38715714  0.20347087]]. Action = [[0.        0.        0.        0.5379417]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 3102 is [True, False, False, False, False, True]
State prediction error at timestep 3102 is 0.012
Current timestep = 3103. State = [[-0.38715735  0.20347084]]. Action = [[0.        0.        0.        0.8647542]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 3103 is [True, False, False, False, False, True]
State prediction error at timestep 3103 is 0.012
Current timestep = 3104. State = [[-0.38715756  0.20347081]]. Action = [[0.         0.         0.         0.54914474]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 3104 is [True, False, False, False, False, True]
State prediction error at timestep 3104 is 0.012
Current timestep = 3105. State = [[-0.38715777  0.20347078]]. Action = [[0.         0.         0.         0.22239625]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 3105 is [True, False, False, False, False, True]
State prediction error at timestep 3105 is 0.012
Current timestep = 3106. State = [[-0.38715795  0.20347075]]. Action = [[ 0.          0.          0.         -0.68296474]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 3106 is [True, False, False, False, False, True]
State prediction error at timestep 3106 is 0.012
Current timestep = 3107. State = [[-0.38715816  0.20347072]]. Action = [[0.        0.        0.        0.8252244]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 3107 is [True, False, False, False, False, True]
State prediction error at timestep 3107 is 0.012
Current timestep = 3108. State = [[-0.38715836  0.20347069]]. Action = [[0.        0.        0.        0.6183559]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 3108 is [True, False, False, False, False, True]
State prediction error at timestep 3108 is 0.012
Current timestep = 3109. State = [[-0.38715857  0.20347066]]. Action = [[ 0.          0.          0.         -0.95989054]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 3109 is [True, False, False, False, False, True]
State prediction error at timestep 3109 is 0.012
Current timestep = 3110. State = [[-0.38715875  0.20347063]]. Action = [[ 0.         0.         0.        -0.9965943]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 3110 is [True, False, False, False, False, True]
State prediction error at timestep 3110 is 0.012
Current timestep = 3111. State = [[-0.38715896  0.20347059]]. Action = [[0.         0.         0.         0.44014096]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 3111 is [True, False, False, False, False, True]
State prediction error at timestep 3111 is 0.012
Current timestep = 3112. State = [[-0.38715914  0.20347056]]. Action = [[0.        0.        0.        0.6840985]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 3112 is [True, False, False, False, False, True]
State prediction error at timestep 3112 is 0.012
Current timestep = 3113. State = [[-0.38715935  0.20347053]]. Action = [[0.         0.         0.         0.21599197]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 3113 is [True, False, False, False, False, True]
State prediction error at timestep 3113 is 0.012
Current timestep = 3114. State = [[-0.38715953  0.2034705 ]]. Action = [[ 0.         0.         0.        -0.0818572]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 3114 is [True, False, False, False, False, True]
State prediction error at timestep 3114 is 0.012
Current timestep = 3115. State = [[-0.3871597   0.20347047]]. Action = [[ 0.          0.          0.         -0.47805238]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 3115 is [True, False, False, False, False, True]
State prediction error at timestep 3115 is 0.012
Current timestep = 3116. State = [[-0.38715988  0.20347044]]. Action = [[0.         0.         0.         0.59841895]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 3116 is [True, False, False, False, False, True]
State prediction error at timestep 3116 is 0.012
Current timestep = 3117. State = [[-0.3871601   0.20347041]]. Action = [[0.         0.         0.         0.37302268]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 3117 is [True, False, False, False, False, True]
State prediction error at timestep 3117 is 0.012
Current timestep = 3118. State = [[-0.38716027  0.20347038]]. Action = [[0.         0.         0.         0.53740215]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 3118 is [True, False, False, False, False, True]
State prediction error at timestep 3118 is 0.012
Current timestep = 3119. State = [[-0.38716045  0.20347035]]. Action = [[0.         0.         0.         0.56939363]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 3119 is [True, False, False, False, False, True]
State prediction error at timestep 3119 is 0.012
Current timestep = 3120. State = [[-0.38716063  0.2034703 ]]. Action = [[0.         0.         0.         0.97248507]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 3120 is [True, False, False, False, False, True]
State prediction error at timestep 3120 is 0.012
Current timestep = 3121. State = [[-0.3871608   0.20347027]]. Action = [[0.         0.         0.         0.02954471]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 3121 is [True, False, False, False, False, True]
State prediction error at timestep 3121 is 0.012
Current timestep = 3122. State = [[-0.387161    0.20347025]]. Action = [[0.         0.         0.         0.31864512]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 3122 is [True, False, False, False, False, True]
State prediction error at timestep 3122 is 0.012
Current timestep = 3123. State = [[-0.38716117  0.20347022]]. Action = [[0.         0.         0.         0.20018637]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 3123 is [True, False, False, False, False, True]
State prediction error at timestep 3123 is 0.012
Current timestep = 3124. State = [[-0.38716134  0.20347019]]. Action = [[0.         0.         0.         0.46462595]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 3124 is [True, False, False, False, False, True]
State prediction error at timestep 3124 is 0.012
Current timestep = 3125. State = [[-0.3871615   0.20347014]]. Action = [[0.       0.       0.       0.740934]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 3125 is [True, False, False, False, False, True]
State prediction error at timestep 3125 is 0.012
Current timestep = 3126. State = [[-0.38716167  0.20347011]]. Action = [[0.        0.        0.        0.9216943]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 3126 is [True, False, False, False, False, True]
State prediction error at timestep 3126 is 0.012
Current timestep = 3127. State = [[-0.38716185  0.20347008]]. Action = [[0.         0.         0.         0.46341133]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 3127 is [True, False, False, False, False, True]
State prediction error at timestep 3127 is 0.012
Current timestep = 3128. State = [[-0.387162    0.20347005]]. Action = [[0.        0.        0.        0.6541624]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 3128 is [True, False, False, False, False, True]
State prediction error at timestep 3128 is 0.012
Current timestep = 3129. State = [[-0.38716218  0.20347   ]]. Action = [[ 0.          0.          0.         -0.27398694]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 3129 is [True, False, False, False, False, True]
State prediction error at timestep 3129 is 0.012
Current timestep = 3130. State = [[-0.38716233  0.20346998]]. Action = [[0.        0.        0.        0.5263139]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 3130 is [True, False, False, False, False, True]
State prediction error at timestep 3130 is 0.012
Current timestep = 3131. State = [[-0.3871625   0.20346995]]. Action = [[ 0.          0.          0.         -0.64913946]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 3131 is [True, False, False, False, False, True]
State prediction error at timestep 3131 is 0.012
Current timestep = 3132. State = [[-0.38716266  0.20346992]]. Action = [[ 0.          0.          0.         -0.71617323]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 3132 is [True, False, False, False, False, True]
State prediction error at timestep 3132 is 0.012
Current timestep = 3133. State = [[-0.38716283  0.20346987]]. Action = [[0.        0.        0.        0.7310289]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 3133 is [True, False, False, False, False, True]
State prediction error at timestep 3133 is 0.012
Current timestep = 3134. State = [[-0.38716298  0.20346984]]. Action = [[0.         0.         0.         0.45218885]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 3134 is [True, False, False, False, False, True]
State prediction error at timestep 3134 is 0.012
Current timestep = 3135. State = [[-0.38716313  0.20346981]]. Action = [[0.         0.         0.         0.93676484]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 3135 is [True, False, False, False, False, True]
State prediction error at timestep 3135 is 0.012
Current timestep = 3136. State = [[-0.3871633   0.20346977]]. Action = [[ 0.          0.          0.         -0.10310102]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 3136 is [True, False, False, False, False, True]
State prediction error at timestep 3136 is 0.012
Current timestep = 3137. State = [[-0.38716346  0.20346974]]. Action = [[ 0.          0.          0.         -0.30895114]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 3137 is [True, False, False, False, False, True]
State prediction error at timestep 3137 is 0.012
Current timestep = 3138. State = [[-0.3871636   0.20346971]]. Action = [[ 0.         0.         0.        -0.5597426]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 3138 is [True, False, False, False, False, True]
State prediction error at timestep 3138 is 0.012
Current timestep = 3139. State = [[-0.38716376  0.20346966]]. Action = [[ 0.         0.         0.        -0.6619484]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 3139 is [True, False, False, False, False, True]
State prediction error at timestep 3139 is 0.012
Current timestep = 3140. State = [[-0.3871639   0.20346963]]. Action = [[0.        0.        0.        0.1502254]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 3140 is [True, False, False, False, False, True]
State prediction error at timestep 3140 is 0.012
Current timestep = 3141. State = [[-0.38716406  0.2034696 ]]. Action = [[ 0.          0.          0.         -0.80698866]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 3141 is [True, False, False, False, False, True]
State prediction error at timestep 3141 is 0.012
Current timestep = 3142. State = [[-0.3871642   0.20346956]]. Action = [[0.         0.         0.         0.23845732]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 3142 is [True, False, False, False, False, True]
State prediction error at timestep 3142 is 0.012
Current timestep = 3143. State = [[-0.38716435  0.20346953]]. Action = [[0.        0.        0.        0.8560039]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 3143 is [True, False, False, False, False, True]
State prediction error at timestep 3143 is 0.012
Current timestep = 3144. State = [[-0.3871645   0.20346949]]. Action = [[ 0.          0.          0.         -0.08671427]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 3144 is [True, False, False, False, False, True]
State prediction error at timestep 3144 is 0.012
Current timestep = 3145. State = [[-0.38716465  0.20346946]]. Action = [[ 0.         0.         0.        -0.4086957]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 3145 is [True, False, False, False, False, True]
State prediction error at timestep 3145 is 0.012
Current timestep = 3146. State = [[-0.3871648   0.20346943]]. Action = [[ 0.         0.         0.        -0.4481604]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 3146 is [True, False, False, False, False, True]
State prediction error at timestep 3146 is 0.012
Current timestep = 3147. State = [[-0.38716492  0.20346938]]. Action = [[0.         0.         0.         0.72962356]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 3147 is [True, False, False, False, False, True]
State prediction error at timestep 3147 is 0.012
Current timestep = 3148. State = [[-0.38716507  0.20346935]]. Action = [[ 0.          0.          0.         -0.17479962]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 3148 is [True, False, False, False, False, True]
State prediction error at timestep 3148 is 0.012
Current timestep = 3149. State = [[-0.38716522  0.2034693 ]]. Action = [[0.        0.        0.        0.9373827]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 3149 is [True, False, False, False, False, True]
State prediction error at timestep 3149 is 0.012
Current timestep = 3150. State = [[-0.38716534  0.20346928]]. Action = [[0.        0.        0.        0.7888465]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 3150 is [True, False, False, False, False, True]
State prediction error at timestep 3150 is 0.012
Current timestep = 3151. State = [[-0.3871655   0.20346923]]. Action = [[0.         0.         0.         0.70701504]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 3151 is [True, False, False, False, False, True]
State prediction error at timestep 3151 is 0.012
Current timestep = 3152. State = [[-0.38716564  0.2034692 ]]. Action = [[ 0.          0.          0.         -0.23082817]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 3152 is [True, False, False, False, False, True]
State prediction error at timestep 3152 is 0.012
Current timestep = 3153. State = [[-0.38716576  0.20346916]]. Action = [[0.        0.        0.        0.0924499]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 3153 is [True, False, False, False, False, True]
State prediction error at timestep 3153 is 0.012
Current timestep = 3154. State = [[-0.3871659   0.20346913]]. Action = [[0.         0.         0.         0.84505653]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 3154 is [True, False, False, False, False, True]
State prediction error at timestep 3154 is 0.012
Current timestep = 3155. State = [[-0.38716602  0.20346908]]. Action = [[ 0.         0.         0.        -0.6424367]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 3155 is [True, False, False, False, False, True]
State prediction error at timestep 3155 is 0.012
Current timestep = 3156. State = [[-0.38716614  0.20346905]]. Action = [[ 0.          0.          0.         -0.50052273]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 3156 is [True, False, False, False, False, True]
State prediction error at timestep 3156 is 0.012
Current timestep = 3157. State = [[-0.3871663   0.20346901]]. Action = [[0.        0.        0.        0.4182731]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 3157 is [True, False, False, False, False, True]
State prediction error at timestep 3157 is 0.012
Current timestep = 3158. State = [[-0.3871664   0.20346898]]. Action = [[0.        0.        0.        0.8181045]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 3158 is [True, False, False, False, False, True]
State prediction error at timestep 3158 is 0.012
Current timestep = 3159. State = [[-0.38716653  0.20346893]]. Action = [[0.         0.         0.         0.21261096]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 3159 is [True, False, False, False, False, True]
State prediction error at timestep 3159 is 0.012
Current timestep = 3160. State = [[-0.38716668  0.2034689 ]]. Action = [[0.         0.         0.         0.06440413]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 3160 is [True, False, False, False, False, True]
State prediction error at timestep 3160 is 0.012
Current timestep = 3161. State = [[-0.3871668   0.20346886]]. Action = [[ 0.         0.         0.        -0.6930645]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 3161 is [True, False, False, False, False, True]
State prediction error at timestep 3161 is 0.012
Current timestep = 3162. State = [[-0.38716692  0.20346883]]. Action = [[ 0.         0.         0.        -0.9610242]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 3162 is [True, False, False, False, False, True]
State prediction error at timestep 3162 is 0.012
Current timestep = 3163. State = [[-0.38716704  0.20346878]]. Action = [[0.        0.        0.        0.9720688]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 3163 is [True, False, False, False, False, True]
State prediction error at timestep 3163 is 0.012
Current timestep = 3164. State = [[-0.38716716  0.20346875]]. Action = [[0.         0.         0.         0.88839746]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 3164 is [True, False, False, False, False, True]
State prediction error at timestep 3164 is 0.012
Current timestep = 3165. State = [[-0.38716727  0.20346871]]. Action = [[ 0.          0.          0.         -0.83859754]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 3165 is [True, False, False, False, False, True]
State prediction error at timestep 3165 is 0.012
Current timestep = 3166. State = [[-0.3871674   0.20346868]]. Action = [[0.        0.        0.        0.0907892]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 3166 is [True, False, False, False, False, True]
State prediction error at timestep 3166 is 0.012
Current timestep = 3167. State = [[-0.3871675   0.20346864]]. Action = [[ 0.         0.         0.        -0.9224766]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 3167 is [True, False, False, False, False, True]
State prediction error at timestep 3167 is 0.012
Current timestep = 3168. State = [[-0.38716763  0.20346859]]. Action = [[ 0.          0.          0.         -0.16004479]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 3168 is [True, False, False, False, False, True]
State prediction error at timestep 3168 is 0.012
Current timestep = 3169. State = [[-0.38716775  0.20346856]]. Action = [[ 0.         0.         0.        -0.1924786]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 3169 is [True, False, False, False, False, True]
State prediction error at timestep 3169 is 0.012
Current timestep = 3170. State = [[-0.38716787  0.20346852]]. Action = [[0.         0.         0.         0.46409357]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 3170 is [True, False, False, False, False, True]
State prediction error at timestep 3170 is 0.012
Current timestep = 3171. State = [[-0.387168    0.20346849]]. Action = [[ 0.          0.          0.         -0.71192735]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 3171 is [True, False, False, False, False, True]
State prediction error at timestep 3171 is 0.012
Current timestep = 3172. State = [[-0.3871681   0.20346844]]. Action = [[ 0.         0.         0.        -0.2952494]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 3172 is [True, False, False, False, False, True]
State prediction error at timestep 3172 is 0.012
Current timestep = 3173. State = [[-0.38716823  0.2034684 ]]. Action = [[0.         0.         0.         0.20441222]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 3173 is [True, False, False, False, False, True]
State prediction error at timestep 3173 is 0.012
Current timestep = 3174. State = [[-0.38716832  0.20346837]]. Action = [[0.         0.         0.         0.04786789]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 3174 is [True, False, False, False, False, True]
State prediction error at timestep 3174 is 0.012
Current timestep = 3175. State = [[-0.38716844  0.20346832]]. Action = [[0.         0.         0.         0.04989386]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 3175 is [True, False, False, False, False, True]
State prediction error at timestep 3175 is 0.012
Current timestep = 3176. State = [[-0.38716856  0.20346828]]. Action = [[0.         0.         0.         0.70061374]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 3176 is [True, False, False, False, False, True]
State prediction error at timestep 3176 is 0.012
Current timestep = 3177. State = [[-0.38716865  0.20346825]]. Action = [[0.         0.         0.         0.16083813]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 3177 is [True, False, False, False, False, True]
State prediction error at timestep 3177 is 0.012
Current timestep = 3178. State = [[-0.38716877  0.2034682 ]]. Action = [[ 0.          0.          0.         -0.85612935]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 3178 is [True, False, False, False, False, True]
State prediction error at timestep 3178 is 0.012
Current timestep = 3179. State = [[-0.38716888  0.20346816]]. Action = [[0.         0.         0.         0.06825483]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 3179 is [True, False, False, False, False, True]
State prediction error at timestep 3179 is 0.012
Current timestep = 3180. State = [[-0.38716897  0.20346813]]. Action = [[0.        0.        0.        0.8885622]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 3180 is [True, False, False, False, False, True]
State prediction error at timestep 3180 is 0.012
Current timestep = 3181. State = [[-0.3871691   0.20346808]]. Action = [[0.         0.         0.         0.12377799]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 3181 is [True, False, False, False, False, True]
State prediction error at timestep 3181 is 0.012
Current timestep = 3182. State = [[-0.38716918  0.20346804]]. Action = [[ 0.          0.          0.         -0.55174696]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 3182 is [True, False, False, False, False, True]
State prediction error at timestep 3182 is 0.012
Current timestep = 3183. State = [[-0.3871693   0.20346801]]. Action = [[0.         0.         0.         0.48406172]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 3183 is [True, False, False, False, False, True]
State prediction error at timestep 3183 is 0.012
Current timestep = 3184. State = [[-0.3871694   0.20346797]]. Action = [[ 0.        0.        0.       -0.907294]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 3184 is [True, False, False, False, False, True]
State prediction error at timestep 3184 is 0.012
Current timestep = 3185. State = [[-0.38716948  0.20346792]]. Action = [[ 0.         0.         0.        -0.8604153]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 3185 is [True, False, False, False, False, True]
State prediction error at timestep 3185 is 0.012
Current timestep = 3186. State = [[-0.3871696   0.20346788]]. Action = [[ 0.          0.          0.         -0.08014882]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 3186 is [True, False, False, False, False, True]
State prediction error at timestep 3186 is 0.012
Current timestep = 3187. State = [[-0.3871697   0.20346785]]. Action = [[ 0.          0.          0.         -0.48500037]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 3187 is [True, False, False, False, False, True]
State prediction error at timestep 3187 is 0.012
Current timestep = 3188. State = [[-0.38716978  0.2034678 ]]. Action = [[ 0.          0.          0.         -0.78738886]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 3188 is [True, False, False, False, False, True]
State prediction error at timestep 3188 is 0.012
Current timestep = 3189. State = [[-0.3871699   0.20346776]]. Action = [[0.        0.        0.        0.6212666]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 3189 is [True, False, False, False, False, True]
State prediction error at timestep 3189 is 0.012
Current timestep = 3190. State = [[-0.38717     0.20346773]]. Action = [[0.         0.         0.         0.91503215]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 3190 is [True, False, False, False, False, True]
State prediction error at timestep 3190 is 0.012
Current timestep = 3191. State = [[-0.38717008  0.20346768]]. Action = [[ 0.          0.          0.         -0.10841423]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 3191 is [True, False, False, False, False, True]
State prediction error at timestep 3191 is 0.012
Current timestep = 3192. State = [[-0.38717017  0.20346764]]. Action = [[ 0.         0.         0.        -0.3163957]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 3192 is [True, False, False, False, False, True]
State prediction error at timestep 3192 is 0.012
Current timestep = 3193. State = [[-0.38717028  0.2034676 ]]. Action = [[0.         0.         0.         0.70959866]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 3193 is [True, False, False, False, False, True]
State prediction error at timestep 3193 is 0.012
Current timestep = 3194. State = [[-0.38717037  0.20346755]]. Action = [[0.        0.        0.        0.8389485]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 3194 is [True, False, False, False, False, True]
State prediction error at timestep 3194 is 0.012
Current timestep = 3195. State = [[-0.38717046  0.20346752]]. Action = [[0.        0.        0.        0.2017901]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 3195 is [True, False, False, False, False, True]
State prediction error at timestep 3195 is 0.012
Current timestep = 3196. State = [[-0.38717055  0.20346747]]. Action = [[ 0.         0.         0.        -0.8001256]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 3196 is [True, False, False, False, False, True]
State prediction error at timestep 3196 is 0.012
Current timestep = 3197. State = [[-0.38717064  0.20346743]]. Action = [[0.         0.         0.         0.72312367]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 3197 is [True, False, False, False, False, True]
State prediction error at timestep 3197 is 0.012
Current timestep = 3198. State = [[-0.38717073  0.20346738]]. Action = [[0.        0.        0.        0.5052197]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 3198 is [True, False, False, False, False, True]
State prediction error at timestep 3198 is 0.012
Current timestep = 3199. State = [[-0.38717082  0.20346735]]. Action = [[ 0.         0.         0.        -0.5163718]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 3199 is [True, False, False, False, False, True]
State prediction error at timestep 3199 is 0.012
Current timestep = 3200. State = [[-0.3871709   0.20346731]]. Action = [[ 0.          0.          0.         -0.86987346]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 3200 is [True, False, False, False, False, True]
State prediction error at timestep 3200 is 0.012
Current timestep = 3201. State = [[-0.387171    0.20346726]]. Action = [[ 0.          0.          0.         -0.60296637]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 3201 is [True, False, False, False, False, True]
State prediction error at timestep 3201 is 0.012
Current timestep = 3202. State = [[-0.3871711   0.20346722]]. Action = [[0.         0.         0.         0.48466754]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 3202 is [True, False, False, False, False, True]
State prediction error at timestep 3202 is 0.012
Current timestep = 3203. State = [[-0.38717118  0.20346718]]. Action = [[0.        0.        0.        0.7308688]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 3203 is [True, False, False, False, False, True]
State prediction error at timestep 3203 is 0.012
Current timestep = 3204. State = [[-0.38717124  0.20346713]]. Action = [[ 0.          0.          0.         -0.48140556]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 3204 is [True, False, False, False, False, True]
State prediction error at timestep 3204 is 0.012
Current timestep = 3205. State = [[-0.38717133  0.2034671 ]]. Action = [[ 0.          0.          0.         -0.10521007]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 3205 is [True, False, False, False, False, True]
State prediction error at timestep 3205 is 0.012
Current timestep = 3206. State = [[-0.38717142  0.20346706]]. Action = [[ 0.         0.         0.        -0.7091991]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 3206 is [True, False, False, False, False, True]
State prediction error at timestep 3206 is 0.012
Current timestep = 3207. State = [[-0.3871715   0.20346701]]. Action = [[0.         0.         0.         0.88183177]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 3207 is [True, False, False, False, False, True]
State prediction error at timestep 3207 is 0.012
Current timestep = 3208. State = [[-0.3871716   0.20346697]]. Action = [[0.         0.         0.         0.67761207]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 3208 is [True, False, False, False, False, True]
State prediction error at timestep 3208 is 0.012
Current timestep = 3209. State = [[-0.38717166  0.20346692]]. Action = [[ 0.          0.          0.         -0.61637443]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 3209 is [True, False, False, False, False, True]
State prediction error at timestep 3209 is 0.012
Current timestep = 3210. State = [[-0.38717175  0.20346688]]. Action = [[0.         0.         0.         0.21973062]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 3210 is [True, False, False, False, False, True]
State prediction error at timestep 3210 is 0.012
Current timestep = 3211. State = [[-0.38717183  0.20346683]]. Action = [[0.        0.        0.        0.9889231]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 3211 is [True, False, False, False, False, True]
State prediction error at timestep 3211 is 0.012
Current timestep = 3212. State = [[-0.3871719  0.2034668]]. Action = [[0.         0.         0.         0.47423208]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 3212 is [True, False, False, False, False, True]
State prediction error at timestep 3212 is 0.012
Current timestep = 3213. State = [[-0.38717198  0.20346676]]. Action = [[0.        0.        0.        0.3889966]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 3213 is [True, False, False, False, False, True]
State prediction error at timestep 3213 is 0.012
Current timestep = 3214. State = [[-0.38717207  0.20346671]]. Action = [[0.         0.         0.         0.14157546]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 3214 is [True, False, False, False, False, True]
State prediction error at timestep 3214 is 0.012
Current timestep = 3215. State = [[-0.38717213  0.20346667]]. Action = [[ 0.          0.          0.         -0.56123936]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 3215 is [True, False, False, False, False, True]
State prediction error at timestep 3215 is 0.012
Current timestep = 3216. State = [[-0.38717222  0.20346662]]. Action = [[ 0.         0.         0.        -0.6027029]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 3216 is [True, False, False, False, False, True]
State prediction error at timestep 3216 is 0.012
Current timestep = 3217. State = [[-0.38717228  0.20346658]]. Action = [[ 0.         0.         0.        -0.4519198]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 3217 is [True, False, False, False, False, True]
State prediction error at timestep 3217 is 0.012
Current timestep = 3218. State = [[-0.38717237  0.20346653]]. Action = [[ 0.          0.          0.         -0.95845336]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 3218 is [True, False, False, False, False, True]
State prediction error at timestep 3218 is 0.012
Current timestep = 3219. State = [[-0.38717243  0.20346649]]. Action = [[ 0.          0.          0.         -0.47867352]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 3219 is [True, False, False, False, False, True]
State prediction error at timestep 3219 is 0.012
Current timestep = 3220. State = [[-0.38717252  0.20346645]]. Action = [[0.         0.         0.         0.02234232]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 3220 is [True, False, False, False, False, True]
State prediction error at timestep 3220 is 0.012
Current timestep = 3221. State = [[-0.38717258  0.20346642]]. Action = [[0.         0.         0.         0.78694606]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 3221 is [True, False, False, False, False, True]
State prediction error at timestep 3221 is 0.012
Current timestep = 3222. State = [[-0.38717267  0.20346637]]. Action = [[0.         0.         0.         0.44653082]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 3222 is [True, False, False, False, False, True]
State prediction error at timestep 3222 is 0.012
Current timestep = 3223. State = [[-0.38717273  0.20346633]]. Action = [[ 0.          0.          0.         -0.89409727]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 3223 is [True, False, False, False, False, True]
State prediction error at timestep 3223 is 0.012
Current timestep = 3224. State = [[-0.3871728   0.20346628]]. Action = [[ 0.          0.          0.         -0.96330583]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 3224 is [True, False, False, False, False, True]
State prediction error at timestep 3224 is 0.012
Current timestep = 3225. State = [[-0.38717288  0.20346624]]. Action = [[ 0.         0.         0.        -0.8800788]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 3225 is [True, False, False, False, False, True]
State prediction error at timestep 3225 is 0.012
Current timestep = 3226. State = [[-0.38717294  0.20346619]]. Action = [[0.         0.         0.         0.22604048]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 3226 is [True, False, False, False, False, True]
State prediction error at timestep 3226 is 0.012
Current timestep = 3227. State = [[-0.387173    0.20346615]]. Action = [[ 0.          0.          0.         -0.47951174]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 3227 is [True, False, False, False, False, True]
State prediction error at timestep 3227 is 0.012
Current timestep = 3228. State = [[-0.3871731  0.2034661]]. Action = [[0.         0.         0.         0.24873483]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 3228 is [True, False, False, False, False, True]
State prediction error at timestep 3228 is 0.012
Current timestep = 3229. State = [[-0.38717315  0.20346606]]. Action = [[0.         0.         0.         0.19107461]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 3229 is [True, False, False, False, False, True]
State prediction error at timestep 3229 is 0.012
Current timestep = 3230. State = [[-0.3871732   0.20346601]]. Action = [[0.         0.         0.         0.33469462]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 3230 is [True, False, False, False, False, True]
State prediction error at timestep 3230 is 0.012
Current timestep = 3231. State = [[-0.38717327  0.20346597]]. Action = [[0.         0.         0.         0.23558474]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 3231 is [True, False, False, False, False, True]
State prediction error at timestep 3231 is 0.012
Current timestep = 3232. State = [[-0.38717335  0.20346592]]. Action = [[ 0.         0.         0.        -0.1549992]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 3232 is [True, False, False, False, False, True]
State prediction error at timestep 3232 is 0.012
Current timestep = 3233. State = [[-0.3871734   0.20346588]]. Action = [[ 0.         0.         0.        -0.1396544]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 3233 is [True, False, False, False, False, True]
State prediction error at timestep 3233 is 0.012
Current timestep = 3234. State = [[-0.38717347  0.20346583]]. Action = [[0.        0.        0.        0.5451145]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 3234 is [True, False, False, False, False, True]
State prediction error at timestep 3234 is 0.012
Current timestep = 3235. State = [[-0.38717353  0.20346579]]. Action = [[ 0.         0.         0.        -0.8248205]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 3235 is [True, False, False, False, False, True]
State prediction error at timestep 3235 is 0.012
Current timestep = 3236. State = [[-0.3871736   0.20346574]]. Action = [[ 0.          0.          0.         -0.81615686]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 3236 is [True, False, False, False, False, True]
State prediction error at timestep 3236 is 0.012
Current timestep = 3237. State = [[-0.38717365  0.2034657 ]]. Action = [[0.        0.        0.        0.6928377]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 3237 is [True, False, False, False, False, True]
State prediction error at timestep 3237 is 0.012
Current timestep = 3238. State = [[-0.3871737   0.20346566]]. Action = [[ 0.          0.          0.         -0.23345041]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 3238 is [True, False, False, False, False, True]
State prediction error at timestep 3238 is 0.012
Current timestep = 3239. State = [[-0.38717377  0.20346561]]. Action = [[0.         0.         0.         0.32532084]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 3239 is [True, False, False, False, False, True]
State prediction error at timestep 3239 is 0.012
Current timestep = 3240. State = [[-0.38717383  0.20346557]]. Action = [[0.         0.         0.         0.22932124]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 3240 is [True, False, False, False, False, True]
State prediction error at timestep 3240 is 0.012
Current timestep = 3241. State = [[-0.38717392  0.20346552]]. Action = [[0.         0.         0.         0.23271501]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 3241 is [True, False, False, False, False, True]
State prediction error at timestep 3241 is 0.012
Current timestep = 3242. State = [[-0.38717398  0.20346548]]. Action = [[0.         0.         0.         0.19714451]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 3242 is [True, False, False, False, False, True]
State prediction error at timestep 3242 is 0.012
Current timestep = 3243. State = [[-0.38717404  0.20346543]]. Action = [[ 0.          0.          0.         -0.19086182]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 3243 is [True, False, False, False, False, True]
State prediction error at timestep 3243 is 0.012
Current timestep = 3244. State = [[-0.38717407  0.20346539]]. Action = [[ 0.          0.          0.         -0.01964635]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 3244 is [True, False, False, False, False, True]
State prediction error at timestep 3244 is 0.012
Current timestep = 3245. State = [[-0.38717413  0.20346534]]. Action = [[0.         0.         0.         0.36617315]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 3245 is [True, False, False, False, False, True]
State prediction error at timestep 3245 is 0.012
Current timestep = 3246. State = [[-0.3871742  0.2034653]]. Action = [[ 0.          0.          0.         -0.71563476]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 3246 is [True, False, False, False, False, True]
State prediction error at timestep 3246 is 0.012
Current timestep = 3247. State = [[-0.38717425  0.20346525]]. Action = [[ 0.          0.          0.         -0.74349874]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 3247 is [True, False, False, False, False, True]
State prediction error at timestep 3247 is 0.012
Current timestep = 3248. State = [[-0.3871743   0.20346521]]. Action = [[0.        0.        0.        0.7741904]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 3248 is [True, False, False, False, False, True]
State prediction error at timestep 3248 is 0.012
Current timestep = 3249. State = [[-0.38717437  0.20346516]]. Action = [[0.         0.         0.         0.95526004]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 3249 is [True, False, False, False, False, True]
State prediction error at timestep 3249 is 0.012
Current timestep = 3250. State = [[-0.38717443  0.20346512]]. Action = [[ 0.          0.          0.         -0.01419115]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 3250 is [True, False, False, False, False, True]
State prediction error at timestep 3250 is 0.012
Current timestep = 3251. State = [[-0.3871745   0.20346507]]. Action = [[0.        0.        0.        0.7812835]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 3251 is [True, False, False, False, False, True]
State prediction error at timestep 3251 is 0.012
Current timestep = 3252. State = [[-0.38717455  0.20346503]]. Action = [[0.         0.         0.         0.76581025]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 3252 is [True, False, False, False, False, True]
State prediction error at timestep 3252 is 0.012
Current timestep = 3253. State = [[-0.38717458  0.20346498]]. Action = [[0.         0.         0.         0.91188455]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 3253 is [True, False, False, False, False, True]
State prediction error at timestep 3253 is 0.012
Current timestep = 3254. State = [[-0.38717464  0.20346494]]. Action = [[ 0.          0.          0.         -0.25607014]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 3254 is [True, False, False, False, False, True]
State prediction error at timestep 3254 is 0.012
Current timestep = 3255. State = [[-0.3871747  0.2034649]]. Action = [[0.         0.         0.         0.10637009]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 3255 is [True, False, False, False, False, True]
State prediction error at timestep 3255 is 0.012
Current timestep = 3256. State = [[-0.38717476  0.20346485]]. Action = [[0.         0.         0.         0.05184472]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 3256 is [True, False, False, False, False, True]
State prediction error at timestep 3256 is 0.012
Current timestep = 3257. State = [[-0.3871748  0.2034648]]. Action = [[0.        0.        0.        0.8555112]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 3257 is [True, False, False, False, False, True]
State prediction error at timestep 3257 is 0.012
Current timestep = 3258. State = [[-0.38717484  0.20346475]]. Action = [[0.        0.        0.        0.8681377]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 3258 is [True, False, False, False, False, True]
State prediction error at timestep 3258 is 0.012
Current timestep = 3259. State = [[-0.3871749  0.2034647]]. Action = [[0.         0.         0.         0.87885594]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 3259 is [True, False, False, False, False, True]
State prediction error at timestep 3259 is 0.012
Current timestep = 3260. State = [[-0.38717493  0.20346466]]. Action = [[ 0.         0.         0.        -0.4668615]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 3260 is [True, False, False, False, False, True]
State prediction error at timestep 3260 is 0.012
Current timestep = 3261. State = [[-0.387175    0.20346461]]. Action = [[0.       0.       0.       0.939054]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 3261 is [True, False, False, False, False, True]
State prediction error at timestep 3261 is 0.012
Current timestep = 3262. State = [[-0.38717505  0.20346457]]. Action = [[ 0.          0.          0.         -0.57794577]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 3262 is [True, False, False, False, False, True]
State prediction error at timestep 3262 is 0.012
Current timestep = 3263. State = [[-0.38717508  0.20346452]]. Action = [[0.         0.         0.         0.31687987]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 3263 is [True, False, False, False, False, True]
State prediction error at timestep 3263 is 0.012
Current timestep = 3264. State = [[-0.38717514  0.20346448]]. Action = [[0.        0.        0.        0.8383043]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 3264 is [True, False, False, False, False, True]
State prediction error at timestep 3264 is 0.012
Current timestep = 3265. State = [[-0.3871752   0.20346443]]. Action = [[ 0.          0.          0.         -0.15505493]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 3265 is [True, False, False, False, False, True]
State prediction error at timestep 3265 is 0.012
Current timestep = 3266. State = [[-0.38717523  0.20346439]]. Action = [[ 0.          0.          0.         -0.92114973]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 3266 is [True, False, False, False, False, True]
State prediction error at timestep 3266 is 0.012
Current timestep = 3267. State = [[-0.3871753   0.20346434]]. Action = [[0.        0.        0.        0.6058185]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 3267 is [True, False, False, False, False, True]
State prediction error at timestep 3267 is 0.012
Current timestep = 3268. State = [[-0.38717532  0.2034643 ]]. Action = [[ 0.         0.         0.        -0.6512843]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 3268 is [True, False, False, False, False, True]
State prediction error at timestep 3268 is 0.012
Current timestep = 3269. State = [[-0.38717538  0.20346424]]. Action = [[0.       0.       0.       0.778075]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 3269 is [True, False, False, False, False, True]
State prediction error at timestep 3269 is 0.012
Current timestep = 3270. State = [[-0.3871754  0.2034642]]. Action = [[ 0.          0.          0.         -0.01836544]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 3270 is [True, False, False, False, False, True]
State prediction error at timestep 3270 is 0.012
Current timestep = 3271. State = [[-0.38717547  0.20346415]]. Action = [[ 0.         0.         0.        -0.8761946]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 3271 is [True, False, False, False, False, True]
State prediction error at timestep 3271 is 0.012
Current timestep = 3272. State = [[-0.3871755  0.2034641]]. Action = [[0.        0.        0.        0.6315893]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 3272 is [True, False, False, False, False, True]
State prediction error at timestep 3272 is 0.012
Current timestep = 3273. State = [[-0.38717556  0.20346406]]. Action = [[ 0.          0.          0.         -0.07609874]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 3273 is [True, False, False, False, False, True]
State prediction error at timestep 3273 is 0.012
Current timestep = 3274. State = [[-0.3871756   0.20346402]]. Action = [[0.        0.        0.        0.2211889]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 3274 is [True, False, False, False, False, True]
State prediction error at timestep 3274 is 0.012
Current timestep = 3275. State = [[-0.38717565  0.20346397]]. Action = [[0.         0.         0.         0.67205167]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 3275 is [True, False, False, False, False, True]
State prediction error at timestep 3275 is 0.012
Current timestep = 3276. State = [[-0.38717568  0.20346393]]. Action = [[ 0.          0.          0.         -0.09476721]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 3276 is [True, False, False, False, False, True]
State prediction error at timestep 3276 is 0.012
Current timestep = 3277. State = [[-0.38717574  0.20346387]]. Action = [[0.         0.         0.         0.34331548]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 3277 is [True, False, False, False, False, True]
State prediction error at timestep 3277 is 0.012
Current timestep = 3278. State = [[-0.38717577  0.20346382]]. Action = [[0.         0.         0.         0.74931026]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 3278 is [True, False, False, False, False, True]
State prediction error at timestep 3278 is 0.012
Current timestep = 3279. State = [[-0.38717583  0.20346378]]. Action = [[ 0.         0.         0.        -0.6526109]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 3279 is [True, False, False, False, False, True]
State prediction error at timestep 3279 is 0.012
Current timestep = 3280. State = [[-0.38717586  0.20346373]]. Action = [[0.         0.         0.         0.72740436]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 3280 is [True, False, False, False, False, True]
State prediction error at timestep 3280 is 0.012
Current timestep = 3281. State = [[-0.3871759   0.20346369]]. Action = [[0.        0.        0.        0.5014553]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 3281 is [True, False, False, False, False, True]
State prediction error at timestep 3281 is 0.012
Current timestep = 3282. State = [[-0.38717595  0.20346364]]. Action = [[0.       0.       0.       0.488315]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 3282 is [True, False, False, False, False, True]
State prediction error at timestep 3282 is 0.012
Current timestep = 3283. State = [[-0.38717598  0.2034636 ]]. Action = [[ 0.          0.          0.         -0.03933358]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 3283 is [True, False, False, False, False, True]
State prediction error at timestep 3283 is 0.012
Current timestep = 3284. State = [[-0.387176    0.20346354]]. Action = [[0.         0.         0.         0.23161077]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 3284 is [True, False, False, False, False, True]
State prediction error at timestep 3284 is 0.012
Current timestep = 3285. State = [[-0.38717607  0.2034635 ]]. Action = [[ 0.          0.          0.         -0.24071538]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 3285 is [True, False, False, False, False, True]
State prediction error at timestep 3285 is 0.012
Current timestep = 3286. State = [[-0.3871761   0.20346345]]. Action = [[ 0.          0.          0.         -0.09992242]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 3286 is [True, False, False, False, False, True]
State prediction error at timestep 3286 is 0.012
Current timestep = 3287. State = [[-0.38717613  0.2034634 ]]. Action = [[ 0.         0.         0.        -0.2945336]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 3287 is [True, False, False, False, False, True]
State prediction error at timestep 3287 is 0.012
Current timestep = 3288. State = [[-0.38717616  0.20346336]]. Action = [[ 0.         0.         0.        -0.3741663]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 3288 is [True, False, False, False, False, True]
State prediction error at timestep 3288 is 0.012
Current timestep = 3289. State = [[-0.38717622  0.20346332]]. Action = [[ 0.         0.         0.        -0.5908869]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 3289 is [True, False, False, False, False, True]
State prediction error at timestep 3289 is 0.012
Current timestep = 3290. State = [[-0.38717625  0.20346326]]. Action = [[0.         0.         0.         0.52559805]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 3290 is [True, False, False, False, False, True]
State prediction error at timestep 3290 is 0.012
Current timestep = 3291. State = [[-0.38717628  0.20346321]]. Action = [[0.       0.       0.       0.673337]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 3291 is [True, False, False, False, False, True]
State prediction error at timestep 3291 is 0.012
Current timestep = 3292. State = [[-0.3871763   0.20346317]]. Action = [[0.         0.         0.         0.93703437]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 3292 is [True, False, False, False, False, True]
State prediction error at timestep 3292 is 0.012
Current timestep = 3293. State = [[-0.38717636  0.20346312]]. Action = [[ 0.          0.          0.         -0.98213255]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 3293 is [True, False, False, False, False, True]
State prediction error at timestep 3293 is 0.012
Current timestep = 3294. State = [[-0.3871764   0.20346308]]. Action = [[0.        0.        0.        0.8504269]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 3294 is [True, False, False, False, False, True]
State prediction error at timestep 3294 is 0.012
Current timestep = 3295. State = [[-0.38717642  0.20346302]]. Action = [[ 0.          0.          0.         -0.10650617]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 3295 is [True, False, False, False, False, True]
State prediction error at timestep 3295 is 0.012
Current timestep = 3296. State = [[-0.38717645  0.20346297]]. Action = [[ 0.          0.          0.         -0.83211565]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 3296 is [True, False, False, False, False, True]
State prediction error at timestep 3296 is 0.012
Current timestep = 3297. State = [[-0.38717648  0.20346293]]. Action = [[ 0.          0.          0.         -0.77518374]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 3297 is [True, False, False, False, False, True]
State prediction error at timestep 3297 is 0.012
Current timestep = 3298. State = [[-0.3871765   0.20346288]]. Action = [[ 0.          0.          0.         -0.18248713]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 3298 is [True, False, False, False, False, True]
State prediction error at timestep 3298 is 0.012
Current timestep = 3299. State = [[-0.38717657  0.20346284]]. Action = [[ 0.         0.         0.        -0.6427774]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 3299 is [True, False, False, False, False, True]
State prediction error at timestep 3299 is 0.012
Current timestep = 3300. State = [[-0.3871766  0.2034628]]. Action = [[0.         0.         0.         0.08642268]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 3300 is [True, False, False, False, False, True]
State prediction error at timestep 3300 is 0.012
Current timestep = 3301. State = [[-0.38717663  0.20346273]]. Action = [[0.         0.         0.         0.72177243]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 3301 is [True, False, False, False, False, True]
State prediction error at timestep 3301 is 0.012
Current timestep = 3302. State = [[-0.38717666  0.20346269]]. Action = [[ 0.          0.          0.         -0.04408473]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 3302 is [True, False, False, False, False, True]
State prediction error at timestep 3302 is 0.012
Current timestep = 3303. State = [[-0.3871767   0.20346265]]. Action = [[ 0.          0.          0.         -0.28777313]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 3303 is [True, False, False, False, False, True]
State prediction error at timestep 3303 is 0.012
Current timestep = 3304. State = [[-0.38717672  0.2034626 ]]. Action = [[0.         0.         0.         0.64044714]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 3304 is [True, False, False, False, False, True]
State prediction error at timestep 3304 is 0.012
Current timestep = 3305. State = [[-0.38717675  0.20346256]]. Action = [[0.        0.        0.        0.9322412]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 3305 is [True, False, False, False, False, True]
State prediction error at timestep 3305 is 0.012
Current timestep = 3306. State = [[-0.38717678  0.2034625 ]]. Action = [[0.        0.        0.        0.2603773]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 3306 is [True, False, False, False, False, True]
State prediction error at timestep 3306 is 0.012
Current timestep = 3307. State = [[-0.3871768   0.20346245]]. Action = [[0.         0.         0.         0.19348562]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 3307 is [True, False, False, False, False, True]
State prediction error at timestep 3307 is 0.012
Current timestep = 3308. State = [[-0.38717684  0.2034624 ]]. Action = [[ 0.          0.          0.         -0.78951025]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 3308 is [True, False, False, False, False, True]
State prediction error at timestep 3308 is 0.012
Current timestep = 3309. State = [[-0.38717687  0.20346236]]. Action = [[0.         0.         0.         0.39774036]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 3309 is [True, False, False, False, False, True]
State prediction error at timestep 3309 is 0.012
Current timestep = 3310. State = [[-0.3871769  0.2034623]]. Action = [[0.         0.         0.         0.22094977]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 3310 is [True, False, False, False, False, True]
State prediction error at timestep 3310 is 0.012
Current timestep = 3311. State = [[-0.38717693  0.20346226]]. Action = [[0.        0.        0.        0.8057444]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 3311 is [True, False, False, False, False, True]
State prediction error at timestep 3311 is 0.012
Current timestep = 3312. State = [[-0.38717696  0.20346221]]. Action = [[0.        0.        0.        0.6151109]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 3312 is [True, False, False, False, False, True]
State prediction error at timestep 3312 is 0.012
Current timestep = 3313. State = [[-0.387177    0.20346217]]. Action = [[0.         0.         0.         0.17659438]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 3313 is [True, False, False, False, False, True]
State prediction error at timestep 3313 is 0.012
Current timestep = 3314. State = [[-0.38717702  0.20346212]]. Action = [[0.         0.         0.         0.57233834]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 3314 is [True, False, False, False, False, True]
State prediction error at timestep 3314 is 0.012
Current timestep = 3315. State = [[-0.38717705  0.20346206]]. Action = [[0.        0.        0.        0.4269135]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 3315 is [True, False, False, False, False, True]
State prediction error at timestep 3315 is 0.012
Current timestep = 3316. State = [[-0.38717708  0.20346202]]. Action = [[0.        0.        0.        0.6184219]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 3316 is [True, False, False, False, False, True]
State prediction error at timestep 3316 is 0.012
Current timestep = 3317. State = [[-0.3871771   0.20346197]]. Action = [[0.        0.        0.        0.6014476]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 3317 is [True, False, False, False, False, True]
State prediction error at timestep 3317 is 0.012
Current timestep = 3318. State = [[-0.38717714  0.20346193]]. Action = [[ 0.         0.         0.        -0.3033353]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 3318 is [True, False, False, False, False, True]
State prediction error at timestep 3318 is 0.012
Current timestep = 3319. State = [[-0.38717717  0.20346187]]. Action = [[ 0.          0.          0.         -0.34238303]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 3319 is [True, False, False, False, False, True]
State prediction error at timestep 3319 is 0.012
Current timestep = 3320. State = [[-0.3871772   0.20346183]]. Action = [[ 0.          0.          0.         -0.13471699]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 3320 is [True, False, False, False, False, True]
State prediction error at timestep 3320 is 0.012
Current timestep = 3321. State = [[-0.38717723  0.20346178]]. Action = [[0.         0.         0.         0.73902893]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 3321 is [True, False, False, False, False, True]
State prediction error at timestep 3321 is 0.012
Current timestep = 3322. State = [[-0.38717726  0.20346174]]. Action = [[0.        0.        0.        0.4109099]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 3322 is [True, False, False, False, False, True]
State prediction error at timestep 3322 is 0.012
Current timestep = 3323. State = [[-0.3871773   0.20346168]]. Action = [[0.         0.         0.         0.94321704]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 3323 is [True, False, False, False, False, True]
State prediction error at timestep 3323 is 0.012
Current timestep = 3324. State = [[-0.3871773   0.20346163]]. Action = [[0.         0.         0.         0.52879477]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 3324 is [True, False, False, False, False, True]
State prediction error at timestep 3324 is 0.012
Current timestep = 3325. State = [[-0.38717732  0.20346159]]. Action = [[ 0.          0.          0.         -0.83188355]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 3325 is [True, False, False, False, False, True]
State prediction error at timestep 3325 is 0.012
Current timestep = 3326. State = [[-0.38717735  0.20346154]]. Action = [[0.        0.        0.        0.9503658]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 3326 is [True, False, False, False, False, True]
State prediction error at timestep 3326 is 0.012
Current timestep = 3327. State = [[-0.38717738  0.20346148]]. Action = [[0.         0.         0.         0.55134666]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 3327 is [True, False, False, False, False, True]
State prediction error at timestep 3327 is 0.012
Current timestep = 3328. State = [[-0.3871774   0.20346144]]. Action = [[0.         0.         0.         0.10166264]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 3328 is [True, False, False, False, False, True]
State prediction error at timestep 3328 is 0.012
Current timestep = 3329. State = [[-0.38717744  0.2034614 ]]. Action = [[0.        0.        0.        0.4464712]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 3329 is [True, False, False, False, False, True]
State prediction error at timestep 3329 is 0.012
Current timestep = 3330. State = [[-0.38717744  0.20346135]]. Action = [[0.        0.        0.        0.6674477]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 3330 is [True, False, False, False, False, True]
State prediction error at timestep 3330 is 0.012
Current timestep = 3331. State = [[-0.38717747  0.20346129]]. Action = [[0.         0.         0.         0.49370933]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 3331 is [True, False, False, False, False, True]
State prediction error at timestep 3331 is 0.012
Current timestep = 3332. State = [[-0.3871775   0.20346124]]. Action = [[0.         0.         0.         0.29046106]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 3332 is [True, False, False, False, False, True]
State prediction error at timestep 3332 is 0.012
Current timestep = 3333. State = [[-0.38717753  0.2034612 ]]. Action = [[0.         0.         0.         0.69296587]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 3333 is [True, False, False, False, False, True]
State prediction error at timestep 3333 is 0.012
Current timestep = 3334. State = [[-0.38717756  0.20346116]]. Action = [[ 0.          0.          0.         -0.03955531]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 3334 is [True, False, False, False, False, True]
State prediction error at timestep 3334 is 0.012
Current timestep = 3335. State = [[-0.38717756  0.2034611 ]]. Action = [[0.        0.        0.        0.4705701]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 3335 is [True, False, False, False, False, True]
State prediction error at timestep 3335 is 0.012
Current timestep = 3336. State = [[-0.3871776   0.20346105]]. Action = [[0.         0.         0.         0.22074842]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 3336 is [True, False, False, False, False, True]
State prediction error at timestep 3336 is 0.012
Current timestep = 3337. State = [[-0.38717762  0.203461  ]]. Action = [[0.        0.        0.        0.5210123]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 3337 is [True, False, False, False, False, True]
State prediction error at timestep 3337 is 0.012
Current timestep = 3338. State = [[-0.38717765  0.20346096]]. Action = [[ 0.         0.         0.        -0.8148171]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 3338 is [True, False, False, False, False, True]
State prediction error at timestep 3338 is 0.012
Current timestep = 3339. State = [[-0.38717765  0.2034609 ]]. Action = [[0.        0.        0.        0.9407511]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 3339 is [True, False, False, False, False, True]
State prediction error at timestep 3339 is 0.012
Current timestep = 3340. State = [[-0.38717768  0.20346086]]. Action = [[0.        0.        0.        0.6068244]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 3340 is [True, False, False, False, False, True]
State prediction error at timestep 3340 is 0.012
Current timestep = 3341. State = [[-0.3871777   0.20346081]]. Action = [[ 0.         0.         0.        -0.0049293]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 3341 is [True, False, False, False, False, True]
State prediction error at timestep 3341 is 0.012
Current timestep = 3342. State = [[-0.3871777   0.20346075]]. Action = [[0.         0.         0.         0.70427847]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 3342 is [True, False, False, False, False, True]
State prediction error at timestep 3342 is 0.012
Current timestep = 3343. State = [[-0.38717774  0.20346071]]. Action = [[0.         0.         0.         0.29244018]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 3343 is [True, False, False, False, False, True]
State prediction error at timestep 3343 is 0.012
Current timestep = 3344. State = [[-0.38717777  0.20346066]]. Action = [[ 0.          0.          0.         -0.58760065]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 3344 is [True, False, False, False, False, True]
State prediction error at timestep 3344 is 0.012
Current timestep = 3345. State = [[-0.38717777  0.20346062]]. Action = [[ 0.         0.         0.        -0.3124962]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 3345 is [True, False, False, False, False, True]
State prediction error at timestep 3345 is 0.012
Current timestep = 3346. State = [[-0.3871778   0.20346056]]. Action = [[0.        0.        0.        0.8111577]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 3346 is [True, False, False, False, False, True]
State prediction error at timestep 3346 is 0.012
Current timestep = 3347. State = [[-0.38717782  0.20346051]]. Action = [[ 0.          0.          0.         -0.13152283]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 3347 is [True, False, False, False, False, True]
State prediction error at timestep 3347 is 0.012
Current timestep = 3348. State = [[-0.38717782  0.20346047]]. Action = [[0.         0.         0.         0.10503876]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 3348 is [True, False, False, False, False, True]
State prediction error at timestep 3348 is 0.012
Current timestep = 3349. State = [[-0.38717785  0.20346041]]. Action = [[0.        0.        0.        0.6940179]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 3349 is [True, False, False, False, False, True]
State prediction error at timestep 3349 is 0.012
Current timestep = 3350. State = [[-0.38717788  0.20346037]]. Action = [[ 0.         0.         0.        -0.3755899]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 3350 is [True, False, False, False, False, True]
State prediction error at timestep 3350 is 0.012
Current timestep = 3351. State = [[-0.38717788  0.20346032]]. Action = [[0.         0.         0.         0.06700253]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 3351 is [True, False, False, False, False, True]
State prediction error at timestep 3351 is 0.012
Current timestep = 3352. State = [[-0.3871779   0.20346028]]. Action = [[0.         0.         0.         0.56929994]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 3352 is [True, False, False, False, False, True]
State prediction error at timestep 3352 is 0.012
Current timestep = 3353. State = [[-0.38717794  0.20346022]]. Action = [[ 0.          0.          0.         -0.00324619]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 3353 is [True, False, False, False, False, True]
State prediction error at timestep 3353 is 0.012
Current timestep = 3354. State = [[-0.38717794  0.20346017]]. Action = [[ 0.          0.          0.         -0.91135234]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 3354 is [True, False, False, False, False, True]
State prediction error at timestep 3354 is 0.012
Current timestep = 3355. State = [[-0.38717797  0.20346013]]. Action = [[ 0.          0.          0.         -0.28362846]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 3355 is [True, False, False, False, False, True]
State prediction error at timestep 3355 is 0.012
Current timestep = 3356. State = [[-0.38717797  0.20346007]]. Action = [[ 0.          0.          0.         -0.74125355]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 3356 is [True, False, False, False, False, True]
State prediction error at timestep 3356 is 0.012
Current timestep = 3357. State = [[-0.387178    0.20346002]]. Action = [[0.         0.         0.         0.26361632]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 3357 is [True, False, False, False, False, True]
State prediction error at timestep 3357 is 0.012
Current timestep = 3358. State = [[-0.38717803  0.20345998]]. Action = [[0.         0.         0.         0.37876427]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 3358 is [True, False, False, False, False, True]
State prediction error at timestep 3358 is 0.012
Current timestep = 3359. State = [[-0.38717803  0.20345993]]. Action = [[ 0.          0.          0.         -0.83867764]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 3359 is [True, False, False, False, False, True]
State prediction error at timestep 3359 is 0.012
Current timestep = 3360. State = [[-0.38717806  0.20345987]]. Action = [[ 0.          0.          0.         -0.22137254]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 3360 is [True, False, False, False, False, True]
State prediction error at timestep 3360 is 0.012
Current timestep = 3361. State = [[-0.38717806  0.20345983]]. Action = [[0.         0.         0.         0.02193165]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 3361 is [True, False, False, False, False, True]
State prediction error at timestep 3361 is 0.012
Current timestep = 3362. State = [[-0.3871781   0.20345978]]. Action = [[ 0.          0.          0.         -0.22694892]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 3362 is [True, False, False, False, False, True]
State prediction error at timestep 3362 is 0.012
Current timestep = 3363. State = [[-0.3871781   0.20345972]]. Action = [[ 0.         0.         0.        -0.5458623]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 3363 is [True, False, False, False, False, True]
State prediction error at timestep 3363 is 0.012
Current timestep = 3364. State = [[-0.38717812  0.20345968]]. Action = [[0.        0.        0.        0.9290054]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 3364 is [True, False, False, False, False, True]
State prediction error at timestep 3364 is 0.012
Current timestep = 3365. State = [[-0.38717812  0.20345964]]. Action = [[0.         0.         0.         0.88595057]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 3365 is [True, False, False, False, False, True]
State prediction error at timestep 3365 is 0.012
Current timestep = 3366. State = [[-0.38717815  0.20345958]]. Action = [[0.       0.       0.       0.926394]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 3366 is [True, False, False, False, False, True]
State prediction error at timestep 3366 is 0.012
Current timestep = 3367. State = [[-0.38717815  0.20345953]]. Action = [[0.         0.         0.         0.74206376]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 3367 is [True, False, False, False, False, True]
State prediction error at timestep 3367 is 0.012
Current timestep = 3368. State = [[-0.38717818  0.20345949]]. Action = [[0.         0.         0.         0.06925786]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 3368 is [True, False, False, False, False, True]
State prediction error at timestep 3368 is 0.012
Current timestep = 3369. State = [[-0.3871782   0.20345944]]. Action = [[ 0.          0.          0.         -0.40371156]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 3369 is [True, False, False, False, False, True]
State prediction error at timestep 3369 is 0.012
Current timestep = 3370. State = [[-0.3871782   0.20345938]]. Action = [[0.         0.         0.         0.22804523]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 3370 is [True, False, False, False, False, True]
State prediction error at timestep 3370 is 0.012
Current timestep = 3371. State = [[-0.3871782   0.20345934]]. Action = [[0.         0.         0.         0.20471716]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 3371 is [True, False, False, False, False, True]
State prediction error at timestep 3371 is 0.012
Current timestep = 3372. State = [[-0.38717824  0.2034593 ]]. Action = [[0.        0.        0.        0.3878076]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 3372 is [True, False, False, False, False, True]
State prediction error at timestep 3372 is 0.012
Current timestep = 3373. State = [[-0.38717824  0.20345923]]. Action = [[0.         0.         0.         0.87833107]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 3373 is [True, False, False, False, False, True]
State prediction error at timestep 3373 is 0.012
Current timestep = 3374. State = [[-0.38717827  0.20345919]]. Action = [[0.        0.        0.        0.7786598]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 3374 is [True, False, False, False, False, True]
State prediction error at timestep 3374 is 0.012
Current timestep = 3375. State = [[-0.38717827  0.20345914]]. Action = [[0.         0.         0.         0.04591286]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 3375 is [True, False, False, False, False, True]
State prediction error at timestep 3375 is 0.012
Current timestep = 3376. State = [[-0.3871783   0.20345908]]. Action = [[ 0.         0.         0.        -0.6182846]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 3376 is [True, False, False, False, False, True]
State prediction error at timestep 3376 is 0.012
Current timestep = 3377. State = [[-0.3871783   0.20345904]]. Action = [[ 0.         0.         0.        -0.7543632]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 3377 is [True, False, False, False, False, True]
State prediction error at timestep 3377 is 0.012
Current timestep = 3378. State = [[-0.38717833  0.203459  ]]. Action = [[ 0.          0.          0.         -0.37311852]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 3378 is [True, False, False, False, False, True]
State prediction error at timestep 3378 is 0.012
Current timestep = 3379. State = [[-0.38717833  0.20345894]]. Action = [[0.         0.         0.         0.24246514]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 3379 is [True, False, False, False, False, True]
State prediction error at timestep 3379 is 0.012
Current timestep = 3380. State = [[-0.38717836  0.20345889]]. Action = [[ 0.         0.         0.        -0.5668986]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 3380 is [True, False, False, False, False, True]
State prediction error at timestep 3380 is 0.012
Current timestep = 3381. State = [[-0.38717836  0.20345885]]. Action = [[0.        0.        0.        0.0058372]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 3381 is [True, False, False, False, False, True]
State prediction error at timestep 3381 is 0.012
Current timestep = 3382. State = [[-0.38717836  0.20345879]]. Action = [[0.       0.       0.       0.543113]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 3382 is [True, False, False, False, False, True]
State prediction error at timestep 3382 is 0.012
Current timestep = 3383. State = [[-0.3871784   0.20345874]]. Action = [[0.        0.        0.        0.6936697]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 3383 is [True, False, False, False, False, True]
State prediction error at timestep 3383 is 0.012
Current timestep = 3384. State = [[-0.3871784  0.2034587]]. Action = [[ 0.          0.          0.         -0.52346283]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 3384 is [True, False, False, False, False, True]
State prediction error at timestep 3384 is 0.012
Current timestep = 3385. State = [[-0.38717842  0.20345864]]. Action = [[ 0.          0.          0.         -0.10606897]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 3385 is [True, False, False, False, False, True]
State prediction error at timestep 3385 is 0.012
Current timestep = 3386. State = [[-0.38717842  0.20345859]]. Action = [[0.        0.        0.        0.5054537]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 3386 is [True, False, False, False, False, True]
State prediction error at timestep 3386 is 0.012
Current timestep = 3387. State = [[-0.38717842  0.20345855]]. Action = [[ 0.        0.        0.       -0.529584]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 3387 is [True, False, False, False, False, True]
State prediction error at timestep 3387 is 0.012
Current timestep = 3388. State = [[-0.38717845  0.20345849]]. Action = [[ 0.          0.          0.         -0.20002759]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 3388 is [True, False, False, False, False, True]
State prediction error at timestep 3388 is 0.012
Current timestep = 3389. State = [[-0.38717845  0.20345844]]. Action = [[0.        0.        0.        0.2741449]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 3389 is [True, False, False, False, False, True]
State prediction error at timestep 3389 is 0.012
Current timestep = 3390. State = [[-0.38717848  0.2034584 ]]. Action = [[0.         0.         0.         0.66495204]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 3390 is [True, False, False, False, False, True]
State prediction error at timestep 3390 is 0.012
Current timestep = 3391. State = [[-0.38717848  0.20345835]]. Action = [[ 0.          0.          0.         -0.22648925]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 3391 is [True, False, False, False, False, True]
State prediction error at timestep 3391 is 0.012
Current timestep = 3392. State = [[-0.38717848  0.2034583 ]]. Action = [[0.         0.         0.         0.15239358]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 3392 is [True, False, False, False, False, True]
State prediction error at timestep 3392 is 0.012
Current timestep = 3393. State = [[-0.3871785   0.20345825]]. Action = [[0.         0.         0.         0.19524252]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 3393 is [True, False, False, False, False, True]
State prediction error at timestep 3393 is 0.012
Current timestep = 3394. State = [[-0.3871785  0.2034582]]. Action = [[ 0.         0.         0.        -0.1012271]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 3394 is [True, False, False, False, False, True]
State prediction error at timestep 3394 is 0.012
Current timestep = 3395. State = [[-0.3871785   0.20345815]]. Action = [[0.        0.        0.        0.9665202]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 3395 is [True, False, False, False, False, True]
State prediction error at timestep 3395 is 0.012
Current timestep = 3396. State = [[-0.38717854  0.2034581 ]]. Action = [[ 0.         0.         0.        -0.1996913]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 3396 is [True, False, False, False, False, True]
State prediction error at timestep 3396 is 0.012
Current timestep = 3397. State = [[-0.38717854  0.20345806]]. Action = [[0.         0.         0.         0.00913823]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 3397 is [True, False, False, False, False, True]
State prediction error at timestep 3397 is 0.012
Current timestep = 3398. State = [[-0.38717854  0.203458  ]]. Action = [[0.         0.         0.         0.58849406]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 3398 is [True, False, False, False, False, True]
State prediction error at timestep 3398 is 0.012
Current timestep = 3399. State = [[-0.38717857  0.20345795]]. Action = [[0.         0.         0.         0.08450234]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 3399 is [True, False, False, False, False, True]
State prediction error at timestep 3399 is 0.012
Current timestep = 3400. State = [[-0.38717857  0.2034579 ]]. Action = [[ 0.          0.          0.         -0.45423597]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 3400 is [True, False, False, False, False, True]
State prediction error at timestep 3400 is 0.012
Current timestep = 3401. State = [[-0.38717857  0.20345785]]. Action = [[0.        0.        0.        0.8536773]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 3401 is [True, False, False, False, False, True]
State prediction error at timestep 3401 is 0.012
Current timestep = 3402. State = [[-0.3871786  0.2034578]]. Action = [[ 0.          0.          0.         -0.64440906]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 3402 is [True, False, False, False, False, True]
State prediction error at timestep 3402 is 0.012
Current timestep = 3403. State = [[-0.3871786   0.20345776]]. Action = [[0.         0.         0.         0.21826172]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 3403 is [True, False, False, False, False, True]
State prediction error at timestep 3403 is 0.012
Current timestep = 3404. State = [[-0.3871786  0.2034577]]. Action = [[ 0.          0.          0.         -0.09749973]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 3404 is [True, False, False, False, False, True]
State prediction error at timestep 3404 is 0.012
Current timestep = 3405. State = [[-0.38717863  0.20345765]]. Action = [[0.         0.         0.         0.20177579]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 3405 is [True, False, False, False, False, True]
State prediction error at timestep 3405 is 0.012
Current timestep = 3406. State = [[-0.38717863  0.20345761]]. Action = [[ 0.         0.         0.        -0.9972185]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 3406 is [True, False, False, False, False, True]
State prediction error at timestep 3406 is 0.012
Current timestep = 3407. State = [[-0.38717863  0.20345755]]. Action = [[0.       0.       0.       0.874558]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 3407 is [True, False, False, False, False, True]
State prediction error at timestep 3407 is 0.012
Current timestep = 3408. State = [[-0.38717863  0.2034575 ]]. Action = [[ 0.         0.         0.        -0.3956982]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 3408 is [True, False, False, False, False, True]
State prediction error at timestep 3408 is 0.012
Current timestep = 3409. State = [[-0.38717866  0.20345746]]. Action = [[ 0.          0.          0.         -0.03974599]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 3409 is [True, False, False, False, False, True]
State prediction error at timestep 3409 is 0.012
Current timestep = 3410. State = [[-0.38717866  0.2034574 ]]. Action = [[ 0.         0.         0.        -0.1573081]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 3410 is [True, False, False, False, False, True]
State prediction error at timestep 3410 is 0.012
Current timestep = 3411. State = [[-0.38717866  0.20345736]]. Action = [[0.        0.        0.        0.6105778]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 3411 is [True, False, False, False, False, True]
State prediction error at timestep 3411 is 0.012
Current timestep = 3412. State = [[-0.3871787   0.20345731]]. Action = [[ 0.         0.         0.        -0.3386606]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 3412 is [True, False, False, False, False, True]
State prediction error at timestep 3412 is 0.012
Current timestep = 3413. State = [[-0.3871787   0.20345725]]. Action = [[0.         0.         0.         0.33213305]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 3413 is [True, False, False, False, False, True]
State prediction error at timestep 3413 is 0.012
Current timestep = 3414. State = [[-0.3871787  0.2034572]]. Action = [[ 0.         0.         0.        -0.7045198]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 3414 is [True, False, False, False, False, True]
State prediction error at timestep 3414 is 0.012
Current timestep = 3415. State = [[-0.3871787   0.20345716]]. Action = [[ 0.         0.         0.        -0.9102677]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 3415 is [True, False, False, False, False, True]
State prediction error at timestep 3415 is 0.012
Current timestep = 3416. State = [[-0.38717872  0.2034571 ]]. Action = [[ 0.          0.          0.         -0.14981389]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 3416 is [True, False, False, False, False, True]
State prediction error at timestep 3416 is 0.012
Current timestep = 3417. State = [[-0.38717872  0.20345706]]. Action = [[ 0.          0.          0.         -0.11641568]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 3417 is [True, False, False, False, False, True]
State prediction error at timestep 3417 is 0.012
Current timestep = 3418. State = [[-0.38717872  0.20345701]]. Action = [[ 0.         0.         0.        -0.6787917]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 3418 is [True, False, False, False, False, True]
State prediction error at timestep 3418 is 0.012
Current timestep = 3419. State = [[-0.38717872  0.20345695]]. Action = [[ 0.          0.          0.         -0.74370456]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 3419 is [True, False, False, False, False, True]
State prediction error at timestep 3419 is 0.012
Current timestep = 3420. State = [[-0.38717875  0.20345691]]. Action = [[0.         0.         0.         0.85886145]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 3420 is [True, False, False, False, False, True]
State prediction error at timestep 3420 is 0.012
Current timestep = 3421. State = [[-0.38717875  0.20345686]]. Action = [[0.         0.         0.         0.71337533]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 3421 is [True, False, False, False, False, True]
State prediction error at timestep 3421 is 0.012
Current timestep = 3422. State = [[-0.38717875  0.2034568 ]]. Action = [[ 0.         0.         0.        -0.6302417]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 3422 is [True, False, False, False, False, True]
State prediction error at timestep 3422 is 0.012
Current timestep = 3423. State = [[-0.38717875  0.20345676]]. Action = [[ 0.        0.        0.       -0.048015]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 3423 is [True, False, False, False, False, True]
State prediction error at timestep 3423 is 0.012
Current timestep = 3424. State = [[-0.38717875  0.2034567 ]]. Action = [[ 0.         0.         0.        -0.6690725]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 3424 is [True, False, False, False, False, True]
State prediction error at timestep 3424 is 0.012
Current timestep = 3425. State = [[-0.38717878  0.20345666]]. Action = [[ 0.          0.          0.         -0.90462196]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 3425 is [True, False, False, False, False, True]
State prediction error at timestep 3425 is 0.012
Current timestep = 3426. State = [[-0.38717878  0.20345661]]. Action = [[ 0.        0.        0.       -0.804376]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 3426 is [True, False, False, False, False, True]
State prediction error at timestep 3426 is 0.012
Current timestep = 3427. State = [[-0.38717878  0.20345655]]. Action = [[ 0.         0.         0.        -0.3143747]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 3427 is [True, False, False, False, False, True]
State prediction error at timestep 3427 is 0.012
Current timestep = 3428. State = [[-0.38717878  0.2034565 ]]. Action = [[ 0.          0.          0.         -0.40318632]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 3428 is [True, False, False, False, False, True]
State prediction error at timestep 3428 is 0.012
Current timestep = 3429. State = [[-0.38717878  0.20345646]]. Action = [[ 0.          0.          0.         -0.18156725]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 3429 is [True, False, False, False, False, True]
State prediction error at timestep 3429 is 0.012
Current timestep = 3430. State = [[-0.3871788  0.2034564]]. Action = [[0.        0.        0.        0.5074626]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 3430 is [True, False, False, False, False, True]
State prediction error at timestep 3430 is 0.012
Current timestep = 3431. State = [[-0.3871788   0.20345636]]. Action = [[0.        0.        0.        0.7158344]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 3431 is [True, False, False, False, False, True]
State prediction error at timestep 3431 is 0.012
Current timestep = 3432. State = [[-0.3871788   0.20345631]]. Action = [[0.        0.        0.        0.1021235]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 3432 is [True, False, False, False, False, True]
State prediction error at timestep 3432 is 0.012
Current timestep = 3433. State = [[-0.3871788   0.20345625]]. Action = [[0.         0.         0.         0.61770475]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 3433 is [True, False, False, False, False, True]
State prediction error at timestep 3433 is 0.012
Current timestep = 3434. State = [[-0.3871788   0.20345621]]. Action = [[ 0.          0.          0.         -0.85310674]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 3434 is [True, False, False, False, False, True]
State prediction error at timestep 3434 is 0.012
Current timestep = 3435. State = [[-0.3871788   0.20345616]]. Action = [[ 0.         0.         0.        -0.7862683]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 3435 is [True, False, False, False, False, True]
State prediction error at timestep 3435 is 0.012
Current timestep = 3436. State = [[-0.38717884  0.2034561 ]]. Action = [[ 0.        0.        0.       -0.121171]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 3436 is [True, False, False, False, False, True]
State prediction error at timestep 3436 is 0.012
Current timestep = 3437. State = [[-0.38717884  0.20345606]]. Action = [[ 0.         0.         0.        -0.4458238]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 3437 is [True, False, False, False, False, True]
State prediction error at timestep 3437 is 0.012
Current timestep = 3438. State = [[-0.38717884  0.20345601]]. Action = [[0.        0.        0.        0.6345662]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 3438 is [True, False, False, False, False, True]
State prediction error at timestep 3438 is 0.012
Current timestep = 3439. State = [[-0.38717884  0.20345595]]. Action = [[ 0.          0.          0.         -0.71397936]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 3439 is [True, False, False, False, False, True]
State prediction error at timestep 3439 is 0.012
Current timestep = 3440. State = [[-0.38717884  0.20345591]]. Action = [[0.         0.         0.         0.15369022]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 3440 is [True, False, False, False, False, True]
State prediction error at timestep 3440 is 0.012
Current timestep = 3441. State = [[-0.38717884  0.20345587]]. Action = [[ 0.          0.          0.         -0.94353527]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 3441 is [True, False, False, False, False, True]
State prediction error at timestep 3441 is 0.012
Current timestep = 3442. State = [[-0.38717884  0.2034558 ]]. Action = [[0.         0.         0.         0.23783374]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 3442 is [True, False, False, False, False, True]
State prediction error at timestep 3442 is 0.012
Current timestep = 3443. State = [[-0.38717887  0.20345576]]. Action = [[0.         0.         0.         0.74856424]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 3443 is [True, False, False, False, False, True]
State prediction error at timestep 3443 is 0.012
Current timestep = 3444. State = [[-0.38717887  0.20345572]]. Action = [[ 0.          0.          0.         -0.93162334]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 3444 is [True, False, False, False, False, True]
State prediction error at timestep 3444 is 0.012
Current timestep = 3445. State = [[-0.38717887  0.20345566]]. Action = [[0.        0.        0.        0.3055849]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 3445 is [True, False, False, False, False, True]
State prediction error at timestep 3445 is 0.012
Current timestep = 3446. State = [[-0.38717887  0.20345561]]. Action = [[ 0.         0.         0.        -0.6492977]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 3446 is [True, False, False, False, False, True]
State prediction error at timestep 3446 is 0.012
Current timestep = 3447. State = [[-0.38717887  0.20345557]]. Action = [[ 0.          0.          0.         -0.08379412]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 3447 is [True, False, False, False, False, True]
State prediction error at timestep 3447 is 0.012
Current timestep = 3448. State = [[-0.38717887  0.20345551]]. Action = [[ 0.          0.          0.         -0.75423974]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 3448 is [True, False, False, False, False, True]
State prediction error at timestep 3448 is 0.012
Current timestep = 3449. State = [[-0.38717887  0.20345546]]. Action = [[0.         0.         0.         0.27378988]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 3449 is [True, False, False, False, False, True]
State prediction error at timestep 3449 is 0.012
Current timestep = 3450. State = [[-0.38717887  0.20345542]]. Action = [[ 0.         0.         0.        -0.0455727]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 3450 is [True, False, False, False, False, True]
State prediction error at timestep 3450 is 0.012
Current timestep = 3451. State = [[-0.3871789   0.20345536]]. Action = [[0.         0.         0.         0.19614851]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 3451 is [True, False, False, False, False, True]
State prediction error at timestep 3451 is 0.012
Current timestep = 3452. State = [[-0.3871789   0.20345531]]. Action = [[0.         0.         0.         0.05389261]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 3452 is [True, False, False, False, False, True]
State prediction error at timestep 3452 is 0.012
Current timestep = 3453. State = [[-0.3871789   0.20345527]]. Action = [[0.        0.        0.        0.8785274]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 3453 is [True, False, False, False, False, True]
State prediction error at timestep 3453 is 0.012
Current timestep = 3454. State = [[-0.3871789   0.20345521]]. Action = [[0.        0.        0.        0.8872156]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 3454 is [True, False, False, False, False, True]
State prediction error at timestep 3454 is 0.012
Current timestep = 3455. State = [[-0.3871789   0.20345517]]. Action = [[0.        0.        0.        0.9660051]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 3455 is [True, False, False, False, False, True]
State prediction error at timestep 3455 is 0.012
Current timestep = 3456. State = [[-0.3871789   0.20345512]]. Action = [[ 0.          0.          0.         -0.14454997]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 3456 is [True, False, False, False, False, True]
State prediction error at timestep 3456 is 0.012
Current timestep = 3457. State = [[-0.3871789   0.20345506]]. Action = [[ 0.          0.          0.         -0.83055925]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 3457 is [True, False, False, False, False, True]
State prediction error at timestep 3457 is 0.012
Current timestep = 3458. State = [[-0.3871789   0.20345502]]. Action = [[ 0.          0.          0.         -0.41807663]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 3458 is [True, False, False, False, False, True]
State prediction error at timestep 3458 is 0.012
Current timestep = 3459. State = [[-0.3871789   0.20345497]]. Action = [[ 0.         0.         0.        -0.9452232]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 3459 is [True, False, False, False, False, True]
State prediction error at timestep 3459 is 0.012
Current timestep = 3460. State = [[-0.3871789   0.20345491]]. Action = [[ 0.          0.          0.         -0.48121798]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 3460 is [True, False, False, False, False, True]
State prediction error at timestep 3460 is 0.012
Current timestep = 3461. State = [[-0.38717893  0.20345487]]. Action = [[ 0.          0.          0.         -0.00880402]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 3461 is [True, False, False, False, False, True]
State prediction error at timestep 3461 is 0.012
Current timestep = 3462. State = [[-0.38717893  0.2034548 ]]. Action = [[ 0.         0.         0.        -0.9112931]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 3462 is [True, False, False, False, False, True]
State prediction error at timestep 3462 is 0.012
Current timestep = 3463. State = [[-0.38717893  0.20345476]]. Action = [[ 0.         0.         0.        -0.7189687]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 3463 is [True, False, False, False, False, True]
State prediction error at timestep 3463 is 0.012
Current timestep = 3464. State = [[-0.38717893  0.20345472]]. Action = [[ 0.         0.         0.        -0.0136655]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 3464 is [True, False, False, False, False, True]
State prediction error at timestep 3464 is 0.012
Current timestep = 3465. State = [[-0.38717893  0.20345466]]. Action = [[0.         0.         0.         0.07903183]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 3465 is [True, False, False, False, False, True]
State prediction error at timestep 3465 is 0.012
Current timestep = 3466. State = [[-0.38717893  0.20345461]]. Action = [[ 0.          0.          0.         -0.10915351]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 3466 is [True, False, False, False, False, True]
State prediction error at timestep 3466 is 0.012
Current timestep = 3467. State = [[-0.38717893  0.20345457]]. Action = [[ 0.         0.         0.        -0.7813416]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 3467 is [True, False, False, False, False, True]
State prediction error at timestep 3467 is 0.012
Current timestep = 3468. State = [[-0.38717893  0.20345451]]. Action = [[ 0.         0.         0.        -0.8759085]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 3468 is [True, False, False, False, False, True]
State prediction error at timestep 3468 is 0.012
Current timestep = 3469. State = [[-0.38717893  0.20345446]]. Action = [[0.         0.         0.         0.46514177]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 3469 is [True, False, False, False, False, True]
State prediction error at timestep 3469 is 0.012
Current timestep = 3470. State = [[-0.38717893  0.20345442]]. Action = [[0.         0.         0.         0.18805623]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 3470 is [True, False, False, False, False, True]
State prediction error at timestep 3470 is 0.012
Current timestep = 3471. State = [[-0.38717893  0.20345436]]. Action = [[0.         0.         0.         0.10843992]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 3471 is [True, False, False, False, False, True]
State prediction error at timestep 3471 is 0.012
Current timestep = 3472. State = [[-0.38717893  0.20345432]]. Action = [[ 0.         0.         0.        -0.6103995]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 3472 is [True, False, False, False, False, True]
State prediction error at timestep 3472 is 0.012
Current timestep = 3473. State = [[-0.38717893  0.20345427]]. Action = [[ 0.         0.         0.        -0.5557888]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 3473 is [True, False, False, False, False, True]
State prediction error at timestep 3473 is 0.012
Current timestep = 3474. State = [[-0.38717893  0.20345421]]. Action = [[0.         0.         0.         0.48943782]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 3474 is [True, False, False, False, False, True]
State prediction error at timestep 3474 is 0.012
Current timestep = 3475. State = [[-0.38717893  0.20345417]]. Action = [[0.         0.         0.         0.34589994]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 3475 is [True, False, False, False, False, True]
State prediction error at timestep 3475 is 0.012
Current timestep = 3476. State = [[-0.38717893  0.20345412]]. Action = [[ 0.         0.         0.        -0.8570243]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 3476 is [True, False, False, False, False, True]
State prediction error at timestep 3476 is 0.012
Current timestep = 3477. State = [[-0.38717893  0.20345406]]. Action = [[ 0.          0.          0.         -0.32677746]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 3477 is [True, False, False, False, False, True]
State prediction error at timestep 3477 is 0.012
Current timestep = 3478. State = [[-0.38717893  0.20345402]]. Action = [[ 0.          0.          0.         -0.73091286]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 3478 is [True, False, False, False, False, True]
State prediction error at timestep 3478 is 0.012
Current timestep = 3479. State = [[-0.38717893  0.20345397]]. Action = [[ 0.          0.          0.         -0.35427868]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 3479 is [True, False, False, False, False, True]
State prediction error at timestep 3479 is 0.012
Current timestep = 3480. State = [[-0.38717893  0.20345391]]. Action = [[0.        0.        0.        0.5655749]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 3480 is [True, False, False, False, False, True]
State prediction error at timestep 3480 is 0.012
Current timestep = 3481. State = [[-0.38717893  0.20345387]]. Action = [[0.         0.         0.         0.30962563]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 3481 is [True, False, False, False, False, True]
State prediction error at timestep 3481 is 0.012
Current timestep = 3482. State = [[-0.38717893  0.20345382]]. Action = [[0.        0.        0.        0.9808965]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 3482 is [True, False, False, False, False, True]
State prediction error at timestep 3482 is 0.012
Current timestep = 3483. State = [[-0.38717896  0.20345376]]. Action = [[ 0.          0.          0.         -0.13356185]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 3483 is [True, False, False, False, False, True]
State prediction error at timestep 3483 is 0.012
Current timestep = 3484. State = [[-0.38717896  0.20345372]]. Action = [[0.         0.         0.         0.23140585]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 3484 is [True, False, False, False, False, True]
State prediction error at timestep 3484 is 0.012
Current timestep = 3485. State = [[-0.38717896  0.20345367]]. Action = [[0.         0.         0.         0.84460473]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 3485 is [True, False, False, False, False, True]
State prediction error at timestep 3485 is 0.012
Current timestep = 3486. State = [[-0.38717896  0.20345362]]. Action = [[0.         0.         0.         0.14724588]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 3486 is [True, False, False, False, False, True]
State prediction error at timestep 3486 is 0.012
Current timestep = 3487. State = [[-0.38717896  0.20345357]]. Action = [[ 0.         0.         0.        -0.1495471]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 3487 is [True, False, False, False, False, True]
State prediction error at timestep 3487 is 0.012
Current timestep = 3488. State = [[-0.38717896  0.20345353]]. Action = [[0.         0.         0.         0.02423096]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 3488 is [True, False, False, False, False, True]
State prediction error at timestep 3488 is 0.012
Current timestep = 3489. State = [[-0.38717896  0.20345347]]. Action = [[0.        0.        0.        0.2205652]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 3489 is [True, False, False, False, False, True]
State prediction error at timestep 3489 is 0.012
Current timestep = 3490. State = [[-0.38717896  0.20345342]]. Action = [[0.         0.         0.         0.10273778]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 3490 is [True, False, False, False, False, True]
State prediction error at timestep 3490 is 0.012
Current timestep = 3491. State = [[-0.38717896  0.20345338]]. Action = [[0.         0.         0.         0.47133458]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 3491 is [True, False, False, False, False, True]
State prediction error at timestep 3491 is 0.012
Current timestep = 3492. State = [[-0.38717896  0.20345332]]. Action = [[ 0.         0.         0.        -0.4242438]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 3492 is [True, False, False, False, False, True]
State prediction error at timestep 3492 is 0.012
Current timestep = 3493. State = [[-0.38717896  0.20345327]]. Action = [[0.        0.        0.        0.5929973]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 3493 is [True, False, False, False, False, True]
State prediction error at timestep 3493 is 0.012
Current timestep = 3494. State = [[-0.38717896  0.20345323]]. Action = [[0.         0.         0.         0.22457683]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 3494 is [True, False, False, False, False, True]
State prediction error at timestep 3494 is 0.012
Current timestep = 3495. State = [[-0.38717896  0.20345317]]. Action = [[0.         0.         0.         0.64640236]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 3495 is [True, False, False, False, False, True]
State prediction error at timestep 3495 is 0.012
Current timestep = 3496. State = [[-0.38717893  0.20345312]]. Action = [[ 0.          0.          0.         -0.15655601]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 3496 is [True, False, False, False, False, True]
State prediction error at timestep 3496 is 0.012
Current timestep = 3497. State = [[-0.38717893  0.20345308]]. Action = [[ 0.          0.          0.         -0.74080765]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 3497 is [True, False, False, False, False, True]
State prediction error at timestep 3497 is 0.012
Current timestep = 3498. State = [[-0.38717893  0.20345302]]. Action = [[ 0.         0.         0.        -0.6318694]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 3498 is [True, False, False, False, False, True]
State prediction error at timestep 3498 is 0.012
Current timestep = 3499. State = [[-0.38717893  0.20345297]]. Action = [[0.         0.         0.         0.38228583]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 3499 is [True, False, False, False, False, True]
State prediction error at timestep 3499 is 0.012
Current timestep = 3500. State = [[-0.38717893  0.20345293]]. Action = [[0.         0.         0.         0.09750056]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 3500 is [True, False, False, False, False, True]
State prediction error at timestep 3500 is 0.012
Current timestep = 3501. State = [[-0.38717893  0.20345287]]. Action = [[ 0.        0.        0.       -0.610652]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 3501 is [True, False, False, False, False, True]
State prediction error at timestep 3501 is 0.012
Current timestep = 3502. State = [[-0.38717893  0.20345283]]. Action = [[0.         0.         0.         0.07859457]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 3502 is [True, False, False, False, False, True]
State prediction error at timestep 3502 is 0.012
Current timestep = 3503. State = [[-0.38717893  0.20345278]]. Action = [[0.        0.        0.        0.6044047]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 3503 is [True, False, False, False, False, True]
State prediction error at timestep 3503 is 0.012
Current timestep = 3504. State = [[-0.38717893  0.20345272]]. Action = [[0.         0.         0.         0.02992237]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 3504 is [True, False, False, False, False, True]
State prediction error at timestep 3504 is 0.012
Current timestep = 3505. State = [[-0.38717893  0.20345268]]. Action = [[0.         0.         0.         0.75760555]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 3505 is [True, False, False, False, False, True]
State prediction error at timestep 3505 is 0.012
Current timestep = 3506. State = [[-0.38717893  0.20345263]]. Action = [[0.         0.         0.         0.45943987]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 3506 is [True, False, False, False, False, True]
State prediction error at timestep 3506 is 0.012
Current timestep = 3507. State = [[-0.38717893  0.20345257]]. Action = [[ 0.          0.          0.         -0.87307966]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 3507 is [True, False, False, False, False, True]
State prediction error at timestep 3507 is 0.012
Current timestep = 3508. State = [[-0.38717893  0.20345253]]. Action = [[ 0.         0.         0.        -0.6712033]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 3508 is [True, False, False, False, False, True]
State prediction error at timestep 3508 is 0.012
Current timestep = 3509. State = [[-0.38717893  0.20345248]]. Action = [[ 0.          0.          0.         -0.46932113]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 3509 is [True, False, False, False, False, True]
State prediction error at timestep 3509 is 0.012
Current timestep = 3510. State = [[-0.38717893  0.20345242]]. Action = [[0.         0.         0.         0.23310995]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 3510 is [True, False, False, False, False, True]
State prediction error at timestep 3510 is 0.012
Current timestep = 3511. State = [[-0.38717893  0.20345238]]. Action = [[0.         0.         0.         0.34117055]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 3511 is [True, False, False, False, False, True]
State prediction error at timestep 3511 is 0.012
Current timestep = 3512. State = [[-0.38717893  0.20345233]]. Action = [[ 0.          0.          0.         -0.42594934]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 3512 is [True, False, False, False, False, True]
State prediction error at timestep 3512 is 0.012
Current timestep = 3513. State = [[-0.38717893  0.20345227]]. Action = [[ 0.         0.         0.        -0.1884458]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 3513 is [True, False, False, False, False, True]
State prediction error at timestep 3513 is 0.012
Current timestep = 3514. State = [[-0.38717893  0.20345223]]. Action = [[0.        0.        0.        0.9943832]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 3514 is [True, False, False, False, False, True]
State prediction error at timestep 3514 is 0.012
Current timestep = 3515. State = [[-0.38717893  0.20345218]]. Action = [[0.         0.         0.         0.06814408]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 3515 is [True, False, False, False, False, True]
State prediction error at timestep 3515 is 0.012
Current timestep = 3516. State = [[-0.38717893  0.20345213]]. Action = [[ 0.          0.          0.         -0.03348035]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 3516 is [True, False, False, False, False, True]
State prediction error at timestep 3516 is 0.012
Current timestep = 3517. State = [[-0.38717893  0.20345208]]. Action = [[ 0.         0.         0.        -0.5681025]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 3517 is [True, False, False, False, False, True]
State prediction error at timestep 3517 is 0.012
Current timestep = 3518. State = [[-0.38717893  0.20345204]]. Action = [[0.         0.         0.         0.13779855]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 3518 is [True, False, False, False, False, True]
State prediction error at timestep 3518 is 0.012
Current timestep = 3519. State = [[-0.38717893  0.20345198]]. Action = [[0.         0.         0.         0.34383833]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 3519 is [True, False, False, False, False, True]
State prediction error at timestep 3519 is 0.012
Current timestep = 3520. State = [[-0.3871789   0.20345193]]. Action = [[ 0.         0.         0.        -0.6245257]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 3520 is [True, False, False, False, False, True]
State prediction error at timestep 3520 is 0.012
Current timestep = 3521. State = [[-0.3871789   0.20345189]]. Action = [[0.         0.         0.         0.46066022]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 3521 is [True, False, False, False, False, True]
State prediction error at timestep 3521 is 0.012
Current timestep = 3522. State = [[-0.3871789   0.20345183]]. Action = [[0.         0.         0.         0.28870034]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 3522 is [True, False, False, False, False, True]
State prediction error at timestep 3522 is 0.012
Current timestep = 3523. State = [[-0.3871789   0.20345178]]. Action = [[0.        0.        0.        0.8623265]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 3523 is [True, False, False, False, False, True]
State prediction error at timestep 3523 is 0.012
Current timestep = 3524. State = [[-0.3871789   0.20345174]]. Action = [[ 0.         0.         0.        -0.5340454]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 3524 is [True, False, False, False, False, True]
State prediction error at timestep 3524 is 0.012
Current timestep = 3525. State = [[-0.3871789   0.20345168]]. Action = [[0.        0.        0.        0.8787044]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 3525 is [True, False, False, False, False, True]
State prediction error at timestep 3525 is 0.012
Current timestep = 3526. State = [[-0.3871789   0.20345163]]. Action = [[0.        0.        0.        0.9955611]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 3526 is [True, False, False, False, False, True]
State prediction error at timestep 3526 is 0.012
Current timestep = 3527. State = [[-0.3871789   0.20345159]]. Action = [[ 0.         0.         0.        -0.4551947]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 3527 is [True, False, False, False, False, True]
State prediction error at timestep 3527 is 0.012
Current timestep = 3528. State = [[-0.3871789   0.20345153]]. Action = [[0.         0.         0.         0.52393675]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 3528 is [True, False, False, False, False, True]
State prediction error at timestep 3528 is 0.012
Current timestep = 3529. State = [[-0.3871789   0.20345148]]. Action = [[0.         0.         0.         0.03873813]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 3529 is [True, False, False, False, False, True]
State prediction error at timestep 3529 is 0.012
Current timestep = 3530. State = [[-0.3871789   0.20345144]]. Action = [[ 0.         0.         0.        -0.5861325]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 3530 is [True, False, False, False, False, True]
State prediction error at timestep 3530 is 0.012
Current timestep = 3531. State = [[-0.3871789  0.2034514]]. Action = [[ 0.         0.         0.        -0.1216346]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 3531 is [True, False, False, False, False, True]
State prediction error at timestep 3531 is 0.012
Current timestep = 3532. State = [[-0.3871789   0.20345134]]. Action = [[0.         0.         0.         0.17494464]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 3532 is [True, False, False, False, False, True]
State prediction error at timestep 3532 is 0.012
Current timestep = 3533. State = [[-0.38717887  0.20345129]]. Action = [[0.         0.         0.         0.17322421]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 3533 is [True, False, False, False, False, True]
State prediction error at timestep 3533 is 0.012
Current timestep = 3534. State = [[-0.38717887  0.20345125]]. Action = [[ 0.          0.          0.         -0.24759912]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 3534 is [True, False, False, False, False, True]
State prediction error at timestep 3534 is 0.012
Current timestep = 3535. State = [[-0.38717887  0.20345119]]. Action = [[ 0.          0.          0.         -0.75012773]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 3535 is [True, False, False, False, False, True]
State prediction error at timestep 3535 is 0.012
Current timestep = 3536. State = [[-0.38717887  0.20345114]]. Action = [[ 0.          0.          0.         -0.81755227]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 3536 is [True, False, False, False, False, True]
State prediction error at timestep 3536 is 0.012
Current timestep = 3537. State = [[-0.38717887  0.2034511 ]]. Action = [[ 0.          0.          0.         -0.90020126]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 3537 is [True, False, False, False, False, True]
State prediction error at timestep 3537 is 0.012
Current timestep = 3538. State = [[-0.38717887  0.20345104]]. Action = [[0.         0.         0.         0.81579924]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 3538 is [True, False, False, False, False, True]
State prediction error at timestep 3538 is 0.012
Current timestep = 3539. State = [[-0.38717887  0.203451  ]]. Action = [[0.         0.         0.         0.33517814]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 3539 is [True, False, False, False, False, True]
State prediction error at timestep 3539 is 0.012
Current timestep = 3540. State = [[-0.38717887  0.20345095]]. Action = [[0.        0.        0.        0.6021751]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 3540 is [True, False, False, False, False, True]
State prediction error at timestep 3540 is 0.012
Current timestep = 3541. State = [[-0.38717887  0.20345089]]. Action = [[0.         0.         0.         0.63934827]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 3541 is [True, False, False, False, False, True]
State prediction error at timestep 3541 is 0.012
Current timestep = 3542. State = [[-0.38717887  0.20345084]]. Action = [[ 0.         0.         0.        -0.8173078]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 3542 is [True, False, False, False, False, True]
State prediction error at timestep 3542 is 0.012
Current timestep = 3543. State = [[-0.38717887  0.2034508 ]]. Action = [[0.         0.         0.         0.30437446]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 3543 is [True, False, False, False, False, True]
State prediction error at timestep 3543 is 0.012
Current timestep = 3544. State = [[-0.38717884  0.20345074]]. Action = [[ 0.          0.          0.         -0.08588946]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 3544 is [True, False, False, False, False, True]
State prediction error at timestep 3544 is 0.012
Current timestep = 3545. State = [[-0.38717884  0.2034507 ]]. Action = [[ 0.         0.         0.        -0.4561113]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 3545 is [True, False, False, False, False, True]
State prediction error at timestep 3545 is 0.012
Current timestep = 3546. State = [[-0.38717884  0.20345065]]. Action = [[ 0.         0.         0.        -0.2863196]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 3546 is [True, False, False, False, False, True]
State prediction error at timestep 3546 is 0.012
Current timestep = 3547. State = [[-0.38717884  0.2034506 ]]. Action = [[0.         0.         0.         0.24251533]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 3547 is [True, False, False, False, False, True]
State prediction error at timestep 3547 is 0.012
Current timestep = 3548. State = [[-0.38717884  0.20345055]]. Action = [[0.         0.         0.         0.25772464]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 3548 is [True, False, False, False, False, True]
State prediction error at timestep 3548 is 0.012
Current timestep = 3549. State = [[-0.38717884  0.2034505 ]]. Action = [[0.        0.        0.        0.7946559]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 3549 is [True, False, False, False, False, True]
State prediction error at timestep 3549 is 0.012
Current timestep = 3550. State = [[-0.38717884  0.20345046]]. Action = [[ 0.          0.          0.         -0.16083294]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 3550 is [True, False, False, False, False, True]
State prediction error at timestep 3550 is 0.012
Current timestep = 3551. State = [[-0.38717884  0.2034504 ]]. Action = [[0.         0.         0.         0.00956571]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 3551 is [True, False, False, False, False, True]
State prediction error at timestep 3551 is 0.012
Current timestep = 3552. State = [[-0.38717884  0.20345035]]. Action = [[0.         0.         0.         0.14857852]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 3552 is [True, False, False, False, False, True]
State prediction error at timestep 3552 is 0.012
Current timestep = 3553. State = [[-0.3871788  0.2034503]]. Action = [[ 0.          0.          0.         -0.28490496]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 3553 is [True, False, False, False, False, True]
State prediction error at timestep 3553 is 0.012
Current timestep = 3554. State = [[-0.3871788   0.20345025]]. Action = [[0.        0.        0.        0.5022532]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 3554 is [True, False, False, False, False, True]
State prediction error at timestep 3554 is 0.012
Current timestep = 3555. State = [[-0.3871788  0.2034502]]. Action = [[ 0.          0.          0.         -0.41444808]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 3555 is [True, False, False, False, False, True]
State prediction error at timestep 3555 is 0.012
Current timestep = 3556. State = [[-0.3871788   0.20345016]]. Action = [[0.         0.         0.         0.20464456]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 3556 is [True, False, False, False, False, True]
State prediction error at timestep 3556 is 0.012
Current timestep = 3557. State = [[-0.3871788  0.2034501]]. Action = [[ 0.         0.         0.        -0.9075777]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 3557 is [True, False, False, False, False, True]
State prediction error at timestep 3557 is 0.012
Current timestep = 3558. State = [[-0.3871788   0.20345005]]. Action = [[0.         0.         0.         0.97363317]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 3558 is [True, False, False, False, False, True]
State prediction error at timestep 3558 is 0.012
Current timestep = 3559. State = [[-0.3871788   0.20345001]]. Action = [[ 0.         0.         0.        -0.7250777]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 3559 is [True, False, False, False, False, True]
State prediction error at timestep 3559 is 0.012
Current timestep = 3560. State = [[-0.3871788   0.20344996]]. Action = [[0.         0.         0.         0.35348487]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 3560 is [True, False, False, False, False, True]
State prediction error at timestep 3560 is 0.012
Current timestep = 3561. State = [[-0.38717878  0.2034499 ]]. Action = [[0.         0.         0.         0.05443728]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 3561 is [True, False, False, False, False, True]
State prediction error at timestep 3561 is 0.012
Current timestep = 3562. State = [[-0.38717878  0.20344986]]. Action = [[0.         0.         0.         0.46345663]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 3562 is [True, False, False, False, False, True]
State prediction error at timestep 3562 is 0.012
Current timestep = 3563. State = [[-0.38717878  0.20344982]]. Action = [[ 0.         0.         0.        -0.9193249]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 3563 is [True, False, False, False, False, True]
State prediction error at timestep 3563 is 0.012
Current timestep = 3564. State = [[-0.38717878  0.20344976]]. Action = [[ 0.        0.        0.       -0.527146]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 3564 is [True, False, False, False, False, True]
State prediction error at timestep 3564 is 0.012
Current timestep = 3565. State = [[-0.38717878  0.20344971]]. Action = [[ 0.         0.         0.        -0.3294012]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 3565 is [True, False, False, False, False, True]
State prediction error at timestep 3565 is 0.012
Current timestep = 3566. State = [[-0.38717878  0.20344967]]. Action = [[ 0.         0.         0.        -0.5271395]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 3566 is [True, False, False, False, False, True]
State prediction error at timestep 3566 is 0.012
Current timestep = 3567. State = [[-0.38717878  0.20344962]]. Action = [[0.         0.         0.         0.10214794]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 3567 is [True, False, False, False, False, True]
State prediction error at timestep 3567 is 0.012
Current timestep = 3568. State = [[-0.38717878  0.20344956]]. Action = [[0.        0.        0.        0.8077333]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 3568 is [True, False, False, False, False, True]
State prediction error at timestep 3568 is 0.012
Current timestep = 3569. State = [[-0.38717875  0.20344952]]. Action = [[ 0.          0.          0.         -0.23624599]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 3569 is [True, False, False, False, False, True]
State prediction error at timestep 3569 is 0.012
Current timestep = 3570. State = [[-0.38717875  0.20344947]]. Action = [[0.        0.        0.        0.8391857]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 3570 is [True, False, False, False, False, True]
State prediction error at timestep 3570 is 0.012
Current timestep = 3571. State = [[-0.38717875  0.20344941]]. Action = [[0.        0.        0.        0.7131157]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 3571 is [True, False, False, False, False, True]
State prediction error at timestep 3571 is 0.012
Current timestep = 3572. State = [[-0.38717875  0.20344937]]. Action = [[0.        0.        0.        0.5716467]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 3572 is [True, False, False, False, False, True]
State prediction error at timestep 3572 is 0.012
Current timestep = 3573. State = [[-0.38717875  0.20344932]]. Action = [[0.         0.         0.         0.00649679]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 3573 is [True, False, False, False, False, True]
State prediction error at timestep 3573 is 0.012
Current timestep = 3574. State = [[-0.38717875  0.20344926]]. Action = [[0.         0.         0.         0.21763921]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 3574 is [True, False, False, False, False, True]
State prediction error at timestep 3574 is 0.012
Current timestep = 3575. State = [[-0.38717875  0.20344922]]. Action = [[ 0.         0.         0.        -0.6978139]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 3575 is [True, False, False, False, False, True]
State prediction error at timestep 3575 is 0.012
Current timestep = 3576. State = [[-0.38717872  0.20344917]]. Action = [[0.        0.        0.        0.1894877]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 3576 is [True, False, False, False, False, True]
State prediction error at timestep 3576 is 0.012
Current timestep = 3577. State = [[-0.38717872  0.20344913]]. Action = [[0.        0.        0.        0.6184795]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 3577 is [True, False, False, False, False, True]
State prediction error at timestep 3577 is 0.012
Current timestep = 3578. State = [[-0.38717872  0.20344907]]. Action = [[0.         0.         0.         0.18289924]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 3578 is [True, False, False, False, False, True]
State prediction error at timestep 3578 is 0.012
Current timestep = 3579. State = [[-0.38717872  0.20344903]]. Action = [[ 0.          0.          0.         -0.32727635]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 3579 is [True, False, False, False, False, True]
State prediction error at timestep 3579 is 0.012
Current timestep = 3580. State = [[-0.38717872  0.20344898]]. Action = [[ 0.          0.          0.         -0.42644167]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 3580 is [True, False, False, False, False, True]
State prediction error at timestep 3580 is 0.012
Current timestep = 3581. State = [[-0.38717872  0.20344892]]. Action = [[0.         0.         0.         0.14450479]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 3581 is [True, False, False, False, False, True]
State prediction error at timestep 3581 is 0.012
Current timestep = 3582. State = [[-0.3871787   0.20344888]]. Action = [[ 0.         0.         0.        -0.8995262]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 3582 is [True, False, False, False, False, True]
State prediction error at timestep 3582 is 0.012
Current timestep = 3583. State = [[-0.3871787   0.20344883]]. Action = [[0.         0.         0.         0.49690914]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 3583 is [True, False, False, False, False, True]
State prediction error at timestep 3583 is 0.012
Current timestep = 3584. State = [[-0.3871787   0.20344879]]. Action = [[ 0.         0.         0.        -0.0130204]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 3584 is [True, False, False, False, False, True]
State prediction error at timestep 3584 is 0.012
Current timestep = 3585. State = [[-0.3871787   0.20344873]]. Action = [[0.         0.         0.         0.15918148]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 3585 is [True, False, False, False, False, True]
State prediction error at timestep 3585 is 0.012
Current timestep = 3586. State = [[-0.3871787   0.20344868]]. Action = [[ 0.          0.          0.         -0.59240204]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 3586 is [True, False, False, False, False, True]
State prediction error at timestep 3586 is 0.012
Current timestep = 3587. State = [[-0.3871787   0.20344864]]. Action = [[0.        0.        0.        0.5845597]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 3587 is [True, False, False, False, False, True]
State prediction error at timestep 3587 is 0.012
Current timestep = 3588. State = [[-0.3871787   0.20344858]]. Action = [[0.         0.         0.         0.09983277]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 3588 is [True, False, False, False, False, True]
State prediction error at timestep 3588 is 0.012
Current timestep = 3589. State = [[-0.38717866  0.20344853]]. Action = [[ 0.          0.          0.         -0.68390906]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 3589 is [True, False, False, False, False, True]
State prediction error at timestep 3589 is 0.012
Current timestep = 3590. State = [[-0.38717866  0.20344849]]. Action = [[ 0.         0.         0.        -0.6444321]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 3590 is [True, False, False, False, False, True]
State prediction error at timestep 3590 is 0.012
Current timestep = 3591. State = [[-0.38717866  0.20344844]]. Action = [[0.        0.        0.        0.9697385]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 3591 is [True, False, False, False, False, True]
State prediction error at timestep 3591 is 0.012
Current timestep = 3592. State = [[-0.38717866  0.20344839]]. Action = [[ 0.         0.         0.        -0.4961726]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 3592 is [True, False, False, False, False, True]
State prediction error at timestep 3592 is 0.012
Current timestep = 3593. State = [[-0.38717866  0.20344834]]. Action = [[0.         0.         0.         0.70486534]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 3593 is [True, False, False, False, False, True]
State prediction error at timestep 3593 is 0.012
Current timestep = 3594. State = [[-0.38717866  0.2034483 ]]. Action = [[0.         0.         0.         0.53818345]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 3594 is [True, False, False, False, False, True]
State prediction error at timestep 3594 is 0.012
Current timestep = 3595. State = [[-0.38717863  0.20344825]]. Action = [[ 0.          0.          0.         -0.35390025]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 3595 is [True, False, False, False, False, True]
State prediction error at timestep 3595 is 0.012
Current timestep = 3596. State = [[-0.38717863  0.20344819]]. Action = [[0.        0.        0.        0.8609679]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 3596 is [True, False, False, False, False, True]
State prediction error at timestep 3596 is 0.012
Current timestep = 3597. State = [[-0.38717863  0.20344815]]. Action = [[ 0.         0.         0.        -0.5800547]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 3597 is [True, False, False, False, False, True]
State prediction error at timestep 3597 is 0.012
Current timestep = 3598. State = [[-0.38717863  0.2034481 ]]. Action = [[0.       0.       0.       0.902861]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 3598 is [True, False, False, False, False, True]
State prediction error at timestep 3598 is 0.012
Current timestep = 3599. State = [[-0.3468978   0.16057837]]. Action = [[ 0.          0.          0.         -0.07876366]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 3599 is [True, False, False, False, False, True]
State prediction error at timestep 3599 is 0.012
Current timestep = 3600. State = [[-0.3467988   0.16065049]]. Action = [[ 0.09710019  0.03057275  0.         -0.29011458]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 3600 is [True, False, False, False, False, True]
State prediction error at timestep 3600 is 0.012
Current timestep = 3601. State = [[-0.3459868   0.15964167]]. Action = [[-0.02702417 -0.05559903  0.         -0.5425733 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 3601 is [True, False, False, False, False, True]
State prediction error at timestep 3601 is 0.012
Current timestep = 3602. State = [[-0.34227708  0.15714246]]. Action = [[ 0.09171223 -0.02792643  0.         -0.95890373]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 3602 is [True, False, False, False, False, True]
State prediction error at timestep 3602 is 0.012
Current timestep = 3603. State = [[-0.3405726   0.15630394]]. Action = [[-0.0193477  -0.00094752  0.         -0.71798015]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3603 is [True, False, False, False, False, True]
State prediction error at timestep 3603 is 0.012
Current timestep = 3604. State = [[-0.33783025  0.15439022]]. Action = [[ 0.06154693 -0.03449697  0.         -0.8532207 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 3604 is [True, False, False, False, False, True]
State prediction error at timestep 3604 is 0.012
Current timestep = 3605. State = [[-0.3363218   0.14969556]]. Action = [[-0.01000373 -0.06437701  0.          0.30023074]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 3605 is [True, False, False, False, False, True]
State prediction error at timestep 3605 is 0.012
Current timestep = 3606. State = [[-0.33762136  0.15161823]]. Action = [[-0.02982501  0.09288847  0.          0.05376065]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 3606 is [True, False, False, False, False, True]
State prediction error at timestep 3606 is 0.012
Current timestep = 3607. State = [[-0.33570474  0.15648039]]. Action = [[0.06063376 0.04911143 0.         0.35967684]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 3607 is [True, False, False, False, False, True]
State prediction error at timestep 3607 is 0.012
Current timestep = 3608. State = [[-0.3384834   0.16294053]]. Action = [[-0.08759663  0.09408148  0.         -0.6039493 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 3608 is [True, False, False, False, False, True]
State prediction error at timestep 3608 is 0.012
Current timestep = 3609. State = [[-0.33796045  0.16213898]]. Action = [[ 0.08109771 -0.08486432  0.         -0.8727584 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 3609 is [True, False, False, False, False, True]
State prediction error at timestep 3609 is 0.012
Current timestep = 3610. State = [[-0.33705202  0.16026151]]. Action = [[-0.02219829  0.00535108  0.          0.33765042]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 3610 is [True, False, False, False, False, True]
State prediction error at timestep 3610 is 0.012
Current timestep = 3611. State = [[-0.33384073  0.16521363]]. Action = [[ 0.08231702  0.09318527  0.         -0.55860615]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 3611 is [True, False, False, False, False, True]
State prediction error at timestep 3611 is 0.012
Current timestep = 3612. State = [[-0.33263814  0.16507716]]. Action = [[-0.01962031 -0.07206564  0.          0.6039543 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 3612 is [True, False, False, False, False, True]
State prediction error at timestep 3612 is 0.012
Current timestep = 3613. State = [[-0.33466637  0.16135973]]. Action = [[-0.04001445 -0.03856369  0.          0.15299678]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 3613 is [True, False, False, False, False, True]
State prediction error at timestep 3613 is 0.012
Current timestep = 3614. State = [[-0.33878484  0.15858985]]. Action = [[-0.0745977  -0.02914801  0.         -0.7198796 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 3614 is [True, False, False, False, False, True]
State prediction error at timestep 3614 is 0.012
Current timestep = 3615. State = [[-0.34473053  0.16077577]]. Action = [[-0.08871222  0.06453947  0.         -0.7321782 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 3615 is [True, False, False, False, False, True]
State prediction error at timestep 3615 is 0.012
Current timestep = 3616. State = [[-0.3514455   0.15856065]]. Action = [[-0.08743886 -0.08462416  0.         -0.8515425 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 3616 is [True, False, False, False, False, True]
State prediction error at timestep 3616 is 0.012
Current timestep = 3617. State = [[-0.3577742  0.152276 ]]. Action = [[-0.07666951 -0.07231954  0.          0.9368992 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 3617 is [True, False, False, False, False, True]
State prediction error at timestep 3617 is 0.012
Current timestep = 3618. State = [[-0.36126477  0.14484882]]. Action = [[-0.01804636 -0.08869004  0.         -0.28841925]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 3618 is [True, False, False, False, False, True]
State prediction error at timestep 3618 is 0.012
Current timestep = 3619. State = [[-0.36520332  0.14327562]]. Action = [[-0.05019833  0.04555544  0.         -0.5766472 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 3619 is [True, False, False, False, False, True]
State prediction error at timestep 3619 is 0.012
Current timestep = 3620. State = [[-0.36384192  0.1398399 ]]. Action = [[ 0.09150889 -0.07743741  0.          0.91513145]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 3620 is [True, False, False, False, False, True]
State prediction error at timestep 3620 is 0.012
Current timestep = 3621. State = [[-0.36423177  0.13690339]]. Action = [[-0.04024636  0.00507899  0.         -0.92309576]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 3621 is [True, False, False, False, False, True]
State prediction error at timestep 3621 is 0.012
Current timestep = 3622. State = [[-0.36457148  0.1390918 ]]. Action = [[ 0.03844287  0.05917879  0.         -0.89014184]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 3622 is [True, False, False, False, False, True]
State prediction error at timestep 3622 is 0.012
Current timestep = 3623. State = [[-0.3651201   0.13601509]]. Action = [[-0.00590459 -0.08948053  0.         -0.30222273]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 3623 is [True, False, False, False, False, True]
State prediction error at timestep 3623 is 0.012
Current timestep = 3624. State = [[-0.36837125  0.1305258 ]]. Action = [[-0.04434357 -0.04012591  0.         -0.6258863 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 3624 is [True, False, False, False, False, True]
State prediction error at timestep 3624 is 0.012
Current timestep = 3625. State = [[-0.36942044  0.12918371]]. Action = [[ 0.02305828  0.02066092  0.         -0.4926985 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 3625 is [True, False, False, False, False, True]
State prediction error at timestep 3625 is 0.012
Current timestep = 3626. State = [[-0.36878043  0.13137525]]. Action = [[0.02348341 0.04556835 0.         0.24396157]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 3626 is [True, False, False, False, False, True]
State prediction error at timestep 3626 is 0.012
Current timestep = 3627. State = [[-0.36936158  0.13331479]]. Action = [[-0.00263029  0.01571908  0.         -0.43140376]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 3627 is [True, False, False, False, False, True]
State prediction error at timestep 3627 is 0.012
Current timestep = 3628. State = [[-0.3747286   0.13711934]]. Action = [[-0.0901558   0.06770349  0.          0.46133494]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 3628 is [True, False, False, False, False, True]
State prediction error at timestep 3628 is 0.012
Current timestep = 3629. State = [[-0.37641147  0.135803  ]]. Action = [[ 0.04470756 -0.07023159  0.          0.30172837]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 3629 is [True, False, False, False, False, True]
State prediction error at timestep 3629 is 0.012
Current timestep = 3630. State = [[-0.37642044  0.13733418]]. Action = [[-0.00599054  0.06872385  0.          0.5864222 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 3630 is [True, False, False, False, False, True]
State prediction error at timestep 3630 is 0.012
Current timestep = 3631. State = [[-0.37486818  0.14324887]]. Action = [[0.0514233  0.06616626 0.         0.04365468]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 3631 is [True, False, False, False, False, True]
State prediction error at timestep 3631 is 0.012
Current timestep = 3632. State = [[-0.37201345  0.14908986]]. Action = [[ 0.0496996   0.05179492  0.         -0.7790682 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 3632 is [True, False, False, False, False, True]
State prediction error at timestep 3632 is 0.012
Current timestep = 3633. State = [[-0.3699966   0.14772324]]. Action = [[ 0.02456842 -0.08474554  0.          0.32510543]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 3633 is [True, False, False, False, False, True]
State prediction error at timestep 3633 is 0.012
Current timestep = 3634. State = [[-0.3736481   0.15005367]]. Action = [[-0.09199263  0.084944    0.         -0.33881104]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 3634 is [True, False, False, False, False, True]
State prediction error at timestep 3634 is 0.012
Current timestep = 3635. State = [[-0.3725492   0.15430076]]. Action = [[0.09854154 0.01807289 0.         0.5372331 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 3635 is [True, False, False, False, False, True]
State prediction error at timestep 3635 is 0.012
Current timestep = 3636. State = [[-0.36984855  0.1558332 ]]. Action = [[-0.0045987  -0.0039205   0.          0.21379995]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 3636 is [True, False, False, False, False, True]
State prediction error at timestep 3636 is 0.012
Current timestep = 3637. State = [[-0.37347996  0.15214169]]. Action = [[-0.09849034 -0.08536541  0.         -0.18349868]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 3637 is [True, False, False, False, False, True]
State prediction error at timestep 3637 is 0.012
Current timestep = 3638. State = [[-0.3730563  0.1504864]]. Action = [[0.0507431  0.01474662 0.         0.01351368]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 3638 is [True, False, False, False, False, True]
State prediction error at timestep 3638 is 0.012
Current timestep = 3639. State = [[-0.372678    0.15289725]]. Action = [[-0.04125503  0.03638213  0.         -0.73331624]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 3639 is [True, False, False, False, False, True]
State prediction error at timestep 3639 is 0.012
Current timestep = 3640. State = [[-0.37558717  0.15041392]]. Action = [[-0.06217634 -0.07633546  0.         -0.6051695 ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 3640 is [True, False, False, False, False, True]
State prediction error at timestep 3640 is 0.012
Current timestep = 3641. State = [[-0.37456197  0.15211934]]. Action = [[ 0.0482005   0.08684518  0.         -0.8835748 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 3641 is [True, False, False, False, False, True]
State prediction error at timestep 3641 is 0.012
Current timestep = 3642. State = [[-0.3720526   0.16011593]]. Action = [[ 0.0220428   0.09642123  0.         -0.30592346]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 3642 is [True, False, False, False, False, True]
State prediction error at timestep 3642 is 0.012
Current timestep = 3643. State = [[-0.36921164  0.16520678]]. Action = [[0.04902407 0.0181913  0.         0.34777677]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 3643 is [True, False, False, False, False, True]
State prediction error at timestep 3643 is 0.012
Current timestep = 3644. State = [[-0.36657414  0.16605401]]. Action = [[ 0.02812564 -0.01849079  0.         -0.46017045]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 3644 is [True, False, False, False, False, True]
State prediction error at timestep 3644 is 0.012
Current timestep = 3645. State = [[-0.3609501   0.16804789]]. Action = [[ 0.09742291  0.03289961  0.         -0.3924414 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 3645 is [True, False, False, False, False, True]
State prediction error at timestep 3645 is 0.012
Current timestep = 3646. State = [[-0.35604358  0.16612081]]. Action = [[ 0.03871112 -0.07158984  0.         -0.6424609 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 3646 is [True, False, False, False, False, True]
State prediction error at timestep 3646 is 0.012
Current timestep = 3647. State = [[-0.35718533  0.16293348]]. Action = [[-0.07346565 -0.02715193  0.          0.76301813]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 3647 is [True, False, False, False, False, True]
State prediction error at timestep 3647 is 0.012
Current timestep = 3648. State = [[-0.3559395   0.15830038]]. Action = [[ 0.04476269 -0.07162335  0.         -0.66849935]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 3648 is [True, False, False, False, False, True]
State prediction error at timestep 3648 is 0.012
Current timestep = 3649. State = [[-0.35503712  0.1590481 ]]. Action = [[-0.02607637  0.06830119  0.         -0.8026365 ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 3649 is [True, False, False, False, False, True]
State prediction error at timestep 3649 is 0.012
Current timestep = 3650. State = [[-0.35257816  0.16048104]]. Action = [[ 0.04871724 -0.00600545  0.         -0.44090986]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 3650 is [True, False, False, False, False, True]
State prediction error at timestep 3650 is 0.012
Current timestep = 3651. State = [[-0.34947568  0.15640156]]. Action = [[ 0.01969104 -0.07496945  0.          0.7285297 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 3651 is [True, False, False, False, False, True]
State prediction error at timestep 3651 is 0.012
Current timestep = 3652. State = [[-0.3432778   0.15396318]]. Action = [[ 0.09498469  0.00758042  0.         -0.6036077 ]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 3652 is [True, False, False, False, False, True]
State prediction error at timestep 3652 is 0.012
Current timestep = 3653. State = [[-0.34049484  0.15599236]]. Action = [[-0.01653335  0.04919118  0.         -0.9738969 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 3653 is [True, False, False, False, False, True]
State prediction error at timestep 3653 is 0.012
Current timestep = 3654. State = [[-0.3406136  0.1563165]]. Action = [[-0.01066177 -0.01590098  0.          0.92966104]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 3654 is [True, False, False, False, False, True]
State prediction error at timestep 3654 is 0.012
Current timestep = 3655. State = [[-0.34264284  0.15628788]]. Action = [[-0.05113684  0.01320934  0.         -0.2978053 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 3655 is [True, False, False, False, False, True]
State prediction error at timestep 3655 is 0.012
Current timestep = 3656. State = [[-0.34291482  0.1537075 ]]. Action = [[ 0.0092694  -0.05412231  0.         -0.99343854]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 3656 is [True, False, False, False, False, True]
State prediction error at timestep 3656 is 0.012
Current timestep = 3657. State = [[-0.34345043  0.15659453]]. Action = [[-0.02375384  0.0949757   0.          0.52597094]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 3657 is [True, False, False, False, False, True]
State prediction error at timestep 3657 is 0.012
Current timestep = 3658. State = [[-0.34585708  0.16402918]]. Action = [[-0.03359877  0.08637881  0.         -0.7366683 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 3658 is [True, False, False, False, False, True]
State prediction error at timestep 3658 is 0.012
Current timestep = 3659. State = [[-0.34724095  0.16552989]]. Action = [[-0.00094877 -0.04064945  0.         -0.07257968]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 3659 is [True, False, False, False, False, True]
State prediction error at timestep 3659 is 0.012
Current timestep = 3660. State = [[-0.34535864  0.16857912]]. Action = [[ 0.05001732  0.06696216  0.         -0.15726393]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 3660 is [True, False, False, False, False, True]
State prediction error at timestep 3660 is 0.012
Current timestep = 3661. State = [[-0.34768876  0.17180389]]. Action = [[-0.06610821  0.00677527  0.          0.8049085 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 3661 is [True, False, False, False, False, True]
State prediction error at timestep 3661 is 0.012
Current timestep = 3662. State = [[-0.3483605  0.1724379]]. Action = [[ 0.03603918 -0.01179919  0.          0.21811187]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 3662 is [True, False, False, False, False, True]
State prediction error at timestep 3662 is 0.012
Current timestep = 3663. State = [[-0.34467077  0.1751093 ]]. Action = [[ 0.07210325  0.04364764  0.         -0.80762726]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 3663 is [True, False, False, False, False, True]
State prediction error at timestep 3663 is 0.012
Current timestep = 3664. State = [[-0.34757608  0.17873526]]. Action = [[-0.09858508  0.03013518  0.          0.09858131]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 3664 is [True, False, False, False, False, True]
State prediction error at timestep 3664 is 0.012
Current timestep = 3665. State = [[-0.35475543  0.17925388]]. Action = [[-0.07347946 -0.0257428   0.          0.56568635]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 3665 is [True, False, False, False, False, True]
State prediction error at timestep 3665 is 0.012
Current timestep = 3666. State = [[-0.35564652  0.17471007]]. Action = [[ 0.04712542 -0.08824219  0.         -0.0091005 ]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 3666 is [True, False, False, False, False, True]
State prediction error at timestep 3666 is 0.012
Current timestep = 3667. State = [[-0.35211977  0.168654  ]]. Action = [[ 0.05869447 -0.06723181  0.          0.09487271]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 3667 is [True, False, False, False, False, True]
State prediction error at timestep 3667 is 0.012
Current timestep = 3668. State = [[-0.34832028  0.16143763]]. Action = [[ 0.04420059 -0.08976229  0.         -0.88959515]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 3668 is [True, False, False, False, False, True]
State prediction error at timestep 3668 is 0.012
Current timestep = 3669. State = [[-0.3475845   0.15813789]]. Action = [[-0.01954111  0.01004522  0.         -0.616497  ]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 3669 is [True, False, False, False, False, True]
State prediction error at timestep 3669 is 0.012
Current timestep = 3670. State = [[-0.3518365   0.16094278]]. Action = [[-0.08512859  0.07450937  0.          0.96338725]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 3670 is [True, False, False, False, False, True]
State prediction error at timestep 3670 is 0.012
Current timestep = 3671. State = [[-0.35160604  0.16270456]]. Action = [[0.06372664 0.00479071 0.         0.7225561 ]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 3671 is [True, False, False, False, False, True]
State prediction error at timestep 3671 is 0.012
Current timestep = 3672. State = [[-0.34647024  0.16594376]]. Action = [[0.07725508 0.06684173 0.         0.15008116]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 3672 is [True, False, False, False, False, True]
State prediction error at timestep 3672 is 0.012
Current timestep = 3673. State = [[-0.34558573  0.16813256]]. Action = [[-0.02246318  0.0048488   0.          0.44259787]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 3673 is [True, False, False, False, False, True]
State prediction error at timestep 3673 is 0.012
Current timestep = 3674. State = [[-0.3470826   0.16349812]]. Action = [[-0.02071913 -0.09663969  0.         -0.09554225]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 3674 is [True, False, False, False, False, True]
State prediction error at timestep 3674 is 0.012
Current timestep = 3675. State = [[-0.35022613  0.15621376]]. Action = [[-0.06381731 -0.08075405  0.          0.0024879 ]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 3675 is [True, False, False, False, False, True]
State prediction error at timestep 3675 is 0.012
Current timestep = 3676. State = [[-0.35210833  0.15281792]]. Action = [[-0.01518913 -0.00243599  0.          0.6448927 ]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 3676 is [True, False, False, False, False, True]
State prediction error at timestep 3676 is 0.012
Current timestep = 3677. State = [[-0.35031888  0.15635246]]. Action = [[ 0.04452113  0.08675852  0.         -0.4343295 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 3677 is [True, False, False, False, False, True]
State prediction error at timestep 3677 is 0.012
Current timestep = 3678. State = [[-0.35144287  0.16360462]]. Action = [[-0.03704944  0.09365793  0.          0.12888992]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 3678 is [True, False, False, False, False, True]
State prediction error at timestep 3678 is 0.012
Current timestep = 3679. State = [[-0.3567379   0.16344301]]. Action = [[-0.07922278 -0.07477973  0.         -0.46637368]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 3679 is [True, False, False, False, False, True]
State prediction error at timestep 3679 is 0.012
Current timestep = 3680. State = [[-0.35564947  0.162247  ]]. Action = [[ 0.08770143  0.01468983  0.         -0.34521103]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 3680 is [True, False, False, False, False, True]
State prediction error at timestep 3680 is 0.012
Current timestep = 3681. State = [[-0.3534601  0.1607091]]. Action = [[-0.0020092  -0.03903082  0.          0.91845846]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 3681 is [True, False, False, False, False, True]
State prediction error at timestep 3681 is 0.012
Current timestep = 3682. State = [[-0.3493826   0.15976863]]. Action = [[ 0.0766662   0.00525479  0.         -0.11572468]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 3682 is [True, False, False, False, False, True]
State prediction error at timestep 3682 is 0.012
Current timestep = 3683. State = [[-0.3444488  0.1627822]]. Action = [[ 0.05498386  0.05807143  0.         -0.21171749]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 3683 is [True, False, False, False, False, True]
State prediction error at timestep 3683 is 0.012
Current timestep = 3684. State = [[-0.34560797  0.16443332]]. Action = [[-0.06533913 -0.00491512  0.         -0.3055302 ]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 3684 is [True, False, False, False, False, True]
State prediction error at timestep 3684 is 0.012
Current timestep = 3685. State = [[-0.3451043   0.16073276]]. Action = [[ 0.04048326 -0.07458464  0.         -0.53464085]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 3685 is [True, False, False, False, False, True]
State prediction error at timestep 3685 is 0.012
Current timestep = 3686. State = [[-0.34397635  0.15853687]]. Action = [[-0.0078641   0.00438555  0.          0.51350534]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 3686 is [True, False, False, False, False, True]
State prediction error at timestep 3686 is 0.012
Current timestep = 3687. State = [[-0.34652385  0.15632206]]. Action = [[-0.06113476 -0.03889204  0.          0.07380819]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 3687 is [True, False, False, False, False, True]
State prediction error at timestep 3687 is 0.012
Current timestep = 3688. State = [[-0.34679747  0.15236771]]. Action = [[ 0.01571812 -0.04666714  0.          0.30009234]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 3688 is [True, False, False, False, False, True]
State prediction error at timestep 3688 is 0.012
Current timestep = 3689. State = [[-0.34441194  0.14515492]]. Action = [[ 0.02919888 -0.09962822  0.          0.80607414]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 3689 is [True, False, False, False, False, True]
State prediction error at timestep 3689 is 0.012
Current timestep = 3690. State = [[-0.34766194  0.14568509]]. Action = [[-0.09799464  0.09650738  0.         -0.5221347 ]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 3690 is [True, False, False, False, False, True]
State prediction error at timestep 3690 is 0.012
Current timestep = 3691. State = [[-0.34902346  0.14970924]]. Action = [[0.03476467 0.03651898 0.         0.14573312]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 3691 is [True, False, False, False, False, True]
State prediction error at timestep 3691 is 0.012
Current timestep = 3692. State = [[-0.35300174  0.15498866]]. Action = [[-0.09164061  0.08100509  0.         -0.65387106]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 3692 is [True, False, False, False, False, True]
State prediction error at timestep 3692 is 0.012
Current timestep = 3693. State = [[-0.3554975   0.15924528]]. Action = [[ 0.02174236  0.02663129  0.         -0.99244714]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 3693 is [True, False, False, False, False, True]
State prediction error at timestep 3693 is 0.012
Current timestep = 3694. State = [[-0.3560287   0.16506976]]. Action = [[0.00523988 0.08119554 0.         0.35920537]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 3694 is [True, False, False, False, False, True]
State prediction error at timestep 3694 is 0.012
Current timestep = 3695. State = [[-0.3618557   0.17211545]]. Action = [[-0.09437621  0.06890398  0.         -0.42239344]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 3695 is [True, False, False, False, False, True]
State prediction error at timestep 3695 is 0.012
Current timestep = 3696. State = [[-0.3640978   0.17968976]]. Action = [[0.05155828 0.07868763 0.         0.70671356]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 3696 is [True, False, False, False, False, True]
State prediction error at timestep 3696 is 0.012
Current timestep = 3697. State = [[-0.3654998  0.1813149]]. Action = [[-0.02240414 -0.05019388  0.          0.20624185]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 3697 is [True, False, False, False, False, True]
State prediction error at timestep 3697 is 0.012
Current timestep = 3698. State = [[-0.3632477   0.18326095]]. Action = [[0.08318827 0.03930425 0.         0.13644636]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 3698 is [True, False, False, False, False, True]
State prediction error at timestep 3698 is 0.012
Current timestep = 3699. State = [[-0.364085    0.18085468]]. Action = [[-0.05742233 -0.09409074  0.         -0.56020117]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 3699 is [True, False, False, False, False, True]
State prediction error at timestep 3699 is 0.012
Current timestep = 3700. State = [[-0.36179996  0.1796205 ]]. Action = [[ 0.09661784  0.0183928   0.         -0.9517094 ]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 3700 is [True, False, False, False, False, True]
State prediction error at timestep 3700 is 0.012
Current timestep = 3701. State = [[-0.36374488  0.18435404]]. Action = [[-0.09929857  0.07536077  0.         -0.3469339 ]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 3701 is [True, False, False, False, False, True]
State prediction error at timestep 3701 is 0.012
Current timestep = 3702. State = [[-0.36773953  0.19098805]]. Action = [[-0.006527    0.0730051   0.         -0.34241647]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 3702 is [True, False, False, False, False, True]
State prediction error at timestep 3702 is 0.012
Current timestep = 3703. State = [[-0.37227228  0.197638  ]]. Action = [[-0.05506812  0.06745661  0.         -0.09724176]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 3703 is [True, False, False, False, False, True]
State prediction error at timestep 3703 is 0.012
Current timestep = 3704. State = [[-0.3724218   0.20119978]]. Action = [[0.06239834 0.00541331 0.         0.7512162 ]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 3704 is [True, False, False, False, False, True]
State prediction error at timestep 3704 is 0.012
Current timestep = 3705. State = [[-0.37271696  0.20018174]]. Action = [[-0.01816568 -0.04674996  0.          0.81213903]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 3705 is [True, False, False, False, False, True]
State prediction error at timestep 3705 is 0.012
Current timestep = 3706. State = [[-0.37387797  0.19999571]]. Action = [[-0.00424081  0.00759538  0.          0.4613073 ]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 3706 is [True, False, False, False, False, True]
State prediction error at timestep 3706 is 0.012
Current timestep = 3707. State = [[-0.37569597  0.20298967]]. Action = [[-0.02435829  0.0430116   0.         -0.8089987 ]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 3707 is [True, False, False, False, False, True]
State prediction error at timestep 3707 is 0.012
Current timestep = 3708. State = [[-0.37805086  0.20519301]]. Action = [[-0.02385406  0.00326093  0.         -0.31597388]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 3708 is [True, False, False, False, False, True]
State prediction error at timestep 3708 is 0.012
Current timestep = 3709. State = [[-0.3779883  0.2043224]]. Action = [[ 0.02229027 -0.03360627  0.          0.44590402]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 3709 is [True, False, False, False, False, True]
State prediction error at timestep 3709 is 0.012
Current timestep = 3710. State = [[-0.37750575  0.20368022]]. Action = [[ 0.         0.         0.        -0.3585273]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 3710 is [True, False, False, False, False, True]
State prediction error at timestep 3710 is 0.012
Current timestep = 3711. State = [[-0.3774939  0.2038326]]. Action = [[0.         0.         0.         0.20318413]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 3711 is [True, False, False, False, False, True]
State prediction error at timestep 3711 is 0.012
Current timestep = 3712. State = [[-0.37803546  0.19905291]]. Action = [[-0.01620083 -0.09690199  0.         -0.580383  ]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 3712 is [True, False, False, False, False, True]
State prediction error at timestep 3712 is 0.012
Current timestep = 3713. State = [[-0.37950325  0.1974354 ]]. Action = [[-0.03037036  0.03200201  0.          0.9259286 ]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 3713 is [True, False, False, False, False, True]
State prediction error at timestep 3713 is 0.012
Current timestep = 3714. State = [[-0.3802207   0.19801278]]. Action = [[0.         0.         0.         0.48744524]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 3714 is [True, False, False, False, False, True]
State prediction error at timestep 3714 is 0.012
Current timestep = 3715. State = [[-0.37673843  0.19422728]]. Action = [[ 0.07079778 -0.06903939  0.         -0.9515236 ]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 3715 is [True, False, False, False, False, True]
State prediction error at timestep 3715 is 0.012
Current timestep = 3716. State = [[-0.37605557  0.19411315]]. Action = [[-0.02884752  0.05361157  0.         -0.06358284]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 3716 is [True, False, False, False, False, True]
State prediction error at timestep 3716 is 0.012
Current timestep = 3717. State = [[-0.37824893  0.19066598]]. Action = [[-0.03594975 -0.09169383  0.          0.45283496]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 3717 is [True, False, False, False, False, True]
State prediction error at timestep 3717 is 0.012
Current timestep = 3718. State = [[-0.37491786  0.18620229]]. Action = [[ 0.08568149 -0.02105047  0.         -0.4738717 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 3718 is [True, False, False, False, False, True]
State prediction error at timestep 3718 is 0.012
Current timestep = 3719. State = [[-0.368595   0.1835982]]. Action = [[ 0.07119926 -0.01558476  0.         -0.33704603]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 3719 is [True, False, False, False, False, True]
State prediction error at timestep 3719 is 0.012
Current timestep = 3720. State = [[-0.3683971   0.17810456]]. Action = [[-0.06426845 -0.07855074  0.         -0.23195046]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 3720 is [True, False, False, False, False, True]
State prediction error at timestep 3720 is 0.012
Current timestep = 3721. State = [[-0.36801872  0.17774701]]. Action = [[0.0335223  0.06452035 0.         0.7512833 ]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 3721 is [True, False, False, False, False, True]
State prediction error at timestep 3721 is 0.012
Current timestep = 3722. State = [[-0.3716517   0.17923665]]. Action = [[-0.09804172  0.01000768  0.          0.5819893 ]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 3722 is [True, False, False, False, False, True]
State prediction error at timestep 3722 is 0.012
Current timestep = 3723. State = [[-0.374192    0.17994703]]. Action = [[0.01049886 0.01582529 0.         0.18173814]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 3723 is [True, False, False, False, False, True]
State prediction error at timestep 3723 is 0.012
Current timestep = 3724. State = [[-0.3787383   0.17899072]]. Action = [[-0.08729844 -0.02354599  0.          0.6884898 ]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 3724 is [True, False, False, False, False, True]
State prediction error at timestep 3724 is 0.012
Current timestep = 3725. State = [[-0.3795265  0.1800494]]. Action = [[ 0.05470956  0.0382713   0.         -0.05931568]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 3725 is [True, False, False, False, False, True]
State prediction error at timestep 3725 is 0.012
Current timestep = 3726. State = [[-0.3759262   0.17741919]]. Action = [[ 0.05964071 -0.07245017  0.          0.6114085 ]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 3726 is [True, False, False, False, False, True]
State prediction error at timestep 3726 is 0.012
Current timestep = 3727. State = [[-0.37429795  0.17068997]]. Action = [[-0.00079885 -0.08310898  0.         -0.2737007 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 3727 is [True, False, False, False, False, True]
State prediction error at timestep 3727 is 0.012
Current timestep = 3728. State = [[-0.37210593  0.16988671]]. Action = [[0.04162357 0.05269385 0.         0.19651747]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 3728 is [True, False, False, False, False, True]
State prediction error at timestep 3728 is 0.012
Current timestep = 3729. State = [[-0.37244332  0.16752568]]. Action = [[-0.03385253 -0.06429456  0.          0.35614502]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 3729 is [True, False, False, False, False, True]
State prediction error at timestep 3729 is 0.012
Current timestep = 3730. State = [[-0.3708557   0.16135901]]. Action = [[ 0.04148761 -0.07049092  0.          0.2218492 ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 3730 is [True, False, False, False, False, True]
State prediction error at timestep 3730 is 0.012
Current timestep = 3731. State = [[-0.37220937  0.15659975]]. Action = [[-0.06492992 -0.02897429  0.         -0.9341432 ]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 3731 is [True, False, False, False, False, True]
State prediction error at timestep 3731 is 0.012
Current timestep = 3732. State = [[-0.37825632  0.1567487 ]]. Action = [[-0.09998016  0.04494252  0.          0.44190788]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 3732 is [True, False, False, False, False, True]
State prediction error at timestep 3732 is 0.012
Current timestep = 3733. State = [[-0.38130575  0.16162169]]. Action = [[ 0.00372623  0.08451138  0.         -0.8095213 ]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 3733 is [True, False, False, False, False, True]
State prediction error at timestep 3733 is 0.012
Current timestep = 3734. State = [[-0.38223195  0.16423562]]. Action = [[0.        0.        0.        0.5322492]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 3734 is [True, False, False, False, False, True]
State prediction error at timestep 3734 is 0.012
Current timestep = 3735. State = [[-0.3801443   0.16232577]]. Action = [[ 0.06249141 -0.04273495  0.         -0.527813  ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 3735 is [True, False, False, False, False, True]
State prediction error at timestep 3735 is 0.012
Current timestep = 3736. State = [[-0.37917802  0.16097324]]. Action = [[ 0.          0.          0.         -0.72214854]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 3736 is [True, False, False, False, False, True]
State prediction error at timestep 3736 is 0.012
Current timestep = 3737. State = [[-0.37565318  0.1649095 ]]. Action = [[0.08786526 0.07914612 0.         0.21414614]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 3737 is [True, False, False, False, False, True]
State prediction error at timestep 3737 is 0.012
Current timestep = 3738. State = [[-0.3740788   0.16764057]]. Action = [[ 0.         0.         0.        -0.4364946]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 3738 is [True, False, False, False, False, True]
State prediction error at timestep 3738 is 0.012
Current timestep = 3739. State = [[-0.37613872  0.17084691]]. Action = [[-0.03360371  0.05318093  0.         -0.6911675 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 3739 is [True, False, False, False, False, True]
State prediction error at timestep 3739 is 0.012
Current timestep = 3740. State = [[-0.37756371  0.17303336]]. Action = [[0.        0.        0.        0.5412402]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 3740 is [True, False, False, False, False, True]
State prediction error at timestep 3740 is 0.012
Current timestep = 3741. State = [[-0.3777064   0.17772266]]. Action = [[ 0.00889204  0.07678091  0.         -0.6431345 ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 3741 is [True, False, False, False, False, True]
State prediction error at timestep 3741 is 0.012
Current timestep = 3742. State = [[-0.37393233  0.17682365]]. Action = [[ 0.08233466 -0.08380958  0.          0.6762934 ]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 3742 is [True, False, False, False, False, True]
State prediction error at timestep 3742 is 0.012
Current timestep = 3743. State = [[-0.36874583  0.17936774]]. Action = [[0.06559617 0.09394775 0.         0.9784653 ]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 3743 is [True, False, False, False, False, True]
State prediction error at timestep 3743 is 0.012
Current timestep = 3744. State = [[-0.36507645  0.1844046 ]]. Action = [[0.03914153 0.03149705 0.         0.9020448 ]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 3744 is [True, False, False, False, False, True]
State prediction error at timestep 3744 is 0.012
Current timestep = 3745. State = [[-0.36640295  0.18306285]]. Action = [[-0.06318755 -0.06632003  0.          0.84522986]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 3745 is [True, False, False, False, False, True]
State prediction error at timestep 3745 is 0.012
Current timestep = 3746. State = [[-0.3715975   0.18037552]]. Action = [[-0.09354973 -0.02974607  0.         -0.19977093]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 3746 is [True, False, False, False, False, True]
State prediction error at timestep 3746 is 0.012
Current timestep = 3747. State = [[-0.36998343  0.18312769]]. Action = [[0.08967436 0.06551758 0.         0.03038132]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 3747 is [True, False, False, False, False, True]
State prediction error at timestep 3747 is 0.012
Current timestep = 3748. State = [[-0.36412686  0.18670438]]. Action = [[ 0.05204987  0.02051628  0.         -0.86030006]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 3748 is [True, False, False, False, False, True]
State prediction error at timestep 3748 is 0.012
Current timestep = 3749. State = [[-0.3617852   0.19151914]]. Action = [[-0.00749396  0.06729729  0.          0.23335052]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 3749 is [True, False, False, False, False, True]
State prediction error at timestep 3749 is 0.012
Current timestep = 3750. State = [[-0.35965472  0.19781741]]. Action = [[0.03004613 0.06555843 0.         0.4387815 ]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 3750 is [True, False, False, False, False, True]
State prediction error at timestep 3750 is 0.012
Current timestep = 3751. State = [[-0.35779732  0.2057148 ]]. Action = [[0.01356117 0.09196983 0.         0.09906018]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 3751 is [True, False, False, False, False, True]
State prediction error at timestep 3751 is 0.012
Current timestep = 3752. State = [[-0.35675284  0.20855325]]. Action = [[ 0.00775079 -0.02916025  0.          0.00051308]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 3752 is [True, False, False, False, False, True]
State prediction error at timestep 3752 is 0.012
Current timestep = 3753. State = [[-0.35456103  0.2051708 ]]. Action = [[ 0.02302562 -0.07954039  0.          0.06468856]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 3753 is [True, False, False, False, False, True]
State prediction error at timestep 3753 is 0.012
Current timestep = 3754. State = [[-0.3535339   0.20354548]]. Action = [[-0.01800091 -0.00277779  0.          0.26091552]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 3754 is [True, False, False, False, False, True]
State prediction error at timestep 3754 is 0.012
Current timestep = 3755. State = [[-0.35076877  0.2004778 ]]. Action = [[ 0.03874879 -0.06962729  0.         -0.784397  ]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 3755 is [True, False, False, False, False, True]
State prediction error at timestep 3755 is 0.012
Current timestep = 3756. State = [[-0.34665838  0.20218724]]. Action = [[0.03770656 0.0741136  0.         0.2713492 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 3756 is [True, False, False, False, False, True]
State prediction error at timestep 3756 is 0.012
Current timestep = 3757. State = [[-0.34162006  0.20743826]]. Action = [[ 0.06609309  0.05867475  0.         -0.13545871]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 3757 is [True, False, False, False, False, True]
State prediction error at timestep 3757 is 0.012
Current timestep = 3758. State = [[-0.33431554  0.20990925]]. Action = [[0.09951299 0.00801859 0.         0.24067712]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 3758 is [True, False, False, False, False, True]
State prediction error at timestep 3758 is 0.012
Current timestep = 3759. State = [[-0.3331338  0.2078929]]. Action = [[-0.06502226 -0.05276278  0.          0.46585906]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 3759 is [True, False, False, False, False, True]
State prediction error at timestep 3759 is 0.012
Current timestep = 3760. State = [[-0.33387503  0.21130823]]. Action = [[0.00802139 0.09563521 0.         0.7616656 ]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 3760 is [True, False, False, False, False, True]
State prediction error at timestep 3760 is 0.012
Current timestep = 3761. State = [[-0.33104238  0.2177992 ]]. Action = [[0.05980901 0.06757491 0.         0.19329512]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 3761 is [True, False, False, False, False, True]
State prediction error at timestep 3761 is 0.012
Current timestep = 3762. State = [[-0.3284494   0.21669132]]. Action = [[ 0.01943491 -0.07551029  0.         -0.4154048 ]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 3762 is [True, False, False, False, False, True]
State prediction error at timestep 3762 is 0.012
Current timestep = 3763. State = [[-0.32655594  0.21190803]]. Action = [[ 0.01084366 -0.06122726  0.          0.53885436]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 3763 is [True, False, False, False, False, True]
State prediction error at timestep 3763 is 0.012
Current timestep = 3764. State = [[-0.3256764  0.2101098]]. Action = [[-0.01038584 -0.0006496   0.         -0.2176035 ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 3764 is [True, False, False, False, False, True]
State prediction error at timestep 3764 is 0.012
Current timestep = 3765. State = [[-0.32591558  0.2054473 ]]. Action = [[-0.02349827 -0.09167647  0.          0.17511964]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 3765 is [True, False, False, False, False, True]
State prediction error at timestep 3765 is 0.012
Current timestep = 3766. State = [[-0.32908443  0.20505999]]. Action = [[-0.07772544  0.05047729  0.         -0.23154628]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 3766 is [True, False, False, False, False, True]
State prediction error at timestep 3766 is 0.012
Current timestep = 3767. State = [[-0.32710117  0.20733498]]. Action = [[ 0.07822093  0.02092437  0.         -0.00082761]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 3767 is [True, False, False, False, False, True]
State prediction error at timestep 3767 is 0.012
Current timestep = 3768. State = [[-0.32689968  0.20736247]]. Action = [[-0.05459937 -0.01249735  0.          0.24044013]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 3768 is [True, False, False, False, False, True]
State prediction error at timestep 3768 is 0.012
Current timestep = 3769. State = [[-0.32667124  0.2020186 ]]. Action = [[ 0.01823603 -0.09942378  0.         -0.87827075]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 3769 is [True, False, False, False, False, True]
State prediction error at timestep 3769 is 0.012
Current timestep = 3770. State = [[-0.33036923  0.20311981]]. Action = [[-0.09575664  0.0932105   0.         -0.00295073]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 3770 is [True, False, False, False, False, True]
State prediction error at timestep 3770 is 0.012
Current timestep = 3771. State = [[-0.3344389   0.20299305]]. Action = [[-0.03176762 -0.05877065  0.          0.58868647]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 3771 is [True, False, False, False, False, True]
State prediction error at timestep 3771 is 0.012
Current timestep = 3772. State = [[-0.3334338   0.19724767]]. Action = [[ 0.04006683 -0.08183628  0.          0.62185335]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 3772 is [True, False, False, False, False, True]
State prediction error at timestep 3772 is 0.012
Current timestep = 3773. State = [[-0.3304984  0.1984522]]. Action = [[0.04441644 0.0893187  0.         0.7639617 ]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 3773 is [True, False, False, False, False, True]
State prediction error at timestep 3773 is 0.012
Current timestep = 3774. State = [[-0.33291084  0.19954257]]. Action = [[-0.06785807 -0.02354527  0.         -0.93841714]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 3774 is [True, False, False, False, False, True]
State prediction error at timestep 3774 is 0.012
Current timestep = 3775. State = [[-0.3326828   0.19946137]]. Action = [[ 0.05978896  0.01298797  0.         -0.97443086]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 3775 is [True, False, False, False, False, True]
State prediction error at timestep 3775 is 0.012
Current timestep = 3776. State = [[-0.32948172  0.19871354]]. Action = [[ 0.04885649 -0.01567019  0.         -0.14186662]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 3776 is [True, False, False, False, False, True]
State prediction error at timestep 3776 is 0.012
Current timestep = 3777. State = [[-0.33054736  0.1945031 ]]. Action = [[-0.04731622 -0.06838534  0.         -0.10539973]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 3777 is [True, False, False, False, False, True]
State prediction error at timestep 3777 is 0.012
Current timestep = 3778. State = [[-0.33372128  0.1927304 ]]. Action = [[-0.03855946  0.01340176  0.         -0.8073894 ]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 3778 is [True, False, False, False, False, True]
State prediction error at timestep 3778 is 0.012
Current timestep = 3779. State = [[-0.3325781   0.19210187]]. Action = [[ 0.05349045 -0.0087264   0.          0.14376533]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 3779 is [True, False, False, False, False, True]
State prediction error at timestep 3779 is 0.012
Current timestep = 3780. State = [[-0.33216313  0.19072807]]. Action = [[-0.01517344 -0.0114428   0.          0.61284256]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 3780 is [True, False, False, False, False, True]
State prediction error at timestep 3780 is 0.012
Current timestep = 3781. State = [[-0.33006063  0.19075517]]. Action = [[0.05506534 0.01860757 0.         0.15829158]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 3781 is [True, False, False, False, False, True]
State prediction error at timestep 3781 is 0.012
Current timestep = 3782. State = [[-0.3299175   0.18732527]]. Action = [[-0.02619261 -0.06852689  0.         -0.51627433]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 3782 is [True, False, False, False, False, True]
State prediction error at timestep 3782 is 0.012
Current timestep = 3783. State = [[-0.33386683  0.18434228]]. Action = [[-0.07360953 -0.00917952  0.          0.8802004 ]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 3783 is [True, False, False, False, False, True]
State prediction error at timestep 3783 is 0.012
Current timestep = 3784. State = [[-0.33513242  0.18452388]]. Action = [[ 0.01549681  0.02115377  0.         -0.9447341 ]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 3784 is [True, False, False, False, False, True]
State prediction error at timestep 3784 is 0.012
Current timestep = 3785. State = [[-0.3395603   0.18614693]]. Action = [[-0.0938248   0.02707391  0.          0.0849936 ]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 3785 is [True, False, False, False, False, True]
State prediction error at timestep 3785 is 0.012
Current timestep = 3786. State = [[-0.34487498  0.18977463]]. Action = [[-0.04241651  0.05571683  0.          0.2710917 ]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 3786 is [True, False, False, False, False, True]
State prediction error at timestep 3786 is 0.012
Current timestep = 3787. State = [[-0.34561798  0.19449687]]. Action = [[ 0.0390852   0.05382281  0.         -0.45068657]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 3787 is [True, False, False, False, False, True]
State prediction error at timestep 3787 is 0.012
Current timestep = 3788. State = [[-0.34560812  0.19192117]]. Action = [[ 0.00610618 -0.09505843  0.          0.21933854]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 3788 is [True, False, False, False, False, True]
State prediction error at timestep 3788 is 0.012
Current timestep = 3789. State = [[-0.34711143  0.18694371]]. Action = [[-0.02318384 -0.04701881  0.         -0.66613626]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 3789 is [True, False, False, False, False, True]
State prediction error at timestep 3789 is 0.012
Current timestep = 3790. State = [[-0.34987745  0.1890987 ]]. Action = [[-0.03097128  0.07668947  0.         -0.16433185]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 3790 is [True, False, False, False, False, True]
State prediction error at timestep 3790 is 0.012
Current timestep = 3791. State = [[-0.35078418  0.19067186]]. Action = [[ 0.01886228 -0.01473529  0.          0.8683747 ]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 3791 is [True, False, False, False, False, True]
State prediction error at timestep 3791 is 0.012
Current timestep = 3792. State = [[-0.3481818   0.18964614]]. Action = [[ 0.06012484 -0.01477724  0.          0.56397295]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 3792 is [True, False, False, False, False, True]
State prediction error at timestep 3792 is 0.012
Current timestep = 3793. State = [[-0.35097045  0.18863012]]. Action = [[-0.0870619  -0.00998602  0.          0.93116   ]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 3793 is [True, False, False, False, False, True]
State prediction error at timestep 3793 is 0.012
Current timestep = 3794. State = [[-0.35734224  0.19013098]]. Action = [[-0.06700824  0.03619359  0.         -0.33696526]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 3794 is [True, False, False, False, False, True]
State prediction error at timestep 3794 is 0.012
Current timestep = 3795. State = [[-0.3650897  0.1963679]]. Action = [[-0.09110731  0.09875769  0.          0.69799113]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 3795 is [True, False, False, False, False, True]
State prediction error at timestep 3795 is 0.012
Current timestep = 3796. State = [[-0.36893576  0.2016548 ]]. Action = [[ 0.01638211  0.03315996  0.         -0.86876225]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 3796 is [True, False, False, False, False, True]
State prediction error at timestep 3796 is 0.012
Current timestep = 3797. State = [[-0.37132567  0.19925998]]. Action = [[-0.01852941 -0.08549852  0.         -0.14734179]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 3797 is [True, False, False, False, False, True]
State prediction error at timestep 3797 is 0.012
Current timestep = 3798. State = [[-0.368667    0.19735864]]. Action = [[ 0.09619147  0.00614177  0.         -0.914121  ]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 3798 is [True, False, False, False, False, True]
State prediction error at timestep 3798 is 0.012
Current timestep = 3799. State = [[-0.36687607  0.20230164]]. Action = [[0.0093957  0.09654468 0.         0.78539395]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 3799 is [True, False, False, False, False, True]
State prediction error at timestep 3799 is 0.012
Current timestep = 3800. State = [[-0.36751568  0.20501895]]. Action = [[ 0.00351705 -0.00981621  0.         -0.8760254 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 3800 is [True, False, False, False, False, True]
State prediction error at timestep 3800 is 0.012
Current timestep = 3801. State = [[-0.3646098   0.20790099]]. Action = [[0.07536861 0.05271789 0.         0.26615047]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 3801 is [True, False, False, False, False, True]
State prediction error at timestep 3801 is 0.012
Current timestep = 3802. State = [[-0.35982707  0.20549323]]. Action = [[ 0.06531275 -0.08494525  0.         -0.02556181]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 3802 is [True, False, False, False, False, True]
State prediction error at timestep 3802 is 0.012
Current timestep = 3803. State = [[-0.3553801   0.20682682]]. Action = [[ 0.0495416   0.07759615  0.         -0.7063848 ]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 3803 is [True, False, False, False, False, True]
State prediction error at timestep 3803 is 0.012
Current timestep = 3804. State = [[-0.35683456  0.20488144]]. Action = [[-0.07853328 -0.09053146  0.         -0.02727169]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 3804 is [True, False, False, False, False, True]
State prediction error at timestep 3804 is 0.012
Current timestep = 3805. State = [[-0.35672122  0.20218438]]. Action = [[ 0.0348822  -0.00655692  0.         -0.7257742 ]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 3805 is [True, False, False, False, False, True]
State prediction error at timestep 3805 is 0.012
Current timestep = 3806. State = [[-0.35880005  0.20524131]]. Action = [[-0.06966759  0.06773328  0.          0.41071582]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 3806 is [True, False, False, False, False, True]
State prediction error at timestep 3806 is 0.012
Current timestep = 3807. State = [[-0.35891873  0.21134783]]. Action = [[ 0.03954371  0.07700474  0.         -0.78350395]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 3807 is [True, False, False, False, False, True]
State prediction error at timestep 3807 is 0.012
Current timestep = 3808. State = [[-0.36188617  0.21207012]]. Action = [[-0.08263572 -0.04524341  0.          0.02255273]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 3808 is [True, False, False, False, False, True]
State prediction error at timestep 3808 is 0.012
Current timestep = 3809. State = [[-0.3681975   0.21635033]]. Action = [[-0.07592352  0.09672862  0.          0.29089665]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 3809 is [True, False, False, False, False, True]
State prediction error at timestep 3809 is 0.012
Current timestep = 3810. State = [[-0.37122616  0.22036862]]. Action = [[0.00476424 0.00478264 0.         0.958987  ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 3810 is [True, False, False, False, False, True]
State prediction error at timestep 3810 is 0.012
Current timestep = 3811. State = [[-0.37310585  0.22009952]]. Action = [[-0.01978293 -0.03091804  0.         -0.78690773]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 3811 is [True, False, False, False, False, True]
State prediction error at timestep 3811 is 0.012
Current timestep = 3812. State = [[-0.37617397  0.22090177]]. Action = [[-0.03711137  0.01690093  0.         -0.11822969]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 3812 is [True, False, False, False, False, True]
State prediction error at timestep 3812 is 0.012
Current timestep = 3813. State = [[-0.3741606   0.21828535]]. Action = [[ 0.07841089 -0.07298554  0.         -0.1875071 ]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 3813 is [True, False, False, False, False, True]
State prediction error at timestep 3813 is 0.012
Current timestep = 3814. State = [[-0.37315205  0.2131903 ]]. Action = [[-0.019435   -0.06024227  0.          0.5858443 ]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 3814 is [True, False, False, False, False, True]
State prediction error at timestep 3814 is 0.012
Current timestep = 3815. State = [[-0.3693186   0.21160154]]. Action = [[ 0.08797418  0.01322623  0.         -0.5752434 ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 3815 is [True, False, False, False, False, True]
State prediction error at timestep 3815 is 0.012
Current timestep = 3816. State = [[-0.36881498  0.20774572]]. Action = [[-0.05372717 -0.07286932  0.         -0.77150005]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 3816 is [True, False, False, False, False, True]
State prediction error at timestep 3816 is 0.012
Current timestep = 3817. State = [[-0.36999783  0.20966557]]. Action = [[ 0.00436531  0.09738044  0.         -0.87173355]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 3817 is [True, False, False, False, False, True]
State prediction error at timestep 3817 is 0.012
Current timestep = 3818. State = [[-0.3745808   0.21668397]]. Action = [[-0.07892545  0.09209772  0.         -0.26341307]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 3818 is [True, False, False, False, False, True]
State prediction error at timestep 3818 is 0.012
Current timestep = 3819. State = [[-0.37396768  0.22459717]]. Action = [[ 0.09767958  0.09970882  0.         -0.0358507 ]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 3819 is [True, False, False, False, False, True]
State prediction error at timestep 3819 is 0.012
Current timestep = 3820. State = [[-0.37557372  0.22603275]]. Action = [[-0.07792839 -0.04758628  0.         -0.27747303]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 3820 is [True, False, False, False, False, True]
State prediction error at timestep 3820 is 0.012
Current timestep = 3821. State = [[-0.37820348  0.22299577]]. Action = [[ 0.00821285 -0.04827775  0.          0.2080828 ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 3821 is [True, False, False, False, False, True]
State prediction error at timestep 3821 is 0.012
Current timestep = 3822. State = [[-0.37586412  0.21682116]]. Action = [[ 0.06009651 -0.09741839  0.         -0.03481346]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 3822 is [True, False, False, False, False, True]
State prediction error at timestep 3822 is 0.012
Current timestep = 3823. State = [[-0.37352052  0.21480282]]. Action = [[ 0.02030779  0.02725209  0.         -0.5217751 ]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 3823 is [True, False, False, False, False, True]
State prediction error at timestep 3823 is 0.012
Current timestep = 3824. State = [[-0.36919472  0.21125418]]. Action = [[ 0.07663362 -0.07467289  0.          0.719236  ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 3824 is [True, False, False, False, False, True]
State prediction error at timestep 3824 is 0.012
Current timestep = 3825. State = [[-0.36796322  0.20488441]]. Action = [[-0.0335824  -0.07091892  0.          0.514451  ]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 3825 is [True, False, False, False, False, True]
State prediction error at timestep 3825 is 0.012
Current timestep = 3826. State = [[-0.3711624   0.20286326]]. Action = [[-0.0675682   0.01863854  0.         -0.5671832 ]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 3826 is [True, False, False, False, False, True]
State prediction error at timestep 3826 is 0.012
Current timestep = 3827. State = [[-0.374726    0.20151857]]. Action = [[-0.04558286 -0.02146161  0.          0.95364296]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 3827 is [True, False, False, False, False, True]
State prediction error at timestep 3827 is 0.012
Current timestep = 3828. State = [[-0.3739714  0.1961481]]. Action = [[ 0.03629839 -0.07844565  0.         -0.45625567]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 3828 is [True, False, False, False, False, True]
State prediction error at timestep 3828 is 0.012
Current timestep = 3829. State = [[-0.3764641   0.19045947]]. Action = [[-0.0813726  -0.04539252  0.         -0.812633  ]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 3829 is [True, False, False, False, False, True]
State prediction error at timestep 3829 is 0.012
Current timestep = 3830. State = [[-0.37850797  0.18788858]]. Action = [[0.         0.         0.         0.13776827]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 3830 is [True, False, False, False, False, True]
State prediction error at timestep 3830 is 0.012
Current timestep = 3831. State = [[-0.37893486  0.186686  ]]. Action = [[ 0.         0.         0.        -0.8907489]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 3831 is [True, False, False, False, False, True]
State prediction error at timestep 3831 is 0.012
Current timestep = 3832. State = [[-0.3795232   0.18567799]]. Action = [[ 0.          0.          0.         -0.13585293]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 3832 is [True, False, False, False, False, True]
State prediction error at timestep 3832 is 0.012
Current timestep = 3833. State = [[-0.37936017  0.18619832]]. Action = [[0.02005033 0.02745409 0.         0.61518717]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 3833 is [True, False, False, False, False, True]
State prediction error at timestep 3833 is 0.012
Current timestep = 3834. State = [[-0.37912345  0.18892233]]. Action = [[0.01637243 0.04994244 0.         0.9914992 ]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 3834 is [True, False, False, False, False, True]
State prediction error at timestep 3834 is 0.012
Current timestep = 3835. State = [[-0.37666222  0.19251484]]. Action = [[0.06994704 0.04676855 0.         0.895746  ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 3835 is [True, False, False, False, False, True]
State prediction error at timestep 3835 is 0.012
Current timestep = 3836. State = [[-0.372012   0.1968481]]. Action = [[0.08743378 0.05849116 0.         0.05737174]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 3836 is [True, False, False, False, False, True]
State prediction error at timestep 3836 is 0.012
Current timestep = 3837. State = [[-0.37163496  0.19470832]]. Action = [[-0.02850753 -0.08334009  0.         -0.6466423 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 3837 is [True, False, False, False, False, True]
State prediction error at timestep 3837 is 0.012
Current timestep = 3838. State = [[-0.371043    0.19202624]]. Action = [[ 0.03740507 -0.00791384  0.          0.20857394]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 3838 is [True, False, False, False, False, True]
State prediction error at timestep 3838 is 0.012
Current timestep = 3839. State = [[-0.37173972  0.1890254 ]]. Action = [[-0.03105428 -0.05172053  0.         -0.22395808]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 3839 is [True, False, False, False, False, True]
State prediction error at timestep 3839 is 0.012
Current timestep = 3840. State = [[-0.37599206  0.18962574]]. Action = [[-0.07586026  0.0441597   0.          0.21188664]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 3840 is [True, False, False, False, False, True]
State prediction error at timestep 3840 is 0.012
Current timestep = 3841. State = [[-0.3763374  0.1907086]]. Action = [[ 0.03884947 -0.00396968  0.         -0.30162823]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 3841 is [True, False, False, False, False, True]
State prediction error at timestep 3841 is 0.012
Current timestep = 3842. State = [[-0.37733716  0.1900218 ]]. Action = [[-0.04145065 -0.01407713  0.         -0.00848591]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 3842 is [True, False, False, False, False, True]
State prediction error at timestep 3842 is 0.012
Current timestep = 3843. State = [[-0.37538803  0.18851483]]. Action = [[ 0.05997217 -0.02166011  0.         -0.44425398]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 3843 is [True, False, False, False, False, True]
State prediction error at timestep 3843 is 0.012
Current timestep = 3844. State = [[-0.37487987  0.1910586 ]]. Action = [[-0.02457199  0.0663598   0.          0.19028318]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 3844 is [True, False, False, False, False, True]
State prediction error at timestep 3844 is 0.012
Current timestep = 3845. State = [[-0.37177     0.19585893]]. Action = [[ 0.08392822  0.05485975  0.         -0.04443896]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 3845 is [True, False, False, False, False, True]
State prediction error at timestep 3845 is 0.012
Current timestep = 3846. State = [[-0.36962557  0.19917358]]. Action = [[0.00433011 0.0257381  0.         0.6972983 ]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 3846 is [True, False, False, False, False, True]
State prediction error at timestep 3846 is 0.012
Current timestep = 3847. State = [[-0.36897975  0.20158476]]. Action = [[0.01124634 0.02151611 0.         0.729776  ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 3847 is [True, False, False, False, False, True]
State prediction error at timestep 3847 is 0.012
Current timestep = 3848. State = [[-0.3684331   0.20768976]]. Action = [[0.00963913 0.09534913 0.         0.4023466 ]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 3848 is [True, False, False, False, False, True]
State prediction error at timestep 3848 is 0.012
Current timestep = 3849. State = [[-0.37265062  0.21035478]]. Action = [[-0.08825184 -0.02406733  0.         -0.40924633]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 3849 is [True, False, False, False, False, True]
State prediction error at timestep 3849 is 0.012
Current timestep = 3850. State = [[-0.3755979   0.21192268]]. Action = [[-0.0065389   0.01830952  0.         -0.7067475 ]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 3850 is [True, False, False, False, False, True]
State prediction error at timestep 3850 is 0.012
Current timestep = 3851. State = [[-0.37411046  0.21292262]]. Action = [[ 0.04410832 -0.01173422  0.          0.24720573]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 3851 is [True, False, False, False, False, True]
State prediction error at timestep 3851 is 0.012
Current timestep = 3852. State = [[-0.37572324  0.2093916 ]]. Action = [[-0.06130675 -0.08262233  0.         -0.2447626 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 3852 is [True, False, False, False, False, True]
State prediction error at timestep 3852 is 0.012
Current timestep = 3853. State = [[-0.3804457   0.20446801]]. Action = [[-0.07366444 -0.06361593  0.         -0.8660712 ]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 3853 is [True, False, False, False, False, True]
State prediction error at timestep 3853 is 0.012
Current timestep = 3854. State = [[-0.38218644  0.20273358]]. Action = [[0.        0.        0.        0.9192945]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 3854 is [True, False, False, False, False, True]
State prediction error at timestep 3854 is 0.012
Current timestep = 3855. State = [[-0.3822688   0.20253344]]. Action = [[ 0.          0.          0.         -0.51767516]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 3855 is [True, False, False, False, False, True]
State prediction error at timestep 3855 is 0.012
Current timestep = 3856. State = [[-0.38245416  0.20227596]]. Action = [[ 0.          0.          0.         -0.84533083]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 3856 is [True, False, False, False, False, True]
State prediction error at timestep 3856 is 0.012
Current timestep = 3857. State = [[-0.38276553  0.20194149]]. Action = [[0.         0.         0.         0.17969704]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 3857 is [True, False, False, False, False, True]
State prediction error at timestep 3857 is 0.012
Current timestep = 3858. State = [[-0.38316146  0.20157672]]. Action = [[ 0.          0.          0.         -0.25036395]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 3858 is [True, False, False, False, False, True]
State prediction error at timestep 3858 is 0.012
Current timestep = 3859. State = [[-0.38026297  0.19686313]]. Action = [[ 0.0657336  -0.08422371  0.          0.90402174]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 3859 is [True, False, False, False, False, True]
State prediction error at timestep 3859 is 0.012
Current timestep = 3860. State = [[-0.37502837  0.19673914]]. Action = [[0.07596702 0.06723251 0.         0.7613988 ]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 3860 is [True, False, False, False, False, True]
State prediction error at timestep 3860 is 0.012
Current timestep = 3861. State = [[-0.36893985  0.19789667]]. Action = [[0.08769903 0.00199511 0.         0.5229316 ]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 3861 is [True, False, False, False, False, True]
State prediction error at timestep 3861 is 0.012
Current timestep = 3862. State = [[-0.36846942  0.1987471 ]]. Action = [[-0.04554353  0.02601474  0.         -0.74969906]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 3862 is [True, False, False, False, False, True]
State prediction error at timestep 3862 is 0.012
Current timestep = 3863. State = [[-0.3700498  0.2032545]]. Action = [[-0.00236066  0.08106267  0.         -0.16699362]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 3863 is [True, False, False, False, False, True]
State prediction error at timestep 3863 is 0.012
Current timestep = 3864. State = [[-0.3730655   0.20704138]]. Action = [[-0.04564058  0.02559135  0.          0.8033011 ]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 3864 is [True, False, False, False, False, True]
State prediction error at timestep 3864 is 0.012
Current timestep = 3865. State = [[-0.37815243  0.21086732]]. Action = [[-0.06597498  0.0483724   0.          0.02708709]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 3865 is [True, False, False, False, False, True]
State prediction error at timestep 3865 is 0.012
Current timestep = 3866. State = [[-0.38163307  0.21694186]]. Action = [[-0.0127931   0.07439073  0.         -0.5576296 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 3866 is [True, False, False, False, False, True]
State prediction error at timestep 3866 is 0.012
Current timestep = 3867. State = [[-0.38335037  0.22031812]]. Action = [[0.         0.         0.         0.85775506]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 3867 is [True, False, False, False, False, True]
State prediction error at timestep 3867 is 0.012
Current timestep = 3868. State = [[-0.38434535  0.22159383]]. Action = [[0.         0.         0.         0.15496457]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 3868 is [True, False, False, False, False, True]
State prediction error at timestep 3868 is 0.012
Current timestep = 3869. State = [[-0.3850827  0.2226886]]. Action = [[0.         0.         0.         0.81703687]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 3869 is [True, False, False, False, False, True]
State prediction error at timestep 3869 is 0.012
Current timestep = 3870. State = [[-0.3856478   0.22366962]]. Action = [[0.         0.         0.         0.43240833]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 3870 is [True, False, False, False, False, True]
State prediction error at timestep 3870 is 0.012
Current timestep = 3871. State = [[-0.38605905  0.22451195]]. Action = [[0.         0.         0.         0.48265016]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 3871 is [True, False, False, False, False, True]
State prediction error at timestep 3871 is 0.012
Current timestep = 3872. State = [[-0.38633448  0.22520071]]. Action = [[0.         0.         0.         0.99866223]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 3872 is [True, False, False, False, False, True]
State prediction error at timestep 3872 is 0.012
Current timestep = 3873. State = [[-0.3864971   0.22573483]]. Action = [[0.         0.         0.         0.84664655]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 3873 is [True, False, False, False, False, True]
State prediction error at timestep 3873 is 0.012
Current timestep = 3874. State = [[-0.3865798   0.22611195]]. Action = [[ 0.          0.          0.         -0.29310572]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 3874 is [True, False, False, False, False, True]
State prediction error at timestep 3874 is 0.012
Current timestep = 3875. State = [[-0.386619   0.2263655]]. Action = [[0.       0.       0.       0.405643]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 3875 is [True, False, False, False, False, True]
State prediction error at timestep 3875 is 0.012
Current timestep = 3876. State = [[-0.3866467   0.22654738]]. Action = [[ 0.         0.         0.        -0.5391452]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 3876 is [True, False, False, False, False, True]
State prediction error at timestep 3876 is 0.012
Current timestep = 3877. State = [[-0.38664085  0.22667992]]. Action = [[ 0.          0.          0.         -0.98053265]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 3877 is [True, False, False, False, False, True]
State prediction error at timestep 3877 is 0.012
Current timestep = 3878. State = [[-0.38660634  0.22677688]]. Action = [[0.        0.        0.        0.8755866]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 3878 is [True, False, False, False, False, True]
State prediction error at timestep 3878 is 0.012
Current timestep = 3879. State = [[-0.38657123  0.22684595]]. Action = [[0.         0.         0.         0.80197906]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 3879 is [True, False, False, False, False, True]
State prediction error at timestep 3879 is 0.012
Current timestep = 3880. State = [[-0.38654447  0.22689523]]. Action = [[0.         0.         0.         0.46974444]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 3880 is [True, False, False, False, False, True]
State prediction error at timestep 3880 is 0.012
Current timestep = 3881. State = [[-0.38652322  0.22693332]]. Action = [[ 0.         0.         0.        -0.9004546]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 3881 is [True, False, False, False, False, True]
State prediction error at timestep 3881 is 0.012
Current timestep = 3882. State = [[-0.3865044   0.22696678]]. Action = [[0.         0.         0.         0.25034928]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 3882 is [True, False, False, False, False, True]
State prediction error at timestep 3882 is 0.012
Current timestep = 3883. State = [[-0.38648784  0.22699982]]. Action = [[0.         0.         0.         0.08334446]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 3883 is [True, False, False, False, False, True]
State prediction error at timestep 3883 is 0.012
Current timestep = 3884. State = [[-0.3864769   0.22703378]]. Action = [[0.        0.        0.        0.6476152]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 3884 is [True, False, False, False, False, True]
State prediction error at timestep 3884 is 0.012
Current timestep = 3885. State = [[-0.3864721  0.2270668]]. Action = [[0.         0.         0.         0.06411147]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 3885 is [True, False, False, False, False, True]
State prediction error at timestep 3885 is 0.012
Current timestep = 3886. State = [[-0.38647047  0.22709702]]. Action = [[ 0.         0.         0.        -0.4848652]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 3886 is [True, False, False, False, False, True]
State prediction error at timestep 3886 is 0.012
Current timestep = 3887. State = [[-0.3864712   0.22712393]]. Action = [[0.        0.        0.        0.9838567]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 3887 is [True, False, False, False, False, True]
State prediction error at timestep 3887 is 0.012
Current timestep = 3888. State = [[-0.38647392  0.22714789]]. Action = [[ 0.          0.          0.         -0.11399174]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 3888 is [True, False, False, False, False, True]
State prediction error at timestep 3888 is 0.012
Current timestep = 3889. State = [[-0.38647777  0.22716892]]. Action = [[0.         0.         0.         0.23451662]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 3889 is [True, False, False, False, False, True]
State prediction error at timestep 3889 is 0.012
Current timestep = 3890. State = [[-0.3864814   0.22718665]]. Action = [[ 0.          0.          0.         -0.15969485]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 3890 is [True, False, False, False, False, True]
State prediction error at timestep 3890 is 0.012
Current timestep = 3891. State = [[-0.38648477  0.22720197]]. Action = [[0.        0.        0.        0.5963607]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 3891 is [True, False, False, False, False, True]
State prediction error at timestep 3891 is 0.012
Current timestep = 3892. State = [[-0.3864879  0.2272153]]. Action = [[ 0.          0.          0.         -0.11510193]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 3892 is [True, False, False, False, False, True]
State prediction error at timestep 3892 is 0.012
Current timestep = 3893. State = [[-0.38649082  0.22722696]]. Action = [[ 0.         0.         0.        -0.6953756]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 3893 is [True, False, False, False, False, True]
State prediction error at timestep 3893 is 0.012
Current timestep = 3894. State = [[-0.3864936  0.2272371]]. Action = [[ 0.          0.          0.         -0.95813775]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 3894 is [True, False, False, False, False, True]
State prediction error at timestep 3894 is 0.012
Current timestep = 3895. State = [[-0.3864962   0.22724597]]. Action = [[0.        0.        0.        0.6353345]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 3895 is [True, False, False, False, False, True]
State prediction error at timestep 3895 is 0.012
Current timestep = 3896. State = [[-0.38649866  0.22725369]]. Action = [[ 0.          0.          0.         -0.86753154]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 3896 is [True, False, False, False, False, True]
State prediction error at timestep 3896 is 0.012
Current timestep = 3897. State = [[-0.38650098  0.22726041]]. Action = [[ 0.         0.         0.        -0.4318831]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 3897 is [True, False, False, False, False, True]
State prediction error at timestep 3897 is 0.012
Current timestep = 3898. State = [[-0.38650322  0.22726627]]. Action = [[ 0.         0.         0.        -0.9648341]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 3898 is [True, False, False, False, False, True]
State prediction error at timestep 3898 is 0.012
Current timestep = 3899. State = [[-0.38650537  0.22727135]]. Action = [[0.         0.         0.         0.94018614]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 3899 is [True, False, False, False, False, True]
State prediction error at timestep 3899 is 0.012
Current timestep = 3900. State = [[-0.38650742  0.22727576]]. Action = [[ 0.          0.          0.         -0.18890446]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 3900 is [True, False, False, False, False, True]
State prediction error at timestep 3900 is 0.012
Current timestep = 3901. State = [[-0.3865094   0.22727959]]. Action = [[ 0.         0.         0.        -0.3491099]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 3901 is [True, False, False, False, False, True]
State prediction error at timestep 3901 is 0.012
Current timestep = 3902. State = [[-0.3865113  0.2272829]]. Action = [[ 0.          0.          0.         -0.26039636]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 3902 is [True, False, False, False, False, True]
State prediction error at timestep 3902 is 0.012
Current timestep = 3903. State = [[-0.38651314  0.22728576]]. Action = [[ 0.          0.          0.         -0.10294437]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 3903 is [True, False, False, False, False, True]
State prediction error at timestep 3903 is 0.012
Current timestep = 3904. State = [[-0.38651493  0.22728823]]. Action = [[0.         0.         0.         0.32955432]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 3904 is [True, False, False, False, False, True]
State prediction error at timestep 3904 is 0.012
Current timestep = 3905. State = [[-0.38651666  0.22729035]]. Action = [[0.        0.        0.        0.9528034]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 3905 is [True, False, False, False, False, True]
State prediction error at timestep 3905 is 0.012
Current timestep = 3906. State = [[-0.38651836  0.22729218]]. Action = [[0.        0.        0.        0.8857825]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 3906 is [True, False, False, False, False, True]
State prediction error at timestep 3906 is 0.012
Current timestep = 3907. State = [[-0.38652     0.22729373]]. Action = [[ 0.          0.          0.         -0.44306397]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 3907 is [True, False, False, False, False, True]
State prediction error at timestep 3907 is 0.012
Current timestep = 3908. State = [[-0.3865216   0.22729506]]. Action = [[0.        0.        0.        0.3889295]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 3908 is [True, False, False, False, False, True]
State prediction error at timestep 3908 is 0.012
Current timestep = 3909. State = [[-0.3865232   0.22729617]]. Action = [[ 0.          0.          0.         -0.60315853]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 3909 is [True, False, False, False, False, True]
State prediction error at timestep 3909 is 0.012
Current timestep = 3910. State = [[-0.38652474  0.22729711]]. Action = [[0.        0.        0.        0.6525161]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 3910 is [True, False, False, False, False, True]
State prediction error at timestep 3910 is 0.012
Current timestep = 3911. State = [[-0.38652626  0.22729795]]. Action = [[ 0.          0.          0.         -0.60042226]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 3911 is [True, False, False, False, False, True]
State prediction error at timestep 3911 is 0.012
Current timestep = 3912. State = [[-0.38652778  0.22729877]]. Action = [[ 0.          0.          0.         -0.72620064]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 3912 is [True, False, False, False, False, True]
State prediction error at timestep 3912 is 0.012
Current timestep = 3913. State = [[-0.38652927  0.22729959]]. Action = [[ 0.          0.          0.         -0.64876634]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 3913 is [True, False, False, False, False, True]
State prediction error at timestep 3913 is 0.012
Current timestep = 3914. State = [[-0.38653076  0.22730039]]. Action = [[0.         0.         0.         0.62084806]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 3914 is [True, False, False, False, False, True]
State prediction error at timestep 3914 is 0.012
Current timestep = 3915. State = [[-0.38653225  0.2273012 ]]. Action = [[0.        0.        0.        0.5393996]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 3915 is [True, False, False, False, False, True]
State prediction error at timestep 3915 is 0.012
Current timestep = 3916. State = [[-0.3865337  0.227302 ]]. Action = [[ 0.          0.          0.         -0.06136447]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 3916 is [True, False, False, False, False, True]
State prediction error at timestep 3916 is 0.012
Current timestep = 3917. State = [[-0.38653514  0.22730279]]. Action = [[0.         0.         0.         0.02171111]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 3917 is [True, False, False, False, False, True]
State prediction error at timestep 3917 is 0.012
Current timestep = 3918. State = [[-0.3865366   0.22730358]]. Action = [[0.        0.        0.        0.1728096]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 3918 is [True, False, False, False, False, True]
State prediction error at timestep 3918 is 0.012
Current timestep = 3919. State = [[-0.38653803  0.22730435]]. Action = [[ 0.        0.        0.       -0.832494]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 3919 is [True, False, False, False, False, True]
State prediction error at timestep 3919 is 0.012
Current timestep = 3920. State = [[-0.38653943  0.22730513]]. Action = [[0.         0.         0.         0.20591784]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 3920 is [True, False, False, False, False, True]
State prediction error at timestep 3920 is 0.012
Current timestep = 3921. State = [[-0.38654086  0.2273059 ]]. Action = [[0.        0.        0.        0.3467878]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 3921 is [True, False, False, False, False, True]
State prediction error at timestep 3921 is 0.012
Current timestep = 3922. State = [[-0.38654223  0.22730666]]. Action = [[ 0.          0.          0.         -0.14697325]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 3922 is [True, False, False, False, False, True]
State prediction error at timestep 3922 is 0.012
Current timestep = 3923. State = [[-0.38654363  0.22730744]]. Action = [[0.         0.         0.         0.34527564]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 3923 is [True, False, False, False, False, True]
State prediction error at timestep 3923 is 0.012
Current timestep = 3924. State = [[-0.386545    0.22730818]]. Action = [[ 0.         0.         0.        -0.5142006]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 3924 is [True, False, False, False, False, True]
State prediction error at timestep 3924 is 0.012
Current timestep = 3925. State = [[-0.38654637  0.22730894]]. Action = [[ 0.          0.          0.         -0.17563891]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 3925 is [True, False, False, False, False, True]
State prediction error at timestep 3925 is 0.012
Current timestep = 3926. State = [[-0.3865477   0.22730969]]. Action = [[ 0.          0.          0.         -0.71319914]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 3926 is [True, False, False, False, False, True]
State prediction error at timestep 3926 is 0.012
Current timestep = 3927. State = [[-0.38654906  0.22731042]]. Action = [[ 0.          0.          0.         -0.14392662]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 3927 is [True, False, False, False, False, True]
State prediction error at timestep 3927 is 0.012
Current timestep = 3928. State = [[-0.3865504   0.22731115]]. Action = [[ 0.          0.          0.         -0.53905416]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 3928 is [True, False, False, False, False, True]
State prediction error at timestep 3928 is 0.012
Current timestep = 3929. State = [[-0.3865517   0.22731188]]. Action = [[0.        0.        0.        0.9174478]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 3929 is [True, False, False, False, False, True]
State prediction error at timestep 3929 is 0.012
Current timestep = 3930. State = [[-0.38655302  0.22731261]]. Action = [[ 0.         0.         0.        -0.5452796]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 3930 is [True, False, False, False, False, True]
State prediction error at timestep 3930 is 0.012
Current timestep = 3931. State = [[-0.38655433  0.22731332]]. Action = [[ 0.         0.         0.        -0.7371687]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 3931 is [True, False, False, False, False, True]
State prediction error at timestep 3931 is 0.012
Current timestep = 3932. State = [[-0.3865556   0.22731404]]. Action = [[0.         0.         0.         0.74460673]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 3932 is [True, False, False, False, False, True]
State prediction error at timestep 3932 is 0.012
Current timestep = 3933. State = [[-0.3865569   0.22731476]]. Action = [[ 0.         0.         0.        -0.9726789]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 3933 is [True, False, False, False, False, True]
State prediction error at timestep 3933 is 0.012
Current timestep = 3934. State = [[-0.38655818  0.22731546]]. Action = [[ 0.          0.          0.         -0.50676006]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 3934 is [True, False, False, False, False, True]
State prediction error at timestep 3934 is 0.012
Current timestep = 3935. State = [[-0.38655943  0.22731616]]. Action = [[0.        0.        0.        0.8363658]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 3935 is [True, False, False, False, False, True]
State prediction error at timestep 3935 is 0.012
Current timestep = 3936. State = [[-0.38656068  0.22731686]]. Action = [[ 0.          0.          0.         -0.79660034]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 3936 is [True, False, False, False, False, True]
State prediction error at timestep 3936 is 0.012
Current timestep = 3937. State = [[-0.38656193  0.22731754]]. Action = [[0.         0.         0.         0.22475886]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 3937 is [True, False, False, False, False, True]
State prediction error at timestep 3937 is 0.012
Current timestep = 3938. State = [[-0.38656315  0.22731823]]. Action = [[0.        0.        0.        0.2004534]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 3938 is [True, False, False, False, False, True]
State prediction error at timestep 3938 is 0.012
Current timestep = 3939. State = [[-0.38656437  0.22731891]]. Action = [[0.         0.         0.         0.67265916]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 3939 is [True, False, False, False, False, True]
State prediction error at timestep 3939 is 0.012
Current timestep = 3940. State = [[-0.3865656   0.22731958]]. Action = [[ 0.          0.          0.         -0.49479514]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 3940 is [True, False, False, False, False, True]
State prediction error at timestep 3940 is 0.012
Current timestep = 3941. State = [[-0.3865668   0.22732025]]. Action = [[ 0.          0.          0.         -0.06006628]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 3941 is [True, False, False, False, False, True]
State prediction error at timestep 3941 is 0.012
Current timestep = 3942. State = [[-0.386568    0.22732092]]. Action = [[0.         0.         0.         0.25592232]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 3942 is [True, False, False, False, False, True]
State prediction error at timestep 3942 is 0.012
Current timestep = 3943. State = [[-0.38656917  0.22732158]]. Action = [[ 0.          0.          0.         -0.89181143]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 3943 is [True, False, False, False, False, True]
State prediction error at timestep 3943 is 0.012
Current timestep = 3944. State = [[-0.38657036  0.22732224]]. Action = [[0.        0.        0.        0.7731705]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 3944 is [True, False, False, False, False, True]
State prediction error at timestep 3944 is 0.012
Current timestep = 3945. State = [[-0.38657153  0.22732289]]. Action = [[0.         0.         0.         0.09764242]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 3945 is [True, False, False, False, False, True]
State prediction error at timestep 3945 is 0.012
Current timestep = 3946. State = [[-0.3865727   0.22732355]]. Action = [[ 0.         0.         0.        -0.5964527]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 3946 is [True, False, False, False, False, True]
State prediction error at timestep 3946 is 0.012
Current timestep = 3947. State = [[-0.38657382  0.22732419]]. Action = [[ 0.          0.          0.         -0.06118679]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 3947 is [True, False, False, False, False, True]
State prediction error at timestep 3947 is 0.012
Current timestep = 3948. State = [[-0.38657495  0.22732483]]. Action = [[ 0.          0.          0.         -0.55208284]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 3948 is [True, False, False, False, False, True]
State prediction error at timestep 3948 is 0.012
Current timestep = 3949. State = [[-0.3865761   0.22732545]]. Action = [[0.         0.         0.         0.23104846]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 3949 is [True, False, False, False, False, True]
State prediction error at timestep 3949 is 0.012
Current timestep = 3950. State = [[-0.38657722  0.2273261 ]]. Action = [[0.       0.       0.       0.360224]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 3950 is [True, False, False, False, False, True]
State prediction error at timestep 3950 is 0.012
Current timestep = 3951. State = [[-0.38657832  0.22732672]]. Action = [[ 0.         0.         0.        -0.3266114]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 3951 is [True, False, False, False, False, True]
State prediction error at timestep 3951 is 0.012
Current timestep = 3952. State = [[-0.38657942  0.22732735]]. Action = [[ 0.          0.          0.         -0.48539567]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 3952 is [True, False, False, False, False, True]
State prediction error at timestep 3952 is 0.012
Current timestep = 3953. State = [[-0.38658053  0.22732796]]. Action = [[0.         0.         0.         0.08608079]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 3953 is [True, False, False, False, False, True]
State prediction error at timestep 3953 is 0.012
Current timestep = 3954. State = [[-0.38658163  0.22732857]]. Action = [[ 0.          0.          0.         -0.51752144]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 3954 is [True, False, False, False, False, True]
State prediction error at timestep 3954 is 0.012
Current timestep = 3955. State = [[-0.3865827   0.22732918]]. Action = [[ 0.          0.          0.         -0.01654649]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 3955 is [True, False, False, False, False, True]
State prediction error at timestep 3955 is 0.012
Current timestep = 3956. State = [[-0.38658378  0.22732979]]. Action = [[ 0.          0.          0.         -0.26867282]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 3956 is [True, False, False, False, False, True]
State prediction error at timestep 3956 is 0.012
Current timestep = 3957. State = [[-0.38658482  0.22733039]]. Action = [[0.         0.         0.         0.06097364]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 3957 is [True, False, False, False, False, True]
State prediction error at timestep 3957 is 0.012
Current timestep = 3958. State = [[-0.3865859   0.22733098]]. Action = [[ 0.         0.         0.        -0.9349029]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 3958 is [True, False, False, False, False, True]
State prediction error at timestep 3958 is 0.012
Current timestep = 3959. State = [[-0.38658693  0.22733158]]. Action = [[ 0.         0.         0.        -0.7357979]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 3959 is [True, False, False, False, False, True]
State prediction error at timestep 3959 is 0.012
Current timestep = 3960. State = [[-0.38658798  0.22733216]]. Action = [[ 0.          0.          0.         -0.59172386]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 3960 is [True, False, False, False, False, True]
State prediction error at timestep 3960 is 0.012
Current timestep = 3961. State = [[-0.386589    0.22733276]]. Action = [[ 0.          0.          0.         -0.38191593]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 3961 is [True, False, False, False, False, True]
State prediction error at timestep 3961 is 0.012
Current timestep = 3962. State = [[-0.38659     0.22733334]]. Action = [[ 0.          0.          0.         -0.39358526]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 3962 is [True, False, False, False, False, True]
State prediction error at timestep 3962 is 0.012
Current timestep = 3963. State = [[-0.38659102  0.2273339 ]]. Action = [[0.         0.         0.         0.57335544]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 3963 is [True, False, False, False, False, True]
State prediction error at timestep 3963 is 0.012
Current timestep = 3964. State = [[-0.38659203  0.22733448]]. Action = [[0.         0.         0.         0.08047199]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 3964 is [True, False, False, False, False, True]
State prediction error at timestep 3964 is 0.012
Current timestep = 3965. State = [[-0.38659304  0.22733505]]. Action = [[0.         0.         0.         0.59972966]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 3965 is [True, False, False, False, False, True]
State prediction error at timestep 3965 is 0.012
Current timestep = 3966. State = [[-0.38659403  0.22733562]]. Action = [[0.        0.        0.        0.3405198]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 3966 is [True, False, False, False, False, True]
State prediction error at timestep 3966 is 0.012
Current timestep = 3967. State = [[-0.386595    0.22733618]]. Action = [[ 0.          0.          0.         -0.05684412]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 3967 is [True, False, False, False, False, True]
State prediction error at timestep 3967 is 0.012
Current timestep = 3968. State = [[-0.38659596  0.22733673]]. Action = [[0.        0.        0.        0.7829869]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 3968 is [True, False, False, False, False, True]
State prediction error at timestep 3968 is 0.012
Current timestep = 3969. State = [[-0.38659695  0.22733729]]. Action = [[0.         0.         0.         0.28449714]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 3969 is [True, False, False, False, False, True]
State prediction error at timestep 3969 is 0.012
Current timestep = 3970. State = [[-0.3865979   0.22733784]]. Action = [[ 0.          0.          0.         -0.09260005]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 3970 is [True, False, False, False, False, True]
State prediction error at timestep 3970 is 0.012
Current timestep = 3971. State = [[-0.38659886  0.22733839]]. Action = [[ 0.         0.         0.        -0.5058286]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 3971 is [True, False, False, False, False, True]
State prediction error at timestep 3971 is 0.012
Current timestep = 3972. State = [[-0.3865998   0.22733893]]. Action = [[0.        0.        0.        0.5080583]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 3972 is [True, False, False, False, False, True]
State prediction error at timestep 3972 is 0.012
Current timestep = 3973. State = [[-0.38660073  0.22733946]]. Action = [[0.        0.        0.        0.5119858]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 3973 is [True, False, False, False, False, True]
State prediction error at timestep 3973 is 0.012
Current timestep = 3974. State = [[-0.38660166  0.22734   ]]. Action = [[0.       0.       0.       0.464998]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 3974 is [True, False, False, False, False, True]
State prediction error at timestep 3974 is 0.012
Current timestep = 3975. State = [[-0.38660258  0.22734053]]. Action = [[0.        0.        0.        0.9385178]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 3975 is [True, False, False, False, False, True]
State prediction error at timestep 3975 is 0.012
Current timestep = 3976. State = [[-0.3866035   0.22734106]]. Action = [[0.        0.        0.        0.6108053]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 3976 is [True, False, False, False, False, True]
State prediction error at timestep 3976 is 0.012
Current timestep = 3977. State = [[-0.3866044   0.22734158]]. Action = [[0.       0.       0.       0.934924]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 3977 is [True, False, False, False, False, True]
State prediction error at timestep 3977 is 0.012
Current timestep = 3978. State = [[-0.38660532  0.2273421 ]]. Action = [[ 0.          0.          0.         -0.50835985]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 3978 is [True, False, False, False, False, True]
State prediction error at timestep 3978 is 0.012
Current timestep = 3979. State = [[-0.38660622  0.22734262]]. Action = [[ 0.         0.         0.        -0.8003554]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 3979 is [True, False, False, False, False, True]
State prediction error at timestep 3979 is 0.012
Current timestep = 3980. State = [[-0.3866071   0.22734314]]. Action = [[ 0.          0.          0.         -0.42166257]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 3980 is [True, False, False, False, False, True]
State prediction error at timestep 3980 is 0.012
Current timestep = 3981. State = [[-0.38660797  0.22734365]]. Action = [[ 0.          0.          0.         -0.35037196]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 3981 is [True, False, False, False, False, True]
State prediction error at timestep 3981 is 0.012
Current timestep = 3982. State = [[-0.38660884  0.22734416]]. Action = [[0.        0.        0.        0.5241817]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 3982 is [True, False, False, False, False, True]
State prediction error at timestep 3982 is 0.012
Current timestep = 3983. State = [[-0.3866097   0.22734466]]. Action = [[ 0.        0.        0.       -0.478549]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 3983 is [True, False, False, False, False, True]
State prediction error at timestep 3983 is 0.012
Current timestep = 3984. State = [[-0.38661057  0.22734515]]. Action = [[0.         0.         0.         0.12151408]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 3984 is [True, False, False, False, False, True]
State prediction error at timestep 3984 is 0.012
Current timestep = 3985. State = [[-0.38661143  0.22734565]]. Action = [[0.        0.        0.        0.6667118]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 3985 is [True, False, False, False, False, True]
State prediction error at timestep 3985 is 0.012
Current timestep = 3986. State = [[-0.38661227  0.22734615]]. Action = [[0.         0.         0.         0.39475882]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 3986 is [True, False, False, False, False, True]
State prediction error at timestep 3986 is 0.012
Current timestep = 3987. State = [[-0.38661313  0.22734663]]. Action = [[ 0.         0.         0.        -0.2917912]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 3987 is [True, False, False, False, False, True]
State prediction error at timestep 3987 is 0.012
Current timestep = 3988. State = [[-0.38661397  0.22734712]]. Action = [[ 0.          0.          0.         -0.20504045]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 3988 is [True, False, False, False, False, True]
State prediction error at timestep 3988 is 0.012
Current timestep = 3989. State = [[-0.38661477  0.22734761]]. Action = [[ 0.          0.          0.         -0.80941516]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 3989 is [True, False, False, False, False, True]
State prediction error at timestep 3989 is 0.012
Current timestep = 3990. State = [[-0.3866156   0.22734809]]. Action = [[0.         0.         0.         0.01086068]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 3990 is [True, False, False, False, False, True]
State prediction error at timestep 3990 is 0.012
Current timestep = 3991. State = [[-0.3866164   0.22734857]]. Action = [[ 0.          0.          0.         -0.05133587]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 3991 is [True, False, False, False, False, True]
State prediction error at timestep 3991 is 0.012
Current timestep = 3992. State = [[-0.3866172   0.22734904]]. Action = [[0.         0.         0.         0.90938663]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 3992 is [True, False, False, False, False, True]
State prediction error at timestep 3992 is 0.012
Current timestep = 3993. State = [[-0.38661802  0.2273495 ]]. Action = [[0.        0.        0.        0.2658236]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 3993 is [True, False, False, False, False, True]
State prediction error at timestep 3993 is 0.012
Current timestep = 3994. State = [[-0.38661882  0.22734998]]. Action = [[0.         0.         0.         0.14130592]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 3994 is [True, False, False, False, False, True]
State prediction error at timestep 3994 is 0.012
Current timestep = 3995. State = [[-0.3866196   0.22735044]]. Action = [[ 0.         0.         0.        -0.7461171]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 3995 is [True, False, False, False, False, True]
State prediction error at timestep 3995 is 0.012
Current timestep = 3996. State = [[-0.3866204  0.2273509]]. Action = [[ 0.         0.         0.        -0.9008284]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 3996 is [True, False, False, False, False, True]
State prediction error at timestep 3996 is 0.012
Current timestep = 3997. State = [[-0.38662118  0.22735135]]. Action = [[0.         0.         0.         0.41283178]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 3997 is [True, False, False, False, False, True]
State prediction error at timestep 3997 is 0.012
Current timestep = 3998. State = [[-0.38662195  0.22735181]]. Action = [[ 0.         0.         0.        -0.1108197]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 3998 is [True, False, False, False, False, True]
State prediction error at timestep 3998 is 0.012
Current timestep = 3999. State = [[-0.3866227   0.22735226]]. Action = [[ 0.          0.          0.         -0.37731296]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 3999 is [True, False, False, False, False, True]
State prediction error at timestep 3999 is 0.012
Current timestep = 4000. State = [[-0.38662347  0.22735271]]. Action = [[0.        0.        0.        0.5103495]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 4000 is [True, False, False, False, False, True]
State prediction error at timestep 4000 is 0.012
Current timestep = 4001. State = [[-0.38662422  0.22735316]]. Action = [[0.         0.         0.         0.14108467]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 4001 is [True, False, False, False, False, True]
State prediction error at timestep 4001 is 0.012
Current timestep = 4002. State = [[-0.38662496  0.2273536 ]]. Action = [[ 0.          0.          0.         -0.68716854]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 4002 is [True, False, False, False, False, True]
State prediction error at timestep 4002 is 0.012
Current timestep = 4003. State = [[-0.3866257   0.22735405]]. Action = [[0.        0.        0.        0.8564211]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 4003 is [True, False, False, False, False, True]
State prediction error at timestep 4003 is 0.012
Current timestep = 4004. State = [[-0.38662645  0.22735448]]. Action = [[ 0.          0.          0.         -0.00415486]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 4004 is [True, False, False, False, False, True]
State prediction error at timestep 4004 is 0.012
Current timestep = 4005. State = [[-0.38662717  0.22735491]]. Action = [[ 0.          0.          0.         -0.15170544]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 4005 is [True, False, False, False, False, True]
State prediction error at timestep 4005 is 0.012
Current timestep = 4006. State = [[-0.3866279   0.22735535]]. Action = [[0.         0.         0.         0.29653096]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 4006 is [True, False, False, False, False, True]
State prediction error at timestep 4006 is 0.012
Current timestep = 4007. State = [[-0.38662863  0.22735578]]. Action = [[0.         0.         0.         0.61961365]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 4007 is [True, False, False, False, False, True]
State prediction error at timestep 4007 is 0.012
Current timestep = 4008. State = [[-0.38662934  0.2273562 ]]. Action = [[0.        0.        0.        0.5897747]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 4008 is [True, False, False, False, False, True]
State prediction error at timestep 4008 is 0.012
Current timestep = 4009. State = [[-0.38663006  0.22735663]]. Action = [[ 0.          0.          0.         -0.32309854]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 4009 is [True, False, False, False, False, True]
State prediction error at timestep 4009 is 0.012
Current timestep = 4010. State = [[-0.38663074  0.22735704]]. Action = [[0.         0.         0.         0.72998047]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 4010 is [True, False, False, False, False, True]
State prediction error at timestep 4010 is 0.012
Current timestep = 4011. State = [[-0.38663146  0.22735746]]. Action = [[ 0.          0.          0.         -0.34160256]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 4011 is [True, False, False, False, False, True]
State prediction error at timestep 4011 is 0.012
Current timestep = 4012. State = [[-0.38663214  0.22735788]]. Action = [[ 0.          0.          0.         -0.47013974]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 4012 is [True, False, False, False, False, True]
State prediction error at timestep 4012 is 0.012
Current timestep = 4013. State = [[-0.38663283  0.2273583 ]]. Action = [[0.       0.       0.       0.789016]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 4013 is [True, False, False, False, False, True]
State prediction error at timestep 4013 is 0.012
Current timestep = 4014. State = [[-0.38663352  0.2273587 ]]. Action = [[0.         0.         0.         0.23374867]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 4014 is [True, False, False, False, False, True]
State prediction error at timestep 4014 is 0.012
Current timestep = 4015. State = [[-0.38663417  0.2273591 ]]. Action = [[ 0.          0.          0.         -0.49982947]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 4015 is [True, False, False, False, False, True]
State prediction error at timestep 4015 is 0.012
Current timestep = 4016. State = [[-0.38663486  0.2273595 ]]. Action = [[ 0.          0.          0.         -0.95601535]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 4016 is [True, False, False, False, False, True]
State prediction error at timestep 4016 is 0.012
Current timestep = 4017. State = [[-0.3866355  0.2273599]]. Action = [[0.        0.        0.        0.6570151]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 4017 is [True, False, False, False, False, True]
State prediction error at timestep 4017 is 0.012
Current timestep = 4018. State = [[-0.38663617  0.22736031]]. Action = [[ 0.          0.          0.         -0.17028499]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 4018 is [True, False, False, False, False, True]
State prediction error at timestep 4018 is 0.012
Current timestep = 4019. State = [[-0.38663682  0.22736071]]. Action = [[ 0.          0.          0.         -0.26534057]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 4019 is [True, False, False, False, False, True]
State prediction error at timestep 4019 is 0.012
Current timestep = 4020. State = [[-0.38663748  0.2273611 ]]. Action = [[0.         0.         0.         0.29289317]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 4020 is [True, False, False, False, False, True]
State prediction error at timestep 4020 is 0.012
Current timestep = 4021. State = [[-0.38663813  0.22736149]]. Action = [[ 0.         0.         0.        -0.5348002]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 4021 is [True, False, False, False, False, True]
State prediction error at timestep 4021 is 0.012
Current timestep = 4022. State = [[-0.38663876  0.22736187]]. Action = [[ 0.         0.         0.        -0.2141251]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 4022 is [True, False, False, False, False, True]
State prediction error at timestep 4022 is 0.012
Current timestep = 4023. State = [[-0.38663942  0.22736226]]. Action = [[0.         0.         0.         0.17330813]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 4023 is [True, False, False, False, False, True]
State prediction error at timestep 4023 is 0.012
Current timestep = 4024. State = [[-0.38664004  0.22736265]]. Action = [[ 0.          0.          0.         -0.12352264]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 4024 is [True, False, False, False, False, True]
State prediction error at timestep 4024 is 0.012
Current timestep = 4025. State = [[-0.38664067  0.22736302]]. Action = [[ 0.        0.        0.       -0.459122]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 4025 is [True, False, False, False, False, True]
State prediction error at timestep 4025 is 0.012
Current timestep = 4026. State = [[-0.3866413   0.22736341]]. Action = [[ 0.         0.         0.        -0.6126565]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 4026 is [True, False, False, False, False, True]
State prediction error at timestep 4026 is 0.012
Current timestep = 4027. State = [[-0.3866419   0.22736378]]. Action = [[0.        0.        0.        0.8078613]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 4027 is [True, False, False, False, False, True]
State prediction error at timestep 4027 is 0.012
Current timestep = 4028. State = [[-0.38664252  0.22736415]]. Action = [[0.         0.         0.         0.13004947]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 4028 is [True, False, False, False, False, True]
State prediction error at timestep 4028 is 0.012
Current timestep = 4029. State = [[-0.3866431   0.22736453]]. Action = [[0.         0.         0.         0.22504008]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 4029 is [True, False, False, False, False, True]
State prediction error at timestep 4029 is 0.012
Current timestep = 4030. State = [[-0.38664374  0.2273649 ]]. Action = [[0.         0.         0.         0.33980834]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 4030 is [True, False, False, False, False, True]
State prediction error at timestep 4030 is 0.012
Current timestep = 4031. State = [[-0.38664433  0.22736526]]. Action = [[ 0.          0.          0.         -0.06048948]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 4031 is [True, False, False, False, False, True]
State prediction error at timestep 4031 is 0.012
Current timestep = 4032. State = [[-0.3866449   0.22736563]]. Action = [[ 0.         0.         0.        -0.9034037]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 4032 is [True, False, False, False, False, True]
State prediction error at timestep 4032 is 0.012
Current timestep = 4033. State = [[-0.3866455   0.22736599]]. Action = [[0.        0.        0.        0.6525254]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 4033 is [True, False, False, False, False, True]
State prediction error at timestep 4033 is 0.012
Current timestep = 4034. State = [[-0.3866461   0.22736634]]. Action = [[ 0.         0.         0.        -0.8088068]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 4034 is [True, False, False, False, False, True]
State prediction error at timestep 4034 is 0.012
Current timestep = 4035. State = [[-0.38664666  0.2273667 ]]. Action = [[0.         0.         0.         0.36146593]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 4035 is [True, False, False, False, False, True]
State prediction error at timestep 4035 is 0.012
Current timestep = 4036. State = [[-0.38664725  0.22736706]]. Action = [[ 0.         0.         0.        -0.2391839]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 4036 is [True, False, False, False, False, True]
State prediction error at timestep 4036 is 0.012
Current timestep = 4037. State = [[-0.38664782  0.2273674 ]]. Action = [[ 0.          0.          0.         -0.03523296]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 4037 is [True, False, False, False, False, True]
State prediction error at timestep 4037 is 0.012
Current timestep = 4038. State = [[-0.3866484   0.22736776]]. Action = [[0.        0.        0.        0.2685219]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 4038 is [True, False, False, False, False, True]
State prediction error at timestep 4038 is 0.012
Current timestep = 4039. State = [[-0.38664895  0.2273681 ]]. Action = [[ 0.          0.          0.         -0.54497033]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 4039 is [True, False, False, False, False, True]
State prediction error at timestep 4039 is 0.012
Current timestep = 4040. State = [[-0.3866495   0.22736844]]. Action = [[0.        0.        0.        0.7809799]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 4040 is [True, False, False, False, False, True]
State prediction error at timestep 4040 is 0.012
Current timestep = 4041. State = [[-0.38665006  0.22736879]]. Action = [[0.       0.       0.       0.757324]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 4041 is [True, False, False, False, False, True]
State prediction error at timestep 4041 is 0.012
Current timestep = 4042. State = [[-0.3866506   0.22736913]]. Action = [[ 0.          0.          0.         -0.04133618]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 4042 is [True, False, False, False, False, True]
State prediction error at timestep 4042 is 0.012
Current timestep = 4043. State = [[-0.38665113  0.22736947]]. Action = [[ 0.          0.          0.         -0.85658675]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 4043 is [True, False, False, False, False, True]
State prediction error at timestep 4043 is 0.012
Current timestep = 4044. State = [[-0.3866517   0.22736982]]. Action = [[0.         0.         0.         0.40317082]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 4044 is [True, False, False, False, False, True]
State prediction error at timestep 4044 is 0.012
Current timestep = 4045. State = [[-0.38665223  0.22737014]]. Action = [[0.        0.        0.        0.9126959]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 4045 is [True, False, False, False, False, True]
State prediction error at timestep 4045 is 0.012
Current timestep = 4046. State = [[-0.38665274  0.22737047]]. Action = [[0.         0.         0.         0.55105793]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 4046 is [True, False, False, False, False, True]
State prediction error at timestep 4046 is 0.012
Current timestep = 4047. State = [[-0.38665327  0.2273708 ]]. Action = [[ 0.         0.         0.        -0.9809922]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 4047 is [True, False, False, False, False, True]
State prediction error at timestep 4047 is 0.012
Current timestep = 4048. State = [[-0.3866538   0.22737113]]. Action = [[ 0.         0.         0.        -0.9803052]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 4048 is [True, False, False, False, False, True]
State prediction error at timestep 4048 is 0.012
Current timestep = 4049. State = [[-0.38665432  0.22737145]]. Action = [[ 0.          0.          0.         -0.57536685]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 4049 is [True, False, False, False, False, True]
State prediction error at timestep 4049 is 0.012
Current timestep = 4050. State = [[-0.38665485  0.22737178]]. Action = [[ 0.          0.          0.         -0.20531005]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 4050 is [True, False, False, False, False, True]
State prediction error at timestep 4050 is 0.012
Current timestep = 4051. State = [[-0.38665536  0.22737211]]. Action = [[0.        0.        0.        0.7816031]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 4051 is [True, False, False, False, False, True]
State prediction error at timestep 4051 is 0.012
Current timestep = 4052. State = [[-0.38665587  0.22737242]]. Action = [[0.        0.        0.        0.5942702]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 4052 is [True, False, False, False, False, True]
State prediction error at timestep 4052 is 0.012
Current timestep = 4053. State = [[-0.38665637  0.22737274]]. Action = [[ 0.          0.          0.         -0.55738926]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 4053 is [True, False, False, False, False, True]
State prediction error at timestep 4053 is 0.012
Current timestep = 4054. State = [[-0.38665688  0.22737306]]. Action = [[ 0.          0.          0.         -0.51202255]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 4054 is [True, False, False, False, False, True]
State prediction error at timestep 4054 is 0.012
Current timestep = 4055. State = [[-0.38665736  0.22737338]]. Action = [[0.        0.        0.        0.3950925]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 4055 is [True, False, False, False, False, True]
State prediction error at timestep 4055 is 0.012
Current timestep = 4056. State = [[-0.38665786  0.22737369]]. Action = [[0.         0.         0.         0.19128728]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 4056 is [True, False, False, False, False, True]
State prediction error at timestep 4056 is 0.012
Current timestep = 4057. State = [[-0.38665834  0.22737399]]. Action = [[ 0.         0.         0.        -0.8422556]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 4057 is [True, False, False, False, False, True]
State prediction error at timestep 4057 is 0.012
Current timestep = 4058. State = [[-0.38665882  0.2273743 ]]. Action = [[0.        0.        0.        0.5252366]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 4058 is [True, False, False, False, False, True]
State prediction error at timestep 4058 is 0.012
Current timestep = 4059. State = [[-0.38665932  0.2273746 ]]. Action = [[0.         0.         0.         0.81259716]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 4059 is [True, False, False, False, False, True]
State prediction error at timestep 4059 is 0.012
Current timestep = 4060. State = [[-0.3866598   0.22737491]]. Action = [[0.       0.       0.       0.737129]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 4060 is [True, False, False, False, False, True]
State prediction error at timestep 4060 is 0.012
Current timestep = 4061. State = [[-0.38666028  0.22737521]]. Action = [[0.         0.         0.         0.06671107]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 4061 is [True, False, False, False, False, True]
State prediction error at timestep 4061 is 0.012
Current timestep = 4062. State = [[-0.38666072  0.2273755 ]]. Action = [[0.        0.        0.        0.6542344]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 4062 is [True, False, False, False, False, True]
State prediction error at timestep 4062 is 0.012
Current timestep = 4063. State = [[-0.3866612  0.2273758]]. Action = [[ 0.          0.          0.         -0.58766764]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 4063 is [True, False, False, False, False, True]
State prediction error at timestep 4063 is 0.012
Current timestep = 4064. State = [[-0.38666168  0.2273761 ]]. Action = [[0.         0.         0.         0.29137063]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 4064 is [True, False, False, False, False, True]
State prediction error at timestep 4064 is 0.012
Current timestep = 4065. State = [[-0.38666213  0.2273764 ]]. Action = [[0.         0.         0.         0.46117818]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 4065 is [True, False, False, False, False, True]
State prediction error at timestep 4065 is 0.012
Current timestep = 4066. State = [[-0.38666257  0.2273767 ]]. Action = [[0.         0.         0.         0.35867977]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 4066 is [True, False, False, False, False, True]
State prediction error at timestep 4066 is 0.012
Current timestep = 4067. State = [[-0.38666302  0.22737698]]. Action = [[ 0.          0.          0.         -0.73920333]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 4067 is [True, False, False, False, False, True]
State prediction error at timestep 4067 is 0.012
Current timestep = 4068. State = [[-0.3866635   0.22737727]]. Action = [[0.         0.         0.         0.70233274]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 4068 is [True, False, False, False, False, True]
State prediction error at timestep 4068 is 0.012
Current timestep = 4069. State = [[-0.38666394  0.22737756]]. Action = [[ 0.          0.          0.         -0.48348325]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 4069 is [True, False, False, False, False, True]
State prediction error at timestep 4069 is 0.012
Current timestep = 4070. State = [[-0.38666436  0.22737785]]. Action = [[0.         0.         0.         0.44214737]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 4070 is [True, False, False, False, False, True]
State prediction error at timestep 4070 is 0.012
Current timestep = 4071. State = [[-0.3866648   0.22737813]]. Action = [[ 0.         0.         0.        -0.4100176]]. Reward = [0.]
Curr episode timestep = 471
Scene graph at timestep 4071 is [True, False, False, False, False, True]
State prediction error at timestep 4071 is 0.012
Current timestep = 4072. State = [[-0.38666525  0.22737841]]. Action = [[0.         0.         0.         0.36988795]]. Reward = [0.]
Curr episode timestep = 472
Scene graph at timestep 4072 is [True, False, False, False, False, True]
State prediction error at timestep 4072 is 0.012
Current timestep = 4073. State = [[-0.38666567  0.2273787 ]]. Action = [[ 0.          0.          0.         -0.20976269]]. Reward = [0.]
Curr episode timestep = 473
Scene graph at timestep 4073 is [True, False, False, False, False, True]
State prediction error at timestep 4073 is 0.012
Current timestep = 4074. State = [[-0.38666612  0.22737896]]. Action = [[0.         0.         0.         0.32000196]]. Reward = [0.]
Curr episode timestep = 474
Scene graph at timestep 4074 is [True, False, False, False, False, True]
State prediction error at timestep 4074 is 0.012
Current timestep = 4075. State = [[-0.38666654  0.22737925]]. Action = [[ 0.          0.          0.         -0.17818987]]. Reward = [0.]
Curr episode timestep = 475
Scene graph at timestep 4075 is [True, False, False, False, False, True]
State prediction error at timestep 4075 is 0.012
Current timestep = 4076. State = [[-0.38666695  0.22737952]]. Action = [[ 0.          0.          0.         -0.04039162]]. Reward = [0.]
Curr episode timestep = 476
Scene graph at timestep 4076 is [True, False, False, False, False, True]
State prediction error at timestep 4076 is 0.012
Current timestep = 4077. State = [[-0.38666737  0.2273798 ]]. Action = [[ 0.          0.          0.         -0.20961744]]. Reward = [0.]
Curr episode timestep = 477
Scene graph at timestep 4077 is [True, False, False, False, False, True]
State prediction error at timestep 4077 is 0.012
Current timestep = 4078. State = [[-0.3866678   0.22738007]]. Action = [[ 0.          0.          0.         -0.19669557]]. Reward = [0.]
Curr episode timestep = 478
Scene graph at timestep 4078 is [True, False, False, False, False, True]
State prediction error at timestep 4078 is 0.012
Current timestep = 4079. State = [[-0.3866682   0.22738034]]. Action = [[0.        0.        0.        0.9476322]]. Reward = [0.]
Curr episode timestep = 479
Scene graph at timestep 4079 is [True, False, False, False, False, True]
State prediction error at timestep 4079 is 0.012
Current timestep = 4080. State = [[-0.38666862  0.2273806 ]]. Action = [[ 0.          0.          0.         -0.79163253]]. Reward = [0.]
Curr episode timestep = 480
Scene graph at timestep 4080 is [True, False, False, False, False, True]
State prediction error at timestep 4080 is 0.012
Current timestep = 4081. State = [[-0.38666904  0.22738087]]. Action = [[ 0.          0.          0.         -0.11052197]]. Reward = [0.]
Curr episode timestep = 481
Scene graph at timestep 4081 is [True, False, False, False, False, True]
State prediction error at timestep 4081 is 0.012
Current timestep = 4082. State = [[-0.38666943  0.22738114]]. Action = [[ 0.          0.          0.         -0.20100683]]. Reward = [0.]
Curr episode timestep = 482
Scene graph at timestep 4082 is [True, False, False, False, False, True]
State prediction error at timestep 4082 is 0.012
Current timestep = 4083. State = [[-0.38666984  0.2273814 ]]. Action = [[0.         0.         0.         0.21254647]]. Reward = [0.]
Curr episode timestep = 483
Scene graph at timestep 4083 is [True, False, False, False, False, True]
State prediction error at timestep 4083 is 0.012
Current timestep = 4084. State = [[-0.38667023  0.22738166]]. Action = [[0.        0.        0.        0.2587825]]. Reward = [0.]
Curr episode timestep = 484
Scene graph at timestep 4084 is [True, False, False, False, False, True]
State prediction error at timestep 4084 is 0.012
Current timestep = 4085. State = [[-0.38667062  0.22738191]]. Action = [[ 0.         0.         0.        -0.4490251]]. Reward = [0.]
Curr episode timestep = 485
Scene graph at timestep 4085 is [True, False, False, False, False, True]
State prediction error at timestep 4085 is 0.012
Current timestep = 4086. State = [[-0.386671    0.22738218]]. Action = [[0.         0.         0.         0.76679134]]. Reward = [0.]
Curr episode timestep = 486
Scene graph at timestep 4086 is [True, False, False, False, False, True]
State prediction error at timestep 4086 is 0.012
Current timestep = 4087. State = [[-0.3866714   0.22738244]]. Action = [[0.        0.        0.        0.5875726]]. Reward = [0.]
Curr episode timestep = 487
Scene graph at timestep 4087 is [True, False, False, False, False, True]
State prediction error at timestep 4087 is 0.012
Current timestep = 4088. State = [[-0.38667178  0.22738269]]. Action = [[ 0.          0.          0.         -0.27412212]]. Reward = [0.]
Curr episode timestep = 488
Scene graph at timestep 4088 is [True, False, False, False, False, True]
State prediction error at timestep 4088 is 0.012
Current timestep = 4089. State = [[-0.38667217  0.22738294]]. Action = [[0.         0.         0.         0.24182224]]. Reward = [0.]
Curr episode timestep = 489
Scene graph at timestep 4089 is [True, False, False, False, False, True]
State prediction error at timestep 4089 is 0.012
Current timestep = 4090. State = [[-0.38667256  0.2273832 ]]. Action = [[0.         0.         0.         0.90632856]]. Reward = [0.]
Curr episode timestep = 490
Scene graph at timestep 4090 is [True, False, False, False, False, True]
State prediction error at timestep 4090 is 0.012
Current timestep = 4091. State = [[-0.38667294  0.22738345]]. Action = [[0.         0.         0.         0.14637697]]. Reward = [0.]
Curr episode timestep = 491
Scene graph at timestep 4091 is [True, False, False, False, False, True]
State prediction error at timestep 4091 is 0.012
Current timestep = 4092. State = [[-0.3866733   0.22738369]]. Action = [[ 0.          0.          0.         -0.15720159]]. Reward = [0.]
Curr episode timestep = 492
Scene graph at timestep 4092 is [True, False, False, False, False, True]
State prediction error at timestep 4092 is 0.012
Current timestep = 4093. State = [[-0.3866737   0.22738394]]. Action = [[ 0.       0.       0.      -0.50285]]. Reward = [0.]
Curr episode timestep = 493
Scene graph at timestep 4093 is [True, False, False, False, False, True]
State prediction error at timestep 4093 is 0.012
Current timestep = 4094. State = [[-0.38667405  0.2273842 ]]. Action = [[0.         0.         0.         0.27692842]]. Reward = [0.]
Curr episode timestep = 494
Scene graph at timestep 4094 is [True, False, False, False, False, True]
State prediction error at timestep 4094 is 0.012
Current timestep = 4095. State = [[-0.3866744   0.22738443]]. Action = [[ 0.          0.          0.         -0.64188886]]. Reward = [0.]
Curr episode timestep = 495
Scene graph at timestep 4095 is [True, False, False, False, False, True]
State prediction error at timestep 4095 is 0.012
Current timestep = 4096. State = [[-0.38667476  0.22738467]]. Action = [[0.        0.        0.        0.5142007]]. Reward = [0.]
Curr episode timestep = 496
Scene graph at timestep 4096 is [True, False, False, False, False, True]
State prediction error at timestep 4096 is 0.012
Current timestep = 4097. State = [[-0.38667512  0.22738492]]. Action = [[ 0.          0.          0.         -0.40771723]]. Reward = [0.]
Curr episode timestep = 497
Scene graph at timestep 4097 is [True, False, False, False, False, True]
State prediction error at timestep 4097 is 0.012
Current timestep = 4098. State = [[-0.38667548  0.22738516]]. Action = [[0.         0.         0.         0.03963268]]. Reward = [0.]
Curr episode timestep = 498
Scene graph at timestep 4098 is [True, False, False, False, False, True]
State prediction error at timestep 4098 is 0.012
Current timestep = 4099. State = [[-0.38667583  0.2273854 ]]. Action = [[ 0.          0.          0.         -0.05884814]]. Reward = [0.]
Curr episode timestep = 499
Scene graph at timestep 4099 is [True, False, False, False, False, True]
State prediction error at timestep 4099 is 0.012
Current timestep = 4100. State = [[-0.3866762   0.22738564]]. Action = [[ 0.         0.         0.        -0.4505328]]. Reward = [0.]
Curr episode timestep = 500
Scene graph at timestep 4100 is [True, False, False, False, False, True]
State prediction error at timestep 4100 is 0.012
Current timestep = 4101. State = [[-0.38667655  0.22738586]]. Action = [[0.        0.        0.        0.4022671]]. Reward = [0.]
Curr episode timestep = 501
Scene graph at timestep 4101 is [True, False, False, False, False, True]
State prediction error at timestep 4101 is 0.012
Current timestep = 4102. State = [[-0.3866769  0.2273861]]. Action = [[0.        0.        0.        0.5314362]]. Reward = [0.]
Curr episode timestep = 502
Scene graph at timestep 4102 is [True, False, False, False, False, True]
State prediction error at timestep 4102 is 0.012
Current timestep = 4103. State = [[-0.38667724  0.22738634]]. Action = [[0.         0.         0.         0.01751184]]. Reward = [0.]
Curr episode timestep = 503
Scene graph at timestep 4103 is [True, False, False, False, False, True]
State prediction error at timestep 4103 is 0.012
Current timestep = 4104. State = [[-0.3866776   0.22738656]]. Action = [[0.         0.         0.         0.77846277]]. Reward = [0.]
Curr episode timestep = 504
Scene graph at timestep 4104 is [True, False, False, False, False, True]
State prediction error at timestep 4104 is 0.012
Current timestep = 4105. State = [[-0.38667792  0.2273868 ]]. Action = [[0.         0.         0.         0.54579866]]. Reward = [0.]
Curr episode timestep = 505
Scene graph at timestep 4105 is [True, False, False, False, False, True]
State prediction error at timestep 4105 is 0.012
Current timestep = 4106. State = [[-0.38667825  0.22738703]]. Action = [[ 0.         0.         0.        -0.1629039]]. Reward = [0.]
Curr episode timestep = 506
Scene graph at timestep 4106 is [True, False, False, False, False, True]
State prediction error at timestep 4106 is 0.012
Current timestep = 4107. State = [[-0.38667858  0.22738725]]. Action = [[ 0.          0.          0.         -0.21998096]]. Reward = [0.]
Curr episode timestep = 507
Scene graph at timestep 4107 is [True, False, False, False, False, True]
State prediction error at timestep 4107 is 0.012
Current timestep = 4108. State = [[-0.38667893  0.22738749]]. Action = [[0.        0.        0.        0.8240197]]. Reward = [0.]
Curr episode timestep = 508
Scene graph at timestep 4108 is [True, False, False, False, False, True]
State prediction error at timestep 4108 is 0.012
Current timestep = 4109. State = [[-0.38667926  0.22738771]]. Action = [[ 0.          0.          0.         -0.03238797]]. Reward = [0.]
Curr episode timestep = 509
Scene graph at timestep 4109 is [True, False, False, False, False, True]
State prediction error at timestep 4109 is 0.012
Current timestep = 4110. State = [[-0.3866796   0.22738793]]. Action = [[0.         0.         0.         0.51712704]]. Reward = [0.]
Curr episode timestep = 510
Scene graph at timestep 4110 is [True, False, False, False, False, True]
State prediction error at timestep 4110 is 0.012
Current timestep = 4111. State = [[-0.3866799   0.22738816]]. Action = [[ 0.          0.          0.         -0.67056686]]. Reward = [0.]
Curr episode timestep = 511
Scene graph at timestep 4111 is [True, False, False, False, False, True]
State prediction error at timestep 4111 is 0.012
Current timestep = 4112. State = [[-0.38668022  0.22738837]]. Action = [[ 0.        0.        0.       -0.846745]]. Reward = [0.]
Curr episode timestep = 512
Scene graph at timestep 4112 is [True, False, False, False, False, True]
State prediction error at timestep 4112 is 0.012
Current timestep = 4113. State = [[-0.38668054  0.22738859]]. Action = [[ 0.         0.         0.        -0.5604148]]. Reward = [0.]
Curr episode timestep = 513
Scene graph at timestep 4113 is [True, False, False, False, False, True]
State prediction error at timestep 4113 is 0.012
Current timestep = 4114. State = [[-0.38668087  0.22738881]]. Action = [[0.         0.         0.         0.98253345]]. Reward = [0.]
Curr episode timestep = 514
Scene graph at timestep 4114 is [True, False, False, False, False, True]
State prediction error at timestep 4114 is 0.012
Current timestep = 4115. State = [[-0.38668117  0.22738902]]. Action = [[ 0.         0.         0.        -0.7735849]]. Reward = [0.]
Curr episode timestep = 515
Scene graph at timestep 4115 is [True, False, False, False, False, True]
State prediction error at timestep 4115 is 0.012
Current timestep = 4116. State = [[-0.3866815   0.22738925]]. Action = [[ 0.          0.          0.         -0.04692221]]. Reward = [0.]
Curr episode timestep = 516
Scene graph at timestep 4116 is [True, False, False, False, False, True]
State prediction error at timestep 4116 is 0.012
Current timestep = 4117. State = [[-0.3866818   0.22738945]]. Action = [[0.        0.        0.        0.6044016]]. Reward = [0.]
Curr episode timestep = 517
Scene graph at timestep 4117 is [True, False, False, False, False, True]
State prediction error at timestep 4117 is 0.012
Current timestep = 4118. State = [[-0.3866821   0.22738968]]. Action = [[0.        0.        0.        0.6465517]]. Reward = [0.]
Curr episode timestep = 518
Scene graph at timestep 4118 is [True, False, False, False, False, True]
State prediction error at timestep 4118 is 0.012
Current timestep = 4119. State = [[-0.3866824   0.22738989]]. Action = [[0.         0.         0.         0.13907921]]. Reward = [0.]
Curr episode timestep = 519
Scene graph at timestep 4119 is [True, False, False, False, False, True]
State prediction error at timestep 4119 is 0.012
Current timestep = 4120. State = [[-0.38668272  0.2273901 ]]. Action = [[ 0.          0.          0.         -0.57957536]]. Reward = [0.]
Curr episode timestep = 520
Scene graph at timestep 4120 is [True, False, False, False, False, True]
State prediction error at timestep 4120 is 0.012
Current timestep = 4121. State = [[-0.38668302  0.2273903 ]]. Action = [[0.        0.        0.        0.0827806]]. Reward = [0.]
Curr episode timestep = 521
Scene graph at timestep 4121 is [True, False, False, False, False, True]
State prediction error at timestep 4121 is 0.012
Current timestep = 4122. State = [[-0.38668332  0.22739051]]. Action = [[0.         0.         0.         0.31388438]]. Reward = [0.]
Curr episode timestep = 522
Scene graph at timestep 4122 is [True, False, False, False, False, True]
State prediction error at timestep 4122 is 0.012
Current timestep = 4123. State = [[-0.3866836   0.22739072]]. Action = [[ 0.         0.         0.        -0.6861366]]. Reward = [0.]
Curr episode timestep = 523
Scene graph at timestep 4123 is [True, False, False, False, False, True]
State prediction error at timestep 4123 is 0.012
Current timestep = 4124. State = [[-0.3866839   0.22739093]]. Action = [[ 0.          0.          0.         -0.54873675]]. Reward = [0.]
Curr episode timestep = 524
Scene graph at timestep 4124 is [True, False, False, False, False, True]
State prediction error at timestep 4124 is 0.012
Current timestep = 4125. State = [[-0.38668418  0.22739112]]. Action = [[ 0.          0.          0.         -0.49883735]]. Reward = [0.]
Curr episode timestep = 525
Scene graph at timestep 4125 is [True, False, False, False, False, True]
State prediction error at timestep 4125 is 0.012
Current timestep = 4126. State = [[-0.38668448  0.22739133]]. Action = [[ 0.          0.          0.         -0.02254927]]. Reward = [0.]
Curr episode timestep = 526
Scene graph at timestep 4126 is [True, False, False, False, False, True]
State prediction error at timestep 4126 is 0.012
Current timestep = 4127. State = [[-0.38668478  0.22739154]]. Action = [[ 0.          0.          0.         -0.73735964]]. Reward = [0.]
Curr episode timestep = 527
Scene graph at timestep 4127 is [True, False, False, False, False, True]
State prediction error at timestep 4127 is 0.012
Current timestep = 4128. State = [[-0.38668504  0.22739173]]. Action = [[ 0.          0.          0.         -0.55894697]]. Reward = [0.]
Curr episode timestep = 528
Scene graph at timestep 4128 is [True, False, False, False, False, True]
State prediction error at timestep 4128 is 0.012
Current timestep = 4129. State = [[-0.38668534  0.22739194]]. Action = [[ 0.         0.         0.        -0.6469235]]. Reward = [0.]
Curr episode timestep = 529
Scene graph at timestep 4129 is [True, False, False, False, False, True]
State prediction error at timestep 4129 is 0.012
Current timestep = 4130. State = [[-0.3866856   0.22739214]]. Action = [[ 0.         0.         0.        -0.9599216]]. Reward = [0.]
Curr episode timestep = 530
Scene graph at timestep 4130 is [True, False, False, False, False, True]
State prediction error at timestep 4130 is 0.012
Current timestep = 4131. State = [[-0.38668588  0.22739233]]. Action = [[ 0.          0.          0.         -0.55844223]]. Reward = [0.]
Curr episode timestep = 531
Scene graph at timestep 4131 is [True, False, False, False, False, True]
State prediction error at timestep 4131 is 0.012
Current timestep = 4132. State = [[-0.38668618  0.22739252]]. Action = [[ 0.         0.         0.        -0.6873301]]. Reward = [0.]
Curr episode timestep = 532
Scene graph at timestep 4132 is [True, False, False, False, False, True]
State prediction error at timestep 4132 is 0.012
Current timestep = 4133. State = [[-0.38668644  0.22739273]]. Action = [[ 0.         0.         0.        -0.6327896]]. Reward = [0.]
Curr episode timestep = 533
Scene graph at timestep 4133 is [True, False, False, False, False, True]
State prediction error at timestep 4133 is 0.012
Current timestep = 4134. State = [[-0.3866867   0.22739293]]. Action = [[ 0.          0.          0.         -0.24535257]]. Reward = [0.]
Curr episode timestep = 534
Scene graph at timestep 4134 is [True, False, False, False, False, True]
State prediction error at timestep 4134 is 0.012
Current timestep = 4135. State = [[-0.38668698  0.22739312]]. Action = [[ 0.          0.          0.         -0.09710509]]. Reward = [0.]
Curr episode timestep = 535
Scene graph at timestep 4135 is [True, False, False, False, False, True]
State prediction error at timestep 4135 is 0.012
Current timestep = 4136. State = [[-0.38668725  0.2273933 ]]. Action = [[ 0.         0.         0.        -0.5419658]]. Reward = [0.]
Curr episode timestep = 536
Scene graph at timestep 4136 is [True, False, False, False, False, True]
State prediction error at timestep 4136 is 0.012
Current timestep = 4137. State = [[-0.38668752  0.2273935 ]]. Action = [[0.        0.        0.        0.8822758]]. Reward = [0.]
Curr episode timestep = 537
Scene graph at timestep 4137 is [True, False, False, False, False, True]
State prediction error at timestep 4137 is 0.012
Current timestep = 4138. State = [[-0.3866878   0.22739369]]. Action = [[0.         0.         0.         0.46909928]]. Reward = [0.]
Curr episode timestep = 538
Scene graph at timestep 4138 is [True, False, False, False, False, True]
State prediction error at timestep 4138 is 0.012
Current timestep = 4139. State = [[-0.38668805  0.22739388]]. Action = [[ 0.          0.          0.         -0.16414654]]. Reward = [0.]
Curr episode timestep = 539
Scene graph at timestep 4139 is [True, False, False, False, False, True]
State prediction error at timestep 4139 is 0.012
Current timestep = 4140. State = [[-0.38668832  0.22739406]]. Action = [[ 0.         0.         0.        -0.7873079]]. Reward = [0.]
Curr episode timestep = 540
Scene graph at timestep 4140 is [True, False, False, False, False, True]
State prediction error at timestep 4140 is 0.012
Current timestep = 4141. State = [[-0.38668856  0.22739425]]. Action = [[ 0.         0.         0.        -0.4250977]]. Reward = [0.]
Curr episode timestep = 541
Scene graph at timestep 4141 is [True, False, False, False, False, True]
State prediction error at timestep 4141 is 0.012
Current timestep = 4142. State = [[-0.38668883  0.22739443]]. Action = [[0.        0.        0.        0.6934978]]. Reward = [0.]
Curr episode timestep = 542
Scene graph at timestep 4142 is [True, False, False, False, False, True]
State prediction error at timestep 4142 is 0.012
Current timestep = 4143. State = [[-0.38668907  0.22739463]]. Action = [[ 0.          0.          0.         -0.82617134]]. Reward = [0.]
Curr episode timestep = 543
Scene graph at timestep 4143 is [True, False, False, False, False, True]
State prediction error at timestep 4143 is 0.012
Current timestep = 4144. State = [[-0.38668934  0.2273948 ]]. Action = [[0.        0.        0.        0.9709023]]. Reward = [0.]
Curr episode timestep = 544
Scene graph at timestep 4144 is [True, False, False, False, False, True]
State prediction error at timestep 4144 is 0.012
Current timestep = 4145. State = [[-0.38668957  0.22739498]]. Action = [[ 0.          0.          0.         -0.17923313]]. Reward = [0.]
Curr episode timestep = 545
Scene graph at timestep 4145 is [True, False, False, False, False, True]
State prediction error at timestep 4145 is 0.012
Current timestep = 4146. State = [[-0.38668984  0.22739516]]. Action = [[0.         0.         0.         0.64003634]]. Reward = [0.]
Curr episode timestep = 546
Scene graph at timestep 4146 is [True, False, False, False, False, True]
State prediction error at timestep 4146 is 0.012
Current timestep = 4147. State = [[-0.38669008  0.22739536]]. Action = [[0.         0.         0.         0.14583218]]. Reward = [0.]
Curr episode timestep = 547
Scene graph at timestep 4147 is [True, False, False, False, False, True]
State prediction error at timestep 4147 is 0.012
Current timestep = 4148. State = [[-0.38669032  0.22739553]]. Action = [[0.         0.         0.         0.17603421]]. Reward = [0.]
Curr episode timestep = 548
Scene graph at timestep 4148 is [True, False, False, False, False, True]
State prediction error at timestep 4148 is 0.012
Current timestep = 4149. State = [[-0.38669056  0.22739571]]. Action = [[0.         0.         0.         0.91460514]]. Reward = [0.]
Curr episode timestep = 549
Scene graph at timestep 4149 is [True, False, False, False, False, True]
State prediction error at timestep 4149 is 0.012
Current timestep = 4150. State = [[-0.3866908   0.22739588]]. Action = [[ 0.         0.         0.        -0.3807155]]. Reward = [0.]
Curr episode timestep = 550
Scene graph at timestep 4150 is [True, False, False, False, False, True]
State prediction error at timestep 4150 is 0.012
Current timestep = 4151. State = [[-0.38669103  0.22739606]]. Action = [[0.        0.        0.        0.9481758]]. Reward = [0.]
Curr episode timestep = 551
Scene graph at timestep 4151 is [True, False, False, False, False, True]
State prediction error at timestep 4151 is 0.012
Current timestep = 4152. State = [[-0.38669127  0.22739623]]. Action = [[0.         0.         0.         0.89509976]]. Reward = [0.]
Curr episode timestep = 552
Scene graph at timestep 4152 is [True, False, False, False, False, True]
State prediction error at timestep 4152 is 0.012
Current timestep = 4153. State = [[-0.3866915   0.22739641]]. Action = [[0.         0.         0.         0.97996974]]. Reward = [0.]
Curr episode timestep = 553
Scene graph at timestep 4153 is [True, False, False, False, False, True]
State prediction error at timestep 4153 is 0.012
Current timestep = 4154. State = [[-0.38669175  0.22739658]]. Action = [[0.        0.        0.        0.6024817]]. Reward = [0.]
Curr episode timestep = 554
Scene graph at timestep 4154 is [True, False, False, False, False, True]
State prediction error at timestep 4154 is 0.012
Current timestep = 4155. State = [[-0.386692    0.22739676]]. Action = [[0.         0.         0.         0.15502477]]. Reward = [0.]
Curr episode timestep = 555
Scene graph at timestep 4155 is [True, False, False, False, False, True]
State prediction error at timestep 4155 is 0.012
Current timestep = 4156. State = [[-0.38669223  0.22739694]]. Action = [[0.         0.         0.         0.16168725]]. Reward = [0.]
Curr episode timestep = 556
Scene graph at timestep 4156 is [True, False, False, False, False, True]
State prediction error at timestep 4156 is 0.012
Current timestep = 4157. State = [[-0.38669246  0.2273971 ]]. Action = [[0.        0.        0.        0.9409139]]. Reward = [0.]
Curr episode timestep = 557
Scene graph at timestep 4157 is [True, False, False, False, False, True]
State prediction error at timestep 4157 is 0.012
Current timestep = 4158. State = [[-0.38669267  0.22739726]]. Action = [[ 0.          0.          0.         -0.78318685]]. Reward = [0.]
Curr episode timestep = 558
Scene graph at timestep 4158 is [True, False, False, False, False, True]
State prediction error at timestep 4158 is 0.012
Current timestep = 4159. State = [[-0.3866929   0.22739744]]. Action = [[ 0.          0.          0.         -0.08684146]]. Reward = [0.]
Curr episode timestep = 559
Scene graph at timestep 4159 is [True, False, False, False, False, True]
State prediction error at timestep 4159 is 0.012
Current timestep = 4160. State = [[-0.38669312  0.2273976 ]]. Action = [[0.        0.        0.        0.3344128]]. Reward = [0.]
Curr episode timestep = 560
Scene graph at timestep 4160 is [True, False, False, False, False, True]
State prediction error at timestep 4160 is 0.012
Current timestep = 4161. State = [[-0.38669336  0.22739777]]. Action = [[0.         0.         0.         0.06435585]]. Reward = [0.]
Curr episode timestep = 561
Scene graph at timestep 4161 is [True, False, False, False, False, True]
State prediction error at timestep 4161 is 0.012
Current timestep = 4162. State = [[-0.38669357  0.22739793]]. Action = [[ 0.         0.         0.        -0.9322376]]. Reward = [0.]
Curr episode timestep = 562
Scene graph at timestep 4162 is [True, False, False, False, False, True]
State prediction error at timestep 4162 is 0.012
Current timestep = 4163. State = [[-0.3866938   0.22739811]]. Action = [[0.        0.        0.        0.2246257]]. Reward = [0.]
Curr episode timestep = 563
Scene graph at timestep 4163 is [True, False, False, False, False, True]
State prediction error at timestep 4163 is 0.012
Current timestep = 4164. State = [[-0.386694    0.22739828]]. Action = [[ 0.         0.         0.        -0.9781104]]. Reward = [0.]
Curr episode timestep = 564
Scene graph at timestep 4164 is [True, False, False, False, False, True]
State prediction error at timestep 4164 is 0.012
Current timestep = 4165. State = [[-0.38669422  0.22739844]]. Action = [[0.         0.         0.         0.15821588]]. Reward = [0.]
Curr episode timestep = 565
Scene graph at timestep 4165 is [True, False, False, False, False, True]
State prediction error at timestep 4165 is 0.012
Current timestep = 4166. State = [[-0.38669443  0.22739859]]. Action = [[0.         0.         0.         0.31150746]]. Reward = [0.]
Curr episode timestep = 566
Scene graph at timestep 4166 is [True, False, False, False, False, True]
State prediction error at timestep 4166 is 0.012
Current timestep = 4167. State = [[-0.38669464  0.22739875]]. Action = [[ 0.          0.          0.         -0.47777045]]. Reward = [0.]
Curr episode timestep = 567
Scene graph at timestep 4167 is [True, False, False, False, False, True]
State prediction error at timestep 4167 is 0.012
Current timestep = 4168. State = [[-0.38669488  0.22739892]]. Action = [[ 0.          0.          0.         -0.34666967]]. Reward = [0.]
Curr episode timestep = 568
Scene graph at timestep 4168 is [True, False, False, False, False, True]
State prediction error at timestep 4168 is 0.012
Current timestep = 4169. State = [[-0.3866951   0.22739908]]. Action = [[0.         0.         0.         0.35224926]]. Reward = [0.]
Curr episode timestep = 569
Scene graph at timestep 4169 is [True, False, False, False, False, True]
State prediction error at timestep 4169 is 0.012
Current timestep = 4170. State = [[-0.3866953   0.22739923]]. Action = [[0.         0.         0.         0.63300955]]. Reward = [0.]
Curr episode timestep = 570
Scene graph at timestep 4170 is [True, False, False, False, False, True]
State prediction error at timestep 4170 is 0.012
Current timestep = 4171. State = [[-0.38669547  0.2273994 ]]. Action = [[ 0.          0.          0.         -0.82629406]]. Reward = [0.]
Curr episode timestep = 571
Scene graph at timestep 4171 is [True, False, False, False, False, True]
State prediction error at timestep 4171 is 0.012
Current timestep = 4172. State = [[-0.38669568  0.22739956]]. Action = [[ 0.         0.         0.        -0.6461122]]. Reward = [0.]
Curr episode timestep = 572
Scene graph at timestep 4172 is [True, False, False, False, False, True]
State prediction error at timestep 4172 is 0.012
Current timestep = 4173. State = [[-0.3866959  0.2273997]]. Action = [[0.         0.         0.         0.44027352]]. Reward = [0.]
Curr episode timestep = 573
Scene graph at timestep 4173 is [True, False, False, False, False, True]
State prediction error at timestep 4173 is 0.012
Current timestep = 4174. State = [[-0.3866961   0.22739987]]. Action = [[0.        0.        0.        0.6349387]]. Reward = [0.]
Curr episode timestep = 574
Scene graph at timestep 4174 is [True, False, False, False, False, True]
State prediction error at timestep 4174 is 0.012
Current timestep = 4175. State = [[-0.3866963   0.22740002]]. Action = [[ 0.          0.          0.         -0.53506243]]. Reward = [0.]
Curr episode timestep = 575
Scene graph at timestep 4175 is [True, False, False, False, False, True]
State prediction error at timestep 4175 is 0.012
Current timestep = 4176. State = [[-0.3866965   0.22740017]]. Action = [[0.         0.         0.         0.21545625]]. Reward = [0.]
Curr episode timestep = 576
Scene graph at timestep 4176 is [True, False, False, False, False, True]
State prediction error at timestep 4176 is 0.012
Current timestep = 4177. State = [[-0.3866967   0.22740033]]. Action = [[ 0.          0.          0.         -0.48396373]]. Reward = [0.]
Curr episode timestep = 577
Scene graph at timestep 4177 is [True, False, False, False, False, True]
State prediction error at timestep 4177 is 0.012
Current timestep = 4178. State = [[-0.3866969   0.22740048]]. Action = [[0.       0.       0.       0.455078]]. Reward = [0.]
Curr episode timestep = 578
Scene graph at timestep 4178 is [True, False, False, False, False, True]
State prediction error at timestep 4178 is 0.012
Current timestep = 4179. State = [[-0.38669708  0.22740063]]. Action = [[0.         0.         0.         0.25324345]]. Reward = [0.]
Curr episode timestep = 579
Scene graph at timestep 4179 is [True, False, False, False, False, True]
State prediction error at timestep 4179 is 0.012
Current timestep = 4180. State = [[-0.3866973   0.22740078]]. Action = [[0.         0.         0.         0.32195628]]. Reward = [0.]
Curr episode timestep = 580
Scene graph at timestep 4180 is [True, False, False, False, False, True]
State prediction error at timestep 4180 is 0.012
Current timestep = 4181. State = [[-0.38669747  0.22740093]]. Action = [[ 0.          0.          0.         -0.05178338]]. Reward = [0.]
Curr episode timestep = 581
Scene graph at timestep 4181 is [True, False, False, False, False, True]
State prediction error at timestep 4181 is 0.012
Current timestep = 4182. State = [[-0.38669768  0.22740108]]. Action = [[0.         0.         0.         0.36575234]]. Reward = [0.]
Curr episode timestep = 582
Scene graph at timestep 4182 is [True, False, False, False, False, True]
State prediction error at timestep 4182 is 0.012
Current timestep = 4183. State = [[-0.38669786  0.22740123]]. Action = [[0.         0.         0.         0.49316478]]. Reward = [0.]
Curr episode timestep = 583
Scene graph at timestep 4183 is [True, False, False, False, False, True]
State prediction error at timestep 4183 is 0.012
Current timestep = 4184. State = [[-0.38669804  0.22740138]]. Action = [[0.       0.       0.       0.422711]]. Reward = [0.]
Curr episode timestep = 584
Scene graph at timestep 4184 is [True, False, False, False, False, True]
State prediction error at timestep 4184 is 0.012
Current timestep = 4185. State = [[-0.38669822  0.22740152]]. Action = [[0.        0.        0.        0.8693538]]. Reward = [0.]
Curr episode timestep = 585
Scene graph at timestep 4185 is [True, False, False, False, False, True]
State prediction error at timestep 4185 is 0.012
Current timestep = 4186. State = [[-0.38669842  0.22740167]]. Action = [[0.         0.         0.         0.30120325]]. Reward = [0.]
Curr episode timestep = 586
Scene graph at timestep 4186 is [True, False, False, False, False, True]
State prediction error at timestep 4186 is 0.012
Current timestep = 4187. State = [[-0.3866986   0.22740182]]. Action = [[ 0.        0.        0.       -0.859274]]. Reward = [0.]
Curr episode timestep = 587
Scene graph at timestep 4187 is [True, False, False, False, False, True]
State prediction error at timestep 4187 is 0.012
Current timestep = 4188. State = [[-0.38669878  0.22740196]]. Action = [[ 0.          0.          0.         -0.02052176]]. Reward = [0.]
Curr episode timestep = 588
Scene graph at timestep 4188 is [True, False, False, False, False, True]
State prediction error at timestep 4188 is 0.012
Current timestep = 4189. State = [[-0.38669896  0.2274021 ]]. Action = [[0.         0.         0.         0.28388047]]. Reward = [0.]
Curr episode timestep = 589
Scene graph at timestep 4189 is [True, False, False, False, False, True]
State prediction error at timestep 4189 is 0.012
Current timestep = 4190. State = [[-0.38669914  0.22740225]]. Action = [[0.         0.         0.         0.28071547]]. Reward = [0.]
Curr episode timestep = 590
Scene graph at timestep 4190 is [True, False, False, False, False, True]
State prediction error at timestep 4190 is 0.012
Current timestep = 4191. State = [[-0.38669932  0.22740239]]. Action = [[ 0.          0.          0.         -0.63956296]]. Reward = [0.]
Curr episode timestep = 591
Scene graph at timestep 4191 is [True, False, False, False, False, True]
State prediction error at timestep 4191 is 0.012
Current timestep = 4192. State = [[-0.3866995   0.22740254]]. Action = [[ 0.         0.         0.        -0.6659844]]. Reward = [0.]
Curr episode timestep = 592
Scene graph at timestep 4192 is [True, False, False, False, False, True]
State prediction error at timestep 4192 is 0.012
Current timestep = 4193. State = [[-0.38669968  0.22740267]]. Action = [[0.         0.         0.         0.96383834]]. Reward = [0.]
Curr episode timestep = 593
Scene graph at timestep 4193 is [True, False, False, False, False, True]
State prediction error at timestep 4193 is 0.012
Current timestep = 4194. State = [[-0.38669986  0.22740282]]. Action = [[0.         0.         0.         0.70061874]]. Reward = [0.]
Curr episode timestep = 594
Scene graph at timestep 4194 is [True, False, False, False, False, True]
State prediction error at timestep 4194 is 0.012
Current timestep = 4195. State = [[-0.38670003  0.22740296]]. Action = [[0.         0.         0.         0.13946068]]. Reward = [0.]
Curr episode timestep = 595
Scene graph at timestep 4195 is [True, False, False, False, False, True]
State prediction error at timestep 4195 is 0.012
Current timestep = 4196. State = [[-0.38670018  0.22740309]]. Action = [[0.         0.         0.         0.33406365]]. Reward = [0.]
Curr episode timestep = 596
Scene graph at timestep 4196 is [True, False, False, False, False, True]
State prediction error at timestep 4196 is 0.012
Current timestep = 4197. State = [[-0.38670036  0.22740324]]. Action = [[ 0.         0.         0.        -0.7663417]]. Reward = [0.]
Curr episode timestep = 597
Scene graph at timestep 4197 is [True, False, False, False, False, True]
State prediction error at timestep 4197 is 0.012
Current timestep = 4198. State = [[-0.38670054  0.22740337]]. Action = [[0.        0.        0.        0.5061989]]. Reward = [0.]
Curr episode timestep = 598
Scene graph at timestep 4198 is [True, False, False, False, False, True]
State prediction error at timestep 4198 is 0.012
Current timestep = 4199. State = [[-0.3867007  0.2274035]]. Action = [[0.         0.         0.         0.76398325]]. Reward = [0.]
Curr episode timestep = 599
Scene graph at timestep 4199 is [True, False, False, False, False, True]
State prediction error at timestep 4199 is 0.012
Current timestep = 4200. State = [[-0.38670087  0.22740364]]. Action = [[0.       0.       0.       0.581743]]. Reward = [0.]
Curr episode timestep = 600
Scene graph at timestep 4200 is [True, False, False, False, False, True]
State prediction error at timestep 4200 is 0.012
Current timestep = 4201. State = [[-0.38670105  0.22740377]]. Action = [[0.         0.         0.         0.32735693]]. Reward = [0.]
Curr episode timestep = 601
Scene graph at timestep 4201 is [True, False, False, False, False, True]
State prediction error at timestep 4201 is 0.012
Current timestep = 4202. State = [[-0.3867012   0.22740391]]. Action = [[0.        0.        0.        0.5315683]]. Reward = [0.]
Curr episode timestep = 602
Scene graph at timestep 4202 is [True, False, False, False, False, True]
State prediction error at timestep 4202 is 0.012
Current timestep = 4203. State = [[-0.38670138  0.22740404]]. Action = [[0.         0.         0.         0.01271904]]. Reward = [0.]
Curr episode timestep = 603
Scene graph at timestep 4203 is [True, False, False, False, False, True]
State prediction error at timestep 4203 is 0.012
Current timestep = 4204. State = [[-0.38670152  0.22740418]]. Action = [[0.         0.         0.         0.34465086]]. Reward = [0.]
Curr episode timestep = 604
Scene graph at timestep 4204 is [True, False, False, False, False, True]
State prediction error at timestep 4204 is 0.012
Current timestep = 4205. State = [[-0.38670167  0.22740431]]. Action = [[ 0.         0.         0.        -0.5323629]]. Reward = [0.]
Curr episode timestep = 605
Scene graph at timestep 4205 is [True, False, False, False, False, True]
State prediction error at timestep 4205 is 0.012
Current timestep = 4206. State = [[-0.38670185  0.22740445]]. Action = [[ 0.          0.          0.         -0.48940587]]. Reward = [0.]
Curr episode timestep = 606
Scene graph at timestep 4206 is [True, False, False, False, False, True]
State prediction error at timestep 4206 is 0.012
Current timestep = 4207. State = [[-0.386702    0.22740458]]. Action = [[ 0.         0.         0.        -0.7813506]]. Reward = [0.]
Curr episode timestep = 607
Scene graph at timestep 4207 is [True, False, False, False, False, True]
State prediction error at timestep 4207 is 0.012
Current timestep = 4208. State = [[-0.38670215  0.22740471]]. Action = [[0.         0.         0.         0.42753553]]. Reward = [0.]
Curr episode timestep = 608
Scene graph at timestep 4208 is [True, False, False, False, False, True]
State prediction error at timestep 4208 is 0.012
Current timestep = 4209. State = [[-0.38670233  0.22740483]]. Action = [[0.        0.        0.        0.6751008]]. Reward = [0.]
Curr episode timestep = 609
Scene graph at timestep 4209 is [True, False, False, False, False, True]
State prediction error at timestep 4209 is 0.012
Current timestep = 4210. State = [[-0.38670248  0.22740497]]. Action = [[0.        0.        0.        0.9162129]]. Reward = [0.]
Curr episode timestep = 610
Scene graph at timestep 4210 is [True, False, False, False, False, True]
State prediction error at timestep 4210 is 0.012
Current timestep = 4211. State = [[-0.38670263  0.2274051 ]]. Action = [[0.         0.         0.         0.54299176]]. Reward = [0.]
Curr episode timestep = 611
Scene graph at timestep 4211 is [True, False, False, False, False, True]
State prediction error at timestep 4211 is 0.012
Current timestep = 4212. State = [[-0.38670278  0.22740522]]. Action = [[ 0.          0.          0.         -0.03257364]]. Reward = [0.]
Curr episode timestep = 612
Scene graph at timestep 4212 is [True, False, False, False, False, True]
State prediction error at timestep 4212 is 0.012
Current timestep = 4213. State = [[-0.38670292  0.22740535]]. Action = [[0.         0.         0.         0.34568417]]. Reward = [0.]
Curr episode timestep = 613
Scene graph at timestep 4213 is [True, False, False, False, False, True]
State prediction error at timestep 4213 is 0.012
Current timestep = 4214. State = [[-0.38670307  0.22740547]]. Action = [[ 0.         0.         0.        -0.9324307]]. Reward = [0.]
Curr episode timestep = 614
Scene graph at timestep 4214 is [True, False, False, False, False, True]
State prediction error at timestep 4214 is 0.012
Current timestep = 4215. State = [[-0.38670322  0.22740561]]. Action = [[ 0.         0.         0.        -0.6693599]]. Reward = [0.]
Curr episode timestep = 615
Scene graph at timestep 4215 is [True, False, False, False, False, True]
State prediction error at timestep 4215 is 0.012
Current timestep = 4216. State = [[-0.38670337  0.22740573]]. Action = [[0.        0.        0.        0.9748659]]. Reward = [0.]
Curr episode timestep = 616
Scene graph at timestep 4216 is [True, False, False, False, False, True]
State prediction error at timestep 4216 is 0.012
Current timestep = 4217. State = [[-0.38670352  0.22740586]]. Action = [[ 0.          0.          0.         -0.27089393]]. Reward = [0.]
Curr episode timestep = 617
Scene graph at timestep 4217 is [True, False, False, False, False, True]
State prediction error at timestep 4217 is 0.012
Current timestep = 4218. State = [[-0.38670367  0.22740598]]. Action = [[0.       0.       0.       0.673499]]. Reward = [0.]
Curr episode timestep = 618
Scene graph at timestep 4218 is [True, False, False, False, False, True]
State prediction error at timestep 4218 is 0.012
Current timestep = 4219. State = [[-0.38670382  0.2274061 ]]. Action = [[0.         0.         0.         0.14251351]]. Reward = [0.]
Curr episode timestep = 619
Scene graph at timestep 4219 is [True, False, False, False, False, True]
State prediction error at timestep 4219 is 0.012
Current timestep = 4220. State = [[-0.38670397  0.22740623]]. Action = [[0.         0.         0.         0.96947026]]. Reward = [0.]
Curr episode timestep = 620
Scene graph at timestep 4220 is [True, False, False, False, False, True]
State prediction error at timestep 4220 is 0.012
Current timestep = 4221. State = [[-0.38670412  0.22740635]]. Action = [[ 0.          0.          0.         -0.12003762]]. Reward = [0.]
Curr episode timestep = 621
Scene graph at timestep 4221 is [True, False, False, False, False, True]
State prediction error at timestep 4221 is 0.012
Current timestep = 4222. State = [[-0.38670427  0.22740647]]. Action = [[0.         0.         0.         0.28101635]]. Reward = [0.]
Curr episode timestep = 622
Scene graph at timestep 4222 is [True, False, False, False, False, True]
State prediction error at timestep 4222 is 0.012
Current timestep = 4223. State = [[-0.3867044   0.22740659]]. Action = [[0.         0.         0.         0.08333397]]. Reward = [0.]
Curr episode timestep = 623
Scene graph at timestep 4223 is [True, False, False, False, False, True]
State prediction error at timestep 4223 is 0.012
Current timestep = 4224. State = [[-0.38670453  0.22740671]]. Action = [[ 0.          0.          0.         -0.49607182]]. Reward = [0.]
Curr episode timestep = 624
Scene graph at timestep 4224 is [True, False, False, False, False, True]
State prediction error at timestep 4224 is 0.012
Current timestep = 4225. State = [[-0.38670468  0.22740683]]. Action = [[0.         0.         0.         0.23320508]]. Reward = [0.]
Curr episode timestep = 625
Scene graph at timestep 4225 is [True, False, False, False, False, True]
State prediction error at timestep 4225 is 0.012
Current timestep = 4226. State = [[-0.3867048   0.22740695]]. Action = [[ 0.         0.         0.        -0.7539104]]. Reward = [0.]
Curr episode timestep = 626
Scene graph at timestep 4226 is [True, False, False, False, False, True]
State prediction error at timestep 4226 is 0.012
Current timestep = 4227. State = [[-0.38670495  0.22740707]]. Action = [[ 0.         0.         0.        -0.6184505]]. Reward = [0.]
Curr episode timestep = 627
Scene graph at timestep 4227 is [True, False, False, False, False, True]
State prediction error at timestep 4227 is 0.012
Current timestep = 4228. State = [[-0.3867051   0.22740719]]. Action = [[ 0.          0.          0.         -0.85212135]]. Reward = [0.]
Curr episode timestep = 628
Scene graph at timestep 4228 is [True, False, False, False, False, True]
State prediction error at timestep 4228 is 0.012
Current timestep = 4229. State = [[-0.38670522  0.2274073 ]]. Action = [[ 0.          0.          0.         -0.16070831]]. Reward = [0.]
Curr episode timestep = 629
Scene graph at timestep 4229 is [True, False, False, False, False, True]
State prediction error at timestep 4229 is 0.012
Current timestep = 4230. State = [[-0.38670537  0.22740743]]. Action = [[0.         0.         0.         0.10093141]]. Reward = [0.]
Curr episode timestep = 630
Scene graph at timestep 4230 is [True, False, False, False, False, True]
State prediction error at timestep 4230 is 0.012
Current timestep = 4231. State = [[-0.3867055   0.22740754]]. Action = [[ 0.          0.          0.         -0.28092563]]. Reward = [0.]
Curr episode timestep = 631
Scene graph at timestep 4231 is [True, False, False, False, False, True]
State prediction error at timestep 4231 is 0.012
Current timestep = 4232. State = [[-0.38670564  0.22740766]]. Action = [[0.        0.        0.        0.6900513]]. Reward = [0.]
Curr episode timestep = 632
Scene graph at timestep 4232 is [True, False, False, False, False, True]
State prediction error at timestep 4232 is 0.012
Current timestep = 4233. State = [[-0.38670576  0.22740778]]. Action = [[ 0.          0.          0.         -0.40494698]]. Reward = [0.]
Curr episode timestep = 633
Scene graph at timestep 4233 is [True, False, False, False, False, True]
State prediction error at timestep 4233 is 0.012
Current timestep = 4234. State = [[-0.38670588  0.22740789]]. Action = [[0.         0.         0.         0.35247278]]. Reward = [0.]
Curr episode timestep = 634
Scene graph at timestep 4234 is [True, False, False, False, False, True]
State prediction error at timestep 4234 is 0.012
Current timestep = 4235. State = [[-0.38670602  0.227408  ]]. Action = [[0.         0.         0.         0.58820105]]. Reward = [0.]
Curr episode timestep = 635
Scene graph at timestep 4235 is [True, False, False, False, False, True]
State prediction error at timestep 4235 is 0.012
Current timestep = 4236. State = [[-0.38670614  0.22740813]]. Action = [[0.         0.         0.         0.04555321]]. Reward = [0.]
Curr episode timestep = 636
Scene graph at timestep 4236 is [True, False, False, False, False, True]
State prediction error at timestep 4236 is 0.012
Current timestep = 4237. State = [[-0.38670626  0.22740823]]. Action = [[0.        0.        0.        0.8325834]]. Reward = [0.]
Curr episode timestep = 637
Scene graph at timestep 4237 is [True, False, False, False, False, True]
State prediction error at timestep 4237 is 0.012
Current timestep = 4238. State = [[-0.3867064   0.22740835]]. Action = [[0.       0.       0.       0.865306]]. Reward = [0.]
Curr episode timestep = 638
Scene graph at timestep 4238 is [True, False, False, False, False, True]
State prediction error at timestep 4238 is 0.012
Current timestep = 4239. State = [[-0.38670653  0.22740847]]. Action = [[ 0.          0.          0.         -0.20628077]]. Reward = [0.]
Curr episode timestep = 639
Scene graph at timestep 4239 is [True, False, False, False, False, True]
State prediction error at timestep 4239 is 0.012
Current timestep = 4240. State = [[-0.38670665  0.22740857]]. Action = [[ 0.          0.          0.         -0.03171229]]. Reward = [0.]
Curr episode timestep = 640
Scene graph at timestep 4240 is [True, False, False, False, False, True]
State prediction error at timestep 4240 is 0.012
Current timestep = 4241. State = [[-0.38670677  0.22740869]]. Action = [[0.         0.         0.         0.89640284]]. Reward = [0.]
Curr episode timestep = 641
Scene graph at timestep 4241 is [True, False, False, False, False, True]
State prediction error at timestep 4241 is 0.012
Current timestep = 4242. State = [[-0.3867069  0.2274088]]. Action = [[ 0.          0.          0.         -0.09990335]]. Reward = [0.]
Curr episode timestep = 642
Scene graph at timestep 4242 is [True, False, False, False, False, True]
State prediction error at timestep 4242 is 0.012
Current timestep = 4243. State = [[-0.386707    0.22740892]]. Action = [[ 0.         0.         0.        -0.4893334]]. Reward = [0.]
Curr episode timestep = 643
Scene graph at timestep 4243 is [True, False, False, False, False, True]
State prediction error at timestep 4243 is 0.012
Current timestep = 4244. State = [[-0.38670716  0.22740902]]. Action = [[ 0.          0.          0.         -0.51983213]]. Reward = [0.]
Curr episode timestep = 644
Scene graph at timestep 4244 is [True, False, False, False, False, True]
State prediction error at timestep 4244 is 0.012
Current timestep = 4245. State = [[-0.38670728  0.22740912]]. Action = [[ 0.         0.         0.        -0.3133893]]. Reward = [0.]
Curr episode timestep = 645
Scene graph at timestep 4245 is [True, False, False, False, False, True]
State prediction error at timestep 4245 is 0.012
Current timestep = 4246. State = [[-0.3867074   0.22740924]]. Action = [[ 0.         0.         0.        -0.6312403]]. Reward = [0.]
Curr episode timestep = 646
Scene graph at timestep 4246 is [True, False, False, False, False, True]
State prediction error at timestep 4246 is 0.012
Current timestep = 4247. State = [[-0.3867075   0.22740935]]. Action = [[ 0.         0.         0.        -0.9797836]]. Reward = [0.]
Curr episode timestep = 647
Scene graph at timestep 4247 is [True, False, False, False, False, True]
State prediction error at timestep 4247 is 0.012
Current timestep = 4248. State = [[-0.38670763  0.22740945]]. Action = [[ 0.         0.         0.        -0.3902601]]. Reward = [0.]
Curr episode timestep = 648
Scene graph at timestep 4248 is [True, False, False, False, False, True]
State prediction error at timestep 4248 is 0.012
Current timestep = 4249. State = [[-0.38670775  0.22740956]]. Action = [[ 0.         0.         0.        -0.3611945]]. Reward = [0.]
Curr episode timestep = 649
Scene graph at timestep 4249 is [True, False, False, False, False, True]
State prediction error at timestep 4249 is 0.012
Current timestep = 4250. State = [[-0.38670784  0.22740968]]. Action = [[ 0.          0.          0.         -0.90188146]]. Reward = [0.]
Curr episode timestep = 650
Scene graph at timestep 4250 is [True, False, False, False, False, True]
State prediction error at timestep 4250 is 0.012
Current timestep = 4251. State = [[-0.38670796  0.22740978]]. Action = [[ 0.         0.         0.        -0.9169128]]. Reward = [0.]
Curr episode timestep = 651
Scene graph at timestep 4251 is [True, False, False, False, False, True]
State prediction error at timestep 4251 is 0.012
Current timestep = 4252. State = [[-0.38670808  0.22740988]]. Action = [[0.         0.         0.         0.08680367]]. Reward = [0.]
Curr episode timestep = 652
Scene graph at timestep 4252 is [True, False, False, False, False, True]
State prediction error at timestep 4252 is 0.012
Current timestep = 4253. State = [[-0.3867082   0.22740999]]. Action = [[ 0.          0.          0.         -0.72209007]]. Reward = [0.]
Curr episode timestep = 653
Scene graph at timestep 4253 is [True, False, False, False, False, True]
State prediction error at timestep 4253 is 0.012
Current timestep = 4254. State = [[-0.38670832  0.2274101 ]]. Action = [[ 0.          0.          0.         -0.69572777]]. Reward = [0.]
Curr episode timestep = 654
Scene graph at timestep 4254 is [True, False, False, False, False, True]
State prediction error at timestep 4254 is 0.012
Current timestep = 4255. State = [[-0.38670844  0.2274102 ]]. Action = [[ 0.         0.         0.        -0.6729631]]. Reward = [0.]
Curr episode timestep = 655
Scene graph at timestep 4255 is [True, False, False, False, False, True]
State prediction error at timestep 4255 is 0.012
Current timestep = 4256. State = [[-0.38670853  0.2274103 ]]. Action = [[ 0.          0.          0.         -0.33801937]]. Reward = [0.]
Curr episode timestep = 656
Scene graph at timestep 4256 is [True, False, False, False, False, True]
State prediction error at timestep 4256 is 0.012
Current timestep = 4257. State = [[-0.38670865  0.2274104 ]]. Action = [[ 0.          0.          0.         -0.16984296]]. Reward = [0.]
Curr episode timestep = 657
Scene graph at timestep 4257 is [True, False, False, False, False, True]
State prediction error at timestep 4257 is 0.012
Current timestep = 4258. State = [[-0.38670877  0.22741051]]. Action = [[ 0.        0.        0.       -0.500547]]. Reward = [0.]
Curr episode timestep = 658
Scene graph at timestep 4258 is [True, False, False, False, False, True]
State prediction error at timestep 4258 is 0.012
Current timestep = 4259. State = [[-0.3867089   0.22741061]]. Action = [[ 0.          0.          0.         -0.24395359]]. Reward = [0.]
Curr episode timestep = 659
Scene graph at timestep 4259 is [True, False, False, False, False, True]
State prediction error at timestep 4259 is 0.012
Current timestep = 4260. State = [[-0.38670897  0.22741072]]. Action = [[0.         0.         0.         0.57877254]]. Reward = [0.]
Curr episode timestep = 660
Scene graph at timestep 4260 is [True, False, False, False, False, True]
State prediction error at timestep 4260 is 0.012
Current timestep = 4261. State = [[-0.3867091   0.22741082]]. Action = [[ 0.         0.         0.        -0.8769512]]. Reward = [0.]
Curr episode timestep = 661
Scene graph at timestep 4261 is [True, False, False, False, False, True]
State prediction error at timestep 4261 is 0.012
Current timestep = 4262. State = [[-0.38670918  0.22741093]]. Action = [[ 0.         0.         0.        -0.8125984]]. Reward = [0.]
Curr episode timestep = 662
Scene graph at timestep 4262 is [True, False, False, False, False, True]
State prediction error at timestep 4262 is 0.012
Current timestep = 4263. State = [[-0.3867093   0.22741103]]. Action = [[0.         0.         0.         0.02331054]]. Reward = [0.]
Curr episode timestep = 663
Scene graph at timestep 4263 is [True, False, False, False, False, True]
State prediction error at timestep 4263 is 0.012
Current timestep = 4264. State = [[-0.38670942  0.22741112]]. Action = [[ 0.         0.         0.        -0.5232295]]. Reward = [0.]
Curr episode timestep = 664
Scene graph at timestep 4264 is [True, False, False, False, False, True]
State prediction error at timestep 4264 is 0.012
Current timestep = 4265. State = [[-0.3867095   0.22741123]]. Action = [[0.         0.         0.         0.96461225]]. Reward = [0.]
Curr episode timestep = 665
Scene graph at timestep 4265 is [True, False, False, False, False, True]
State prediction error at timestep 4265 is 0.012
Current timestep = 4266. State = [[-0.38670963  0.22741133]]. Action = [[0.         0.         0.         0.48589945]]. Reward = [0.]
Curr episode timestep = 666
Scene graph at timestep 4266 is [True, False, False, False, False, True]
State prediction error at timestep 4266 is 0.012
Current timestep = 4267. State = [[-0.38670972  0.22741142]]. Action = [[ 0.         0.         0.        -0.6509914]]. Reward = [0.]
Curr episode timestep = 667
Scene graph at timestep 4267 is [True, False, False, False, False, True]
State prediction error at timestep 4267 is 0.012
Current timestep = 4268. State = [[-0.3867098   0.22741152]]. Action = [[0.         0.         0.         0.30428338]]. Reward = [0.]
Curr episode timestep = 668
Scene graph at timestep 4268 is [True, False, False, False, False, True]
State prediction error at timestep 4268 is 0.012
Current timestep = 4269. State = [[-0.38670993  0.22741163]]. Action = [[ 0.          0.          0.         -0.33302748]]. Reward = [0.]
Curr episode timestep = 669
Scene graph at timestep 4269 is [True, False, False, False, False, True]
State prediction error at timestep 4269 is 0.012
Current timestep = 4270. State = [[-0.38671002  0.22741172]]. Action = [[ 0.          0.          0.         -0.30072784]]. Reward = [0.]
Curr episode timestep = 670
Scene graph at timestep 4270 is [True, False, False, False, False, True]
State prediction error at timestep 4270 is 0.012
Current timestep = 4271. State = [[-0.38671014  0.22741182]]. Action = [[0.         0.         0.         0.41317225]]. Reward = [0.]
Curr episode timestep = 671
Scene graph at timestep 4271 is [True, False, False, False, False, True]
State prediction error at timestep 4271 is 0.012
Current timestep = 4272. State = [[-0.38671023  0.22741193]]. Action = [[ 0.         0.         0.        -0.9474585]]. Reward = [0.]
Curr episode timestep = 672
Scene graph at timestep 4272 is [True, False, False, False, False, True]
State prediction error at timestep 4272 is 0.012
Current timestep = 4273. State = [[-0.38671032  0.22741202]]. Action = [[0.         0.         0.         0.72784877]]. Reward = [0.]
Curr episode timestep = 673
Scene graph at timestep 4273 is [True, False, False, False, False, True]
State prediction error at timestep 4273 is 0.012
Current timestep = 4274. State = [[-0.38671044  0.22741212]]. Action = [[ 0.          0.          0.         -0.18890595]]. Reward = [0.]
Curr episode timestep = 674
Scene graph at timestep 4274 is [True, False, False, False, False, True]
State prediction error at timestep 4274 is 0.012
Current timestep = 4275. State = [[-0.38671052  0.22741221]]. Action = [[0.        0.        0.        0.5189762]]. Reward = [0.]
Curr episode timestep = 675
Scene graph at timestep 4275 is [True, False, False, False, False, True]
State prediction error at timestep 4275 is 0.012
Current timestep = 4276. State = [[-0.3867106  0.2274123]]. Action = [[ 0.        0.        0.       -0.696401]]. Reward = [0.]
Curr episode timestep = 676
Scene graph at timestep 4276 is [True, False, False, False, False, True]
State prediction error at timestep 4276 is 0.012
Current timestep = 4277. State = [[-0.3867107  0.2274124]]. Action = [[ 0.          0.          0.         -0.55575943]]. Reward = [0.]
Curr episode timestep = 677
Scene graph at timestep 4277 is [True, False, False, False, False, True]
State prediction error at timestep 4277 is 0.012
Current timestep = 4278. State = [[-0.38671082  0.22741249]]. Action = [[ 0.          0.          0.         -0.07734978]]. Reward = [0.]
Curr episode timestep = 678
Scene graph at timestep 4278 is [True, False, False, False, False, True]
State prediction error at timestep 4278 is 0.012
Current timestep = 4279. State = [[-0.3867109  0.2274126]]. Action = [[0.         0.         0.         0.20781219]]. Reward = [0.]
Curr episode timestep = 679
Scene graph at timestep 4279 is [True, False, False, False, False, True]
State prediction error at timestep 4279 is 0.012
Current timestep = 4280. State = [[-0.386711    0.22741269]]. Action = [[ 0.          0.          0.         -0.16834462]]. Reward = [0.]
Curr episode timestep = 680
Scene graph at timestep 4280 is [True, False, False, False, False, True]
State prediction error at timestep 4280 is 0.012
Current timestep = 4281. State = [[-0.3867111   0.22741278]]. Action = [[ 0.         0.         0.        -0.9408392]]. Reward = [0.]
Curr episode timestep = 681
Scene graph at timestep 4281 is [True, False, False, False, False, True]
State prediction error at timestep 4281 is 0.012
Current timestep = 4282. State = [[-0.38671118  0.22741288]]. Action = [[ 0.          0.          0.         -0.28577447]]. Reward = [0.]
Curr episode timestep = 682
Scene graph at timestep 4282 is [True, False, False, False, False, True]
State prediction error at timestep 4282 is 0.012
Current timestep = 4283. State = [[-0.38671127  0.22741297]]. Action = [[0.         0.         0.         0.18860269]]. Reward = [0.]
Curr episode timestep = 683
Scene graph at timestep 4283 is [True, False, False, False, False, True]
State prediction error at timestep 4283 is 0.012
Current timestep = 4284. State = [[-0.3867114   0.22741306]]. Action = [[ 0.         0.         0.        -0.7583294]]. Reward = [0.]
Curr episode timestep = 684
Scene graph at timestep 4284 is [True, False, False, False, False, True]
State prediction error at timestep 4284 is 0.012
Current timestep = 4285. State = [[-0.38671148  0.22741315]]. Action = [[ 0.          0.          0.         -0.23069346]]. Reward = [0.]
Curr episode timestep = 685
Scene graph at timestep 4285 is [True, False, False, False, False, True]
State prediction error at timestep 4285 is 0.012
Current timestep = 4286. State = [[-0.38671157  0.22741325]]. Action = [[ 0.          0.          0.         -0.35576606]]. Reward = [0.]
Curr episode timestep = 686
Scene graph at timestep 4286 is [True, False, False, False, False, True]
State prediction error at timestep 4286 is 0.012
Current timestep = 4287. State = [[-0.38671166  0.22741334]]. Action = [[ 0.          0.          0.         -0.03163409]]. Reward = [0.]
Curr episode timestep = 687
Scene graph at timestep 4287 is [True, False, False, False, False, True]
State prediction error at timestep 4287 is 0.012
Current timestep = 4288. State = [[-0.38671175  0.22741343]]. Action = [[ 0.         0.         0.        -0.0783388]]. Reward = [0.]
Curr episode timestep = 688
Scene graph at timestep 4288 is [True, False, False, False, False, True]
State prediction error at timestep 4288 is 0.012
Current timestep = 4289. State = [[-0.38671184  0.22741352]]. Action = [[ 0.          0.          0.         -0.02118975]]. Reward = [0.]
Curr episode timestep = 689
Scene graph at timestep 4289 is [True, False, False, False, False, True]
State prediction error at timestep 4289 is 0.012
Current timestep = 4290. State = [[-0.38671193  0.22741361]]. Action = [[ 0.         0.         0.        -0.2933426]]. Reward = [0.]
Curr episode timestep = 690
Scene graph at timestep 4290 is [True, False, False, False, False, True]
State prediction error at timestep 4290 is 0.012
Current timestep = 4291. State = [[-0.386712   0.2274137]]. Action = [[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 -1.1920929e-06]]. Reward = [0.]
Curr episode timestep = 691
Scene graph at timestep 4291 is [True, False, False, False, False, True]
State prediction error at timestep 4291 is 0.012
Current timestep = 4292. State = [[-0.3867121   0.22741379]]. Action = [[0.         0.         0.         0.96929073]]. Reward = [0.]
Curr episode timestep = 692
Scene graph at timestep 4292 is [True, False, False, False, False, True]
State prediction error at timestep 4292 is 0.012
Current timestep = 4293. State = [[-0.38671216  0.22741388]]. Action = [[ 0.         0.         0.        -0.8972954]]. Reward = [0.]
Curr episode timestep = 693
Scene graph at timestep 4293 is [True, False, False, False, False, True]
State prediction error at timestep 4293 is 0.012
Current timestep = 4294. State = [[-0.38671225  0.22741397]]. Action = [[0.         0.         0.         0.92153525]]. Reward = [0.]
Curr episode timestep = 694
Scene graph at timestep 4294 is [True, False, False, False, False, True]
State prediction error at timestep 4294 is 0.012
Current timestep = 4295. State = [[-0.38671234  0.22741406]]. Action = [[0.         0.         0.         0.21161008]]. Reward = [0.]
Curr episode timestep = 695
Scene graph at timestep 4295 is [True, False, False, False, False, True]
State prediction error at timestep 4295 is 0.012
Current timestep = 4296. State = [[-0.38671243  0.22741415]]. Action = [[ 0.          0.          0.         -0.46596843]]. Reward = [0.]
Curr episode timestep = 696
Scene graph at timestep 4296 is [True, False, False, False, False, True]
State prediction error at timestep 4296 is 0.012
Current timestep = 4297. State = [[-0.38671252  0.22741424]]. Action = [[0.        0.        0.        0.6829479]]. Reward = [0.]
Curr episode timestep = 697
Scene graph at timestep 4297 is [True, False, False, False, False, True]
State prediction error at timestep 4297 is 0.012
Current timestep = 4298. State = [[-0.3867126   0.22741432]]. Action = [[ 0.          0.          0.         -0.47265917]]. Reward = [0.]
Curr episode timestep = 698
Scene graph at timestep 4298 is [True, False, False, False, False, True]
State prediction error at timestep 4298 is 0.012
Current timestep = 4299. State = [[-0.3867127   0.22741441]]. Action = [[ 0.         0.         0.        -0.6111821]]. Reward = [0.]
Curr episode timestep = 699
Scene graph at timestep 4299 is [True, False, False, False, False, True]
State prediction error at timestep 4299 is 0.012
Current timestep = 4300. State = [[-0.38671276  0.2274145 ]]. Action = [[ 0.          0.          0.         -0.85339147]]. Reward = [0.]
Curr episode timestep = 700
Scene graph at timestep 4300 is [True, False, False, False, False, True]
State prediction error at timestep 4300 is 0.012
Current timestep = 4301. State = [[-0.38671285  0.22741458]]. Action = [[0.        0.        0.        0.9222429]]. Reward = [0.]
Curr episode timestep = 701
Scene graph at timestep 4301 is [True, False, False, False, False, True]
State prediction error at timestep 4301 is 0.012
Current timestep = 4302. State = [[-0.38671294  0.22741467]]. Action = [[ 0.          0.          0.         -0.68450075]]. Reward = [0.]
Curr episode timestep = 702
Scene graph at timestep 4302 is [True, False, False, False, False, True]
State prediction error at timestep 4302 is 0.012
Current timestep = 4303. State = [[-0.386713    0.22741476]]. Action = [[ 0.          0.          0.         -0.83454704]]. Reward = [0.]
Curr episode timestep = 703
Scene graph at timestep 4303 is [True, False, False, False, False, True]
State prediction error at timestep 4303 is 0.012
Current timestep = 4304. State = [[-0.3867131   0.22741485]]. Action = [[0.         0.         0.         0.42371416]]. Reward = [0.]
Curr episode timestep = 704
Scene graph at timestep 4304 is [True, False, False, False, False, True]
State prediction error at timestep 4304 is 0.012
Current timestep = 4305. State = [[-0.38671318  0.22741494]]. Action = [[0.         0.         0.         0.16316366]]. Reward = [0.]
Curr episode timestep = 705
Scene graph at timestep 4305 is [True, False, False, False, False, True]
State prediction error at timestep 4305 is 0.012
Current timestep = 4306. State = [[-0.38671327  0.22741501]]. Action = [[0.        0.        0.        0.5758021]]. Reward = [0.]
Curr episode timestep = 706
Scene graph at timestep 4306 is [True, False, False, False, False, True]
State prediction error at timestep 4306 is 0.012
Current timestep = 4307. State = [[-0.38671333  0.2274151 ]]. Action = [[0.         0.         0.         0.91702676]]. Reward = [0.]
Curr episode timestep = 707
Scene graph at timestep 4307 is [True, False, False, False, False, True]
State prediction error at timestep 4307 is 0.012
Current timestep = 4308. State = [[-0.38671342  0.22741519]]. Action = [[ 0.         0.         0.        -0.6752805]]. Reward = [0.]
Curr episode timestep = 708
Scene graph at timestep 4308 is [True, False, False, False, False, True]
State prediction error at timestep 4308 is 0.012
Current timestep = 4309. State = [[-0.38671347  0.22741526]]. Action = [[ 0.         0.         0.        -0.2083208]]. Reward = [0.]
Curr episode timestep = 709
Scene graph at timestep 4309 is [True, False, False, False, False, True]
State prediction error at timestep 4309 is 0.012
Current timestep = 4310. State = [[-0.38671356  0.22741535]]. Action = [[ 0.          0.          0.         -0.13371658]]. Reward = [0.]
Curr episode timestep = 710
Scene graph at timestep 4310 is [True, False, False, False, False, True]
State prediction error at timestep 4310 is 0.012
Current timestep = 4311. State = [[-0.38671365  0.22741544]]. Action = [[0.         0.         0.         0.17433047]]. Reward = [0.]
Curr episode timestep = 711
Scene graph at timestep 4311 is [True, False, False, False, False, True]
State prediction error at timestep 4311 is 0.012
Current timestep = 4312. State = [[-0.3867137   0.22741552]]. Action = [[0.         0.         0.         0.37866473]]. Reward = [0.]
Curr episode timestep = 712
Scene graph at timestep 4312 is [True, False, False, False, False, True]
State prediction error at timestep 4312 is 0.012
Current timestep = 4313. State = [[-0.3867138  0.2274156]]. Action = [[ 0.         0.         0.        -0.5468336]]. Reward = [0.]
Curr episode timestep = 713
Scene graph at timestep 4313 is [True, False, False, False, False, True]
State prediction error at timestep 4313 is 0.012
Current timestep = 4314. State = [[-0.38671386  0.22741568]]. Action = [[ 0.          0.          0.         -0.10377216]]. Reward = [0.]
Curr episode timestep = 714
Scene graph at timestep 4314 is [True, False, False, False, False, True]
State prediction error at timestep 4314 is 0.012
Current timestep = 4315. State = [[-0.38671395  0.22741577]]. Action = [[0.        0.        0.        0.7819257]]. Reward = [0.]
Curr episode timestep = 715
Scene graph at timestep 4315 is [True, False, False, False, False, True]
State prediction error at timestep 4315 is 0.012
Current timestep = 4316. State = [[-0.386714    0.22741584]]. Action = [[ 0.          0.          0.         -0.81411886]]. Reward = [0.]
Curr episode timestep = 716
Scene graph at timestep 4316 is [True, False, False, False, False, True]
State prediction error at timestep 4316 is 0.012
Current timestep = 4317. State = [[-0.3867141   0.22741593]]. Action = [[0.        0.        0.        0.5994736]]. Reward = [0.]
Curr episode timestep = 717
Scene graph at timestep 4317 is [True, False, False, False, False, True]
State prediction error at timestep 4317 is 0.012
Current timestep = 4318. State = [[-0.38671416  0.22741601]]. Action = [[0.         0.         0.         0.98408556]]. Reward = [0.]
Curr episode timestep = 718
Scene graph at timestep 4318 is [True, False, False, False, False, True]
State prediction error at timestep 4318 is 0.012
Current timestep = 4319. State = [[-0.38671425  0.2274161 ]]. Action = [[ 0.         0.         0.        -0.0751164]]. Reward = [0.]
Curr episode timestep = 719
Scene graph at timestep 4319 is [True, False, False, False, False, True]
State prediction error at timestep 4319 is 0.012
Current timestep = 4320. State = [[-0.3867143   0.22741617]]. Action = [[ 0.          0.          0.         -0.34878528]]. Reward = [0.]
Curr episode timestep = 720
Scene graph at timestep 4320 is [True, False, False, False, False, True]
State prediction error at timestep 4320 is 0.012
Current timestep = 4321. State = [[-0.38671437  0.22741626]]. Action = [[0.         0.         0.         0.03234243]]. Reward = [0.]
Curr episode timestep = 721
Scene graph at timestep 4321 is [True, False, False, False, False, True]
State prediction error at timestep 4321 is 0.012
Current timestep = 4322. State = [[-0.38671446  0.22741634]]. Action = [[0.         0.         0.         0.17634869]]. Reward = [0.]
Curr episode timestep = 722
Scene graph at timestep 4322 is [True, False, False, False, False, True]
State prediction error at timestep 4322 is 0.012
Current timestep = 4323. State = [[-0.38671452  0.22741643]]. Action = [[0.       0.       0.       0.232445]]. Reward = [0.]
Curr episode timestep = 723
Scene graph at timestep 4323 is [True, False, False, False, False, True]
State prediction error at timestep 4323 is 0.012
Current timestep = 4324. State = [[-0.3867146  0.2274165]]. Action = [[ 0.          0.          0.         -0.01075435]]. Reward = [0.]
Curr episode timestep = 724
Scene graph at timestep 4324 is [True, False, False, False, False, True]
State prediction error at timestep 4324 is 0.012
Current timestep = 4325. State = [[-0.38671467  0.22741657]]. Action = [[0.        0.        0.        0.1362387]]. Reward = [0.]
Curr episode timestep = 725
Scene graph at timestep 4325 is [True, False, False, False, False, True]
State prediction error at timestep 4325 is 0.012
Current timestep = 4326. State = [[-0.38671473  0.22741666]]. Action = [[ 0.         0.         0.        -0.4350736]]. Reward = [0.]
Curr episode timestep = 726
Scene graph at timestep 4326 is [True, False, False, False, False, True]
State prediction error at timestep 4326 is 0.012
Current timestep = 4327. State = [[-0.38671482  0.22741674]]. Action = [[0.         0.         0.         0.32399964]]. Reward = [0.]
Curr episode timestep = 727
Scene graph at timestep 4327 is [True, False, False, False, False, True]
State prediction error at timestep 4327 is 0.012
Current timestep = 4328. State = [[-0.38671488  0.22741681]]. Action = [[0.         0.         0.         0.44586515]]. Reward = [0.]
Curr episode timestep = 728
Scene graph at timestep 4328 is [True, False, False, False, False, True]
State prediction error at timestep 4328 is 0.012
Current timestep = 4329. State = [[-0.38671494  0.22741689]]. Action = [[0.         0.         0.         0.08726227]]. Reward = [0.]
Curr episode timestep = 729
Scene graph at timestep 4329 is [True, False, False, False, False, True]
State prediction error at timestep 4329 is 0.012
Current timestep = 4330. State = [[-0.386715    0.22741698]]. Action = [[0.        0.        0.        0.5722753]]. Reward = [0.]
Curr episode timestep = 730
Scene graph at timestep 4330 is [True, False, False, False, False, True]
State prediction error at timestep 4330 is 0.012
Current timestep = 4331. State = [[-0.38671508  0.22741705]]. Action = [[0.         0.         0.         0.05978143]]. Reward = [0.]
Curr episode timestep = 731
Scene graph at timestep 4331 is [True, False, False, False, False, True]
State prediction error at timestep 4331 is 0.012
Current timestep = 4332. State = [[-0.38671514  0.22741713]]. Action = [[ 0.         0.         0.        -0.5899673]]. Reward = [0.]
Curr episode timestep = 732
Scene graph at timestep 4332 is [True, False, False, False, False, True]
State prediction error at timestep 4332 is 0.012
Current timestep = 4333. State = [[-0.3867152  0.2274172]]. Action = [[0.         0.         0.         0.17341518]]. Reward = [0.]
Curr episode timestep = 733
Scene graph at timestep 4333 is [True, False, False, False, False, True]
State prediction error at timestep 4333 is 0.012
Current timestep = 4334. State = [[-0.38671526  0.22741729]]. Action = [[0.         0.         0.         0.57331216]]. Reward = [0.]
Curr episode timestep = 734
Scene graph at timestep 4334 is [True, False, False, False, False, True]
State prediction error at timestep 4334 is 0.012
Current timestep = 4335. State = [[-0.38671535  0.22741736]]. Action = [[ 0.          0.          0.         -0.81557167]]. Reward = [0.]
Curr episode timestep = 735
Scene graph at timestep 4335 is [True, False, False, False, False, True]
State prediction error at timestep 4335 is 0.012
Current timestep = 4336. State = [[-0.3867154   0.22741744]]. Action = [[ 0.          0.          0.         -0.72332674]]. Reward = [0.]
Curr episode timestep = 736
Scene graph at timestep 4336 is [True, False, False, False, False, True]
State prediction error at timestep 4336 is 0.012
Current timestep = 4337. State = [[-0.38671547  0.22741751]]. Action = [[ 0.          0.          0.         -0.20861769]]. Reward = [0.]
Curr episode timestep = 737
Scene graph at timestep 4337 is [True, False, False, False, False, True]
State prediction error at timestep 4337 is 0.012
Current timestep = 4338. State = [[-0.38671553  0.22741759]]. Action = [[0.        0.        0.        0.9992075]]. Reward = [0.]
Curr episode timestep = 738
Scene graph at timestep 4338 is [True, False, False, False, False, True]
State prediction error at timestep 4338 is 0.012
Current timestep = 4339. State = [[-0.3867156   0.22741766]]. Action = [[ 0.          0.          0.         -0.53649044]]. Reward = [0.]
Curr episode timestep = 739
Scene graph at timestep 4339 is [True, False, False, False, False, True]
State prediction error at timestep 4339 is 0.012
Current timestep = 4340. State = [[-0.38671565  0.22741774]]. Action = [[ 0.          0.          0.         -0.56930137]]. Reward = [0.]
Curr episode timestep = 740
Scene graph at timestep 4340 is [True, False, False, False, False, True]
State prediction error at timestep 4340 is 0.012
Current timestep = 4341. State = [[-0.3867157   0.22741781]]. Action = [[ 0.         0.         0.        -0.4285426]]. Reward = [0.]
Curr episode timestep = 741
Scene graph at timestep 4341 is [True, False, False, False, False, True]
State prediction error at timestep 4341 is 0.012
Current timestep = 4342. State = [[-0.3867158   0.22741789]]. Action = [[0.         0.         0.         0.18003201]]. Reward = [0.]
Curr episode timestep = 742
Scene graph at timestep 4342 is [True, False, False, False, False, True]
State prediction error at timestep 4342 is 0.012
Current timestep = 4343. State = [[-0.38671586  0.22741796]]. Action = [[ 0.          0.          0.         -0.82853466]]. Reward = [0.]
Curr episode timestep = 743
Scene graph at timestep 4343 is [True, False, False, False, False, True]
State prediction error at timestep 4343 is 0.012
Current timestep = 4344. State = [[-0.38671592  0.22741804]]. Action = [[0.         0.         0.         0.46637154]]. Reward = [0.]
Curr episode timestep = 744
Scene graph at timestep 4344 is [True, False, False, False, False, True]
State prediction error at timestep 4344 is 0.012
Current timestep = 4345. State = [[-0.38671598  0.22741811]]. Action = [[ 0.          0.          0.         -0.06430006]]. Reward = [0.]
Curr episode timestep = 745
Scene graph at timestep 4345 is [True, False, False, False, False, True]
State prediction error at timestep 4345 is 0.012
Current timestep = 4346. State = [[-0.38671604  0.22741818]]. Action = [[0.         0.         0.         0.33805382]]. Reward = [0.]
Curr episode timestep = 746
Scene graph at timestep 4346 is [True, False, False, False, False, True]
State prediction error at timestep 4346 is 0.012
Current timestep = 4347. State = [[-0.3867161   0.22741826]]. Action = [[ 0.          0.          0.         -0.63245606]]. Reward = [0.]
Curr episode timestep = 747
Scene graph at timestep 4347 is [True, False, False, False, False, True]
State prediction error at timestep 4347 is 0.012
Current timestep = 4348. State = [[-0.38671616  0.22741833]]. Action = [[0.         0.         0.         0.27812755]]. Reward = [0.]
Curr episode timestep = 748
Scene graph at timestep 4348 is [True, False, False, False, False, True]
State prediction error at timestep 4348 is 0.012
Current timestep = 4349. State = [[-0.38671622  0.22741841]]. Action = [[0.        0.        0.        0.4452454]]. Reward = [0.]
Curr episode timestep = 749
Scene graph at timestep 4349 is [True, False, False, False, False, True]
State prediction error at timestep 4349 is 0.012
Current timestep = 4350. State = [[-0.38671628  0.22741848]]. Action = [[0.         0.         0.         0.48001373]]. Reward = [0.]
Curr episode timestep = 750
Scene graph at timestep 4350 is [True, False, False, False, False, True]
State prediction error at timestep 4350 is 0.012
Current timestep = 4351. State = [[-0.38671634  0.22741856]]. Action = [[ 0.          0.          0.         -0.02683169]]. Reward = [0.]
Curr episode timestep = 751
Scene graph at timestep 4351 is [True, False, False, False, False, True]
State prediction error at timestep 4351 is 0.012
Current timestep = 4352. State = [[-0.3867164   0.22741863]]. Action = [[0.        0.        0.        0.7453127]]. Reward = [0.]
Curr episode timestep = 752
Scene graph at timestep 4352 is [True, False, False, False, False, True]
State prediction error at timestep 4352 is 0.012
Current timestep = 4353. State = [[-0.38671646  0.2274187 ]]. Action = [[ 0.          0.          0.         -0.79171133]]. Reward = [0.]
Curr episode timestep = 753
Scene graph at timestep 4353 is [True, False, False, False, False, True]
State prediction error at timestep 4353 is 0.012
Current timestep = 4354. State = [[-0.3867165   0.22741878]]. Action = [[ 0.          0.          0.         -0.04342389]]. Reward = [0.]
Curr episode timestep = 754
Scene graph at timestep 4354 is [True, False, False, False, False, True]
State prediction error at timestep 4354 is 0.012
Current timestep = 4355. State = [[-0.38671657  0.22741885]]. Action = [[ 0.          0.          0.         -0.74022746]]. Reward = [0.]
Curr episode timestep = 755
Scene graph at timestep 4355 is [True, False, False, False, False, True]
State prediction error at timestep 4355 is 0.012
Current timestep = 4356. State = [[-0.38671663  0.22741891]]. Action = [[0.         0.         0.         0.51679385]]. Reward = [0.]
Curr episode timestep = 756
Scene graph at timestep 4356 is [True, False, False, False, False, True]
State prediction error at timestep 4356 is 0.012
Current timestep = 4357. State = [[-0.3867167   0.22741899]]. Action = [[0.         0.         0.         0.13068676]]. Reward = [0.]
Curr episode timestep = 757
Scene graph at timestep 4357 is [True, False, False, False, False, True]
State prediction error at timestep 4357 is 0.012
Current timestep = 4358. State = [[-0.38671672  0.22741906]]. Action = [[0.         0.         0.         0.77577186]]. Reward = [0.]
Curr episode timestep = 758
Scene graph at timestep 4358 is [True, False, False, False, False, True]
State prediction error at timestep 4358 is 0.012
Current timestep = 4359. State = [[-0.38671678  0.22741914]]. Action = [[0.        0.        0.        0.6916952]]. Reward = [0.]
Curr episode timestep = 759
Scene graph at timestep 4359 is [True, False, False, False, False, True]
State prediction error at timestep 4359 is 0.012
Current timestep = 4360. State = [[-0.38671684  0.22741921]]. Action = [[0.        0.        0.        0.6325717]]. Reward = [0.]
Curr episode timestep = 760
Scene graph at timestep 4360 is [True, False, False, False, False, True]
State prediction error at timestep 4360 is 0.012
Current timestep = 4361. State = [[-0.3867169   0.22741927]]. Action = [[0.         0.         0.         0.12676907]]. Reward = [0.]
Curr episode timestep = 761
Scene graph at timestep 4361 is [True, False, False, False, False, True]
State prediction error at timestep 4361 is 0.012
Current timestep = 4362. State = [[-0.38671696  0.22741935]]. Action = [[0.         0.         0.         0.43952322]]. Reward = [0.]
Curr episode timestep = 762
Scene graph at timestep 4362 is [True, False, False, False, False, True]
State prediction error at timestep 4362 is 0.012
Current timestep = 4363. State = [[-0.38671702  0.22741942]]. Action = [[0.         0.         0.         0.33048272]]. Reward = [0.]
Curr episode timestep = 763
Scene graph at timestep 4363 is [True, False, False, False, False, True]
State prediction error at timestep 4363 is 0.012
Current timestep = 4364. State = [[-0.38671708  0.22741948]]. Action = [[0.        0.        0.        0.8711592]]. Reward = [0.]
Curr episode timestep = 764
Scene graph at timestep 4364 is [True, False, False, False, False, True]
State prediction error at timestep 4364 is 0.012
Current timestep = 4365. State = [[-0.3867171   0.22741956]]. Action = [[0.         0.         0.         0.19716918]]. Reward = [0.]
Curr episode timestep = 765
Scene graph at timestep 4365 is [True, False, False, False, False, True]
State prediction error at timestep 4365 is 0.012
Current timestep = 4366. State = [[-0.38671717  0.22741963]]. Action = [[0.         0.         0.         0.08974135]]. Reward = [0.]
Curr episode timestep = 766
Scene graph at timestep 4366 is [True, False, False, False, False, True]
State prediction error at timestep 4366 is 0.012
Current timestep = 4367. State = [[-0.38671723  0.22741969]]. Action = [[0.         0.         0.         0.21903789]]. Reward = [0.]
Curr episode timestep = 767
Scene graph at timestep 4367 is [True, False, False, False, False, True]
State prediction error at timestep 4367 is 0.012
Current timestep = 4368. State = [[-0.3867173   0.22741976]]. Action = [[ 0.         0.         0.        -0.8774866]]. Reward = [0.]
Curr episode timestep = 768
Scene graph at timestep 4368 is [True, False, False, False, False, True]
State prediction error at timestep 4368 is 0.012
Current timestep = 4369. State = [[-0.38671735  0.22741984]]. Action = [[ 0.          0.          0.         -0.65886134]]. Reward = [0.]
Curr episode timestep = 769
Scene graph at timestep 4369 is [True, False, False, False, False, True]
State prediction error at timestep 4369 is 0.012
Current timestep = 4370. State = [[-0.38671738  0.2274199 ]]. Action = [[ 0.         0.         0.        -0.6035295]]. Reward = [0.]
Curr episode timestep = 770
Scene graph at timestep 4370 is [True, False, False, False, False, True]
State prediction error at timestep 4370 is 0.012
Current timestep = 4371. State = [[-0.38671744  0.22741997]]. Action = [[0.        0.        0.        0.8331313]]. Reward = [0.]
Curr episode timestep = 771
Scene graph at timestep 4371 is [True, False, False, False, False, True]
State prediction error at timestep 4371 is 0.012
Current timestep = 4372. State = [[-0.3867175   0.22742005]]. Action = [[ 0.          0.          0.         -0.24722499]]. Reward = [0.]
Curr episode timestep = 772
Scene graph at timestep 4372 is [True, False, False, False, False, True]
State prediction error at timestep 4372 is 0.012
Current timestep = 4373. State = [[-0.38671756  0.2274201 ]]. Action = [[0.         0.         0.         0.47537374]]. Reward = [0.]
Curr episode timestep = 773
Scene graph at timestep 4373 is [True, False, False, False, False, True]
State prediction error at timestep 4373 is 0.012
Current timestep = 4374. State = [[-0.3867176   0.22742018]]. Action = [[ 0.          0.          0.         -0.07837039]]. Reward = [0.]
Curr episode timestep = 774
Scene graph at timestep 4374 is [True, False, False, False, False, True]
State prediction error at timestep 4374 is 0.012
Current timestep = 4375. State = [[-0.38671765  0.22742024]]. Action = [[0.         0.         0.         0.69877565]]. Reward = [0.]
Curr episode timestep = 775
Scene graph at timestep 4375 is [True, False, False, False, False, True]
State prediction error at timestep 4375 is 0.012
Current timestep = 4376. State = [[-0.3867177   0.22742032]]. Action = [[0.         0.         0.         0.53389704]]. Reward = [0.]
Curr episode timestep = 776
Scene graph at timestep 4376 is [True, False, False, False, False, True]
State prediction error at timestep 4376 is 0.012
Current timestep = 4377. State = [[-0.38671774  0.22742037]]. Action = [[0.        0.        0.        0.9180021]]. Reward = [0.]
Curr episode timestep = 777
Scene graph at timestep 4377 is [True, False, False, False, False, True]
State prediction error at timestep 4377 is 0.012
Current timestep = 4378. State = [[-0.3867178   0.22742045]]. Action = [[ 0.         0.         0.        -0.9874041]]. Reward = [0.]
Curr episode timestep = 778
Scene graph at timestep 4378 is [True, False, False, False, False, True]
State prediction error at timestep 4378 is 0.012
Current timestep = 4379. State = [[-0.38671786  0.22742051]]. Action = [[0.        0.        0.        0.9609165]]. Reward = [0.]
Curr episode timestep = 779
Scene graph at timestep 4379 is [True, False, False, False, False, True]
State prediction error at timestep 4379 is 0.012
Current timestep = 4380. State = [[-0.3867179   0.22742058]]. Action = [[0.         0.         0.         0.45483673]]. Reward = [0.]
Curr episode timestep = 780
Scene graph at timestep 4380 is [True, False, False, False, False, True]
State prediction error at timestep 4380 is 0.012
Current timestep = 4381. State = [[-0.38671795  0.22742064]]. Action = [[ 0.       0.       0.      -0.21603]]. Reward = [0.]
Curr episode timestep = 781
Scene graph at timestep 4381 is [True, False, False, False, False, True]
State prediction error at timestep 4381 is 0.012
Current timestep = 4382. State = [[-0.386718    0.22742072]]. Action = [[ 0.          0.          0.         -0.78591454]]. Reward = [0.]
Curr episode timestep = 782
Scene graph at timestep 4382 is [True, False, False, False, False, True]
State prediction error at timestep 4382 is 0.012
Current timestep = 4383. State = [[-0.38671803  0.22742078]]. Action = [[ 0.         0.         0.        -0.6730823]]. Reward = [0.]
Curr episode timestep = 783
Scene graph at timestep 4383 is [True, False, False, False, False, True]
State prediction error at timestep 4383 is 0.012
Current timestep = 4384. State = [[-0.3867181   0.22742085]]. Action = [[0.         0.         0.         0.11140454]]. Reward = [0.]
Curr episode timestep = 784
Scene graph at timestep 4384 is [True, False, False, False, False, True]
State prediction error at timestep 4384 is 0.012
Current timestep = 4385. State = [[-0.38671815  0.22742091]]. Action = [[0.        0.        0.        0.4763553]]. Reward = [0.]
Curr episode timestep = 785
Scene graph at timestep 4385 is [True, False, False, False, False, True]
State prediction error at timestep 4385 is 0.012
Current timestep = 4386. State = [[-0.38671818  0.22742099]]. Action = [[ 0.          0.          0.         -0.88082904]]. Reward = [0.]
Curr episode timestep = 786
Scene graph at timestep 4386 is [True, False, False, False, False, True]
State prediction error at timestep 4386 is 0.012
Current timestep = 4387. State = [[-0.38671824  0.22742105]]. Action = [[ 0.          0.          0.         -0.05694747]]. Reward = [0.]
Curr episode timestep = 787
Scene graph at timestep 4387 is [True, False, False, False, False, True]
State prediction error at timestep 4387 is 0.012
Current timestep = 4388. State = [[-0.38671827  0.2274211 ]]. Action = [[0.         0.         0.         0.06995666]]. Reward = [0.]
Curr episode timestep = 788
Scene graph at timestep 4388 is [True, False, False, False, False, True]
State prediction error at timestep 4388 is 0.012
Current timestep = 4389. State = [[-0.38671833  0.22742118]]. Action = [[0.         0.         0.         0.49283338]]. Reward = [0.]
Curr episode timestep = 789
Scene graph at timestep 4389 is [True, False, False, False, False, True]
State prediction error at timestep 4389 is 0.012
Current timestep = 4390. State = [[-0.38671836  0.22742124]]. Action = [[ 0.         0.         0.        -0.7985157]]. Reward = [0.]
Curr episode timestep = 790
Scene graph at timestep 4390 is [True, False, False, False, False, True]
State prediction error at timestep 4390 is 0.012
Current timestep = 4391. State = [[-0.38671842  0.2274213 ]]. Action = [[ 0.         0.         0.        -0.5020809]]. Reward = [0.]
Curr episode timestep = 791
Scene graph at timestep 4391 is [True, False, False, False, False, True]
State prediction error at timestep 4391 is 0.012
Current timestep = 4392. State = [[-0.38671848  0.22742137]]. Action = [[ 0.         0.         0.        -0.5542712]]. Reward = [0.]
Curr episode timestep = 792
Scene graph at timestep 4392 is [True, False, False, False, False, True]
State prediction error at timestep 4392 is 0.012
Current timestep = 4393. State = [[-0.3867185   0.22742143]]. Action = [[0.        0.        0.        0.7321763]]. Reward = [0.]
Curr episode timestep = 793
Scene graph at timestep 4393 is [True, False, False, False, False, True]
State prediction error at timestep 4393 is 0.012
Current timestep = 4394. State = [[-0.38671857  0.22742149]]. Action = [[ 0.          0.          0.         -0.95968896]]. Reward = [0.]
Curr episode timestep = 794
Scene graph at timestep 4394 is [True, False, False, False, False, True]
State prediction error at timestep 4394 is 0.012
Current timestep = 4395. State = [[-0.3867186   0.22742157]]. Action = [[0.         0.         0.         0.46984386]]. Reward = [0.]
Curr episode timestep = 795
Scene graph at timestep 4395 is [True, False, False, False, False, True]
State prediction error at timestep 4395 is 0.012
Current timestep = 4396. State = [[-0.38671866  0.22742163]]. Action = [[ 0.        0.        0.       -0.909949]]. Reward = [0.]
Curr episode timestep = 796
Scene graph at timestep 4396 is [True, False, False, False, False, True]
State prediction error at timestep 4396 is 0.012
Current timestep = 4397. State = [[-0.3867187   0.22742169]]. Action = [[0.         0.         0.         0.77415967]]. Reward = [0.]
Curr episode timestep = 797
Scene graph at timestep 4397 is [True, False, False, False, False, True]
State prediction error at timestep 4397 is 0.012
Current timestep = 4398. State = [[-0.38671875  0.22742176]]. Action = [[0.         0.         0.         0.67385316]]. Reward = [0.]
Curr episode timestep = 798
Scene graph at timestep 4398 is [True, False, False, False, False, True]
State prediction error at timestep 4398 is 0.012
Current timestep = 4399. State = [[-0.38671878  0.22742182]]. Action = [[0.        0.        0.        0.7728785]]. Reward = [0.]
Curr episode timestep = 799
Scene graph at timestep 4399 is [True, False, False, False, False, True]
State prediction error at timestep 4399 is 0.012
Current timestep = 4400. State = [[-0.38671884  0.22742188]]. Action = [[ 0.          0.          0.         -0.48970604]]. Reward = [0.]
Curr episode timestep = 800
Scene graph at timestep 4400 is [True, False, False, False, False, True]
State prediction error at timestep 4400 is 0.012
Current timestep = 4401. State = [[-0.38671887  0.22742194]]. Action = [[0.         0.         0.         0.15401208]]. Reward = [0.]
Curr episode timestep = 801
Scene graph at timestep 4401 is [True, False, False, False, False, True]
State prediction error at timestep 4401 is 0.012
Current timestep = 4402. State = [[-0.3867189   0.22742201]]. Action = [[ 0.          0.          0.         -0.25384748]]. Reward = [0.]
Curr episode timestep = 802
Scene graph at timestep 4402 is [True, False, False, False, False, True]
State prediction error at timestep 4402 is 0.012
Current timestep = 4403. State = [[-0.38671896  0.22742207]]. Action = [[ 0.         0.         0.        -0.9607331]]. Reward = [0.]
Curr episode timestep = 803
Scene graph at timestep 4403 is [True, False, False, False, False, True]
State prediction error at timestep 4403 is 0.012
Current timestep = 4404. State = [[-0.386719    0.22742213]]. Action = [[0.         0.         0.         0.56275773]]. Reward = [0.]
Curr episode timestep = 804
Scene graph at timestep 4404 is [True, False, False, False, False, True]
State prediction error at timestep 4404 is 0.012
Current timestep = 4405. State = [[-0.38671905  0.2274222 ]]. Action = [[ 0.         0.         0.        -0.7664917]]. Reward = [0.]
Curr episode timestep = 805
Scene graph at timestep 4405 is [True, False, False, False, False, True]
State prediction error at timestep 4405 is 0.012
Current timestep = 4406. State = [[-0.38671908  0.22742225]]. Action = [[0.        0.        0.        0.9626868]]. Reward = [0.]
Curr episode timestep = 806
Scene graph at timestep 4406 is [True, False, False, False, False, True]
State prediction error at timestep 4406 is 0.012
Current timestep = 4407. State = [[-0.38671914  0.22742233]]. Action = [[0.        0.        0.        0.4012072]]. Reward = [0.]
Curr episode timestep = 807
Scene graph at timestep 4407 is [True, False, False, False, False, True]
State prediction error at timestep 4407 is 0.012
Current timestep = 4408. State = [[-0.38671917  0.22742239]]. Action = [[ 0.         0.         0.        -0.4218349]]. Reward = [0.]
Curr episode timestep = 808
Scene graph at timestep 4408 is [True, False, False, False, False, True]
State prediction error at timestep 4408 is 0.012
Current timestep = 4409. State = [[-0.3867192   0.22742245]]. Action = [[0.        0.        0.        0.3471098]]. Reward = [0.]
Curr episode timestep = 809
Scene graph at timestep 4409 is [True, False, False, False, False, True]
State prediction error at timestep 4409 is 0.012
Current timestep = 4410. State = [[-0.38671926  0.2274225 ]]. Action = [[ 0.         0.         0.        -0.8956872]]. Reward = [0.]
Curr episode timestep = 810
Scene graph at timestep 4410 is [True, False, False, False, False, True]
State prediction error at timestep 4410 is 0.012
Current timestep = 4411. State = [[-0.3867193   0.22742257]]. Action = [[0.         0.         0.         0.45121694]]. Reward = [0.]
Curr episode timestep = 811
Scene graph at timestep 4411 is [True, False, False, False, False, True]
State prediction error at timestep 4411 is 0.012
Current timestep = 4412. State = [[-0.38671935  0.22742262]]. Action = [[0.         0.         0.         0.91184115]]. Reward = [0.]
Curr episode timestep = 812
Scene graph at timestep 4412 is [True, False, False, False, False, True]
State prediction error at timestep 4412 is 0.012
Current timestep = 4413. State = [[-0.38671938  0.22742268]]. Action = [[ 0.          0.          0.         -0.27369094]]. Reward = [0.]
Curr episode timestep = 813
Scene graph at timestep 4413 is [True, False, False, False, False, True]
State prediction error at timestep 4413 is 0.012
Current timestep = 4414. State = [[-0.3867194   0.22742276]]. Action = [[ 0.          0.          0.         -0.36178935]]. Reward = [0.]
Curr episode timestep = 814
Scene graph at timestep 4414 is [True, False, False, False, False, True]
State prediction error at timestep 4414 is 0.012
Current timestep = 4415. State = [[-0.38671947  0.22742282]]. Action = [[ 0.        0.        0.       -0.536415]]. Reward = [0.]
Curr episode timestep = 815
Scene graph at timestep 4415 is [True, False, False, False, False, True]
State prediction error at timestep 4415 is 0.012
Current timestep = 4416. State = [[-0.3867195   0.22742288]]. Action = [[0.         0.         0.         0.73572755]]. Reward = [0.]
Curr episode timestep = 816
Scene graph at timestep 4416 is [True, False, False, False, False, True]
State prediction error at timestep 4416 is 0.012
Current timestep = 4417. State = [[-0.38671952  0.22742294]]. Action = [[ 0.        0.        0.       -0.855019]]. Reward = [0.]
Curr episode timestep = 817
Scene graph at timestep 4417 is [True, False, False, False, False, True]
State prediction error at timestep 4417 is 0.012
Current timestep = 4418. State = [[-0.38671958  0.227423  ]]. Action = [[ 0.          0.          0.         -0.14910543]]. Reward = [0.]
Curr episode timestep = 818
Scene graph at timestep 4418 is [True, False, False, False, False, True]
State prediction error at timestep 4418 is 0.012
Current timestep = 4419. State = [[-0.3867196   0.22742306]]. Action = [[ 0.         0.         0.        -0.5059366]]. Reward = [0.]
Curr episode timestep = 819
Scene graph at timestep 4419 is [True, False, False, False, False, True]
State prediction error at timestep 4419 is 0.012
Current timestep = 4420. State = [[-0.38671964  0.22742312]]. Action = [[ 0.         0.         0.        -0.6058234]]. Reward = [0.]
Curr episode timestep = 820
Scene graph at timestep 4420 is [True, False, False, False, False, True]
State prediction error at timestep 4420 is 0.012
Current timestep = 4421. State = [[-0.3867197   0.22742318]]. Action = [[0.         0.         0.         0.97666264]]. Reward = [0.]
Curr episode timestep = 821
Scene graph at timestep 4421 is [True, False, False, False, False, True]
State prediction error at timestep 4421 is 0.012
Current timestep = 4422. State = [[-0.38671973  0.22742324]]. Action = [[0.         0.         0.         0.49169695]]. Reward = [0.]
Curr episode timestep = 822
Scene graph at timestep 4422 is [True, False, False, False, False, True]
State prediction error at timestep 4422 is 0.012
Current timestep = 4423. State = [[-0.38671976  0.2274233 ]]. Action = [[ 0.          0.          0.         -0.62014365]]. Reward = [0.]
Curr episode timestep = 823
Scene graph at timestep 4423 is [True, False, False, False, False, True]
State prediction error at timestep 4423 is 0.012
Current timestep = 4424. State = [[-0.3867198   0.22742335]]. Action = [[ 0.          0.          0.         -0.27880865]]. Reward = [0.]
Curr episode timestep = 824
Scene graph at timestep 4424 is [True, False, False, False, False, True]
State prediction error at timestep 4424 is 0.012
Current timestep = 4425. State = [[-0.38671985  0.22742341]]. Action = [[ 0.          0.          0.         -0.18690038]]. Reward = [0.]
Curr episode timestep = 825
Scene graph at timestep 4425 is [True, False, False, False, False, True]
State prediction error at timestep 4425 is 0.012
Current timestep = 4426. State = [[-0.38671988  0.22742347]]. Action = [[0.        0.        0.        0.7374344]]. Reward = [0.]
Curr episode timestep = 826
Scene graph at timestep 4426 is [True, False, False, False, False, True]
State prediction error at timestep 4426 is 0.012
Current timestep = 4427. State = [[-0.3867199   0.22742353]]. Action = [[0.        0.        0.        0.8829675]]. Reward = [0.]
Curr episode timestep = 827
Scene graph at timestep 4427 is [True, False, False, False, False, True]
State prediction error at timestep 4427 is 0.012
Current timestep = 4428. State = [[-0.38671994  0.2274236 ]]. Action = [[ 0.          0.          0.         -0.18265265]]. Reward = [0.]
Curr episode timestep = 828
Scene graph at timestep 4428 is [True, False, False, False, False, True]
State prediction error at timestep 4428 is 0.012
Current timestep = 4429. State = [[-0.38672     0.22742365]]. Action = [[ 0.          0.          0.         -0.30821776]]. Reward = [0.]
Curr episode timestep = 829
Scene graph at timestep 4429 is [True, False, False, False, False, True]
State prediction error at timestep 4429 is 0.012
Current timestep = 4430. State = [[-0.38672003  0.22742371]]. Action = [[ 0.         0.         0.        -0.7307177]]. Reward = [0.]
Curr episode timestep = 830
Scene graph at timestep 4430 is [True, False, False, False, False, True]
State prediction error at timestep 4430 is 0.012
Current timestep = 4431. State = [[-0.38672006  0.22742377]]. Action = [[ 0.          0.          0.         -0.91473407]]. Reward = [0.]
Curr episode timestep = 831
Scene graph at timestep 4431 is [True, False, False, False, False, True]
State prediction error at timestep 4431 is 0.012
Current timestep = 4432. State = [[-0.3867201   0.22742383]]. Action = [[ 0.          0.          0.         -0.44110787]]. Reward = [0.]
Curr episode timestep = 832
Scene graph at timestep 4432 is [True, False, False, False, False, True]
State prediction error at timestep 4432 is 0.012
Current timestep = 4433. State = [[-0.38672015  0.22742389]]. Action = [[ 0.         0.         0.        -0.9436776]]. Reward = [0.]
Curr episode timestep = 833
Scene graph at timestep 4433 is [True, False, False, False, False, True]
State prediction error at timestep 4433 is 0.012
Current timestep = 4434. State = [[-0.38672018  0.22742395]]. Action = [[0.        0.        0.        0.5547898]]. Reward = [0.]
Curr episode timestep = 834
Scene graph at timestep 4434 is [True, False, False, False, False, True]
State prediction error at timestep 4434 is 0.012
Current timestep = 4435. State = [[-0.3867202  0.227424 ]]. Action = [[ 0.         0.         0.        -0.1394136]]. Reward = [0.]
Curr episode timestep = 835
Scene graph at timestep 4435 is [True, False, False, False, False, True]
State prediction error at timestep 4435 is 0.012
Current timestep = 4436. State = [[-0.38672024  0.22742406]]. Action = [[ 0.         0.         0.        -0.9120833]]. Reward = [0.]
Curr episode timestep = 836
Scene graph at timestep 4436 is [True, False, False, False, False, True]
State prediction error at timestep 4436 is 0.012
Current timestep = 4437. State = [[-0.38672027  0.22742411]]. Action = [[ 0.         0.         0.        -0.6214035]]. Reward = [0.]
Curr episode timestep = 837
Scene graph at timestep 4437 is [True, False, False, False, False, True]
State prediction error at timestep 4437 is 0.012
Current timestep = 4438. State = [[-0.38672033  0.22742417]]. Action = [[ 0.         0.         0.        -0.5437629]]. Reward = [0.]
Curr episode timestep = 838
Scene graph at timestep 4438 is [True, False, False, False, False, True]
State prediction error at timestep 4438 is 0.012
Current timestep = 4439. State = [[-0.38672036  0.22742423]]. Action = [[ 0.          0.          0.         -0.09071767]]. Reward = [0.]
Curr episode timestep = 839
Scene graph at timestep 4439 is [True, False, False, False, False, True]
State prediction error at timestep 4439 is 0.012
Current timestep = 4440. State = [[-0.3867204  0.2274243]]. Action = [[ 0.          0.          0.         -0.49475324]]. Reward = [0.]
Curr episode timestep = 840
Scene graph at timestep 4440 is [True, False, False, False, False, True]
State prediction error at timestep 4440 is 0.012
Current timestep = 4441. State = [[-0.38672042  0.22742435]]. Action = [[0.         0.         0.         0.40811598]]. Reward = [0.]
Curr episode timestep = 841
Scene graph at timestep 4441 is [True, False, False, False, False, True]
State prediction error at timestep 4441 is 0.012
Current timestep = 4442. State = [[-0.38672045  0.22742441]]. Action = [[0.        0.        0.        0.5951741]]. Reward = [0.]
Curr episode timestep = 842
Scene graph at timestep 4442 is [True, False, False, False, False, True]
State prediction error at timestep 4442 is 0.012
Current timestep = 4443. State = [[-0.3867205   0.22742446]]. Action = [[ 0.         0.         0.        -0.6819753]]. Reward = [0.]
Curr episode timestep = 843
Scene graph at timestep 4443 is [True, False, False, False, False, True]
State prediction error at timestep 4443 is 0.012
Current timestep = 4444. State = [[-0.38672054  0.22742452]]. Action = [[ 0.          0.          0.         -0.23890728]]. Reward = [0.]
Curr episode timestep = 844
Scene graph at timestep 4444 is [True, False, False, False, False, True]
State prediction error at timestep 4444 is 0.012
Current timestep = 4445. State = [[-0.38672057  0.22742458]]. Action = [[0.         0.         0.         0.25522614]]. Reward = [0.]
Curr episode timestep = 845
Scene graph at timestep 4445 is [True, False, False, False, False, True]
State prediction error at timestep 4445 is 0.012
Current timestep = 4446. State = [[-0.3867206   0.22742464]]. Action = [[0.         0.         0.         0.62710786]]. Reward = [0.]
Curr episode timestep = 846
Scene graph at timestep 4446 is [True, False, False, False, False, True]
State prediction error at timestep 4446 is 0.012
Current timestep = 4447. State = [[-0.38672063  0.2274247 ]]. Action = [[0.         0.         0.         0.05472624]]. Reward = [0.]
Curr episode timestep = 847
Scene graph at timestep 4447 is [True, False, False, False, False, True]
State prediction error at timestep 4447 is 0.012
Current timestep = 4448. State = [[-0.38672066  0.22742474]]. Action = [[ 0.          0.          0.         -0.36361575]]. Reward = [0.]
Curr episode timestep = 848
Scene graph at timestep 4448 is [True, False, False, False, False, True]
State prediction error at timestep 4448 is 0.012
Current timestep = 4449. State = [[-0.3867207  0.2274248]]. Action = [[0.         0.         0.         0.10713065]]. Reward = [0.]
Curr episode timestep = 849
Scene graph at timestep 4449 is [True, False, False, False, False, True]
State prediction error at timestep 4449 is 0.012
Current timestep = 4450. State = [[-0.38672072  0.22742486]]. Action = [[ 0.          0.          0.         -0.08466232]]. Reward = [0.]
Curr episode timestep = 850
Scene graph at timestep 4450 is [True, False, False, False, False, True]
State prediction error at timestep 4450 is 0.012
Current timestep = 4451. State = [[-0.38672078  0.22742492]]. Action = [[0.         0.         0.         0.48106766]]. Reward = [0.]
Curr episode timestep = 851
Scene graph at timestep 4451 is [True, False, False, False, False, True]
State prediction error at timestep 4451 is 0.012
Current timestep = 4452. State = [[-0.3867208   0.22742498]]. Action = [[0.         0.         0.         0.34041584]]. Reward = [0.]
Curr episode timestep = 852
Scene graph at timestep 4452 is [True, False, False, False, False, True]
State prediction error at timestep 4452 is 0.012
Current timestep = 4453. State = [[-0.38672084  0.22742502]]. Action = [[0.         0.         0.         0.20827675]]. Reward = [0.]
Curr episode timestep = 853
Scene graph at timestep 4453 is [True, False, False, False, False, True]
State prediction error at timestep 4453 is 0.012
Current timestep = 4454. State = [[-0.38672087  0.22742508]]. Action = [[0.        0.        0.        0.5436039]]. Reward = [0.]
Curr episode timestep = 854
Scene graph at timestep 4454 is [True, False, False, False, False, True]
State prediction error at timestep 4454 is 0.012
Current timestep = 4455. State = [[-0.3867209   0.22742514]]. Action = [[0.        0.        0.        0.5260787]]. Reward = [0.]
Curr episode timestep = 855
Scene graph at timestep 4455 is [True, False, False, False, False, True]
State prediction error at timestep 4455 is 0.012
Current timestep = 4456. State = [[-0.38672093  0.22742519]]. Action = [[0.         0.         0.         0.89128935]]. Reward = [0.]
Curr episode timestep = 856
Scene graph at timestep 4456 is [True, False, False, False, False, True]
State prediction error at timestep 4456 is 0.012
Current timestep = 4457. State = [[-0.38672096  0.22742525]]. Action = [[ 0.         0.         0.        -0.3346436]]. Reward = [0.]
Curr episode timestep = 857
Scene graph at timestep 4457 is [True, False, False, False, False, True]
State prediction error at timestep 4457 is 0.012
Current timestep = 4458. State = [[-0.386721   0.2274253]]. Action = [[0.         0.         0.         0.91521776]]. Reward = [0.]
Curr episode timestep = 858
Scene graph at timestep 4458 is [True, False, False, False, False, True]
State prediction error at timestep 4458 is 0.012
Current timestep = 4459. State = [[-0.38672101  0.22742537]]. Action = [[ 0.         0.         0.        -0.6117785]]. Reward = [0.]
Curr episode timestep = 859
Scene graph at timestep 4459 is [True, False, False, False, False, True]
State prediction error at timestep 4459 is 0.012
Current timestep = 4460. State = [[-0.38672104  0.22742541]]. Action = [[ 0.         0.         0.        -0.5523713]]. Reward = [0.]
Curr episode timestep = 860
Scene graph at timestep 4460 is [True, False, False, False, False, True]
State prediction error at timestep 4460 is 0.012
Current timestep = 4461. State = [[-0.38672107  0.22742547]]. Action = [[0.         0.         0.         0.70018244]]. Reward = [0.]
Curr episode timestep = 861
Scene graph at timestep 4461 is [True, False, False, False, False, True]
State prediction error at timestep 4461 is 0.012
Current timestep = 4462. State = [[-0.3867211   0.22742553]]. Action = [[ 0.          0.          0.         -0.25825572]]. Reward = [0.]
Curr episode timestep = 862
Scene graph at timestep 4462 is [True, False, False, False, False, True]
State prediction error at timestep 4462 is 0.012
Current timestep = 4463. State = [[-0.38672113  0.22742558]]. Action = [[ 0.          0.          0.         -0.31617236]]. Reward = [0.]
Curr episode timestep = 863
Scene graph at timestep 4463 is [True, False, False, False, False, True]
State prediction error at timestep 4463 is 0.012
Current timestep = 4464. State = [[-0.38672116  0.22742563]]. Action = [[0.        0.        0.        0.8658644]]. Reward = [0.]
Curr episode timestep = 864
Scene graph at timestep 4464 is [True, False, False, False, False, True]
State prediction error at timestep 4464 is 0.012
Current timestep = 4465. State = [[-0.3867212  0.2274257]]. Action = [[ 0.          0.          0.         -0.44775045]]. Reward = [0.]
Curr episode timestep = 865
Scene graph at timestep 4465 is [True, False, False, False, False, True]
State prediction error at timestep 4465 is 0.012
Current timestep = 4466. State = [[-0.38672122  0.22742574]]. Action = [[ 0.          0.          0.         -0.00883609]]. Reward = [0.]
Curr episode timestep = 866
Scene graph at timestep 4466 is [True, False, False, False, False, True]
State prediction error at timestep 4466 is 0.012
Current timestep = 4467. State = [[-0.38672125  0.2274258 ]]. Action = [[ 0.          0.          0.         -0.37736362]]. Reward = [0.]
Curr episode timestep = 867
Scene graph at timestep 4467 is [True, False, False, False, False, True]
State prediction error at timestep 4467 is 0.012
Current timestep = 4468. State = [[-0.3867213   0.22742586]]. Action = [[0.       0.       0.       0.781911]]. Reward = [0.]
Curr episode timestep = 868
Scene graph at timestep 4468 is [True, False, False, False, False, True]
State prediction error at timestep 4468 is 0.012
Current timestep = 4469. State = [[-0.38672134  0.2274259 ]]. Action = [[ 0.          0.          0.         -0.63379955]]. Reward = [0.]
Curr episode timestep = 869
Scene graph at timestep 4469 is [True, False, False, False, False, True]
State prediction error at timestep 4469 is 0.012
Current timestep = 4470. State = [[-0.38672137  0.22742596]]. Action = [[0.         0.         0.         0.82152355]]. Reward = [0.]
Curr episode timestep = 870
Scene graph at timestep 4470 is [True, False, False, False, False, True]
State prediction error at timestep 4470 is 0.012
Current timestep = 4471. State = [[-0.3867214   0.22742602]]. Action = [[0.       0.       0.       0.743806]]. Reward = [0.]
Curr episode timestep = 871
Scene graph at timestep 4471 is [True, False, False, False, False, True]
State prediction error at timestep 4471 is 0.012
Current timestep = 4472. State = [[-0.38672143  0.22742607]]. Action = [[ 0.          0.          0.         -0.16020048]]. Reward = [0.]
Curr episode timestep = 872
Scene graph at timestep 4472 is [True, False, False, False, False, True]
State prediction error at timestep 4472 is 0.012
Current timestep = 4473. State = [[-0.38672146  0.22742613]]. Action = [[0.        0.        0.        0.4027574]]. Reward = [0.]
Curr episode timestep = 873
Scene graph at timestep 4473 is [True, False, False, False, False, True]
State prediction error at timestep 4473 is 0.012
Current timestep = 4474. State = [[-0.38672146  0.22742617]]. Action = [[0.         0.         0.         0.53447413]]. Reward = [0.]
Curr episode timestep = 874
Scene graph at timestep 4474 is [True, False, False, False, False, True]
State prediction error at timestep 4474 is 0.012
Current timestep = 4475. State = [[-0.3867215   0.22742623]]. Action = [[0.         0.         0.         0.99157834]]. Reward = [0.]
Curr episode timestep = 875
Scene graph at timestep 4475 is [True, False, False, False, False, True]
State prediction error at timestep 4475 is 0.012
Current timestep = 4476. State = [[-0.38672152  0.22742629]]. Action = [[ 0.        0.        0.       -0.547939]]. Reward = [0.]
Curr episode timestep = 876
Scene graph at timestep 4476 is [True, False, False, False, False, True]
State prediction error at timestep 4476 is 0.012
Current timestep = 4477. State = [[-0.38672155  0.22742634]]. Action = [[0.         0.         0.         0.91457605]]. Reward = [0.]
Curr episode timestep = 877
Scene graph at timestep 4477 is [True, False, False, False, False, True]
State prediction error at timestep 4477 is 0.012
Current timestep = 4478. State = [[-0.38672158  0.2274264 ]]. Action = [[ 0.         0.         0.        -0.6858098]]. Reward = [0.]
Curr episode timestep = 878
Scene graph at timestep 4478 is [True, False, False, False, False, True]
State prediction error at timestep 4478 is 0.012
Current timestep = 4479. State = [[-0.3867216   0.22742644]]. Action = [[ 0.         0.         0.        -0.4406222]]. Reward = [0.]
Curr episode timestep = 879
Scene graph at timestep 4479 is [True, False, False, False, False, True]
State prediction error at timestep 4479 is 0.012
Current timestep = 4480. State = [[-0.38672164  0.2274265 ]]. Action = [[0.         0.         0.         0.24146736]]. Reward = [0.]
Curr episode timestep = 880
Scene graph at timestep 4480 is [True, False, False, False, False, True]
State prediction error at timestep 4480 is 0.012
Current timestep = 4481. State = [[-0.38672167  0.22742654]]. Action = [[0.         0.         0.         0.29230392]]. Reward = [0.]
Curr episode timestep = 881
Scene graph at timestep 4481 is [True, False, False, False, False, True]
State prediction error at timestep 4481 is 0.012
Current timestep = 4482. State = [[-0.3867217  0.2274266]]. Action = [[ 0.          0.          0.         -0.17927378]]. Reward = [0.]
Curr episode timestep = 882
Scene graph at timestep 4482 is [True, False, False, False, False, True]
State prediction error at timestep 4482 is 0.012
Current timestep = 4483. State = [[-0.38672173  0.22742665]]. Action = [[ 0.          0.          0.         -0.16345578]]. Reward = [0.]
Curr episode timestep = 883
Scene graph at timestep 4483 is [True, False, False, False, False, True]
State prediction error at timestep 4483 is 0.012
Current timestep = 4484. State = [[-0.38672176  0.22742671]]. Action = [[0.         0.         0.         0.48205376]]. Reward = [0.]
Curr episode timestep = 884
Scene graph at timestep 4484 is [True, False, False, False, False, True]
State prediction error at timestep 4484 is 0.012
Current timestep = 4485. State = [[-0.3867218   0.22742675]]. Action = [[0.         0.         0.         0.35579228]]. Reward = [0.]
Curr episode timestep = 885
Scene graph at timestep 4485 is [True, False, False, False, False, True]
State prediction error at timestep 4485 is 0.012
Current timestep = 4486. State = [[-0.38672182  0.22742681]]. Action = [[ 0.         0.         0.        -0.3501585]]. Reward = [0.]
Curr episode timestep = 886
Scene graph at timestep 4486 is [True, False, False, False, False, True]
State prediction error at timestep 4486 is 0.012
Current timestep = 4487. State = [[-0.38672185  0.22742687]]. Action = [[0.         0.         0.         0.08915627]]. Reward = [0.]
Curr episode timestep = 887
Scene graph at timestep 4487 is [True, False, False, False, False, True]
State prediction error at timestep 4487 is 0.012
Current timestep = 4488. State = [[-0.38672188  0.22742692]]. Action = [[ 0.          0.          0.         -0.74324393]]. Reward = [0.]
Curr episode timestep = 888
Scene graph at timestep 4488 is [True, False, False, False, False, True]
State prediction error at timestep 4488 is 0.012
Current timestep = 4489. State = [[-0.3867219   0.22742698]]. Action = [[0.         0.         0.         0.09593117]]. Reward = [0.]
Curr episode timestep = 889
Scene graph at timestep 4489 is [True, False, False, False, False, True]
State prediction error at timestep 4489 is 0.012
Current timestep = 4490. State = [[-0.38672194  0.22742702]]. Action = [[0.         0.         0.         0.62560964]]. Reward = [0.]
Curr episode timestep = 890
Scene graph at timestep 4490 is [True, False, False, False, False, True]
State prediction error at timestep 4490 is 0.012
Current timestep = 4491. State = [[-0.38672197  0.22742707]]. Action = [[0.         0.         0.         0.38946033]]. Reward = [0.]
Curr episode timestep = 891
Scene graph at timestep 4491 is [True, False, False, False, False, True]
State prediction error at timestep 4491 is 0.012
Current timestep = 4492. State = [[-0.38672197  0.22742712]]. Action = [[0.        0.        0.        0.9509523]]. Reward = [0.]
Curr episode timestep = 892
Scene graph at timestep 4492 is [True, False, False, False, False, True]
State prediction error at timestep 4492 is 0.012
Current timestep = 4493. State = [[-0.386722    0.22742717]]. Action = [[ 0.          0.          0.         -0.87242657]]. Reward = [0.]
Curr episode timestep = 893
Scene graph at timestep 4493 is [True, False, False, False, False, True]
State prediction error at timestep 4493 is 0.012
Current timestep = 4494. State = [[-0.38672203  0.22742723]]. Action = [[ 0.          0.          0.         -0.18150282]]. Reward = [0.]
Curr episode timestep = 894
Scene graph at timestep 4494 is [True, False, False, False, False, True]
State prediction error at timestep 4494 is 0.012
Current timestep = 4495. State = [[-0.38672206  0.22742727]]. Action = [[0.         0.         0.         0.45707905]]. Reward = [0.]
Curr episode timestep = 895
Scene graph at timestep 4495 is [True, False, False, False, False, True]
State prediction error at timestep 4495 is 0.012
Current timestep = 4496. State = [[-0.3867221   0.22742733]]. Action = [[ 0.          0.          0.         -0.82471836]]. Reward = [0.]
Curr episode timestep = 896
Scene graph at timestep 4496 is [True, False, False, False, False, True]
State prediction error at timestep 4496 is 0.012
Current timestep = 4497. State = [[-0.38672212  0.22742738]]. Action = [[ 0.         0.         0.        -0.6246657]]. Reward = [0.]
Curr episode timestep = 897
Scene graph at timestep 4497 is [True, False, False, False, False, True]
State prediction error at timestep 4497 is 0.012
Current timestep = 4498. State = [[-0.38672215  0.22742744]]. Action = [[0.         0.         0.         0.62717795]]. Reward = [0.]
Curr episode timestep = 898
Scene graph at timestep 4498 is [True, False, False, False, False, True]
State prediction error at timestep 4498 is 0.012
Current timestep = 4499. State = [[-0.01081682  0.1375236 ]]. Action = [[ 0.          0.          0.         -0.47845364]]. Reward = [0.]
Curr episode timestep = 899
Scene graph at timestep 4499 is [False, True, False, False, False, True]
State prediction error at timestep 4499 is 0.012
Current timestep = 4500. State = [[-0.01115639  0.14353316]]. Action = [[-0.09036543  0.09957755  0.          0.19409132]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 4500 is [False, True, False, False, False, True]
State prediction error at timestep 4500 is 0.012
Current timestep = 4501. State = [[-0.01473145  0.15044194]]. Action = [[-0.02970158  0.07187783  0.         -0.15057945]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 4501 is [False, True, False, False, False, True]
State prediction error at timestep 4501 is 0.012
Current timestep = 4502. State = [[-0.0201051   0.15499777]]. Action = [[-0.09382442  0.02092595  0.         -0.3765416 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 4502 is [False, True, False, False, False, True]
State prediction error at timestep 4502 is 0.012
Current timestep = 4503. State = [[-0.02155905  0.16026305]]. Action = [[0.02281592 0.05350082 0.         0.22262025]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 4503 is [False, True, False, False, False, True]
State prediction error at timestep 4503 is 0.012
Current timestep = 4504. State = [[-0.02381994  0.1631704 ]]. Action = [[-0.05961201 -0.01664377  0.         -0.5717944 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4504 is [False, True, False, False, False, True]
State prediction error at timestep 4504 is 0.012
Current timestep = 4505. State = [[-0.02423052  0.16783145]]. Action = [[0.01968154 0.05755218 0.         0.63445973]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 4505 is [False, True, False, False, False, True]
State prediction error at timestep 4505 is 0.012
Current timestep = 4506. State = [[-0.02805325  0.17032419]]. Action = [[-0.09576563 -0.02766696  0.         -0.9462577 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 4506 is [False, True, False, False, False, True]
State prediction error at timestep 4506 is 0.012
Current timestep = 4507. State = [[-0.02822167  0.17181233]]. Action = [[ 0.05177579  0.00370876  0.         -0.50230885]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 4507 is [False, True, False, False, False, True]
State prediction error at timestep 4507 is 0.012
Current timestep = 4508. State = [[-0.0224541  0.172753 ]]. Action = [[ 0.09199803 -0.01069497  0.          0.83902156]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 4508 is [False, True, False, False, False, True]
State prediction error at timestep 4508 is 0.012
Current timestep = 4509. State = [[-0.02313857  0.17617355]]. Action = [[-0.08154742  0.05436454  0.          0.88481903]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 4509 is [False, True, False, False, False, True]
State prediction error at timestep 4509 is 0.012
Current timestep = 4510. State = [[-0.02413491  0.17931828]]. Action = [[ 0.0262581   0.00908605  0.         -0.48926926]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 4510 is [False, True, False, False, False, True]
State prediction error at timestep 4510 is 0.012
Current timestep = 4511. State = [[-0.02696118  0.18171428]]. Action = [[-0.06713952  0.02094116  0.          0.9230648 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 4511 is [False, True, False, False, False, True]
State prediction error at timestep 4511 is 0.012
Current timestep = 4512. State = [[-0.02575718  0.18464212]]. Action = [[0.07430769 0.02720297 0.         0.69099057]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 4512 is [False, True, False, False, False, True]
State prediction error at timestep 4512 is 0.012
Current timestep = 4513. State = [[-0.01999388  0.1810778 ]]. Action = [[ 0.08501933 -0.09770261  0.          0.76980627]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 4513 is [False, True, False, False, False, True]
State prediction error at timestep 4513 is 0.012
Current timestep = 4514. State = [[-0.01526639  0.17962001]]. Action = [[ 0.04635208  0.03178906  0.         -0.79387337]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 4514 is [False, True, False, False, False, True]
State prediction error at timestep 4514 is 0.012
Current timestep = 4515. State = [[-0.00994486  0.17602347]]. Action = [[ 0.0758679  -0.077962    0.         -0.60927397]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 4515 is [False, True, False, False, False, True]
State prediction error at timestep 4515 is 0.012
Current timestep = 4516. State = [[-0.01002103  0.17576036]]. Action = [[-0.0648382   0.05464857  0.          0.29048133]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 4516 is [False, True, False, False, False, True]
State prediction error at timestep 4516 is 0.012
Current timestep = 4517. State = [[-0.00918055  0.17218131]]. Action = [[ 0.03818763 -0.09086817  0.          0.9984238 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 4517 is [False, True, False, False, False, True]
State prediction error at timestep 4517 is 0.012
Current timestep = 4518. State = [[-0.00802134  0.17118339]]. Action = [[-0.00974729  0.04779587  0.         -0.46262383]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 4518 is [False, True, False, False, False, True]
State prediction error at timestep 4518 is 0.012
Current timestep = 4519. State = [[-0.00519917  0.17668812]]. Action = [[ 0.05545343  0.0967155   0.         -0.4526453 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 4519 is [False, True, False, False, False, True]
State prediction error at timestep 4519 is 0.012
Current timestep = 4520. State = [[-0.00451401  0.17781258]]. Action = [[-0.02073296 -0.03192825  0.          0.72312415]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 4520 is [False, True, False, False, False, True]
State prediction error at timestep 4520 is 0.012
Current timestep = 4521. State = [[-0.00758028  0.17872767]]. Action = [[-0.06536374  0.03154074  0.          0.13030612]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 4521 is [False, True, False, False, False, True]
State prediction error at timestep 4521 is 0.012
Current timestep = 4522. State = [[-0.00822999  0.17989574]]. Action = [[ 0.01183239 -0.00301208  0.         -0.53002626]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 4522 is [False, True, False, False, False, True]
State prediction error at timestep 4522 is 0.012
Current timestep = 4523. State = [[-0.00748831  0.17840602]]. Action = [[ 0.00087693 -0.03743643  0.          0.64581966]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 4523 is [False, True, False, False, False, True]
State prediction error at timestep 4523 is 0.012
Current timestep = 4524. State = [[-0.00302251  0.18015762]]. Action = [[0.08796207 0.05365669 0.         0.20935166]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 4524 is [False, True, False, False, False, True]
State prediction error at timestep 4524 is 0.012
Current timestep = 4525. State = [[-0.00331911  0.18301533]]. Action = [[-0.0656613   0.02224734  0.         -0.9923777 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 4525 is [False, True, False, False, False, True]
State prediction error at timestep 4525 is 0.012
Current timestep = 4526. State = [[-0.00924966  0.18179591]]. Action = [[-0.09404421 -0.05121996  0.         -0.26433188]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 4526 is [False, True, False, False, False, True]
State prediction error at timestep 4526 is 0.012
Current timestep = 4527. State = [[-0.00899071  0.180993  ]]. Action = [[0.06548726 0.00354852 0.         0.79441786]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 4527 is [False, True, False, False, False, True]
State prediction error at timestep 4527 is 0.012
Current timestep = 4528. State = [[-0.00296463  0.17975163]]. Action = [[ 0.08834308 -0.02640671  0.         -0.9497853 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 4528 is [False, True, False, False, False, True]
State prediction error at timestep 4528 is 0.012
Current timestep = 4529. State = [[0.00123184 0.18124235]]. Action = [[0.03336731 0.05148653 0.         0.46327484]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 4529 is [False, True, False, False, False, True]
State prediction error at timestep 4529 is 0.012
Current timestep = 4530. State = [[-0.00185384  0.18670717]]. Action = [[-0.09596147  0.07945599  0.         -0.45845735]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 4530 is [False, True, False, False, False, True]
State prediction error at timestep 4530 is 0.012
Current timestep = 4531. State = [[-0.00234924  0.18636812]]. Action = [[ 0.04245352 -0.06595088  0.         -0.6364673 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 4531 is [False, True, False, False, False, True]
State prediction error at timestep 4531 is 0.012
Current timestep = 4532. State = [[-0.00393421  0.18789123]]. Action = [[-0.05954095  0.0586498   0.          0.47729743]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 4532 is [False, True, False, False, False, True]
State prediction error at timestep 4532 is 0.012
Current timestep = 4533. State = [[-0.00560856  0.18581189]]. Action = [[-0.00928964 -0.08712456  0.          0.14888418]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 4533 is [False, True, False, False, False, True]
State prediction error at timestep 4533 is 0.012
Current timestep = 4534. State = [[-0.00831908  0.18137562]]. Action = [[-0.06193104 -0.04742642  0.         -0.35642928]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 4534 is [False, True, False, False, False, True]
State prediction error at timestep 4534 is 0.012
Current timestep = 4535. State = [[-0.00836208  0.18171662]]. Action = [[ 0.02432762  0.03429557  0.         -0.96452415]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 4535 is [False, True, False, False, False, True]
State prediction error at timestep 4535 is 0.012
Current timestep = 4536. State = [[-0.01126969  0.18134576]]. Action = [[-0.08045469 -0.02932677  0.         -0.35748065]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 4536 is [False, True, False, False, False, True]
State prediction error at timestep 4536 is 0.012
Current timestep = 4537. State = [[-0.01461954  0.17665   ]]. Action = [[-0.03243032 -0.08174437  0.          0.37554288]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 4537 is [False, True, False, False, False, True]
State prediction error at timestep 4537 is 0.012
Current timestep = 4538. State = [[-0.01113931  0.17241304]]. Action = [[ 0.0968936  -0.02774614  0.         -0.94408566]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 4538 is [False, True, False, False, False, True]
State prediction error at timestep 4538 is 0.012
Current timestep = 4539. State = [[-0.01190039  0.16710116]]. Action = [[-0.08565323 -0.07037488  0.         -0.4892465 ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 4539 is [False, True, False, False, False, True]
State prediction error at timestep 4539 is 0.012
Current timestep = 4540. State = [[-0.01045791  0.16572511]]. Action = [[0.09028032 0.03627048 0.         0.39052558]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 4540 is [False, True, False, False, False, True]
State prediction error at timestep 4540 is 0.012
Current timestep = 4541. State = [[-0.00573816  0.16050604]]. Action = [[ 0.05686367 -0.09542384  0.          0.9071739 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 4541 is [False, True, False, False, False, True]
State prediction error at timestep 4541 is 0.012
Current timestep = 4542. State = [[-0.00237718  0.15106368]]. Action = [[ 0.03400446 -0.09731487  0.         -0.9853682 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 4542 is [False, True, False, False, False, True]
State prediction error at timestep 4542 is 0.012
Current timestep = 4543. State = [[-0.0041655   0.14346828]]. Action = [[-0.07034484 -0.04940809  0.          0.42906094]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 4543 is [False, True, False, False, False, True]
State prediction error at timestep 4543 is 0.012
Current timestep = 4544. State = [[-0.00993581  0.14227314]]. Action = [[-0.09587533  0.04655736  0.         -0.07347417]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 4544 is [False, True, False, False, False, True]
State prediction error at timestep 4544 is 0.012
Current timestep = 4545. State = [[-0.00930301  0.14684339]]. Action = [[0.08269703 0.0936885  0.         0.13980293]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 4545 is [False, True, False, False, False, True]
State prediction error at timestep 4545 is 0.012
Current timestep = 4546. State = [[-0.00501184  0.14584371]]. Action = [[ 0.04811873 -0.05652621  0.         -0.95504934]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 4546 is [False, True, False, False, False, True]
State prediction error at timestep 4546 is 0.012
Current timestep = 4547. State = [[-0.00050643  0.1478235 ]]. Action = [[ 0.06521621  0.0888428   0.         -0.98024166]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 4547 is [False, True, False, False, False, True]
State prediction error at timestep 4547 is 0.012
Current timestep = 4548. State = [[0.00442035 0.15181787]]. Action = [[ 0.07191371  0.0401243   0.         -0.89836985]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 4548 is [False, True, False, False, False, True]
State prediction error at timestep 4548 is 0.012
Current timestep = 4549. State = [[0.00236101 0.1500604 ]]. Action = [[-0.0984717 -0.0584165  0.        -0.8417218]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 4549 is [False, True, False, False, False, True]
State prediction error at timestep 4549 is 0.012
Current timestep = 4550. State = [[-0.00425581  0.14725563]]. Action = [[-0.08946182 -0.02642644  0.          0.39936948]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 4550 is [False, True, False, False, False, True]
State prediction error at timestep 4550 is 0.012
Current timestep = 4551. State = [[-0.00439677  0.14591841]]. Action = [[ 0.05796411 -0.01293691  0.          0.8210058 ]]. Reward = [0.]
Curr episode timestep = 51
Scene graph at timestep 4551 is [False, True, False, False, False, True]
State prediction error at timestep 4551 is 0.012
Current timestep = 4552. State = [[-0.00539398  0.14618713]]. Action = [[-0.05387894  0.01347204  0.          0.88193583]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 4552 is [False, True, False, False, False, True]
State prediction error at timestep 4552 is 0.012
Current timestep = 4553. State = [[-0.0026373   0.14743443]]. Action = [[0.09373515 0.01558323 0.         0.5136726 ]]. Reward = [0.]
Curr episode timestep = 53
Scene graph at timestep 4553 is [False, True, False, False, False, True]
State prediction error at timestep 4553 is 0.012
Current timestep = 4554. State = [[-0.00052931  0.15282789]]. Action = [[-0.00562739  0.09730097  0.          0.26572   ]]. Reward = [0.]
Curr episode timestep = 54
Scene graph at timestep 4554 is [False, True, False, False, False, True]
State prediction error at timestep 4554 is 0.012
Current timestep = 4555. State = [[-0.00463442  0.15693344]]. Action = [[-0.08666099  0.01267286  0.          0.6992402 ]]. Reward = [0.]
Curr episode timestep = 55
Scene graph at timestep 4555 is [False, True, False, False, False, True]
State prediction error at timestep 4555 is 0.012
Current timestep = 4556. State = [[-0.0046888   0.15674956]]. Action = [[ 0.04841679 -0.03223976  0.          0.90128684]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 4556 is [False, True, False, False, False, True]
State prediction error at timestep 4556 is 0.012
Current timestep = 4557. State = [[-0.00599993  0.15731975]]. Action = [[-0.06018682  0.01548819  0.          0.6064677 ]]. Reward = [0.]
Curr episode timestep = 57
Scene graph at timestep 4557 is [False, True, False, False, False, True]
State prediction error at timestep 4557 is 0.012
Current timestep = 4558. State = [[-0.00597768  0.15449208]]. Action = [[ 0.02484785 -0.07855433  0.          0.0075978 ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 4558 is [False, True, False, False, False, True]
State prediction error at timestep 4558 is 0.012
Current timestep = 4559. State = [[-0.00153699  0.15095013]]. Action = [[ 0.07347212 -0.02743683  0.         -0.10042369]]. Reward = [0.]
Curr episode timestep = 59
Scene graph at timestep 4559 is [False, True, False, False, False, True]
State prediction error at timestep 4559 is 0.012
Current timestep = 4560. State = [[-0.00131585  0.15145187]]. Action = [[-0.04520011  0.03388362  0.         -0.49164295]]. Reward = [0.]
Curr episode timestep = 60
Scene graph at timestep 4560 is [False, True, False, False, False, True]
State prediction error at timestep 4560 is 0.012
Current timestep = 4561. State = [[1.1610404e-04 1.5283041e-01]]. Action = [[ 0.05232015  0.01108699  0.         -0.5761923 ]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 4561 is [False, True, False, False, False, True]
State prediction error at timestep 4561 is 0.012
Current timestep = 4562. State = [[-0.00159949  0.15695728]]. Action = [[-0.06605086  0.07562942  0.          0.3804407 ]]. Reward = [0.]
Curr episode timestep = 62
Scene graph at timestep 4562 is [False, True, False, False, False, True]
State prediction error at timestep 4562 is 0.012
Current timestep = 4563. State = [[-0.00545385  0.15935332]]. Action = [[-0.04280874 -0.00655112  0.          0.19600022]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 4563 is [False, True, False, False, False, True]
State prediction error at timestep 4563 is 0.012
Current timestep = 4564. State = [[-0.00319592  0.16176842]]. Action = [[0.08400967 0.03866314 0.         0.84082294]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 4564 is [False, True, False, False, False, True]
State prediction error at timestep 4564 is 0.012
Current timestep = 4565. State = [[-0.00131005  0.16472259]]. Action = [[ 0.00131178  0.0270199   0.         -0.18490529]]. Reward = [0.]
Curr episode timestep = 65
Scene graph at timestep 4565 is [False, True, False, False, False, True]
State prediction error at timestep 4565 is 0.012
Current timestep = 4566. State = [[-0.00129306  0.16898924]]. Action = [[0.00273933 0.05544656 0.         0.32549715]]. Reward = [0.]
Curr episode timestep = 66
Scene graph at timestep 4566 is [False, True, False, False, False, True]
State prediction error at timestep 4566 is 0.012
Current timestep = 4567. State = [[-0.00596127  0.17475152]]. Action = [[-0.095991    0.06151225  0.         -0.19524896]]. Reward = [0.]
Curr episode timestep = 67
Scene graph at timestep 4567 is [False, True, False, False, False, True]
State prediction error at timestep 4567 is 0.012
Current timestep = 4568. State = [[-0.0103392   0.17772889]]. Action = [[-0.03417121 -0.00842722  0.          0.10279059]]. Reward = [0.]
Curr episode timestep = 68
Scene graph at timestep 4568 is [False, True, False, False, False, True]
State prediction error at timestep 4568 is 0.012
Current timestep = 4569. State = [[-0.00781813  0.17632292]]. Action = [[ 0.08443519 -0.05182643  0.         -0.77540934]]. Reward = [0.]
Curr episode timestep = 69
Scene graph at timestep 4569 is [False, True, False, False, False, True]
State prediction error at timestep 4569 is 0.012
Current timestep = 4570. State = [[-0.00400951  0.17731147]]. Action = [[ 0.03966125  0.03669941  0.         -0.02487653]]. Reward = [0.]
Curr episode timestep = 70
Scene graph at timestep 4570 is [False, True, False, False, False, True]
State prediction error at timestep 4570 is 0.012
Current timestep = 4571. State = [[-0.00196343  0.17736018]]. Action = [[ 0.02161898 -0.02837248  0.         -0.31425452]]. Reward = [0.]
Curr episode timestep = 71
Scene graph at timestep 4571 is [False, True, False, False, False, True]
State prediction error at timestep 4571 is 0.012
Current timestep = 4572. State = [[0.00087848 0.17264597]]. Action = [[ 0.04246803 -0.0812361   0.         -0.06223631]]. Reward = [0.]
Curr episode timestep = 72
Scene graph at timestep 4572 is [False, True, False, False, False, True]
State prediction error at timestep 4572 is 0.012
Current timestep = 4573. State = [[0.00024153 0.16937551]]. Action = [[-0.0493     -0.01040962  0.         -0.668296  ]]. Reward = [0.]
Curr episode timestep = 73
Scene graph at timestep 4573 is [False, True, False, False, False, True]
State prediction error at timestep 4573 is 0.012
Current timestep = 4574. State = [[0.00303285 0.17072167]]. Action = [[0.07937054 0.04468029 0.         0.36329436]]. Reward = [0.]
Curr episode timestep = 74
Scene graph at timestep 4574 is [False, True, False, False, False, True]
State prediction error at timestep 4574 is 0.012
Current timestep = 4575. State = [[0.00284829 0.16912982]]. Action = [[-0.06631706 -0.04920304  0.          0.42055857]]. Reward = [0.]
Curr episode timestep = 75
Scene graph at timestep 4575 is [False, True, False, False, False, True]
State prediction error at timestep 4575 is 0.012
Current timestep = 4576. State = [[0.00404925 0.16993104]]. Action = [[ 0.05289952  0.05095128  0.         -0.80476576]]. Reward = [0.]
Curr episode timestep = 76
Scene graph at timestep 4576 is [False, True, False, False, False, True]
State prediction error at timestep 4576 is 0.012
Current timestep = 4577. State = [[0.00725318 0.17345099]]. Action = [[0.03552201 0.04806542 0.         0.40925217]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 4577 is [False, True, False, False, False, True]
State prediction error at timestep 4577 is 0.012
Current timestep = 4578. State = [[0.00800327 0.17053577]]. Action = [[-0.0108655  -0.08584814  0.         -0.58174896]]. Reward = [0.]
Curr episode timestep = 78
Scene graph at timestep 4578 is [False, True, False, False, False, True]
State prediction error at timestep 4578 is 0.012
Current timestep = 4579. State = [[0.00824232 0.16571543]]. Action = [[-0.00393543 -0.0419131   0.          0.13418746]]. Reward = [0.]
Curr episode timestep = 79
Scene graph at timestep 4579 is [False, True, False, False, False, True]
State prediction error at timestep 4579 is 0.012
Current timestep = 4580. State = [[0.0054507  0.16519788]]. Action = [[-0.07326071  0.02439539  0.         -0.06255728]]. Reward = [0.]
Curr episode timestep = 80
Scene graph at timestep 4580 is [False, True, False, False, False, True]
State prediction error at timestep 4580 is 0.012
Current timestep = 4581. State = [[0.00600046 0.16280419]]. Action = [[ 0.03802731 -0.05722448  0.          0.11093092]]. Reward = [0.]
Curr episode timestep = 81
Scene graph at timestep 4581 is [False, True, False, False, False, True]
State prediction error at timestep 4581 is 0.012
Current timestep = 4582. State = [[0.0035129  0.16569665]]. Action = [[-0.08860832  0.09629946  0.         -0.45461118]]. Reward = [0.]
Curr episode timestep = 82
Scene graph at timestep 4582 is [False, True, False, False, False, True]
State prediction error at timestep 4582 is 0.012
Current timestep = 4583. State = [[-0.00241294  0.171901  ]]. Action = [[-0.08298908  0.05928164  0.          0.31479645]]. Reward = [0.]
Curr episode timestep = 83
Scene graph at timestep 4583 is [False, True, False, False, False, True]
State prediction error at timestep 4583 is 0.012
Current timestep = 4584. State = [[-0.0048536   0.17224728]]. Action = [[-0.00423866 -0.05109724  0.         -0.29306906]]. Reward = [0.]
Curr episode timestep = 84
Scene graph at timestep 4584 is [False, True, False, False, False, True]
State prediction error at timestep 4584 is 0.012
Current timestep = 4585. State = [[-0.00293814  0.1758413 ]]. Action = [[ 0.05091409  0.08477662  0.         -0.8915175 ]]. Reward = [0.]
Curr episode timestep = 85
Scene graph at timestep 4585 is [False, True, False, False, False, True]
State prediction error at timestep 4585 is 0.012
Current timestep = 4586. State = [[-0.0022016   0.17688549]]. Action = [[ 0.00190149 -0.04305861  0.         -0.39488804]]. Reward = [0.]
Curr episode timestep = 86
Scene graph at timestep 4586 is [False, True, False, False, False, True]
State prediction error at timestep 4586 is 0.012
Current timestep = 4587. State = [[-5.8118960e-05  1.7557932e-01]]. Action = [[ 0.05302951 -0.01350588  0.          0.04135394]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 4587 is [False, True, False, False, False, True]
State prediction error at timestep 4587 is 0.012
Current timestep = 4588. State = [[0.00301315 0.17335388]]. Action = [[ 0.04581984 -0.03618943  0.          0.72162604]]. Reward = [0.]
Curr episode timestep = 88
Scene graph at timestep 4588 is [False, True, False, False, False, True]
State prediction error at timestep 4588 is 0.012
Current timestep = 4589. State = [[0.00213143 0.17666486]]. Action = [[-0.0364099   0.09184026  0.          0.06101656]]. Reward = [0.]
Curr episode timestep = 89
Scene graph at timestep 4589 is [False, True, False, False, False, True]
State prediction error at timestep 4589 is 0.012
Current timestep = 4590. State = [[0.00478153 0.17665642]]. Action = [[ 0.08723547 -0.05375756  0.          0.03129768]]. Reward = [0.]
Curr episode timestep = 90
Scene graph at timestep 4590 is [False, True, False, False, False, True]
State prediction error at timestep 4590 is 0.012
Current timestep = 4591. State = [[0.01126902 0.17128445]]. Action = [[ 0.09318402 -0.06955999  0.         -0.5597247 ]]. Reward = [0.]
Curr episode timestep = 91
Scene graph at timestep 4591 is [False, True, False, False, False, True]
State prediction error at timestep 4591 is 0.012
Current timestep = 4592. State = [[0.01473074 0.16687615]]. Action = [[ 0.01512579 -0.02570999  0.         -0.2774999 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 4592 is [False, True, False, False, False, True]
State prediction error at timestep 4592 is 0.012
Current timestep = 4593. State = [[0.0180131  0.16860051]]. Action = [[ 0.05113835  0.07423367  0.         -0.8266041 ]]. Reward = [0.]
Curr episode timestep = 93
Scene graph at timestep 4593 is [False, True, False, False, False, True]
State prediction error at timestep 4593 is 0.012
Current timestep = 4594. State = [[0.01605803 0.17221536]]. Action = [[-0.08307512  0.04361849  0.          0.02394772]]. Reward = [0.]
Curr episode timestep = 94
Scene graph at timestep 4594 is [False, True, False, False, False, True]
State prediction error at timestep 4594 is 0.012
Current timestep = 4595. State = [[0.01428751 0.17800352]]. Action = [[ 0.00362234  0.08701832  0.         -0.22064668]]. Reward = [0.]
Curr episode timestep = 95
Scene graph at timestep 4595 is [False, True, False, False, False, True]
State prediction error at timestep 4595 is 0.012
Current timestep = 4596. State = [[0.0186695  0.18050696]]. Action = [[ 0.09805959 -0.01060165  0.          0.10523748]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 4596 is [False, True, False, False, False, True]
State prediction error at timestep 4596 is 0.012
Current timestep = 4597. State = [[0.022953   0.17688736]]. Action = [[ 0.03538605 -0.07316894  0.          0.64172935]]. Reward = [0.]
Curr episode timestep = 97
Scene graph at timestep 4597 is [False, True, False, False, False, True]
State prediction error at timestep 4597 is 0.012
Current timestep = 4598. State = [[0.0228399  0.17373739]]. Action = [[-0.03661778 -0.02000075  0.          0.08633399]]. Reward = [0.]
Curr episode timestep = 98
Scene graph at timestep 4598 is [False, True, False, False, False, True]
State prediction error at timestep 4598 is 0.012
Current timestep = 4599. State = [[0.01906481 0.16880903]]. Action = [[-0.08414306 -0.08601101  0.          0.025105  ]]. Reward = [0.]
Curr episode timestep = 99
Scene graph at timestep 4599 is [False, True, False, False, False, True]
State prediction error at timestep 4599 is 0.012
Current timestep = 4600. State = [[0.01971883 0.16193397]]. Action = [[ 0.03443304 -0.08278621  0.         -0.82177144]]. Reward = [0.]
Curr episode timestep = 100
Scene graph at timestep 4600 is [False, True, False, False, False, True]
State prediction error at timestep 4600 is 0.012
Current timestep = 4601. State = [[0.02149418 0.15464696]]. Action = [[-0.01105847 -0.07767554  0.         -0.02919799]]. Reward = [0.]
Curr episode timestep = 101
Scene graph at timestep 4601 is [False, True, False, False, False, True]
State prediction error at timestep 4601 is 0.012
Current timestep = 4602. State = [[0.02687255 0.15229817]]. Action = [[ 0.09451684  0.02815155  0.         -0.42911947]]. Reward = [0.]
Curr episode timestep = 102
Scene graph at timestep 4602 is [False, True, False, False, False, True]
State prediction error at timestep 4602 is 0.012
Current timestep = 4603. State = [[0.03326729 0.14919046]]. Action = [[ 0.06241373 -0.04397108  0.          0.8950112 ]]. Reward = [0.]
Curr episode timestep = 103
Scene graph at timestep 4603 is [False, True, False, False, False, True]
State prediction error at timestep 4603 is 0.012
Current timestep = 4604. State = [[0.03686875 0.15061486]]. Action = [[ 0.02019066  0.08654282  0.         -0.41952825]]. Reward = [0.]
Curr episode timestep = 104
Scene graph at timestep 4604 is [False, True, False, False, False, True]
State prediction error at timestep 4604 is 0.012
Current timestep = 4605. State = [[0.03560977 0.15607406]]. Action = [[-0.05317178  0.07934263  0.          0.13964593]]. Reward = [0.]
Curr episode timestep = 105
Scene graph at timestep 4605 is [False, True, False, False, False, True]
State prediction error at timestep 4605 is 0.012
Current timestep = 4606. State = [[0.03318401 0.16039553]]. Action = [[-0.03524446  0.03737963  0.         -0.7759716 ]]. Reward = [0.]
Curr episode timestep = 106
Scene graph at timestep 4606 is [False, True, False, False, False, True]
State prediction error at timestep 4606 is 0.012
Current timestep = 4607. State = [[0.03190061 0.1603906 ]]. Action = [[-0.01843706 -0.03506435  0.         -0.63764364]]. Reward = [0.]
Curr episode timestep = 107
Scene graph at timestep 4607 is [False, True, False, False, False, True]
State prediction error at timestep 4607 is 0.012
Current timestep = 4608. State = [[0.03585793 0.1563021 ]]. Action = [[ 0.08496725 -0.07024745  0.         -0.8763411 ]]. Reward = [0.]
Curr episode timestep = 108
Scene graph at timestep 4608 is [False, True, False, False, False, True]
State prediction error at timestep 4608 is 0.012
Current timestep = 4609. State = [[0.04024365 0.15899242]]. Action = [[0.03835649 0.09906321 0.         0.0955236 ]]. Reward = [0.]
Curr episode timestep = 109
Scene graph at timestep 4609 is [False, True, False, False, False, True]
State prediction error at timestep 4609 is 0.012
Current timestep = 4610. State = [[0.03967731 0.15713716]]. Action = [[-0.04544817 -0.09863606  0.         -0.04755723]]. Reward = [0.]
Curr episode timestep = 110
Scene graph at timestep 4610 is [False, True, False, False, False, True]
State prediction error at timestep 4610 is 0.012
Current timestep = 4611. State = [[0.03880795 0.15444136]]. Action = [[-0.01007692 -0.00142387  0.          0.6118288 ]]. Reward = [0.]
Curr episode timestep = 111
Scene graph at timestep 4611 is [False, True, False, False, False, True]
State prediction error at timestep 4611 is 0.012
Current timestep = 4612. State = [[0.04091939 0.15005061]]. Action = [[ 0.03588843 -0.08122308  0.          0.28987157]]. Reward = [0.]
Curr episode timestep = 112
Scene graph at timestep 4612 is [False, True, False, False, False, True]
State prediction error at timestep 4612 is 0.012
Current timestep = 4613. State = [[0.04155563 0.14483234]]. Action = [[-0.02282877 -0.04449108  0.          0.78096485]]. Reward = [0.]
Curr episode timestep = 113
Scene graph at timestep 4613 is [False, True, False, False, False, True]
State prediction error at timestep 4613 is 0.012
Current timestep = 4614. State = [[0.04503487 0.14530972]]. Action = [[0.07281391 0.05530327 0.         0.2751708 ]]. Reward = [0.]
Curr episode timestep = 114
Scene graph at timestep 4614 is [False, True, False, False, False, True]
State prediction error at timestep 4614 is 0.012
Current timestep = 4615. State = [[0.04515563 0.15091874]]. Action = [[-0.04711381  0.09436531  0.          0.4406849 ]]. Reward = [0.]
Curr episode timestep = 115
Scene graph at timestep 4615 is [False, True, False, False, False, True]
State prediction error at timestep 4615 is 0.012
Current timestep = 4616. State = [[0.04364733 0.15709616]]. Action = [[-0.0089097   0.06374522  0.         -0.9236261 ]]. Reward = [0.]
Curr episode timestep = 116
Scene graph at timestep 4616 is [False, True, False, False, False, True]
State prediction error at timestep 4616 is 0.012
Current timestep = 4617. State = [[0.04105254 0.15945736]]. Action = [[-0.04815061 -0.00748583  0.          0.6225084 ]]. Reward = [0.]
Curr episode timestep = 117
Scene graph at timestep 4617 is [False, True, False, False, False, True]
State prediction error at timestep 4617 is 0.012
Current timestep = 4618. State = [[0.03872214 0.15826702]]. Action = [[-0.02663686 -0.03918461  0.          0.6978185 ]]. Reward = [0.]
Curr episode timestep = 118
Scene graph at timestep 4618 is [False, True, False, False, False, True]
State prediction error at timestep 4618 is 0.012
Current timestep = 4619. State = [[0.03866596 0.15587729]]. Action = [[ 0.00851341 -0.03767423  0.         -0.14474392]]. Reward = [0.]
Curr episode timestep = 119
Scene graph at timestep 4619 is [False, True, False, False, False, True]
State prediction error at timestep 4619 is 0.012
Current timestep = 4620. State = [[0.04008581 0.15566853]]. Action = [[0.02246924 0.01317082 0.         0.7110553 ]]. Reward = [0.]
Curr episode timestep = 120
Scene graph at timestep 4620 is [False, True, False, False, False, True]
State prediction error at timestep 4620 is 0.012
Current timestep = 4621. State = [[0.04279029 0.15367977]]. Action = [[ 0.04504832 -0.04799209  0.         -0.32320893]]. Reward = [0.]
Curr episode timestep = 121
Scene graph at timestep 4621 is [False, True, False, False, False, True]
State prediction error at timestep 4621 is 0.012
Current timestep = 4622. State = [[0.04485445 0.1562313 ]]. Action = [[0.02155592 0.08381362 0.         0.08939219]]. Reward = [0.]
Curr episode timestep = 122
Scene graph at timestep 4622 is [False, True, False, False, False, True]
State prediction error at timestep 4622 is 0.012
Current timestep = 4623. State = [[0.04480623 0.1575746 ]]. Action = [[-0.00763816 -0.0208213   0.         -0.46048772]]. Reward = [0.]
Curr episode timestep = 123
Scene graph at timestep 4623 is [False, True, False, False, False, True]
State prediction error at timestep 4623 is 0.012
Current timestep = 4624. State = [[0.04299808 0.15906656]]. Action = [[-0.0321616  0.0377342  0.        -0.0535593]]. Reward = [0.]
Curr episode timestep = 124
Scene graph at timestep 4624 is [False, True, False, False, False, True]
State prediction error at timestep 4624 is 0.012
Current timestep = 4625. State = [[0.04087161 0.1637047 ]]. Action = [[-0.02419163  0.06332584  0.         -0.25892556]]. Reward = [0.]
Curr episode timestep = 125
Scene graph at timestep 4625 is [False, True, False, False, False, True]
State prediction error at timestep 4625 is 0.012
Current timestep = 4626. State = [[0.03868967 0.16506368]]. Action = [[-0.02854645 -0.02650778  0.          0.63939834]]. Reward = [0.]
Curr episode timestep = 126
Scene graph at timestep 4626 is [False, True, False, False, False, True]
State prediction error at timestep 4626 is 0.012
Current timestep = 4627. State = [[0.04177639 0.16645133]]. Action = [[ 0.09107354  0.02868281  0.         -0.5206423 ]]. Reward = [0.]
Curr episode timestep = 127
Scene graph at timestep 4627 is [False, True, False, False, False, True]
State prediction error at timestep 4627 is 0.012
Current timestep = 4628. State = [[0.04527031 0.17034748]]. Action = [[0.03223705 0.0531451  0.         0.7484901 ]]. Reward = [0.]
Curr episode timestep = 128
Scene graph at timestep 4628 is [False, True, False, False, False, True]
State prediction error at timestep 4628 is 0.012
Current timestep = 4629. State = [[0.04800673 0.17459655]]. Action = [[0.04536452 0.04224264 0.         0.64074755]]. Reward = [0.]
Curr episode timestep = 129
Scene graph at timestep 4629 is [False, True, False, False, False, True]
State prediction error at timestep 4629 is 0.012
Current timestep = 4630. State = [[0.04828829 0.17430088]]. Action = [[-0.01551216 -0.04421572  0.         -0.6506794 ]]. Reward = [0.]
Curr episode timestep = 130
Scene graph at timestep 4630 is [False, True, False, False, False, True]
State prediction error at timestep 4630 is 0.012
Current timestep = 4631. State = [[0.04451819 0.17637964]]. Action = [[-0.07765652  0.05350966  0.         -0.98627657]]. Reward = [0.]
Curr episode timestep = 131
Scene graph at timestep 4631 is [False, True, False, False, False, True]
State prediction error at timestep 4631 is 0.012
Current timestep = 4632. State = [[0.04356002 0.17949645]]. Action = [[0.01696309 0.01281482 0.         0.7881167 ]]. Reward = [0.]
Curr episode timestep = 132
Scene graph at timestep 4632 is [False, True, False, False, False, True]
State prediction error at timestep 4632 is 0.012
Current timestep = 4633. State = [[0.0448658  0.18480441]]. Action = [[ 0.01822279  0.07667824  0.         -0.31652248]]. Reward = [0.]
Curr episode timestep = 133
Scene graph at timestep 4633 is [False, True, False, False, False, True]
State prediction error at timestep 4633 is 0.012
Current timestep = 4634. State = [[0.04229141 0.19069058]]. Action = [[-0.06336419  0.0460036   0.         -0.6895671 ]]. Reward = [0.]
Curr episode timestep = 134
Scene graph at timestep 4634 is [False, True, False, False, False, True]
State prediction error at timestep 4634 is 0.012
Current timestep = 4635. State = [[0.04108249 0.1951937 ]]. Action = [[ 0.01059271  0.02793842  0.         -0.5775445 ]]. Reward = [0.]
Curr episode timestep = 135
Scene graph at timestep 4635 is [False, True, False, False, False, True]
State prediction error at timestep 4635 is 0.012
Current timestep = 4636. State = [[0.04367432 0.19904327]]. Action = [[ 0.05640612  0.02843305  0.         -0.43157429]]. Reward = [0.]
Curr episode timestep = 136
Scene graph at timestep 4636 is [False, True, False, False, False, True]
State prediction error at timestep 4636 is 0.012
Current timestep = 4637. State = [[0.04291286 0.198928  ]]. Action = [[-0.04620639 -0.04734775  0.         -0.9772843 ]]. Reward = [0.]
Curr episode timestep = 137
Scene graph at timestep 4637 is [False, True, False, False, False, True]
State prediction error at timestep 4637 is 0.012
Current timestep = 4638. State = [[0.04176916 0.19436714]]. Action = [[-0.00368276 -0.08615519  0.          0.676036  ]]. Reward = [0.]
Curr episode timestep = 138
Scene graph at timestep 4638 is [False, True, False, False, False, True]
State prediction error at timestep 4638 is 0.012
Current timestep = 4639. State = [[0.04325444 0.19330208]]. Action = [[ 0.02823041  0.02253641  0.         -0.7035775 ]]. Reward = [0.]
Curr episode timestep = 139
Scene graph at timestep 4639 is [False, True, False, False, False, True]
State prediction error at timestep 4639 is 0.012
Current timestep = 4640. State = [[0.04571421 0.18990028]]. Action = [[ 0.0322359  -0.07868277  0.          0.22222626]]. Reward = [0.]
Curr episode timestep = 140
Scene graph at timestep 4640 is [False, True, False, False, False, True]
State prediction error at timestep 4640 is 0.012
Current timestep = 4641. State = [[0.04523719 0.18214208]]. Action = [[-0.04087649 -0.09939743  0.          0.800823  ]]. Reward = [0.]
Curr episode timestep = 141
Scene graph at timestep 4641 is [False, True, False, False, False, True]
State prediction error at timestep 4641 is 0.012
Current timestep = 4642. State = [[0.04310333 0.17935632]]. Action = [[-0.04153013  0.0222803   0.          0.04387438]]. Reward = [0.]
Curr episode timestep = 142
Scene graph at timestep 4642 is [False, True, False, False, False, True]
State prediction error at timestep 4642 is 0.012
Current timestep = 4643. State = [[0.04252179 0.17597127]]. Action = [[-0.00369344 -0.06047845  0.          0.00063694]]. Reward = [0.]
Curr episode timestep = 143
Scene graph at timestep 4643 is [False, True, False, False, False, True]
State prediction error at timestep 4643 is 0.012
Current timestep = 4644. State = [[0.0390045  0.17571452]]. Action = [[-0.08519982  0.04760482  0.         -0.08875096]]. Reward = [0.]
Curr episode timestep = 144
Scene graph at timestep 4644 is [False, True, False, False, False, True]
State prediction error at timestep 4644 is 0.012
Current timestep = 4645. State = [[0.03815139 0.17602575]]. Action = [[ 0.02290796 -0.00957716  0.         -0.24424326]]. Reward = [0.]
Curr episode timestep = 145
Scene graph at timestep 4645 is [False, True, False, False, False, True]
State prediction error at timestep 4645 is 0.012
Current timestep = 4646. State = [[0.03578374 0.17636575]]. Action = [[-0.06468207  0.01873274  0.         -0.9602413 ]]. Reward = [0.]
Curr episode timestep = 146
Scene graph at timestep 4646 is [False, True, False, False, False, True]
State prediction error at timestep 4646 is 0.012
Current timestep = 4647. State = [[0.03089775 0.17387486]]. Action = [[-0.07093567 -0.0599888   0.          0.33288252]]. Reward = [0.]
Curr episode timestep = 147
Scene graph at timestep 4647 is [False, True, False, False, False, True]
State prediction error at timestep 4647 is 0.012
Current timestep = 4648. State = [[0.03038305 0.16996458]]. Action = [[ 0.03001697 -0.04016773  0.          0.02969873]]. Reward = [0.]
Curr episode timestep = 148
Scene graph at timestep 4648 is [False, True, False, False, False, True]
State prediction error at timestep 4648 is 0.012
Current timestep = 4649. State = [[0.0273707  0.17261706]]. Action = [[-0.07471755  0.08573589  0.          0.4185177 ]]. Reward = [0.]
Curr episode timestep = 149
Scene graph at timestep 4649 is [False, True, False, False, False, True]
State prediction error at timestep 4649 is 0.012
Current timestep = 4650. State = [[0.02423088 0.17251587]]. Action = [[-0.01496428 -0.05401099  0.         -0.01038682]]. Reward = [0.]
Curr episode timestep = 150
Scene graph at timestep 4650 is [False, True, False, False, False, True]
State prediction error at timestep 4650 is 0.012
Current timestep = 4651. State = [[0.02337068 0.1720815 ]]. Action = [[ 0.00500213  0.0201563   0.         -0.73015857]]. Reward = [0.]
Curr episode timestep = 151
Scene graph at timestep 4651 is [False, True, False, False, False, True]
State prediction error at timestep 4651 is 0.012
Current timestep = 4652. State = [[0.01920461 0.17062987]]. Action = [[-0.07307073 -0.03974235  0.         -0.78612196]]. Reward = [0.]
Curr episode timestep = 152
Scene graph at timestep 4652 is [False, True, False, False, False, True]
State prediction error at timestep 4652 is 0.012
Current timestep = 4653. State = [[0.01557199 0.17189182]]. Action = [[-0.01740932  0.04667052  0.         -0.32237297]]. Reward = [0.]
Curr episode timestep = 153
Scene graph at timestep 4653 is [False, True, False, False, False, True]
State prediction error at timestep 4653 is 0.012
Current timestep = 4654. State = [[0.01049972 0.17385812]]. Action = [[-0.06989564  0.00850113  0.         -0.62764716]]. Reward = [0.]
Curr episode timestep = 154
Scene graph at timestep 4654 is [False, True, False, False, False, True]
State prediction error at timestep 4654 is 0.012
Current timestep = 4655. State = [[0.00375717 0.17694072]]. Action = [[-0.07489653  0.04529848  0.          0.67982185]]. Reward = [0.]
Curr episode timestep = 155
Scene graph at timestep 4655 is [False, True, False, False, False, True]
State prediction error at timestep 4655 is 0.012
Current timestep = 4656. State = [[-0.00338716  0.18017301]]. Action = [[-0.07491504  0.02148931  0.         -0.9359845 ]]. Reward = [0.]
Curr episode timestep = 156
Scene graph at timestep 4656 is [False, True, False, False, False, True]
State prediction error at timestep 4656 is 0.012
Current timestep = 4657. State = [[-0.00656349  0.18270364]]. Action = [[ 0.01371703  0.01820699  0.         -0.02890873]]. Reward = [0.]
Curr episode timestep = 157
Scene graph at timestep 4657 is [False, True, False, False, False, True]
State prediction error at timestep 4657 is 0.012
Current timestep = 4658. State = [[-0.01066241  0.18712668]]. Action = [[-0.04882632  0.06049686  0.         -0.42004776]]. Reward = [0.]
Curr episode timestep = 158
Scene graph at timestep 4658 is [False, True, False, False, False, True]
State prediction error at timestep 4658 is 0.012
Current timestep = 4659. State = [[-0.01087985  0.18505187]]. Action = [[ 0.06788149 -0.09348556  0.          0.04719257]]. Reward = [0.]
Curr episode timestep = 159
Scene graph at timestep 4659 is [False, True, False, False, False, True]
State prediction error at timestep 4659 is 0.012
Current timestep = 4660. State = [[-0.0148098   0.18729205]]. Action = [[-0.08154039  0.09447596  0.          0.49392128]]. Reward = [0.]
Curr episode timestep = 160
Scene graph at timestep 4660 is [False, True, False, False, False, True]
State prediction error at timestep 4660 is 0.012
Current timestep = 4661. State = [[-0.01718759  0.18644814]]. Action = [[ 0.03954156 -0.0794861   0.         -0.9752238 ]]. Reward = [0.]
Curr episode timestep = 161
Scene graph at timestep 4661 is [False, True, False, False, False, True]
State prediction error at timestep 4661 is 0.012
Current timestep = 4662. State = [[-0.02134866  0.18352589]]. Action = [[-0.07107897 -0.01700284  0.          0.68406856]]. Reward = [0.]
Curr episode timestep = 162
Scene graph at timestep 4662 is [False, True, False, False, False, True]
State prediction error at timestep 4662 is 0.012
Current timestep = 4663. State = [[-0.02449027  0.18656996]]. Action = [[ 0.01138469  0.0733349   0.         -0.42190003]]. Reward = [0.]
Curr episode timestep = 163
Scene graph at timestep 4663 is [False, True, False, False, False, True]
State prediction error at timestep 4663 is 0.012
Current timestep = 4664. State = [[-0.03002733  0.19328058]]. Action = [[-0.07685666  0.08853471  0.         -0.5921456 ]]. Reward = [0.]
Curr episode timestep = 164
Scene graph at timestep 4664 is [False, True, False, False, False, True]
State prediction error at timestep 4664 is 0.012
Current timestep = 4665. State = [[-0.03597765  0.2011158 ]]. Action = [[-0.03420543  0.08797298  0.          0.80598176]]. Reward = [0.]
Curr episode timestep = 165
Scene graph at timestep 4665 is [False, True, False, False, False, True]
State prediction error at timestep 4665 is 0.012
Current timestep = 4666. State = [[-0.04097612  0.20699957]]. Action = [[-0.03361512  0.03952395  0.          0.04199266]]. Reward = [0.]
Curr episode timestep = 166
Scene graph at timestep 4666 is [False, True, False, False, False, True]
State prediction error at timestep 4666 is 0.012
Current timestep = 4667. State = [[-0.04769551  0.2099562 ]]. Action = [[-0.07421914  0.0039778   0.         -0.8489416 ]]. Reward = [0.]
Curr episode timestep = 167
Scene graph at timestep 4667 is [False, True, False, False, False, True]
State prediction error at timestep 4667 is 0.012
Current timestep = 4668. State = [[-0.04980317  0.21452217]]. Action = [[ 0.04644831  0.05860267  0.         -0.22334772]]. Reward = [0.]
Curr episode timestep = 168
Scene graph at timestep 4668 is [False, True, False, False, False, True]
State prediction error at timestep 4668 is 0.012
Current timestep = 4669. State = [[-0.05223243  0.21433246]]. Action = [[-0.03558823 -0.06471974  0.         -0.48873675]]. Reward = [0.]
Curr episode timestep = 169
Scene graph at timestep 4669 is [True, False, False, False, False, True]
State prediction error at timestep 4669 is 0.012
Current timestep = 4670. State = [[-0.05859933  0.21727368]]. Action = [[-0.08207544  0.07226556  0.         -0.5299205 ]]. Reward = [0.]
Curr episode timestep = 170
Scene graph at timestep 4670 is [True, False, False, False, False, True]
State prediction error at timestep 4670 is 0.012
Current timestep = 4671. State = [[-0.05931112  0.21549264]]. Action = [[ 0.06526294 -0.09856976  0.         -0.44022286]]. Reward = [0.]
Curr episode timestep = 171
Scene graph at timestep 4671 is [True, False, False, False, False, True]
State prediction error at timestep 4671 is 0.012
Current timestep = 4672. State = [[-0.05714484  0.20988572]]. Action = [[ 0.02986995 -0.06349698  0.          0.37536788]]. Reward = [0.]
Curr episode timestep = 172
Scene graph at timestep 4672 is [True, False, False, False, False, True]
State prediction error at timestep 4672 is 0.012
Current timestep = 4673. State = [[-0.05506382  0.20294535]]. Action = [[ 0.0336253  -0.09112053  0.         -0.44502658]]. Reward = [0.]
Curr episode timestep = 173
Scene graph at timestep 4673 is [True, False, False, False, False, True]
State prediction error at timestep 4673 is 0.012
Current timestep = 4674. State = [[-0.05293091  0.20307155]]. Action = [[ 0.03045068  0.07887491  0.         -0.7870223 ]]. Reward = [0.]
Curr episode timestep = 174
Scene graph at timestep 4674 is [True, False, False, False, False, True]
State prediction error at timestep 4674 is 0.012
Current timestep = 4675. State = [[-0.05629059  0.20622578]]. Action = [[-0.08305017  0.03503273  0.          0.2477547 ]]. Reward = [0.]
Curr episode timestep = 175
Scene graph at timestep 4675 is [True, False, False, False, False, True]
State prediction error at timestep 4675 is 0.012
Current timestep = 4676. State = [[-0.05774858  0.20543736]]. Action = [[ 0.0243315  -0.03168055  0.         -0.501115  ]]. Reward = [0.]
Curr episode timestep = 176
Scene graph at timestep 4676 is [True, False, False, False, False, True]
State prediction error at timestep 4676 is 0.012
Current timestep = 4677. State = [[-0.05533437  0.20558687]]. Action = [[0.04843632 0.03123515 0.         0.15782058]]. Reward = [0.]
Curr episode timestep = 177
Scene graph at timestep 4677 is [True, False, False, False, False, True]
State prediction error at timestep 4677 is 0.012
Current timestep = 4678. State = [[-0.05598262  0.20127332]]. Action = [[-0.03561174 -0.09328114  0.         -0.76989603]]. Reward = [0.]
Curr episode timestep = 178
Scene graph at timestep 4678 is [True, False, False, False, False, True]
State prediction error at timestep 4678 is 0.012
Current timestep = 4679. State = [[-0.05260302  0.19750686]]. Action = [[ 0.09503477 -0.00586922  0.         -0.1208061 ]]. Reward = [0.]
Curr episode timestep = 179
Scene graph at timestep 4679 is [True, False, False, False, False, True]
State prediction error at timestep 4679 is 0.012
Current timestep = 4680. State = [[-0.05163303  0.1962051 ]]. Action = [[-3.8831770e-02 -5.5246055e-05  0.0000000e+00 -9.5473289e-02]]. Reward = [0.]
Curr episode timestep = 180
Scene graph at timestep 4680 is [True, False, False, False, False, True]
State prediction error at timestep 4680 is 0.012
Current timestep = 4681. State = [[-0.05314942  0.19773029]]. Action = [[-0.01494872  0.04507922  0.          0.03845704]]. Reward = [0.]
Curr episode timestep = 181
Scene graph at timestep 4681 is [True, False, False, False, False, True]
State prediction error at timestep 4681 is 0.012
Current timestep = 4682. State = [[-0.05748435  0.1998009 ]]. Action = [[-0.08148662  0.02074836  0.          0.3897215 ]]. Reward = [0.]
Curr episode timestep = 182
Scene graph at timestep 4682 is [True, False, False, False, False, True]
State prediction error at timestep 4682 is 0.012
Current timestep = 4683. State = [[-0.06025158  0.19843285]]. Action = [[-0.01338471 -0.04363308  0.         -0.04513496]]. Reward = [0.]
Curr episode timestep = 183
Scene graph at timestep 4683 is [True, False, False, False, False, True]
State prediction error at timestep 4683 is 0.012
Current timestep = 4684. State = [[-0.058967    0.19598606]]. Action = [[ 0.03584673 -0.02372283  0.          0.48044813]]. Reward = [0.]
Curr episode timestep = 184
Scene graph at timestep 4684 is [True, False, False, False, False, True]
State prediction error at timestep 4684 is 0.012
Current timestep = 4685. State = [[-0.06252385  0.19386663]]. Action = [[-0.09869551 -0.02516256  0.         -0.48392093]]. Reward = [0.]
Curr episode timestep = 185
Scene graph at timestep 4685 is [True, False, False, False, False, True]
State prediction error at timestep 4685 is 0.012
Current timestep = 4686. State = [[-0.06465986  0.19467878]]. Action = [[0.01711843 0.03190579 0.         0.7488725 ]]. Reward = [0.]
Curr episode timestep = 186
Scene graph at timestep 4686 is [True, False, False, False, False, True]
State prediction error at timestep 4686 is 0.012
Current timestep = 4687. State = [[-0.06057374  0.19825853]]. Action = [[ 0.09427352  0.05596118  0.         -0.717242  ]]. Reward = [0.]
Curr episode timestep = 187
Scene graph at timestep 4687 is [True, False, False, False, False, True]
State prediction error at timestep 4687 is 0.012
Current timestep = 4688. State = [[-0.05671361  0.19783258]]. Action = [[ 0.04591403 -0.03761759  0.         -0.30317175]]. Reward = [0.]
Curr episode timestep = 188
Scene graph at timestep 4688 is [True, False, False, False, False, True]
State prediction error at timestep 4688 is 0.012
Current timestep = 4689. State = [[-0.054078    0.19458985]]. Action = [[ 0.03473485 -0.03602218  0.         -0.38998324]]. Reward = [0.]
Curr episode timestep = 189
Scene graph at timestep 4689 is [True, False, False, False, False, True]
State prediction error at timestep 4689 is 0.012
Current timestep = 4690. State = [[-0.05007911  0.19558385]]. Action = [[ 0.06679984  0.05524722  0.         -0.3722707 ]]. Reward = [0.]
Curr episode timestep = 190
Scene graph at timestep 4690 is [True, False, False, False, False, True]
State prediction error at timestep 4690 is 0.012
Current timestep = 4691. State = [[-0.04998463  0.19827764]]. Action = [[-0.0330857   0.03257493  0.          0.14731288]]. Reward = [0.]
Curr episode timestep = 191
Scene graph at timestep 4691 is [False, True, False, False, False, True]
State prediction error at timestep 4691 is 0.012
Current timestep = 4692. State = [[-0.04804827  0.20112553]]. Action = [[ 0.06130233  0.03912764  0.         -0.51513445]]. Reward = [0.]
Curr episode timestep = 192
Scene graph at timestep 4692 is [False, True, False, False, False, True]
State prediction error at timestep 4692 is 0.012
Current timestep = 4693. State = [[-0.04973337  0.20493948]]. Action = [[-0.06997582  0.04966886  0.         -0.75607836]]. Reward = [0.]
Curr episode timestep = 193
Scene graph at timestep 4693 is [False, True, False, False, False, True]
State prediction error at timestep 4693 is 0.012
Current timestep = 4694. State = [[-0.05286915  0.20513815]]. Action = [[-0.02677285 -0.03916743  0.         -0.629396  ]]. Reward = [0.]
Curr episode timestep = 194
Scene graph at timestep 4694 is [True, False, False, False, False, True]
State prediction error at timestep 4694 is 0.012
Current timestep = 4695. State = [[-0.05710379  0.20159717]]. Action = [[-0.07724816 -0.06431177  0.         -0.18957603]]. Reward = [0.]
Curr episode timestep = 195
Scene graph at timestep 4695 is [True, False, False, False, False, True]
State prediction error at timestep 4695 is 0.012
Current timestep = 4696. State = [[-0.05685802  0.1973056 ]]. Action = [[ 0.04147846 -0.05695158  0.         -0.61168903]]. Reward = [0.]
Curr episode timestep = 196
Scene graph at timestep 4696 is [True, False, False, False, False, True]
State prediction error at timestep 4696 is 0.012
Current timestep = 4697. State = [[-0.05425283  0.19352178]]. Action = [[ 0.02109897 -0.03855442  0.          0.7167014 ]]. Reward = [0.]
Curr episode timestep = 197
Scene graph at timestep 4697 is [True, False, False, False, False, True]
State prediction error at timestep 4697 is 0.012
Current timestep = 4698. State = [[-0.05317655  0.195376  ]]. Action = [[ 1.3806671e-04  6.8811409e-02  0.0000000e+00 -2.1020120e-01]]. Reward = [0.]
Curr episode timestep = 198
Scene graph at timestep 4698 is [True, False, False, False, False, True]
State prediction error at timestep 4698 is 0.012
Current timestep = 4699. State = [[-0.05102424  0.19586733]]. Action = [[ 0.03992742 -0.02435013  0.         -0.59407526]]. Reward = [0.]
Curr episode timestep = 199
Scene graph at timestep 4699 is [True, False, False, False, False, True]
State prediction error at timestep 4699 is 0.012
Current timestep = 4700. State = [[-0.05282966  0.19185133]]. Action = [[-0.07125075 -0.06295991  0.         -0.4192444 ]]. Reward = [0.]
Curr episode timestep = 200
Scene graph at timestep 4700 is [True, False, False, False, False, True]
State prediction error at timestep 4700 is 0.012
Current timestep = 4701. State = [[-0.05329647  0.19138266]]. Action = [[ 0.02193324  0.03496122  0.         -0.9631895 ]]. Reward = [0.]
Curr episode timestep = 201
Scene graph at timestep 4701 is [True, False, False, False, False, True]
State prediction error at timestep 4701 is 0.012
Current timestep = 4702. State = [[-0.05102747  0.1945877 ]]. Action = [[ 0.03748675  0.05274583  0.         -0.7629124 ]]. Reward = [0.]
Curr episode timestep = 202
Scene graph at timestep 4702 is [True, False, False, False, False, True]
State prediction error at timestep 4702 is 0.012
Current timestep = 4703. State = [[-0.05305354  0.20108588]]. Action = [[-0.05699163  0.09906956  0.         -0.11832589]]. Reward = [0.]
Curr episode timestep = 203
Scene graph at timestep 4703 is [True, False, False, False, False, True]
State prediction error at timestep 4703 is 0.012
Current timestep = 4704. State = [[-0.05830852  0.20957543]]. Action = [[-0.06498818  0.09601866  0.          0.44132233]]. Reward = [0.]
Curr episode timestep = 204
Scene graph at timestep 4704 is [True, False, False, False, False, True]
State prediction error at timestep 4704 is 0.012
Current timestep = 4705. State = [[-0.06096846  0.21651468]]. Action = [[ 0.00243952  0.05193626  0.         -0.5883604 ]]. Reward = [0.]
Curr episode timestep = 205
Scene graph at timestep 4705 is [True, False, False, False, False, True]
State prediction error at timestep 4705 is 0.012
Current timestep = 4706. State = [[-0.06511851  0.22240487]]. Action = [[-0.0628055   0.05006307  0.          0.16519201]]. Reward = [0.]
Curr episode timestep = 206
Scene graph at timestep 4706 is [True, False, False, False, False, True]
State prediction error at timestep 4706 is 0.012
Current timestep = 4707. State = [[-0.06840448  0.22951446]]. Action = [[-0.00722781  0.07065284  0.          0.19073117]]. Reward = [0.]
Curr episode timestep = 207
Scene graph at timestep 4707 is [True, False, False, False, False, True]
State prediction error at timestep 4707 is 0.012
Current timestep = 4708. State = [[-0.06572388  0.22943261]]. Action = [[ 0.0900886  -0.08340707  0.          0.99888086]]. Reward = [0.]
Curr episode timestep = 208
Scene graph at timestep 4708 is [True, False, False, False, False, True]
State prediction error at timestep 4708 is 0.012
Current timestep = 4709. State = [[-0.06203324  0.22560218]]. Action = [[ 0.04476187 -0.05328424  0.          0.5842891 ]]. Reward = [0.]
Curr episode timestep = 209
Scene graph at timestep 4709 is [True, False, False, False, False, True]
State prediction error at timestep 4709 is 0.012
Current timestep = 4710. State = [[-0.05782529  0.22293745]]. Action = [[ 0.06618603 -0.02889166  0.          0.0345701 ]]. Reward = [0.]
Curr episode timestep = 210
Scene graph at timestep 4710 is [True, False, False, False, False, True]
State prediction error at timestep 4710 is 0.012
Current timestep = 4711. State = [[-0.05868259  0.21985646]]. Action = [[-0.06451811 -0.04508835  0.          0.47490168]]. Reward = [0.]
Curr episode timestep = 211
Scene graph at timestep 4711 is [True, False, False, False, False, True]
State prediction error at timestep 4711 is 0.012
Current timestep = 4712. State = [[-0.0558265  0.2195048]]. Action = [[ 0.09880387  0.02575169  0.         -0.43476146]]. Reward = [0.]
Curr episode timestep = 212
Scene graph at timestep 4712 is [True, False, False, False, False, True]
State prediction error at timestep 4712 is 0.012
Current timestep = 4713. State = [[-0.05181917  0.2240305 ]]. Action = [[ 0.02375511  0.08799159  0.         -0.20978624]]. Reward = [0.]
Curr episode timestep = 213
Scene graph at timestep 4713 is [True, False, False, False, False, True]
State prediction error at timestep 4713 is 0.012
Current timestep = 4714. State = [[-0.0527975  0.2268314]]. Action = [[-0.04411487  0.00670459  0.          0.8171742 ]]. Reward = [0.]
Curr episode timestep = 214
Scene graph at timestep 4714 is [True, False, False, False, False, True]
State prediction error at timestep 4714 is 0.012
Current timestep = 4715. State = [[-0.05793948  0.22861487]]. Action = [[-0.09837859  0.02072859  0.         -0.8967826 ]]. Reward = [0.]
Curr episode timestep = 215
Scene graph at timestep 4715 is [True, False, False, False, False, True]
State prediction error at timestep 4715 is 0.012
Current timestep = 4716. State = [[-0.06022042  0.22864677]]. Action = [[-0.00555087 -0.02795453  0.          0.63507795]]. Reward = [0.]
Curr episode timestep = 216
Scene graph at timestep 4716 is [True, False, False, False, False, True]
State prediction error at timestep 4716 is 0.012
Current timestep = 4717. State = [[-0.05643648  0.22834013]]. Action = [[ 0.07685021 -0.00081092  0.          0.5442493 ]]. Reward = [0.]
Curr episode timestep = 217
Scene graph at timestep 4717 is [True, False, False, False, False, True]
State prediction error at timestep 4717 is 0.012
Current timestep = 4718. State = [[-0.05798655  0.2335458 ]]. Action = [[-0.08427523  0.09739687  0.         -0.7436653 ]]. Reward = [0.]
Curr episode timestep = 218
Scene graph at timestep 4718 is [True, False, False, False, False, True]
State prediction error at timestep 4718 is 0.012
Current timestep = 4719. State = [[-0.0580444   0.23791291]]. Action = [[0.0521323 0.0142927 0.        0.8964727]]. Reward = [0.]
Curr episode timestep = 219
Scene graph at timestep 4719 is [True, False, False, False, False, True]
State prediction error at timestep 4719 is 0.012
Current timestep = 4720. State = [[-0.06061815  0.24098052]]. Action = [[-0.07761578  0.03130654  0.         -0.97023886]]. Reward = [0.]
Curr episode timestep = 220
Scene graph at timestep 4720 is [True, False, False, False, False, True]
State prediction error at timestep 4720 is 0.012
Current timestep = 4721. State = [[-0.0605148  0.2478199]]. Action = [[ 0.06390376  0.0967376   0.         -0.6084075 ]]. Reward = [0.]
Curr episode timestep = 221
Scene graph at timestep 4721 is [True, False, False, False, False, True]
State prediction error at timestep 4721 is 0.012
Current timestep = 4722. State = [[-0.05474651  0.24779944]]. Action = [[ 0.09994509 -0.07708088  0.          0.21812952]]. Reward = [0.]
Curr episode timestep = 222
Scene graph at timestep 4722 is [True, False, False, False, False, True]
State prediction error at timestep 4722 is 0.012
Current timestep = 4723. State = [[-0.05237936  0.24685691]]. Action = [[-0.00834339  0.01316452  0.          0.85593426]]. Reward = [0.]
Curr episode timestep = 223
Scene graph at timestep 4723 is [True, False, False, False, False, True]
State prediction error at timestep 4723 is 0.012
Current timestep = 4724. State = [[-0.05538779  0.24483506]]. Action = [[-0.07020988 -0.05826912  0.          0.6874713 ]]. Reward = [0.]
Curr episode timestep = 224
Scene graph at timestep 4724 is [True, False, False, False, False, True]
State prediction error at timestep 4724 is 0.012
Current timestep = 4725. State = [[-0.05846715  0.24670237]]. Action = [[-0.03871694  0.0570054   0.          0.58284986]]. Reward = [0.]
Curr episode timestep = 225
Scene graph at timestep 4725 is [True, False, False, False, False, True]
State prediction error at timestep 4725 is 0.012
Current timestep = 4726. State = [[-0.0616283   0.25086457]]. Action = [[-0.04724637  0.03424496  0.          0.01515067]]. Reward = [0.]
Curr episode timestep = 226
Scene graph at timestep 4726 is [True, False, False, False, False, True]
State prediction error at timestep 4726 is 0.012
Current timestep = 4727. State = [[-0.06280752  0.24937297]]. Action = [[-0.00141091 -0.07164403  0.          0.8223264 ]]. Reward = [0.]
Curr episode timestep = 227
Scene graph at timestep 4727 is [True, False, False, False, False, True]
State prediction error at timestep 4727 is 0.012
Current timestep = 4728. State = [[-0.06680337  0.2472035 ]]. Action = [[-0.08950496 -0.0178823   0.          0.16277564]]. Reward = [0.]
Curr episode timestep = 228
Scene graph at timestep 4728 is [True, False, False, False, False, True]
State prediction error at timestep 4728 is 0.012
Current timestep = 4729. State = [[-0.07356041  0.24901734]]. Action = [[-0.09561182  0.03131977  0.         -0.20074558]]. Reward = [0.]
Curr episode timestep = 229
Scene graph at timestep 4729 is [True, False, False, False, False, True]
State prediction error at timestep 4729 is 0.012
Current timestep = 4730. State = [[-0.07585157  0.24851029]]. Action = [[ 0.01233338 -0.04603035  0.          0.3077321 ]]. Reward = [0.]
Curr episode timestep = 230
Scene graph at timestep 4730 is [True, False, False, False, False, True]
State prediction error at timestep 4730 is 0.012
Current timestep = 4731. State = [[-0.07753241  0.24661866]]. Action = [[-0.0329152  -0.02118676  0.          0.41990387]]. Reward = [0.]
Curr episode timestep = 231
Scene graph at timestep 4731 is [True, False, False, False, False, True]
State prediction error at timestep 4731 is 0.012
Current timestep = 4732. State = [[-0.07758099  0.243507  ]]. Action = [[ 0.02561932 -0.05120822  0.         -0.5352205 ]]. Reward = [0.]
Curr episode timestep = 232
Scene graph at timestep 4732 is [True, False, False, False, False, True]
State prediction error at timestep 4732 is 0.012
Current timestep = 4733. State = [[-0.07797618  0.24073862]]. Action = [[-0.01187376 -0.0178166   0.          0.6638855 ]]. Reward = [0.]
Curr episode timestep = 233
Scene graph at timestep 4733 is [True, False, False, False, False, True]
State prediction error at timestep 4733 is 0.012
Current timestep = 4734. State = [[-0.08243116  0.24464302]]. Action = [[-0.07064033  0.09835715  0.         -0.49333322]]. Reward = [0.]
Curr episode timestep = 234
Scene graph at timestep 4734 is [True, False, False, False, False, True]
State prediction error at timestep 4734 is 0.012
Current timestep = 4735. State = [[-0.08253176  0.24630563]]. Action = [[ 0.06448793 -0.02068571  0.         -0.578988  ]]. Reward = [0.]
Curr episode timestep = 235
Scene graph at timestep 4735 is [True, False, False, False, False, True]
State prediction error at timestep 4735 is 0.012
Current timestep = 4736. State = [[-0.08234531  0.24536766]]. Action = [[-0.00777244 -0.00280707  0.          0.82088065]]. Reward = [0.]
Curr episode timestep = 236
Scene graph at timestep 4736 is [True, False, False, False, False, True]
State prediction error at timestep 4736 is 0.012
Current timestep = 4737. State = [[-0.08241268  0.2427604 ]]. Action = [[ 0.0190406  -0.04225489  0.         -0.6690625 ]]. Reward = [0.]
Curr episode timestep = 237
Scene graph at timestep 4737 is [True, False, False, False, False, True]
State prediction error at timestep 4737 is 0.012
Current timestep = 4738. State = [[-0.0792382   0.24486573]]. Action = [[ 0.07393604  0.08077279  0.         -0.8767858 ]]. Reward = [0.]
Curr episode timestep = 238
Scene graph at timestep 4738 is [True, False, False, False, False, True]
State prediction error at timestep 4738 is 0.012
Current timestep = 4739. State = [[-0.0780464   0.24643973]]. Action = [[ 0.00448994 -0.00096517  0.          0.85591006]]. Reward = [0.]
Curr episode timestep = 239
Scene graph at timestep 4739 is [True, False, False, False, False, True]
State prediction error at timestep 4739 is 0.012
Current timestep = 4740. State = [[-0.08006442  0.24986422]]. Action = [[-0.02921899  0.0739009   0.          0.52695096]]. Reward = [0.]
Curr episode timestep = 240
Scene graph at timestep 4740 is [True, False, False, False, False, True]
State prediction error at timestep 4740 is 0.012
Current timestep = 4741. State = [[-0.07979592  0.2505456 ]]. Action = [[ 0.03833402 -0.02932255  0.          0.50824857]]. Reward = [0.]
Curr episode timestep = 241
Scene graph at timestep 4741 is [True, False, False, False, False, True]
State prediction error at timestep 4741 is 0.012
Current timestep = 4742. State = [[-0.0789005   0.24665962]]. Action = [[ 0.00554427 -0.06142217  0.          0.55316615]]. Reward = [0.]
Curr episode timestep = 242
Scene graph at timestep 4742 is [True, False, False, False, False, True]
State prediction error at timestep 4742 is 0.012
Current timestep = 4743. State = [[-0.07660795  0.24282654]]. Action = [[ 0.04245133 -0.03419375  0.         -0.8881166 ]]. Reward = [0.]
Curr episode timestep = 243
Scene graph at timestep 4743 is [True, False, False, False, False, True]
State prediction error at timestep 4743 is 0.012
Current timestep = 4744. State = [[-0.07226964  0.24083997]]. Action = [[ 0.06159703 -0.00454873  0.          0.9522196 ]]. Reward = [0.]
Curr episode timestep = 244
Scene graph at timestep 4744 is [True, False, False, False, False, True]
State prediction error at timestep 4744 is 0.012
Current timestep = 4745. State = [[-0.07196136  0.24421224]]. Action = [[-0.03370593  0.08532069  0.          0.99617434]]. Reward = [0.]
Curr episode timestep = 245
Scene graph at timestep 4745 is [True, False, False, False, False, True]
State prediction error at timestep 4745 is 0.012
Current timestep = 4746. State = [[-0.07354145  0.24763948]]. Action = [[-0.01743428  0.0218906   0.         -0.43761444]]. Reward = [0.]
Curr episode timestep = 246
Scene graph at timestep 4746 is [True, False, False, False, False, True]
State prediction error at timestep 4746 is 0.012
Current timestep = 4747. State = [[-0.07488874  0.250755  ]]. Action = [[-0.01849394  0.04203444  0.         -0.4773723 ]]. Reward = [0.]
Curr episode timestep = 247
Scene graph at timestep 4747 is [True, False, False, False, False, True]
State prediction error at timestep 4747 is 0.012
Current timestep = 4748. State = [[-0.07175492  0.25204772]]. Action = [[ 0.07687049 -0.00692833  0.          0.2469213 ]]. Reward = [0.]
Curr episode timestep = 248
Scene graph at timestep 4748 is [True, False, False, False, False, True]
State prediction error at timestep 4748 is 0.012
Current timestep = 4749. State = [[-0.07071573  0.2547747 ]]. Action = [[-0.0219091   0.05156877  0.          0.06997812]]. Reward = [0.]
Curr episode timestep = 249
Scene graph at timestep 4749 is [True, False, False, False, False, True]
State prediction error at timestep 4749 is 0.012
Current timestep = 4750. State = [[-0.06783307  0.2613633 ]]. Action = [[ 0.07452043  0.0918064   0.         -0.32770026]]. Reward = [0.]
Curr episode timestep = 250
Scene graph at timestep 4750 is [True, False, False, False, False, True]
State prediction error at timestep 4750 is 0.012
Current timestep = 4751. State = [[-0.06467984  0.26019832]]. Action = [[ 0.02374635 -0.09078123  0.          0.9294257 ]]. Reward = [0.]
Curr episode timestep = 251
Scene graph at timestep 4751 is [True, False, False, False, False, True]
State prediction error at timestep 4751 is 0.012
Current timestep = 4752. State = [[-0.06808382  0.2622728 ]]. Action = [[-0.09800243  0.07895982  0.         -0.5818854 ]]. Reward = [0.]
Curr episode timestep = 252
Scene graph at timestep 4752 is [True, False, False, False, False, True]
State prediction error at timestep 4752 is 0.012
Current timestep = 4753. State = [[-0.07255275  0.26624894]]. Action = [[-0.0479018   0.00821879  0.          0.32067657]]. Reward = [0.]
Curr episode timestep = 253
Scene graph at timestep 4753 is [True, False, False, False, False, True]
State prediction error at timestep 4753 is 0.012
Current timestep = 4754. State = [[-0.07012205  0.2679561 ]]. Action = [[0.07923064 0.00039639 0.         0.0985533 ]]. Reward = [0.]
Curr episode timestep = 254
Scene graph at timestep 4754 is [True, False, False, False, False, True]
State prediction error at timestep 4754 is 0.012
Current timestep = 4755. State = [[-0.06785389  0.26610228]]. Action = [[-0.00689668 -0.05755912  0.          0.9510418 ]]. Reward = [0.]
Curr episode timestep = 255
Scene graph at timestep 4755 is [True, False, False, False, False, True]
State prediction error at timestep 4755 is 0.012
Current timestep = 4756. State = [[-0.06424003  0.26941875]]. Action = [[0.06588127 0.08779419 0.         0.77338934]]. Reward = [0.]
Curr episode timestep = 256
Scene graph at timestep 4756 is [True, False, False, False, False, True]
State prediction error at timestep 4756 is 0.012
Current timestep = 4757. State = [[-0.06100304  0.2716384 ]]. Action = [[ 0.02133535 -0.01497503  0.          0.47692895]]. Reward = [0.]
Curr episode timestep = 257
Scene graph at timestep 4757 is [True, False, False, False, False, True]
State prediction error at timestep 4757 is 0.012
Current timestep = 4758. State = [[-0.06128666  0.27466747]]. Action = [[-0.03229569  0.05534769  0.         -0.28752977]]. Reward = [0.]
Curr episode timestep = 258
Scene graph at timestep 4758 is [True, False, False, False, False, True]
State prediction error at timestep 4758 is 0.012
Current timestep = 4759. State = [[-0.05932173  0.2802767 ]]. Action = [[ 0.05100702  0.06534448  0.         -0.24281573]]. Reward = [0.]
Curr episode timestep = 259
Scene graph at timestep 4759 is [True, False, False, False, False, True]
State prediction error at timestep 4759 is 0.012
Current timestep = 4760. State = [[-0.05460569  0.2875014 ]]. Action = [[0.06981913 0.09160476 0.         0.45236945]]. Reward = [0.]
Curr episode timestep = 260
Scene graph at timestep 4760 is [True, False, False, False, False, True]
State prediction error at timestep 4760 is 0.012
Current timestep = 4761. State = [[-0.04898651  0.29406554]]. Action = [[0.08040934 0.06341282 0.         0.30927753]]. Reward = [0.]
Curr episode timestep = 261
Scene graph at timestep 4761 is [False, True, False, False, False, True]
State prediction error at timestep 4761 is 0.012
Current timestep = 4762. State = [[-0.04207039  0.29367176]]. Action = [[ 0.09349477 -0.05968769  0.          0.5623988 ]]. Reward = [0.]
Curr episode timestep = 262
Scene graph at timestep 4762 is [False, True, False, False, False, True]
State prediction error at timestep 4762 is 0.012
Current timestep = 4763. State = [[-0.04174746  0.2971127 ]]. Action = [[-0.06520151  0.09119081  0.         -0.6909679 ]]. Reward = [0.]
Curr episode timestep = 263
Scene graph at timestep 4763 is [False, True, False, False, False, True]
State prediction error at timestep 4763 is 0.012
Current timestep = 4764. State = [[-0.04494807  0.30304047]]. Action = [[-0.0456018   0.03973439  0.         -0.7999196 ]]. Reward = [0.]
Curr episode timestep = 264
Scene graph at timestep 4764 is [False, True, False, False, False, True]
State prediction error at timestep 4764 is 0.012
Current timestep = 4765. State = [[-0.05028811  0.3105999 ]]. Action = [[-0.09409751  0.08543911  0.         -0.4688927 ]]. Reward = [0.]
Curr episode timestep = 265
Scene graph at timestep 4765 is [True, False, False, False, False, True]
State prediction error at timestep 4765 is 0.012
Current timestep = 4766. State = [[-0.05532587  0.3184174 ]]. Action = [[-0.05330813  0.05306495  0.         -0.7145759 ]]. Reward = [0.]
Curr episode timestep = 266
Scene graph at timestep 4766 is [True, False, False, False, False, True]
State prediction error at timestep 4766 is 0.012
Current timestep = 4767. State = [[-0.05359745  0.32514676]]. Action = [[ 0.07949639  0.05024347  0.         -0.9890287 ]]. Reward = [0.]
Curr episode timestep = 267
Scene graph at timestep 4767 is [True, False, False, False, False, True]
State prediction error at timestep 4767 is 0.012
Current timestep = 4768. State = [[-0.05171805  0.33175892]]. Action = [[0.0020576  0.05534659 0.         0.41002798]]. Reward = [0.]
Curr episode timestep = 268
Scene graph at timestep 4768 is [True, False, False, False, False, True]
State prediction error at timestep 4768 is 0.012
Current timestep = 4769. State = [[-0.04746565  0.33157936]]. Action = [[ 0.08360832 -0.08082765  0.         -0.99429744]]. Reward = [0.]
Curr episode timestep = 269
Scene graph at timestep 4769 is [False, True, False, False, False, True]
State prediction error at timestep 4769 is 0.012
Current timestep = 4770. State = [[-0.04115634  0.32651192]]. Action = [[ 0.06771458 -0.08412993  0.         -0.8259963 ]]. Reward = [0.]
Curr episode timestep = 270
Scene graph at timestep 4770 is [False, True, False, False, False, True]
State prediction error at timestep 4770 is 0.012
Current timestep = 4771. State = [[-0.04028188  0.32899255]]. Action = [[-0.04513646  0.08934673  0.          0.26696634]]. Reward = [0.]
Curr episode timestep = 271
Scene graph at timestep 4771 is [False, True, False, False, False, True]
State prediction error at timestep 4771 is 0.012
Current timestep = 4772. State = [[-0.03862246  0.33525965]]. Action = [[ 0.04397594  0.05607563  0.         -0.8625098 ]]. Reward = [0.]
Curr episode timestep = 272
Scene graph at timestep 4772 is [False, True, False, False, False, True]
State prediction error at timestep 4772 is 0.012
Current timestep = 4773. State = [[-0.03987285  0.33366883]]. Action = [[-0.07898627 -0.09462836  0.         -0.34962225]]. Reward = [0.]
Curr episode timestep = 273
Scene graph at timestep 4773 is [False, True, False, False, False, True]
State prediction error at timestep 4773 is 0.012
Current timestep = 4774. State = [[-0.04183738  0.33162338]]. Action = [[-0.01890064 -0.0099906   0.         -0.8808653 ]]. Reward = [0.]
Curr episode timestep = 274
Scene graph at timestep 4774 is [False, True, False, False, False, True]
State prediction error at timestep 4774 is 0.012
Current timestep = 4775. State = [[-0.04624212  0.33687934]]. Action = [[-0.08961317  0.09555682  0.         -0.20524192]]. Reward = [0.]
Curr episode timestep = 275
Scene graph at timestep 4775 is [False, True, False, False, False, True]
State prediction error at timestep 4775 is 0.012
Current timestep = 4776. State = [[-0.04651107  0.33973312]]. Action = [[ 0.04606872 -0.02144475  0.          0.48219895]]. Reward = [0.]
Curr episode timestep = 276
Scene graph at timestep 4776 is [False, True, False, False, False, True]
State prediction error at timestep 4776 is 0.012
Current timestep = 4777. State = [[-0.04080132  0.33955386]]. Action = [[ 0.09842145 -0.00473864  0.          0.67600155]]. Reward = [0.]
Curr episode timestep = 277
Scene graph at timestep 4777 is [False, True, False, False, False, True]
State prediction error at timestep 4777 is 0.012
Current timestep = 4778. State = [[-0.03915998  0.33982214]]. Action = [[-0.02319146  0.00786072  0.          0.6132686 ]]. Reward = [0.]
Curr episode timestep = 278
Scene graph at timestep 4778 is [False, True, False, False, False, True]
State prediction error at timestep 4778 is 0.012
Current timestep = 4779. State = [[-0.04023147  0.3368635 ]]. Action = [[-0.01666822 -0.06749456  0.         -0.4922831 ]]. Reward = [0.]
Curr episode timestep = 279
Scene graph at timestep 4779 is [False, True, False, False, False, True]
State prediction error at timestep 4779 is 0.012
Current timestep = 4780. State = [[-0.03760699  0.33065885]]. Action = [[ 0.05109737 -0.08364551  0.          0.9294951 ]]. Reward = [0.]
Curr episode timestep = 280
Scene graph at timestep 4780 is [False, True, False, False, False, True]
State prediction error at timestep 4780 is 0.012
Current timestep = 4781. State = [[-0.03799732  0.3269384 ]]. Action = [[-0.05441856 -0.01241271  0.         -0.348518  ]]. Reward = [0.]
Curr episode timestep = 281
Scene graph at timestep 4781 is [False, True, False, False, False, True]
State prediction error at timestep 4781 is 0.012
Current timestep = 4782. State = [[-0.04313977  0.33004725]]. Action = [[-0.09210654  0.07706272  0.         -0.9100147 ]]. Reward = [0.]
Curr episode timestep = 282
Scene graph at timestep 4782 is [False, True, False, False, False, True]
State prediction error at timestep 4782 is 0.012
Current timestep = 4783. State = [[-0.04992657  0.33034608]]. Action = [[-0.09374722 -0.04667733  0.          0.3341787 ]]. Reward = [0.]
Curr episode timestep = 283
Scene graph at timestep 4783 is [False, True, False, False, False, True]
State prediction error at timestep 4783 is 0.012
Current timestep = 4784. State = [[-0.04926115  0.32920226]]. Action = [[ 8.261546e-02 -4.518628e-04  0.000000e+00  5.179119e-01]]. Reward = [0.]
Curr episode timestep = 284
Scene graph at timestep 4784 is [False, True, False, False, False, True]
State prediction error at timestep 4784 is 0.012
Current timestep = 4785. State = [[-0.04490181  0.3257105 ]]. Action = [[ 0.04119767 -0.06518663  0.         -0.69985926]]. Reward = [0.]
Curr episode timestep = 285
Scene graph at timestep 4785 is [False, True, False, False, False, True]
State prediction error at timestep 4785 is 0.012
Current timestep = 4786. State = [[-0.04626407  0.3200684 ]]. Action = [[-0.07382465 -0.07028958  0.          0.13624752]]. Reward = [0.]
Curr episode timestep = 286
Scene graph at timestep 4786 is [False, True, False, False, False, True]
State prediction error at timestep 4786 is 0.012
Current timestep = 4787. State = [[-0.04479151  0.31562114]]. Action = [[ 0.05969437 -0.03520376  0.          0.6257591 ]]. Reward = [0.]
Curr episode timestep = 287
Scene graph at timestep 4787 is [False, True, False, False, False, True]
State prediction error at timestep 4787 is 0.012
Current timestep = 4788. State = [[-0.04037469  0.31801492]]. Action = [[ 0.05110156  0.09270903  0.         -0.6901676 ]]. Reward = [0.]
Curr episode timestep = 288
Scene graph at timestep 4788 is [False, True, False, False, False, True]
State prediction error at timestep 4788 is 0.012
Current timestep = 4789. State = [[-0.03593878  0.3187849 ]]. Action = [[ 0.06357067 -0.01445044  0.          0.852705  ]]. Reward = [0.]
Curr episode timestep = 289
Scene graph at timestep 4789 is [False, True, False, False, False, True]
State prediction error at timestep 4789 is 0.012
Current timestep = 4790. State = [[-0.03666154  0.316822  ]]. Action = [[-0.0604779  -0.01699696  0.         -0.08330536]]. Reward = [0.]
Curr episode timestep = 290
Scene graph at timestep 4790 is [False, True, False, False, False, True]
State prediction error at timestep 4790 is 0.012
Current timestep = 4791. State = [[-0.03397873  0.3153457 ]]. Action = [[ 0.09327241 -0.00135843  0.          0.5081997 ]]. Reward = [0.]
Curr episode timestep = 291
Scene graph at timestep 4791 is [False, True, False, False, False, True]
State prediction error at timestep 4791 is 0.012
Current timestep = 4792. State = [[-0.03389585  0.31212035]]. Action = [[-0.06675027 -0.04981522  0.          0.7475774 ]]. Reward = [0.]
Curr episode timestep = 292
Scene graph at timestep 4792 is [False, True, False, False, False, True]
State prediction error at timestep 4792 is 0.012
Current timestep = 4793. State = [[-0.03612861  0.30711034]]. Action = [[-0.02021897 -0.05981375  0.         -0.0107097 ]]. Reward = [0.]
Curr episode timestep = 293
Scene graph at timestep 4793 is [False, True, False, False, False, True]
State prediction error at timestep 4793 is 0.012
Current timestep = 4794. State = [[-0.03375001  0.30294737]]. Action = [[ 0.05574154 -0.0297192   0.          0.899724  ]]. Reward = [0.]
Curr episode timestep = 294
Scene graph at timestep 4794 is [False, True, False, False, False, True]
State prediction error at timestep 4794 is 0.012
Current timestep = 4795. State = [[-0.03104554  0.30077574]]. Action = [[0.02087204 0.00032505 0.         0.0738101 ]]. Reward = [0.]
Curr episode timestep = 295
Scene graph at timestep 4795 is [False, True, False, False, False, True]
State prediction error at timestep 4795 is 0.012
Current timestep = 4796. State = [[-0.02733013  0.2947879 ]]. Action = [[ 0.05775531 -0.09225764  0.          0.76098084]]. Reward = [0.]
Curr episode timestep = 296
Scene graph at timestep 4796 is [False, True, False, False, False, True]
State prediction error at timestep 4796 is 0.012
Current timestep = 4797. State = [[-0.02225211  0.28849512]]. Action = [[ 0.06042347 -0.03618988  0.         -0.16790915]]. Reward = [0.]
Curr episode timestep = 297
Scene graph at timestep 4797 is [False, True, False, False, False, True]
State prediction error at timestep 4797 is 0.012
Current timestep = 4798. State = [[-0.0200641   0.28500506]]. Action = [[-0.00304747 -0.00605206  0.          0.660553  ]]. Reward = [0.]
Curr episode timestep = 298
Scene graph at timestep 4798 is [False, True, False, False, False, True]
State prediction error at timestep 4798 is 0.012
Current timestep = 4799. State = [[-0.01567056  0.28378767]]. Action = [[0.08114094 0.01971216 0.         0.25548863]]. Reward = [0.]
Curr episode timestep = 299
Scene graph at timestep 4799 is [False, True, False, False, False, True]
State prediction error at timestep 4799 is 0.012
Current timestep = 4800. State = [[-0.01155872  0.2799475 ]]. Action = [[ 0.02973407 -0.04839049  0.         -0.05805397]]. Reward = [0.]
Curr episode timestep = 300
Scene graph at timestep 4800 is [False, True, False, False, False, True]
State prediction error at timestep 4800 is 0.012
Current timestep = 4801. State = [[-0.0072802   0.27981144]]. Action = [[0.05797251 0.06297336 0.         0.1838044 ]]. Reward = [0.]
Curr episode timestep = 301
Scene graph at timestep 4801 is [False, True, False, False, False, True]
State prediction error at timestep 4801 is 0.012
Current timestep = 4802. State = [[-0.00309302  0.27648142]]. Action = [[ 0.04349809 -0.06872939  0.          0.93389773]]. Reward = [0.]
Curr episode timestep = 302
Scene graph at timestep 4802 is [False, True, False, False, False, True]
State prediction error at timestep 4802 is 0.012
Current timestep = 4803. State = [[0.00234165 0.27291006]]. Action = [[ 0.06997729 -0.00028732  0.         -0.08044147]]. Reward = [0.]
Curr episode timestep = 303
Scene graph at timestep 4803 is [False, True, False, False, False, True]
State prediction error at timestep 4803 is 0.012
Current timestep = 4804. State = [[0.00834652 0.27344665]]. Action = [[ 0.06987821  0.0471297   0.         -0.56672853]]. Reward = [0.]
Curr episode timestep = 304
Scene graph at timestep 4804 is [False, True, False, False, False, True]
State prediction error at timestep 4804 is 0.012
Current timestep = 4805. State = [[0.01125985 0.2732633 ]]. Action = [[ 0.00604004 -0.00418877  0.         -0.8658227 ]]. Reward = [0.]
Curr episode timestep = 305
Scene graph at timestep 4805 is [False, True, False, False, False, True]
State prediction error at timestep 4805 is 0.012
Current timestep = 4806. State = [[0.01634296 0.27477172]]. Action = [[0.08585577 0.05102389 0.         0.69064355]]. Reward = [0.]
Curr episode timestep = 306
Scene graph at timestep 4806 is [False, True, False, False, False, True]
State prediction error at timestep 4806 is 0.012
Current timestep = 4807. State = [[0.02223508 0.27339026]]. Action = [[ 0.05877673 -0.0400974   0.          0.30222797]]. Reward = [0.]
Curr episode timestep = 307
Scene graph at timestep 4807 is [False, True, False, False, False, True]
State prediction error at timestep 4807 is 0.012
Current timestep = 4808. State = [[0.02162837 0.2760165 ]]. Action = [[-0.07354339  0.08480605  0.         -0.907025  ]]. Reward = [0.]
Curr episode timestep = 308
Scene graph at timestep 4808 is [False, True, False, False, False, True]
State prediction error at timestep 4808 is 0.012
Current timestep = 4809. State = [[0.01866233 0.2759891 ]]. Action = [[-0.05079241 -0.05909287  0.          0.30245376]]. Reward = [0.]
Curr episode timestep = 309
Scene graph at timestep 4809 is [False, True, False, False, False, True]
State prediction error at timestep 4809 is 0.012
Current timestep = 4810. State = [[0.02120761 0.27428335]]. Action = [[ 0.05726188 -0.01474983  0.         -0.30660725]]. Reward = [0.]
Curr episode timestep = 310
Scene graph at timestep 4810 is [False, True, False, False, False, True]
State prediction error at timestep 4810 is 0.012
Current timestep = 4811. State = [[0.026837  0.2773885]]. Action = [[0.06135162 0.06639374 0.         0.8014152 ]]. Reward = [0.]
Curr episode timestep = 311
Scene graph at timestep 4811 is [False, True, False, False, False, True]
State prediction error at timestep 4811 is 0.012
Current timestep = 4812. State = [[0.02685941 0.27719197]]. Action = [[-0.07229878 -0.05531417  0.          0.8564632 ]]. Reward = [0.]
Curr episode timestep = 312
Scene graph at timestep 4812 is [False, True, False, False, False, True]
State prediction error at timestep 4812 is 0.012
Current timestep = 4813. State = [[0.0268148 0.2786947]]. Action = [[ 0.01719634  0.04785495  0.         -0.82544965]]. Reward = [0.]
Curr episode timestep = 313
Scene graph at timestep 4813 is [False, True, False, False, False, True]
State prediction error at timestep 4813 is 0.012
Current timestep = 4814. State = [[0.03038669 0.28539264]]. Action = [[ 0.05827831  0.09663715  0.         -0.05682999]]. Reward = [0.]
Curr episode timestep = 314
Scene graph at timestep 4814 is [False, True, False, False, False, True]
State prediction error at timestep 4814 is 0.012
Current timestep = 4815. State = [[0.03588128 0.29256955]]. Action = [[ 0.08825039  0.0752487   0.         -0.4859863 ]]. Reward = [0.]
Curr episode timestep = 315
Scene graph at timestep 4815 is [False, True, False, False, False, True]
State prediction error at timestep 4815 is 0.012
Current timestep = 4816. State = [[0.03780758 0.29690748]]. Action = [[-0.00604919  0.02609795  0.         -0.39142394]]. Reward = [0.]
Curr episode timestep = 316
Scene graph at timestep 4816 is [False, True, False, False, False, True]
State prediction error at timestep 4816 is 0.012
Current timestep = 4817. State = [[0.03821647 0.29902276]]. Action = [[0.01099231 0.00624256 0.         0.65479803]]. Reward = [0.]
Curr episode timestep = 317
Scene graph at timestep 4817 is [False, True, False, False, False, True]
State prediction error at timestep 4817 is 0.012
Current timestep = 4818. State = [[0.04279628 0.29992872]]. Action = [[ 0.0875501  -0.00188536  0.          0.46954072]]. Reward = [0.]
Curr episode timestep = 318
Scene graph at timestep 4818 is [False, True, False, False, False, True]
State prediction error at timestep 4818 is 0.012
Current timestep = 4819. State = [[0.04791954 0.30176258]]. Action = [[ 0.05515864  0.03082477  0.         -0.48748106]]. Reward = [0.]
Curr episode timestep = 319
Scene graph at timestep 4819 is [False, True, False, False, False, True]
State prediction error at timestep 4819 is 0.012
Current timestep = 4820. State = [[0.04813417 0.3014818 ]]. Action = [[-0.04419521 -0.03318984  0.          0.96558774]]. Reward = [0.]
Curr episode timestep = 320
Scene graph at timestep 4820 is [False, True, False, False, False, True]
State prediction error at timestep 4820 is 0.012
Current timestep = 4821. State = [[0.04411598 0.29874164]]. Action = [[-0.08762549 -0.05224523  0.         -0.6109681 ]]. Reward = [0.]
Curr episode timestep = 321
Scene graph at timestep 4821 is [False, True, False, False, False, True]
State prediction error at timestep 4821 is 0.012
Current timestep = 4822. State = [[0.04392993 0.29637155]]. Action = [[ 0.01640165 -0.03220339  0.         -0.8562213 ]]. Reward = [0.]
Curr episode timestep = 322
Scene graph at timestep 4822 is [False, True, False, False, False, True]
State prediction error at timestep 4822 is 0.012
Current timestep = 4823. State = [[0.04159522 0.29485038]]. Action = [[-0.09065206 -0.02420253  0.         -0.12408084]]. Reward = [0.]
Curr episode timestep = 323
Scene graph at timestep 4823 is [False, True, False, False, False, True]
State prediction error at timestep 4823 is 0.012
Current timestep = 4824. State = [[0.04024555 0.2944876 ]]. Action = [[-0.01199243 -0.00886437  0.          0.48000896]]. Reward = [0.]
Curr episode timestep = 324
Scene graph at timestep 4824 is [False, True, False, False, False, True]
State prediction error at timestep 4824 is 0.012
Current timestep = 4825. State = [[0.0389775  0.29675806]]. Action = [[-0.0432841   0.0355373   0.          0.92737365]]. Reward = [0.]
Curr episode timestep = 325
Scene graph at timestep 4825 is [False, True, False, False, False, True]
State prediction error at timestep 4825 is 0.012
Current timestep = 4826. State = [[0.03828948 0.29451025]]. Action = [[-0.01265785 -0.08373366  0.          0.22045743]]. Reward = [0.]
Curr episode timestep = 326
Scene graph at timestep 4826 is [False, True, False, False, False, True]
State prediction error at timestep 4826 is 0.012
Current timestep = 4827. State = [[0.04254238 0.29137945]]. Action = [[ 0.08054916 -0.01967444  0.         -0.06827259]]. Reward = [0.]
Curr episode timestep = 327
Scene graph at timestep 4827 is [False, True, False, False, False, True]
State prediction error at timestep 4827 is 0.012
Current timestep = 4828. State = [[0.04828298 0.29260692]]. Action = [[0.06641368 0.04871707 0.         0.03907967]]. Reward = [0.]
Curr episode timestep = 328
Scene graph at timestep 4828 is [False, True, False, False, False, True]
State prediction error at timestep 4828 is 0.012
Current timestep = 4829. State = [[0.05300261 0.2957862 ]]. Action = [[0.06080548 0.05097211 0.         0.6518085 ]]. Reward = [0.]
Curr episode timestep = 329
Scene graph at timestep 4829 is [False, False, True, False, False, True]
State prediction error at timestep 4829 is 0.012
Current timestep = 4830. State = [[0.05506008 0.30043796]]. Action = [[ 0.01464657  0.07442673  0.         -0.88914746]]. Reward = [0.]
Curr episode timestep = 330
Scene graph at timestep 4830 is [False, False, True, False, False, True]
State prediction error at timestep 4830 is 0.012
Current timestep = 4831. State = [[0.05534572 0.30048534]]. Action = [[ 0.00208445 -0.0402017   0.         -0.55428404]]. Reward = [0.]
Curr episode timestep = 331
Scene graph at timestep 4831 is [False, False, True, False, False, True]
State prediction error at timestep 4831 is 0.012
Current timestep = 4832. State = [[0.05206859 0.29880297]]. Action = [[-0.0779653  -0.01443731  0.         -0.7964528 ]]. Reward = [0.]
Curr episode timestep = 332
Scene graph at timestep 4832 is [False, False, True, False, False, True]
State prediction error at timestep 4832 is 0.012
Current timestep = 4833. State = [[0.05201362 0.29867047]]. Action = [[ 0.03568269  0.00286237  0.         -0.54788226]]. Reward = [0.]
Curr episode timestep = 333
Scene graph at timestep 4833 is [False, False, True, False, False, True]
State prediction error at timestep 4833 is 0.012
Current timestep = 4834. State = [[0.05477101 0.29954895]]. Action = [[ 0.03313815  0.01540048  0.         -0.9432381 ]]. Reward = [0.]
Curr episode timestep = 334
Scene graph at timestep 4834 is [False, False, True, False, False, True]
State prediction error at timestep 4834 is 0.012
Current timestep = 4835. State = [[0.05304832 0.29937515]]. Action = [[-0.06810646 -0.01697963  0.          0.56388783]]. Reward = [0.]
Curr episode timestep = 335
Scene graph at timestep 4835 is [False, False, True, False, False, True]
State prediction error at timestep 4835 is 0.012
Current timestep = 4836. State = [[0.05488577 0.29968363]]. Action = [[ 0.07916787  0.01462028  0.         -0.8137484 ]]. Reward = [0.]
Curr episode timestep = 336
Scene graph at timestep 4836 is [False, False, True, False, False, True]
State prediction error at timestep 4836 is 0.012
Current timestep = 4837. State = [[0.06074479 0.30041862]]. Action = [[0.07671373 0.01077341 0.         0.80880356]]. Reward = [0.]
Curr episode timestep = 337
Scene graph at timestep 4837 is [False, False, True, False, False, True]
State prediction error at timestep 4837 is 0.012
Current timestep = 4838. State = [[0.06128312 0.30548134]]. Action = [[-0.03575154  0.0994306   0.         -0.46388972]]. Reward = [0.]
Curr episode timestep = 338
Scene graph at timestep 4838 is [False, False, True, False, False, True]
State prediction error at timestep 4838 is 0.012
Current timestep = 4839. State = [[0.06369153 0.3051756 ]]. Action = [[ 0.06660595 -0.06978796  0.          0.13033605]]. Reward = [0.]
Curr episode timestep = 339
Scene graph at timestep 4839 is [False, False, True, False, False, True]
State prediction error at timestep 4839 is 0.012
Current timestep = 4840. State = [[0.0684302  0.30650184]]. Action = [[0.05990251 0.06849597 0.         0.8335998 ]]. Reward = [0.]
Curr episode timestep = 340
Scene graph at timestep 4840 is [False, False, True, False, False, True]
State prediction error at timestep 4840 is 0.012
Current timestep = 4841. State = [[0.07262456 0.30578813]]. Action = [[ 0.05320334 -0.04599122  0.         -0.4474244 ]]. Reward = [0.]
Curr episode timestep = 341
Scene graph at timestep 4841 is [False, False, True, False, False, True]
State prediction error at timestep 4841 is 0.012
Current timestep = 4842. State = [[0.07654813 0.29967815]]. Action = [[ 0.04017533 -0.08724169  0.          0.27914977]]. Reward = [0.]
Curr episode timestep = 342
Scene graph at timestep 4842 is [False, False, True, False, False, True]
State prediction error at timestep 4842 is 0.012
Current timestep = 4843. State = [[0.07691225 0.29919204]]. Action = [[-0.03541862  0.05959683  0.         -0.8820771 ]]. Reward = [0.]
Curr episode timestep = 343
Scene graph at timestep 4843 is [False, False, True, False, False, True]
State prediction error at timestep 4843 is 0.012
Current timestep = 4844. State = [[0.07298037 0.29592973]]. Action = [[-0.09993081 -0.09847191  0.         -0.9257148 ]]. Reward = [0.]
Curr episode timestep = 344
Scene graph at timestep 4844 is [False, False, True, False, False, True]
State prediction error at timestep 4844 is 0.012
Current timestep = 4845. State = [[0.07388896 0.2933874 ]]. Action = [[ 0.0642791   0.01022427  0.         -0.02313834]]. Reward = [0.]
Curr episode timestep = 345
Scene graph at timestep 4845 is [False, False, True, False, False, True]
State prediction error at timestep 4845 is 0.012
Current timestep = 4846. State = [[0.07586595 0.2950369 ]]. Action = [[-0.02190725  0.03301088  0.         -0.4796033 ]]. Reward = [0.]
Curr episode timestep = 346
Scene graph at timestep 4846 is [False, False, True, False, False, True]
State prediction error at timestep 4846 is 0.012
Current timestep = 4847. State = [[0.07980984 0.29876193]]. Action = [[ 0.07024793  0.05312652  0.         -0.040236  ]]. Reward = [0.]
Curr episode timestep = 347
Scene graph at timestep 4847 is [False, False, True, False, False, True]
State prediction error at timestep 4847 is 0.012
Current timestep = 4848. State = [[0.08642803 0.29856014]]. Action = [[ 0.08335479 -0.03533638  0.          0.9102386 ]]. Reward = [0.]
Curr episode timestep = 348
Scene graph at timestep 4848 is [False, False, True, False, False, True]
State prediction error at timestep 4848 is 0.012
Current timestep = 4849. State = [[0.08726797 0.29409418]]. Action = [[-0.08050293 -0.07383643  0.          0.23659551]]. Reward = [0.]
Curr episode timestep = 349
Scene graph at timestep 4849 is [False, False, True, False, False, True]
State prediction error at timestep 4849 is 0.012
Current timestep = 4850. State = [[0.08958019 0.28841758]]. Action = [[ 0.06946781 -0.06188301  0.          0.4632163 ]]. Reward = [0.]
Curr episode timestep = 350
Scene graph at timestep 4850 is [False, False, True, False, False, True]
State prediction error at timestep 4850 is 0.012
Current timestep = 4851. State = [[0.09620044 0.28331995]]. Action = [[ 0.0774251  -0.04258174  0.          0.06383979]]. Reward = [0.]
Curr episode timestep = 351
Scene graph at timestep 4851 is [False, False, True, False, False, True]
State prediction error at timestep 4851 is 0.012
Current timestep = 4852. State = [[0.10279731 0.28273907]]. Action = [[0.07636132 0.04857    0.         0.37591434]]. Reward = [0.]
Curr episode timestep = 352
Scene graph at timestep 4852 is [False, False, True, False, False, True]
State prediction error at timestep 4852 is 0.012
Current timestep = 4853. State = [[0.10860588 0.28441444]]. Action = [[ 0.07270274  0.04178878  0.         -0.08755809]]. Reward = [0.]
Curr episode timestep = 353
Scene graph at timestep 4853 is [False, False, True, False, False, True]
State prediction error at timestep 4853 is 0.012
Current timestep = 4854. State = [[0.11119056 0.28497314]]. Action = [[ 0.00992265  0.01338229  0.         -0.8537009 ]]. Reward = [0.]
Curr episode timestep = 354
Scene graph at timestep 4854 is [False, False, True, False, False, True]
State prediction error at timestep 4854 is 0.012
Current timestep = 4855. State = [[0.109417   0.28441137]]. Action = [[-0.05701762 -0.00361361  0.          0.38522255]]. Reward = [0.]
Curr episode timestep = 355
Scene graph at timestep 4855 is [False, False, True, False, False, True]
State prediction error at timestep 4855 is 0.012
Current timestep = 4856. State = [[0.11165501 0.2846022 ]]. Action = [[ 0.07710429  0.0186132   0.         -0.43653488]]. Reward = [0.]
Curr episode timestep = 356
Scene graph at timestep 4856 is [False, False, True, False, False, True]
State prediction error at timestep 4856 is 0.012
Current timestep = 4857. State = [[0.11362766 0.28342193]]. Action = [[-0.01645673 -0.02697463  0.          0.08622825]]. Reward = [0.]
Curr episode timestep = 357
Scene graph at timestep 4857 is [False, False, True, False, False, True]
State prediction error at timestep 4857 is 0.012
Current timestep = 4858. State = [[0.11307072 0.28437084]]. Action = [[-0.024552    0.03588905  0.         -0.56252414]]. Reward = [0.]
Curr episode timestep = 358
Scene graph at timestep 4858 is [False, False, True, False, False, True]
State prediction error at timestep 4858 is 0.012
Current timestep = 4859. State = [[0.11476414 0.28781655]]. Action = [[0.03413679 0.04343165 0.         0.8713534 ]]. Reward = [0.]
Curr episode timestep = 359
Scene graph at timestep 4859 is [False, False, True, False, False, True]
State prediction error at timestep 4859 is 0.012
Current timestep = 4860. State = [[0.1196261 0.2898688]]. Action = [[0.07871222 0.00909127 0.         0.15436411]]. Reward = [0.]
Curr episode timestep = 360
Scene graph at timestep 4860 is [False, False, True, False, False, True]
State prediction error at timestep 4860 is 0.012
Current timestep = 4861. State = [[0.11885262 0.29090983]]. Action = [[-9.7947478e-02  2.1147728e-04  0.0000000e+00 -7.6777726e-01]]. Reward = [0.]
Curr episode timestep = 361
Scene graph at timestep 4861 is [False, False, True, False, False, True]
State prediction error at timestep 4861 is 0.012
Current timestep = 4862. State = [[0.11664637 0.29367012]]. Action = [[-0.00376353  0.03946122  0.          0.57674766]]. Reward = [0.]
Curr episode timestep = 362
Scene graph at timestep 4862 is [False, False, True, False, False, True]
State prediction error at timestep 4862 is 0.012
Current timestep = 4863. State = [[0.11537175 0.29278037]]. Action = [[-0.0256926  -0.05802182  0.          0.50552917]]. Reward = [0.]
Curr episode timestep = 363
Scene graph at timestep 4863 is [False, False, True, False, False, True]
State prediction error at timestep 4863 is 0.012
Current timestep = 4864. State = [[0.115384   0.29437885]]. Action = [[ 0.00591463  0.05059066  0.         -0.13222677]]. Reward = [0.]
Curr episode timestep = 364
Scene graph at timestep 4864 is [False, False, True, False, False, True]
State prediction error at timestep 4864 is 0.012
Current timestep = 4865. State = [[0.11231977 0.29221925]]. Action = [[-0.09882435 -0.09340312  0.          0.09048772]]. Reward = [0.]
Curr episode timestep = 365
Scene graph at timestep 4865 is [False, False, True, False, False, True]
State prediction error at timestep 4865 is 0.012
Current timestep = 4866. State = [[0.10940423 0.29086483]]. Action = [[-0.02905618  0.0101303   0.         -0.05906606]]. Reward = [0.]
Curr episode timestep = 366
Scene graph at timestep 4866 is [False, False, True, False, False, True]
State prediction error at timestep 4866 is 0.012
Current timestep = 4867. State = [[0.11173926 0.29146838]]. Action = [[ 6.2102892e-02  2.8161705e-04  0.0000000e+00 -7.7094179e-01]]. Reward = [0.]
Curr episode timestep = 367
Scene graph at timestep 4867 is [False, False, True, False, False, True]
State prediction error at timestep 4867 is 0.012
Current timestep = 4868. State = [[0.11030472 0.29440752]]. Action = [[-0.07496474  0.05008591  0.          0.02305722]]. Reward = [0.]
Curr episode timestep = 368
Scene graph at timestep 4868 is [False, False, True, False, False, True]
State prediction error at timestep 4868 is 0.012
Current timestep = 4869. State = [[0.10585866 0.2947525 ]]. Action = [[-0.06078071 -0.03826706  0.         -0.78657454]]. Reward = [0.]
Curr episode timestep = 369
Scene graph at timestep 4869 is [False, False, True, False, False, True]
State prediction error at timestep 4869 is 0.012
Current timestep = 4870. State = [[0.10275092 0.290743  ]]. Action = [[-0.0464185  -0.07563257  0.          0.8029994 ]]. Reward = [0.]
Curr episode timestep = 370
Scene graph at timestep 4870 is [False, False, True, False, False, True]
State prediction error at timestep 4870 is 0.012
Current timestep = 4871. State = [[0.09994179 0.289535  ]]. Action = [[-0.05177234  0.01030929  0.         -0.6909388 ]]. Reward = [0.]
Curr episode timestep = 371
Scene graph at timestep 4871 is [False, False, True, False, False, True]
State prediction error at timestep 4871 is 0.012
Current timestep = 4872. State = [[0.1002152  0.29216754]]. Action = [[0.03024391 0.04045863 0.         0.5907972 ]]. Reward = [0.]
Curr episode timestep = 372
Scene graph at timestep 4872 is [False, False, True, False, False, True]
State prediction error at timestep 4872 is 0.012
Current timestep = 4873. State = [[0.10130798 0.2935955 ]]. Action = [[ 0.0101067  -0.00245484  0.          0.7960985 ]]. Reward = [0.]
Curr episode timestep = 373
Scene graph at timestep 4873 is [False, False, True, False, False, True]
State prediction error at timestep 4873 is 0.012
Current timestep = 4874. State = [[0.10003375 0.29505506]]. Action = [[-0.0285427   0.02363928  0.          0.60779023]]. Reward = [0.]
Curr episode timestep = 374
Scene graph at timestep 4874 is [False, False, True, False, False, True]
State prediction error at timestep 4874 is 0.012
Current timestep = 4875. State = [[0.09568103 0.2974377 ]]. Action = [[-0.0703003   0.02376233  0.          0.4730314 ]]. Reward = [0.]
Curr episode timestep = 375
Scene graph at timestep 4875 is [False, False, True, False, False, True]
State prediction error at timestep 4875 is 0.012
Current timestep = 4876. State = [[0.09649684 0.30034566]]. Action = [[ 0.08945405  0.03697524  0.         -0.22905773]]. Reward = [0.]
Curr episode timestep = 376
Scene graph at timestep 4876 is [False, False, True, False, False, True]
State prediction error at timestep 4876 is 0.012
Current timestep = 4877. State = [[0.09738266 0.29762805]]. Action = [[-0.03196289 -0.08790059  0.         -0.5929374 ]]. Reward = [0.]
Curr episode timestep = 377
Scene graph at timestep 4877 is [False, False, True, False, False, True]
State prediction error at timestep 4877 is 0.012
Current timestep = 4878. State = [[0.09924863 0.29200235]]. Action = [[ 0.05517104 -0.05977247  0.          0.61481285]]. Reward = [0.]
Curr episode timestep = 378
Scene graph at timestep 4878 is [False, False, True, False, False, True]
State prediction error at timestep 4878 is 0.012
Current timestep = 4879. State = [[0.09670123 0.28955483]]. Action = [[-0.09624333 -0.00153726  0.         -0.08544624]]. Reward = [0.]
Curr episode timestep = 379
Scene graph at timestep 4879 is [False, False, True, False, False, True]
State prediction error at timestep 4879 is 0.012
Current timestep = 4880. State = [[0.0912371  0.29289207]]. Action = [[-0.06241905  0.07249675  0.          0.6838044 ]]. Reward = [0.]
Curr episode timestep = 380
Scene graph at timestep 4880 is [False, False, True, False, False, True]
State prediction error at timestep 4880 is 0.012
Current timestep = 4881. State = [[0.08554973 0.29314172]]. Action = [[-0.07599276 -0.04509697  0.          0.16320252]]. Reward = [0.]
Curr episode timestep = 381
Scene graph at timestep 4881 is [False, False, True, False, False, True]
State prediction error at timestep 4881 is 0.012
Current timestep = 4882. State = [[0.07973311 0.29473054]]. Action = [[-0.07537091  0.0427021   0.          0.820812  ]]. Reward = [0.]
Curr episode timestep = 382
Scene graph at timestep 4882 is [False, False, True, False, False, True]
State prediction error at timestep 4882 is 0.012
Current timestep = 4883. State = [[0.07942819 0.29383415]]. Action = [[ 0.05088418 -0.05491083  0.          0.29776347]]. Reward = [0.]
Curr episode timestep = 383
Scene graph at timestep 4883 is [False, False, True, False, False, True]
State prediction error at timestep 4883 is 0.012
Current timestep = 4884. State = [[0.0775208  0.29459628]]. Action = [[-0.05283704  0.04200541  0.         -0.2598896 ]]. Reward = [0.]
Curr episode timestep = 384
Scene graph at timestep 4884 is [False, False, True, False, False, True]
State prediction error at timestep 4884 is 0.012
Current timestep = 4885. State = [[0.07893156 0.29730102]]. Action = [[0.09130066 0.0298254  0.         0.29231954]]. Reward = [0.]
Curr episode timestep = 385
Scene graph at timestep 4885 is [False, False, True, False, False, True]
State prediction error at timestep 4885 is 0.012
Current timestep = 4886. State = [[0.0783372  0.29638934]]. Action = [[-0.05377395 -0.04122793  0.          0.5224596 ]]. Reward = [0.]
Curr episode timestep = 386
Scene graph at timestep 4886 is [False, False, True, False, False, True]
State prediction error at timestep 4886 is 0.012
Current timestep = 4887. State = [[0.0721541  0.29076162]]. Action = [[-0.09193892 -0.0914295   0.          0.13040054]]. Reward = [0.]
Curr episode timestep = 387
Scene graph at timestep 4887 is [False, False, True, False, False, True]
State prediction error at timestep 4887 is 0.012
Current timestep = 4888. State = [[0.06877132 0.29082304]]. Action = [[ 0.00068697  0.06066775  0.         -0.6724989 ]]. Reward = [0.]
Curr episode timestep = 388
Scene graph at timestep 4888 is [False, False, True, False, False, True]
State prediction error at timestep 4888 is 0.012
Current timestep = 4889. State = [[0.07073204 0.29157257]]. Action = [[ 0.06369535 -0.01226351  0.          0.30397773]]. Reward = [0.]
Curr episode timestep = 389
Scene graph at timestep 4889 is [False, False, True, False, False, True]
State prediction error at timestep 4889 is 0.012
Current timestep = 4890. State = [[0.06802201 0.289578  ]]. Action = [[-0.08756599 -0.03072472  0.         -0.15800357]]. Reward = [0.]
Curr episode timestep = 390
Scene graph at timestep 4890 is [False, False, True, False, False, True]
State prediction error at timestep 4890 is 0.012
Current timestep = 4891. State = [[0.06415267 0.2850723 ]]. Action = [[-0.01681145 -0.06534589  0.         -0.23775434]]. Reward = [0.]
Curr episode timestep = 391
Scene graph at timestep 4891 is [False, False, True, False, False, True]
State prediction error at timestep 4891 is 0.012
Current timestep = 4892. State = [[0.06427103 0.28518257]]. Action = [[ 0.03881834  0.05696697  0.         -0.5546557 ]]. Reward = [0.]
Curr episode timestep = 392
Scene graph at timestep 4892 is [False, False, True, False, False, True]
State prediction error at timestep 4892 is 0.012
Current timestep = 4893. State = [[0.06033592 0.288983  ]]. Action = [[-0.07556736  0.05724778  0.          0.92047346]]. Reward = [0.]
Curr episode timestep = 393
Scene graph at timestep 4893 is [False, False, True, False, False, True]
State prediction error at timestep 4893 is 0.012
Current timestep = 4894. State = [[0.05207277 0.29282367]]. Action = [[-0.09783273  0.04005251  0.         -0.73944247]]. Reward = [0.]
Curr episode timestep = 394
Scene graph at timestep 4894 is [False, False, True, False, False, True]
State prediction error at timestep 4894 is 0.012
Current timestep = 4895. State = [[0.04449031 0.29257244]]. Action = [[-0.07099325 -0.04427489  0.          0.91451585]]. Reward = [0.]
Curr episode timestep = 395
Scene graph at timestep 4895 is [False, True, False, False, False, True]
State prediction error at timestep 4895 is 0.012
Current timestep = 4896. State = [[0.0389214  0.29168925]]. Action = [[-0.0465589  -0.00738598  0.         -0.22252905]]. Reward = [0.]
Curr episode timestep = 396
Scene graph at timestep 4896 is [False, True, False, False, False, True]
State prediction error at timestep 4896 is 0.012
Current timestep = 4897. State = [[0.03461755 0.29116657]]. Action = [[-0.03247268 -0.01594021  0.          0.2615769 ]]. Reward = [0.]
Curr episode timestep = 397
Scene graph at timestep 4897 is [False, True, False, False, False, True]
State prediction error at timestep 4897 is 0.012
Current timestep = 4898. State = [[0.0353728 0.2951779]]. Action = [[ 0.08587917  0.08983418  0.         -0.3865733 ]]. Reward = [0.]
Curr episode timestep = 398
Scene graph at timestep 4898 is [False, True, False, False, False, True]
State prediction error at timestep 4898 is 0.012
Current timestep = 4899. State = [[0.03479405 0.29316115]]. Action = [[-0.03216655 -0.09556858  0.         -0.33878767]]. Reward = [0.]
Curr episode timestep = 399
Scene graph at timestep 4899 is [False, True, False, False, False, True]
State prediction error at timestep 4899 is 0.012
Current timestep = 4900. State = [[0.03071449 0.29165718]]. Action = [[-0.03632346  0.02778275  0.          0.2121507 ]]. Reward = [0.]
Curr episode timestep = 400
Scene graph at timestep 4900 is [False, True, False, False, False, True]
State prediction error at timestep 4900 is 0.012
Current timestep = 4901. State = [[0.02445906 0.29342043]]. Action = [[-0.07226475  0.02411638  0.          0.7279873 ]]. Reward = [0.]
Curr episode timestep = 401
Scene graph at timestep 4901 is [False, True, False, False, False, True]
State prediction error at timestep 4901 is 0.012
Current timestep = 4902. State = [[0.01738298 0.29564816]]. Action = [[-0.06942694  0.0247121   0.         -0.95955306]]. Reward = [0.]
Curr episode timestep = 402
Scene graph at timestep 4902 is [False, True, False, False, False, True]
State prediction error at timestep 4902 is 0.012
Current timestep = 4903. State = [[0.01313254 0.2969761 ]]. Action = [[-0.00995231  0.00284942  0.          0.18653071]]. Reward = [0.]
Curr episode timestep = 403
Scene graph at timestep 4903 is [False, True, False, False, False, True]
State prediction error at timestep 4903 is 0.012
Current timestep = 4904. State = [[0.01322717 0.29766545]]. Action = [[ 0.05083484  0.00834262  0.         -0.57846296]]. Reward = [0.]
Curr episode timestep = 404
Scene graph at timestep 4904 is [False, True, False, False, False, True]
State prediction error at timestep 4904 is 0.012
Current timestep = 4905. State = [[0.01671342 0.2966548 ]]. Action = [[ 0.0898835  -0.01592173  0.         -0.01495486]]. Reward = [0.]
Curr episode timestep = 405
Scene graph at timestep 4905 is [False, True, False, False, False, True]
State prediction error at timestep 4905 is 0.012
Current timestep = 4906. State = [[0.01847441 0.29452205]]. Action = [[ 0.02411018 -0.01347984  0.          0.8333738 ]]. Reward = [0.]
Curr episode timestep = 406
Scene graph at timestep 4906 is [False, True, False, False, False, True]
State prediction error at timestep 4906 is 0.012
Current timestep = 4907. State = [[0.01823635 0.29016706]]. Action = [[ 0.0063133  -0.05680157  0.          0.63742864]]. Reward = [0.]
Curr episode timestep = 407
Scene graph at timestep 4907 is [False, True, False, False, False, True]
State prediction error at timestep 4907 is 0.012
Current timestep = 4908. State = [[0.01885286 0.2852466 ]]. Action = [[ 0.02485069 -0.03961363  0.          0.02618802]]. Reward = [0.]
Curr episode timestep = 408
Scene graph at timestep 4908 is [False, True, False, False, False, True]
State prediction error at timestep 4908 is 0.012
Current timestep = 4909. State = [[0.0190795  0.27946016]]. Action = [[-0.00162122 -0.06187618  0.         -0.44042003]]. Reward = [0.]
Curr episode timestep = 409
Scene graph at timestep 4909 is [False, True, False, False, False, True]
State prediction error at timestep 4909 is 0.012
Current timestep = 4910. State = [[0.0206068  0.27948794]]. Action = [[0.03731883 0.07040327 0.         0.816762  ]]. Reward = [0.]
Curr episode timestep = 410
Scene graph at timestep 4910 is [False, True, False, False, False, True]
State prediction error at timestep 4910 is 0.012
Current timestep = 4911. State = [[0.01677872 0.282642  ]]. Action = [[-0.09973927  0.04624524  0.          0.75988626]]. Reward = [0.]
Curr episode timestep = 411
Scene graph at timestep 4911 is [False, True, False, False, False, True]
State prediction error at timestep 4911 is 0.012
Current timestep = 4912. State = [[0.01089139 0.27922615]]. Action = [[-0.06288634 -0.09151544  0.          0.34397423]]. Reward = [0.]
Curr episode timestep = 412
Scene graph at timestep 4912 is [False, True, False, False, False, True]
State prediction error at timestep 4912 is 0.012
Current timestep = 4913. State = [[0.01153575 0.27512273]]. Action = [[ 0.06247558 -0.02070681  0.          0.28116095]]. Reward = [0.]
Curr episode timestep = 413
Scene graph at timestep 4913 is [False, True, False, False, False, True]
State prediction error at timestep 4913 is 0.012
Current timestep = 4914. State = [[0.01392564 0.27727836]]. Action = [[0.02304395 0.07358264 0.         0.60691357]]. Reward = [0.]
Curr episode timestep = 414
Scene graph at timestep 4914 is [False, True, False, False, False, True]
State prediction error at timestep 4914 is 0.012
Current timestep = 4915. State = [[0.01327498 0.2791831 ]]. Action = [[-0.0179036   0.00511836  0.         -0.44584548]]. Reward = [0.]
Curr episode timestep = 415
Scene graph at timestep 4915 is [False, True, False, False, False, True]
State prediction error at timestep 4915 is 0.012
Current timestep = 4916. State = [[0.01015276 0.28081468]]. Action = [[-0.04901114  0.02811056  0.         -0.70360774]]. Reward = [0.]
Curr episode timestep = 416
Scene graph at timestep 4916 is [False, True, False, False, False, True]
State prediction error at timestep 4916 is 0.012
Current timestep = 4917. State = [[0.00650994 0.28274715]]. Action = [[-0.04176437  0.01375456  0.          0.01422572]]. Reward = [0.]
Curr episode timestep = 417
Scene graph at timestep 4917 is [False, True, False, False, False, True]
State prediction error at timestep 4917 is 0.012
Current timestep = 4918. State = [[0.0038571  0.28248873]]. Action = [[-0.02517845 -0.02766679  0.          0.5761366 ]]. Reward = [0.]
Curr episode timestep = 418
Scene graph at timestep 4918 is [False, True, False, False, False, True]
State prediction error at timestep 4918 is 0.012
Current timestep = 4919. State = [[0.00309445 0.27837005]]. Action = [[ 2.5679916e-04 -7.7960715e-02  0.0000000e+00  6.3616085e-01]]. Reward = [0.]
Curr episode timestep = 419
Scene graph at timestep 4919 is [False, True, False, False, False, True]
State prediction error at timestep 4919 is 0.012
Current timestep = 4920. State = [[0.00579609 0.28054565]]. Action = [[ 0.06428465  0.09111824  0.         -0.05033922]]. Reward = [0.]
Curr episode timestep = 420
Scene graph at timestep 4920 is [False, True, False, False, False, True]
State prediction error at timestep 4920 is 0.012
Current timestep = 4921. State = [[0.00749832 0.2802369 ]]. Action = [[ 0.00931378 -0.0556152   0.          0.9127476 ]]. Reward = [0.]
Curr episode timestep = 421
Scene graph at timestep 4921 is [False, True, False, False, False, True]
State prediction error at timestep 4921 is 0.012
Current timestep = 4922. State = [[0.00393063 0.27829581]]. Action = [[-0.08270423 -0.00966702  0.         -0.97805727]]. Reward = [0.]
Curr episode timestep = 422
Scene graph at timestep 4922 is [False, True, False, False, False, True]
State prediction error at timestep 4922 is 0.012
Current timestep = 4923. State = [[1.6616992e-04 2.8291479e-01]]. Action = [[-0.03108531  0.09351742  0.         -0.2734961 ]]. Reward = [0.]
Curr episode timestep = 423
Scene graph at timestep 4923 is [False, True, False, False, False, True]
State prediction error at timestep 4923 is 0.012
Current timestep = 4924. State = [[0.00133461 0.2835156 ]]. Action = [[ 0.05494749 -0.0512977   0.         -0.60383725]]. Reward = [0.]
Curr episode timestep = 424
Scene graph at timestep 4924 is [False, True, False, False, False, True]
State prediction error at timestep 4924 is 0.012
Current timestep = 4925. State = [[-0.001371    0.28438085]]. Action = [[-0.08055643  0.03918076  0.         -0.0016315 ]]. Reward = [0.]
Curr episode timestep = 425
Scene graph at timestep 4925 is [False, True, False, False, False, True]
State prediction error at timestep 4925 is 0.012
Current timestep = 4926. State = [[-0.0020785   0.28453884]]. Action = [[ 0.04012946 -0.02739304  0.         -0.58507776]]. Reward = [0.]
Curr episode timestep = 426
Scene graph at timestep 4926 is [False, True, False, False, False, True]
State prediction error at timestep 4926 is 0.012
Current timestep = 4927. State = [[0.00102777 0.28558794]]. Action = [[ 0.05724875  0.03558557  0.         -0.8943571 ]]. Reward = [0.]
Curr episode timestep = 427
Scene graph at timestep 4927 is [False, True, False, False, False, True]
State prediction error at timestep 4927 is 0.012
Current timestep = 4928. State = [[0.00221796 0.29120725]]. Action = [[0.01137708 0.09676161 0.         0.36659026]]. Reward = [0.]
Curr episode timestep = 428
Scene graph at timestep 4928 is [False, True, False, False, False, True]
State prediction error at timestep 4928 is 0.012
Current timestep = 4929. State = [[0.0057876  0.28947946]]. Action = [[ 0.0853345  -0.09122075  0.          0.639045  ]]. Reward = [0.]
Curr episode timestep = 429
Scene graph at timestep 4929 is [False, True, False, False, False, True]
State prediction error at timestep 4929 is 0.012
Current timestep = 4930. State = [[0.00715442 0.28459087]]. Action = [[-0.01540596 -0.03918186  0.         -0.04916275]]. Reward = [0.]
Curr episode timestep = 430
Scene graph at timestep 4930 is [False, True, False, False, False, True]
State prediction error at timestep 4930 is 0.012
Current timestep = 4931. State = [[0.00716678 0.28649455]]. Action = [[0.00747786 0.0737155  0.         0.34397614]]. Reward = [0.]
Curr episode timestep = 431
Scene graph at timestep 4931 is [False, True, False, False, False, True]
State prediction error at timestep 4931 is 0.012
Current timestep = 4932. State = [[0.01082557 0.28545484]]. Action = [[ 0.07627644 -0.05364419  0.         -0.29948962]]. Reward = [0.]
Curr episode timestep = 432
Scene graph at timestep 4932 is [False, True, False, False, False, True]
State prediction error at timestep 4932 is 0.012
Current timestep = 4933. State = [[0.01211781 0.27927044]]. Action = [[-0.02557626 -0.08243273  0.         -0.24769396]]. Reward = [0.]
Curr episode timestep = 433
Scene graph at timestep 4933 is [False, True, False, False, False, True]
State prediction error at timestep 4933 is 0.012
Current timestep = 4934. State = [[0.00871099 0.27369595]]. Action = [[-0.07933019 -0.05042115  0.          0.06515372]]. Reward = [0.]
Curr episode timestep = 434
Scene graph at timestep 4934 is [False, True, False, False, False, True]
State prediction error at timestep 4934 is 0.012
Current timestep = 4935. State = [[0.00612725 0.2680445 ]]. Action = [[-0.03591763 -0.0722097   0.          0.08766079]]. Reward = [0.]
Curr episode timestep = 435
Scene graph at timestep 4935 is [False, True, False, False, False, True]
State prediction error at timestep 4935 is 0.012
Current timestep = 4936. State = [[0.00744114 0.2620849 ]]. Action = [[ 0.02465029 -0.06031319  0.          0.2099272 ]]. Reward = [0.]
Curr episode timestep = 436
Scene graph at timestep 4936 is [False, True, False, False, False, True]
State prediction error at timestep 4936 is 0.012
Current timestep = 4937. State = [[0.00620982 0.2587807 ]]. Action = [[-0.06050375 -0.00808661  0.         -0.2874571 ]]. Reward = [0.]
Curr episode timestep = 437
Scene graph at timestep 4937 is [False, True, False, False, False, True]
State prediction error at timestep 4937 is 0.012
Current timestep = 4938. State = [[0.00418656 0.2538269 ]]. Action = [[-0.02957396 -0.07566057  0.         -0.741699  ]]. Reward = [0.]
Curr episode timestep = 438
Scene graph at timestep 4938 is [False, True, False, False, False, True]
State prediction error at timestep 4938 is 0.012
Current timestep = 4939. State = [[0.00696263 0.24621058]]. Action = [[ 0.05796986 -0.08359239  0.         -0.3712597 ]]. Reward = [0.]
Curr episode timestep = 439
Scene graph at timestep 4939 is [False, True, False, False, False, True]
State prediction error at timestep 4939 is 0.012
Current timestep = 4940. State = [[0.01229428 0.23763466]]. Action = [[ 0.06425264 -0.08175657  0.          0.7326219 ]]. Reward = [0.]
Curr episode timestep = 440
Scene graph at timestep 4940 is [False, True, False, False, False, True]
State prediction error at timestep 4940 is 0.012
Current timestep = 4941. State = [[0.01774418 0.23216148]]. Action = [[ 0.06489836 -0.00878457  0.         -0.12460071]]. Reward = [0.]
Curr episode timestep = 441
Scene graph at timestep 4941 is [False, True, False, False, False, True]
State prediction error at timestep 4941 is 0.012
Current timestep = 4942. State = [[0.01959543 0.23104362]]. Action = [[-0.00493872  0.03744989  0.         -0.2760496 ]]. Reward = [0.]
Curr episode timestep = 442
Scene graph at timestep 4942 is [False, True, False, False, False, True]
State prediction error at timestep 4942 is 0.012
Current timestep = 4943. State = [[0.02209377 0.22753625]]. Action = [[ 0.05011072 -0.04756865  0.         -0.23921847]]. Reward = [0.]
Curr episode timestep = 443
Scene graph at timestep 4943 is [False, True, False, False, False, True]
State prediction error at timestep 4943 is 0.012
Current timestep = 4944. State = [[0.02622834 0.22658633]]. Action = [[0.05813948 0.05205841 0.         0.2844057 ]]. Reward = [0.]
Curr episode timestep = 444
Scene graph at timestep 4944 is [False, True, False, False, False, True]
State prediction error at timestep 4944 is 0.012
Current timestep = 4945. State = [[0.02758611 0.2258745 ]]. Action = [[-0.00108021 -0.0059812   0.          0.9198401 ]]. Reward = [0.]
Curr episode timestep = 445
Scene graph at timestep 4945 is [False, True, False, False, False, True]
State prediction error at timestep 4945 is 0.012
Current timestep = 4946. State = [[0.03083184 0.22872537]]. Action = [[ 0.07335829  0.08793203  0.         -0.77548885]]. Reward = [0.]
Curr episode timestep = 446
Scene graph at timestep 4946 is [False, True, False, False, False, True]
State prediction error at timestep 4946 is 0.012
Current timestep = 4947. State = [[0.03394961 0.22932631]]. Action = [[ 0.03365579 -0.01837073  0.         -0.36049652]]. Reward = [0.]
Curr episode timestep = 447
Scene graph at timestep 4947 is [False, True, False, False, False, True]
State prediction error at timestep 4947 is 0.012
Current timestep = 4948. State = [[0.03709167 0.22891979]]. Action = [[ 0.0480468   0.01604231  0.         -0.5184789 ]]. Reward = [0.]
Curr episode timestep = 448
Scene graph at timestep 4948 is [False, True, False, False, False, True]
State prediction error at timestep 4948 is 0.012
Current timestep = 4949. State = [[0.0399039  0.23065673]]. Action = [[0.03317408 0.03847446 0.         0.45615375]]. Reward = [0.]
Curr episode timestep = 449
Scene graph at timestep 4949 is [False, True, False, False, False, True]
State prediction error at timestep 4949 is 0.012
Current timestep = 4950. State = [[0.04164928 0.23440701]]. Action = [[0.01885559 0.05730393 0.         0.4744662 ]]. Reward = [0.]
Curr episode timestep = 450
Scene graph at timestep 4950 is [False, True, False, False, False, True]
State prediction error at timestep 4950 is 0.012
Current timestep = 4951. State = [[0.04093895 0.2400047 ]]. Action = [[-0.02477127  0.07157194  0.          0.00605154]]. Reward = [0.]
Curr episode timestep = 451
Scene graph at timestep 4951 is [False, True, False, False, False, True]
State prediction error at timestep 4951 is 0.012
Current timestep = 4952. State = [[0.04206045 0.24044229]]. Action = [[ 0.0332334  -0.05137142  0.         -0.2881651 ]]. Reward = [0.]
Curr episode timestep = 452
Scene graph at timestep 4952 is [False, True, False, False, False, True]
State prediction error at timestep 4952 is 0.012
Current timestep = 4953. State = [[0.04560519 0.24459411]]. Action = [[ 0.04989516  0.09702668  0.         -0.56015664]]. Reward = [0.]
Curr episode timestep = 453
Scene graph at timestep 4953 is [False, True, False, False, False, True]
State prediction error at timestep 4953 is 0.012
Current timestep = 4954. State = [[0.04437843 0.2511054 ]]. Action = [[-0.06006768  0.05299897  0.         -0.69019055]]. Reward = [0.]
Curr episode timestep = 454
Scene graph at timestep 4954 is [False, True, False, False, False, True]
State prediction error at timestep 4954 is 0.012
Current timestep = 4955. State = [[0.04277787 0.25409254]]. Action = [[-0.00583369 -0.0062963   0.          0.48717713]]. Reward = [0.]
Curr episode timestep = 455
Scene graph at timestep 4955 is [False, True, False, False, False, True]
State prediction error at timestep 4955 is 0.012
Current timestep = 4956. State = [[0.04355978 0.25995582]]. Action = [[ 0.01742287  0.08630513  0.         -0.24860287]]. Reward = [0.]
Curr episode timestep = 456
Scene graph at timestep 4956 is [False, True, False, False, False, True]
State prediction error at timestep 4956 is 0.012
Current timestep = 4957. State = [[0.04056227 0.26627997]]. Action = [[-0.07418229  0.03735309  0.          0.24064457]]. Reward = [0.]
Curr episode timestep = 457
Scene graph at timestep 4957 is [False, True, False, False, False, True]
State prediction error at timestep 4957 is 0.012
Current timestep = 4958. State = [[0.03993662 0.27447116]]. Action = [[ 0.03539211  0.09560689  0.         -0.9783287 ]]. Reward = [0.]
Curr episode timestep = 458
Scene graph at timestep 4958 is [False, True, False, False, False, True]
State prediction error at timestep 4958 is 0.012
Current timestep = 4959. State = [[0.04404632 0.27639434]]. Action = [[ 0.07411506 -0.06040057  0.          0.44709182]]. Reward = [0.]
Curr episode timestep = 459
Scene graph at timestep 4959 is [False, True, False, False, False, True]
State prediction error at timestep 4959 is 0.012
Current timestep = 4960. State = [[0.04445894 0.28068617]]. Action = [[-0.03400388  0.08768111  0.         -0.28283894]]. Reward = [0.]
Curr episode timestep = 460
Scene graph at timestep 4960 is [False, True, False, False, False, True]
State prediction error at timestep 4960 is 0.012
Current timestep = 4961. State = [[0.04813126 0.28486234]]. Action = [[0.09928431 0.00096107 0.         0.90612245]]. Reward = [0.]
Curr episode timestep = 461
Scene graph at timestep 4961 is [False, True, False, False, False, True]
State prediction error at timestep 4961 is 0.012
Current timestep = 4962. State = [[0.04943647 0.28374255]]. Action = [[-0.04579953 -0.05496116  0.         -0.44999087]]. Reward = [0.]
Curr episode timestep = 462
Scene graph at timestep 4962 is [False, True, False, False, False, True]
State prediction error at timestep 4962 is 0.012
Current timestep = 4963. State = [[0.04616257 0.28533027]]. Action = [[-0.0595412   0.03917991  0.          0.18156254]]. Reward = [0.]
Curr episode timestep = 463
Scene graph at timestep 4963 is [False, True, False, False, False, True]
State prediction error at timestep 4963 is 0.012
Current timestep = 4964. State = [[0.04905314 0.28704605]]. Action = [[ 0.09592815 -0.00587063  0.          0.39374042]]. Reward = [0.]
Curr episode timestep = 464
Scene graph at timestep 4964 is [False, True, False, False, False, True]
State prediction error at timestep 4964 is 0.012
Current timestep = 4965. State = [[0.05005077 0.2829008 ]]. Action = [[-0.06645367 -0.09884493  0.          0.85484326]]. Reward = [0.]
Curr episode timestep = 465
Scene graph at timestep 4965 is [False, False, True, False, False, True]
State prediction error at timestep 4965 is 0.012
Current timestep = 4966. State = [[0.05188831 0.2767442 ]]. Action = [[ 0.05182254 -0.07000241  0.          0.00076485]]. Reward = [0.]
Curr episode timestep = 466
Scene graph at timestep 4966 is [False, False, True, False, False, True]
State prediction error at timestep 4966 is 0.012
Current timestep = 4967. State = [[0.05129429 0.2739205 ]]. Action = [[-0.06633462 -0.00557247  0.          0.20292151]]. Reward = [0.]
Curr episode timestep = 467
Scene graph at timestep 4967 is [False, False, True, False, False, True]
State prediction error at timestep 4967 is 0.012
Current timestep = 4968. State = [[0.05471119 0.26877478]]. Action = [[ 0.08991732 -0.08485121  0.          0.7090733 ]]. Reward = [0.]
Curr episode timestep = 468
Scene graph at timestep 4968 is [False, False, True, False, False, True]
State prediction error at timestep 4968 is 0.012
Current timestep = 4969. State = [[0.05852033 0.26871964]]. Action = [[ 0.00967357  0.07536795  0.         -0.8309622 ]]. Reward = [0.]
Curr episode timestep = 469
Scene graph at timestep 4969 is [False, False, True, False, False, True]
State prediction error at timestep 4969 is 0.012
Current timestep = 4970. State = [[0.05928094 0.27224877]]. Action = [[-0.00404109  0.04652274  0.          0.83218336]]. Reward = [0.]
Curr episode timestep = 470
Scene graph at timestep 4970 is [False, False, True, False, False, True]
State prediction error at timestep 4970 is 0.012
Current timestep = 4971. State = [[0.05913173 0.27481106]]. Action = [[-0.00953785  0.02837882  0.          0.27438438]]. Reward = [0.]
