Current timestep = 0. State = [[-0.00999966  1.4274173  -0.5057368   0.35372102  0.0114686   0.11338098
   0.          0.        ]]. Action = [[-0.25171328 -0.0313229 ]]. Reward = [0.19813816]
Abstract state at timestep 0 is 3
State prediction error at timestep 0 is 0.012
Human Feedback received at timestpe 0 of -10
Current timestep = 1. State = [[-0.01484957  1.435308   -0.4914723   0.3506365   0.01787505  0.1281405
   0.          0.        ]]. Action = [[ 0.84154165 -0.03610903]]. Reward = [-0.3670645]
Abstract state at timestep 1 is 3
State prediction error at timestep 1 is 0.012
Human Feedback received at timestpe 1 of -10
Current timestep = 2. State = [[-0.01962099  1.4429581  -0.48401946  0.33990997  0.02467805  0.13607278
   0.          0.        ]]. Action = [[0.11218834 0.3684529 ]]. Reward = [-0.3897526]
Abstract state at timestep 2 is 3
State prediction error at timestep 2 is 0.012
Human Feedback received at timestpe 2 of 10
Current timestep = 3. State = [[-0.02439251  1.4500087  -0.4840397   0.31323764  0.03147995  0.13605079
   0.          0.        ]]. Action = [[-0.71815014 -0.24135602]]. Reward = [0.09740584]
Abstract state at timestep 3 is 3
State prediction error at timestep 3 is 0.012
Human Feedback received at timestpe 3 of 10
Current timestep = 4. State = [[-0.02916431  1.4564602  -0.48405966  0.28656682  0.03828093  0.13603225
   0.          0.        ]]. Action = [[-0.61133254  0.41269743]]. Reward = [0.06878359]
Abstract state at timestep 4 is 3
State prediction error at timestep 4 is 0.012
Human Feedback received at timestpe 4 of 10
Current timestep = 5. State = [[-0.03390227  1.4627347  -0.47868818  0.27873573  0.04313117  0.09701376
   0.          0.        ]]. Action = [[0.33000338 0.97395396]]. Reward = [-0.49156496]
Abstract state at timestep 5 is 3
State prediction error at timestep 5 is 0.012
Human Feedback received at timestpe 5 of 10
Current timestep = 6. State = [[-0.03856897  1.4684092  -0.469759    0.2521052   0.04618958  0.06117396
   0.          0.        ]]. Action = [[-0.6263261  0.7551751]]. Reward = [1.1722037]
Abstract state at timestep 6 is 3
State prediction error at timestep 6 is 0.012
Human Feedback received at timestpe 6 of 10
Current timestep = 7. State = [[-0.04323588  1.4734838  -0.46976715  0.22543764  0.04924786  0.06117101
   0.          0.        ]]. Action = [[-0.22719568 -0.21903908]]. Reward = [0.38123494]
Abstract state at timestep 7 is 3
State prediction error at timestep 7 is 0.012
Human Feedback received at timestpe 7 of 10
Current timestep = 8. State = [[-0.04796295  1.4779617  -0.47732425  0.19886734  0.05381487  0.09134816
   0.          0.        ]]. Action = [[-0.26063323 -0.8540395 ]]. Reward = [-0.54796493]
Abstract state at timestep 8 is 3
State prediction error at timestep 8 is 0.012
Human Feedback received at timestpe 8 of 10
Current timestep = 9. State = [[-0.05261927  1.4818361  -0.46843824  0.17208885  0.05660132  0.05573406
   0.          0.        ]]. Action = [[-0.9080984   0.91687274]]. Reward = [1.095457]
Abstract state at timestep 9 is 3
State prediction error at timestep 9 is 0.012
Human Feedback received at timestpe 9 of 10
Current timestep = 10. State = [[-0.05722027  1.4851081  -0.4615237   0.14537236  0.05800441  0.02806428
   0.          0.        ]]. Action = [[-0.77618587  0.81647944]]. Reward = [1.0082704]
Abstract state at timestep 10 is 3
State prediction error at timestep 10 is 0.012
Human Feedback received at timestpe 10 of 10
Current timestep = 11. State = [[-0.06188412  1.4877833  -0.46939236  0.11877907  0.06097969  0.05951108
   0.          0.        ]]. Action = [[-0.7904283 -0.8448607]]. Reward = [-0.6398774]
Abstract state at timestep 11 is 3
State prediction error at timestep 11 is 0.012
Human Feedback received at timestpe 11 of 10
Current timestep = 12. State = [[-0.06675243  1.4912282  -0.4891282   0.15301362  0.06325309  0.04547197
   0.          0.        ]]. Action = [[ 0.98109853 -0.42437196]]. Reward = [-3.7212443]
Abstract state at timestep 12 is 3
State prediction error at timestep 12 is 0.012
Human Feedback received at timestpe 12 of 10
Current timestep = 13. State = [[-0.07162075  1.4940732  -0.48913255  0.1263334   0.06552707  0.04548435
   0.          0.        ]]. Action = [[-0.76810884 -0.2252906 ]]. Reward = [0.1978136]
Abstract state at timestep 13 is 3
State prediction error at timestep 13 is 0.012
Human Feedback received at timestpe 13 of 10
Current timestep = 14. State = [[-0.07643671  1.4963222  -0.4825635   0.09991777  0.06647907  0.01904187
   0.          0.        ]]. Action = [[-0.52692956  0.7933922 ]]. Reward = [0.8710204]
Abstract state at timestep 14 is 3
State prediction error at timestep 14 is 0.012
Human Feedback received at timestpe 14 of 10
Current timestep = 15. State = [[-0.08121042  1.49798    -0.47724947  0.07368009  0.06635781 -0.00242527
   0.          0.        ]]. Action = [[-0.5097861  0.7123525]]. Reward = [0.78967494]
Abstract state at timestep 15 is 3
State prediction error at timestep 15 is 0.012
Human Feedback received at timestpe 15 of 10
Current timestep = 16. State = [[-0.08618002  1.4998946  -0.49608773  0.08513996  0.06549781 -0.01720169
   0.          0.        ]]. Action = [[0.754961   0.42991686]]. Reward = [-2.4398272]
Abstract state at timestep 16 is 3
State prediction error at timestep 16 is 0.012
Human Feedback received at timestpe 16 of 10
Current timestep = 17. State = [[-0.09114952  1.5012094  -0.49608374  0.05846446  0.06463838 -0.01719014
   0.          0.        ]]. Action = [[-0.8663189  -0.08161724]]. Reward = [0.30775717]
Abstract state at timestep 17 is 3
State prediction error at timestep 17 is 0.012
Human Feedback received at timestpe 17 of 10
Current timestep = 18. State = [[-0.0961711   1.5019253  -0.5026041   0.03179981  0.06508299  0.00889295
   0.          0.        ]]. Action = [[-0.70227194 -0.5783321 ]]. Reward = [-0.5737453]
Abstract state at timestep 18 is 3
State prediction error at timestep 18 is 0.012
Human Feedback received at timestpe 18 of 10
Current timestep = 19. State = [[-0.10120964  1.5033797  -0.5044952   0.06461701  0.06571815  0.01270421
   0.          0.        ]]. Action = [[0.835178   0.24431825]]. Reward = [-1.0176833]
Abstract state at timestep 19 is 3
State prediction error at timestep 19 is 0.012
Human Feedback received at timestpe 19 of 10
Current timestep = 20. State = [[-0.10634156  1.5054252  -0.5155274   0.09080846  0.0680248   0.04613703
   0.          0.        ]]. Action = [[ 0.6681106 -0.8201386]]. Reward = [-2.2296295]
Abstract state at timestep 20 is 3
State prediction error at timestep 20 is 0.012
Human Feedback received at timestpe 20 of 10
Current timestep = 21. State = [[-0.11153183  1.5068572  -0.522833    0.06346311  0.07180665  0.0756437
   0.          0.        ]]. Action = [[-0.795724   -0.67114556]]. Reward = [-0.89922345]
Abstract state at timestep 21 is 3
State prediction error at timestep 21 is 0.012
Human Feedback received at timestpe 21 of 10
Current timestep = 22. State = [[-0.11677933  1.5076787  -0.53003585  0.03624652  0.07703957  0.10466783
   0.          0.        ]]. Action = [[-0.09268057 -0.6453748 ]]. Reward = [-1.1245209]
Abstract state at timestep 22 is 3
State prediction error at timestep 22 is 0.012
Human Feedback received at timestpe 22 of 10
Current timestep = 23. State = [[-0.1220129   1.5084805  -0.5307034   0.03524696  0.08432055  0.14563243
   0.          0.        ]]. Action = [[ 0.5081463 -0.9684069]]. Reward = [-1.1644962]
Abstract state at timestep 23 is 3
State prediction error at timestep 23 is 0.012
Human Feedback received at timestpe 23 of 10
Current timestep = 24. State = [[-0.12730809  1.5086434  -0.5384859   0.00670568  0.09320372  0.17766339
   0.          0.        ]]. Action = [[-0.09885544 -0.98391116]]. Reward = [-1.6431792]
Abstract state at timestep 24 is 3
State prediction error at timestep 24 is 0.012
Human Feedback received at timestpe 24 of 10
Current timestep = 25. State = [[-0.13256797  1.5091002  -0.536533    0.01960705  0.10367075  0.20934029
   0.          0.        ]]. Action = [[ 0.80396664 -0.614913  ]]. Reward = [-1.2627364]
Abstract state at timestep 25 is 3
State prediction error at timestep 25 is 0.012
Human Feedback received at timestpe 25 of 10
Current timestep = 26. State = [[-0.13778439  1.51001    -0.53373605  0.03955444  0.11567775  0.24014029
   0.          0.        ]]. Action = [[ 0.9057598 -0.5426887]]. Reward = [-1.4708413]
Abstract state at timestep 26 is 3
State prediction error at timestep 26 is 0.012
Human Feedback received at timestpe 26 of 10
Current timestep = 27. State = [[-0.14310122  1.5109049  -0.5434963   0.03881534  0.12743163  0.23507753
   0.          0.        ]]. Action = [[0.77972317 0.24568582]]. Reward = [-2.5487704]
Abstract state at timestep 27 is 3
State prediction error at timestep 27 is 0.012
Human Feedback received at timestpe 27 of 10
Current timestep = 28. State = [[-0.14835596  1.511974   -0.53787106  0.04640649  0.13977277  0.24682286
   0.          0.        ]]. Action = [[0.72262514 0.14124179]]. Reward = [-1.1482153]
Abstract state at timestep 28 is 3
State prediction error at timestep 28 is 0.012
Human Feedback received at timestpe 28 of 10
Current timestep = 29. State = [[-0.15361099  1.5124449  -0.53786856  0.01972719  0.1521138   0.24682026
   0.          0.        ]]. Action = [[-0.93959844 -0.4160719 ]]. Reward = [-1.1692592]
Abstract state at timestep 29 is 3
State prediction error at timestep 29 is 0.012
Human Feedback received at timestpe 29 of 10
Current timestep = 30. State = [[-0.15891047  1.5123082  -0.54342127 -0.00751117  0.16558644  0.26945263
   0.          0.        ]]. Action = [[-0.5909092  -0.51715577]]. Reward = [-1.9279538]
Abstract state at timestep 30 is 3
State prediction error at timestep 30 is 0.012
Human Feedback received at timestpe 30 of 10
Current timestep = 31. State = [[-0.16415462  1.5115923  -0.53642124 -0.03319874  0.17761494  0.24057019
   0.          0.        ]]. Action = [[-0.52596897  0.7692232 ]]. Reward = [-0.6078866]
Abstract state at timestep 31 is 3
State prediction error at timestep 31 is 0.012
Human Feedback received at timestpe 31 of 10
Current timestep = 32. State = [[-0.16933422  1.5103012  -0.5282539  -0.05864583  0.18795174  0.20673564
   0.          0.        ]]. Action = [[-0.8847439   0.73590827]]. Reward = [-0.38941938]
Abstract state at timestep 32 is 3
State prediction error at timestep 32 is 0.012
Human Feedback received at timestpe 32 of 10
Current timestep = 33. State = [[-0.17444448  1.5084276  -0.5195454  -0.0843824   0.19650939  0.17115322
   0.          0.        ]]. Action = [[-0.12906367  0.7894316 ]]. Reward = [-0.23650376]
Abstract state at timestep 33 is 3
State prediction error at timestep 33 is 0.012
Human Feedback received at timestpe 33 of 10
Current timestep = 34. State = [[-0.1795784   1.506694   -0.5201588  -0.07796868  0.20333476  0.13650754
   0.          0.        ]]. Action = [[0.0787133 0.8607116]]. Reward = [-0.7195133]
Abstract state at timestep 34 is 3
State prediction error at timestep 34 is 0.012
Human Feedback received at timestpe 34 of 10
Current timestep = 35. State = [[-0.18471222  1.5043609  -0.52015764 -0.10463916  0.21016012  0.1365071
   0.          0.        ]]. Action = [[-0.7212042  -0.33679414]]. Reward = [-0.9734246]
Abstract state at timestep 35 is 3
State prediction error at timestep 35 is 0.012
Human Feedback received at timestpe 35 of 10
Current timestep = 36. State = [[-0.18976927  1.5014596  -0.5104556  -0.12962934  0.21495286  0.09585514
   0.          0.        ]]. Action = [[-0.33016783  0.8093991 ]]. Reward = [0.1138576]
Abstract state at timestep 36 is 3
State prediction error at timestep 36 is 0.012
Human Feedback received at timestpe 36 of 10
Current timestep = 37. State = [[-0.19489689  1.4979393  -0.51929176 -0.15742558  0.22156541  0.13225113
   0.          0.        ]]. Action = [[-0.4848113 -0.731575 ]]. Reward = [-1.9964138]
Abstract state at timestep 37 is 3
State prediction error at timestep 37 is 0.012
Human Feedback received at timestpe 37 of 10
Current timestep = 38. State = [[-0.20003152  1.4943081  -0.5202899  -0.1624212   0.22847715  0.13823476
   0.          0.        ]]. Action = [[ 0.03129029 -0.37598264]]. Reward = [-0.79535526]
Abstract state at timestep 38 is 3
State prediction error at timestep 38 is 0.012
Human Feedback received at timestpe 38 of 10
Current timestep = 39. State = [[-0.20531507  1.4910707  -0.53519106 -0.14496656  0.23541138  0.13868466
   0.          0.        ]]. Action = [[ 0.5114145  -0.25821555]]. Reward = [-1.6128789]
Abstract state at timestep 39 is 3
State prediction error at timestep 39 is 0.012
Human Feedback received at timestpe 39 of 10
Current timestep = 40. State = [[-0.21055517  1.4882793  -0.53008354 -0.12504229  0.24157621  0.12329675
   0.          0.        ]]. Action = [[0.6324959  0.57640886]]. Reward = [0.30985814]
Abstract state at timestep 40 is 3
State prediction error at timestep 40 is 0.012
Human Feedback received at timestpe 40 of 10
Current timestep = 41. State = [[-0.21579537  1.4848887  -0.53008235 -0.15171203  0.24774101  0.12329644
   0.          0.        ]]. Action = [[-0.38231504  0.49787724]]. Reward = [-1.0285603]
Abstract state at timestep 41 is 3
State prediction error at timestep 41 is 0.012
Human Feedback received at timestpe 41 of 10
Current timestep = 42. State = [[-0.22125082  1.4814683  -0.55107135 -0.1529556   0.25337172  0.11261393
   0.          0.        ]]. Action = [[0.5672929 0.0467298]]. Reward = [-2.5932329]
Abstract state at timestep 42 is 3
State prediction error at timestep 42 is 0.012
Human Feedback received at timestpe 42 of 10
Current timestep = 43. State = [[-0.22666296  1.4774715  -0.54557765 -0.17840104  0.25782147  0.08899538
   0.          0.        ]]. Action = [[-0.7356826  0.501621 ]]. Reward = [-0.35588586]
Abstract state at timestep 43 is 3
State prediction error at timestep 43 is 0.012
Human Feedback received at timestpe 43 of 10
Current timestep = 44. State = [[-0.2321535   1.4739637  -0.55149835 -0.15633442  0.2603186   0.04994293
   0.          0.        ]]. Action = [[0.6753404 0.9819474]]. Reward = [-0.19053403]
Abstract state at timestep 44 is 3
State prediction error at timestep 44 is 0.012
Human Feedback received at timestpe 44 of 10
Current timestep = 45. State = [[-0.23783931  1.470507   -0.57290494 -0.15440702  0.2647398   0.08842406
   0.          0.        ]]. Action = [[ 0.39411008 -0.9514527 ]]. Reward = [-2.4399836]
Abstract state at timestep 45 is 3
State prediction error at timestep 45 is 0.012
Human Feedback received at timestpe 45 of 10
Current timestep = 46. State = [[-0.24348025  1.4664643  -0.5672685  -0.18025889  0.26799107  0.06502484
   0.          0.        ]]. Action = [[-0.22808409  0.68879914]]. Reward = [-0.22528504]
Abstract state at timestep 46 is 3
State prediction error at timestep 46 is 0.012
Human Feedback received at timestpe 46 of 10
Current timestep = 47. State = [[-0.24927282  1.4626348  -0.58242196 -0.17077999  0.27122942  0.06476726
   0.          0.        ]]. Action = [[0.5683497  0.03624845]]. Reward = [-1.4499557]
Abstract state at timestep 47 is 3
State prediction error at timestep 47 is 0.012
Human Feedback received at timestpe 47 of 10
Current timestep = 48. State = [[-0.25504723  1.4586648  -0.57864505 -0.17666216  0.2724672   0.02475549
   0.          0.        ]]. Action = [[0.33490884 0.9955809 ]]. Reward = [0.13229755]
Abstract state at timestep 48 is 3
State prediction error at timestep 48 is 0.012
Human Feedback received at timestpe 48 of 10
Current timestep = 49. State = [[-0.26115188  1.4547893  -0.6127532  -0.17267857  0.27481395  0.04693517
   0.          0.        ]]. Action = [[ 0.5350745 -0.682824 ]]. Reward = [-3.371056]
Abstract state at timestep 49 is 3
State prediction error at timestep 49 is 0.012
Human Feedback received at timestpe 49 of 10
Current timestep = 50. State = [[-0.2673103   1.4502962  -0.61949706 -0.20038457  0.27856702  0.07506159
   0.          0.        ]]. Action = [[-0.462237  -0.8078437]]. Reward = [-1.5157089]
Abstract state at timestep 50 is 3
State prediction error at timestep 50 is 0.012
Human Feedback received at timestpe 50 of 10
Current timestep = 51. State = [[-0.27367067  1.4460914  -0.63822067 -0.18729773  0.2808115   0.04488953
   0.          0.        ]]. Action = [[0.9888065  0.63734305]]. Reward = [-1.6490031]
Abstract state at timestep 51 is 3
State prediction error at timestep 51 is 0.012
Human Feedback received at timestpe 51 of 10
Current timestep = 52. State = [[-0.28008157  1.4420035  -0.643649   -0.18217422  0.28344384  0.05264724
   0.          0.        ]]. Action = [[0.45343387 0.18591177]]. Reward = [-0.58018315]
Abstract state at timestep 52 is 3
State prediction error at timestep 52 is 0.012
Human Feedback received at timestpe 52 of 10
Current timestep = 53. State = [[-0.28649244  1.4373158  -0.64364874 -0.20884143  0.2860762   0.05264723
   0.          0.        ]]. Action = [[-0.07054466 -0.01341397]]. Reward = [-0.701954]
Abstract state at timestep 53 is 3
State prediction error at timestep 53 is 0.012
Human Feedback received at timestpe 53 of -10
Current timestep = 54. State = [[-0.29294926  1.4320061  -0.64944875 -0.23673114  0.28995335  0.07754304
   0.          0.        ]]. Action = [[-0.5272524  -0.63252145]]. Reward = [-1.470754]
Abstract state at timestep 54 is 3
State prediction error at timestep 54 is 0.012
Human Feedback received at timestpe 54 of -10
Current timestep = 55. State = [[-0.29942256  1.426606   -0.6514543  -0.24083062  0.2942067   0.08506688
   0.          0.        ]]. Action = [[ 0.05387342 -0.01878482]]. Reward = [-0.51553977]
Abstract state at timestep 55 is 3
State prediction error at timestep 55 is 0.012
Human Feedback received at timestpe 55 of -10
Current timestep = 56. State = [[-0.30589586  1.4206061  -0.6514536  -0.2674987   0.29846007  0.08506678
   0.          0.        ]]. Action = [[-0.73070806  0.14945793]]. Reward = [-0.9421636]
Abstract state at timestep 56 is 3
State prediction error at timestep 56 is 0.012
Human Feedback received at timestpe 56 of -10
Current timestep = 57. State = [[-0.31244454  1.4139632  -0.6610045  -0.29651526  0.3048028   0.12685467
   0.          0.        ]]. Action = [[-0.0072552  -0.91120285]]. Reward = [-2.1750233]
Abstract state at timestep 57 is 0
State prediction error at timestep 57 is 0.012
Human Feedback received at timestpe 57 of -10
Current timestep = 58. State = [[-0.3191576   1.407136   -0.6760793  -0.30444726  0.3097438   0.0988202
   0.          0.        ]]. Action = [[0.50718474 0.5536649 ]]. Reward = [-1.917376]
Abstract state at timestep 58 is 0
State prediction error at timestep 58 is 0.012
Human Feedback received at timestpe 58 of -10
Current timestep = 59. State = [[-0.32587075  1.3997089  -0.6760784  -0.33111587  0.3146848   0.09882007
   0.          0.        ]]. Action = [[-0.19945228 -0.4208697 ]]. Reward = [-1.0548378]
Abstract state at timestep 59 is 0
State prediction error at timestep 59 is 0.012
Human Feedback received at timestpe 59 of -10
Current timestep = 60. State = [[-0.3325351   1.3917077  -0.6698943  -0.3563603   0.3182817   0.07193828
   0.          0.        ]]. Action = [[-0.13703519  0.633682  ]]. Reward = [-0.35041988]
Abstract state at timestep 60 is 0
State prediction error at timestep 60 is 0.012
Human Feedback received at timestpe 60 of -10
Current timestep = 61. State = [[-0.33926663  1.3830622  -0.6784464  -0.38541758  0.32378823  0.11013049
   0.          0.        ]]. Action = [[-0.9457915  -0.95380545]]. Reward = [-2.0471091]
Abstract state at timestep 61 is 0
State prediction error at timestep 61 is 0.012
Human Feedback received at timestpe 61 of -10
Current timestep = 62. State = [[-0.34599823  1.373817   -0.6784452  -0.41208667  0.32929474  0.11013027
   0.          0.        ]]. Action = [[-0.23950827  0.1285665 ]]. Reward = [-1.1669003]
Abstract state at timestep 62 is 0
State prediction error at timestep 62 is 0.012
Human Feedback received at timestpe 62 of -10
Current timestep = 63. State = [[-0.35265702  1.3640132  -0.6692166  -0.43649074  0.33277577  0.06962067
   0.          0.        ]]. Action = [[-0.2076205   0.84736323]]. Reward = [-0.10755692]
Abstract state at timestep 63 is 0
State prediction error at timestep 63 is 0.012
Human Feedback received at timestpe 63 of -10
Current timestep = 64. State = [[-0.3595468   1.3543148  -0.6936808  -0.4321271   0.33769065  0.09829734
   0.          0.        ]]. Action = [[ 0.00437176 -0.70835865]]. Reward = [-1.7282734]
Abstract state at timestep 64 is 0
State prediction error at timestep 64 is 0.012
Human Feedback received at timestpe 64 of -10
Current timestep = 65. State = [[-0.36643666  1.3440169  -0.69367975 -0.4587957   0.3426055   0.09829719
   0.          0.        ]]. Action = [[-0.75898826 -0.4909749 ]]. Reward = [-1.116876]
Abstract state at timestep 65 is 0
State prediction error at timestep 65 is 0.012
Human Feedback received at timestpe 65 of -10
Current timestep = 66. State = [[-0.37339363  1.3330903  -0.70210445 -0.48716843  0.34932578  0.1344057
   0.          0.        ]]. Action = [[-0.79688615 -0.7912775 ]]. Reward = [-2.116941]
Abstract state at timestep 66 is 0
State prediction error at timestep 66 is 0.012
Human Feedback received at timestpe 66 of -10
Current timestep = 67. State = [[-0.38070026  1.3229394  -0.7389526  -0.45318893  0.35805005  0.1744854
   0.          0.        ]]. Action = [[ 0.8637451 -0.9374181]]. Reward = [-1.6316655]
Abstract state at timestep 67 is 0
State prediction error at timestep 67 is 0.012
Human Feedback received at timestpe 67 of -10
Current timestep = 68. State = [[-0.38820535  1.3126531  -0.75843245 -0.45917597  0.36641607  0.16732033
   0.          0.        ]]. Action = [[0.22972906 0.15535784]]. Reward = [-2.2188125]
Abstract state at timestep 68 is 0
State prediction error at timestep 68 is 0.012
Human Feedback received at timestpe 68 of -10
Current timestep = 69. State = [[-0.39571062  1.3017676  -0.75842935 -0.4858481   0.37478203  0.16731954
   0.          0.        ]]. Action = [[-0.94583106  0.09854746]]. Reward = [-1.4194839]
Abstract state at timestep 69 is 0
State prediction error at timestep 69 is 0.012
Human Feedback received at timestpe 69 of -10
Current timestep = 70. State = [[-0.40321612  1.290283   -0.7584261  -0.51252025  0.38314795  0.16731872
   0.          0.        ]]. Action = [[-0.23795521 -0.35956395]]. Reward = [-1.4261767]
Abstract state at timestep 70 is 0
State prediction error at timestep 70 is 0.012
Human Feedback received at timestpe 70 of -10
Current timestep = 71. State = [[-0.41074434  1.278795   -0.75949234 -0.5123899   0.39025736  0.14218798
   0.          0.        ]]. Action = [[0.33756256 0.6699455 ]]. Reward = [-0.14498045]
Abstract state at timestep 71 is 0
State prediction error at timestep 71 is 0.012
Human Feedback received at timestpe 71 of -10
Current timestep = 72. State = [[-0.41826224  1.2673131  -0.7591468  -0.5123488   0.39812165  0.15728608
   0.          0.        ]]. Action = [[ 0.9312334 -0.0839349]]. Reward = [-0.18615825]
Abstract state at timestep 72 is 0
State prediction error at timestep 72 is 0.012
Human Feedback received at timestpe 72 of -10
Current timestep = 73. State = [[-0.42587146  1.2557452  -0.7684597  -0.51627153  0.40621093  0.16178551
   0.          0.        ]]. Action = [[0.66605365 0.02484822]]. Reward = [-1.1948284]
Abstract state at timestep 73 is 0
State prediction error at timestep 73 is 0.012
Human Feedback received at timestpe 73 of -10
Current timestep = 74. State = [[-0.43381453  1.2445183  -0.8015693  -0.5010798   0.41402748  0.15633081
   0.          0.        ]]. Action = [[ 0.663007   -0.47462064]]. Reward = [-2.1799238]
Abstract state at timestep 74 is 0
State prediction error at timestep 74 is 0.012
Human Feedback received at timestpe 74 of -10
Current timestep = 75. State = [[-0.44218293  1.2340236  -0.8439406  -0.46853083  0.42169476  0.15334554
   0.          0.        ]]. Action = [[0.9885509 0.314659 ]]. Reward = [-2.3518376]
Abstract state at timestep 75 is 0
State prediction error at timestep 75 is 0.012
Human Feedback received at timestpe 75 of -10
Current timestep = 76. State = [[-0.4505992   1.2228942  -0.8500018  -0.49716812  0.4307742   0.18158905
   0.          0.        ]]. Action = [[-0.33015168 -0.6903735 ]]. Reward = [-2.1148157]
Abstract state at timestep 76 is 0
State prediction error at timestep 76 is 0.012
Human Feedback received at timestpe 76 of -10
Current timestep = 77. State = [[-0.45905226  1.2111455  -0.8545944  -0.5250447   0.44087982  0.20211247
   0.          0.        ]]. Action = [[-0.65279466 -0.56067777]]. Reward = [-2.0502238]
Abstract state at timestep 77 is 0
State prediction error at timestep 77 is 0.012
Human Feedback received at timestpe 77 of -10
Current timestep = 78. State = [[-0.46750578  1.198798   -0.854589   -0.55171907  0.45098537  0.20211104
   0.          0.        ]]. Action = [[-0.2143808  -0.38811082]]. Reward = [-1.5826937]
Abstract state at timestep 78 is 0
State prediction error at timestep 78 is 0.012
Human Feedback received at timestpe 78 of -10
Current timestep = 79. State = [[-0.47592825  1.1858763  -0.8505788  -0.5770177   0.4601425   0.18314263
   0.          0.        ]]. Action = [[-0.3790155  0.5556381]]. Reward = [-1.1026429]
Abstract state at timestep 79 is 0
State prediction error at timestep 79 is 0.012
Human Feedback received at timestpe 79 of -10
Current timestep = 80. State = [[-0.48427373  1.1724116  -0.8407677  -0.6005007   0.4670048   0.1372464
   0.          0.        ]]. Action = [[-0.9060122  0.9276371]]. Reward = [-0.31822905]
Abstract state at timestep 80 is 0
State prediction error at timestep 80 is 0.012
Human Feedback received at timestpe 80 of -10
Current timestep = 81. State = [[-0.49261937  1.1583475  -0.8407649  -0.6271708   0.4738671   0.13724595
   0.          0.        ]]. Action = [[-0.7957199   0.32077074]]. Reward = [-1.284081]
Abstract state at timestep 81 is 0
State prediction error at timestep 81 is 0.012
Human Feedback received at timestpe 81 of -10
Current timestep = 82. State = [[-0.5012647   1.1444908  -0.87062484 -0.61794823  0.4806316   0.1352903
   0.          0.        ]]. Action = [[ 0.4349053  -0.38812524]]. Reward = [-1.833896]
Abstract state at timestep 82 is 0
State prediction error at timestep 82 is 0.012
Human Feedback received at timestpe 82 of -10
Current timestep = 83. State = [[-0.5103159   1.1309218  -0.9108335  -0.60507107  0.48699605  0.12728983
   0.          0.        ]]. Action = [[ 0.83053076 -0.17703742]]. Reward = [-2.6245708]
Abstract state at timestep 83 is 0
State prediction error at timestep 83 is 0.012
Human Feedback received at timestpe 83 of -10
Current timestep = 84. State = [[-0.5193673   1.1167532  -0.910831   -0.63174075  0.49336052  0.12728949
   0.          0.        ]]. Action = [[-0.37429643  0.07169163]]. Reward = [-1.2231015]
Abstract state at timestep 84 is 0
State prediction error at timestep 84 is 0.012
Human Feedback received at timestpe 84 of -10
Current timestep = 85. State = [[-0.5288061   1.1030781  -0.94956654 -0.6098369   0.49974307  0.12765196
   0.          0.        ]]. Action = [[0.617476   0.46081853]]. Reward = [-2.0530524]
Abstract state at timestep 85 is 0
State prediction error at timestep 85 is 0.012
Human Feedback received at timestpe 85 of -10
Current timestep = 86. State = [[-0.5384978   1.0895014  -0.97373104 -0.605077    0.5048714   0.10256652
   0.          0.        ]]. Action = [[0.62376046 0.5458137 ]]. Reward = [-1.7649857]
Abstract state at timestep 86 is 0
State prediction error at timestep 86 is 0.012
Human Feedback received at timestpe 86 of -10
Current timestep = 87. State = [[-0.5484084   1.07604    -0.99706775 -0.60051644  0.5116577   0.1357258
   0.          0.        ]]. Action = [[ 0.2491368 -0.7390872]]. Reward = [-1.8823491]
Abstract state at timestep 87 is 0
State prediction error at timestep 87 is 0.012
Human Feedback received at timestpe 87 of -10
Current timestep = 88. State = [[-0.55826515  1.0620197  -0.9902275  -0.6248358   0.5168154   0.10315418
   0.          0.        ]]. Action = [[-0.09070539  0.73236644]]. Reward = [-0.43983787]
Abstract state at timestep 88 is 0
State prediction error at timestep 88 is 0.012
Human Feedback received at timestpe 88 of -10
Current timestep = 89. State = [[-0.5682369   1.0478635  -1.0019217  -0.6309758   0.5222178   0.10804798
   0.          0.        ]]. Action = [[ 0.5582912 -0.0730992]]. Reward = [-1.3115704]
Abstract state at timestep 89 is 0
State prediction error at timestep 89 is 0.012
Human Feedback received at timestpe 89 of -10
Current timestep = 90. State = [[-0.5784841   1.0339489  -1.0296249  -0.62032086  0.5278096   0.11183629
   0.          0.        ]]. Action = [[ 0.45370817 -0.16076946]]. Reward = [-1.8527884]
Abstract state at timestep 90 is 0
State prediction error at timestep 90 is 0.012
Human Feedback received at timestpe 90 of -10
Current timestep = 91. State = [[-0.5888      1.0198119  -1.0376307  -0.63067716  0.53472155  0.13823904
   0.          0.        ]]. Action = [[ 0.22526193 -0.51758724]]. Reward = [-1.3923091]
Abstract state at timestep 91 is 0
State prediction error at timestep 91 is 0.012
Human Feedback received at timestpe 91 of -10
Current timestep = 92. State = [[-0.5994105   1.0055238  -1.0666573  -0.6372585   0.5411661   0.12889205
   0.          0.        ]]. Action = [[0.38118923 0.42284977]]. Reward = [-2.9820466]
Abstract state at timestep 92 is 0
State prediction error at timestep 92 is 0.012
Human Feedback received at timestpe 92 of -10
Current timestep = 93. State = [[-0.6102877   0.9912875  -1.0932899  -0.6349661   0.54758847  0.12844655
   0.          0.        ]]. Action = [[0.9190297  0.02757192]]. Reward = [-2.454475]
Abstract state at timestep 93 is 0
State prediction error at timestep 93 is 0.012
Human Feedback received at timestpe 93 of -10
Current timestep = 94. State = [[-0.62116516  0.9764518  -1.0932871  -0.6616357   0.55401075  0.12844618
   0.          0.        ]]. Action = [[-0.13178349 -0.2618026 ]]. Reward = [-1.3216859]
Abstract state at timestep 94 is 1
State prediction error at timestep 94 is 0.012
Human Feedback received at timestpe 94 of -10
Current timestep = 95. State = [[-0.6322137   0.96164864 -1.109017   -0.6596431   0.5588455   0.09669591
   0.          0.        ]]. Action = [[0.38461792 0.755185  ]]. Reward = [-1.3171256]
Abstract state at timestep 95 is 1
State prediction error at timestep 95 is 0.012
Human Feedback received at timestpe 95 of -10
Current timestep = 96. State = [[-0.6432624   0.94624585 -1.1090155  -0.6863115   0.5636803   0.09669583
   0.          0.        ]]. Action = [[-0.4631548   0.22268188]]. Reward = [-1.2003763]
Abstract state at timestep 96 is 1
State prediction error at timestep 96 is 0.012
Human Feedback received at timestpe 96 of -10
Current timestep = 97. State = [[-0.6543112   0.9302432  -1.1090139  -0.71297973  0.56851506  0.09669571
   0.          0.        ]]. Action = [[-0.8048057   0.37288344]]. Reward = [-1.218416]
Abstract state at timestep 97 is 1
State prediction error at timestep 97 is 0.012
Human Feedback received at timestpe 97 of -10
Current timestep = 98. State = [[-0.66559637  0.91411185 -1.1325259  -0.71866065  0.5732104   0.09390654
   0.          0.        ]]. Action = [[0.45382118 0.309937  ]]. Reward = [-2.3198876]
Abstract state at timestep 98 is 1
State prediction error at timestep 98 is 0.012
Human Feedback received at timestpe 98 of -10
Current timestep = 99. State = [[-0.6768348   0.8974198  -1.1265979  -0.74305844  0.5764436   0.06466441
   0.          0.        ]]. Action = [[-0.8087294  0.8847685]]. Reward = [-0.5055351]
Abstract state at timestep 99 is 1
State prediction error at timestep 99 is 0.012
Human Feedback received at timestpe 99 of -10
Current timestep = 100. State = [[-0.68813556  0.88006157 -1.1346079  -0.77344966  0.5817887   0.1069022
   0.          0.        ]]. Action = [[-0.31309545 -0.80205333]]. Reward = [-2.2281055]
Abstract state at timestep 100 is 1
State prediction error at timestep 100 is 0.012
Human Feedback received at timestpe 100 of -10
Current timestep = 101. State = [[-0.6994364   0.86210376 -1.134606   -0.8001183   0.5871338   0.10690197
   0.          0.        ]]. Action = [[-0.48068845 -0.02700591]]. Reward = [-1.3533874]
Abstract state at timestep 101 is 1
State prediction error at timestep 101 is 0.012
Human Feedback received at timestpe 101 of -10
Current timestep = 102. State = [[-0.71107846  0.844152   -1.1668999  -0.7990518   0.5903358   0.06403968
   0.          0.        ]]. Action = [[0.8275392 0.906095 ]]. Reward = [-2.5708091]
Abstract state at timestep 102 is 1
State prediction error at timestep 102 is 0.012
Human Feedback received at timestpe 102 of -10
Current timestep = 103. State = [[-0.7227205   0.82560056 -1.1668992  -0.8257191   0.59353775  0.06403966
   0.          0.        ]]. Action = [[-0.14345437  0.1242373 ]]. Reward = [-1.1947868]
Abstract state at timestep 103 is 1
State prediction error at timestep 103 is 0.012
Human Feedback received at timestpe 103 of -10
Current timestep = 104. State = [[-0.7347311   0.807302   -1.2053416  -0.8152041   0.5986485   0.10221495
   0.          0.        ]]. Action = [[ 0.7275841 -0.8305749]]. Reward = [-2.793007]
Abstract state at timestep 104 is 1
State prediction error at timestep 104 is 0.012
Human Feedback received at timestpe 104 of -10
Current timestep = 105. State = [[-0.74681747  0.78910404 -1.2122164  -0.81043303  0.6029284   0.08559836
   0.          0.        ]]. Action = [[0.75264156 0.5712166 ]]. Reward = [-0.500609]
Abstract state at timestep 105 is 1
State prediction error at timestep 105 is 0.012
Human Feedback received at timestpe 105 of -10
Current timestep = 106. State = [[-0.7589039   0.7703063  -1.2122152  -0.8371009   0.6072083   0.08559798
   0.          0.        ]]. Action = [[-0.45766354 -0.22698152]]. Reward = [-1.4140284]
Abstract state at timestep 106 is 1
State prediction error at timestep 106 is 0.012
Human Feedback received at timestpe 106 of -10
Current timestep = 107. State = [[-0.77105564  0.7508533  -1.2204261  -0.8670251   0.61354023  0.1266379
   0.          0.        ]]. Action = [[-0.494803  -0.8974389]]. Reward = [-2.5396628]
Abstract state at timestep 107 is 1
State prediction error at timestep 107 is 0.012
Human Feedback received at timestpe 107 of -10
Current timestep = 108. State = [[-0.7832741   0.73073    -1.228958   -0.89774126  0.6221497   0.17218925
   0.          0.        ]]. Action = [[-0.4895029 -0.8923292]]. Reward = [-2.8714862]
Abstract state at timestep 108 is 1
State prediction error at timestep 108 is 0.012
Human Feedback received at timestpe 108 of -10
Current timestep = 109. State = [[-0.79579484  0.7106515  -1.2591608  -0.8958011   0.63078123  0.1726301
   0.          0.        ]]. Action = [[0.8332331  0.16367233]]. Reward = [-3.045844]
Abstract state at timestep 109 is 1
State prediction error at timestep 109 is 0.012
Human Feedback received at timestpe 109 of -10
Current timestep = 110. State = [[-0.8083471   0.68993014 -1.2632439  -0.92488796  0.6406123   0.19662124
   0.          0.        ]]. Action = [[-0.3475114 -0.7091607]]. Reward = [-2.6205208]
Abstract state at timestep 110 is 1
State prediction error at timestep 110 is 0.012
Human Feedback received at timestpe 110 of -10
Current timestep = 111. State = [[-0.8208556   0.6686606  -1.2575475  -0.94866735  0.64887655  0.16528471
   0.          0.        ]]. Action = [[-0.32843554  0.7207265 ]]. Reward = [-1.4078178]
Abstract state at timestep 111 is 1
State prediction error at timestep 111 is 0.012
Human Feedback received at timestpe 111 of -10
Current timestep = 112. State = [[-0.83361465  0.6474548  -1.2828023  -0.94600093  0.6574542   0.17155267
   0.          0.        ]]. Action = [[0.23814046 0.44459188]]. Reward = [-2.5868547]
Abstract state at timestep 112 is 1
State prediction error at timestep 112 is 0.012
Human Feedback received at timestpe 112 of -10
Current timestep = 113. State = [[-0.8463119   0.6257185  -1.2748543  -0.96870744  0.6638577   0.12807032
   0.          0.        ]]. Action = [[-0.59271836  0.91396666]]. Reward = [-1.091346]
Abstract state at timestep 113 is 1
State prediction error at timestep 113 is 0.012
Human Feedback received at timestpe 113 of -10
Current timestep = 114. State = [[-0.8596528   0.60448164 -1.340249   -0.94710237  0.6716043   0.15493155
   0.          0.        ]]. Action = [[ 0.9283267  -0.62709564]]. Reward = [-4.9205813]
Abstract state at timestep 114 is 1
State prediction error at timestep 114 is 0.012
Human Feedback received at timestpe 114 of -10
Current timestep = 115. State = [[-0.8734309   0.58372825 -1.3843315  -0.92585295  0.67984587  0.16483228
   0.          0.        ]]. Action = [[ 0.9320116  -0.27012765]]. Reward = [-3.5055513]
Abstract state at timestep 115 is 1
State prediction error at timestep 115 is 0.012
Human Feedback received at timestpe 115 of -10
Current timestep = 116. State = [[-0.8872595   0.56231445 -1.3907619  -0.9560234   0.68992066  0.20149617
   0.          0.        ]]. Action = [[-0.06753051 -0.71768504]]. Reward = [-3.2452974]
Abstract state at timestep 116 is 1
State prediction error at timestep 116 is 0.012
Human Feedback received at timestpe 116 of -10
Current timestep = 117. State = [[-0.9010886   0.54030174 -1.3907536  -0.98269665  0.6999954   0.20149477
   0.          0.        ]]. Action = [[-0.3619951   0.02913284]]. Reward = [-2.5538511]
Abstract state at timestep 117 is 1
State prediction error at timestep 117 is 0.012
Human Feedback received at timestpe 117 of -10
Current timestep = 118. State = [[-0.91485715  0.51777214 -1.3828218  -1.0046865   0.7077167   0.1544266
   0.          0.        ]]. Action = [[-0.8985103   0.91865706]]. Reward = [-1.4911419]
Abstract state at timestep 118 is 1
State prediction error at timestep 118 is 0.012
Human Feedback received at timestpe 118 of -10
Current timestep = 119. State = [[-0.9290407   0.4951541  -1.4239467  -1.0084571   0.7150046   0.14575717
   0.          0.        ]]. Action = [[ 0.13654983 -0.01006943]]. Reward = [-4.6148844]
Abstract state at timestep 119 is 1
State prediction error at timestep 119 is 0.012
Human Feedback received at timestpe 119 of -10
Current timestep = 120. State = [[-0.94341546  0.4723996  -1.4420445  -1.0139698   0.7209862   0.11963187
   0.          0.        ]]. Action = [[0.325765   0.60132027]]. Reward = [-2.8440473]
Abstract state at timestep 120 is 2
State prediction error at timestep 120 is 0.012
Human Feedback received at timestpe 120 of -10
Current timestep = 121. State = [[-0.9577905   0.44904542 -1.4420415  -1.0406386   0.72696775  0.11963159
   0.          0.        ]]. Action = [[-0.19829243  0.36233544]]. Reward = [-2.4202425]
Abstract state at timestep 121 is 2
State prediction error at timestep 121 is 0.012
Human Feedback received at timestpe 121 of -10
Current timestep = 122. State = [[-0.972432    0.4255613  -1.4687022  -1.0464512   0.73299116  0.120468
   0.          0.        ]]. Action = [[ 0.87484074 -0.03554404]]. Reward = [-3.7532902]
Abstract state at timestep 122 is 2
State prediction error at timestep 122 is 0.012
Human Feedback received at timestpe 122 of -10
Current timestep = 123. State = [[-0.98758614  0.4021961  -1.5187619  -1.0404721   0.7374426   0.08902965
   0.          0.        ]]. Action = [[0.4789095 0.6086904]]. Reward = [-4.933457]
Abstract state at timestep 123 is 2
State prediction error at timestep 123 is 0.012
Human Feedback received at timestpe 123 of -10
Current timestep = 124. State = [[ 0.00448837  1.4139664   0.4546031   0.13538213 -0.00519406 -0.10297447
   0.          0.        ]]. Action = [[-0.06177199 -0.6493672 ]]. Reward = [-100.]
Abstract state at timestep 124 is 2
State prediction error at timestep 124 is 0.012
Human Feedback received at timestpe 124 of -10
Current timestep = 125. State = [[ 0.00893011  1.4164301   0.44811988  0.1094755  -0.00910584 -0.07824206
   0.          0.        ]]. Action = [[-0.312747   -0.59949154]]. Reward = [0.6458752]
Abstract state at timestep 125 is 3
State prediction error at timestep 125 is 0.012
Human Feedback received at timestpe 125 of -10
Current timestep = 126. State = [[ 0.01341867  1.419026    0.45408377  0.11533182 -0.01427381 -0.10336876
   0.          0.        ]]. Action = [[0.36222327 0.6289604 ]]. Reward = [-1.7234069]
Abstract state at timestep 126 is 3
State prediction error at timestep 126 is 0.012
Human Feedback received at timestpe 126 of -10
Current timestep = 127. State = [[ 0.01775408  1.4220566   0.43710852  0.13465482 -0.01780438 -0.07061841
   0.          0.        ]]. Action = [[ 0.66010165 -0.9037737 ]]. Reward = [0.17523156]
Abstract state at timestep 127 is 3
State prediction error at timestep 127 is 0.012
Human Feedback received at timestpe 127 of 10
Current timestep = 128. State = [[ 0.02208958  1.4244871   0.43711862  0.10797998 -0.02133526 -0.07062419
   0.          0.        ]]. Action = [[-0.44426787  0.08845139]]. Reward = [0.10992341]
Abstract state at timestep 128 is 3
State prediction error at timestep 128 is 0.012
Human Feedback received at timestpe 128 of 10
Current timestep = 129. State = [[ 0.0263916   1.4263184   0.43292585  0.08135138 -0.02402225 -0.05374412
   0.          0.        ]]. Action = [[-0.9802714  -0.55001134]]. Reward = [0.4999111]
Abstract state at timestep 129 is 3
State prediction error at timestep 129 is 0.012
Human Feedback received at timestpe 129 of 10
Current timestep = 130. State = [[ 0.03069382  1.4275498   0.4329327   0.05468253 -0.02670913 -0.053743
   0.          0.        ]]. Action = [[-0.74578816  0.05335343]]. Reward = [0.01262793]
Abstract state at timestep 130 is 3
State prediction error at timestep 130 is 0.012
Human Feedback received at timestpe 130 of 10
Current timestep = 131. State = [[ 0.03493385  1.4292614   0.42531362  0.07605402 -0.02799916 -0.0258032
   0.          0.        ]]. Action = [[ 0.6909238  -0.73126566]]. Reward = [-0.15419297]
Abstract state at timestep 131 is 3
State prediction error at timestep 131 is 0.012
Human Feedback received at timestpe 131 of 10
Current timestep = 132. State = [[ 0.03902235  1.4309912   0.40903687  0.07686581 -0.02818797 -0.00377637
   0.          0.        ]]. Action = [[ 0.28700054 -0.6568596 ]]. Reward = [1.1712466]
Abstract state at timestep 132 is 3
State prediction error at timestep 132 is 0.012
Human Feedback received at timestpe 132 of -10
Current timestep = 133. State = [[ 0.04304037  1.4321258   0.4001922   0.05046291 -0.02660144  0.03173345
   0.          0.        ]]. Action = [[-0.9837475  -0.78596085]]. Reward = [1.2936625]
Abstract state at timestep 133 is 3
State prediction error at timestep 133 is 0.012
Human Feedback received at timestpe 133 of -10
Current timestep = 134. State = [[ 0.04694023  1.4334738   0.38902122  0.05992376 -0.02564315  0.01916769
   0.          0.        ]]. Action = [[ 0.9941654 -0.3260429]]. Reward = [0.62492114]
Abstract state at timestep 134 is 3
State prediction error at timestep 134 is 0.012
Human Feedback received at timestpe 134 of -10
Current timestep = 135. State = [[ 0.05085068  1.4356422   0.39169955  0.09636921 -0.02629132 -0.01296438
   0.          0.        ]]. Action = [[0.8162111 0.7270007]]. Reward = [-1.5661819]
Abstract state at timestep 135 is 3
State prediction error at timestep 135 is 0.012
Human Feedback received at timestpe 135 of -10
Current timestep = 136. State = [[ 0.05483904  1.4376833   0.4012447   0.09066798 -0.02868125 -0.04780298
   0.          0.        ]]. Action = [[0.12642705 0.87872946]]. Reward = [-1.4510431]
Abstract state at timestep 136 is 3
State prediction error at timestep 136 is 0.012
Human Feedback received at timestpe 136 of -10
Current timestep = 137. State = [[ 0.05895767  1.4398655   0.41373459  0.09694301 -0.03052199 -0.03681844
   0.          0.        ]]. Action = [[0.7834474  0.43771553]]. Reward = [-2.043821]
Abstract state at timestep 137 is 3
State prediction error at timestep 137 is 0.012
Human Feedback received at timestpe 137 of -10
Current timestep = 138. State = [[ 0.0630248   1.4414489   0.407268    0.07036209 -0.0310659  -0.01087927
   0.          0.        ]]. Action = [[-0.8297069 -0.5488757]]. Reward = [0.9176272]
Abstract state at timestep 138 is 3
State prediction error at timestep 138 is 0.012
Human Feedback received at timestpe 138 of -10
Current timestep = 139. State = [[ 0.06706218  1.4431329   0.40448865  0.07482925 -0.03181863 -0.01505599
   0.          0.        ]]. Action = [[0.5622382 0.3013432]]. Reward = [-0.30108902]
Abstract state at timestep 139 is 3
State prediction error at timestep 139 is 0.012
Human Feedback received at timestpe 139 of -10
Current timestep = 140. State = [[ 0.07109948  1.4442167   0.40449056  0.04815501 -0.03257076 -0.01504419
   0.          0.        ]]. Action = [[-0.14545417 -0.23961288]]. Reward = [0.19773404]
Abstract state at timestep 140 is 3
State prediction error at timestep 140 is 0.012
Human Feedback received at timestpe 140 of -10
Current timestep = 141. State = [[ 0.07513676  1.4447007   0.40449268  0.02148894 -0.03332291 -0.01504396
   0.          0.        ]]. Action = [[-0.7411633   0.02888215]]. Reward = [0.08442883]
Abstract state at timestep 141 is 3
State prediction error at timestep 141 is 0.012
Human Feedback received at timestpe 141 of -10
Current timestep = 142. State = [[ 0.07912836  1.4449055   0.40016818  0.00908832 -0.03432224 -0.01998843
   0.          0.        ]]. Action = [[ 0.0488553  -0.05184942]]. Reward = [0.18017364]
Abstract state at timestep 142 is 3
State prediction error at timestep 142 is 0.012
Human Feedback received at timestpe 142 of -10
Current timestep = 143. State = [[ 8.2998753e-02  1.4449220e+00  3.8716501e-01  7.2779157e-04
  -3.4443468e-02 -2.4249158e-03  0.0000000e+00  0.0000000e+00]]. Action = [[ 0.36042    -0.54344183]]. Reward = [1.0547547]
Abstract state at timestep 143 is 3
State prediction error at timestep 143 is 0.012
Human Feedback received at timestpe 143 of -10
Current timestep = 144. State = [[ 0.08686914  1.4443383   0.38716492 -0.02594293 -0.03456496 -0.00243026
   0.          0.        ]]. Action = [[-0.67744553 -0.27333593]]. Reward = [-0.06334417]
Abstract state at timestep 144 is 3
State prediction error at timestep 144 is 0.012
Human Feedback received at timestpe 144 of -10
Current timestep = 145. State = [[ 0.09080668  1.4431486   0.39558008 -0.05292163 -0.03637525 -0.03620882
   0.          0.        ]]. Action = [[-0.07950634  0.9019809 ]]. Reward = [-1.2206432]
Abstract state at timestep 145 is 3
State prediction error at timestep 145 is 0.012
Human Feedback received at timestpe 145 of -10
Current timestep = 146. State = [[ 0.09480295  1.4421486   0.40341505 -0.04454077 -0.04012413 -0.07498454
   0.          0.        ]]. Action = [[0.18815112 0.9733188 ]]. Reward = [-1.1843743]
Abstract state at timestep 146 is 3
State prediction error at timestep 146 is 0.012
Human Feedback received at timestpe 146 of -10
Current timestep = 147. State = [[ 0.09875107  1.4410512   0.39888847 -0.04888443 -0.04415794 -0.08068363
   0.          0.        ]]. Action = [[ 0.42199445 -0.14095664]]. Reward = [-0.13426444]
Abstract state at timestep 147 is 3
State prediction error at timestep 147 is 0.012
Human Feedback received at timestpe 147 of -10
Current timestep = 148. State = [[ 0.10264711  1.439349    0.39237478 -0.07573512 -0.04688872 -0.05462046
   0.          0.        ]]. Action = [[-0.18365097 -0.85378295]]. Reward = [0.06950618]
Abstract state at timestep 148 is 3
State prediction error at timestep 148 is 0.012
Human Feedback received at timestpe 148 of -10
Current timestep = 149. State = [[ 0.10641003  1.4375141   0.37813002 -0.08161689 -0.04871047 -0.03643507
   0.          0.        ]]. Action = [[ 0.23587132 -0.5593137 ]]. Reward = [1.0493066]
Abstract state at timestep 149 is 3
State prediction error at timestep 149 is 0.012
Human Feedback received at timestpe 149 of -10
Current timestep = 150. State = [[ 0.11011696  1.4350915   0.37109944 -0.10768109 -0.04911479 -0.00808631
   0.          0.        ]]. Action = [[-0.45434356 -0.7269826 ]]. Reward = [0.19461103]
Abstract state at timestep 150 is 3
State prediction error at timestep 150 is 0.012
Human Feedback received at timestpe 150 of -10
Current timestep = 151. State = [[ 0.11372013  1.4332637   0.36139253 -0.08127237 -0.05017869 -0.02127792
   0.          0.        ]]. Action = [[ 0.9658947  -0.39439988]]. Reward = [1.3517494]
Abstract state at timestep 151 is 3
State prediction error at timestep 151 is 0.012
Human Feedback received at timestpe 151 of -10
Current timestep = 152. State = [[ 0.1173233   1.430836    0.3613925  -0.10793913 -0.05124259 -0.02127792
   0.          0.        ]]. Action = [[-0.3761841   0.00181615]]. Reward = [-0.5683007]
Abstract state at timestep 152 is 3
State prediction error at timestep 152 is 0.012
Human Feedback received at timestpe 152 of -10
Current timestep = 153. State = [[ 0.12096977  1.4277973   0.36684483 -0.13512349 -0.05340702 -0.04328873
   0.          0.        ]]. Action = [[-0.40399706  0.7135651 ]]. Reward = [-1.3425037]
Abstract state at timestep 153 is 3
State prediction error at timestep 153 is 0.012
Human Feedback received at timestpe 153 of -10
Current timestep = 154. State = [[ 0.12456093  1.4241669   0.35987407 -0.16138664 -0.05416929 -0.01524516
   0.          0.        ]]. Action = [[-0.13486528 -0.76608545]]. Reward = [-0.11483536]
Abstract state at timestep 154 is 3
State prediction error at timestep 154 is 0.012
Human Feedback received at timestpe 154 of -10
Current timestep = 155. State = [[ 0.12815198  1.4199363   0.35987407 -0.18805332 -0.05493157 -0.0152452
   0.          0.        ]]. Action = [[-0.29374695 -0.311545  ]]. Reward = [-0.85075665]
Abstract state at timestep 155 is 3
State prediction error at timestep 155 is 0.012
Human Feedback received at timestpe 155 of -10
Current timestep = 156. State = [[ 0.13162136  1.4156373   0.34574372 -0.19102146 -0.05374929  0.02364551
   0.          0.        ]]. Action = [[ 0.08817601 -0.9705828 ]]. Reward = [1.4265712]
Abstract state at timestep 156 is 3
State prediction error at timestep 156 is 0.012
Human Feedback received at timestpe 156 of -10
Current timestep = 157. State = [[ 1.3512745e-01  1.4117215e+00  3.5054055e-01 -1.7403765e-01
  -5.3685077e-02  1.2844001e-03  0.0000000e+00  0.0000000e+00]]. Action = [[0.4007175  0.51455307]]. Reward = [0.50151676]
Abstract state at timestep 157 is 3
State prediction error at timestep 157 is 0.012
Human Feedback received at timestpe 157 of -10
Current timestep = 158. State = [[ 0.13858786  1.4072056   0.34482318 -0.20065673 -0.05247656  0.02417016
   0.          0.        ]]. Action = [[-0.8410596 -0.5526781]]. Reward = [-0.2386792]
Abstract state at timestep 158 is 3
State prediction error at timestep 158 is 0.012
Human Feedback received at timestpe 158 of -10
Current timestep = 159. State = [[ 0.14199543  1.4020952   0.338178   -0.2270373  -0.04993343  0.05086302
   0.          0.        ]]. Action = [[-0.8487031  -0.64967614]]. Reward = [-0.12699355]
Abstract state at timestep 159 is 3
State prediction error at timestep 159 is 0.012
Human Feedback received at timestpe 159 of -10
Current timestep = 160. State = [[ 0.14535113  1.3963888   0.3316757  -0.25349888 -0.04608585  0.07695162
   0.          0.        ]]. Action = [[-0.02738202 -0.6441283 ]]. Reward = [-0.11480628]
Abstract state at timestep 160 is 3
State prediction error at timestep 160 is 0.012
Human Feedback received at timestpe 160 of -10
Current timestep = 161. State = [[ 0.14870682  1.3900824   0.33167562 -0.28016675 -0.04223827  0.07695154
   0.          0.        ]]. Action = [[-0.24167597 -0.23225856]]. Reward = [-0.6944196]
Abstract state at timestep 161 is 3
State prediction error at timestep 161 is 0.012
Human Feedback received at timestpe 161 of -10
Current timestep = 162. State = [[ 0.15195389  1.383781    0.32139555 -0.2799713  -0.03897144  0.06533659
   0.          0.        ]]. Action = [[ 0.52388895 -0.2938996 ]]. Reward = [1.4825879]
Abstract state at timestep 162 is 3
State prediction error at timestep 162 is 0.012
Human Feedback received at timestpe 162 of -10
Current timestep = 163. State = [[ 0.15520096  1.3768797   0.3213955  -0.3066389  -0.03570462  0.06533656
   0.          0.        ]]. Action = [[-0.66058767 -0.47577   ]]. Reward = [-0.82050747]
Abstract state at timestep 163 is 3
State prediction error at timestep 163 is 0.012
Human Feedback received at timestpe 163 of -10
Current timestep = 164. State = [[ 0.15853624  1.3693662   0.33247823 -0.33391678 -0.03466416  0.02080955
   0.          0.        ]]. Action = [[-0.808468  0.928993]]. Reward = [-1.9155334]
Abstract state at timestep 164 is 3
State prediction error at timestep 164 is 0.012
Human Feedback received at timestpe 164 of -10
Current timestep = 165. State = [[ 0.1618104   1.3612539   0.32480428 -0.3604849  -0.03208647  0.05155354
   0.          0.        ]]. Action = [[-0.5120719  -0.83660877]]. Reward = [-0.40132216]
Abstract state at timestep 165 is 3
State prediction error at timestep 165 is 0.012
Human Feedback received at timestpe 165 of -10
Current timestep = 166. State = [[ 0.16519031  1.3530636   0.33494166 -0.3639537  -0.02907091  0.06031144
   0.          0.        ]]. Action = [[0.9557936  0.08451402]]. Reward = [-0.15812157]
Abstract state at timestep 166 is 3
State prediction error at timestep 166 is 0.012
Human Feedback received at timestpe 166 of -10
Current timestep = 167. State = [[ 0.16840744  1.3446206   0.31717104 -0.3751643  -0.02459215  0.08957543
   0.          0.        ]]. Action = [[ 0.30050135 -0.7967107 ]]. Reward = [1.3623121]
Abstract state at timestep 167 is 3
State prediction error at timestep 167 is 0.012
Human Feedback received at timestpe 167 of -10
Current timestep = 168. State = [[ 0.17156763  1.336221    0.3118043  -0.37324923 -0.02042459  0.08335125
   0.          0.        ]]. Action = [[ 0.10477936 -0.00771433]]. Reward = [1.5364486]
Abstract state at timestep 168 is 3
State prediction error at timestep 168 is 0.012
Human Feedback received at timestpe 168 of -10
Current timestep = 169. State = [[ 0.17465296  1.3272258   0.30239838 -0.39971453 -0.01437219  0.12104791
   0.          0.        ]]. Action = [[-0.8615772 -0.9035846]]. Reward = [-0.05606577]
Abstract state at timestep 169 is 3
State prediction error at timestep 169 is 0.012
Human Feedback received at timestpe 169 of 10
Current timestep = 170. State = [[ 0.17782097  1.3183644   0.31031632 -0.3937902  -0.00796922  0.12805948
   0.          0.        ]]. Action = [[0.37650073 0.32275176]]. Reward = [1.2553614]
Abstract state at timestep 170 is 3
State prediction error at timestep 170 is 0.012
Human Feedback received at timestpe 170 of 10
Current timestep = 171. State = [[ 0.18098907  1.3089036   0.31031626 -0.42046028 -0.00156625  0.12805912
   0.          0.        ]]. Action = [[-0.33921468 -0.30874026]]. Reward = [-0.586033]
Abstract state at timestep 171 is 3
State prediction error at timestep 171 is 0.012
Human Feedback received at timestpe 171 of 10
Current timestep = 172. State = [[ 0.18411484  1.2988456   0.30501646 -0.44703257  0.0058981   0.14928713
   0.          0.        ]]. Action = [[-0.16757077 -0.54156214]]. Reward = [-1.3571068]
Abstract state at timestep 172 is 3
State prediction error at timestep 172 is 0.012
Human Feedback received at timestpe 172 of 10
Current timestep = 173. State = [[ 0.18725233  1.2891467   0.30612105 -0.4311142   0.01343492  0.15073645
   0.          0.        ]]. Action = [[ 0.66994    -0.28540534]]. Reward = [1.1547495]
Abstract state at timestep 173 is 3
State prediction error at timestep 173 is 0.012
Human Feedback received at timestpe 173 of 10
Current timestep = 174. State = [[ 0.19038992  1.2788485   0.30612105 -0.45778564  0.02097171  0.15073584
   0.          0.        ]]. Action = [[-0.5287606  -0.16415924]]. Reward = [-1.9768047]
Abstract state at timestep 174 is 3
State prediction error at timestep 174 is 0.012
Human Feedback received at timestpe 174 of 10
Current timestep = 175. State = [[ 0.19343558  1.2683643   0.29734018 -0.46608517  0.02811068  0.14277937
   0.          0.        ]]. Action = [[ 0.15260148 -0.12867564]]. Reward = [-0.11010022]
Abstract state at timestep 175 is 3
State prediction error at timestep 175 is 0.012
Human Feedback received at timestpe 175 of 10
Current timestep = 176. State = [[ 0.19648123  1.2572807   0.29734033 -0.49275616  0.03524963  0.14277887
   0.          0.        ]]. Action = [[-0.03210825 -0.07110012]]. Reward = [-1.9313765]
Abstract state at timestep 176 is 3
State prediction error at timestep 176 is 0.012
Human Feedback received at timestpe 176 of 10
Current timestep = 177. State = [[ 0.19952688  1.2455977   0.29734054 -0.51942706  0.04238855  0.14277834
   0.          0.        ]]. Action = [[-0.5035846  0.3568728]]. Reward = [-1.9069798]
Abstract state at timestep 177 is 3
State prediction error at timestep 177 is 0.012
Human Feedback received at timestpe 177 of 10
Current timestep = 178. State = [[ 0.20250817  1.2333205   0.28926548 -0.5459328   0.05114047  0.17503843
   0.          0.        ]]. Action = [[-0.50467384 -0.90453404]]. Reward = [-1.6702954]
Abstract state at timestep 178 is 3
State prediction error at timestep 178 is 0.012
Human Feedback received at timestpe 178 of 10
Current timestep = 179. State = [[ 0.20546837  1.2211983   0.28909624 -0.5390098   0.05797848  0.1367604
   0.          0.        ]]. Action = [[0.0031929 0.9829929]]. Reward = [0.9023808]
Abstract state at timestep 179 is 3
State prediction error at timestep 179 is 0.012
Human Feedback received at timestpe 179 of 10
Current timestep = 180. State = [[ 0.208496    1.2084787   0.29756802 -0.56552726  0.06311946  0.10281941
   0.          0.        ]]. Action = [[-0.6923585  0.8169414]]. Reward = [-2.0748408]
Abstract state at timestep 180 is 3
State prediction error at timestep 180 is 0.012
Human Feedback received at timestpe 180 of 10
Current timestep = 181. State = [[ 0.21152362  1.1951594   0.2975682  -0.59219617  0.06826042  0.1028192
   0.          0.        ]]. Action = [[-0.1754173   0.30456305]]. Reward = [-1.6259302]
Abstract state at timestep 181 is 3
State prediction error at timestep 181 is 0.012
Human Feedback received at timestpe 181 of 10
Current timestep = 182. State = [[ 0.21459608  1.1812426   0.30319238 -0.61872166  0.07227401  0.08027209
   0.          0.        ]]. Action = [[-0.97298694  0.5307454 ]]. Reward = [-1.7277863]
Abstract state at timestep 182 is 3
State prediction error at timestep 182 is 0.012
Human Feedback received at timestpe 182 of 10
Current timestep = 183. State = [[ 0.21760377  1.1667107   0.29504347 -0.6461449   0.07793596  0.11323919
   0.          0.        ]]. Action = [[-0.9755058  -0.79303753]]. Reward = [-1.3456938]
Abstract state at timestep 183 is 3
State prediction error at timestep 183 is 0.012
Human Feedback received at timestpe 183 of 10
Current timestep = 184. State = [[ 0.22042751  1.1519986   0.27546892 -0.6542486   0.08477549  0.13679045
   0.          0.        ]]. Action = [[ 0.21305335 -0.66898245]]. Reward = [0.5515675]
Abstract state at timestep 184 is 3
State prediction error at timestep 184 is 0.012
Human Feedback received at timestpe 184 of 10
Current timestep = 185. State = [[ 0.22323123  1.1372628   0.2734093  -0.65534025  0.0916734   0.13795811
   0.          0.        ]]. Action = [[ 0.15339625 -0.19529057]]. Reward = [0.50945455]
Abstract state at timestep 185 is 3
State prediction error at timestep 185 is 0.012
Human Feedback received at timestpe 185 of 10
Current timestep = 186. State = [[ 0.22605324  1.122219    0.27646953 -0.6689741   0.09735605  0.11365318
   0.          0.        ]]. Action = [[0.03681099 0.60344255]]. Reward = [-0.69794166]
Abstract state at timestep 186 is 3
State prediction error at timestep 186 is 0.012
Human Feedback received at timestpe 186 of 10
Current timestep = 187. State = [[ 0.22887516  1.1065756   0.2764699  -0.69564354  0.1030387   0.11365293
   0.          0.        ]]. Action = [[-0.31294394  0.37502968]]. Reward = [-1.5636696]
Abstract state at timestep 187 is 3
State prediction error at timestep 187 is 0.012
Human Feedback received at timestpe 187 of 10
Current timestep = 188. State = [[ 0.23169298  1.0911548   0.2758106  -0.6857927   0.10896344  0.11849475
   0.          0.        ]]. Action = [[0.31660235 0.05754244]]. Reward = [1.6006957]
Abstract state at timestep 188 is 3
State prediction error at timestep 188 is 0.012
Human Feedback received at timestpe 188 of 10
Current timestep = 189. State = [[ 0.23448925  1.0758425   0.27352494 -0.681008    0.1150273   0.12127725
   0.          0.        ]]. Action = [[0.18864536 0.10213578]]. Reward = [1.1826789]
Abstract state at timestep 189 is 3
State prediction error at timestep 189 is 0.012
Human Feedback received at timestpe 189 of 10
Current timestep = 190. State = [[ 0.23728552  1.0599306   0.27352545 -0.70767766  0.12109116  0.12127694
   0.          0.        ]]. Action = [[-0.29898667  0.4017638 ]]. Reward = [-1.594313]
Abstract state at timestep 190 is 3
State prediction error at timestep 190 is 0.012
Human Feedback received at timestpe 190 of 10
Current timestep = 191. State = [[ 0.2400134   1.0433985   0.26493382 -0.73541486  0.12891194  0.15641533
   0.          0.        ]]. Action = [[-0.6231183  -0.81921107]]. Reward = [-1.5530156]
Abstract state at timestep 191 is 3
State prediction error at timestep 191 is 0.012
Human Feedback received at timestpe 191 of 10
Current timestep = 192. State = [[ 0.2427413   1.0262673   0.26493478 -0.7620867   0.1367327   0.15641469
   0.          0.        ]]. Action = [[-0.09714389  0.30142403]]. Reward = [-1.6901189]
Abstract state at timestep 192 is 3
State prediction error at timestep 192 is 0.012
Human Feedback received at timestpe 192 of 10
Current timestep = 193. State = [[ 0.2454691   1.0085369   0.2649358  -0.7887584   0.1445534   0.15641402
   0.          0.        ]]. Action = [[-0.7408704  -0.04370892]]. Reward = [-1.6455383]
Abstract state at timestep 193 is 3
State prediction error at timestep 193 is 0.012
Human Feedback received at timestpe 193 of 10
Current timestep = 194. State = [[ 0.24805507  0.99106306  0.25102696 -0.77736485  0.15210566  0.15104575
   0.          0.        ]]. Action = [[0.80777395 0.41144633]]. Reward = [2.125443]
Abstract state at timestep 194 is 3
State prediction error at timestep 194 is 0.012
Human Feedback received at timestpe 194 of 10
Current timestep = 195. State = [[ 0.25033227  0.97375333  0.2192713  -0.7702101   0.16054596  0.16880532
   0.          0.        ]]. Action = [[ 0.8333303 -0.6593675]]. Reward = [2.0906923]
Abstract state at timestep 195 is 4
State prediction error at timestep 195 is 0.012
Human Feedback received at timestpe 195 of 10
Current timestep = 196. State = [[ 0.25260934  0.95584446  0.21927269 -0.7968826   0.16898617  0.16880445
   0.          0.        ]]. Action = [[-0.39654934  0.17691553]]. Reward = [-1.7370625]
Abstract state at timestep 196 is 4
State prediction error at timestep 196 is 0.012
Human Feedback received at timestpe 196 of 10
Current timestep = 197. State = [[ 0.25485057  0.9381761   0.2175566  -0.7860222   0.17557412  0.13175878
   0.          0.        ]]. Action = [[0.11918807 0.92147255]]. Reward = [1.8868767]
Abstract state at timestep 197 is 4
State prediction error at timestep 197 is 0.012
Human Feedback received at timestpe 197 of 10
Current timestep = 198. State = [[ 0.2570919   0.9199083   0.21755747 -0.81269246  0.18216205  0.13175836
   0.          0.        ]]. Action = [[-0.3942654  0.2698264]]. Reward = [-1.5306028]
Abstract state at timestep 198 is 4
State prediction error at timestep 198 is 0.012
Human Feedback received at timestpe 198 of 10
Current timestep = 199. State = [[ 0.25933313  0.90104115  0.21755846 -0.8393627   0.18874992  0.131758
   0.          0.        ]]. Action = [[-0.84671134 -0.16999316]]. Reward = [-1.4838909]
Abstract state at timestep 199 is 4
State prediction error at timestep 199 is 0.012
Human Feedback received at timestpe 199 of 10
Current timestep = 200. State = [[ 0.26150265  0.8815524   0.20854136 -0.86725765  0.1971986   0.1689736
   0.          0.        ]]. Action = [[-0.6031826 -0.8776253]]. Reward = [-1.5492885]
Abstract state at timestep 200 is 4
State prediction error at timestep 200 is 0.012
Human Feedback received at timestpe 200 of 10
Current timestep = 201. State = [[ 0.26367196  0.86146474  0.20854306 -0.89393014  0.20564725  0.1689728
   0.          0.        ]]. Action = [[-0.0947938   0.11940181]]. Reward = [-1.5795901]
Abstract state at timestep 201 is 4
State prediction error at timestep 201 is 0.012
Human Feedback received at timestpe 201 of 10
Current timestep = 202. State = [[ 0.2658412   0.840778    0.20854485 -0.9206026   0.21409582  0.16897199
   0.          0.        ]]. Action = [[-0.9161871  -0.10994452]]. Reward = [-1.533483]
Abstract state at timestep 202 is 4
State prediction error at timestep 202 is 0.012
Human Feedback received at timestpe 202 of 10
Current timestep = 203. State = [[ 0.26781923  0.82003987  0.18994197 -0.9228604   0.22204001  0.15888394
   0.          0.        ]]. Action = [[0.46416402 0.28773856]]. Reward = [1.0721674]
Abstract state at timestep 203 is 4
State prediction error at timestep 203 is 0.012
Human Feedback received at timestpe 203 of 10
Current timestep = 204. State = [[ 0.26965255  0.7996883   0.17547211 -0.90571415  0.23000215  0.15924296
   0.          0.        ]]. Action = [[0.37101126 0.4353497 ]]. Reward = [2.836866]
Abstract state at timestep 204 is 4
State prediction error at timestep 204 is 0.012
Human Feedback received at timestpe 204 of 10
Current timestep = 205. State = [[ 0.27124578  0.77955437  0.15198171 -0.8960106   0.23745836  0.1491243
   0.          0.        ]]. Action = [[0.26967788 0.2768674 ]]. Reward = [2.2917118]
Abstract state at timestep 205 is 4
State prediction error at timestep 205 is 0.012
Human Feedback received at timestpe 205 of 10
Current timestep = 206. State = [[ 0.27275285  0.7602289   0.14274423 -0.8602131   0.24554935  0.16181967
   0.          0.        ]]. Action = [[ 0.8918381  -0.08319229]]. Reward = [4.3623343]
Abstract state at timestep 206 is 4
State prediction error at timestep 206 is 0.012
Human Feedback received at timestpe 206 of 10
Current timestep = 207. State = [[ 0.27425975  0.7403043   0.14274618 -0.88688505  0.2536403   0.161819
   0.          0.        ]]. Action = [[-0.8352671  -0.28873467]]. Reward = [-1.621086]
Abstract state at timestep 207 is 4
State prediction error at timestep 207 is 0.012
Human Feedback received at timestpe 207 of 10
Current timestep = 208. State = [[ 0.27576646  0.7197806   0.1427482  -0.913557    0.26173124  0.1618183
   0.          0.        ]]. Action = [[-0.42733485 -0.4148028 ]]. Reward = [-1.5759298]
Abstract state at timestep 208 is 4
State prediction error at timestep 208 is 0.012
Human Feedback received at timestpe 208 of 10
Current timestep = 209. State = [[ 0.2768156   0.69985443  0.09596951 -0.8872329   0.27087364  0.18284799
   0.          0.        ]]. Action = [[ 0.87544143 -0.7239744 ]]. Reward = [3.824962]
Abstract state at timestep 209 is 4
State prediction error at timestep 209 is 0.012
Human Feedback received at timestpe 209 of 10
Current timestep = 210. State = [[ 0.27786446  0.67932934  0.09597225 -0.9139063   0.28001598  0.18284693
   0.          0.        ]]. Action = [[-0.14821762 -0.35281932]]. Reward = [-1.7014725]
Abstract state at timestep 210 is 4
State prediction error at timestep 210 is 0.012
Human Feedback received at timestpe 210 of 10
Current timestep = 211. State = [[ 0.27885333  0.6581872   0.08848357 -0.9416753   0.29071435  0.21396787
   0.          0.        ]]. Action = [[-0.27990204 -0.9768368 ]]. Reward = [-1.8744665]
Abstract state at timestep 211 is 4
State prediction error at timestep 211 is 0.012
Human Feedback received at timestpe 211 of 10
Current timestep = 212. State = [[ 0.27975035  0.63775796  0.07860982 -0.9102277   0.30216706  0.22905347
   0.          0.        ]]. Action = [[ 0.8357575  -0.13484061]]. Reward = [3.6406307]
Abstract state at timestep 212 is 4
State prediction error at timestep 212 is 0.012
Human Feedback received at timestpe 212 of 10
Current timestep = 213. State = [[ 0.28052855  0.6175059   0.06657743 -0.9024635   0.31380853  0.23282926
   0.          0.        ]]. Action = [[ 0.82087827 -0.11461991]]. Reward = [1.2503072]
Abstract state at timestep 213 is 4
State prediction error at timestep 213 is 0.012
Human Feedback received at timestpe 213 of 10
Current timestep = 214. State = [[ 0.28130636  0.5966558   0.06658258 -0.92914104  0.32544988  0.23282711
   0.          0.        ]]. Action = [[-0.10910773 -0.09684318]]. Reward = [-1.9653724]
Abstract state at timestep 214 is 4
State prediction error at timestep 214 is 0.012
Human Feedback received at timestpe 214 of 10
Current timestep = 215. State = [[ 0.28172332  0.5765011   0.03082902 -0.89825076  0.33678758  0.22675371
   0.          0.        ]]. Action = [[ 0.89846647 -0.08456141]]. Reward = [3.6548193]
Abstract state at timestep 215 is 4
State prediction error at timestep 215 is 0.012
Human Feedback received at timestpe 215 of 10
Current timestep = 216. State = [[ 0.28213978  0.555748    0.03083425 -0.9249276   0.34812516  0.22675169
   0.          0.        ]]. Action = [[-0.15927696 -0.2231164 ]]. Reward = [-1.9608576]
Abstract state at timestep 216 is 4
State prediction error at timestep 216 is 0.012
Human Feedback received at timestpe 216 of 10
Current timestep = 217. State = [[ 0.28252488  0.53437495  0.02688799 -0.9527748   0.36035752  0.24464746
   0.          0.        ]]. Action = [[-0.0850479  -0.52216256]]. Reward = [-2.130133]
Abstract state at timestep 217 is 4
State prediction error at timestep 217 is 0.012
Human Feedback received at timestpe 217 of 10
Current timestep = 218. State = [[ 0.28277054  0.5134812   0.01245613 -0.9317073   0.3731603   0.2560559
   0.          0.        ]]. Action = [[0.5887401  0.41447234]]. Reward = [2.444891]
Abstract state at timestep 218 is 4
State prediction error at timestep 218 is 0.012
Human Feedback received at timestpe 218 of 10
Current timestep = 219. State = [[ 0.28296146  0.49195957  0.00563883 -0.96009624  0.38747105  0.28621477
   0.          0.        ]]. Action = [[-0.447047  -0.8177222]]. Reward = [-2.421636]
Abstract state at timestep 219 is 4
State prediction error at timestep 219 is 0.012
Human Feedback received at timestpe 219 of 10
Current timestep = 220. State = [[ 0.2829674   0.47072384 -0.01302278 -0.94758314  0.40202132  0.2910052
   0.          0.        ]]. Action = [[0.80872035 0.0300796 ]]. Reward = [1.3479731]
Abstract state at timestep 220 is 5
State prediction error at timestep 220 is 0.012
Human Feedback received at timestpe 220 of 10
Current timestep = 221. State = [[ 0.282708    0.4500857  -0.04142969 -0.9217331   0.41868645  0.3333028
   0.          0.        ]]. Action = [[ 0.6354867 -0.9461646]]. Reward = [2.332659]
Abstract state at timestep 221 is 5
State prediction error at timestep 221 is 0.012
Human Feedback received at timestpe 221 of 10
Current timestep = 222. State = [[ 0.282232    0.43015066 -0.06161853 -0.8902373   0.43387443  0.30375957
   0.          0.        ]]. Action = [[0.82021856 0.7949493 ]]. Reward = [2.9172876]
Abstract state at timestep 222 is 5
State prediction error at timestep 222 is 0.012
Human Feedback received at timestpe 222 of 10
Current timestep = 223. State = [[ 0.28181392  0.4096668  -0.05409395 -0.9142463   0.44727194  0.26795003
   0.          0.        ]]. Action = [[-0.53827024  0.9906614 ]]. Reward = [-1.9936068]
Abstract state at timestep 223 is 5
State prediction error at timestep 223 is 0.012
Human Feedback received at timestpe 223 of 10
Current timestep = 224. State = [[ 0.28107634  0.38950533 -0.0858581  -0.89999634  0.4605683   0.2659265
   0.          0.        ]]. Action = [[ 0.8528724  -0.12350124]]. Reward = [1.2594042]
Abstract state at timestep 224 is 5
State prediction error at timestep 224 is 0.012
Human Feedback received at timestpe 224 of 10
Current timestep = 225. State = [[ 0.28006238  0.36916223 -0.11520543 -0.9087814   0.47583395  0.3053127
   0.          0.        ]]. Action = [[ 0.6995175  -0.96350336]]. Reward = [-1.3118951]
Abstract state at timestep 225 is 5
State prediction error at timestep 225 is 0.012
Human Feedback received at timestpe 225 of 10
Current timestep = 226. State = [[ 0.2790475   0.3482219  -0.11519227 -0.9354655   0.49109936  0.3053078
   0.          0.        ]]. Action = [[-0.7417892   0.33694494]]. Reward = [-2.460308]
Abstract state at timestep 226 is 5
State prediction error at timestep 226 is 0.012
Human Feedback received at timestpe 226 of 10
Current timestep = 227. State = [[ 0.27768525  0.32779112 -0.1481837  -0.9123602   0.50453967  0.2688058
   0.          0.        ]]. Action = [[0.62286437 0.84478045]]. Reward = [1.872279]
Abstract state at timestep 227 is 5
State prediction error at timestep 227 is 0.012
Human Feedback received at timestpe 227 of 10
Current timestep = 228. State = [[ 0.2759549   0.30792361 -0.18306331 -0.88674074  0.5158818   0.22684188
   0.          0.        ]]. Action = [[0.6916561  0.97382605]]. Reward = [2.0821226]
Abstract state at timestep 228 is 5
State prediction error at timestep 228 is 0.012
Human Feedback received at timestpe 228 of 10
Current timestep = 229. State = [[ 0.2742239   0.2874576  -0.18305546 -0.9134168   0.52722377  0.22683986
   0.          0.        ]]. Action = [[-0.3375982  0.2454791]]. Reward = [-2.1277347]
Abstract state at timestep 229 is 5
State prediction error at timestep 229 is 0.012
Human Feedback received at timestpe 229 of 10
Current timestep = 230. State = [[ 0.27254295  0.26643455 -0.17664257 -0.9377019   0.5370028   0.19558078
   0.          0.        ]]. Action = [[-0.11588824  0.81036186]]. Reward = [-1.6497834]
Abstract state at timestep 230 is 5
State prediction error at timestep 230 is 0.012
Human Feedback received at timestpe 230 of 10
Current timestep = 231. State = [[ 0.27053127  0.24569665 -0.20974049 -0.9251155   0.5468639   0.19722348
   0.          0.        ]]. Action = [[ 0.8105295  -0.38037252]]. Reward = [0.8712827]
Abstract state at timestep 231 is 5
State prediction error at timestep 231 is 0.012
Human Feedback received at timestpe 231 of 10
Current timestep = 232. State = [[ 0.26823577  0.22497712 -0.2379493  -0.92431015  0.5565961   0.1946434
   0.          0.        ]]. Action = [[ 0.3212031  -0.30296052]]. Reward = [-0.22100651]
Abstract state at timestep 232 is 5
State prediction error at timestep 232 is 0.012
Human Feedback received at timestpe 232 of 10
Current timestep = 233. State = [[ 0.2659852   0.20370649 -0.23209894 -0.948306    0.5647999   0.16407749
   0.          0.        ]]. Action = [[-0.71794885  0.67524683]]. Reward = [-1.519151]
Abstract state at timestep 233 is 5
State prediction error at timestep 233 is 0.012
Human Feedback received at timestpe 233 of 10
Current timestep = 234. State = [[ 0.26362658  0.18232335 -0.24134406 -0.9526915   0.57121897  0.1283817
   0.          0.        ]]. Action = [[0.5970105  0.85096276]]. Reward = [-0.10625482]
Abstract state at timestep 234 is 5
State prediction error at timestep 234 is 0.012
Human Feedback received at timestpe 234 of 10
Current timestep = 235. State = [[ 0.26106328  0.16080302 -0.2617653  -0.9588083   0.5776134   0.1278892
   0.          0.        ]]. Action = [[0.1517849 0.4118315]]. Reward = [-0.5316045]
Abstract state at timestep 235 is 5
State prediction error at timestep 235 is 0.012
Human Feedback received at timestpe 235 of 10
Current timestep = 236. State = [[ 0.2584998   0.1386831  -0.26176253 -0.9854778   0.58400786  0.12788884
   0.          0.        ]]. Action = [[-0.05480081  0.31369674]]. Reward = [-1.888423]
Abstract state at timestep 236 is 5
State prediction error at timestep 236 is 0.012
Human Feedback received at timestpe 236 of 10
Current timestep = 237. State = [[ 0.25552493  0.11705268 -0.30132097 -0.9630488   0.5885509   0.09086086
   0.          0.        ]]. Action = [[0.90193546 0.8506783 ]]. Reward = [1.5203788]
Abstract state at timestep 237 is 5
State prediction error at timestep 237 is 0.012
Human Feedback received at timestpe 237 of 10
Current timestep = 238. State = [[ 0.25233507  0.09544445 -0.3219144  -0.9616726   0.59202766  0.06953425
   0.          0.        ]]. Action = [[0.7496005  0.51290095]]. Reward = [-0.00127434]
Abstract state at timestep 238 is 5
State prediction error at timestep 238 is 0.012
Human Feedback received at timestpe 238 of 10
Current timestep = 239. State = [[ 0.24882488  0.07384473 -0.35494286 -0.9617528   0.5966905   0.09325755
   0.          0.        ]]. Action = [[ 0.6044471 -0.5467224]]. Reward = [-0.8040296]
Abstract state at timestep 239 is 5
State prediction error at timestep 239 is 0.012
Human Feedback received at timestpe 239 of 10
Current timestep = 240. State = [[ 0.24521628  0.05191806 -0.36483803 -0.9763311   0.60145074  0.09520593
   0.          1.        ]]. Action = [[ 0.13379979 -0.13012809]]. Reward = [8.532684]
Abstract state at timestep 240 is 5
State prediction error at timestep 240 is 0.012
Human Feedback received at timestpe 240 of 10
Current timestep = 241. State = [[ 0.24148521  0.03060759 -0.3655704  -0.94490904  0.5896868  -0.24000153
   0.          1.        ]]. Action = [[-0.73203194 -0.27900124]]. Reward = [4.8109307]
Abstract state at timestep 241 is 5
State prediction error at timestep 241 is 0.012
Human Feedback received at timestpe 241 of 10
Current timestep = 242. State = [[ 0.23784427  0.00999478 -0.33856037 -0.9060118   0.5604229  -0.58523905
   0.          0.        ]]. Action = [[-0.7190644   0.62625265]]. Reward = [-1.9602597]
Abstract state at timestep 242 is 5
State prediction error at timestep 242 is 0.012
Human Feedback received at timestpe 242 of 10
Current timestep = 243. State = [[ 0.00140476  1.4019378   0.14226715 -0.3992155  -0.00162093 -0.03222566
   0.          0.        ]]. Action = [[ 0.85031915 -0.14114434]]. Reward = [-100.]
Abstract state at timestep 243 is 5
State prediction error at timestep 243 is 0.012
Human Feedback received at timestpe 243 of 10
Current timestep = 244. State = [[ 0.00265818  1.3937702   0.127694   -0.36301425 -0.00394821 -0.04654941
   0.          0.        ]]. Action = [[ 0.87017345 -0.13479125]]. Reward = [4.202267]
Abstract state at timestep 244 is 3
State prediction error at timestep 244 is 0.012
Human Feedback received at timestpe 244 of 10
Current timestep = 245. State = [[ 0.00395451  1.3849995   0.13307543 -0.38982552 -0.00735151 -0.06807263
   0.          0.        ]]. Action = [[-0.10417193  0.5711534 ]]. Reward = [-2.190258]
Abstract state at timestep 245 is 3
State prediction error at timestep 245 is 0.012
Human Feedback received at timestpe 245 of 10
Current timestep = 246. State = [[ 0.00525103  1.3756287   0.13308573 -0.41649243 -0.01075416 -0.06805911
   0.          0.        ]]. Action = [[-0.18796861 -0.35736012]]. Reward = [-1.936125]
Abstract state at timestep 246 is 3
State prediction error at timestep 246 is 0.012
Human Feedback received at timestpe 246 of 10
Current timestep = 247. State = [[ 0.0065237   1.366149    0.13084702 -0.42135912 -0.01428728 -0.07066873
   0.          0.        ]]. Action = [[0.13431776 0.10692334]]. Reward = [0.027054]
Abstract state at timestep 247 is 3
State prediction error at timestep 247 is 0.012
Human Feedback received at timestpe 247 of 10
Current timestep = 248. State = [[ 0.00778389  1.3568059   0.12968491 -0.4152838  -0.01791377 -0.07253639
   0.          0.        ]]. Action = [[ 0.1601466  -0.23232818]]. Reward = [1.0115588]
Abstract state at timestep 248 is 3
State prediction error at timestep 248 is 0.012
Human Feedback received at timestpe 248 of 10
Current timestep = 249. State = [[ 0.00897713  1.3478953   0.1233717  -0.39607865 -0.02191833 -0.08009889
   0.          0.        ]]. Action = [[0.5927012  0.21763086]]. Reward = [2.272332]
Abstract state at timestep 249 is 3
State prediction error at timestep 249 is 0.012
Human Feedback received at timestpe 249 of 10
Current timestep = 250. State = [[ 0.01017055  1.3383849   0.1233834  -0.4227538  -0.02592201 -0.08008064
   0.          0.        ]]. Action = [[-0.7914612   0.10105276]]. Reward = [-2.004496]
Abstract state at timestep 250 is 3
State prediction error at timestep 250 is 0.012
Human Feedback received at timestpe 250 of 10
Current timestep = 251. State = [[ 0.01136408  1.3282745   0.12339516 -0.44941992 -0.02992523 -0.08007171
   0.          0.        ]]. Action = [[-0.16305518 -0.05132365]]. Reward = [-1.9564052]
Abstract state at timestep 251 is 3
State prediction error at timestep 251 is 0.012
Human Feedback received at timestpe 251 of 10
Current timestep = 252. State = [[ 0.01244164  1.3184129   0.11244166 -0.43839896 -0.03455885 -0.09268124
   0.          0.        ]]. Action = [[ 0.6825583  -0.07032621]]. Reward = [1.6157297]
Abstract state at timestep 252 is 3
State prediction error at timestep 252 is 0.012
Human Feedback received at timestpe 252 of 10
Current timestep = 253. State = [[ 0.01345596  1.308762    0.10650853 -0.4290589  -0.03958002 -0.1004326
   0.          0.        ]]. Action = [[ 0.4944303  -0.04624939]]. Reward = [1.2885643]
Abstract state at timestep 253 is 3
State prediction error at timestep 253 is 0.012
Human Feedback received at timestpe 253 of 10
Current timestep = 254. State = [[ 0.01447048  1.298511    0.1065229  -0.45573267 -0.04460035 -0.10041542
   0.          0.        ]]. Action = [[-0.4754002   0.06806803]]. Reward = [-2.0716333]
Abstract state at timestep 254 is 3
State prediction error at timestep 254 is 0.012
Human Feedback received at timestpe 254 of 10
Current timestep = 255. State = [[ 0.0154851   1.2876606   0.1065375  -0.48240086 -0.04962007 -0.10040355
   0.          0.        ]]. Action = [[-0.15998614  0.01879144]]. Reward = [-2.019046]
Abstract state at timestep 255 is 3
State prediction error at timestep 255 is 0.012
Human Feedback received at timestpe 255 of 10
Current timestep = 256. State = [[ 0.0165      1.2762105   0.1065519  -0.50907093 -0.05463903 -0.10038837
   0.          0.        ]]. Action = [[-0.96232367  0.20345414]]. Reward = [-1.9659669]
Abstract state at timestep 256 is 3
State prediction error at timestep 256 is 0.012
Human Feedback received at timestpe 256 of 10
Current timestep = 257. State = [[ 0.0175149   1.2641608   0.1065663  -0.5357417  -0.0596572  -0.10037261
   0.          0.        ]]. Action = [[-0.18102425  0.18736851]]. Reward = [-1.9118289]
Abstract state at timestep 257 is 3
State prediction error at timestep 257 is 0.012
Human Feedback received at timestpe 257 of 10
Current timestep = 258. State = [[ 0.01860533  1.2515085   0.11601233 -0.56261516 -0.06656594 -0.1381871
   0.          0.        ]]. Action = [[-0.97106034  0.77745485]]. Reward = [-2.2720637]
Abstract state at timestep 258 is 3
State prediction error at timestep 258 is 0.012
Human Feedback received at timestpe 258 of 10
Current timestep = 259. State = [[ 0.01962309  1.2382624   0.10688391 -0.58894277 -0.07163496 -0.10138942
   0.          0.        ]]. Action = [[-0.8365448 -0.909334 ]]. Reward = [-1.6224521]
Abstract state at timestep 259 is 3
State prediction error at timestep 259 is 0.012
Human Feedback received at timestpe 259 of 10
Current timestep = 260. State = [[ 0.02058859  1.22442     0.10033828 -0.6154047  -0.07538779 -0.07506342
   0.          0.        ]]. Action = [[-0.848588  -0.8023626]]. Reward = [-1.5136417]
Abstract state at timestep 260 is 3
State prediction error at timestep 260 is 0.012
Human Feedback received at timestpe 260 of 10
Current timestep = 261. State = [[ 0.02168989  1.2107158   0.11588274 -0.60937625 -0.08108926 -0.1140396
   0.          0.        ]]. Action = [[0.10149813 0.97973585]]. Reward = [0.92692786]
Abstract state at timestep 261 is 3
State prediction error at timestep 261 is 0.012
Human Feedback received at timestpe 261 of 10
Current timestep = 262. State = [[ 0.02302103  1.197178    0.14051753 -0.60209405 -0.08843064 -0.1468412
   0.          0.        ]]. Action = [[0.24527383 0.8706162 ]]. Reward = [0.6063393]
Abstract state at timestep 262 is 3
State prediction error at timestep 262 is 0.012
Human Feedback received at timestpe 262 of 10
Current timestep = 263. State = [[ 0.02430401  1.1835178   0.13605462 -0.6075899  -0.09612678 -0.15393664
   0.          0.        ]]. Action = [[ 0.5962651  -0.33817333]]. Reward = [-0.08213445]
Abstract state at timestep 263 is 3
State prediction error at timestep 263 is 0.012
Human Feedback received at timestpe 263 of 10
Current timestep = 264. State = [[ 0.02552938  1.1692722   0.12879792 -0.63355553 -0.10234459 -0.12436785
   0.          0.        ]]. Action = [[-0.0015713  -0.72476137]]. Reward = [-1.6097063]
Abstract state at timestep 264 is 3
State prediction error at timestep 264 is 0.012
Human Feedback received at timestpe 264 of 10
Current timestep = 265. State = [[ 0.02666798  1.1544323   0.11791126 -0.6598268  -0.10637406 -0.08059646
   0.          0.        ]]. Action = [[-0.27982354 -0.93395925]]. Reward = [-1.3263617]
Abstract state at timestep 265 is 3
State prediction error at timestep 265 is 0.012
Human Feedback received at timestpe 265 of 10
Current timestep = 266. State = [[ 0.02778473  1.1398917   0.11436994 -0.6464441  -0.1090581  -0.05368558
   0.          0.        ]]. Action = [[ 0.17595124 -0.6927856 ]]. Reward = [2.3650196]
Abstract state at timestep 266 is 3
State prediction error at timestep 266 is 0.012
Human Feedback received at timestpe 266 of 10
Current timestep = 267. State = [[ 0.02899141  1.1252947   0.12314165 -0.6489386  -0.11150988 -0.04904008
   0.          0.        ]]. Action = [[0.15071869 0.3322369 ]]. Reward = [0.63488847]
Abstract state at timestep 267 is 3
State prediction error at timestep 267 is 0.012
Human Feedback received at timestpe 267 of 10
Current timestep = 268. State = [[ 0.03013     1.111072    0.11466352 -0.63218385 -0.11230227 -0.01584766
   0.          0.        ]]. Action = [[ 0.8368778 -0.8932294]]. Reward = [2.839253]
Abstract state at timestep 268 is 3
State prediction error at timestep 268 is 0.012
Human Feedback received at timestpe 268 of 10
Current timestep = 269. State = [[ 0.03126869  1.0962491   0.1146635  -0.65885055 -0.11309464 -0.01584763
   0.          0.        ]]. Action = [[-0.2894814 -0.1830532]]. Reward = [-1.2262484]
Abstract state at timestep 269 is 3
State prediction error at timestep 269 is 0.012
Human Feedback received at timestpe 269 of 10
Current timestep = 270. State = [[ 0.03240728  1.0808264   0.1146635  -0.68551725 -0.11388702 -0.01584767
   0.          0.        ]]. Action = [[-0.4159391   0.26382685]]. Reward = [-1.169634]
Abstract state at timestep 270 is 3
State prediction error at timestep 270 is 0.012
Human Feedback received at timestpe 270 of 10
Current timestep = 271. State = [[ 0.03354587  1.0648035   0.11466348 -0.7121839  -0.11467939 -0.01584768
   0.          0.        ]]. Action = [[-0.35184693 -0.263579  ]]. Reward = [-1.1126714]
Abstract state at timestep 271 is 3
State prediction error at timestep 271 is 0.012
Human Feedback received at timestpe 271 of 10
Current timestep = 272. State = [[ 0.03475065  1.0488297   0.12119301 -0.71000236 -0.11539715 -0.01435493
   0.          0.        ]]. Action = [[ 0.42144644 -0.18576759]]. Reward = [1.4160453]
Abstract state at timestep 272 is 3
State prediction error at timestep 272 is 0.012
Human Feedback received at timestpe 272 of 10
Current timestep = 273. State = [[ 0.03592186  1.0327826   0.11682644 -0.7131864  -0.11510107  0.00592163
   0.          0.        ]]. Action = [[ 0.467592  -0.5455249]]. Reward = [1.1509144]
Abstract state at timestep 273 is 3
State prediction error at timestep 273 is 0.012
Human Feedback received at timestpe 273 of 10
Current timestep = 274. State = [[ 0.03724623  1.0167994   0.13166054 -0.7102987  -0.11433679  0.0152859
   0.          0.        ]]. Action = [[0.4537598  0.40216815]]. Reward = [1.4803045]
Abstract state at timestep 274 is 3
State prediction error at timestep 274 is 0.012
Human Feedback received at timestpe 274 of 10
Current timestep = 275. State = [[ 0.03850117  1.0002346   0.12293363 -0.73601747 -0.11179528  0.05083007
   0.          0.        ]]. Action = [[-0.9451013 -0.8251441]]. Reward = [-0.5015501]
Abstract state at timestep 275 is 3
State prediction error at timestep 275 is 0.012
Human Feedback received at timestpe 275 of 10
Current timestep = 276. State = [[ 0.0396801   0.98308355  0.11339511 -0.76194066 -0.10732411  0.08942322
   0.          0.        ]]. Action = [[-0.08960819 -0.86487967]]. Reward = [-0.28159317]
Abstract state at timestep 276 is 3
State prediction error at timestep 276 is 0.012
Human Feedback received at timestpe 276 of 10
Current timestep = 277. State = [[ 0.04082041  0.96581584  0.10835622 -0.76704985 -0.10168906  0.11270116
   0.          0.        ]]. Action = [[ 0.05922306 -0.6011182 ]]. Reward = [1.673875]
Abstract state at timestep 277 is 4
State prediction error at timestep 277 is 0.012
Human Feedback received at timestpe 277 of 10
Current timestep = 278. State = [[ 0.0420001   0.94837874  0.11037991 -0.77448237 -0.09415848  0.15061149
   0.          0.        ]]. Action = [[ 0.01442564 -0.9740138 ]]. Reward = [1.5443429]
Abstract state at timestep 278 is 4
State prediction error at timestep 278 is 0.012
Human Feedback received at timestpe 278 of 10
Current timestep = 279. State = [[ 0.04317989  0.93034244  0.11037922 -0.8011537  -0.08662793  0.15061092
   0.          0.        ]]. Action = [[-0.84891605  0.4732709 ]]. Reward = [-0.09182787]
Abstract state at timestep 279 is 4
State prediction error at timestep 279 is 0.012
Human Feedback received at timestpe 279 of 10
Current timestep = 280. State = [[ 0.04436846  0.91226506  0.11280571 -0.80310494 -0.08063615  0.11983585
   0.          0.        ]]. Action = [[0.87929595 0.6759536 ]]. Reward = [1.8703675]
Abstract state at timestep 280 is 4
State prediction error at timestep 280 is 0.012
Human Feedback received at timestpe 280 of 10
Current timestep = 281. State = [[ 0.04561281  0.8935889   0.11978648 -0.8298091  -0.0760389   0.0919449
   0.          0.        ]]. Action = [[-0.49262512  0.75975275]]. Reward = [-0.44612953]
Abstract state at timestep 281 is 4
State prediction error at timestep 281 is 0.012
Human Feedback received at timestpe 281 of 10
Current timestep = 282. State = [[ 0.04687452  0.8749811   0.12342898 -0.82687473 -0.07332705  0.05423711
   0.          0.        ]]. Action = [[0.4135332 0.9023546]]. Reward = [2.1211545]
Abstract state at timestep 282 is 4
State prediction error at timestep 282 is 0.012
Human Feedback received at timestpe 282 of 10
Current timestep = 283. State = [[ 0.04813614  0.8557733   0.12342892 -0.85354203 -0.07061519  0.05423707
   0.          0.        ]]. Action = [[-0.12414062 -0.06988275]]. Reward = [-0.45624492]
Abstract state at timestep 283 is 4
State prediction error at timestep 283 is 0.012
Human Feedback received at timestpe 283 of 10
Current timestep = 284. State = [[ 0.04944019  0.83595973  0.12874845 -0.8805264  -0.06897448  0.03281428
   0.          0.        ]]. Action = [[-0.2416668   0.69626284]]. Reward = [-0.63316184]
Abstract state at timestep 284 is 4
State prediction error at timestep 284 is 0.012
Human Feedback received at timestpe 284 of 10
Current timestep = 285. State = [[ 0.0508955   0.81671107  0.1434246  -0.8554039  -0.06688275  0.04183438
   0.          0.        ]]. Action = [[0.57748175 0.17399645]]. Reward = [4.139539]
Abstract state at timestep 285 is 4
State prediction error at timestep 285 is 0.012
Human Feedback received at timestpe 285 of 10
Current timestep = 286. State = [[ 0.05240278  0.7973524   0.1504849  -0.8603821  -0.06664103  0.00483437
   0.          0.        ]]. Action = [[0.41105115 0.9079218 ]]. Reward = [1.0976907]
Abstract state at timestep 286 is 4
State prediction error at timestep 286 is 0.012
Human Feedback received at timestpe 286 of 10
Current timestep = 287. State = [[ 0.05386228  0.77739304  0.14450547 -0.8870098  -0.06520354  0.0287497
   0.          0.        ]]. Action = [[-0.87985206 -0.52428895]]. Reward = [-0.4164462]
Abstract state at timestep 287 is 4
State prediction error at timestep 287 is 0.012
Human Feedback received at timestpe 287 of 10
Current timestep = 288. State = [[ 0.05527935  0.7580973   0.14070216 -0.8575508  -0.06421621  0.01974673
   0.          0.        ]]. Action = [[ 0.6174278  -0.08774775]]. Reward = [4.739454]
Abstract state at timestep 288 is 4
State prediction error at timestep 288 is 0.012
Human Feedback received at timestpe 288 of 10
Current timestep = 289. State = [[ 0.05664434  0.7382139   0.13416708 -0.8836028  -0.06190787  0.04616676
   0.          0.        ]]. Action = [[-0.686432   -0.70893675]]. Reward = [-0.2891983]
Abstract state at timestep 289 is 4
State prediction error at timestep 289 is 0.012
Human Feedback received at timestpe 289 of 10
Current timestep = 290. State = [[ 0.0579196   0.71844035  0.12575445 -0.87875175 -0.06014883  0.03518077
   0.          0.        ]]. Action = [[ 0.86467266 -0.25432026]]. Reward = [2.4601183]
Abstract state at timestep 290 is 4
State prediction error at timestep 290 is 0.012
Human Feedback received at timestpe 290 of 10
Current timestep = 291. State = [[ 0.05919494  0.6980669   0.12575442 -0.9054186  -0.05838978  0.0351808
   0.          0.        ]]. Action = [[-0.15976018  0.4767716 ]]. Reward = [-0.44475734]
Abstract state at timestep 291 is 4
State prediction error at timestep 291 is 0.012
Human Feedback received at timestpe 291 of 10
Current timestep = 292. State = [[ 0.0604167   0.6775878   0.12073387 -0.9101254  -0.05696718  0.02845227
   0.          0.        ]]. Action = [[ 0.03078353 -0.3747223 ]]. Reward = [1.6184099]
Abstract state at timestep 292 is 4
State prediction error at timestep 292 is 0.012
Human Feedback received at timestpe 292 of 10
Current timestep = 293. State = [[ 0.06163845  0.6565088   0.12073386 -0.93679214 -0.05554457  0.0284523
   0.          0.        ]]. Action = [[-0.5400804   0.24625003]]. Reward = [-0.41391036]
Abstract state at timestep 293 is 4
State prediction error at timestep 293 is 0.012
Human Feedback received at timestpe 293 of 10
Current timestep = 294. State = [[ 0.06286021  0.6348297   0.12073384 -0.9634589  -0.05412195  0.0284523
   0.          0.        ]]. Action = [[-0.7419314   0.19842076]]. Reward = [-0.3569638]
Abstract state at timestep 294 is 4
State prediction error at timestep 294 is 0.012
Human Feedback received at timestpe 294 of 10
Current timestep = 295. State = [[ 0.06416893  0.61315125  0.1274248  -0.96336406 -0.05070209  0.06839699
   0.          0.        ]]. Action = [[ 0.421484  -0.9420088]]. Reward = [2.167872]
Abstract state at timestep 295 is 4
State prediction error at timestep 295 is 0.012
Human Feedback received at timestpe 295 of 10
Current timestep = 296. State = [[ 0.06547775  0.59087306  0.12742475 -0.9900318  -0.04728223  0.06839694
   0.          0.        ]]. Action = [[-0.23951054  0.12434006]]. Reward = [-0.10136978]
Abstract state at timestep 296 is 4
State prediction error at timestep 296 is 0.012
Human Feedback received at timestpe 296 of 10
Current timestep = 297. State = [[ 0.06678657  0.56799495  0.12742467 -1.0166993  -0.04386238  0.06839688
   0.          0.        ]]. Action = [[-0.6443793  -0.21106172]]. Reward = [-0.04532246]
Abstract state at timestep 297 is 4
State prediction error at timestep 297 is 0.012
Human Feedback received at timestpe 297 of 10
Current timestep = 298. State = [[ 0.06816129  0.54451996  0.13567705 -1.0432819  -0.04209219  0.03540386
   0.          0.        ]]. Action = [[-0.19966185  0.7638252 ]]. Reward = [-0.27342594]
Abstract state at timestep 298 is 4
State prediction error at timestep 298 is 0.012
Human Feedback received at timestpe 298 of 10
Current timestep = 299. State = [[ 0.06962261  0.521578    0.14408562 -1.0195873  -0.04006829  0.04047779
   0.          0.        ]]. Action = [[ 0.6264653  -0.31137848]]. Reward = [4.4498696]
Abstract state at timestep 299 is 4
State prediction error at timestep 299 is 0.012
Human Feedback received at timestpe 299 of 10
Current timestep = 300. State = [[ 0.07109042  0.49856937  0.14476721 -1.0225518  -0.03808034  0.03975905
   0.          0.        ]]. Action = [[ 0.06399536 -0.47263944]]. Reward = [1.9953299]
Abstract state at timestep 300 is 4
State prediction error at timestep 300 is 0.012
Human Feedback received at timestpe 300 of 10
Current timestep = 301. State = [[ 0.07255821  0.47496086  0.1447672  -1.0492188  -0.03609237  0.03975904
   0.          0.        ]]. Action = [[-0.2848524  -0.23423773]]. Reward = [-0.12812059]
Abstract state at timestep 301 is 5
State prediction error at timestep 301 is 0.012
Human Feedback received at timestpe 301 of 10
Current timestep = 302. State = [[ 0.07409678  0.4507453   0.15364352 -1.076239   -0.03588573  0.00413322
   0.          0.        ]]. Action = [[-0.3535977   0.77980995]]. Reward = [-0.43430176]
Abstract state at timestep 302 is 5
State prediction error at timestep 302 is 0.012
Human Feedback received at timestpe 302 of 10
Current timestep = 303. State = [[ 0.07567005  0.4263109   0.15584673 -1.0859406  -0.03442514  0.02921159
   0.          0.        ]]. Action = [[ 0.1392361 -0.5698542]]. Reward = [1.3485419]
Abstract state at timestep 303 is 5
State prediction error at timestep 303 is 0.012
Human Feedback received at timestpe 303 of 10
Current timestep = 304. State = [[ 0.07724333  0.4012765   0.15584671 -1.1126074  -0.03296457  0.02921153
   0.          0.        ]]. Action = [[-0.8546834  -0.41679358]]. Reward = [-0.06109463]
Abstract state at timestep 304 is 5
State prediction error at timestep 304 is 0.012
Human Feedback received at timestpe 304 of 10
Current timestep = 305. State = [[ 0.07880487  0.37618104  0.15479341 -1.115327   -0.0316124   0.02704305
   0.          0.        ]]. Action = [[ 0.83326375 -0.30824268]]. Reward = [2.0350788]
Abstract state at timestep 305 is 5
State prediction error at timestep 305 is 0.012
Human Feedback received at timestpe 305 of 10
Current timestep = 306. State = [[ 0.08032636  0.35049462  0.14974666 -1.1415677  -0.02924495  0.04734879
   0.          0.        ]]. Action = [[-0.19093382 -0.5993737 ]]. Reward = [0.16228426]
Abstract state at timestep 306 is 5
State prediction error at timestep 306 is 0.012
Human Feedback received at timestpe 306 of 10
Current timestep = 307. State = [[ 0.08184776  0.32420835  0.14974663 -1.168235   -0.02687751  0.04734874
   0.          0.        ]]. Action = [[-0.26868045 -0.49667573]]. Reward = [0.11229557]
Abstract state at timestep 307 is 5
State prediction error at timestep 307 is 0.012
Human Feedback received at timestpe 307 of 10
Current timestep = 308. State = [[ 0.08330002  0.29732895  0.1410666  -1.1945728  -0.02276906  0.0821693
   0.          0.        ]]. Action = [[-0.17657363 -0.9105944 ]]. Reward = [0.43581402]
Abstract state at timestep 308 is 5
State prediction error at timestep 308 is 0.012
Human Feedback received at timestpe 308 of 10
Current timestep = 309. State = [[ 0.08469267  0.2708934   0.13678882 -1.1748772  -0.02032214  0.04893855
   0.          0.        ]]. Action = [[0.8477192 0.677847 ]]. Reward = [4.448507]
Abstract state at timestep 309 is 5
State prediction error at timestep 309 is 0.012
Human Feedback received at timestpe 309 of 10
Current timestep = 310. State = [[ 0.08608532  0.24385794  0.13678882 -1.2015442  -0.01787522  0.04893851
   0.          0.        ]]. Action = [[-0.64542884 -0.28570068]]. Reward = [0.11723176]
Abstract state at timestep 310 is 5
State prediction error at timestep 310 is 0.012
Human Feedback received at timestpe 310 of 10
Current timestep = 311. State = [[ 0.08742056  0.21621831  0.12957191 -1.2283878  -0.01398444  0.07781566
   0.          0.        ]]. Action = [[-0.8038177  -0.58711743]]. Reward = [0.32015884]
Abstract state at timestep 311 is 5
State prediction error at timestep 311 is 0.012
Human Feedback received at timestpe 311 of 10
Current timestep = 312. State = [[ 0.08884706  0.18929695  0.137034   -1.1964642  -0.00843782  0.11093235
   0.          0.        ]]. Action = [[ 0.96315384 -0.6606284 ]]. Reward = [5.743244]
Abstract state at timestep 312 is 5
State prediction error at timestep 312 is 0.012
Human Feedback received at timestpe 312 of 10
Current timestep = 313. State = [[ 0.09033909  0.16243552  0.14330193 -1.1938206  -0.00260487  0.11665896
   0.          0.        ]]. Action = [[0.8758993 0.2608112]]. Reward = [2.8158164]
Abstract state at timestep 313 is 5
State prediction error at timestep 313 is 0.012
Human Feedback received at timestpe 313 of 10
Current timestep = 314. State = [[ 0.09176283  0.13498236  0.13471228 -1.2201462   0.00494859  0.15106949
   0.          0.        ]]. Action = [[-0.56804013 -0.6990388 ]]. Reward = [-0.5076019]
Abstract state at timestep 314 is 5
State prediction error at timestep 314 is 0.012
Human Feedback received at timestpe 314 of 10
Current timestep = 315. State = [[ 0.09318648  0.10692996  0.1347123  -1.2468178   0.01250205  0.15106906
   0.          0.        ]]. Action = [[-0.5040084   0.16281736]]. Reward = [-1.2684734]
Abstract state at timestep 315 is 5
State prediction error at timestep 315 is 0.012
Human Feedback received at timestpe 315 of 10
Current timestep = 316. State = [[ 0.09455939  0.07827767  0.12833653 -1.2735358   0.02133245  0.17660786
   0.          0.        ]]. Action = [[-0.19089293 -0.7745232 ]]. Reward = [-1.5892751]
Abstract state at timestep 316 is 5
State prediction error at timestep 316 is 0.012
Human Feedback received at timestpe 316 of 10
Current timestep = 317. State = [[ 0.09582891  0.04983696  0.11843549 -1.2641753   0.0297385   0.16812137
   0.          0.        ]]. Action = [[ 0.7362801  -0.32034814]]. Reward = [1.4006199]
Abstract state at timestep 317 is 5
State prediction error at timestep 317 is 0.012
Human Feedback received at timestpe 317 of 10
Current timestep = 318. State = [[ 0.09705524  0.02198146  0.11256554 -1.2382512   0.03968823  0.19899435
   0.          0.        ]]. Action = [[ 0.80504394 -0.733399  ]]. Reward = [2.197661]
Abstract state at timestep 318 is 5
State prediction error at timestep 318 is 0.012
Human Feedback received at timestpe 318 of 10
Current timestep = 319. State = [[ 0.09834671 -0.00646404  0.12074864 -1.2644864   0.04799386  0.16611245
   0.          1.        ]]. Action = [[-0.36093986  0.94406533]]. Reward = [6.5484157]
Abstract state at timestep 319 is 5
State prediction error at timestep 319 is 0.012
Human Feedback received at timestpe 319 of 10
Current timestep = 320. State = [[ 0.09970923 -0.03423256  0.14600272 -1.2339971   0.03838974 -0.19205657
   1.          1.        ]]. Action = [[ 0.24430656 -0.07841563]]. Reward = [12.8508835]
Abstract state at timestep 320 is 5
State prediction error at timestep 320 is 0.012
Human Feedback received at timestpe 320 of 10
Current timestep = 321. State = [[ 0.00572128  1.4087312   0.5794996  -0.09729181 -0.00662287 -0.13126534
   0.          0.        ]]. Action = [[ 0.2658242 -0.8740796]]. Reward = [-100.]
Abstract state at timestep 321 is 5
State prediction error at timestep 321 is 0.012
Human Feedback received at timestpe 321 of 10
Current timestep = 322. State = [[ 0.01156549  1.4069089   0.5904027  -0.0810312  -0.01253889 -0.11833107
   0.          0.        ]]. Action = [[0.79426134 0.3452214 ]]. Reward = [-1.5148464]
Abstract state at timestep 322 is 3
State prediction error at timestep 322 is 0.012
Human Feedback received at timestpe 322 of 10
Current timestep = 323. State = [[ 0.01740685  1.4053293   0.59015954 -0.07026827 -0.01849991 -0.11923138
   0.          0.        ]]. Action = [[0.6676128  0.36968005]]. Reward = [-0.53338486]
Abstract state at timestep 323 is 3
State prediction error at timestep 323 is 0.012
Human Feedback received at timestpe 323 of 10
Current timestep = 324. State = [[ 0.02324839  1.40315     0.5901771  -0.09694525 -0.02445992 -0.1192107
   0.          0.        ]]. Action = [[-0.08811665 -0.08041161]]. Reward = [-0.762372]
Abstract state at timestep 324 is 3
State prediction error at timestep 324 is 0.012
Human Feedback received at timestpe 324 of 10
Current timestep = 325. State = [[ 0.02909946  1.4012119   0.5911519  -0.08625205 -0.03043941 -0.11960094
   0.          0.        ]]. Action = [[ 0.45671082 -0.33206046]]. Reward = [-0.5660673]
Abstract state at timestep 325 is 3
State prediction error at timestep 325 is 0.012
Human Feedback received at timestpe 325 of 10
Current timestep = 326. State = [[ 0.03498735  1.3986747   0.5957592  -0.11292193 -0.03733769 -0.13797823
   0.          0.        ]]. Action = [[-0.33238232  0.59223986]]. Reward = [-1.3629669]
Abstract state at timestep 326 is 3
State prediction error at timestep 326 is 0.012
Human Feedback received at timestpe 326 of 10
Current timestep = 327. State = [[ 0.04091606  1.3955379   0.6008775  -0.13963316 -0.04525668 -0.15839443
   0.          0.        ]]. Action = [[-0.702532   0.6142738]]. Reward = [-1.5650392]
Abstract state at timestep 327 is 3
State prediction error at timestep 327 is 0.012
Human Feedback received at timestpe 327 of 10
Current timestep = 328. State = [[ 0.04680719  1.3924313   0.59739244 -0.13834481 -0.05344424 -0.1637667
   0.          0.        ]]. Action = [[0.34663177 0.3878219 ]]. Reward = [-0.36016378]
Abstract state at timestep 328 is 3
State prediction error at timestep 328 is 0.012
Human Feedback received at timestpe 328 of 10
Current timestep = 329. State = [[ 0.05269871  1.3887254   0.5974158  -0.16502348 -0.0616305  -0.16374013
   0.          0.        ]]. Action = [[-0.8805623  -0.14046508]]. Reward = [-1.1280085]
Abstract state at timestep 329 is 3
State prediction error at timestep 329 is 0.012
Human Feedback received at timestpe 329 of 10
Current timestep = 330. State = [[ 0.05873785  1.3851823   0.6131642  -0.15787746 -0.07079653 -0.18333739
   0.          0.        ]]. Action = [[0.9909924  0.59629333]]. Reward = [-2.2407808]
Abstract state at timestep 330 is 3
State prediction error at timestep 330 is 0.012
Human Feedback received at timestpe 330 of 10
Current timestep = 331. State = [[ 0.06477728  1.38104     0.61318976 -0.18455906 -0.07996077 -0.18330154
   0.          0.        ]]. Action = [[-0.66008794 -0.28255308]]. Reward = [-1.2494435]
Abstract state at timestep 331 is 3
State prediction error at timestep 331 is 0.012
Human Feedback received at timestpe 331 of 10
Current timestep = 332. State = [[ 0.07075443  1.3771706   0.60746366 -0.17252104 -0.08963893 -0.1935812
   0.          0.        ]]. Action = [[0.35440433 0.15557837]]. Reward = [0.0736971]
Abstract state at timestep 332 is 3
State prediction error at timestep 332 is 0.012
Human Feedback received at timestpe 332 of 10
Current timestep = 333. State = [[ 0.07662801  1.3735478   0.59581083 -0.1615418  -0.09801921 -0.16762076
   0.          0.        ]]. Action = [[ 0.14754117 -0.71008694]]. Reward = [0.715362]
Abstract state at timestep 333 is 3
State prediction error at timestep 333 is 0.012
Human Feedback received at timestpe 333 of 10
Current timestep = 334. State = [[ 0.08266363  1.3698499   0.6113932  -0.16487932 -0.10580094 -0.15564914
   0.          0.        ]]. Action = [[ 0.61002874 -0.17554092]]. Reward = [-2.276833]
Abstract state at timestep 334 is 3
State prediction error at timestep 334 is 0.012
Human Feedback received at timestpe 334 of 10
Current timestep = 335. State = [[ 0.08862247  1.3655741   0.60172045 -0.1904611  -0.11160605 -0.11611275
   0.          0.        ]]. Action = [[-0.83101434 -0.9477239 ]]. Reward = [-0.01032945]
Abstract state at timestep 335 is 3
State prediction error at timestep 335 is 0.012
Human Feedback received at timestpe 335 of 10
Current timestep = 336. State = [[ 0.09474268  1.3616009   0.61913973 -0.17712975 -0.11868925 -0.14167662
   0.          0.        ]]. Action = [[0.5557227 0.6844026]]. Reward = [-1.8903259]
Abstract state at timestep 336 is 3
State prediction error at timestep 336 is 0.012
Human Feedback received at timestpe 336 of -10
Current timestep = 337. State = [[ 0.10086317  1.3570281   0.6191584  -0.203811   -0.12577043 -0.14163664
   0.          0.        ]]. Action = [[-0.6573057  0.3619163]]. Reward = [-1.0820932]
Abstract state at timestep 337 is 3
State prediction error at timestep 337 is 0.012
Human Feedback received at timestpe 337 of -10
Current timestep = 338. State = [[ 0.107053    1.3531668   0.62411904 -0.1720487  -0.13089296 -0.10245968
   0.          0.        ]]. Action = [[ 0.8749373 -0.9507672]]. Reward = [-0.04021407]
Abstract state at timestep 338 is 3
State prediction error at timestep 338 is 0.012
Human Feedback received at timestpe 338 of -10
Current timestep = 339. State = [[ 0.1131712   1.3491853   0.615703   -0.1773072  -0.13477334 -0.0776144
   0.          0.        ]]. Action = [[ 0.5334997 -0.6846394]]. Reward = [0.37596828]
Abstract state at timestep 339 is 3
State prediction error at timestep 339 is 0.012
Human Feedback received at timestpe 339 of -10
Current timestep = 340. State = [[ 0.11930571  1.3449768   0.6187734  -0.18753456 -0.14008091 -0.10616086
   0.          0.        ]]. Action = [[0.01558077 0.683658  ]]. Reward = [-0.92134887]
Abstract state at timestep 340 is 3
State prediction error at timestep 340 is 0.012
Human Feedback received at timestpe 340 of -10
Current timestep = 341. State = [[ 0.12538452  1.3401811   0.6117546  -0.21351098 -0.14395463 -0.0774812
   0.          0.        ]]. Action = [[-0.21224499 -0.57995296]]. Reward = [-0.1199244]
Abstract state at timestep 341 is 3
State prediction error at timestep 341 is 0.012
Human Feedback received at timestpe 341 of -10
Current timestep = 342. State = [[ 0.13169165  1.335824    0.63399196 -0.19396888 -0.14723884 -0.06568965
   0.          0.        ]]. Action = [[0.49600828 0.21491241]]. Reward = [-1.6851431]
Abstract state at timestep 342 is 3
State prediction error at timestep 342 is 0.012
Human Feedback received at timestpe 342 of -10
Current timestep = 343. State = [[ 0.13812074  1.3318174   0.6450295  -0.17828861 -0.14934917 -0.0422098
   0.          0.        ]]. Action = [[ 0.43924665 -0.50004685]]. Reward = [-0.7295119]
Abstract state at timestep 343 is 3
State prediction error at timestep 343 is 0.012
Human Feedback received at timestpe 343 of -10
Current timestep = 344. State = [[ 0.14459896  1.3272035   0.65116465 -0.20540038 -0.15269849 -0.06699236
   0.          0.        ]]. Action = [[-0.4574952  0.6167934]]. Reward = [-1.3207299]
Abstract state at timestep 344 is 3
State prediction error at timestep 344 is 0.012
Human Feedback received at timestpe 344 of -10
Current timestep = 345. State = [[ 0.15107736  1.3219898   0.6511753  -0.23206738 -0.15604652 -0.06696676
   0.          0.        ]]. Action = [[-0.03827846 -0.32204366]]. Reward = [-0.7385146]
Abstract state at timestep 345 is 3
State prediction error at timestep 345 is 0.012
Human Feedback received at timestpe 345 of -10
Current timestep = 346. State = [[ 0.15749207  1.3161906   0.6437536  -0.25798067 -0.15832487 -0.04556582
   0.          0.        ]]. Action = [[-0.430637   -0.96287733]]. Reward = [0.021745]
Abstract state at timestep 346 is 3
State prediction error at timestep 346 is 0.012
Human Feedback received at timestpe 346 of -10
Current timestep = 347. State = [[ 0.16408186  1.3107615   0.6620532  -0.24162245 -0.16139142 -0.061331
   0.          0.        ]]. Action = [[0.44096553 0.6125511 ]]. Reward = [-1.2068206]
Abstract state at timestep 347 is 3
State prediction error at timestep 347 is 0.012
Human Feedback received at timestpe 347 of -10
Current timestep = 348. State = [[ 0.17067175  1.3047326   0.662053   -0.26828992 -0.16445796 -0.06133095
   0.          0.        ]]. Action = [[-0.70409673  0.15635729]]. Reward = [-0.7504914]
Abstract state at timestep 348 is 3
State prediction error at timestep 348 is 0.012
Human Feedback received at timestpe 348 of -10
Current timestep = 349. State = [[ 0.17754917  1.2988777   0.6917594  -0.26067045 -0.168473   -0.08030085
   0.          0.        ]]. Action = [[0.9173441  0.65946627]]. Reward = [-2.7091935]
Abstract state at timestep 349 is 3
State prediction error at timestep 349 is 0.012
Human Feedback received at timestpe 349 of -10
Current timestep = 350. State = [[ 0.1844267   1.2924229   0.69175905 -0.28733847 -0.17248805 -0.08030081
   0.          0.        ]]. Action = [[-0.01359129  0.36248136]]. Reward = [-0.8392982]
Abstract state at timestep 350 is 3
State prediction error at timestep 350 is 0.012
Human Feedback received at timestpe 350 of -10
Current timestep = 351. State = [[ 0.19125184  1.2864492   0.68589526 -0.26588845 -0.17586648 -0.06756879
   0.          0.        ]]. Action = [[ 0.75275135 -0.50893474]]. Reward = [1.2200942]
Abstract state at timestep 351 is 3
State prediction error at timestep 351 is 0.012
Human Feedback received at timestpe 351 of -10
Current timestep = 352. State = [[ 0.19828376  1.2810936   0.70627534 -0.23839855 -0.17896149 -0.06190019
   0.          0.        ]]. Action = [[ 0.71670604 -0.13133341]]. Reward = [-1.1226704]
Abstract state at timestep 352 is 3
State prediction error at timestep 352 is 0.012
Human Feedback received at timestpe 352 of -10
Current timestep = 353. State = [[ 0.2055151   1.2764401   0.7260324  -0.20717743 -0.18186364 -0.05804303
   0.          0.        ]]. Action = [[ 0.9221773  -0.30285203]]. Reward = [-1.1905048]
Abstract state at timestep 353 is 3
State prediction error at timestep 353 is 0.012
Human Feedback received at timestpe 353 of -10
Current timestep = 354. State = [[ 0.21279278  1.2719463   0.73215353 -0.20026222 -0.18627037 -0.08813484
   0.          0.        ]]. Action = [[0.00783741 0.72205865]]. Reward = [-0.691379]
Abstract state at timestep 354 is 3
State prediction error at timestep 354 is 0.012
Human Feedback received at timestpe 354 of -10
Current timestep = 355. State = [[ 0.22007045  1.266853    0.73215306 -0.22693048 -0.19067714 -0.08813489
   0.          0.        ]]. Action = [[-0.07348067 -0.06658101]]. Reward = [-0.80763626]
Abstract state at timestep 355 is 3
State prediction error at timestep 355 is 0.012
Human Feedback received at timestpe 355 of -10
Current timestep = 356. State = [[ 0.22762518  1.2618847   0.76093215 -0.22152649 -0.19617905 -0.11003791
   0.          0.        ]]. Action = [[0.33900595 0.65699387]]. Reward = [-3.0139554]
Abstract state at timestep 356 is 3
State prediction error at timestep 356 is 0.012
Human Feedback received at timestpe 356 of -10
Current timestep = 357. State = [[ 0.23524551  1.2568332   0.76751786 -0.22524346 -0.20169324 -0.11028423
   0.          0.        ]]. Action = [[ 0.20127523 -0.03266454]]. Reward = [-1.1089259]
Abstract state at timestep 357 is 3
State prediction error at timestep 357 is 0.012
Human Feedback received at timestpe 357 of -10
Current timestep = 358. State = [[ 0.24278697  1.251814    0.7579835  -0.22360274 -0.20556282 -0.0773917
   0.          0.        ]]. Action = [[ 0.31717396 -0.8609601 ]]. Reward = [0.7024991]
Abstract state at timestep 358 is 3
State prediction error at timestep 358 is 0.012
Human Feedback received at timestpe 358 of -10
Current timestep = 359. State = [[ 0.25047082  1.246991    0.77081794 -0.2146961  -0.20801388 -0.04902126
   0.          0.        ]]. Action = [[ 0.25524783 -0.6378873 ]]. Reward = [-1.1164259]
Abstract state at timestep 359 is 3
State prediction error at timestep 359 is 0.012
Human Feedback received at timestpe 359 of -10
Current timestep = 360. State = [[ 0.2581547   1.2415681   0.7708177  -0.24136327 -0.21046494 -0.04902125
   0.          0.        ]]. Action = [[-0.22661531 -0.4613214 ]]. Reward = [-0.62403005]
Abstract state at timestep 360 is 3
State prediction error at timestep 360 is 0.012
Human Feedback received at timestpe 360 of -10
Current timestep = 361. State = [[ 0.26588696  1.2355376   0.7768585  -0.26854363 -0.21413946 -0.07349041
   0.          0.        ]]. Action = [[-0.52468646  0.69155   ]]. Reward = [-1.382369]
Abstract state at timestep 361 is 3
State prediction error at timestep 361 is 0.012
Human Feedback received at timestpe 361 of -10
Current timestep = 362. State = [[ 0.27361917  1.2289073   0.7768582  -0.29521143 -0.21781397 -0.07349034
   0.          0.        ]]. Action = [[-0.51023155  0.35552084]]. Reward = [-0.7945798]
Abstract state at timestep 362 is 3
State prediction error at timestep 362 is 0.012
Human Feedback received at timestpe 362 of -10
Current timestep = 363. State = [[ 0.28158674  1.2228705   0.8020314  -0.26909062 -0.22313954 -0.10651164
   0.          0.        ]]. Action = [[0.5710242 0.8183851]]. Reward = [-1.8710266]
Abstract state at timestep 363 is 3
State prediction error at timestep 363 is 0.012
Human Feedback received at timestpe 363 of -10
Current timestep = 364. State = [[ 0.28962573  1.2169557   0.80737036 -0.26341084 -0.22665651 -0.07033911
   0.          0.        ]]. Action = [[ 0.42557907 -0.88092583]]. Reward = [-0.52777106]
Abstract state at timestep 364 is 3
State prediction error at timestep 364 is 0.012
Human Feedback received at timestpe 364 of -10
Current timestep = 365. State = [[ 0.29764977  1.210931    0.80427915 -0.268052   -0.22856185 -0.03810677
   0.          0.        ]]. Action = [[ 0.73227286 -0.8239961 ]]. Reward = [0.07006145]
Abstract state at timestep 365 is 3
State prediction error at timestep 365 is 0.012
Human Feedback received at timestpe 365 of -10
Current timestep = 366. State = [[ 0.3057455   1.204283    0.81329995 -0.29605237 -0.23234087 -0.07558037
   0.          0.        ]]. Action = [[-0.7077293   0.86167765]]. Reward = [-1.728619]
Abstract state at timestep 366 is 3
State prediction error at timestep 366 is 0.012
Human Feedback received at timestpe 366 of -10
Current timestep = 367. State = [[ 0.31411973  1.1983035   0.84080046 -0.26629025 -0.23576772 -0.06853694
   0.          0.        ]]. Action = [[ 0.79446125 -0.18445301]]. Reward = [-1.8874252]
Abstract state at timestep 367 is 6
State prediction error at timestep 367 is 0.012
Human Feedback received at timestpe 367 of -10
Current timestep = 368. State = [[ 0.32257128  1.1926762   0.84886086 -0.25070146 -0.23953277 -0.07530103
   0.          0.        ]]. Action = [[0.25893295 0.25214028]]. Reward = [-0.55369824]
Abstract state at timestep 368 is 6
State prediction error at timestep 368 is 0.012
Human Feedback received at timestpe 368 of -10
Current timestep = 369. State = [[ 0.3312955   1.1869377   0.87767553 -0.2559085  -0.2448766  -0.10687615
   0.          0.        ]]. Action = [[0.45602834 0.8529171 ]]. Reward = [-3.3676937]
Abstract state at timestep 369 is 6
State prediction error at timestep 369 is 0.012
Human Feedback received at timestpe 369 of -10
Current timestep = 370. State = [[ 0.34015712  1.1809975   0.891091   -0.26484066 -0.24990214 -0.10051103
   0.          0.        ]]. Action = [[0.65697694 0.17837882]]. Reward = [-1.9605566]
Abstract state at timestep 370 is 6
State prediction error at timestep 370 is 0.012
Human Feedback received at timestpe 370 of -10
Current timestep = 371. State = [[ 0.34901875  1.1744577   0.8910901  -0.29150933 -0.25492772 -0.10051084
   0.          0.        ]]. Action = [[-0.8351611  -0.38379776]]. Reward = [-0.9182844]
Abstract state at timestep 371 is 6
State prediction error at timestep 371 is 0.012
Human Feedback received at timestpe 371 of -10
Current timestep = 372. State = [[ 0.3578388  1.1673354  0.8858501 -0.3172167 -0.2588463 -0.0783715
   0.         0.       ]]. Action = [[-0.58193916 -0.67108834]]. Reward = [-0.32239655]
Abstract state at timestep 372 is 6
State prediction error at timestep 372 is 0.012
Human Feedback received at timestpe 372 of -10
Current timestep = 373. State = [[ 0.36665565  1.1602951   0.8836379  -0.31324443 -0.26084548 -0.03998312
   0.          0.        ]]. Action = [[ 0.11296523 -0.94576174]]. Reward = [0.3566487]
Abstract state at timestep 373 is 6
State prediction error at timestep 373 is 0.012
Human Feedback received at timestpe 373 of -10
Current timestep = 374. State = [[ 0.37577564  1.1536304   0.9157115  -0.29687876 -0.26464057 -0.07590203
   0.          0.        ]]. Action = [[0.74548745 0.9273988 ]]. Reward = [-2.824897]
Abstract state at timestep 374 is 6
State prediction error at timestep 374 is 0.012
Human Feedback received at timestpe 374 of -10
Current timestep = 375. State = [[ 0.38521585  1.147423    0.9471736  -0.27645785 -0.2678593  -0.06437542
   0.          0.        ]]. Action = [[0.5538995  0.47669947]]. Reward = [-2.668096]
Abstract state at timestep 375 is 6
State prediction error at timestep 375 is 0.012
Human Feedback received at timestpe 375 of -10
Current timestep = 376. State = [[ 0.3947398   1.1410146   0.9554974  -0.28538796 -0.27103043 -0.06342249
   0.          0.        ]]. Action = [[0.5260085  0.02541208]]. Reward = [-1.2978812]
Abstract state at timestep 376 is 6
State prediction error at timestep 376 is 0.012
Human Feedback received at timestpe 376 of -10
Current timestep = 377. State = [[ 0.4044199   1.1347524   0.9698766  -0.27866358 -0.27294463 -0.03828408
   0.          0.        ]]. Action = [[ 0.08205271 -0.57161003]]. Reward = [-1.2916147]
Abstract state at timestep 377 is 6
State prediction error at timestep 377 is 0.012
Human Feedback received at timestpe 377 of -10
Current timestep = 378. State = [[ 0.41439858  1.1291994   1.0016539  -0.24750778 -0.2768274  -0.07765502
   0.          0.        ]]. Action = [[0.87867403 0.9567058 ]]. Reward = [-2.7824738]
Abstract state at timestep 378 is 6
State prediction error at timestep 378 is 0.012
Human Feedback received at timestpe 378 of -10
Current timestep = 379. State = [[ 0.42457685  1.1241035   1.0216166  -0.22721063 -0.28071293 -0.07771097
   0.          0.        ]]. Action = [[0.6605929 0.1119225]]. Reward = [-1.9949723]
Abstract state at timestep 379 is 6
State prediction error at timestep 379 is 0.012
Human Feedback received at timestpe 379 of -10
Current timestep = 380. State = [[ 0.4346859   1.1184347   1.0128872  -0.25233182 -0.28275704 -0.04088194
   0.          0.        ]]. Action = [[-0.54371923 -0.8486065 ]]. Reward = [0.21108854]
Abstract state at timestep 380 is 6
State prediction error at timestep 380 is 0.012
Human Feedback received at timestpe 380 of -10
Current timestep = 381. State = [[ 0.4448598   1.1121327   1.0210973  -0.2808107  -0.28657115 -0.07628201
   0.          0.        ]]. Action = [[-0.33544803  0.78376555]]. Reward = [-1.7080212]
Abstract state at timestep 381 is 6
State prediction error at timestep 381 is 0.012
Human Feedback received at timestpe 381 of -10
Current timestep = 382. State = [[ 0.45503378  1.1052309   1.0210968  -0.30747855 -0.29038525 -0.07628192
   0.          0.        ]]. Action = [[-0.06223816 -0.09504437]]. Reward = [-0.8625831]
Abstract state at timestep 382 is 6
State prediction error at timestep 382 is 0.012
Human Feedback received at timestpe 382 of -10
Current timestep = 383. State = [[ 0.46533298  1.0980315   1.0319445  -0.3203768  -0.29246366 -0.04156812
   0.          0.        ]]. Action = [[ 0.28456545 -0.7951282 ]]. Reward = [-1.5716083]
Abstract state at timestep 383 is 6
State prediction error at timestep 383 is 0.012
Human Feedback received at timestpe 383 of -10
Current timestep = 384. State = [[ 0.47581157  1.0915864   1.0502696  -0.28693718 -0.29495212 -0.04976934
   0.          0.        ]]. Action = [[0.78469515 0.39253473]]. Reward = [-1.1609757]
Abstract state at timestep 384 is 6
State prediction error at timestep 384 is 0.012
Human Feedback received at timestpe 384 of -10
Current timestep = 385. State = [[ 0.48652735  1.084944    1.073323   -0.29557294 -0.2967524  -0.0360048
   0.          0.        ]]. Action = [[0.64818466 0.23868382]]. Reward = [-2.7047353]
Abstract state at timestep 385 is 6
State prediction error at timestep 385 is 0.012
Human Feedback received at timestpe 385 of -10
Current timestep = 386. State = [[ 0.49730054  1.0787842   1.0772564  -0.2737584  -0.29669213  0.00120503
   0.          0.        ]]. Action = [[ 0.8475375  -0.97303504]]. Reward = [-0.00744839]
Abstract state at timestep 386 is 6
State prediction error at timestep 386 is 0.012
Human Feedback received at timestpe 386 of -10
Current timestep = 387. State = [[ 0.50823337  1.0728627   1.0914557  -0.2628063  -0.29480729  0.03769623
   0.          0.        ]]. Action = [[ 0.7400118  -0.85029477]]. Reward = [-1.1397616]
Abstract state at timestep 387 is 6
State prediction error at timestep 387 is 0.012
Human Feedback received at timestpe 387 of -10
Current timestep = 388. State = [[ 5.1951152e-01  1.0671345e+00  1.1278245e+00 -2.5458398e-01
  -2.9481623e-01 -1.7888943e-04  0.0000000e+00  0.0000000e+00]]. Action = [[0.2459948 0.9512203]]. Reward = [-3.5433576]
Abstract state at timestep 388 is 6
State prediction error at timestep 388 is 0.012
Human Feedback received at timestpe 388 of -10
Current timestep = 389. State = [[ 5.3078967e-01  1.0608064e+00  1.1278244e+00 -2.8125066e-01
  -2.9482517e-01 -1.7894300e-04  0.0000000e+00  0.0000000e+00]]. Action = [[-0.3304484 -0.0240348]]. Reward = [-0.5488723]
Abstract state at timestep 389 is 6
State prediction error at timestep 389 is 0.012
Human Feedback received at timestpe 389 of -10
Current timestep = 390. State = [[ 0.5420148   1.0539029   1.1211253  -0.30653965 -0.2933992   0.02851922
   0.          0.        ]]. Action = [[-0.2676065  -0.68456566]]. Reward = [0.23852828]
Abstract state at timestep 390 is 6
State prediction error at timestep 390 is 0.012
Human Feedback received at timestpe 390 of -10
Current timestep = 391. State = [[ 5.5333579e-01  1.0469350e+00  1.1321027e+00 -3.0968347e-01
  -2.9340765e-01 -1.6893698e-04  0.0000000e+00  0.0000000e+00]]. Action = [[0.48913252 0.64145064]]. Reward = [-1.2907854]
Abstract state at timestep 391 is 6
State prediction error at timestep 391 is 0.012
Human Feedback received at timestpe 391 of -10
Current timestep = 392. State = [[ 0.56461763  1.0393772   1.1272123  -0.33571488 -0.29240933  0.01996657
   0.          0.        ]]. Action = [[-0.19973123 -0.63378894]]. Reward = [-0.03064007]
Abstract state at timestep 392 is 6
State prediction error at timestep 392 is 0.012
Human Feedback received at timestpe 392 of -10
Current timestep = 393. State = [[ 0.57620144  1.0321757   1.1569375  -0.3197781  -0.29092434  0.02969962
   0.          0.        ]]. Action = [[ 0.9127474  -0.46609902]]. Reward = [-2.4838767]
Abstract state at timestep 393 is 6
State prediction error at timestep 393 is 0.012
Human Feedback received at timestpe 393 of -10
Current timestep = 394. State = [[ 0.5878682   1.0243322   1.1674314  -0.34874794 -0.2917023  -0.01555913
   0.          0.        ]]. Action = [[-0.29132938  0.98038983]]. Reward = [-1.8084929]
Abstract state at timestep 394 is 6
State prediction error at timestep 394 is 0.012
Human Feedback received at timestpe 394 of -10
Current timestep = 395. State = [[ 0.5995761   1.0166724   1.1720514  -0.34069008 -0.29299232 -0.02580051
   0.          0.        ]]. Action = [[ 0.99008    -0.04217392]]. Reward = [-0.569582]
Abstract state at timestep 395 is 6
State prediction error at timestep 395 is 0.012
Human Feedback received at timestpe 395 of -10
Current timestep = 396. State = [[ 0.6112841   1.0084125   1.1720512  -0.36735687 -0.29428238 -0.02580078
   0.          0.        ]]. Action = [[-0.05181456  0.22106326]]. Reward = [-0.7919346]
Abstract state at timestep 396 is 6
State prediction error at timestep 396 is 0.012
Human Feedback received at timestpe 396 of -10
Current timestep = 397. State = [[ 0.62299216  0.9995526   1.1720511  -0.39402372 -0.29557243 -0.02580116
   0.          0.        ]]. Action = [[-0.9389157  -0.13174242]]. Reward = [-0.8110599]
Abstract state at timestep 397 is 6
State prediction error at timestep 397 is 0.012
Human Feedback received at timestpe 397 of -10
Current timestep = 398. State = [[ 0.6348337   0.9906242   1.1853054  -0.39705208 -0.29674864 -0.02352425
   0.          0.        ]]. Action = [[0.13770723 0.31754637]]. Reward = [-1.5190943]
Abstract state at timestep 398 is 7
State prediction error at timestep 398 is 0.012
Human Feedback received at timestpe 398 of -10
Current timestep = 399. State = [[ 0.64668405  0.98159695  1.1865896  -0.4015235  -0.29833755 -0.03177797
   0.          0.        ]]. Action = [[0.8283657  0.46658075]]. Reward = [-0.58626306]
Abstract state at timestep 399 is 7
State prediction error at timestep 399 is 0.012
Human Feedback received at timestpe 399 of -10
Current timestep = 400. State = [[ 6.5884000e-01  9.7313732e-01  1.2155926e+00 -3.7598544e-01
  -2.9833734e-01  3.9688398e-06  0.0000000e+00  0.0000000e+00]]. Action = [[ 0.8866837  -0.63728833]]. Reward = [-2.246527]
Abstract state at timestep 400 is 7
State prediction error at timestep 400 is 0.012
Human Feedback received at timestpe 400 of -10
Current timestep = 401. State = [[ 0.6710442   0.96405333  1.2217017  -0.4039933  -0.29965547 -0.02636278
   0.          0.        ]]. Action = [[-0.48922116  0.8047106 ]]. Reward = [-1.5331893]
Abstract state at timestep 401 is 7
State prediction error at timestep 401 is 0.012
Human Feedback received at timestpe 401 of -10
Current timestep = 402. State = [[ 0.68324834  0.9543695   1.2217017  -0.43066016 -0.3009736  -0.02636244
   0.          0.        ]]. Action = [[-0.99637276  0.45623076]]. Reward = [-0.9065075]
Abstract state at timestep 402 is 7
State prediction error at timestep 402 is 0.012
Human Feedback received at timestpe 402 of -10
Current timestep = 403. State = [[ 0.6953999   0.94411814  1.2149829  -0.45558006 -0.30081087  0.00325468
   0.          0.        ]]. Action = [[-0.738671  -0.7303585]]. Reward = [-0.1105058]
Abstract state at timestep 403 is 7
State prediction error at timestep 403 is 0.012
Human Feedback received at timestpe 403 of -10
Current timestep = 404. State = [[ 0.7077166   0.9340313   1.2330242  -0.44857553 -0.30219284 -0.02763907
   0.          0.        ]]. Action = [[0.13729692 0.7401476 ]]. Reward = [-1.709758]
Abstract state at timestep 404 is 7
State prediction error at timestep 404 is 0.012
Human Feedback received at timestpe 404 of -10
Current timestep = 405. State = [[ 0.7201349   0.92414933  1.2434347  -0.43953425 -0.30386618 -0.03346608
   0.          0.        ]]. Action = [[ 0.24539316 -0.37497103]]. Reward = [-1.0019394]
Abstract state at timestep 405 is 7
State prediction error at timestep 405 is 0.012
Human Feedback received at timestpe 405 of -10
Current timestep = 406. State = [[ 0.73269427  0.914241    1.2574623  -0.44069108 -0.30544576 -0.03159214
   0.          0.        ]]. Action = [[0.3079679 0.2936554]]. Reward = [-1.7170862]
Abstract state at timestep 406 is 7
State prediction error at timestep 406 is 0.012
Human Feedback received at timestpe 406 of -10
Current timestep = 407. State = [[ 0.7455702   0.9047459   1.2907953  -0.422682   -0.3087658  -0.06640103
   0.          0.        ]]. Action = [[0.81334615 0.88116693]]. Reward = [-3.2846303]
Abstract state at timestep 407 is 7
State prediction error at timestep 407 is 0.012
Human Feedback received at timestpe 407 of -10
Current timestep = 408. State = [[ 0.7584461   0.8946509   1.2907947  -0.44934955 -0.3120858  -0.06640033
   0.          0.        ]]. Action = [[-0.9553662   0.07436097]]. Reward = [-1.2365357]
Abstract state at timestep 408 is 7
State prediction error at timestep 408 is 0.012
Human Feedback received at timestpe 408 of -10
Current timestep = 409. State = [[ 0.77151966  0.88519835  1.3119589  -0.42110607 -0.31684402 -0.09516413
   0.          0.        ]]. Action = [[0.73750556 0.56615937]]. Reward = [-2.0000932]
Abstract state at timestep 409 is 7
State prediction error at timestep 409 is 0.012
Human Feedback received at timestpe 409 of -10
Current timestep = 410. State = [[ 0.78486997  0.87577546  1.3390247  -0.41967863 -0.32099196 -0.08295973
   0.          0.        ]]. Action = [[ 0.7862469  -0.12218225]]. Reward = [-3.3975441]
Abstract state at timestep 410 is 7
State prediction error at timestep 410 is 0.012
Human Feedback received at timestpe 410 of -10
Current timestep = 411. State = [[ 0.7985779   0.86682975  1.3742821  -0.39835957 -0.32461923 -0.07254556
   0.          0.        ]]. Action = [[ 0.5229448  -0.00350201]]. Reward = [-3.6110632]
Abstract state at timestep 411 is 7
State prediction error at timestep 411 is 0.012
Human Feedback received at timestpe 411 of -10
Current timestep = 412. State = [[ 0.812286    0.85728425  1.3742815  -0.4250273  -0.32824653 -0.07254528
   0.          0.        ]]. Action = [[-0.27581036 -0.2839027 ]]. Reward = [-1.366289]
Abstract state at timestep 412 is 7
State prediction error at timestep 412 is 0.012
Human Feedback received at timestpe 412 of -10
Current timestep = 413. State = [[ 0.82599413  0.84713906  1.3742809  -0.451695   -0.33187383 -0.07254584
   0.          0.        ]]. Action = [[-0.50515705  0.43885493]]. Reward = [-1.3915613]
Abstract state at timestep 413 is 7
State prediction error at timestep 413 is 0.012
Human Feedback received at timestpe 413 of -10
Current timestep = 414. State = [[ 0.83970225  0.8363939   1.3742806  -0.4783627  -0.3355011  -0.07254595
   0.          0.        ]]. Action = [[-0.665667  -0.4742297]]. Reward = [-1.4177272]
Abstract state at timestep 414 is 7
State prediction error at timestep 414 is 0.012
Human Feedback received at timestpe 414 of -10
Current timestep = 415. State = [[ 0.85349905  0.8250142   1.385429   -0.50711054 -0.34149504 -0.1198791
   0.          0.        ]]. Action = [[-0.95293504  0.9427171 ]]. Reward = [-2.8320706]
Abstract state at timestep 415 is 7
State prediction error at timestep 415 is 0.012
Human Feedback received at timestpe 415 of -10
Current timestep = 416. State = [[ 0.8676079   0.8137479   1.4150503  -0.5017178  -0.3458674  -0.08744749
   0.          0.        ]]. Action = [[ 0.9372016  -0.54495615]]. Reward = [-3.5930822]
Abstract state at timestep 416 is 7
State prediction error at timestep 416 is 0.012
Human Feedback received at timestpe 416 of -10
Current timestep = 417. State = [[ 0.88178426  0.80185306  1.4235241  -0.5300888  -0.3520543  -0.12373789
   0.          0.        ]]. Action = [[-0.86893636  0.99166226]]. Reward = [-2.6484401]
Abstract state at timestep 417 is 7
State prediction error at timestep 417 is 0.012
Human Feedback received at timestpe 417 of -10
Current timestep = 418. State = [[ 0.8961731   0.7902267   1.4447542  -0.5181835  -0.3582426  -0.12376593
   0.          0.        ]]. Action = [[ 0.18488848 -0.42433035]]. Reward = [-2.6782281]
Abstract state at timestep 418 is 7
State prediction error at timestep 418 is 0.012
Human Feedback received at timestpe 418 of -10
Current timestep = 419. State = [[ 0.9105619   0.7780007   1.4447525  -0.54485327 -0.3644309  -0.12376615
   0.          0.        ]]. Action = [[-0.08703005  0.32107306]]. Reward = [-1.8246803]
Abstract state at timestep 419 is 7
State prediction error at timestep 419 is 0.012
Human Feedback received at timestpe 419 of -10
Current timestep = 420. State = [[ 0.92522013  0.7657179   1.4730499  -0.54776627 -0.37208492 -0.15308084
   0.          0.        ]]. Action = [[0.7581136 0.7693286]]. Reward = [-4.1357327]
Abstract state at timestep 420 is 7
State prediction error at timestep 420 is 0.012
Human Feedback received at timestpe 420 of -10
Current timestep = 421. State = [[ 0.93987846  0.7528357   1.4730473  -0.57443756 -0.3797389  -0.1530802
   0.          0.        ]]. Action = [[-0.2460351   0.27240837]]. Reward = [-2.0378597]
Abstract state at timestep 421 is 7
State prediction error at timestep 421 is 0.012
Human Feedback received at timestpe 421 of -10
Current timestep = 422. State = [[ 0.9546499   0.7401127   1.4846957  -0.5675016  -0.38777456 -0.16071233
   0.          0.        ]]. Action = [[ 0.05619097 -0.12247956]]. Reward = [-2.1715467]
Abstract state at timestep 422 is 7
State prediction error at timestep 422 is 0.012
Human Feedback received at timestpe 422 of -10
Current timestep = 423. State = [[ 0.96942174  0.72679055  1.4846926  -0.59417325 -0.39581013 -0.1607116
   0.          0.        ]]. Action = [[-0.56888187 -0.4178825 ]]. Reward = [-2.1419568]
Abstract state at timestep 423 is 7
State prediction error at timestep 423 is 0.012
Human Feedback received at timestpe 423 of -10
Current timestep = 424. State = [[ 0.9842474   0.7128389   1.4914706  -0.62258136 -0.40535146 -0.19082671
   0.          0.        ]]. Action = [[-0.9821889  0.850801 ]]. Reward = [-3.0479114]
Abstract state at timestep 424 is 7
State prediction error at timestep 424 is 0.012
Human Feedback received at timestpe 424 of -10
Current timestep = 425. State = [[ 0.9991247   0.698586    1.497869   -0.63640136 -0.4162555  -0.21808133
   0.          0.        ]]. Action = [[0.08684075 0.60448813]]. Reward = [-2.7833898]
Abstract state at timestep 425 is 7
State prediction error at timestep 425 is 0.012
Human Feedback received at timestpe 425 of -10
Current timestep = 426. State = [[-0.00209742  1.4194839  -0.21246192  0.380612    0.00243718  0.04812581
   0.          0.        ]]. Action = [[-0.3787294   0.53455853]]. Reward = [-100.]
Abstract state at timestep 426 is 7
State prediction error at timestep 426 is 0.012
Human Feedback received at timestpe 426 of -10
Current timestep = 427. State = [[-0.00424004  1.4274693  -0.2178103   0.35489023  0.00594573  0.07017784
   0.          0.        ]]. Action = [[-0.52748287 -0.6106347 ]]. Reward = [0.7815195]
Abstract state at timestep 427 is 3
State prediction error at timestep 427 is 0.012
Human Feedback received at timestpe 427 of -10
Current timestep = 428. State = [[-0.00642672  1.4362633  -0.22066024  0.39083883  0.00792077  0.03950449
   0.          0.        ]]. Action = [[0.81948495 0.6537334 ]]. Reward = [-4.613051]
Abstract state at timestep 428 is 3
State prediction error at timestep 428 is 0.012
Human Feedback received at timestpe 428 of -10
Current timestep = 429. State = [[-0.0086133   1.444457   -0.22066553  0.36415577  0.00989667  0.03952195
   0.          0.        ]]. Action = [[-0.96705204 -0.37116373]]. Reward = [1.2849718]
Abstract state at timestep 429 is 3
State prediction error at timestep 429 is 0.012
Human Feedback received at timestpe 429 of -10
Current timestep = 430. State = [[-0.01079998  1.4520509  -0.22067156  0.3374921   0.01187184  0.03950743
   0.          0.        ]]. Action = [[-0.09991413  0.23794222]]. Reward = [1.2980005]
Abstract state at timestep 430 is 3
State prediction error at timestep 430 is 0.012
Human Feedback received at timestpe 430 of -10
Current timestep = 431. State = [[-0.01303034  1.4590415  -0.22613208  0.3106542   0.01494121  0.06139295
   0.          0.        ]]. Action = [[-0.9918956 -0.535717 ]]. Reward = [0.8752647]
Abstract state at timestep 431 is 3
State prediction error at timestep 431 is 0.012
Human Feedback received at timestpe 431 of -10
Current timestep = 432. State = [[-0.01537104  1.4664315  -0.23558629  0.32843545  0.01643969  0.02997248
   0.          0.        ]]. Action = [[0.5203731 0.6142607]]. Reward = [-3.13254]
Abstract state at timestep 432 is 3
State prediction error at timestep 432 is 0.012
Human Feedback received at timestpe 432 of -10
Current timestep = 433. State = [[-0.0177886   1.4732279  -0.24521427  0.30201757  0.0198668   0.0685482
   0.          0.        ]]. Action = [[-0.19643217 -0.7833507 ]]. Reward = [0.4675773]
Abstract state at timestep 433 is 3
State prediction error at timestep 433 is 0.012
Human Feedback received at timestpe 433 of -10
Current timestep = 434. State = [[-0.02020626  1.4794244  -0.24522528  0.27535233  0.02329206  0.06851144
   0.          0.        ]]. Action = [[-0.9518235  -0.14730775]]. Reward = [1.0658119]
Abstract state at timestep 434 is 3
State prediction error at timestep 434 is 0.012
Human Feedback received at timestpe 434 of -10
Current timestep = 435. State = [[-0.02255955  1.4856768  -0.23913887  0.27781737  0.02707199  0.07560483
   0.          0.        ]]. Action = [[0.86727905 0.03574967]]. Reward = [-1.0711589]
Abstract state at timestep 435 is 3
State prediction error at timestep 435 is 0.012
Human Feedback received at timestpe 435 of 10
Current timestep = 436. State = [[-0.02482967  1.4924467  -0.23133573  0.30080178  0.0313403   0.08537397
   0.          0.        ]]. Action = [[ 0.6755545  -0.43423444]]. Reward = [-2.649241]
Abstract state at timestep 436 is 3
State prediction error at timestep 436 is 0.012
Human Feedback received at timestpe 436 of -10
Current timestep = 437. State = [[-0.02708902  1.4990604  -0.23152824  0.29381976  0.03686907  0.11058547
   0.          0.        ]]. Action = [[ 0.49168003 -0.55490094]]. Reward = [-0.919355]
Abstract state at timestep 437 is 3
State prediction error at timestep 437 is 0.012
Human Feedback received at timestpe 437 of -10
Current timestep = 438. State = [[-0.02934866  1.5050746  -0.23154446  0.26714942  0.04239654  0.11055945
   0.          0.        ]]. Action = [[-0.21914208  0.17039609]]. Reward = [0.89689076]
Abstract state at timestep 438 is 3
State prediction error at timestep 438 is 0.012
Human Feedback received at timestpe 438 of -10
Current timestep = 439. State = [[-0.03169594  1.5109376  -0.23995598  0.2604184   0.04757054  0.10348953
   0.          0.        ]]. Action = [[0.32565296 0.1606834 ]]. Reward = [-1.3658117]
Abstract state at timestep 439 is 3
State prediction error at timestep 439 is 0.012
Human Feedback received at timestpe 439 of -10
Current timestep = 440. State = [[-0.03411426  1.5168948  -0.24682939  0.2645974   0.05251389  0.09887574
   0.          0.        ]]. Action = [[ 0.14128327 -0.11833352]]. Reward = [-2.0401335]
Abstract state at timestep 440 is 3
State prediction error at timestep 440 is 0.012
Human Feedback received at timestpe 440 of -10
Current timestep = 441. State = [[-0.0364707   1.522815   -0.24227846  0.2628693   0.05908909  0.13151553
   0.          0.        ]]. Action = [[ 0.78360903 -0.653043  ]]. Reward = [-1.10583]
Abstract state at timestep 441 is 3
State prediction error at timestep 441 is 0.012
Human Feedback received at timestpe 441 of -10
Current timestep = 442. State = [[-0.03876486  1.5281415  -0.23446493  0.2365226   0.06408802  0.09998819
   0.          0.        ]]. Action = [[-0.44709003  0.8114203 ]]. Reward = [1.3824562]
Abstract state at timestep 442 is 3
State prediction error at timestep 442 is 0.012
Human Feedback received at timestpe 442 of -10
Current timestep = 443. State = [[-0.04100895  1.5341587  -0.22791445  0.26728478  0.06756454  0.06953646
   0.          0.        ]]. Action = [[0.98417425 0.81247103]]. Reward = [-3.0992212]
Abstract state at timestep 443 is 3
State prediction error at timestep 443 is 0.012
Human Feedback received at timestpe 443 of -10
Current timestep = 444. State = [[-0.04319859  1.5395777  -0.22109123  0.24074773  0.06967144  0.04214148
   0.          0.        ]]. Action = [[-0.8587577  0.8262317]]. Reward = [1.6566914]
Abstract state at timestep 444 is 3
State prediction error at timestep 444 is 0.012
Human Feedback received at timestpe 444 of -10
Current timestep = 445. State = [[-0.04532175  1.5457786  -0.21291454  0.27556488  0.07026395  0.01185142
   0.          0.        ]]. Action = [[0.78426456 0.8246758 ]]. Reward = [-3.114695]
Abstract state at timestep 445 is 3
State prediction error at timestep 445 is 0.012
Human Feedback received at timestpe 445 of -10
Current timestep = 446. State = [[-0.04737358  1.5513827  -0.20395854  0.24912652  0.06906039 -0.02407361
   0.          0.        ]]. Action = [[-0.86513203  0.7867614 ]]. Reward = [2.1573503]
Abstract state at timestep 446 is 3
State prediction error at timestep 446 is 0.012
Human Feedback received at timestpe 446 of -10
Current timestep = 447. State = [[-0.04949512  1.5570489  -0.20886333  0.251982    0.06579126 -0.06538855
   0.          0.        ]]. Action = [[0.95258    0.93394005]]. Reward = [-1.0992066]
Abstract state at timestep 447 is 3
State prediction error at timestep 447 is 0.012
Human Feedback received at timestpe 447 of -10
Current timestep = 448. State = [[-0.0515337   1.5621206  -0.19845338  0.22563124  0.06043656 -0.10710315
   0.          0.        ]]. Action = [[-0.363778   0.9473157]]. Reward = [2.6737425]
Abstract state at timestep 448 is 3
State prediction error at timestep 448 is 0.012
Human Feedback received at timestpe 448 of -10
Current timestep = 449. State = [[-0.05359592  1.5672715  -0.20083387  0.22914454  0.05509953 -0.10675035
   0.          0.        ]]. Action = [[ 0.5874661 -0.4123146]]. Reward = [-0.6472192]
Abstract state at timestep 449 is 3
State prediction error at timestep 449 is 0.012
Human Feedback received at timestpe 449 of -10
Current timestep = 450. State = [[-0.05554314  1.5727173  -0.19003192  0.2422034   0.05044611 -0.09307648
   0.          0.        ]]. Action = [[ 0.97632647 -0.00223863]]. Reward = [-0.6977129]
Abstract state at timestep 450 is 3
State prediction error at timestep 450 is 0.012
Human Feedback received at timestpe 450 of -10
Current timestep = 451. State = [[-0.0574419   1.577544   -0.18394364  0.21471088  0.04458978 -0.11712657
   0.          0.        ]]. Action = [[-0.31841606  0.51452816]]. Reward = [2.5935597]
Abstract state at timestep 451 is 3
State prediction error at timestep 451 is 0.012
Human Feedback received at timestpe 451 of -10
Current timestep = 452. State = [[-0.05934057  1.5817711  -0.18394342  0.1880413   0.03873346 -0.11712636
   0.          0.        ]]. Action = [[-0.57652146  0.35458672]]. Reward = [2.1242614]
Abstract state at timestep 452 is 3
State prediction error at timestep 452 is 0.012
Human Feedback received at timestpe 452 of -10
Current timestep = 453. State = [[-0.06119718  1.5853971  -0.17865993  0.16131406  0.03182076 -0.13825427
   0.          0.        ]]. Action = [[-0.5237228  0.5289302]]. Reward = [2.539841]
Abstract state at timestep 453 is 3
State prediction error at timestep 453 is 0.012
Human Feedback received at timestpe 453 of -10
Current timestep = 454. State = [[-0.06298418  1.5888903  -0.17368878  0.15534605  0.02687903 -0.09883436
   0.          0.        ]]. Action = [[ 0.7703767  -0.85738623]]. Reward = [0.61551917]
Abstract state at timestep 454 is 3
State prediction error at timestep 454 is 0.012
Human Feedback received at timestpe 454 of -10
Current timestep = 455. State = [[-0.06477118  1.5917836  -0.17368868  0.12867734  0.02193733 -0.09883422
   0.          0.        ]]. Action = [[-0.853665    0.08602011]]. Reward = [1.8841882]
Abstract state at timestep 455 is 3
State prediction error at timestep 455 is 0.012
Human Feedback received at timestpe 455 of -10
Current timestep = 456. State = [[-0.06655522  1.5945297  -0.1746548   0.12209935  0.01823333 -0.07408009
   0.          0.        ]]. Action = [[ 0.3076086 -0.5657064]]. Reward = [0.18144757]
Abstract state at timestep 456 is 3
State prediction error at timestep 456 is 0.012
Human Feedback received at timestpe 456 of -10
Current timestep = 457. State = [[-0.06839313  1.5966696  -0.18140386  0.09512296  0.01588284 -0.04700965
   0.          0.        ]]. Action = [[-0.910904   -0.70641214]]. Reward = [0.8194255]
Abstract state at timestep 457 is 3
State prediction error at timestep 457 is 0.012
Human Feedback received at timestpe 457 of -10
Current timestep = 458. State = [[-0.0701828   1.5982072  -0.17535786  0.06837471  0.01232221 -0.07121275
   0.          0.        ]]. Action = [[-0.8112168   0.80557203]]. Reward = [1.8319612]
Abstract state at timestep 458 is 3
State prediction error at timestep 458 is 0.012
Human Feedback received at timestpe 458 of -10
Current timestep = 459. State = [[-0.07213831  1.5996735  -0.19274524  0.06518561  0.00955933 -0.0552578
   0.          0.        ]]. Action = [[ 0.52908874 -0.54819727]]. Reward = [-1.6500033]
Abstract state at timestep 459 is 3
State prediction error at timestep 459 is 0.012
Human Feedback received at timestpe 459 of -10
Current timestep = 460. State = [[-0.07409372  1.6005397  -0.19274522  0.0385183   0.00679644 -0.05525776
   0.          0.        ]]. Action = [[-0.20279306 -0.4841634 ]]. Reward = [0.87217027]
Abstract state at timestep 460 is 3
State prediction error at timestep 460 is 0.012
Human Feedback received at timestpe 460 of -10
Current timestep = 461. State = [[-0.07590389  1.6017928  -0.17642845  0.05570702  0.00226657 -0.09059735
   0.          0.        ]]. Action = [[0.8463166 0.9498532]]. Reward = [1.1681044]
Abstract state at timestep 461 is 3
State prediction error at timestep 461 is 0.012
Human Feedback received at timestpe 461 of -10
Current timestep = 462. State = [[-0.07763491  1.6038722  -0.16889252  0.09242025 -0.00188733 -0.083078
   0.          0.        ]]. Action = [[0.8933201 0.3565675]]. Reward = [-1.2132123]
Abstract state at timestep 462 is 3
State prediction error at timestep 462 is 0.012
Human Feedback received at timestpe 462 of -10
Current timestep = 463. State = [[-0.07941475  1.6053514  -0.17501698  0.06574146 -0.0048147  -0.05854763
   0.          0.        ]]. Action = [[-0.29803133 -0.5562528 ]]. Reward = [0.09101246]
Abstract state at timestep 463 is 3
State prediction error at timestep 463 is 0.012
Human Feedback received at timestpe 463 of -10
Current timestep = 464. State = [[-0.08128567  1.6068728  -0.18576863  0.06761117 -0.00612302 -0.02616635
   0.          0.        ]]. Action = [[ 0.81782365 -0.8400054 ]]. Reward = [-1.6632869]
Abstract state at timestep 464 is 3
State prediction error at timestep 464 is 0.012
Human Feedback received at timestpe 464 of -10
Current timestep = 465. State = [[-0.08308611  1.607792   -0.17692903  0.04084184 -0.00920181 -0.06157578
   0.          0.        ]]. Action = [[-0.26276588  0.75736856]]. Reward = [1.1792032]
Abstract state at timestep 465 is 3
State prediction error at timestep 465 is 0.012
Human Feedback received at timestpe 465 of -10
Current timestep = 466. State = [[-0.08481207  1.6080989  -0.16757387  0.01360041 -0.01415606 -0.09908463
   0.          0.        ]]. Action = [[-0.8310437   0.97713923]]. Reward = [0.7813096]
Abstract state at timestep 466 is 3
State prediction error at timestep 466 is 0.012
Human Feedback received at timestpe 466 of -10
Current timestep = 467. State = [[-0.08653793  1.6078062  -0.1675739  -0.01306831 -0.01911029 -0.09908448
   0.          0.        ]]. Action = [[-0.01020187  0.25492954]]. Reward = [-0.4711622]
Abstract state at timestep 467 is 3
State prediction error at timestep 467 is 0.012
Human Feedback received at timestpe 467 of -10
Current timestep = 468. State = [[-0.08833037  1.6081991  -0.1751004   0.01740619 -0.02320101 -0.08181442
   0.          0.        ]]. Action = [[ 0.9362881  -0.50047773]]. Reward = [-1.5515709]
Abstract state at timestep 468 is 3
State prediction error at timestep 468 is 0.012
Human Feedback received at timestpe 468 of -10
Current timestep = 469. State = [[-0.09012289  1.6079923  -0.17510043 -0.00926188 -0.02729172 -0.08181433
   0.          0.        ]]. Action = [[-0.7013855   0.01931775]]. Reward = [-0.3365284]
Abstract state at timestep 469 is 3
State prediction error at timestep 469 is 0.012
Human Feedback received at timestpe 469 of -10
Current timestep = 470. State = [[-0.09191532  1.6071858  -0.17510048 -0.03592994 -0.03138242 -0.08181424
   0.          0.        ]]. Action = [[-0.52757215  0.3627473 ]]. Reward = [-0.67903936]
Abstract state at timestep 470 is 3
State prediction error at timestep 470 is 0.012
Human Feedback received at timestpe 470 of -10
Current timestep = 471. State = [[-0.09370776  1.6057794  -0.17510054 -0.06259801 -0.03547313 -0.08181416
   0.          0.        ]]. Action = [[-0.43887514 -0.12875408]]. Reward = [-0.9994788]
Abstract state at timestep 471 is 3
State prediction error at timestep 471 is 0.012
Human Feedback received at timestpe 471 of -10
Current timestep = 472. State = [[-0.0955018   1.6044704  -0.17730103 -0.05823193 -0.03755027 -0.04154251
   0.          0.        ]]. Action = [[ 0.5046607 -0.9847365]]. Reward = [-0.40937072]
Abstract state at timestep 472 is 3
State prediction error at timestep 472 is 0.012
Human Feedback received at timestpe 472 of -10
Current timestep = 473. State = [[-0.09749775  1.6036379  -0.19920221 -0.03700096 -0.03793634 -0.00772136
   0.          0.        ]]. Action = [[ 0.86451113 -0.9721306 ]]. Reward = [-1.8753968]
Abstract state at timestep 473 is 3
State prediction error at timestep 473 is 0.012
Human Feedback received at timestpe 473 of -10
Current timestep = 474. State = [[-0.0992732   1.6032113  -0.1762186  -0.01900612 -0.03924895 -0.02625254
   0.          0.        ]]. Action = [[0.6234524 0.6333959]]. Reward = [2.1748238]
Abstract state at timestep 474 is 3
State prediction error at timestep 474 is 0.012
Human Feedback received at timestpe 474 of -10
Current timestep = 475. State = [[-0.10104875  1.6021843  -0.1762186  -0.04567294 -0.04056158 -0.02625251
   0.          0.        ]]. Action = [[-0.66571975  0.4381032 ]]. Reward = [-0.5199073]
Abstract state at timestep 475 is 3
State prediction error at timestep 475 is 0.012
Human Feedback received at timestpe 475 of -10
Current timestep = 476. State = [[-0.10270796  1.601344   -0.163324   -0.0374238  -0.04313221 -0.05141255
   0.          0.        ]]. Action = [[0.53530693 0.67465544]]. Reward = [1.0141762]
Abstract state at timestep 476 is 3
State prediction error at timestep 476 is 0.012
Human Feedback received at timestpe 476 of -10
Current timestep = 477. State = [[-0.10436726  1.5999036  -0.16332403 -0.06409101 -0.04570284 -0.05141254
   0.          0.        ]]. Action = [[-0.85264605  0.43462968]]. Reward = [-0.9132715]
Abstract state at timestep 477 is 3
State prediction error at timestep 477 is 0.012
Human Feedback received at timestpe 477 of -10
Current timestep = 478. State = [[-0.10588255  1.5983855  -0.14789473 -0.06759209 -0.04928863 -0.07171615
   0.          0.        ]]. Action = [[0.42392647 0.59683716]]. Reward = [0.83553666]
Abstract state at timestep 478 is 3
State prediction error at timestep 478 is 0.012
Human Feedback received at timestpe 478 of -10
Current timestep = 479. State = [[-0.10743799  1.5962756  -0.15295374 -0.09385705 -0.05185501 -0.05132767
   0.          0.        ]]. Action = [[-0.695051   -0.61793566]]. Reward = [-1.759638]
Abstract state at timestep 479 is 3
State prediction error at timestep 479 is 0.012
Human Feedback received at timestpe 479 of -10
Current timestep = 480. State = [[-0.10884361  1.594489   -0.13851738 -0.07948026 -0.05387669 -0.04043362
   0.          0.        ]]. Action = [[ 0.3337623  -0.46881998]]. Reward = [1.7419537]
Abstract state at timestep 480 is 3
State prediction error at timestep 480 is 0.012
Human Feedback received at timestpe 480 of -10
Current timestep = 481. State = [[-0.11017513  1.5920959  -0.12921664 -0.10650543 -0.05776559 -0.07777785
   0.          0.        ]]. Action = [[-0.79557586  0.7587408 ]]. Reward = [-0.95726055]
Abstract state at timestep 481 is 3
State prediction error at timestep 481 is 0.012
Human Feedback received at timestpe 481 of -10
Current timestep = 482. State = [[-0.11156063  1.5898161  -0.13423884 -0.10149682 -0.06203114 -0.08531086
   0.          0.        ]]. Action = [[ 0.04263461 -0.09326351]]. Reward = [-0.44894424]
Abstract state at timestep 482 is 3
State prediction error at timestep 482 is 0.012
Human Feedback received at timestpe 482 of -10
Current timestep = 483. State = [[-0.11283445  1.5879195  -0.12339445 -0.08446637 -0.06596875 -0.07875223
   0.          0.        ]]. Action = [[0.4581195  0.20876658]]. Reward = [1.4432635]
Abstract state at timestep 483 is 3
State prediction error at timestep 483 is 0.012
Human Feedback received at timestpe 483 of -10
Current timestep = 484. State = [[-0.1141633   1.5854242  -0.13030948 -0.11102203 -0.06852178 -0.05106059
   0.          0.        ]]. Action = [[-0.37064636 -0.66265553]]. Reward = [-2.2013733]
Abstract state at timestep 484 is 3
State prediction error at timestep 484 is 0.012
Human Feedback received at timestpe 484 of -10
Current timestep = 485. State = [[-0.11537943  1.5836264  -0.11927404 -0.08000897 -0.07082823 -0.04612908
   0.          0.        ]]. Action = [[0.91222835 0.36524403]]. Reward = [2.409806]
Abstract state at timestep 485 is 3
State prediction error at timestep 485 is 0.012
Human Feedback received at timestpe 485 of -10
Current timestep = 486. State = [[-0.11653795  1.581216   -0.11204485 -0.10731675 -0.074596   -0.07535534
   0.          0.        ]]. Action = [[-0.4224937  0.5942446]]. Reward = [-1.3151261]
Abstract state at timestep 486 is 3
State prediction error at timestep 486 is 0.012
Human Feedback received at timestpe 486 of -10
Current timestep = 487. State = [[-0.11774254  1.5782045  -0.11782052 -0.13397603 -0.07721014 -0.0522827
   0.          0.        ]]. Action = [[-0.6807353 -0.5759227]]. Reward = [-2.3137777]
Abstract state at timestep 487 is 3
State prediction error at timestep 487 is 0.012
Human Feedback received at timestpe 487 of -10
Current timestep = 488. State = [[-0.11894713  1.5745932  -0.1178206  -0.16064326 -0.07982427 -0.05228267
   0.          0.        ]]. Action = [[-0.2609135   0.43026066]]. Reward = [-1.9908322]
Abstract state at timestep 488 is 3
State prediction error at timestep 488 is 0.012
Human Feedback received at timestpe 488 of -10
Current timestep = 489. State = [[-0.12015162  1.5703819  -0.11782066 -0.1873105  -0.08243841 -0.05228267
   0.          0.        ]]. Action = [[-0.36613905  0.02485895]]. Reward = [-2.057267]
Abstract state at timestep 489 is 3
State prediction error at timestep 489 is 0.012
Human Feedback received at timestpe 489 of -10
Current timestep = 490. State = [[-0.12130442  1.5655597  -0.11131437 -0.21454334 -0.08636876 -0.07860679
   0.          0.        ]]. Action = [[-0.29437798  0.8185606 ]]. Reward = [-1.9873556]
Abstract state at timestep 490 is 3
State prediction error at timestep 490 is 0.012
Human Feedback received at timestpe 490 of -10
Current timestep = 491. State = [[-0.12240019  1.560136   -0.1041608  -0.24137259 -0.09173162 -0.1072572
   0.          0.        ]]. Action = [[-0.25606215  0.70086753]]. Reward = [-2.1437361]
Abstract state at timestep 491 is 3
State prediction error at timestep 491 is 0.012
Human Feedback received at timestpe 491 of -10
Current timestep = 492. State = [[-0.12358351  1.5549345  -0.11228591 -0.23156406 -0.09773062 -0.11998
   0.          0.        ]]. Action = [[0.6492827  0.03515482]]. Reward = [0.21554713]
Abstract state at timestep 492 is 3
State prediction error at timestep 492 is 0.012
Human Feedback received at timestpe 492 of -10
Current timestep = 493. State = [[-0.12476683  1.5491333  -0.11228631 -0.2582337  -0.10372961 -0.11997969
   0.          0.        ]]. Action = [[-0.68244255  0.01838219]]. Reward = [-2.4548593]
Abstract state at timestep 493 is 3
State prediction error at timestep 493 is 0.012
Human Feedback received at timestpe 493 of -10
Current timestep = 494. State = [[-0.12589912  1.5427307  -0.1058974  -0.28509292 -0.11100863 -0.14558068
   0.          0.        ]]. Action = [[-0.98005533  0.8266083 ]]. Reward = [-2.3772237]
Abstract state at timestep 494 is 3
State prediction error at timestep 494 is 0.012
Human Feedback received at timestpe 494 of -10
Current timestep = 495. State = [[-0.12693281  1.5368001  -0.09466885 -0.26424503 -0.11964692 -0.17276636
   0.          0.        ]]. Action = [[0.55329967 0.6473994 ]]. Reward = [1.8097563]
Abstract state at timestep 495 is 3
State prediction error at timestep 495 is 0.012
Human Feedback received at timestpe 495 of -10
Current timestep = 496. State = [[-0.1279664   1.5302709  -0.09466992 -0.29091793 -0.1282852  -0.17276546
   0.          0.        ]]. Action = [[-0.66737556  0.41626585]]. Reward = [-2.7459736]
Abstract state at timestep 496 is 3
State prediction error at timestep 496 is 0.012
Human Feedback received at timestpe 496 of -10
Current timestep = 497. State = [[-0.1289999   1.5231423  -0.09467106 -0.3175908  -0.13692342 -0.1727646
   0.          0.        ]]. Action = [[-0.59611166  0.14702559]]. Reward = [-2.7088294]
Abstract state at timestep 497 is 3
State prediction error at timestep 497 is 0.012
Human Feedback received at timestpe 497 of -10
Current timestep = 498. State = [[-0.13010578  1.5154301  -0.10378975 -0.34341466 -0.143709   -0.1357114
   0.          0.        ]]. Action = [[-0.3351276  -0.97787976]]. Reward = [-2.6843717]
Abstract state at timestep 498 is 3
State prediction error at timestep 498 is 0.012
Human Feedback received at timestpe 498 of -10
Current timestep = 499. State = [[-0.13125868  1.5071375  -0.1097075  -0.36910307 -0.14926852 -0.11119077
   0.          0.        ]]. Action = [[-0.66326386 -0.7860285 ]]. Reward = [-2.393895]
Abstract state at timestep 499 is 3
State prediction error at timestep 499 is 0.012
Human Feedback received at timestpe 499 of -10
Current timestep = 500. State = [[-0.13248166  1.4982592  -0.11852819 -0.39497608 -0.1530366  -0.07536152
   0.          0.        ]]. Action = [[-0.643495   -0.88681054]]. Reward = [-2.2611887]
Abstract state at timestep 500 is 3
State prediction error at timestep 500 is 0.012
Human Feedback received at timestpe 500 of -10
Current timestep = 501. State = [[-0.13362074  1.489249   -0.11029353 -0.40083104 -0.15664072 -0.07208268
   0.          0.        ]]. Action = [[0.03436577 0.39860976]]. Reward = [0.03667507]
Abstract state at timestep 501 is 3
State prediction error at timestep 501 is 0.012
Human Feedback received at timestpe 501 of -10
Current timestep = 502. State = [[-0.13465223  1.4807934  -0.0994744  -0.3761961  -0.16030905 -0.07336684
   0.          0.        ]]. Action = [[0.8726561  0.47136235]]. Reward = [2.8454208]
Abstract state at timestep 502 is 3
State prediction error at timestep 502 is 0.012
Human Feedback received at timestpe 502 of -10
Current timestep = 503. State = [[-0.13568363  1.471738   -0.09947467 -0.40286392 -0.16397738 -0.07336679
   0.          0.        ]]. Action = [[-0.06130469 -0.43543458]]. Reward = [-2.0582476]
Abstract state at timestep 503 is 3
State prediction error at timestep 503 is 0.012
Human Feedback received at timestpe 503 of -10
Current timestep = 504. State = [[-0.13671502  1.4620827  -0.09947494 -0.4295317  -0.16764572 -0.0733667
   0.          0.        ]]. Action = [[-0.64062566 -0.14641297]]. Reward = [-2.008643]
Abstract state at timestep 504 is 3
State prediction error at timestep 504 is 0.012
Human Feedback received at timestpe 504 of -10
Current timestep = 505. State = [[-0.13768664  1.4518176  -0.09197016 -0.4568168  -0.17283483 -0.10378227
   0.          0.        ]]. Action = [[-0.16328365  0.7022412 ]]. Reward = [-2.0354037]
Abstract state at timestep 505 is 3
State prediction error at timestep 505 is 0.012
Human Feedback received at timestpe 505 of -10
Current timestep = 506. State = [[-0.13865805  1.440953   -0.09197073 -0.4834857  -0.17802393 -0.10378204
   0.          0.        ]]. Action = [[-0.9831903 -0.1400302]]. Reward = [-2.0638692]
Abstract state at timestep 506 is 3
State prediction error at timestep 506 is 0.012
Human Feedback received at timestpe 506 of -10
Current timestep = 507. State = [[-0.13950682  1.4299066  -0.08003059 -0.491538   -0.18288271 -0.09717591
   0.          0.        ]]. Action = [[0.20376682 0.02466536]]. Reward = [-0.1606394]
Abstract state at timestep 507 is 3
State prediction error at timestep 507 is 0.012
Human Feedback received at timestpe 507 of -10
Current timestep = 508. State = [[-0.14014101  1.4189564  -0.05916614 -0.48721412 -0.18715619 -0.08546948
   0.          0.        ]]. Action = [[ 0.52196336 -0.23220217]]. Reward = [1.1496581]
Abstract state at timestep 508 is 3
State prediction error at timestep 508 is 0.012
Human Feedback received at timestpe 508 of -10
Current timestep = 509. State = [[-0.14089079  1.4078352  -0.0721401  -0.49462712 -0.19000441 -0.05696403
   0.          0.        ]]. Action = [[ 0.4425615 -0.7885103]]. Reward = [-0.3322965]
Abstract state at timestep 509 is 3
State prediction error at timestep 509 is 0.012
Human Feedback received at timestpe 509 of -10
Current timestep = 510. State = [[-0.14155646  1.396097   -0.0615956  -0.52235514 -0.19500192 -0.09995046
   0.          0.        ]]. Action = [[-0.2651195  0.892221 ]]. Reward = [-1.9766701]
Abstract state at timestep 510 is 3
State prediction error at timestep 510 is 0.012
Human Feedback received at timestpe 510 of -10
Current timestep = 511. State = [[-0.1421258   1.3850405  -0.05359168 -0.4918433  -0.19836952 -0.06735204
   0.          0.        ]]. Action = [[ 0.9250442 -0.8168889]]. Reward = [3.5661156]
Abstract state at timestep 511 is 3
State prediction error at timestep 511 is 0.012
Human Feedback received at timestpe 511 of -10
Current timestep = 512. State = [[-0.14269514  1.3733841  -0.05359196 -0.51851094 -0.20173712 -0.06735193
   0.          0.        ]]. Action = [[-0.22701037  0.38210607]]. Reward = [-1.8350065]
Abstract state at timestep 512 is 3
State prediction error at timestep 512 is 0.012
Human Feedback received at timestpe 512 of -10
Current timestep = 513. State = [[-0.14329147  1.3617427  -0.05785496 -0.5176367  -0.20352657 -0.03578902
   0.          0.        ]]. Action = [[ 0.1738671 -0.8023792]]. Reward = [0.81385475]
Abstract state at timestep 513 is 3
State prediction error at timestep 513 is 0.012
Human Feedback received at timestpe 513 of -10
Current timestep = 514. State = [[-0.14383975  1.3503064  -0.05113266 -0.5088006  -0.20724729 -0.07441466
   0.          0.        ]]. Action = [[0.38323772 0.9020045 ]]. Reward = [1.4745263]
Abstract state at timestep 514 is 3
State prediction error at timestep 514 is 0.012
Human Feedback received at timestpe 514 of -10
Current timestep = 515. State = [[-0.14410725  1.3396959  -0.02500834 -0.47182673 -0.20900768 -0.03520783
   0.          0.        ]]. Action = [[ 0.9140072 -0.8241176]]. Reward = [4.451758]
Abstract state at timestep 515 is 3
State prediction error at timestep 515 is 0.012
Human Feedback received at timestpe 515 of -10
Current timestep = 516. State = [[-0.14437476  1.3284853  -0.02500842 -0.4984937  -0.21076809 -0.0352078
   0.          0.        ]]. Action = [[-0.02964413  0.27057528]]. Reward = [-1.7275068]
Abstract state at timestep 516 is 3
State prediction error at timestep 516 is 0.012
Human Feedback received at timestpe 516 of -10
Current timestep = 517. State = [[-0.14469194  1.3166887  -0.03125396 -0.524365   -0.21124254 -0.00948918
   0.          0.        ]]. Action = [[-0.17173558 -0.7659553 ]]. Reward = [-1.51869]
Abstract state at timestep 517 is 3
State prediction error at timestep 517 is 0.012
Human Feedback received at timestpe 517 of 10
Current timestep = 518. State = [[-0.14496765  1.3042748  -0.02601025 -0.55195063 -0.21281669 -0.03148261
   0.          0.        ]]. Action = [[-0.5658524   0.57037735]]. Reward = [-1.6704419]
Abstract state at timestep 518 is 3
State prediction error at timestep 518 is 0.012
Human Feedback received at timestpe 518 of 10
Current timestep = 519. State = [[-0.14511013  1.292243   -0.01119038 -0.5351988  -0.21590935 -0.06185332
   0.          0.        ]]. Action = [[0.7106898  0.68668246]]. Reward = [2.332438]
Abstract state at timestep 519 is 3
State prediction error at timestep 519 is 0.012
Human Feedback received at timestpe 519 of 10
Current timestep = 520. State = [[-0.14517966  1.2802719  -0.00184011 -0.53280497 -0.22108236 -0.10346039
   0.          0.        ]]. Action = [[0.6697124 0.9690454]]. Reward = [0.642712]
Abstract state at timestep 520 is 3
State prediction error at timestep 520 is 0.012
Human Feedback received at timestpe 520 of 10
Current timestep = 521. State = [[-0.1451786   1.2676744   0.00705713 -0.5609476  -0.2281161  -0.14067458
   0.          0.        ]]. Action = [[-0.05839312  0.94628024]]. Reward = [-2.2984998]
Abstract state at timestep 521 is 3
State prediction error at timestep 521 is 0.012
Human Feedback received at timestpe 521 of 10
Current timestep = 522. State = [[-0.1451149   1.2555327   0.01164629 -0.54045856 -0.23346454 -0.10696886
   0.          0.        ]]. Action = [[ 0.58726704 -0.8565628 ]]. Reward = [2.4491131]
Abstract state at timestep 522 is 3
State prediction error at timestep 522 is 0.012
Human Feedback received at timestpe 522 of 10
Current timestep = 523. State = [[-0.14480504  1.2435696   0.03711483 -0.53267735 -0.23968986 -0.12450618
   0.          0.        ]]. Action = [[0.59359586 0.53379023]]. Reward = [0.9758487]
Abstract state at timestep 523 is 3
State prediction error at timestep 523 is 0.012
Human Feedback received at timestpe 523 of 10
Current timestep = 524. State = [[-0.1444951   1.2310071   0.03711369 -0.5593471  -0.24591517 -0.12450595
   0.          0.        ]]. Action = [[-0.5382015  -0.20133603]]. Reward = [-2.0319946]
Abstract state at timestep 524 is 3
State prediction error at timestep 524 is 0.012
Human Feedback received at timestpe 524 of 10
Current timestep = 525. State = [[-0.14402151  1.2184504   0.05319678 -0.55905914 -0.25186118 -0.11892049
   0.          0.        ]]. Action = [[0.6054083  0.30620217]]. Reward = [0.31642997]
Abstract state at timestep 525 is 3
State prediction error at timestep 525 is 0.012
Human Feedback received at timestpe 525 of 10
Current timestep = 526. State = [[-0.14347696  1.2052639   0.06214596 -0.58741033 -0.2597015  -0.15680625
   0.          0.        ]]. Action = [[-0.9326884   0.93433404]]. Reward = [-2.4065902]
Abstract state at timestep 526 is 3
State prediction error at timestep 526 is 0.012
Human Feedback received at timestpe 526 of 10
Current timestep = 527. State = [[-0.14293222  1.191478    0.06214401 -0.614082   -0.26754177 -0.15680556
   0.          0.        ]]. Action = [[-0.89883226 -0.0293349 ]]. Reward = [-2.061695]
Abstract state at timestep 527 is 3
State prediction error at timestep 527 is 0.012
Human Feedback received at timestpe 527 of 10
Current timestep = 528. State = [[-0.14234543  1.177069    0.06746386 -0.6420403  -0.27653855 -0.17993575
   0.          0.        ]]. Action = [[-0.5873246  0.5696218]]. Reward = [-2.314845]
Abstract state at timestep 528 is 3
State prediction error at timestep 528 is 0.012
Human Feedback received at timestpe 528 of 10
Current timestep = 529. State = [[-0.14171581  1.1626803   0.07005025 -0.6408587  -0.28381792 -0.14558718
   0.          0.        ]]. Action = [[ 0.220667   -0.84896934]]. Reward = [0.5893811]
Abstract state at timestep 529 is 3
State prediction error at timestep 529 is 0.012
Human Feedback received at timestpe 529 of 10
Current timestep = 530. State = [[-0.1411438   1.147722    0.06275384 -0.66589993 -0.2895223  -0.11408733
   0.          0.        ]]. Action = [[-0.4692098 -0.7746659]]. Reward = [-1.5194315]
Abstract state at timestep 530 is 3
State prediction error at timestep 530 is 0.012
Human Feedback received at timestpe 530 of 10
Current timestep = 531. State = [[-0.14045715  1.1329631   0.0743904  -0.65710133 -0.29542267 -0.11800798
   0.          0.        ]]. Action = [[0.6650382  0.10845613]]. Reward = [1.3885379]
Abstract state at timestep 531 is 3
State prediction error at timestep 531 is 0.012
Human Feedback received at timestpe 531 of 10
Current timestep = 532. State = [[-0.13985443  1.1176342   0.06384306 -0.68200946 -0.29910898 -0.07372604
   0.          0.        ]]. Action = [[-0.13554764 -0.91468596]]. Reward = [-1.2367157]
Abstract state at timestep 532 is 3
State prediction error at timestep 532 is 0.012
Human Feedback received at timestpe 532 of 10
Current timestep = 533. State = [[-0.13920984  1.1016878   0.06911697 -0.7096927  -0.30391768 -0.09617411
   0.          0.        ]]. Action = [[-0.60796297  0.563499  ]]. Reward = [-1.713488]
Abstract state at timestep 533 is 3
State prediction error at timestep 533 is 0.012
Human Feedback received at timestpe 533 of 10
Current timestep = 534. State = [[-0.13834134  1.0857596   0.08954708 -0.70848525 -0.30671257 -0.05589787
   0.          0.        ]]. Action = [[ 0.56792927 -0.8886103 ]]. Reward = [0.9426013]
Abstract state at timestep 534 is 3
State prediction error at timestep 534 is 0.012
Human Feedback received at timestpe 534 of 10
Current timestep = 535. State = [[-0.13740186  1.0700041   0.09703706 -0.7009013  -0.30991393 -0.0640272
   0.          0.        ]]. Action = [[ 0.6429335  -0.20960104]]. Reward = [1.6616775]
Abstract state at timestep 535 is 3
State prediction error at timestep 535 is 0.012
Human Feedback received at timestpe 535 of 10
Current timestep = 536. State = [[-0.1364624   1.0536488   0.09703667 -0.7275688  -0.3131153  -0.06402718
   0.          0.        ]]. Action = [[-0.7766265   0.19202328]]. Reward = [-1.3284782]
Abstract state at timestep 536 is 3
State prediction error at timestep 536 is 0.012
Human Feedback received at timestpe 536 of 10
Current timestep = 537. State = [[-0.13546638  1.0366702   0.10414173 -0.7555916  -0.31782806 -0.0942555
   0.          0.        ]]. Action = [[-0.72500855  0.76058364]]. Reward = [-1.6699128]
Abstract state at timestep 537 is 3
State prediction error at timestep 537 is 0.012
Human Feedback received at timestpe 537 of 10
Current timestep = 538. State = [[-0.13441248  1.0195136   0.11006363 -0.7635513  -0.3226935  -0.09730892
   0.          0.        ]]. Action = [[0.02177775 0.20798695]]. Reward = [0.20411924]
Abstract state at timestep 538 is 3
State prediction error at timestep 538 is 0.012
Human Feedback received at timestpe 538 of 10
Current timestep = 539. State = [[-0.13321571  1.002312    0.1262008  -0.7659928  -0.32948664 -0.13586295
   0.          0.        ]]. Action = [[0.9629799  0.89136255]]. Reward = [0.23289141]
Abstract state at timestep 539 is 3
State prediction error at timestep 539 is 0.012
Human Feedback received at timestpe 539 of 10
Current timestep = 540. State = [[-0.13201876  0.9845108   0.12619892 -0.79266304 -0.33627975 -0.13586251
   0.          0.        ]]. Action = [[-0.18245506 -0.04228806]]. Reward = [-1.5317037]
Abstract state at timestep 540 is 3
State prediction error at timestep 540 is 0.012
Human Feedback received at timestpe 540 of 10
Current timestep = 541. State = [[-0.13082162  0.9661101   0.12619703 -0.8193333  -0.34307286 -0.1358621
   0.          0.        ]]. Action = [[-0.22378439  0.37617683]]. Reward = [-1.474625]
Abstract state at timestep 541 is 4
State prediction error at timestep 541 is 0.012
Human Feedback received at timestpe 541 of 10
Current timestep = 542. State = [[-0.12949648  0.94758797  0.1389342  -0.82475024 -0.34980428 -0.13462831
   0.          0.        ]]. Action = [[ 0.3740667  -0.08103198]]. Reward = [0.2363678]
Abstract state at timestep 542 is 4
State prediction error at timestep 542 is 0.012
Human Feedback received at timestpe 542 of 10
Current timestep = 543. State = [[-0.12817116  0.9284663   0.13893226 -0.8514204  -0.35653567 -0.1346279
   0.          0.        ]]. Action = [[-0.9759673   0.11308277]]. Reward = [-1.3917911]
Abstract state at timestep 543 is 4
State prediction error at timestep 543 is 0.012
Human Feedback received at timestpe 543 of 10
Current timestep = 544. State = [[-0.1267991   0.9087131   0.14484958 -0.8798454  -0.3646095  -0.1614764
   0.          0.        ]]. Action = [[-0.4190005   0.79392886]]. Reward = [-1.7565504]
Abstract state at timestep 544 is 4
State prediction error at timestep 544 is 0.012
Human Feedback received at timestpe 544 of 10
Current timestep = 545. State = [[-0.1252449   0.88877606  0.16274872 -0.88797164 -0.37235308 -0.15487123
   0.          0.        ]]. Action = [[0.59892297 0.3330425 ]]. Reward = [-0.12560974]
Abstract state at timestep 545 is 4
State prediction error at timestep 545 is 0.012
Human Feedback received at timestpe 545 of 10
Current timestep = 546. State = [[-0.12358494  0.8689689   0.17363772 -0.8823337  -0.3804601  -0.16214058
   0.          0.        ]]. Action = [[ 0.13606572 -0.4711839 ]]. Reward = [1.3539184]
Abstract state at timestep 546 is 4
State prediction error at timestep 546 is 0.012
Human Feedback received at timestpe 546 of 10
Current timestep = 547. State = [[-0.12187481  0.8485329   0.17994845 -0.9106838  -0.38997656 -0.19032967
   0.          0.        ]]. Action = [[-0.59313    0.6510427]]. Reward = [-1.8274807]
Abstract state at timestep 547 is 4
State prediction error at timestep 547 is 0.012
Human Feedback received at timestpe 547 of 10
Current timestep = 548. State = [[-0.12008925  0.8274575   0.18940958 -0.9397019  -0.40158278 -0.23212504
   0.          0.        ]]. Action = [[-0.13875282  0.91249204]]. Reward = [-2.1074312]
Abstract state at timestep 548 is 4
State prediction error at timestep 548 is 0.012
Human Feedback received at timestpe 548 of 10
Current timestep = 549. State = [[-0.11834955  0.80581784  0.18349645 -0.9644918  -0.4118213  -0.20477054
   0.          0.        ]]. Action = [[-0.94626546 -0.71032465]]. Reward = [-1.197868]
Abstract state at timestep 549 is 4
State prediction error at timestep 549 is 0.012
Human Feedback received at timestpe 549 of 10
Current timestep = 550. State = [[-0.11641607  0.7839964   0.20439422 -0.97310644 -0.4237453  -0.23848018
   0.          0.        ]]. Action = [[0.596187  0.8101344]]. Reward = [-0.52401817]
Abstract state at timestep 550 is 4
State prediction error at timestep 550 is 0.012
Human Feedback received at timestpe 550 of 10
Current timestep = 551. State = [[-0.11414985  0.7623133   0.23717156 -0.9669116  -0.43520293 -0.22915272
   0.          0.        ]]. Action = [[ 0.5366347 -0.0348435]]. Reward = [0.6783793]
Abstract state at timestep 551 is 4
State prediction error at timestep 551 is 0.012
Human Feedback received at timestpe 551 of 10
Current timestep = 552. State = [[-0.11188316  0.74003166  0.23716469 -0.9935884  -0.4466605  -0.22915062
   0.          0.        ]]. Action = [[-0.78902376 -0.49282312]]. Reward = [-1.5013565]
Abstract state at timestep 552 is 4
State prediction error at timestep 552 is 0.012
Human Feedback received at timestpe 552 of 10
Current timestep = 553. State = [[-0.109616    0.7171516   0.23715767 -1.020265   -0.45811793 -0.22914858
   0.          0.        ]]. Action = [[-0.06665581 -0.3679859 ]]. Reward = [-1.4460944]
Abstract state at timestep 553 is 4
State prediction error at timestep 553 is 0.012
Human Feedback received at timestpe 553 of 10
Current timestep = 554. State = [[-0.10703764  0.6944837   0.2664491  -1.0103246  -0.46760935 -0.18982837
   0.          0.        ]]. Action = [[ 0.207376   -0.92177874]]. Reward = [1.381453]
Abstract state at timestep 554 is 4
State prediction error at timestep 554 is 0.012
Human Feedback received at timestpe 554 of 10
Current timestep = 555. State = [[-0.10421495  0.6723735   0.2926221  -0.9862123  -0.47909492 -0.22971193
   0.          0.        ]]. Action = [[0.934845   0.75566316]]. Reward = [2.3827214]
Abstract state at timestep 555 is 4
State prediction error at timestep 555 is 0.012
Human Feedback received at timestpe 555 of 10
Current timestep = 556. State = [[-0.10132418  0.64960474  0.30125165 -1.01622    -0.49269578 -0.27201647
   0.          0.        ]]. Action = [[-0.52077633  0.8330765 ]]. Reward = [-2.2131035]
Abstract state at timestep 556 is 4
State prediction error at timestep 556 is 0.012
Human Feedback received at timestpe 556 of 10
Current timestep = 557. State = [[-0.09837551  0.62619996  0.30846077 -1.0451592  -0.50797373 -0.30556017
   0.          0.        ]]. Action = [[-0.22573829  0.65749335]]. Reward = [-2.1691618]
Abstract state at timestep 557 is 4
State prediction error at timestep 557 is 0.012
Human Feedback received at timestpe 557 of 10
Current timestep = 558. State = [[-0.0954258  0.6021978  0.3084467 -1.0718429 -0.5232515 -0.305556
   0.         0.       ]]. Action = [[-0.54002935 -0.17599857]]. Reward = [-1.6723236]
Abstract state at timestep 558 is 4
State prediction error at timestep 558 is 0.012
Human Feedback received at timestpe 558 of 10
Current timestep = 559. State = [[-0.09225579  0.57822526  0.33043438 -1.0706964  -0.53861666 -0.3073032
   0.          0.        ]]. Action = [[ 0.2296462  -0.36770654]]. Reward = [0.17792204]
Abstract state at timestep 559 is 4
State prediction error at timestep 559 is 0.012
Human Feedback received at timestpe 559 of 10
Current timestep = 560. State = [[-0.08912535  0.5536936   0.32520542 -1.0952153  -0.5526657  -0.28098142
   0.          0.        ]]. Action = [[-0.45990932 -0.5814149 ]]. Reward = [-1.1457567]
Abstract state at timestep 560 is 4
State prediction error at timestep 560 is 0.012
Human Feedback received at timestpe 560 of 10
Current timestep = 561. State = [[-0.08599405  0.5285642   0.32519257 -1.1218964  -0.5667146  -0.28097767
   0.          0.        ]]. Action = [[-0.26978648 -0.09917009]]. Reward = [-1.4340376]
Abstract state at timestep 561 is 4
State prediction error at timestep 561 is 0.012
Human Feedback received at timestpe 561 of 10
Current timestep = 562. State = [[-0.08268795  0.5033774   0.3427497  -1.124639   -0.5809796  -0.28529936
   0.          0.        ]]. Action = [[ 0.50872016 -0.1895991 ]]. Reward = [0.12298043]
Abstract state at timestep 562 is 4
State prediction error at timestep 562 is 0.012
Human Feedback received at timestpe 562 of 10
Current timestep = 563. State = [[-0.07923403  0.4780339   0.35756475 -1.1317875  -0.59542334 -0.28887472
   0.          0.        ]]. Action = [[0.01637113 0.49590337]]. Reward = [-0.16191052]
Abstract state at timestep 563 is 4
State prediction error at timestep 563 is 0.012
Human Feedback received at timestpe 563 of 10
Current timestep = 564. State = [[-0.07566929  0.45295924  0.3671569  -1.1193149  -0.60820985 -0.2557299
   0.          0.        ]]. Action = [[ 0.7080227  -0.87988454]]. Reward = [1.8639958]
Abstract state at timestep 564 is 5
State prediction error at timestep 564 is 0.012
Human Feedback received at timestpe 564 of 10
Current timestep = 565. State = [[-0.0721036   0.42728636  0.36714527 -1.1459929  -0.6209962  -0.25572708
   0.          0.        ]]. Action = [[-0.46260703  0.41281605]]. Reward = [-1.2251645]
Abstract state at timestep 565 is 5
State prediction error at timestep 565 is 0.012
Human Feedback received at timestpe 565 of 10
Current timestep = 566. State = [[-0.06853714  0.40101528  0.36713344 -1.1726706  -0.6337824  -0.25572425
   0.          0.        ]]. Action = [[-0.28187126  0.00646961]]. Reward = [-1.171801]
Abstract state at timestep 566 is 5
State prediction error at timestep 566 is 0.012
Human Feedback received at timestpe 566 of 10
Current timestep = 567. State = [[-0.06491546  0.37409657  0.37397406 -1.2022514  -0.6483233  -0.29081827
   0.          0.        ]]. Action = [[-0.6342962  0.8113942]]. Reward = [-1.7917036]
Abstract state at timestep 567 is 5
State prediction error at timestep 567 is 0.012
Human Feedback received at timestpe 567 of 10
Current timestep = 568. State = [[-0.06129265  0.34658018  0.3739582  -1.2289321  -0.66286397 -0.29081398
   0.          0.        ]]. Action = [[-0.98909587 -0.01176226]]. Reward = [-1.2308356]
Abstract state at timestep 568 is 5
State prediction error at timestep 568 is 0.012
Human Feedback received at timestpe 568 of 10
Current timestep = 569. State = [[-0.05766869  0.31846592  0.37394202 -1.2556129  -0.67740446 -0.29080972
   0.          0.        ]]. Action = [[-0.08018714 -0.0380137 ]]. Reward = [-1.1770877]
Abstract state at timestep 569 is 5
State prediction error at timestep 569 is 0.012
Human Feedback received at timestpe 569 of 10
Current timestep = 570. State = [[-0.05370855  0.29041323  0.40747547 -1.2530208  -0.69201183 -0.2921473
   0.          0.        ]]. Action = [[0.48693657 0.00477016]]. Reward = [0.39721906]
Abstract state at timestep 570 is 5
State prediction error at timestep 570 is 0.012
Human Feedback received at timestpe 570 of 10
Current timestep = 571. State = [[-0.04974718  0.26176274  0.40745854 -1.2797014  -0.70661896 -0.29214305
   0.          0.        ]]. Action = [[-0.13366961 -0.27904463]]. Reward = [-1.1110165]
Abstract state at timestep 571 is 5
State prediction error at timestep 571 is 0.012
Human Feedback received at timestpe 571 of 10
Current timestep = 572. State = [[-0.04583225  0.23257664  0.40130243 -1.3028096  -0.71941495 -0.2559197
   0.          0.        ]]. Action = [[-0.73560256 -0.7800369 ]]. Reward = [-0.38437897]
Abstract state at timestep 572 is 5
State prediction error at timestep 572 is 0.012
Human Feedback received at timestpe 572 of 10
Current timestep = 573. State = [[-0.04156046  0.20329443  0.43671903 -1.3070636  -0.7319932  -0.2515648
   0.          0.        ]]. Action = [[ 0.2168324  -0.07798249]]. Reward = [0.02700632]
Abstract state at timestep 573 is 5
State prediction error at timestep 573 is 0.012
Human Feedback received at timestpe 573 of 10
Current timestep = 574. State = [[-0.03722248  0.17332293  0.44514504 -1.338959   -0.74714583 -0.3030532
   0.          0.        ]]. Action = [[-0.31271613  0.99898577]]. Reward = [-1.815127]
Abstract state at timestep 574 is 5
State prediction error at timestep 574 is 0.012
Human Feedback received at timestpe 574 of 10
Current timestep = 575. State = [[-0.03292026  0.14281084  0.44027266 -1.3623794  -0.7607483  -0.27204967
   0.          0.        ]]. Action = [[-0.21546072 -0.5866436 ]]. Reward = [-0.37974638]
Abstract state at timestep 575 is 5
State prediction error at timestep 575 is 0.012
Human Feedback received at timestpe 575 of 10
Current timestep = 576. State = [[-0.02842598  0.11188152  0.46080542 -1.3819574  -0.7763568  -0.31216922
   0.          0.        ]]. Action = [[0.04112291 0.89267325]]. Reward = [-1.1324056]
Abstract state at timestep 576 is 5
State prediction error at timestep 576 is 0.012
Human Feedback received at timestpe 576 of 10
Current timestep = 577. State = [[-0.02370033  0.08086547  0.48400742 -1.3860983  -0.7923108  -0.31907943
   0.          0.        ]]. Action = [[ 0.41492712 -0.09009129]]. Reward = [0.1679346]
Abstract state at timestep 577 is 5
State prediction error at timestep 577 is 0.012
Human Feedback received at timestpe 577 of 10
Current timestep = 578. State = [[-0.01897326  0.04925173  0.48398486 -1.4127799  -0.80826443 -0.31907374
   1.          0.        ]]. Action = [[-0.4035716  -0.35423017]]. Reward = [9.032478]
Abstract state at timestep 578 is 5
State prediction error at timestep 578 is 0.012
Human Feedback received at timestpe 578 of 10
Current timestep = 579. State = [[-0.01705275  0.04539328  0.30339822 -0.287001   -0.91741914 -2.0587542
   1.          0.        ]]. Action = [[-0.828861  -0.2635529]]. Reward = [97.087975]
Abstract state at timestep 579 is 5
State prediction error at timestep 579 is 0.012
Human Feedback received at timestpe 579 of 10
Current timestep = 580. State = [[-0.01415205  0.04145309  0.34038538 -0.22290015 -1.0035557  -1.7223282
   1.          0.        ]]. Action = [[ 0.97341466 -0.7145954 ]]. Reward = [-7.3860598]
Abstract state at timestep 580 is 5
State prediction error at timestep 580 is 0.012
Human Feedback received at timestpe 580 of 10
Current timestep = 581. State = [[-0.01094322  0.03707801  0.35214087 -0.24035999 -1.0760418  -1.5401884
   1.          0.        ]]. Action = [[-0.6648915  -0.02795124]]. Reward = [-8.682092]
Abstract state at timestep 581 is 5
State prediction error at timestep 581 is 0.012
Human Feedback received at timestpe 581 of 10
Current timestep = 582. State = [[-0.00786295  0.03684984  0.3045735  -0.04008457 -1.0509716   0.19982134
   1.          0.        ]]. Action = [[-0.57139313  0.10665047]]. Reward = [14.520217]
Abstract state at timestep 582 is 5
State prediction error at timestep 582 is 0.012
Human Feedback received at timestpe 582 of 10
Current timestep = 583. State = [[-0.00410643  0.03699533  0.3618631  -0.00916204 -1.0172158   0.3942291
   1.          0.        ]]. Action = [[ 0.57230544 -0.7663967 ]]. Reward = [-2.3154886]
Abstract state at timestep 583 is 5
State prediction error at timestep 583 is 0.012
Human Feedback received at timestpe 583 of 10
Current timestep = 584. State = [[-3.5848617e-04  3.6691271e-02  3.5631543e-01 -1.7165158e-02
  -9.8097563e-01  5.0579315e-01  1.0000000e+00  0.0000000e+00]]. Action = [[-0.625463  -0.7223548]]. Reward = [4.180344]
Abstract state at timestep 584 is 5
State prediction error at timestep 584 is 0.012
Human Feedback received at timestpe 584 of 10
Current timestep = 585. State = [[ 0.00338974  0.03580185  0.3542686  -0.03627634 -0.94531196  0.54954153
   1.          0.        ]]. Action = [[-0.84151584  0.49005258]]. Reward = [3.7002323]
Abstract state at timestep 585 is 5
State prediction error at timestep 585 is 0.012
Human Feedback received at timestpe 585 of 10
Current timestep = 586. State = [[ 0.00746899  0.03459965  0.38657928 -0.04520818 -0.91020834  0.5918527
   1.          0.        ]]. Action = [[ 0.47319067 -0.75868875]]. Reward = [0.01389097]
Abstract state at timestep 586 is 5
State prediction error at timestep 586 is 0.012
Human Feedback received at timestpe 586 of 10
Current timestep = 587. State = [[ 0.01190109  0.03320762  0.4221549  -0.05119287 -0.87782896  0.5787939
   1.          0.        ]]. Action = [[0.01329482 0.20205629]]. Reward = [-0.5053548]
Abstract state at timestep 587 is 5
State prediction error at timestep 587 is 0.012
Human Feedback received at timestpe 587 of 10
Current timestep = 588. State = [[ 0.01692076  0.03168026  0.4809518  -0.05528349 -0.8463332   0.59031
   1.          0.        ]]. Action = [[0.4698782 0.4513011]]. Reward = [-3.0220282]
Abstract state at timestep 588 is 5
State prediction error at timestep 588 is 0.012
Human Feedback received at timestpe 588 of 10
Current timestep = 589. State = [[ 0.02247677  0.03020998  0.53436667 -0.05097533 -0.81576544  0.59816635
   1.          0.        ]]. Action = [[0.518111   0.29335082]]. Reward = [-2.6121688]
Abstract state at timestep 589 is 5
State prediction error at timestep 589 is 0.012
Human Feedback received at timestpe 589 of 10
Current timestep = 590. State = [[ 0.02803021  0.02813681  0.5342857  -0.0776461  -0.7858641   0.59804976
   1.          0.        ]]. Action = [[-0.79163     0.01623476]]. Reward = [2.4733727]
Abstract state at timestep 590 is 5
State prediction error at timestep 590 is 0.012
Human Feedback received at timestpe 590 of 10
Current timestep = 591. State = [[ 0.03382139  0.02584742  0.5585648  -0.08840536 -0.75753224  0.56666136
   1.          0.        ]]. Action = [[0.17561269 0.7200632 ]]. Reward = [-0.21180257]
Abstract state at timestep 591 is 5
State prediction error at timestep 591 is 0.012
Human Feedback received at timestpe 591 of 10
Current timestep = 592. State = [[ 0.03961639  0.02302359  0.5575274  -0.11203293 -0.72804636  0.5897453
   1.          0.        ]]. Action = [[-0.9001391   0.09162426]]. Reward = [2.3077705]
Abstract state at timestep 592 is 5
State prediction error at timestep 592 is 0.012
Human Feedback received at timestpe 592 of 10
Current timestep = 593. State = [[ 0.04586582  0.02003876  0.6018288  -0.11931697 -0.6978431   0.60409224
   1.          0.        ]]. Action = [[0.1656779 0.8843081]]. Reward = [-2.0912223]
Abstract state at timestep 593 is 5
State prediction error at timestep 593 is 0.012
Human Feedback received at timestpe 593 of 10
Current timestep = 594. State = [[ 0.0526391   0.01704405  0.6523214  -0.11954718 -0.6660138   0.63661206
   1.          0.        ]]. Action = [[0.9163158  0.87280846]]. Reward = [-2.6227217]
Abstract state at timestep 594 is 5
State prediction error at timestep 594 is 0.012
Human Feedback received at timestpe 594 of 10
Current timestep = 595. State = [[ 0.05957928  0.01415235  0.665056   -0.11387677 -0.6301116   0.7180778
   1.          0.        ]]. Action = [[ 0.3535148  -0.98925376]]. Reward = [1.6118007]
Abstract state at timestep 595 is 5
State prediction error at timestep 595 is 0.012
Human Feedback received at timestpe 595 of 10
Current timestep = 596. State = [[ 0.06656647  0.01068851  0.6689851  -0.14000712 -0.5941994   0.7182745
   1.          0.        ]]. Action = [[-0.67390823  0.8127836 ]]. Reward = [2.0742643]
Abstract state at timestep 596 is 5
State prediction error at timestep 596 is 0.012
Human Feedback received at timestpe 596 of 10
Current timestep = 597. State = [[ 0.07422743  0.00768722  0.73652804 -0.12054355 -0.55933595  0.69730175
   1.          0.        ]]. Action = [[0.8096527  0.87305737]]. Reward = [-3.8166728]
Abstract state at timestep 597 is 5
State prediction error at timestep 597 is 0.012
Human Feedback received at timestpe 597 of 10
Current timestep = 598. State = [[ 0.08234368  0.00505279  0.7814456  -0.10494838 -0.52452046  0.6963395
   1.          0.        ]]. Action = [[ 0.5995822  -0.21077585]]. Reward = [-1.7592282]
Abstract state at timestep 598 is 5
State prediction error at timestep 598 is 0.012
Human Feedback received at timestpe 598 of 10
Current timestep = 599. State = [[ 0.09066906  0.00252315  0.8020073  -0.1010977  -0.49000305  0.69037616
   0.          0.        ]]. Action = [[ 0.19419134 -0.16872978]]. Reward = [-9.537219]
Abstract state at timestep 599 is 5
State prediction error at timestep 599 is 0.012
Human Feedback received at timestpe 599 of 10
Current timestep = 600. State = [[ 9.9149987e-02 -1.6655922e-05  8.1722385e-01 -1.0233192e-01
  -4.5574251e-01  6.8523872e-01  0.0000000e+00  0.0000000e+00]]. Action = [[ 0.24067259 -0.2474345 ]]. Reward = [0.8701994]
Abstract state at timestep 600 is 5
State prediction error at timestep 600 is 0.012
Human Feedback received at timestpe 600 of 10
Current timestep = 601. State = [[ 0.10768995 -0.00318688  0.8241633  -0.13153261 -0.4231694   0.6514883
   0.          0.        ]]. Action = [[-0.94438577  0.8243147 ]]. Reward = [1.2751229]
Abstract state at timestep 601 is 5
State prediction error at timestep 601 is 0.012
Human Feedback received at timestpe 601 of 10
Current timestep = 602. State = [[ 0.11623363 -0.00694319  0.82409966 -0.15823199 -0.39059916  0.65143156
   0.          0.        ]]. Action = [[-0.49337268 -0.3398766 ]]. Reward = [1.9306965]
Abstract state at timestep 602 is 5
State prediction error at timestep 602 is 0.012
Human Feedback received at timestpe 602 of 10
Current timestep = 603. State = [[ 0.12478085 -0.0112854   0.8240369  -0.1849351  -0.3580334   0.6513425
   0.          0.        ]]. Action = [[-0.16303945 -0.41738147]]. Reward = [1.8335288]
Abstract state at timestep 603 is 5
State prediction error at timestep 603 is 0.012
Human Feedback received at timestpe 603 of 10
Current timestep = 604. State = [[ 0.13326903 -0.01616613  0.8160144  -0.20914339 -0.32364184  0.6878589
   0.          0.        ]]. Action = [[-0.18620634 -0.95345557]]. Reward = [2.7294047]
Abstract state at timestep 604 is 5
State prediction error at timestep 604 is 0.012
Human Feedback received at timestpe 604 of 10
Current timestep = 605. State = [[ 0.14193687 -0.02076426  0.8322772  -0.19707854 -0.28789577  0.7149506
   0.          0.        ]]. Action = [[ 0.45369148 -0.6467637 ]]. Reward = [1.1266993]
Abstract state at timestep 605 is 5
State prediction error at timestep 605 is 0.012
Human Feedback received at timestpe 605 of 10
Current timestep = 606. State = [[-0.00687199  1.3986168  -0.6960753  -0.5468367   0.00796974  0.15767151
   0.          0.        ]]. Action = [[0.01128411 0.93000317]]. Reward = [-100.]
Abstract state at timestep 606 is 5
State prediction error at timestep 606 is 0.012
Human Feedback received at timestpe 606 of 10
Current timestep = 607. State = [[-0.0136447   1.3871231  -0.6856754  -0.51090455  0.01627563  0.16613494
   0.          0.        ]]. Action = [[0.8388915  0.01337445]]. Reward = [3.0476327]
Abstract state at timestep 607 is 3
State prediction error at timestep 607 is 0.012
Human Feedback received at timestpe 607 of 10
Current timestep = 608. State = [[-0.02052488  1.3755392  -0.6959217  -0.5149434   0.02408839  0.15626958
   0.          0.        ]]. Action = [[0.9127598  0.38587153]]. Reward = [-0.98183435]
Abstract state at timestep 608 is 3
State prediction error at timestep 608 is 0.012
Human Feedback received at timestpe 608 of 10
Current timestep = 609. State = [[-0.02745485  1.3633597  -0.70214653 -0.541481    0.03314276  0.18110445
   0.          0.        ]]. Action = [[-0.12376618 -0.5939901 ]]. Reward = [-1.8140477]
Abstract state at timestep 609 is 3
State prediction error at timestep 609 is 0.012
Human Feedback received at timestpe 609 of 10
Current timestep = 610. State = [[-0.03432331  1.3509383  -0.6963272  -0.55230504  0.04252838  0.1877291
   0.          0.        ]]. Action = [[ 0.12573886 -0.10675621]]. Reward = [-0.08968768]
Abstract state at timestep 610 is 3
State prediction error at timestep 610 is 0.012
Human Feedback received at timestpe 610 of 10
Current timestep = 611. State = [[-0.04119205  1.3379178  -0.6963545  -0.5789823   0.05191245  0.18769881
   0.          0.        ]]. Action = [[-0.58713055 -0.13458979]]. Reward = [-1.3401753]
Abstract state at timestep 611 is 3
State prediction error at timestep 611 is 0.012
Human Feedback received at timestpe 611 of 10
Current timestep = 612. State = [[-0.04815807  1.3251317  -0.7057601  -0.5686042   0.06096965  0.18116093
   0.          0.        ]]. Action = [[ 0.14220703 -0.19584465]]. Reward = [0.10694575]
Abstract state at timestep 612 is 3
State prediction error at timestep 612 is 0.012
Human Feedback received at timestpe 612 of 10
Current timestep = 613. State = [[-0.0551157   1.312532   -0.7050978  -0.56039226  0.07021919  0.1850079
   0.          0.        ]]. Action = [[0.28743887 0.42453074]]. Reward = [0.67851025]
Abstract state at timestep 613 is 3
State prediction error at timestep 613 is 0.012
Human Feedback received at timestpe 613 of 10
Current timestep = 614. State = [[-0.06201553  1.2993321  -0.6978371  -0.5870522   0.07800923  0.15581492
   0.          0.        ]]. Action = [[-0.22694188  0.6272304 ]]. Reward = [-0.6358008]
Abstract state at timestep 614 is 3
State prediction error at timestep 614 is 0.012
Human Feedback received at timestpe 614 of 10
Current timestep = 615. State = [[-0.06900883  1.2862009  -0.7086124  -0.58411175  0.08720686  0.18396951
   0.          0.        ]]. Action = [[ 0.61344814 -0.7118628 ]]. Reward = [-0.54695773]
Abstract state at timestep 615 is 3
State prediction error at timestep 615 is 0.012
Human Feedback received at timestpe 615 of 10
Current timestep = 616. State = [[-0.0760025   1.2724708  -0.7086381  -0.6107927   0.09640212  0.18392214
   0.          0.        ]]. Action = [[-0.7670791  -0.12008917]]. Reward = [-1.3099799]
Abstract state at timestep 616 is 3
State prediction error at timestep 616 is 0.012
Human Feedback received at timestpe 616 of 10
Current timestep = 617. State = [[-0.0830534   1.258139   -0.7157754  -0.6376984   0.10702362  0.2124495
   0.          0.        ]]. Action = [[-0.3664701  -0.57948595]]. Reward = [-2.0035374]
Abstract state at timestep 617 is 3
State prediction error at timestep 617 is 0.012
Human Feedback received at timestpe 617 of 10
Current timestep = 618. State = [[-0.09010477  1.2432084  -0.71580595 -0.66437715  0.11764281  0.21240313
   0.          0.        ]]. Action = [[-0.18995124 -0.21939164]]. Reward = [-1.4183897]
Abstract state at timestep 618 is 3
State prediction error at timestep 618 is 0.012
Human Feedback received at timestpe 618 of 10
Current timestep = 619. State = [[-0.09715652  1.2276793  -0.71583563 -0.69105583  0.12826058  0.21237457
   0.          0.        ]]. Action = [[-0.8300927  -0.24825007]]. Reward = [-1.4028587]
Abstract state at timestep 619 is 3
State prediction error at timestep 619 is 0.012
Human Feedback received at timestpe 619 of 10
Current timestep = 620. State = [[-0.10415163  1.211561   -0.7087005  -0.71717924  0.13742566  0.18331839
   0.          0.        ]]. Action = [[-0.07713079  0.9098393 ]]. Reward = [-0.72400534]
Abstract state at timestep 620 is 3
State prediction error at timestep 620 is 0.012
Human Feedback received at timestpe 620 of 10
Current timestep = 621. State = [[-0.11113663  1.1952025  -0.7058921  -0.72773755  0.14480534  0.14760743
   0.          0.        ]]. Action = [[0.07019186 0.89527404]]. Reward = [0.08375434]
Abstract state at timestep 621 is 3
State prediction error at timestep 621 is 0.012
Human Feedback received at timestpe 621 of 10
Current timestep = 622. State = [[-0.11814175  1.1791819  -0.70602274 -0.712578    0.15031412  0.11018535
   0.          0.        ]]. Action = [[0.9839325 0.9345367]]. Reward = [1.7241971]
Abstract state at timestep 622 is 3
State prediction error at timestep 622 is 0.012
Human Feedback received at timestpe 622 of 10
Current timestep = 623. State = [[-0.1252534   1.1632056  -0.7164786  -0.7105997   0.15563072  0.10634172
   0.          0.        ]]. Action = [[ 0.7996049 -0.2632689]]. Reward = [0.11471818]
Abstract state at timestep 623 is 3
State prediction error at timestep 623 is 0.012
Human Feedback received at timestpe 623 of 10
Current timestep = 624. State = [[-0.13233462  1.1472167  -0.71239644 -0.7110697   0.15990888  0.08557069
   0.          0.        ]]. Action = [[0.3474412  0.56957626]]. Reward = [1.1197923]
Abstract state at timestep 624 is 3
State prediction error at timestep 624 is 0.012
Human Feedback received at timestpe 624 of 10
Current timestep = 625. State = [[-0.13941602  1.1306279  -0.71240765 -0.7377424   0.16418664  0.08556322
   0.          0.        ]]. Action = [[-0.48205912 -0.28462952]]. Reward = [-0.76692253]
Abstract state at timestep 625 is 3
State prediction error at timestep 625 is 0.012
Human Feedback received at timestpe 625 of 10
Current timestep = 626. State = [[-0.14649764  1.1134394  -0.71241957 -0.764413    0.16846363  0.08554704
   0.          0.        ]]. Action = [[-0.3894487   0.41555512]]. Reward = [-0.7479406]
Abstract state at timestep 626 is 3
State prediction error at timestep 626 is 0.012
Human Feedback received at timestpe 626 of 10
Current timestep = 627. State = [[-0.15366478  1.0960981  -0.7208202  -0.77119887  0.17257978  0.08233061
   0.          0.        ]]. Action = [[ 0.72271   -0.3176986]]. Reward = [-0.11743267]
Abstract state at timestep 627 is 3
State prediction error at timestep 627 is 0.012
Human Feedback received at timestpe 627 of 10
Current timestep = 628. State = [[-0.16067362  1.0787629  -0.7033926  -0.7707456   0.17509721  0.05035312
   0.          0.        ]]. Action = [[0.60655594 0.90624833]]. Reward = [2.3112538]
Abstract state at timestep 628 is 3
State prediction error at timestep 628 is 0.012
Human Feedback received at timestpe 628 of 10
Current timestep = 629. State = [[-0.1679202   1.0618681  -0.72665423 -0.7511152   0.17708753  0.03981012
   0.          0.        ]]. Action = [[0.6980232  0.03274632]]. Reward = [0.94387615]
Abstract state at timestep 629 is 3
State prediction error at timestep 629 is 0.012
Human Feedback received at timestpe 629 of 10
Current timestep = 630. State = [[-0.17529783  1.0447518  -0.73935926 -0.76091844  0.17868638  0.03198011
   0.          0.        ]]. Action = [[0.06869078 0.49943697]]. Reward = [-0.33769098]
Abstract state at timestep 630 is 3
State prediction error at timestep 630 is 0.012
Human Feedback received at timestpe 630 of 10
Current timestep = 631. State = [[-0.18271875  1.0270047  -0.7448441  -0.789097    0.18145451  0.05536237
   0.          0.        ]]. Action = [[-0.34591043 -0.52691865]]. Reward = [-1.0847571]
Abstract state at timestep 631 is 3
State prediction error at timestep 631 is 0.012
Human Feedback received at timestpe 631 of 10
Current timestep = 632. State = [[-0.1902956   1.0099539  -0.76210964 -0.7583612   0.18589701  0.08884991
   0.          0.        ]]. Action = [[ 0.9516902 -0.7655267]]. Reward = [1.7780141]
Abstract state at timestep 632 is 3
State prediction error at timestep 632 is 0.012
Human Feedback received at timestpe 632 of 10
Current timestep = 633. State = [[-0.19798413  0.9930718  -0.7712854  -0.75061804  0.18834335  0.04892682
   0.          0.        ]]. Action = [[0.21945083 0.9859054 ]]. Reward = [0.94299597]
Abstract state at timestep 633 is 3
State prediction error at timestep 633 is 0.012
Human Feedback received at timestpe 633 of 10
Current timestep = 634. State = [[-0.20561895  0.97561127 -0.76451886 -0.7761603   0.1893789   0.0207112
   0.          0.        ]]. Action = [[-0.33081526  0.6699195 ]]. Reward = [0.11263436]
Abstract state at timestep 634 is 4
State prediction error at timestep 634 is 0.012
Human Feedback received at timestpe 634 of 10
Current timestep = 635. State = [[-0.21325383  0.95755064 -0.76451886 -0.802827    0.19041444  0.02071111
   0.          0.        ]]. Action = [[-0.22398686 -0.44100857]]. Reward = [-0.41576126]
Abstract state at timestep 635 is 4
State prediction error at timestep 635 is 0.012
Human Feedback received at timestpe 635 of 10
Current timestep = 636. State = [[-0.22095355  0.93887144 -0.7726656  -0.8305353   0.19312651  0.05424145
   0.          0.        ]]. Action = [[-0.03849185 -0.84614664]]. Reward = [-1.2237331]
Abstract state at timestep 636 is 4
State prediction error at timestep 636 is 0.012
Human Feedback received at timestpe 636 of 10
Current timestep = 637. State = [[-0.22867604  0.9211088  -0.7742381  -0.789712    0.19513018  0.04007326
   0.          0.        ]]. Action = [[0.9463494 0.538484 ]]. Reward = [3.8804429]
Abstract state at timestep 637 is 4
State prediction error at timestep 637 is 0.012
Human Feedback received at timestpe 637 of 10
Current timestep = 638. State = [[-0.23660287  0.903881   -0.7944311  -0.76590794  0.19688393  0.03507496
   0.          0.        ]]. Action = [[0.794466   0.31745338]]. Reward = [1.2713012]
Abstract state at timestep 638 is 4
State prediction error at timestep 638 is 0.012
Human Feedback received at timestpe 638 of -10
Current timestep = 639. State = [[-0.24467607  0.8865519  -0.8086985  -0.7703655   0.19827448  0.027811
   0.          0.        ]]. Action = [[ 0.39603782 -0.489398  ]]. Reward = [-0.22307955]
Abstract state at timestep 639 is 4
State prediction error at timestep 639 is 0.012
Human Feedback received at timestpe 639 of -10
Current timestep = 640. State = [[-0.2527492   0.8686229  -0.8086985  -0.7970323   0.19966504  0.02781097
   0.          0.        ]]. Action = [[-0.11383194 -0.41547537]]. Reward = [-0.48998317]
Abstract state at timestep 640 is 4
State prediction error at timestep 640 is 0.012
Human Feedback received at timestpe 640 of -10
Current timestep = 641. State = [[-0.2608224   0.8500939  -0.80869853 -0.8236991   0.20105557  0.027811
   0.          0.        ]]. Action = [[-0.4387505  -0.07388496]]. Reward = [-0.48240986]
Abstract state at timestep 641 is 4
State prediction error at timestep 641 is 0.012
Human Feedback received at timestpe 641 of -10
Current timestep = 642. State = [[-0.26889554  0.8309648  -0.80869853 -0.85036594  0.20244612  0.02781101
   0.          0.        ]]. Action = [[-0.39604962 -0.25876087]]. Reward = [-0.47500908]
Abstract state at timestep 642 is 4
State prediction error at timestep 642 is 0.012
Human Feedback received at timestpe 642 of -10
Current timestep = 643. State = [[-0.27703714  0.8120154  -0.81395656 -0.8421679   0.20224017 -0.00411873
   0.          0.        ]]. Action = [[0.4632269 0.7758266]]. Reward = [1.5472205]
Abstract state at timestep 643 is 4
State prediction error at timestep 643 is 0.012
Human Feedback received at timestpe 643 of -10
Current timestep = 644. State = [[-0.28514963  0.79337513 -0.81173563 -0.8285213   0.20272861  0.00976878
   0.          0.        ]]. Action = [[0.9529164 0.2536049]]. Reward = [2.2822428]
Abstract state at timestep 644 is 4
State prediction error at timestep 644 is 0.012
Human Feedback received at timestpe 644 of -10
Current timestep = 645. State = [[-0.29337153  0.7746009  -0.822468   -0.83444756  0.20301048  0.00563751
   0.          0.        ]]. Action = [[0.36776018 0.23380637]]. Reward = [0.06841506]
Abstract state at timestep 645 is 4
State prediction error at timestep 645 is 0.012
Human Feedback received at timestpe 645 of -10
Current timestep = 646. State = [[-0.3015934   0.7552267  -0.822468   -0.8611142   0.20329237  0.00563779
   0.          0.        ]]. Action = [[-0.38028896 -0.3560158 ]]. Reward = [-0.4344966]
Abstract state at timestep 646 is 4
State prediction error at timestep 646 is 0.012
Human Feedback received at timestpe 646 of -10
Current timestep = 647. State = [[-0.3098486   0.736437   -0.82448596 -0.8349567   0.20224988 -0.02084977
   0.          0.        ]]. Action = [[0.79866266 0.73209715]]. Reward = [2.9738421]
Abstract state at timestep 647 is 1
State prediction error at timestep 647 is 0.012
Human Feedback received at timestpe 647 of -10
Current timestep = 648. State = [[-0.3181038   0.71704733 -0.8244859  -0.86162347  0.20120741 -0.02084937
   0.          0.        ]]. Action = [[-0.8567055  0.4136629]]. Reward = [-0.3554633]
Abstract state at timestep 648 is 1
State prediction error at timestep 648 is 0.012
Human Feedback received at timestpe 648 of -10
Current timestep = 649. State = [[-0.32641602  0.69704634 -0.8316264  -0.8889803   0.20161812  0.00821426
   0.          0.        ]]. Action = [[-0.8813748  -0.65301824]]. Reward = [-1.0634986]
Abstract state at timestep 649 is 1
State prediction error at timestep 649 is 0.012
Human Feedback received at timestpe 649 of -10
Current timestep = 650. State = [[-0.33492804  0.676987   -0.85289365 -0.8917595   0.20332281  0.03409382
   0.          0.        ]]. Action = [[ 0.07489419 -0.6792902 ]]. Reward = [-0.57722694]
Abstract state at timestep 650 is 1
State prediction error at timestep 650 is 0.012
Human Feedback received at timestpe 650 of -10
Current timestep = 651. State = [[-0.34350777  0.65631425 -0.8613847  -0.9192626   0.20675662  0.06867609
   0.          0.        ]]. Action = [[-0.61118925 -0.74373543]]. Reward = [-1.4934708]
Abstract state at timestep 651 is 1
State prediction error at timestep 651 is 0.012
Human Feedback received at timestpe 651 of -10
Current timestep = 652. State = [[-0.35215512  0.63550085 -0.8681201  -0.92551464  0.21017523  0.06837216
   0.          0.        ]]. Action = [[0.09275436 0.42230225]]. Reward = [-0.0001395]
Abstract state at timestep 652 is 1
State prediction error at timestep 652 is 0.012
Human Feedback received at timestpe 652 of -10
Current timestep = 653. State = [[-0.36088222  0.6140558  -0.8781807  -0.95390326  0.21570015  0.11049849
   0.          0.        ]]. Action = [[-0.86088246 -0.96729946]]. Reward = [-1.916021]
Abstract state at timestep 653 is 1
State prediction error at timestep 653 is 0.012
Human Feedback received at timestpe 653 of -10
Current timestep = 654. State = [[-0.3696794   0.5919867  -0.8869912  -0.98193187  0.22305876  0.14717202
   0.          0.        ]]. Action = [[-0.27773    -0.91018414]]. Reward = [-1.9962058]
Abstract state at timestep 654 is 1
State prediction error at timestep 654 is 0.012
Human Feedback received at timestpe 654 of -10
Current timestep = 655. State = [[-0.37850636  0.5705232  -0.8889454  -0.9548931   0.22938143  0.12645349
   0.          0.        ]]. Action = [[0.87045527 0.63733697]]. Reward = [2.2558556]
Abstract state at timestep 655 is 1
State prediction error at timestep 655 is 0.012
Human Feedback received at timestpe 655 of -10
Current timestep = 656. State = [[-0.38737434  0.54844385 -0.894097   -0.9824585   0.23678595  0.1480905
   0.          0.        ]]. Action = [[-0.977295  -0.5809112]]. Reward = [-1.8139787]
Abstract state at timestep 656 is 1
State prediction error at timestep 656 is 0.012
Human Feedback received at timestpe 656 of -10
Current timestep = 657. State = [[-0.3965393   0.52668715 -0.92312145 -0.96804744  0.24352185  0.1347181
   0.          0.        ]]. Action = [[ 0.7407911  -0.22927636]]. Reward = [-0.6408546]
Abstract state at timestep 657 is 1
State prediction error at timestep 657 is 0.012
Human Feedback received at timestpe 657 of -10
Current timestep = 658. State = [[-0.40566474  0.5043425  -0.9181485  -0.9940364   0.24922946  0.11415218
   0.          0.        ]]. Action = [[-0.802382    0.67722225]]. Reward = [-0.94283074]
Abstract state at timestep 658 is 1
State prediction error at timestep 658 is 0.012
Human Feedback received at timestpe 658 of -10
Current timestep = 659. State = [[-0.4150164   0.4822597  -0.9404119  -0.98235637  0.25457782  0.10696687
   0.          0.        ]]. Action = [[0.75458455 0.21889639]]. Reward = [-0.37278068]
Abstract state at timestep 659 is 1
State prediction error at timestep 659 is 0.012
Human Feedback received at timestpe 659 of -10
Current timestep = 660. State = [[-0.42451042  0.46005687 -0.95592535 -0.9879394   0.26123735  0.13319048
   0.          0.        ]]. Action = [[ 0.8044739 -0.6525839]]. Reward = [-1.4081548]
Abstract state at timestep 660 is 2
State prediction error at timestep 660 is 0.012
Human Feedback received at timestpe 660 of -10
Current timestep = 661. State = [[-0.43398333  0.4376497  -0.9542025  -0.9971224   0.26830605  0.1413739
   0.          0.        ]]. Action = [[0.31978178 0.34611845]]. Reward = [-0.48254833]
Abstract state at timestep 661 is 2
State prediction error at timestep 661 is 0.012
Human Feedback received at timestpe 661 of -10
Current timestep = 662. State = [[-0.4434012   0.41466296 -0.9472674  -1.0226474   0.27392116  0.1123023
   0.          0.        ]]. Action = [[-0.95735884  0.69369316]]. Reward = [-1.0394108]
Abstract state at timestep 662 is 2
State prediction error at timestep 662 is 0.012
Human Feedback received at timestpe 662 of -10
Current timestep = 663. State = [[-0.4528191   0.39107668 -0.94726646 -1.0493165   0.27953625  0.11230186
   0.          0.        ]]. Action = [[-0.3920715  -0.01418412]]. Reward = [-1.653206]
Abstract state at timestep 663 is 2
State prediction error at timestep 663 is 0.012
Human Feedback received at timestpe 663 of -10
Current timestep = 664. State = [[-0.46223712  0.3668908  -0.9472653  -1.0759857   0.28515136  0.11230211
   0.          0.        ]]. Action = [[-0.03240645  0.14685893]]. Reward = [-1.7348148]
Abstract state at timestep 664 is 2
State prediction error at timestep 664 is 0.012
Human Feedback received at timestpe 664 of -10
Current timestep = 665. State = [[-0.471922    0.3431453  -0.97585505 -1.0568113   0.29274008  0.1517743
   0.          0.        ]]. Action = [[ 0.723727  -0.9650372]]. Reward = [-0.87115276]
Abstract state at timestep 665 is 2
State prediction error at timestep 665 is 0.012
Human Feedback received at timestpe 665 of -10
Current timestep = 666. State = [[-0.48186392  0.31976002 -0.9995944  -1.0404421   0.2983158   0.11151419
   0.          0.        ]]. Action = [[0.5169833 0.9133272]]. Reward = [-0.73048687]
Abstract state at timestep 666 is 2
State prediction error at timestep 666 is 0.012
Human Feedback received at timestpe 666 of -10
Current timestep = 667. State = [[-0.4919291   0.29675347 -1.0139408  -1.0240523   0.30598888  0.1534617
   0.          0.        ]]. Action = [[ 0.5068345 -0.9666131]]. Reward = [-0.4705454]
Abstract state at timestep 667 is 2
State prediction error at timestep 667 is 0.012
Human Feedback received at timestpe 667 of -10
Current timestep = 668. State = [[-0.5020644   0.27312055 -1.0227255  -1.0523169   0.3155211   0.19064419
   0.          0.        ]]. Action = [[-0.12247831 -0.79637474]]. Reward = [-3.3139484]
Abstract state at timestep 668 is 2
State prediction error at timestep 668 is 0.012
Human Feedback received at timestpe 668 of -10
Current timestep = 669. State = [[-0.5122      0.24888884 -1.022722   -1.0789909   0.32505324  0.19064303
   0.          0.        ]]. Action = [[-0.712843   -0.23841894]]. Reward = [-2.669817]
Abstract state at timestep 669 is 2
State prediction error at timestep 669 is 0.012
Human Feedback received at timestpe 669 of -10
Current timestep = 670. State = [[-0.5223358   0.22405823 -1.0227184  -1.1056648   0.33458534  0.19064184
   0.          0.        ]]. Action = [[-0.20426834 -0.01589221]]. Reward = [-2.7895417]
Abstract state at timestep 670 is 2
State prediction error at timestep 670 is 0.012
Human Feedback received at timestpe 670 of -10
Current timestep = 671. State = [[-0.5324719   0.19862874 -1.0227147  -1.1323386   0.34411737  0.19064054
   0.          0.        ]]. Action = [[-0.5990985  -0.24857134]]. Reward = [-2.9168198]
Abstract state at timestep 671 is 2
State prediction error at timestep 671 is 0.012
Human Feedback received at timestpe 671 of -10
Current timestep = 672. State = [[-0.54260826  0.17260037 -1.0227109  -1.1590124   0.35364932  0.19063917
   0.          0.        ]]. Action = [[-0.37088054  0.34261596]]. Reward = [-3.0513396]
Abstract state at timestep 672 is 2
State prediction error at timestep 672 is 0.012
Human Feedback received at timestpe 672 of -10
Current timestep = 673. State = [[-0.55297196  0.14668852 -1.0441438  -1.153574    0.36184692  0.16395243
   0.          0.        ]]. Action = [[0.48923492 0.544919  ]]. Reward = [-2.352121]
Abstract state at timestep 673 is 2
State prediction error at timestep 673 is 0.012
Human Feedback received at timestpe 673 of -10
Current timestep = 674. State = [[-0.56338644  0.12013987 -1.0506073  -1.1822817   0.3715282   0.19362582
   0.          0.        ]]. Action = [[-0.1980055 -0.8641309]]. Reward = [-3.9584308]
Abstract state at timestep 674 is 2
State prediction error at timestep 674 is 0.012
Human Feedback received at timestpe 674 of -10
Current timestep = 675. State = [[-0.5738012   0.09299234 -1.050603   -1.2089559   0.38120943  0.19362459
   0.          0.        ]]. Action = [[-0.9766602  -0.21847332]]. Reward = [-3.4949543]
Abstract state at timestep 675 is 2
State prediction error at timestep 675 is 0.012
Human Feedback received at timestpe 675 of -10
Current timestep = 676. State = [[-0.58414525  0.06528655 -1.0416206  -1.233315    0.3888964   0.15373942
   0.          0.        ]]. Action = [[-0.6618639   0.93640876]]. Reward = [-2.711748]
Abstract state at timestep 676 is 2
State prediction error at timestep 676 is 0.012
Human Feedback received at timestpe 676 of -10
Current timestep = 677. State = [[-0.5947264   0.03741947 -1.0666474  -1.2408942   0.3980204   0.18247989
   0.          1.        ]]. Action = [[ 0.44092607 -0.73228985]]. Reward = [5.837439]
Abstract state at timestep 677 is 2
State prediction error at timestep 677 is 0.012
Human Feedback received at timestpe 677 of -10
Current timestep = 678. State = [[-0.5954766   0.03321556 -0.23844555 -0.25805637  0.50128055  1.9466416
   0.          1.        ]]. Action = [[-0.54645604 -0.86661536]]. Reward = [118.095]
Abstract state at timestep 678 is 2
State prediction error at timestep 678 is 0.012
Human Feedback received at timestpe 678 of -10
Current timestep = 679. State = [[-0.59675944  0.02927178 -0.20031902 -0.2041394   0.584009    1.654248
   0.          1.        ]]. Action = [[ 0.40843987 -0.43282878]]. Reward = [-2.0570138]
Abstract state at timestep 679 is 2
State prediction error at timestep 679 is 0.012
Human Feedback received at timestpe 679 of -10
Current timestep = 680. State = [[-0.5975175   0.02949387 -0.07363756 -0.00126503  0.5705296  -0.08927531
   0.          1.        ]]. Action = [[0.56404006 0.32667828]]. Reward = [22.27249]
Abstract state at timestep 680 is 2
State prediction error at timestep 680 is 0.012
Human Feedback received at timestpe 680 of -10
Current timestep = 681. State = [[-0.59855247  0.03040839 -0.09086166  0.03813879  0.54761666 -0.3375106
   0.          1.        ]]. Action = [[ 0.44322538 -0.7109239 ]]. Reward = [-0.5437607]
Abstract state at timestep 681 is 2
State prediction error at timestep 681 is 0.012
Human Feedback received at timestpe 681 of -10
Current timestep = 682. State = [[-0.59983397  0.0316053  -0.10652371  0.058575    0.51935446 -0.51165044
   0.          1.        ]]. Action = [[0.722471   0.18550348]]. Reward = [0.13120925]
Abstract state at timestep 682 is 2
State prediction error at timestep 682 is 0.012
Human Feedback received at timestpe 682 of -10
Current timestep = 683. State = [[-0.6013441   0.0326691  -0.12799671  0.05582277  0.49333847 -0.52033323
   0.          1.        ]]. Action = [[ 0.88531816 -0.53498703]]. Reward = [0.33887982]
Abstract state at timestep 683 is 2
State prediction error at timestep 683 is 0.012
Human Feedback received at timestpe 683 of -10
Current timestep = 684. State = [[-0.60299176  0.0337201  -0.14239386  0.05449834  0.46840897 -0.49860883
   0.          1.        ]]. Action = [[0.0119704  0.05167878]]. Reward = [0.8881934]
Abstract state at timestep 684 is 2
State prediction error at timestep 684 is 0.012
Human Feedback received at timestpe 684 of -10
Current timestep = 685. State = [[-0.60465056  0.0349135  -0.14238773  0.06072833  0.44256675 -0.5168659
   0.          0.        ]]. Action = [[0.9179064  0.68729067]]. Reward = [-8.129526]
Abstract state at timestep 685 is 2
State prediction error at timestep 685 is 0.012
Human Feedback received at timestpe 685 of -10
Current timestep = 686. State = [[-0.6065989   0.03604747 -0.17057958  0.05781633  0.41620696 -0.5272174
   0.          0.        ]]. Action = [[ 0.49299634 -0.3291995 ]]. Reward = [-0.32051796]
Abstract state at timestep 686 is 2
State prediction error at timestep 686 is 0.012
Human Feedback received at timestpe 686 of -10
Current timestep = 687. State = [[-0.6085847   0.03656174 -0.1750372   0.02956756  0.39091834 -0.5057925
   0.          0.        ]]. Action = [[-0.5465809 -0.6164951]]. Reward = [2.5685217]
Abstract state at timestep 687 is 2
State prediction error at timestep 687 is 0.012
Human Feedback received at timestpe 687 of -10
Current timestep = 688. State = [[-0.6107565   0.03758913 -0.19394398  0.0518309   0.36621106 -0.4941663
   0.          0.        ]]. Action = [[ 0.4546113 -0.2658944]]. Reward = [-0.29382136]
Abstract state at timestep 688 is 2
State prediction error at timestep 688 is 0.012
Human Feedback received at timestpe 688 of -10
Current timestep = 689. State = [[-0.6130507   0.03840209 -0.2046802   0.04222104  0.3401614  -0.52101344
   0.          0.        ]]. Action = [[0.19671631 0.604738  ]]. Reward = [1.3493876]
Abstract state at timestep 689 is 2
State prediction error at timestep 689 is 0.012
Human Feedback received at timestpe 689 of -10
Current timestep = 690. State = [[-0.6156648   0.03927184 -0.2380842   0.04395691  0.31581825 -0.48688293
   0.          0.        ]]. Action = [[ 0.2121743 -0.8684697]]. Reward = [-1.3517965]
Abstract state at timestep 690 is 2
State prediction error at timestep 690 is 0.012
Human Feedback received at timestpe 690 of -10
Current timestep = 691. State = [[-0.61835754  0.03991736 -0.24578866  0.03360631  0.29150313 -0.4863212
   0.          0.        ]]. Action = [[ 0.04352772 -0.15997213]]. Reward = [1.4053792]
Abstract state at timestep 691 is 2
State prediction error at timestep 691 is 0.012
Human Feedback received at timestpe 691 of -10
Current timestep = 692. State = [[-0.62097985  0.04000906 -0.23664907  0.00895733  0.26521745 -0.52573496
   0.          0.        ]]. Action = [[-0.2774825   0.84433925]]. Reward = [3.4666574]
Abstract state at timestep 692 is 2
State prediction error at timestep 692 is 0.012
Human Feedback received at timestpe 692 of -10
Current timestep = 693. State = [[-0.6236036   0.03951016 -0.23660736 -0.01773552  0.23893474 -0.52567554
   0.          0.        ]]. Action = [[-0.6347967  -0.35764176]]. Reward = [2.3243546]
Abstract state at timestep 693 is 2
State prediction error at timestep 693 is 0.012
Human Feedback received at timestpe 693 of -10
Current timestep = 694. State = [[-0.6262656   0.03871294 -0.24033454 -0.03145731  0.21271299 -0.5244559
   0.          0.        ]]. Action = [[0.05138981 0.07776785]]. Reward = [1.6924249]
Abstract state at timestep 694 is 2
State prediction error at timestep 694 is 0.012
Human Feedback received at timestpe 694 of -10
Current timestep = 695. State = [[-0.6290763   0.03845702 -0.25516477 -0.00786845  0.18660414 -0.5221974
   0.          0.        ]]. Action = [[0.47277558 0.38699365]]. Reward = [0.8208443]
Abstract state at timestep 695 is 2
State prediction error at timestep 695 is 0.012
Human Feedback received at timestpe 695 of -10
Current timestep = 696. State = [[-0.6320505   0.03821104 -0.27099028 -0.00783221  0.16009896 -0.530125
   0.          0.        ]]. Action = [[ 0.53420496 -0.14939743]]. Reward = [0.54327065]
Abstract state at timestep 696 is 2
State prediction error at timestep 696 is 0.012
Human Feedback received at timestpe 696 of -10
Current timestep = 697. State = [[-0.6351431   0.03796464 -0.2824768  -0.00830466  0.13335246 -0.53495145
   0.          0.        ]]. Action = [[ 0.7837937  -0.44285524]]. Reward = [0.9503122]
Abstract state at timestep 697 is 2
State prediction error at timestep 697 is 0.012
Human Feedback received at timestpe 697 of -10
Current timestep = 698. State = [[-0.6383223   0.03776036 -0.2923451  -0.0070012   0.10790341 -0.50900096
   0.          0.        ]]. Action = [[ 0.09271669 -0.6272862 ]]. Reward = [1.063027]
Abstract state at timestep 698 is 2
State prediction error at timestep 698 is 0.012
Human Feedback received at timestpe 698 of -10
Current timestep = 699. State = [[-0.64153653  0.03767274 -0.29726857 -0.00233258  0.08393381 -0.47941056
   0.          0.        ]]. Action = [[ 0.8109813  -0.64070034]]. Reward = [1.3008606]
Abstract state at timestep 699 is 2
State prediction error at timestep 699 is 0.012
Human Feedback received at timestpe 699 of -10
Current timestep = 700. State = [[-0.6447509   0.03699325 -0.2972378  -0.02902674  0.05996724 -0.4793501
   0.          0.        ]]. Action = [[-0.3582796 -0.0322063]]. Reward = [1.9422934]
Abstract state at timestep 700 is 2
State prediction error at timestep 700 is 0.012
Human Feedback received at timestpe 700 of -10
Current timestep = 701. State = [[-0.6479653   0.03572188 -0.29720804 -0.05571983  0.03600234 -0.4793167
   0.          0.        ]]. Action = [[-0.5447743  -0.32054746]]. Reward = [1.7092663]
Abstract state at timestep 701 is 2
State prediction error at timestep 701 is 0.012
Human Feedback received at timestpe 701 of -10
Current timestep = 702. State = [[-0.6511797   0.03385864 -0.29717916 -0.08241422  0.01203975 -0.47927046
   0.          0.        ]]. Action = [[-0.1438883  -0.00132906]]. Reward = [1.484343]
Abstract state at timestep 702 is 2
State prediction error at timestep 702 is 0.012
Human Feedback received at timestpe 702 of -10
Current timestep = 703. State = [[-0.6544206   0.03184677 -0.29860145 -0.08941331 -0.01313756 -0.5035662
   0.          0.        ]]. Action = [[0.41022778 0.5375576 ]]. Reward = [-0.9816067]
Abstract state at timestep 703 is 2
State prediction error at timestep 703 is 0.012
Human Feedback received at timestpe 703 of -10
Current timestep = 704. State = [[-0.6576611   0.02924374 -0.29857403 -0.11611409 -0.03831084 -0.50348514
   0.          0.        ]]. Action = [[-0.290448   0.3100078]]. Reward = [-3.6945639]
Abstract state at timestep 704 is 2
State prediction error at timestep 704 is 0.012
Human Feedback received at timestpe 704 of -10
Current timestep = 705. State = [[-0.6610421   0.02694055 -0.3144315  -0.10314768 -0.06171768 -0.4681546
   0.          0.        ]]. Action = [[ 0.19276857 -0.9101254 ]]. Reward = [-3.9309218]
Abstract state at timestep 705 is 2
State prediction error at timestep 705 is 0.012
Human Feedback received at timestpe 705 of -10
Current timestep = 706. State = [[-0.66448843  0.02405263 -0.3226857  -0.12940772 -0.08345255 -0.43471393
   0.          0.        ]]. Action = [[-0.37879467 -0.984361  ]]. Reward = [-4.2112236]
Abstract state at timestep 706 is 2
State prediction error at timestep 706 is 0.012
Human Feedback received at timestpe 706 of -10
Current timestep = 707. State = [[-0.6679342   0.02057134 -0.32266343 -0.15609781 -0.10518679 -0.43470162
   0.          0.        ]]. Action = [[-0.00299329 -0.48478913]]. Reward = [-3.583297]
Abstract state at timestep 707 is 2
State prediction error at timestep 707 is 0.012
Human Feedback received at timestpe 707 of -10
Current timestep = 708. State = [[-0.67134404  0.01674257 -0.31133854 -0.17253467 -0.1346453  -0.58914465
   0.          1.        ]]. Action = [[-0.89063466 -0.03269476]]. Reward = [6.972883]
Abstract state at timestep 708 is 2
State prediction error at timestep 708 is 0.012
Human Feedback received at timestpe 708 of -10
Current timestep = 709. State = [[-0.67467904  0.01265052 -0.29170367 -0.18620795 -0.1764115  -0.8353345
   0.          1.        ]]. Action = [[-0.9206425  0.7360873]]. Reward = [-3.5352538]
Abstract state at timestep 709 is 2
State prediction error at timestep 709 is 0.012
Human Feedback received at timestpe 709 of -10
Current timestep = 710. State = [[-0.67799175  0.00828653 -0.28013948 -0.20089476 -0.22796634 -1.0311539
   1.          1.        ]]. Action = [[-0.32399058  0.1451205 ]]. Reward = [4.654321]
Abstract state at timestep 710 is 2
State prediction error at timestep 710 is 0.012
Human Feedback received at timestpe 710 of -10
Current timestep = 711. State = [[ 0.0024436   1.398628    0.24748492 -0.5463146  -0.00282463 -0.056059
   0.          0.        ]]. Action = [[-0.24506325 -0.24832118]]. Reward = [-100.]
Abstract state at timestep 711 is 2
State prediction error at timestep 711 is 0.012
Human Feedback received at timestpe 711 of -10
Current timestep = 712. State = [[ 0.00478916  1.3870848   0.23898406 -0.51304024 -0.00720531 -0.08762175
   0.          0.        ]]. Action = [[0.7307122 0.6122525]]. Reward = [3.816206]
Abstract state at timestep 712 is 3
State prediction error at timestep 712 is 0.012
Human Feedback received at timestpe 712 of -10
Current timestep = 713. State = [[ 0.00715075  1.3755717   0.24052909 -0.51172996 -0.01152078 -0.08631723
   0.          0.        ]]. Action = [[0.44591022 0.0860337 ]]. Reward = [0.5550514]
Abstract state at timestep 713 is 3
State prediction error at timestep 713 is 0.012
Human Feedback received at timestpe 713 of -10
Current timestep = 714. State = [[ 0.00929451  1.3639913   0.217285   -0.514711   -0.01440756 -0.05774102
   0.          0.        ]]. Action = [[ 0.57396984 -0.8531006 ]]. Reward = [1.2808073]
Abstract state at timestep 714 is 3
State prediction error at timestep 714 is 0.012
Human Feedback received at timestpe 714 of -10
Current timestep = 715. State = [[ 0.01153059  1.3524721   0.2284447  -0.5120151  -0.01918221 -0.09550221
   0.          0.        ]]. Action = [[0.48988664 0.9602027 ]]. Reward = [0.22331521]
Abstract state at timestep 715 is 3
State prediction error at timestep 715 is 0.012
Human Feedback received at timestpe 715 of -10
Current timestep = 716. State = [[ 0.01384125  1.3412163   0.23440404 -0.5003022  -0.02249017 -0.06616514
   0.          0.        ]]. Action = [[ 0.5734736 -0.6000492]]. Reward = [1.3559225]
Abstract state at timestep 716 is 3
State prediction error at timestep 716 is 0.012
Human Feedback received at timestpe 716 of -10
Current timestep = 717. State = [[ 0.01616011  1.3299415   0.23672402 -0.5011812  -0.02727087 -0.09562243
   0.          0.        ]]. Action = [[0.7621424 0.6758517]]. Reward = [0.18384819]
Abstract state at timestep 717 is 3
State prediction error at timestep 717 is 0.012
Human Feedback received at timestpe 717 of -10
Current timestep = 718. State = [[ 0.01856318  1.3184067   0.2447618  -0.51274884 -0.03167904 -0.08817165
   0.          0.        ]]. Action = [[0.20362091 0.40307343]]. Reward = [-0.86085135]
Abstract state at timestep 718 is 3
State prediction error at timestep 718 is 0.012
Human Feedback received at timestpe 718 of -10
Current timestep = 719. State = [[ 0.02088995  1.3067552   0.23754044 -0.51795256 -0.03649935 -0.09641508
   0.          0.        ]]. Action = [[0.14323938 0.12570786]]. Reward = [0.3427526]
Abstract state at timestep 719 is 3
State prediction error at timestep 719 is 0.012
Human Feedback received at timestpe 719 of -10
Current timestep = 720. State = [[ 0.02321949  1.2950677   0.23980871 -0.51963294 -0.04327433 -0.13551177
   0.          0.        ]]. Action = [[0.5384946 0.9314865]]. Reward = [-0.01903566]
Abstract state at timestep 720 is 3
State prediction error at timestep 720 is 0.012
Human Feedback received at timestpe 720 of 10
Current timestep = 721. State = [[ 0.02556963  1.2831857   0.24053736 -0.528259   -0.04874731 -0.10946965
   0.          0.        ]]. Action = [[ 0.02102292 -0.61892647]]. Reward = [-0.3499911]
Abstract state at timestep 721 is 3
State prediction error at timestep 721 is 0.012
Human Feedback received at timestpe 721 of 10
Current timestep = 722. State = [[ 0.02798099  1.2706949   0.24822924 -0.5553926  -0.05576601 -0.1403869
   0.          0.        ]]. Action = [[-0.8127632  0.6800442]]. Reward = [-2.268173]
Abstract state at timestep 722 is 3
State prediction error at timestep 722 is 0.012
Human Feedback received at timestpe 722 of 10
Current timestep = 723. State = [[ 0.03045797  1.2576084   0.25644615 -0.5819626  -0.06442073 -0.17311072
   0.          0.        ]]. Action = [[-0.658608   0.8156121]]. Reward = [-2.3492668]
Abstract state at timestep 723 is 3
State prediction error at timestep 723 is 0.012
Human Feedback received at timestpe 723 of 10
Current timestep = 724. State = [[ 0.03293533  1.243923    0.2564713  -0.6086373  -0.07307375 -0.17307606
   0.          0.        ]]. Action = [[-0.15591979  0.13701129]]. Reward = [-1.9541979]
Abstract state at timestep 724 is 3
State prediction error at timestep 724 is 0.012
Human Feedback received at timestpe 724 of 10
Current timestep = 725. State = [[ 0.03541308  1.2296385   0.25649604 -0.63531226 -0.08172575 -0.1730558
   0.          0.        ]]. Action = [[-0.5577664  -0.35039037]]. Reward = [-1.9110612]
Abstract state at timestep 725 is 3
State prediction error at timestep 725 is 0.012
Human Feedback received at timestpe 725 of 10
Current timestep = 726. State = [[ 0.03785067  1.2156786   0.251625   -0.62088555 -0.08952767 -0.15605278
   0.          0.        ]]. Action = [[ 0.7225938 -0.5020162]]. Reward = [1.854485]
Abstract state at timestep 726 is 3
State prediction error at timestep 726 is 0.012
Human Feedback received at timestpe 726 of 10
Current timestep = 727. State = [[ 0.04028855  1.2011191   0.25164574 -0.64756745 -0.09732862 -0.15603319
   0.          0.        ]]. Action = [[-0.20503688  0.3761872 ]]. Reward = [-1.8136024]
Abstract state at timestep 727 is 3
State prediction error at timestep 727 is 0.012
Human Feedback received at timestpe 727 of 10
Current timestep = 728. State = [[ 0.04273825  1.18651     0.25293416 -0.64982533 -0.10524121 -0.15826647
   0.          0.        ]]. Action = [[ 0.43712568 -0.35547888]]. Reward = [0.18754672]
Abstract state at timestep 728 is 3
State prediction error at timestep 728 is 0.012
Human Feedback received at timestpe 728 of 10
Current timestep = 729. State = [[ 0.04503975  1.171838    0.23625913 -0.6525301  -0.11132119 -0.12161039
   0.          0.        ]]. Action = [[ 0.47477627 -0.97263044]]. Reward = [0.93234485]
Abstract state at timestep 729 is 3
State prediction error at timestep 729 is 0.012
Human Feedback received at timestpe 729 of 10
Current timestep = 730. State = [[ 0.04728537  1.1565821   0.22922082 -0.6783978  -0.11596228 -0.09283015
   0.          0.        ]]. Action = [[-0.31541836 -0.66823417]]. Reward = [-1.1779066]
Abstract state at timestep 730 is 3
State prediction error at timestep 730 is 0.012
Human Feedback received at timestpe 730 of 10
Current timestep = 731. State = [[ 0.04953117  1.1407264   0.22923326 -0.70506704 -0.12060302 -0.09282283
   0.          0.        ]]. Action = [[-0.8810258  -0.27600598]]. Reward = [-1.4212741]
Abstract state at timestep 731 is 3
State prediction error at timestep 731 is 0.012
Human Feedback received at timestpe 731 of 10
Current timestep = 732. State = [[ 0.05180426  1.1246986   0.23344927 -0.7128563  -0.12672086 -0.1223678
   0.          0.        ]]. Action = [[0.4600525  0.68103385]]. Reward = [-0.13147712]
Abstract state at timestep 732 is 3
State prediction error at timestep 732 is 0.012
Human Feedback received at timestpe 732 of 10
Current timestep = 733. State = [[ 0.05415983  1.1080589   0.24379107 -0.7402635  -0.13492379 -0.16407338
   0.          0.        ]]. Action = [[-0.67126393  0.84440506]]. Reward = [-2.1212692]
Abstract state at timestep 733 is 3
State prediction error at timestep 733 is 0.012
Human Feedback received at timestpe 733 of 10
Current timestep = 734. State = [[ 0.05645018  1.090832    0.2355758  -0.7662451  -0.14145467 -0.13062933
   0.          0.        ]]. Action = [[-0.30181086 -0.78781587]]. Reward = [-1.1943487]
Abstract state at timestep 734 is 3
State prediction error at timestep 734 is 0.012
Human Feedback received at timestpe 734 of 10
Current timestep = 735. State = [[ 0.05879316  1.0729915   0.2421973  -0.79367524 -0.1493358  -0.15763713
   0.          0.        ]]. Action = [[-0.66204756  0.6478708 ]]. Reward = [-1.8551491]
Abstract state at timestep 735 is 3
State prediction error at timestep 735 is 0.012
Human Feedback received at timestpe 735 of 10
Current timestep = 736. State = [[ 0.06121826  1.0553335   0.2521825  -0.7858045  -0.15899958 -0.19327548
   0.          0.        ]]. Action = [[0.95392275 0.82542527]]. Reward = [0.91796815]
Abstract state at timestep 736 is 3
State prediction error at timestep 736 is 0.012
Human Feedback received at timestpe 736 of 10
Current timestep = 737. State = [[ 0.06360722  1.0370866   0.24763152 -0.8119278  -0.16773075 -0.17462337
   0.          0.        ]]. Action = [[-0.6559491 -0.5728567]]. Reward = [-1.4403296]
Abstract state at timestep 737 is 3
State prediction error at timestep 737 is 0.012
Human Feedback received at timestpe 737 of 10
Current timestep = 738. State = [[ 0.0659174   1.0188069   0.23850589 -0.813296   -0.17522702 -0.14992547
   0.          0.        ]]. Action = [[ 0.4097544  -0.69247466]]. Reward = [0.9583891]
Abstract state at timestep 738 is 3
State prediction error at timestep 738 is 0.012
Human Feedback received at timestpe 738 of 10
Current timestep = 739. State = [[ 0.06822767  0.9999281   0.23850468 -0.8399673  -0.18272327 -0.14992511
   0.          0.        ]]. Action = [[-0.5909597   0.02762902]]. Reward = [-1.4437495]
Abstract state at timestep 739 is 3
State prediction error at timestep 739 is 0.012
Human Feedback received at timestpe 739 of 10
Current timestep = 740. State = [[ 0.07071972  0.98115766  0.2578494  -0.8353378  -0.19140042 -0.17354353
   0.          0.        ]]. Action = [[0.48648214 0.6333358 ]]. Reward = [0.639671]
Abstract state at timestep 740 is 4
State prediction error at timestep 740 is 0.012
Human Feedback received at timestpe 740 of 10
Current timestep = 741. State = [[ 0.07338371  0.9626819   0.27351654 -0.8220797  -0.19855306 -0.14305292
   0.          0.        ]]. Action = [[ 0.4071784 -0.6584465]]. Reward = [1.6608905]
Abstract state at timestep 741 is 4
State prediction error at timestep 741 is 0.012
Human Feedback received at timestpe 741 of 10
Current timestep = 742. State = [[ 0.0760479   0.94360673  0.2735153  -0.84875053 -0.20570566 -0.14305219
   0.          0.        ]]. Action = [[-0.922754    0.10316873]]. Reward = [-1.3690296]
Abstract state at timestep 742 is 4
State prediction error at timestep 742 is 0.012
Human Feedback received at timestpe 742 of 10
Current timestep = 743. State = [[ 0.07900123  0.92525643  0.30194932 -0.81651175 -0.21238282 -0.13354321
   0.          0.        ]]. Action = [[0.98610425 0.10843635]]. Reward = [2.9565856]
Abstract state at timestep 743 is 4
State prediction error at timestep 743 is 0.012
Human Feedback received at timestpe 743 of 10
Current timestep = 744. State = [[ 0.08189917  0.9063236   0.29497057 -0.8422076  -0.21761641 -0.10467142
   0.          0.        ]]. Action = [[-0.42053354 -0.609902  ]]. Reward = [-0.86240727]
Abstract state at timestep 744 is 4
State prediction error at timestep 744 is 0.012
Human Feedback received at timestpe 744 of 10
Current timestep = 745. State = [[ 0.0847971   0.8867914   0.29496983 -0.86887646 -0.22284997 -0.10467124
   0.          0.        ]]. Action = [[-0.69539    -0.32867497]]. Reward = [-1.1265422]
Abstract state at timestep 745 is 4
State prediction error at timestep 745 is 0.012
Human Feedback received at timestpe 745 of 10
Current timestep = 746. State = [[ 0.08778954  0.867254    0.30438453 -0.8691081  -0.22806302 -0.10426118
   0.          0.        ]]. Action = [[0.2417841 0.1743629]]. Reward = [0.87863773]
Abstract state at timestep 746 is 4
State prediction error at timestep 746 is 0.012
Human Feedback received at timestpe 746 of 10
Current timestep = 747. State = [[ 0.09078197  0.8471171   0.30438378 -0.8957769  -0.23327607 -0.10426102
   0.          0.        ]]. Action = [[-0.4976647   0.37088263]]. Reward = [-1.0705312]
Abstract state at timestep 747 is 4
State prediction error at timestep 747 is 0.012
Human Feedback received at timestpe 747 of 10
Current timestep = 748. State = [[ 0.09384517  0.82679456  0.31254038 -0.9042238  -0.23958595 -0.12619787
   0.          0.        ]]. Action = [[0.28493166 0.50330544]]. Reward = [0.08407641]
Abstract state at timestep 748 is 4
State prediction error at timestep 748 is 0.012
Human Feedback received at timestpe 748 of 10
Current timestep = 749. State = [[ 0.09690847  0.8058725   0.3125392  -0.9308937  -0.24589583 -0.12619755
   0.          0.        ]]. Action = [[-0.11628664  0.45122695]]. Reward = [-1.1129649]
Abstract state at timestep 749 is 4
State prediction error at timestep 749 is 0.012
Human Feedback received at timestpe 749 of 10
Current timestep = 750. State = [[ 0.09997196  0.7843509   0.312538   -0.9575635  -0.25220567 -0.126197
   0.          0.        ]]. Action = [[-0.12950587  0.26586938]]. Reward = [-1.064612]
Abstract state at timestep 750 is 4
State prediction error at timestep 750 is 0.012
Human Feedback received at timestpe 750 of 10
Current timestep = 751. State = [[ 0.10303545  0.76222986  0.31253675 -0.98423344 -0.2585155  -0.1261966
   0.          0.        ]]. Action = [[-0.78643084 -0.46888477]]. Reward = [-1.0162205]
Abstract state at timestep 751 is 4
State prediction error at timestep 751 is 0.012
Human Feedback received at timestpe 751 of 10
Current timestep = 752. State = [[ 0.10610304  0.74077505  0.31188047 -0.9544591  -0.26374876 -0.10466515
   0.          0.        ]]. Action = [[ 0.779346   -0.70302886]]. Reward = [4.1255536]
Abstract state at timestep 752 is 4
State prediction error at timestep 752 is 0.012
Human Feedback received at timestpe 752 of 10
Current timestep = 753. State = [[ 0.10941763  0.7195532   0.33480793 -0.94380563 -0.2671768  -0.06856076
   0.          0.        ]]. Action = [[ 0.7939844 -0.7294052]]. Reward = [1.6863126]
Abstract state at timestep 753 is 4
State prediction error at timestep 753 is 0.012
Human Feedback received at timestpe 753 of 10
Current timestep = 754. State = [[ 0.11297159  0.6984727   0.3597732  -0.9377068  -0.27165452 -0.08955397
   0.          0.        ]]. Action = [[0.16282475 0.5679289 ]]. Reward = [1.0958464]
Abstract state at timestep 754 is 4
State prediction error at timestep 754 is 0.012
Human Feedback received at timestpe 754 of 10
Current timestep = 755. State = [[ 0.11655102  0.6771734   0.3624977  -0.94749737 -0.27633435 -0.09359674
   0.          0.        ]]. Action = [[ 0.01653409 -0.41296673]]. Reward = [0.4097679]
Abstract state at timestep 755 is 4
State prediction error at timestep 755 is 0.012
Human Feedback received at timestpe 755 of 10
Current timestep = 756. State = [[ 0.12017641  0.65599823  0.36539754 -0.94166017 -0.27926907 -0.05869447
   0.          0.        ]]. Action = [[ 0.24999154 -0.86598897]]. Reward = [1.9549617]
Abstract state at timestep 756 is 4
State prediction error at timestep 756 is 0.012
Human Feedback received at timestpe 756 of 10
Current timestep = 757. State = [[ 0.12380181  0.6342233   0.36539727 -0.9683275  -0.2822038  -0.05869448
   0.          0.        ]]. Action = [[-0.9483472 -0.3394674]]. Reward = [-0.7119011]
Abstract state at timestep 757 is 4
State prediction error at timestep 757 is 0.012
Human Feedback received at timestpe 757 of 10
Current timestep = 758. State = [[ 0.1274273   0.61184835  0.36539698 -0.9949948  -0.28513852 -0.05869441
   0.          0.        ]]. Action = [[-0.9956655   0.32350957]]. Reward = [-0.6709864]
Abstract state at timestep 758 is 4
State prediction error at timestep 758 is 0.012
Human Feedback received at timestpe 758 of 10
Current timestep = 759. State = [[ 0.13113365  0.58997     0.37254372 -0.97274363 -0.2871008  -0.03924507
   0.          0.        ]]. Action = [[ 0.49770367 -0.5708886 ]]. Reward = [3.4553235]
Abstract state at timestep 759 is 4
State prediction error at timestep 759 is 0.012
Human Feedback received at timestpe 759 of 10
Current timestep = 760. State = [[ 0.13486461  0.5684598   0.3739648  -0.9561785  -0.28799304 -0.01784492
   0.          0.        ]]. Action = [[ 0.9148903 -0.6600899]]. Reward = [3.110208]
Abstract state at timestep 760 is 4
State prediction error at timestep 760 is 0.012
Human Feedback received at timestpe 760 of 10
Current timestep = 761. State = [[ 0.13854256  0.5463719   0.36728042 -0.98158926 -0.28746703  0.01052038
   0.          0.        ]]. Action = [[-0.70948297 -0.7401458 ]]. Reward = [-0.0465297]
Abstract state at timestep 761 is 4
State prediction error at timestep 761 is 0.012
Human Feedback received at timestpe 761 of 10
Current timestep = 762. State = [[ 0.14229937  0.52433646  0.37654823 -0.97951996 -0.2883602  -0.01786371
   0.          0.        ]]. Action = [[0.0433898 0.6511135]]. Reward = [1.6355013]
Abstract state at timestep 762 is 4
State prediction error at timestep 762 is 0.012
Human Feedback received at timestpe 762 of 10
Current timestep = 763. State = [[ 0.14615354  0.5027018   0.3849768  -0.9614521  -0.2879046   0.00911209
   0.          0.        ]]. Action = [[ 0.8903451 -0.710396 ]]. Reward = [3.093363]
Abstract state at timestep 763 is 4
State prediction error at timestep 763 is 0.012
Human Feedback received at timestpe 763 of 10
Current timestep = 764. State = [[ 0.14994612  0.48048928  0.37723127 -0.98682797 -0.28582335  0.04162558
   0.          0.        ]]. Action = [[-0.32801533 -0.64347905]]. Reward = [0.12533616]
Abstract state at timestep 764 is 4
State prediction error at timestep 764 is 0.012
Human Feedback received at timestpe 764 of 10
Current timestep = 765. State = [[ 0.1540204   0.45820084  0.40668684 -0.9904522  -0.2850571   0.01532497
   0.          0.        ]]. Action = [[0.27756667 0.7218077 ]]. Reward = [0.43574122]
Abstract state at timestep 765 is 5
State prediction error at timestep 765 is 0.012
Human Feedback received at timestpe 765 of 10
Current timestep = 766. State = [[ 0.1580307   0.43590367  0.39841235 -0.990478   -0.28237543  0.05363356
   0.          0.        ]]. Action = [[ 0.30608118 -0.9663287 ]]. Reward = [2.3253229]
Abstract state at timestep 766 is 5
State prediction error at timestep 766 is 0.012
Human Feedback received at timestpe 766 of 10
Current timestep = 767. State = [[ 0.1620409   0.41300663  0.3984121  -1.0171453  -0.27969375  0.05363352
   0.          0.        ]]. Action = [[-0.6245511  -0.47275913]]. Reward = [-0.20959727]
Abstract state at timestep 767 is 5
State prediction error at timestep 767 is 0.012
Human Feedback received at timestpe 767 of 10
Current timestep = 768. State = [[ 0.16635695  0.3905034   0.42692867 -0.99925905 -0.27490056  0.09586366
   0.          0.        ]]. Action = [[ 0.90490806 -0.8724773 ]]. Reward = [2.6620045]
Abstract state at timestep 768 is 5
State prediction error at timestep 768 is 0.012
Human Feedback received at timestpe 768 of 10
Current timestep = 769. State = [[ 0.17067309  0.3674004   0.42692786 -1.0259275  -0.2701074   0.09586352
   0.          0.        ]]. Action = [[-0.33580798  0.09765232]]. Reward = [-0.04262724]
Abstract state at timestep 769 is 5
State prediction error at timestep 769 is 0.012
Human Feedback received at timestpe 769 of 10
Current timestep = 770. State = [[ 0.17490892  0.34373438  0.4167902  -1.0505824  -0.26315466  0.13905448
   0.          0.        ]]. Action = [[-0.7005149 -0.9655289]]. Reward = [0.706964]
Abstract state at timestep 770 is 5
State prediction error at timestep 770 is 0.012
Human Feedback received at timestpe 770 of 10
Current timestep = 771. State = [[ 0.17914486  0.31946906  0.41678858 -1.0772532  -0.25620198  0.13905403
   0.          0.        ]]. Action = [[-0.2937255   0.06793427]]. Reward = [0.15273944]
Abstract state at timestep 771 is 5
State prediction error at timestep 771 is 0.012
Human Feedback received at timestpe 771 of 10
Current timestep = 772. State = [[ 0.18353224  0.29496598  0.43330288 -1.0880886  -0.25066224  0.11079474
   0.          0.        ]]. Action = [[0.09569621 0.7097001 ]]. Reward = [0.642886]
Abstract state at timestep 772 is 5
State prediction error at timestep 772 is 0.012
Human Feedback received at timestpe 772 of 10
Current timestep = 773. State = [[ 0.18791962  0.26986328  0.43330187 -1.1147578  -0.2451225   0.11079448
   0.          0.        ]]. Action = [[-0.72946674 -0.30797338]]. Reward = [-0.0720665]
Abstract state at timestep 773 is 5
State prediction error at timestep 773 is 0.012
Human Feedback received at timestpe 773 of 10
Current timestep = 774. State = [[ 0.19235706  0.24414626  0.4395681  -1.1422887  -0.2408793   0.08486418
   0.          0.        ]]. Action = [[-0.9130742   0.70731556]]. Reward = [-0.58796453]
Abstract state at timestep 774 is 5
State prediction error at timestep 774 is 0.012
Human Feedback received at timestpe 774 of 10
Current timestep = 775. State = [[ 0.19674739  0.21785195  0.43361822 -1.1677568  -0.23537077  0.11017051
   0.          0.        ]]. Action = [[-0.40086293 -0.82999414]]. Reward = [0.08144149]
Abstract state at timestep 775 is 5
State prediction error at timestep 775 is 0.012
Human Feedback received at timestpe 775 of 10
Current timestep = 776. State = [[ 0.20109625  0.19096914  0.4283873  -1.1937726  -0.22878627  0.13169006
   0.          0.        ]]. Action = [[-0.58733565 -0.5307183 ]]. Reward = [0.00017472]
Abstract state at timestep 776 is 5
State prediction error at timestep 776 is 0.012
Human Feedback received at timestpe 776 of 10
Current timestep = 777. State = [[ 0.20548287  0.16347857  0.43310896 -1.2209518  -0.22316651  0.1123953
   0.          0.        ]]. Action = [[-0.46955895  0.54345584]]. Reward = [-0.69845736]
Abstract state at timestep 777 is 5
State prediction error at timestep 777 is 0.012
Human Feedback received at timestpe 777 of -10
Current timestep = 778. State = [[ 0.20991507  0.13537861  0.43882284 -1.2482291  -0.2187136   0.08905833
   0.          0.        ]]. Action = [[-0.57641596  0.58093786]]. Reward = [-1.0547551]
Abstract state at timestep 778 is 5
State prediction error at timestep 778 is 0.012
Human Feedback received at timestpe 778 of 10
Current timestep = 779. State = [[ 0.21446753  0.10774627  0.45101166 -1.2274793  -0.21443182  0.08563541
   0.          0.        ]]. Action = [[0.923872  0.0535357]]. Reward = [2.6571295]
Abstract state at timestep 779 is 5
State prediction error at timestep 779 is 0.012
Human Feedback received at timestpe 779 of 10
Current timestep = 780. State = [[ 0.21902008  0.07951427  0.45101112 -1.2541476  -0.21015006  0.0856353
   0.          0.        ]]. Action = [[-0.01745504  0.03154099]]. Reward = [-1.3777345]
Abstract state at timestep 780 is 5
State prediction error at timestep 780 is 0.012
Human Feedback received at timestpe 780 of 10
Current timestep = 781. State = [[ 0.22357264  0.05068246  0.45101064 -1.2808156  -0.2058683   0.08563515
   0.          0.        ]]. Action = [[-0.11703128  0.12712479]]. Reward = [-1.708101]
Abstract state at timestep 781 is 5
State prediction error at timestep 781 is 0.012
Human Feedback received at timestpe 781 of 10
Current timestep = 782. State = [[ 0.22829047  0.02176274  0.46710768 -1.2846786  -0.20116101  0.09414585
   0.          0.        ]]. Action = [[ 0.02720618 -0.30478972]]. Reward = [-0.59742856]
Abstract state at timestep 782 is 5
State prediction error at timestep 782 is 0.012
Human Feedback received at timestpe 782 of 10
Current timestep = 783. State = [[ 0.23307696 -0.00707001  0.4719923  -1.2805622  -0.19445542  0.13411155
   0.          0.        ]]. Action = [[ 0.55509853 -0.9681096 ]]. Reward = [0.24100058]
Abstract state at timestep 783 is 5
State prediction error at timestep 783 is 0.012
Human Feedback received at timestpe 783 of 10
Current timestep = 784. State = [[ 0.23794612 -0.03572169  0.45949927 -1.2696517  -0.16955131  0.49466425
   1.          1.        ]]. Action = [[-0.54412884 -0.18403071]]. Reward = [23.201017]
Abstract state at timestep 784 is 5
State prediction error at timestep 784 is 0.012
Human Feedback received at timestpe 784 of -10
Current timestep = 785. State = [[ 0.00738926  1.419344    0.74842966  0.37436968 -0.00855545 -0.16953056
   0.          0.        ]]. Action = [[-0.66055787 -0.70569754]]. Reward = [-100.]
Abstract state at timestep 785 is 5
State prediction error at timestep 785 is 0.012
Human Feedback received at timestpe 785 of -10
Current timestep = 786. State = [[ 0.01465073  1.428119    0.7352706   0.38992545 -0.01757308 -0.18036805
   0.          0.        ]]. Action = [[ 0.7764467  -0.31445348]]. Reward = [-1.5939066]
Abstract state at timestep 786 is 3
State prediction error at timestep 786 is 0.012
Human Feedback received at timestpe 786 of 10
Current timestep = 787. State = [[ 0.02182169  1.4363024   0.7238983   0.36361983 -0.02429695 -0.13449022
   0.          0.        ]]. Action = [[-0.27246922 -0.9625329 ]]. Reward = [0.6886671]
Abstract state at timestep 787 is 3
State prediction error at timestep 787 is 0.012
Human Feedback received at timestpe 787 of 10
Current timestep = 788. State = [[ 0.02899284  1.4438868   0.7239167   0.33694926 -0.03102128 -0.13449928
   0.          0.        ]]. Action = [[-0.8598656 -0.4167542]]. Reward = [-0.28349692]
Abstract state at timestep 788 is 3
State prediction error at timestep 788 is 0.012
Human Feedback received at timestpe 788 of 10
Current timestep = 789. State = [[ 0.03631764  1.4513489   0.741137    0.33144453 -0.03958665 -0.17132345
   0.          0.        ]]. Action = [[0.3204217 0.9566463]]. Reward = [-3.1840024]
Abstract state at timestep 789 is 3
State prediction error at timestep 789 is 0.012
Human Feedback received at timestpe 789 of 10
Current timestep = 790. State = [[ 0.04364262  1.4582119   0.7411622   0.30476692 -0.04814991 -0.17128125
   0.          0.        ]]. Action = [[-0.12312281 -0.24753392]]. Reward = [-0.5127236]
Abstract state at timestep 790 is 3
State prediction error at timestep 790 is 0.012
Human Feedback received at timestpe 790 of 10
Current timestep = 791. State = [[ 0.05096798  1.4644756   0.7411869   0.27809435 -0.05671217 -0.17126113
   0.          0.        ]]. Action = [[-0.36659658  0.16604269]]. Reward = [-0.53236836]
Abstract state at timestep 791 is 3
State prediction error at timestep 791 is 0.012
Human Feedback received at timestpe 791 of 10
Current timestep = 792. State = [[ 0.05829363  1.4701405   0.7412118   0.25142065 -0.06527305 -0.17123377
   0.          0.        ]]. Action = [[-0.4061718  -0.31822133]]. Reward = [-0.55462724]
Abstract state at timestep 792 is 3
State prediction error at timestep 792 is 0.012
Human Feedback received at timestpe 792 of 10
Current timestep = 793. State = [[ 0.06562576  1.4759641   0.7434453   0.25834775 -0.07542329 -0.20302364
   0.          0.        ]]. Action = [[0.20730412 0.74991536]]. Reward = [-2.267468]
Abstract state at timestep 793 is 3
State prediction error at timestep 793 is 0.012
Human Feedback received at timestpe 793 of 10
Current timestep = 794. State = [[ 0.07292185  1.4811959   0.73891294  0.23203675 -0.08464871 -0.18452531
   0.          0.        ]]. Action = [[-0.53084457 -0.60555655]]. Reward = [-0.24094929]
Abstract state at timestep 794 is 3
State prediction error at timestep 794 is 0.012
Human Feedback received at timestpe 794 of -10
Current timestep = 795. State = [[ 0.08024206  1.4864652   0.74136865  0.23363683 -0.09393102 -0.18566358
   0.          0.        ]]. Action = [[0.01076972 0.01375067]]. Reward = [-1.9260678]
Abstract state at timestep 795 is 3
State prediction error at timestep 795 is 0.012
Human Feedback received at timestpe 795 of -10
Current timestep = 796. State = [[ 0.08756246  1.4911354   0.7413946   0.20695558 -0.10321162 -0.18562873
   0.          0.        ]]. Action = [[-0.08583176  0.29015017]]. Reward = [-0.678144]
Abstract state at timestep 796 is 3
State prediction error at timestep 796 is 0.012
Human Feedback received at timestpe 796 of -10
Current timestep = 797. State = [[ 0.09491424  1.496298    0.7462055   0.22865592 -0.11418308 -0.2194496
   0.          0.        ]]. Action = [[0.5013709 0.7597914]]. Reward = [-2.9767241]
Abstract state at timestep 797 is 3
State prediction error at timestep 797 is 0.012
Human Feedback received at timestpe 797 of -10
Current timestep = 798. State = [[ 0.10230388  1.5016402   0.7500814   0.23654424 -0.12525472 -0.2214529
   0.          0.        ]]. Action = [[ 0.15786684 -0.2805732 ]]. Reward = [-2.4667275]
Abstract state at timestep 798 is 3
State prediction error at timestep 798 is 0.012
Human Feedback received at timestpe 798 of -10
Current timestep = 799. State = [[ 0.10978184  1.5075686   0.76017237  0.26239085 -0.13760082 -0.2469447
   0.          0.        ]]. Action = [[0.6593591 0.5673311]]. Reward = [-3.9132528]
Abstract state at timestep 799 is 3
State prediction error at timestep 799 is 0.012
Human Feedback received at timestpe 799 of -10
Current timestep = 800. State = [[ 0.11720209  1.512914    0.7528815   0.23653884 -0.14844723 -0.21694753
   0.          0.        ]]. Action = [[-0.0858404  -0.70726377]]. Reward = [-0.19264399]
Abstract state at timestep 800 is 3
State prediction error at timestep 800 is 0.012
Human Feedback received at timestpe 800 of -10
Current timestep = 801. State = [[ 0.12468024  1.5176537   0.7601183   0.20938452 -0.16074818 -0.24604146
   0.          0.        ]]. Action = [[-0.06871021  0.90279615]]. Reward = [-1.7156445]
Abstract state at timestep 801 is 3
State prediction error at timestep 801 is 0.012
Human Feedback received at timestpe 801 of -10
Current timestep = 802. State = [[ 0.13215914  1.5217953   0.7601517   0.18270084 -0.17304626 -0.24598348
   0.          0.        ]]. Action = [[-0.12207502  0.03878617]]. Reward = [-1.0424128]
Abstract state at timestep 802 is 3
State prediction error at timestep 802 is 0.012
Human Feedback received at timestpe 802 of -10
Current timestep = 803. State = [[ 0.13963862  1.5253388   0.7601838   0.15601678 -0.18534264 -0.24594966
   0.          0.        ]]. Action = [[-0.71509165 -0.4020986 ]]. Reward = [-1.0719855]
Abstract state at timestep 803 is 3
State prediction error at timestep 803 is 0.012
Human Feedback received at timestpe 803 of -10
Current timestep = 804. State = [[ 0.14711866  1.5282842   0.7602152   0.12933245 -0.19763705 -0.24591067
   0.          0.        ]]. Action = [[-0.7188564  -0.27250296]]. Reward = [-1.1035676]
Abstract state at timestep 804 is 3
State prediction error at timestep 804 is 0.012
Human Feedback received at timestpe 804 of -10
Current timestep = 805. State = [[ 0.15483657  1.5315071   0.7834202   0.14164795 -0.20937851 -0.23485008
   0.          0.        ]]. Action = [[ 0.9475684 -0.3986498]]. Reward = [-4.361267]
Abstract state at timestep 805 is 3
State prediction error at timestep 805 is 0.012
Human Feedback received at timestpe 805 of -10
Current timestep = 806. State = [[ 0.16251048  1.5346597   0.77952087  0.13834642 -0.22166237 -0.24569921
   0.          0.        ]]. Action = [[ 0.5077462  -0.08881068]]. Reward = [-1.4050897]
Abstract state at timestep 806 is 3
State prediction error at timestep 806 is 0.012
Human Feedback received at timestpe 806 of -10
Current timestep = 807. State = [[ 0.17012167  1.537234    0.77159643  0.11280275 -0.2322941  -0.21265323
   0.          0.        ]]. Action = [[-0.5574118 -0.8169536]]. Reward = [-0.23514813]
Abstract state at timestep 807 is 3
State prediction error at timestep 807 is 0.012
Human Feedback received at timestpe 807 of -10
Current timestep = 808. State = [[ 0.17784777  1.5397756   0.7811709   0.11159339 -0.2410023  -0.17417967
   0.          0.        ]]. Action = [[ 0.6155102 -0.8891229]]. Reward = [-2.409506]
Abstract state at timestep 808 is 3
State prediction error at timestep 808 is 0.012
Human Feedback received at timestpe 808 of -10
Current timestep = 809. State = [[ 0.18563013  1.5417007   0.78821504  0.08389352 -0.25116786 -0.20332897
   0.          0.        ]]. Action = [[-0.08397353  0.85012555]]. Reward = [-1.6809696]
Abstract state at timestep 809 is 3
State prediction error at timestep 809 is 0.012
Human Feedback received at timestpe 809 of -10
Current timestep = 810. State = [[ 0.1934826   1.5434492   0.7955756   0.07590804 -0.2617154  -0.21095745
   0.          0.        ]]. Action = [[0.64249635 0.4745797 ]]. Reward = [-2.22261]
Abstract state at timestep 810 is 3
State prediction error at timestep 810 is 0.012
Human Feedback received at timestpe 810 of -10
Current timestep = 811. State = [[ 0.20133972  1.5445863   0.7956317   0.04873126 -0.27186027 -0.2028974
   0.          0.        ]]. Action = [[-0.58608717 -0.4720571 ]]. Reward = [-1.0203196]
Abstract state at timestep 811 is 3
State prediction error at timestep 811 is 0.012
Human Feedback received at timestpe 811 of -10
Current timestep = 812. State = [[ 0.20927343  1.5454223   0.80316895  0.03530169 -0.28191158 -0.20102625
   0.          0.        ]]. Action = [[ 0.17776096 -0.14675051]]. Reward = [-2.051347]
Abstract state at timestep 812 is 3
State prediction error at timestep 812 is 0.012
Human Feedback received at timestpe 812 of -10
Current timestep = 813. State = [[ 0.21748725  1.5466976   0.8308036   0.05483114 -0.29161057 -0.19397971
   0.          0.        ]]. Action = [[0.6726481  0.31221056]]. Reward = [-4.326085]
Abstract state at timestep 813 is 3
State prediction error at timestep 813 is 0.012
Human Feedback received at timestpe 813 of -10
Current timestep = 814. State = [[ 0.22570133  1.5473742   0.83080035  0.02815688 -0.30130947 -0.19397877
   0.          0.        ]]. Action = [[-0.7007272   0.15437317]]. Reward = [-1.0199728]
Abstract state at timestep 814 is 3
State prediction error at timestep 814 is 0.012
Human Feedback received at timestpe 814 of -10
Current timestep = 815. State = [[ 0.23424634  1.548574    0.86243135  0.05165426 -0.30949357 -0.16368183
   0.          0.        ]]. Action = [[ 0.7536638 -0.5621452]]. Reward = [-4.612518]
Abstract state at timestep 815 is 3
State prediction error at timestep 815 is 0.012
Human Feedback received at timestpe 815 of -10
Current timestep = 816. State = [[ 0.2427514   1.5491961   0.85731155  0.02618095 -0.3165635  -0.14139919
   0.          0.        ]]. Action = [[-0.1275649 -0.5715167]]. Reward = [-0.2884979]
Abstract state at timestep 816 is 3
State prediction error at timestep 816 is 0.012
Human Feedback received at timestpe 816 of -10
Current timestep = 817. State = [[ 2.5125647e-01  1.5492189e+00  8.5730964e-01 -4.8971700e-04
  -3.2363337e-01 -1.4139852e-01  0.0000000e+00  0.0000000e+00]]. Action = [[-0.15441525  0.22244465]]. Reward = [-0.80300283]
Abstract state at timestep 817 is 3
State prediction error at timestep 817 is 0.012
Human Feedback received at timestpe 817 of -10
Current timestep = 818. State = [[ 0.25990772  1.548969    0.8700074  -0.01221265 -0.32872307 -0.10179394
   0.          0.        ]]. Action = [[ 0.39935398 -0.91780496]]. Reward = [-2.140917]
Abstract state at timestep 818 is 3
State prediction error at timestep 818 is 0.012
Human Feedback received at timestpe 818 of -10
Current timestep = 819. State = [[ 0.26869288  1.5485332   0.88322484 -0.02044231 -0.33363912 -0.09832101
   0.          0.        ]]. Action = [[ 0.0194242  -0.21691102]]. Reward = [-2.0861778]
Abstract state at timestep 819 is 3
State prediction error at timestep 819 is 0.012
Human Feedback received at timestpe 819 of -10
Current timestep = 820. State = [[ 0.2774046   1.5475292   0.87398845 -0.04527782 -0.33658105 -0.05883844
   0.          0.        ]]. Action = [[-0.66065407 -0.99127764]]. Reward = [0.45371658]
Abstract state at timestep 820 is 3
State prediction error at timestep 820 is 0.012
Human Feedback received at timestpe 820 of -10
Current timestep = 821. State = [[ 0.28616714  1.5458922   0.8804375  -0.07373569 -0.34096566 -0.0876918
   0.          0.        ]]. Action = [[-0.13920045  0.8801396 ]]. Reward = [-1.2968001]
Abstract state at timestep 821 is 3
State prediction error at timestep 821 is 0.012
Human Feedback received at timestpe 821 of -10
Current timestep = 822. State = [[ 0.29488534  1.5436729   0.87487936 -0.09936025 -0.34416977 -0.0640817
   0.          0.        ]]. Action = [[-0.40800607 -0.6969124 ]]. Reward = [0.01727481]
Abstract state at timestep 822 is 3
State prediction error at timestep 822 is 0.012
Human Feedback received at timestpe 822 of -10
Current timestep = 823. State = [[ 0.30391854  1.5422374   0.90832996 -0.06500766 -0.34942695 -0.10514455
   0.          0.        ]]. Action = [[0.9752505 0.9302002]]. Reward = [-3.896041]
Abstract state at timestep 823 is 3
State prediction error at timestep 823 is 0.012
Human Feedback received at timestpe 823 of -10
Current timestep = 824. State = [[ 0.31327182  1.5406523   0.9421517  -0.07212915 -0.35661006 -0.1436623
   0.          0.        ]]. Action = [[0.1623962 0.9420357]]. Reward = [-4.374657]
Abstract state at timestep 824 is 6
State prediction error at timestep 824 is 0.012
Human Feedback received at timestpe 824 of -10
Current timestep = 825. State = [[ 0.32260162  1.5392003   0.9382108  -0.06584118 -0.36213154 -0.11042957
   0.          0.        ]]. Action = [[ 0.91458917 -0.9161777 ]]. Reward = [-0.47421825]
Abstract state at timestep 825 is 6
State prediction error at timestep 825 is 0.012
Human Feedback received at timestpe 825 of -10
Current timestep = 826. State = [[ 0.33222276  1.538036    0.9670628  -0.0530047  -0.36736268 -0.10462268
   0.          0.        ]]. Action = [[ 0.26437056 -0.41000617]]. Reward = [-3.598745]
Abstract state at timestep 826 is 6
State prediction error at timestep 826 is 0.012
Human Feedback received at timestpe 826 of -10
Current timestep = 827. State = [[ 0.34201735  1.5375228   0.9831835  -0.02376937 -0.37129268 -0.07860008
   0.          0.        ]]. Action = [[ 0.6640377  -0.70916575]]. Reward = [-2.3191354]
Abstract state at timestep 827 is 6
State prediction error at timestep 827 is 0.012
Human Feedback received at timestpe 827 of -10
Current timestep = 828. State = [[ 0.35181206  1.5364096   0.9831828  -0.05043726 -0.37522268 -0.07860003
   0.          0.        ]]. Action = [[-0.5646575   0.25773323]]. Reward = [-0.6005698]
Abstract state at timestep 828 is 6
State prediction error at timestep 828 is 0.012
Human Feedback received at timestpe 828 of -10
Current timestep = 829. State = [[ 0.36192495  1.5352434   1.0167298  -0.05328332 -0.38101327 -0.11581103
   0.          0.        ]]. Action = [[0.29096913 0.9251492 ]]. Reward = [-4.280682]
Abstract state at timestep 829 is 6
State prediction error at timestep 829 is 0.012
Human Feedback received at timestpe 829 of -10
Current timestep = 830. State = [[ 0.3723011   1.5341586   1.0427239  -0.04958651 -0.38645506 -0.10883582
   0.          0.        ]]. Action = [[ 0.46809077 -0.35988188]]. Reward = [-3.4780123]
Abstract state at timestep 830 is 6
State prediction error at timestep 830 is 0.012
Human Feedback received at timestpe 830 of -10
Current timestep = 831. State = [[ 0.38288927  1.5331057   1.0658642  -0.04872596 -0.39397046 -0.15030853
   0.          0.        ]]. Action = [[0.4907863  0.98881316]]. Reward = [-3.4632246]
Abstract state at timestep 831 is 6
State prediction error at timestep 831 is 0.012
Human Feedback received at timestpe 831 of -10
Current timestep = 832. State = [[ 0.39347774  1.5314535   1.0658615  -0.07539703 -0.4014859  -0.15030792
   0.          0.        ]]. Action = [[-0.6226668  -0.03263897]]. Reward = [-1.0061637]
Abstract state at timestep 832 is 6
State prediction error at timestep 832 is 0.012
Human Feedback received at timestpe 832 of -10
Current timestep = 833. State = [[ 0.40430078  1.530387    1.0896962  -0.04951448 -0.4094313  -0.15890808
   0.          0.        ]]. Action = [[ 0.7468977 -0.4628172]]. Reward = [-3.455833]
Abstract state at timestep 833 is 6
State prediction error at timestep 833 is 0.012
Human Feedback received at timestpe 833 of -10
Current timestep = 834. State = [[ 0.41554755  1.5298545   1.1316801  -0.02570894 -0.41697067 -0.1507874
   0.          0.        ]]. Action = [[0.8013058  0.00360441]]. Reward = [-5.3788795]
Abstract state at timestep 834 is 6
State prediction error at timestep 834 is 0.012
Human Feedback received at timestpe 834 of -10
Current timestep = 835. State = [[ 0.4269023   1.5290508   1.1423962  -0.03778737 -0.42446464 -0.14987996
   0.          0.        ]]. Action = [[ 0.1436603  -0.21147603]]. Reward = [-2.2498434]
Abstract state at timestep 835 is 6
State prediction error at timestep 835 is 0.012
Human Feedback received at timestpe 835 of -10
Current timestep = 836. State = [[ 0.43825713  1.527648    1.1423934  -0.06445836 -0.4319586  -0.14987938
   0.          0.        ]]. Action = [[-0.81662863 -0.3781302 ]]. Reward = [-1.0425828]
Abstract state at timestep 836 is 6
State prediction error at timestep 836 is 0.012
Human Feedback received at timestpe 836 of -10
Current timestep = 837. State = [[ 0.4495534   1.5256922   1.1348794  -0.08854708 -0.437678   -0.11438801
   0.          0.        ]]. Action = [[-0.07122326 -0.70637006]]. Reward = [-0.13255785]
Abstract state at timestep 837 is 6
State prediction error at timestep 837 is 0.012
Human Feedback received at timestpe 837 of -10
Current timestep = 838. State = [[ 0.46105298  1.523295    1.1571252  -0.10879862 -0.44549823 -0.15640448
   0.          0.        ]]. Action = [[0.04853332 0.982404  ]]. Reward = [-3.4581857]
Abstract state at timestep 838 is 6
State prediction error at timestep 838 is 0.012
Human Feedback received at timestpe 838 of -10
Current timestep = 839. State = [[ 0.47255287  1.5202985   1.1571219  -0.13546993 -0.45331842 -0.15640381
   0.          0.        ]]. Action = [[-0.29096156  0.3252722 ]]. Reward = [-1.1124068]
Abstract state at timestep 839 is 6
State prediction error at timestep 839 is 0.012
Human Feedback received at timestpe 839 of -10
Current timestep = 840. State = [[ 0.48423654  1.5171975   1.1767101  -0.14056411 -0.4624928  -0.18348733
   0.          0.        ]]. Action = [[0.4203509  0.61979985]]. Reward = [-3.209421]
Abstract state at timestep 840 is 6
State prediction error at timestep 840 is 0.012
Human Feedback received at timestpe 840 of -10
Current timestep = 841. State = [[ 0.4961422   1.514116    1.1988124  -0.13971923 -0.4716009  -0.18216184
   0.          0.        ]]. Action = [[ 0.6700535  -0.16977727]]. Reward = [-3.419587]
Abstract state at timestep 841 is 6
State prediction error at timestep 841 is 0.012
Human Feedback received at timestpe 841 of -10
Current timestep = 842. State = [[ 0.5080482   1.5104357   1.1988076  -0.16639215 -0.4807089  -0.18216081
   0.          0.        ]]. Action = [[-0.50955904 -0.21823263]]. Reward = [-1.273983]
Abstract state at timestep 842 is 6
State prediction error at timestep 842 is 0.012
Human Feedback received at timestpe 842 of -10
Current timestep = 843. State = [[ 0.5200165   1.5061066   1.2066826  -0.19587101 -0.49170622 -0.21994643
   0.          0.        ]]. Action = [[-0.29528975  0.7509217 ]]. Reward = [-2.3162055]
Abstract state at timestep 843 is 6
State prediction error at timestep 843 is 0.012
Human Feedback received at timestpe 843 of -10
Current timestep = 844. State = [[ 0.53223145  1.5020692   1.231548   -0.18306498 -0.50299627 -0.22580066
   0.          0.        ]]. Action = [[0.62545276 0.06232405]]. Reward = [-3.6553671]
Abstract state at timestep 844 is 6
State prediction error at timestep 844 is 0.012
Human Feedback received at timestpe 844 of -10
Current timestep = 845. State = [[ 0.5443718   1.4974825   1.2221011  -0.20684008 -0.51210225 -0.1821192
   0.          0.        ]]. Action = [[-0.36062968 -0.98159015]]. Reward = [-0.35864994]
Abstract state at timestep 845 is 6
State prediction error at timestep 845 is 0.012
Human Feedback received at timestpe 845 of -10
Current timestep = 846. State = [[ 0.5565125   1.4922969   1.2220961  -0.23351285 -0.5212081  -0.18211818
   0.          0.        ]]. Action = [[-0.0323447   0.27586687]]. Reward = [-1.3158754]
Abstract state at timestep 846 is 6
State prediction error at timestep 846 is 0.012
Human Feedback received at timestpe 846 of -10
Current timestep = 847. State = [[ 0.56894433  1.4871471   1.2525786  -0.23250271 -0.5319098  -0.21403512
   0.          0.        ]]. Action = [[0.29844272 0.7456614 ]]. Reward = [-4.221757]
Abstract state at timestep 847 is 6
State prediction error at timestep 847 is 0.012
Human Feedback received at timestpe 847 of -10
Current timestep = 848. State = [[ 0.5815433   1.481842    1.2707193  -0.24008442 -0.54435045 -0.24881199
   0.          0.        ]]. Action = [[0.92563295 0.7457607 ]]. Reward = [-3.4384706]
Abstract state at timestep 848 is 6
State prediction error at timestep 848 is 0.012
Human Feedback received at timestpe 848 of -10
Current timestep = 849. State = [[ 0.59436524  1.476599    1.2946318  -0.23812875 -0.5587783  -0.28855628
   0.          0.        ]]. Action = [[0.35100055 0.90157545]]. Reward = [-3.9737675]
Abstract state at timestep 849 is 6
State prediction error at timestep 849 is 0.012
Human Feedback received at timestpe 849 of -10
Current timestep = 850. State = [[ 0.60713404  1.4708064   1.2877781  -0.26204038 -0.5714899  -0.2542315
   0.          0.        ]]. Action = [[-0.00970751 -0.8202976 ]]. Reward = [-1.0231891]
Abstract state at timestep 850 is 6
State prediction error at timestep 850 is 0.012
Human Feedback received at timestpe 850 of -10
Current timestep = 851. State = [[ 0.62007844  1.4647424   1.3036859  -0.27351066 -0.5823875  -0.21795245
   0.          0.        ]]. Action = [[ 0.38078666 -0.8076555 ]]. Reward = [-3.0508997]
Abstract state at timestep 851 is 6
State prediction error at timestep 851 is 0.012
Human Feedback received at timestpe 851 of -10
Current timestep = 852. State = [[ 0.63322127  1.4586719   1.3236556  -0.27396733 -0.593525   -0.22274952
   0.          0.        ]]. Action = [[0.69582677 0.02953684]]. Reward = [-3.29234]
Abstract state at timestep 852 is 6
State prediction error at timestep 852 is 0.012
Human Feedback received at timestpe 852 of -10
Current timestep = 853. State = [[ 0.6463644   1.4520029   1.3236469  -0.30064267 -0.60466236 -0.22274764
   0.          0.        ]]. Action = [[-0.5823582  0.488878 ]]. Reward = [-1.5971167]
Abstract state at timestep 853 is 6
State prediction error at timestep 853 is 0.012
Human Feedback received at timestpe 853 of -10
Current timestep = 854. State = [[ 0.6595413   1.4446938   1.3279425  -0.32961538 -0.6170023  -0.24679884
   0.          0.        ]]. Action = [[-0.22849405  0.5357747 ]]. Reward = [-2.2131507]
Abstract state at timestep 854 is 6
State prediction error at timestep 854 is 0.012
Human Feedback received at timestpe 854 of -10
Current timestep = 855. State = [[ 0.6727516   1.4367592   1.3320558  -0.35791928 -0.630371   -0.26737368
   0.          0.        ]]. Action = [[-0.9173478  0.5688182]]. Reward = [-2.2946277]
Abstract state at timestep 855 is 6
State prediction error at timestep 855 is 0.012
Human Feedback received at timestpe 855 of -10
Current timestep = 856. State = [[ 0.68592644  1.4282718   1.3272883  -0.3820429  -0.6424013  -0.240607
   0.          0.        ]]. Action = [[-0.6203667 -0.5185557]]. Reward = [-1.2035903]
Abstract state at timestep 856 is 6
State prediction error at timestep 856 is 0.012
Human Feedback received at timestpe 856 of -10
Current timestep = 857. State = [[ 0.6993038   1.4194863   1.3461212  -0.39469978 -0.65280515 -0.2080771
   0.          0.        ]]. Action = [[ 0.3793764  -0.68762636]]. Reward = [-3.2246811]
Abstract state at timestep 857 is 6
State prediction error at timestep 857 is 0.012
Human Feedback received at timestpe 857 of -10
Current timestep = 858. State = [[ 0.71325856  1.4107803   1.4053863  -0.3920299  -0.6651562  -0.24702099
   0.          0.        ]]. Action = [[0.4346478  0.93209386]]. Reward = [-6.9471116]
Abstract state at timestep 858 is 6
State prediction error at timestep 858 is 0.012
Human Feedback received at timestpe 858 of -10
Current timestep = 859. State = [[ 0.7276594   1.4020836   1.4495363  -0.39150986 -0.67704314 -0.2377396
   0.          0.        ]]. Action = [[ 0.40352166 -0.13253349]]. Reward = [-5.525532]
Abstract state at timestep 859 is 6
State prediction error at timestep 859 is 0.012
Human Feedback received at timestpe 859 of -10
Current timestep = 860. State = [[ 0.74206144  1.3927883   1.4495252  -0.41818583 -0.68893    -0.23773725
   0.          0.        ]]. Action = [[-0.07713979  0.18265772]]. Reward = [-1.7527843]
Abstract state at timestep 860 is 6
State prediction error at timestep 860 is 0.012
Human Feedback received at timestpe 860 of -10
Current timestep = 861. State = [[ 0.75686014  1.3841236   1.4882145  -0.38971427 -0.6996338  -0.21407661
   0.          0.        ]]. Action = [[ 0.75161743 -0.68535745]]. Reward = [-4.2693777]
Abstract state at timestep 861 is 6
State prediction error at timestep 861 is 0.012
Human Feedback received at timestpe 861 of -10
Current timestep = 862. State = [[ 0.77211607  1.375541    1.5336564  -0.38601628 -0.71007395 -0.2088038
   0.          0.        ]]. Action = [[ 0.5677135  -0.20741194]]. Reward = [-5.577262]
Abstract state at timestep 862 is 6
State prediction error at timestep 862 is 0.012
Human Feedback received at timestpe 862 of -10
Current timestep = 863. State = [[ 0.78779393  1.3667642   1.575262   -0.39440203 -0.7198511  -0.19554245
   0.          0.        ]]. Action = [[ 0.727273   -0.34598404]]. Reward = [-5.48862]
Abstract state at timestep 863 is 6
State prediction error at timestep 863 is 0.012
Human Feedback received at timestpe 863 of -10
Current timestep = 864. State = [[ 0.8037054   1.3579379   1.5987942  -0.39678878 -0.7299346  -0.20166953
   0.          0.        ]]. Action = [[ 0.41938853 -0.24159789]]. Reward = [-3.6027162]
Abstract state at timestep 864 is 6
State prediction error at timestep 864 is 0.012
Human Feedback received at timestpe 864 of -10
Current timestep = 865. State = [[ 0.81972045  1.3489883   1.6078895  -0.40160576 -0.7384378  -0.17006361
   0.          0.        ]]. Action = [[ 0.48939037 -0.7631167 ]]. Reward = [-2.1517787]
Abstract state at timestep 865 is 6
State prediction error at timestep 865 is 0.012
Human Feedback received at timestpe 865 of -10
Current timestep = 866. State = [[ 0.83568954  1.3395095   1.6018353  -0.4242876  -0.74503094 -0.13186333
   0.          0.        ]]. Action = [[-0.26864016 -0.9515855 ]]. Reward = [-0.6968834]
Abstract state at timestep 866 is 6
State prediction error at timestep 866 is 0.012
Human Feedback received at timestpe 866 of -10
Current timestep = 867. State = [[ 0.85186994  1.3295475   1.6243658  -0.4466834  -0.75357175 -0.1708165
   0.          0.        ]]. Action = [[0.17346406 0.866186  ]]. Reward = [-3.837644]
Abstract state at timestep 867 is 6
State prediction error at timestep 867 is 0.012
Human Feedback received at timestpe 867 of -10
Current timestep = 868. State = [[ 0.8680506   1.3189864   1.6243597  -0.47335455 -0.76211256 -0.17081568
   0.          0.        ]]. Action = [[-0.84490865 -0.12996733]]. Reward = [-1.5757124]
Abstract state at timestep 868 is 6
State prediction error at timestep 868 is 0.012
Human Feedback received at timestpe 868 of -10
Current timestep = 869. State = [[ 0.8842615   1.3077738   1.6282752  -0.5029526  -0.7719849  -0.19744574
   0.          0.        ]]. Action = [[-0.1812259  0.6640625]]. Reward = [-2.1999087]
Abstract state at timestep 869 is 6
State prediction error at timestep 869 is 0.012
Human Feedback received at timestpe 869 of -10
Current timestep = 870. State = [[ 0.9004223   1.2960443   1.6216376  -0.5249494  -0.779674   -0.15378289
   0.          0.        ]]. Action = [[-0.7287253  -0.84991956]]. Reward = [-0.7710535]
Abstract state at timestep 870 is 6
State prediction error at timestep 870 is 0.012
Human Feedback received at timestpe 870 of -10
Current timestep = 871. State = [[ 0.9165834   1.2837154   1.6216322  -0.55161965 -0.7873631  -0.15378225
   0.          0.        ]]. Action = [[-0.11783624 -0.01479512]]. Reward = [-1.5312375]
Abstract state at timestep 871 is 6
State prediction error at timestep 871 is 0.012
Human Feedback received at timestpe 871 of -10
Current timestep = 872. State = [[ 0.9327761   1.2707318   1.6257524  -0.58142585 -0.7964744  -0.18222718
   0.          0.        ]]. Action = [[-0.5904313  0.5740508]]. Reward = [-2.1971493]
Abstract state at timestep 872 is 6
State prediction error at timestep 872 is 0.012
Human Feedback received at timestpe 872 of -10
Current timestep = 873. State = [[ 0.9492426   1.2576456   1.6521218  -0.5853691  -0.80424356 -0.15538327
   0.          0.        ]]. Action = [[ 0.2857877 -0.5950826]]. Reward = [-3.537593]
Abstract state at timestep 873 is 6
State prediction error at timestep 873 is 0.012
Human Feedback received at timestpe 873 of -10
Current timestep = 874. State = [[ 0.9657091   1.2439601   1.6521162  -0.61203927 -0.8120127  -0.15538268
   0.          0.        ]]. Action = [[-0.96541727  0.02643073]]. Reward = [-1.5992366]
Abstract state at timestep 874 is 6
State prediction error at timestep 874 is 0.012
Human Feedback received at timestpe 874 of -10
Current timestep = 875. State = [[ 0.9825144   1.2300835   1.6867297  -0.6211349  -0.8209603  -0.17895392
   0.          0.        ]]. Action = [[0.47169423 0.5140873 ]]. Reward = [-4.6424994]
Abstract state at timestep 875 is 6
State prediction error at timestep 875 is 0.012
Human Feedback received at timestpe 875 of -10
Current timestep = 876. State = [[ 0.9993202   1.2156078   1.6867222  -0.6478062  -0.829908   -0.17895295
   0.          0.        ]]. Action = [[-0.97184336  0.18854117]]. Reward = [-1.7664642]
Abstract state at timestep 876 is 6
State prediction error at timestep 876 is 0.012
Human Feedback received at timestpe 876 of -10
Current timestep = 877. State = [[-0.00161657  1.4097692  -0.16376449 -0.0511573   0.00188007  0.0370951
   0.          0.        ]]. Action = [[0.54026175 0.5001869 ]]. Reward = [-100.]
Abstract state at timestep 877 is 6
State prediction error at timestep 877 is 0.012
Human Feedback received at timestpe 877 of -10
Current timestep = 878. State = [[-0.00341244  1.408742   -0.18242298 -0.04566468  0.00468465  0.05609738
   0.          0.        ]]. Action = [[ 0.6668854 -0.651292 ]]. Reward = [-2.095899]
Abstract state at timestep 878 is 3
State prediction error at timestep 878 is 0.012
Human Feedback received at timestpe 878 of -10
Current timestep = 879. State = [[-0.00511169  1.4082862  -0.17121069 -0.0202625   0.00595755  0.0254604
   0.          0.        ]]. Action = [[0.6416726 0.8095763]]. Reward = [1.2118402]
Abstract state at timestep 879 is 3
State prediction error at timestep 879 is 0.012
Human Feedback received at timestpe 879 of -10
Current timestep = 880. State = [[-0.00670891  1.4078658  -0.16151133 -0.01869373  0.00773278  0.03550772
   0.          0.        ]]. Action = [[0.3342762  0.18143463]]. Reward = [0.6453049]
Abstract state at timestep 880 is 3
State prediction error at timestep 880 is 0.012
Human Feedback received at timestpe 880 of -10
Current timestep = 881. State = [[-0.00830603  1.4068453  -0.1615169  -0.04536265  0.00950701  0.0354882
   0.          0.        ]]. Action = [[-0.1655057 -0.2590834]]. Reward = [-0.59389603]
Abstract state at timestep 881 is 3
State prediction error at timestep 881 is 0.012
Human Feedback received at timestpe 881 of -10
Current timestep = 882. State = [[-0.00981979  1.4052193  -0.15104668 -0.07226416  0.00918167 -0.00650731
   0.          0.        ]]. Action = [[-0.93729013  0.97195864]]. Reward = [0.19730164]
Abstract state at timestep 882 is 3
State prediction error at timestep 882 is 0.012
Human Feedback received at timestpe 882 of -10
Current timestep = 883. State = [[-0.01133347  1.4029933  -0.15104523 -0.09893237  0.0088573  -0.0064879
   0.          0.        ]]. Action = [[-0.29119146  0.4045037 ]]. Reward = [-1.0578929]
Abstract state at timestep 883 is 3
State prediction error at timestep 883 is 0.012
Human Feedback received at timestpe 883 of -10
Current timestep = 884. State = [[-0.01284723  1.4001673  -0.15104422 -0.12560074  0.00853253 -0.00649605
   0.          0.        ]]. Action = [[-0.5332578  0.090837 ]]. Reward = [-1.2744545]
Abstract state at timestep 884 is 3
State prediction error at timestep 884 is 0.012
Human Feedback received at timestpe 884 of -10
Current timestep = 885. State = [[-0.01443968  1.3967466  -0.16092753 -0.15203384  0.01018855  0.03312334
   0.          0.        ]]. Action = [[-0.5706095 -0.8108663]]. Reward = [-2.3437645]
Abstract state at timestep 885 is 3
State prediction error at timestep 885 is 0.012
Human Feedback received at timestpe 885 of -10
Current timestep = 886. State = [[-0.01597414  1.3927329  -0.1536509  -0.17839731  0.01038257  0.00388134
   0.          0.        ]]. Action = [[-0.6812011   0.67253196]]. Reward = [-1.0457114]
Abstract state at timestep 886 is 3
State prediction error at timestep 886 is 0.012
Human Feedback received at timestpe 886 of -10
Current timestep = 887. State = [[-0.01766539  1.38924    -0.1686112  -0.15523593  0.00987111 -0.01023024
   0.          0.        ]]. Action = [[ 0.80535185 -0.4437071 ]]. Reward = [0.75304216]
Abstract state at timestep 887 is 3
State prediction error at timestep 887 is 0.012
Human Feedback received at timestpe 887 of -10
Current timestep = 888. State = [[-0.01927442  1.3851527  -0.15828826 -0.1816477   0.00729035 -0.05162007
   0.          0.        ]]. Action = [[-0.07126111  0.9952979 ]]. Reward = [-0.5400364]
Abstract state at timestep 888 is 3
State prediction error at timestep 888 is 0.012
Human Feedback received at timestpe 888 of -10
Current timestep = 889. State = [[-0.02093334  1.3804629  -0.1645563  -0.20843175  0.00596868 -0.0264356
   0.          0.        ]]. Action = [[-0.64238757 -0.62653923]]. Reward = [-1.8824098]
Abstract state at timestep 889 is 3
State prediction error at timestep 889 is 0.012
Human Feedback received at timestpe 889 of -10
Current timestep = 890. State = [[-0.02256117  1.3760502  -0.160324   -0.19610505  0.00353916 -0.04859513
   0.          0.        ]]. Action = [[0.9703412 0.5453553]]. Reward = [1.595755]
Abstract state at timestep 890 is 3
State prediction error at timestep 890 is 0.012
Human Feedback received at timestpe 890 of -10
Current timestep = 891. State = [[-2.4257373e-02  1.3716933e+00 -1.6684546e-01 -1.9363873e-01
   7.9537020e-04 -5.4880779e-02  0.0000000e+00  0.0000000e+00]]. Action = [[ 0.87294006 -0.4946915 ]]. Reward = [0.19580218]
Abstract state at timestep 891 is 3
State prediction error at timestep 891 is 0.012
Human Feedback received at timestpe 891 of -10
Current timestep = 892. State = [[-0.02590504  1.3667288  -0.16076872 -0.22064155 -0.00316405 -0.07919532
   0.          0.        ]]. Action = [[-0.18217933  0.7413788 ]]. Reward = [-1.505425]
Abstract state at timestep 892 is 3
State prediction error at timestep 892 is 0.012
Human Feedback received at timestpe 892 of -10
Current timestep = 893. State = [[-0.02756872  1.3618894  -0.16097511 -0.21511003 -0.00850452 -0.10681897
   0.          0.        ]]. Action = [[0.01787066 0.66037965]]. Reward = [0.20677613]
Abstract state at timestep 893 is 3
State prediction error at timestep 893 is 0.012
Human Feedback received at timestpe 893 of -10
Current timestep = 894. State = [[-0.02910252  1.3572531  -0.14696515 -0.20610218 -0.0148413  -0.12674698
   0.          0.        ]]. Action = [[0.02470183 0.5641594 ]]. Reward = [1.2099402]
Abstract state at timestep 894 is 3
State prediction error at timestep 894 is 0.012
Human Feedback received at timestpe 894 of -10
Current timestep = 895. State = [[-0.03063602  1.3520174  -0.14694698 -0.23277755 -0.02117719 -0.12672935
   0.          0.        ]]. Action = [[-0.191347   -0.25697613]]. Reward = [-2.3280709]
Abstract state at timestep 895 is 3
State prediction error at timestep 895 is 0.012
Human Feedback received at timestpe 895 of -10
Current timestep = 896. State = [[-0.03222246  1.3461798  -0.15357563 -0.25952473 -0.02618146 -0.1000946
   0.          0.        ]]. Action = [[-0.34297097 -0.8106737 ]]. Reward = [-2.57291]
Abstract state at timestep 896 is 3
State prediction error at timestep 896 is 0.012
Human Feedback received at timestpe 896 of -10
Current timestep = 897. State = [[-0.03385229  1.3405802  -0.15907624 -0.24894714 -0.03005642 -0.07750592
   0.          0.        ]]. Action = [[ 0.681811  -0.5842132]]. Reward = [0.5113346]
Abstract state at timestep 897 is 3
State prediction error at timestep 897 is 0.012
Human Feedback received at timestpe 897 of -10
Current timestep = 898. State = [[-0.03532753  1.3349055  -0.14281264 -0.25231323 -0.0347114  -0.09310796
   0.          0.        ]]. Action = [[0.7372296  0.53532684]]. Reward = [0.37184465]
Abstract state at timestep 898 is 3
State prediction error at timestep 898 is 0.012
Human Feedback received at timestpe 898 of -10
Current timestep = 899. State = [[-0.03680258  1.3286309  -0.14279929 -0.2789852  -0.03936537 -0.09308767
   0.          0.        ]]. Action = [[-0.7815238   0.09421408]]. Reward = [-2.1902678]
Abstract state at timestep 899 is 3
State prediction error at timestep 899 is 0.012
Human Feedback received at timestpe 899 of -10
Current timestep = 900. State = [[-0.03834524  1.3223048  -0.15099107 -0.28124472 -0.04261182 -0.06493478
   0.          0.        ]]. Action = [[ 0.19214845 -0.7225364 ]]. Reward = [-0.47769204]
Abstract state at timestep 900 is 3
State prediction error at timestep 900 is 0.012
Human Feedback received at timestpe 900 of -10
Current timestep = 901. State = [[-0.04004812  1.3158774  -0.16843157 -0.285719   -0.04444916 -0.03674983
   0.          0.        ]]. Action = [[ 0.6550269 -0.8079358]]. Reward = [-1.0644642]
Abstract state at timestep 901 is 3
State prediction error at timestep 901 is 0.012
Human Feedback received at timestpe 901 of -10
Current timestep = 902. State = [[-0.04170198  1.3088307  -0.16226956 -0.31327927 -0.0475296  -0.06160891
   0.          0.        ]]. Action = [[-0.96780586  0.54555786]]. Reward = [-1.739358]
Abstract state at timestep 902 is 3
State prediction error at timestep 902 is 0.012
Human Feedback received at timestpe 902 of -10
Current timestep = 903. State = [[-0.04335584  1.3011842  -0.16226962 -0.3399468  -0.05061006 -0.0616089
   0.          0.        ]]. Action = [[-0.3056832 -0.043814 ]]. Reward = [-1.9371153]
Abstract state at timestep 903 is 3
State prediction error at timestep 903 is 0.012
Human Feedback received at timestpe 903 of -10
Current timestep = 904. State = [[-0.04500971  1.2929379  -0.16226968 -0.36661428 -0.0536905  -0.06160886
   0.          0.        ]]. Action = [[-0.4726925 -0.1964069]]. Reward = [-1.9126112]
Abstract state at timestep 904 is 3
State prediction error at timestep 904 is 0.012
Human Feedback received at timestpe 904 of -10
Current timestep = 905. State = [[-0.04666347  1.2840916  -0.16226974 -0.39328176 -0.05677095 -0.06160882
   0.          0.        ]]. Action = [[-0.3964367  0.09428  ]]. Reward = [-1.8821061]
Abstract state at timestep 905 is 3
State prediction error at timestep 905 is 0.012
Human Feedback received at timestpe 905 of -10
Current timestep = 906. State = [[-0.04833946  1.2758505  -0.16416076 -0.36639902 -0.06016435 -0.06786837
   0.          0.        ]]. Action = [[0.6479609  0.26002097]]. Reward = [2.6257691]
Abstract state at timestep 906 is 3
State prediction error at timestep 906 is 0.012
Human Feedback received at timestpe 906 of -10
Current timestep = 907. State = [[-0.04996014  1.2669954  -0.15721337 -0.3937667  -0.06496255 -0.09596373
   0.          0.        ]]. Action = [[-0.14593291  0.7845838 ]]. Reward = [-1.874503]
Abstract state at timestep 907 is 3
State prediction error at timestep 907 is 0.012
Human Feedback received at timestpe 907 of -10
Current timestep = 908. State = [[-0.05149202  1.2583832  -0.14858195 -0.38297138 -0.06951985 -0.09114598
   0.          0.        ]]. Action = [[ 0.2510984  -0.42747724]]. Reward = [1.5316513]
Abstract state at timestep 908 is 3
State prediction error at timestep 908 is 0.012
Human Feedback received at timestpe 908 of -10
Current timestep = 909. State = [[-0.05302391  1.2491713  -0.14858213 -0.40963984 -0.07407714 -0.09114581
   0.          0.        ]]. Action = [[-0.93151915 -0.248559  ]]. Reward = [-2.0386822]
Abstract state at timestep 909 is 3
State prediction error at timestep 909 is 0.012
Human Feedback received at timestpe 909 of -10
Current timestep = 910. State = [[-0.05451727  1.2405187  -0.14464274 -0.38479963 -0.07872143 -0.09288568
   0.          0.        ]]. Action = [[ 0.65107393 -0.41241384]]. Reward = [2.6126363]
Abstract state at timestep 910 is 3
State prediction error at timestep 910 is 0.012
Human Feedback received at timestpe 910 of -10
Current timestep = 911. State = [[-0.05601435  1.2317219  -0.14488786 -0.39123052 -0.08349349 -0.09544136
   0.          0.        ]]. Action = [[ 0.2492224  -0.12591517]]. Reward = [-0.40356138]
Abstract state at timestep 911 is 3
State prediction error at timestep 911 is 0.012
Human Feedback received at timestpe 911 of -10
Current timestep = 912. State = [[-0.05751143  1.2223253  -0.14488812 -0.41789907 -0.08826555 -0.09544122
   0.          0.        ]]. Action = [[-0.97564   -0.3393858]]. Reward = [-2.0560398]
Abstract state at timestep 912 is 3
State prediction error at timestep 912 is 0.012
Human Feedback received at timestpe 912 of -10
Current timestep = 913. State = [[-0.05906677  1.2130547  -0.15224463 -0.41221973 -0.09152923 -0.06527352
   0.          0.        ]]. Action = [[ 0.07839537 -0.76892203]]. Reward = [0.6941448]
Abstract state at timestep 913 is 3
State prediction error at timestep 913 is 0.012
Human Feedback received at timestpe 913 of -10
Current timestep = 914. State = [[-0.06062222  1.2031845  -0.15224475 -0.43888733 -0.0947929  -0.06527348
   0.          0.        ]]. Action = [[-0.15581977  0.07786858]]. Reward = [-1.8590374]
Abstract state at timestep 914 is 3
State prediction error at timestep 914 is 0.012
Human Feedback received at timestpe 914 of -10
Current timestep = 915. State = [[-0.06213589  1.1927037  -0.14700948 -0.4660931  -0.09911961 -0.08653434
   0.          0.        ]]. Action = [[-0.82583207  0.6488712 ]]. Reward = [-1.8315881]
Abstract state at timestep 915 is 3
State prediction error at timestep 915 is 0.012
Human Feedback received at timestpe 915 of -10
Current timestep = 916. State = [[-0.06364956  1.1816232  -0.1470097  -0.49276134 -0.10344633 -0.08653428
   0.          0.        ]]. Action = [[-0.5210643  -0.33583724]]. Reward = [-1.8837675]
Abstract state at timestep 916 is 3
State prediction error at timestep 916 is 0.012
Human Feedback received at timestpe 916 of -10
Current timestep = 917. State = [[-0.06516619  1.1712298  -0.14862059 -0.46213853 -0.10646315 -0.06033617
   0.          0.        ]]. Action = [[ 0.8211838 -0.6983514]]. Reward = [3.3111782]
Abstract state at timestep 917 is 3
State prediction error at timestep 917 is 0.012
Human Feedback received at timestpe 917 of -10
Current timestep = 918. State = [[-0.06668282  1.1602366  -0.1486207  -0.48880592 -0.10947994 -0.06033612
   0.          0.        ]]. Action = [[-0.89818347  0.12506914]]. Reward = [-1.7578951]
Abstract state at timestep 918 is 3
State prediction error at timestep 918 is 0.012
Human Feedback received at timestpe 918 of -10
Current timestep = 919. State = [[-0.06813498  1.1500292  -0.14346668 -0.453787   -0.11121529 -0.03470687
   0.          0.        ]]. Action = [[ 0.863273   -0.62494725]]. Reward = [4.036249]
Abstract state at timestep 919 is 3
State prediction error at timestep 919 is 0.012
Human Feedback received at timestpe 919 of -10
Current timestep = 920. State = [[-0.0696785   1.140416   -0.15380475 -0.42729285 -0.11175467 -0.01078748
   0.          0.        ]]. Action = [[ 0.7024832 -0.7263957]]. Reward = [2.798673]
Abstract state at timestep 920 is 3
State prediction error at timestep 920 is 0.012
Human Feedback received at timestpe 920 of -10
Current timestep = 921. State = [[-0.07117061  1.1301906  -0.14734821 -0.45460615 -0.11360627 -0.03703224
   0.          0.        ]]. Action = [[-0.8145191  0.6815803]]. Reward = [-1.5700867]
Abstract state at timestep 921 is 3
State prediction error at timestep 921 is 0.012
Human Feedback received at timestpe 921 of -10
Current timestep = 922. State = [[-0.0725337   1.1207232  -0.1328617  -0.421038   -0.11702222 -0.06831922
   0.          0.        ]]. Action = [[0.80627084 0.7491467 ]]. Reward = [3.9397218]
Abstract state at timestep 922 is 3
State prediction error at timestep 922 is 0.012
Human Feedback received at timestpe 922 of -10
Current timestep = 923. State = [[-0.07379751  1.111402   -0.12134628 -0.41468152 -0.12203577 -0.10027087
   0.          0.        ]]. Action = [[0.41972685 0.7849951 ]]. Reward = [1.1271906]
Abstract state at timestep 923 is 3
State prediction error at timestep 923 is 0.012
Human Feedback received at timestpe 923 of -10
Current timestep = 924. State = [[-0.07512818  1.1025568  -0.12898716 -0.3934539  -0.12608744 -0.08103307
   0.          0.        ]]. Action = [[ 0.34886122 -0.5896032 ]]. Reward = [2.0497894]
Abstract state at timestep 924 is 3
State prediction error at timestep 924 is 0.012
Human Feedback received at timestpe 924 of -10
Current timestep = 925. State = [[-0.07657423  1.0941008  -0.14221165 -0.3760305  -0.12847361 -0.04772327
   0.          0.        ]]. Action = [[ 0.873744  -0.9389544]]. Reward = [1.489164]
Abstract state at timestep 925 is 3
State prediction error at timestep 925 is 0.012
Human Feedback received at timestpe 925 of -10
Current timestep = 926. State = [[-0.07785358  1.0857861  -0.12601063 -0.36970899 -0.13038774 -0.0382826
   0.          0.        ]]. Action = [[0.34035254 0.39931726]]. Reward = [1.5708935]
Abstract state at timestep 926 is 3
State prediction error at timestep 926 is 0.012
Human Feedback received at timestpe 926 of -10
Current timestep = 927. State = [[-0.07906084  1.0768648  -0.11698663 -0.39683864 -0.13411638 -0.07457289
   0.          0.        ]]. Action = [[-0.4122597  0.9115062]]. Reward = [-1.8321009]
Abstract state at timestep 927 is 3
State prediction error at timestep 927 is 0.012
Human Feedback received at timestpe 927 of -10
Current timestep = 928. State = [[-0.08030987  1.0673525  -0.12222134 -0.42301092 -0.13678108 -0.05329444
   0.          0.        ]]. Action = [[-0.27020591 -0.5123943 ]]. Reward = [-2.0015635]
Abstract state at timestep 928 is 3
State prediction error at timestep 928 is 0.012
Human Feedback received at timestpe 928 of -10
Current timestep = 929. State = [[-0.08160248  1.0572518  -0.1277134  -0.44905898 -0.13832429 -0.0308643
   0.          0.        ]]. Action = [[-0.8090671  -0.50400436]]. Reward = [-1.8274156]
Abstract state at timestep 929 is 3
State prediction error at timestep 929 is 0.012
Human Feedback received at timestpe 929 of -10
Current timestep = 930. State = [[-0.08277626  1.0474269  -0.11600894 -0.43679574 -0.13969578 -0.02742965
   0.          0.        ]]. Action = [[0.46157312 0.41323447]]. Reward = [2.1067984]
Abstract state at timestep 930 is 3
State prediction error at timestep 930 is 0.012
Human Feedback received at timestpe 930 of -10
Current timestep = 931. State = [[-0.08395014  1.037002   -0.11600897 -0.46346256 -0.14106727 -0.02742964
   0.          0.        ]]. Action = [[-0.9915035  0.290493 ]]. Reward = [-1.6895646]
Abstract state at timestep 931 is 3
State prediction error at timestep 931 is 0.012
Human Feedback received at timestpe 931 of -10
Current timestep = 932. State = [[-0.08510084  1.0268854  -0.11341293 -0.44978246 -0.14272714 -0.03319745
   0.          0.        ]]. Action = [[ 0.16225672 -0.04859072]]. Reward = [2.048597]
Abstract state at timestep 932 is 3
State prediction error at timestep 932 is 0.012
Human Feedback received at timestpe 932 of -10
Current timestep = 933. State = [[-0.08625164  1.0161688  -0.11341298 -0.47644937 -0.144387   -0.03319742
   0.          0.        ]]. Action = [[-0.87364084 -0.45286238]]. Reward = [-1.6977979]
Abstract state at timestep 933 is 3
State prediction error at timestep 933 is 0.012
Human Feedback received at timestpe 933 of -10
Current timestep = 934. State = [[-0.08724108  1.0058708  -0.09865768 -0.45771286 -0.14467108 -0.00568147
   0.          0.        ]]. Action = [[ 0.5855577 -0.5541181]]. Reward = [2.8883963]
Abstract state at timestep 934 is 3
State prediction error at timestep 934 is 0.012
Human Feedback received at timestpe 934 of -10
Current timestep = 935. State = [[-0.08816004  0.9949614  -0.08982687 -0.48507178 -0.14674287 -0.04143527
   0.          0.        ]]. Action = [[-0.5361392  0.9220178]]. Reward = [-1.6654936]
Abstract state at timestep 935 is 3
State prediction error at timestep 935 is 0.012
Human Feedback received at timestpe 935 of -10
Current timestep = 936. State = [[-0.0890791   0.9834519  -0.08982693 -0.51173884 -0.14881463 -0.04143526
   0.          0.        ]]. Action = [[-0.8571727   0.36575007]]. Reward = [-1.6934173]
Abstract state at timestep 936 is 4
State prediction error at timestep 936 is 0.012
Human Feedback received at timestpe 936 of -10
Current timestep = 937. State = [[-0.08999815  0.9713425  -0.08982702 -0.5384058  -0.15088642 -0.04143523
   0.          0.        ]]. Action = [[-9.7965240e-02  3.2782555e-05]]. Reward = [-1.6381576]
Abstract state at timestep 937 is 4
State prediction error at timestep 937 is 0.012
Human Feedback received at timestpe 937 of -10
Current timestep = 938. State = [[-0.09091711  0.9586331  -0.08982709 -0.56507283 -0.1529582  -0.04143522
   0.          0.        ]]. Action = [[-0.98946726  0.03888571]]. Reward = [-1.5823948]
Abstract state at timestep 938 is 4
State prediction error at timestep 938 is 0.012
Human Feedback received at timestpe 938 of -10
Current timestep = 939. State = [[-0.09183617  0.94532377 -0.08982717 -0.59173983 -0.15502997 -0.04143523
   0.          0.        ]]. Action = [[-0.31304836 -0.03090715]]. Reward = [-1.5262138]
Abstract state at timestep 939 is 4
State prediction error at timestep 939 is 0.012
Human Feedback received at timestpe 939 of -10
Current timestep = 940. State = [[-0.09271012  0.9321423  -0.08517755 -0.5860725  -0.15724237 -0.04424768
   0.          0.        ]]. Action = [[ 0.59173465 -0.35570097]]. Reward = [1.4721872]
Abstract state at timestep 940 is 4
State prediction error at timestep 940 is 0.012
Human Feedback received at timestpe 940 of -10
Current timestep = 941. State = [[-0.09353723  0.91834944 -0.07929636 -0.6133864  -0.16065632 -0.06827908
   0.          0.        ]]. Action = [[-0.62955874  0.50279486]]. Reward = [-1.6185029]
Abstract state at timestep 941 is 4
State prediction error at timestep 941 is 0.012
Human Feedback received at timestpe 941 of -10
Current timestep = 942. State = [[-0.09416561  0.9047174  -0.05996173 -0.6061786  -0.16353858 -0.05764528
   0.          0.        ]]. Action = [[0.6771555 0.2890241]]. Reward = [1.7451743]
Abstract state at timestep 942 is 4
State prediction error at timestep 942 is 0.012
Human Feedback received at timestpe 942 of -10
Current timestep = 943. State = [[-0.09479399  0.8904855  -0.0599619  -0.632846   -0.16642085 -0.05764526
   0.          0.        ]]. Action = [[-0.33325195  0.06915569]]. Reward = [-1.5337702]
Abstract state at timestep 943 is 4
State prediction error at timestep 943 is 0.012
Human Feedback received at timestpe 943 of -10
Current timestep = 944. State = [[-0.09541778  0.87648124 -0.05910088 -0.6227866  -0.16970493 -0.06568177
   0.          0.        ]]. Action = [[ 0.77673364 -0.4328289 ]]. Reward = [1.8003656]
Abstract state at timestep 944 is 4
State prediction error at timestep 944 is 0.012
Human Feedback received at timestpe 944 of -10
Current timestep = 945. State = [[-0.09597969  0.8618677  -0.05134336 -0.6500505  -0.17455827 -0.09706686
   0.          0.        ]]. Action = [[-0.43885756  0.86710835]]. Reward = [-1.7139697]
Abstract state at timestep 945 is 4
State prediction error at timestep 945 is 0.012
Human Feedback received at timestpe 945 of -10
Current timestep = 946. State = [[-0.09659395  0.846677   -0.05796815 -0.67555845 -0.17802887 -0.06941172
   0.          0.        ]]. Action = [[-0.80016977 -0.7751728 ]]. Reward = [-1.4642735]
Abstract state at timestep 946 is 4
State prediction error at timestep 946 is 0.012
Human Feedback received at timestpe 946 of -10
Current timestep = 947. State = [[-0.09720822  0.8308863  -0.05796842 -0.70222604 -0.18149945 -0.06941166
   0.          0.        ]]. Action = [[-0.04336137 -0.4200771 ]]. Reward = [-1.4428393]
Abstract state at timestep 947 is 4
State prediction error at timestep 947 is 0.012
Human Feedback received at timestpe 947 of -10
Current timestep = 948. State = [[-0.09782238  0.81449574 -0.05796868 -0.72889364 -0.18497005 -0.06941159
   0.          0.        ]]. Action = [[-0.20253849 -0.04554236]]. Reward = [-1.3846847]
Abstract state at timestep 948 is 4
State prediction error at timestep 948 is 0.012
Human Feedback received at timestpe 948 of -10
Current timestep = 949. State = [[-0.09838762  0.7974917  -0.05180743 -0.75633514 -0.1897073  -0.09474494
   0.          0.        ]]. Action = [[-0.92423826  0.59956586]]. Reward = [-1.5018214]
Abstract state at timestep 949 is 4
State prediction error at timestep 949 is 0.012
Human Feedback received at timestpe 949 of -10
Current timestep = 950. State = [[-0.09901476  0.7799123  -0.05963274 -0.7817015  -0.19281274 -0.06210873
   0.          0.        ]]. Action = [[-0.38746977 -0.768189  ]]. Reward = [-1.1835845]
Abstract state at timestep 950 is 4
State prediction error at timestep 950 is 0.012
Human Feedback received at timestpe 950 of -10
Current timestep = 951. State = [[-0.09958696  0.76259726 -0.05387559 -0.76999956 -0.19617927 -0.06733096
   0.          0.        ]]. Action = [[0.7042017  0.22140479]]. Reward = [2.3268108]
Abstract state at timestep 951 is 4
State prediction error at timestep 951 is 0.012
Human Feedback received at timestpe 951 of -10
Current timestep = 952. State = [[-0.10010042  0.74467266 -0.04652127 -0.79729766 -0.20103677 -0.09714948
   0.          0.        ]]. Action = [[-0.18568718  0.85782504]]. Reward = [-1.4184661]
Abstract state at timestep 952 is 4
State prediction error at timestep 952 is 0.012
Human Feedback received at timestpe 952 of -10
Current timestep = 953. State = [[-0.10042353  0.72682256 -0.0279367  -0.79394    -0.20544699 -0.08820444
   0.          0.        ]]. Action = [[0.42021132 0.17878878]]. Reward = [1.5324752]
Abstract state at timestep 953 is 4
State prediction error at timestep 953 is 0.012
Human Feedback received at timestpe 953 of -10
Current timestep = 954. State = [[-0.10074663  0.70837253 -0.02793719 -0.8206082  -0.20985721 -0.08820431
   0.          0.        ]]. Action = [[-0.5779477   0.36622643]]. Reward = [-1.2835932]
Abstract state at timestep 954 is 4
State prediction error at timestep 954 is 0.012
Human Feedback received at timestpe 954 of -10
Current timestep = 955. State = [[-0.10093145  0.6900613  -0.01427062 -0.8144386  -0.2141168  -0.08519161
   0.          0.        ]]. Action = [[0.04901934 0.28349924]]. Reward = [1.8784263]
Abstract state at timestep 955 is 4
State prediction error at timestep 955 is 0.012
Human Feedback received at timestpe 955 of -10
Current timestep = 956. State = [[-0.10111942  0.67153543 -0.0164923  -0.82370484 -0.21644919 -0.04664761
   0.          0.        ]]. Action = [[ 0.21766222 -0.9590584 ]]. Reward = [0.45445877]
Abstract state at timestep 956 is 4
State prediction error at timestep 956 is 0.012
Human Feedback received at timestpe 956 of -10
Current timestep = 957. State = [[-0.1012971   0.6532032  -0.01727667 -0.8148444  -0.21694437 -0.0099041
   0.          0.        ]]. Action = [[ 0.6685538  -0.93396616]]. Reward = [2.3659236]
Abstract state at timestep 957 is 4
State prediction error at timestep 957 is 0.012
Human Feedback received at timestpe 957 of -10
Current timestep = 958. State = [[-0.10132112  0.63490534 -0.00218162 -0.81326896 -0.21716677 -0.00444818
   0.          0.        ]]. Action = [[0.70705223 0.38523078]]. Reward = [1.7044481]
Abstract state at timestep 958 is 4
State prediction error at timestep 958 is 0.012
Human Feedback received at timestpe 958 of -10
Current timestep = 959. State = [[-0.10147409  0.61652154 -0.01675177 -0.81684035 -0.21568748  0.02958563
   0.          0.        ]]. Action = [[ 0.37350297 -0.90368253]]. Reward = [1.3530246]
Abstract state at timestep 959 is 4
State prediction error at timestep 959 is 0.012
Human Feedback received at timestpe 959 of -10
Current timestep = 960. State = [[-0.10152607  0.59811044 -0.00673794 -0.81804717 -0.21413022  0.03114524
   0.          0.        ]]. Action = [[0.36954474 0.19631457]]. Reward = [1.6590792]
Abstract state at timestep 960 is 4
State prediction error at timestep 960 is 0.012
Human Feedback received at timestpe 960 of -10
Current timestep = 961. State = [[-0.10157814  0.57909936 -0.00673801 -0.84471405 -0.21257295  0.03114524
   0.          0.        ]]. Action = [[-0.2643276  -0.05145156]]. Reward = [-0.6383384]
Abstract state at timestep 961 is 4
State prediction error at timestep 961 is 0.012
Human Feedback received at timestpe 961 of -10
Current timestep = 962. State = [[-0.10163011  0.5594883  -0.00673807 -0.8713809  -0.21101569  0.03114522
   0.          0.        ]]. Action = [[-0.29849374 -0.04426306]]. Reward = [-0.58120036]
Abstract state at timestep 962 is 4
State prediction error at timestep 962 is 0.012
Human Feedback received at timestpe 962 of -10
Current timestep = 963. State = [[-0.10168209  0.5392773  -0.00673814 -0.89804775 -0.20945843  0.03114521
   0.          0.        ]]. Action = [[-0.6639882  -0.39157444]]. Reward = [-0.5244744]
Abstract state at timestep 963 is 4
State prediction error at timestep 963 is 0.012
Human Feedback received at timestpe 963 of -10
Current timestep = 964. State = [[-0.10179768  0.51847947 -0.01471296 -0.9239045  -0.20627546  0.06365894
   0.          0.        ]]. Action = [[-0.8403208  -0.69280136]]. Reward = [-0.25720498]
Abstract state at timestep 964 is 4
State prediction error at timestep 964 is 0.012
Human Feedback received at timestpe 964 of -10
Current timestep = 965. State = [[-0.10177326  0.4976118  -0.00228945 -0.92679906 -0.20150417  0.09542595
   0.          0.        ]]. Action = [[ 0.6939218  -0.65935105]]. Reward = [1.971802]
Abstract state at timestep 965 is 4
State prediction error at timestep 965 is 0.012
Human Feedback received at timestpe 965 of -10
Current timestep = 966. State = [[-0.10152302  0.4766782   0.02163277 -0.92992437 -0.19808686  0.06834637
   0.          0.        ]]. Action = [[0.9704609 0.7717502]]. Reward = [1.7399213]
Abstract state at timestep 966 is 5
State prediction error at timestep 966 is 0.012
Human Feedback received at timestpe 966 of 10
Current timestep = 967. State = [[-0.1013298   0.4551654   0.01443807 -0.9554792  -0.19317414  0.09825461
   0.          0.        ]]. Action = [[-0.49282944 -0.646887  ]]. Reward = [0.03677662]
Abstract state at timestep 967 is 5
State prediction error at timestep 967 is 0.012
Human Feedback received at timestpe 967 of 10
Current timestep = 968. State = [[-0.1010706   0.43303972  0.0227093  -0.98295003 -0.18994525  0.06457767
   0.          0.        ]]. Action = [[-0.39474386  0.6930764 ]]. Reward = [-0.2973152]
Abstract state at timestep 968 is 5
State prediction error at timestep 968 is 0.012
Human Feedback received at timestpe 968 of 10
Current timestep = 969. State = [[-0.10081148  0.4103141   0.02270905 -1.0096174  -0.18671638  0.06457759
   0.          0.        ]]. Action = [[-0.10318941 -0.07366562]]. Reward = [-0.12705186]
Abstract state at timestep 969 is 5
State prediction error at timestep 969 is 0.012
Human Feedback received at timestpe 969 of 10
Current timestep = 970. State = [[-0.10050936  0.3869816   0.02807482 -1.0367334  -0.18457483  0.04283108
   0.          0.        ]]. Action = [[-0.82119995  0.6020496 ]]. Reward = [-0.25837874]
Abstract state at timestep 970 is 5
State prediction error at timestep 970 is 0.012
Human Feedback received at timestpe 970 of 10
Current timestep = 971. State = [[-0.10027333  0.36307004  0.01976065 -1.0622641  -0.18071769  0.07714274
   0.          0.        ]]. Action = [[-0.21889788 -0.70521474]]. Reward = [0.14698735]
Abstract state at timestep 971 is 5
State prediction error at timestep 971 is 0.012
Human Feedback received at timestpe 971 of 10
Current timestep = 972. State = [[-0.10003729  0.33855873  0.01976031 -1.088932   -0.17686056  0.07714266
   0.          0.        ]]. Action = [[-0.25262064 -0.20327741]]. Reward = [0.08271112]
Abstract state at timestep 972 is 5
State prediction error at timestep 972 is 0.012
Human Feedback received at timestpe 972 of 10
Current timestep = 973. State = [[-0.09984283  0.31345454  0.01454177 -1.1151626  -0.17194569  0.09829725
   0.          0.        ]]. Action = [[-0.8562513 -0.6612668]]. Reward = [0.2627686]
Abstract state at timestep 973 is 5
State prediction error at timestep 973 is 0.012
Human Feedback received at timestpe 973 of 10
Current timestep = 974. State = [[-0.09953461  0.28822598  0.02705203 -1.1208397  -0.16817674  0.07537941
   0.          0.        ]]. Action = [[0.8378346 0.585263 ]]. Reward = [1.8971198]
Abstract state at timestep 974 is 5
State prediction error at timestep 974 is 0.012
Human Feedback received at timestpe 974 of 10
Current timestep = 975. State = [[-0.0991807   0.26238844  0.03278574 -1.148042   -0.16557367  0.05206145
   0.          0.        ]]. Action = [[-0.723224   0.6093693]]. Reward = [-0.05027514]
Abstract state at timestep 975 is 5
State prediction error at timestep 975 is 0.012
Human Feedback received at timestpe 975 of 10
Current timestep = 976. State = [[-0.09876537  0.23666348  0.04056455 -1.1432241  -0.1646109   0.0192554
   0.          0.        ]]. Action = [[0.15208328 0.7900851 ]]. Reward = [2.7626324]
Abstract state at timestep 976 is 5
State prediction error at timestep 976 is 0.012
Human Feedback received at timestpe 976 of 10
Current timestep = 977. State = [[-0.0983779   0.21131459  0.03841531 -1.12658    -0.16426785  0.00686108
   0.          0.        ]]. Action = [[ 0.9224355 -0.1810801]]. Reward = [3.7521012]
Abstract state at timestep 977 is 5
State prediction error at timestep 977 is 0.012
Human Feedback received at timestpe 977 of 10
Current timestep = 978. State = [[-0.09794464  0.18675135  0.04346967 -1.0917178  -0.16441548 -0.00295287
   0.          0.        ]]. Action = [[ 0.7807096 -0.4503169]]. Reward = [5.4048395]
Abstract state at timestep 978 is 5
State prediction error at timestep 978 is 0.012
Human Feedback received at timestpe 978 of 10
Current timestep = 979. State = [[-0.09751139  0.16158809  0.04346967 -1.1183845  -0.1645631  -0.00295258
   0.          0.        ]]. Action = [[-0.9960822  -0.40708613]]. Reward = [-0.46468326]
Abstract state at timestep 979 is 5
State prediction error at timestep 979 is 0.012
Human Feedback received at timestpe 979 of 10
Current timestep = 980. State = [[-0.0970541   0.13649899  0.04611055 -1.1151131  -0.1649414  -0.00756619
   0.          0.        ]]. Action = [[0.59027886 0.45693898]]. Reward = [2.1643755]
Abstract state at timestep 980 is 5
State prediction error at timestep 980 is 0.012
Human Feedback received at timestpe 980 of 10
Current timestep = 981. State = [[-0.09660301  0.11117686  0.04569944 -1.1254958  -0.16553408 -0.01185384
   0.          0.        ]]. Action = [[ 0.0695715  -0.23237932]]. Reward = [0.7648126]
Abstract state at timestep 981 is 5
State prediction error at timestep 981 is 0.012
Human Feedback received at timestpe 981 of 10
Current timestep = 982. State = [[-0.09600945  0.08585609  0.05960237 -1.1253932  -0.16578242 -0.00496697
   0.          0.        ]]. Action = [[ 0.68030643 -0.1247806 ]]. Reward = [1.5168923]
Abstract state at timestep 982 is 5
State prediction error at timestep 982 is 0.012
Human Feedback received at timestpe 982 of 10
Current timestep = 983. State = [[-0.09541588  0.05993536  0.05960237 -1.1520597  -0.16603078 -0.00496711
   0.          0.        ]]. Action = [[-0.61477864 -0.24252224]]. Reward = [-1.0758276]
Abstract state at timestep 983 is 5
State prediction error at timestep 983 is 0.012
Human Feedback received at timestpe 983 of 10
Current timestep = 984. State = [[-0.09478178  0.03401829  0.06377998 -1.1519101  -0.16640191 -0.00742255
   0.          0.        ]]. Action = [[0.06709599 0.49623942]]. Reward = [0.9931061]
Abstract state at timestep 984 is 5
State prediction error at timestep 984 is 0.012
Human Feedback received at timestpe 984 of 10
Current timestep = 985. State = [[-0.09400406  0.00855704  0.07802983 -1.13164    -0.16665713 -0.00510455
   1.          0.        ]]. Action = [[ 0.51318204 -0.35204238]]. Reward = [12.313135]
Abstract state at timestep 985 is 5
State prediction error at timestep 985 is 0.012
Human Feedback received at timestpe 985 of 10
Current timestep = 986. State = [[-0.09307547 -0.01571666  0.07511634 -1.0770402  -0.15023826  0.32675418
   1.          0.        ]]. Action = [[0.07678187 0.6155093 ]]. Reward = [6.928919]
Abstract state at timestep 986 is 5
State prediction error at timestep 986 is 0.012
Human Feedback received at timestpe 986 of 10
Current timestep = 987. State = [[-7.6646806e-04  1.4051297e+00 -7.7648178e-02 -2.5735289e-01
   8.9491735e-04  1.7588453e-02  0.0000000e+00  0.0000000e+00]]. Action = [[-0.58871424 -0.71714187]]. Reward = [-100.]
Abstract state at timestep 987 is 5
State prediction error at timestep 987 is 0.012
Human Feedback received at timestpe 987 of 10
Current timestep = 988. State = [[-0.00160017  1.3987534  -0.08594628 -0.28338507  0.00344937  0.05109454
   0.          0.        ]]. Action = [[-0.07531005 -0.7783412 ]]. Reward = [-2.373219]
Abstract state at timestep 988 is 3
State prediction error at timestep 988 is 0.012
Human Feedback received at timestpe 988 of 10
Current timestep = 989. State = [[-0.00252171  1.3928589  -0.09432776 -0.2619856   0.00559215  0.04285952
   0.          0.        ]]. Action = [[ 0.6684673  -0.20175159]]. Reward = [1.8929598]
Abstract state at timestep 989 is 3
State prediction error at timestep 989 is 0.012
Human Feedback received at timestpe 989 of 10
Current timestep = 990. State = [[-0.00354404  1.3870963  -0.10393319 -0.25612816  0.00726525  0.03346554
   0.          0.        ]]. Action = [[0.21686399 0.19275653]]. Reward = [0.4299202]
Abstract state at timestep 990 is 3
State prediction error at timestep 990 is 0.012
Human Feedback received at timestpe 990 of 10
Current timestep = 991. State = [[-0.00447502  1.3816164  -0.09525461 -0.24356006  0.00939672  0.04263334
   0.          0.        ]]. Action = [[0.82887554 0.06876302]]. Reward = [1.5490515]
Abstract state at timestep 991 is 3
State prediction error at timestep 991 is 0.012
Human Feedback received at timestpe 991 of 10
Current timestep = 992. State = [[-0.00548191  1.3767391  -0.10425308 -0.2167952   0.01292244  0.07052071
   0.          0.        ]]. Action = [[ 0.6128144  -0.71794033]]. Reward = [1.9677979]
Abstract state at timestep 992 is 3
State prediction error at timestep 992 is 0.012
Human Feedback received at timestpe 992 of 10
Current timestep = 993. State = [[-0.00648899  1.3712617  -0.10426352 -0.24347071  0.01644721  0.07050189
   0.          0.        ]]. Action = [[-0.44345802 -0.14420271]]. Reward = [-2.234862]
Abstract state at timestep 993 is 3
State prediction error at timestep 993 is 0.012
Human Feedback received at timestpe 993 of 10
Current timestep = 994. State = [[-0.00740347  1.3665218  -0.09553096 -0.21071261  0.02048263  0.08071585
   0.          0.        ]]. Action = [[ 0.8788811  -0.18738115]]. Reward = [3.1380935]
Abstract state at timestep 994 is 3
State prediction error at timestep 994 is 0.012
Human Feedback received at timestpe 994 of 10
Current timestep = 995. State = [[-0.00841656  1.3615868  -0.10493153 -0.21938191  0.02407561  0.07186605
   0.          0.        ]]. Action = [[ 0.03602076 -0.15000159]]. Reward = [-1.204642]
Abstract state at timestep 995 is 3
State prediction error at timestep 995 is 0.012
Human Feedback received at timestpe 995 of 10
Current timestep = 996. State = [[-0.00970497  1.3572466  -0.13360624 -0.19298719  0.02878794  0.09425513
   0.          0.        ]]. Action = [[ 0.9660013 -0.7947445]]. Reward = [0.48943973]
Abstract state at timestep 996 is 3
State prediction error at timestep 996 is 0.012
Human Feedback received at timestpe 996 of 10
Current timestep = 997. State = [[-0.01105213  1.3523113  -0.14096025 -0.21948443  0.03496807  0.12361388
   0.          0.        ]]. Action = [[-0.04613531 -0.6509905 ]]. Reward = [-2.7578862]
Abstract state at timestep 997 is 3
State prediction error at timestep 997 is 0.012
Human Feedback received at timestpe 997 of 10
Current timestep = 998. State = [[-0.01243725  1.3473682  -0.14300407 -0.21979591  0.0394199   0.08904465
   0.          0.        ]]. Action = [[0.18356848 0.83559585]]. Reward = [-0.29182246]
Abstract state at timestep 998 is 3
State prediction error at timestep 998 is 0.012
Human Feedback received at timestpe 998 of 10
Current timestep = 999. State = [[-0.01388207  1.342455   -0.14877352 -0.21848646  0.04366878  0.08498548
   0.          0.        ]]. Action = [[ 0.6597595 -0.0060041]]. Reward = [-0.394673]
Abstract state at timestep 999 is 3
State prediction error at timestep 999 is 0.012
Human Feedback received at timestpe 999 of 10
Current timestep = 1000. State = [[-0.01527462  1.3377211  -0.14390928 -0.21054062  0.04827042  0.09204127
   0.          0.        ]]. Action = [[ 0.08892429 -0.1560266 ]]. Reward = [0.7788669]
Abstract state at timestep 1000 is 3
State prediction error at timestep 1000 is 0.012
Human Feedback received at timestpe 1000 of 10
Current timestep = 1001. State = [[-0.01674118  1.3329761  -0.15103604 -0.21103933  0.05261321  0.08686373
   0.          0.        ]]. Action = [[ 0.42141473 -0.44918495]]. Reward = [-0.6241628]
Abstract state at timestep 1001 is 3
State prediction error at timestep 1001 is 0.012
Human Feedback received at timestpe 1001 of 10
Current timestep = 1002. State = [[-0.01816368  1.3281114  -0.14692059 -0.21637765  0.05724232  0.09259063
   0.          0.        ]]. Action = [[0.32741153 0.27893376]]. Reward = [-0.3800298]
Abstract state at timestep 1002 is 3
State prediction error at timestep 1002 is 0.012
Human Feedback received at timestpe 1002 of 10
Current timestep = 1003. State = [[-0.01958628  1.3226471  -0.14693375 -0.2430498   0.06187038  0.09256957
   0.          0.        ]]. Action = [[-0.3956883   0.17022693]]. Reward = [-2.1652923]
Abstract state at timestep 1003 is 3
State prediction error at timestep 1003 is 0.012
Human Feedback received at timestpe 1003 of 10
Current timestep = 1004. State = [[-0.02126331  1.3176819  -0.17307888 -0.22090131  0.06720094  0.10662071
   0.          0.        ]]. Action = [[ 0.9677942 -0.5883095]]. Reward = [-0.01391546]
Abstract state at timestep 1004 is 3
State prediction error at timestep 1004 is 0.012
Human Feedback received at timestpe 1004 of 10
Current timestep = 1005. State = [[-0.02274752  1.3126445  -0.15329103 -0.22411245  0.07202525  0.0964947
   0.          0.        ]]. Action = [[0.92595387 0.52146196]]. Reward = [0.6250459]
Abstract state at timestep 1005 is 3
State prediction error at timestep 1005 is 0.012
Human Feedback received at timestpe 1005 of 10
Current timestep = 1006. State = [[-0.02425718  1.3080902  -0.15440221 -0.20258452  0.07544013  0.06830394
   0.          0.        ]]. Action = [[0.5006734 0.6803559]]. Reward = [1.546256]
Abstract state at timestep 1006 is 3
State prediction error at timestep 1006 is 0.012
Human Feedback received at timestpe 1006 of 10
Current timestep = 1007. State = [[-0.02587214  1.3038853  -0.1646691  -0.1870459   0.07858802  0.06296315
   0.          0.        ]]. Action = [[ 0.33030808 -0.11701512]]. Reward = [0.45434073]
Abstract state at timestep 1007 is 3
State prediction error at timestep 1007 is 0.012
Human Feedback received at timestpe 1007 of 10
Current timestep = 1008. State = [[-0.02742767  1.2990845  -0.15721796 -0.2134498   0.0802376   0.03299455
   0.          0.        ]]. Action = [[-0.56866044  0.63430095]]. Reward = [-1.29696]
Abstract state at timestep 1008 is 3
State prediction error at timestep 1008 is 0.012
Human Feedback received at timestpe 1008 of 10
Current timestep = 1009. State = [[-0.02885418  1.2942743  -0.1430391  -0.21381642  0.08062266  0.00770176
   0.          0.        ]]. Action = [[0.49668002 0.72881794]]. Reward = [0.977983]
Abstract state at timestep 1009 is 3
State prediction error at timestep 1009 is 0.012
Human Feedback received at timestpe 1009 of 10
Current timestep = 1010. State = [[-0.03028069  1.2888637  -0.14303944 -0.2404898   0.08100767  0.0077009
   0.          0.        ]]. Action = [[-0.52209294 -0.34280014]]. Reward = [-1.7571849]
Abstract state at timestep 1010 is 3
State prediction error at timestep 1010 is 0.012
Human Feedback received at timestpe 1010 of 10
Current timestep = 1011. State = [[-0.03163815  1.2828529  -0.13439038 -0.26707372  0.07966304 -0.02689544
   0.          0.        ]]. Action = [[-0.9793097  0.7778163]]. Reward = [-1.2079034]
Abstract state at timestep 1011 is 3
State prediction error at timestep 1011 is 0.012
Human Feedback received at timestpe 1011 of 10
Current timestep = 1012. State = [[-0.03299446  1.2762207  -0.13427205 -0.29469317  0.07831883 -0.02688432
   0.          0.        ]]. Action = [[-0.2516241  -0.20941359]]. Reward = [-1.6920779]
Abstract state at timestep 1012 is 3
State prediction error at timestep 1012 is 0.012
Human Feedback received at timestpe 1012 of 10
Current timestep = 1013. State = [[-0.03429442  1.2689891  -0.12721024 -0.32125983  0.07556181 -0.05514057
   0.          0.        ]]. Action = [[-0.0922305  0.774933 ]]. Reward = [-1.1968762]
Abstract state at timestep 1013 is 3
State prediction error at timestep 1013 is 0.012
Human Feedback received at timestpe 1013 of 10
Current timestep = 1014. State = [[-0.03554869  1.2611583  -0.12148663 -0.34783426  0.07165921 -0.07805201
   0.          0.        ]]. Action = [[-0.18325979  0.7522106 ]]. Reward = [-1.1440375]
Abstract state at timestep 1014 is 3
State prediction error at timestep 1014 is 0.012
Human Feedback received at timestpe 1014 of 10
Current timestep = 1015. State = [[-0.03672085  1.2527454  -0.11115855 -0.37363902  0.06567019 -0.11978048
   0.          0.        ]]. Action = [[-0.85807836  0.9059336 ]]. Reward = [-0.72908884]
Abstract state at timestep 1015 is 3
State prediction error at timestep 1015 is 0.012
Human Feedback received at timestpe 1015 of 10
Current timestep = 1016. State = [[-0.03792772  1.2437346  -0.11550989 -0.40025806  0.06054951 -0.10241368
   0.          0.        ]]. Action = [[-0.24579227 -0.5363314 ]]. Reward = [-1.2838244]
Abstract state at timestep 1016 is 3
State prediction error at timestep 1016 is 0.012
Human Feedback received at timestpe 1016 of 10
Current timestep = 1017. State = [[-0.03910504  1.2348834  -0.11283819 -0.39319208  0.05570683 -0.09685355
   0.          0.        ]]. Action = [[ 0.6125312  -0.37792307]]. Reward = [1.8763465]
Abstract state at timestep 1017 is 3
State prediction error at timestep 1017 is 0.012
Human Feedback received at timestpe 1017 of 10
Current timestep = 1018. State = [[-0.04020481  1.2262982  -0.10559341 -0.38141263  0.05137105 -0.08671582
   0.          0.        ]]. Action = [[0.9021027  0.45371294]]. Reward = [2.3331397]
Abstract state at timestep 1018 is 3
State prediction error at timestep 1018 is 0.012
Human Feedback received at timestpe 1018 of 10
Current timestep = 1019. State = [[-0.04138193  1.2171049  -0.1152905  -0.40850967  0.04898304 -0.04776005
   0.          0.        ]]. Action = [[-0.29915196 -0.7929649 ]]. Reward = [-1.7408264]
Abstract state at timestep 1019 is 3
State prediction error at timestep 1019 is 0.012
Human Feedback received at timestpe 1019 of 10
Current timestep = 1020. State = [[-0.04262104  1.2080432  -0.1233536  -0.40272617  0.04843129 -0.01103506
   0.          0.        ]]. Action = [[ 0.9514384  -0.89072347]]. Reward = [0.9643427]
Abstract state at timestep 1020 is 3
State prediction error at timestep 1020 is 0.012
Human Feedback received at timestpe 1020 of 10
Current timestep = 1021. State = [[-0.04386025  1.1983814  -0.12335359 -0.42939287  0.04787955 -0.01103503
   0.          0.        ]]. Action = [[-0.01598918  0.21174324]]. Reward = [-1.5402908]
Abstract state at timestep 1021 is 3
State prediction error at timestep 1021 is 0.012
Human Feedback received at timestpe 1021 of 10
Current timestep = 1022. State = [[-0.04503355  1.1888826  -0.11719477 -0.42216402  0.04774445 -0.00270224
   0.          0.        ]]. Action = [[ 0.7141204  -0.22159284]]. Reward = [1.5643189]
Abstract state at timestep 1022 is 3
State prediction error at timestep 1022 is 0.012
Human Feedback received at timestpe 1022 of 10
Current timestep = 1023. State = [[-0.04620685  1.1787838  -0.11719477 -0.4488307   0.04760936 -0.00270224
   0.          0.        ]]. Action = [[-0.06641001 -0.3633207 ]]. Reward = [-1.5568545]
Abstract state at timestep 1023 is 3
State prediction error at timestep 1023 is 0.012
Human Feedback received at timestpe 1023 of 10
Current timestep = 1024. State = [[-0.04738388  1.168848   -0.11879909 -0.44162554  0.04869505  0.02171377
   0.          0.        ]]. Action = [[ 0.7312217 -0.5264485]]. Reward = [1.2594209]
Abstract state at timestep 1024 is 3
State prediction error at timestep 1024 is 0.012
Human Feedback received at timestpe 1024 of 10
Current timestep = 1025. State = [[-0.0485055   1.158324   -0.11184023 -0.4677228   0.04837826 -0.00633567
   0.          0.        ]]. Action = [[-0.07246268  0.7472129 ]]. Reward = [-1.3021659]
Abstract state at timestep 1025 is 3
State prediction error at timestep 1025 is 0.012
Human Feedback received at timestpe 1025 of 10
Current timestep = 1026. State = [[-0.04975576  1.1478784  -0.1259835  -0.46428356  0.04931842  0.01880335
   0.          0.        ]]. Action = [[ 0.28232884 -0.6740318 ]]. Reward = [0.7152572]
Abstract state at timestep 1026 is 3
State prediction error at timestep 1026 is 0.012
Human Feedback received at timestpe 1026 of 10
Current timestep = 1027. State = [[-0.0510685   1.1380714  -0.1321205  -0.43589142  0.05015863  0.01680439
   0.          0.        ]]. Action = [[0.78302526 0.34089684]]. Reward = [3.1823082]
Abstract state at timestep 1027 is 3
State prediction error at timestep 1027 is 0.012
Human Feedback received at timestpe 1027 of 10
Current timestep = 1028. State = [[-0.05238123  1.1276646  -0.1321205  -0.46255815  0.05099885  0.01680437
   0.          0.        ]]. Action = [[-0.7947282   0.13953054]]. Reward = [-1.6086487]
Abstract state at timestep 1028 is 3
State prediction error at timestep 1028 is 0.012
Human Feedback received at timestpe 1028 of 10
Current timestep = 1029. State = [[-0.05369396  1.1166577  -0.1321205  -0.48922488  0.05183906  0.01680433
   0.          0.        ]]. Action = [[-0.21539068 -0.17455852]]. Reward = [-1.5601739]
Abstract state at timestep 1029 is 3
State prediction error at timestep 1029 is 0.012
Human Feedback received at timestpe 1029 of 10
Current timestep = 1030. State = [[-0.05500669  1.1050508  -0.13212049 -0.5158916   0.05267929  0.01680434
   0.          0.        ]]. Action = [[-0.50441813  0.37922466]]. Reward = [-1.5101194]
Abstract state at timestep 1030 is 3
State prediction error at timestep 1030 is 0.012
Human Feedback received at timestpe 1030 of 10
Current timestep = 1031. State = [[-0.0563859   1.0928426  -0.14046967 -0.5426771   0.05519159  0.05024593
   0.          0.        ]]. Action = [[-0.70024157 -0.8972438 ]]. Reward = [-1.8679986]
Abstract state at timestep 1031 is 3
State prediction error at timestep 1031 is 0.012
Human Feedback received at timestpe 1031 of 10
Current timestep = 1032. State = [[-0.0577652   1.0800346  -0.14046963 -0.5693443   0.05770388  0.05024591
   0.          0.        ]]. Action = [[-0.35189497  0.13521767]]. Reward = [-1.5648724]
Abstract state at timestep 1032 is 3
State prediction error at timestep 1032 is 0.012
Human Feedback received at timestpe 1032 of 10
Current timestep = 1033. State = [[-0.05929403  1.0675011  -0.15734987 -0.55722564  0.06211298  0.08818223
   0.          0.        ]]. Action = [[ 0.74160194 -0.97962   ]]. Reward = [1.2517216]
Abstract state at timestep 1033 is 3
State prediction error at timestep 1033 is 0.012
Human Feedback received at timestpe 1033 of 10
Current timestep = 1034. State = [[-0.06073103  1.0552709  -0.14731783 -0.54371554  0.06568512  0.07144301
   0.          0.        ]]. Action = [[0.46679425 0.5283296 ]]. Reward = [2.1894877]
Abstract state at timestep 1034 is 3
State prediction error at timestep 1034 is 0.012
Human Feedback received at timestpe 1034 of 10
Current timestep = 1035. State = [[-0.06216812  1.0424408  -0.14731771 -0.57038325  0.06925726  0.07144292
   0.          0.        ]]. Action = [[-0.18365943 -0.28167975]]. Reward = [-1.6628957]
Abstract state at timestep 1035 is 3
State prediction error at timestep 1035 is 0.012
Human Feedback received at timestpe 1035 of 10
Current timestep = 1036. State = [[-0.06366644  1.0290093  -0.15499766 -0.59720033  0.07436763  0.10220768
   0.          0.        ]]. Action = [[-0.8400543  -0.68170196]]. Reward = [-1.9885088]
Abstract state at timestep 1036 is 3
State prediction error at timestep 1036 is 0.012
Human Feedback received at timestpe 1036 of 10
Current timestep = 1037. State = [[-0.06511202  1.0149802  -0.14837387 -0.6237169   0.07815097  0.07566654
   0.          0.        ]]. Action = [[-0.7220962   0.69756424]]. Reward = [-1.4217547]
Abstract state at timestep 1037 is 3
State prediction error at timestep 1037 is 0.012
Human Feedback received at timestpe 1037 of 10
Current timestep = 1038. State = [[-0.0665575   1.0003511  -0.14837374 -0.6503846   0.0819343   0.07566647
   0.          0.        ]]. Action = [[-0.8410473   0.45741403]]. Reward = [-1.5251842]
Abstract state at timestep 1038 is 3
State prediction error at timestep 1038 is 0.012
Human Feedback received at timestpe 1038 of 10
Current timestep = 1039. State = [[-0.06822729  0.9861849  -0.17174104 -0.6298782   0.08664893  0.09429293
   0.          0.        ]]. Action = [[ 0.42290735 -0.5958358 ]]. Reward = [2.121548]
Abstract state at timestep 1039 is 3
State prediction error at timestep 1039 is 0.012
Human Feedback received at timestpe 1039 of 10
Current timestep = 1040. State = [[-0.06979342  0.9721633  -0.15979296 -0.6233693   0.08980509  0.06312294
   0.          0.        ]]. Action = [[0.7279557 0.8518729]]. Reward = [1.7220987]
Abstract state at timestep 1040 is 4
State prediction error at timestep 1040 is 0.012
Human Feedback received at timestpe 1040 of 10
Current timestep = 1041. State = [[-0.07130365  0.95754975 -0.15278289 -0.6495959   0.09154809  0.03486008
   0.          0.        ]]. Action = [[-0.8691346  0.5744257]]. Reward = [-1.1248003]
Abstract state at timestep 1041 is 4
State prediction error at timestep 1041 is 0.012
Human Feedback received at timestpe 1041 of 10
Current timestep = 1042. State = [[-0.07284632  0.9431584  -0.15611033 -0.6397273   0.09337338  0.03650584
   0.          0.        ]]. Action = [[ 0.6899786 -0.3888924]]. Reward = [1.8694946]
Abstract state at timestep 1042 is 4
State prediction error at timestep 1042 is 0.012
Human Feedback received at timestpe 1042 of 10
Current timestep = 1043. State = [[-0.07448921  0.9285725  -0.16783056 -0.6484953   0.0968811   0.07015427
   0.          0.        ]]. Action = [[ 0.26372588 -0.8461533 ]]. Reward = [-0.2606388]
Abstract state at timestep 1043 is 4
State prediction error at timestep 1043 is 0.012
Human Feedback received at timestpe 1043 of 10
Current timestep = 1044. State = [[-0.07619152  0.9142017  -0.17374173 -0.63893163  0.10035832  0.06954477
   0.          0.        ]]. Action = [[0.7923584  0.28847837]]. Reward = [1.5746269]
Abstract state at timestep 1044 is 4
State prediction error at timestep 1044 is 0.012
Human Feedback received at timestpe 1044 of 10
Current timestep = 1045. State = [[-0.07783966  0.8992321  -0.1669546  -0.6654621   0.10247806  0.04239494
   0.          0.        ]]. Action = [[-0.51058185  0.8008146 ]]. Reward = [-1.1536508]
Abstract state at timestep 1045 is 4
State prediction error at timestep 1045 is 0.012
Human Feedback received at timestpe 1045 of 10
Current timestep = 1046. State = [[-0.0794878   0.8836626  -0.16695455 -0.6921291   0.10459779  0.04239495
   0.          0.        ]]. Action = [[-0.95349956  0.06464779]]. Reward = [-1.265032]
Abstract state at timestep 1046 is 4
State prediction error at timestep 1046 is 0.012
Human Feedback received at timestpe 1046 of 10
Current timestep = 1047. State = [[-0.08118725  0.86811405 -0.17204434 -0.6912006   0.10668156  0.04167552
   0.          0.        ]]. Action = [[ 0.34440553 -0.17469162]]. Reward = [1.0918192]
Abstract state at timestep 1047 is 4
State prediction error at timestep 1047 is 0.012
Human Feedback received at timestpe 1047 of 10
Current timestep = 1048. State = [[-0.08292427  0.85295534 -0.17729035 -0.6739788   0.11024078  0.07118439
   0.          0.        ]]. Action = [[ 0.3655665  -0.66490275]]. Reward = [2.4501727]
Abstract state at timestep 1048 is 4
State prediction error at timestep 1048 is 0.012
Human Feedback received at timestpe 1048 of 10
Current timestep = 1049. State = [[-0.08471556  0.83718324 -0.18411097 -0.7013586   0.11518731  0.09893082
   0.          0.        ]]. Action = [[-0.10302013 -0.7645536 ]]. Reward = [-1.7871878]
Abstract state at timestep 1049 is 4
State prediction error at timestep 1049 is 0.012
Human Feedback received at timestpe 1049 of 10
Current timestep = 1050. State = [[-0.08652773  0.82196146 -0.18781856 -0.67704684  0.12174706  0.13119507
   0.          0.        ]]. Action = [[ 0.9522197  -0.65344346]]. Reward = [2.7777069]
Abstract state at timestep 1050 is 4
State prediction error at timestep 1050 is 0.012
Human Feedback received at timestpe 1050 of 10
Current timestep = 1051. State = [[-0.0885642   0.8072597  -0.20962529 -0.65391785  0.12769648  0.11898814
   0.          0.        ]]. Action = [[0.5730293  0.04693067]]. Reward = [2.201038]
Abstract state at timestep 1051 is 4
State prediction error at timestep 1051 is 0.012
Human Feedback received at timestpe 1051 of 10
Current timestep = 1052. State = [[-0.09060068  0.7919582  -0.20962474 -0.6805874   0.13364586  0.11898778
   0.          0.        ]]. Action = [[-0.39053023 -0.3439988 ]]. Reward = [-1.6412741]
Abstract state at timestep 1052 is 4
State prediction error at timestep 1052 is 0.012
Human Feedback received at timestpe 1052 of 10
Current timestep = 1053. State = [[-0.09263726  0.7760572  -0.20962417 -0.707257    0.13959526  0.11898748
   0.          0.        ]]. Action = [[-0.7146388  -0.47537816]]. Reward = [-1.5921882]
Abstract state at timestep 1053 is 4
State prediction error at timestep 1053 is 0.012
Human Feedback received at timestpe 1053 of 10
Current timestep = 1054. State = [[-0.09467392  0.7595567  -0.20962355 -0.7339266   0.14554463  0.1189872
   0.          0.        ]]. Action = [[-0.57335305  0.48623753]]. Reward = [-1.5424503]
Abstract state at timestep 1054 is 4
State prediction error at timestep 1054 is 0.012
Human Feedback received at timestpe 1054 of 10
Current timestep = 1055. State = [[-0.0966569   0.743282   -0.20332249 -0.7238132   0.15055323  0.1001719
   0.          0.        ]]. Action = [[0.5627526  0.57581973]]. Reward = [1.9816232]
Abstract state at timestep 1055 is 4
State prediction error at timestep 1055 is 0.012
Human Feedback received at timestpe 1055 of 10
Current timestep = 1056. State = [[-0.09866285  0.7269663  -0.20576541 -0.72567326  0.15571542  0.10324405
   0.          0.        ]]. Action = [[ 0.16420817 -0.27272677]]. Reward = [0.65472037]
Abstract state at timestep 1056 is 4
State prediction error at timestep 1056 is 0.012
Human Feedback received at timestpe 1056 of 10
Current timestep = 1057. State = [[-0.10085859  0.7113351  -0.22448564 -0.6952408   0.1606247   0.09818551
   0.          0.        ]]. Action = [[0.71469665 0.18196094]]. Reward = [3.1397262]
Abstract state at timestep 1057 is 4
State prediction error at timestep 1057 is 0.012
Human Feedback received at timestpe 1057 of 10
Current timestep = 1058. State = [[-0.1030056   0.6965694  -0.2186886  -0.65669554  0.16461179  0.07974188
   0.          0.        ]]. Action = [[0.9173386 0.6541219]]. Reward = [4.5679107]
Abstract state at timestep 1058 is 4
State prediction error at timestep 1058 is 0.012
Human Feedback received at timestpe 1058 of 10
Current timestep = 1059. State = [[-0.10503864  0.68155605 -0.20601706 -0.66756076  0.16732936  0.05435128
   0.          0.        ]]. Action = [[0.24262023 0.7012117 ]]. Reward = [0.32737792]
Abstract state at timestep 1059 is 4
State prediction error at timestep 1059 is 0.012
Human Feedback received at timestpe 1059 of 10
Current timestep = 1060. State = [[-0.10700054  0.66596246 -0.1970764  -0.6931468   0.16821338  0.01768046
   0.          0.        ]]. Action = [[-0.7461113   0.98564744]]. Reward = [-0.8072132]
Abstract state at timestep 1060 is 4
State prediction error at timestep 1060 is 0.012
Human Feedback received at timestpe 1060 of 10
Current timestep = 1061. State = [[-0.10918999  0.6510036  -0.22096829 -0.66506994  0.1702432   0.04059599
   0.          0.        ]]. Action = [[ 0.62868285 -0.6181594 ]]. Reward = [2.9549758]
Abstract state at timestep 1061 is 4
State prediction error at timestep 1061 is 0.012
Human Feedback received at timestpe 1061 of 10
Current timestep = 1062. State = [[-0.1114274   0.6354341  -0.22699937 -0.69235885  0.17350318  0.06519921
   0.          0.        ]]. Action = [[-0.8068784 -0.5981946]]. Reward = [-1.6276423]
Abstract state at timestep 1062 is 4
State prediction error at timestep 1062 is 0.012
Human Feedback received at timestpe 1062 of 10
Current timestep = 1063. State = [[-0.11370239  0.6204919  -0.2312319  -0.6645324   0.17724562  0.07484888
   0.          0.        ]]. Action = [[ 0.55678415 -0.479398  ]]. Reward = [3.323702]
Abstract state at timestep 1063 is 4
State prediction error at timestep 1063 is 0.012
Human Feedback received at timestpe 1063 of 10
Current timestep = 1064. State = [[-0.11596213  0.6058921  -0.23027952 -0.64939857  0.18157007  0.08648898
   0.          0.        ]]. Action = [[0.45859683 0.40628362]]. Reward = [2.2016156]
Abstract state at timestep 1064 is 4
State prediction error at timestep 1064 is 0.012
Human Feedback received at timestpe 1064 of 10
Current timestep = 1065. State = [[-0.11825418  0.59157467 -0.23386283 -0.6369098   0.18623814  0.09336161
   0.          0.        ]]. Action = [[0.15327835 0.1331358 ]]. Reward = [1.7744154]
Abstract state at timestep 1065 is 4
State prediction error at timestep 1065 is 0.012
Human Feedback received at timestpe 1065 of 10
Current timestep = 1066. State = [[-0.12054634  0.5766574  -0.23386233 -0.66357815  0.19090621  0.09336147
   0.          0.        ]]. Action = [[-0.09603268 -0.42898023]]. Reward = [-1.5606229]
Abstract state at timestep 1066 is 4
State prediction error at timestep 1066 is 0.012
Human Feedback received at timestpe 1066 of 10
Current timestep = 1067. State = [[-0.12283859  0.56114054 -0.23386183 -0.6902466   0.19557428  0.0933613
   0.          0.        ]]. Action = [[-0.27174056  0.34462285]]. Reward = [-1.5179962]
Abstract state at timestep 1067 is 4
State prediction error at timestep 1067 is 0.012
Human Feedback received at timestpe 1067 of 10
Current timestep = 1068. State = [[-0.12513074  0.54502386 -0.2338613  -0.716915    0.20024234  0.09336112
   0.          0.        ]]. Action = [[-0.90305567 -0.38093972]]. Reward = [-1.4749784]
Abstract state at timestep 1068 is 4
State prediction error at timestep 1068 is 0.012
Human Feedback received at timestpe 1068 of 10
Current timestep = 1069. State = [[-0.12753296  0.52909    -0.2460604  -0.70897454  0.2061291   0.11773565
   0.          0.        ]]. Action = [[ 0.47415912 -0.5598222 ]]. Reward = [1.0328382]
Abstract state at timestep 1069 is 4
State prediction error at timestep 1069 is 0.012
Human Feedback received at timestpe 1069 of 10
Current timestep = 1070. State = [[-0.13005896  0.51317626 -0.26021093 -0.70835674  0.21381365  0.15369047
   0.          0.        ]]. Action = [[ 0.29724908 -0.88118166]]. Reward = [0.07697601]
Abstract state at timestep 1070 is 4
State prediction error at timestep 1070 is 0.012
Human Feedback received at timestpe 1070 of 10
Current timestep = 1071. State = [[-0.13253184  0.4966749  -0.25354093 -0.7343138   0.22013591  0.12644543
   0.          0.        ]]. Action = [[-0.16079676  0.572804  ]]. Reward = [-1.336058]
Abstract state at timestep 1071 is 4
State prediction error at timestep 1071 is 0.012
Human Feedback received at timestpe 1071 of 10
Current timestep = 1072. State = [[-0.13498163  0.48026228 -0.2517931  -0.7304838   0.2270257   0.13779575
   0.          0.        ]]. Action = [[ 0.8292887  -0.07293892]]. Reward = [0.9739445]
Abstract state at timestep 1072 is 5
State prediction error at timestep 1072 is 0.012
Human Feedback received at timestpe 1072 of 10
Current timestep = 1073. State = [[-0.1376193   0.4644132  -0.26890326 -0.7052034   0.23223254  0.10413643
   0.          0.        ]]. Action = [[0.5762541  0.77230334]]. Reward = [2.4622664]
Abstract state at timestep 1073 is 5
State prediction error at timestep 1073 is 0.012
Human Feedback received at timestpe 1073 of 10
Current timestep = 1074. State = [[-0.14037581  0.44855347 -0.27935684 -0.70546913  0.23600362  0.07542177
   0.          0.        ]]. Action = [[0.7094085  0.62479544]]. Reward = [0.38115418]
Abstract state at timestep 1074 is 5
State prediction error at timestep 1074 is 0.012
Human Feedback received at timestpe 1074 of 10
Current timestep = 1075. State = [[-0.14319782  0.43206647 -0.28763115 -0.73363775  0.24151857  0.11029919
   0.          0.        ]]. Action = [[-0.49772942 -0.9806415 ]]. Reward = [-2.0222151]
Abstract state at timestep 1075 is 5
State prediction error at timestep 1075 is 0.012
Human Feedback received at timestpe 1075 of 10
Current timestep = 1076. State = [[-0.14614725  0.41561073 -0.30235198 -0.7326036   0.2490588   0.15080467
   0.          0.        ]]. Action = [[ 0.32951188 -0.9910754 ]]. Reward = [0.0252721]
Abstract state at timestep 1076 is 5
State prediction error at timestep 1076 is 0.012
Human Feedback received at timestpe 1076 of 10
Current timestep = 1077. State = [[-0.1493824   0.3991058  -0.33161753 -0.7349486   0.25732154  0.16525485
   0.          0.        ]]. Action = [[ 0.9189408 -0.5560324]]. Reward = [-1.0652909]
Abstract state at timestep 1077 is 5
State prediction error at timestep 1077 is 0.012
Human Feedback received at timestpe 1077 of 10
Current timestep = 1078. State = [[-0.1526638   0.38198727 -0.3373965  -0.7624708   0.26678553  0.18927996
   0.          0.        ]]. Action = [[-0.08401114 -0.7207593 ]]. Reward = [-2.2383718]
Abstract state at timestep 1078 is 5
State prediction error at timestep 1078 is 0.012
Human Feedback received at timestpe 1078 of 10
Current timestep = 1079. State = [[-0.1559453   0.3642701  -0.33739358 -0.7891447   0.27624947  0.1892788
   0.          0.        ]]. Action = [[-0.5463452 -0.2840904]]. Reward = [-1.8805907]
Abstract state at timestep 1079 is 5
State prediction error at timestep 1079 is 0.012
Human Feedback received at timestpe 1079 of 10
Current timestep = 1080. State = [[-0.159447    0.3465081  -0.35757437 -0.7908389   0.28385028  0.15201715
   0.          0.        ]]. Action = [[0.7145392 0.7542293]]. Reward = [-0.52606714]
Abstract state at timestep 1080 is 5
State prediction error at timestep 1080 is 0.012
Human Feedback received at timestpe 1080 of 10
Current timestep = 1081. State = [[-0.16294889  0.32814682 -0.35757238 -0.8175102   0.2914511   0.15201652
   0.          0.        ]]. Action = [[-0.40765393 -0.42179275]]. Reward = [-1.6914936]
Abstract state at timestep 1081 is 5
State prediction error at timestep 1081 is 0.012
Human Feedback received at timestpe 1081 of 10
Current timestep = 1082. State = [[-0.16640845  0.30920842 -0.3521886  -0.84296733  0.2978877   0.12873192
   0.          0.        ]]. Action = [[-0.6320062  0.5031686]]. Reward = [-1.2644697]
Abstract state at timestep 1082 is 5
State prediction error at timestep 1082 is 0.012
Human Feedback received at timestpe 1082 of 10
Current timestep = 1083. State = [[-0.16993542  0.28964776 -0.36064085 -0.8710096   0.3060947   0.1641398
   0.          0.        ]]. Action = [[-0.4580928  -0.83937025]]. Reward = [-2.2271633]
Abstract state at timestep 1083 is 5
State prediction error at timestep 1083 is 0.012
Human Feedback received at timestpe 1083 of 10
Current timestep = 1084. State = [[-0.17373915  0.27008474 -0.38990775 -0.8715079   0.3159862   0.19782983
   0.          0.        ]]. Action = [[ 0.16958451 -0.847486  ]]. Reward = [-0.92563266]
Abstract state at timestep 1084 is 5
State prediction error at timestep 1084 is 0.012
Human Feedback received at timestpe 1084 of 10
Current timestep = 1085. State = [[-0.17746039  0.2499678  -0.37943664 -0.8956974   0.32359326  0.15214153
   0.          0.        ]]. Action = [[-0.98379326  0.9404931 ]]. Reward = [-1.1302544]
Abstract state at timestep 1085 is 5
State prediction error at timestep 1085 is 0.012
Human Feedback received at timestpe 1085 of 10
Current timestep = 1086. State = [[-0.18116179  0.22984658 -0.37808707 -0.8960717   0.331871    0.16555485
   0.          0.        ]]. Action = [[ 0.7367921  -0.17901063]]. Reward = [0.31944767]
Abstract state at timestep 1086 is 5
State prediction error at timestep 1086 is 0.012
Human Feedback received at timestpe 1086 of 10
Current timestep = 1087. State = [[-0.18513927  0.2102051  -0.405541   -0.874769    0.34002674  0.16311449
   0.          0.        ]]. Action = [[ 0.7488427 -0.4721111]]. Reward = [1.0137222]
Abstract state at timestep 1087 is 5
State prediction error at timestep 1087 is 0.012
Human Feedback received at timestpe 1087 of 10
Current timestep = 1088. State = [[-0.1890562   0.1900009  -0.39785355 -0.8994329   0.3464784   0.12903371
   0.          0.        ]]. Action = [[-0.3570401  0.7485887]]. Reward = [-1.3894906]
Abstract state at timestep 1088 is 5
State prediction error at timestep 1088 is 0.012
Human Feedback received at timestpe 1088 of 10
Current timestep = 1089. State = [[-0.19291715  0.1692308  -0.39072663 -0.92423683  0.35134846  0.09740082
   0.          0.        ]]. Action = [[-0.5284621   0.67991495]]. Reward = [-1.3601048]
Abstract state at timestep 1089 is 5
State prediction error at timestep 1089 is 0.012
Human Feedback received at timestpe 1089 of 10
Current timestep = 1090. State = [[-0.19684076  0.14782692 -0.39864475 -0.9528339   0.35795832  0.13219698
   0.          0.        ]]. Action = [[-0.11007273 -0.74269235]]. Reward = [-2.5807428]
Abstract state at timestep 1090 is 5
State prediction error at timestep 1090 is 0.012
Human Feedback received at timestpe 1090 of 10
Current timestep = 1091. State = [[-0.20076446  0.12582365 -0.39864287 -0.979504    0.36456814  0.13219662
   0.          0.        ]]. Action = [[-0.918029    0.47194982]]. Reward = [-2.2028527]
Abstract state at timestep 1091 is 5
State prediction error at timestep 1091 is 0.012
Human Feedback received at timestpe 1091 of 10
Current timestep = 1092. State = [[-0.20463796  0.10325003 -0.39226058 -1.0045295   0.36976257  0.10388912
   0.          0.        ]]. Action = [[-0.4275542  0.6937578]]. Reward = [-1.856072]
Abstract state at timestep 1092 is 5
State prediction error at timestep 1092 is 0.012
Human Feedback received at timestpe 1092 of 10
Current timestep = 1093. State = [[-0.20851155  0.08007675 -0.39225936 -1.031198    0.37495703  0.10388891
   0.          0.        ]]. Action = [[-0.6442274  -0.33416986]]. Reward = [-2.422762]
Abstract state at timestep 1093 is 5
State prediction error at timestep 1093 is 0.012
Human Feedback received at timestpe 1093 of 10
Current timestep = 1094. State = [[-0.21075287  0.06011411 -0.21847656 -0.885474    0.3762809   0.03589815
   0.          1.        ]]. Action = [[-0.48335433 -0.9379338 ]]. Reward = [29.385134]
Abstract state at timestep 1094 is 5
State prediction error at timestep 1094 is 0.012
Human Feedback received at timestpe 1094 of 10
Current timestep = 1095. State = [[-0.21370897  0.04117557 -0.27001494 -0.8350896   0.3557632  -0.40204477
   0.          1.        ]]. Action = [[0.75533223 0.6217084 ]]. Reward = [5.3588367]
Abstract state at timestep 1095 is 5
State prediction error at timestep 1095 is 0.012
Human Feedback received at timestpe 1095 of 10
Current timestep = 1096. State = [[-0.2165029   0.02368256 -0.24251644 -0.7691539   0.3182594  -0.74889433
   0.          1.        ]]. Action = [[0.8352182 0.7422017]]. Reward = [10.554979]
Abstract state at timestep 1096 is 5
State prediction error at timestep 1096 is 0.012
Human Feedback received at timestpe 1096 of 10
Current timestep = 1097. State = [[-0.00175295  1.4066783  -0.17757879 -0.18852541  0.00203812  0.04022427
   0.          0.        ]]. Action = [[-0.21348834  0.40902376]]. Reward = [-100.]
Abstract state at timestep 1097 is 5
State prediction error at timestep 1097 is 0.012
Human Feedback received at timestpe 1097 of 10
Current timestep = 1098. State = [[-0.00345983  1.4018579  -0.17151555 -0.214238    0.00285792  0.01639805
   0.          0.        ]]. Action = [[-0.2799673   0.63219786]]. Reward = [-1.1638492]
Abstract state at timestep 1098 is 3
State prediction error at timestep 1098 is 0.012
Human Feedback received at timestpe 1098 of 10
Current timestep = 1099. State = [[-0.00522213  1.3964466  -0.17847131 -0.24050899  0.00507127  0.04427107
   0.          0.        ]]. Action = [[-0.22568828 -0.9365571 ]]. Reward = [-2.2145646]
Abstract state at timestep 1099 is 3
State prediction error at timestep 1099 is 0.012
Human Feedback received at timestpe 1099 of 10
Current timestep = 1100. State = [[-0.00698452  1.3904352  -0.17847835 -0.2671809   0.00728347  0.04424816
   0.          0.        ]]. Action = [[-0.55129814  0.16568136]]. Reward = [-1.8024857]
Abstract state at timestep 1100 is 3
State prediction error at timestep 1100 is 0.012
Human Feedback received at timestpe 1100 of 10
Current timestep = 1101. State = [[-0.00874691  1.3838238  -0.17848478 -0.2938501   0.00949562  0.04424739
   0.          0.        ]]. Action = [[-0.36001205 -0.13116324]]. Reward = [-1.8109771]
Abstract state at timestep 1101 is 3
State prediction error at timestep 1101 is 0.012
Human Feedback received at timestpe 1101 of 10
Current timestep = 1102. State = [[-0.01045837  1.3766149  -0.17208026 -0.32039386  0.01042157  0.01852073
   0.          0.        ]]. Action = [[-0.31461567  0.57664764]]. Reward = [-1.3774095]
Abstract state at timestep 1102 is 3
State prediction error at timestep 1102 is 0.012
Human Feedback received at timestpe 1102 of 10
Current timestep = 1103. State = [[-0.01222734  1.3693087  -0.17757401 -0.32472685  0.01109004  0.01337067
   0.          0.        ]]. Action = [[ 0.19208813 -0.41768026]]. Reward = [-0.15924768]
Abstract state at timestep 1103 is 3
State prediction error at timestep 1103 is 0.012
Human Feedback received at timestpe 1103 of 10
Current timestep = 1104. State = [[-0.01399632  1.3614025  -0.17757593 -0.3513995   0.01175835  0.01336746
   0.          0.        ]]. Action = [[-0.31571996  0.3697486 ]]. Reward = [-1.6390442]
Abstract state at timestep 1104 is 3
State prediction error at timestep 1104 is 0.012
Human Feedback received at timestpe 1104 of 10
Current timestep = 1105. State = [[-0.01562099  1.35397    -0.16387591 -0.3303412   0.01315303  0.0278962
   0.          0.        ]]. Action = [[ 0.85357296 -0.23048872]]. Reward = [2.8202899]
Abstract state at timestep 1105 is 3
State prediction error at timestep 1105 is 0.012
Human Feedback received at timestpe 1105 of 10
Current timestep = 1106. State = [[-0.01720924  1.3462262  -0.16042265 -0.34418514  0.01473199  0.03158205
   0.          0.        ]]. Action = [[ 0.04214215 -0.40980637]]. Reward = [-0.63978386]
Abstract state at timestep 1106 is 3
State prediction error at timestep 1106 is 0.012
Human Feedback received at timestpe 1106 of 10
Current timestep = 1107. State = [[-0.01885777  1.3384571  -0.16618854 -0.3453075   0.01605198  0.0264024
   0.          0.        ]]. Action = [[ 0.6567769  -0.13289559]]. Reward = [0.045848]
Abstract state at timestep 1107 is 3
State prediction error at timestep 1107 is 0.012
Human Feedback received at timestpe 1107 of 10
Current timestep = 1108. State = [[-0.02044392  1.3309535  -0.1580419  -0.33348978  0.01548508 -0.01133891
   0.          0.        ]]. Action = [[0.7233641  0.94947505]]. Reward = [1.9351379]
Abstract state at timestep 1108 is 3
State prediction error at timestep 1108 is 0.012
Human Feedback received at timestpe 1108 of 10
Current timestep = 1109. State = [[-0.02208309  1.3228464  -0.16470021 -0.36032477  0.01625477  0.01539504
   0.          0.        ]]. Action = [[-0.35145962 -0.6156328 ]]. Reward = [-2.001368]
Abstract state at timestep 1109 is 3
State prediction error at timestep 1109 is 0.012
Human Feedback received at timestpe 1109 of 10
Current timestep = 1110. State = [[-0.02372236  1.3141394  -0.16470301 -0.38698998  0.01702333  0.01537302
   0.          0.        ]]. Action = [[-0.09029263  0.13790894]]. Reward = [-1.6490299]
Abstract state at timestep 1110 is 3
State prediction error at timestep 1110 is 0.012
Human Feedback received at timestpe 1110 of 10
Current timestep = 1111. State = [[-0.02542782  1.3052468  -0.17103341 -0.39522868  0.0175023   0.00958024
   0.          0.        ]]. Action = [[0.36160707 0.25241554]]. Reward = [-0.3730015]
Abstract state at timestep 1111 is 3
State prediction error at timestep 1111 is 0.012
Human Feedback received at timestpe 1111 of 10
Current timestep = 1112. State = [[-0.02719107  1.2957494  -0.17828865 -0.42213407  0.0194365   0.03868755
   0.          0.        ]]. Action = [[-0.6451979 -0.8811558]]. Reward = [-2.033035]
Abstract state at timestep 1112 is 3
State prediction error at timestep 1112 is 0.012
Human Feedback received at timestpe 1112 of 10
Current timestep = 1113. State = [[-0.02895451  1.285652   -0.17829461 -0.44880125  0.02136967  0.03866694
   0.          0.        ]]. Action = [[-0.05830598 -0.21468842]]. Reward = [-1.6556164]
Abstract state at timestep 1113 is 3
State prediction error at timestep 1113 is 0.012
Human Feedback received at timestpe 1113 of 10
Current timestep = 1114. State = [[-0.03070393  1.2755523  -0.17562416 -0.44889033  0.0220509   0.01362565
   0.          0.        ]]. Action = [[0.3168794  0.60544133]]. Reward = [0.811463]
Abstract state at timestep 1114 is 3
State prediction error at timestep 1114 is 0.012
Human Feedback received at timestpe 1114 of 10
Current timestep = 1115. State = [[-0.03266096  1.2655408  -0.19772804 -0.44498098  0.02404035  0.03979278
   0.          0.        ]]. Action = [[ 0.61501896 -0.7844381 ]]. Reward = [0.04017242]
Abstract state at timestep 1115 is 3
State prediction error at timestep 1115 is 0.012
Human Feedback received at timestpe 1115 of 10
Current timestep = 1116. State = [[-0.03478708  1.2553351  -0.21538576 -0.45364147  0.02678281  0.05485421
   0.          0.        ]]. Action = [[ 0.5601392 -0.5366596]]. Reward = [-1.034151]
Abstract state at timestep 1116 is 3
State prediction error at timestep 1116 is 0.012
Human Feedback received at timestpe 1116 of 10
Current timestep = 1117. State = [[-0.0369133   1.2445292  -0.2153934  -0.48031157  0.02952494  0.05484756
   0.          0.        ]]. Action = [[-0.46960413 -0.17573798]]. Reward = [-1.6221604]
Abstract state at timestep 1117 is 3
State prediction error at timestep 1117 is 0.012
Human Feedback received at timestpe 1117 of 10
Current timestep = 1118. State = [[-0.03916492  1.2341619  -0.22969742 -0.46086684  0.03402065  0.08992204
   0.          0.        ]]. Action = [[ 0.5176197 -0.9039542]]. Reward = [1.471075]
Abstract state at timestep 1118 is 3
State prediction error at timestep 1118 is 0.012
Human Feedback received at timestpe 1118 of 10
Current timestep = 1119. State = [[-0.04150028  1.2242012  -0.23977384 -0.44284958  0.04018958  0.12338972
   0.          0.        ]]. Action = [[ 0.895502  -0.8369373]]. Reward = [1.1957172]
Abstract state at timestep 1119 is 3
State prediction error at timestep 1119 is 0.012
Human Feedback received at timestpe 1119 of 10
Current timestep = 1120. State = [[-0.04383583  1.213641   -0.23979118 -0.46952578  0.04635723  0.12336419
   0.          0.        ]]. Action = [[-0.38377863  0.4526608 ]]. Reward = [-1.931501]
Abstract state at timestep 1120 is 3
State prediction error at timestep 1120 is 0.012
Human Feedback received at timestpe 1120 of 10
Current timestep = 1121. State = [[-0.0460391   1.2028625  -0.22465535 -0.47918993  0.05065027  0.08586832
   0.          0.        ]]. Action = [[0.0646199 0.9375632]]. Reward = [0.24935749]
Abstract state at timestep 1121 is 3
State prediction error at timestep 1121 is 0.012
Human Feedback received at timestpe 1121 of 10
Current timestep = 1122. State = [[-0.04824152  1.1914625  -0.22459388 -0.5068146   0.0549434   0.0858628
   0.          0.        ]]. Action = [[-0.1419838   0.11558366]]. Reward = [-1.8100169]
Abstract state at timestep 1122 is 3
State prediction error at timestep 1122 is 0.012
Human Feedback received at timestpe 1122 of 10
Current timestep = 1123. State = [[-0.05044403  1.1794629  -0.22459373 -0.53348285  0.05923653  0.08586261
   0.          0.        ]]. Action = [[-0.7180029  -0.05836856]]. Reward = [-1.6877693]
Abstract state at timestep 1123 is 3
State prediction error at timestep 1123 is 0.012
Human Feedback received at timestpe 1123 of 10
Current timestep = 1124. State = [[-0.05264654  1.1668634  -0.22459361 -0.56015104  0.06352965  0.08586254
   0.          0.        ]]. Action = [[-0.25495237 -0.04025412]]. Reward = [-1.6470075]
Abstract state at timestep 1124 is 3
State prediction error at timestep 1124 is 0.012
Human Feedback received at timestpe 1124 of 10
Current timestep = 1125. State = [[-0.05489321  1.153666   -0.23011783 -0.5867946   0.06892626  0.10793207
   0.          0.        ]]. Action = [[-0.7355886  -0.59274405]]. Reward = [-1.9298962]
Abstract state at timestep 1125 is 3
State prediction error at timestep 1125 is 0.012
Human Feedback received at timestpe 1125 of 10
Current timestep = 1126. State = [[-0.05714045  1.1410905  -0.23043346 -0.5591868   0.0745795   0.11306477
   0.          0.        ]]. Action = [[0.9274534  0.01804018]]. Reward = [2.9404387]
Abstract state at timestep 1126 is 3
State prediction error at timestep 1126 is 0.012
Human Feedback received at timestpe 1126 of 10
Current timestep = 1127. State = [[-0.05938768  1.1279154  -0.23043318 -0.58585614  0.08023272  0.11306415
   0.          0.        ]]. Action = [[-0.22531807 -0.06339782]]. Reward = [-1.7350308]
Abstract state at timestep 1127 is 3
State prediction error at timestep 1127 is 0.012
Human Feedback received at timestpe 1127 of 10
Current timestep = 1128. State = [[-0.06144047  1.1146429  -0.21016702 -0.59016246  0.08507766  0.09689874
   0.          0.        ]]. Action = [[0.7493391 0.6214013]]. Reward = [0.85646635]
Abstract state at timestep 1128 is 3
State prediction error at timestep 1128 is 0.012
Human Feedback received at timestpe 1128 of 10
Current timestep = 1129. State = [[-0.06349335  1.1007706  -0.21016677 -0.61683106  0.0899226   0.09689866
   0.          0.        ]]. Action = [[-0.50473714  0.3664478 ]]. Reward = [-1.6294736]
Abstract state at timestep 1129 is 3
State prediction error at timestep 1129 is 0.012
Human Feedback received at timestpe 1129 of 10
Current timestep = 1130. State = [[-0.06559467  1.0871551  -0.21368751 -0.6053501   0.09344414  0.07043093
   0.          0.        ]]. Action = [[0.23529303 0.62408304]]. Reward = [1.7599846]
Abstract state at timestep 1130 is 3
State prediction error at timestep 1130 is 0.012
Human Feedback received at timestpe 1130 of 10
Current timestep = 1131. State = [[-0.06780138  1.0736254  -0.22608943 -0.60166776  0.09881908  0.10749855
   0.          0.        ]]. Action = [[ 0.7933438  -0.92032325]]. Reward = [0.4241083]
Abstract state at timestep 1131 is 3
State prediction error at timestep 1131 is 0.012
Human Feedback received at timestpe 1131 of 10
Current timestep = 1132. State = [[-0.07000808  1.0594962  -0.22608908 -0.62833685  0.10419399  0.10749833
   0.          0.        ]]. Action = [[-0.00529373 -0.08130425]]. Reward = [-1.6447735]
Abstract state at timestep 1132 is 3
State prediction error at timestep 1132 is 0.012
Human Feedback received at timestpe 1132 of 10
Current timestep = 1133. State = [[-0.07235718  1.045329   -0.23984507 -0.63000196  0.1090941   0.09800217
   0.          0.        ]]. Action = [[ 0.5502198  -0.08056515]]. Reward = [0.04131059]
Abstract state at timestep 1133 is 3
State prediction error at timestep 1133 is 0.012
Human Feedback received at timestpe 1133 of 10
Current timestep = 1134. State = [[-0.07487984  1.0313215  -0.25664848 -0.62288     0.11345121  0.08714211
   0.          0.        ]]. Action = [[0.48752928 0.28978467]]. Reward = [0.76360005]
Abstract state at timestep 1134 is 3
State prediction error at timestep 1134 is 0.012
Human Feedback received at timestpe 1134 of 10
Current timestep = 1135. State = [[-0.0773489   1.0167302  -0.24991302 -0.64873415  0.11643326  0.05964116
   0.          0.        ]]. Action = [[-0.03410465  0.5677208 ]]. Reward = [-1.0308658]
Abstract state at timestep 1135 is 3
State prediction error at timestep 1135 is 0.012
Human Feedback received at timestpe 1135 of 10
Current timestep = 1136. State = [[-0.07981806  1.001539   -0.24991293 -0.6754015   0.11941531  0.05964114
   0.          0.        ]]. Action = [[-0.17374682  0.31306553]]. Reward = [-1.2976921]
Abstract state at timestep 1136 is 3
State prediction error at timestep 1136 is 0.012
Human Feedback received at timestpe 1136 of 10
Current timestep = 1137. State = [[-0.08239651  0.98696923 -0.26079014 -0.64778906  0.12234376  0.0585691
   0.          0.        ]]. Action = [[ 0.92043126 -0.34987712]]. Reward = [3.0344253]
Abstract state at timestep 1137 is 3
State prediction error at timestep 1137 is 0.012
Human Feedback received at timestpe 1137 of 10
Current timestep = 1138. State = [[-0.08481912  0.9723859  -0.24385431 -0.64827615  0.12392926  0.03171005
   0.          0.        ]]. Action = [[0.8407217  0.81359756]]. Reward = [1.5424453]
Abstract state at timestep 1138 is 4
State prediction error at timestep 1138 is 0.012
Human Feedback received at timestpe 1138 of 10
Current timestep = 1139. State = [[-0.08718739  0.9572109  -0.23703727 -0.674461    0.12413754  0.00416543
   0.          0.        ]]. Action = [[-0.9930186  0.7516494]]. Reward = [-0.7807407]
Abstract state at timestep 1139 is 4
State prediction error at timestep 1139 is 0.012
Human Feedback received at timestpe 1139 of 10
Current timestep = 1140. State = [[-0.08961926  0.9420828  -0.2433538  -0.6723716   0.1243007   0.00326342
   0.          0.        ]]. Action = [[ 0.13854647 -0.28730667]]. Reward = [1.281243]
Abstract state at timestep 1140 is 4
State prediction error at timestep 1140 is 0.012
Human Feedback received at timestpe 1140 of 10
Current timestep = 1141. State = [[-0.0920722   0.9270999  -0.24565211 -0.6659393   0.12465177  0.00702174
   0.          0.        ]]. Action = [[ 0.96769047 -0.23393238]]. Reward = [1.6625514]
Abstract state at timestep 1141 is 4
State prediction error at timestep 1141 is 0.012
Human Feedback received at timestpe 1141 of 10
Current timestep = 1142. State = [[-0.09465218  0.9122867  -0.25805965 -0.6583691   0.12471508  0.00126619
   0.          0.        ]]. Action = [[ 0.21223938 -0.10857886]]. Reward = [1.5259677]
Abstract state at timestep 1142 is 4
State prediction error at timestep 1142 is 0.012
Human Feedback received at timestpe 1142 of 10
Current timestep = 1143. State = [[-0.09721442  0.8982956  -0.25499743 -0.6217245   0.12349339 -0.02443385
   0.          0.        ]]. Action = [[0.9860523 0.7352762]]. Reward = [4.681769]
Abstract state at timestep 1143 is 4
State prediction error at timestep 1143 is 0.012
Human Feedback received at timestpe 1143 of 10
Current timestep = 1144. State = [[-0.09987545  0.8846303  -0.2628942  -0.607078    0.1202977  -0.06391345
   0.          0.        ]]. Action = [[0.41457903 0.94664836]]. Reward = [2.4509232]
Abstract state at timestep 1144 is 4
State prediction error at timestep 1144 is 0.012
Human Feedback received at timestpe 1144 of 10
Current timestep = 1145. State = [[-0.1023819   0.8709147  -0.24635617 -0.6092433   0.11603301 -0.08529378
   0.          0.        ]]. Action = [[0.8982682 0.7069384]]. Reward = [1.8933166]
Abstract state at timestep 1145 is 4
State prediction error at timestep 1145 is 0.012
Human Feedback received at timestpe 1145 of 10
Current timestep = 1146. State = [[-0.10488834  0.85659945 -0.24635589 -0.6359115   0.11176832 -0.0852937
   0.          0.        ]]. Action = [[-0.7910394  -0.15796894]]. Reward = [-0.66172326]
Abstract state at timestep 1146 is 4
State prediction error at timestep 1146 is 0.012
Human Feedback received at timestpe 1146 of 10
Current timestep = 1147. State = [[-0.10734854  0.84169066 -0.24054909 -0.6622134   0.10633262 -0.10871391
   0.          0.        ]]. Action = [[-0.3198915  0.6663703]]. Reward = [-0.286161]
Abstract state at timestep 1147 is 4
State prediction error at timestep 1147 is 0.012
Human Feedback received at timestpe 1147 of 10
Current timestep = 1148. State = [[-0.10988216  0.82699114 -0.24914518 -0.6530101   0.10215012 -0.08365041
   0.          0.        ]]. Action = [[ 0.05189538 -0.6085864 ]]. Reward = [2.2296796]
Abstract state at timestep 1148 is 4
State prediction error at timestep 1148 is 0.012
Human Feedback received at timestpe 1148 of 10
Current timestep = 1149. State = [[-0.11254434  0.8121722  -0.26156408 -0.6583167   0.0975265  -0.0924726
   0.          0.        ]]. Action = [[0.06770885 0.27689946]]. Reward = [0.7896864]
Abstract state at timestep 1149 is 4
State prediction error at timestep 1149 is 0.012
Human Feedback received at timestpe 1149 of 10
Current timestep = 1150. State = [[-0.11520662  0.7967533  -0.26156384 -0.68498504  0.09290287 -0.09247248
   0.          0.        ]]. Action = [[-0.10191631  0.24360919]]. Reward = [-0.5332664]
Abstract state at timestep 1150 is 4
State prediction error at timestep 1150 is 0.012
Human Feedback received at timestpe 1150 of 10
Current timestep = 1151. State = [[-0.11780701  0.7807417  -0.25378755 -0.71125275  0.08671468 -0.1237641
   0.          0.        ]]. Action = [[-0.7960041   0.74184394]]. Reward = [-0.05233818]
Abstract state at timestep 1151 is 4
State prediction error at timestep 1151 is 0.012
Human Feedback received at timestpe 1151 of 10
Current timestep = 1152. State = [[-0.12034579  0.76414764 -0.2460422  -0.73708045  0.07895365 -0.15522046
   0.          0.        ]]. Action = [[-0.6154616  0.736055 ]]. Reward = [0.16668473]
Abstract state at timestep 1152 is 4
State prediction error at timestep 1152 is 0.012
Human Feedback received at timestpe 1152 of 10
Current timestep = 1153. State = [[-0.12278347  0.7482528  -0.2367189  -0.70607823  0.07197467 -0.13957979
   0.          0.        ]]. Action = [[ 0.8761289 -0.4359668]]. Reward = [5.1829696]
Abstract state at timestep 1153 is 4
State prediction error at timestep 1153 is 0.012
Human Feedback received at timestpe 1153 of 10
Current timestep = 1154. State = [[-0.12522116  0.7317587  -0.23671845 -0.732749    0.06499571 -0.13957928
   0.          0.        ]]. Action = [[-0.6189437  -0.44297576]]. Reward = [-0.24907196]
Abstract state at timestep 1154 is 4
State prediction error at timestep 1154 is 0.012
Human Feedback received at timestpe 1154 of 10
Current timestep = 1155. State = [[-0.12765893  0.71466523 -0.23671801 -0.7594196   0.05801677 -0.13957885
   0.          0.        ]]. Action = [[-0.32091618  0.48023248]]. Reward = [-0.20242214]
Abstract state at timestep 1155 is 4
State prediction error at timestep 1155 is 0.012
Human Feedback received at timestpe 1155 of 10
Current timestep = 1156. State = [[-0.13009682  0.69697255 -0.23671761 -0.7860903   0.05103784 -0.13957839
   0.          0.        ]]. Action = [[-0.10825789  0.39184558]]. Reward = [-0.15547982]
Abstract state at timestep 1156 is 4
State prediction error at timestep 1156 is 0.012
Human Feedback received at timestpe 1156 of 10
Current timestep = 1157. State = [[-0.13258305  0.6786714  -0.2428062  -0.81319886  0.04528521 -0.11505254
   0.          0.        ]]. Action = [[-0.7208042  -0.76718426]]. Reward = [-0.46827507]
Abstract state at timestep 1157 is 4
State prediction error at timestep 1157 is 0.012
Human Feedback received at timestpe 1157 of 10
Current timestep = 1158. State = [[-0.13511714  0.6603719  -0.2460355  -0.8131054   0.0380022  -0.14566049
   0.          0.        ]]. Action = [[0.40976465 0.695091  ]]. Reward = [2.1567245]
Abstract state at timestep 1158 is 4
State prediction error at timestep 1158 is 0.012
Human Feedback received at timestpe 1158 of 10
Current timestep = 1159. State = [[-0.13768777  0.6414668  -0.25062388 -0.8400785   0.03164183 -0.12720726
   0.          0.        ]]. Action = [[-0.525694  -0.5215869]]. Reward = [-0.29730085]
Abstract state at timestep 1159 is 4
State prediction error at timestep 1159 is 0.012
Human Feedback received at timestpe 1159 of 10
Current timestep = 1160. State = [[-0.14032412  0.6219582  -0.25886208 -0.8669527   0.02693298 -0.09417723
   0.          0.        ]]. Action = [[-0.60104907 -0.99558425]]. Reward = [-0.5211663]
Abstract state at timestep 1160 is 4
State prediction error at timestep 1160 is 0.012
Human Feedback received at timestpe 1160 of 10
Current timestep = 1161. State = [[-0.14292899  0.6028585  -0.25698307 -0.8488207   0.02347885 -0.06908263
   0.          0.        ]]. Action = [[ 0.3621645  -0.52445275]]. Reward = [3.7180185]
Abstract state at timestep 1161 is 4
State prediction error at timestep 1161 is 0.012
Human Feedback received at timestpe 1161 of 10
Current timestep = 1162. State = [[-0.14556447  0.5837675  -0.25880226 -0.8484215   0.01878816 -0.09381369
   0.          0.        ]]. Action = [[0.487666   0.54308784]]. Reward = [2.0076888]
Abstract state at timestep 1162 is 4
State prediction error at timestep 1162 is 0.012
Human Feedback received at timestpe 1162 of 10
Current timestep = 1163. State = [[-0.14824219  0.565438   -0.26290038 -0.81458896  0.01398115 -0.0961403
   0.          0.        ]]. Action = [[ 0.75841105 -0.16657639]]. Reward = [5.031783]
Abstract state at timestep 1163 is 4
State prediction error at timestep 1163 is 0.012
Human Feedback received at timestpe 1163 of 10
Current timestep = 1164. State = [[-0.15095262  0.54743093 -0.26748088 -0.80028564  0.01045905 -0.07044192
   0.          0.        ]]. Action = [[ 0.25439203 -0.6244842 ]]. Reward = [3.029841]
Abstract state at timestep 1164 is 4
State prediction error at timestep 1164 is 0.012
Human Feedback received at timestpe 1164 of 10
Current timestep = 1165. State = [[-0.15347414  0.52962494 -0.24727213 -0.79135114  0.00563536 -0.09647392
   0.          0.        ]]. Action = [[0.38244557 0.7543514 ]]. Reward = [3.3691144]
Abstract state at timestep 1165 is 4
State prediction error at timestep 1165 is 0.012
Human Feedback received at timestpe 1165 of 10
Current timestep = 1166. State = [[-0.1559166   0.51122993 -0.23733822 -0.8175466  -0.00117873 -0.13628173
   0.          0.        ]]. Action = [[-0.78204346  0.916147  ]]. Reward = [-0.10981985]
Abstract state at timestep 1166 is 4
State prediction error at timestep 1166 is 0.012
Human Feedback received at timestpe 1166 of 10
Current timestep = 1167. State = [[-0.15840578  0.49313802 -0.24179752 -0.80410737 -0.00821281 -0.14068149
   0.          0.        ]]. Action = [[ 0.51864433 -0.16540015]]. Reward = [1.8834924]
Abstract state at timestep 1167 is 4
State prediction error at timestep 1167 is 0.012
Human Feedback received at timestpe 1167 of 10
Current timestep = 1168. State = [[-0.16099472  0.4749947  -0.25128442 -0.8064293  -0.0157219  -0.15018204
   0.          0.        ]]. Action = [[0.45803785 0.43558562]]. Reward = [0.17245723]
Abstract state at timestep 1168 is 5
State prediction error at timestep 1168 is 0.012
Human Feedback received at timestpe 1168 of 10
Current timestep = 1169. State = [[-0.16360836  0.4571699  -0.2525021  -0.7923311  -0.02446412 -0.17484441
   0.          0.        ]]. Action = [[0.38833714 0.53009677]]. Reward = [1.8069983]
Abstract state at timestep 1169 is 5
State prediction error at timestep 1169 is 0.012
Human Feedback received at timestpe 1169 of 10
Current timestep = 1170. State = [[-0.1662179   0.43941766 -0.25330377 -0.7891321  -0.03202041 -0.15112574
   0.          0.        ]]. Action = [[ 0.01557243 -0.5694128 ]]. Reward = [0.9311351]
Abstract state at timestep 1170 is 5
State prediction error at timestep 1170 is 0.012
Human Feedback received at timestpe 1170 of 10
Current timestep = 1171. State = [[-0.16886711  0.4220303  -0.25860363 -0.7729228  -0.03825978 -0.12478767
   0.          0.        ]]. Action = [[ 0.2662555 -0.6675591]]. Reward = [2.0657032]
Abstract state at timestep 1171 is 5
State prediction error at timestep 1171 is 0.012
Human Feedback received at timestpe 1171 of 10
Current timestep = 1172. State = [[-0.1714222   0.40444323 -0.2495817  -0.78180915 -0.04411118 -0.11702813
   0.          0.        ]]. Action = [[ 0.0535686  -0.03127098]]. Reward = [0.22137713]
Abstract state at timestep 1172 is 5
State prediction error at timestep 1172 is 0.012
Human Feedback received at timestpe 1172 of 10
Current timestep = 1173. State = [[-0.17403841  0.38698077 -0.2576775  -0.77623093 -0.04801137 -0.07800367
   0.          0.        ]]. Action = [[ 0.41535342 -0.9825558 ]]. Reward = [1.1436552]
Abstract state at timestep 1173 is 5
State prediction error at timestep 1173 is 0.012
Human Feedback received at timestpe 1173 of 10
Current timestep = 1174. State = [[-0.17665462  0.36891854 -0.2576776  -0.80289894 -0.05191156 -0.07800357
   0.          0.        ]]. Action = [[-0.5737407  -0.19636309]]. Reward = [-1.3969346]
Abstract state at timestep 1174 is 5
State prediction error at timestep 1174 is 0.012
Human Feedback received at timestpe 1174 of 10
Current timestep = 1175. State = [[-0.17915955  0.35103688 -0.24694362 -0.79486823 -0.05542269 -0.0702226
   0.          0.        ]]. Action = [[0.85401654 0.19064772]]. Reward = [1.9518028]
Abstract state at timestep 1175 is 5
State prediction error at timestep 1175 is 0.012
Human Feedback received at timestpe 1175 of 10
Current timestep = 1176. State = [[-0.18159075  0.33315605 -0.2411581  -0.7947778  -0.05736081 -0.03876241
   0.          0.        ]]. Action = [[ 0.06776392 -0.75269806]]. Reward = [1.2700636]
Abstract state at timestep 1176 is 5
State prediction error at timestep 1176 is 0.012
Human Feedback received at timestpe 1176 of 10
Current timestep = 1177. State = [[-0.1839983   0.31514227 -0.24040833 -0.8006243  -0.05770167 -0.00681728
   0.          0.        ]]. Action = [[ 0.5090854  -0.74670553]]. Reward = [0.6297741]
Abstract state at timestep 1177 is 5
State prediction error at timestep 1177 is 0.012
Human Feedback received at timestpe 1177 of 10
Current timestep = 1178. State = [[-0.18643828  0.29708135 -0.24339938 -0.8027302  -0.05829065 -0.01177965
   0.          0.        ]]. Action = [[0.44686353 0.24806595]]. Reward = [0.8548125]
Abstract state at timestep 1178 is 5
State prediction error at timestep 1178 is 0.012
Human Feedback received at timestpe 1178 of 10
Current timestep = 1179. State = [[-0.18886252  0.27928662 -0.24175143 -0.7909038  -0.05896321 -0.01345089
   0.          0.        ]]. Action = [[0.5436349  0.48469043]]. Reward = [2.2392883]
Abstract state at timestep 1179 is 5
State prediction error at timestep 1179 is 0.012
Human Feedback received at timestpe 1179 of 10
Current timestep = 1180. State = [[-0.1912198   0.26088488 -0.2333436  -0.81795007 -0.06132507 -0.04723728
   0.          0.        ]]. Action = [[-0.9052147   0.95646024]]. Reward = [-1.2514921]
Abstract state at timestep 1180 is 5
State prediction error at timestep 1180 is 0.012
Human Feedback received at timestpe 1180 of 10
Current timestep = 1181. State = [[-0.19360189  0.24255545 -0.23443277 -0.814801   -0.06505951 -0.07468902
   0.          0.        ]]. Action = [[0.64762664 0.5644152 ]]. Reward = [0.9465125]
Abstract state at timestep 1181 is 5
State prediction error at timestep 1181 is 0.012
Human Feedback received at timestpe 1181 of 10
Current timestep = 1182. State = [[-0.19598398  0.22362621 -0.23443289 -0.84146875 -0.06879396 -0.07468896
   0.          0.        ]]. Action = [[-0.6523683   0.15130746]]. Reward = [-1.6399705]
Abstract state at timestep 1182 is 5
State prediction error at timestep 1182 is 0.012
Human Feedback received at timestpe 1182 of 10
Current timestep = 1183. State = [[-0.19836608  0.20409717 -0.23443301 -0.8681366  -0.07252839 -0.07468887
   0.          0.        ]]. Action = [[-0.03483081  0.4672519 ]]. Reward = [-1.6713449]
Abstract state at timestep 1183 is 5
State prediction error at timestep 1183 is 0.012
Human Feedback received at timestpe 1183 of 10
Current timestep = 1184. State = [[-0.20074812  0.18396829 -0.23443313 -0.89480436 -0.07626284 -0.07468881
   0.          0.        ]]. Action = [[-0.21962357 -0.30098987]]. Reward = [-1.7187067]
Abstract state at timestep 1184 is 5
State prediction error at timestep 1184 is 0.012
Human Feedback received at timestpe 1184 of 10
Current timestep = 1185. State = [[-0.20313016  0.16323961 -0.23443325 -0.92147225 -0.07999729 -0.07468878
   0.          0.        ]]. Action = [[-0.56230617 -0.02628273]]. Reward = [-1.785507]
Abstract state at timestep 1185 is 5
State prediction error at timestep 1185 is 0.012
Human Feedback received at timestpe 1185 of 10
Current timestep = 1186. State = [[-0.2055122   0.1419111  -0.23443337 -0.9481401  -0.08373173 -0.0746887
   0.          0.        ]]. Action = [[-0.1901784  -0.26276088]]. Reward = [-1.8755479]
Abstract state at timestep 1186 is 5
State prediction error at timestep 1186 is 0.012
Human Feedback received at timestpe 1186 of 10
Current timestep = 1187. State = [[-0.20776597  0.12069827 -0.21963759 -0.9431223  -0.08942442 -0.11385398
   0.          0.        ]]. Action = [[0.83116126 0.9892664 ]]. Reward = [0.9064132]
Abstract state at timestep 1187 is 5
State prediction error at timestep 1187 is 0.012
Human Feedback received at timestpe 1187 of 10
Current timestep = 1188. State = [[-0.21009426  0.09888812 -0.22896893 -0.9695769  -0.09324871 -0.07648591
   0.          0.        ]]. Action = [[-0.64777684 -0.77478915]]. Reward = [-2.386597]
Abstract state at timestep 1188 is 5
State prediction error at timestep 1188 is 0.012
Human Feedback received at timestpe 1188 of 10
Current timestep = 1189. State = [[-0.21242246  0.07647815 -0.2289691  -0.9962447  -0.097073   -0.07648586
   0.          0.        ]]. Action = [[-0.88429654  0.07841158]]. Reward = [-2.3363438]
Abstract state at timestep 1189 is 5
State prediction error at timestep 1189 is 0.012
Human Feedback received at timestpe 1189 of 10
Current timestep = 1190. State = [[-0.21463847  0.05410875 -0.21679541 -0.9945149  -0.10183933 -0.09532657
   0.          0.        ]]. Action = [[0.27205276 0.5066619 ]]. Reward = [0.19382082]
Abstract state at timestep 1190 is 5
State prediction error at timestep 1190 is 0.012
Human Feedback received at timestpe 1190 of 10
Current timestep = 1191. State = [[-0.21685442  0.03113967 -0.21679568 -1.0211834  -0.10660566 -0.09532643
   0.          1.        ]]. Action = [[-0.3894     -0.49601126]]. Reward = [7.1436424]
Abstract state at timestep 1191 is 5
State prediction error at timestep 1191 is 0.012
Human Feedback received at timestpe 1191 of 10
Current timestep = 1192. State = [[-0.21881142  0.00845762 -0.1693522  -1.0099132  -0.13056658 -0.47646898
   1.          1.        ]]. Action = [[-0.27806306  0.8954475 ]]. Reward = [9.580278]
Abstract state at timestep 1192 is 5
State prediction error at timestep 1192 is 0.012
Human Feedback received at timestpe 1192 of 10
Current timestep = 1193. State = [[-0.22090688 -0.01308427 -0.18888544 -0.95941234 -0.15148897 -0.41884297
   1.          1.        ]]. Action = [[0.20449328 0.9023584 ]]. Reward = [2.0865998]
Abstract state at timestep 1193 is 5
State prediction error at timestep 1193 is 0.012
Human Feedback received at timestpe 1193 of 10
Current timestep = 1194. State = [[-0.00203009  1.4029598  -0.20564818 -0.3537866   0.00235924  0.04658238
   0.          0.        ]]. Action = [[-0.94576424  0.4094882 ]]. Reward = [-100.]
Abstract state at timestep 1194 is 5
State prediction error at timestep 1194 is 0.012
Human Feedback received at timestpe 1194 of 10
Current timestep = 1195. State = [[-0.00406065  1.3944228  -0.20537022 -0.37942728  0.00466096  0.04603933
   0.          0.        ]]. Action = [[-0.67404556 -0.36075795]]. Reward = [-1.5996866]
Abstract state at timestep 1195 is 3
State prediction error at timestep 1195 is 0.012
Human Feedback received at timestpe 1195 of 10
Current timestep = 1196. State = [[-0.00609112  1.3852853  -0.20537743 -0.40611932  0.00696142  0.04601356
   0.          0.        ]]. Action = [[-0.08571553 -0.01803154]]. Reward = [-1.682512]
Abstract state at timestep 1196 is 3
State prediction error at timestep 1196 is 0.012
Human Feedback received at timestpe 1196 of 10
Current timestep = 1197. State = [[-0.00812159  1.3755478  -0.20538422 -0.4327921   0.0092616   0.04600798
   0.          0.        ]]. Action = [[-0.28132224 -0.37717366]]. Reward = [-1.6529701]
Abstract state at timestep 1197 is 3
State prediction error at timestep 1197 is 0.012
Human Feedback received at timestpe 1197 of 10
Current timestep = 1198. State = [[-0.01015224  1.3652103  -0.205391   -0.45946133  0.01156141  0.04600076
   0.          0.        ]]. Action = [[-0.20962542  0.30013382]]. Reward = [-1.6202672]
Abstract state at timestep 1198 is 3
State prediction error at timestep 1198 is 0.012
Human Feedback received at timestpe 1198 of 10
Current timestep = 1199. State = [[-0.012183    1.3542728  -0.20539781 -0.48612988  0.01386089  0.04599385
   0.          0.        ]]. Action = [[-0.83405226 -0.4948995 ]]. Reward = [-1.5840527]
Abstract state at timestep 1199 is 3
State prediction error at timestep 1199 is 0.012
Human Feedback received at timestpe 1199 of 10
Current timestep = 1200. State = [[-0.01417065  1.3427329  -0.19999485 -0.51289713  0.01507597  0.02430401
   0.          0.        ]]. Action = [[-0.3135656  0.6714401]]. Reward = [-1.2665725]
Abstract state at timestep 1200 is 3
State prediction error at timestep 1200 is 0.012
Human Feedback received at timestpe 1200 of 10
Current timestep = 1201. State = [[-0.01608267  1.3305871  -0.19051787 -0.53980327  0.01439223 -0.01367614
   0.          0.        ]]. Action = [[-0.94319475  0.8964596 ]]. Reward = [-0.93891394]
Abstract state at timestep 1201 is 3
State prediction error at timestep 1201 is 0.012
Human Feedback received at timestpe 1201 of 10
Current timestep = 1202. State = [[-0.01799479  1.3178414  -0.19051546 -0.5664717   0.01370919 -0.01366227
   0.          0.        ]]. Action = [[-0.26508415 -0.19085813]]. Reward = [-1.1810119]
Abstract state at timestep 1202 is 3
State prediction error at timestep 1202 is 0.012
Human Feedback received at timestpe 1202 of 10
Current timestep = 1203. State = [[-0.01998425  1.3044901  -0.20023727 -0.5934008   0.01497628  0.02534439
   0.          0.        ]]. Action = [[-0.35014606 -0.8332626 ]]. Reward = [-1.6819639]
Abstract state at timestep 1203 is 3
State prediction error at timestep 1203 is 0.012
Human Feedback received at timestpe 1203 of 10
Current timestep = 1204. State = [[-0.02202864  1.2905314  -0.20712066 -0.6204134   0.01762302  0.05293971
   0.          0.        ]]. Action = [[-0.97841424 -0.7845176 ]]. Reward = [-1.6757185]
Abstract state at timestep 1204 is 3
State prediction error at timestep 1204 is 0.012
Human Feedback received at timestpe 1204 of 10
Current timestep = 1205. State = [[-0.0241683   1.2765031  -0.21762273 -0.62353     0.02124059  0.07235835
   0.          0.        ]]. Action = [[ 0.22203958 -0.53988665]]. Reward = [0.20321733]
Abstract state at timestep 1205 is 3
State prediction error at timestep 1205 is 0.012
Human Feedback received at timestpe 1205 of 10
Current timestep = 1206. State = [[-0.02623358  1.2630401  -0.2106175  -0.598417    0.0252874   0.0809435
   0.          0.        ]]. Action = [[ 0.60573936 -0.2128365 ]]. Reward = [3.2980487]
Abstract state at timestep 1206 is 3
State prediction error at timestep 1206 is 0.012
Human Feedback received at timestpe 1206 of 10
Current timestep = 1207. State = [[-0.02827911  1.2497462  -0.20879367 -0.5909179   0.02948842  0.08402792
   0.          0.        ]]. Action = [[0.03216588 0.02834129]]. Reward = [1.5175864]
Abstract state at timestep 1207 is 3
State prediction error at timestep 1207 is 0.012
Human Feedback received at timestpe 1207 of 10
Current timestep = 1208. State = [[-0.03021698  1.2365497  -0.198614   -0.5866098   0.03426042  0.09544857
   0.          0.        ]]. Action = [[0.93328404 0.22517633]]. Reward = [1.287491]
Abstract state at timestep 1208 is 3
State prediction error at timestep 1208 is 0.012
Human Feedback received at timestpe 1208 of 10
Current timestep = 1209. State = [[-0.0321166   1.2227614  -0.19379467 -0.61290437  0.03805839  0.07596617
   0.          0.        ]]. Action = [[-0.6423526  0.6058736]]. Reward = [-1.373565]
Abstract state at timestep 1209 is 3
State prediction error at timestep 1209 is 0.012
Human Feedback received at timestpe 1209 of 10
Current timestep = 1210. State = [[-0.03394813  1.2083778  -0.18525966 -0.63932353  0.04014161  0.04166811
   0.          0.        ]]. Action = [[-0.4041376   0.73122776]]. Reward = [-1.0785663]
Abstract state at timestep 1210 is 3
State prediction error at timestep 1210 is 0.012
Human Feedback received at timestpe 1210 of 10
Current timestep = 1211. State = [[-0.03577967  1.1933942  -0.18526523 -0.6659927   0.04222502  0.04167224
   0.          0.        ]]. Action = [[-0.40116775  0.3625015 ]]. Reward = [-1.2815967]
Abstract state at timestep 1211 is 3
State prediction error at timestep 1211 is 0.012
Human Feedback received at timestpe 1211 of 10
Current timestep = 1212. State = [[-0.03761129  1.1778108  -0.18527101 -0.6926618   0.04430774  0.04165827
   0.          0.        ]]. Action = [[-0.07372743 -0.10761243]]. Reward = [-1.229406]
Abstract state at timestep 1212 is 3
State prediction error at timestep 1212 is 0.012
Human Feedback received at timestpe 1212 of 10
Current timestep = 1213. State = [[-0.03943891  1.1629571  -0.18508306 -0.66023386  0.04659193  0.04568805
   0.          0.        ]]. Action = [[0.81060624 0.25468063]]. Reward = [4.1111665]
Abstract state at timestep 1213 is 3
State prediction error at timestep 1213 is 0.012
Human Feedback received at timestpe 1213 of 10
Current timestep = 1214. State = [[-0.04140663  1.1483448  -0.19855008 -0.64949304  0.0483451   0.03506681
   0.          0.        ]]. Action = [[0.41178024 0.31611145]]. Reward = [1.7185417]
Abstract state at timestep 1214 is 3
State prediction error at timestep 1214 is 0.012
Human Feedback received at timestpe 1214 of 10
Current timestep = 1215. State = [[-0.04335461  1.1335732  -0.19672403 -0.65657717  0.05025728  0.03824701
   0.          0.        ]]. Action = [[0.21793151 0.14701807]]. Reward = [0.4698579]
Abstract state at timestep 1215 is 3
State prediction error at timestep 1215 is 0.012
Human Feedback received at timestpe 1215 of 10
Current timestep = 1216. State = [[-0.04521122  1.1182036  -0.1852791  -0.68307877  0.04987473 -0.00765137
   0.          0.        ]]. Action = [[-0.9439955  0.998947 ]]. Reward = [-0.6977794]
Abstract state at timestep 1216 is 3
State prediction error at timestep 1216 is 0.012
Human Feedback received at timestpe 1216 of 10
Current timestep = 1217. State = [[-0.04706793  1.1022341  -0.18527746 -0.70974606  0.04949327 -0.0076301
   0.          0.        ]]. Action = [[-0.2642988   0.16068304]]. Reward = [-0.9510018]
Abstract state at timestep 1217 is 3
State prediction error at timestep 1217 is 0.012
Human Feedback received at timestpe 1217 of 10
Current timestep = 1218. State = [[-0.04909592  1.0866603  -0.20177345 -0.6921306   0.04846965 -0.0204738
   0.          0.        ]]. Action = [[ 0.6396098  -0.37181604]]. Reward = [2.662269]
Abstract state at timestep 1218 is 3
State prediction error at timestep 1218 is 0.012
Human Feedback received at timestpe 1218 of 10
Current timestep = 1219. State = [[-0.05112333  1.0704651  -0.20169981 -0.719756    0.04744648 -0.02046368
   0.          0.        ]]. Action = [[-0.50494206  0.05816877]]. Reward = [-0.94346374]
Abstract state at timestep 1219 is 3
State prediction error at timestep 1219 is 0.012
Human Feedback received at timestpe 1219 of 10
Current timestep = 1220. State = [[-0.05307894  1.0536714  -0.19270284 -0.7462969   0.04462129 -0.05650347
   0.          0.        ]]. Action = [[-0.7346742  0.9287019]]. Reward = [-0.40669018]
Abstract state at timestep 1220 is 3
State prediction error at timestep 1220 is 0.012
Human Feedback received at timestpe 1220 of 10
Current timestep = 1221. State = [[-0.05510311  1.0362674  -0.20130989 -0.7734839   0.04352689 -0.02188819
   0.          0.        ]]. Action = [[-0.5703734  -0.72642225]]. Reward = [-1.0324348]
Abstract state at timestep 1221 is 3
State prediction error at timestep 1221 is 0.012
Human Feedback received at timestpe 1221 of 10
Current timestep = 1222. State = [[-0.05728054  1.0189017  -0.21838132 -0.77182984  0.04415738  0.01260963
   0.          0.        ]]. Action = [[ 0.00842249 -0.8657336 ]]. Reward = [1.1940026]
Abstract state at timestep 1222 is 3
State prediction error at timestep 1222 is 0.012
Human Feedback received at timestpe 1222 of 10
Current timestep = 1223. State = [[-0.05930958  1.0017828  -0.20206901 -0.7608138   0.04332899 -0.01656777
   0.          0.        ]]. Action = [[0.9843544 0.8458307]]. Reward = [2.9510329]
Abstract state at timestep 1223 is 3
State prediction error at timestep 1223 is 0.012
Human Feedback received at timestpe 1223 of 10
Current timestep = 1224. State = [[-0.06127043  0.9840789  -0.19351467 -0.7867715   0.04077742 -0.05103111
   0.          0.        ]]. Action = [[-0.16338217  0.90381193]]. Reward = [-0.31967264]
Abstract state at timestep 1224 is 3
State prediction error at timestep 1224 is 0.012
Human Feedback received at timestpe 1224 of 10
Current timestep = 1225. State = [[-0.06318321  0.96625715 -0.1889824  -0.7920159   0.03850913 -0.04536558
   0.          0.        ]]. Action = [[ 0.44717753 -0.06595856]]. Reward = [1.373146]
Abstract state at timestep 1225 is 4
State prediction error at timestep 1225 is 0.012
Human Feedback received at timestpe 1225 of 10
Current timestep = 1226. State = [[-0.06504574  0.94783634 -0.18267731 -0.8186211   0.03497821 -0.07061831
   0.          0.        ]]. Action = [[-0.83561933  0.7509465 ]]. Reward = [-0.29448998]
Abstract state at timestep 1226 is 4
State prediction error at timestep 1226 is 0.012
Human Feedback received at timestpe 1226 of 10
Current timestep = 1227. State = [[-0.06690826  0.92881554 -0.18267725 -0.8452887   0.0314473  -0.07061826
   0.          0.        ]]. Action = [[-0.20654911 -0.32690245]]. Reward = [-0.3672722]
Abstract state at timestep 1227 is 4
State prediction error at timestep 1227 is 0.012
Human Feedback received at timestpe 1227 of 10
Current timestep = 1228. State = [[-0.06880493  0.9098747  -0.18599558 -0.8417421   0.02782443 -0.07245725
   0.          0.        ]]. Action = [[ 0.19033384 -0.09375268]]. Reward = [2.33436]
Abstract state at timestep 1228 is 4
State prediction error at timestep 1228 is 0.012
Human Feedback received at timestpe 1228 of 10
Current timestep = 1229. State = [[-0.0707015   0.89033407 -0.18599552 -0.8684098   0.02420157 -0.07245716
   0.          0.        ]]. Action = [[-0.55914307  0.22672677]]. Reward = [-0.3099701]
Abstract state at timestep 1229 is 4
State prediction error at timestep 1229 is 0.012
Human Feedback received at timestpe 1229 of 10
Current timestep = 1230. State = [[-0.07258739  0.87099826 -0.18621317 -0.8593333   0.02185873 -0.04685692
   0.          0.        ]]. Action = [[ 0.4779836 -0.562859 ]]. Reward = [2.790328]
Abstract state at timestep 1230 is 4
State prediction error at timestep 1230 is 0.012
Human Feedback received at timestpe 1230 of 10
Current timestep = 1231. State = [[-0.0744071   0.8519596  -0.17996688 -0.84613883  0.01988224 -0.03953008
   0.          0.        ]]. Action = [[0.6919309 0.3957746]]. Reward = [3.246532]
Abstract state at timestep 1231 is 4
State prediction error at timestep 1231 is 0.012
Human Feedback received at timestpe 1231 of 10
Current timestep = 1232. State = [[-0.07627773  0.83350486 -0.18641928 -0.8201955   0.01924428 -0.01275878
   0.          0.        ]]. Action = [[ 0.5110729  -0.65617865]]. Reward = [4.034115]
Abstract state at timestep 1232 is 4
State prediction error at timestep 1232 is 0.012
Human Feedback received at timestpe 1232 of 10
Current timestep = 1233. State = [[-0.07807951  0.8144534  -0.1777732  -0.846703    0.016874   -0.0474057
   0.          0.        ]]. Action = [[-0.94378114  0.7569829 ]]. Reward = [-0.3106784]
Abstract state at timestep 1233 is 4
State prediction error at timestep 1233 is 0.012
Human Feedback received at timestpe 1233 of 10
Current timestep = 1234. State = [[-0.07976399  0.7960128  -0.16412935 -0.8195353   0.0126063  -0.0853539
   0.          0.        ]]. Action = [[0.8564229 0.9938669]]. Reward = [4.872858]
Abstract state at timestep 1234 is 4
State prediction error at timestep 1234 is 0.012
Human Feedback received at timestpe 1234 of 10
Current timestep = 1235. State = [[-0.08144846  0.7769726  -0.16412932 -0.84620357  0.0083386  -0.08535378
   0.          0.        ]]. Action = [[-0.18927604 -0.47485673]]. Reward = [-0.31279466]
Abstract state at timestep 1235 is 4
State prediction error at timestep 1235 is 0.012
Human Feedback received at timestpe 1235 of 10
Current timestep = 1236. State = [[-0.08318186  0.7587952  -0.16882063 -0.80787265  0.00388241 -0.08912378
   0.          0.        ]]. Action = [[0.93505335 0.30109966]]. Reward = [5.609311]
Abstract state at timestep 1236 is 4
State prediction error at timestep 1236 is 0.012
Human Feedback received at timestpe 1236 of 10
Current timestep = 1237. State = [[-0.08499928  0.74001473 -0.17937428 -0.83468074  0.00153995 -0.04684915
   0.          0.        ]]. Action = [[-0.22395569 -0.97987205]]. Reward = [-0.79046667]
Abstract state at timestep 1237 is 4
State prediction error at timestep 1237 is 0.012
Human Feedback received at timestpe 1237 of 10
Current timestep = 1238. State = [[-8.6697772e-02  7.2166246e-01 -1.6804011e-01 -8.1566042e-01
  -2.4750148e-04 -3.5749115e-02  0.0000000e+00  0.0000000e+00]]. Action = [[0.36842144 0.38046598]]. Reward = [3.8215606]
Abstract state at timestep 1238 is 4
State prediction error at timestep 1238 is 0.012
Human Feedback received at timestpe 1238 of 10
Current timestep = 1239. State = [[-0.08839627  0.70271003 -0.16804011 -0.8423273  -0.00203496 -0.0357491
   0.          0.        ]]. Action = [[-0.20535612  0.23448598]]. Reward = [-0.93191713]
Abstract state at timestep 1239 is 4
State prediction error at timestep 1239 is 0.012
Human Feedback received at timestpe 1239 of 10
Current timestep = 1240. State = [[-0.08997726  0.68472177 -0.15682788 -0.7994804  -0.00328887 -0.02507832
   0.          0.        ]]. Action = [[0.9896631  0.28232288]]. Reward = [5.760966]
Abstract state at timestep 1240 is 4
State prediction error at timestep 1240 is 0.012
Human Feedback received at timestpe 1240 of 10
Current timestep = 1241. State = [[-0.09137821  0.6672034  -0.13693935 -0.778607   -0.00639826 -0.06218776
   0.          0.        ]]. Action = [[0.6077533  0.98905706]]. Reward = [3.5518231]
Abstract state at timestep 1241 is 4
State prediction error at timestep 1241 is 0.012
Human Feedback received at timestpe 1241 of 10
Current timestep = 1242. State = [[-0.09275532  0.6501652  -0.13465163 -0.7572679  -0.00941922 -0.06041892
   0.          0.        ]]. Action = [[0.74674726 0.0581938 ]]. Reward = [3.2453887]
Abstract state at timestep 1242 is 4
State prediction error at timestep 1242 is 0.012
Human Feedback received at timestpe 1242 of 10
Current timestep = 1243. State = [[-0.09419546  0.6325204  -0.14256464 -0.78422487 -0.01085657 -0.02874708
   0.          0.        ]]. Action = [[-0.4764849 -0.9938354]]. Reward = [-1.2414893]
Abstract state at timestep 1243 is 4
State prediction error at timestep 1243 is 0.012
Human Feedback received at timestpe 1243 of 10
Current timestep = 1244. State = [[-0.09547796  0.6147068  -0.12480396 -0.7917483  -0.01425507 -0.06797034
   0.          0.        ]]. Action = [[0.00988972 0.966697  ]]. Reward = [0.7768438]
Abstract state at timestep 1244 is 4
State prediction error at timestep 1244 is 0.012
Human Feedback received at timestpe 1244 of 10
Current timestep = 1245. State = [[-0.09670496  0.59629816 -0.11784468 -0.8182129  -0.01904605 -0.09581967
   0.          0.        ]]. Action = [[-0.557702   0.7894455]]. Reward = [-1.2170442]
Abstract state at timestep 1245 is 4
State prediction error at timestep 1245 is 0.012
Human Feedback received at timestpe 1245 of 10
Current timestep = 1246. State = [[-0.09796991  0.57729286 -0.12260731 -0.84473133 -0.02288233 -0.07672572
   0.          0.        ]]. Action = [[-0.3582539 -0.5948996]]. Reward = [-1.2399794]
Abstract state at timestep 1246 is 4
State prediction error at timestep 1246 is 0.012
Human Feedback received at timestpe 1246 of 10
Current timestep = 1247. State = [[-0.09923477  0.5576878  -0.12260735 -0.87139916 -0.02671862 -0.07672565
   0.          0.        ]]. Action = [[-0.6613323   0.44535136]]. Reward = [-1.1137003]
Abstract state at timestep 1247 is 4
State prediction error at timestep 1247 is 0.012
Human Feedback received at timestpe 1247 of 10
Current timestep = 1248. State = [[-0.10044146  0.5374755  -0.11529604 -0.89842993 -0.03202226 -0.10607276
   0.          0.        ]]. Action = [[-0.05667216  0.66427255]]. Reward = [-1.1650293]
Abstract state at timestep 1248 is 4
State prediction error at timestep 1248 is 0.012
Human Feedback received at timestpe 1248 of 10
Current timestep = 1249. State = [[-0.10161324  0.5176024  -0.11035179 -0.88341117 -0.03876582 -0.13487133
   0.          0.        ]]. Action = [[0.8053162 0.6773325]]. Reward = [2.516399]
Abstract state at timestep 1249 is 4
State prediction error at timestep 1249 is 0.012
Human Feedback received at timestpe 1249 of 10
Current timestep = 1250. State = [[-0.10278501  0.49712986 -0.11035198 -0.9100815  -0.04550938 -0.13487093
   0.          0.        ]]. Action = [[-0.42999625 -0.43857312]]. Reward = [-1.3376378]
Abstract state at timestep 1250 is 4
State prediction error at timestep 1250 is 0.012
Human Feedback received at timestpe 1250 of 10
Current timestep = 1251. State = [[-0.10399523  0.47672403 -0.11392131 -0.9071567  -0.05252409 -0.14029421
   0.          0.        ]]. Action = [[ 0.9550042  -0.15665197]]. Reward = [1.2227515]
Abstract state at timestep 1251 is 5
State prediction error at timestep 1251 is 0.012
Human Feedback received at timestpe 1251 of 10
Current timestep = 1252. State = [[-0.10525942  0.45620313 -0.11899313 -0.91232115 -0.05986685 -0.14685538
   0.          0.        ]]. Action = [[0.7878921  0.19925952]]. Reward = [0.3955109]
Abstract state at timestep 1252 is 5
State prediction error at timestep 1252 is 0.012
Human Feedback received at timestpe 1252 of 10
Current timestep = 1253. State = [[-0.10639839  0.43568224 -0.10455781 -0.9124419  -0.06910802 -0.18482336
   0.          0.        ]]. Action = [[0.19649374 0.95648146]]. Reward = [1.0015569]
Abstract state at timestep 1253 is 5
State prediction error at timestep 1253 is 0.012
Human Feedback received at timestpe 1253 of 10
Current timestep = 1254. State = [[-0.10763617  0.41599354 -0.11366908 -0.8755488  -0.07911007 -0.20004085
   0.          0.        ]]. Action = [[0.88441825 0.36975372]]. Reward = [4.148062]
Abstract state at timestep 1254 is 5
State prediction error at timestep 1254 is 0.012
Human Feedback received at timestpe 1254 of 10
Current timestep = 1255. State = [[-0.10894756  0.3962361  -0.12057058 -0.87869936 -0.08958133 -0.20942517
   0.          0.        ]]. Action = [[ 0.26662135 -0.3434568 ]]. Reward = [0.23445384]
Abstract state at timestep 1255 is 5
State prediction error at timestep 1255 is 0.012
Human Feedback received at timestpe 1255 of 10
Current timestep = 1256. State = [[-0.11032943  0.37588885 -0.12941362 -0.904872   -0.09827189 -0.17381102
   0.          0.        ]]. Action = [[-0.56982356 -0.77279174]]. Reward = [-1.6874001]
Abstract state at timestep 1256 is 5
State prediction error at timestep 1256 is 0.012
Human Feedback received at timestpe 1256 of 10
Current timestep = 1257. State = [[-0.11163054  0.35583353 -0.12262188 -0.891859   -0.10569283 -0.14841896
   0.          0.        ]]. Action = [[ 0.51027703 -0.55647093]]. Reward = [2.2790294]
Abstract state at timestep 1257 is 5
State prediction error at timestep 1257 is 0.012
Human Feedback received at timestpe 1257 of 10
Current timestep = 1258. State = [[-0.11300974  0.33596936 -0.12983593 -0.8834464  -0.11373146 -0.16077267
   0.          0.        ]]. Action = [[0.50946975 0.36707163]]. Reward = [1.547638]
Abstract state at timestep 1258 is 5
State prediction error at timestep 1258 is 0.012
Human Feedback received at timestpe 1258 of 10
Current timestep = 1259. State = [[-0.11430693  0.31668314 -0.12158871 -0.85780835 -0.12180474 -0.16146567
   0.          0.        ]]. Action = [[ 0.87599325 -0.05748993]]. Reward = [3.3451495]
Abstract state at timestep 1259 is 5
State prediction error at timestep 1259 is 0.012
Human Feedback received at timestpe 1259 of 10
Current timestep = 1260. State = [[-0.11554155  0.29677936 -0.1137308  -0.88543415 -0.13148403 -0.19358623
   0.          0.        ]]. Action = [[-0.5336151   0.87370384]]. Reward = [-1.8063211]
Abstract state at timestep 1260 is 5
State prediction error at timestep 1260 is 0.012
Human Feedback received at timestpe 1260 of 10
Current timestep = 1261. State = [[-0.11677609  0.27627683 -0.11373228 -0.9121085  -0.14116327 -0.19358496
   0.          0.        ]]. Action = [[-0.05894399 -0.03152585]]. Reward = [-1.7607881]
Abstract state at timestep 1261 is 5
State prediction error at timestep 1261 is 0.012
Human Feedback received at timestpe 1261 of 10
Current timestep = 1262. State = [[-0.11784725  0.25582075 -0.09788396 -0.9100603  -0.1503752  -0.18423882
   0.          0.        ]]. Action = [[0.2723117 0.1036346]]. Reward = [1.1025014]
Abstract state at timestep 1262 is 5
State prediction error at timestep 1262 is 0.012
Human Feedback received at timestpe 1262 of 10
Current timestep = 1263. State = [[-0.11891832  0.23476575 -0.0978855  -0.936734   -0.1595871  -0.18423772
   0.          0.        ]]. Action = [[-0.3786927  0.4979713]]. Reward = [-1.7243694]
Abstract state at timestep 1263 is 5
State prediction error at timestep 1263 is 0.012
Human Feedback received at timestpe 1263 of 10
Current timestep = 1264. State = [[-0.11990843  0.2134977  -0.08782442 -0.946488   -0.17078257 -0.22390947
   0.          0.        ]]. Action = [[0.15950286 0.9896593 ]]. Reward = [-0.3650543]
Abstract state at timestep 1264 is 5
State prediction error at timestep 1264 is 0.012
Human Feedback received at timestpe 1264 of 10
Current timestep = 1265. State = [[-0.12089834  0.19163133 -0.087827   -0.9731651  -0.18197796 -0.22390755
   0.          0.        ]]. Action = [[-0.79796094  0.42594278]]. Reward = [-1.9476871]
Abstract state at timestep 1265 is 5
State prediction error at timestep 1265 is 0.012
Human Feedback received at timestpe 1265 of 10
Current timestep = 1266. State = [[-0.12188806  0.1691665  -0.08782975 -0.99984205 -0.19317324 -0.22390561
   0.          0.        ]]. Action = [[-0.55231875 -0.40668112]]. Reward = [-1.9690572]
Abstract state at timestep 1266 is 5
State prediction error at timestep 1266 is 0.012
Human Feedback received at timestpe 1266 of 10
Current timestep = 1267. State = [[-0.12278242  0.14695281 -0.07825036 -0.9887747  -0.20443968 -0.22532871
   0.          0.        ]]. Action = [[ 0.14015841 -0.12818384]]. Reward = [1.5857784]
Abstract state at timestep 1267 is 5
State prediction error at timestep 1267 is 0.012
Human Feedback received at timestpe 1267 of 10
Current timestep = 1268. State = [[-0.12367658  0.1241408  -0.0782535  -1.0154518  -0.21570602 -0.22532673
   0.          0.        ]]. Action = [[-0.09451407 -0.4509207 ]]. Reward = [-2.1600444]
Abstract state at timestep 1268 is 5
State prediction error at timestep 1268 is 0.012
Human Feedback received at timestpe 1268 of 10
Current timestep = 1269. State = [[-0.12461176  0.10074278 -0.08344595 -1.0414149  -0.22589943 -0.20386784
   0.          0.        ]]. Action = [[-0.44503748 -0.60036016]]. Reward = [-2.167106]
Abstract state at timestep 1269 is 5
State prediction error at timestep 1269 is 0.012
Human Feedback received at timestpe 1269 of 10
Current timestep = 1270. State = [[-0.12546167  0.07795916 -0.07642005 -1.0139413  -0.23458084 -0.17362842
   0.          0.        ]]. Action = [[ 0.6842463 -0.7816436]]. Reward = [2.902432]
Abstract state at timestep 1270 is 5
State prediction error at timestep 1270 is 0.012
Human Feedback received at timestpe 1270 of 10
Current timestep = 1271. State = [[-0.12623206  0.05504867 -0.06850547 -1.0196263  -0.24324375 -0.17325824
   0.          0.        ]]. Action = [[ 0.8083515 -0.2783476]]. Reward = [-0.64864314]
Abstract state at timestep 1271 is 5
State prediction error at timestep 1271 is 0.012
Human Feedback received at timestpe 1271 of 10
Current timestep = 1272. State = [[-0.12696418  0.03251432 -0.0663401  -1.0026805  -0.25024107 -0.13994567
   0.          0.        ]]. Action = [[ 0.38227987 -0.85033035]]. Reward = [1.4378132]
Abstract state at timestep 1272 is 5
State prediction error at timestep 1272 is 0.012
Human Feedback received at timestpe 1272 of 10
Current timestep = 1273. State = [[-0.12765455  0.01014191 -0.0636688  -0.9952544  -0.2557184  -0.10954692
   1.          0.        ]]. Action = [[ 0.550678  -0.7730674]]. Reward = [10.255322]
Abstract state at timestep 1273 is 5
State prediction error at timestep 1273 is 0.012
Human Feedback received at timestpe 1273 of 10
Current timestep = 1274. State = [[-0.1284171  -0.01106478 -0.0835251  -0.94202656 -0.24648626  0.1872988
   1.          0.        ]]. Action = [[0.71543646 0.97385097]]. Reward = [5.7097325]
Abstract state at timestep 1274 is 5
State prediction error at timestep 1274 is 0.012
Human Feedback received at timestpe 1274 of 10
Current timestep = 1275. State = [[ 0.00236988  1.4216859   0.24003275  0.4784868  -0.00273937 -0.054371
   0.          0.        ]]. Action = [[-0.469716    0.05149865]]. Reward = [-100.]
Abstract state at timestep 1275 is 5
State prediction error at timestep 1275 is 0.012
Human Feedback received at timestpe 1275 of 10
Current timestep = 1276. State = [[ 0.00466194  1.4318733   0.22995105  0.45277482 -0.00346906 -0.01459444
   0.          0.        ]]. Action = [[-0.81966853 -0.8470007 ]]. Reward = [1.6319836]
Abstract state at timestep 1276 is 3
State prediction error at timestep 1276 is 0.012
Human Feedback received at timestpe 1276 of 10
Current timestep = 1277. State = [[ 0.00685158  1.4419427   0.22020324  0.44752422 -0.00469631 -0.02454761
   0.          0.        ]]. Action = [[ 0.56834817 -0.17770249]]. Reward = [-0.46023703]
Abstract state at timestep 1277 is 3
State prediction error at timestep 1277 is 0.012
Human Feedback received at timestpe 1277 of 10
Current timestep = 1278. State = [[ 0.00904121  1.451412    0.22020714  0.42084903 -0.00592262 -0.02452848
   0.          0.        ]]. Action = [[-0.03919953  0.2402687 ]]. Reward = [1.3079364]
Abstract state at timestep 1278 is 3
State prediction error at timestep 1278 is 0.012
Human Feedback received at timestpe 1278 of 10
Current timestep = 1279. State = [[ 0.01115799  1.4606688   0.21328409  0.4114117  -0.00750509 -0.03165262
   0.          0.        ]]. Action = [[0.03792262 0.28788435]]. Reward = [-0.08425279]
Abstract state at timestep 1279 is 3
State prediction error at timestep 1279 is 0.012
Human Feedback received at timestpe 1279 of -10
Current timestep = 1280. State = [[ 0.01314764  1.4701364   0.19930685  0.42078167 -0.00784045 -0.00670765
   0.          0.        ]]. Action = [[ 0.5254121  -0.70842236]]. Reward = [-1.4505664]
Abstract state at timestep 1280 is 3
State prediction error at timestep 1280 is 0.012
Human Feedback received at timestpe 1280 of -10
Current timestep = 1281. State = [[ 0.01509171  1.4790009   0.19358535  0.3939865  -0.0070294   0.01622239
   0.          0.        ]]. Action = [[-0.2729597  -0.51357603]]. Reward = [1.8394239]
Abstract state at timestep 1281 is 3
State prediction error at timestep 1281 is 0.012
Human Feedback received at timestpe 1281 of -10
Current timestep = 1282. State = [[ 0.01712656  1.4880952   0.20358948  0.40418324 -0.00713256 -0.00206328
   0.          0.        ]]. Action = [[0.43484426 0.52164745]]. Reward = [-2.5113304]
Abstract state at timestep 1282 is 3
State prediction error at timestep 1282 is 0.012
Human Feedback received at timestpe 1282 of -10
Current timestep = 1283. State = [[ 0.01905889  1.4973401   0.19384554  0.41087854 -0.00773978 -0.0121455
   0.          0.        ]]. Action = [[ 0.8028281  -0.21810913]]. Reward = [-1.4326383]
Abstract state at timestep 1283 is 3
State prediction error at timestep 1283 is 0.012
Human Feedback received at timestpe 1283 of -10
Current timestep = 1284. State = [[ 0.02103787  1.5059853   0.19971344  0.38421345 -0.00952252 -0.03565851
   0.          0.        ]]. Action = [[-0.6299233  0.7454647]]. Reward = [1.0613505]
Abstract state at timestep 1284 is 3
State prediction error at timestep 1284 is 0.012
Human Feedback received at timestpe 1284 of -10
Current timestep = 1285. State = [[ 0.02290363  1.5149777   0.18895403  0.39965275 -0.0118706  -0.04696628
   0.          0.        ]]. Action = [[ 0.8416407 -0.2744394]]. Reward = [-2.318029]
Abstract state at timestep 1285 is 3
State prediction error at timestep 1285 is 0.012
Human Feedback received at timestpe 1285 of -10
Current timestep = 1286. State = [[ 0.02472534  1.523378    0.18341663  0.37333328 -0.01310526 -0.02469547
   0.          0.        ]]. Action = [[-0.5120852  -0.64814264]]. Reward = [1.6257187]
Abstract state at timestep 1286 is 3
State prediction error at timestep 1286 is 0.012
Human Feedback received at timestpe 1286 of -10
Current timestep = 1287. State = [[ 0.0267168   1.5324255   0.20170037  0.4020851  -0.01562541 -0.05040771
   0.          0.        ]]. Action = [[0.92627   0.7658851]]. Reward = [-4.860249]
Abstract state at timestep 1287 is 3
State prediction error at timestep 1287 is 0.012
Human Feedback received at timestpe 1287 of -10
Current timestep = 1288. State = [[ 0.02878571  1.5416377   0.20911038  0.40939793 -0.01781704 -0.04383679
   0.          0.        ]]. Action = [[0.4742465 0.4352032]]. Reward = [-2.3522115]
Abstract state at timestep 1288 is 3
State prediction error at timestep 1288 is 0.012
Human Feedback received at timestpe 1288 of -10
Current timestep = 1289. State = [[ 0.03080521  1.5502484   0.20290057  0.38269436 -0.01876349 -0.01893037
   0.          0.        ]]. Action = [[-0.25433886 -0.6083065 ]]. Reward = [1.6778069]
Abstract state at timestep 1289 is 3
State prediction error at timestep 1289 is 0.012
Human Feedback received at timestpe 1289 of -10
Current timestep = 1290. State = [[ 0.03279734  1.5591967   0.19812056  0.39771703 -0.01768041  0.02166331
   0.          0.        ]]. Action = [[ 0.96192133 -0.9881356 ]]. Reward = [-2.2319589]
Abstract state at timestep 1290 is 3
State prediction error at timestep 1290 is 0.012
Human Feedback received at timestpe 1290 of -10
Current timestep = 1291. State = [[ 0.03491373  1.5688276   0.20830974  0.42807525 -0.01438114  0.06599154
   0.          0.        ]]. Action = [[ 0.86110353 -0.95769733]]. Reward = [-4.1191187]
Abstract state at timestep 1291 is 3
State prediction error at timestep 1291 is 0.012
Human Feedback received at timestpe 1291 of -10
Current timestep = 1292. State = [[ 0.03713188  1.578404    0.22032197  0.42562586 -0.01290271  0.02957112
   0.          0.        ]]. Action = [[0.5239103  0.93059194]]. Reward = [-1.3911864]
Abstract state at timestep 1292 is 3
State prediction error at timestep 1292 is 0.012
Human Feedback received at timestpe 1292 of -10
Current timestep = 1293. State = [[ 0.03935013  1.5873802   0.22031844  0.39895773 -0.01142315  0.02959376
   0.          0.        ]]. Action = [[-0.10612094 -0.35257006]]. Reward = [1.5972304]
Abstract state at timestep 1293 is 3
State prediction error at timestep 1293 is 0.012
Human Feedback received at timestpe 1293 of -10
Current timestep = 1294. State = [[ 0.04159937  1.5963454   0.22466533  0.39845604 -0.01116302  0.00520304
   0.          0.        ]]. Action = [[0.8820437 0.5861523]]. Reward = [-1.3438315]
Abstract state at timestep 1294 is 3
State prediction error at timestep 1294 is 0.012
Human Feedback received at timestpe 1294 of -10
Current timestep = 1295. State = [[ 0.04393158  1.6055934   0.23258758  0.41102865 -0.01054634  0.01233492
   0.          0.        ]]. Action = [[0.3931917  0.40050292]]. Reward = [-2.5623443]
Abstract state at timestep 1295 is 3
State prediction error at timestep 1295 is 0.012
Human Feedback received at timestpe 1295 of -10
Current timestep = 1296. State = [[ 0.04620457  1.6142336   0.22517622  0.3840192  -0.00844739  0.04198259
   0.          0.        ]]. Action = [[-0.4115284 -0.7373197]]. Reward = [2.0281525]
Abstract state at timestep 1296 is 3
State prediction error at timestep 1296 is 0.012
Human Feedback received at timestpe 1296 of -10
Current timestep = 1297. State = [[ 0.04847755  1.6222738   0.22516957  0.35735348 -0.00634923  0.04196709
   0.          0.        ]]. Action = [[-0.6915799  0.2803011]]. Reward = [1.6785926]
Abstract state at timestep 1297 is 3
State prediction error at timestep 1297 is 0.012
Human Feedback received at timestpe 1297 of -10
Current timestep = 1298. State = [[ 0.05075035  1.629714    0.22516361  0.33068496 -0.00425107  0.041967
   0.          0.        ]]. Action = [[-0.10535556 -0.1893614 ]]. Reward = [1.6905692]
Abstract state at timestep 1298 is 3
State prediction error at timestep 1298 is 0.012
Human Feedback received at timestpe 1298 of -10
Current timestep = 1299. State = [[ 5.2963160e-02  1.6365622e+00  2.1764119e-01  3.0436769e-01
  -6.4702716e-04  7.2087258e-02  0.0000000e+00  0.0000000e+00]]. Action = [[-0.38329637 -0.72565717]]. Reward = [2.2359796]
Abstract state at timestep 1299 is 3
State prediction error at timestep 1299 is 0.012
Human Feedback received at timestpe 1299 of -10
Current timestep = 1300. State = [[0.05517597 1.6427889  0.21762851 0.27674386 0.00295644 0.07206924
  0.         0.        ]]. Action = [[-0.6525794   0.44842362]]. Reward = [1.3505539]
Abstract state at timestep 1300 is 3
State prediction error at timestep 1300 is 0.012
Human Feedback received at timestpe 1300 of -10
Current timestep = 1301. State = [[0.05738878 1.648416   0.21762848 0.2500761  0.0065599  0.07206921
  0.         0.        ]]. Action = [[-0.33082092 -0.3789481 ]]. Reward = [1.1249509]
Abstract state at timestep 1301 is 3
State prediction error at timestep 1301 is 0.012
Human Feedback received at timestpe 1301 of -10
Current timestep = 1302. State = [[0.05961533 1.6545417  0.22033858 0.2722452  0.00885274 0.04585679
  0.         0.        ]]. Action = [[0.7618288 0.6207082]]. Reward = [-3.0048337]
Abstract state at timestep 1302 is 3
State prediction error at timestep 1302 is 0.012
Human Feedback received at timestpe 1302 of -10
Current timestep = 1303. State = [[0.06170397 1.6610911  0.20715728 0.29106534 0.01053544 0.033654
  0.         0.        ]]. Action = [[0.8381095  0.34899652]]. Reward = [-1.8081193]
Abstract state at timestep 1303 is 3
State prediction error at timestep 1303 is 0.012
Human Feedback received at timestpe 1303 of -10
Current timestep = 1304. State = [[0.0638421  1.6670353  0.21336737 0.26419428 0.01097535 0.00879818
  0.         0.        ]]. Action = [[-0.6342683   0.68783474]]. Reward = [1.0996637]
Abstract state at timestep 1304 is 3
State prediction error at timestep 1304 is 0.012
Human Feedback received at timestpe 1304 of -10
Current timestep = 1305. State = [[0.0658864  1.67289    0.20249899 0.2601839  0.01287586 0.03801034
  0.         0.        ]]. Action = [[ 0.8198006  -0.76596206]]. Reward = [-0.08943195]
Abstract state at timestep 1305 is 3
State prediction error at timestep 1305 is 0.012
Human Feedback received at timestpe 1305 of -10
Current timestep = 1306. State = [[0.06791162 1.6788374  0.20212507 0.26433122 0.01327575 0.00799782
  0.         0.        ]]. Action = [[0.07894611 0.7249832 ]]. Reward = [-1.1314707]
Abstract state at timestep 1306 is 3
State prediction error at timestep 1306 is 0.012
Human Feedback received at timestpe 1306 of -10
Current timestep = 1307. State = [[0.06993695 1.6841849  0.20212507 0.2376645  0.01367565 0.00799781
  0.         0.        ]]. Action = [[-0.14837092 -0.37702894]]. Reward = [1.4936643]
Abstract state at timestep 1307 is 3
State prediction error at timestep 1307 is 0.012
Human Feedback received at timestpe 1307 of -10
Current timestep = 1308. State = [[ 7.1858786e-02  1.6899633e+00  1.9222334e-01  2.5681594e-01
   1.3640944e-02 -6.9406623e-04  0.0000000e+00  0.0000000e+00]]. Action = [[0.47446895 0.37038064]]. Reward = [-1.6825973]
Abstract state at timestep 1308 is 3
State prediction error at timestep 1308 is 0.012
Human Feedback received at timestpe 1308 of -10
Current timestep = 1309. State = [[7.37829208e-02 1.69651818e+00 1.92372113e-01 2.91330248e-01
  1.36746885e-02 6.74779294e-04 0.00000000e+00 0.00000000e+00]]. Action = [[0.79807544 0.26188624]]. Reward = [-3.768912]
Abstract state at timestep 1309 is 3
State prediction error at timestep 1309 is 0.012
Human Feedback received at timestpe 1309 of -10
Current timestep = 1310. State = [[0.07556629 1.7028267  0.17657785 0.28036928 0.01541145 0.03473531
  0.         0.        ]]. Action = [[ 0.29763412 -0.883135  ]]. Reward = [0.7444025]
Abstract state at timestep 1310 is 3
State prediction error at timestep 1310 is 0.012
Human Feedback received at timestpe 1310 of -10
Current timestep = 1311. State = [[0.07734976 1.7085356  0.17657784 0.25370234 0.01714821 0.03473532
  0.         0.        ]]. Action = [[-0.6256473  0.3069737]]. Reward = [1.471817]
Abstract state at timestep 1311 is 3
State prediction error at timestep 1311 is 0.012
Human Feedback received at timestpe 1311 of -10
Current timestep = 1312. State = [[0.07918654 1.7136418  0.18327518 0.22693363 0.01754458 0.00792765
  0.         0.        ]]. Action = [[-0.40108836  0.6209569 ]]. Reward = [1.1635841]
Abstract state at timestep 1312 is 3
State prediction error at timestep 1312 is 0.012
Human Feedback received at timestpe 1312 of -10
Current timestep = 1313. State = [[0.08094826 1.7190006  0.1760754  0.23816957 0.01764024 0.00191336
  0.         0.        ]]. Action = [[ 0.28659356 -0.20109618]]. Reward = [-1.1948974]
Abstract state at timestep 1313 is 3
State prediction error at timestep 1313 is 0.012
Human Feedback received at timestpe 1313 of -10
Current timestep = 1314. State = [[0.08249702 1.7244695  0.15301529 0.24304213 0.01947915 0.03677816
  0.         0.        ]]. Action = [[ 0.3435378  -0.92617303]]. Reward = [-0.06792163]
Abstract state at timestep 1314 is 3
State prediction error at timestep 1314 is 0.012
Human Feedback received at timestpe 1314 of -10
Current timestep = 1315. State = [[0.08404579 1.7293386  0.15301529 0.21637514 0.02131806 0.03677816
  0.         0.        ]]. Action = [[-0.94845885  0.18249917]]. Reward = [1.5408931]
Abstract state at timestep 1315 is 3
State prediction error at timestep 1315 is 0.012
Human Feedback received at timestpe 1315 of -10
Current timestep = 1316. State = [[0.08559465 1.7336076  0.1530153  0.18970822 0.02315696 0.03677816
  0.         0.        ]]. Action = [[-0.3179322  -0.09794265]]. Reward = [1.5107254]
Abstract state at timestep 1316 is 3
State prediction error at timestep 1316 is 0.012
Human Feedback received at timestpe 1316 of -10
Current timestep = 1317. State = [[0.0870759  1.7372681  0.14453566 0.16262348 0.02669726 0.07080609
  0.         0.        ]]. Action = [[-0.6736336 -0.7875047]]. Reward = [1.865048]
Abstract state at timestep 1317 is 3
State prediction error at timestep 1317 is 0.012
Human Feedback received at timestpe 1317 of -10
Current timestep = 1318. State = [[0.08837958 1.7411292  0.12580983 0.17151943 0.03119826 0.09001989
  0.         0.        ]]. Action = [[ 0.43308997 -0.6060323 ]]. Reward = [-0.5897215]
Abstract state at timestep 1318 is 3
State prediction error at timestep 1318 is 0.012
Human Feedback received at timestpe 1318 of -10
Current timestep = 1319. State = [[0.08972521 1.7443936  0.1310821  0.1450081  0.03464206 0.06887611
  0.         0.        ]]. Action = [[-0.3849318  0.5375166]]. Reward = [1.0306135]
Abstract state at timestep 1319 is 3
State prediction error at timestep 1319 is 0.012
Human Feedback received at timestpe 1319 of -10
Current timestep = 1320. State = [[0.09117088 1.7484779  0.14045295 0.18142487 0.03869999 0.08115862
  0.         0.        ]]. Action = [[ 0.9491215  -0.17040426]]. Reward = [-4.510035]
Abstract state at timestep 1320 is 3
State prediction error at timestep 1320 is 0.012
Human Feedback received at timestpe 1320 of -10
Current timestep = 1321. State = [[0.09261656 1.7519625  0.14045304 0.15475683 0.0427579  0.08115851
  0.         0.        ]]. Action = [[-0.73784846  0.4644935 ]]. Reward = [1.2835194]
Abstract state at timestep 1321 is 3
State prediction error at timestep 1321 is 0.012
Human Feedback received at timestpe 1321 of -10
Current timestep = 1322. State = [[0.09401627 1.754839   0.1346958  0.12767872 0.04797441 0.10433004
  0.         0.        ]]. Action = [[-0.24797231 -0.61828524]]. Reward = [1.5047994]
Abstract state at timestep 1322 is 3
State prediction error at timestep 1322 is 0.012
Human Feedback received at timestpe 1322 of -10
Current timestep = 1323. State = [[0.09547377 1.7571111  0.14193437 0.10085872 0.05174572 0.07542652
  0.         0.        ]]. Action = [[-0.88212854  0.82555366]]. Reward = [0.5106522]
Abstract state at timestep 1323 is 3
State prediction error at timestep 1323 is 0.012
Human Feedback received at timestpe 1323 of -10
Current timestep = 1324. State = [[0.09681825 1.7594563  0.13105324 0.10410675 0.05510246 0.06713479
  0.         0.        ]]. Action = [[ 0.18248498 -0.18297625]]. Reward = [-0.07966976]
Abstract state at timestep 1324 is 3
State prediction error at timestep 1324 is 0.012
Human Feedback received at timestpe 1324 of -10
Current timestep = 1325. State = [[0.09807167 1.7616314  0.12034778 0.09648211 0.06003578 0.09866634
  0.         0.        ]]. Action = [[ 0.57406306 -0.8011281 ]]. Reward = [0.33477452]
Abstract state at timestep 1325 is 3
State prediction error at timestep 1325 is 0.012
Human Feedback received at timestpe 1325 of -10
Current timestep = 1326. State = [[0.09929047 1.7636397  0.11697874 0.08905164 0.06489004 0.0970851
  0.         0.        ]]. Action = [[0.07397139 0.46849763]]. Reward = [-0.1308454]
Abstract state at timestep 1326 is 3
State prediction error at timestep 1326 is 0.012
Human Feedback received at timestpe 1326 of -10
Current timestep = 1327. State = [[0.10052061 1.7657949  0.119132   0.09561356 0.06872518 0.07670267
  0.         0.        ]]. Action = [[0.01696599 0.51387954]]. Reward = [-1.3474257]
Abstract state at timestep 1327 is 3
State prediction error at timestep 1327 is 0.012
Human Feedback received at timestpe 1327 of -10
Current timestep = 1328. State = [[0.10183239 1.768254   0.12673198 0.10907902 0.07312929 0.08808221
  0.         0.        ]]. Action = [[0.97296214 0.11069965]]. Reward = [-2.4347868]
Abstract state at timestep 1328 is 3
State prediction error at timestep 1328 is 0.012
Human Feedback received at timestpe 1328 of -10
Current timestep = 1329. State = [[0.10320845 1.7705569  0.13430868 0.10218013 0.07639143 0.06524286
  0.         0.        ]]. Action = [[0.11833668 0.60273874]]. Reward = [-0.904792]
Abstract state at timestep 1329 is 3
State prediction error at timestep 1329 is 0.012
Human Feedback received at timestpe 1329 of -10
Current timestep = 1330. State = [[0.10446405 1.7728609  0.12267635 0.10225572 0.0792394  0.05695945
  0.         0.        ]]. Action = [[0.46985567 0.27624762]]. Reward = [0.16276565]
Abstract state at timestep 1330 is 3
State prediction error at timestep 1330 is 0.012
Human Feedback received at timestpe 1330 of -10
Current timestep = 1331. State = [[0.10569467 1.7752719  0.12013699 0.1069972  0.08214575 0.05812699
  0.         0.        ]]. Action = [[ 0.5532998 -0.0470311]]. Reward = [-0.8887381]
Abstract state at timestep 1331 is 3
State prediction error at timestep 1331 is 0.012
Human Feedback received at timestpe 1331 of -10
Current timestep = 1332. State = [[0.10680714 1.778229   0.10856384 0.13128532 0.08479702 0.05302544
  0.         0.        ]]. Action = [[ 0.8840128  -0.23075062]]. Reward = [-1.7977201]
Abstract state at timestep 1332 is 3
State prediction error at timestep 1332 is 0.012
Human Feedback received at timestpe 1332 of -10
Current timestep = 1333. State = [[0.1079196  1.7805865  0.10856392 0.10461807 0.08744829 0.05302543
  0.         0.        ]]. Action = [[-0.21322751 -0.3390838 ]]. Reward = [1.4518548]
Abstract state at timestep 1333 is 3
State prediction error at timestep 1333 is 0.012
Human Feedback received at timestpe 1333 of -10
Current timestep = 1334. State = [[0.10912886 1.7835189  0.12004846 0.13028103 0.08832509 0.01753579
  0.         0.        ]]. Action = [[0.86476946 0.96248937]]. Reward = [-3.335244]
Abstract state at timestep 1334 is 3
State prediction error at timestep 1334 is 0.012
Human Feedback received at timestpe 1334 of -10
Current timestep = 1335. State = [[0.1102952  1.7858464  0.11464711 0.10332847 0.0902889  0.03927613
  0.         0.        ]]. Action = [[-0.1919797  -0.69255114]]. Reward = [1.825164]
Abstract state at timestep 1335 is 3
State prediction error at timestep 1335 is 0.012
Human Feedback received at timestpe 1335 of -10
Current timestep = 1336. State = [[0.11149788 1.7888733  0.11938696 0.13447379 0.09115616 0.01734522
  0.         0.        ]]. Action = [[0.9992254 0.6365254]]. Reward = [-3.2636395]
Abstract state at timestep 1336 is 3
State prediction error at timestep 1336 is 0.012
Human Feedback received at timestpe 1336 of -10
Current timestep = 1337. State = [[ 0.11265478  1.7923727   0.11608456  0.15555348  0.09076519 -0.00781941
   0.          0.        ]]. Action = [[0.5252414 0.5988679]]. Reward = [-1.9912003]
Abstract state at timestep 1337 is 3
State prediction error at timestep 1337 is 0.012
Human Feedback received at timestpe 1337 of -10
Current timestep = 1338. State = [[ 0.11366653  1.7963023   0.1019548   0.17469428  0.08999385 -0.01542667
   0.          0.        ]]. Action = [[0.35924804 0.12041736]]. Reward = [-1.3428278]
Abstract state at timestep 1338 is 3
State prediction error at timestep 1338 is 0.012
Human Feedback received at timestpe 1338 of -10
Current timestep = 1339. State = [[ 0.11473532  1.7996349   0.109104    0.14824966  0.08778907 -0.04409573
   0.          0.        ]]. Action = [[-0.63475496  0.7943357 ]]. Reward = [1.6772414]
Abstract state at timestep 1339 is 3
State prediction error at timestep 1339 is 0.012
Human Feedback received at timestpe 1339 of -10
Current timestep = 1340. State = [[ 0.11585025  1.8023782   0.11491153  0.12212713  0.08440765 -0.0676285
   0.          0.        ]]. Action = [[-0.34692526  0.70262074]]. Reward = [1.6742103]
Abstract state at timestep 1340 is 3
State prediction error at timestep 1340 is 0.012
Human Feedback received at timestpe 1340 of -10
Current timestep = 1341. State = [[ 0.11689711  1.8054733   0.10816522  0.1377498   0.08095986 -0.06895585
   0.          0.        ]]. Action = [[ 0.63371825 -0.45133263]]. Reward = [-0.96115315]
Abstract state at timestep 1341 is 3
State prediction error at timestep 1341 is 0.012
Human Feedback received at timestpe 1341 of -10
Current timestep = 1342. State = [[ 0.1179081   1.8089697   0.10618865  0.155664    0.0759203  -0.10079116
   0.          0.        ]]. Action = [[0.2804438 0.7726803]]. Reward = [-1.3959386]
Abstract state at timestep 1342 is 3
State prediction error at timestep 1342 is 0.012
Human Feedback received at timestpe 1342 of -10
Current timestep = 1343. State = [[ 0.11877699  1.8123798   0.09251735  0.15184008  0.07034539 -0.11149808
   0.          0.        ]]. Action = [[ 0.3216933  -0.16600358]]. Reward = [1.0761039]
Abstract state at timestep 1343 is 3
State prediction error at timestep 1343 is 0.012
Human Feedback received at timestpe 1343 of -10
Current timestep = 1344. State = [[ 0.11964579  1.8151904   0.09251763  0.12517084  0.06477048 -0.11149786
   0.          0.        ]]. Action = [[-0.6509229   0.44107056]]. Reward = [2.4867969]
Abstract state at timestep 1344 is 3
State prediction error at timestep 1344 is 0.012
Human Feedback received at timestpe 1344 of -10
Current timestep = 1345. State = [[ 0.12051459  1.8174014   0.09251788  0.09850157  0.0591956  -0.11149763
   0.          0.        ]]. Action = [[-0.01387209 -0.2180605 ]]. Reward = [2.382503]
Abstract state at timestep 1345 is 3
State prediction error at timestep 1345 is 0.012
Human Feedback received at timestpe 1345 of -10
Current timestep = 1346. State = [[ 0.12135649  1.8197421   0.09180426  0.10430233  0.05167884 -0.15033522
   0.          0.        ]]. Action = [[0.9875765 0.9084234]]. Reward = [-0.19406632]
Abstract state at timestep 1346 is 3
State prediction error at timestep 1346 is 0.012
Human Feedback received at timestpe 1346 of -10
Current timestep = 1347. State = [[ 0.12219848  1.8214833   0.09180465  0.07763094  0.04416211 -0.15033466
   0.          0.        ]]. Action = [[-0.7068293 -0.3289113]]. Reward = [2.4445305]
Abstract state at timestep 1347 is 3
State prediction error at timestep 1347 is 0.012
Human Feedback received at timestpe 1347 of -10
Current timestep = 1348. State = [[ 0.12304039  1.8226254   0.09180498  0.05095955  0.03664543 -0.15033406
   0.          0.        ]]. Action = [[-0.97754586 -0.43520153]]. Reward = [2.1547978]
Abstract state at timestep 1348 is 3
State prediction error at timestep 1348 is 0.012
Human Feedback received at timestpe 1348 of -10
Current timestep = 1349. State = [[ 0.12388229  1.8231678   0.09180526  0.02428817  0.02912876 -0.15033348
   0.          0.        ]]. Action = [[-0.05554688  0.19812512]]. Reward = [1.6954937]
Abstract state at timestep 1349 is 3
State prediction error at timestep 1349 is 0.012
Human Feedback received at timestpe 1349 of -10
Current timestep = 1350. State = [[ 0.12470607  1.824455    0.08792081  0.0572927   0.02365419 -0.10949121
   0.          0.        ]]. Action = [[ 0.869179  -0.9575926]]. Reward = [-0.8933471]
Abstract state at timestep 1350 is 3
State prediction error at timestep 1350 is 0.012
Human Feedback received at timestpe 1350 of -10
Current timestep = 1351. State = [[ 0.12546377  1.8251482   0.07964022  0.03087423  0.01983527 -0.07637854
   0.          0.        ]]. Action = [[-0.43559498 -0.87877107]]. Reward = [2.2337086]
Abstract state at timestep 1351 is 3
State prediction error at timestep 1351 is 0.012
Human Feedback received at timestpe 1351 of -10
Current timestep = 1352. State = [[ 0.12616396  1.8252363   0.07242341  0.00393925  0.01746337 -0.0474383
   0.          0.        ]]. Action = [[-0.06300521 -0.6255816 ]]. Reward = [1.4933046]
Abstract state at timestep 1352 is 3
State prediction error at timestep 1352 is 0.012
Human Feedback received at timestpe 1352 of -10
Current timestep = 1353. State = [[ 0.1268303   1.8254501   0.06914867  0.0095185   0.01497378 -0.04979204
   0.          0.        ]]. Action = [[0.265154  0.4445219]]. Reward = [0.30623424]
Abstract state at timestep 1353 is 3
State prediction error at timestep 1353 is 0.012
Human Feedback received at timestpe 1353 of -10
Current timestep = 1354. State = [[ 0.12741832  1.8250504   0.05933814 -0.0177564   0.01445212 -0.01043303
   0.          0.        ]]. Action = [[-0.04514468 -0.9705857 ]]. Reward = [0.8451146]
Abstract state at timestep 1354 is 3
State prediction error at timestep 1354 is 0.012
Human Feedback received at timestpe 1354 of -10
Current timestep = 1355. State = [[ 0.12803164  1.8249342   0.06170636 -0.0051681   0.01408699 -0.00730259
   0.          0.        ]]. Action = [[ 0.40627778 -0.04356968]]. Reward = [-0.16557142]
Abstract state at timestep 1355 is 3
State prediction error at timestep 1355 is 0.012
Human Feedback received at timestpe 1355 of -10
Current timestep = 1356. State = [[ 0.12864503  1.8242178   0.06170636 -0.03183478  0.01372186 -0.0073026
   0.          0.        ]]. Action = [[-0.660281   -0.32372832]]. Reward = [-0.6475227]
Abstract state at timestep 1356 is 3
State prediction error at timestep 1356 is 0.012
Human Feedback received at timestpe 1356 of -10
Current timestep = 1357. State = [[ 0.12925835  1.8229015   0.06170636 -0.05850146  0.01335675 -0.00730261
   0.          0.        ]]. Action = [[-0.31493157  0.23532486]]. Reward = [-1.3960687]
Abstract state at timestep 1357 is 3
State prediction error at timestep 1357 is 0.012
Human Feedback received at timestpe 1357 of -10
Current timestep = 1358. State = [[ 0.13001719  1.82137     0.07800692 -0.06803995  0.01125622 -0.04201064
   0.          0.        ]]. Action = [[0.01857388 0.87148535]]. Reward = [-1.6695956]
Abstract state at timestep 1358 is 3
State prediction error at timestep 1358 is 0.012
Human Feedback received at timestpe 1358 of -10
Current timestep = 1359. State = [[ 0.13081321  1.8192459   0.08268576 -0.09439095  0.0082174  -0.06077659
   0.          0.        ]]. Action = [[-0.46420765  0.56651926]]. Reward = [-1.704389]
Abstract state at timestep 1359 is 3
State prediction error at timestep 1359 is 0.012
Human Feedback received at timestpe 1359 of -10
Current timestep = 1360. State = [[ 0.13160925  1.816522    0.08268578 -0.12105838  0.00517857 -0.06077655
   0.          0.        ]]. Action = [[-0.6586607  -0.31347883]]. Reward = [-1.5417908]
Abstract state at timestep 1360 is 3
State prediction error at timestep 1360 is 0.012
Human Feedback received at timestpe 1360 of -10
Current timestep = 1361. State = [[ 0.13236876  1.8139205   0.07918508 -0.11560582  0.0019822  -0.06392767
   0.          0.        ]]. Action = [[ 0.6005945 -0.2472384]]. Reward = [0.9811936]
Abstract state at timestep 1361 is 3
State prediction error at timestep 1361 is 0.012
Human Feedback received at timestpe 1361 of -10
Current timestep = 1362. State = [[ 0.13319874  1.8115406   0.08764064 -0.10577501 -0.00259515 -0.09154697
   0.          0.        ]]. Action = [[0.05127323 0.7015779 ]]. Reward = [0.26720285]
Abstract state at timestep 1362 is 3
State prediction error at timestep 1362 is 0.012
Human Feedback received at timestpe 1362 of -10
Current timestep = 1363. State = [[ 0.13404341  1.810008    0.08904069 -0.06813014 -0.00711626 -0.09042184
   0.          0.        ]]. Action = [[ 0.8807199  -0.14791906]]. Reward = [1.9373635]
Abstract state at timestep 1363 is 3
State prediction error at timestep 1363 is 0.012
Human Feedback received at timestpe 1363 of -10
Current timestep = 1364. State = [[ 0.13488808  1.8078759   0.08904068 -0.09479851 -0.01163735 -0.0904217
   0.          0.        ]]. Action = [[-0.21096241  0.317814  ]]. Reward = [-2.039924]
Abstract state at timestep 1364 is 3
State prediction error at timestep 1364 is 0.012
Human Feedback received at timestpe 1364 of -10
Current timestep = 1365. State = [[ 0.13573274  1.8051437   0.08904066 -0.12146689 -0.01615842 -0.09042156
   0.          0.        ]]. Action = [[-0.13314414  0.44601274]]. Reward = [-2.24089]
Abstract state at timestep 1365 is 3
State prediction error at timestep 1365 is 0.012
Human Feedback received at timestpe 1365 of -10
Current timestep = 1366. State = [[ 0.13647985  1.8026571   0.07979128 -0.11056993 -0.02117229 -0.10027745
   0.          0.        ]]. Action = [[ 0.7271526 -0.215927 ]]. Reward = [0.9071781]
Abstract state at timestep 1366 is 3
State prediction error at timestep 1366 is 0.012
Human Feedback received at timestpe 1366 of -10
Current timestep = 1367. State = [[ 0.13722706  1.799571    0.07979122 -0.13723873 -0.02618616 -0.10027727
   0.          0.        ]]. Action = [[-0.9729511  0.024351 ]]. Reward = [-2.4387937]
Abstract state at timestep 1367 is 3
State prediction error at timestep 1367 is 0.012
Human Feedback received at timestpe 1367 of -10
Current timestep = 1368. State = [[ 0.13799056  1.7963645   0.08139504 -0.1426027  -0.03116265 -0.09952958
   0.          0.        ]]. Action = [[ 0.63224244 -0.36885613]]. Reward = [-0.97344905]
Abstract state at timestep 1368 is 3
State prediction error at timestep 1368 is 0.012
Human Feedback received at timestpe 1368 of -10
Current timestep = 1369. State = [[ 0.13875417  1.7925584   0.08139495 -0.16927145 -0.03613912 -0.09952942
   0.          0.        ]]. Action = [[-0.14385676 -0.15575051]]. Reward = [-2.486763]
Abstract state at timestep 1369 is 3
State prediction error at timestep 1369 is 0.012
Human Feedback received at timestpe 1369 of -10
Current timestep = 1370. State = [[ 0.13945857  1.78816     0.0739687  -0.19557911 -0.03962441 -0.06970572
   0.          0.        ]]. Action = [[-0.6083758  -0.73346025]]. Reward = [-2.064969]
Abstract state at timestep 1370 is 3
State prediction error at timestep 1370 is 0.012
Human Feedback received at timestpe 1370 of -10
Current timestep = 1371. State = [[ 0.14007111  1.7839285   0.0653109  -0.18818098 -0.04362759 -0.08006385
   0.          0.        ]]. Action = [[0.5190866  0.07509732]]. Reward = [0.77959955]
Abstract state at timestep 1371 is 3
State prediction error at timestep 1371 is 0.012
Human Feedback received at timestpe 1371 of -10
Current timestep = 1372. State = [[ 0.14053592  1.7797309   0.04975146 -0.18665536 -0.04686299 -0.06470789
   0.          0.        ]]. Action = [[ 0.42737865 -0.5345914 ]]. Reward = [0.46316016]
Abstract state at timestep 1372 is 3
State prediction error at timestep 1372 is 0.012
Human Feedback received at timestpe 1372 of -10
Current timestep = 1373. State = [[ 0.14089231  1.7756716   0.03952923 -0.18054429 -0.05070556 -0.07685138
   0.          0.        ]]. Action = [[ 0.74984837 -0.43095022]]. Reward = [0.59022856]
Abstract state at timestep 1373 is 3
State prediction error at timestep 1373 is 0.012
Human Feedback received at timestpe 1373 of -10
Current timestep = 1374. State = [[ 0.14136906  1.772265    0.05118901 -0.15153137 -0.05418795 -0.06964764
   0.          0.        ]]. Action = [[0.99820113 0.300884  ]]. Reward = [2.1755424]
Abstract state at timestep 1374 is 3
State prediction error at timestep 1374 is 0.012
Human Feedback received at timestpe 1374 of -10
Current timestep = 1375. State = [[ 0.14178124  1.7682575   0.04310786 -0.17818044 -0.05605399 -0.03732086
   0.          0.        ]]. Action = [[-0.31913793 -0.7360014 ]]. Reward = [-2.150198]
Abstract state at timestep 1375 is 3
State prediction error at timestep 1375 is 0.012
Human Feedback received at timestpe 1375 of -10
Current timestep = 1376. State = [[ 0.1421934   1.76365     0.04310783 -0.2048474  -0.05792003 -0.03732086
   0.          0.        ]]. Action = [[-0.0995146  0.4514748]]. Reward = [-2.33195]
Abstract state at timestep 1376 is 3
State prediction error at timestep 1376 is 0.012
Human Feedback received at timestpe 1376 of -10
Current timestep = 1377. State = [[ 0.14276361  1.7596595   0.05839213 -0.17740074 -0.0592731  -0.0270614
   0.          0.        ]]. Action = [[ 0.669034   -0.42158002]]. Reward = [2.2645242]
Abstract state at timestep 1377 is 3
State prediction error at timestep 1377 is 0.012
Human Feedback received at timestpe 1377 of -10
Current timestep = 1378. State = [[ 0.14333877  1.7556224   0.06082479 -0.17956464 -0.0625495  -0.06552808
   0.          0.        ]]. Action = [[0.29686463 0.9393749 ]]. Reward = [-0.43493286]
Abstract state at timestep 1378 is 3
State prediction error at timestep 1378 is 0.012
Human Feedback received at timestpe 1378 of -10
Current timestep = 1379. State = [[ 0.14391384  1.7509854   0.0608247  -0.2062322  -0.06582589 -0.06552802
   0.          0.        ]]. Action = [[-0.93863535 -0.4237852 ]]. Reward = [-2.412993]
Abstract state at timestep 1379 is 3
State prediction error at timestep 1379 is 0.012
Human Feedback received at timestpe 1379 of -10
Current timestep = 1380. State = [[ 0.14444447  1.7457542   0.05524058 -0.23258932 -0.06797871 -0.0430561
   0.          0.        ]]. Action = [[-0.02451164 -0.67425185]]. Reward = [-2.1229737]
Abstract state at timestep 1380 is 3
State prediction error at timestep 1380 is 0.012
Human Feedback received at timestpe 1380 of -10
Current timestep = 1381. State = [[ 0.14491358  1.7399246   0.04751977 -0.25912672 -0.06858558 -0.01213742
   0.          0.        ]]. Action = [[-0.8322194 -0.7228733]]. Reward = [-1.9441421]
Abstract state at timestep 1381 is 3
State prediction error at timestep 1381 is 0.012
Human Feedback received at timestpe 1381 of -10
Current timestep = 1382. State = [[ 0.1454461   1.7334783   0.05549776 -0.28660768 -0.07080757 -0.04443968
   0.          0.        ]]. Action = [[-0.9258889   0.87596726]]. Reward = [-2.4588923]
Abstract state at timestep 1382 is 3
State prediction error at timestep 1382 is 0.012
Human Feedback received at timestpe 1382 of -10
Current timestep = 1383. State = [[ 0.14591178  1.7264358   0.04712463 -0.31302533 -0.07135026 -0.01085394
   0.          0.        ]]. Action = [[-0.57771266 -0.78427863]]. Reward = [-1.8420553]
Abstract state at timestep 1383 is 3
State prediction error at timestep 1383 is 0.012
Human Feedback received at timestpe 1383 of -10
Current timestep = 1384. State = [[ 0.14637308  1.7191718   0.04678141 -0.32287768 -0.07199672 -0.01292912
   0.          0.        ]]. Action = [[ 0.0231936  -0.49255812]]. Reward = [-0.46787047]
Abstract state at timestep 1384 is 3
State prediction error at timestep 1384 is 0.012
Human Feedback received at timestpe 1384 of -10
Current timestep = 1385. State = [[ 0.14680147  1.7113137   0.04265463 -0.34923285 -0.07181038  0.00372676
   0.          0.        ]]. Action = [[-0.5496159 -0.5128294]]. Reward = [-1.7753428]
Abstract state at timestep 1385 is 3
State prediction error at timestep 1385 is 0.012
Human Feedback received at timestpe 1385 of -10
Current timestep = 1386. State = [[ 0.14718819  1.7033899   0.03879752 -0.35217667 -0.07193453 -0.00248319
   0.          0.        ]]. Action = [[0.20405638 0.32445788]]. Reward = [0.34520924]
Abstract state at timestep 1386 is 3
State prediction error at timestep 1386 is 0.012
Human Feedback received at timestpe 1386 of -10
Current timestep = 1387. State = [[ 0.14752483  1.6948652   0.03252017 -0.378816   -0.07080412  0.02260853
   0.          0.        ]]. Action = [[-0.41371238 -0.6444013 ]]. Reward = [-1.6501346]
Abstract state at timestep 1387 is 3
State prediction error at timestep 1387 is 0.012
Human Feedback received at timestpe 1387 of -10
Current timestep = 1388. State = [[ 0.14771195  1.6862485   0.01598785 -0.38283405 -0.06810264  0.05402967
   0.          0.        ]]. Action = [[ 0.09082627 -0.8148886 ]]. Reward = [0.6430091]
Abstract state at timestep 1388 is 3
State prediction error at timestep 1388 is 0.012
Human Feedback received at timestpe 1388 of -10
Current timestep = 1389. State = [[ 0.14785138  1.677038    0.00998174 -0.40918735 -0.06419306  0.07819165
   0.          0.        ]]. Action = [[-0.04120559 -0.7098818 ]]. Reward = [-1.3281654]
Abstract state at timestep 1389 is 3
State prediction error at timestep 1389 is 0.012
Human Feedback received at timestpe 1389 of -10
Current timestep = 1390. State = [[ 0.14808865  1.6686988   0.02087584 -0.37050804 -0.06137042  0.05645279
   0.          0.        ]]. Action = [[0.8978231 0.5359105]]. Reward = [4.6314354]
Abstract state at timestep 1390 is 3
State prediction error at timestep 1390 is 0.012
Human Feedback received at timestpe 1390 of -10
Current timestep = 1391. State = [[ 0.14837237  1.6606252   0.02663602 -0.3587515  -0.05964892  0.03443014
   0.          0.        ]]. Action = [[0.46724224 0.5158378 ]]. Reward = [1.8739134]
Abstract state at timestep 1391 is 3
State prediction error at timestep 1391 is 0.012
Human Feedback received at timestpe 1391 of -10
Current timestep = 1392. State = [[ 0.14870425  1.6519498   0.03266653 -0.38554877 -0.0591359   0.0102605
   0.          0.        ]]. Action = [[-0.01701319  0.5154433 ]]. Reward = [-1.8221666]
Abstract state at timestep 1392 is 3
State prediction error at timestep 1392 is 0.012
Human Feedback received at timestpe 1392 of -10
Current timestep = 1393. State = [[ 0.14903602  1.6426744   0.03266653 -0.41221544 -0.05862287  0.01026051
   0.          0.        ]]. Action = [[-0.32822436 -0.12882173]]. Reward = [-1.685678]
Abstract state at timestep 1393 is 3
State prediction error at timestep 1393 is 0.012
Human Feedback received at timestpe 1393 of -10
Current timestep = 1394. State = [[ 0.1493679   1.6327993   0.03266652 -0.43888214 -0.05810983  0.01026053
   0.          0.        ]]. Action = [[-0.17532814  0.19630516]]. Reward = [-1.6270927]
Abstract state at timestep 1394 is 3
State prediction error at timestep 1394 is 0.012
Human Feedback received at timestpe 1394 of -10
Current timestep = 1395. State = [[ 0.14977093  1.6228366   0.04179399 -0.4428414  -0.05957851 -0.02937382
   0.          0.        ]]. Action = [[0.62036896 0.9793967 ]]. Reward = [0.09778668]
Abstract state at timestep 1395 is 3
State prediction error at timestep 1395 is 0.012
Human Feedback received at timestpe 1395 of -10
Current timestep = 1396. State = [[ 0.15017395  1.6122742   0.04179397 -0.46950826 -0.0610472  -0.02937381
   0.          0.        ]]. Action = [[-0.61207414  0.14668357]]. Reward = [-1.7544088]
Abstract state at timestep 1396 is 3
State prediction error at timestep 1396 is 0.012
Human Feedback received at timestpe 1396 of -10
Current timestep = 1397. State = [[ 0.15051441  1.6022202   0.03603207 -0.44692048 -0.06301345 -0.03932527
   0.          0.        ]]. Action = [[0.63906384 0.10217381]]. Reward = [2.8547797]
Abstract state at timestep 1397 is 3
State prediction error at timestep 1397 is 0.012
Human Feedback received at timestpe 1397 of -10
Current timestep = 1398. State = [[ 0.15085478  1.5915663   0.03603204 -0.4735875  -0.0649797  -0.03932526
   0.          0.        ]]. Action = [[-0.7940487  -0.10709894]]. Reward = [-1.7977076]
Abstract state at timestep 1398 is 3
State prediction error at timestep 1398 is 0.012
Human Feedback received at timestpe 1398 of -10
Current timestep = 1399. State = [[ 0.15122461  1.5807968   0.04026569 -0.47878936 -0.06822492 -0.06490424
   0.          0.        ]]. Action = [[0.42099524 0.60022473]]. Reward = [-0.03941495]
Abstract state at timestep 1399 is 3
State prediction error at timestep 1399 is 0.012
Human Feedback received at timestpe 1399 of -10
Current timestep = 1400. State = [[ 0.15159445  1.5694276   0.0402656  -0.50545686 -0.07147013 -0.0649042
   0.          0.        ]]. Action = [[-0.9785821  -0.04996032]]. Reward = [-1.8542132]
Abstract state at timestep 1400 is 3
State prediction error at timestep 1400 is 0.012
Human Feedback received at timestpe 1400 of -10
Current timestep = 1401. State = [[ 0.15197325  1.5580332   0.03928258 -0.50648206 -0.07285876 -0.02777257
   0.          0.        ]]. Action = [[ 0.17709458 -0.9246324 ]]. Reward = [0.6927779]
Abstract state at timestep 1401 is 3
State prediction error at timestep 1401 is 0.012
Human Feedback received at timestpe 1401 of -10
Current timestep = 1402. State = [[ 0.15228891  1.5460404   0.03136814 -0.5330026  -0.07266262  0.00392284
   0.          0.        ]]. Action = [[-0.9209645  -0.71366566]]. Reward = [-1.4034843]
Abstract state at timestep 1402 is 3
State prediction error at timestep 1402 is 0.012
Human Feedback received at timestpe 1402 of -10
Current timestep = 1403. State = [[ 0.15266685  1.5347902   0.03761175 -0.5000054  -0.07247912  0.00366993
   0.          0.        ]]. Action = [[ 0.8478415 -0.1754458]]. Reward = [4.1076884]
Abstract state at timestep 1403 is 3
State prediction error at timestep 1403 is 0.012
Human Feedback received at timestpe 1403 of -10
Current timestep = 1404. State = [[ 0.15320912  1.5243244   0.05545288 -0.46520507 -0.07369594 -0.02433624
   0.          0.        ]]. Action = [[0.83454716 0.7465471 ]]. Reward = [3.908689]
Abstract state at timestep 1404 is 3
State prediction error at timestep 1404 is 0.012
Human Feedback received at timestpe 1404 of -10
Current timestep = 1405. State = [[ 0.15375146  1.5132587   0.05545288 -0.49187186 -0.07491276 -0.02433625
   0.          0.        ]]. Action = [[-0.42111194  0.30291736]]. Reward = [-1.6751102]
Abstract state at timestep 1405 is 3
State prediction error at timestep 1405 is 0.012
Human Feedback received at timestpe 1405 of -10
Current timestep = 1406. State = [[ 0.1544344   1.5024157   0.0690678  -0.48194578 -0.07566965 -0.01513831
   0.          0.        ]]. Action = [[ 0.37239194 -0.17648101]]. Reward = [1.6020045]
Abstract state at timestep 1406 is 3
State prediction error at timestep 1406 is 0.012
Human Feedback received at timestpe 1406 of -10
Current timestep = 1407. State = [[ 0.15514079  1.4915874   0.06976832 -0.48121318 -0.07481905  0.01701236
   0.          0.        ]]. Action = [[ 0.12749088 -0.7877661 ]]. Reward = [1.0246357]
Abstract state at timestep 1407 is 3
State prediction error at timestep 1407 is 0.012
Human Feedback received at timestpe 1407 of -10
Current timestep = 1408. State = [[ 0.15584707  1.480159    0.06976832 -0.50788    -0.07396845  0.01701238
   0.          0.        ]]. Action = [[-0.6697093  -0.36493933]]. Reward = [-1.4261738]
Abstract state at timestep 1408 is 3
State prediction error at timestep 1408 is 0.012
Human Feedback received at timestpe 1408 of -10
Current timestep = 1409. State = [[ 0.15655336  1.468131    0.06976832 -0.53454673 -0.07311782  0.01701237
   0.          0.        ]]. Action = [[-0.91010326 -0.1631676 ]]. Reward = [-1.3693466]
Abstract state at timestep 1409 is 3
State prediction error at timestep 1409 is 0.012
Human Feedback received at timestpe 1409 of -10
Current timestep = 1410. State = [[ 0.1572403   1.4563711   0.06660609 -0.5225555  -0.07104757  0.04140509
   0.          0.        ]]. Action = [[ 0.4376713 -0.624591 ]]. Reward = [2.3643079]
Abstract state at timestep 1410 is 3
State prediction error at timestep 1410 is 0.012
Human Feedback received at timestpe 1410 of -10
Current timestep = 1411. State = [[ 0.15793343  1.444439    0.06865802 -0.5302798  -0.07039951  0.01296116
   0.          0.        ]]. Action = [[0.1377449  0.67180943]]. Reward = [0.2604377]
Abstract state at timestep 1411 is 3
State prediction error at timestep 1411 is 0.012
Human Feedback received at timestpe 1411 of -10
Current timestep = 1412. State = [[ 0.15871772  1.4328346   0.07614234 -0.51564795 -0.06813709  0.04524809
   0.          0.        ]]. Action = [[ 0.67201734 -0.6997086 ]]. Reward = [2.4460266]
Abstract state at timestep 1412 is 3
State prediction error at timestep 1412 is 0.012
Human Feedback received at timestpe 1412 of -10
Current timestep = 1413. State = [[ 0.1595107   1.4213268   0.07712229 -0.5113679  -0.0659804   0.04313399
   0.          0.        ]]. Action = [[0.91999304 0.08968353]]. Reward = [1.471433]
Abstract state at timestep 1413 is 3
State prediction error at timestep 1413 is 0.012
Human Feedback received at timestpe 1413 of -10
Current timestep = 1414. State = [[ 0.16030379  1.4092188   0.07712226 -0.53803504 -0.06382369  0.0431341
   0.          0.        ]]. Action = [[-0.92279863 -0.49778926]]. Reward = [-1.228433]
Abstract state at timestep 1414 is 3
State prediction error at timestep 1414 is 0.012
Human Feedback received at timestpe 1414 of -10
Current timestep = 1415. State = [[ 0.16108894  1.3976867   0.07660763 -0.5124527  -0.06193417  0.03779054
   0.          0.        ]]. Action = [[0.5314028 0.1369803]]. Reward = [3.6347377]
Abstract state at timestep 1415 is 3
State prediction error at timestep 1415 is 0.012
Human Feedback received at timestpe 1415 of -10
Current timestep = 1416. State = [[ 0.1618741   1.3855548   0.0766076  -0.5391197  -0.06004469  0.03778952
   0.          0.        ]]. Action = [[-0.53378165  0.34262443]]. Reward = [-1.2538192]
Abstract state at timestep 1416 is 3
State prediction error at timestep 1416 is 0.012
Human Feedback received at timestpe 1416 of -10
Current timestep = 1417. State = [[ 0.1625864   1.3738987   0.06837735 -0.51794344 -0.05722612  0.05637141
   0.          0.        ]]. Action = [[ 0.5336596 -0.5549263]]. Reward = [3.3942754]
Abstract state at timestep 1417 is 3
State prediction error at timestep 1417 is 0.012
Human Feedback received at timestpe 1417 of -10
Current timestep = 1418. State = [[ 0.16325235  1.3622533   0.06186826 -0.5173951  -0.05255202  0.09348189
   0.          0.        ]]. Action = [[ 0.03079152 -0.9325157 ]]. Reward = [1.5689555]
Abstract state at timestep 1418 is 3
State prediction error at timestep 1418 is 0.012
Human Feedback received at timestpe 1418 of -10
Current timestep = 1419. State = [[ 0.16404685  1.3504399   0.0763249  -0.52493954 -0.04946166  0.06180714
   0.          0.        ]]. Action = [[0.14937091 0.81189466]]. Reward = [0.337762]
Abstract state at timestep 1419 is 3
State prediction error at timestep 1419 is 0.012
Human Feedback received at timestpe 1419 of -10
Current timestep = 1420. State = [[ 0.16478166  1.3380387   0.06882978 -0.55101746 -0.04486112  0.09201083
   0.          0.        ]]. Action = [[-0.4367981 -0.7376805]]. Reward = [-0.8240918]
Abstract state at timestep 1420 is 3
State prediction error at timestep 1420 is 0.012
Human Feedback received at timestpe 1420 of 10
Current timestep = 1421. State = [[ 0.16551647  1.3250377   0.06882966 -0.5776859  -0.04026059  0.09201066
   0.          0.        ]]. Action = [[-0.67737144 -0.3440084 ]]. Reward = [-0.90600026]
Abstract state at timestep 1421 is 3
State prediction error at timestep 1421 is 0.012
Human Feedback received at timestpe 1421 of 10
Current timestep = 1422. State = [[ 0.16631107  1.31232     0.07309525 -0.56507325 -0.03398308  0.1255502
   0.          0.        ]]. Action = [[ 0.14622784 -0.8083435 ]]. Reward = [2.8825216]
Abstract state at timestep 1422 is 3
State prediction error at timestep 1422 is 0.012
Human Feedback received at timestpe 1422 of 10
Current timestep = 1423. State = [[ 0.16713257  1.2994046   0.0757141  -0.57388026 -0.02762259  0.12720974
   0.          0.        ]]. Action = [[ 0.16386914 -0.04511029]]. Reward = [0.824998]
Abstract state at timestep 1423 is 3
State prediction error at timestep 1423 is 0.012
Human Feedback received at timestpe 1423 of 10
Current timestep = 1424. State = [[ 0.16794491  1.2872156   0.07649244 -0.54165936 -0.02294333  0.09358509
   0.          0.        ]]. Action = [[0.7666404 0.7467923]]. Reward = [4.5608544]
Abstract state at timestep 1424 is 3
State prediction error at timestep 1424 is 0.012
Human Feedback received at timestpe 1424 of 10
Current timestep = 1425. State = [[ 0.16875724  1.2744267   0.07649236 -0.5683279  -0.01826408  0.09358493
   0.          0.        ]]. Action = [[-0.17251414  0.33489728]]. Reward = [-0.91654193]
Abstract state at timestep 1425 is 3
State prediction error at timestep 1425 is 0.012
Human Feedback received at timestpe 1425 of 10
Current timestep = 1426. State = [[ 0.16956958  1.2610382   0.0764923  -0.5949964  -0.01358485  0.09358482
   0.          0.        ]]. Action = [[-0.73896056  0.23516572]]. Reward = [-0.85981077]
Abstract state at timestep 1426 is 3
State prediction error at timestep 1426 is 0.012
Human Feedback received at timestpe 1426 of 10
Current timestep = 1427. State = [[ 0.17038193  1.2470499   0.07649226 -0.6216648  -0.00890562  0.09358471
   0.          0.        ]]. Action = [[-0.86095965 -0.47716224]]. Reward = [-0.80283433]
Abstract state at timestep 1427 is 3
State prediction error at timestep 1427 is 0.012
Human Feedback received at timestpe 1427 of 10
Current timestep = 1428. State = [[ 0.17112207  1.2329919   0.06760172 -0.624776   -0.00257862  0.12654006
   0.          0.        ]]. Action = [[ 0.1956774  -0.83204836]]. Reward = [1.6039964]
Abstract state at timestep 1428 is 3
State prediction error at timestep 1428 is 0.012
Human Feedback received at timestpe 1428 of 10
Current timestep = 1429. State = [[ 0.17186221  1.2183343   0.06760168 -0.651446    0.00374835  0.12653968
   0.          0.        ]]. Action = [[-0.92020166 -0.07414454]]. Reward = [-1.3277574]
Abstract state at timestep 1429 is 3
State prediction error at timestep 1429 is 0.012
Human Feedback received at timestpe 1429 of 10
Current timestep = 1430. State = [[ 0.17260237  1.2030774   0.06760167 -0.6781159   0.01007532  0.12653933
   0.          0.        ]]. Action = [[-0.45456636 -0.17492366]]. Reward = [-1.7859515]
Abstract state at timestep 1430 is 3
State prediction error at timestep 1430 is 0.012
Human Feedback received at timestpe 1430 of 10
Current timestep = 1431. State = [[ 0.17338857  1.1886072   0.07194169 -0.64317405  0.01665856  0.1316648
   0.          0.        ]]. Action = [[0.7727194  0.02751064]]. Reward = [3.9258394]
Abstract state at timestep 1431 is 3
State prediction error at timestep 1431 is 0.012
Human Feedback received at timestpe 1431 of 10
Current timestep = 1432. State = [[ 0.17423706  1.1735324   0.07976377 -0.67006457  0.02167691  0.10036705
   0.          0.        ]]. Action = [[-0.27339494  0.6836902 ]]. Reward = [-1.8043092]
Abstract state at timestep 1432 is 3
State prediction error at timestep 1432 is 0.012
Human Feedback received at timestpe 1432 of 10
Current timestep = 1433. State = [[ 0.17508546  1.1578577   0.07976383 -0.6967333   0.02669525  0.10036685
   0.          0.        ]]. Action = [[-0.5026638  0.3334744]]. Reward = [-1.6131281]
Abstract state at timestep 1433 is 3
State prediction error at timestep 1433 is 0.012
Human Feedback received at timestpe 1433 of 10
Current timestep = 1434. State = [[ 0.1758872   1.1415739   0.0738977  -0.7238475   0.03289247  0.12394463
   0.          0.        ]]. Action = [[-0.4084251  -0.66870403]]. Reward = [-1.6747102]
Abstract state at timestep 1434 is 3
State prediction error at timestep 1434 is 0.012
Human Feedback received at timestpe 1434 of 10
Current timestep = 1435. State = [[ 0.17668895  1.1246908   0.07389783 -0.7505173   0.03908968  0.1239443
   0.          0.        ]]. Action = [[-0.2625599   0.08878958]]. Reward = [-1.6174781]
Abstract state at timestep 1435 is 3
State prediction error at timestep 1435 is 0.012
Human Feedback received at timestpe 1435 of 10
Current timestep = 1436. State = [[ 0.17746201  1.1075772   0.07111505 -0.7607701   0.04519873  0.12218116
   0.          0.        ]]. Action = [[ 0.3423097  -0.32159752]]. Reward = [-0.1281618]
Abstract state at timestep 1436 is 3
State prediction error at timestep 1436 is 0.012
Human Feedback received at timestpe 1436 of 10
Current timestep = 1437. State = [[ 0.17823496  1.0898643   0.07111524 -0.7874399   0.05130778  0.12218083
   0.          0.        ]]. Action = [[-0.65436816  0.04506803]]. Reward = [-1.5305052]
Abstract state at timestep 1437 is 3
State prediction error at timestep 1437 is 0.012
Human Feedback received at timestpe 1437 of 10
Current timestep = 1438. State = [[ 0.17894468  1.072554    0.0649274  -0.7695636   0.05728352  0.11951472
   0.          0.        ]]. Action = [[0.3599738  0.47017932]]. Reward = [2.7294314]
Abstract state at timestep 1438 is 3
State prediction error at timestep 1438 is 0.012
Human Feedback received at timestpe 1438 of 10
Current timestep = 1439. State = [[ 0.17969532  1.0551816   0.07073229 -0.7722803   0.06156924  0.08571439
   0.          0.        ]]. Action = [[0.08821607 0.84846234]]. Reward = [0.7618458]
Abstract state at timestep 1439 is 3
State prediction error at timestep 1439 is 0.012
Human Feedback received at timestpe 1439 of 10
Current timestep = 1440. State = [[ 0.18050012  1.0382081   0.07570092 -0.7545804   0.06629475  0.09451003
   0.          0.        ]]. Action = [[0.45289338 0.32827067]]. Reward = [2.6830823]
Abstract state at timestep 1440 is 3
State prediction error at timestep 1440 is 0.012
Human Feedback received at timestpe 1440 of 10
Current timestep = 1441. State = [[ 0.18111944  1.0217314   0.0577913  -0.73249334  0.07038836  0.08187225
   0.          0.        ]]. Action = [[ 0.6746416  -0.18432838]]. Reward = [3.3114455]
Abstract state at timestep 1441 is 3
State prediction error at timestep 1441 is 0.012
Human Feedback received at timestpe 1441 of 10
Current timestep = 1442. State = [[ 0.1815013   1.0054878   0.03308051 -0.7221886   0.07543386  0.10091022
   0.          0.        ]]. Action = [[ 0.93442774 -0.664374  ]]. Reward = [1.9599859]
Abstract state at timestep 1442 is 3
State prediction error at timestep 1442 is 0.012
Human Feedback received at timestpe 1442 of 10
Current timestep = 1443. State = [[ 0.18188305  0.98864454  0.03308074 -0.7488574   0.08047935  0.10091005
   0.          0.        ]]. Action = [[-0.48470986 -0.3738433 ]]. Reward = [-1.5185428]
Abstract state at timestep 1443 is 3
State prediction error at timestep 1443 is 0.012
Human Feedback received at timestpe 1443 of 10
Current timestep = 1444. State = [[ 0.18223362  0.9723294   0.02849736 -0.7254797   0.08697511  0.12991509
   0.          0.        ]]. Action = [[ 0.5374725  -0.64229554]]. Reward = [3.053076]
Abstract state at timestep 1444 is 4
State prediction error at timestep 1444 is 0.012
Human Feedback received at timestpe 1444 of 10
Current timestep = 1445. State = [[ 0.18262215  0.95602584  0.03195288 -0.72502196  0.09380969  0.13669167
   0.          0.        ]]. Action = [[ 0.23371994 -0.09684998]]. Reward = [0.7575397]
Abstract state at timestep 1445 is 4
State prediction error at timestep 1445 is 0.012
Human Feedback received at timestpe 1445 of 10
Current timestep = 1446. State = [[ 0.1830391   0.9401254   0.03437765 -0.70716435  0.10106544  0.14511506
   0.          0.        ]]. Action = [[ 0.9589331 -0.3247714]]. Reward = [2.3065898]
Abstract state at timestep 1446 is 4
State prediction error at timestep 1446 is 0.012
Human Feedback received at timestpe 1446 of 10
Current timestep = 1447. State = [[ 0.18339005  0.92362505  0.02611959 -0.7339801   0.1099721   0.17813322
   0.          0.        ]]. Action = [[-0.47590065 -0.9610952 ]]. Reward = [-1.9517574]
Abstract state at timestep 1447 is 4
State prediction error at timestep 1447 is 0.012
Human Feedback received at timestpe 1447 of 10
Current timestep = 1448. State = [[ 0.1838254   0.907377    0.03572528 -0.7227348   0.11774026  0.15536323
   0.          0.        ]]. Action = [[0.27523518 0.6490693 ]]. Reward = [1.6796898]
Abstract state at timestep 1448 is 4
State prediction error at timestep 1448 is 0.012
Human Feedback received at timestpe 1448 of 10
Current timestep = 1449. State = [[ 0.18425398  0.89144754  0.03700583 -0.7084528   0.12356236  0.116442
   0.          0.        ]]. Action = [[0.19374132 0.9721887 ]]. Reward = [2.1814404]
Abstract state at timestep 1449 is 4
State prediction error at timestep 1449 is 0.012
Human Feedback received at timestpe 1449 of 10
Current timestep = 1450. State = [[ 0.18468256  0.8749184   0.03700634 -0.73512226  0.12938446  0.11644173
   0.          0.        ]]. Action = [[-0.5867472  -0.35101056]]. Reward = [-1.6364263]
Abstract state at timestep 1450 is 4
State prediction error at timestep 1450 is 0.012
Human Feedback received at timestpe 1450 of 10
Current timestep = 1451. State = [[ 0.18511705  0.85836166  0.03734984 -0.736394    0.13546182  0.12154714
   0.          0.        ]]. Action = [[0.9356208 0.3132459]]. Reward = [0.5833345]
Abstract state at timestep 1451 is 4
State prediction error at timestep 1451 is 0.012
Human Feedback received at timestpe 1451 of 10
Current timestep = 1452. State = [[ 0.18539973  0.8424714   0.02389823 -0.7066357   0.13981651  0.08709407
   0.          0.        ]]. Action = [[0.67376375 0.7668817 ]]. Reward = [3.8671377]
Abstract state at timestep 1452 is 4
State prediction error at timestep 1452 is 0.012
Human Feedback received at timestpe 1452 of 10
Current timestep = 1453. State = [[ 0.18561868  0.8271634   0.01579827 -0.68094325  0.14588831  0.12143606
   0.          0.        ]]. Action = [[ 0.6579889 -0.7576656]]. Reward = [3.2023175]
Abstract state at timestep 1453 is 4
State prediction error at timestep 1453 is 0.012
Human Feedback received at timestpe 1453 of 10
Current timestep = 1454. State = [[ 0.18570805  0.8119566   0.00314211 -0.6764362   0.15168251  0.11588405
   0.          0.        ]]. Action = [[0.7252798  0.44230735]]. Reward = [1.1112076]
Abstract state at timestep 1454 is 4
State prediction error at timestep 1454 is 0.012
Human Feedback received at timestpe 1454 of 10
Current timestep = 1455. State = [[ 0.1855731   0.79695183 -0.01863959 -0.6674153   0.15682448  0.10283949
   0.          0.        ]]. Action = [[0.8064774  0.20903766]]. Reward = [1.5567093]
Abstract state at timestep 1455 is 4
State prediction error at timestep 1455 is 0.012
Human Feedback received at timestpe 1455 of 10
Current timestep = 1456. State = [[ 0.18537684  0.78133523 -0.0263279  -0.69479424  0.16352925  0.13409503
   0.          0.        ]]. Action = [[-0.5104155 -0.6515346]]. Reward = [-1.9270313]
Abstract state at timestep 1456 is 4
State prediction error at timestep 1456 is 0.012
Human Feedback received at timestpe 1456 of 10
Current timestep = 1457. State = [[ 0.1851534   0.7656608  -0.02919321 -0.6974083   0.17038202  0.13705581
   0.          0.        ]]. Action = [[ 0.18981898 -0.22109938]]. Reward = [0.3931586]
Abstract state at timestep 1457 is 4
State prediction error at timestep 1457 is 0.012
Human Feedback received at timestpe 1457 of 10
Current timestep = 1458. State = [[ 0.18492985  0.749387   -0.02919224 -0.72407883  0.17723478  0.13705537
   0.          0.        ]]. Action = [[-0.97679096 -0.07712173]]. Reward = [-1.7638794]
Abstract state at timestep 1458 is 4
State prediction error at timestep 1458 is 0.012
Human Feedback received at timestpe 1458 of 10
Current timestep = 1459. State = [[ 0.18456888  0.7332155  -0.042691   -0.71953374  0.1838435   0.13217413
   0.          0.        ]]. Action = [[0.39413822 0.26353765]]. Reward = [1.0946819]
Abstract state at timestep 1459 is 4
State prediction error at timestep 1459 is 0.012
Human Feedback received at timestpe 1459 of 10
Current timestep = 1460. State = [[ 0.18426237  0.71645594 -0.03583772 -0.74551666  0.18905559  0.10424212
   0.          0.        ]]. Action = [[-0.49331754  0.66714   ]]. Reward = [-1.4673032]
Abstract state at timestep 1460 is 4
State prediction error at timestep 1460 is 0.012
Human Feedback received at timestpe 1460 of 10
Current timestep = 1461. State = [[ 0.18389511  0.6998075  -0.04204137 -0.74062324  0.194404    0.10696819
   0.          0.        ]]. Action = [[0.83128357 0.07376039]]. Reward = [1.2671964]
Abstract state at timestep 1461 is 4
State prediction error at timestep 1461 is 0.012
Human Feedback received at timestpe 1461 of 10
Current timestep = 1462. State = [[ 0.18359824  0.6825764  -0.03320408 -0.7662932   0.19794323  0.07078395
   0.          0.        ]]. Action = [[-0.5474791  0.7256094]]. Reward = [-1.2224758]
Abstract state at timestep 1462 is 4
State prediction error at timestep 1462 is 0.012
Human Feedback received at timestpe 1462 of 10
Current timestep = 1463. State = [[ 0.18314609  0.66548425 -0.05005939 -0.76030445  0.20282358  0.09760705
   0.          0.        ]]. Action = [[ 0.92227507 -0.6693413 ]]. Reward = [1.3708383]
Abstract state at timestep 1463 is 4
State prediction error at timestep 1463 is 0.012
Human Feedback received at timestpe 1463 of 10
Current timestep = 1464. State = [[ 0.18269396  0.6477925  -0.05005879 -0.786973    0.20770392  0.09760688
   0.          0.        ]]. Action = [[-0.50009    -0.46917522]]. Reward = [-1.4329144]
Abstract state at timestep 1464 is 4
State prediction error at timestep 1464 is 0.012
Human Feedback received at timestpe 1464 of 10
Current timestep = 1465. State = [[ 0.18224172  0.62950104 -0.05005819 -0.8136416   0.21258426  0.0976067
   0.          0.        ]]. Action = [[-0.27703893 -0.23385882]]. Reward = [-1.3784997]
Abstract state at timestep 1465 is 4
State prediction error at timestep 1465 is 0.012
Human Feedback received at timestpe 1465 of 10
Current timestep = 1466. State = [[ 0.1818142   0.61150104 -0.048267   -0.8008058   0.21815667  0.11144807
   0.          0.        ]]. Action = [[0.9495976  0.14697266]]. Reward = [2.1816514]
Abstract state at timestep 1466 is 4
State prediction error at timestep 1466 is 0.012
Human Feedback received at timestpe 1466 of 10
Current timestep = 1467. State = [[ 0.18117896  0.5940265  -0.0688465  -0.77744186  0.22354262  0.10771906
   0.          0.        ]]. Action = [[0.9350469 0.0703851]]. Reward = [3.0401826]
Abstract state at timestep 1467 is 4
State prediction error at timestep 1467 is 0.012
Human Feedback received at timestpe 1467 of 10
Current timestep = 1468. State = [[ 0.18049231  0.57707363 -0.07451452 -0.75435483  0.22946368  0.11842153
   0.          0.        ]]. Action = [[0.9816855  0.33445835]]. Reward = [2.9964993]
Abstract state at timestep 1468 is 4
State prediction error at timestep 1468 is 0.012
Human Feedback received at timestpe 1468 of 10
Current timestep = 1469. State = [[ 0.17964725  0.5602593  -0.08886147 -0.74799186  0.23388453  0.08841727
   0.          0.        ]]. Action = [[0.7041868  0.63652277]]. Reward = [1.3891239]
Abstract state at timestep 1469 is 4
State prediction error at timestep 1469 is 0.012
Human Feedback received at timestpe 1469 of 10
Current timestep = 1470. State = [[ 0.17874518  0.542825   -0.09604236 -0.7757959   0.2398039   0.11838727
   0.          0.        ]]. Action = [[-0.1384691  -0.67717695]]. Reward = [-1.7729278]
Abstract state at timestep 1470 is 4
State prediction error at timestep 1470 is 0.012
Human Feedback received at timestpe 1470 of 10
Current timestep = 1471. State = [[ 0.177777    0.52522427 -0.10265657 -0.78321624  0.24574436  0.11880942
   0.          0.        ]]. Action = [[ 0.1077503  -0.25449574]]. Reward = [0.12024775]
Abstract state at timestep 1471 is 4
State prediction error at timestep 1471 is 0.012
Human Feedback received at timestpe 1471 of 10
Current timestep = 1472. State = [[ 0.17680883  0.50702405 -0.10265552 -0.80988574  0.2516848   0.11880918
   0.          0.        ]]. Action = [[-0.8786596   0.05407608]]. Reward = [-1.4863707]
Abstract state at timestep 1472 is 4
State prediction error at timestep 1472 is 0.012
Human Feedback received at timestpe 1472 of 10
Current timestep = 1473. State = [[ 0.17581654  0.4889273  -0.10383523 -0.80509686  0.25638175  0.09393857
   0.          0.        ]]. Action = [[0.75896704 0.66461205]]. Reward = [1.445584]
Abstract state at timestep 1473 is 4
State prediction error at timestep 1473 is 0.012
Human Feedback received at timestpe 1473 of 10
Current timestep = 1474. State = [[ 0.17466077  0.4710929  -0.12011478 -0.7934421   0.26102215  0.09280779
   0.          0.        ]]. Action = [[ 0.4611503  -0.08679169]]. Reward = [1.9599783]
Abstract state at timestep 1474 is 5
State prediction error at timestep 1474 is 0.012
Human Feedback received at timestpe 1474 of 10
Current timestep = 1475. State = [[ 0.1734397   0.45262307 -0.12840468 -0.82201713  0.26745275  0.12861177
   0.          0.        ]]. Action = [[-0.08974171 -0.8090815 ]]. Reward = [-1.8462877]
Abstract state at timestep 1475 is 5
State prediction error at timestep 1475 is 0.012
Human Feedback received at timestpe 1475 of 10
Current timestep = 1476. State = [[ 0.17214307  0.4335307  -0.13785678 -0.8500659   0.2758467   0.16787943
   0.          0.        ]]. Action = [[-0.32789445 -0.8802291 ]]. Reward = [-1.958562]
Abstract state at timestep 1476 is 5
State prediction error at timestep 1476 is 0.012
Human Feedback received at timestpe 1476 of 10
Current timestep = 1477. State = [[ 0.17077693  0.41380405 -0.1466198  -0.8786617   0.28612775  0.20562129
   0.          0.        ]]. Action = [[-0.40968853 -0.8233887 ]]. Reward = [-2.136923]
Abstract state at timestep 1477 is 5
State prediction error at timestep 1477 is 0.012
Human Feedback received at timestpe 1477 of 10
Current timestep = 1478. State = [[ 0.16929016  0.39388254 -0.15847002 -0.887355    0.29622644  0.20197356
   0.          0.        ]]. Action = [[0.40545547 0.42705452]]. Reward = [-0.38536]
Abstract state at timestep 1478 is 5
State prediction error at timestep 1478 is 0.012
Human Feedback received at timestpe 1478 of 10
Current timestep = 1479. State = [[ 0.16780329  0.37336236 -0.15846637 -0.9140299   0.30632502  0.20197213
   0.          0.        ]]. Action = [[-0.69063324 -0.4175024 ]]. Reward = [-1.6984861]
Abstract state at timestep 1479 is 5
State prediction error at timestep 1479 is 0.012
Human Feedback received at timestpe 1479 of 10
Current timestep = 1480. State = [[ 0.16623917  0.35291407 -0.1664229  -0.910959    0.31670845  0.20766874
   0.          0.        ]]. Action = [[0.9976549 0.4433043]]. Reward = [0.74792564]
Abstract state at timestep 1480 is 5
State prediction error at timestep 1480 is 0.012
Human Feedback received at timestpe 1480 of 10
Current timestep = 1481. State = [[ 0.16447219  0.3328542  -0.18516243 -0.89342177  0.3255067   0.17596512
   0.          0.        ]]. Action = [[0.80835676 0.7284478 ]]. Reward = [2.0734475]
Abstract state at timestep 1481 is 5
State prediction error at timestep 1481 is 0.012
Human Feedback received at timestpe 1481 of 10
Current timestep = 1482. State = [[ 0.16264725  0.31215972 -0.1924762  -0.92203707  0.33592817  0.20842895
   0.          0.        ]]. Action = [[-0.36274397 -0.667589  ]]. Reward = [-2.0845892]
Abstract state at timestep 1482 is 5
State prediction error at timestep 1482 is 0.012
Human Feedback received at timestpe 1482 of 10
Current timestep = 1483. State = [[ 0.1607153   0.29112568 -0.20295191 -0.9371492   0.3461469   0.20437483
   0.          0.        ]]. Action = [[ 0.06567979 -0.42877495]]. Reward = [-0.9327871]
Abstract state at timestep 1483 is 5
State prediction error at timestep 1483 is 0.012
Human Feedback received at timestpe 1483 of 10
Current timestep = 1484. State = [[ 0.15878734  0.26997843 -0.20133922 -0.9419573   0.35511735  0.17940938
   0.          0.        ]]. Action = [[0.1788559  0.65271604]]. Reward = [0.4033242]
Abstract state at timestep 1484 is 5
State prediction error at timestep 1484 is 0.012
Human Feedback received at timestpe 1484 of 10
Current timestep = 1485. State = [[ 0.15685911  0.24823208 -0.20133576 -0.9686302   0.36408776  0.1794084
   0.          0.        ]]. Action = [[-0.5669249  -0.30008316]]. Reward = [-1.5496275]
Abstract state at timestep 1485 is 5
State prediction error at timestep 1485 is 0.012
Human Feedback received at timestpe 1485 of 10
Current timestep = 1486. State = [[ 0.15493059  0.22588685 -0.20133221 -0.99530315  0.3730581   0.17940737
   0.          0.        ]]. Action = [[-0.9505345  -0.30137944]]. Reward = [-1.5372821]
Abstract state at timestep 1486 is 5
State prediction error at timestep 1486 is 0.012
Human Feedback received at timestpe 1486 of 10
Current timestep = 1487. State = [[ 0.15300187  0.20294252 -0.20132859 -1.0219761   0.38202843  0.17940637
   0.          0.        ]]. Action = [[-0.3465802 -0.3036222]]. Reward = [-1.5369364]
Abstract state at timestep 1487 is 5
State prediction error at timestep 1487 is 0.012
Human Feedback received at timestpe 1487 of 10
Current timestep = 1488. State = [[ 0.15107298  0.17939931 -0.20132487 -1.0486491   0.39099866  0.17940539
   0.          0.        ]]. Action = [[-0.5945491  -0.24084127]]. Reward = [-1.5532036]
Abstract state at timestep 1488 is 5
State prediction error at timestep 1488 is 0.012
Human Feedback received at timestpe 1488 of 10
Current timestep = 1489. State = [[ 0.14909324  0.15586103 -0.2050041  -1.0480961   0.39851692  0.15036562
   0.          0.        ]]. Action = [[0.4087205 0.7404125]]. Reward = [0.88371754]
Abstract state at timestep 1489 is 5
State prediction error at timestep 1489 is 0.012
Human Feedback received at timestpe 1489 of 10
Current timestep = 1490. State = [[ 0.14706507  0.13169153 -0.21113841 -1.0765597   0.40743083  0.17827798
   0.          0.        ]]. Action = [[-0.3265084 -0.6120014]]. Reward = [-1.9931412]
Abstract state at timestep 1490 is 5
State prediction error at timestep 1490 is 0.012
Human Feedback received at timestpe 1490 of 10
Current timestep = 1491. State = [[ 0.14503661  0.10692295 -0.21113452 -1.1032326   0.4163446   0.17827602
   0.          0.        ]]. Action = [[-0.7894612   0.08400738]]. Reward = [-1.7877957]
Abstract state at timestep 1491 is 5
State prediction error at timestep 1491 is 0.012
Human Feedback received at timestpe 1491 of 10
Current timestep = 1492. State = [[ 0.14294338  0.08151341 -0.2192647  -1.1322838   0.42711163  0.21533987
   0.          0.        ]]. Action = [[-0.27434427 -0.9395974 ]]. Reward = [-2.5475738]
Abstract state at timestep 1492 is 5
State prediction error at timestep 1492 is 0.012
Human Feedback received at timestpe 1492 of 10
Current timestep = 1493. State = [[ 0.14084491  0.05607105 -0.21880265 -1.1335157   0.43682718  0.19431177
   0.          0.        ]]. Action = [[0.10671079 0.58146596]]. Reward = [0.0284115]
Abstract state at timestep 1493 is 5
State prediction error at timestep 1493 is 0.012
Human Feedback received at timestpe 1493 of 10
Current timestep = 1494. State = [[ 0.13868685  0.03059822 -0.22514844 -1.1350724   0.44703725  0.20420113
   0.          1.        ]]. Action = [[ 0.9577601  -0.04138547]]. Reward = [9.368044]
Abstract state at timestep 1494 is 5
State prediction error at timestep 1494 is 0.012
Human Feedback received at timestpe 1494 of 10
Current timestep = 1495. State = [[ 0.13651028  0.00660411 -0.2178401  -1.067279    0.44156176 -0.11732248
   0.          1.        ]]. Action = [[ 0.25306416 -0.2073139 ]]. Reward = [7.685127]
Abstract state at timestep 1495 is 5
State prediction error at timestep 1495 is 0.012
Human Feedback received at timestpe 1495 of 10
Current timestep = 1496. State = [[-0.00737457  1.4007452  -0.74697864 -0.45225203  0.00855205  0.16920173
   0.          0.        ]]. Action = [[0.3954966 0.7138896]]. Reward = [-100.]
Abstract state at timestep 1496 is 5
State prediction error at timestep 1496 is 0.012
Human Feedback received at timestpe 1496 of 10
Current timestep = 1497. State = [[-0.01473293  1.391041   -0.7424927  -0.43134096  0.01512515  0.1314753
   0.          0.        ]]. Action = [[0.88853717 0.8553473 ]]. Reward = [1.4509437]
Abstract state at timestep 1497 is 3
State prediction error at timestep 1497 is 0.012
Human Feedback received at timestpe 1497 of 10
Current timestep = 1498. State = [[-0.02212391  1.3807403  -0.74656284 -0.45791292  0.02250588  0.14762853
   0.          0.        ]]. Action = [[-0.4362353 -0.516749 ]]. Reward = [-1.4451416]
Abstract state at timestep 1498 is 3
State prediction error at timestep 1498 is 0.012
Human Feedback received at timestpe 1498 of 10
Current timestep = 1499. State = [[-0.02951517  1.36984    -0.7465857  -0.4845842   0.02988493  0.14759454
   0.          0.        ]]. Action = [[-0.759366   -0.15699548]]. Reward = [-1.0874166]
Abstract state at timestep 1499 is 3
State prediction error at timestep 1499 is 0.012
Human Feedback received at timestpe 1499 of 10
Current timestep = 1500. State = [[-0.03690662  1.3583405  -0.7466078  -0.511256    0.03726296  0.14757447
   0.          0.        ]]. Action = [[-0.17766452 -0.46119165]]. Reward = [-1.0877726]
Abstract state at timestep 1500 is 3
State prediction error at timestep 1500 is 0.012
Human Feedback received at timestpe 1500 of 10
Current timestep = 1501. State = [[-0.04442348  1.3471174  -0.7604879  -0.49905145  0.04596899  0.17413698
   0.          0.        ]]. Action = [[ 0.56206274 -0.72059715]]. Reward = [-0.500638]
Abstract state at timestep 1501 is 3
State prediction error at timestep 1501 is 0.012
Human Feedback received at timestpe 1501 of 10
Current timestep = 1502. State = [[-0.05189877  1.3359475  -0.75662214 -0.4967386   0.05496784  0.17999348
   0.          0.        ]]. Action = [[0.22596323 0.12535703]]. Reward = [0.45575342]
Abstract state at timestep 1502 is 3
State prediction error at timestep 1502 is 0.012
Human Feedback received at timestpe 1502 of 10
Current timestep = 1503. State = [[-0.05937433  1.3241787  -0.75664824 -0.523415    0.06396525  0.17996511
   0.          0.        ]]. Action = [[-0.68189245 -0.27660632]]. Reward = [-1.248355]
Abstract state at timestep 1503 is 3
State prediction error at timestep 1503 is 0.012
Human Feedback received at timestpe 1503 of 10
Current timestep = 1504. State = [[-0.06685019  1.311811   -0.75667435 -0.5500886   0.07296134  0.17993852
   0.          0.        ]]. Action = [[-0.09942359  0.00735283]]. Reward = [-1.2453078]
Abstract state at timestep 1504 is 3
State prediction error at timestep 1504 is 0.012
Human Feedback received at timestpe 1504 of 10
Current timestep = 1505. State = [[-0.07432652  1.2988442  -0.7567002  -0.57676214  0.08195601  0.17990984
   0.          0.        ]]. Action = [[-0.13365132  0.43566608]]. Reward = [-1.2400415]
Abstract state at timestep 1505 is 3
State prediction error at timestep 1505 is 0.012
Human Feedback received at timestpe 1505 of 10
Current timestep = 1506. State = [[-0.08180304  1.2852787  -0.75672585 -0.6034373   0.09094923  0.17988119
   0.          0.        ]]. Action = [[-0.62101024 -0.46463525]]. Reward = [-1.2326256]
Abstract state at timestep 1506 is 3
State prediction error at timestep 1506 is 0.012
Human Feedback received at timestpe 1506 of 10
Current timestep = 1507. State = [[-0.08932094  1.2723863  -0.7610235  -0.5735758   0.1001116   0.18326417
   0.          0.        ]]. Action = [[ 0.77793944 -0.01682848]]. Reward = [1.5434515]
Abstract state at timestep 1507 is 3
State prediction error at timestep 1507 is 0.012
Human Feedback received at timestpe 1507 of 10
Current timestep = 1508. State = [[-0.09694719  1.2594011  -0.77149665 -0.5777271   0.10892371  0.17625844
   0.          0.        ]]. Action = [[0.89165866 0.20829082]]. Reward = [-1.012593]
Abstract state at timestep 1508 is 3
State prediction error at timestep 1508 is 0.012
Human Feedback received at timestpe 1508 of 10
Current timestep = 1509. State = [[-0.10462599  1.2468152  -0.7768331  -0.560048    0.11783084  0.17815892
   0.          0.        ]]. Action = [[ 0.35422206 -0.4560727 ]]. Reward = [0.7159478]
Abstract state at timestep 1509 is 3
State prediction error at timestep 1509 is 0.012
Human Feedback received at timestpe 1509 of 10
Current timestep = 1510. State = [[-0.11228161  1.2339795  -0.7729074  -0.5710638   0.12514357  0.146268
   0.          0.        ]]. Action = [[0.32451594 0.7943541 ]]. Reward = [-0.07411291]
Abstract state at timestep 1510 is 3
State prediction error at timestep 1510 is 0.012
Human Feedback received at timestpe 1510 of 10
Current timestep = 1511. State = [[-0.12002754  1.2209208  -0.78165627 -0.5809923   0.13218273  0.14079608
   0.          0.        ]]. Action = [[0.07982969 0.46081185]]. Reward = [-0.9328592]
Abstract state at timestep 1511 is 3
State prediction error at timestep 1511 is 0.012
Human Feedback received at timestpe 1511 of 10
Current timestep = 1512. State = [[-0.12777385  1.2072628  -0.7816757  -0.6076676   0.13922073  0.14077258
   0.          0.        ]]. Action = [[-0.42100787  0.14102006]]. Reward = [-1.0396863]
Abstract state at timestep 1512 is 3
State prediction error at timestep 1512 is 0.012
Human Feedback received at timestpe 1512 of 10
Current timestep = 1513. State = [[-0.13558045  1.1930029  -0.78922707 -0.6345807   0.14776479  0.17089692
   0.          0.        ]]. Action = [[-0.53391796 -0.8798099 ]]. Reward = [-1.8100818]
Abstract state at timestep 1513 is 3
State prediction error at timestep 1513 is 0.012
Human Feedback received at timestpe 1513 of 10
Current timestep = 1514. State = [[-0.14341573  1.1786096  -0.79214704 -0.6405804   0.15639013  0.17252229
   0.          0.        ]]. Action = [[ 0.28671265 -0.08461839]]. Reward = [-0.32153192]
Abstract state at timestep 1514 is 3
State prediction error at timestep 1514 is 0.012
Human Feedback received at timestpe 1514 of 10
Current timestep = 1515. State = [[-0.15129499  1.1636118  -0.7976452  -0.6676141   0.16611889  0.1945928
   0.          0.        ]]. Action = [[-0.5522672  -0.57500964]]. Reward = [-1.742669]
Abstract state at timestep 1515 is 3
State prediction error at timestep 1515 is 0.012
Human Feedback received at timestpe 1515 of 10
Current timestep = 1516. State = [[-0.1592801   1.1487596  -0.80687636 -0.6610509   0.17450002  0.16763774
   0.          0.        ]]. Action = [[0.1301589 0.6184838]]. Reward = [0.04710348]
Abstract state at timestep 1516 is 3
State prediction error at timestep 1516 is 0.012
Human Feedback received at timestpe 1516 of 10
Current timestep = 1517. State = [[-0.16726561  1.1333082  -0.80689734 -0.68773323  0.1828808   0.16763103
   0.          0.        ]]. Action = [[-0.6178359  -0.13088995]]. Reward = [-1.1342927]
Abstract state at timestep 1517 is 3
State prediction error at timestep 1517 is 0.012
Human Feedback received at timestpe 1517 of 10
Current timestep = 1518. State = [[-0.17528924  1.1172414  -0.8116914  -0.71525425  0.19225861  0.1875731
   0.          0.        ]]. Action = [[-0.26894057 -0.6171781 ]]. Reward = [-1.6534392]
Abstract state at timestep 1518 is 3
State prediction error at timestep 1518 is 0.012
Human Feedback received at timestpe 1518 of 10
Current timestep = 1519. State = [[-0.18354921  1.1011404  -0.83455724 -0.7167316   0.20089372  0.17271744
   0.          0.        ]]. Action = [[ 0.92110753 -0.41441768]]. Reward = [-1.5162994]
Abstract state at timestep 1519 is 3
State prediction error at timestep 1519 is 0.012
Human Feedback received at timestpe 1519 of 10
Current timestep = 1520. State = [[-0.19186315  1.0844274  -0.8413256  -0.7441761   0.21091014  0.20034663
   0.          0.        ]]. Action = [[-0.83738774 -0.84829277]]. Reward = [-1.834211]
Abstract state at timestep 1520 is 3
State prediction error at timestep 1520 is 0.012
Human Feedback received at timestpe 1520 of -10
Current timestep = 1521. State = [[-0.20028535  1.0682855  -0.8527552  -0.7189537   0.22156547  0.21311359
   0.          0.        ]]. Action = [[ 0.6434175  -0.47703707]]. Reward = [0.908619]
Abstract state at timestep 1521 is 3
State prediction error at timestep 1521 is 0.012
Human Feedback received at timestpe 1521 of -10
Current timestep = 1522. State = [[-0.20879355  1.0521269  -0.8609781  -0.7197254   0.23185448  0.20578022
   0.          0.        ]]. Action = [[0.2319938  0.03782582]]. Reward = [-0.46769047]
Abstract state at timestep 1522 is 3
State prediction error at timestep 1522 is 0.012
Human Feedback received at timestpe 1522 of -10
Current timestep = 1523. State = [[-0.21730193  1.0353696  -0.8609751  -0.7464007   0.2421434   0.20577843
   0.          0.        ]]. Action = [[-0.5191866   0.40574253]]. Reward = [-1.2862116]
Abstract state at timestep 1523 is 3
State prediction error at timestep 1523 is 0.012
Human Feedback received at timestpe 1523 of -10
Current timestep = 1524. State = [[-0.22581653  1.0187058  -0.86204356 -0.74238163  0.25291726  0.2154772
   0.          0.        ]]. Action = [[ 0.8613862  -0.11178404]]. Reward = [0.2746523]
Abstract state at timestep 1524 is 3
State prediction error at timestep 1524 is 0.012
Human Feedback received at timestpe 1524 of -10
Current timestep = 1525. State = [[-0.23433137  1.0014439  -0.8620399  -0.7690577   0.26369104  0.21547541
   0.          0.        ]]. Action = [[-0.48918372  0.0889492 ]]. Reward = [-1.3416042]
Abstract state at timestep 1525 is 3
State prediction error at timestep 1525 is 0.012
Human Feedback received at timestpe 1525 of -10
Current timestep = 1526. State = [[-0.24278536  0.9843184  -0.8545295  -0.7628042   0.27303854  0.18695065
   0.          0.        ]]. Action = [[0.91758156 0.8290428 ]]. Reward = [1.1971102]
Abstract state at timestep 1526 is 3
State prediction error at timestep 1526 is 0.012
Human Feedback received at timestpe 1526 of -10
Current timestep = 1527. State = [[-0.25123954  0.96659404 -0.8545264  -0.789478    0.282386    0.18694961
   0.          0.        ]]. Action = [[-0.679123    0.16887808]]. Reward = [-1.2172008]
Abstract state at timestep 1527 is 4
State prediction error at timestep 1527 is 0.012
Human Feedback received at timestpe 1527 of -10
Current timestep = 1528. State = [[-0.2600205   0.9493475  -0.8880156  -0.768468    0.29259697  0.2042191
   0.          0.        ]]. Action = [[ 0.8441783 -0.5277661]]. Reward = [-0.96972996]
Abstract state at timestep 1528 is 4
State prediction error at timestep 1528 is 0.012
Human Feedback received at timestpe 1528 of -10
Current timestep = 1529. State = [[-0.26880175  0.9315023  -0.88801193 -0.7951431   0.30280787  0.20421779
   0.          0.        ]]. Action = [[-0.4939286   0.35092437]]. Reward = [-1.3032316]
Abstract state at timestep 1529 is 4
State prediction error at timestep 1529 is 0.012
Human Feedback received at timestpe 1529 of -10
Current timestep = 1530. State = [[-0.2777668   0.9142256  -0.90837765 -0.7703732   0.3151117   0.24607635
   0.          0.        ]]. Action = [[ 0.9889481  -0.91099334]]. Reward = [-0.06205427]
Abstract state at timestep 1530 is 4
State prediction error at timestep 1530 is 0.012
Human Feedback received at timestpe 1530 of -10
Current timestep = 1531. State = [[-0.28706583  0.89744943 -0.94347656 -0.74862015  0.329231    0.28238505
   0.          0.        ]]. Action = [[ 0.51980925 -0.9062925 ]]. Reward = [-1.6763177]
Abstract state at timestep 1531 is 4
State prediction error at timestep 1531 is 0.012
Human Feedback received at timestpe 1531 of -10
Current timestep = 1532. State = [[-0.29636544  0.8800757  -0.9434687  -0.77530277  0.34335005  0.28238118
   0.          0.        ]]. Action = [[-0.30316448 -0.07575595]]. Reward = [-1.727026]
Abstract state at timestep 1532 is 4
State prediction error at timestep 1532 is 0.012
Human Feedback received at timestpe 1532 of -10
Current timestep = 1533. State = [[-0.30566567  0.8621046  -0.94346035 -0.8019852   0.35746887  0.2823773
   0.          0.        ]]. Action = [[-0.18132365 -0.3386684 ]]. Reward = [-1.7277046]
Abstract state at timestep 1533 is 4
State prediction error at timestep 1533 is 0.012
Human Feedback received at timestpe 1533 of -10
Current timestep = 1534. State = [[-0.3151768   0.8444993  -0.9646025  -0.78588766  0.37171575  0.28493765
   0.          0.        ]]. Action = [[0.874279   0.13292062]]. Reward = [-0.97193116]
Abstract state at timestep 1534 is 1
State prediction error at timestep 1534 is 0.012
Human Feedback received at timestpe 1534 of -10
Current timestep = 1535. State = [[-0.3249073   0.8273558  -0.9866966  -0.7655447   0.38620642  0.28981343
   0.          0.        ]]. Action = [[0.9813962 0.3423338]]. Reward = [-0.9565572]
Abstract state at timestep 1535 is 1
State prediction error at timestep 1535 is 0.012
Human Feedback received at timestpe 1535 of -10
Current timestep = 1536. State = [[-0.33458704  0.80965346 -0.98011196 -0.7901099   0.39917558  0.2593834
   0.          0.        ]]. Action = [[-0.83495426  0.6050854 ]]. Reward = [-1.0422782]
Abstract state at timestep 1536 is 1
State prediction error at timestep 1536 is 0.012
Human Feedback received at timestpe 1536 of -10
Current timestep = 1537. State = [[-0.34469637  0.7922813  -1.024211   -0.77589715  0.41343895  0.28526714
   0.          0.        ]]. Action = [[ 0.5592673  -0.71676725]]. Reward = [-3.0767407]
Abstract state at timestep 1537 is 1
State prediction error at timestep 1537 is 0.012
Human Feedback received at timestpe 1537 of -10
Current timestep = 1538. State = [[-0.35480648  0.7743117  -1.024201   -0.80257964  0.4277021   0.28526324
   0.          0.        ]]. Action = [[-0.9485385  0.4565816]]. Reward = [-1.8255591]
Abstract state at timestep 1538 is 1
State prediction error at timestep 1538 is 0.012
Human Feedback received at timestpe 1538 of -10
Current timestep = 1539. State = [[-0.36520958  0.75646204 -1.0531328  -0.79727566  0.44165325  0.27902335
   0.          0.        ]]. Action = [[0.4238484  0.00723088]]. Reward = [-2.4048095]
Abstract state at timestep 1539 is 1
State prediction error at timestep 1539 is 0.012
Human Feedback received at timestpe 1539 of -10
Current timestep = 1540. State = [[-0.3756134   0.73801476 -1.0531225  -0.8239572   0.45560423  0.27901965
   0.          0.        ]]. Action = [[-0.94645715 -0.15597242]]. Reward = [-1.8310213]
Abstract state at timestep 1540 is 1
State prediction error at timestep 1540 is 0.012
Human Feedback received at timestpe 1540 of -10
Current timestep = 1541. State = [[-0.38623923  0.71980923 -1.0733602  -0.81270343  0.46747878  0.23749137
   0.          0.        ]]. Action = [[0.37604427 0.98291266]]. Reward = [-1.2193977]
Abstract state at timestep 1541 is 1
State prediction error at timestep 1541 is 0.012
Human Feedback received at timestpe 1541 of -10
Current timestep = 1542. State = [[-0.39719877  0.7017992  -1.1064206  -0.80400825  0.47908142  0.23205292
   0.          0.        ]]. Action = [[ 0.8209169  -0.23306865]]. Reward = [-2.5223932]
Abstract state at timestep 1542 is 1
State prediction error at timestep 1542 is 0.012
Human Feedback received at timestpe 1542 of -10
Current timestep = 1543. State = [[-0.40815887  0.683191   -1.1064129  -0.83068496  0.49068397  0.23205075
   0.          0.        ]]. Action = [[-0.12684447 -0.04953921]]. Reward = [-1.6870639]
Abstract state at timestep 1543 is 1
State prediction error at timestep 1543 is 0.012
Human Feedback received at timestpe 1543 of -10
Current timestep = 1544. State = [[-0.4192183   0.6647929  -1.1151229  -0.82099515  0.5009838   0.20599589
   0.          0.        ]]. Action = [[0.60394776 0.7174833 ]]. Reward = [-0.42352903]
Abstract state at timestep 1544 is 1
State prediction error at timestep 1544 is 0.012
Human Feedback received at timestpe 1544 of -10
Current timestep = 1545. State = [[-0.43043786  0.6462256  -1.1328312  -0.82923156  0.51326007  0.24552603
   0.          0.        ]]. Action = [[ 0.53381574 -0.8955244 ]]. Reward = [-2.451589]
Abstract state at timestep 1545 is 1
State prediction error at timestep 1545 is 0.012
Human Feedback received at timestpe 1545 of -10
Current timestep = 1546. State = [[-0.44172335  0.62701577 -1.1410317  -0.8585307   0.5274543   0.28388515
   0.          0.        ]]. Action = [[-0.30737108 -0.7670205 ]]. Reward = [-2.90015]
Abstract state at timestep 1546 is 1
State prediction error at timestep 1546 is 0.012
Human Feedback received at timestpe 1546 of -10
Current timestep = 1547. State = [[-0.45334816  0.6077957  -1.1744777  -0.8589521   0.541208    0.27507475
   0.          0.        ]]. Action = [[ 0.85176563 -0.0803296 ]]. Reward = [-3.4906373]
Abstract state at timestep 1547 is 1
State prediction error at timestep 1547 is 0.012
Human Feedback received at timestpe 1547 of -10
Current timestep = 1548. State = [[-0.46534127  0.58908606 -1.2103007  -0.83600163  0.5539065   0.25396955
   0.          0.        ]]. Action = [[0.7833288 0.524735 ]]. Reward = [-2.389457]
Abstract state at timestep 1548 is 1
State prediction error at timestep 1548 is 0.012
Human Feedback received at timestpe 1548 of -10
Current timestep = 1549. State = [[-0.47728592  0.56982595 -1.2039834  -0.8599743   0.5649931   0.22173175
   0.          0.        ]]. Action = [[-0.13382334  0.6510874 ]]. Reward = [-1.2488478]
Abstract state at timestep 1549 is 1
State prediction error at timestep 1549 is 0.012
Human Feedback received at timestpe 1549 of -10
Current timestep = 1550. State = [[-0.48919478  0.55000114 -1.19934    -0.88471025  0.57490337  0.19820678
   0.          0.        ]]. Action = [[-0.06429404  0.50957894]]. Reward = [-1.3610312]
Abstract state at timestep 1550 is 1
State prediction error at timestep 1550 is 0.012
Human Feedback received at timestpe 1550 of -10
Current timestep = 1551. State = [[-0.50150394  0.53016996 -1.23796    -0.8844524   0.5832099   0.16612974
   0.          0.        ]]. Action = [[0.7959337 0.5468526]]. Reward = [-3.5972142]
Abstract state at timestep 1551 is 1
State prediction error at timestep 1551 is 0.012
Human Feedback received at timestpe 1551 of -10
Current timestep = 1552. State = [[-0.5142411   0.5105355  -1.2792366  -0.8750786   0.5897395   0.13059255
   0.          0.        ]]. Action = [[0.47808218 0.73643696]]. Reward = [-3.2272873]
Abstract state at timestep 1552 is 1
State prediction error at timestep 1552 is 0.012
Human Feedback received at timestpe 1552 of -10
Current timestep = 1553. State = [[-0.52708805  0.49084204 -1.2906089  -0.87791866  0.5967747   0.14070423
   0.          0.        ]]. Action = [[ 0.8836708  -0.09134418]]. Reward = [-1.6466023]
Abstract state at timestep 1553 is 1
State prediction error at timestep 1553 is 0.012
Human Feedback received at timestpe 1553 of -10
Current timestep = 1554. State = [[-0.5399353   0.4705491  -1.2906053  -0.9045887   0.6038099   0.14070377
   0.          0.        ]]. Action = [[-0.5271511  0.3255347]]. Reward = [-1.81484]
Abstract state at timestep 1554 is 2
State prediction error at timestep 1554 is 0.012
Human Feedback received at timestpe 1554 of -10
Current timestep = 1555. State = [[-0.5527827   0.4496567  -1.2906018  -0.9312588   0.610845    0.14070329
   0.          0.        ]]. Action = [[-0.8845709   0.31260288]]. Reward = [-1.885947]
Abstract state at timestep 1555 is 2
State prediction error at timestep 1555 is 0.012
Human Feedback received at timestpe 1555 of -10
Current timestep = 1556. State = [[-0.56594384  0.42883137 -1.3230618  -0.9288429   0.61925     0.16809939
   0.          0.        ]]. Action = [[ 0.9098674 -0.5786715]]. Reward = [-3.3978148]
Abstract state at timestep 1556 is 2
State prediction error at timestep 1556 is 0.012
Human Feedback received at timestpe 1556 of -10
Current timestep = 1557. State = [[-0.57943153  0.40850246 -1.3547418  -0.9063606   0.626497    0.14493999
   0.          0.        ]]. Action = [[0.70805836 0.64170885]]. Reward = [-2.2314057]
Abstract state at timestep 1557 is 2
State prediction error at timestep 1557 is 0.012
Human Feedback received at timestpe 1557 of -10
Current timestep = 1558. State = [[-0.5929195   0.38757408 -1.354738   -0.9330309   0.63374394  0.14493944
   0.          0.        ]]. Action = [[-0.40451503 -0.38198197]]. Reward = [-2.1625159]
Abstract state at timestep 1558 is 2
State prediction error at timestep 1558 is 0.012
Human Feedback received at timestpe 1558 of -10
Current timestep = 1559. State = [[-0.606449    0.36599323 -1.3600858  -0.9626785   0.64252067  0.17553447
   0.          0.        ]]. Action = [[-0.21954715 -0.8567645 ]]. Reward = [-3.036646]
Abstract state at timestep 1559 is 2
State prediction error at timestep 1559 is 0.012
Human Feedback received at timestpe 1559 of -10
Current timestep = 1560. State = [[-0.6202754   0.34431997 -1.3911562  -0.96754557  0.65305656  0.2107176
   0.          0.        ]]. Action = [[ 0.2826686 -0.7978948]]. Reward = [-4.2034082]
Abstract state at timestep 1560 is 2
State prediction error at timestep 1560 is 0.012
Human Feedback received at timestpe 1560 of -10
Current timestep = 1561. State = [[-0.6341024   0.32204792 -1.3911477  -0.9942196   0.66359234  0.21071593
   0.          0.        ]]. Action = [[-0.2654274   0.29480922]]. Reward = [-2.7661233]
Abstract state at timestep 1561 is 2
State prediction error at timestep 1561 is 0.012
Human Feedback received at timestpe 1561 of -10
Current timestep = 1562. State = [[-0.64793     0.29917705 -1.3911393  -1.0208937   0.67412806  0.21071431
   0.          0.        ]]. Action = [[-0.59091216  0.12704313]]. Reward = [-2.864502]
Abstract state at timestep 1562 is 2
State prediction error at timestep 1562 is 0.012
Human Feedback received at timestpe 1562 of -10
Current timestep = 1563. State = [[-0.6617583   0.27570727 -1.3911306  -1.0475677   0.6846637   0.21071267
   0.          0.        ]]. Action = [[-0.01070595 -0.4156394 ]]. Reward = [-2.9671154]
Abstract state at timestep 1563 is 2
State prediction error at timestep 1563 is 0.012
Human Feedback received at timestpe 1563 of -10
Current timestep = 1564. State = [[-0.6755872   0.2516387  -1.3911217  -1.0742416   0.69519925  0.21071112
   0.          0.        ]]. Action = [[-0.44384432  0.18105638]]. Reward = [-3.0738373]
Abstract state at timestep 1564 is 2
State prediction error at timestep 1564 is 0.012
Human Feedback received at timestpe 1564 of -10
Current timestep = 1565. State = [[-0.68941665  0.22697125 -1.3911128  -1.1009154   0.7057347   0.21070953
   0.          0.        ]]. Action = [[-0.51069665  0.1762631 ]]. Reward = [-3.1844518]
Abstract state at timestep 1565 is 2
State prediction error at timestep 1565 is 0.012
Human Feedback received at timestpe 1565 of -10
Current timestep = 1566. State = [[-0.7031841   0.20179833 -1.3828948  -1.1223096   0.7137253   0.15981181
   0.          0.        ]]. Action = [[-0.4042704  0.9732001]]. Reward = [-2.0998847]
Abstract state at timestep 1566 is 2
State prediction error at timestep 1566 is 0.012
Human Feedback received at timestpe 1566 of -10
Current timestep = 1567. State = [[-0.716952    0.17602609 -1.3828895  -1.1489804   0.72171587  0.1598108
   0.          0.        ]]. Action = [[-0.46428192 -0.01336288]]. Reward = [-3.1590192]
Abstract state at timestep 1567 is 2
State prediction error at timestep 1567 is 0.012
Human Feedback received at timestpe 1567 of -10
Current timestep = 1568. State = [[-0.73066986  0.14971091 -1.3764904  -1.1723392   0.7279193   0.12406842
   0.          0.        ]]. Action = [[-0.77583617  0.9354185 ]]. Reward = [-2.4229174]
Abstract state at timestep 1568 is 2
State prediction error at timestep 1568 is 0.012
Human Feedback received at timestpe 1568 of -10
Current timestep = 1569. State = [[-0.7444403   0.12272537 -1.3832538  -1.2030722   0.7361554   0.16472113
   0.          1.        ]]. Action = [[-0.89102256 -0.8942189 ]]. Reward = [5.7682114]
Abstract state at timestep 1569 is 2
State prediction error at timestep 1569 is 0.012
Human Feedback received at timestpe 1569 of -10
Current timestep = 1570. State = [[-0.7579832   0.09819933 -1.3499404  -1.0878571   0.731365   -0.09508988
   0.          1.        ]]. Action = [[-0.31113875  0.8416904 ]]. Reward = [9.423359]
Abstract state at timestep 1570 is 2
State prediction error at timestep 1570 is 0.012
Human Feedback received at timestpe 1570 of -10
Current timestep = 1571. State = [[-0.7722281   0.07366155 -1.407016   -1.0803428   0.70840144 -0.45928997
   0.          1.        ]]. Action = [[ 0.29827678 -0.22903812]]. Reward = [-3.061509]
Abstract state at timestep 1571 is 2
State prediction error at timestep 1571 is 0.012
Human Feedback received at timestpe 1571 of -10
Current timestep = 1572. State = [[ 0.0068059   1.4025534   0.68935573 -0.3718675  -0.00787962 -0.1561492
   0.          0.        ]]. Action = [[0.1375966  0.64010406]]. Reward = [-100.]
Abstract state at timestep 1572 is 2
State prediction error at timestep 1572 is 0.012
Human Feedback received at timestpe 1572 of -10
Current timestep = 1573. State = [[ 0.01357918  1.393617    0.6842902  -0.39722645 -0.01476576 -0.13773541
   0.          0.        ]]. Action = [[-0.265853   -0.55082744]]. Reward = [-0.6132353]
Abstract state at timestep 1573 is 3
State prediction error at timestep 1573 is 0.012
Human Feedback received at timestpe 1573 of -10
Current timestep = 1574. State = [[ 0.02040625  1.3846803   0.6894408  -0.39726943 -0.0214182  -0.13306127
   0.          0.        ]]. Action = [[ 0.01273024 -0.3892101 ]]. Reward = [-0.37991896]
Abstract state at timestep 1574 is 3
State prediction error at timestep 1574 is 0.012
Human Feedback received at timestpe 1574 of -10
Current timestep = 1575. State = [[ 0.0272336   1.3751441   0.6894602  -0.4239489  -0.02806977 -0.13304381
   0.          0.        ]]. Action = [[-0.47013217  0.04489005]]. Reward = [-1.0901529]
Abstract state at timestep 1575 is 3
State prediction error at timestep 1575 is 0.012
Human Feedback received at timestpe 1575 of 10
Current timestep = 1576. State = [[ 0.03400698  1.3656185   0.68283004 -0.4234675  -0.03350449 -0.10870451
   0.          0.        ]]. Action = [[ 0.42888212 -0.6318461 ]]. Reward = [0.7498527]
Abstract state at timestep 1576 is 3
State prediction error at timestep 1576 is 0.012
Human Feedback received at timestpe 1576 of -10
Current timestep = 1577. State = [[ 0.04078054  1.3554933   0.6828459  -0.45014274 -0.03893886 -0.10869702
   0.          0.        ]]. Action = [[-0.4951762   0.23667431]]. Reward = [-0.98855746]
Abstract state at timestep 1577 is 3
State prediction error at timestep 1577 is 0.012
Human Feedback received at timestpe 1577 of -10
Current timestep = 1578. State = [[ 0.04750528  1.345191    0.6782536  -0.45804343 -0.04465768 -0.11438715
   0.          0.        ]]. Action = [[ 0.33916473 -0.09226614]]. Reward = [0.17842878]
Abstract state at timestep 1578 is 3
State prediction error at timestep 1578 is 0.012
Human Feedback received at timestpe 1578 of -10
Current timestep = 1579. State = [[ 0.05423021  1.3342888   0.6782702  -0.4847181  -0.05037538 -0.11436417
   0.          0.        ]]. Action = [[-0.9557016  -0.35315073]]. Reward = [-1.0313895]
Abstract state at timestep 1579 is 3
State prediction error at timestep 1579 is 0.012
Human Feedback received at timestpe 1579 of -10
Current timestep = 1580. State = [[ 0.06112804  1.3233941   0.69482684 -0.48439768 -0.05536826 -0.09986698
   0.          0.        ]]. Action = [[ 0.7092898  -0.42115897]]. Reward = [-1.0313305]
Abstract state at timestep 1580 is 3
State prediction error at timestep 1580 is 0.012
Human Feedback received at timestpe 1580 of -10
Current timestep = 1581. State = [[ 0.06797647  1.3119075   0.68860686 -0.5106562  -0.05910444 -0.07473001
   0.          0.        ]]. Action = [[-0.5857671 -0.5083091]]. Reward = [-0.30330342]
Abstract state at timestep 1581 is 3
State prediction error at timestep 1581 is 0.012
Human Feedback received at timestpe 1581 of -10
Current timestep = 1582. State = [[ 0.074825    1.2998211   0.6886169  -0.5373237  -0.06284028 -0.07472344
   0.          0.        ]]. Action = [[-0.8103445  -0.30794883]]. Reward = [-0.8196872]
Abstract state at timestep 1582 is 3
State prediction error at timestep 1582 is 0.012
Human Feedback received at timestpe 1582 of -10
Current timestep = 1583. State = [[ 0.08174296  1.2876027   0.6953267  -0.54319084 -0.06633996 -0.06999998
   0.          0.        ]]. Action = [[ 0.07348192 -0.17037821]]. Reward = [-0.22310908]
Abstract state at timestep 1583 is 3
State prediction error at timestep 1583 is 0.012
Human Feedback received at timestpe 1583 of -10
Current timestep = 1584. State = [[ 0.088661    1.2747844   0.69533646 -0.569864   -0.06983928 -0.06999291
   0.          0.        ]]. Action = [[-0.71275     0.33803964]]. Reward = [-0.7842243]
Abstract state at timestep 1584 is 3
State prediction error at timestep 1584 is 0.012
Human Feedback received at timestpe 1584 of -10
Current timestep = 1585. State = [[ 0.09553614  1.2617525   0.6913263  -0.57938194 -0.07362539 -0.07572873
   0.          0.        ]]. Action = [[ 0.1754638 -0.2509128]]. Reward = [0.39644378]
Abstract state at timestep 1585 is 3
State prediction error at timestep 1585 is 0.012
Human Feedback received at timestpe 1585 of -10
Current timestep = 1586. State = [[ 0.10235806  1.2481248   0.6846617  -0.60579497 -0.07606928 -0.04888218
   0.          0.        ]]. Action = [[-0.7818829 -0.7419064]]. Reward = [-0.18040653]
Abstract state at timestep 1586 is 3
State prediction error at timestep 1586 is 0.012
Human Feedback received at timestpe 1586 of -10
Current timestep = 1587. State = [[ 0.10918007  1.2338972   0.6846675  -0.6324626  -0.07851349 -0.04888855
   0.          0.        ]]. Action = [[-0.9353018  -0.45124555]]. Reward = [-0.67371917]
Abstract state at timestep 1587 is 3
State prediction error at timestep 1587 is 0.012
Human Feedback received at timestpe 1587 of -10
Current timestep = 1588. State = [[ 0.11604643  1.2190663   0.6902085  -0.6593454  -0.08206908 -0.07111814
   0.          0.        ]]. Action = [[-0.5157137  0.5190139]]. Reward = [-1.2015587]
Abstract state at timestep 1588 is 3
State prediction error at timestep 1588 is 0.012
Human Feedback received at timestpe 1588 of -10
Current timestep = 1589. State = [[ 0.12298355  1.204025    0.69899076 -0.6687963  -0.08730255 -0.10467903
   0.          0.        ]]. Action = [[0.18736649 0.83721507]]. Reward = [-0.58571374]
Abstract state at timestep 1589 is 3
State prediction error at timestep 1589 is 0.012
Human Feedback received at timestpe 1589 of -10
Current timestep = 1590. State = [[ 0.12992087  1.188384    0.6990055  -0.69547117 -0.09253472 -0.10465282
   0.          0.        ]]. Action = [[-0.16549253 -0.3577612 ]]. Reward = [-0.9047217]
Abstract state at timestep 1590 is 3
State prediction error at timestep 1590 is 0.012
Human Feedback received at timestpe 1590 of -10
Current timestep = 1591. State = [[ 0.13700494  1.1727896   0.71484953 -0.69350857 -0.09892572 -0.12783176
   0.          0.        ]]. Action = [[0.5498432 0.6436479]]. Reward = [-0.41356948]
Abstract state at timestep 1591 is 3
State prediction error at timestep 1591 is 0.012
Human Feedback received at timestpe 1591 of -10
Current timestep = 1592. State = [[ 0.14423504  1.1572202   0.73069584 -0.6924858  -0.10656855 -0.15287027
   0.          0.        ]]. Action = [[0.04356158 0.65797806]]. Reward = [-0.5545168]
Abstract state at timestep 1592 is 3
State prediction error at timestep 1592 is 0.012
Human Feedback received at timestpe 1592 of -10
Current timestep = 1593. State = [[ 0.15146533  1.1410518   0.7307165  -0.71916294 -0.11420997 -0.1528422
   0.          0.        ]]. Action = [[-0.399724    0.34108114]]. Reward = [-1.1075978]
Abstract state at timestep 1593 is 3
State prediction error at timestep 1593 is 0.012
Human Feedback received at timestpe 1593 of -10
Current timestep = 1594. State = [[ 0.15869589  1.1242839   0.7307374  -0.74583703 -0.12185045 -0.15282354
   0.          0.        ]]. Action = [[-0.19618863 -0.4053861 ]]. Reward = [-1.0906785]
Abstract state at timestep 1594 is 3
State prediction error at timestep 1594 is 0.012
Human Feedback received at timestpe 1594 of -10
Current timestep = 1595. State = [[ 0.16607705  1.108274    0.74559796 -0.71218127 -0.12930693 -0.14914331
   0.          0.        ]]. Action = [[0.9982048 0.4180622]]. Reward = [1.7400604]
Abstract state at timestep 1595 is 3
State prediction error at timestep 1595 is 0.012
Human Feedback received at timestpe 1595 of -10
Current timestep = 1596. State = [[ 0.1734662   1.0920695   0.7465161  -0.7208722  -0.1368879  -0.15163304
   0.          0.        ]]. Action = [[0.03485346 0.19593084]]. Reward = [-0.09276209]
Abstract state at timestep 1596 is 3
State prediction error at timestep 1596 is 0.012
Human Feedback received at timestpe 1596 of -10
Current timestep = 1597. State = [[ 0.18093853  1.0752492   0.7575053  -0.74854857 -0.14714111 -0.20507066
   0.          0.        ]]. Action = [[-0.20876682  0.9446156 ]]. Reward = [-2.2343924]
Abstract state at timestep 1597 is 3
State prediction error at timestep 1597 is 0.012
Human Feedback received at timestpe 1597 of -10
Current timestep = 1598. State = [[ 0.18846703  1.0578043   0.76401734 -0.77647406 -0.15829583 -0.22309425
   0.          0.        ]]. Action = [[-0.9237529   0.59896684]]. Reward = [-1.9797955]
Abstract state at timestep 1598 is 3
State prediction error at timestep 1598 is 0.012
Human Feedback received at timestpe 1598 of -10
Current timestep = 1599. State = [[ 0.19613838  1.0405977   0.7764179  -0.76575893 -0.16757798 -0.18564317
   0.          0.        ]]. Action = [[ 0.4426521  -0.86301434]]. Reward = [0.26542062]
Abstract state at timestep 1599 is 3
State prediction error at timestep 1599 is 0.012
Human Feedback received at timestpe 1599 of -10
Current timestep = 1600. State = [[ 0.20376225  1.0228031   0.7704381  -0.79179984 -0.17563985 -0.16123733
   0.          0.        ]]. Action = [[-0.31005698 -0.5955762 ]]. Reward = [-0.6484368]
Abstract state at timestep 1600 is 3
State prediction error at timestep 1600 is 0.012
Human Feedback received at timestpe 1600 of -10
Current timestep = 1601. State = [[ 0.2113862   1.0044094   0.7704368  -0.81847185 -0.18370168 -0.16123654
   0.          0.        ]]. Action = [[-0.33056808  0.42639923]]. Reward = [-1.0840995]
Abstract state at timestep 1601 is 3
State prediction error at timestep 1601 is 0.012
Human Feedback received at timestpe 1601 of -10
Current timestep = 1602. State = [[ 0.21901026  0.985862    0.76894224 -0.8251596  -0.19026497 -0.13126639
   0.          0.        ]]. Action = [[ 0.26314592 -0.7459968 ]]. Reward = [0.39753282]
Abstract state at timestep 1602 is 3
State prediction error at timestep 1602 is 0.012
Human Feedback received at timestpe 1602 of -10
Current timestep = 1603. State = [[ 0.22675896  0.9676515   0.7827553  -0.8103858  -0.1982047  -0.15879436
   0.          0.        ]]. Action = [[0.40799952 0.64242697]]. Reward = [0.69962275]
Abstract state at timestep 1603 is 4
State prediction error at timestep 1603 is 0.012
Human Feedback received at timestpe 1603 of 10
Current timestep = 1604. State = [[ 0.23472461  0.9492465   0.8059179  -0.8192844  -0.20763274 -0.18856083
   0.          0.        ]]. Action = [[0.13070428 0.77524257]]. Reward = [-1.786778]
Abstract state at timestep 1604 is 4
State prediction error at timestep 1604 is 0.012
Human Feedback received at timestpe 1604 of 10
Current timestep = 1605. State = [[ 0.24269037  0.9302426   0.8059157  -0.84595835 -0.21706069 -0.18855931
   0.          0.        ]]. Action = [[-0.45062184 -0.45114148]]. Reward = [-1.2134477]
Abstract state at timestep 1605 is 4
State prediction error at timestep 1605 is 0.012
Human Feedback received at timestpe 1605 of -10
Current timestep = 1606. State = [[ 0.2506563   0.91064     0.8059133  -0.8726322  -0.22648859 -0.18855807
   0.          0.        ]]. Action = [[-0.20027089 -0.31402475]]. Reward = [-1.2009627]
Abstract state at timestep 1606 is 4
State prediction error at timestep 1606 is 0.012
Human Feedback received at timestpe 1606 of -10
Current timestep = 1607. State = [[ 0.2585494   0.8904558   0.79677075 -0.89824116 -0.23404256 -0.15107915
   0.          0.        ]]. Action = [[-0.92383885 -0.79141146]]. Reward = [-0.33682245]
Abstract state at timestep 1607 is 4
State prediction error at timestep 1607 is 0.012
Human Feedback received at timestpe 1607 of -10
Current timestep = 1608. State = [[ 0.2666053   0.87088954  0.8149533  -0.8711317  -0.24355936 -0.19033647
   0.          0.        ]]. Action = [[0.86733735 0.8854716 ]]. Reward = [1.1661297]
Abstract state at timestep 1608 is 4
State prediction error at timestep 1608 is 0.012
Human Feedback received at timestpe 1608 of -10
Current timestep = 1609. State = [[ 0.27484703  0.85130596  0.8331353  -0.8718965  -0.25267497 -0.18231238
   0.          0.        ]]. Action = [[ 0.11189973 -0.23511785]]. Reward = [-0.7621111]
Abstract state at timestep 1609 is 4
State prediction error at timestep 1609 is 0.012
Human Feedback received at timestpe 1609 of -10
Current timestep = 1610. State = [[ 0.28331584  0.83161396  0.8573204  -0.87703675 -0.26333955 -0.21329176
   0.          0.        ]]. Action = [[0.65240145 0.8235817 ]]. Reward = [-1.7869837]
Abstract state at timestep 1610 is 4
State prediction error at timestep 1610 is 0.012
Human Feedback received at timestpe 1610 of -10
Current timestep = 1611. State = [[ 0.2917964   0.8122709   0.8568982  -0.8613067  -0.27237514 -0.1807117
   0.          0.        ]]. Action = [[ 0.6048099 -0.8650296]]. Reward = [1.5251265]
Abstract state at timestep 1611 is 4
State prediction error at timestep 1611 is 0.012
Human Feedback received at timestpe 1611 of -10
Current timestep = 1612. State = [[ 0.30032578  0.7923045   0.8630185  -0.8893099  -0.2827269  -0.20703559
   0.          0.        ]]. Action = [[-0.36450076  0.5970483 ]]. Reward = [-1.9017124]
Abstract state at timestep 1612 is 4
State prediction error at timestep 1612 is 0.012
Human Feedback received at timestpe 1612 of -10
Current timestep = 1613. State = [[ 0.30903062  0.77232546  0.88028175 -0.88988954 -0.29280418 -0.201546
   0.          0.        ]]. Action = [[ 0.15011168 -0.29706693]]. Reward = [-0.8840884]
Abstract state at timestep 1613 is 7
State prediction error at timestep 1613 is 0.012
Human Feedback received at timestpe 1613 of -10
Current timestep = 1614. State = [[ 0.31787127  0.7525083   0.8949872  -0.8829972  -0.30408382 -0.22559266
   0.          0.        ]]. Action = [[0.01912045 0.5520439 ]]. Reward = [-0.3542513]
Abstract state at timestep 1614 is 7
State prediction error at timestep 1614 is 0.012
Human Feedback received at timestpe 1614 of -10
Current timestep = 1615. State = [[ 0.3267826   0.7320564   0.9038749  -0.9116929  -0.3172909  -0.26414162
   0.          0.        ]]. Action = [[-0.9157774   0.85993576]]. Reward = [-2.4814525]
Abstract state at timestep 1615 is 7
State prediction error at timestep 1615 is 0.012
Human Feedback received at timestpe 1615 of -10
Current timestep = 1616. State = [[ 0.3356944   0.7110068   0.903868   -0.93837357 -0.33049783 -0.2641384
   0.          0.        ]]. Action = [[-0.08381015 -0.40104926]]. Reward = [-1.6873684]
Abstract state at timestep 1616 is 7
State prediction error at timestep 1616 is 0.012
Human Feedback received at timestpe 1616 of -10
Current timestep = 1617. State = [[ 0.34453383  0.689388    0.8947083  -0.9633385  -0.34176075 -0.22525826
   0.          0.        ]]. Action = [[-0.65064037 -0.8830146 ]]. Reward = [-0.77881676]
Abstract state at timestep 1617 is 7
State prediction error at timestep 1617 is 0.012
Human Feedback received at timestpe 1617 of -10
Current timestep = 1618. State = [[ 0.35377693  0.66806275  0.9358469  -0.9505698  -0.3538773  -0.24233058
   0.          0.        ]]. Action = [[0.49649763 0.5710418 ]]. Reward = [-1.9004003]
Abstract state at timestep 1618 is 7
State prediction error at timestep 1618 is 0.012
Human Feedback received at timestpe 1618 of -10
Current timestep = 1619. State = [[ 0.3633582   0.6472294   0.9693314  -0.928734   -0.36569345 -0.23632231
   0.          0.        ]]. Action = [[0.7301891  0.22307944]]. Reward = [-0.9210935]
Abstract state at timestep 1619 is 7
State prediction error at timestep 1619 is 0.012
Human Feedback received at timestpe 1619 of -10
Current timestep = 1620. State = [[ 0.37293997  0.6257977   0.96932507 -0.9554118  -0.37750944 -0.23632002
   0.          0.        ]]. Action = [[-0.95119804 -0.42681944]]. Reward = [-1.665059]
Abstract state at timestep 1620 is 7
State prediction error at timestep 1620 is 0.012
Human Feedback received at timestpe 1620 of -10
Current timestep = 1621. State = [[ 0.3828972   0.60503966  1.0066717  -0.9255177  -0.3891586  -0.23298319
   0.          0.        ]]. Action = [[0.81857705 0.1658225 ]]. Reward = [-0.8338311]
Abstract state at timestep 1621 is 7
State prediction error at timestep 1621 is 0.012
Human Feedback received at timestpe 1621 of -10
Current timestep = 1622. State = [[ 0.392855    0.58368325  1.0066653  -0.9521949  -0.40080765 -0.23298106
   0.          0.        ]]. Action = [[-0.98478836 -0.08735859]]. Reward = [-1.7397499]
Abstract state at timestep 1622 is 7
State prediction error at timestep 1622 is 0.012
Human Feedback received at timestpe 1622 of -10
Current timestep = 1623. State = [[ 0.40277672  0.56174856  1.0020745  -0.97770923 -0.41144    -0.21264748
   0.          0.        ]]. Action = [[-0.6219067  -0.58889747]]. Reward = [-1.282136]
Abstract state at timestep 1623 is 7
State prediction error at timestep 1623 is 0.012
Human Feedback received at timestpe 1623 of -10
Current timestep = 1624. State = [[ 0.41297483  0.54000777  1.0294796  -0.96910435 -0.4218805  -0.20881002
   0.          0.        ]]. Action = [[ 0.5778228  -0.42924726]]. Reward = [-1.5236701]
Abstract state at timestep 1624 is 7
State prediction error at timestep 1624 is 0.012
Human Feedback received at timestpe 1624 of -10
Current timestep = 1625. State = [[ 0.42364055  0.5186266   1.0769345  -0.95342404 -0.43312272 -0.2248445
   0.          0.        ]]. Action = [[0.9699093 0.5534167]]. Reward = [-2.867952]
Abstract state at timestep 1625 is 7
State prediction error at timestep 1625 is 0.012
Human Feedback received at timestpe 1625 of -10
Current timestep = 1626. State = [[ 0.4343067   0.49664676  1.0769279  -0.9801004  -0.44436485 -0.22484258
   0.          0.        ]]. Action = [[-0.6169579   0.15212524]]. Reward = [-1.9154677]
Abstract state at timestep 1626 is 7
State prediction error at timestep 1626 is 0.012
Human Feedback received at timestpe 1626 of -10
Current timestep = 1627. State = [[ 0.44509012  0.47495908  1.0892198  -0.96740115 -0.45629975 -0.23869817
   0.          0.        ]]. Action = [[0.7104268  0.14616466]]. Reward = [-0.63088065]
Abstract state at timestep 1627 is 8
State prediction error at timestep 1627 is 0.012
Human Feedback received at timestpe 1627 of -10
Current timestep = 1628. State = [[ 0.4562436   0.45372665  1.1248726  -0.94681525 -0.46678913 -0.20978737
   0.          0.        ]]. Action = [[ 0.5525187  -0.61379194]]. Reward = [-1.90409]
Abstract state at timestep 1628 is 8
State prediction error at timestep 1628 is 0.012
Human Feedback received at timestpe 1628 of -10
Current timestep = 1629. State = [[ 0.46758977  0.43217406  1.1452005  -0.9614938  -0.47852236 -0.2346644
   0.          0.        ]]. Action = [[0.30764592 0.6213716 ]]. Reward = [-3.2159863]
Abstract state at timestep 1629 is 8
State prediction error at timestep 1629 is 0.012
Human Feedback received at timestpe 1629 of -10
Current timestep = 1630. State = [[ 0.47898045  0.40998662  1.1507938  -0.9902255  -0.49160865 -0.26172584
   0.          0.        ]]. Action = [[-0.76482594  0.7835026 ]]. Reward = [-2.995454]
Abstract state at timestep 1630 is 8
State prediction error at timestep 1630 is 0.012
Human Feedback received at timestpe 1630 of -10
Current timestep = 1631. State = [[ 0.49031895  0.38724312  1.144075   -1.0145161  -0.5030845  -0.2295163
   0.          0.        ]]. Action = [[-0.7649315 -0.9107446]]. Reward = [-1.6980441]
Abstract state at timestep 1631 is 8
State prediction error at timestep 1631 is 0.012
Human Feedback received at timestpe 1631 of -10
Current timestep = 1632. State = [[ 0.5020382   0.3647398   1.183461   -1.0044376  -0.51612943 -0.26089865
   0.          0.        ]]. Action = [[0.33130503 0.7516041 ]]. Reward = [-3.4164581]
Abstract state at timestep 1632 is 8
State prediction error at timestep 1632 is 0.012
Human Feedback received at timestpe 1632 of -10
Current timestep = 1633. State = [[ 0.51383287  0.34232184  1.1915585  -1.000998   -0.5299136  -0.27568167
   0.          0.        ]]. Action = [[0.75832605 0.3436234 ]]. Reward = [-1.7264256]
Abstract state at timestep 1633 is 8
State prediction error at timestep 1633 is 0.012
Human Feedback received at timestpe 1633 of -10
Current timestep = 1634. State = [[ 0.5256284   0.319306    1.1915464  -1.0276786  -0.54369754 -0.2756781
   0.          0.        ]]. Action = [[-0.12246257  0.07171631]]. Reward = [-2.8661644]
Abstract state at timestep 1634 is 8
State prediction error at timestep 1634 is 0.012
Human Feedback received at timestpe 1634 of -10
Current timestep = 1635. State = [[ 0.5374757   0.29565004  1.1980093  -1.0568064  -0.5590691  -0.30743125
   0.          0.        ]]. Action = [[-0.63983846  0.6208749 ]]. Reward = [-3.7986002]
Abstract state at timestep 1635 is 8
State prediction error at timestep 1635 is 0.012
Human Feedback received at timestpe 1635 of -10
Current timestep = 1636. State = [[ 0.5493623   0.27135795  1.202891   -1.0856823  -0.57571113 -0.3328403
   0.          0.        ]]. Action = [[-0.61810243  0.6185396 ]]. Reward = [-3.8998106]
Abstract state at timestep 1636 is 8
State prediction error at timestep 1636 is 0.012
Human Feedback received at timestpe 1636 of -10
Current timestep = 1637. State = [[ 0.5612502   0.24646898  1.202872   -1.1123685  -0.5923528  -0.33283395
   0.          0.        ]]. Action = [[-0.91637087 -0.02620709]]. Reward = [-3.4884493]
Abstract state at timestep 1637 is 8
State prediction error at timestep 1637 is 0.012
Human Feedback received at timestpe 1637 of -10
Current timestep = 1638. State = [[ 0.5731796   0.2209455   1.2079394  -1.1412252  -0.61029685 -0.3588813
   0.          0.        ]]. Action = [[-0.6230352  0.6351161]]. Reward = [-4.284797]
Abstract state at timestep 1638 is 8
State prediction error at timestep 1638 is 0.012
Human Feedback received at timestpe 1638 of -10
Current timestep = 1639. State = [[ 0.5850789   0.19486421  1.2037933  -1.1657393  -0.62709296 -0.33592182
   0.          0.        ]]. Action = [[-0.06379908 -0.5510592 ]]. Reward = [-3.3296552]
Abstract state at timestep 1639 is 8
State prediction error at timestep 1639 is 0.012
Human Feedback received at timestpe 1639 of -10
Current timestep = 1640. State = [[ 0.59733105  0.16897947  1.2390015  -1.1572032  -0.644009   -0.33832034
   0.          0.        ]]. Action = [[ 0.41534603 -0.4034868 ]]. Reward = [-4.276633]
Abstract state at timestep 1640 is 8
State prediction error at timestep 1640 is 0.012
Human Feedback received at timestpe 1640 of -10
Current timestep = 1641. State = [[ 0.6095846   0.14249784  1.23898    -1.1838894  -0.6609247  -0.33831367
   0.          0.        ]]. Action = [[-0.35887688  0.20208788]]. Reward = [-4.0472336]
Abstract state at timestep 1641 is 8
State prediction error at timestep 1641 is 0.012
Human Feedback received at timestpe 1641 of -10
Current timestep = 1642. State = [[ 0.6220461   0.11565822  1.260704   -1.2005457  -0.6792425  -0.36635658
   0.          0.        ]]. Action = [[0.28760695 0.64597225]]. Reward = [-5.4347553]
Abstract state at timestep 1642 is 8
State prediction error at timestep 1642 is 0.012
Human Feedback received at timestpe 1642 of -10
Current timestep = 1643. State = [[ 0.6350357   0.08933102  1.3134859  -1.1780603  -0.69781476 -0.3714449
   1.          0.        ]]. Action = [[ 0.9829328 -0.1201269]]. Reward = [4.6368704]
Abstract state at timestep 1643 is 8
State prediction error at timestep 1643 is 0.012
Human Feedback received at timestpe 1643 of -10
Current timestep = 1644. State = [[ 0.6422281   0.08833574  0.8311796  -0.15175654 -0.8102594  -2.1440356
   1.          0.        ]]. Action = [[-0.02759123 -0.13925612]]. Reward = [80.003845]
Abstract state at timestep 1644 is 8
State prediction error at timestep 1644 is 0.012
Human Feedback received at timestpe 1644 of -10
Current timestep = 1645. State = [[ 0.6490742   0.09545983  0.77272606  0.22588946 -0.92484814 -2.23503
   1.          0.        ]]. Action = [[-0.80588114  0.35883915]]. Reward = [-8.25166]
Abstract state at timestep 1645 is 8
State prediction error at timestep 1645 is 0.012
Human Feedback received at timestpe 1645 of -10
Current timestep = 1646. State = [[ 0.6564652   0.10152212  0.8006469   0.20493193 -1.0314066  -2.1227007
   1.          0.        ]]. Action = [[0.06107318 0.16215682]]. Reward = [-13.775436]
Abstract state at timestep 1646 is 8
State prediction error at timestep 1646 is 0.012
Human Feedback received at timestpe 1646 of -10
Current timestep = 1647. State = [[ 0.66411245  0.10713659  0.8161289   0.1854206  -1.1391863  -2.1557462
   1.          0.        ]]. Action = [[0.12969875 0.2921095 ]]. Reward = [-12.837342]
Abstract state at timestep 1647 is 8
State prediction error at timestep 1647 is 0.012
Human Feedback received at timestpe 1647 of -10
Current timestep = 1648. State = [[ 0.6727316   0.11297644  0.9034066   0.190687   -1.24921    -2.2006216
   0.          0.        ]]. Action = [[0.95559454 0.8454406 ]]. Reward = [-30.904884]
Abstract state at timestep 1648 is 8
State prediction error at timestep 1648 is 0.012
Human Feedback received at timestpe 1648 of -10
Current timestep = 1649. State = [[ 0.68209916  0.1185073   0.96625125  0.17553958 -1.357396   -2.1638641
   0.          0.        ]]. Action = [[ 0.68833613 -0.63137627]]. Reward = [-17.982817]
Abstract state at timestep 1649 is 8
State prediction error at timestep 1649 is 0.012
Human Feedback received at timestpe 1649 of -10
Current timestep = 1650. State = [[ 0.69156855  0.12346624  0.96491337  0.14847524 -1.4654825  -2.1618733
   0.          0.        ]]. Action = [[-0.88503295  0.27346265]]. Reward = [-11.24753]
Abstract state at timestep 1650 is 8
State prediction error at timestep 1650 is 0.012
Human Feedback received at timestpe 1650 of -10
Current timestep = 1651. State = [[ 0.7016159   0.12809974  1.0109121   0.13398765 -1.5723118  -2.1367276
   0.          0.        ]]. Action = [[ 0.2368083 -0.5202895]]. Reward = [-16.30344]
Abstract state at timestep 1651 is 8
State prediction error at timestep 1651 is 0.012
Human Feedback received at timestpe 1651 of -10
Current timestep = 1652. State = [[ 0.71222055  0.13217741  1.0550985   0.10921041 -1.6791978  -2.1381302
   0.          0.        ]]. Action = [[0.33194745 0.36693192]]. Reward = [-16.10343]
Abstract state at timestep 1652 is 8
State prediction error at timestep 1652 is 0.012
Human Feedback received at timestpe 1652 of -10
Current timestep = 1653. State = [[ 0.72344434  0.13557424  1.1055801   0.07978205 -1.7860322  -2.1379933
   0.          0.        ]]. Action = [[ 0.47941124 -0.20287979]]. Reward = [-16.84293]
Abstract state at timestep 1653 is 8
State prediction error at timestep 1653 is 0.012
Human Feedback received at timestpe 1653 of -10
Current timestep = 1654. State = [[ 0.7347662   0.13833426  1.1041081   0.05314155 -1.8927635  -2.1360488
   0.          0.        ]]. Action = [[-0.04338604 -0.3547197 ]]. Reward = [-11.529936]
Abstract state at timestep 1654 is 8
State prediction error at timestep 1654 is 0.012
Human Feedback received at timestpe 1654 of -10
Current timestep = 1655. State = [[ 0.74618244  0.1404422   1.1026485   0.02660863 -1.9993955  -2.134073
   0.          0.        ]]. Action = [[-0.971041    0.21912348]]. Reward = [-11.582433]
Abstract state at timestep 1655 is 8
State prediction error at timestep 1655 is 0.012
Human Feedback received at timestpe 1655 of -10
Current timestep = 1656. State = [[ 0.7576704   0.14181176  1.098534   -0.00397352 -2.1075792  -2.1651254
   0.          0.        ]]. Action = [[-0.13430703  0.6923729 ]]. Reward = [-11.550665]
Abstract state at timestep 1656 is 8
State prediction error at timestep 1656 is 0.012
Human Feedback received at timestpe 1656 of -10
Current timestep = 1657. State = [[ 0.7692453   0.14249827  1.0970993  -0.03028166 -2.2156608  -2.1630828
   0.          0.        ]]. Action = [[-0.75726867  0.42798185]]. Reward = [-11.856254]
Abstract state at timestep 1657 is 8
State prediction error at timestep 1657 is 0.012
Human Feedback received at timestpe 1657 of -10
Current timestep = 1658. State = [[ 0.7817106   0.14169274  1.1779182  -0.0909851  -2.3219063  -2.1263022
   0.          0.        ]]. Action = [[ 0.97893465 -0.76272404]]. Reward = [-20.54684]
Abstract state at timestep 1658 is 8
State prediction error at timestep 1658 is 0.012
Human Feedback received at timestpe 1658 of -10
Current timestep = 1659. State = [[ 0.7942726   0.14023319  1.1802505  -0.11428545 -2.4267933  -2.0990722
   0.          0.        ]]. Action = [[-0.42793494 -0.56486595]]. Reward = [-12.150909]
Abstract state at timestep 1659 is 8
State prediction error at timestep 1659 is 0.012
Human Feedback received at timestpe 1659 of -10
Current timestep = 1660. State = [[ 0.80712336  0.1375896   1.2019501  -0.16124023 -2.5314293  -2.0940545
   0.          0.        ]]. Action = [[0.6310017  0.14395344]]. Reward = [-14.623824]
Abstract state at timestep 1660 is 8
State prediction error at timestep 1660 is 0.012
Human Feedback received at timestpe 1660 of -10
Current timestep = 1661. State = [[ 0.8203451   0.13334543  1.23158    -0.22677003 -2.637315   -2.1190715
   0.          0.        ]]. Action = [[0.2555294 0.6298704]]. Reward = [-15.98698]
Abstract state at timestep 1661 is 8
State prediction error at timestep 1661 is 0.012
Human Feedback received at timestpe 1661 of -10
Current timestep = 1662. State = [[ 0.83361185  0.12837046  1.2306392  -0.25264227 -2.7431064  -2.1171794
   0.          0.        ]]. Action = [[-0.05963051  0.31716478]]. Reward = [-12.21383]
Abstract state at timestep 1662 is 8
State prediction error at timestep 1662 is 0.012
Human Feedback received at timestpe 1662 of -10
Current timestep = 1663. State = [[ 0.84697187  0.12271486  1.2366494  -0.27570432 -2.8476117  -2.0913353
   0.          0.        ]]. Action = [[-0.2472158  -0.93713677]]. Reward = [-12.786966]
Abstract state at timestep 1663 is 8
State prediction error at timestep 1663 is 0.012
Human Feedback received at timestpe 1663 of -10
Current timestep = 1664. State = [[ 0.86057645  0.11543213  1.2596014  -0.3407381  -2.9503376  -2.0557098
   0.          0.        ]]. Action = [[ 0.61299944 -0.8188109 ]]. Reward = [-15.572366]
Abstract state at timestep 1664 is 8
State prediction error at timestep 1664 is 0.012
Human Feedback received at timestpe 1664 of -10
Current timestep = 1665. State = [[ 0.87415063  0.10740446  1.2533593  -0.36694354 -3.0541787  -2.0780396
   0.          0.        ]]. Action = [[-0.90547425  0.6372268 ]]. Reward = [-11.756798]
Abstract state at timestep 1665 is 8
State prediction error at timestep 1665 is 0.012
Human Feedback received at timestpe 1665 of -10
Current timestep = 1666. State = [[ 0.88780993  0.09784885  1.2608025  -0.42761716 -3.1580942  -2.0795262
   0.          0.        ]]. Action = [[ 0.37034535 -0.32694376]]. Reward = [-14.380779]
Abstract state at timestep 1666 is 8
State prediction error at timestep 1666 is 0.012
Human Feedback received at timestpe 1666 of -10
Current timestep = 1667. State = [[ 0.9015236   0.08754802  1.2678492  -0.45355538 -3.2605107  -2.049509
   0.          0.        ]]. Action = [[-0.21024954 -0.84256804]]. Reward = [-13.043708]
Abstract state at timestep 1667 is 8
State prediction error at timestep 1667 is 0.012
Human Feedback received at timestpe 1667 of -10
Current timestep = 1668. State = [[ 0.9152252  0.0765097  1.2679329 -0.4793149 -3.362854  -2.048032
   0.         0.       ]]. Action = [[-0.36633396  0.2324779 ]]. Reward = [-12.396836]
Abstract state at timestep 1668 is 8
State prediction error at timestep 1668 is 0.012
Human Feedback received at timestpe 1668 of -10
Current timestep = 1669. State = [[ 0.9287016  0.063981   1.2465489 -0.538412  -3.4663444 -2.071006
   0.         0.       ]]. Action = [[0.6166469 0.645414 ]]. Reward = [-12.094375]
Abstract state at timestep 1669 is 8
State prediction error at timestep 1669 is 0.012
Human Feedback received at timestpe 1669 of -10
Current timestep = 1670. State = [[ 0.94194204  0.05010661  1.2254103  -0.5910841  -3.5708575  -2.0914905
   0.          0.        ]]. Action = [[0.45847487 0.5581217 ]]. Reward = [-12.190229]
Abstract state at timestep 1670 is 8
State prediction error at timestep 1670 is 0.012
Human Feedback received at timestpe 1670 of -10
Current timestep = 1671. State = [[ 0.9550959   0.03552362  1.2202842  -0.615459   -3.6765392  -2.1148899
   0.          0.        ]]. Action = [[-0.6220392  0.7376232]]. Reward = [-12.457211]
Abstract state at timestep 1671 is 8
State prediction error at timestep 1671 is 0.012
Human Feedback received at timestpe 1671 of -10
Current timestep = 1672. State = [[ 0.9681988   0.02021471  1.2209504  -0.6412652  -3.7821393  -2.1132665
   0.          0.        ]]. Action = [[-0.00123465  0.20283544]]. Reward = [-13.065707]
Abstract state at timestep 1672 is 8
State prediction error at timestep 1672 is 0.012
Human Feedback received at timestpe 1672 of -10
Current timestep = 1673. State = [[ 0.98121583  0.00422281  1.2183998  -0.66514605 -3.888642   -2.131328
   0.          0.        ]]. Action = [[-0.20593023  0.5365491 ]]. Reward = [-12.850454]
Abstract state at timestep 1673 is 8
State prediction error at timestep 1673 is 0.012
Human Feedback received at timestpe 1673 of -10
Current timestep = 1674. State = [[ 0.9938637  -0.01277939  1.1895263  -0.70463586 -3.9946766  -2.1219707
   0.          0.        ]]. Action = [[0.65665317 0.47711468]]. Reward = [-11.567051]
Abstract state at timestep 1674 is 8
State prediction error at timestep 1674 is 0.012
Human Feedback received at timestpe 1674 of -10
Current timestep = 1675. State = [[ 0.00252256  1.3986875   0.25548956 -0.54366875 -0.0029162  -0.0578722
   0.          0.        ]]. Action = [[ 0.9251698  -0.13291478]]. Reward = [-100.]
Abstract state at timestep 1675 is 8
State prediction error at timestep 1675 is 0.012
Human Feedback received at timestpe 1675 of -10
Current timestep = 1676. State = [[ 0.00515003  1.3872358   0.2651375  -0.50896704 -0.00528382 -0.0473561
   0.          0.        ]]. Action = [[0.7623285  0.00314605]]. Reward = [3.3255558]
Abstract state at timestep 1676 is 3
State prediction error at timestep 1676 is 0.012
Human Feedback received at timestpe 1676 of -10
Current timestep = 1677. State = [[ 0.0077774   1.3751831   0.26514477 -0.5356876  -0.00764993 -0.04732693
   0.          0.        ]]. Action = [[-0.34851843  0.18038046]]. Reward = [-1.4154555]
Abstract state at timestep 1677 is 3
State prediction error at timestep 1677 is 0.012
Human Feedback received at timestpe 1677 of -10
Current timestep = 1678. State = [[ 0.01049423  1.3631227   0.27538264 -0.5360464  -0.01131386 -0.07328592
   0.          0.        ]]. Action = [[0.89628327 0.6974499 ]]. Reward = [0.03940097]
Abstract state at timestep 1678 is 3
State prediction error at timestep 1678 is 0.012
Human Feedback received at timestpe 1678 of -10
Current timestep = 1679. State = [[ 0.01321116  1.3504622   0.27539366 -0.5627202  -0.01497671 -0.07326342
   0.          0.        ]]. Action = [[-0.2982546  0.0684495]]. Reward = [-1.4876064]
Abstract state at timestep 1679 is 3
State prediction error at timestep 1679 is 0.012
Human Feedback received at timestpe 1679 of -10
Current timestep = 1680. State = [[ 0.0158803   1.3372078   0.2694077  -0.58911204 -0.01743535 -0.04917751
   0.          0.        ]]. Action = [[-0.6563805 -0.5295813]]. Reward = [-1.0689267]
Abstract state at timestep 1680 is 3
State prediction error at timestep 1680 is 0.012
Human Feedback received at timestpe 1680 of -10
Current timestep = 1681. State = [[ 0.01854954  1.3233534   0.26941434 -0.6157808  -0.01989414 -0.04918049
   0.          0.        ]]. Action = [[-0.0681051  -0.08991122]]. Reward = [-1.2987316]
Abstract state at timestep 1681 is 3
State prediction error at timestep 1681 is 0.012
Human Feedback received at timestpe 1681 of -10
Current timestep = 1682. State = [[ 0.02121887  1.3088989   0.26942134 -0.64244956 -0.02235227 -0.04916706
   0.          0.        ]]. Action = [[-0.4095739  -0.20584965]]. Reward = [-1.256305]
Abstract state at timestep 1682 is 3
State prediction error at timestep 1682 is 0.012
Human Feedback received at timestpe 1682 of -10
Current timestep = 1683. State = [[ 0.023944    1.2938477   0.27641186 -0.6690088  -0.02620878 -0.07713737
   0.          0.        ]]. Action = [[-0.13733476  0.6408386 ]]. Reward = [-1.6253275]
Abstract state at timestep 1683 is 3
State prediction error at timestep 1683 is 0.012
Human Feedback received at timestpe 1683 of 10
Current timestep = 1684. State = [[ 0.02662125  1.2781935   0.27040154 -0.6957958  -0.02885849 -0.05299902
   0.          0.        ]]. Action = [[-0.30723548 -0.62543476]]. Reward = [-0.9867683]
Abstract state at timestep 1684 is 3
State prediction error at timestep 1684 is 0.012
Human Feedback received at timestpe 1684 of 10
Current timestep = 1685. State = [[ 0.02916031  1.262884    0.25732714 -0.68049026 -0.03225002 -0.0678369
   0.          0.        ]]. Action = [[0.97155476 0.15673113]]. Reward = [2.7872918]
Abstract state at timestep 1685 is 3
State prediction error at timestep 1685 is 0.012
Human Feedback received at timestpe 1685 of 10
Current timestep = 1686. State = [[ 0.03158169  1.2474552   0.24406171 -0.6857693  -0.03415094 -0.0380215
   0.          0.        ]]. Action = [[ 0.5418298 -0.8067755]]. Reward = [1.052421]
Abstract state at timestep 1686 is 3
State prediction error at timestep 1686 is 0.012
Human Feedback received at timestpe 1686 of 10
Current timestep = 1687. State = [[ 0.03400307  1.2314264   0.24406672 -0.712438   -0.03605236 -0.03803218
   0.          0.        ]]. Action = [[-0.33301437 -0.43133378]]. Reward = [-1.1121844]
Abstract state at timestep 1687 is 3
State prediction error at timestep 1687 is 0.012
Human Feedback received at timestpe 1687 of 10
Current timestep = 1688. State = [[ 0.03646488  1.215927    0.24595058 -0.68885237 -0.03582403  0.00456682
   0.          0.        ]]. Action = [[ 0.97436047 -0.9903785 ]]. Reward = [3.4033058]
Abstract state at timestep 1688 is 3
State prediction error at timestep 1688 is 0.012
Human Feedback received at timestpe 1688 of 10
Current timestep = 1689. State = [[ 0.03903685  1.200326    0.25492793 -0.69333076 -0.03358182  0.0448485
   0.          0.        ]]. Action = [[ 0.8823482  -0.84396744]]. Reward = [0.74095976]
Abstract state at timestep 1689 is 3
State prediction error at timestep 1689 is 0.012
Human Feedback received at timestpe 1689 of 10
Current timestep = 1690. State = [[ 0.0415637   1.1851858   0.25073582 -0.67285365 -0.03166407  0.03835864
   0.          0.        ]]. Action = [[0.34975708 0.17171502]]. Reward = [3.5598366]
Abstract state at timestep 1690 is 3
State prediction error at timestep 1690 is 0.012
Human Feedback received at timestpe 1690 of 10
Current timestep = 1691. State = [[ 0.04410286  1.1700152   0.25055522 -0.67417973 -0.0283384   0.06651972
   0.          0.        ]]. Action = [[ 0.85257196 -0.6419293 ]]. Reward = [1.4242678]
Abstract state at timestep 1691 is 3
State prediction error at timestep 1691 is 0.012
Human Feedback received at timestpe 1691 of 10
Current timestep = 1692. State = [[ 0.04669523  1.1549011   0.25568703 -0.6716721  -0.02482191  0.07033582
   0.          0.        ]]. Action = [[ 0.8368819  -0.07474875]]. Reward = [1.630284]
Abstract state at timestep 1692 is 3
State prediction error at timestep 1692 is 0.012
Human Feedback received at timestpe 1692 of 10
Current timestep = 1693. State = [[ 0.04951744  1.1404868   0.2803346  -0.6406084  -0.02296398  0.0371618
   0.          0.        ]]. Action = [[0.8865477 0.9522784]]. Reward = [3.2457182]
Abstract state at timestep 1693 is 3
State prediction error at timestep 1693 is 0.012
Human Feedback received at timestpe 1693 of 10
Current timestep = 1694. State = [[ 0.05236359  1.1264594   0.2838451  -0.623431   -0.02219968  0.01528708
   0.          0.        ]]. Action = [[0.26264822 0.51517606]]. Reward = [2.685594]
Abstract state at timestep 1694 is 3
State prediction error at timestep 1694 is 0.012
Human Feedback received at timestpe 1694 of 10
Current timestep = 1695. State = [[ 0.0552578   1.1129024   0.2884982  -0.6025169  -0.02128457  0.01830378
   0.          0.        ]]. Action = [[0.3883438  0.37349308]]. Reward = [2.921645]
Abstract state at timestep 1695 is 3
State prediction error at timestep 1695 is 0.012
Human Feedback received at timestpe 1695 of 10
Current timestep = 1696. State = [[ 0.05815201  1.0987453   0.288495   -0.62919056 -0.02036997  0.0182935
   0.          0.        ]]. Action = [[-0.3699075  -0.11120987]]. Reward = [-0.9247702]
Abstract state at timestep 1696 is 3
State prediction error at timestep 1696 is 0.012
Human Feedback received at timestpe 1696 of 10
Current timestep = 1697. State = [[ 0.06099033  1.0845815   0.281086   -0.62947255 -0.0176472   0.05446048
   0.          0.        ]]. Action = [[ 0.15021706 -0.90853995]]. Reward = [1.7510761]
Abstract state at timestep 1697 is 3
State prediction error at timestep 1697 is 0.012
Human Feedback received at timestpe 1697 of 10
Current timestep = 1698. State = [[ 0.06382875  1.0698175   0.28107765 -0.65614635 -0.01492555  0.05443773
   0.          0.        ]]. Action = [[-0.80587244 -0.4895262 ]]. Reward = [-0.71388113]
Abstract state at timestep 1698 is 3
State prediction error at timestep 1698 is 0.012
Human Feedback received at timestpe 1698 of 10
Current timestep = 1699. State = [[ 0.0665122   1.055392    0.26636198 -0.6411197  -0.01296421  0.03923049
   0.          0.        ]]. Action = [[0.92721224 0.23734021]]. Reward = [3.2870252]
Abstract state at timestep 1699 is 3
State prediction error at timestep 1699 is 0.012
Human Feedback received at timestpe 1699 of 10
Current timestep = 1700. State = [[ 0.06925698  1.0403446   0.2740589  -0.6687654  -0.01254915  0.00830088
   0.          0.        ]]. Action = [[-0.6187504  0.9743608]]. Reward = [-1.353037]
Abstract state at timestep 1700 is 3
State prediction error at timestep 1700 is 0.012
Human Feedback received at timestpe 1700 of 10
Current timestep = 1701. State = [[ 0.07183714  1.0252613   0.25573605 -0.6703527  -0.01029411  0.0451008
   0.          0.        ]]. Action = [[ 0.6816654 -0.9838493]]. Reward = [1.957416]
Abstract state at timestep 1701 is 3
State prediction error at timestep 1701 is 0.012
Human Feedback received at timestpe 1701 of 10
Current timestep = 1702. State = [[ 0.0744174   1.009578    0.25573608 -0.6970198  -0.00803908  0.04510076
   0.          0.        ]]. Action = [[-0.6701927   0.27294326]]. Reward = [-0.72635365]
Abstract state at timestep 1702 is 3
State prediction error at timestep 1702 is 0.012
Human Feedback received at timestpe 1702 of 10
Current timestep = 1703. State = [[ 0.07704411  0.99329585  0.26156563 -0.7236466  -0.00695134  0.02175486
   0.          0.        ]]. Action = [[-0.3178023   0.50647426]]. Reward = [-1.0040672]
Abstract state at timestep 1703 is 3
State prediction error at timestep 1703 is 0.012
Human Feedback received at timestpe 1703 of 10
Current timestep = 1704. State = [[ 0.07966499  0.9772531   0.2610355  -0.7130108  -0.0059079   0.02086881
   0.          0.        ]]. Action = [[0.3594215  0.07587373]]. Reward = [2.4965043]
Abstract state at timestep 1704 is 4
State prediction error at timestep 1704 is 0.012
Human Feedback received at timestpe 1704 of 10
Current timestep = 1705. State = [[ 0.08224507  0.9606053   0.25589654 -0.73988426 -0.00383581  0.04144204
   0.          0.        ]]. Action = [[-0.7646017 -0.568202 ]]. Reward = [-0.53183776]
Abstract state at timestep 1705 is 4
State prediction error at timestep 1705 is 0.012
Human Feedback received at timestpe 1705 of 10
Current timestep = 1706. State = [[ 0.08482504  0.94335794  0.25589657 -0.76655126 -0.00176372  0.04144191
   0.          0.        ]]. Action = [[-0.17144752  0.35797048]]. Reward = [-0.6221375]
Abstract state at timestep 1706 is 4
State prediction error at timestep 1706 is 0.012
Human Feedback received at timestpe 1706 of 10
Current timestep = 1707. State = [[ 0.08748303  0.925512    0.2656855  -0.7931522  -0.00165196  0.00223522
   0.          0.        ]]. Action = [[-0.82302797  0.87571764]]. Reward = [-1.0956725]
Abstract state at timestep 1707 is 4
State prediction error at timestep 1707 is 0.012
Human Feedback received at timestpe 1707 of 10
Current timestep = 1708. State = [[ 0.09024601  0.9076478   0.2757001  -0.7939666  -0.00105707  0.01189761
   0.          0.        ]]. Action = [[0.2747444 0.3136537]]. Reward = [1.2193062]
Abstract state at timestep 1708 is 4
State prediction error at timestep 1708 is 0.012
Human Feedback received at timestpe 1708 of 10
Current timestep = 1709. State = [[ 9.3008995e-02  8.8918364e-01  2.7570009e-01 -8.2063323e-01
  -4.6217960e-04  1.1897581e-02  0.0000000e+00  0.0000000e+00]]. Action = [[-0.70210433 -0.13461995]]. Reward = [-0.6551906]
Abstract state at timestep 1709 is 4
State prediction error at timestep 1709 is 0.012
Human Feedback received at timestpe 1709 of 10
Current timestep = 1710. State = [[ 9.5757008e-02  8.7065494e-01  2.7426544e-01 -8.2349664e-01
   6.2479703e-05  1.0493020e-02  0.0000000e+00  0.0000000e+00]]. Action = [[0.2528293  0.15479517]]. Reward = [1.4389963]
Abstract state at timestep 1710 is 4
State prediction error at timestep 1710 is 0.012
Human Feedback received at timestpe 1710 of 10
Current timestep = 1711. State = [[ 9.8504923e-02  8.5152626e-01  2.7426541e-01 -8.5016328e-01
   5.8712537e-04  1.0493024e-02  0.0000000e+00  0.0000000e+00]]. Action = [[-0.36037385  0.35942578]]. Reward = [-0.7164703]
Abstract state at timestep 1711 is 4
State prediction error at timestep 1711 is 0.012
Human Feedback received at timestpe 1711 of 10
Current timestep = 1712. State = [[ 0.10128231  0.83230907  0.2770659  -0.8540954   0.00124883  0.01323423
   0.          0.        ]]. Action = [[0.34275055 0.47897637]]. Reward = [1.1476979]
Abstract state at timestep 1712 is 4
State prediction error at timestep 1712 is 0.012
Human Feedback received at timestpe 1712 of 10
Current timestep = 1713. State = [[ 0.10417299  0.81286854  0.289336   -0.8640217   0.00098936 -0.0051894
   0.          0.        ]]. Action = [[0.22636056 0.5365486 ]]. Reward = [0.39225343]
Abstract state at timestep 1713 is 4
State prediction error at timestep 1713 is 0.012
Human Feedback received at timestpe 1713 of 10
Current timestep = 1714. State = [[ 1.0727396e-01  7.9400468e-01  3.1110173e-01 -8.3839303e-01
  -3.6505974e-06 -1.9860389e-02  0.0000000e+00  0.0000000e+00]]. Action = [[0.72103524 0.58342314]]. Reward = [3.3454766]
Abstract state at timestep 1714 is 4
State prediction error at timestep 1714 is 0.012
Human Feedback received at timestpe 1714 of 10
Current timestep = 1715. State = [[ 0.11033411  0.775687    0.3072193  -0.81411755 -0.00118468 -0.02362073
   0.          0.        ]]. Action = [[0.6235597  0.21490633]]. Reward = [3.8203976]
Abstract state at timestep 1715 is 4
State prediction error at timestep 1715 is 0.012
Human Feedback received at timestpe 1715 of 10
Current timestep = 1716. State = [[ 0.11339436  0.75676936  0.3072193  -0.8407843  -0.00236572 -0.02362075
   0.          0.        ]]. Action = [[-0.5137458  -0.28781474]]. Reward = [-0.7902973]
Abstract state at timestep 1716 is 4
State prediction error at timestep 1716 is 0.012
Human Feedback received at timestpe 1716 of 10
Current timestep = 1717. State = [[ 0.1163846   0.73805124  0.3021849  -0.83191925 -0.00547422 -0.06217007
   0.          0.        ]]. Action = [[0.94689083 0.82392335]]. Reward = [2.1823192]
Abstract state at timestep 1717 is 4
State prediction error at timestep 1717 is 0.012
Human Feedback received at timestpe 1717 of 10
Current timestep = 1718. State = [[ 0.11937495  0.7187335   0.30218488 -0.8585866  -0.00858271 -0.06217001
   0.          0.        ]]. Action = [[-0.39356756  0.34786415]]. Reward = [-0.9627296]
Abstract state at timestep 1718 is 4
State prediction error at timestep 1718 is 0.012
Human Feedback received at timestpe 1718 of 10
Current timestep = 1719. State = [[ 0.12239466  0.6992859   0.30680066 -0.8643657  -0.01335163 -0.09537823
   0.          0.        ]]. Action = [[0.2669158  0.81637096]]. Reward = [0.4762022]
Abstract state at timestep 1719 is 4
State prediction error at timestep 1719 is 0.012
Human Feedback received at timestpe 1719 of 10
Current timestep = 1720. State = [[ 0.12541428  0.67923874  0.3068006  -0.8910342  -0.01812053 -0.09537805
   0.          0.        ]]. Action = [[-0.12709218 -0.09257501]]. Reward = [-1.0746943]
Abstract state at timestep 1720 is 4
State prediction error at timestep 1720 is 0.012
Human Feedback received at timestpe 1720 of 10
Current timestep = 1721. State = [[ 0.12843399  0.65859205  0.30680054 -0.91770273 -0.02288941 -0.09537789
   0.          0.        ]]. Action = [[-0.50363845  0.23814678]]. Reward = [-1.0301892]
Abstract state at timestep 1721 is 4
State prediction error at timestep 1721 is 0.012
Human Feedback received at timestpe 1721 of 10
Current timestep = 1722. State = [[ 0.1314536   0.6373454   0.3068005  -0.9443712  -0.02765829 -0.09537781
   0.          0.        ]]. Action = [[-0.6593549   0.03632402]]. Reward = [-0.9859483]
Abstract state at timestep 1722 is 4
State prediction error at timestep 1722 is 0.012
Human Feedback received at timestpe 1722 of 10
Current timestep = 1723. State = [[ 0.13436289  0.61637264  0.29634726 -0.9322355  -0.03301212 -0.10707661
   0.          0.        ]]. Action = [[ 0.5747516 -0.3307966]]. Reward = [2.694912]
Abstract state at timestep 1723 is 4
State prediction error at timestep 1723 is 0.012
Human Feedback received at timestpe 1723 of 10
Current timestep = 1724. State = [[ 0.13734683  0.5947901   0.30573133 -0.95940346 -0.04025048 -0.14476727
   0.          0.        ]]. Action = [[-0.4328059  0.8309163]]. Reward = [-1.5816519]
Abstract state at timestep 1724 is 4
State prediction error at timestep 1724 is 0.012
Human Feedback received at timestpe 1724 of 10
Current timestep = 1725. State = [[ 0.14041033  0.5726044   0.31569046 -0.9863051  -0.04948522 -0.18469474
   0.          0.        ]]. Action = [[-0.45367414  0.8063748 ]]. Reward = [-1.7259396]
Abstract state at timestep 1725 is 4
State prediction error at timestep 1725 is 0.012
Human Feedback received at timestpe 1725 of 10
Current timestep = 1726. State = [[ 0.1435171   0.5498114   0.32112405 -1.0133969  -0.05981467 -0.20658883
   0.          0.        ]]. Action = [[-0.96525866  0.55716705]]. Reward = [-1.6625295]
Abstract state at timestep 1726 is 4
State prediction error at timestep 1726 is 0.012
Human Feedback received at timestpe 1726 of 10
Current timestep = 1727. State = [[ 0.1465743   0.5264257   0.3149065  -1.0397553  -0.06889407 -0.18158829
   0.          0.        ]]. Action = [[-0.77661794 -0.71435916]]. Reward = [-1.0847892]
Abstract state at timestep 1727 is 4
State prediction error at timestep 1727 is 0.012
Human Feedback received at timestpe 1727 of 10
Current timestep = 1728. State = [[ 0.14963455  0.5031082   0.31408733 -1.0367306  -0.07687605 -0.15963969
   0.          0.        ]]. Action = [[ 0.5222833  -0.53299206]]. Reward = [1.4268441]
Abstract state at timestep 1728 is 4
State prediction error at timestep 1728 is 0.012
Human Feedback received at timestpe 1728 of 10
Current timestep = 1729. State = [[ 0.15269509  0.4800291   0.3158994  -1.0262705  -0.08662061 -0.19489147
   0.          0.        ]]. Action = [[0.16656876 0.85693955]]. Reward = [1.888248]
Abstract state at timestep 1729 is 4
State prediction error at timestep 1729 is 0.012
Human Feedback received at timestpe 1729 of 10
Current timestep = 1730. State = [[ 0.15575571  0.45635128  0.31589842 -1.052945   -0.09636513 -0.19489017
   0.          0.        ]]. Action = [[-0.6917725  0.4367628]]. Reward = [-1.3736047]
Abstract state at timestep 1730 is 5
State prediction error at timestep 1730 is 0.012
Human Feedback received at timestpe 1730 of 10
Current timestep = 1731. State = [[ 0.15885592  0.4326334   0.31871417 -1.0547084  -0.10498257 -0.17234871
   0.          0.        ]]. Action = [[ 0.18133569 -0.52012765]]. Reward = [0.8277524]
Abstract state at timestep 1731 is 5
State prediction error at timestep 1731 is 0.012
Human Feedback received at timestpe 1731 of 10
Current timestep = 1732. State = [[ 0.16195612  0.40831655  0.31871322 -1.0813812  -0.11360005 -0.17234984
   0.          0.        ]]. Action = [[-0.5696667   0.33799553]]. Reward = [-1.2563199]
Abstract state at timestep 1732 is 5
State prediction error at timestep 1732 is 0.012
Human Feedback received at timestpe 1732 of 10
Current timestep = 1733. State = [[ 0.16506138  0.3842603   0.32050326 -1.0699555  -0.12351837 -0.198367
   0.          0.        ]]. Action = [[0.10971808 0.5667535 ]]. Reward = [1.9741049]
Abstract state at timestep 1733 is 5
State prediction error at timestep 1733 is 0.012
Human Feedback received at timestpe 1733 of 10
Current timestep = 1734. State = [[ 0.16827393  0.3604656   0.3298363  -1.0582749  -0.13205025 -0.17063741
   0.          0.        ]]. Action = [[ 0.9219134  -0.58055925]]. Reward = [1.7257684]
Abstract state at timestep 1734 is 5
State prediction error at timestep 1734 is 0.012
Human Feedback received at timestpe 1734 of 10
Current timestep = 1735. State = [[ 0.17148666  0.3360718   0.32983515 -1.0849477  -0.14058197 -0.17063467
   0.          0.        ]]. Action = [[-0.32711118  0.3958149 ]]. Reward = [-1.3510969]
Abstract state at timestep 1735 is 5
State prediction error at timestep 1735 is 0.012
Human Feedback received at timestpe 1735 of 10
Current timestep = 1736. State = [[ 0.1746995   0.31107897  0.32983392 -1.1116204  -0.14911366 -0.17063369
   0.          0.        ]]. Action = [[-0.31242907  0.28397202]]. Reward = [-1.3558564]
Abstract state at timestep 1736 is 5
State prediction error at timestep 1736 is 0.012
Human Feedback received at timestpe 1736 of 10
Current timestep = 1737. State = [[ 0.17791232  0.28548712  0.3298326  -1.1382929  -0.1576453  -0.1706328
   0.          0.        ]]. Action = [[-0.75219923 -0.32739675]]. Reward = [-1.3735114]
Abstract state at timestep 1737 is 5
State prediction error at timestep 1737 is 0.012
Human Feedback received at timestpe 1737 of 10
Current timestep = 1738. State = [[ 0.18129234  0.26031175  0.34839028 -1.120041   -0.16803451 -0.20778409
   0.          0.        ]]. Action = [[0.6472602  0.91978383]]. Reward = [1.8171573]
Abstract state at timestep 1738 is 5
State prediction error at timestep 1738 is 0.012
Human Feedback received at timestpe 1738 of 10
Current timestep = 1739. State = [[ 0.18471995  0.23549345  0.35340664 -1.1042767  -0.17869985 -0.21330719
   0.          0.        ]]. Action = [[0.64125204 0.41242588]]. Reward = [1.8321177]
Abstract state at timestep 1739 is 5
State prediction error at timestep 1739 is 0.012
Human Feedback received at timestpe 1739 of 10
Current timestep = 1740. State = [[ 0.18806724  0.21009336  0.34332266 -1.1299485  -0.18731095 -0.17222157
   0.          0.        ]]. Action = [[-0.21396846 -0.93312556]]. Reward = [-1.307194]
Abstract state at timestep 1740 is 5
State prediction error at timestep 1740 is 0.012
Human Feedback received at timestpe 1740 of 10
Current timestep = 1741. State = [[ 0.19141082  0.18512422  0.34352028 -1.1109222  -0.19653161 -0.18441348
   0.          0.        ]]. Action = [[0.9150801  0.21802056]]. Reward = [2.1724696]
Abstract state at timestep 1741 is 5
State prediction error at timestep 1741 is 0.012
Human Feedback received at timestpe 1741 of 10
Current timestep = 1742. State = [[ 0.19478531  0.15985365  0.34663913 -1.1243827  -0.2057914  -0.18519586
   0.          0.        ]]. Action = [[ 0.00183642 -0.03199512]]. Reward = [-1.0237678]
Abstract state at timestep 1742 is 5
State prediction error at timestep 1742 is 0.012
Human Feedback received at timestpe 1742 of 10
Current timestep = 1743. State = [[ 0.19821616  0.13396269  0.3537149  -1.1522307  -0.21652943 -0.2147604
   0.          0.        ]]. Action = [[-0.38447696  0.65077376]]. Reward = [-2.6889246]
Abstract state at timestep 1743 is 5
State prediction error at timestep 1743 is 0.012
Human Feedback received at timestpe 1743 of 10
Current timestep = 1744. State = [[ 0.20178357  0.10791157  0.3670347  -1.1593696  -0.22694129 -0.20823725
   0.          0.        ]]. Action = [[0.15648103 0.28887582]]. Reward = [-1.2513175]
Abstract state at timestep 1744 is 5
State prediction error at timestep 1744 is 0.012
Human Feedback received at timestpe 1744 of 10
Current timestep = 1745. State = [[ 0.20561019  0.08203662  0.39404574 -1.1517947  -0.23849526 -0.23107903
   0.          0.        ]]. Action = [[0.24487507 0.6373844 ]]. Reward = [-0.7411836]
Abstract state at timestep 1745 is 5
State prediction error at timestep 1745 is 0.012
Human Feedback received at timestpe 1745 of 10
Current timestep = 1746. State = [[ 0.20957461  0.05614887  0.40921837 -1.1526948  -0.25149587 -0.26001203
   0.          0.        ]]. Action = [[0.24118519 0.7074207 ]]. Reward = [-1.6512401]
Abstract state at timestep 1746 is 5
State prediction error at timestep 1746 is 0.012
Human Feedback received at timestpe 1746 of 10
Current timestep = 1747. State = [[ 0.21347514  0.02969278  0.4011076  -1.1777599  -0.2627721  -0.22552495
   0.          0.        ]]. Action = [[-0.03920794 -0.96167463]]. Reward = [-3.1139634]
Abstract state at timestep 1747 is 5
State prediction error at timestep 1747 is 0.012
Human Feedback received at timestpe 1747 of 10
Current timestep = 1748. State = [[ 0.21762963  0.00392043  0.42636243 -1.1474361  -0.27394187 -0.22339594
   0.          0.        ]]. Action = [[0.9080486  0.45824564]]. Reward = [0.39329925]
Abstract state at timestep 1748 is 5
State prediction error at timestep 1748 is 0.012
Human Feedback received at timestpe 1748 of 10
Current timestep = 1749. State = [[ 0.2217845  -0.02245037  0.42635822 -1.1741129  -0.28511158 -0.22339413
   0.          0.        ]]. Action = [[-0.8772119   0.30074644]]. Reward = [-4.1462073]
Abstract state at timestep 1749 is 5
State prediction error at timestep 1749 is 0.012
Human Feedback received at timestpe 1749 of 10
Current timestep = 1750. State = [[ 0.22588196 -0.04939566  0.41909426 -1.1994246  -0.294741   -0.19258867
   1.          1.        ]]. Action = [[-0.24771553 -0.719272  ]]. Reward = [16.044651]
Abstract state at timestep 1750 is 5
State prediction error at timestep 1750 is 0.012
Human Feedback received at timestpe 1750 of 10
Current timestep = 1751. State = [[ 0.0059576   1.4205178   0.6034275   0.42654487 -0.0068966  -0.1366854
   0.          0.        ]]. Action = [[-0.01074535  0.6413734 ]]. Reward = [-100.]
Abstract state at timestep 1751 is 5
State prediction error at timestep 1751 is 0.012
Human Feedback received at timestpe 1751 of 10
Current timestep = 1752. State = [[ 0.01194143  1.4308143   0.6051162   0.45758104 -0.01355307 -0.13314047
   0.          0.        ]]. Action = [[0.8695766  0.03407049]]. Reward = [-3.9479837]
Abstract state at timestep 1752 is 3
State prediction error at timestep 1752 is 0.012
Human Feedback received at timestpe 1752 of 10
Current timestep = 1753. State = [[ 0.01786632  1.4405216   0.5977102   0.43138102 -0.01871427 -0.1032335
   0.          0.        ]]. Action = [[-0.59115344 -0.9982169 ]]. Reward = [0.6297782]
Abstract state at timestep 1753 is 3
State prediction error at timestep 1753 is 0.012
Human Feedback received at timestpe 1753 of 10
Current timestep = 1754. State = [[ 0.02379141  1.4496294   0.5977243   0.40471324 -0.02387549 -0.10323401
   0.          0.        ]]. Action = [[-0.81561327  0.4030192 ]]. Reward = [0.09174882]
Abstract state at timestep 1754 is 3
State prediction error at timestep 1754 is 0.012
Human Feedback received at timestpe 1754 of 10
Current timestep = 1755. State = [[ 0.02973022  1.4590621   0.6008369   0.4191037  -0.03075123 -0.13752753
   0.          0.        ]]. Action = [[0.41438818 0.81873894]]. Reward = [-2.9499357]
Abstract state at timestep 1755 is 3
State prediction error at timestep 1755 is 0.012
Human Feedback received at timestpe 1755 of 10
Current timestep = 1756. State = [[ 0.03566923  1.4678952   0.6008569   0.3924244  -0.03762497 -0.13748775
   0.          0.        ]]. Action = [[-0.3815     -0.16839117]]. Reward = [-0.09244189]
Abstract state at timestep 1756 is 3
State prediction error at timestep 1756 is 0.012
Human Feedback received at timestpe 1756 of 10
Current timestep = 1757. State = [[ 0.04174213  1.4767442   0.61367315  0.39311734 -0.04393387 -0.12618992
   0.          0.        ]]. Action = [[ 0.48025703 -0.23263693]]. Reward = [-2.8672502]
Abstract state at timestep 1757 is 3
State prediction error at timestep 1757 is 0.012
Human Feedback received at timestpe 1757 of 10
Current timestep = 1758. State = [[ 0.04772864  1.4857302   0.6055435   0.39915794 -0.05075722 -0.13647944
   0.          0.        ]]. Action = [[ 0.270442   -0.17873847]]. Reward = [-1.4366324]
Abstract state at timestep 1758 is 3
State prediction error at timestep 1758 is 0.012
Human Feedback received at timestpe 1758 of -10
Current timestep = 1759. State = [[ 0.05368309  1.4947529   0.60258776  0.40075588 -0.05783453 -0.14155957
   0.          0.        ]]. Action = [[0.6983516  0.17300022]]. Reward = [-1.7262448]
Abstract state at timestep 1759 is 3
State prediction error at timestep 1759 is 0.012
Human Feedback received at timestpe 1759 of -10
Current timestep = 1760. State = [[ 0.0597044   1.5041777   0.60913676  0.41858467 -0.06477747 -0.13887127
   0.          0.        ]]. Action = [[ 0.5652063  -0.20142502]]. Reward = [-3.4347687]
Abstract state at timestep 1760 is 3
State prediction error at timestep 1760 is 0.012
Human Feedback received at timestpe 1760 of -10
Current timestep = 1761. State = [[ 0.06577949  1.5143485   0.61453927  0.45171928 -0.07174038 -0.13927138
   0.          0.        ]]. Action = [[ 0.72566915 -0.38552034]]. Reward = [-4.3569574]
Abstract state at timestep 1761 is 3
State prediction error at timestep 1761 is 0.012
Human Feedback received at timestpe 1761 of -10
Current timestep = 1762. State = [[ 0.07185479  1.5239198   0.6145583   0.4250395  -0.07870213 -0.13924758
   0.          0.        ]]. Action = [[-0.8591687   0.11719251]]. Reward = [-0.13217255]
Abstract state at timestep 1762 is 3
State prediction error at timestep 1762 is 0.012
Human Feedback received at timestpe 1762 of -10
Current timestep = 1763. State = [[ 0.07791653  1.5334337   0.61339796  0.42244256 -0.08586184 -0.14320752
   0.          0.        ]]. Action = [[ 0.61324275 -0.30482107]]. Reward = [-1.6948436]
Abstract state at timestep 1763 is 3
State prediction error at timestep 1763 is 0.012
Human Feedback received at timestpe 1763 of -10
Current timestep = 1764. State = [[ 0.08404131  1.5432031   0.61962587  0.43377864 -0.09295552 -0.14188698
   0.          0.        ]]. Action = [[0.39140415 0.18966055]]. Reward = [-3.0840018]
Abstract state at timestep 1764 is 3
State prediction error at timestep 1764 is 0.012
Human Feedback received at timestpe 1764 of -10
Current timestep = 1765. State = [[ 0.09016629  1.5523733   0.6196449   0.40710047 -0.10004823 -0.14186735
   0.          0.        ]]. Action = [[-0.71523756  0.07608569]]. Reward = [-0.16307026]
Abstract state at timestep 1765 is 3
State prediction error at timestep 1765 is 0.012
Human Feedback received at timestpe 1765 of -10
Current timestep = 1766. State = [[ 0.09635486  1.5609417   0.62759346  0.38021153 -0.10872913 -0.17363368
   0.          0.        ]]. Action = [[-0.9166531  0.7043836]]. Reward = [-1.0184988]
Abstract state at timestep 1766 is 3
State prediction error at timestep 1766 is 0.012
Human Feedback received at timestpe 1766 of -10
Current timestep = 1767. State = [[ 0.10254383  1.5689108   0.6276185   0.35353565 -0.11740804 -0.17359342
   0.          0.        ]]. Action = [[-0.827861   -0.03199273]]. Reward = [-0.35856077]
Abstract state at timestep 1767 is 3
State prediction error at timestep 1767 is 0.012
Human Feedback received at timestpe 1767 of -10
Current timestep = 1768. State = [[ 0.10854273  1.5769475   0.6073505   0.3565842  -0.12482843 -0.14842173
   0.          0.        ]]. Action = [[ 0.9288027  -0.82333165]]. Reward = [-0.29307142]
Abstract state at timestep 1768 is 3
State prediction error at timestep 1768 is 0.012
Human Feedback received at timestpe 1768 of -10
Current timestep = 1769. State = [[ 0.11469784  1.584757    0.62396777  0.34635273 -0.13325912 -0.16862902
   0.          0.        ]]. Action = [[0.25111294 0.5820422 ]]. Reward = [-2.8063457]
Abstract state at timestep 1769 is 3
State prediction error at timestep 1769 is 0.012
Human Feedback received at timestpe 1769 of -10
Current timestep = 1770. State = [[ 0.12091675  1.5926034   0.6303076   0.34796607 -0.14165714 -0.16797575
   0.          0.        ]]. Action = [[0.87888503 0.29835224]]. Reward = [-2.5829341]
Abstract state at timestep 1770 is 3
State prediction error at timestep 1770 is 0.012
Human Feedback received at timestpe 1770 of -10
Current timestep = 1771. State = [[ 0.12713747  1.6007488   0.62911135  0.36133304 -0.1486921  -0.14071205
   0.          0.        ]]. Action = [[ 0.26640785 -0.7006631 ]]. Reward = [-2.326431]
Abstract state at timestep 1771 is 3
State prediction error at timestep 1771 is 0.012
Human Feedback received at timestpe 1771 of -10
Current timestep = 1772. State = [[ 0.13335839  1.6082946   0.6291289   0.33465406 -0.15572648 -0.1407004
   0.          0.        ]]. Action = [[-0.04116184 -0.27589297]]. Reward = [-0.21624163]
Abstract state at timestep 1772 is 3
State prediction error at timestep 1772 is 0.012
Human Feedback received at timestpe 1772 of -10
Current timestep = 1773. State = [[ 0.13964911  1.6155622   0.63592565  0.32227388 -0.16259485 -0.1373795
   0.          0.        ]]. Action = [[ 0.01352489 -0.12688214]]. Reward = [-1.6487571]
Abstract state at timestep 1773 is 3
State prediction error at timestep 1773 is 0.012
Human Feedback received at timestpe 1773 of -10
Current timestep = 1774. State = [[ 0.14599724  1.6227999   0.6416874   0.32091135 -0.16948518 -0.13781866
   0.          0.        ]]. Action = [[ 0.0847441  -0.46339822]]. Reward = [-2.08186]
Abstract state at timestep 1774 is 3
State prediction error at timestep 1774 is 0.012
Human Feedback received at timestpe 1774 of -10
Current timestep = 1775. State = [[ 0.15239458  1.6294206   0.6478753   0.2933119  -0.17765148 -0.16334024
   0.          0.        ]]. Action = [[-0.735062   0.7721385]]. Reward = [-0.9295094]
Abstract state at timestep 1775 is 3
State prediction error at timestep 1775 is 0.012
Human Feedback received at timestpe 1775 of -10
Current timestep = 1776. State = [[ 0.15887308  1.6361926   0.6563966   0.29992878 -0.18622969 -0.17156914
   0.          0.        ]]. Action = [[ 0.26869488 -0.07367617]]. Reward = [-2.833353]
Abstract state at timestep 1776 is 3
State prediction error at timestep 1776 is 0.012
Human Feedback received at timestpe 1776 of -10
Current timestep = 1777. State = [[ 0.16547498  1.6427809   0.66802704  0.29180604 -0.19411257 -0.15765753
   0.          0.        ]]. Action = [[0.3452195 0.246279 ]]. Reward = [-2.4411993]
Abstract state at timestep 1777 is 3
State prediction error at timestep 1777 is 0.012
Human Feedback received at timestpe 1777 of -10
Current timestep = 1778. State = [[ 0.17239818  1.6499839   0.6994182   0.3191815  -0.20126033 -0.1429553
   0.          0.        ]]. Action = [[ 0.7847476  -0.02320504]]. Reward = [-5.7523427]
Abstract state at timestep 1778 is 3
State prediction error at timestep 1778 is 0.012
Human Feedback received at timestpe 1778 of -10
Current timestep = 1779. State = [[ 0.17932138  1.6565874   0.69941694  0.29251063 -0.20840807 -0.1429548
   0.          0.        ]]. Action = [[-0.5571717   0.06501865]]. Reward = [-0.37609223]
Abstract state at timestep 1779 is 3
State prediction error at timestep 1779 is 0.012
Human Feedback received at timestpe 1779 of -10
Current timestep = 1780. State = [[ 0.18624477  1.6625917   0.69941556  0.26583976 -0.21555579 -0.14295433
   0.          0.        ]]. Action = [[-0.64408845  0.23362827]]. Reward = [-0.39866763]
Abstract state at timestep 1780 is 3
State prediction error at timestep 1780 is 0.012
Human Feedback received at timestpe 1780 of -10
Current timestep = 1781. State = [[ 0.1934535   1.6693132   0.7275256   0.29774815 -0.22228359 -0.13455603
   0.          0.        ]]. Action = [[0.9939711  0.20854795]]. Reward = [-5.5076375]
Abstract state at timestep 1781 is 3
State prediction error at timestep 1781 is 0.012
Human Feedback received at timestpe 1781 of -10
Current timestep = 1782. State = [[ 0.20083933  1.6765866   0.7463521   0.3220676  -0.23016265 -0.15758117
   0.          0.        ]]. Action = [[0.7114595 0.5211456]]. Reward = [-4.547105]
Abstract state at timestep 1782 is 3
State prediction error at timestep 1782 is 0.012
Human Feedback received at timestpe 1782 of -10
Current timestep = 1783. State = [[ 0.20828219  1.6832472   0.75349486  0.2945572  -0.23950689 -0.18688467
   0.          0.        ]]. Action = [[-0.57548666  0.72177327]]. Reward = [-1.3218417]
Abstract state at timestep 1783 is 3
State prediction error at timestep 1783 is 0.012
Human Feedback received at timestpe 1783 of -10
Current timestep = 1784. State = [[ 0.21595994  1.6901705   0.77654374  0.30624664 -0.24842736 -0.17840925
   0.          0.        ]]. Action = [[0.23465407 0.17248082]]. Reward = [-4.432616]
Abstract state at timestep 1784 is 3
State prediction error at timestep 1784 is 0.012
Human Feedback received at timestpe 1784 of -10
Current timestep = 1785. State = [[ 0.22363767  1.6964948   0.77654135  0.2795734  -0.25734773 -0.17840812
   0.          0.        ]]. Action = [[-0.97071    -0.26254362]]. Reward = [-0.6765506]
Abstract state at timestep 1785 is 3
State prediction error at timestep 1785 is 0.012
Human Feedback received at timestpe 1785 of -10
Current timestep = 1786. State = [[ 0.23151846  1.702862    0.79641837  0.2815021  -0.2658655  -0.17035565
   0.          0.        ]]. Action = [[ 0.20729184 -0.25573653]]. Reward = [-3.705501]
Abstract state at timestep 1786 is 3
State prediction error at timestep 1786 is 0.012
Human Feedback received at timestpe 1786 of -10
Current timestep = 1787. State = [[ 0.23948565  1.7094269   0.8064066   0.28997773 -0.27579433 -0.19857642
   0.          0.        ]]. Action = [[0.28557265 0.60408294]]. Reward = [-3.1885521]
Abstract state at timestep 1787 is 3
State prediction error at timestep 1787 is 0.012
Human Feedback received at timestpe 1787 of -10
Current timestep = 1788. State = [[ 0.24748544  1.7153764   0.81049615  0.26240218 -0.28660452 -0.21620353
   0.          0.        ]]. Action = [[-0.10802442  0.54033494]]. Reward = [-1.2944556]
Abstract state at timestep 1788 is 3
State prediction error at timestep 1788 is 0.012
Human Feedback received at timestpe 1788 of -10
Current timestep = 1789. State = [[ 0.25548545  1.7207272   0.81049216  0.23572606 -0.2974146  -0.21620181
   0.          0.        ]]. Action = [[-0.10419828  0.23601127]]. Reward = [-0.9424299]
Abstract state at timestep 1789 is 3
State prediction error at timestep 1789 is 0.012
Human Feedback received at timestpe 1789 of -10
Current timestep = 1790. State = [[ 0.26348582  1.7254798   0.8104879   0.20904997 -0.30822465 -0.21620007
   0.          0.        ]]. Action = [[-0.22656953  0.13916326]]. Reward = [-0.9639096]
Abstract state at timestep 1790 is 3
State prediction error at timestep 1790 is 0.012
Human Feedback received at timestpe 1790 of -10
Current timestep = 1791. State = [[ 0.27167863  1.7309324   0.8283311   0.24038677 -0.31759745 -0.1874559
   0.          0.        ]]. Action = [[ 0.7119262 -0.7242096]]. Reward = [-4.4292684]
Abstract state at timestep 1791 is 3
State prediction error at timestep 1791 is 0.012
Human Feedback received at timestpe 1791 of -10
Current timestep = 1792. State = [[ 0.27987176  1.7357861   0.8283278   0.21371308 -0.32697016 -0.18745477
   0.          0.        ]]. Action = [[-0.65149176 -0.37056386]]. Reward = [-0.83997136]
Abstract state at timestep 1792 is 3
State prediction error at timestep 1792 is 0.012
Human Feedback received at timestpe 1792 of -10
Current timestep = 1793. State = [[ 0.28802758  1.7400668   0.82353085  0.18843478 -0.3352643  -0.16588262
   0.          0.        ]]. Action = [[-0.8764727  -0.66519666]]. Reward = [-0.3394278]
Abstract state at timestep 1793 is 3
State prediction error at timestep 1793 is 0.012
Human Feedback received at timestpe 1793 of -10
Current timestep = 1794. State = [[ 0.29623002  1.7437314   0.8293489   0.16072522 -0.34478796 -0.19047305
   0.          0.        ]]. Action = [[-0.78408897  0.558012  ]]. Reward = [-1.4627317]
Abstract state at timestep 1794 is 3
State prediction error at timestep 1794 is 0.012
Human Feedback received at timestpe 1794 of -10
Current timestep = 1795. State = [[ 0.30471295  1.7476593   0.85571086  0.17277136 -0.3525852  -0.15594457
   0.          0.        ]]. Action = [[ 0.30543017 -0.76408756]]. Reward = [-4.349336]
Abstract state at timestep 1795 is 3
State prediction error at timestep 1795 is 0.012
Human Feedback received at timestpe 1795 of -10
Current timestep = 1796. State = [[ 0.31314546  1.7510227   0.84926283  0.14799923 -0.35892308 -0.12675694
   0.          0.        ]]. Action = [[-0.30896127 -0.7806367 ]]. Reward = [-0.04345335]
Abstract state at timestep 1796 is 6
State prediction error at timestep 1796 is 0.012
Human Feedback received at timestpe 1796 of -10
Current timestep = 1797. State = [[ 0.32188454  1.7546855   0.88113135  0.16096559 -0.36653984 -0.15233494
   0.          0.        ]]. Action = [[0.2903099 0.647159 ]]. Reward = [-4.8559427]
Abstract state at timestep 1797 is 6
State prediction error at timestep 1797 is 0.012
Human Feedback received at timestpe 1797 of -10
Current timestep = 1798. State = [[ 0.3305521   1.7577958   0.8720152   0.13687636 -0.37210298 -0.1112626
   0.          0.        ]]. Action = [[-0.9301739 -0.8689797]]. Reward = [0.25564408]
Abstract state at timestep 1798 is 6
State prediction error at timestep 1798 is 0.012
Human Feedback received at timestpe 1798 of -10
Current timestep = 1799. State = [[ 0.3391882   1.7603259   0.86801976  0.11129145 -0.37677202 -0.09338095
   0.          0.        ]]. Action = [[-0.5041949 -0.5352886]]. Reward = [-0.13630979]
Abstract state at timestep 1799 is 6
State prediction error at timestep 1799 is 0.012
Human Feedback received at timestpe 1799 of -10
Current timestep = 1800. State = [[ 0.34776896  1.7622834   0.8610366   0.08621559 -0.37991965 -0.06295326
   0.          0.        ]]. Action = [[-0.8341965  -0.89561754]]. Reward = [0.28029355]
Abstract state at timestep 1800 is 6
State prediction error at timestep 1800 is 0.012
Human Feedback received at timestpe 1800 of -10
Current timestep = 1801. State = [[ 0.35634965  1.7636411   0.8610361   0.05954814 -0.38306728 -0.06295322
   0.          0.        ]]. Action = [[-0.42264628  0.42098212]]. Reward = [-0.39099836]
Abstract state at timestep 1801 is 6
State prediction error at timestep 1801 is 0.012
Human Feedback received at timestpe 1801 of -10
Current timestep = 1802. State = [[ 0.36506003  1.7654384   0.8721415   0.0795791  -0.38424522 -0.02355868
   0.          0.        ]]. Action = [[ 0.31598115 -0.9614088 ]]. Reward = [-1.9617456]
Abstract state at timestep 1802 is 6
State prediction error at timestep 1802 is 0.012
Human Feedback received at timestpe 1802 of -10
Current timestep = 1803. State = [[ 0.37377042  1.7666357   0.87214124  0.05291233 -0.38542318 -0.02355923
   0.          0.        ]]. Action = [[-0.7445859   0.41597986]]. Reward = [-0.21135275]
Abstract state at timestep 1803 is 6
State prediction error at timestep 1803 is 0.012
Human Feedback received at timestpe 1803 of -10
Current timestep = 1804. State = [[ 0.38273153  1.7678381   0.89837456  0.0528321  -0.38783666 -0.04826955
   0.          0.        ]]. Action = [[0.93854094 0.6346265 ]]. Reward = [-3.4744875]
Abstract state at timestep 1804 is 6
State prediction error at timestep 1804 is 0.012
Human Feedback received at timestpe 1804 of -10
Current timestep = 1805. State = [[ 0.39169484  1.7690233   0.8972171   0.05243412 -0.38877952 -0.01885699
   0.          0.        ]]. Action = [[ 0.02754903 -0.73376685]]. Reward = [-0.46004423]
Abstract state at timestep 1805 is 6
State prediction error at timestep 1805 is 0.012
Human Feedback received at timestpe 1805 of -10
Current timestep = 1806. State = [[ 0.40065822  1.7696085   0.8972171   0.02576739 -0.38972235 -0.01885666
   0.          0.        ]]. Action = [[-0.79356027  0.16740203]]. Reward = [-0.23115334]
Abstract state at timestep 1806 is 6
State prediction error at timestep 1806 is 0.012
Human Feedback received at timestpe 1806 of -10
Current timestep = 1807. State = [[ 0.4099229   1.7700807   0.9282605   0.020493   -0.39163244 -0.03820199
   0.          0.        ]]. Action = [[0.29109037 0.57125115]]. Reward = [-3.744613]
Abstract state at timestep 1807 is 6
State prediction error at timestep 1807 is 0.012
Human Feedback received at timestpe 1807 of -10
Current timestep = 1808. State = [[ 0.4195407   1.7708158   0.96205616  0.03259734 -0.39192924 -0.00593581
   0.          0.        ]]. Action = [[ 0.75378966 -0.59334636]]. Reward = [-4.0136404]
Abstract state at timestep 1808 is 6
State prediction error at timestep 1808 is 0.012
Human Feedback received at timestpe 1808 of -10
Current timestep = 1809. State = [[ 0.4291585   1.770951    0.96205616  0.00593067 -0.39222604 -0.0059362
   0.          0.        ]]. Action = [[-0.30090404 -0.34267306]]. Reward = [-0.2135673]
Abstract state at timestep 1809 is 6
State prediction error at timestep 1809 is 0.012
Human Feedback received at timestpe 1809 of -10
Current timestep = 1810. State = [[ 0.43883306  1.770457    0.9692117  -0.0224399  -0.39409286 -0.03733672
   0.          0.        ]]. Action = [[-0.5565983  0.7289916]]. Reward = [-1.130577]
Abstract state at timestep 1810 is 6
State prediction error at timestep 1810 is 0.012
Human Feedback received at timestpe 1810 of -10
Current timestep = 1811. State = [[ 0.4487563   1.7705632   0.99440557  0.0041371  -0.39631912 -0.04452472
   0.          0.        ]]. Action = [[0.6205503  0.40900445]]. Reward = [-3.2115507]
Abstract state at timestep 1811 is 6
State prediction error at timestep 1811 is 0.012
Human Feedback received at timestpe 1811 of -10
Current timestep = 1812. State = [[ 0.4586796   1.7700692   0.9944054  -0.02252996 -0.39854535 -0.04452476
   0.          0.        ]]. Action = [[-0.66206807  0.10699785]]. Reward = [-0.44577625]
Abstract state at timestep 1812 is 6
State prediction error at timestep 1812 is 0.012
Human Feedback received at timestpe 1812 of -10
Current timestep = 1813. State = [[ 0.46854153  1.7690078   0.98669416 -0.04731789 -0.39907312 -0.01055521
   0.          0.        ]]. Action = [[-0.18462789 -0.8688945 ]]. Reward = [0.45714062]
Abstract state at timestep 1813 is 6
State prediction error at timestep 1813 is 0.012
Human Feedback received at timestpe 1813 of -10
Current timestep = 1814. State = [[ 0.47840357  1.7673463   0.98669404 -0.07398459 -0.3996009  -0.01055551
   0.          0.        ]]. Action = [[-0.80599594 -0.4108346 ]]. Reward = [-0.310955]
Abstract state at timestep 1814 is 6
State prediction error at timestep 1814 is 0.012
Human Feedback received at timestpe 1814 of -10
Current timestep = 1815. State = [[ 0.48842725  1.7655964   1.0044583  -0.07836131 -0.40183768 -0.04473571
   0.          0.        ]]. Action = [[0.5988631 0.7860532]]. Reward = [-2.387521]
Abstract state at timestep 1815 is 6
State prediction error at timestep 1815 is 0.012
Human Feedback received at timestpe 1815 of -10
Current timestep = 1816. State = [[ 0.49853125  1.7635422   1.0124936  -0.09189539 -0.40408957 -0.04503767
   0.          0.        ]]. Action = [[0.18068624 0.45683396]]. Reward = [-1.39109]
Abstract state at timestep 1816 is 6
State prediction error at timestep 1816 is 0.012
Human Feedback received at timestpe 1816 of -10
Current timestep = 1817. State = [[ 0.5087085   1.7608466   1.0217302  -0.12095202 -0.40839702 -0.08614926
   0.          0.        ]]. Action = [[-0.95893407  0.87451863]]. Reward = [-1.6983768]
Abstract state at timestep 1817 is 6
State prediction error at timestep 1817 is 0.012
Human Feedback received at timestpe 1817 of -10
Current timestep = 1818. State = [[ 0.51894444  1.7585917   1.0269997  -0.10120269 -0.41205475 -0.07315435
   0.          0.        ]]. Action = [[ 0.9899142 -0.5589607]]. Reward = [-1.0624412]
Abstract state at timestep 1818 is 6
State prediction error at timestep 1818 is 0.012
Human Feedback received at timestpe 1818 of -10
Current timestep = 1819. State = [[ 0.52918065  1.755737    1.026999   -0.12787038 -0.41571245 -0.07315426
   0.          0.        ]]. Action = [[-0.8134917  0.2814293]]. Reward = [-0.6802373]
Abstract state at timestep 1819 is 6
State prediction error at timestep 1819 is 0.012
Human Feedback received at timestpe 1819 of -10
Current timestep = 1820. State = [[ 0.5394167   1.7522824   1.0269983  -0.15453808 -0.41937014 -0.07315417
   0.          0.        ]]. Action = [[-0.63285035  0.24433589]]. Reward = [-0.69672954]
Abstract state at timestep 1820 is 6
State prediction error at timestep 1820 is 0.012
Human Feedback received at timestpe 1820 of -10
Current timestep = 1821. State = [[ 0.5498945   1.7490535   1.0526016  -0.14495125 -0.42458954 -0.10438742
   0.          0.        ]]. Action = [[0.6295427 0.6967299]]. Reward = [-3.1877034]
Abstract state at timestep 1821 is 6
State prediction error at timestep 1821 is 0.012
Human Feedback received at timestpe 1821 of -10
Current timestep = 1822. State = [[ 0.560861    1.7465715   1.1011374  -0.11167084 -0.42946103 -0.09742915
   0.          0.        ]]. Action = [[ 0.96535516 -0.25326324]]. Reward = [-5.302533]
Abstract state at timestep 1822 is 6
State prediction error at timestep 1822 is 0.012
Human Feedback received at timestpe 1822 of -10
Current timestep = 1823. State = [[ 0.5720318   1.7444491   1.1218982  -0.09581886 -0.43470523 -0.10488375
   0.          0.        ]]. Action = [[0.94501877 0.25446916]]. Reward = [-2.8788202]
Abstract state at timestep 1823 is 6
State prediction error at timestep 1823 is 0.012
Human Feedback received at timestpe 1823 of -10
Current timestep = 1824. State = [[ 0.5833629   1.7426465   1.1384041  -0.0817586  -0.44047135 -0.11532229
   0.          0.        ]]. Action = [[0.8972821  0.05278265]]. Reward = [-2.5818493]
Abstract state at timestep 1824 is 6
State prediction error at timestep 1824 is 0.012
Human Feedback received at timestpe 1824 of -10
Current timestep = 1825. State = [[ 0.59469414  1.7402445   1.1384025  -0.10842781 -0.44623744 -0.11532208
   0.          0.        ]]. Action = [[-0.03806967  0.0655055 ]]. Reward = [-0.93395305]
Abstract state at timestep 1825 is 6
State prediction error at timestep 1825 is 0.012
Human Feedback received at timestpe 1825 of -10
Current timestep = 1826. State = [[ 0.6063652   1.7383612   1.1736825  -0.08581427 -0.4534345  -0.14394087
   0.          0.        ]]. Action = [[0.6779871  0.61838984]]. Reward = [-4.518937]
Abstract state at timestep 1826 is 6
State prediction error at timestep 1826 is 0.012
Human Feedback received at timestpe 1826 of -10
Current timestep = 1827. State = [[ 0.61795884  1.7359302   1.1638732  -0.10951436 -0.45837474 -0.09880479
   0.          0.        ]]. Action = [[-0.15007287 -0.93427217]]. Reward = [0.10202033]
Abstract state at timestep 1827 is 6
State prediction error at timestep 1827 is 0.012
Human Feedback received at timestpe 1827 of -10
Current timestep = 1828. State = [[ 0.6296097   1.7333537   1.1680433  -0.11549056 -0.46163857 -0.06527684
   0.          0.        ]]. Action = [[ 0.09032655 -0.80738467]]. Reward = [-1.1384277]
Abstract state at timestep 1828 is 6
State prediction error at timestep 1828 is 0.012
Human Feedback received at timestpe 1828 of -10
Current timestep = 1829. State = [[ 0.64123285  1.7302016   1.1644857  -0.1408181  -0.46403906 -0.04801002
   0.          0.        ]]. Action = [[-0.70881486 -0.5293332 ]]. Reward = [-0.28340167]
Abstract state at timestep 1829 is 6
State prediction error at timestep 1829 is 0.012
Human Feedback received at timestpe 1829 of -10
Current timestep = 1830. State = [[ 0.65333176  1.7272477   1.2130024  -0.13232864 -0.46748012 -0.06882215
   0.          0.        ]]. Action = [[0.8118217 0.6520467]]. Reward = [-5.506062]
Abstract state at timestep 1830 is 6
State prediction error at timestep 1830 is 0.012
Human Feedback received at timestpe 1830 of -10
Current timestep = 1831. State = [[ 0.6656729   1.724528    1.2385294  -0.12238386 -0.47237763 -0.09794967
   0.          0.        ]]. Action = [[0.26307797 0.6361582 ]]. Reward = [-3.3209658]
Abstract state at timestep 1831 is 6
State prediction error at timestep 1831 is 0.012
Human Feedback received at timestpe 1831 of -10
Current timestep = 1832. State = [[ 0.67830545  1.7220803   1.2677062  -0.11030146 -0.4772979  -0.09840521
   0.          0.        ]]. Action = [[ 0.3548845  -0.07783496]]. Reward = [-3.7195947]
Abstract state at timestep 1832 is 6
State prediction error at timestep 1832 is 0.012
Human Feedback received at timestpe 1832 of -10
Current timestep = 1833. State = [[ 0.69093835  1.7190329   1.2677047  -0.13696997 -0.4822182  -0.09840541
   0.          0.        ]]. Action = [[-0.74309075  0.35799026]]. Reward = [-0.93464273]
Abstract state at timestep 1833 is 6
State prediction error at timestep 1833 is 0.012
Human Feedback received at timestpe 1833 of -10
Current timestep = 1834. State = [[ 0.70353335  1.7154133   1.2629095  -0.16207047 -0.48601335 -0.07590302
   0.          0.        ]]. Action = [[-0.9790182  -0.51368386]]. Reward = [-0.3517396]
Abstract state at timestep 1834 is 6
State prediction error at timestep 1834 is 0.012
Human Feedback received at timestpe 1834 of -10
Current timestep = 1835. State = [[ 0.7165108   1.7118424   1.3018973  -0.16017939 -0.49067163 -0.09316577
   0.          0.        ]]. Action = [[0.16489494 0.50291705]]. Reward = [-4.667284]
Abstract state at timestep 1835 is 6
State prediction error at timestep 1835 is 0.012
Human Feedback received at timestpe 1835 of -10
Current timestep = 1836. State = [[ 0.7295475   1.707625    1.309458   -0.18951705 -0.49714077 -0.12938258
   0.          0.        ]]. Action = [[-0.25866222  0.89872503]]. Reward = [-1.9319327]
Abstract state at timestep 1836 is 6
State prediction error at timestep 1836 is 0.012
Human Feedback received at timestpe 1836 of -10
Current timestep = 1837. State = [[ 0.7425846   1.7028079   1.3094556  -0.2161868  -0.5036099  -0.12938218
   0.          0.        ]]. Action = [[-0.50726926  0.2557869 ]]. Reward = [-1.1293341]
Abstract state at timestep 1837 is 6
State prediction error at timestep 1837 is 0.012
Human Feedback received at timestpe 1837 of -10
Current timestep = 1838. State = [[ 0.75562173  1.6973914   1.3094531  -0.24285658 -0.51007897 -0.1293818
   0.          0.        ]]. Action = [[-0.36935353 -0.13335878]]. Reward = [-1.1371013]
Abstract state at timestep 1838 is 6
State prediction error at timestep 1838 is 0.012
Human Feedback received at timestpe 1838 of -10
Current timestep = 1839. State = [[ 0.76896685  1.6920338   1.3388014  -0.23972608 -0.514941   -0.09724043
   0.          0.        ]]. Action = [[ 0.16473174 -0.7058575 ]]. Reward = [-3.5720594]
Abstract state at timestep 1839 is 6
State prediction error at timestep 1839 is 0.012
Human Feedback received at timestpe 1839 of -10
Current timestep = 1840. State = [[ 0.7823122   1.6860765   1.3387998  -0.26639453 -0.51980305 -0.09724046
   0.          0.        ]]. Action = [[-0.54690635  0.24184477]]. Reward = [-0.9969046]
Abstract state at timestep 1840 is 6
State prediction error at timestep 1840 is 0.012
Human Feedback received at timestpe 1840 of -10
Current timestep = 1841. State = [[ 0.7956995   1.6794755   1.3442272  -0.29548666 -0.5260637  -0.12521212
   0.          0.        ]]. Action = [[-0.8127295  0.5819497]]. Reward = [-1.7416539]
Abstract state at timestep 1841 is 6
State prediction error at timestep 1841 is 0.012
Human Feedback received at timestpe 1841 of -10
Current timestep = 1842. State = [[ 0.8094322   1.6731422   1.3806119  -0.2843482  -0.5344573  -0.16787338
   0.          0.        ]]. Action = [[0.59786797 0.9788914 ]]. Reward = [-4.4570746]
Abstract state at timestep 1842 is 6
State prediction error at timestep 1842 is 0.012
Human Feedback received at timestpe 1842 of -10
Current timestep = 1843. State = [[ 0.823579   1.6671909  1.4218873 -0.2673732 -0.5427458 -0.1657703
   0.         0.       ]]. Action = [[ 0.692981   -0.27533615]]. Reward = [-4.8912435]
Abstract state at timestep 1843 is 6
State prediction error at timestep 1843 is 0.012
Human Feedback received at timestpe 1843 of -10
Current timestep = 1844. State = [[ 0.8379377   1.6614008   1.4412601  -0.25952643 -0.5489787  -0.12465763
   0.          0.        ]]. Action = [[ 0.47504354 -0.96643406]]. Reward = [-2.7600179]
Abstract state at timestep 1844 is 6
State prediction error at timestep 1844 is 0.012
Human Feedback received at timestpe 1844 of -10
Current timestep = 1845. State = [[ 0.85225105  1.6550602   1.4353807  -0.28346214 -0.5536685  -0.09379677
   0.          0.        ]]. Action = [[-0.42564213 -0.7038536 ]]. Reward = [-0.44131595]
Abstract state at timestep 1845 is 6
State prediction error at timestep 1845 is 0.012
Human Feedback received at timestpe 1845 of -10
Current timestep = 1846. State = [[ 0.8666792  1.6488638  1.4455373 -0.2765253 -0.5568471 -0.0635737
   0.         0.       ]]. Action = [[ 0.6065626 -0.7862227]]. Reward = [-1.5633007]
Abstract state at timestep 1846 is 6
State prediction error at timestep 1846 is 0.012
Human Feedback received at timestpe 1846 of -10
Current timestep = 1847. State = [[ 0.88110715  1.6420676   1.4455367  -0.3031927  -0.56002575 -0.06357341
   0.          0.        ]]. Action = [[-0.5663332  -0.28851628]]. Reward = [-0.91859084]
Abstract state at timestep 1847 is 6
State prediction error at timestep 1847 is 0.012
Human Feedback received at timestpe 1847 of -10
Current timestep = 1848. State = [[ 0.89580154  1.635097    1.473141   -0.31135175 -0.56434137 -0.08631194
   0.          0.        ]]. Action = [[0.3004639 0.5586014]]. Reward = [-3.600331]
Abstract state at timestep 1848 is 6
State prediction error at timestep 1848 is 0.012
Human Feedback received at timestpe 1848 of -10
Current timestep = 1849. State = [[ 0.9104565   1.6275666   1.468043   -0.33577347 -0.5673407  -0.0599866
   0.          0.        ]]. Action = [[-0.65607107 -0.7354646 ]]. Reward = [-0.3998627]
Abstract state at timestep 1849 is 6
State prediction error at timestep 1849 is 0.012
Human Feedback received at timestpe 1849 of -10
Current timestep = 1850. State = [[ 0.92563933  1.6206069   1.5226034  -0.3111561  -0.5723864  -0.10091428
   0.          0.        ]]. Action = [[0.8316028 0.9315777]]. Reward = [-5.7604218]
Abstract state at timestep 1850 is 6
State prediction error at timestep 1850 is 0.012
Human Feedback received at timestpe 1850 of -10
Current timestep = 1851. State = [[ 0.94085675  1.6135432   1.5244253  -0.3151053  -0.57554543 -0.06318041
   0.          0.        ]]. Action = [[ 0.10359406 -0.88165176]]. Reward = [-0.9147042]
Abstract state at timestep 1851 is 6
State prediction error at timestep 1851 is 0.012
Human Feedback received at timestpe 1851 of -10
Current timestep = 1852. State = [[ 0.9561151   1.605835    1.5296888  -0.34426472 -0.5801013  -0.09111725
   0.          0.        ]]. Action = [[-0.65374714  0.5589855 ]]. Reward = [-1.7126787]
Abstract state at timestep 1852 is 6
State prediction error at timestep 1852 is 0.012
Human Feedback received at timestpe 1852 of -10
Current timestep = 1853. State = [[ 0.97169304  1.5979059   1.5634459  -0.35488877 -0.58678716 -0.13371745
   0.          0.        ]]. Action = [[0.08523726 0.9782543 ]]. Reward = [-4.511383]
Abstract state at timestep 1853 is 6
State prediction error at timestep 1853 is 0.012
Human Feedback received at timestpe 1853 of -10
Current timestep = 1854. State = [[ 0.98727113  1.5893774   1.5634428  -0.38155857 -0.593473   -0.13371703
   0.          0.        ]]. Action = [[-0.7951075  -0.05364156]]. Reward = [-1.3687744]
Abstract state at timestep 1854 is 6
State prediction error at timestep 1854 is 0.012
Human Feedback received at timestpe 1854 of -10
Current timestep = 1855. State = [[ 0.00449924  1.4039598   0.4557013  -0.30936053 -0.00520665 -0.10322317
   0.          0.        ]]. Action = [[0.17887878 0.484581  ]]. Reward = [-100.]
Abstract state at timestep 1855 is 6
State prediction error at timestep 1855 is 0.012
Human Feedback received at timestpe 1855 of -10
Current timestep = 1856. State = [[ 0.00899849  1.3964226   0.4550857  -0.33500725 -0.01030745 -0.10202529
   0.          0.        ]]. Action = [[-0.32642853  0.0968951 ]]. Reward = [-1.189277]
Abstract state at timestep 1856 is 3
State prediction error at timestep 1856 is 0.012
Human Feedback received at timestpe 1856 of -10
Current timestep = 1857. State = [[ 0.01349621  1.3889371   0.45301285 -0.3327201  -0.01352075 -0.064272
   0.          0.        ]]. Action = [[ 0.7066977  -0.89557725]]. Reward = [0.44318834]
Abstract state at timestep 1857 is 3
State prediction error at timestep 1857 is 0.012
Human Feedback received at timestpe 1857 of -10
Current timestep = 1858. State = [[ 0.01799393  1.3808515   0.453022   -0.359398   -0.01673461 -0.06428283
   0.          0.        ]]. Action = [[-0.88046867 -0.41263425]]. Reward = [-1.1379164]
Abstract state at timestep 1858 is 3
State prediction error at timestep 1858 is 0.012
Human Feedback received at timestpe 1858 of -10
Current timestep = 1859. State = [[ 0.02249184  1.3721659   0.4530317  -0.38606498 -0.0199475  -0.06426384
   0.          0.        ]]. Action = [[-0.18171668  0.3785901 ]]. Reward = [-1.1542124]
Abstract state at timestep 1859 is 3
State prediction error at timestep 1859 is 0.012
Human Feedback received at timestpe 1859 of -10
Current timestep = 1860. State = [[ 0.02698984  1.3628805   0.45304146 -0.4127333  -0.02315991 -0.06425373
   0.          0.        ]]. Action = [[-0.7188775   0.25679743]]. Reward = [-1.1650689]
Abstract state at timestep 1860 is 3
State prediction error at timestep 1860 is 0.012
Human Feedback received at timestpe 1860 of -10
Current timestep = 1861. State = [[ 0.03155937  1.3535933   0.45806497 -0.41278458 -0.02425963 -0.02199613
   0.          0.        ]]. Action = [[ 0.91646814 -0.9348801 ]]. Reward = [0.11745117]
Abstract state at timestep 1861 is 3
State prediction error at timestep 1861 is 0.012
Human Feedback received at timestpe 1861 of -10
Current timestep = 1862. State = [[ 0.0361289   1.3437059   0.45806774 -0.4394578  -0.02536028 -0.02201503
   0.          0.        ]]. Action = [[-0.26231915  0.43786263]]. Reward = [-0.9498357]
Abstract state at timestep 1862 is 3
State prediction error at timestep 1862 is 0.012
Human Feedback received at timestpe 1862 of -10
Current timestep = 1863. State = [[ 0.0409256   1.3342903   0.48227286 -0.41851637 -0.0279323  -0.05144509
   0.          0.        ]]. Action = [[0.46219873 0.8469348 ]]. Reward = [0.04895473]
Abstract state at timestep 1863 is 3
State prediction error at timestep 1863 is 0.012
Human Feedback received at timestpe 1863 of -10
Current timestep = 1864. State = [[ 0.04563856  1.3249642   0.47251058 -0.41452014 -0.02912861 -0.02392903
   0.          0.        ]]. Action = [[ 0.68842053 -0.73634547]]. Reward = [1.520118]
Abstract state at timestep 1864 is 3
State prediction error at timestep 1864 is 0.012
Human Feedback received at timestpe 1864 of -10
Current timestep = 1865. State = [[ 0.05035162  1.315038    0.47251385 -0.44118994 -0.0303255  -0.02393982
   0.          0.        ]]. Action = [[-0.7456936  -0.48603934]]. Reward = [-0.9349874]
Abstract state at timestep 1865 is 3
State prediction error at timestep 1865 is 0.012
Human Feedback received at timestpe 1865 of -10
Current timestep = 1866. State = [[ 0.05498123  1.3051108   0.4646288  -0.44123793 -0.03197391 -0.03297107
   0.          0.        ]]. Action = [[ 0.4025097  -0.08344829]]. Reward = [1.1688732]
Abstract state at timestep 1866 is 3
State prediction error at timestep 1866 is 0.012
Human Feedback received at timestpe 1866 of 10
Current timestep = 1867. State = [[ 0.05953617  1.2950978   0.4575767  -0.4450703  -0.03402584 -0.04104277
   0.          0.        ]]. Action = [[ 0.21733999 -0.39977723]]. Reward = [0.83538646]
Abstract state at timestep 1867 is 3
State prediction error at timestep 1867 is 0.012
Human Feedback received at timestpe 1867 of 10
Current timestep = 1868. State = [[ 0.06409121  1.2844849   0.45758262 -0.4717411  -0.03607731 -0.04103328
   0.          0.        ]]. Action = [[-0.41158247 -0.3977816 ]]. Reward = [-1.054703]
Abstract state at timestep 1868 is 3
State prediction error at timestep 1868 is 0.012
Human Feedback received at timestpe 1868 of 10
Current timestep = 1869. State = [[ 0.06869125  1.2736933   0.46050626 -0.4796342  -0.03657619 -0.00997832
   0.          0.        ]]. Action = [[ 0.01335216 -0.7556489 ]]. Reward = [0.05830187]
Abstract state at timestep 1869 is 3
State prediction error at timestep 1869 is 0.012
Human Feedback received at timestpe 1869 of 10
Current timestep = 1870. State = [[ 0.0732913   1.2623018   0.4605074  -0.50630605 -0.0370758  -0.00999305
   0.          0.        ]]. Action = [[-0.8550342  -0.09300989]]. Reward = [-0.88726777]
Abstract state at timestep 1870 is 3
State prediction error at timestep 1870 is 0.012
Human Feedback received at timestpe 1870 of 10
Current timestep = 1871. State = [[ 0.07794084  1.2503114   0.46670812 -0.53295124 -0.03881617 -0.03481023
   0.          0.        ]]. Action = [[-0.5288993   0.51018786]]. Reward = [-1.4213293]
Abstract state at timestep 1871 is 3
State prediction error at timestep 1871 is 0.012
Human Feedback received at timestpe 1871 of 10
Current timestep = 1872. State = [[ 0.0826499   1.2377198   0.47416258 -0.5597152  -0.04204882 -0.06465911
   0.          0.        ]]. Action = [[-0.4422996  0.6685717]]. Reward = [-1.6315554]
Abstract state at timestep 1872 is 3
State prediction error at timestep 1872 is 0.012
Human Feedback received at timestpe 1872 of 10
Current timestep = 1873. State = [[ 0.08733062  1.2250757   0.4729175  -0.5620965  -0.04683842 -0.09580053
   0.          0.        ]]. Action = [[0.56678224 0.68021655]]. Reward = [0.3931474]
Abstract state at timestep 1873 is 3
State prediction error at timestep 1873 is 0.012
Human Feedback received at timestpe 1873 of 10
Current timestep = 1874. State = [[ 0.09201155  1.2118319   0.472931   -0.5887716  -0.05162673 -0.09577507
   0.          0.        ]]. Action = [[-0.10005111 -0.1128369 ]]. Reward = [-1.2539262]
Abstract state at timestep 1874 is 3
State prediction error at timestep 1874 is 0.012
Human Feedback received at timestpe 1874 of 10
Current timestep = 1875. State = [[ 0.09681769  1.1987191   0.48496968 -0.5829506  -0.05594951 -0.08646312
   0.          0.        ]]. Action = [[0.42469013 0.46054518]]. Reward = [0.31247053]
Abstract state at timestep 1875 is 3
State prediction error at timestep 1875 is 0.012
Human Feedback received at timestpe 1875 of 10
Current timestep = 1876. State = [[ 0.10157299  1.1859338   0.48029432 -0.5684185  -0.06066927 -0.09440356
   0.          0.        ]]. Action = [[0.6727145  0.13168097]]. Reward = [1.9258065]
Abstract state at timestep 1876 is 3
State prediction error at timestep 1876 is 0.012
Human Feedback received at timestpe 1876 of 10
Current timestep = 1877. State = [[ 0.10633945  1.1732128   0.48326865 -0.5656606  -0.06723085 -0.13124332
   0.          0.        ]]. Action = [[0.20001376 0.906888  ]]. Reward = [0.3795577]
Abstract state at timestep 1877 is 3
State prediction error at timestep 1877 is 0.012
Human Feedback received at timestpe 1877 of 10
Current timestep = 1878. State = [[ 0.11110602  1.1598923   0.48328704 -0.5923349  -0.0737907  -0.13120882
   0.          0.        ]]. Action = [[-0.13328958 -0.22205853]]. Reward = [-1.4227905]
Abstract state at timestep 1878 is 3
State prediction error at timestep 1878 is 0.012
Human Feedback received at timestpe 1878 of 10
Current timestep = 1879. State = [[ 0.11587296  1.1459723   0.48330483 -0.61900747 -0.08035006 -0.13119872
   0.          0.        ]]. Action = [[-0.75365996 -0.11340064]]. Reward = [-1.4031796]
Abstract state at timestep 1879 is 3
State prediction error at timestep 1879 is 0.012
Human Feedback received at timestpe 1879 of 10
Current timestep = 1880. State = [[ 0.12063875  1.1314316   0.48320565 -0.6466313  -0.08690915 -0.1311818
   0.          0.        ]]. Action = [[-0.16800296  0.20677876]]. Reward = [-1.4481405]
Abstract state at timestep 1880 is 3
State prediction error at timestep 1880 is 0.012
Human Feedback received at timestpe 1880 of 10
Current timestep = 1881. State = [[ 0.12557717  1.1170664   0.5019886  -0.6389477  -0.0949841  -0.16149887
   0.          0.        ]]. Action = [[0.44948745 0.80609727]]. Reward = [-0.20748101]
Abstract state at timestep 1881 is 3
State prediction error at timestep 1881 is 0.012
Human Feedback received at timestpe 1881 of 10
Current timestep = 1882. State = [[ 0.13044901  1.1021011   0.49363843 -0.6655408  -0.10139171 -0.12815228
   0.          0.        ]]. Action = [[-0.57394516 -0.8833259 ]]. Reward = [-0.8436112]
Abstract state at timestep 1882 is 3
State prediction error at timestep 1882 is 0.012
Human Feedback received at timestpe 1882 of 10
Current timestep = 1883. State = [[ 0.13535547  1.0874312   0.4972307  -0.6524603  -0.10791819 -0.13052966
   0.          0.        ]]. Action = [[ 0.40354073 -0.46496332]]. Reward = [1.3636378]
Abstract state at timestep 1883 is 3
State prediction error at timestep 1883 is 0.012
Human Feedback received at timestpe 1883 of 10
Current timestep = 1884. State = [[ 0.14033404  1.0721581   0.5062479  -0.67943853 -0.11625255 -0.16668703
   0.          0.        ]]. Action = [[-0.2508176  0.8452004]]. Reward = [-2.1041045]
Abstract state at timestep 1884 is 3
State prediction error at timestep 1884 is 0.012
Human Feedback received at timestpe 1884 of 10
Current timestep = 1885. State = [[ 0.1452466   1.0570931   0.5002272  -0.6702758  -0.12517919 -0.17853247
   0.          0.        ]]. Action = [[ 0.61700654 -0.29688525]]. Reward = [1.3870294]
Abstract state at timestep 1885 is 3
State prediction error at timestep 1885 is 0.012
Human Feedback received at timestpe 1885 of 10
Current timestep = 1886. State = [[ 0.15029593  1.0425301   0.51562    -0.6481889  -0.13582666 -0.2129494
   0.          0.        ]]. Action = [[0.74629927 0.84278464]]. Reward = [0.8297789]
Abstract state at timestep 1886 is 3
State prediction error at timestep 1886 is 0.012
Human Feedback received at timestpe 1886 of 10
Current timestep = 1887. State = [[ 0.15540972  1.0273645   0.52367944 -0.67519087 -0.14809015 -0.2452697
   0.          0.        ]]. Action = [[-0.6863949  0.7790005]]. Reward = [-2.4454966]
Abstract state at timestep 1887 is 3
State prediction error at timestep 1887 is 0.012
Human Feedback received at timestpe 1887 of 10
Current timestep = 1888. State = [[ 0.16072407  1.0123312   0.54312325 -0.6693505  -0.15976892 -0.23357527
   0.          0.        ]]. Action = [[0.6055851  0.11791515]]. Reward = [-0.7555044]
Abstract state at timestep 1888 is 3
State prediction error at timestep 1888 is 0.012
Human Feedback received at timestpe 1888 of 10
Current timestep = 1889. State = [[ 0.16606407  0.99749726  0.5478002  -0.660828   -0.173581   -0.27624142
   0.          0.        ]]. Action = [[0.6802125  0.97877383]]. Reward = [0.0782418]
Abstract state at timestep 1889 is 3
State prediction error at timestep 1889 is 0.012
Human Feedback received at timestpe 1889 of 10
Current timestep = 1890. State = [[ 0.17140445  0.98206574  0.54779613 -0.68751043 -0.1873929  -0.27623782
   0.          0.        ]]. Action = [[-0.12356609 -0.24397528]]. Reward = [-2.0201995]
Abstract state at timestep 1890 is 4
State prediction error at timestep 1890 is 0.012
Human Feedback received at timestpe 1890 of 10
Current timestep = 1891. State = [[ 0.17688008  0.9671638   0.56132543 -0.66410625 -0.2012379  -0.27690002
   0.          0.        ]]. Action = [[ 0.480834   -0.45056152]]. Reward = [0.7149292]
Abstract state at timestep 1891 is 4
State prediction error at timestep 1891 is 0.012
Human Feedback received at timestpe 1891 of 10
Current timestep = 1892. State = [[ 0.18239078  0.95224804  0.5649922  -0.66488355 -0.21528475 -0.28093657
   0.          0.        ]]. Action = [[ 0.15614808 -0.20967287]]. Reward = [-0.5097594]
Abstract state at timestep 1892 is 4
State prediction error at timestep 1892 is 0.012
Human Feedback received at timestpe 1892 of 10
Current timestep = 1893. State = [[ 0.18797159  0.93671465  0.57375586 -0.69273525 -0.23114125 -0.31713006
   0.          0.        ]]. Action = [[-0.39623725  0.8735049 ]]. Reward = [-2.8919687]
Abstract state at timestep 1893 is 4
State prediction error at timestep 1893 is 0.012
Human Feedback received at timestpe 1893 of 10
Current timestep = 1894. State = [[ 0.19358787  0.9209453   0.5753846  -0.70307994 -0.24511231 -0.27942115
   0.          0.        ]]. Action = [[ 0.19184303 -0.93188727]]. Reward = [-1.0743158]
Abstract state at timestep 1894 is 4
State prediction error at timestep 1894 is 0.012
Human Feedback received at timestpe 1894 of 10
Current timestep = 1895. State = [[ 0.19920464  0.9045784   0.57537884 -0.7297624  -0.25908318 -0.27941734
   0.          0.        ]]. Action = [[-0.5782218 -0.3469535]]. Reward = [-1.9951029]
Abstract state at timestep 1895 is 4
State prediction error at timestep 1895 is 0.012
Human Feedback received at timestpe 1895 of 10
Current timestep = 1896. State = [[ 0.20500107  0.88797784  0.5927933  -0.74018395 -0.27253965 -0.26912922
   0.          0.        ]]. Action = [[0.4498086 0.1954329]]. Reward = [-1.9705875]
Abstract state at timestep 1896 is 4
State prediction error at timestep 1896 is 0.012
Human Feedback received at timestpe 1896 of 10
Current timestep = 1897. State = [[ 0.21080208  0.8714818   0.5937551  -0.73576236 -0.2865598  -0.28040272
   0.          0.        ]]. Action = [[ 0.9798677  -0.02904272]]. Reward = [0.05730111]
Abstract state at timestep 1897 is 4
State prediction error at timestep 1897 is 0.012
Human Feedback received at timestpe 1897 of 10
Current timestep = 1898. State = [[ 0.21660367  0.8543883   0.5937482  -0.76244473 -0.30057973 -0.28039894
   0.          0.        ]]. Action = [[-0.4869395  0.3177086]]. Reward = [-1.9728043]
Abstract state at timestep 1898 is 4
State prediction error at timestep 1898 is 0.012
Human Feedback received at timestpe 1898 of 10
Current timestep = 1899. State = [[ 0.22240563  0.8366973   0.59374106 -0.7891272  -0.31459948 -0.28039512
   0.          0.        ]]. Action = [[-0.72677505 -0.28634965]]. Reward = [-1.9538224]
Abstract state at timestep 1899 is 4
State prediction error at timestep 1899 is 0.012
Human Feedback received at timestpe 1899 of 10
Current timestep = 1900. State = [[ 0.22831354  0.8190662   0.60441583 -0.7866275  -0.32878304 -0.28367105
   0.          0.        ]]. Action = [[0.3578683  0.10713518]]. Reward = [-0.523162]
Abstract state at timestep 1900 is 4
State prediction error at timestep 1900 is 0.012
Human Feedback received at timestpe 1900 of 10
Current timestep = 1901. State = [[ 0.23427172  0.801179    0.60788375 -0.7977807  -0.3413938  -0.25221527
   0.          0.        ]]. Action = [[ 0.26939273 -0.7555905 ]]. Reward = [-1.0142661]
Abstract state at timestep 1901 is 4
State prediction error at timestep 1901 is 0.012
Human Feedback received at timestpe 1901 of 10
Current timestep = 1902. State = [[ 0.24038915  0.7835219   0.6250153  -0.7879727  -0.3553358  -0.2788401
   0.          0.        ]]. Action = [[0.8200313  0.54431987]]. Reward = [-0.44484663]
Abstract state at timestep 1902 is 4
State prediction error at timestep 1902 is 0.012
Human Feedback received at timestpe 1902 of 10
Current timestep = 1903. State = [[ 0.24655132  0.76524657  0.63056964 -0.81586134 -0.37048057 -0.302895
   0.          0.        ]]. Action = [[-0.17793357  0.6757114 ]]. Reward = [-2.5145173]
Abstract state at timestep 1903 is 4
State prediction error at timestep 1903 is 0.012
Human Feedback received at timestpe 1903 of 10
Current timestep = 1904. State = [[ 0.25265056  0.74640816  0.6225234  -0.8405801  -0.38385612 -0.26751098
   0.          0.        ]]. Action = [[-0.74243724 -0.91587114]]. Reward = [-1.2533311]
Abstract state at timestep 1904 is 4
State prediction error at timestep 1904 is 0.012
Human Feedback received at timestpe 1904 of 10
Current timestep = 1905. State = [[ 0.25879353  0.72694045  0.6280333  -0.8689917  -0.39850125 -0.29290277
   0.          0.        ]]. Action = [[-0.7694933  0.6195617]]. Reward = [-2.4638693]
Abstract state at timestep 1905 is 4
State prediction error at timestep 1905 is 0.012
Human Feedback received at timestpe 1905 of 10
Current timestep = 1906. State = [[ 0.2649374   0.7068757   0.628023   -0.8956748  -0.41314614 -0.29289845
   0.          0.        ]]. Action = [[-0.69370997  0.03817785]]. Reward = [-1.9638759]
Abstract state at timestep 1906 is 4
State prediction error at timestep 1906 is 0.012
Human Feedback received at timestpe 1906 of 10
Current timestep = 1907. State = [[ 0.27150506  0.6873572   0.66996455 -0.87140864 -0.42741454 -0.28536808
   0.          0.        ]]. Action = [[ 0.661963   -0.21495974]]. Reward = [-0.6174505]
Abstract state at timestep 1907 is 4
State prediction error at timestep 1907 is 0.012
Human Feedback received at timestpe 1907 of 10
Current timestep = 1908. State = [[ 0.2782999   0.66785103  0.6942435  -0.87151355 -0.44348168 -0.32134277
   0.          0.        ]]. Action = [[0.10909176 0.86594534]]. Reward = [-1.7516978]
Abstract state at timestep 1908 is 4
State prediction error at timestep 1908 is 0.012
Human Feedback received at timestpe 1908 of 10
Current timestep = 1909. State = [[ 0.2850956   0.64774793  0.6942298  -0.8981999  -0.4595485  -0.32133707
   0.          0.        ]]. Action = [[-0.7451959   0.38285136]]. Reward = [-2.1249497]
Abstract state at timestep 1909 is 4
State prediction error at timestep 1909 is 0.012
Human Feedback received at timestpe 1909 of 10
Current timestep = 1910. State = [[ 0.29207534  0.6274821   0.71236694 -0.9055317  -0.47545016 -0.31803364
   0.          0.        ]]. Action = [[ 0.02540863 -0.05071986]]. Reward = [-1.8790668]
Abstract state at timestep 1910 is 4
State prediction error at timestep 1910 is 0.012
Human Feedback received at timestpe 1910 of 10
Current timestep = 1911. State = [[ 0.2990058   0.60665655  0.70595944 -0.93008673 -0.48984486 -0.28789458
   0.          0.        ]]. Action = [[-0.51531714 -0.7048568 ]]. Reward = [-1.433062]
Abstract state at timestep 1911 is 4
State prediction error at timestep 1911 is 0.012
Human Feedback received at timestpe 1911 of 10
Current timestep = 1912. State = [[ 0.3062047   0.5860432   0.73279375 -0.92080617 -0.50432086 -0.28952053
   0.          0.        ]]. Action = [[ 0.3166268  -0.01978427]]. Reward = [-1.0468262]
Abstract state at timestep 1912 is 4
State prediction error at timestep 1912 is 0.012
Human Feedback received at timestpe 1912 of -10
Current timestep = 1913. State = [[ 0.31344613  0.56480193  0.7380327  -0.9492456  -0.5200381  -0.31434485
   0.          0.        ]]. Action = [[-0.7150361   0.51603174]]. Reward = [-2.619585]
Abstract state at timestep 1913 is 7
State prediction error at timestep 1913 is 0.012
Human Feedback received at timestpe 1913 of -10
Current timestep = 1914. State = [[ 0.32119027  0.5438858   0.78991985 -0.93563163 -0.5377515  -0.35426787
   0.          0.        ]]. Action = [[0.7444104 0.9782951]]. Reward = [-2.8413777]
Abstract state at timestep 1914 is 7
State prediction error at timestep 1914 is 0.012
Human Feedback received at timestpe 1914 of -10
Current timestep = 1915. State = [[ 0.3293315   0.5235204   0.83093804 -0.91194916 -0.5571797  -0.38856345
   0.          0.        ]]. Action = [[0.90050435 0.6951506 ]]. Reward = [-1.8581496]
Abstract state at timestep 1915 is 7
State prediction error at timestep 1915 is 0.012
Human Feedback received at timestpe 1915 of -10
Current timestep = 1916. State = [[ 0.3378107   0.5034571   0.8646563  -0.89879066 -0.5767509  -0.39142513
   0.          0.        ]]. Action = [[0.8405429  0.00963807]]. Reward = [-2.35686]
Abstract state at timestep 1916 is 7
State prediction error at timestep 1916 is 0.012
Human Feedback received at timestpe 1916 of -10
Current timestep = 1917. State = [[ 0.34669152  0.48336297  0.905296   -0.90069234 -0.5971552  -0.40808767
   0.          0.        ]]. Action = [[0.63562536 0.50041604]]. Reward = [-4.1411853]
Abstract state at timestep 1917 is 7
State prediction error at timestep 1917 is 0.012
Human Feedback received at timestpe 1917 of -10
Current timestep = 1918. State = [[ 0.3558751   0.4630729   0.93496454 -0.9094549  -0.617101   -0.39891428
   0.          0.        ]]. Action = [[ 0.6241379 -0.2273578]]. Reward = [-3.886092]
Abstract state at timestep 1918 is 8
State prediction error at timestep 1918 is 0.012
Human Feedback received at timestpe 1918 of -10
Current timestep = 1919. State = [[ 0.36530715  0.44271672  0.9595979  -0.9126141  -0.6370611  -0.39920157
   0.          0.        ]]. Action = [[0.69575095 0.04101753]]. Reward = [-3.2399576]
Abstract state at timestep 1919 is 8
State prediction error at timestep 1919 is 0.012
Human Feedback received at timestpe 1919 of -10
Current timestep = 1920. State = [[ 0.37527305  0.4224038   1.0139973  -0.9115587  -0.6585909  -0.43059626
   0.          0.        ]]. Action = [[0.84411573 0.8152579 ]]. Reward = [-5.482031]
Abstract state at timestep 1920 is 8
State prediction error at timestep 1920 is 0.012
Human Feedback received at timestpe 1920 of -10
Current timestep = 1921. State = [[ 0.38520497  0.4015368   1.0093031  -0.9358873  -0.6788346  -0.40487394
   0.          0.        ]]. Action = [[-0.6698299 -0.523966 ]]. Reward = [-2.474235]
Abstract state at timestep 1921 is 8
State prediction error at timestep 1921 is 0.012
Human Feedback received at timestpe 1921 of -10
Current timestep = 1922. State = [[ 0.3952362   0.3803934   1.020376   -0.94917953 -0.7009023  -0.44135356
   0.          0.        ]]. Action = [[0.20615399 0.7920699 ]]. Reward = [-3.339669]
Abstract state at timestep 1922 is 8
State prediction error at timestep 1922 is 0.012
Human Feedback received at timestpe 1922 of -10
Current timestep = 1923. State = [[ 0.4056488   0.35955235  1.0568717  -0.93520874 -0.72120523 -0.40605918
   0.          0.        ]]. Action = [[ 0.3728435 -0.8064507]]. Reward = [-3.3753088]
Abstract state at timestep 1923 is 8
State prediction error at timestep 1923 is 0.012
Human Feedback received at timestpe 1923 of -10
Current timestep = 1924. State = [[ 0.41601172  0.33819354  1.0500062  -0.95745575 -0.7393712  -0.36331922
   0.          0.        ]]. Action = [[-0.4263875 -0.7917876]]. Reward = [-2.2238019]
Abstract state at timestep 1924 is 8
State prediction error at timestep 1924 is 0.012
Human Feedback received at timestpe 1924 of -10
Current timestep = 1925. State = [[ 0.42669153  0.31649745  1.0810869  -0.9723618  -0.75699884 -0.35255343
   0.          0.        ]]. Action = [[ 0.60463476 -0.21784282]]. Reward = [-4.8202653]
Abstract state at timestep 1925 is 8
State prediction error at timestep 1925 is 0.012
Human Feedback received at timestpe 1925 of -10
Current timestep = 1926. State = [[ 0.4373333   0.29425114  1.0760038  -0.9962848  -0.77317387 -0.32350048
   0.          0.        ]]. Action = [[-0.01974761 -0.68828124]]. Reward = [-2.4603298]
Abstract state at timestep 1926 is 8
State prediction error at timestep 1926 is 0.012
Human Feedback received at timestpe 1926 of -10
Current timestep = 1927. State = [[ 0.44846392  0.2721714   1.124728   -0.9890219  -0.7893806  -0.32413617
   0.          0.        ]]. Action = [[ 0.9341246  -0.13169128]]. Reward = [-4.7902]
Abstract state at timestep 1927 is 8
State prediction error at timestep 1927 is 0.012
Human Feedback received at timestpe 1927 of -10
Current timestep = 1928. State = [[ 0.45962077  0.2494591   1.1278598  -1.0177461  -0.8065795  -0.34397674
   0.          0.        ]]. Action = [[-0.15022051  0.53944874]]. Reward = [-3.716753]
Abstract state at timestep 1928 is 8
State prediction error at timestep 1928 is 0.012
Human Feedback received at timestpe 1928 of -10
Current timestep = 1929. State = [[ 0.47140798  0.22678621  1.1919181  -1.017028   -0.8255871  -0.38015193
   0.          0.        ]]. Action = [[0.82520986 0.84701204]]. Reward = [-6.9847717]
Abstract state at timestep 1929 is 8
State prediction error at timestep 1929 is 0.012
Human Feedback received at timestpe 1929 of -10
Current timestep = 1930. State = [[ 0.48374844  0.20405975  1.2466388  -1.0193179  -0.8440971  -0.37019953
   0.          0.        ]]. Action = [[0.98992777 0.33483064]]. Reward = [-6.6865854]
Abstract state at timestep 1930 is 8
State prediction error at timestep 1930 is 0.012
Human Feedback received at timestpe 1930 of -10
Current timestep = 1931. State = [[ 0.49674958  0.18158677  1.3139398  -1.0093662  -0.8648575  -0.41520858
   0.          0.        ]]. Action = [[0.7657875  0.96536326]]. Reward = [-7.413699]
Abstract state at timestep 1931 is 8
State prediction error at timestep 1931 is 0.012
Human Feedback received at timestpe 1931 of -10
Current timestep = 1932. State = [[ 0.51028097  0.15923347  1.3666965  -1.0042864  -0.8857144  -0.4171378
   0.          0.        ]]. Action = [[0.7116457  0.37466872]]. Reward = [-6.820223]
Abstract state at timestep 1932 is 8
State prediction error at timestep 1932 is 0.012
Human Feedback received at timestpe 1932 of -10
Current timestep = 1933. State = [[ 0.5246194   0.13708629  1.4467815  -0.995076   -0.9061332  -0.40837568
   0.          0.        ]]. Action = [[0.94305086 0.1969577 ]]. Reward = [-9.09571]
Abstract state at timestep 1933 is 8
State prediction error at timestep 1933 is 0.012
Human Feedback received at timestpe 1933 of -10
Current timestep = 1934. State = [[ 0.53926593  0.11497744  1.4765561  -0.9929322  -0.9254035  -0.3854064
   0.          0.        ]]. Action = [[ 0.49902344 -0.58274966]]. Reward = [-5.4261084]
Abstract state at timestep 1934 is 8
State prediction error at timestep 1934 is 0.012
Human Feedback received at timestpe 1934 of -10
Current timestep = 1935. State = [[ 0.5542289   0.09265374  1.5089695  -1.0036044  -0.9464611  -0.42115098
   0.          0.        ]]. Action = [[0.1456747  0.75828576]]. Reward = [-6.641337]
Abstract state at timestep 1935 is 8
State prediction error at timestep 1935 is 0.012
Human Feedback received at timestpe 1935 of -10
Current timestep = 1936. State = [[ 0.56922406  0.06968208  1.5126071  -1.0333333  -0.96888006 -0.44838008
   0.          0.        ]]. Action = [[-0.4811747  0.6874769]]. Reward = [-5.381181]
Abstract state at timestep 1936 is 8
State prediction error at timestep 1936 is 0.012
Human Feedback received at timestpe 1936 of -10
Current timestep = 1937. State = [[ 0.58424675  0.04606298  1.5156449  -1.0630316  -0.99258447 -0.47408825
   0.          0.        ]]. Action = [[-0.9766384  0.5653417]]. Reward = [-5.586172]
Abstract state at timestep 1937 is 8
State prediction error at timestep 1937 is 0.012
Human Feedback received at timestpe 1937 of -10
Current timestep = 1938. State = [[ 0.5996275  0.0223235  1.5511819 -1.0687774 -1.0166204 -0.4807182
   0.         0.       ]]. Action = [[ 0.9725779 -0.4575193]]. Reward = [-7.343703]
Abstract state at timestep 1938 is 8
State prediction error at timestep 1938 is 0.012
Human Feedback received at timestpe 1938 of -10
Current timestep = 1939. State = [[ 0.61535585 -0.00187046  1.5851994  -1.0889114  -1.0401907  -0.47140795
   0.          0.        ]]. Action = [[ 0.9416206  -0.12988919]]. Reward = [-8.123601]
Abstract state at timestep 1939 is 8
State prediction error at timestep 1939 is 0.012
Human Feedback received at timestpe 1939 of -10
Current timestep = 1940. State = [[ 0.63108844 -0.02666068  1.5851396  -1.1156021  -1.0637602  -0.47138995
   0.          0.        ]]. Action = [[-0.60896075  0.16329896]]. Reward = [-5.505055]
Abstract state at timestep 1940 is 8
State prediction error at timestep 1940 is 0.012
Human Feedback received at timestpe 1940 of -10
Current timestep = 1941. State = [[ 0.64707965 -0.05179169  1.6095715  -1.1297933  -1.0854212  -0.4332203
   0.          0.        ]]. Action = [[ 0.00661409 -0.80751985]]. Reward = [-6.905972]
Abstract state at timestep 1941 is 8
State prediction error at timestep 1941 is 0.012
Human Feedback received at timestpe 1941 of -10
Current timestep = 1942. State = [[ 0.66309583 -0.07757702  1.6122916  -1.1598566  -1.1084683  -0.4609409
   0.          0.        ]]. Action = [[-0.14479917  0.5521802 ]]. Reward = [-6.1314]
Abstract state at timestep 1942 is 8
State prediction error at timestep 1942 is 0.012
Human Feedback received at timestpe 1942 of -10
Current timestep = 1943. State = [[ 0.6791382  -0.10403615  1.6152141  -1.191057   -1.1333057  -0.49675098
   0.          0.        ]]. Action = [[-0.15861619  0.8585055 ]]. Reward = [-6.5268874]
Abstract state at timestep 1943 is 8
State prediction error at timestep 1943 is 0.012
Human Feedback received at timestpe 1943 of -10
Current timestep = 1944. State = [[ 0.6958288  -0.13095298  1.680364   -1.2129338  -1.1603367  -0.5406211
   0.          0.        ]]. Action = [[0.17191112 0.8940655 ]]. Reward = [-11.556667]
Abstract state at timestep 1944 is 8
State prediction error at timestep 1944 is 0.012
Human Feedback received at timestpe 1944 of -10
Current timestep = 1945. State = [[ 0.71295625 -0.15812351  1.723444   -1.2245122  -1.1875389  -0.54404354
   0.          0.        ]]. Action = [[ 0.39517403 -0.01785398]]. Reward = [-9.329778]
Abstract state at timestep 1945 is 8
State prediction error at timestep 1945 is 0.012
Human Feedback received at timestpe 1945 of -10
Current timestep = 1946. State = [[ 0.7306503  -0.18544546  1.7795     -1.2316213  -1.2150422  -0.550068
   0.          0.        ]]. Action = [[0.634846   0.18962014]]. Reward = [-10.347019]
Abstract state at timestep 1946 is 8
State prediction error at timestep 1946 is 0.012
Human Feedback received at timestpe 1946 of -10
Current timestep = 1947. State = [[ 0.7490513  -0.21319613  1.8489071  -1.2497243  -1.2407792  -0.5147374
   0.          0.        ]]. Action = [[ 0.94528365 -0.5259989 ]]. Reward = [-12.130569]
Abstract state at timestep 1947 is 8
State prediction error at timestep 1947 is 0.012
Human Feedback received at timestpe 1947 of -10
Current timestep = 1948. State = [[ 0.767717  -0.241389   1.8747597 -1.2695649 -1.2665782 -0.5159808
   0.         0.       ]]. Action = [[0.13595486 0.36080372]]. Reward = [-8.600457]
Abstract state at timestep 1948 is 8
State prediction error at timestep 1948 is 0.012
Human Feedback received at timestpe 1948 of -10
Current timestep = 1949. State = [[ 0.7863884 -0.2701792  1.8746802 -1.2962489 -1.292376  -0.5159571
   0.         0.       ]]. Action = [[-0.5629919   0.20189917]]. Reward = [-6.7536473]
